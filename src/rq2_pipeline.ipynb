{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def _slugify(name: str, maxlen: int = 120) -> str:\n",
    "    s = name.lower()\n",
    "    s = re.sub(r\"[^\\w\\s-]+\", \"\", s)      # remove punctuation except _ and -\n",
    "    s = re.sub(r\"\\s+\", \"-\", s).strip(\"-\")# spaces -> dashes\n",
    "    s = re.sub(r\"-{2,}\", \"-\", s)         # collapse dashes\n",
    "    return s[:maxlen]\n",
    "\n",
    "def _find_year(p: Path):\n",
    "    m = re.search(r\"(19|20)\\d{2}\", str(p))\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def convert_pdfs_to_txt(folder_path: str,\n",
    "                        dest_root: str = \"data/raw\",\n",
    "                        recursive: bool = True,\n",
    "                        overwrite: bool = False):\n",
    "    \"\"\"\n",
    "    Convert PDFs in folder_path to TXT using PyPDF2.\n",
    "\n",
    "    Saves to: DEST/<year>/<year>_<slug>.txt\n",
    "    - year is inferred from any 4-digit 19xx/20xx in the path or filename.\n",
    "    - if not found, falls back to DEST/unknown_year/<slug>.txt\n",
    "    \"\"\"\n",
    "    src = Path(folder_path).expanduser().resolve()\n",
    "    dest = Path(dest_root).expanduser().resolve()\n",
    "    pdf_iter = src.rglob(\"*.pdf\") if recursive else src.glob(\"*.pdf\")\n",
    "\n",
    "    found = False\n",
    "    for pdf_file in pdf_iter:\n",
    "        found = True\n",
    "        year = _find_year(pdf_file) or \"unknown_year\"\n",
    "        slug = _slugify(pdf_file.stem)\n",
    "        out_dir = dest / str(year)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_txt = out_dir / f\"{year}_{slug}.txt\" if isinstance(year, int) else out_dir / f\"{slug}.txt\"\n",
    "\n",
    "        if out_txt.exists() and not overwrite:\n",
    "            print(f\"Skipping (exists): {out_txt}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            reader = PdfReader(str(pdf_file))\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "\n",
    "            out_txt.write_text(text, encoding=\"utf-8\")\n",
    "            print(f\"Converted: {pdf_file}  ‚Üí  {out_txt}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {pdf_file}: {e}\")\n",
    "\n",
    "    if not found:\n",
    "        print(\"No PDF files found.\")\n",
    "\n",
    "# üü¢ Change this to your bucket path\n",
    "folder_path = \"research/bucket2/2024-2025\"\n",
    "\n",
    "# Example run (recursive scan, write to data/raw/<year>/...)\n",
    "convert_pdfs_to_txt(folder_path, dest_root=\"data/raw2\", recursive=True, overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import regex as re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Only needs to run once per environment\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "INPUT_FOLDER = Path(\"data/raw2/2024\")\n",
    "OUTPUT_FOLDER = Path(\"data/cleaned2/2024\")\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "TOO_SHORT_LOG = OUTPUT_FOLDER.parent / \"too_short.log\"\n",
    "MIN_CHARS = 500  # log anything shorter after cleaning\n",
    "\n",
    "SECTION_RE = re.compile(r'\\b(references|bibliography|acknowledgements|acknowledgments)\\b', re.I)\n",
    "\n",
    "def undo_hyphenation(text: str) -> str:\n",
    "    # \"word-\\nword\" -> \"wordword\"\n",
    "    return re.sub(r'(?<=\\w)-\\s*\\n\\s*(?=\\w)', '', text)\n",
    "\n",
    "def strip_bullets(line_block: str) -> str:\n",
    "    # remove bullets at start of lines (‚Ä¢, *, -, ‚Äì)\n",
    "    return re.sub(r'(?m)^\\s*[‚Ä¢\\*\\-\\u2013]\\s+', '', line_block)\n",
    "\n",
    "def clean_text(raw: str) -> str:\n",
    "    # Normalize unicode (curly quotes, NBSP, ligatures ‚Üí ASCII-friendly forms)\n",
    "    t = unicodedata.normalize('NFKC', raw)\n",
    "\n",
    "    # Early: standardize newlines\n",
    "    t = t.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "    # Undo hyphenated line breaks before removing newlines\n",
    "    t = undo_hyphenation(t)\n",
    "\n",
    "    # Drop everything after references/bibliography/acknowledgements (heuristic)\n",
    "    t = SECTION_RE.split(t)[0]\n",
    "\n",
    "    # Strip bullets at line starts (common in lists)\n",
    "    t = strip_bullets(t)\n",
    "\n",
    "    # Lowercase\n",
    "    t = t.lower()\n",
    "\n",
    "    # Remove URLs/DOIs/arXiv-ish links\n",
    "    t = re.sub(r'(https?://\\S+|www\\.\\S+|doi:\\S+|doi\\s*\\S+)', ' ', t)\n",
    "\n",
    "    # Remove citation brackets like [12], [3,7], (Fig. 2), (Table 3) loosely\n",
    "    t = re.sub(r'\\[[^\\]\\n]{1,50}\\]', ' ', t)  # square-bracket citations\n",
    "    t = re.sub(r'\\(fig\\.\\s*\\d+[a-z]?\\)|\\(table\\s*\\d+[a-z]?\\)', ' ', t, flags=re.I)\n",
    "\n",
    "    # Remove standalone numbers but keep alphanumerics like \"h2o\" or \"e2e\"\n",
    "    t = re.sub(r'(?<!\\w)\\d+(?!\\w)', ' ', t)\n",
    "\n",
    "    # Keep letters, digits embedded in words, spaces, and sentence enders . ! ?\n",
    "    # Also keep brackets for sentence boundaries? We'll remove most symbols but preserve .?! explicitly.\n",
    "    t = re.sub(r\"[^a-z0-9\\s\\.\\!\\?]\", \" \", t)\n",
    "\n",
    "    # Collapse whitespace\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "    return t\n",
    "\n",
    "converted, skipped = 0, 0\n",
    "TOO_SHORT_LOG.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "# Process recursively: **/*.txt\n",
    "for txt_file in INPUT_FOLDER.rglob(\"*.txt\"):\n",
    "    raw = txt_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    cleaned = clean_text(raw)\n",
    "\n",
    "    # Tokenize after cleaning (punkt uses .?!)\n",
    "    sentences = sent_tokenize(cleaned)\n",
    "    words = word_tokenize(cleaned)\n",
    "\n",
    "    # Save as sentence-per-line (good for later sentence-level analysis)\n",
    "    out_path = OUTPUT_FOLDER / txt_file.name\n",
    "    out_path.write_text(\"\\n\".join(sentences), encoding=\"utf-8\")\n",
    "\n",
    "    if len(cleaned) < MIN_CHARS:\n",
    "        with TOO_SHORT_LOG.open(\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(str(txt_file) + \"\\n\")\n",
    "\n",
    "    print(f\"Processed: {txt_file.name} ‚Äî {len(sentences)} sentences, {len(words)} words\")\n",
    "    converted += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Cleaned {converted} files ‚Üí {OUTPUT_FOLDER}\")\n",
    "print(f\"üìù Short/possibly-bad files logged at: {TOO_SHORT_LOG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5fdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RQ2 from cleaned2 windows (TXT inputs) ===\n",
    "from pathlib import Path\n",
    "import re, math\n",
    "from typing import Optional, List, Dict, Set, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy, textstat\n",
    "from scipy.stats import mannwhitneyu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT = Path(\"data/cleaned2\")\n",
    "BASIC_LIST = Path(\"data/resources/basic_english_3000.txt\")\n",
    "OUT_DIR  = Path(\"data/metrics\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGS_DIR = OUT_DIR / \"figs\"; FIGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR = OUT_DIR / \"logs\"; LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# tolerate typo \"20222-2023\"\n",
    "CANDIDATES = {\n",
    "    \"2020-2021\": [ROOT / \"2020\"],\n",
    "    \"2022-2023\": [ROOT / \"2022\"],\n",
    "    \"2024-2025\": [ROOT / \"2024\"],\n",
    "}\n",
    "WINDOWS = {}\n",
    "for label, opts in CANDIDATES.items():\n",
    "    for p in opts:\n",
    "        if p.exists():\n",
    "            WINDOWS[label] = p\n",
    "            break\n",
    "print(\"Windows found:\", WINDOWS)\n",
    "\n",
    "def find_year(path: Path) -> Optional[int]:\n",
    "    m = re.search(r\"(19|20)\\d{2}\", str(path))\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def load_basic(path: Path) -> Set[str]:\n",
    "    words = set()\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        w = line.strip().lower()\n",
    "        if w and not w.startswith(\"#\"):\n",
    "            words.add(w)\n",
    "    if not words:\n",
    "        raise ValueError(f\"No entries found in {path}\")\n",
    "    return words\n",
    "\n",
    "def sentence_is_passive(sent) -> bool:\n",
    "    has_nsubjpass = any(t.dep_ == \"nsubjpass\" for t in sent)\n",
    "    if has_nsubjpass:\n",
    "        return True\n",
    "    has_be_aux = any((t.dep_ in (\"aux\",\"auxpass\")) and (t.lemma_ == \"be\") for t in sent)\n",
    "    has_vbn    = any(t.tag_ == \"VBN\" for t in sent)\n",
    "    return bool(has_be_aux and has_vbn)\n",
    "\n",
    "def fre_fkgl_from_text(text: str) -> Tuple[float,float,int,int,int]:\n",
    "    words = textstat.lexicon_count(text, removepunct=True)\n",
    "    sents = textstat.sentence_count(text)\n",
    "    syls  = textstat.syllable_count(text)\n",
    "    if words == 0 or sents == 0:\n",
    "        return math.nan, math.nan, words, sents, syls\n",
    "    fre  = 206.835 - 1.015*(words/sents) - 84.6*(syls/words)\n",
    "    fkgl = 0.39*(words/sents) + 11.8*(syls/words) - 15.59\n",
    "    return float(fre), float(fkgl), int(words), int(sents), int(syls)\n",
    "\n",
    "def basic_coverage_from_doc(doc, basic: Set[str]) -> float:\n",
    "    uniq = {t.lemma_.lower() for t in doc if t.is_alpha}\n",
    "    return (len(uniq & basic) / len(uniq)) if uniq else math.nan\n",
    "\n",
    "def holm(pvals: List[float]) -> List[float]:\n",
    "    m = len(pvals)\n",
    "    order = np.argsort(pvals)\n",
    "    ps = np.array(pvals)[order]\n",
    "    adj = np.empty(m, float)\n",
    "    running = 0.0\n",
    "    for i in range(m):\n",
    "        val = (m - i) * ps[i]\n",
    "        running = max(running, val)\n",
    "        adj[order[i]] = min(1.0, running)\n",
    "    return adj.tolist()\n",
    "\n",
    "# resources\n",
    "BASIC = load_basic(BASIC_LIST)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])  # tagger/parser/lemmatizer kept\n",
    "\n",
    "MIN_CHARS = 500\n",
    "SHORT_LOG = LOGS_DIR / \"rq2_cleaned2_too_short.log\"\n",
    "SHORT_LOG.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "# compute per paper\n",
    "rows: List[Dict] = []\n",
    "for window, root in WINDOWS.items():\n",
    "    txts = list(root.rglob(\"*.txt\"))\n",
    "    if not txts:\n",
    "        print(f\"‚ÑπÔ∏è No .txt files under {root} ({window})\")\n",
    "        continue\n",
    "    for p in tqdm(txts, desc=f\"Processing {window}\"):\n",
    "        try:\n",
    "            text = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "            if len(text) < MIN_CHARS:\n",
    "                with SHORT_LOG.open(\"a\", encoding=\"utf-8\") as f:\n",
    "                    f.write(str(p) + \"\\n\")\n",
    "\n",
    "            fre, fkgl, wcnt, scnt, sycnt = fre_fkgl_from_text(text)\n",
    "            doc = nlp(text)\n",
    "\n",
    "            sents = list(doc.sents)\n",
    "            total_sents = len(sents)\n",
    "            if total_sents > 0:\n",
    "                passive_ratio = float(sum(sentence_is_passive(s) for s in sents) / total_sents)\n",
    "            else:\n",
    "                passive_ratio = math.nan\n",
    "\n",
    "            basic_cov = basic_coverage_from_doc(doc, BASIC)\n",
    "\n",
    "            rows.append({\n",
    "                \"paper_id\": p.stem, \"path\": str(p), \"year\": find_year(p),\n",
    "                \"rq2_window\": window,\n",
    "                \"fre\": fre, \"fkgl\": fkgl,\n",
    "                \"passive_ratio\": passive_ratio,\n",
    "                \"basic3000_coverage\": basic_cov,\n",
    "                \"words\": wcnt, \"sentences\": scnt, \"syllables\": sycnt,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed {p}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "PER_PAPER = OUT_DIR / \"rq2_metrics_per_paper_from_cleaned2.csv\"\n",
    "df.to_csv(PER_PAPER, index=False)\n",
    "print(f\"‚úÖ Saved per-paper ‚Üí {PER_PAPER}\")\n",
    "print(f\"üìù Short files log ‚Üí {SHORT_LOG}\")\n",
    "\n",
    "# summarize + MWU + boxplots\n",
    "RQ2_ORDER = [\"2020-2021\",\"2022-2023\",\"2024-2025\"]\n",
    "df = df[df[\"rq2_window\"].isin(RQ2_ORDER)].copy()\n",
    "df[\"rq2_window\"] = pd.Categorical(df[\"rq2_window\"], categories=RQ2_ORDER, ordered=True)\n",
    "\n",
    "def summarize_and_test(value_col: str, label: str, stub: str):\n",
    "    summary = (\n",
    "        df.groupby(\"rq2_window\", observed=True)[value_col]\n",
    "          .agg(n=\"count\", mean=\"mean\", median=\"median\")\n",
    "          .reset_index()\n",
    "          .round(4)\n",
    "    )\n",
    "    summary.to_csv(OUT_DIR / f\"rq2_summary_{stub}.csv\", index=False)\n",
    "\n",
    "    pairs = [(\"2020-2021\",\"2022-2023\"), (\"2020-2021\",\"2024-2025\"), (\"2022-2023\",\"2024-2025\")]\n",
    "    rows, pvals = [], []\n",
    "    for a,b in pairs:\n",
    "        A = df.loc[df[\"rq2_window\"]==a, value_col].dropna().to_numpy()\n",
    "        B = df.loc[df[\"rq2_window\"]==b, value_col].dropna().to_numpy()\n",
    "        if len(A)==0 or len(B)==0:\n",
    "            rows.append({\"metric\":label,\"group_A\":a,\"group_B\":b,\"n_A\":len(A),\"n_B\":len(B),\n",
    "                         \"median_A\":np.nan,\"median_B\":np.nan,\"U\":np.nan,\"p\":np.nan,\n",
    "                         \"p_holm\":np.nan,\"effect_size_rbc\":np.nan})\n",
    "            pvals.append(np.nan); continue\n",
    "        U, p = mannwhitneyu(A,B,alternative=\"two-sided\")\n",
    "        rbc = 1 - 2*U/(len(A)*len(B))\n",
    "        rows.append({\"metric\":label,\"group_A\":a,\"group_B\":b,\n",
    "                     \"n_A\":len(A),\"n_B\":len(B),\n",
    "                     \"median_A\":float(np.median(A)),\"median_B\":float(np.median(B)),\n",
    "                     \"U\":float(U),\"p\":float(p),\n",
    "                     \"effect_size_rbc\":float(rbc)})\n",
    "        pvals.append(float(p))\n",
    "\n",
    "    valid = [i for i,p in enumerate(pvals) if not np.isnan(p)]\n",
    "    adj = [np.nan]*len(pvals)\n",
    "    if valid:\n",
    "        adj_vals = holm([pvals[i] for i in valid])\n",
    "        for i,val in zip(valid, adj_vals):\n",
    "            adj[i] = val\n",
    "    for r,a in zip(rows, adj):\n",
    "        r[\"p_holm\"] = a\n",
    "    mwu = pd.DataFrame(rows).round(4)\n",
    "    mwu.to_csv(OUT_DIR / f\"rq2_mwu_{stub}.csv\", index=False)\n",
    "\n",
    "    # boxplot\n",
    "    data = [df.loc[df[\"rq2_window\"]==w, value_col].dropna().to_numpy() for w in RQ2_ORDER]\n",
    "    fig, ax = plt.subplots(figsize=(8,5), dpi=150)\n",
    "    bp = ax.boxplot(data, labels=RQ2_ORDER, showmeans=False, showfliers=False)\n",
    "    ax.set_title(f\"{label} by RQ2 windows\")\n",
    "    ax.set_ylabel(label)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    for i, arr in enumerate(data, start=1):\n",
    "        if len(arr):\n",
    "            med = np.median(arr); n = len(arr)\n",
    "            ax.text(i, bp[\"medians\"][i-1].get_ydata()[0], f\" med={med:.2f}\\n n={n}\", fontsize=9)\n",
    "    for ext in [\"png\",\"svg\"]:\n",
    "        fig.savefig(FIGS_DIR / f\"{stub}_rq2.{ext}\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"‚úÖ {label}: wrote rq2_summary_{stub}.csv, rq2_mwu_{stub}.csv, and figs/{stub}_rq2.(png|svg)\")\n",
    "    return summary, mwu\n",
    "\n",
    "sum_fre,  mwu_fre  = summarize_and_test(\"fre\",                \"FRE\",                \"fre\")\n",
    "sum_fkgl, mwu_fkgl = summarize_and_test(\"fkgl\",               \"FKGL\",               \"fkgl\")\n",
    "sum_pass, mwu_pass = summarize_and_test(\"passive_ratio\",      \"Passive Ratio\",      \"passive\")\n",
    "sum_basic,mwu_basic= summarize_and_test(\"basic3000_coverage\", \"Basic 3k Coverage\",  \"basiccov\")\n",
    "\n",
    "# Combined\n",
    "pd.concat([s.assign(metric=lbl) for s,lbl in [\n",
    "    (sum_fre,\"FRE\"), (sum_fkgl,\"FKGL\"), (sum_pass,\"Passive Ratio\"), (sum_basic,\"Basic 3k Coverage\")\n",
    "]]).to_csv(OUT_DIR / \"rq2_summary_all.csv\", index=False)\n",
    "\n",
    "pd.concat([m for m in [mwu_fre,mwu_fkgl,mwu_pass,mwu_basic]]).to_csv(OUT_DIR / \"rq2_mwu_all.csv\", index=False)\n",
    "\n",
    "print(\"\\nüìÅ Outputs:\", OUT_DIR)\n",
    "print(\"üñºÔ∏è Figures:\", FIGS_DIR)\n",
    "print(\"üìù Short files log:\", SHORT_LOG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "MET = Path(\"data/metrics/rq2_metrics_per_paper_from_cleaned2.csv\")\n",
    "df = pd.read_csv(MET)\n",
    "df = df[df[\"rq2_window\"].isin([\"2020-2021\",\"2022-2023\",\"2024-2025\"])].copy()\n",
    "\n",
    "df[\"wps\"] = df[\"words\"] / df[\"sentences\"].replace(0, np.nan)\n",
    "df[\"spw\"] = df[\"syllables\"] / df[\"words\"].replace(0, np.nan)\n",
    "summary = (df.groupby(\"rq2_window\")[[\"fre\",\"fkgl\",\"wps\",\"spw\"]]\n",
    "             .agg(n=(\"fre\",\"count\"), fre_median=(\"fre\",\"median\"),\n",
    "                  fkgl_median=(\"fkgl\",\"median\"),\n",
    "                  wps_median=(\"wps\",\"median\"),\n",
    "                  spw_median=(\"spw\",\"median\"))\n",
    "             .round(3))\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33822b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crude punctuation per 1000 words, using already-extracted counts\n",
    "punct = (df.assign(punct_per_1k = df[\"sentences\"] / (df[\"words\"]/1000).replace(0,np.nan))\n",
    "           .groupby(\"rq2_window\")[\"punct_per_1k\"].median().round(2))\n",
    "punct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_summary = (df.groupby(\"rq2_window\")[[\"words\",\"sentences\"]]\n",
    "                 .median().rename(columns={\"words\":\"words_median\",\"sentences\":\"sents_median\"}))\n",
    "len_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Passive Voice Ratio (RQ1: 2010‚Äì2014, 2015‚Äì2019, 20205) ===\n",
    "#   - passive_per_paper.csv\n",
    "#   - passive_summary.csv\n",
    "#   - passive_mwu_rq1.csv\n",
    "#   - passive_differences.csv\n",
    "#   - figs/passive_rq1.(png|svg)\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# ---------- paths ----------\n",
    "BUCKETS = {\n",
    "    \"2010-2014\": Path(\"data/cleaned/2010\"),\n",
    "    \"2015-2019\": Path(\"data/cleaned/2015\"),\n",
    "    \"2020-2025\": Path(\"data/cleaned/2020\"),\n",
    "}\n",
    "OUT_DIR  = Path(\"data/metrics\")\n",
    "FIGS_DIR = OUT_DIR / \"figs\"\n",
    "LOGS_DIR = OUT_DIR / \"logs\"\n",
    "for p in [OUT_DIR, FIGS_DIR, LOGS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PER_PAPER_CSV = OUT_DIR / \"passive_per_paper.csv\"\n",
    "SUMMARY_CSV   = OUT_DIR / \"passive_summary.csv\"\n",
    "DIFFS_CSV     = OUT_DIR / \"passive_differences.csv\"\n",
    "MWU_CSV       = OUT_DIR / \"passive_mwu_rq1.csv\"\n",
    "SHORT_LOG     = LOGS_DIR / \"too_short_passive.log\"\n",
    "SHORT_LOG.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "MIN_CHARS = 500  # log short files\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def find_year(path: Path) -> Optional[int]:\n",
    "    m = re.search(r\"(19|20)\\d{2}\", str(path))\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def sentence_is_passive(sent) -> bool:\n",
    "    \"\"\"\n",
    "    Passive if:\n",
    "      - any token has dep_ == 'nsubjpass', OR\n",
    "      - (any aux/auxpass with lemma 'be') AND (any token with tag_ == 'VBN')\n",
    "    \"\"\"\n",
    "    has_nsubjpass = any(t.dep_ == \"nsubjpass\" for t in sent)\n",
    "    if has_nsubjpass:\n",
    "        return True\n",
    "    has_be_aux = any((t.dep_ in (\"aux\",\"auxpass\")) and (t.lemma_ == \"be\") for t in sent)\n",
    "    has_vbn    = any(t.tag_ == \"VBN\" for t in sent)\n",
    "    return bool(has_be_aux and has_vbn)\n",
    "\n",
    "def holm_correction(pvals: List[float]) -> List[float]:\n",
    "    m = len(pvals)\n",
    "    order_idx = np.argsort(pvals)\n",
    "    p_sorted = np.array(pvals)[order_idx]\n",
    "    adj = np.empty(m, dtype=float)\n",
    "    running = 0.0\n",
    "    for i in range(m):\n",
    "        adj_i = (m - i) * p_sorted[i]\n",
    "        running = max(running, adj_i)\n",
    "        adj[order_idx[i]] = min(1.0, running)\n",
    "    return adj.tolist()\n",
    "\n",
    "# Load spaCy (parser on for sents; disable NER for speed)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "\n",
    "# ---------- compute per paper ----------\n",
    "rows: List[Dict] = []\n",
    "for bucket, root in BUCKETS.items():\n",
    "    if not root.exists():\n",
    "        print(f\"‚ö†Ô∏è Missing folder: {root} (skipping {bucket})\")\n",
    "        continue\n",
    "    txts = list(root.rglob(\"*.txt\"))\n",
    "    if not txts:\n",
    "        print(f\"‚ÑπÔ∏è No .txt files under {root}\")\n",
    "        continue\n",
    "\n",
    "    for p in tqdm(txts, desc=f\"Passive ratio {bucket}\"):\n",
    "        try:\n",
    "            text = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "            if len(text) < MIN_CHARS:\n",
    "                with SHORT_LOG.open(\"a\", encoding=\"utf-8\") as f:\n",
    "                    f.write(str(p) + \"\\n\")\n",
    "\n",
    "            doc = nlp(text)\n",
    "            sents = list(doc.sents)\n",
    "            total_sents = len(sents)\n",
    "            passive_ratio = np.nan\n",
    "            if total_sents > 0:\n",
    "                flags = [sentence_is_passive(s) for s in sents]\n",
    "                passive_ratio = float(sum(flags) / total_sents)\n",
    "\n",
    "            rows.append({\n",
    "                \"paper_id\": p.stem,\n",
    "                \"path\": str(p),\n",
    "                \"year\": find_year(p),\n",
    "                \"rq1_bucket\": bucket,\n",
    "                \"passive_ratio\": passive_ratio,\n",
    "                \"total_sentences\": total_sents,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed {p}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(PER_PAPER_CSV, index=False)\n",
    "print(f\"‚úÖ Saved per-paper passive ratios ‚Üí {PER_PAPER_CSV}\")\n",
    "\n",
    "# ---------- summary per bucket (shown on screen) ----------\n",
    "order = [\"2010-2014\",\"2015-2019\",\"2020-2025\"]\n",
    "df[\"rq1_bucket\"] = pd.Categorical(df[\"rq1_bucket\"], categories=order, ordered=True)\n",
    "summary = (\n",
    "    df.groupby(\"rq1_bucket\")[[\"passive_ratio\"]]\n",
    "      .agg(n=(\"passive_ratio\",\"count\"),\n",
    "           mean=(\"passive_ratio\",\"mean\"),\n",
    "           median=(\"passive_ratio\",\"median\"))\n",
    "      .round(4)\n",
    ")\n",
    "summary.to_csv(SUMMARY_CSV, index=False)\n",
    "print(f\"‚úÖ Saved summary ‚Üí {SUMMARY_CSV}\")\n",
    "print(\"\\n=== Passive Voice Ratio (per bucket) ===\")\n",
    "display(summary)\n",
    "\n",
    "# ---------- differences (means) ----------\n",
    "pairs = [(\"2010-2014\",\"2015-2019\"), (\"2010-2014\",\"2020-2025\"), (\"2015-2019\",\"2020-2025\")]\n",
    "diff_rows = []\n",
    "\n",
    "# summary already has rq1_bucket as its index\n",
    "for g1, g2 in pairs:\n",
    "    s1, s2 = summary.loc[g1], summary.loc[g2]\n",
    "    diff_rows.append({\n",
    "        \"comparison\": f\"{g1} vs {g2}\",\n",
    "        \"mean_diff\": float(s1[\"mean\"] - s2[\"mean\"]),\n",
    "        \"median_diff\": float(s1[\"median\"] - s2[\"median\"]),\n",
    "    })\n",
    "\n",
    "diffs = pd.DataFrame(diff_rows).round(4)\n",
    "diffs.to_csv(DIFFS_CSV, index=False)\n",
    "print(f\"\\n‚úÖ Saved differences ‚Üí {DIFFS_CSV}\")\n",
    "print(\"=== Mean/Median Differences (g1 - g2) ===\")\n",
    "display(diffs)\n",
    "\n",
    "\n",
    "# ---------- Mann‚ÄìWhitney U with Holm correction ----------\n",
    "rows_stats = []\n",
    "for metric in [\"passive_ratio\"]:\n",
    "    pvals = []\n",
    "    tmp = []\n",
    "    for g1, g2 in pairs:\n",
    "        A = df.loc[df[\"rq1_bucket\"]==g1, metric].dropna().to_numpy()\n",
    "        B = df.loc[df[\"rq1_bucket\"]==g2, metric].dropna().to_numpy()\n",
    "        if len(A)==0 or len(B)==0:\n",
    "            tmp.append((g1,g2,np.nan,np.nan,np.nan,len(A),len(B),np.nan,np.nan))\n",
    "            pvals.append(np.nan)\n",
    "            continue\n",
    "        U, p = mannwhitneyu(A, B, alternative=\"two-sided\")\n",
    "        rbc = 1.0 - 2.0 * U / (len(A)*len(B))  # rank-biserial effect size\n",
    "        medA, medB = float(np.median(A)), float(np.median(B))\n",
    "        tmp.append((g1,g2,float(U),float(p),float(rbc),len(A),len(B),medA,medB))\n",
    "        pvals.append(float(p))\n",
    "    # Holm within this metric\n",
    "    valid_idx = [i for i,p in enumerate(pvals) if not np.isnan(p)]\n",
    "    adj_all = [np.nan]*len(pvals)\n",
    "    if valid_idx:\n",
    "        adj_vals = holm_correction([pvals[i] for i in valid_idx])\n",
    "        for i, adj in zip(valid_idx, adj_vals):\n",
    "            adj_all[i] = adj\n",
    "    for (g1,g2,U,p,rbc,nA,nB,medA,medB), p_holm in zip(tmp, adj_all):\n",
    "        rows_stats.append({\n",
    "            \"metric\": metric,\n",
    "            \"group_A\": g1, \"group_B\": g2,\n",
    "            \"n_A\": nA, \"n_B\": nB,\n",
    "            \"median_A\": medA, \"median_B\": medB,\n",
    "            \"U\": U, \"p\": p, \"p_holm\": p_holm,\n",
    "            \"effect_size_rbc\": rbc\n",
    "        })\n",
    "\n",
    "mwu_df = pd.DataFrame(rows_stats)\n",
    "mwu_df.to_csv(MWU_CSV, index=False)\n",
    "print(f\"\\n‚úÖ Saved MWU results ‚Üí {MWU_CSV}\")\n",
    "print(\"=== Mann‚ÄìWhitney U (two-sided), Holm-adjusted p-values ===\")\n",
    "display(mwu_df.round(4))\n",
    "\n",
    "# ---------- boxplot ----------\n",
    "def boxplot_passive(df, order, title, fname_stub):\n",
    "    data = [df.loc[df[\"rq1_bucket\"]==b, \"passive_ratio\"].dropna().to_numpy() for b in order]\n",
    "    if all(len(d)==0 for d in data):\n",
    "        print(\"‚ö†Ô∏è No passive_ratio data, skipping plot.\")\n",
    "        return\n",
    "    fig, ax = plt.subplots(figsize=(8,5), dpi=150)\n",
    "    bp = ax.boxplot(data, labels=order, showmeans=False, showfliers=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Passive Voice Ratio\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    # annotate medians & n\n",
    "    for i, arr in enumerate(data, start=1):\n",
    "        if len(arr):\n",
    "            med = np.median(arr); n = len(arr)\n",
    "            ax.text(i, bp[\"medians\"][i-1].get_ydata()[0], f\" med={med:.2f}\\n n={n}\", fontsize=9)\n",
    "    for ext in [\"png\",\"svg\"]:\n",
    "        fig.savefig(FIGS_DIR / f\"{fname_stub}.{ext}\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "boxplot_passive(df, order, \"Passive Voice Ratio by RQ1\", \"passive_rq1\")\n",
    "print(f\"üé® Figure saved in ‚Üí {FIGS_DIR}\")\n",
    "print(f\"üìù Short files logged at ‚Üí {SHORT_LOG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76069ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- differences (means) ----------\n",
    "pairs = [(\"2010-2014\",\"2015-2019\"), (\"2010-2014\",\"2020-2025\"), (\"2015-2019\",\"2020-2025\")]\n",
    "diff_rows = []\n",
    "\n",
    "# summary already has rq1_bucket as its index\n",
    "for g1, g2 in pairs:\n",
    "    s1, s2 = summary.loc[g1], summary.loc[g2]\n",
    "    diff_rows.append({\n",
    "        \"comparison\": f\"{g1} vs {g2}\",\n",
    "        \"mean_diff\": float(s1[\"mean\"] - s2[\"mean\"]),\n",
    "        \"median_diff\": float(s1[\"median\"] - s2[\"median\"]),\n",
    "    })\n",
    "\n",
    "diffs = pd.DataFrame(diff_rows).round(4)\n",
    "diffs.to_csv(DIFFS_CSV, index=False)\n",
    "print(f\"\\n‚úÖ Saved differences ‚Üí {DIFFS_CSV}\")\n",
    "print(\"=== Mean/Median Differences (g1 - g2) ===\")\n",
    "display(diffs)\n",
    "\n",
    "\n",
    "# ---------- Mann‚ÄìWhitney U with Holm correction ----------\n",
    "rows_stats = []\n",
    "for metric in [\"passive_ratio\"]:\n",
    "    pvals = []\n",
    "    tmp = []\n",
    "    for g1, g2 in pairs:\n",
    "        A = df.loc[df[\"rq1_bucket\"]==g1, metric].dropna().to_numpy()\n",
    "        B = df.loc[df[\"rq1_bucket\"]==g2, metric].dropna().to_numpy()\n",
    "        if len(A)==0 or len(B)==0:\n",
    "            tmp.append((g1,g2,np.nan,np.nan,np.nan,len(A),len(B),np.nan,np.nan))\n",
    "            pvals.append(np.nan)\n",
    "            continue\n",
    "        U, p = mannwhitneyu(A, B, alternative=\"two-sided\")\n",
    "        rbc = 1.0 - 2.0 * U / (len(A)*len(B))  # rank-biserial effect size\n",
    "        medA, medB = float(np.median(A)), float(np.median(B))\n",
    "        tmp.append((g1,g2,float(U),float(p),float(rbc),len(A),len(B),medA,medB))\n",
    "        pvals.append(float(p))\n",
    "    # Holm within this metric\n",
    "    valid_idx = [i for i,p in enumerate(pvals) if not np.isnan(p)]\n",
    "    adj_all = [np.nan]*len(pvals)\n",
    "    if valid_idx:\n",
    "        adj_vals = holm_correction([pvals[i] for i in valid_idx])\n",
    "        for i, adj in zip(valid_idx, adj_vals):\n",
    "            adj_all[i] = adj\n",
    "    for (g1,g2,U,p,rbc,nA,nB,medA,medB), p_holm in zip(tmp, adj_all):\n",
    "        rows_stats.append({\n",
    "            \"metric\": metric,\n",
    "            \"group_A\": g1, \"group_B\": g2,\n",
    "            \"n_A\": nA, \"n_B\": nB,\n",
    "            \"median_A\": medA, \"median_B\": medB,\n",
    "            \"U\": U, \"p\": p, \"p_holm\": p_holm,\n",
    "            \"effect_size_rbc\": rbc\n",
    "        })\n",
    "\n",
    "mwu_df = pd.DataFrame(rows_stats)\n",
    "mwu_df.to_csv(MWU_CSV, index=False)\n",
    "print(f\"\\n‚úÖ Saved MWU results ‚Üí {MWU_CSV}\")\n",
    "print(\"=== Mann‚ÄìWhitney U (two-sided), Holm-adjusted p-values ===\")\n",
    "display(mwu_df.round(4))\n",
    "\n",
    "# ---------- boxplot ----------\n",
    "def boxplot_passive(df, order, title, fname_stub):\n",
    "    data = [df.loc[df[\"rq1_bucket\"]==b, \"passive_ratio\"].dropna().to_numpy() for b in order]\n",
    "    if all(len(d)==0 for d in data):\n",
    "        print(\"‚ö†Ô∏è No passive_ratio data, skipping plot.\")\n",
    "        return\n",
    "    fig, ax = plt.subplots(figsize=(8,5), dpi=150)\n",
    "    bp = ax.boxplot(data, labels=order, showmeans=False, showfliers=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Passive Voice Ratio\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    # annotate medians & n\n",
    "    for i, arr in enumerate(data, start=1):\n",
    "        if len(arr):\n",
    "            med = np.median(arr); n = len(arr)\n",
    "            ax.text(i, bp[\"medians\"][i-1].get_ydata()[0], f\" med={med:.2f}\\n n={n}\", fontsize=9)\n",
    "    for ext in [\"png\",\"svg\"]:\n",
    "        fig.savefig(FIGS_DIR / f\"{fname_stub}.{ext}\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "boxplot_passive(df, order, \"Passive Voice Ratio by RQ1\", \"passive_rq1\")\n",
    "print(f\"üé® Figure saved in ‚Üí {FIGS_DIR}\")\n",
    "print(f\"üìù Short files logged at ‚Üí {SHORT_LOG}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
