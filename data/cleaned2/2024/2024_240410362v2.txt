3dgen ai assisted generation of provably correct binary format parsers sarah fakhoury markus kuppe shuvendu k. lahiri tahina ramananandro and nikhil swamy microsoft research redmond usa sfakhoury makuppe shuvendu taramana nswamy microsoft.com abstract improper parsing of attacker controlled input is a leading source of software security vulnerabilities especially when programmers transcribe informal format descriptions in rfcs into efficient parsing logic in low level memory unsafe languages.
several researchers have proposed formal specification languages for data formats from which efficient code can be extracted.
however distilling informal requirements into formal specifications is challenging and despite their benefits new formal languages are hard for people to learn and use.
in this work we present 3dgen a framework that makes use of ai agents to transform mixed informal input including natural language documents i.e.
rfcs and example inputs into format specifications in a language called 3d.
to support humans in understanding and trusting the generated specifications 3dgen uses symbolic methods to also synthesize test inputs that can be validated against an external oracle.
symbolic test generation also helps in distinguishing multiple plausible solutions.
through a process of repeated refinement 3dgen produces a 3d specification that conforms to a test suite and which yields safe efficient provably correct parsing code in c. we have evaluated 3dgen on internet standard formats demonstrating the potential for ai agents to produce formally verified c code at a non trivial scale.
a key enabler is the use of a domain specific language to limit ai outputs to a class for which automated symbolic analysis is tractable.
index terms code generation agentic ai systems trustworthy ai programming i. i ntroduction improper parsing of attacker controlled input is a leading source of software security vulnerabilities 12especially when programmers transcribe informal format descriptions into efficient parsing logic in low level memory unsafe languages.
for example the format of tcp headers is specified in natural language and packet diagrams in the classic rfcs and meanwhile tcpinput.c the tcp header parser in the linux kernel was patched to prevent an out of bounds access in after being in the kernel for nearly years.
in response researchers have proposed languages for describing low level binary message formats backed by code generators that yield parsing and serialization tools e.g.
nail and everparse .
everparse is notable in that it produces formally verified c code from a format description language called 3d guaranteeing memory safety functional correctness and double fetch freedom.. in an ideal world one might hope for specifications to always be written in domain specific languages dsls like 3d yield trustworthy executable code.
however more commonly specifications are not entirely formal and come from a variety of sources ranging from natural language documents diagrams example code snippets sample input output pairs etc.
extracting a formal specification from such a variety of sources requires a significant human effort typically requiring a process that involves learning a new dsl understanding the informal specification expressing one s understanding of the informal specification in the dsl iterating to refine intent revisiting the previous steps to arrive at a desired specification.
this is challenging enough that developers often directly transcribe informal specifications into executable code in general purpose programming languages leaving the door open to low level coding errors that lead to security vulnerabilities.
a.3dgen a framework for ai assisted dsl programming in this work we present dgen a framework that uses ai agents to assist a human in translating an informal specification to executable code via a dsl grounded specifically in generating binary format parsers using 3d.
our framework is agnostic to the ai model used though for our experiments we use gpt4 .
the core of dgenis an automated intent refinement loop which assists a user in constructing a 3d specification that matches an oracle s behavior on a set of test inputs.
figure sketches the high level workflow whose main elements mirror the steps outlined above.
.
teaching a dsl to an agent 3d is a small language whose syntax is based on c s syntax for typedefs structures and unions.
its manual is relatively compact consisting of around lines of text and around examples.
we teach 3dgenabout 3d by giving it access to the manual and the ability to query parts of the manual based on techniques that we describe in iii b. .
digesting informal specifications into 3d a user gathers a collection of informal specifications including natural language documents that describe message formats and sample test inputs and presents it to dgen.
in turn our framework prompts the underlying agents to generate a 3d specification.
.
refining intent the 3d compiler analyzes candidate 3d specifications providing syntax and type errors that we feed back to the agents to repair their code until the produced 3darxiv .10362v2 may 2024fig.
workflow of dgen specifications are at least well defined.
next exploiting the fact that 3d is a small language with a well designed formal semantics we develop dtestgena new symbolic test case generator for 3d.
this allows us to automatically generate new test inputs for candidate specifications and we rely on various external oracles to decide the intended classification of an input.
enriching the input with the new test cases we repeat the loop.
having converged with dgen s help on a given 3d specification the user relies on everparse to generate verified c code that is guaranteed to parse only all messages that are well formed according to the specification.
we evaluate dgenon internet standard formats starting from their specification in rfcs.
while dtestgencan generate tests from candidate specifications we still require oracles to label those tests with their desired outcome specifically we use the wireshark3network packet analyzer to decide if a packet should be accepted or not.
interestingly in cases 3dgendiscovers constraints specified in rfcs that wireshark does not enforce.
additionally for protocol formats we also evaluated dgen s ability to produce 3d specification that match the behavior of prior handwritten specifications for various formats provided as samples by the authors of everparse.
in this setting dgenuncovers cases in which the human authored specifications were incorrect.
that said the specifications dgenproduces are only as good as the tests on which it is evaluated.
in cases dgenproduces specifications that agree with wireshark but dtestgen detects via symbolic differential testing that the generated specification is semantically distinct from a human authored everparse sample the dgen produced specification does not enforce a constraint that it should.
as such we caution that dgenshould not be used to blindly match the behavior of a legacy tool.
instead we envision dgenand its symbolic tools to be used by humans to iteratively refine a natural language document into a formal specification while also a carefully curated test suite.
a key enabler of our technique is the use of an effectively analyzable dsl coupled with a verified code generator as a medium of interaction between a user s informal intent and ai generated output.
in contrast directly prompting ai agents to produce c code from informal specifications would leave open the question of analyzing ad hoc c code for safety and security and with an unclear formal basis against which to assess code correctness.
further targeting a dsl enables us to integrate powerful fully automated tools like symbolic test case generation and differential analysis that are usually intractable for large general purpose languages.
we conjecture that future ai assisted programming techniques might also benefit from the use of effectively analyzable dsls as intermediate languages.
in summary we make the following contributions an architecture for ai assisted programming using dsls coupled with symbolic analysis tools to refine informal user intent into formal specifications grounded in the scenario of binary format parsers.
a new symbolic analysis and test generation tool for the 3d format language integrated in dgen s intent refinement loop.
an evaluation of dgenon a suite of binary format parsers specified in internet standard rfcs yielding safe and secure c code.
ii.
p roblem formulation ramananandro et al.
present everparse a library of parser and serializer combinators in the f programming language.
they prove that every well typed program assembled from their parser combinators produces a parser that is the inverse of the corresponding serializer i.e.
s.parse serialize s some s and b v.parse b some v serialize v b. parsers for formats that satisfy this mutual inverse property are particularly relevant in security critical settings.
everparse combinators are themselves embedded within a fragment of f called low which supports transpilation to c via a tool called karamel.
swamy et al.
present a dsl built on top of everparse combinators called 3d a language similar to c s language of type definitions with typedefs structures and unions.
3d allows users to express a variety of tag length value style formats which are commonly used in many networking protocols and other variable length formats.
internet rfcs often specify tag length value formats in natural language in an ad hoc way.
for example the tcp rfc specifies the format of tcp options as follows there are two cases for the format of an option case a single octet of option kind.
case an octet of option kind an octet of option length and the actual option data octets.
... currently defined options include kind indicated in octal kind length meaning end of option list.
no operation.
maximum segment size.
... maximum segment size max seg size kind length maximum segment size option data bits ... to produce a parser for a tcp option in 3d one starts by specifying the format declaratively.
here s one way to do it defining an option as a structure with two fields a byte field kind with a constraint that restricts its values to and and a payload field of type option of kind kind a type that depends on the value of the kind field.
typedef struct option uint8 kind kind 0x00 kind 0x01 kind 0x02 option of kind kind payload option the type option of kind acasetype in 3d represents a form of union type in c where the parameter kind discriminates the case of the union.
when kind is or the payload is empty and when the kind is the payload has type max seg size .
casetype option of kind uint8 kind switch kind case 0x00 unit case0 unit empty payload case 0x01 unit case1 unit empty payload case 0x02 max seg size case2 option of kind finally the type max seg size is a structure with one byte for the length and bytes for an unsigned bit big endian integer for the maxsegsize .
typedef struct max seg size uint8 length uint16be maxsegsize max seg size from this specification everparse in its simplest mode generates a c program with the following signature a function checkoption which when called with a byte buffer input containing at least length bytes checks that input contains a valid representation of option returning an error code recording success or details about where and why validation failed.
everparse error code checkoption uint8 input uint64 length a 3d user turning an ad hoc description from an rfc to a specification must convince themselves that they have capturedthe intent of the rfc a process that typically involves careful review combined with testing.
while 3d was designed to be used by c programmers and benefits from its resemblance to c the constructs it offers including type dependency value constraints parameterization case analysis etc.
take effort to learn and use correctly.
further while everparse guarantees that the generated c code is memory safe free from bugs that trigger undefined behaviors and faithfully parses exactly the specified format the source specification is still subject to audit.
for example one could easily have specified uint16 maxsegsize forgetting a convention that networking protocols like tcp typically use big endian integers users need assistance in specification testing and validation.
swamy et al.
report that 3d has been used to specify a suite of networking protocols used in production software at microsoft including in the kernel of the windows release.
they report using 3d to specify structs casetypes and enum type definitions in around lines of 3d specifications stating that describing those message formats required careful specification engineering and discovery over a period of months.
with dgen we seek to lower this overhead making 3d accessible to non experts by directly synthesizing specifications from informal intent and to offer systematic testing tools to assist with validation.
iii.
t he3dgenapproach in this section we make precise the workflow in figure showing how we derive a 3d specification from rfcs and tests.
we start by describing the algorithm abstractly parameterized by several non deterministic choices ai based components and a test generator for 3d.
we then describe anagent based implementation of the ai based components and dtestgen a new symbolic test generator for 3d.
a.3dg en an abstract algorithm we assume the 3d dsl is equipped with the following functions 3ds ynchk a syntax and type checker function given a specification pchecks for syntax as well as type constraints imposed by the 3d language.
3de xec an execution function for any 3d specificationpthat satisfies 3ds ynchk p given a packet i 3de xec p i returns true iff the specification paccepts the packet i. concretely we use everparse to compile p to c code and execute it on i.
3ddoc natural language documentation about the 3d language and examples provided as a manual.
algorithm takes as input an rfc document function lblimpl that is used to classify packets as well as a possibly empty seed sets of positive and negative packets i 0and i .
the desired 3d specification pshould accept the positive packets i 0and reject i .
the algorithm returns a set of possible candidate 3d specifications candprogs along with an augmented set of positive i and negative i packets generated by dtestgenand labeled using lblimpl ensuring that every specification in candprogs is consistent with the 3augmented set of packet inputs.
formally i i i i and for each p candprogs 3de xec p i true for each i i and 3de xec p i false for each i i .
the algorithm iterates non deterministically accumulating state which records all relevant information to be fed to an llm in st initialized to the 3ddoc the rfc and the seed tests.
at each iteration it performs one of the following two actions non deterministically i augment candprogs with a new well formed 3d specification pby querying an llm lines or ii augment the labeled packets in i and i using dtestgenand l abel inputs lines .
finally at lines candidates in candprogs that are not consistent with the labeled packets are pruned and any failing candidate test pairs are added to the state line .
to generate a candidate program p at line we query llm with the accumulated state this step is implemented using agents as described in section iii b. if pfails the 3ds ynchk we update the state with the error and retry.
the 3d symbolic test generator dtestgentakes as input a set of well formed candidate programs that satisfy the current i i and outputs new unlabeled packets by symbolically analyzing the programs in candprogs we describe the precise implementation in section iii c. we then use lblimpl to label each packet as positive or negative concretely we use wireshark as an implementation of lblimpl .
details of label inputs is present in section iv c. algorithm 3dg enalgorithm input rfc lblimpl i i output candprogs i i i i i i st 3ddoc rfc i i candprogs for do if then p query llm st se 3ds ynchk p ifse success then st st p se continue end if candprogs candprogs p end if if then i 3dtestgen candprogs i i i i i i label inputs i lblimpl end if forq candprogs do for all i i i do ifw i i 3de xec q i i i 3de xec q i !
then st st q i candprogs candprogs q break end if end for end for end for return candprogs i i b. agent based implementation constructing a prompt for an llm from the diverse information in algorithm s accumulated state is non trivial.
it involves choosing relevant sections of natural language documentations from several pages of rfc 3ddoc relevantexamples failing tests to focus on etc.
composing a single monolithic prompt with all relevant context needed to solve a task is often impossible given the restricted token contextwindow for llms.
instead research shows that llm based agents significantly extend the capabilities of standalone llms by equipping them with the abilities needed to solve tasks in a self directed fashion such as long term planning reasoning conversing with other llms using tools and retrieving information critical to task resolution .
agents demonstrate improved performance and generalization of task resolution abilities for a number of increasingly complex and real world tasks .
furthermore orchestrating multiple agents that are instructed to cooperate together can scale up the capabilities of a single agent by decomposing tasks improving factuality and reasoning and validation .
motivated by these findings we design an agent system based on the autogen multi agent framework.
autogen allows the instantiation of multiple agents each unique in their task description access to tools and inputs and instructed to cooperate together to achieve a solution.
we choose to use a multi agent framework over a single agent to decompose tasks and reduce overall input in the context window shielding other agents from unrelated intermediate reasoning steps involved in distinct task refinement loops.
in the autogen multi agent setup agents converse in a group chat setting critiquing and reflecting on task progress based on conversation history and adapting from feedback.
autogen provides the multiagent conversation framework as a high level abstraction requiring only meta prompts and tool customization from the user.
the agent framework designed for dgenis not reliant on one particular llm however we use gpt4 32k across all experiments.
the dgenmulti agent framework is implemented concretely as three distinct agents planner agent the planner agent is a tool backed agent that orchestrates the multi agent conversation.
in autogen it is instantiated as the group chat manager .
it has access to the meta task prompt descriptions of the other two agents and the ability to invoke tools 3ds ynchk and 3de xec and communicate the results to the other agents.
3d developer agent the 3d developer agent is tasked with generating 3d code based on instructions communicated from the other two agents.
this agent has access to the full 3d language manual 3ddoc a set of task examples and high level tips about generating syntactically correct 3d code.
domain expert agent the domain expert agent is tasked with communicating specifications to the 3d developer agent and critiquing generated 3d code.
it has access to all domain relevant documents needed to solve the problem.
in this work the domain expert agent has access to an rfc the network protocol specification document needed to solve the task and examples of the task.
all three agents communicate via an inter agent group chat 4until one of two termination conditions are met either the output of 3de xec indicates that the generated 3d specification passes on the test set or the maximum number of iterations as set by the user have been completed.
the control flow of task resolution follows the paradigm provided in autogen and is entirely conversation driven i.e.
the participating agents decisions on which agents to send messages to and the procedure of computation are functions of the inter agent conversation.
an example of control flow is as follows the domain expert agent communicates the relevant parts of the rfc specification to the 3d developer agent the 3d agent generates a candidate specification the planner agent makes a call to 3ds ynchkand communicates the result to the group the 3d agent reflects on a syntax error reported by the planner and refines the specification.
one example of the control flow is later shown in figure .
c.3dtestgen symbolic test case generation in this section we discuss our implementation of the 3dtestgensub routine of algorithm .
our test packet generator called dtestgen is implemented as an extension of the everparse toolchain and is grounded in the formal semantics of 3d.
dtestgenencodes 3d programs into the smt lib version language a.k.a.
smt2 relying on smt solver z3 to produce test cases.
given a 3d program p to obtain positive resp.
negative test cases dtestgen encodes the semantics of pto z3 and asks for models of the existential predicate does there exist a sequence of bytes that makes psucceed resp.
fail .
z3 returns with one of the following answers sat z3 finds a model to satisfy predicate including a concrete sequence of bytes that makes the parser succeed resp.
fail unsat the predicate is unsatisfiable which means that palways fails resp.
succeeds unknown z3 times out.
while there may be multiple causes to z3 timeout in our case this happens rarely.
further given two 3d programs p1andp2 3dtestgen can also produce differential test cases by asking z3 to find a sequence of bytes that satisfy p1but not p2.
if z3 returns unsat then there are no such test cases every packet satisfying p1also satisfies p2.
separately we can ask z3 the same satisfiability question but with p1andp2swapped.
if z3 returns unsat for both ways then the 3d programs p1andp2 accept and reject the exact same packets they are semantically equivalent.
we do not bound the size of packets.
the semantics of a 3d program is represented by a pure f function whose simplified signature is a value of type parser t a function of the form input seq byte option t nat which when applied to an input sequence of bytes may fail returning none or succeed with some v n where vis the parsed value of type t and nis the number of bytes of the input that were consumed.
as described in ii everparse provides combinators library functions that allow combining simpler parsers to build morecomplex ones in a correct by construction way.
for example the following 3d program defines a message data format specification as a structure of two unsigned bit integer fields first andsecond where first has a constraint on its value typedef struct message uint8 first first uint8 second message the semantics of that 3d program is modeled in f by the following message parser parse message as an application of the parse paircombinator let parse message parse pair parse refine parse uint8 first first parse uint8 where parse pair defined in everparse has a higher order type parser t1 parser t2 parser t1 t2 .
operationally the code above first checks that the input sequence contains at least one byte then parses the first byte using parse uint8 and reads it into the variable first then advances the position in the input by one byte then checks that first then tries to read and return the next byte.
if any of the checks fail the parser returns none .
otherwise it returns some first second a pair containing the two bytes that were read and 2to indicate that two bytes were consumed.
we would like to encode parse message to z3 but smt2 does not directly support higher order functions like parse pair.
so at the heart of dtestgenis a specialization pass over the 3d parser combinator ast to turn it into a firstorder program.
for starters the smt2 semantics of a 3d program is given in the context of an uninterpreted function input representing the input byte sequence on which the parser operates.
the assertion below constrains z3 to pick models for the input array where every element is a byte in the range .
declare fun input int int assert forall i int and input i input i next we encode a 3d program as an smt2 state transforming function where the state records among other things the remaining size of the input byte sequence remaining input size the number of bytes read so far current pos whether or not the parser has failed has failed and the value they return return value .
we start by showing a simplified encoding of parse uint8 define fun parse uint8 s0 state state if and not has failed s0 remaining input size s0 success state input current pos s0 return value.
incr current pos s0 new position.
decr remaining input size s0 new remaining size.
fail state s0 next we show the encoding of the parse message parser where dtestgenhas inlined the parse pair and parse refine higher order combinators from the 3d ast.
this representation of the parse message is adequate for test case generation.
define fun parse message s0 state state let s1 parse uint8 s0 if has failed s1 s1 if return value s1 parse uint8 s1 fail state s1 given a query such as the following which constrains the initial state init and asserts that message parser parse message does not fail when applied to init z3 can produce models for the input variable and its length in bytes yielding a positive test case to generate a negative test case we would assert instead that has failed parse message init .
since the input byte sequence can be arbitrarily long we do not constrain its initial size.
declare fun init state initial state.
assert and not has failed init current pos init assert not has failed parse message init check sat eval remaining input size init input size from model.
eval input retrieve first input byte.
if z3 returns a model then dtestgencan iteratively query z3 for further distinct models with additional appropriate assertions to avoid duplicates.
however with this encoding z3 generates models that may not cover all possible branches.
our implementation uses a more sophisticated encoding to track which branches of a specification are covered by a given test case allowing us to systematically generate tests that cover all branches up to a user provided branch depth.
we provide more details in the appendix.
leveraging the existing semantics of 3d and its compact structured language of parser combinators our implementation of dtestgentook less than person weeks and around lines of f ocaml and smt2.
iv.
e xperimental setup a. network protocols we evaluate dgenon network protocols specified in ietf standards.
table i lists each protocol and a short description and the specific rfc number.
we include the length of the rfc in pages as a rough measure of complexity though rfcs contain a lot of information beyond the description of the format the number in parenthesis when present shows the number of pages in the rfc concerned with header formats.
b. generating specifications with 3dgen to evaluate dgen s ability to translate natural language specifications into 3d format specifications we use it to generate candidate specifications for the protocols in table i. we deem a generation successful if the produced specification correctly classifies a test set of generated packets labeled by wireshark.
we report a pass metric which counts the number of successful generations out of runs.
to evaluate how well agents in the dgenmulti agent framework are able to understand the natural language specifications contained in the network protocol rfc as well as its ability to learn 3d protocolrfc version length pages description udp user datagram protocol icmpv4 internet control message protocol vxlan virtual extensible local area network ipv6 internet protocol version ipv4 internet protocol version tcp transmission control protocol ethernet ethernet ii frames in vxlan gre generic routing encapsulation igmpv2 internet group managment protocol dhcp dynamic host configuration protocol dccp datagram congestion control protocol arp address resolution protocol ntp network time protocol nbns netbios name service nsh network service header tftp trivial file transfer protocol rtp transport protocol for real time applications ppp point to point protocol tpkt iso transport service on top of tcp ospf internet official protocol standards table i dataset of protocols and corresponding rfcs.
denotes protocols for which there is a human written 3d specification.
page numbers in indicate the length of the extracted rfc.
syntax we explore the number of refinement loops needed to generate a syntax and type correct solution as determined by 3ds ynchkand a semantically correct solution with respect to the test set as determined by 3de xec.
in addition we highlight common mistakes made by the agents as well as several instances where the agent is able to learn constraints from the rfc that are not enforced by the wireshark.
for each protocol we instantiate dgen using gpt 432k as the underlying llm at temperature .
.
we set the number of specifications to generate to and the max number of syntax or packet refinements to per attempt.
if the agents are able to produce a specification that passes before refinements the agent loop is terminated.
we observe that allowing more refinement loops within the dgenagent conversation flow does not always lead to a successful attempt at generating a specification.
on the other hand reducing the number of refinement loops often does not give the agents enough attempts at solving the problem.
this is especially true when the protocol is more complex requiring the agents to produce a longer specification for example in the case of icmp where there are distinct message types for which the agent must generate a 3d specification.
for each protocol we download the rfc from the ietf data tracker4as a text file to provide as input in the 3d developer agent prompt.
in some cases the full rfc is prohibitively long and would exhaust the gpt 32k token window.
since we are only interested in the part of the specification related to the header data format in such cases we manually extract the pages of the rfc related to the data format specification usually labeled in a section called header specification .
the length of the extract pages is denoted in in table i.in the future we plan to explore building a retrieval tool specific to rfc extraction.
6c.
generating a labeled test set for each protocol we build a test suite consisting of a mixture of realworld packet captures and synthetically generated tests by 3dtestgen where we use wireshark to decide if the packet should be considered valid or not.
for each protocol we collected a small number of real world packets from various sources on the internet and retain only those that wireshark considers valid we discard the negative cases since they are sometimes arbitrarily malformed.
for synthetic tests we run one iteration of the dgenloop seeded with the realworld packets.
this produces a single candidate specification on which we run dtestgento generate test cases.
we configure dtestgento fully explore a trace with branch points and observed that while many examples have a large number of branches e.g.
icmp has branches none of them have more than branches.
we then collect at least two examples from each branch point until we reach examples.
this gives us some confidence that the generated test suite is diverse though its completeness is limited by the quality of the specification on which dtestgenis executed.
we then use wireshark to label the tests obtaining both positive and negative test cases.
using wireshark to label packets comes with its own challenges.
for starters wireshark is a protocol analyzer typically used for diagnostics and experimentation and by design does not always enforce all constraints when validating a packet.
wireshark does not implement a dissector for a single rfc but rather for a family of rfcs.
thus a dissector may be more permissive compared to a given rfc perhaps because a related rfc mandates such a behavior our experiments in section v uncover many such unenforced constraints.
to label a test case produced by dtestgen we rely on a wireshark feature called export pdu which allows validating a given packet header without encapsulating it within outer protocol headers.
two exceptions were ethernet which does not require outer encapsulation and tftp which is not supported by export pdu.
we wrapped tftp headers generated by 3dtestgenwith a dummy udp header.
for ethernet ipv4 ipv6 vxlan tcp and udp we also had to generate dummy payloads to prevent wireshark from raising trivial errors.
we also had to disable checksums since this is not enforced at the level of the formats.
as such using wireshark as a labeler for dtestgenoutputs involved a non trivial effort.
d. handwritten 3d specifications the everparse github5repository contains 3d specifications for seven network protocols written by the authors of everparse.
protocols with an existing handwritten 3d specification are marked with a in table i. in section v c we use dtestgento compare the specifications generated by 3dgento the seven handwritten specifications.
we report if any of the specifications produced by dgenare semantically equivalent to the handwritten specifications and otherwise use the generated set of tests to identify the cause s of differences.
r esults a. capabilities of 3dgen in this section we present experimental evidence to answer the following central question underpinning our work rq1 can 3dgen produce format specifications for networks protocols standardized in rfcs?
table ii details results of dgenon our dataset of network protocols we report the pass metric the average number of syntax refinement and packet feedback refinement loops across all attempts.
at a first glance dgenis able to generate a passing specification for protocols with a pass .
for two protocols such as udp and igmp dgengenerates a passing specification in all attempts requiring an average of .
syntax refinements and packet refinements for udp and .
and for igmp respectively.
for the other seven ipv4 dhcp dccp arp ntp nbns and nsh dgen can generate at least one passing specification but is not successful in all attempts.
for the remaining protocols dgenis unable to generate a specification that passes on the test set labeled by wireshark.
we investigate the cause of the errors and find in all cases that dgengenerates a specification that is consistent with the header format described in the rfc but that wireshark labels packets as valid despite there being constraint violations i.e.
wireshark does not fully enforce the rfc.
in some cases wireshark emits a warning about these violations which can be filtered on a case by case basis.
however this is not a straightforward task as some warnings do not impact the data format specification e.g.
wireshark emits a warning when a packet indicates the tcp connection is reset.
besides in most cases a warning is not reported.
using the rfc as a guide two authors manually identified tests that wireshark labels too permissively and corrected the labels.
using these corrected labels we checked if any of the 3dgengenerated specifications already pass on this modified test set or else restart the dgenloop with the corrected tests.
protocols for which dgenis able to generate a specification that passes on the corrected test set are denoted as in table ii dgenis able to generate at least one candidate specification that is consistent with the labels in allcases.
labeler and rfc disagreement we look more closely at examples where wireshark is too permissive table iii details the cause s of disagreement between the wireshark labels and the constraints specified by the rfc in each case.
for example for rtp rfc 35506states that the version field is bits and the version defined by this specification is two .
although the rfc does not indicate a strong constraint that the version field must be set to a large number of negative packets in the rtp test set include version numbers other than .
wireshark labels these packets as acceptable however the dgenagent consistently generates a specification with uint16be version version .
in this case the 7fig.
example of a packet refinement loop by the dgenagent for vxlan rfc agent is unable to learn from feedback about why a test with a different version value should pass because wireshark does not provide any warning.
enforcing this constraint by changing the wireshark label to negative allows the specification to pass all tests.
similarly for tftp rfc 13507states that a tftp header contains a byte opcode field and enumerates possible opcode values.
dgenalways produces a specification constraining the value of the opcode field to one of the values in the rfc.
wireshark does not label packets with other opcode values as malformed.
when we manually label tests with incorrect opcode fields as negative the specification generated by dgenpasses on the test set.
in the case of gre rfc 27848states the version number field must contain the value zero .
however wireshark does not enforce version constraints on gre likely because the for the pptp variant of gre the version field is set to and wireshark uses the same dissector for all gre versions.
in the case of ipv6 the generated specification consistently fails to reject packets labeled as malformed by wireshark.
the ipv6 nextheader field indicates the value of the encapsulated packet however the rfc focuses only on the constraints of a single layer not of any encapsulated packets.
in contrast wireshark validates packet contents across layers and rejects packets that don t encapsulate the next layer correctly.
agent mistakes from table ii we observe that the agents frequently make syntax mistakes despite having access to the language manual for the 3d language.
however given that 3d is not yet a widely used dsl syntax mistakes from a model like gpt are anticipated.
we observe that the agents struggle most with using correct 3d bitfield notation.
using only the primitives 3d supports uint8 uint16 uint32 uint64 and their be counterparts and refraining from using reserved keywords like type as identifier names also require refinement steps.
on the other hand the agents are able to easily learn some other 3d specific constructs such as the consume allnotation.
we also observe that semantic mistakes i.e.
incorrect specifications can stem from the agent s difficulty in understanding the natural language in the rfc document.
figure shows one such example for vxlan.
the rfc describes the fields in the header in natural language and also provides an ascii diagram.
however the natural language description of the fields do not indicate the order in which the different values should occur in the vxlan header and without the ascii diagram a reader would not be able to correctly interpret the rfc.
the agent first produces a specification which is then executed using 3de xec resulting in a parsing error on the flags field for one of the tests in the test set.
then the agent reflects on the result of 3de xec and determines that the parsing failed due to the mis ordering of the reserved and ifields.
it then refined the specification by flipping the order of the fields and produces a candidate that passes on all tests.
interestingly the language in the rfc first describes the iflag and then says specifies the values of the other bits without indicating that there are reserved bits followed by an i bit followed by the remaining bits.
ambiguities in the rfc language may cause the agent to misinterpret the true intent.
result 3dgenis able to generate syntactically correct 3d code and learn from mistakes to refine specifications.
even in the presence of a noisy labeler and non exhaustive tests 3dgen enables users to leverage the generated specifications to align the test set with the rfc yielding specifications that pass all aligned tests for all network protocols.
protocolaccepted x avg.
syntax refinementsavg.
packet refinements udp .
icmp .
vxlan .
.
ipv6 .
.
ipv4 ethernet .
.
tcp .
.
gre .
.
dhcp .
dccp .
.
tpkt .
.
arp .
.
ntp .
nbns .
igmp .
nsh .
.
tftp rtp ppp .
ospfv3 .
pass pass table ii results of dgenfor network protocols.
denotes protocols for which the test labels were adjusted to be consistent with the rfc.
8protocol detected rfc vs wireshark disagreementwireshark message icmp header length constraints none ethernet ethertype payload length none vxlanreserved bits must be i flag must be header must be bytesnone none none ipv6 payload length exceeds framing length warning grereserved0 must be zero version number must be zeronone none tftp opcode fields must be between none tcpwindow fields must not be zero ack number must be consistent with ack flagwarning warning tpktversion field must be reserved field must be bitsnone none pppcode field must be between length field must be octet at least size data must be constrained by lengthnone none none rtp version must be none ospfversion field must not be reserved field must be header length must be bytesnone none none table iii constraints specified in the rfc that wireshark does not enforce.
b. distinguishing candidates with differential testing in many cases dgenproduces multiple specifications that are compatible with the test set.
in this section we aim to answer the following question rq2 how do candidate format specifications generated for the same protocol differ?
we make use of dtestgento help us answer this question in particular its differential testing feature to find tests that distinguish specifications or prove them semantically equivalent.
distinguishing tests if any can be surfaced to the user along with feedback from dtestgenlocalizing semantic differences in 3d specifications to help the user identify their desired specification.
table iv shows protocols for which dgengenerates multiple candidate specifications and the results of dtestgen s differential testing between every pair of candidates with a description of the differences found if any.
out of protocols have at least two semantically distinct specifications whereas for vxlan the two candidates are semantically equivalent.
for example for arp dgengenerates candidate specifications two which are semantically equivalent whereas the third mistakenly adds a field to the end of the arp header uint8 remainder .
this field consumes the rest of the data in the packet and is often used for optional variable length fields.
the arp rfc does not describe such a field and the specification is incorrect but passes the test set because there is no negative label test for which there is additional data at the end of the arp header.
3dgengenerates two candidate specifications for ipv4 and dtestgenfind a test that distinguishes them.
one spec protocol candidates distinct candidatesdivergent fields udp optional data field ipv4 additional constraints on flag values vxlan none dhcp 2options field length additional constraints on flags field arp incorrect additional remainder field ntp additional constraints on leapindicator status type fields igmp optional otherfields tcp constraints on options field table iv semantically distinct candidate specifications ification has a field uint16be flags flags reserved0 flags df flags mf where reserved0 df mfare equal to and which is consistent with the rfc.
the second specification has the same field as uint16be flags and does not enforce constraints on the value.
while these constraints should be added to be consistent with the rfc the test set did not contain a test violating this constraint thus both specifications were able to pass the test set.
in both the cases of arp and ipv4 dtestgenlabels the one specification as more permissive than the other e.g.
for ipv4 every test that passes on the first specification also passes on the second but not the other way around.
for both of these cases the stricter specification correctly implements the rfc.
thus a user of dgencould decide to always accept the stricter specification as a pruning heuristic between candidates.
result multiple distinct specifications may be produced by 3dgenfor a single protocol and the degree to which they diverge is dependent on the quality and coverage of the test suite on which they are evaluated.
3dtestgenhelps by finding differentiating tests or by grouping equivalent candidates allowing users to focus on a semantic differences exhibited by concrete test cases.
c.3dgenvs.
human written specs the authors of everparse provide specifications for out of the protocols we ran dgenon.
in this section we ask rq3 how do format specifications generated by dgen compare to handwritten specifications?
as before we use dtestgen s differential testing to semantically compare dgen s specifications to the handwritten ones with the results in table v. for ipv6 and ethernet 3dtestgenproves that the specifications are equivalent though syntactically distinct.
for udp icmp and vxlan we use dtestgento identify tests that distinguish the handwritten and generated specifications.
in all three cases the root cause is incorrect or missing constraints in the handwritten specifications demonstrating that even experts make mistakes when interpreting rfcs as 3d and that dgencan help in ensuring consistency with rfcs.
for udp the handwritten specification is missing a constraint on the length field that exists in the dgen specification.
for icmp the unused bytes field is too short misinterpreting the bytes as bits.
similarly in vxlan thevxlanid is two bytes short.
after correcting the handwritten specification dtestgenproves them equivalent to the dgengenerated specifications.
pull requests with the 9revised specifications were merged into everparse for all three protocols.
on the other hand for tcp and ipv4 the dgenspecification is missing constraints that exist in the handwritten specification.
for tcp although the produced specification passes on the set of tests it is underconstrained and does not include a condition checking if the syn flag is set to and it does not implement all possible constraints for different max segment size payloads.
instead it includes size constraints that are general to all options.
for ipv4 there are missing constraints on the ihl totallength and options fields which indicates that tests labeled by wireshark do not capture these constraints.
we explore whether dgenwould be able to generate an equivalent specification if it had access to a set of tests that can capture the missing constraints.
to do this we use dtestgen to generate positive and negative tests from the handwritten specification guaranteeing that tests exercising the constraints will be included in the test set.
with these tests dgen is able to produce two passing specifications that contain the missing constraints after an average of syntax and packet refinements.
the generated specifications are both semantically equivalent to the handwritten specification.
result 3dgenis able to produce 3d specifications semantically equivalent to human written 3d.
in addition using our framework we were able to uncover three bugs in existing handwritten 3d code for udp icmp and vxlan highlighting the difficulties in translating rfcs into correct implementations.
protocol equivalent?
root cause divergence after h.s.
fix udp h.s.
missing constraint on length field icmp h.s.
unused bytes type too short vxlan h.s.
vxlanid field too short ipv6 none n a ipv4 g.s missing value constraints on ihl totallength n a ethernet none n a tcp g.s.
missing constraints on options payload n a table v comparison of dgengenerated specifications to handwritten specifications denoted h.s.
.
we list the cause s of divergence and where applicable we correct the handwritten specification.
vi.
r elated work llms have enabled generating code from informal natural language requirements and have shown ability to generate human like code on benchmark problems however they come with no guarantees and have been known to contain bugs and security errors .
alphacode and codet have used tests to cluster and rank generated code to improve the empirical accuracy on benchmarks however they do not add trust to the generated code as the natural language does not impose any correctness checks.
on the other hand classical program synthesis formulates the problem of generating code that meets a formal specification.
however these techniques are limited due to lack of availability of formal specifications along with the intractable theoretical complexity of the synthesis.
lately program synthesis has been applied in restricted domains withinput output examples as specifications constrained by restrictions on syntax e.g.
sygus .
these restrictions make it difficult to apply them for new domains with formal guarantees.
office domain specific language odsl has been proposed as an intermediate layer for llms to translate natural language user commands to programs over office apis.
although it shares our motivation for using 3d as a dsl generated programs from odsl do not have any formal guarantees since the generated programs lack a formal notion of correctness and there is no symbolic encoding of programs in odsl into a logical formula.
closer to our setting ticoder uses llms to partially formalize user intent as tests.
unlike dgen ticoder requires a user in the loop to validate each test relies on an llmbased test generation that cannot be as exhaustive as our symbolic technique and cannot provide any formal guarantees on the generated code.
endres et al.
generate declarative postconditions in java and python using llms and evaluate the quality of specifications offline using validation tests but do not generate tests or verified code.
misu et al.
generate formal specifications and code that satisfies such specifications in dafny programming language using llms but there is no automation in helping the user establish the correctness of the specifications.
all these approaches are evaluated for a simple setup where the requirements are present as a few line docstrings and do not require problem decomposition or the translation of requirements from complex documents such as rfcs.
sage uses natural language processing nlp techniques to translate informal requirements in rfcs into protocol implementations semi automatically.
sage extracts and surfaces ambiguities in rfcs through an intermediate logical form that are resolved by the user before generating code.
unlike 3dg en sage can generate protocol implementation in addition to the parser however the generated code may have functional and security bugs as it lacks formal specifications.
extending 3dg enand the 3d language to support full protocol implementation would be interesting avenue for future work.
vii.
c onclusion programming in natural language using ai is a powerful new capability.
but for ai based program synthesizers to be truly useful they must also be trustworthy.
we believe coupling ai programming assistants with symbolic tools to support intent formalization and refinement as well guarantees about generated outputs is a key step towards fully realizing their potential.
we have explored this idea showing it is possible to synthesize verified binary format parsers from specification documents using ai agents while providing symbolic test case generators to help both humans and ais confirm and refine intent and verification tools to ensure that intent is preserved down to executable c code.
as a next step we plan to evaluate our approach through user studies to assess whether tools like dgenmore easily enable humans to author correct by construction programs in new dsls.
10references j. bangert and n. zeldovich nail a practical tool for parsing and generating data formats in 11th usenix symposium on operating systems design and implementation osdi .
broomfield co usenix association oct. pp.
.
.
available presentation bangert t. ramananandro a. delignat lavaud c. fournet n. swamy t. chajed n. kobeissi and j. protzenko everparse verified secure zerocopy parsers for authenticated message formats in proceedings of the 28th usenix conference on security symposium ser.
sec .
usa usenix association p. .
n. swamy t. ramananandro a. rastogi i. spiridonova h. ni d. malloy j. vazquez m. tang o. cardona and a. gupta hardening attack surfaces with formally proven binary format parsers in proceedings of the 43rd acm sigplan international conference on programming language design and implementation pldi june san diego ca usa .
.
available openai gpt technical report .
j. protzenko j. k. zinzindohou e a. rastogi t. ramananandro p. wang s. zanella b eguelin a. delignat lavaud c. hritcu k. bhargavan c. fournet and n. swamy verified low level programming embedded in f pacmpl vol.
no.
icfp pp.
sep. .
.
available s. yao j. zhao d. yu n. du i. shafran k. narasimhan and y .
cao react synergizing reasoning and acting in language models arxiv preprint arxiv .
.
y .
gao y .
xiong x. gao k. jia j. pan y .
bi y .
dai j. sun and h. wang retrieval augmented generation for large language models a survey arxiv preprint arxiv .
.
z. xi w. chen x. guo w. he y .
ding b. hong m. zhang j. wang s. jin e. zhou et al.
the rise and potential of large language model based agents a survey arxiv preprint arxiv .
.
l. wang c. ma x. feng z. zhang h. yang j. zhang z. chen j. tang x. chen y .
lin et al.
a survey on large language model based autonomous agents arxiv preprint arxiv .
.
y .
du s. li a. torralba j. b. tenenbaum and i. mordatch improving factuality and reasoning in language models through multiagent debate arxiv preprint arxiv .
.
c. qian x. cong c. yang w. chen y .
su j. xu z. liu and m. sun communicative agents for software development arxiv preprint arxiv .
.
q. wu g. bansal j. zhang y .
wu s. zhang e. zhu b. li l. jiang x. zhang and c. wang autogen enabling next gen llm applications via multi agent conversation framework arxiv preprint arxiv .
.
c. barrett p. fontaine and c. tinelli the satisfiability modulo theories library smt lib .
l. de moura and n. bj rner z3 an efficient smt solver in tools and algorithms for the construction and analysis of systems 14th international conference tacas held as part of the joint european conferences on theory and practice of software etaps budapest hungary march april .
proceedings .
springer pp.
.
m. chen j. tworek h. jun q. yuan h. p. d. o. pinto j. kaplan h. edwards y .
burda n. joseph g. brockman et al.
evaluating large language models trained on code arxiv preprint arxiv .
.
j. austin a. odena m. nye m. bosma h. michalewski d. dohan e. jiang c. cai m. terry q. le et al.
program synthesis with large language models arxiv preprint arxiv .
.
h. pearce b. ahmad b. tan b. dolan gavitt and r. karri asleep at the keyboard?
assessing the security of github copilot s code contributions in ieee symposium on security and privacy sp pp.
.
y .
li d. choi j. chung n. kushman j. schrittwieser r. leblond t. eccles j. keeling f. gimeno a. d. lago t. hubert p. choy c. d. m. d autume i. babuschkin x. chen p. s. huang j. welbl s. gowal a. cherepanov j. molloy d. j. mankowitz e. s. robson p. kohli n. de freitas k. kavukcuoglu and o. vinyals competition level code generation with alphacode .
.
available b. chen f. zhang a. nguyen d. zan z. lin j. g. lou and w. chen codet code generation with generated tests .
.
available z. manna and r. waldinger a deductive approach to program synthesis acm trans.
program.
lang.
syst.
vol.
no.
p. jan .
.
available s. gulwani o. polozov and r. singh program synthesis found.
trends program.
lang.
vol.
no.
pp.
.
.
available r. alur r. bod k g. juniwal m. m. k. martin m. raghothaman s. a. seshia r. singh a. solar lezama e. torlak and a. udupa syntax guided synthesis in formal methods in computer aided design fmcad portland or usa october .
ieee pp.
.
.
available document a. gandhi t. q. nguyen h. jiao r. steen and a. bhatawdekar natural language commanding via program synthesis .
s. k. lahiri s. fakhoury a. naik g. sakkas s. chakraborty m. musuvathi p. choudhury c. von veh j. p. inala c. wang and j. gao interactive code generation via test driven user intent formalization corr vol.
abs .
.
.
available m. endres s. fakhoury s. chakraborty and s. k. lahiri formalizing natural language intent into program specifications via large language models corr vol.
abs .
.
.
available m. md rakib hossain misu c. v .
lopes i. ma and j. noble towards ai assisted synthesis of verified dafny methods .
j. yen t. l evai q. ye x. ren r. govindan and b. raghavan semiautomated protocol disambiguation and code generation in proceedings of the acm sigcomm conference ser.
sigcomm .
new york ny usa association for computing machinery p. .
.
available 11appendix a. branch coverage with 3dtestgen in this supplement we briefly cover how 3dtestgen produces tests that achieve branch coverage.
recall the message parser from section iii of the paper.
it has has two branches and four paths fail to parse the first byte fail because the first byte is less than fail to parse the second byte success.
thus to query z3 for models that achieve a form of branch coverage we instrument our encoding with branch tags in practice 3dtestgen does not instrument every branch heuristically only picking branches of interest focusing on those that involve value constraints and casetype s. next we introduce a global uninterpreted function branch trace representing a trace of branches to be taken.
thestate argument to an encoded parser also contains a branch index component which records a position in the branch trace.
for a given branch trace the encoding forces the parser to follow that trace of branches.
by querying z3 while fixing the branch trace we obtain models of the input that also are compatible with the trace i.e.
the input is a byte sequence that forces the parser to follow the branch trace.
then by simply enumerating the traces up to a user specified branch depth in a depth first fashion we get z3 to generate a diversity of input models that achieve branch coverage.
we show a fragment of the parse message parser encoding augmented with branch tags below.
note how each branch of the constraint check for x 42is taken only if the corresponding branch tag in the trace also permits it if the constraint holds if it does not.
define fun parse message s0 state state let s1 parse uint8 s0 if has failed s1 s1 if and return value s1 branch trace branch index s1 parse uint8 incr branch index s1 if and not return value s1 branch trace branch index s1 now to generate models that explore a given trace of branches we add the following assertions to the query to constrain the prefix of the branch trace recorded by the parser.
assert branch index init start from index .
take the first branch in message.
assert and branch trace make at least as many choices as branch depth.
assert branch index parse message init branch depth b. comparing code produced by 3dgen to handwritten specifications we report the high level characteristics of code produced by dgenin table vi.
for each characteristic lines of code loc number of constraints etc.
we report the mean across all valid specifications generated by dgenin the first column.
in the last two columns we compare characteristicsmetric mean all protocols 3dgen h.s.
loc 3d .
.
fields .
.
.
constraints .
.
casetypes .
.
.
structs .
.
.
bitfields .
.
.
enum .
.
.
consume all .
.
.
table vi highlevel characteristics of code produced by 3dgen.
mean is reported across all specifications.
for the subset for which a handwritten spec exists the last two columns compare characteristics between generated specifications g.s.
and handwritten specifications h.s.
.
of the generated specification to the correct handwritten specification if applicable across all protocols.
table vii contains the full breakdown of metrics for each protocol.
in general we observe that handwritten specifications have on average more lines of code ignoring comments and empty lines than code generated by dgen.
this could be due to formatting and stylistic choices.
for example in figure the handwritten specification adds extra lines around the version constraint and extracts the version number into a defined variable where the dgenspec uses a constant.
while the mean is the same we observe that the number of bitfields can vary between the generated and handwritten specifications.
an example of this can be seen in figure where the handwritten specification divides the trafficclass and flowlabel fields.
the dgenspecification combined both of these fields into one trafficclassflowlabel field of the appropriate size.
there is no constraint on the value of this field in either specification therefore both specifications are semantically equivalent.
on the other hand figure shows an example of semantically equivalent specification where 3dgenrepresented the v lantag field with three bitfield variables pcp dei and v id .
interestingly both dgenand the handwritten specifications contain the same number of casetypes with a mean of .
across the seven specifications for which a handwritten spec exists.
the number of constraints in the dgenspecification is lower than that of the handwritten specifications which follows from observations in rq3 table v where the ipv6 and tcp specifications are missing constraints.
c. syntactic characteristics of code produced by 3dgen results of rq3 in this work as well as results from related work in the domain confirm that accurately translating nuanced and often ambiguous rfc specifications into correct code by hand is an error prone task and often laborious task.
table vii contains several syntactic metrics of the code generated by dgenfor each protocol.
though these syntactic metrics may not serve as an ideal proxy for the complexity of a protocol s data format specification they do give some 12fig.
semantically equivalent 3d specification for ethernet ii frames in vxlan.
left handwritten specification right dgen specification.
fig.
semantically equivalent 3d specification for ipv6.
left handwritten specification right dgenspecification.
protocol loc c loc 3d fields constraints casetypes structs bitfields enum consume all udp h.s.
icmpv4 h.s.
vxlan h.s.
ipv6 h.s.
ipv4 h.s.
tcp h.s.
ethernet h.s.
gre igmpv2 dhcp dccp arp ntp nbns nsh tftp rtp ppp tpkt ospf table vii syntactic metrics of 3d code produced by dgenand the handwritten specification h.s.
for each of the protocols used in this work.
insight into the relative complexity and structural elements of the generated code.
we report both the lines of 3d code generated by dgen as well as the lines of c code automatically generated from the 3d specification by everparse.
overall we observe a modest range of lines of 3d code generated for the selected protocols dgengenerated as little as tpkt and at most icmp lines of code.
intuitively the number of fields follows overall lines of code ranging from igmp tpkt to icmp .
although we observe only a modest numbers of lines of 3d code generated the lines of auto generated c code to correctly parse these specifications is considerably larger we comment more on this shortly.
the number of structs bitfields enums and consume all types used varies based on the protocol specification.
the number of value constraints can indicate increasing nuance in the data specification.
for example nbns spans lines of code but contains constraints as measured by boolean operators.
this is because of the bitfields have value constraints defined in the nbns rfc .
the nm flags field defines value constraints for each flag of either or .
the casetypes field appears to be a reliable indicator if the protocol contains multiple message types however for the protocols studied there is never more than one casetype neededto specify the data type.
interestingly the number of lines of c code produced for each of the formats is several factors larger than the size of the 3d specification for several reasons.
first designed as as declarative specification language 3d is inherently more compact than imperative c code that implements a parser e.g.
the parser implementation has to repeatedly check if there is enough space left in the input buffer to parse the next field.
further the c code includes various features that are important for a practical parser including error handling logic such error handling is not present in individual 3d specifications and is instead baked into the definition of the 3d language.
this points to the benefit of using a compact specification language as a target for ai generation many features can be incorporated into the language definition rather than having the programmer specify them repeatedly for every program.
directly generating say 1k lines of c code for an icmp parser even if it could be ai generated would pose a difficult program verification problem using a dsl like 3d enables analysis such as symbolic test case generation to systematically test and refine ai generated code and correctby construction code generation ultimately yields verified c code.