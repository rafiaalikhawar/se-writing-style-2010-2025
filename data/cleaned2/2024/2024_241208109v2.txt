unseen horizons unveiling the real capability of llm code generation beyond the familiar yuanliang zhang yifan xie shanshan li ke liu chong wang zhouyang jia xiangbing huang jie song chaopeng luo zhizheng zheng rulin xu yitong liu si zheng xiangke liao college of computer science and technology national university of defense technology changsha china zhangyuanliang13 xieyifan shanshanli liuke23 jiazhouyang xbhuang songj19 luochaopeng18 zhengzhizheng23 xurulin11 liuyitong22 xkliao nudt.edu.cn ridicious1997 si.zheng1009 gmail.com abstract recently large language models llms have shown strong potential in code generation tasks.
however there are still gaps before they can be fully applied in actual software development processes.
accurately assessing the code generation capabilities of large language models has become an important basis for evaluating and improving the models.
some existing works have constructed datasets to evaluate the capabilities of these models.
however the current evaluation process may encounter the illusion of specialist in familiarity primarily due to three gaps the exposure of target code case timeliness and dependency availability.
the fundamental reason for these gaps is that the code in current datasets may have been extensively exposed and exercised during the training phase and due to the continuous training and development of llm their timeliness has been severely compromised.
the key to solve the problem is to as much as possible evaluate the llms using code that they have not encountered before.
thus the fundamental idea in this paper is to draw on the concept of code obfuscation changing code at different levels while ensuring the functionality and output.
to this end we build a code obfuscation based benchmark o bfus eval.
we first collect raw cases from five real world projects including function description and code.
then we use three level strategy symbol structure and semantic to obfuscate descriptions code and context dependencies.
we evaluate four llms on o bfuseval and compared the effectiveness of different obfuscation strategy.
we use official test suites of these projects to evaluate the generated code.
the results show that after obfuscation the average decrease ratio of test pass rate can up to .
.
index terms large language model code generation capability code dataset i. i ntroduction with the rapid development of the large language model llm the code generation capability of llms has attracted lots of attention .
however how to accurately assess the code generation capability of llms in production level software development is still an open question.
a variety of benchmark tests for code generation have been proposed however there are still gaps between these benchmark tests and the actual software development process.
traditional datasets as evaluation benchmarks play key roles in evaluating the capabilities of llms.
however co first authors corresponding author new codesimilar codetraining data evolution timelinellm release fig.
the familiarity level of code to llm.
the more transparent elements indicate less familiarity.
they focus mainly on standalone functions based on algorithmic problems which cannot reflect the complexity of real software development as llms may face potential challenges in handling code that is interdependent with other contextual elements of the project .
there have been several benchmarks which are built based on realworld production projects while there remain three gaps for these benchmarks to objectively evaluate the code generation capability of llm exposure of target code case timeliness and dependency availability.
gap target code has been exposed in the pre training stage.
previous benchmarks have only rewritten the functional descriptions without modifying the code itself.
this could result in the target code being exposed to llms during training making the evaluation results not objective as the code has been exercised extensively.
gap collected case is time sensitive.
with the rapid development of llms data will be continuously trained.
although previous benchmark has collected modified code from history after llms training the modified code may still have been exposed to llms because of the existence of code clones.
in addition benchmarks that rely on historical data will suffer from the timeliness problem and cannot be used to evaluate subsequent releases of llms.
gap precise dependencies are difficult to provide in real usage scenarios.
existing benchmarks directly provide the model with all the dependencies needed to generate the target code.
however such conditions can not be always satisfied in real development.arxiv .08109v2 jan 2025in conclusion existing evaluation process may suffer from the specialist in familiarity problem which means llms can perform well on code that they are very familiar with often due to extensive experience or repeated exposure.
this term highlights the individual s strength in specific wellknown domains but it also implies that their expertise may not extend beyond these familiar areas.
the primary reason is that the code used to evaluate llms may be extensively exposed and exercised for training.
as shown in fig.
the unfamiliarity of code to llm is increased along with the timeline.
unfortunately even for the code collected after llm training and release may be similar to the training data due to the existence of code reuse.
to solve these problems we need to evaluate using code that llms have not encountered before as much as possible.
to this end we propose a new obfuscation based benchmark obfus eval to evaluate llms code generation capability.
our main target is to evaluate the llm on the code generation tasks that it has never encountered before and simulate real software development process.
o bfus eval has three key characteristics to solve gap we collect highly starred projects from github and select functions from them that are introduced after a certain time point.
these functions are covered by the official test suites.
to solve gap all the raw data have been obfuscated by different level strategies symbol structure and semantic to rewrite both functional descriptions and code.
the process of code obfuscation can ensure that datasets are reused without the concern that they might still become training data in the future the code obfuscation process can be repeated .
to solve gap we provide relevant code dependencies in a compromise manner simulating real world development scenarios without deliberately sacrificing the generation capabilities of llm.
we identify all the contextual dependencies necessary for each function including necessary api calls structures macros etc.
and also add some dependencies that are not related to the target function code for obfuscation.
to effectively utilize our dataset and evaluate llm s real capability on generating unfamiliar code we built a projectlevel execution platform that provides an off the shelf runtime environment to automatically evaluate the functional correctness of the generated code.
we developed this platform based on docker cloning and building the environment for all projects.
given a model generated code the code will automatically replace the original code.
then the projects will be compiled and tested to see whether there are compilation errors or test failures.
we comprehensively evaluated four state of the art code generation models chatgpt3.
chatgpt4 chatgpt40125 and deepseek coder v2 on o bfus eval.
we analyzed each model s effectiveness under different obfuscation strategies.
the results show that after code obfuscation the average decrease ratio of test pass rate can up to .
.
in addition we found that even passing all the tests code generated by llms may still suffer from non functional code issues e.g.
code robustness which can guide the developers to better discernand utilize the code generated by llms.
the main contributions of the paper are as follows we reveal that existing benchmarks are insufficient for objectively evaluating the code generation capabilities of llms primarily due to three gaps exposure of target code case timeliness and dependency availability.
we propose an obfuscation based approach to rewrite the functional descriptions code and dependencies to prevent the target code from being exposed in the training stage.
we design different levels of obfuscation strategies and examine their effectiveness.
future research can design sophisticated obfuscation process to better explore the potential of llm s capability based on our results.
we build an obfuscation based benchmark o bfus eval1 using code from real world projects.
we evaluated four state of the art code generation models on o bfus eval.
the results show that after code obfuscation the average decrease ratio of test pass rate is .
.
demonstrating the inflated capabilities of llms.
we also identify nonfunctional code issues in the passed cases which can be studied in future work.
ii.
background in this section we first conduct a comprehensive examination of the latest advancements in large language models llms within code generation.
subsequently we delve into the related work of evaluations crafted for code generation along with the limitations and challenges encountered in assessing the performance of llms.
finally we introduce the motivation for incorporating code obfuscation in the evaluation of large language models.
a. large language models for code generation.
the process of code generation which involves the automatic creation of complete program code or the completion of code snippets from higher level representations such as natural language descriptions models or specifications plays a pivotal role in enhancing programming efficiency and mitigating human error .
recent advancements in large language models llms for code generation have garnered significant attention in the realm of computer science research.
these llms such as gpt chatglm codex and codegen have demonstrated remarkable capabilities not only in general natural language processing tasks but also in the specific area of code generation.
notably gpt achieved the highest pass rate on the humaneval benchmark indicating a growing trend to evaluate the code generation capacity of general llms .
code specific llms which are trained primarily on massive code specific corpora often outperform general llms in code generation tasks .
diverse training approaches have been employed with some models like incoder and starcoder being trained with the filling in the middle capability for infilling missing code based on context.
varieties i llm s code generation performance on code competition problems of different time oj websitegpt3.
turbo .
gpt4.
preview .
zero shot few shot zero shot few shot leetcode19.
.
.
.
.
.
leetcode95.
.
.
.
.
.
of code llms have been proposed such as wizardcoder instruct starcoder and instruct codegen each designed with different training objectives.
b. evaluations for llm s code generation benchmark construction.
current benchmarks built based on real projects usually rewrite only the functional descriptions without modifying the code which may lead to the code leak issue.
swe bench collects modified code from the project s history.
however the code may be in the training set of subsequent releases of llms.
future llms may become experts in solving problems in swebench but they may still struggle with new code problems in real world scenarios.
evocodebench periodically update the dataset but there is still possibility of introducing similar code due to the existence of code clones.
context dependencies.
traditional benchmarks focus on generating independent code units ignoring the contextual relationships between code .
for example swebench does not provide the complete dependencies of the generated code so it is hard to distinguish the capability of llms to generate the target code and its dependencies.
however current studies indicate that only about of methods in open source projects are relatively independent in real world scenarios methods often depend on each other or share variables which is not considered in these traditional benchmarks.
some works provide complete dependencies but do not include useless and obfuscated dependencies.
this discrepancy does not align with software development scenarios and fails to accurately measure the ability of llms to assist developers in practical settings.
therefore we need evaluation methods closer to real world scenarios to comprehensively assess llms performance in real world software development.
evaluation methods.
when evaluating the code generation capabilities of llms existing studies and benchmarks focus on the basic correctness of the code which is usually verified by executing simple test cases e.g.
unit tests .
in our work we try to assess both syntactic and functional correctness of llms generated code in real scenarios by leveraging both compile checking and systematic testing which aligns more closely with the requirements of realworld development.
in addition previous benchmarks were compared to humaneval to prove their validity .
however since the length of code to be generated fig.
examples of code obfuscation.
by these benchmark tests does not match the distribution of code lengths in humaneval this comparison is inherently unfair.
it therefore does not accurately reflect the validity of the benchmark tests.
c. motivation of using code obfuscation as llms are continuously trained and released traditional datasets would constantly be learned and trained by these models.
therefore the timeliness of code may be a crucial factor when testing the generation capacity of llm.
in other words code may become easier to generate because it already exists or similar in the training set.
to validate our conjecture we conduct a pilot study to check whether the timeliness of code will affect the result of llm generation capability.
we use gpt .
turbo released at .
.
and gpt .
preview released at .
.
to do code competition problems from leetcode .
we collect the problems from .
to .
problems and the problems from .
to .
problems as our test data.
the later problems came out after the release of two models which were theoretically not presented in the model s training data.
table i shows the results.
we find that the pass rates of the early problems are much higher than later problems.
due to the fact that code competition websites contain problems of varying difficulty levels and there is no deliberate increase of the difficulty of new problems the reason is that these older problems appeared in the model s training dataset so that models can handle them more easily.
relying solely on the latest code as a dataset is not a sustainable approach in the long run as models will continuously train and evolve and due to the existence of code reuse even code written after the training cutoff date may still be similar to code in the training set.
during the construction of our dataset to mitigate the impact that llms may have seen the code we have drawn inspiration from code obfuscation techniques which are originally used for making applications difficult to be decompiled or disassembled.
fig.
illustrates two examples of code obfuscation changing the variable names and changing the code implementation of the same logic .
after obfuscation the code will become different from the training set while maintaining its functionality and output.fail manual check raw data collection semantic obfuscation structure obfuscation symbol obfuscation system test functionally correct code symbol obfuscationcode generation code completioncode pass passfailsource code replacement systematic testing and code reviewinteractive generation prs extraction and function filtering modified function ...repository selection ...mature software complete test suite ...contextual dependency identification global variablestructs ...human labeling add requirementrelabel requirement test case coverage code obfuscationnon functional issuescompilation errors functional errorscompile fig.
workflow of dataset construction and testing iii.
b enchmark construction and testing in this section we describe the approach of building and testing o bfus eval to show the capability of llm and the workflow is shown in fig.
.
the building process mainly includes two phases collecting raw data from open source projects section iii a and obfuscating code section iii b .
after that we construct a testing framework to evaluate the effectiveness of code generation and code completion by the models on o bfus eval section iii c .
a. raw data collection to construct o bfus eval we first need to collect the raw data.
the raw data includes functions modified after the large model training data cutoff date from real world open source projects as well as the context information these functions depend on within the project.
overall we divide the raw data collection process into two parts function collection and contextual dependency provision.
functions collection function collection includes three main steps step repository selection.
the existing dataset mainly covers java and python projects.
to demonstrate the code generation capabilities of the large language models in other programming languages we chose c projects to build o bfus eval.
we set two conditions to filter repositories from github the repository should be mature and well maintained the project should have a comprehensive test suite for systematic testing.
finally we selected five projects with over 20k average stars.
step prs extraction and function filtering.
we selected merged prs from the chosen repositories and extract functions that meet the task criteria.
specifically we extracted prs and filter functions based on the following four criteria the prs are merged after a certain time point to coincide with the training data cutoff date of specific models we tested more discussion in section iv a2 the prs modify the repository s test files to verify the modified code s functional correctness the functions are modified in the pr to ensure that llm had not seen modified code in previous code base the functions are covered by the test suites to ensure that the functionality of the functions is effectively verified.table ii the statics of prs extraction and function filtering.
softwaremerged prs with modified test covered prs tests modified functions functions redis libvips lvgl libgit2 fluent total based on the above criteria we finally selected functions for constructing code generation and code completion tasks and the statistical results are shown in table ii.
step human labeling.
in this step we manually provide functional descriptions for each test covered function.
specifically we assembled a team of seven senior software engineers each with at least five years of c programming experience.
the team is responsible for rewriting the existing functional descriptions and providing manually written descriptions for functions without descriptions aiming to reduce the model s dependence on the original functional descriptions encountered during the pre training phase.
during this process we implemented a double check mechanism.
when any two engineers have a disagreement a third engineer is brought in to discuss and reach a final consensus together.
contextual dependency provision previous work has shown that more than of the functions depend on other contextual information in the project therefore the inability to provide dependencies can lead to a significant decline in the generative capabilities of large language models.
however accurately providing the dependencies required for code generation is extremely difficult and does not align with real world development scenarios.
consequently we adopt a conservative approach to providing dependencies.
we first use syntax tree analysis to identify and collect all relevant contextual dependencies in the code.
we extract dependencies from project files including the names of functions declarations function bodies global variables structures macros as well as function comments.
next wetable iii the composition of o bfus eval soft.original symbol obfuscation structure obfuscation semantic obfuscation symbol structure symbol semantic functions functions functions functions obfuscation functions obfuscation functions redis libvips lvgl libgit2 fluent total compile the code to obtain the llvm ir intermediate code representation of the files.
by matching keywords in the ir syntax such as call to indicate a function invocation we traverse the ir files to acquire the names of those dependencies.
by cross referencing the results from the first step we can obtain the contextual information of the target function.
we also provide similar but different dependencies for each contextual dependency to simulate the disturbances caused by irrelevant information in the actual development process.
b. code obfuscation despite selecting code from the project revision history that was modified after the training time of the large model we also applied additional code obfuscation techniques to the dataset to enhance protection against code leakage and ensure the applicability of our benchmarks in future releases of the large model.
fig.
shows the example process of obfuscating the dataset with three strategies.
to objectively evaluate the effectiveness of the llm when dealing with obfuscated code we constructed code generation and code completion scenarios considering the code completion task as a subtask of the code generation task.
we apply symbol obfuscation and structure obfuscation strategies in code generation scenarios and symbol obfuscation and semantic obfuscation strategies in code completion scenarios the strategies can be used in combination .
distinguishing different obfuscation strategies for various task scenarios is due to the fact that only in the code completion scenario can semantically obfuscated code fragments be retained and a llm be required to generate complete code.
this is to test the llm s true generation capability when faced with semantically obfuscated code.
we do not fully integrate the three types of obfuscation together because different obfuscation strategies are suitable for different types of code.
next we will discuss in detail the effects and practice of each obfuscation.
symbol obfuscation we first use a comprehensive symbol obfuscation strategy to not only rewrite the functional descriptions of the functions but also perform thorough identifier rewrites for all meaningful identifiers in the target code and the provided context.
this means that all identifiers for functions variables class names etc.
in the code are obfuscated regardless of the context in which they appear in the source code.
we use nltk to do the word segmentation and replacement.
this strategy is designed atthe token level to change the llm s familiarity to the target code.
structure obfuscation after symbol obfuscation we further change the code structure automatically using a structure obfuscation strategy.
in this stage we employ the strategy to adjust and integrate the calling structure of the target function so that the execution path and organization of the function are changed.
specifically we use llvm to unfold and integrate the functions that are called in the objective function to change the structure of the code.
we extract all the called functions and their implementations within the target function based on the context and then utilize the abstract syntax tree ast to handle parameter passing and automatically unfold the called functions.
semantic obfuscation in semantic obfuscation we meticulously rewrite code snippets within functions to ensure that the new code is semantically equivalent to the original yet the implementation logic differs.
the goal of this process is to maintain the functional consistency while introducing a new implementation method effectively obfuscating the code at the method level.
through semantic transformation we ensure that the code can still achieve the same functionality but for the model its generative logic is completely different from the original code.
this semantic obfuscation provides a more challenging task to test the code understanding and generative capabilities of llm.
since this obfuscation method relies on specific semantics of the code the current approach involves manually rewriting the code and conducting a double check.
we highly recommend that future research should delve deeper into semantic obfuscation strategies and design templates to automate this process.
through raw data collection and code obfuscation we constructed the o bfus eval which is shown in table iii.
apart from symbol obfuscation we did not apply structure and semantic obfuscation to all the original data.
this is partly because the characteristics of the code may be suitable for specific obfuscation methods such as nested structures and partly due to the cost of manual inspection.
the code examples from redis are more numerous and regular so we applied more semantic obfuscation to them.
future research could design automated code obfuscation framework for obfuscation and inspection.
c. systematic testing and code review to evaluate the llm s code generation capabilities on the o bfus eval and the effectiveness of our code obfus const int isstringnull stringptr null const int responsetype customerptr responsetype const char response isstringnull responsetype ?
r n isstringnull ?
r n stringptr const size t responselength isstringnull responsetype ?
isstringnull ?
strlen stringptr ... ... struct typedef struct clientinfo uint64 t uniqueid incremental unique id for the client.
... ... char buffer clientinfo api void appendresponsenull clientinfo c void appendresponsebulk clientinfo c robject obj ... ... void appendresponsebulkcstring clientinfo c const char s if s null appendresponsenull c else appendresponsebulkcbuffer c s strlen s if s null if c resp addreplyproto c r n else addreplyproto c r n else addreplylonglongwithprefix c strlen s ... ... struct typedef struct client uint64 t id client incremental unique id.
... ... char buf client api void addreplyproto client c const char s size t len this...objects.
void addreplybulk client c robj obj ... ...the function sends a response to a designated client incorporating the content from the c string parameter s. if s is null it replies with a null type otherwise it converts s into a c buffer and responds with a binary block bulk type specifying a length corresponding to strlen s .
void addreplybulkcstring client c const char s if s null addreplynull c else addreplybulkcbuffer c s strlen s struct typedef struct client uint64 t id client incremental unique id.
... ... char buf client api void addreplynull client c void addreplybulk client c robj obj add a object as a bulk reply ... ... the function sends a response to a designated client incorporating the content from the c string parameter s. if s is null it replies with a null type otherwise it converts s into a c buffer and responds with a binary block bulk type specifying a length corresponding to strlen s .1project contexts 2requirement 3signature 4reference code1project contexts 2requirement 3signature 4reference code void addreplybulkcstring client c const char s the function sends a response to a designated client incorporating the content from the c string parameter s. if s is null it replies with a null type otherwise it converts s into a c buffer and responds with a binary block bulk type specifying a length corresponding to strlen s .1project contexts 2requirement 3signature 4reference codethe function sends a response to a designated client incorporating the content from the c string parameter s. if s is null it replies with a null type otherwise it converts s into a c buffer and responds with a binary block bulk type specifying a length corresponding to strlen s .
void appendresponsebulkcstring clientinfo c const char s struct typedef struct clientinfo uint64 t uniqueid incremental unique id for the client.
... ... char buffer clientinfo api void appendresponsenull clientinfo c void appendresponsebulk clientinfo c robject obj ... ...1project contexts 2requirement 3signature 4reference codesemantic obfuscation structure obfuscationsymbol obfuscationfig.
an example of code obfuscation process cation methods we designed an automated code execution and verification platform.
the platform is built on docker images providing an isolated sandbox environment to ensure that the tested codes do not interfere with each other.
the evaluation process of generated code mainly includes two parts systematic testing and code review.
systematic testing we use the systematic testing process to evaluate the model and the dataset.
we utilize compilation checks and official test suites to detect syntax and semantic errors.
we construct the prompt to guide the large model in code generation scenarios and code completion scenarios.
the composition of the prompt is detailed below instruction we provide explicit instructions to guide the llms to generate code related to the software.
context we provide detailed context information including structs macros functions global variables etc.
these contexts include both the necessary dependencies for implementing the target function and the context that is irrelevant to the target function.
function description we provide a functional description of the target function to guide llms in generating code.
based on this description we provide only the declaration of the target function for code generation scenarios and partial code implementation details of the target function forcode completion scenarios .
fig.
shows an example of the prompt for the code generation scenario.
we provide functional descriptions in the to guide the large model s code generation.
after obtaining the code generated by the model we integrate instruct from now on you play the role of the c code generator .
you can generate the corresponding function code according to the function description provided by the user.
please do not return anything other than the target code.
don t return anything other than the function code.
the process is as follows this is objective function description this function sends a reply to the specified ... ... type reply with a length of strlen s .
this is the declaration of the objective function void addreplybulkcstring client c const char s context here are some function context details you may need to know when writing objective function for the project functions may be used void addreplynull client c ... ... structs may be used ... ...macros may be used ... ... global variables may be used ... ...fig.
example of prompt for code generation scenarios it into the software for compilation and system testing.
if errors occur we separately record compilation errors and test errors then analyze the error information.
for code that passes the tests we will conduct a manual code review.
code review we used compilation checks and test suites to evaluate the syntactic correctness and functional correctness of the generated code respectively.
however table iv the performance of llms in code generation scenarios.
original means the pass rate of all raw code tasks.
original structure means the pass rate of those raw code tasks which later perform structure obfuscation.
all the numbers have omitted the percentage sign.
software modeloriginal symbol original structure structure symbol structure cpr tpr cpr tpr cpr tpr cpr tpr cpr tpr redisgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
libvipsgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
lvglgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
libgitsgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
fluentgpt3.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
means that the pass rate has increased decreased by less than ratio .
means that the pass rate has increased decreased by more than ratio .
2the change magnitudes are calculated by comparing to original and the original structure .
through manual inspection we found that even the code was functionally correct i.e.
it was able to pass the tests there were still some non functional code quality issues.
these problems may include deficiencies in code efficiency code robustness etc.
therefore we manually analyzed these nonfunctional code quality issues section iv b3 .
iv.
e valuation in this section we describe our experimental setup and the evaluation results of four llms on our dataset.
our evaluation focuses primarily on the performance of llms on our dataset and whether code obfuscation can further reveal the true capabilities of these llms.
a. evaluation setup model selection we chose a general purpose large language model chatgpt and a code focused large language model deepseek.
both of them are mature and widely used llms.
for chatgpt we use the gpt .
turbo gpt turbo and gpt turbo in our experiments.
for deepseek we use deepseek coder v2 with the default settings.
we use default value for llm s parameters when generating code.
raw data selection note that the training datasets for gpt turbo were finalized as of april gpt3.
turbo is also before that time .
we selected thecode starting from may to dec as the original data.
therefore for gpt .
turbo and gpt turbo these codes were not included in the training set while for gpt turbo and deepseek coder v2 they might have encountered some of these code snippets during training.
by so we not only ensure a balanced distribution in our dataset with both seen and unseen data but also objectively and authentically demonstrate the generative capabilities of llms across different types of code.
evaluation metrics to assess the correctness of the generated code snippet we employed two key performance metrics to measure the code generation capabilities of the llms in real world development scenarios compile pass rate cpr andtest pass rate tpr .
we first replace the original function with the function generated by the llms and then compile the software.
after that we perform system tests associated with that function.
cpr and tpr are representative metrics that can illustrate generated code that passes compilation and tests respectively.
cpr demonstrates the basic ability of large language models to generate syntactically correct code while tpr reflects the capability of large language models to understand and correctly generate complex functional code.
specifically tpr can demonstrate whether the llm can be used directly in production scenarios.
both cpr and tpr use pass rate to eliminate fluctuations.table v the performance of llms in code completion scenarios.
original means the pass rate of all raw code tasks.
original semantic means the pass rate of those raw code tasks which later perform semantic obfuscation.
all the numbers have omitted the percentage sign.
software modeloriginal symbol original semantic semantic symbol semantic cpr tpr cpr tpr cpr tpr cpr tpr cpr tpr redisgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
libvipsgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
lvglgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
libgitsgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
fluentgpt3.
.
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
gpt4 .
.
.
.
.
.
.
.
.
.
deepseek .
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
means that the pass rate has increased decreased by less than ratio .
means that the pass rate has increased decreased by more than ratio .
2the change magnitudes are calculated by comparing to original and the original semantic .
b. results and analysis to evaluate the performance of large models on our dataset we conduct experiments on four large models using o bfus eval.
specifically we explore the effectiveness of code obfuscation and the various among different obfuscation strategies.
we investigate the following three research questions rq1 how effective are large language models in generating code on our datasets?
rq2 how does code obfuscation further reveal the capabilities of llms and how effective are different obfuscation strategies?
rq3 what are the issues hidden in llm generated code?
rq1 how effective are large language models in generating code on our datasets the model usually performs better on the code similar to training data.
thus we collected code data after model training and utilized code obfuscation methods to further eliminate code leakage.
in this research question we conduct experiments with several widely used and proven effective large language models on our collected dataset.
the overall results are presented in table iv and table v. the cprs are among .
to .
on original raw code with an average of .
which is significantly lower than the llm s performance on traditional datasets e.g.
humaneval .
the average tprs are .
and .
on original codegeneration and completion.
after we applied different levels of code obfuscation this result dropped to .
and .
.
this indicates that the code generated by llms is difficult to pass the official tests of software and be directly used in production environments.
developers still need to manually fix and adjust the code.
user editconclusion for rq1 large language models still fall significantly short of meeting the requirements for unfamiliar code generation completion tasks in real world production environments.
the basic pass rate of compilation remains a significant bottleneck.
even if it passes the compilation it may still not meet the actual functional requirements of the software.
rq2 how does code obfuscation further reveal the capabilities of llms and how effective are different obfuscation strategies we use three obfuscation strategies section iii b to modify the collected raw code to minimize the possibility that the code might resemble the training data.
we specifically compare the tpr before and after different code obfuscations to evaluate the syntactic and functional correctness of generated code.
we try them separately and also their combinations.
the results are shown in fig.
detailed data can be found in table iv and table v .
overall effect.
all obfuscation strategies have reduced the tpr of code generation by llms.
since we did not deliberately increase the difficulty and complexity of the codeoriginal symbol010203040tpr .
.
.
.
.
.
.
.4gpt3.
gpt4 gpt4 deepseek a symbol obfuscation original structure structure symbol structure010203040tpr .
.
.
.
.
.
.
.
.
.
.
.9gpt3.
gpt4 gpt4 deepseek b stucture symbol obfuscation original semantic semantic symbol semantic010203040tpr .
.
.
.
.
.
.
.
.
.
.
.6gpt3.
gpt4 gpt4 deepseek c semantic symbol obfuscation fig.
tpr under different code obfuscation strategies.
after introducing various degrees of obfuscation the rankings of four llms tend to be stabilize and consistent.
in code obfuscation discussed in section v code obfuscation can make the tested code less familiar to large models.
even though the decline may not be particularly significant it represents the trend of the llms capabilities and if applied in a large scale production environment it could still have a considerable impact.
as for tested llms gpt4 gpt4 and deepseek code are obviously better than gpt3.
.
however the ranking of their capability on the original code is inconsistent.
after obfuscation their ranking becomes more stable gpt40125 deepseek code gpt4 gpt3.
.
this further proves that using code obfuscation can more accurately demonstrate the capabilities of the models.
strategy comparison.
in this paper we intuitively determine the effectiveness of code obfuscation strategies by the tpr decrease ratio comparing to the original code tasks eliminate the inflated capabilities of the large model .
symbol and structure obfuscation can be very effective with the average tpr decrease ratio of .
and .
.
semantic obfuscation is not that effective with an average decrease ratio .
.
this is mainly because our current semantic obfuscation strategies are still relatively simple using some heuristics to rewrite code manually without making in depth modifications to the code.
we also find that the use of mixed strategies can lead to a further decrease in tpr symbol structure can have an average decrease ratio of .
demonstrating the effectiveness of mixed strategies.
although different obfuscation methods have different effectiveness we still recommend that future researchers should try various obfuscation strategies and their combinations which can not only ensure the fairness of code obfuscation but also explore the performance of llms on more types of code implementations.
user editconclusion for rq2 all obfuscation strategies can help eliminate the inflated code generation capabilities of llms.
symbol and structure obfuscation are particularly effective.
future research could further explore more sophisticated semantic obfuscation methods and additional strategies and automate the entire obfuscation process efficiently.
rq3 what are the issues hidden in llm generated code to enable developers to better utilize the code generated by large language models for downstream development tasks we further analyzed common issues hidden in the generated code that may affect development tasks.
due to the large size of the o bfus eval we employed stratified sampling for manual code review.
the sample size was calculated through the finite population correction ensuring our sample accurately represents the dataset.
we set the confidence level to and the margin of error to which are standard statistical thresholds.
through this method we extracted pieces of llm generated code from five software and identified the following three categories of issues syntax errors codes lead to compilation errors.
functional errors codes fail to meet the functional requirements of development fail the official tests .
non functional code quality issues codes potentially causing performance and reliability issues.
due to the target software being from diverse domains the functionalities and the code semantics are various so we mainly focus on syntax errors and non functional code quality issues .
syntax errors.
we refer to the llm generated code that causes compilation errors in the software as syntax error code.
such errors significantly impact development efficiency.
we extract error logs and manually analyze the code that failed to compile ultimately categorizing the syntax errors into major categories and subcategories as shown in table vi.
in summary large language models perform worst in handling function and type declarations particularly implicit function declarations and type conflicts.
and llms perform poorly in generating code related to structures often resulting in issues such as accessing non existent members.
these errors may be due to the presence of similarly named functions or structures in the training data of the llms leading to the use of functions or structures outside the provided context in code generation tasks.
we recommend that developers focus on checking external dependencies such as called functions and structures when using llms to generate code.
additionally llms often perform poorly when handling code involving pointers leading to errors such as converting integers to pointers without casting and incompatible pointer types.
non functional code quality issues.
for llm generated codes that have passed systematic testing we conducted a manual code quality review and found that the code oftentable vi syntax errors of llm generated code category proportion function and type declaration errors .
implicit declaration of function .
type conflict .
api parameter count mismatch .
undeclared type .
data structure and member access errors .
non existent structure member .
misuse of structure pointer .
use operator to access an integer member .
type conversion and assignment errors .
making a pointer from an integer without a cast .
incompatible pointer type .
incompatible type assignment .
redefinition .
scope and definition errors .
conflict between static and non static declarations .
incorrect access to structure or union member .
other syntax errors .
lvalue required as the left operand of assignment .
incorrect use of array pointer or vector .
assignment to expression with array type .
incorrect use of parentheses .
invalid binary operands .
expected expression error .
array subscript is not an integer .
subscripted value is pointer to function .
others .
had non functional quality issues such as poor performance and security vulnerabilities.
these issues do not directly affect the normal execution of the code but they can pose potential threats to the software.
for example poor performance may cause system response time delays affecting user experience and overall performance security vulnerabilities may be exploited by malicious attackers leading to data breaches or system crashes.
we have summarized common non functional code quality issues into the following three categories resource management in llm generated code resource management code is often inadequate especially in terms of memory or file management.
for example llm generated code often does not free dynamically allocated memory at the end of the program.
such code can pass compilation and testing but it may lead to potential memory leaks resulting in software performance issues.
code efficiency fig.
a shows an example of low code efficiency.
wtiff pack2tiff is an image data conversion function in the libvips software.
in the original code the function adopts corresponding processing methods according to different image encoding formats while the llmgenerated code uses an inefficient loop to process each pixel modifying and copying pixel by pixel.
although the llm generated code can meet functionality its performance is far inferior to the original code affecting the overall performance of the software.
code robustness the robustness of the generated code is not guaranteed including missing error checking code incomplete error handling and inadequate feedback message.
original code void wtiff pack2tiff wtiff wtiff vipsregion in vipsrect area vipspel q different condition differenet method for int y area top y rect bottom area y vipspel p vipspel region addr in area left y if wtiff ready coding coding labq labq2labc q p area width else if omit multiple branches else memcpy q p area width image sizeof pel wtiff ready llm generated code void wtiff pack2tiff wtiff wtiff vipsregion in vipsrect area vipspel q loop through each pixel point for int y area top y rect bottom area y for int x area left x area left area width x vipspel p vipspel region addr in x y memcpy q p image sizeof pel wtiff ready a an example of low efficiency code.
original code void clusterupdatemyselfannouncedports void if !myself return error handling deriveannounceports myself port myself pport myself cport llm generated code void clusterupdatemyselfannouncedports void myself port server.cluster announce port myself cport server.cluster announce bus port myself pport server.cluster announce tls port b an example of missing error handling.
fig.
examples of non functional code quality issue.
fig.
b shows an example of missing error handling.
in the original code the program first checks if the myself pointer is null to prevent null pointer reference.
however the llm generated code does not perform null pointer checks which could lead to accessing the pointer when it is uninitialized or freed causing software crashes.
user editconclusion for rq3 function and type declaration errors are the most common syntax error of llm generated code.
while even if the code passes compilation and system testing it may still have non functional issues which will negatively affect software reliability and performance.
future research should establish more comprehensive evaluation metrics to evaluate the quality of code generated by llms.
v. t hreats to validity raw data collection.
to simulate real world development scenarios we select mature system software from the real world as the target software for our research.
we chose these software systems because they are widely used have a rich development history and contain mature test suites.
we believe our study is representative although some results may not apply to all kinds of software and all kinds of code language.
there are other human efforts evolved in the data collection process e.g.
description rewriting .
to minimize the impact of human error we organize a team of seven senior software engineers each with at least five years of experience in c programming.
additionally we conduct a double check progress in each step.code complexity.
obfuscation strategies can introduce changes in code complexity primarily in structural and semantic obfuscation.
for example function inlining in structural obfuscation may lead to an increase in the number of lines of code potentially affecting the generation capabilities of large models.
in practice we did not intentionally increase the complexity of the code in any obfuscation method our guiding principle was to ensure that the semantics of the code remained the same before and after obfuscation.
testing process.
due to the presence of flaky tests the testing environment of real software projects can be unstable.
even correct code may fail tests due to contextual or environmental issues.
therefore for each case we run tests at least five times to mitigate intermediate test results.
official test suites may not comprehensively test the correctness of functionality but this represents the best efforts allowing for a better assessment of whether the code meets development requirements.
vi.
c onclusion accurately assessing the code generation capabilities of llms is crucial for their evaluation and improvement.
while existing works have constructed datasets to gauge these capabilities three main gaps persist in objectively evaluating llms real potential the exposure of target code case timeliness and dependency availability.
these gaps arise because the code in current datasets may have been exposed during the training phase of llms and the continuous training and development of llms severely compromise their timeliness.
to address the problem this paper adopts the concept of code obfuscation altering code at various levels while preserving its functionality and output.
we developed a code obfuscationbased benchmark o bfus eval by collecting raw cases from five real world projects which include function descriptions and code.
we then obfuscated descriptions code and context dependencies using a three level strategy symbol structure and semantic .
evaluating four llms on o bfus eval and comparing the effectiveness of different obfuscation strategies we found that after obfuscation the average test pass rate can decreased by .
.
.