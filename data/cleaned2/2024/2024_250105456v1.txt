llm based input space partitioning testing for library apis jiageng li fudan university jgli22 m.fudan.edu.cnzhen dong fudan university zhendong fudan.edu.cnchong wang nanyang technological university chong.wang ntu.edu.sghaozhen you fudan university hzyou23 m.fudan.edu.cn cen zhang nanyang technological university cen001 e.ntu.edu.sgyang liu nanyang technological university yangliu ntu.edu.sgxin peng fudan university pengxin fudan.edu.cn abstract automated library apis testing is difficult as it requires exploring a vast space of parameter inputs that may involve objects with complex data types.
existing search based approaches with limited knowledge of relations between object states and program branches often suffer from the low efficiency issue i.e.
tending to generate invalid inputs.
symbolic execution based approaches can effectively identify such relations but fail to scale to large programs.
in this work we present an llm based input space partitioning testing approach lisp for library apis.
the approach leverages llms to understand the code of a library api under test and perform input space partitioning based on its understanding and rich common knowledge.
specifically we provide the signature and code of the api under test to llms with the expectation of obtaining a text description of each input space partition of the api under test.
then we generate inputs through employing the generated text description to sample inputs from each partition ultimately resulting in test suites that systematically explore the program behavior of the api.
we evaluate lisp on more than library api methods taken from popular open source java libraries e.g.
apache commons lang with .6k stars guava with .8k stars on github .
our experiment results show that lisp is effective in library api testing.
it significantly outperforms state of theart tool evosuite in terms of edge coverage.
on average lisp achieves .
branch coverage surpassing evosuite by .
times.
in total lisp triggers exceptions or errors in the experiments and discovers previously unknown vulnerabilities during evaluation which have been assigned cve ids.
index terms input space partitioning testing large language models symbolic execution api testing.
i. i ntroduction the third party libraries as an essential part in software ecosystems have become one of the most significant contributors to fast development of today s software system.
according to a recent study a java project directly relies on different third party libraries.
vulnerabilities within these libraries can pose significant risks to numerous software systems.
consequently testing libraries is imperative to ensure system security.
however testing library apis is notoriously challenging as it entails exploring a vast input space of multiple pa corresponding author.rameters particularly when these parameters involve objects with complex data types.
the behavior of the libraries can be constrained by a specific state of one or more input objects.
triggering such a state involves generating input values satisfying relevant conditions as well as generating statements to instantiate these objects.
this poses numerous challenges for existing automated test generation techniques search based testing most existing techniques frame automated test generation as an optimization problem over the input space with the goal of generating inputs to achieve maximal code coverage for instance evosuite a widely used automated test generation tool adopts a genetic algorithm to generate tests.
the problem with this type of techniques is the low efficiency issue when tackling the expansive space of inputs involving multiple objects with complex data types within library apis symbolic execution symbolic execution is an effective testing technique that can generate inputs that cover desired program paths.
yannic noller et al.
leverages symbolic execution to guide fuzzing to generate inputs that cover deep program behavior .
despite significant efficiency improvement these techniques face difficulties in scaling to large programs due to inherent limitations of symbolic execution e.g.
spf has limited support for heap input.
sushi proposed by pietro braione et al.
can be only applied to java classes.
in this paper we view automated test generation as a program input space sampling problem.
the ideal way to sample is to compute input space partitions and then choose inputs from each partition so as to cover all possible program behavior.
in this perspective search based approaches kind of leverage heuristics to guide search aiming to sample inputs from as many partitions as possible.
symbolic execution based approaches attempt to compute input space partitions by solving program path conditions and then sample inputs from each partition.
both type of approaches come at a cost.
the former requires executing a large amount of inputs that go through redundant program paths the latter requires heavy computation resources to solve path conditions.
in this work we propose an large language model llm based input space partitioning testing approach for libraryarxiv .05456v1 dec 2024apis.
specifically we leverage llms to infer the input space partitions of a library api under test and then sample inputs from each partition so as to generate test suites with high quality.
recently llms have demonstrated promising capabilities in understanding programs and common knowledge reasoning leading to their widespread adoption in the software engineering domain .
motivated by these capabilities we explore using llms to automate input space partitioning achieving the objectives of symbolic execution without explicitly performing it .
to this end we propose a framework that interacts with llms to compute input space partitions for a given library api and generate input values based on textual descriptions of each partition resulting in high quality test inputs.
subsequently the framework takes those inputs to generate test suites for library api testing.
we evaluated lisp on apis from widely used libraries including apache commons lang3 and google guava.
the results show lisp is highly effective in testing library apis achieving exceptionally high code coverage with a minimal number of generated inputs.
in the comparison experiments lisp outperformed the state of the art technique evosuite achieving .
times higher edge coverage.
furthermore lisp identified exceptions across the libraries including previously undiscovered vulnerabilities which have been assigned cve ids.
to support future research we make our the experimental data and results publicly available at the following link lisp .
ii.
m otivating examples apcomplexmath .
j a v a 2p u b l i c s t a t i c apcomplex pow apcomplex z apcomplex w 3throws a p f l o a t r u n t i m e e x c e p t i o n apcomplex r e s u l t a p f l o a t h e l p e r .
checkpow z w math .
min z .
p r e c i s i o n w. p r e c i s i o n i f r e s u l t !
n u l l return r e s u l t e l s e i f z .
r e a l .
signum z .
imag .
signum a p f l o a t x z .
r e a l a p f l o a t one new a p f l o a t 1l long .max value x .
r a d i x x i g n o r e some code return exp w. m u l t i p l y apfloatmath .
l o g x e l s e return exp w. m u l t i p l y l o g z listing .
org.apfloat.apcomplexmath pow a. importance of code understanding and common knowledge listing presents an api method named pow within theclass apcomplexmath from the apfloat .
this method which takes two parameters named zandw exhibits distinct behaviors based on the content of zandw which means that each input space can be represented by the states of z andw.
specifically when result !
null the api returns theresult directly line when z.real .signum isgreater than or equal to 0andz.imag .signum equals line the api returns the result at line .
otherwise the api engages in a calculation for complex numbers line .
in software testing precise partitioning of the input space facilitates efficient input generation.
symbolic execution is the ideal solution to partition the input space.
we attempt one of the state of the art tools spf.
however it fails to work due to insufficient modeling of native methods when creating an apcomplex object.
search based testing is another approach for input space partitioning which is more scalable compared to symbolic execution.
we use the state of the art tool in the sbst field evosuite with the default configuration and run it for 200s.
evosuite generates test cases but only achieves coverage.
we find that evosuite generates a large number of equivalent inputs none of which can reach line .
in the context of exponentiation awareness of certain corner cases is crucial.
for instance 00is typically undefined the computation process of zw z r is different from that of zw z r .
failure to bridge the gap between such background knowledge and software testing leads to blind exploration of a vast search space for zandw.
therefore it is essential to present an approach that effectively understands and navigates the input space while avoiding falling into the trap of generating invalid or single scenario inputs.
this approach should integrate common knowledge in both codelevel and semantic level.
b. input space partitioning with large language models recently large language models llms have demonstrated considerable capabilities across diverse domains such as code understanding common knowledge acquisition and code generation which align with the requirements for library api testing.
assume that we need to test the pow method.
we can employ llms to partition the input space.
specifically we can provide the signature and code of pow for llms and instruct them to partition the input space.
then we can obtain the text form of the input space partitioning results such as z real part is non negative and imaginary part is w is an apcomplex number.
z real part is negative or imaginary part is non zero w is an apcomplex number .
from the above input space partitioning results we know that llms believes that it should generate a complex number with real positive and imaginary zero which is exactly one of the conditions for entering a block line in listing another implicit condition is result null .
c. input generation with large language models listing presents two types apcomplex andapfloat .
apcomplex inherits java.lang.number and represents complex numbers in mathematics.
apfloat inherits the former type and represents float numbers.
in addition we present two constructors of type apcomplex and the first constructor requires inputs of type apfloat .assume that we intend to construct a corresponding apcomplex instance for the parameter z which complies with the requirements of the text description of this input space partition real part is non negative and imaginary part is .
in general the process can be divided into two necessary steps.
1p u b l i c c l a s s apcomplex extends number p r i v a t e a p f l o a t r e a l p r i v a t e a p f l o a t imag p u b l i c apcomplex a p f l o a t r e a l a p f l o a t imag .
.
p u b l i c apcomplex s t r i n g v a l u e .
.
o v e r l o o k o t h e r c o n s t r u c t o r s 9p u b l i c c l a s s a p f l o a t extends apcomplex p r i v a t e a p f l o a t i m p l impl p u b l i c a p f l o a t long v a l u e .
.
p u b l i c a p f l o a t s t r i n g value long p r e c i s i o n .
.
o v e r l o o k o t h e r c o n s t r u c t o r s listing .
type apcomplex and type apfloat top down type dependency analysis and constructor selection to generate inputs for a reference type we need to acquire all derived classes of that type and all constructors of any involved reference types.
for this example to generate an input object of apcomplex type representing i we first retrieve its available constructors and then identify the appropriate constructors.
this process continues recursively until all relevant reference types are addressed resulting in a sequence of constructors that can be used to generate the target object.
specifically we provide llms with the text description of partition so as to drive llms to select the appropriate constructors.
in listing the first constructor that takes real andimag as two parameters is exactly what we need.
since the type of real andimag is still a reference type we repeat the previous process to generate two apfloat objects.
in this case we use llms to select three constructors as depicted in the upper half of listing .
s e l e c t e d c o n s t r u c t o r s a f t e r t y p e dependency a n a l y s i s a p f l o a t r e a l new a p f l o a t todo a p f l o a t imag new a p f l o a t todo a p f l o a t c1 new apcomplex r e a l imag o b j e c t i n s t a n t i a t i o n s t a t e m e n t s f l o a t r e a l v a l u e .
f f l o a t imag value .
f a p f l o a t r e a l new a p f l o a t r e a l v a l u e a p f l o a t imag new a p f l o a t imag value a p f l o a t c1 new apcomplex r e a l imag listing .
selected constructors and instantiation statements bottom up object instantiation with concrete values after obtaining the appropriate constructors we need to fill in correct values to generate the desired input object.
for this example to instantiate an apcomplex instance representing1 i it is required to construct an apfloat object representing 1and another apfloat object representing according to the selected constructors in the upper half of listing .
specifically we can provide llms with these selected constructors supplemented by a text description ofthe partition with specific values so as to guide llms to generate valid inputs as shown in the lower half of listing .
looking at the process of constructing the zforpow llms can serve as a vital tool in the field of input space partitioning testing.
specifically we have utilized the code understanding and generation capabilities of llms in three place i.e.
input space partitioning top down type dependency analysis and bottom up object instantiation.
iii.
a pproach lisp we introduce lisp a novel workflow designed to strategically guide large language models llms in understanding the source code of api methods.
this approach ultimately generates high quality inputs and tests drivers for library apis.
in figure the lower section i.e.
the gray part illustrates the common process of existing input generation approaches.
we find that search based approaches typically search and partition the input space at runtime often neglecting the source code of the apis .
building on these insights the upper section of figure depicts our proposed workflow which decomposes the api input generation process into three parts input space partitioning top down type dependency analysis andbottom up object instantiation .
a. input space partitioning to systematically generate inputs for a given api under test with the goal of covering all branches and triggering exceptional behaviors efficiently a thorough understanding of the input search space is crucial.
semantic level .
inputs often embody concepts within specific domains e.g.
exponentiation reflecting background knowledge.
this semantic level understanding imposes constraints on input values effectively narrowing and categorizing the input space into distinct partitions.
for example for the parameter zof the pow function in listing a valid value should contain two numbers representing the real part and the imaginary part respectively.
code level .
when implementing a functionality the specific implementation is contingent on factors such as projectspecific logic code optimization strategies and others.
consequently the input space is further restricted and partitioned at code level.
for example pow incorporates a special branch for the parameter zto handle the case where zrepresents a positive real number.
we have designed a prompt to harness the capacities of llms at the semantic and code levels.
the prompt is illustrated in figure .
system instruction .
we highlight input space partitioning as the task we expect the llm to accomplish.
few shot cot examples .
question .
we include only the source code of the api under test.
we emphasize that the source of the api under test encapsulates both semantic level and codelevel knowledge to understand the input space of its parameters.
in addition we also implement a lisp variant described in section iv a which includes the calledfig.
.
approach overview of lisp fig.
.
the prompt for input space partitioning methods based on the call graph in order to provide more contexts.
this variant is called lisp cg.
answer .
we construct a chain of thought that analyzes the code in the order of method signature body and parameters.
we expect the llm to understand the code under our guidance and provide partitioning results for achieving high coverage.
for this part the input is the source code table i of the api under test and the output is a collection of textual descriptions of the input space partitions referred to as specification s table i .
example.
for the pow api presented in listing lisp can produce partitions of the input space.
these partitions are represented in textual form e.g.
z real part is non negative and imaginary part is w is an apcomplex number which covered line .
b. top down type dependency analysis the type of each parameter in the api under test typically can be classified into the primitive type and the reference fig.
.
the prompt for top down type dependency analysis type.
for the primitive type we can create them directly with language specific syntax.
however for the reference type creating an object is not trivial and the following two categories of issues arise simultaneously.
nested reference types .
in various common oop languages the reference type often involve multiple levels of nesting which means that constructing an object of a reference type may require multiple calls to constructors.
multiple constructor candidates .
since a type tends to own multiple constructors different constructors often yield different construction results.
for the first issue we construct a type dependency graph tdg .
in detail we abstract each reference type as a node and view the usage of each reference type during the instantiation of an object as an edge and select all reachable types derived from the types of parameters in the directed acyclic graph.
for the second issue we engage in an interaction with the llm to select the most appropriate constructor basedtable i glossary of keywords in prompts no keyword description example code the source code of the api under test.
public static apfloat pow apcomplex z apcomplex w ... type the fully qualified name of a type.
org.apfloat.apfloat org.apfloat.apcomplex parameter the parameter list of the api method under test.
apcomplex z apcomplex w constructor the constructor of a type.
apcomplex apfloat real apfloat imag dependencythe is a and has a relationships between two types.
represented as text class org.apfloat.apfloat constructors public apfloat float value specification the constraints on the input space partition.
z with n or n on the text description of the input space partition i.e.
specification .
we design a prompt to drive llms to select the most appropriate constructor for each type along the topdown process.
the prompt is illustrated in figure .
system instruction .
we highlight constructor selection as the task and expect that the llm can employ the specification to select only one constructor table i for each type.
few shot cot examples .
question .
for each parameter in the api under test we provide a list of constructor s for each type and attach the corresponding specification along with the dependency information of the parameter type recorded in the tdg.
answer .
we expects the llm not only to take all provided information into consideration but also to select only one constructor for each type.
for this part the inputs are the code of the api under test and the specification s while the output is a mappings between parameter table i and its corresponding constructor table i sequence used for instantiation.
examples .
for the constructors presented in listing lisp can output the selected constructors like the upper half of listing .
specifically lisp first selects the first constructor for the apcomplex type parameter in the api under test and then selects the first constructor of apfloat for both apfloat real and apfloat imag according to one of partitions outputted by input space partitioning.
we break down the type dependency analysis task through the tdg into multiple sub tasks which increases the number of interactions with the llm but reduces the token of a single prompt which avoids exceeding the token limit and also helps the llm focus on selecting the appropriate constructor for a single type.
c. bottom up object instantiation the ultimate goal of lisp is to generate high quality inputs.
we need to fill in appropriate values into the selected constructors and obtain instantiation statements through interaction with llms.
we design a prompt to drive llms to fill the appropriate values into the selected constructor.
the prompt is illustrated in figure .
system instruction .
we highlight two parts of statements that the llm is supposed to provide the instantiation statements about the target inputs and the import statements related to instantiation.
fig.
.
the prompt for bottom up object instantiation few shot cot examples .
question .
we provide all selected constructor s and the specification to assist the llm in filling in the appropriate values.
then we consider the objects instantiated in this way as arguments.
answer .
we construct a chain of thought and expect the llm to synthesize the instantiate statements and the relevant import statements.
for this part the inputs are specification s and selected constructor s while the outputs are statements that can be used in object instantiation.
examples .
for the selected constructors presented in the upper half of listing if the specification represents 0i lisp can fill .0f and .0f into selected constructors and finally generate instantiation statements like in the lower half of listing .
test driver generation .
after interacting with the llm and extracting the statements for constructor invocation we encapsulates these statements with the necessary class and method declarations i.e.
class driver and void main ... .
the generated driver is expected to instantiate objects and invoke the api under test.
this process results in the creation of an executable program.
the driver template is available .iv.
e valuation we conduct extensive experiments to evaluate lisp with the following research questions.
rq1 code coverage .
to what extent can lisp cover the code?
can lisp outperform the state of the art test tools evosuite and spf in terms of code coverage?
rq2 usefulness .
can lisp trigger exceptions?
we only focus on unhandled exceptions and errors both of which implement java.lang.throwable but used in different scenarios can lisp find vulnerabilities previously not discovered?
rq3 cost .
can lisp outperform evosuite in terms of time while keeping the token consumption within a reasonable range?
rq4 ablation study .
are input space partitioning and top down type dependency analysis of lisp both effective?
how do they contribute?
a. evaluation setup experiment subjects .
to evaluate lisp we selected java libraries from previous studies and some awesome lists i.e.
awesome java useful java links with the requirement that each selected library is highly starred and has recent code commits.
all experimental data and results are available on our site .
table ii details of j ava libraries selected .
loc the number of line of code of the library stars the number of stars of the github repository apis the number of selected api methods no library name version loc stars apis commons lang3 .
.
.6k .6k guava .
.
jre .7k .8k jfreechart .
.
.1k .1k jgrapht .
.
.8k .5k joda time .
.
.2k .9k threeten .
.
.9k time4j base .
.
.3k ical4j .
.
rc3 .1k sis utility .
.8k xchart .
.
.9k .5k we have obtained api methods employing the following strategies for method selection to improve the quality of our datasets.
exclude methods within abstract classes or interfaces since the classes or interfaces cannot be instantiated directly.
exclude methods that only have one basic block since edge coverage is guaranteed and meaningless.
exclude methods inherited from class object e.g.
equals tostring hashcode .
implementation .
to demonstrate the feasibility of lisp we have implemented it in java.
specifically we utilize jdt andsoot to obtain ast class hierarchy and call graph.
we employ langchain to interact with llms.
it is important to note that while the implementation is specificto java the underlying concept of lisp can be applied to common oop languages and automated testing frameworks in a more general scene.
baselines variant .
we have chosen two baselines in order to better conduct various experiments.
search based baseline.
evosuite a state of the art tool in the field of sbst is still actively maintained and has continuously been incorporating new sbst optimization algorithms since its release.
it is widely used in both academia and industry.
we choose the latest version released in evosuite v1.
.
and refer to the time budget used in previous studies.
.
llm based baseline.
we only provide the signature and code of the library api under test and expect the llm to output the same format of results of lisp directly.
lisp cg lisp with call graph .
a variant that first obtains the call graph of the target library and then includes the source code of those methods called within the api under test when constructing the prompt in order to investigate the impact of the source code of the called method as mentioned in section iii.
we include the source code of only one layer of methods invoked by the api under test.
lisp never exceed the token limits during our evaluation even though there are no prompt trimming or compression tricks in lisp.
the prompt of lisp cg is available at our site .
symbolic based baseline.
we have tried spf with lazy initialization whose performance and scalability are among the best.
we initially run spf on apis but only are able to run.
the remaining apis suffer from issues such as path explosion insufficient support for collections arrays and interfaces etc.
as a result we abandon the comparison with symbolic execution tools.
metrics .
we evaluate lisp and baselines based on branch coverage and the number of found exceptions.
specifically we adopt the branch coverage collection module used in evosuite to record coverage during each execution.
for exception detection we employ the same module in jqf to record detected exceptions.
identifying false positives.
unlike system testing api testing may generate false positives.
these false positives occur when the generated inputs violate the assumptions of the apis leading to exceptions.
the api assumptions are typically specified in javadoc comments.
for instance as shown in figure api intarraytolong from library commons lang3 assumes their parameters need to meet srcpos nints src.length constraint.
during testing inputs that do not meet such constraints can be generated resulting in false positives.
we identify such false positives based on a convention used in the java api specification.
specifically when an api assumption is violated the type of exception thrown is often specified in the javadoc comments or the signature of the api.
javadoc exceptions.
as shown in figure exceptionarrayindexoutofboundsexception for constrainttable iii details of results in rq1.
metrics indicatorslibrariesoverallcommons lang3 jfreechart jgrapht guava joda time threeten time4j ical4j sis utility xchart inputlisp evosuite 100s evosuite 150s evosuite 200s llm baseline lisp cg edgelisp evosuite 100s evosuite 150s evosuite 200s llm baseline lisp cg edge inputlisp .
.
.
.
.
.
.
.
.
.
.
evosuite 100s .
.
.
.
.
.
.
.
.
.
.
evosuite 150s .
.
.
.
.
.
.
.
.
.
.
evosuite 200s .
.
.
.
.
.
.
.
.
.
.
llm baseline .
.
.
.
.
.
.
.
.
.
.
lisp cg .
.
.
.
.
.
.
.
.
.
.
timelisp evosuite 100s evosuite 150s evosuite 200s llm baseline lisp cg time inputlisp .
.
.
.
.
.
.
.
.
.
.
evosuite 100s .
.
.
.
.
.
.
.
.
.
.
evosuite 150s .
.
.
.
.
.
.
.
.
.
.
evosuite 200s .
.
.
.
.
.
.
.
.
.
.
llm baseline .
.
.
.
.
.
.
.
.
.
.
lisp cg .
.
.
.
.
.
.
.
.
.
.
fig.
.
false positive exception examples javadoc signature srcpos n src.length is specified in the javadoc comments.
signature exceptions.
as shown in figure exception numberformatexception is specified in its signature.
in our experiments we take a conservative approach by filtering out all exceptions related to api assumption violations during result reporting.
specifically for each api under test we use soot to extract exceptions declared in javadoc comments and signatures and exclude these exceptions from the collected data during testing.
the related code can be found in our artifact .evaluation environment .
our experiments run on a bit linux machine ubuntu .
with a .8ghz core amd ryzen 5700u cpu and 16gb ram and use an openai api key with rpm to run all experiments.
we use gpt3.
turbo with a token limit of 16k.
to make the output more consistent we set the temperature to .
b. rq1 code coverage test inputs with higher code coverage are usually indicative of more comprehensive execution across the api functionalities.
in addition it is critical to generate high quality inputs stably for api testing.
in this study we evaluate lisp from three dimensions average code coverage for individual libraries and overall average quality indicated by the coverage improvement caused by inputs and efficiency indicated by the speed of generating valid inputs .
table iii presents the results of our experiment input.
i for the lisp and llm baseline rows each number represents the total number of valid inputs generated by the experiment.
these inputs are generated by the tool for each api in the corresponding java library executed once.
ii for the evosuite xs rows each number represents the total number of inputs generated by running each api for x seconds using evosuite.
edge.
in section iv a for the lispfig.
.
average code coverage of the selected libraries.
fig.
.
a sankey diagram illustrating the filtering process that utilizes javadoc exceptions rule and signature exceptions rule to handle all captured exceptions and errors.
andllm baseline rows each number represents the total number of distinct edges covered by running each api just once in the corresponding library which is also identical to the numerator of the average code coverage metric.
time.
each number represents the total time to generate inputs for all apis in the corresponding java library.
result analysis .
average code coverage.
as shown in figure and table iii in the selected libraries lisp overall outperforms both baselines with an average code coverage that is .
times that of evosuite 100s .
times that of evosuite 150s and .
times that of evosuite 200s.
lisp cg achieves similar code coverage with much more inputs.
in addition as shown in table v lisp cg consumes much more tokens.
quality.
as shown in table iii in terms of coverage improvement caused by inputs lisp still overall outperforms both baselines with fewer inputs but highest edge coverage whose code coverage improvement per input is .
times that of evosuite 100s .
times that of evosuite 150s and .
times that of evosuite 200s.
llmbased baseline generates the smallest number of inputs and attained less edges than lisp.
efficiency.
as shown in table iii considering the time efficiency for generating valid inputs evosuite outperforms lisp because evosuite uses search based algorithms making it easier to generate valid inputs.
however the efficiency of llm based variants is not unacceptable.
summaries .
in terms of code coverage lisp outperforms both search based baseline i.e.
evosuite and llmbased baseline in terms of quality lisp outperforms both baselines and achieves the highest coverage improvement per input.
in terms of efficiency lisp outperforms all evosuite variants but llm based approach exhibited less fig.
.
top exception types found by lisp.
fig.
.
a venn diagram representing the distribution of exceptions found by lisp evosuite 200s llm baseline as well as the details of cves time cost because lisp requires more interaction with llms.
c. rq2 usefulness the ability to find software vulnerabilities is one of the most effective criterion for judging an automated testing tool.
in this study we mainly concern three aspects statistics indicated by categories and count of exceptions differences indicated by the diversity in exceptions triggered by lisp and baselines and vulnerabilities indicated by findings .
result .
statistics.
lisp captures a total of java exceptions or errors.
as shown in figure after applying the two filtering rules outlined in section iv a wherein rule javadoc exceptions filters out of those and rule signature exceptions subsequently filters out an additional we finally obtain exceptions totaling types.
as shown in figure it is important to note that npe accounts for the largest proportion reaching .
followed by index out of bound is the second most common accounting for a total of .
aioob .
sioob .
ioob .
.
we also record the exceptions captured by baselines among which llm baseline captures types of exceptions a total of while evosuite with a time budget of 200s the best in evosuite captures types of exceptions a total of but due to space constraints we no longer tabulate .
differences.
as depicted in figure lisp captures all the exceptions identified by llm baseline which is expected given that lisp has extended the capabilities of llm baseline through prompt engineering.
in absolute terms lisp only misses exceptions that evosuite detects while evosuite fails to identify exceptions that lisp detects.
vulnerabilities.
we conduct a case by case study on exceptions found during our evaluation.
then we identify vulnerabili ties and report them.
as shown in figure previously undiscovered vulnerabilities are identified as cves to date all of which are detectable by lisp with of those being unique findings of our approach.
table iv shows that npe still accounts for the largest proportion in identified cves.
in addition a stackoverflowerror is identified as a cve.
table iv the type and idof found cve s. categories cve id nullpointerexceptioncve cve cve cve cve cve cve arrayindexoutofboundsexceptioncve cve cve cve stringindexoutofboundsexception cve stackoverflowerror cve case study cve .
to better illustrate the role of lisp in triggering exceptions and discovering vulnerabilities we select one of cves that lisp found during our experiments cve2024 .
as shown in listing modpow is an instance method of doublemodmath used to calculate the result of an modm where mdenotes the return value of getmodulus .
when n it naturally returns 1directly.
when n due tofermat s little theorem am mod m holds when mis prime therefore am n an mod m .
inmodpow it employs recursive calls to gradually transform nintom n until l m n where ldenotes the number of recursive layers.
for power calculation it is not wrong in mathematics.
however in the field of programming the size of the stack is limited.
if m 1is excessively small and n is a negative number with an extremely large absolute value e.g.
p n .
too many recursive calls will lead to a stack overflow.
doublemodmath .
j a v a 2p u b l i c f i n a l double modpow double a double n i f n return e l s e i f n return modpow a getmodulus n i g n o r e some code return r doubleelementarymodmath .
j a v a 12p u b l i c f i n a l double getmodulus return t h i s .
modulus 15p r i v a t e double modulus listing .
cve stackoverflowerror due to recursive calls 1p u b l i c c l a s s testmodpow test p u b l i c void testmodpow doublemodmath dmm new doublemodmath a s s i g n t o modulus dmm.
setmodulus throw j a v a .
l a n g .
s t a c k o v e r f l o w e r r o r8 dmm.
modpow .
listing .
poc of cve we attribute the generation of this input originates to llms understanding of code and real world knowledge.
at the code level llms recognize the significance of recursive calls when n .
at the conceptual level llms consider that when m is small modpow demands a substantial number of recursive calls to enter the subsequent logic by combining real world knowledge from fermat s little theorem with the possible reasons of stack overflow.
case study lisp s miss.
to better illustrate the limitations of lisp and explore how to further enhance the current lisp capabilities we conduct a case by case analysis on the exceptions that evosuite can trigger but lisp misses.
finally we find that index out of bound accounts for .
while npe accounts for .
.
s t r i n g s .
j a v a 2p u b l i c s t a t i c s t r i n g t o s t r i n g f i n a l class ?
c l a s s e f i n a l o b j e c t .
.
.
p r o p e r t i e s f i n a l s t r i n g b u i l d e r b u f f e r new s t r i n g b u i l d e r .
append c l a s s e s .
getshortname c l a s s e .
append i g n o r e some code f o r i n t i i p r o p e r t i e s .
l e n g t h i f i n a l o b j e c t v a l u e p r o p e r t i e s i f v a l u e !
n u l l i g n o r e some code return b u f f e r .
append .
t o s t r i n g listing .
an exception that evosuite detected but lisp failed as shown in listing tostring is a static method that evosuite has successfully triggered an exception for but lisp misses.
this method takes a class object and a varargs ofobject as parameters.
by reviewing the code we find that if the number of arguments passed to the properties is not even an arrayindexoutofboundsexception will be triggered at line .
we have summarized two reasons why lisp fails to trigger this exception.
the current prompt design of lisp lacks special treatment for arrays resulting in not good enough performance in detecting indexout of bound exceptions.
lisp generates fewer inputs and undergoes a certain randomness.
in the future we will further enhance lisp in these aspects.
summaries .
in terms of statistics lisp triggers exceptions a total of types.
in addition lisp fully covers the exceptions triggered by llm baseline while also triggering .
of the exceptions triggered by search based baseline i.e.
evosuite 200s .
in comparison the search based baseline only triggered .
of the exceptions.
in terms of vulnerabilities lisp identifies previously undiscovered cves in total and of them are derived from the exceptions that both baselines fail to trigger.table v details of parsing failure compiling failure and token consumption in rq3.
metrics indicatorslibraries overall commons lang3 jfreechart jgrapht guava joda time threeten time4j ical4j sis utility xchart api failedlisp lisp cg llm baseline invalid input lisp .
.
.
.
.
.
.
.
.
.
.
lisp cg .
.
.
.
.
.
.
.
.
.
.
llm baseline .
.
.
.
.
.
.
.
.
.
.
token inputlisp lisp cg llm baseline token outputlisp lisp cg llm baseline costlisp .
.
.
.
.
.
.
.
.
.
.
lisp cg .
.
.
.
.
.
.
.
.
.
.
llm baseline .
.
.
.
.
.
.
.
.
.
.
d. rq3 cost two main aspects of cost need to be considered when using llms to generate inputs.
failures.
how many apis the llm cannot correctly provide parsable answers due to hallucinations.
additionally how much of the generated code is actually not executable.
token consumption.
whether the token cost of interacting with the llm is within an acceptable range.
table v presents the results of experiments.
api failed.
each ratio represents the number of apis that failed to generate any inputs the total number of apis .
invalid input.
each number represents the ratio to the total number of inputs generated cannot be run directly.
token input and token output.
each number represent the amount of tokens consumed.
cost.
it is obtained according to token input and token output which is based on the openai billing standard in us dollars.
result .
failures.
as shown in table v all the llmbased variants demonstrate stable output under gpt .
turbo .
however nearly inputs generated by both lisp and the baseline cannot be run directly while lisp cg has around lower failure rate.
token consumption.
the pricing of gpt .
turbo we use is us .
per 1m input tokens and us .
1m output tokens .
as shown in table v after testing apis lisp incurs a cost of .
with .95m tokens as input and .24m tokens as output.
also we run lisp cg and llm baseline.
for lisp cg lisp with deeper functions on the input side the token consumption increases significantly over on libraries like jfreechart and guava.
the overall input token consumption across the libraries increased by more than .
on the output side the token consumption increases slightly since the output formats are not changed.
for llm baseline both the input token and output token consumption decrease significantly because the llm baseline refrains from frequently interacting with the llm on the task of constructor selection.
analysis .
the lisp and lisp cg can yield parsing failures during the whole workflow depicted in figure .
in contrast the llm based baseline only outputs the results directly which reduces interactions and fewer parsing failures.
actually nearly failure rate is acceptable .
the failure rate is stable across libraries for lisp and lispcg.
lisp cg provides the llm with more context and results in a lower failure rate.
however the baseline exhibits a large variance possibly due to a lack of task decomposition for input generation.
summaries .
in terms of failures nearly half of the inputs generated by lisp are not runnable but it is still acceptable .
in terms of token consumption lisp naturally consumes more tokens than the llm based baseline but overall it still remains within a reasonable range.
furthermore lisp cg consumes much more token than lisp although it achieves more stable output and higher coverage.
e. rq4 ablation study in this study we explore the role of each part within lisp and evaluate their contributions to the overall approach.
in section ii we have summarized the input object generation process and the importance of input space partitioning.
here we design an ablation study that consists of three parts no isp tda since we need instantiation statements to generate input objects and test drivers .
isp oi without top down type dependency analysis a variant that cannot select the appropriate constructors step by step and expects llms to generate inputs directly.
tda oi without input space partitioning a variant that only simulates the process of input generation solely through top down type dependency analysis and bottom up object instantiation.fig.
.
the experiment results of ablation study.
result analysis .
as shown in figure we can see that lisp overall performs the best followed by w o tda oi and w o isp.
isp oi brings a certain decline code coverage of isp oi is .
which is .
of lisp .
based on the results of input space partitioning the llm still generates inputs purposefully.
however the absence of tda in this variant contributes to the generation of invalid objects.
tda oi brings a significant decrease both in average code coverage and in exceptions code coverage of tda oi is .
which is .
of lisp .
this further indicates that the llm lacks essential directives in the process of constructor selection due to the absence of input space partitioning.
summaries .
input space partitioning and top down type dependency analysis are both effective and contribute significantly to lisp.
input space partitioning significantly improves the code coverage of the input objects generated by llms.
top down type dependency analysis assists llms in effectively understanding nested reference types and generating valid objects.
v. l imitations interpretability challenges.
since the selected llm used in section iv is closed source we cannot provide a set of state of the art prompts.
complicated api interactions.
currently lisp cannot generate a sequence of api calls to handle interactions between apis.
this is our future research direction.
currently used drivers.
the term inputs of a method should also include environment variables system configurations and more.
our drivers can merely generate arguments for the api under test.
document enhanced prompt engineering.
currently we only include code comments when feeding api code into llms.
we believe that it would be beneficial to integrate relevant documentation and we plan to investigate retrieval augmented generation rag to achieve such an integration in future work.
vi.
r elated work a. input generation input object generation is a crucial component of automatic test suite generation that has received significant attention from researchers.
over time various techniques have been employed in the field of object oriented input generation .
gordon fraser et al.
developed evosuite which is considered the state of the art sbst tool.
to further improve performance other research projects promote the search based approaches through advanced algorithms.
.
for instance yun lin et al.
developed evoobj that constructs an object construction graph via static analysis to generate a test seed template.
harrison green et al.
developed graphfuzz that mutates the dataflow graph to generate more test templates and unit tests.
b. large language models present large language models llms are typically developed through a two step process .
initially they are trained on massive quantities of diverse text data enabling them to capture the intricacies of language and acquire a wide range of knowledge .
subsequently these pretrained models undergo a fine tuning phase using additional datasets further refining their understanding and text generation abilities allowing them to possess extensive knowledge language understanding and text generation capabilities .
in addition they possess the capabilities to generate consistent and appropriate text results for various natural language processing tasks such as text generation information extraction etc.
recently llms are applied to various fields of secure software development life cycle including implementation maintenance and testing .
to interact with llms more efficiently prompts with task definitions and demonstrations are typically employed for better performance .
in the context of software testing llms are often provided with zero shot or few shot prompts to synthesize input generators method invocations and assertions .
vii.
c onclusion and future work in this paper we explore the potential of llms in the field of input space partitioning testing.
compared to the existing techniques we have utilized the information in the code which plays a crucial role in constructing high quality inputs.
our experiments show that our approach achieves higher coverage higher efficiency and stronger ability to find vulnerabilities.
in future work we aim to build upon and extend these findings.
we plan to address the sophisticated challenges of api testing such as test generation involving multiple apis and api testing in microservices.
furthermore we will delve into the combination between software testing and llm related emerging technologies e.g.
agents in order to explore the boundary of automated software testing.
we hope that llms can enable the automated design and execution of test cases the comprehensive analysis of results and even the suggestion of improvements.
in this manner we will refine not only the efficacy and accuracy of automated tests but also their scalability across diverse and complex software systems.