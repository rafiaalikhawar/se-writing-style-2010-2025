invivo fuzzing by amplifying actual executions octavio galland canonical argentinamarcel b ohme mpi sp germany abstract a major bottleneck that remains when fuzzing software libraries is the need for fuzz drivers i.e.
the glue code between the fuzzer and the library.
despite years of fuzzing critical security flaws are still found e.g.
by manual auditing because the fuzz drivers do not cover the complex interactions between the library and the host programs using it.
in this work we propose an alternative approach to library fuzzing which leverages a valid execution context that is set up by a given program using the library the host and amplify its execution.
more specifically we execute the host until a designated function from a list of target functions has been reached and then perform coverage guided function level fuzzing on it.
once the fuzzing quota is exhausted we move on to fuzzing the next target from the list.
in this way we not only reduce the amount of manual work needed by a developer to incorporate fuzzing into their workflow but we also allow the fuzzer to explore parts of the library as they are used in realworld programs that may otherwise not have been tested due to the simplicity of most fuzz drivers.
i. i ntroduction today fuzz drivers have to be developed to make a software library ammenable to fuzzing.
fuzzing is a popular automated testing technique which has proven to be very effective at bug finding with tens of thousands of vulnerabilities discovered in commonly used software .
since this technique involves executing the program when applying it to code libraries it becomes necessary to implement a fuzz driver.
a fuzz driver is a piece of code that acts as the entry point for execution during the fuzzing campaign.
it sets up an artificial calling context and is responsible for accepting data from the fuzzer and feeding it into the library with the appropriate format.
traditionally fuzz drivers are implemented manually which constitutes a major hinderance to widespread adoption of fuzzing.
for instance google incentivices the development of fuzz drivers for important open source projects by paying up to 30k usd of integration awards .
google s project ossfuzz is primarily a community maintained collection of fuzz drivers for open source projects.
moreover fuzz drivers do not capture the complex interaction that actual host programs have with the library.
they often set up too simplistic a context and seperately target very specific parts of any given api.
while this allows developers to maximize fuzzer throughput for instance libfuzzer s documentation advices developers to make fuzz drivers execute as fast as possible and leave any global state unmodified after execution has finished it also reduces the search space for bugs that could be observed during normal execution by a host but not during executions generated via the fuzz drivers.
work done while affiliated with mpi sp.amplifier point amplifier constraints asn1 parse sizeof pp len bio const char pp long len int len c openssl hexstr2buf sizeof str c const char str long ossl punycode decode sizeof penc enclen char penc size tenclen sizeof pdec enclen int pdec int poutlen enclen c sizeof poutlen poutlen enclen cms kek cipher sizeof in inlen char size t char in size tinlen inlen c cms keyagreerecipientinfo int table i four of amplifier points semi automatically selected for o penssl.
cis a constant chosen to prevent spurious out of memory errors.
for brevity we omit names for parameters which are not fuzzed .
in fact despite an abundance of fuzz drivers and years of fuzzing it is still possible to find vulnerabilities in software libraries by manual auditing that could have been found by fuzzing if only the right fuzz driver was written.
for instance recently a high severity vulneratility has been found in the openssl project which involved faulty memory management during parsing of punycode and resulted in a stackbuffer overflow cve .
in the aftermath of the discovery it was found that this vulnerability could be exposed in a matter of minutes through fuzzing if only the relevant part of the code was being targeted.1moreover the relevant function was being executed by the test suite which suggests that if the test suite had been amplified by fuzzing the bug might have been spotted earlier.
in this paper we propose in vivo fuzzing to make all code subject to fuzzing by i identifying amplifier points ii injecting function level fuzzers at amplifier points and iii amplifying actual executions from a host application that is using the target library.
this approach side steps any requirement for fuzz drivers and allows us to amplify executions generated in any way as they are entering an amplifier point.
amplifier points .
while it is possible to choose every function entry as amplifier point to maximize utility we would like to focus on the most interesting functions.
in order to identify such functions the user can rely on their expert knowledge of the codebase or on automated static analyses.
for our implementation 2we choose functions that are associated with parsing a specific data chunk from the input sequence of bytes.
without loss of generality this simplifies the data types used for amplification and minimizes the number of false positives.
why cve was not detected by fuzz testing criteria involves having at least one parameter whose type is a pointer to a byte stream and has a parsing related name e.g.
parse decode .
table i col. shows four of amplifier points automatically identified for openssl.
amplifier preconditions .
in vivo fuzzing mutates the input parameters of functions chosen as amplifier points.
the hope is that the mutational approach corrupts the valid program state minimally to maintain the validity of the resulting program state and minimize the number of false positives.
nevertheless there are certain constraints that need to be satisfied to maintain validity.
these preconditions take the form of a conjunction of constraints that arguments need to satisfy.
to minimize false positives when specifying amplifier points we allow such preconditions to be specified as well.
table icol.
shows the preconditions for the four amplifier points in openssl.
instrumentation and runtime .
in order to fuzz a library with our approach it is first necessary to find a suitable host which uses it and instrument both of them during compilation.
this instrumentation enables us to intercept any call to an amplifier point during an execution of the host.
upon invocation of an amplifier point we can proceed to amplify the execution by repeatedly forking into a shadow execution replacing the parameters passed to the function with parameters provided by the fuzzer and allowing this shadow execution to terminate while monitoring the shadow process for potential crashes.
in vivo fuzzing iii .
to study the effectiveness of our invivo approach we implemented our tool called afllive and measured the difference in code coverage achieved between the unamplified original executions and the amplified shadow executions.
for each of the four target libraries we chose a host program and input to generate unamplified executions.
indeed we observe a substantial increase in code coverage without false positives indicating that afllive effectively explores the valid neighborhood of the original execution.
auto harnessing iv .
an approach to enable fuzzing for a library without manual intervention is the automatic synthesis of fuzz drivers.
to study the difference in effectiveness we compare afllive against state of the art fuzz driver generators.
specifically we choose the fuzz drivers generated by fuzzgen and fudge and compare them with our approach on the fuzzgen and fudge benchmarks.3ensuring the same initial conditions we find that our prototype is able to identify bugs in one of the subjects memory corruption bugs and assertion violations while fuzzgen and fudge are unable to find any.
furthermore our prototype consistently achieves greater code coverage on all of their benchmarks.
test amplification v .
we discuss the amplification of the executions generated by a test suite as a special use case of invivo fuzzing.
for the openssl example amplifying the test suite did not only rediscover the punycode vulnerability but also found a previously unknown vulnerability that received .4k usd in bug bounty.
test cases often cover certain 3we spent several months conducting experiments with the utopia fuzz driver generator but could only reproduce false positives on the original and most recent versions of the benchmark programs.
details in the appendix.
fig.
overall procedure.
edge cases or are designed to expose regressions similar to previously discovered bugs.
amplifying such test cases allows us to search their neighborhood to bring to light new bugs or existing bugs that have been incompletely fixed.
in fact over of days exploited in the wild are variants of previously discovered vulnerabilities.4also test suites often achieve high code coverage.
amplifying the test suite thus enables the fuzzer to reach deep into the code.
during amplification the test cases practically become fuzz drivers for in vivo fuzzing.
in summary the main contributions of this work are an approach that auto enables fuzzing for every compilable system or library subject to user defined constraints that is executed e.g.
in production.
a way to harness existing test suites by amplifying their coverage and exploring the neighborhoods states induced by existing regression tests.
an open source prototype implementation afllive and an extensive evaluation available at octaviogalland afllive.
ii.
i n vivofuzzing given a host process pand a set of interesting functions f called amplifier points in vivo fuzzing piggybacks on the correct execution of the host process to generate a valid library state calling context and arguments for any function f f. trying to minimize interference with the original process an in vivo fuzzer proceeds to repeatedly fork the execution and mutate the parameters of a targeted function call within the constraints cspecified by the user and in a coverage guided manner to generate a crashing function call.
in vivo fuzzing is inspired by the mutational fuzzing approach for file processing programs or protocol implementations .
given a valid seed input such as a pdf file for a pdf reader a mutational fuzzer slightly corrupts the valid file by applying various mutation operators to generate semi valid files that can still reach deep into the parsing process but suddenly induce crashes in the fileprocessing program.
we might consider the generated inputs to be within the neighborhood of the valid seed file.
moreover given a seed corpus with a high diversity a mutational fuzzer can cover a large diversity of program behaviors in the fileprocessing program.
in vivo fuzzing function fuzz input amplifier points f types t constraints c input instrumented process p time budget t0andt1 global corpus q local corpus qf for all f f crashes q shadow process p fork p for each function f fexecuted in pdo objects objs collect initial args p f types t tcorresponding to f args args serialize objs f t add args to local corpus qf add f args to global q end for for each function f fexecuted in pdo while t0not expired do argsq select qf forf find types t tand constraints c c fuzz function args p f t c q q q f q end while end for while campaign not aborted and t1not expired do tuple f q select q forf find types t tand constraints c c fuzz function args p f t c q q q f q end while output crashes q similarly we propose to use as seed a valid calling context andvalid function arguments generated by a host.
this way an in vivo fuzzer remains within the neighborhood of a valid program state when fuzzing a function.
assuming the host application generates several calls to the library at different amplifier points our in vivo fuzzer can reach deep into the program and cover and amplify a diverse set of program states.
a. overall procedure figure sketches the overall procedure.
given the host code including the library code and the user specified amplifier points and constraints the first step is to compile and instrument the program.
our instrumentation pass introduces a function call into our in vivo runtime within the preamble of every function identified as amplifier point.
during fuzzing this transfer of control allows the runtime to create a shadow process and independently fuzz the function arguments in that shadow process in collaboration with the in vivo fuzzer.
we implemented our prototype afllive on top of afl .02c .
instrumentation .
our instrumentation pass llvm adds the runtime whose purpose is to mediate between the invivo fuzzer and running process of the instrumented binary.
at the entry point of the main function afllive inserts a call into our runtime to initialize any necessary state and communicate with the fuzzer.
at the entry point of an amplifier point the instrumentation pass inserts a call into our runtime containing the name of the amplifier point and the memory addresses of the arguments that will be fuzzed.
additionally afllive hooks the exit point of every amplifier point to facilitate early termination of the host if configured in this way.amplifier points .
to focus the in vivo fuzzing on interesting library functions we require the user to specify a set of functions called amplifier points.
this selection need not be limited to library api functions only.
it is possible to choose these amplifier points manually or using an auto discovery process.
generally we would be looking for functions whose signature or behavior suggests they may be attacker controllable and contain vulnerabilities.
for instance our prototype uses codeql to find parsing functions5 which are usercontrolled by default and have the added benefit that constraint specification for them tends to be particularly simple since they typically take a byte array and its length .
amplifier constraints .
to minimize the number of false positives the in vivo fuzzer also takes user provided amplifier constraints that the generated function parameters need to satisfy before they are passed into the amplified function.
these amplifier constraints carry the same role as the preconditions in property based testing .
they take the form of binary relationships between arguments and or constants.
for example in row of table i a constraint can be seen which implies that the pointer ppmust point to an array of length len and that len should be less than a constant c. amplifier types .
the instrumentation pass also records type information for the given amplifier points in json format .
during fuzzing these amplifier types are used to serialize function parameter objects to a sequence of bytes for the in vivo fuzzer and vice versa deserialize for the runtime similar to the coverage guided java fuzzing approach proposed by padhye lemieux and sen .
this type information is composed of the bitwidth for primitive types fields types and offsets for struct types and the type of the pointee for pointers.
note that since the collected types are in llvm intermediate representation ir types these three cases cover every kind of variable types encountered for fuzzing most targets.
b. in vivo fuzzing algorithm algorithm starts with the user provided amplifier points and constraints the auto generated amplifier types an instance of the instrumented host binary p and two user provided time budgets t0andt1 which determines the lengths of the screening phase and the main fuzzing loop respectively .
global and local corpora .
in line all seed corpora are initially set to the empty set.
the fuzzer maintains two global corpora qandq and one local corpus qffor every amplifier function f f. throughout the campaign the global corpus will contain tuples where the first element is an amplifier point and the second the serialized function arguments.
a local corpus does not need the amplifier information and is hence a set of serialized function arguments.
since the fuzzer proceeds in a coverage guided manner the local and global corpora q andq contain arguments that have been observed to be coverage increasing and crash inducing resp.
.
5this script checks each function s name against a predefined list of substrings and validates if at least one of its parameters is a pointer or double pointer of type char oruint8 t and another one is an number.forking .
in line the execution of process pis forked which allows the host to continue execution normally while we keep a handle to the shadow execution which will be used for fuzzing.
we assume that the forked process is isolated from the original execution and does not interfere with it.
conceptually we assume the process has the ability to be rewound back to the invocation of any amplifier point which is needed to alternate amplifier points during fuzzing.
auto collecting initial seeds .
in line the fuzzer harvests the initial seeds from the original execution.
these seeds are later used for coverage guided mutational fuzzing.
for every amplifier point that is executed in the original running process our instrumentation pass made sure the call is routed through the in vivo runtime which collects the function arguments as objects from the forked shadow process line .
these objects corresponding to the function arguments are serialized and added to the global and local corpora.
screening loop .
in line the fuzzer fuzzes every executed amplifier point for a fixed amount of time in order to collect sufficient coverage information for the main fuzzing loop.
the time budget t0for every amplifier point is fixed by the user.
without the screening loop all amplifier points will be considered as equally good at generating coverage increasing inputs since the coverage collected during the initial non amplified execution will be exactly the same for all initial seeds.
the screening loop over all amplifier functions forces the fuzzer to explore which regions of code each amplifier point is capable of covering.
the function select line selects the next best seed from the current local queue while the function fuzz function args line fuzzes the selected seed.
during fuzzing all coverage increasing inputs are added to the global and local queues q q f while all crashing inputs are added to the set of crashes q .
main fuzzing loop .
in line the fuzzer fuzzes the seeds selected from the global queue until the campaign is aborted or the time budget t1is depleted.
to select the next seed we can now simply reuse the default heuristics of the underlying fuzzer afl .
given a seed corpus of serialized function arguments this is how we fuzz those arguments in a coverage guided manner with a minimal false positive rate.
early termination .afllive can be configured to terminate at the exit of or an arbitrary period of time after an amplifier function has returned e.g.
if the fuzzer throughput is too low.
our intuition is that crashes often arise shortly after the call to the amplified function.
early termination allows the user to strike a balance between performance and stability for a given campaign at the risk of introducing false negatives.
c. mutational fuzzing of function arguments algorithm shows fuzz function args called in line and of algorithm .
given the shadow process the amplifier point types and constraints and the seed arguments it mutates the seed to generate alternative function arguments.
those that increased code coverage are added to the local and global corpora while those that induced a unique crash are added to the set of crashes.algorithm function fuzz function args input process p function f types t constraints c args q input global corpus q local corpus qf crashes q energy e compute energy f q q while enot expired do mutated args q mutate q mutated objs o deserialize q t c process p fork rewind wait p f result r substitute continue p f o ifr new crash detected then add f q toq else if r coverage increased then add f q toq addq toqf end if end while output global corpus q local corpus qf crashes q mutation .
in line an optimal number of mutations o of the serialized function arguments qare created.
what is considered as optimal is computed in the compute energy function while the mutation operators applied to the arguments are implemented in the mutate function.
since the serialized arguments is just a sequence of bytes we can reuse the implementations of both functions in a classic fuzzer .
deserialization .
in line the in vivo runtime receives and parses the mutated sequence of bytes into the actual function argument objects using the intrumenter provided type information t. this process is deterministic deserializing the same byte sequence multiple times results in the same argument objects being generated which ensures consistency and reproducibility.
the deserialization procedure also enforces the user provided constraints c. we discuss the procedure of deserialize in a separate section below.
spawning shadow executions .
in line and the in vivo runtime uses the shadow process p to spawn another shadow execution which is rewound back to right before the selected function fis called so as to continue executing with the mutated function parameters.
technically we can implement the function fork rewind wait by considering p as running in a virtual machine and using a snapshot restore mechanism to restore a snapshot of p right before fis called.
this approach fully isolates the constructed process p from the shadow process p and the original process p but it also introduces a performance and memory overhead for storing and loading the snapshots.
in our prototype we chose to fully reexecute the host application until fis reached to conceptually rewind it and start a fork server at fwhere the runtime interferes to provide the function call parameters o. coverage guidance .
in line to the fuzzer adds function arguments to the corpora that are observed to be coverageincreasing.
function arguments that are observed to induce crashes are added to the corpus containing the crashing inputs.
d. serialization and deserialization in order to reuse existing greybox fuzzers to implement seed selection select prioritization compute energy andalgorithm function deserialize input function argument byte sequence q input function argument types t input function argument constraints c output function argument objects o objects o fortype intdo object obj deserialize arg q type c add objtoo end for function deserialize arg q type object obj iftype is primitive then obj q.consume bytes type.bitwidth else if type struct then forfield fieldtype intype.fields do obj.field deserialize arg q fieldtype c end for else if type pointer then type type .pointeetype length q.consume bytes fori ... length do obj deserialize arg q type c end for end if object obj enforce constraints obj c return obj end function mutation mutate we need to translate function arguments into a sequence of bytes which the fuzzer can handle and back again.
we accomodate the serialization serialize and deserialization deserialize procedures in the invivo runtime that is instrumented into the host binary cf.
fig.
.
on a high level this process is similar to the appraoch proposed by padhye et al.
which enables coverage guided mutational fuzzing for an object oriented language like java.
algorithm presents the procedure of the deserialize function.
the procedure of serialize is analogous.
given a seed byte sequence the argument types and the argument constraints the deserialization algorithm computes the function argument objects to be passed into the function call.
in line the runtime generates one object for every function argument using its type information.
line sketches the recursive procedure of the corresponding deserialize arg function which also enforces the validity of the synthesized function argument objects.
the provided sequence of bytes qis consumed such that each byte is used at most once for the construction of the function argument objects.
the function consume bytes keeps an offset into the fuzzer provided byte sequence initially set to .
when called the function returns the desired amount of bytes available in the sequence and advances the offset by that same amount of bytes.
if the in vivo runtime attempts to consume more bytes than available the function returns all available bytes and the remaining bytes set to zero.
forprimitive types line the runtime reads as many bytes from the fuzzer provided byte sequence qas needed in order to properly cast them into the appropriate type t.subject type loc version host ap m. c. boringssl encryption .2k dd52194 crypto test bzip2 compression .2k .
.
bzip2 libass rendering .4k .
.
ffmpeg libexif parsing .7k .
.
photographer table ii detailed information about our subject programs.
forstructured types line an empty instance of the structure is allocated and the algorithm is then applied repeatedly and recursively for each field of the structure consuming the available bytes from the byte sequence q. forpointer types line our current prototype deserializes those as arrays.
the value represented by the four bytes consumed from the byte sequence qdetermine the number of elements length that are to be included in the array.
this includes arrays of length one single elements and zero null pointers .
this is because in the cprogramming language a pointer can transparently point to one element or the beginning of a list of elements.
we can recover the width of a single element from the pointee type information type .
the individual elements can then be deserialized recursively.
we rely on the user provided constraints to enforce the validity of the deserialized array length cf.
tab.
i .
constraint enforcement .
in line the fuzzer runtime modifies the constructed function argument objects to render them valid with respect to the user provided constraints c. these constraints denote inequalities between constants primitive type parameters lengths of array parameters or array items.
in order to enforce them the runtime goes over the deserialized values bounding the value of each left hand side of a constraint with respect to the right hand side.
this implies a dependency relationship between the values of the left hand side of a constraint and its right hand side.
this in turn means that the set of constraints specified by the user can not denote circular dependencies in order to allow the runtime to traverse the set of arguments in a valid order.
additionally the user can tag string arguments as filenames for which the runtime will dump fuzzing data into a temporary file and replace the string provided to the function with the corresponding filename.
serialization .
as mentioned earlier the serialization in algorithm line proceeds analogously translating the function argument objects ointo a byte sequence q such that if algorithm is applied to q we would recover o. however it might not be immediately clear how pointers are handled.
how do we know a priori whether a pointer points to no element at all a single element or a number of elements?
in this case we rely on user specified constraints to properly indicate the size of the array by way of reference.
if the user provided constraints are not strong enough to assign a value to the length of the array referred to by a pointer our fuzzer prototype defaults to treating character pointers as null terminated strings in which case the length of the array is calculated by looking for the first occurrence of the null byte in the string and any other pointers as pointers to single elements.iii.
i sexecution amplification effective ?
to study the effectiveness of our in vivo approach we implement afllive and measure the difference in code coverage achieved between the unamplified original executions and the amplified shadow executions on four target libraries.
for each one of them we choose a host program and one host input to generate unamplified executions and use a simple codeql script to choose interesting amplifier points heuristically.
a. experimental setup libraries and hosts .
table ii shows information about the benchmarks selected for thisexperiment two more to follow .
we randomly picked four widely used open source c libraries that parse host provided input data.
these libraries cover a wide range of domains from cryptography to rendering.
applications using these libraries might attempt to parse untrusted data and thus any errors present in them might represent potential security vulnerabilities.
for every library we picked one host and one input for that host whose execution we sought to amplify.
for our host selection criteria we focused on programs that were either developed or endorsed by the same group that developed the library.
this was done with the intention of minimizing the likelihood of potential crashes stemming from wrong library usage instead of actual bugs in the library.
forboringssl we used a binary as host that is supposed to test the encryption functionality of the library which also generates the one unamplified execution.
for bzip2 we used the example application bundled with the source code as host and a compressed version of a text file containing sample text6 to generate the unamplified execution.
for libass we used ffmpeg as host a large video and audio editing library that integrates subtitle functionality via libass .
the unamplified execution was generated by adding subtitle track with a single subtitle to the shortest possible video.
for libexif we used an example application bundled with the source code and one of the test images7to generate the unamplified execution.
amplifier points and constraints are identified using a codeql script implementing heuristics to identify parsing related functions section ii a .
this script returns potential amplifier points consisting of at most a few hundred functions.
we then went through the list adjusting the automatically inferred constraints based on the function signature and example invocations within the code.
column apin table ii shows how many of the identified amplifier points were executed during the host execution used for the fuzzing campaign.
column m. c. in turn shows the median number of constraints specified for each amplifier point as a proxy metric of the amount of effort involved in setting up each subject.
fuzzing campaigns .
for every project we started in vivo campaigns initialized with the same original execution using afllive .
all campaigns were run for hours each on a amd epyc 7713p core processor with 256gb of ram.
the quick brown fox jumps over the lazy dog canon tags.jpg time hs .
.
.
.
.0lines covered a bzip2 time hs 3915039250393503945039550lines covered b boringssl time hs 42504812537559386500lines covered c libass time hs 10001350170020502400lines covered d libexif fig.
coverage vs time.
the horizontal dashed lines indicate thebaseline coverage from the original unamplified execution.
the vertical dashed lines indicate when afllive switched from the screening to the main fuzzing loop on the average.
b. experimental results presentation .
the results are shown in figure .
all values reflect coverage within the library and not on the host.
the vertical dashed line indicates when on the average afllive switched from screening to the main fuzzing loop.
however since the screening loop only lasts one minute for every target function executed it is barely visible in cases where few functions were amplified.
the horizontal dashed line indicates the coverage achieved by the unamplified host execution.
results .
the greatest coverage increases were obtained in libass andlibexif where afllive achieved an increase of38 lines and lines over the unamplified baseline respectively.
for bzip2 andboringssl afllive managed to achieve a coverage increase of lines and .
lines respectively.
the lack of coverage increase for boringssl is further confirmed by a visual inspection of figure 2b where we can see the campaign reach a plateau about hour into the hour campaign while coverage increases well after the screening loop has finished .
although line coverage did not increase after the first few hours new path increasing inputs kept being added to the corpus throughout the campaign.
we attribute this to the fact that out of the functions executed by the host were fully covered in terms of lines by the unamplified host execution.
this in turn means there was little room for improvement upon initial line coverage.
the substantial increase for libass andlibexif is observed over the 24h campaign and would likely continue to increase.
this suggests that amplifying the right executions can bring tremendous benefits to automatic vulnerability discovery where the amplified executions reach deep into the code base.
false positives .
no crashes were reported in these previously well fuzzed programs during the campaign.
this in turn implies that no false positives were reported either althoughsota library type loc version synth.
fuzz driver loc host initial corpus ap m. c. fuzzgenlibaom video codec .0k 3613e5d av1 dec fuzzer aomdec sample av1 file .
libvpx video codec .5k .
.
simple decoder vpxdec sample vp9 file libgsm speech compressor .7k .
.
cod2lin stl rpedemo sample wav file fudgehtslib file parser .0k .
hts open samtools sample sam andfasta file leptonica image processor .0k .
.
pix rotate shear tesseract sample png file with english text table iii summary of setup for each test subjects for comparison against state of the art sota fuzz driver generators.
it is important to keep in mind that the rate of false positives depends on the quality of the specified amplifier constraints.
iv.
o nboarding libraries without fuzz drivers an advantage of in vivo fuzzing is that it makes fuzz drivers superfluous iii .
a fuzz driver is a piece of code that acts as a glue code between an off the shelf fuzzer and the libraryunder test.
the driver sets up an artificial calling context and is responsible for accepting data from the fuzzer and feeding it into the library with the appropriate format.
however effective fuzz drivers are often manually implemented which constitutes a major hinderance to widespread adoption of fuzzing.
for instance google incentivices the development of fuzz drivers for important open source projects bypaying up to 30k usd for the successful and effective integration .
in fact google s project oss fuzz is primarily a community maintained collection of fuzz drivers for open source projects.
an existing approach to overcome this hindrance is to automatically synthesize fuzz drivers.
for instance f uzzgen leverages a whole system analysis to infer the library s interface and synthesizes fuzz drivers specifically against that interface.
f udge scans a repository for usages of the library s api uses program slicing to extract the corresponding code snippets synthesizes a fuzz driver candidate for every code snippet by concretizing place holders and evaluate the generated fuzz driver candidates by building and running it.
intelligen also first infers the library s interface annotated with vulnerability likelhoods and generates fuzz drivers for the entry functions through hierarchical parameter replacement and type inference.
daisy first dynamically observes how a host system calls the library s api and then synthesizes fuzz drivers that follow a similar object usage pattern via a series of api calls.
however these approaches hoist the tested library only very artificially resulting in a high false positive and false negative rate.
the libraries would never be integrated or used in this way in real applications.
approaches that immitate the actual usage as faithfully as possible will still not be as close to fuzzing a library as it is actually used.
this is precisely our proposal we suggest to amplify actual user generated executions where a library is actually used.
in the following we compare the effectiveness of automatic fuzz driver generation to in vivo fuzzing as implemented inafllive .
like fuzz driver generation techniques in vivo fuzzing requires only the source code and little human intervention in the specification of amplifier points and constraints.a.
experimental setup fuzz driver generators .
we selected f uzzgen and fudge according to the following selection criteria.
we consider approaches that target clibraries and that are either themselves publicly available and compilable or the generated drivers are publicly available and compilable.
we also considered the following fuzz driver generators but excluded them for the following reasons.
graphfuzz focuses on objectoriented libraries and in the case of clibraries a complete dataflow specification8must be provided which we do not have available.
for daisy despite substantial effort we did not succeed in compiling the available fuzz drivers due to missing dependencies.
for intelligen neither the tool itself nor fuzz drivers generated by it were publicly available.
for the comparison against f uzzgen since the tool itself was not available we selected three of the seven libraries as shown in table iii.
out of the four excluded libraries three had an api that consisted of a single function that accepted a complex struct object which wraps the actual library call and maintains the entire state of the library interaction9.
the remaining library was excluded because it could not be compiled or easily fixed .
for the three selected libraries we used the only driver available for libaom and libvpx and a random fuzz driver codlin forlibgsm .
for the comparison against f udge we selected all fuzz drivers mentioned in the paper except opencv as shown in table iii.
opencv was excluded since the entire api consisted of c rather than c functions.
leptonica andhtslib are highly popular libraries used for image processing and high throughput sequencing data processing respectively.
hosts and original execution .
for every library we picked one host and one input for that host whose execution we could amplify cf.
table iii .
to be fair we provided each auto generated fuzz driver with an initial corpus that generates precisely the same values for the library api as our in vivo fuzzer.
our intention is that the tested libraries execute on the same piece of data during the first run for instance they should attempt to decode the same byte stream in the case of decoders .
for our host selection criteria we focused on programs that were either developed or endorsed by the same group that developed the library.
this was done with the intention of minimizing the likelihood that observed crashes stem from us using the library incorrectly rather than demonstrating actual bugs in the library.
9example for libhevc external libhevc refs heads main test decoder main.c time hs 010000200003000040000lines covered a libaom f uzzgen time hs 88009000920094009600lines covered b libvpx f uzzgen time hs 40062585010751300lines covered c libgsm f uzzgen time hs 45005625675078759000lines covered d htslib f udge time hs 01500300045006000lines covered e leptonica f udge library bug type id htslib null ptr.
deref.
htslib uaf htslib buffer overflow htslib out of memory htslib out of memory htslib assertion violation htslib assertion violation f crashes found fig.
coverage vs time comparison between state of the art dash dots and in vivo fuzzing solid plus crashes found.
fuzzing campaigns .
for all of the five projects we started in vivo fuzzing campaigns initialized with the same original execution using afllive and normal afl campaigns using the synthesized fuzz harnesses.
all campaigns were run for 24hours each on a amd epyc 7713p core processor with 256gb of ram.
b. experimental results presentation .
figure show the results in terms of coverage over time and crashes found for all five subjects.
the dashed vertical line indicates when on the average afllive switched from screening to the main fuzzing loop.
in all cases only coverage achieved within the library is counted excluding any coverage information about the host or the fuzz driver.
coverage results .
for the entire duration of the campaign and for all subjects afllive achieves substantially more coverage than the campaigns via the synthesized fuzz drivers.
both seem to plateau at around the same time.
however invivo fuzzing has the capability to cover substantially more code before reaching that plateau.
it is interesting to note that afllive constistently achieves more initial coverage than afl via the synthesized fuzz drivers when the campaign is started.
we find that a synthesized fuzz driver only exercises a handful of api functions in a rather shallow manner while a host application often interacts with a library via a complex series of api function calls.
the synthesized fuzz drivers do not seem to be able to mimic these complex interactions.the case libgsm seems pathological since there is little coverage increase over time for both fuzzers.
upon closer inspection we found that the encoding and decoding routines in this library consisted almost entirely of sequential blocks of instructions with no control flow statements.
this explains why neither fuzzer was able to increase coverage substantially via the selected amplifier points.
bug finding results .
our in vivo fuzzer afllive found seven previously unknown crashes in htslib cf.
fig.
.f .
five were memory safety bugs a null pointer dereference and two out of memory errors within cram cram encode.c as well as a heap overflow in header.c and a use after free inmd5.c .
the remaining two crashes were assertion violations in cram cram io.c andcram cram codecs.c .
afllive found these seven memory corruption bugs despite the f udge synthesized and later manually adjusted 10having continuously fuzzed the library for four years11.
no further crashes were reported by other campaigns.
false positives .
all of the reported crashes were true positives which could be reproduced after the campaigns were finished.
moreover manual inspection revealed that all seven crashes were reproducible via the host program by providing an appropriate system level input which we confirmed could be under attacker control.
v. a mplifying the program smanual testsuite afllive can amplify any execution including one that is generated by a manually constructed test suite .
test cases often cover certain edge cases or are designed to catch regressions similar to previously discovered bugs.
over of days exploited in the wild are variants of previously discovered vulnerabilities .
amplifying test cases allows us to search their neighborhood and bring to light new bugs or those that have been incompletely fixed.
since test suite are designed with code coverage in mind amplifying test executions might allow us to reach deep into the code effectively rendering every function ammenable to fuzzing.
distributing energy .
ideally we would like to fuzz every amplifier point that is executed by the test suite for the same amount of time.
however some amplifier points are executed by a large number of test cases while other amplifier points are executed just by a single test case.
so how much energy do we assign to each test case to achieve this objective?
algorithm illustrates our algorithm to distribute the available energy evenly over the amplifier points executed by the test suite s. in line it finds the amplifier function executed by each test case s sand counts how many amplifiers are executed in total.
in line it skips test cases that execute no unfuzzed amplifier point line .
otherwise it computes the proportion of all executed amplifiers that are executed by test case sand still unfuzzed as the time budget t1 fors line and starts a corresponding fuzzing campaign line .
specifically the function fuzz implements the proposed in vivo fuzzing approach as defined in algorithm .
open fuzzer.c test amplification input test suite s input amplifier points f types t constraints c time t0 map test2func setfuncs fortests sdo test2func get exec amplifiers s f funcs funcs test2func end for executed funcs fuzzed funcs while not aborted do forsinsdo unfuzzed test2func fuzzed funcs ifunfuzzed 0then time budget t1 unfuzzed executed fuzz f t c exec s t0 t1 fuzzed funcs fuzzed funcs test2func end if end for end while initial library type loc version coverage ap m. c. openssl cryptography 1m .
.
libxml2 parsing 308k .
.
opus speech 80k .
.
compressor table iv information about libraries and manual test suites.
a. experimental setup table ivshows the selected libraries the corresponding test suite coverage and the number of executed amplifier points ap .
we randomly chose libraries from diverse domains that are security critical well fuzzed years 12and widely used open source c libraries.
for test amplification no host or host input is needed as all libraries had test suites and testing frameworks readily available.
like for the other experiments the amplifier points were auto identified using our tool ii a and manually constrained afterwards.
state of the art.
there exists a fuzz driver generator specific for test amplification called ut opia .
given a libraryunder test and the gtest orboost test suite ut opia first performs a lightweight static analysis before synthesizing fuzz drivers for the tested library functions.
the static analysis is used to identify the precondition of every library function.
for every test case the synthesis first identifies the library functions used in the test case and the constants used as parameters in a corresponding function call and then generates a fuzz driver for the library functions by rendering the constant library function call parameters subject to fuzzing.
for our experiments we reuse the identified functions and preconditions as amplifier points and constraints using a straightforward translation to ensure the fairness of the comparison.
this demonstrates the versitality of our in vivo approach which allows diverse means of automatic amplifier point identification and requires no specific test framework.
commit contains openssl libxml2 oss fuzz commit a143b9b3 time hs 135400135600135800136000136200lines covered a openssl time hs .
.
.
.
.0lines covered b libxml2 time hs 1550016062166251718817750lines covered c opusbug type id buffer overflow cve buffer overflow pr use after free cve denial of service issue d bugs found in openssl.
fig.
coverage and bugs in test amplification campaigns.
unfortunately despite several months of experimentation we realized that on the utopia benchmark programs using theutopia identified amplifier points and constraints all crashing inputs generated by ut opia and afllive are false positives .
upon manual examination we found that the drivers synthesized by ut opia as well as the results of its analysis did lead to an incorrect usage of the libraries and thus to a large amount of spurious crashes.
to be sure we repeated the analysis by filtering inputs that did not crash on the most recent version assuming these bugs would now be fixed but only found that the remaining crashers were flaky i.e.
crashed again if run repeatedly.
since the level of automation provides not much room for misusage we conclude that an experimental comparison would not provide much insight.
b. experimental results presentation .
figure shows the average coverage over time and the bugs found during test amplification.
the vertical dashed lines indicate a change in test case during the fuzzing campaign line of alg.
.
the horizontal dashed line indicates the initial coverage for the library s test suite.
we only measure coverage of the library.
coverage results .afllive achieved an increase over the manual test suite by around loc for openssl and over loc for libxml2 .
no increase in coverage was achieved foropus .
closer inspection revealed that the manual test suite is of very high quality and nearly saturated covering almost of lines of code in opus.
there are five test cases that exercise all of the amplifier points selected for opus which explains why all of the time budget was invested into one test case .
the latter is true also for libxml2 where the first test case already exercises all but one amplifier point.
foropenssl we see that switching test cases to exercise new amplifier points is effective and after saturation code coverage increases again when the next test case is fuzzed.
this highlights that using our approach once the amplifier points have been identified and their constraints correctly specified the user is able to setup several fuzzing campaigns with littleextra effort.
towards the end of the hour campaign it is also interesting to note that coverage saturates despite switching to test cases that exercise new amplifier points.
bug finding results .afllive discovers bugs in openssl two of which have previously been found only by manual auditing including the high severity punycode vulnerability cve and two of which have not previously been known including a moderate severity use after free cve2023 .
no false positive crashes were reported.
vi.
s emi automated identification of amplifier points and constraints the two main concepts of invivo fuzzing are amplifier points aps and constraints acs .
while aps identify interesting functions acs make implicit function preconditions explicit just like like user defined preconditions in property based testing pbt or user defined repok methods in search based software testing sbst .
in general acs canbe written to reduce false positives but they do not need to be.
in terms of effort there is a tradeoff between specifying acs versus going through the false positives.
for instance suppose afllive finds a possible null pointerdereference on a function parameter but that function is never called with a null pointer.
this is a false positive and invivo users can encode this implicit assumption explicitly.
a. semi automatic identification for our experiments we used a semi automated approach.
an initial set of aps acs was first automatically identified and then manually refined.
for automation we developed a codeql script to identify aps loc and a python script to generate acs loc .13for manual refinement for subjects where no executed aps where identified bzip2 libexif andlibgsm we added the main entry points of the library as aps via documentation .
we added or modified acs to ensure these conditions sizeof buf len len c requires that variable lendetermines the length of the buffer bufand lenis less than the constant c. sizeof buf c requires that the length of the buffer is smaller than the constant c or is file filename requires that the string filename refers to a valid file where fuzzing input will be dumped.
these patterns account for of all acs.
as an indicator of the additional manual effort for each subject we note that we either added or removed constraints for no more than of the automatically identified amplifier points across all subjects.
even then no more than two constraints needed to be added removed.
in comparison to ac specification writing a fuzz driver from scratch could take an experienced developer several hours and would need to be maintained afterwards.
for instance the driver integrated into oss fuzz for libass was written over the course of two days by a core developer of the project and iterated upon several times.
generatorinferred config.
curated config.
subject cov.
loc t.p.
f.p.
cov.
loc t.p.
f.p.
boringssl .
.
bzip2 .
libass .
.
libexif .
htslib .
.
leptonica .
.
libaom .
.
libgsm .
libvpx .
.
libxml2 .
.
openssl .
.
opus .
.
table v coverage and bugs in fully automated campaigns.
b. ablation study in order to study the impact of our additional manual effort to reduce false positives we compare the effectiveness of afllive using only the auto generated aps and acs to the effectiveness of afllive using the manually augmented set of aps and acs.
all campaigns were run for hours each on a amd epyc 7713p core cpu with 256gb of ram.
coverage results .
table v shows the average coverage achieved throughout the campaign along with false and true positives reported for both the fully automated and manually modified configurations.
for all subjects with identifiable amplifier points coverage achieved via auto generated aps and acs was on par i.e.
same order of magnitude with the coverage achieved through the semi automatic approach.
for the subject where no executed aps were identified automatically i.e.
bzip2 libexif andlibgsm the campaigns failed to run.
however after manually specifying amplifier points and constraints across the three subjects the campaigns run and managed to increase coverage significantly over the original execution see figure figure .
for some subjects the automatically inferred constraints led to a higher code coverage such as in the case of boringssl libass libxml2 andopus .
this can be attributed to us being overly conservative when manually modifying constraints in an effort to prevent a high false positive rate.
bug finding results .
given only the automatically inferred constraints afllive failed to find the previously discovered bugs.
expectedly this also led to a higher number of false positives for two of the subjects boringssl andopenssl which were also the most complex subjects that we analyzed.
still no more than five false positives were reported in each case and could thus be triaged in a reasonable amount of time less than a few hours .
vii.
r elated work automatic unit level testing.
long before fuzzing entered the stage the software engineering community studied automatic approaches for unit level test generation .
examples of a unitare java objects or c functions.
one major research challenge of automatic unit level testing has been to minimize the number of false positives i.e.
bugs that only appear during automatic testing but never in production whenthe unit is properly used.
there are two approaches to tackle this problem a to let the user specify conditions representing the valid usage of that unit and b to observe how the unit is used e.g.
during system testing and to enforce the inferred protocol during unit testing .
daisy takes approach b while afllive takes approach a to minimize the number of false positives during in vivo fuzzing.
valid calling context .
another major research challenge of automatic unit level testing has been to generate a valid sequence of api calls and construct the required objects to pass in as parameters to these calls.
given the preconditions called contract randoop constructs the sequence of api calls and objects in a feedback directed manner continuously evolving test cases that do not violate the user provided contract.
jqf and cgpt add coverage guidance.
however fundamentally these tools follow a generational approach where the api calls and objects are generated out of thin air and validated only against a user provided specification.
in contrast ours is a mutational approach where we piggyback on a valid sequence of api calls that are passed valid objects.
like the mutational approach on the system level this allows us to reach much deeper into the code.
staying within the neighborhood of a valid program state there is a low risk of false positives.
selective symbolic execution first introduced the invivo approach by injecting a symbolic execution engine into a program binary that would activate whenever an expansion point is reached and collapse the symbolic state corsetting whenever symbolic execution becomes impractical e.g.
for library calls.
in contrast our coverage guided in vivo fuzzer does not require the symbolic execution machinery for tracking and solving symbolic states.
our approach is coverage guided and works even for deployed binaries using actual executions if non interference between shadow and original execution is guaranteed by the snapshotting mechanism.
snapshot fuzzing .
the first lightweight snapshot restore mechanism in fuzzing was the afl fork server .
it would allow the fuzzer to skip the expensive execution prefix during repeated execution of the same program with different inputs.
snappy further explored how to set the fork server as late as possible into the execution of the program.
nyx introduced a proper virtual machine vm based snapshotrestore mechanism.
in contrast we relax the constraint that the fuzzer must produce a system level input and instead propose to use the snapshot mechanism to amplify an execution at userspecified amplifier points to generate shadow executions.
in vivo fuzzing in production .
our long term vision assuming several technical challenges are tackled is to integrate invivo fuzzing into the production system so as to fuzz the entire supply chain of a software system including all of its dependencies.
the idea to integrate bug finding into production is not very far fetched.
for instance google is running a nooverhead version of addresssanitizer on every android phone and every chrome browser .
apart from bug finding google has long been running google wide profilers gwp which conduct light weight program analysisacross entire fleets of machines .
mozilla implemented the approach for firefox .
the open source community implemented the approach for the linux kernel .
viii.
p erspective existing fuzzers are designed to test a software system in vitro i.e.
under artificial lab conditions.
however the effectiveness of in vitro fuzzing is limited .
it is these limitations which we sought to address in this paper.
solving dependency on fuzz driver quality .
a fuzzer must first be glued to the software via fuzz drivers.
typically fuzz drivers are tediously developed and continuously updated over months.
for instance google pays up to 20k usd for fuzz drivers of critical open source software .
to reduce some manual effort recent research has focussed on generating drivers automatically .
whenever a security was found by manual auditing the developer would add a new fuzz driver through which the fuzzer is able to find the security flaw.
while the drivers can be improved over time this dependency on driver quality cannot be avoided.
openssl has drivers in oss fuzz which have been continuously fuzzed over the past six years .
in contrast in vivo fuzzing eliminates the need for fuzz drivers entirely.
just by amplifying the developer test suite our in vivo prototype found a critical bug in unfuzzed code of openssl cve .
solving structure aware fuzzing .
a fuzzer s effectiveness depends critically on the quality of the initial seed corpus .
for instance if we are fuzzing an png image library inputs that were generated by mutating valid png image files will reach more deeply into the library than a random string of bytes.
however valid input structures are easily broken and new input structures are difficult to generate by chance.
for instance if none of the seed images contains an optional exif chunk specifying some metadata it will hardly be generated.
recent work including ours has addressed this using or learning the input structure and inventing the missing data chunks .
however the critical dependence on initial seeds remains.
in contrast in vivo fuzzing allows us to define as amplifier point that function in the parser which handles an interesting data chunk or set amplifier points deep in the program functionality to entirely skip the parser.
solving stateful fuzzing .
some software systems require inputs in a certain order.
for instance the transmission control protocol tcp requires a three way handshake between client and server before data can actually be sent.
without knowing precisely the implemented protocol it is difficult for a fuzzer to generate the right sequence of packets with the correct structure.
recent work including ours has used mutational feedback direct fuzzing that uses response codes state variables or human annotations to identify and leverage the sequence of software states for a sequence of inputs packets .
however these approaches heavily depend on the recorded sequences of packets that are used to seed the mutational fuzzers.
in contrast in vivo fuzzing allows us to define as amplifier point that function which handles a certain state or state transition.