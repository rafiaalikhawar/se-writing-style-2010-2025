leveraging propagated infection to crossfire mutants hang du university of california irvine irvine ca usa hdu5 uci.eduvijay krishna palepu microsoft silicon valley campus mountain view ca usa vijay.palepu microsoft.comjames a. jones university of california irvine irvine ca usa jajones uci.edu abstract mutation testing was proposed to identify weaknesses in test suites by repeatedly generating artificially faulty versions of the software i.e.
mutants and determining if the test suite is sufficient to detect them i.e.
kill them .
when the tests are insufficient each surviving mutant provides an opportunity to improve the test suite.
we conducted a study and found that many such surviving mutants up to for the subjects of our study are detectable by simply augmenting existing tests with additional assertions or assertion amplification .
moreover we find that many of these mutants are detectable by multiple existing tests giving developers options for how to detect them.
to help with these challenges we created a technique that performs memory state analysis to identify candidate assertions that developers can use to detect the surviving mutants.
additionally we build upon prior research that identifies crossfiring opportunities tests that coincidentally kill multiple mutants.
to this end we developed a theoretical model that describes the varying granularities that crossfiring can occur in the existing test suite which provide opportunities and options for how to kill surviving mutants.
we operationalize this model to an accompanying technique that optimizes the assertion amplification of the existing tests to crossfire multiple mutants with fewer added assertions optionally concentrated within fewer tests.
our experiments show that we can kill allsurviving mutants that are detectable with existing test data with only .
of the identified assertion candidates and increasing by a factor of 6x on average the number of killed mutants from amplified tests over tests that do not crossfire.
i. i ntroduction the ultimate goal of mutation testing is to allow software developers to create stronger test suites.
it does this by injecting artificial faults i.e.
mutations into a program to identify weaknesses in the test suite i.e.
mutations that are not detected .
a developer would then write tests to detect orkill the undetected or surviving mutants.
the intuition of this approach is that by strengthening the test suite to detect the mutations the test suite will then be more likely to catch future real faults before they can cause any adverse effects upon users.
multiple works on test generation and amplification e.g.
focus on automating the improvement of test suites.
some of these works address generating specific parts of the test suite such as test data and test oracles e.g.
while others generate entire test suites from scratch e.g.
.
additionally some techniques amplify existing test suites by exploring new test data and assertions e.g.
.
these approaches enhance test suitesand are evaluated based on their ability to produce higher mutant killing ratios.
however the usage scenarios of these techniques often differ from typical mutation testing practices in either or both of the following two key ways mutation testing practitioners target individual surviving mutants and incrementally improve existing test suites and they perform mutant killing activities on preconstructed human written test suites that already contain test data and oracles .
from we recognize the importance of analyzing specific surviving mutants to help practitioners target and kill individual mutants.
from we acknowledge the presence of multiple existing developer written tests that may execute the mutant creating opportunities for test amplification if a slight improvement to an existing test can kill a surviving mutant there is no need to design a different test from scratch.
the classic fault error propagation model ripr model investigates such scenarios where a test case executes a specific fault.
the model includes four conditions the fault must be executed reachability infect the program states infection propagate the infection propagation and have appropriate test oracles to reveal the fault revealability .
the last condition of revealability relies on the test case having appropriate and sufficient test oracles.
if it does not adding additional assertions or assertion amplification may help reveal the fault.
following the ripr model du et al.
empirically investigates the end to end runtime effects of mutation execution which uncovers opportunities to kill surviving mutants through such amplification.
furthermore while targeting a specific surviving mutant mutation testing researchers discovered that a human designed test for one surviving mutant sometimes coincidentally kills other surviving mutants a phenomenon termed crossfire .
understanding and leveraging these mechanisms can strengthen each incremental test augmentation mutantkilling attempt.
in this work we offer a model to investigate the causes and intricacies behind the crossfire phenomenon in both the mutation analysis and mutation testing processes empirically analyze existing test suites mutant crossfire capabilities at both the test and assertion granularities systematically investigate assertion amplification opportunities for each surviving mutant develop techniques that recom arxiv .09846v1 nov 2024mend mutant crossfiring assertions with crossfiring goals at varied granularities compare and evaluate our assertionamplification techniques of varied crossfiring strategies and gain initial insights into mutant killing assertion candidates characteristics.
through our analysis we found varied mutant killing capabilities of individual assertions and test cases across different projects unveiled how passing test runs exhibit propagation and discovered overwhelming surviving mutant killing opportunities through assertion amplification.
our surviving mutant crossfiring techniques allow for a small selective set of assertion amplified developer written tests to crossfire a substantially larger number of surviving mutants by a factor of6.
.
the main contributions of this paper include an analysis technique that assesses the granular infected memory locations that resulted from the propagation of the infection caused by execution of the injected faults.
this technique offers recommendations for additional assertions that can be used to kill surviving mutants.
a theoretical model that dissects and analyzes propagation at fine grained levels and illustrates the crossfire effects in mutant kills and a technique that provides optimizations for adding more effective assertions to tests.
an empirical evaluation of our proposed techniques showing the varied capabilities of tests and assertions for detecting propagated state infection assessing our ability to recommend assertions to kill surviving mutants and assessing our optimizations to crossfire mutants.
an implementation and dataset to allow for future research and experimental reproducibility.
ii.
m otivation and challenges mutation testing involves both test automation and developer effort.
a tool like pit or java typically handles the automated portion.
these tools inject faults rerun the test suite for each mutant calculate the mutation score and report unkilled mutants.
the output of the tool provides developers with two key benefits an assessment of the test suite s strength through the mutation score and a prescription on improving the test suite via a list of surviving mutants.
with these results developers must then strengthen the test suite by targeting surviving mutants.
the manual process that a developer might take to kill surviving mutants is depicted in the top row of figure .
once a mutation testing tool is used to reveal surviving mutants a developer may wish to kill one surviving mutant by first identifying a test that executes the mutation.
the ripr model prescribes the execution or reachability as the first condition to detect a fault.
next a developer would want to find a test that not only executes the mutation but also does so with test data that causes the mutation to affect orinfect the state.
then a developer would need to create a test assertion to detect an infected state that propagated back to the test in order to reveal the mutation or fault and kill the mutant.each of these steps provides challenges for a developer.
to find such infections a developer might probe the state through print statements or a debugger to determine if any part of the state that is accessible from the test case shows any infection as evidenced by differences with the original unmutated program s state from the same test.
even once such differences in state are found another challenge is determining if those differences are caused by the infection from the mutation or from nondeterministic values such as a date or time of day field a hashcode or a thread identifier .
even once a real infection has been identified there may be multiple ways to access that infection and the developer would need to make a choice as to how to access it in order to detect it with an assertion.
moreover this entire process must be repeated for each surviving mutant.
mutation testing tools often report hundreds or thousands of surviving mutants even for mature and well tested software .
this last challenge of the magnitude of the problem could be somewhat alleviated by the phenomenon of crossfiring mutants a test for one surviving mutant sometimes coincidentally kills other surviving mutants.
however such a manual mutant by mutant approach would likely not exploit the crossfire effects to their true potential.
based on the potential opportunities and these observed challenges for developers to perform the manual portion of analyzing each surviving mutant our motivation is to provide conceptual models and analyses to help researchers understand the various aspects of this task as well as to create practical techniques to help developers kill surviving mutants with greater assistance.
iii.
a model a b reakdown of mutant crossfire effects to understand the natural occurrence of the mutant crossfire phenomena and to exploit its potential in killing surviving mutants we developed a model in figure to illustrate the observed mutant crossfire effects as a result of intricate fine grained memory infection in the mutation analysis phase and the mutation testing phase.
the model s structure takes the shape of the letter a which symbolizes the divergence of two mutation phases an existing test case is evaluated on killed detected mutants during the mutation analysis phase on the left leg and subsequently this test case may be augmented with assertions in the mutation testing phase to kill surviving mutants on the right leg.
we start by explaining the a model s left leg in the mutation analysis phase by breaking down an existing test using the example shown in the bottom row of figure .
the example includes both the original test figure c and the augmented test figure g and an anatomy of mutation effects in the intermediate subfigures figure d f .
in block an existing test case was executed on mutants and demonstrates its capability to kill mutants.
for instance test in figure c killed two mutants m4andm5 .
when a test kills mutants it can fail by assertions block or nonassertion failures such as crashes block .
.
test s 2manualdevelopereffortcodetestsmutation testing toolsurvivingmutantskill a single mutantidentify test that executes mutationidentify test that causes state infectiondifferentiate infection from nondeterminismwrite a new assertionrepeat for each surviving mutant without regard for crossfire optimizationidentify test that causes detectable infection propagationautomation assisted approachcodetestsmutation testing toolsurvivingmutantsinstrument original and mutated codeexecute instrumented code to record and analyzememory state in testsconstruct location mutant matrixcrossfire optimized assertion candidatesinfection nondeterminism and access path labels testpublic void test1 var var1 ... var var2 ... assertequals var2.f5 testpublic void test2 var var3 ... assertequals var3.f7 assertequals var3.f9 original test casesoriginal statemutant statetest1originalprogrammutant 1executen timesexecute observed state differences assessed as infection that propagated from the faultobserved state difference assessed as nondeterministic memory locationreturned n statesreturned statecomparecompare memory state analysisfor a single mutanttest1var1var2f4flaky f6test2var3f1 m1f2 m1 m2f3 m3f7 m7f8 m3f9 m6f5 m4 m5legend m1infection caused by mutation m1.
no assertion that checks at this location.
m1infection caused by mutation m1.
there is an assertion that checks i.e.
test fails detects m1 at this location.labeled memory graphs to identify all detectable infection locations for all mutantsm1m2m3f1f2f3f3f8var1var2var3test1 test2surviving mutantsmemorylocationvariabletestcase mutant to location infection matrixfor surviving mutants testpublic void test1 var var1 ... var var2 ... assertequals var2.f5 assertequals var1.f2 assertequals var1.f3 testpublic void test2 var var3 ... assertequals var3.f7 assertequals var3.f9 test cases withaugmented assertions a b c d e f g fig.
process to kill surviving mutants by manual developer effort top that does not optimize for crossfiring due to its piecemeal approach and an automation assisted approach bottom that analyzes state infection and optimizes for crossfiring.
.
test t was able to kill m mutants2.
n assertions in t were able to kill m mutants3.
assertion in t was able to kill m m mutants4.
assertion was able to kill mutant5.
detect unrevealed propagation perform fine grained state analysis6.
a newly added assertion kills a surviving mutant7.
an added assertion may kill multiple surviving m m mutants8.
multiple added n assertions in t kill surviving m mutants .
produced new test potentially crossfires m mutantsmutation analysis mutants were killed mutation testing to kill surviving mutants testcaseassertionskill pair all assertionssingle assertion .
non assertion test failures9.
new test data test codekkkkss s sks fig.
a model a breakdown of mutant crossfire effects set of assertions cumulatively killed two mutants m6andm7 .
as a test case may contain multiple assertions each assertion may be capable of killing multiple mutants block .
test s assertion of var2.f5 detects two mutations m4and m5 .
as a result an individual assertion contributes to a mutant kill block creating a set of assertion mutant pairs e.g.
var2.f5 m4 .
at the apex of the model an analysis can reveal propagated infection despite the fact that the tests pass block .
as described in section ii performing such analysis can be difficult and time consuming.
however an automated analysismay be able to identify infections that propagate from a mutation back to a test and as such suggest an assertion candidate to kill it block .
in figure e for instance if we add an assertion in test that asserts the memory location at node f3 then the surviving mutant m3will be killed.
moreover each added assertion may kill multiple surviving mutants block .
for instance in figure e an assertion for memory location f2intest crossfires surviving mutants m1andm2 because those two mutants trigger infection at the same memory location.
furthermore a test may be augmented with multiple assertions block and each of them may kill some surviving mutants.
as a result the newly produced test e.g.
test1 in figure g with assertion amplification exhibits its capability of killing multiple surviving mutants block .
note that such mutant kills may also be produced by crafting a brand new test case with new test data and execution logic block .
.
throughout the a model we demonstrate the crossfire effects of an existing test case from the individual test case and individual assertion level as a result of assessing granular memory infections for multiple mutants.
also we recognize the potential to kill multiple surviving mutants at the testand assertion level in the test augmentation process.
moreover such assertion amplification opportunities may occur across multiple existing tests for each surviving mutant.
in the next section we present our technique to strategically augment an existing test suite with new assertions to kill surviving mutants according to this crossfire aware model and thus offer developer automated assistance to strengthen their test suite.
3iv.
a pproach in this section we describe our technique to produce assertion candidates for strategically killing surviving mutants.
our technique can be decomposed into the following steps run mutation testing tool on program pwith its test suite tto get the list of surviving mutants m. instrument pto record all reachable memory states for each test case in t. the output is the instrumented program p .
execute the instrumented program p ntimes on its test suite tto produce ncopies of memory states s. perform a comparison across all ncopies of s. those memory locations that are consistent across all ncopies ofsare labeled as deterministic sp d and those locations that show any differences are labeled as nondeterministic sp n. for each surviving mutant miinm instrument mutant mito record all memory states for every test case.
the output is instrumented mutant program m i. execute instrumented mutant m iwith test suite tto record all state for all test cases smi.
filter the state of the mutant smito remove all nondeterministic locations smi d. compare deterministic state of the original program sp d with the deterministic state of the mutant smi dto identify all locations smi ithat reveal infection.
build a matrix mfor all memory locations that reveal any infections smi dacross all surviving mutants m. performing strategies on mto optimize crossfiring to produce a list of assertion candidates and for each assertion candidate the list of surviving mutants that it would kill.
this process can be summarized into two primary stages a a fine grained memory state analysis on surviving mutants through which we analyze the location of state infection in memory and the ways to access the pollution so as to derive assertion candidates steps and b assertioncandidate selection where we leverage analyzed granular infection behaviors to design assertion candidate selection strategies that crossfire mutants steps .
this process is depicted in the second row of figure along with example test cases memory states memory location to mutant matrix and resulting augmented test cases.
a. memory analysis and assertion candidate generation a new assertion may be derived to check a specific previously unchecked granular program state behavior through accessing variables that are directly exposed from the test case scope.
as such we analyzed each variable s program states for each passing test run figure d .
note in this work we refer to variables as any local variables fields of testclass instances method return values instantiated objects or static fields that is any memory location that is immediately accessible from each test case s scope.
for each variable s program state analysis we performed nrepetitive test runson the original program to identify nondeterministic memory locations such as node f6in figure e and compared their states to their counterpart from a mutant while ignoring non deterministic locations.
we used breadth first search in the traversal of each pair of matched memory graphs to perform such a comparison starting from the root variable.
each node in the object graph represents an instance of an object or primitive value at the leaves and is given a unique node id.
each edge indicates a relation between objects an element from a size changeable collection e.g.
array list or a field of an object.
during graph traversal any granular memory differences detected at a node is marked and the traversal along that path ceases any further comparisons deeper along that path.
meanwhile graph structural differences may occur during comparison which can result from null fields and mismatches in collection sizes.
if a collection size infection occurs further state comparison under the collection is stopped.
therefore the algorithm yields a set of granular state difference details between two object graphs.
each of them includes a unique node id that specifies the location of the infection relative to the object graph.
such an analysis is performed on all surviving mutants covering test runs and individually on each variable.
to mitigate the redundant calculation and analysis of variables pointing to the same object in memory we apply a hashing algorithm on variable level object graphs.
as a result this approach yields a set of granular state difference details between two object graphs.
each of them includes a unique node id that specifies the location of the infection retrievable from an object graph.
as a result we produce comprehensive sets of programstate infection locations for surviving mutants each of them includes the surviving mutant id test case id variable id and node id accessible via the variable pinpointing the exact pollution figure f .
this information forms a set of assertion candidates with each specifying which surviving mutant can be killed which test case can be augmented which variable in the test case can access the pollution which part of the object graph should be asserted and what are their expected and polluted values.
b. assertion candidate selection and mutant crossfire to reduce the inevitable human in the loop engineering cost only a few assertions are required to kill all of the assertion actionable mutants.
for example some assertions may be written with shorter access paths than others.
specifically we measure the depth of the polluted node accessible from the corresponding variable starting from depth of .
in figure e node f3has a depth of relative to var and a depth of relative to var .
as such an assertion checking memory location f3may be easier to access from variable var thus potentially making the assertion more readable with less comprehension and engineering cost.
moreover we recognize that practitioners often perform incremental augmentation and validation to kill surviving mutants.
focusing these efforts within a few locations in the test code can reduce the engineering and validation burden minimizing the need to 4primary mutant crossfire optimization goalc1.
iteratively search for the most capable assertionsc2.
iteratively search for the most capable variablesc3.
iteratively search for the most capable testsb.
select assertions via shortest access paths d1.
for each selected variable search for the most capable assertions d2.
within each selected test search for the most capable assertionsa.
memory analysis produce assertion candidates strategy 1strategy 2strategy 3fig.
mutant killing strategies switch contexts between different amplification locations in the test code.
as such we can minimize the number of assertions e.g.
checks for f2andf8 minimize the number of variable checks e.g.
checks for var and minimize the number of tests to perform such assertion amplification e.g.
improve test only rather than both tests while achieving the same mutation score.
as such we presented three different mutant crossfiring strategies shown in figure .
in block b an initial optimization heuristic can be applied to select candidate assertions by filtering out the assertion candidates via non shortest access paths for each surviving mutant.
this filtering is based on the heuristic that assertions checking attributes deeply accessible from a variable are more likely to be brittle which may reduce the maintainability of the test suite.
then we apply greedy heuristics iteratively search for the assertion variable test that kills the largest number of surviving mutants c1 c2 and c3 among all candidate assertions until all assertionactionable surviving mutants are killed.
such greedy heuristics prioritize assertions variable checks or tests that should be augmented based on their ability to kill the largest number of mutants thereby limiting the human engineering burden.
similarly greedy heuristics could be applied further on nonfinest searching scopes i.e.
variables and tests where we continue to iteratively search for the most capable assertions related to a specific variable d1 or test d2 corresponding to strategy and strategy .
as a result our technique produces assertion candidates that not only kill but also crossfire surviving mutants which requires fewer and more concentrated updates in the existing test suite to strengthen the test suite.
v. e valuation in this section we outline the experimental design to assess the effectiveness of our approach for generating assertion candidates that kill surviving mutants while optimizing for crossfiring assertions.
we enumerate the research questions that will guide our empirical investigations.
to answer those questions we implemented our approach performed experimentation on popular open source java programs and report our findings in section vi.
a. research questions these research questions are structured to assess both legs or facets of the a model how test assertions detect infection i.e.
kill mutants and how assertions and tests crossfire multiple mutants.rq1 for killed mutants how do tests and assertions contribute to the test suite fault detection capabilities?
tests often contain multiple assertions that together reveal infections through test failures.
however the fault detection capabilities of individual assertions in a test may vary.
for instance a single test with two assertions may kill three mutants but with only one assertion killing all three mutants.
for a developer this may potentially make some assertions more useful than others.
in a different example a single test contains three assertions each of which kills a unique mutant and as such each demonstrate their utility.
we investigate this phenomenon by measuring a the count of mutants killed by each test b the count of mutants killed by each assertion and c the count of assertions in each test.
rq2 how many surviving mutants are detectable by existing tests and thus killable by our approach?
tests can only detect infections that propagate to the test code s execution scope.
often infections may propagate to a test s execution scope but may go unrevealed because the test lacked an appropriate assertion to detect the infection.
if a developer can detect faults by augmenting an existing test with an assertion without writing a whole new test case it might save engineering cost to create new test inputs and identify surviving mutants that are guaranteed to not be equivalent mutants.
we investigate this phenomenon and report the number of surviving mutants that could be killed by augmenting existing tests with assertions.
rq3 how many tests offer the opportunity for assertion amplification?
we investigate the number of tests that do not reveal propagated infections and offer the chance to add newer assertions to kill surviving mutants.
we suspect that developers would ultimately want to or perhaps even need to assess generated assertion candidates.
and so if we augment a greater number of tests with assertions then that may increase the manual work for a developer.
when manually assessing the generated assertion candidates the developer would need to understand the logic for more test cases.
in our experiments we report the number of tests wherein our memory state analysis was able to generate assertion candidates.
rq4 how effective are the crossfire strategies at reducing the need for additional assertions to kill surviving mutants?
as explained from the right leg of the a model surviving mutants could be killed and even crossfired.
our technique searches for assertions test variables or test cases that guide the killing of a maximal number of mutants to achieve the best crossfire effects.
developers may need to manually assess generated assertion candidates.
in that event it might be useful if developers need to examine fewer test cases test variables and assertions while killing a maximal number of surviving mutants.
we evaluate the magnitude of such crossfire effects and capabilities of three different mutant crossfire strategies.
we further compare them and discuss the trade offs of the three strategies.
5b.
experimental setup mutation analysis with pit.
to conduct our empirical analysis and technique evaluation we employed pit a mutationtesting tool for java extensively utilized in research and practice e.g.
.
we used the defaults group of mutation operators provided by pit which contains a set of mutation operators that has been widely adopted in practice.
each mutation operator in this group ensures one to one mappings between the bytecode syntax and the resulting mutation and pre filters for bytecode equivalent mutants thereby mitigating equivalent and duplicate mutants.we modified pit s source code to enable non mutation test runs isolate mutant execution in separate jvm instances and collect final program states for each test run.
we also configured pit to enable the execution of all covering test runs for all mutants.
memory object graph instrumentation.
to collect final program memory states we instrumented test code with asm to identify and record a list of test variables and memory state accessible in the test s execution scope.
we collect the memory object graphs for each local variable static field and heap location that is accessible from a test method.
we use xstream to record memory object graphs with configurations to exclude states related to threading and logging utilities.
we customized xstream to support comparison of arrays and collections as part of our fine grained memory state analysis detailed in section iv a. we also employed static field cleaners to mitigate state or test data pollution that might occur across two successive test runs.
these implementation details are captured in our artifact.
experimental steps.
we first ran our analysis to attribute testfailure causes for failing test runs.
specifically we count the number of mutants that each test case and each assertion kills.
next we compare program states between mutated and original runs on individual variables in the maintained variable list on surviving mutants which produces comprehensive assertion candidates as introduced in section iv a. finally we apply the three mutant crossfire strategies introduced in section iv b. the greedy heuristics used in our strategies may produce multiple equally optimal choices at a given step thus yielding close to optimal but nondeterministic performance.
as such we ran each of our strategies times to evaluate their average performance.
subject programs.
we ran our experiments on open source java projects chosen for their use of the m aven build tool inclusion of developer written ju nit5 tests no documentation of flakiness of tests minimal dependence on multi threading and external mocking libraries and finally compatibility with jdk and the xstream library.
each column of table i provides subject project lines of code number of tests number of analyzed mutants number of analyzed test runs average number of covering tests for each analyzed mutant the mutation score for covered mutants and time taken by our experiment for the subject.
across the subjects we analyzed fine grained memory data fromtable i experimental subject programs avg.
subject project kloc t mut run ct ms time commons cli .
.
4h 56min joda money .
.
12h 30min cdk data .
.
49h 53min jline reader .
.
167h 36min commons validator .
.
8h 41min commons codec .
.
14h 56min spotify web api .
.
1h 44min commons text .
.
24h 07min dyn4j .
.
28h 01min jfreechart .
.
155h 16min over .
million mutated test runs for mutants.
we found no test flakiness in the subjects test suites.
experiment running time.
our experiment ran on a .2ghz apple m1 arm processor with 16gb ram and required days approx.
to complete cumulatively for all subject programs.
we designed the experiment to answer the research questions that we pose in this work.
answering such research questions requires comprehensive runtime data which we collect through the experiment s multiple stages a running a program s non mutated runs b running a program s mutated test run with instrumentation to collect runtime memory graphs and c analyzing memory graphs for both surviving and killed mutants across all test runs.
collectively each such step incurs running time costs.
in table i we list these running times that vary with each program from as little as hour minutes s potify web api to as much as hours minutes j line reader often depending on the number of mutants and covering tests.
it is important to note that our experimental setup has suboptimal performance and is not designed for use in practice.
our experiment was designed to test the scope and feasibility of our approach and includes time consuming redundant steps to ensure the integrity of our experimental data.
for instance we record memory data from test runs on both killed and surviving mutants which are voluminous and incur substantial i o and compression decompression costs to enable experimentation and exhaustive data analysis.
in practice much of these expenses would not be needed.
moreover the analysis could be performed on individual or a smaller subset of mutants.
a tool developer could forego such costly redundancies when implementing our approach as a developer tool e.g.
in an ide or a ci cd system which assuredly would offering significant speed ups.
vi.
results rq1 test and assertion fault detection for killed mutants in figure we employ a small multiples approach to illustrate varied capabilities of tests and assertions in killing mutants across representative subject projects.
in each project we present two sub figures at the same scale the left highlights the capability of test cases while the right delves into the granularity of individual assertions.
test cases are visualized as regions outlined with gray borders.
assertions are depicted as square pixels within the grey borders of their enclosing test case.
the size of a test s enclosed area with the gray border reflects the count of assertions within that a commons cli b commons codec c commons validator d jline reader e joda money f spotify web api g legend mutant killing crossfiring capability fig.
test and assertion crossfiring capabilities test case.
the test cases and their assertions are sorted by their names and locations.
in the right sub figure for each project each pixel s color indicates an assertion s mutant killing capability with darker redder pixels denoting higher numbers of killed mutants i.e.
greater crossfiring by the corresponding assertion.
this color coding is also detailed in the legend in figure 4g where darker redder shades indicate that an assertion or test has killed more mutants while the lighter more yellow shades suggesting fewer mutants killed and white would indicate no mutant kills.
for the left sub figure the entire region of a test within a grey boundary is colored to reflect the overall strength of a test case i.e.
the number of mutants each test case fails on aggregated by test failures from all sources.
in other words the color in these regions represents the crossfiring capability as measured at the test level.
when comparing mutant killing capabilities several key takeaways stand out the patterns formed by striped rectangular regions observed in the left sub figures for each subject reveal that the majority of developer written test cases contain multiple assertions.
darker shades of red dominate the left sub figures across all subjects.
these left sub figures show mutant kill counts for individual test cases.
the dark red shades suggest the aggregated effects of all of a test s assertions capabilities combined with its non assertion failures contributions.
in contrast we see lighter shades of yellow and orange in the right sub figures.
for tests constituent assertions some carry significantly more weight than others within a single test case or throughout the test suite.
in fact many assertions detect zero faults white of the mutants used whereas others in the same test case detect many.
overall the sparse lighter colored pixels at the assertion level reveal a surprisingly smaller fraction and a more dispersedcapability of individual assertions in their contributions to mutant kills.
notably testipv6 in c ommons validator marked with green boundary in figure 4c stands out with assertions and spans more than lines in test code.1this test case demonstrates a strong mutant killing capability as a whole deep red test region in the left subfigure but only assertions contribute to the mutation score.
interestingly the patterned bottom in figure 4e for j oda money shows the use of unit tests that share similar groups of assertions which could be parameterized.
answering rq1 while a single test case may demonstrate a strong mutant killing capability the constituent assertions unevenly contribute to that capability which reveals that some assertions are more capable of detecting more faults.
rq2 killable surviving mutants we present the results for both rq2 andrq3 in table ii where we present summary statistics for assertion candidates for killing surviving mutants as identified through our analysis.
we group the columns of table ii into three categories magnitude of killable surviving mutants a count of surviving mutants surviving alongside those that are killable killable as identified by our analysis.
ways of killing each killable mutant average number of ways to kill each killable mutant through checks by different a assertions assert b test variables var and c test cases test .
assertion candidate characteristics a count of number of assertions to kill all killable surviving mutants assert along with the number of tests test and test variables var used in devising the assertions.
1this may indicate a test smell instance because each individual assertion can be isolated as one single unit test case and parameterized.
7table ii surviving mutant killing opportunities magnitude of killable ways of killing each assertion candidate surviving mutants killable mutant avg characteristics subject project killable surviving assert var test assert var test commons cli commons valida.
spotify web api cdk data commons text dyn4j commons codec joda money jline reader jfreechart the column labeled magnitude of killable surviving mutants in table ii shows that our analysis is able to identify of surviving mutants as killable depending on the subject program.
in other words the existing tests already provide the necessary test data to execute infect and cause infection propagation back to at least one test however the tests do not have sufficient assertions to reveal it.
for instance our memory state analysis shows that of c ommons cli s surviving mutants are killable with assertion amplification to existing tests.
that number is as high as in the case of spotify web api where out of surviving mutants are killable.
answering rq2 for our subject programs a fine grained memory state analysis reveals that of surviving mutants exhibit propagated infections not revealed by test cases which can be killed through assertion augmentation of existing tests.
rq3 opportunities in tests for assertion amplification given that many surviving mutants are indeed killable through assertion augmentation of existing tests we next investigate the number of ways available tests test variables assertions to kill such mutants.
again consider the data in table ii.
for each mutant our technique is able to identify the total number of tests test variables and specific candidate assertions that can be of use in killing the surviving mutants.
consider s potify web api s killable surviving mutants.
we find that on average to kill a surviving s potify web apimutant our analysis can identify assertion candidates that can be written using different test variables e.g.
local variables method return values which spread across existing tests in s potify web api s test suite.
further for all killable mutants our analysis detected killing assertion candidates using different test variables in different existing test methods in s potify web api s test suite.
across all subject projects we identify comprehensive candidate solutions assertions tests variables to kill surviving killable mutants through our analysis.
the extensive mutantkilling opportunities arise from the fact that a single surviving mutant may produce a varied magnitude avg.
locations of propagation on multiple test cases avg.
tests which can be accessed through multiple variables avg.
variables .furthermore we additionally assessed the average depth for an assertion to access a specific field whose value can be asserted or evaluated from a variable in the test code.
we found that the average depth ranges from .5to12.1across all subject projects.
for example access paths that are four nodes deep suggest accessing heap locations through complex series of memory dereferences e.g.
var1.f1.f1.f3.f4 .
long access paths can make assertions hard to read and brittle leading to test anti patterns.
therefore it is important to filter out assertion candidates with excessively long access paths.
answering rq3 our memory state analysis uncovers extensive assertion amplification opportunities for each killable surviving mutant on average each can be detected through infected locations across tests in test code while only one location in one test would be necessary to kill it.
as such developers would have numerous options to kill each mutant.
rq4 optimizing crossfire strategies in table iii we present the performance of three mutant killing strategies introduced in section iv.
in the first three columns we present project s name the number of killable surviving mutants kill as a baseline and the average depth dep of an assertion s access path when accessing the runtime state from a variable in test code.
in figure we show examples of access paths where for instance var2.f4.f3 is an access path usable in an assertion and accessed from the test code s local variable var2 with a depth of .
for each strategy assertion variable test greedy we provide three crossfire performance metrics including the number of assertions assert variables var and tests test to kill the baseline number of surviving mutants from separate runs.
each strategy s best performance metrics are bolded with a crossfire factor included in the parentheses which is the average mutant killing capability of the test case element.
take s potify web apias an example iteratively searching for the most capable assertion strategy assertiongreedy yields a solution with an average of assertions that can be devised using over test variables across more than test cases.
the assertions would kill all killable surviving mutants where each assertion on average kills .
i.e.
the crossfire factor surviving mutants.
similarly iteratively searching for the most capable testvariable check strategy variable greedy yields a solution that on average yields the same number of assertions as in strategy but only requires a focus on variables across test cases.
further devising assertions using any one of those test variables would on average kill .8surviving mutants crossfire factor .
likewise iteratively searching for the most capable test case strategy test greedy produces a solution that only requires augmenting test cases where each assertionaugmented test on average kills .6surviving mutants.
moreover the average depth of assertions access paths is .5for killable mutants as a result of filtering out all assertions with 8table iii surviving mutant killing strategies subject project kill dep strategy assertion greedy strategy variable greedy strategy test greedy assert factor var test assert var factor test assert var test factor commons cli .
.
.
.
.
.
.
.
.
.
.
.
.
commons valid.
.
.
.
.
.
.
.
.
.
.
.
.
.
spotify web api .
.
.
.
.
.
.
.
.
.
.
.
.
cdk data .
.
.
.
.
.
.
.
.
.
.
.
.
commons text .
.
.
.
.
.
.
.
.
.
.
.
.
dyn4j .
.
.
.
.
.
.
.
.
.
.
.
.
commons codec .
.
.
.
.
.
.
.
.
.
.
.
.
joda money .
.
.
.
.
.
.
.
.
.
.
.
.
jline reader .
.
.
.
.
.
.
.
.
.
.
.
.
jfreechart .
.
.
.
.
.
.
.
.
.
.
.
.
non shortest depths much shorter than the access path depth of5.
which is the average depth when not filtering out nonshortest depth access paths.
across all subjects we observe significant mutant crossfire effects enabled by our optimizing technique.
each assertion can crossfire as many as .2surviving mutants in jfreechart with the assertion greedy strategy and each assertion augmented test can crossfire as many as .4surviving mutants in j line reader with the test greedy strategy.
such leveraged crossfire effects can enlarge each incremental assertion amplification effort and scope the overall engineering and validation efforts within a few assertions variables or tests.
for example our analysis found assertion amplification opportunities within tests from rq3 across all subjects while the test greedy strategy can scope the number down to 900tests by aggregating the last column in table iii .
as a result only 684out of 989assertion candidates are selected.
moreover each candidate assertion to kill surviving mutants has the shortest depth of access path to assert the state which on average ranges .
.
as compared to .
.1for candidate solutions before any of our three different optimizations.
such a reduction may mitigate rendering hard to read and brittle assertions that check attributes deeply accessible from a variable.
when comparing the three optimizing strategies we find that the test greedy strategy strategy is able to substantially reduce the number of tests to be improved.
remarkably for spotify web api the strategy almost halves the number of target tests from .
to .
and test variables from .
to .
that may require consideration for assertion amplification with a negligible rise in the number of assertions from .
to .
.
such significance reduction in the target tests can also be observed in multiple projects such as c ommons cli c ommons validator spotify web api cdk data and j line reader while not significantly increasing the number of assertions or variables to be checked for all subjects.
answering rq4 our mutant crossfire techniques with the test greedy strategy can scope the amplification efforts down to1 684from 989assertion candidates while retaining the ability to kill all 504surviving killable mutants across all ten subject programs.vii.
d iscussion our experimental results from the previous section offer several key insights into how we do test amplification the characteristics of killable surviving mutants and cross firing effects of tests which we discuss next.
we also offer a qualitative exposition of assertion candidates that we generate using real examples from our experimental data.
key takeaways from experimental data.
our approach for assertion amplification looks to kill surviving mutants.
we target surviving mutants because we find that many such hard to kill mutants propagate program state infections that go undetected by existing tests.
in our experimental subjects we note that of surviving mutants can be killed with such additional mutant killing assertions.
we also observe that multiple existing test cases can be amplified with additional assertions to kill surviving mutants.
interestingly a single surviving mutant can exhibit multiple state infections across various test cases for each surviving mutant on average our memory state analysis can detect different infection locations across existing tests.
we speculate the reasons behind such broad spectrum killability of surviving mutants software tests are intentional in their design and typically do not cover every possible fault in a program.
they reflect a software tester s intent and priorities e.g.
the behaviors they are testing for or the faults they are guarding against.
as such the fact that multiple test cases on average produce detectable infection from surviving mutants may be an indication that these mutations are relevant to the test data that were chosen by the software s developers but the developers simply did not provide sufficient assertions to detect some relevant fault revealing attributes.
we further surmise that such surviving mutations likely mimic faults that are meaningful to the program s logic and semantics as well as its human written test data and harnesses.
therefore such surviving mutants may warrant additional assertions to guard against faulty program behaviors.
critically we again observe this broad spectrum killability when studying crossfiring properties of tests and their constituent parts in many cases a single test assertion test variable or test case can detect and kill multiple mutants.
we leverage this observation to scope the amplification efforts within only a few test cases that we might augment which can bring down the number of assertion candidates from from spotify web api assertequals audio.getsegments .length assertnotnull audio.getsegments a assertequals .
audio.getsegments .getpitches b from commons cli option o optionbuilder.hasarg false .
withdescription display the groovy and jvm versions .withlongopt version .create v assertnotnull o c assertequals o.getargs d asserttrue parsedreadablefilestream.getfd .valid e from joda money throwable t assertthrows nullpointerexception.class bigmoney.of currencyunit null bigdec 2 345 assertequals currency must not be null t.getmessage f fig.
assertion examples to1 among tests while still being able to kill all 504surviving killable mutants across the ten subject programs.
this provides a crossfire factor of .
i.e.
900tests crossfiring 504surviving mutants .
representative examples of assertion candidates.
in figure we enumerate six representative examples of assertion candidates generated from our experiments on three subject programs s potify web api joda money and commons cli.
the assertion candidates are highlighted in bold and presented alongside snippets of the original test code.
each assertion candidate is marked as a through f .
these examples offer insights into the characteristics and suitability of assertion candidates produced by our approach.
while not exhaustive they serve as a qualitative exposition of our technique and results.
to capture a diversity of assertion candidates we include examples that a might be adopted by developers or b might introduce test anti patterns.
we also showcase how our approach safeguards against assertion candidates that might introduce test anti patterns.
examples that might be adopted by developers.
consider the assertion example a from s potify web apiand c and d from c ommons cli.
we speculate that such assertions are likely to be adopted by developers due to their simplicity.
these assertions check a variable directly e.g.
c performs a null check on test variable o or have shallow access paths to attributes such as fields defined in project production code e.g.
o.getargs in d or audio.getsegments in a .
for our experimental subjects we find that on average .
of the assertion candidates using the test greedy strategy simply check a test variable directly including checking primitive values string values variable type or their nullability.
we also observe that of assertion candidates access first party attributes from production code via fields or accessor methods e.g.
getargs .
further assertion examples in a c and d test variables and states in first party production code without requiring access to third party or system code.
on average of all assertion candidates from our experiments access variables and program states from first party production code.examples that might introduce test anti patterns.
consider the example assertions e in c ommons cli and f in joda money .
these assertions might introduce test antipatterns for different reasons and as such might not be adopted by developers.
assertion example e checks an attribute from an external library via a deep access path to examine the validity of a file descriptor .getfd .valid .
assertion example f checks the value of a method return t.getmessage from a system level class throwable .
we hypothesize that developers might avoid writing tests for external library code especially with deep and specific access paths leading to a higher likelihood of inducing test anti patterns due to reliance on external libraries and specificity.
notably as a side effect our crossfiring based filtering strategy see section iv b and rq4 experiment results in section vi reduces the average depth of access paths for assertion candidates from .
to .
.
as such when optimizing for cross firing effects our approach mitigates the likelihood of selecting assertion candidates with deep complex access paths that might lead to test anti patterns.
for instance between assertion examples a and b in spotify web apithat both detect the same mutant when optimizing for the number of tests i.e.
test greedy strategy shown in results for rq4 our approach would opt for assertion candidate a the simpler assertion candidate via shorter access paths.
future work.
we acknowledge that our insights into the selected assertion candidate examples depend on the authors categorization methods and do not capture actual developer sentiment or feedback.
the actual suitability of each assertion candidate is subject to the specific test case context testing and project requirements.
moreover we recognize that our techniques provide multiple options for each surviving mutant while only selecting one based on our strategy.
offering developers multiple choices allows them to select the most suitable assertion candidates or make decisions to isolate a new test thus reducing the occurrence of anti pattern assertions.
in the future we will conduct user studies to evaluate the suitability of these assertion candidates and design tools that investigate human aspects in mutation testing research.
viii.
t hreats to validity the external threats stem from the generalizability of our findings our observations on test assertion level mutant detection characteristics of unrevealed propagation and the performance of mutant crossfire strategies may not apply to other mutation operators subject projects or programming languages.
however we use a popular mutation testing framework pit with all its default group of mutation operators and select subject projects that vary in production code size test suite size and complexity.
further across all of our subjects we saw consistent observations every subject has many surviving mutants that are killable through mere assertion augmentation of existing tests and that crossfiring 10was a source of substantial savings in terms of the number of assertions needed to kill all killable surviving mutants.
internal validity is challenged by the presence of duplicate mutants which pit addresses through using a restrictive set of mutation operators that prevent operator subsumption ensuring a one to one mapping between mutants and target syntax and filtering out byte code identical equivalent mutants .
execution nondeterminism is another concern.
we mitigate it by our use of repetitive no mutation test runs followed by analysis of test consistency through object graph walks and isolation of each mutant s runs in separate jvm instances with static field cleaners.
finally the construct validity threats come from the limitations of our evaluation metrics and experimental setup.
conducting human involved studies or submitting pull requests to project maintainers would gain further insights into the actual suitability of our suggested assertion candidates.
a challenge to such a study of pull request acceptance rates is motivating the pull request to project maintainers who have no experience nor knowledge of mutation testing i.e.
we must answer the question why are we submitting a test that catches a bug that does not exist?
for developers who may not be aware of such approaches.
in this study we demonstrate the potential benefits of using different crossfire strategies present our assertion candidates characteristics and discuss assertion candidates suitability.
in the future we will conduct human studies to further explore the suitability of our approach.
ix.
r elated work mutant crossfiring in mutation testing.
recent literature distinguishes between mutation analysis and mutation testing mutation analysis assesses the strength of the test suite while mutation testing focuses on resolving each surviving mutant to strengthen the test suite.
smith and williams documented mutant crossfire where a new test targeting one surviving mutant coincidentally kills others.
jia and harman noted that mutants can be collaterally killed by tests aimed at different mutants.
this phenomenon where a single test kills multiple mutants appears in mutation testing research on mutation redundancies e.g.
mutant subsumption relationships e.g.
and mutant ranking techniques e.g.
.
we also observe and confirm the crossfire phenomenon in mutation testing from our investigations.
unlike prior studies that analyze mutants we offer a model to examine the causes of this phenomenon at fine grained memory state levels.
furthermore we use these insights to develop and prioritize crossfiring assertion candidates to target crossfiring mutants.
moreover we recognize that practitioners often work with individual surviving mutants and perform incremental augmentation in empirical mutation testing research both in academia e.g.
and in industry e.g.
.
this focus informs our work which differs from other test generation works in many aspects.test generation and amplification.
past efforts in test generation include test data generation e.g.
assertion generation in programs e.g.
or test code e.g.
and whole test suite generation e.g.
.
some of these efforts are mutationbased e.g.
.
additionally vera p erez proposed a mutation operator that suggests improvements into test suites with infection and propagation analysis previous work has also explored assertions roles in mutant killing and test suite effectiveness brittle assertions and realistic tests .
many works exploit existing tests and are considered test amplification .
danglot et al.
conducted a snowballing literature study and categorized test amplification into four types adding new tests synthesizing tests for changes modifying test execution and modifying existing test code.
our work falls into the last category but differs from prior works in key ways.
existing test generation and amplification work primarily aim to achieve a broader goal of improving test suites while using coverage mutation score as a proxy fitness function.
for example fraser and arcuri developed e vosuite to generate an entire test suite from source code baudry et al.
created d spot to perform test amplification by exploring more input space and assertions to enhance humanwritten tests.
in contrast our approach targets individual surviving mutants in mutation testing and prescribes assertion candidates to kill such unkilled mutants.
further to target individual surviving mutants our approach conducts a comprehensive memory graph walk to identify specific differences in memory state yielding precise assertion candidates e.g.
asserting a specific element in an array rather than the entire array .
prior test generation amplification techniques e.g.
compare primitive or stringtype values or entire objects to capture program states for overall test suite improvement.
in contrast we capture the full object state detecting infections in any enclosed fields arrays or collections accessible from an object.
additionally we mitigate brittle assertions by selecting those that check shallow attributes of a variable while rendering minimal and precise assertion candidates.
finally previous techniques apply separate heuristics to minimize tests such as reducing the number of generated assertions and prioritizing the most effective tests .
our amplification technique targets individual mutant killing and as such expects incremental code changes by practitioners.
therefore instead of selecting a single minimization approach we develop and compare different strategies that scope the incremental amplification efforts to a few assertions variables or test cases that ultimately achieve the same mutation score.
x. c onclusion in this work we developed a technique to identify assertionamplification opportunities for surviving mutants via memorystate analysis.
we found that up to of surviving mutants can be killed by reusing existing tests and augmenting their 11assertions.
each surviving mutant offers multiple locations in the test code for potential assertion amplification.
additionally we used the phenomenon of mutant crossfiring as encountered by practitioners to construct a theoretical model and offer empirical insights for crossfiring at various granularities.
building on these insights we devised a technique that optimizes the amplification process with which we find that we can kill all such killable surviving mutants detected from our analysis with fewer tests and fewer assertions providing a crossfire factor of .1x.
in future work we aim to conduct humancentered studies and validate our approach with mutationtesting practitioners.