dockerfile flakiness characterization and repair taha shabani university of british columbia vancouver canada taha.shabani ece.ubc.canoor nashid university of british columbia vancouver canada nashid ece.ubc.ca parsa alian university of british columbia vancouver canada palian ece.ubc.caali mesbah university of british columbia vancouver canada amesbah ece.ubc.ca abstract dockerfile flakiness unpredictable temporal build failures caused by external dependencies and evolving environments undermines deployment reliability and increases debugging overhead.
unlike traditional dockerfile issues flakiness occurs without modifications to the dockerfile itself complicating its resolution.
in this work we present the first comprehensive study of dockerfile flakiness featuring a nine month analysis of dockerized projects revealing that around exhibit flaky behavior.
we propose a taxonomy categorizing common flakiness causes including dependency errors and server connectivity issues.
existing tools fail to effectively address these challenges due to their reliance on pre defined rules and limited generalizability.
to overcome these limitations we introduce flaki dock a novel repair framework combining static and dynamic analysis similarity retrieval and an iterative feedback loop powered by large language models llms .
our evaluation demonstrates that f laki dock achieves a repair accuracy of .
significantly surpassing state of the art tools and baselines.
index terms docker flakiness large language models automated program repair i. i ntroduction docker is a set of platform as a service paas products that use os level virtualization to automate building deploying and delivering applications in containers.
this approach simplifies deployment across diverse systems and plays a critical role in the ci cd pipeline highlighting the importance of ensuring dockerfile reliability during builds to maintain software dependability.
existing academic and industrial efforts mainly focus on identifying dockerfile smell or bug patterns.
static analysis studies offer a linter to detect smells inside dockerfiles.
while existing techniques effectively identify various dockerfile smells they often rely on pre defined rules that are frequently outdated or poorly maintained .
parfum enriches the dockerfile ast with structural information derived from command lines enabling the automatic detection and repair of smells.
s hipwright employs a human in the loop approach to repair broken dockerfiles by clustering failure patterns using a modified bert model and hdbscan then formalizing solutions into a repair pattern database with regular expressions and fix functions.unlike test flakiness dockerfile builds can exhibit temporal failures that emerge over time due to dynamic changes in external dependencies such as updates to base images thirdparty libraries or environmental settings occurring without any modifications to the dockerfile itself.
these temporal failures can manifest as either deterministic or non deterministic behaviours depending on the nature of the underlying issues.
we refer to this phenomenon as dockerfile flakiness the unpredictable temporal behaviour of the dockerfile build process where builds may fail over time even though the content of the dockerfile itself remains unchanged.
deterministic failures consistently cause builds to fail after a specific point often due to changes such as the deprecation of a base image or the removal of a required dependency.
in contrast nondeterministic failures occur sporadically resulting in random build successes and failures.
such issues are typically caused by transient factors including server connectivity problems or temporary inconsistencies in package manager caches.
existing studies assume the reliability of the dockerfiles and their build output over time so that a build failure indicates the changes applied directly to the source dockerfile.
the literature largely overlooks the issue of flakiness in dockerfile builds which can disrupt the deployment process particularly in ci cd pipelines by hindering automatic builds.
this leads to delays and consumes valuable developer time and effort in diagnosing and resolving the underlying causes of the flakiness.
in this work we first examine the consistency and reliability of dockerfile builds over time.
in a longitudinal study spanning a nine month timeframe we built and analyzed dockerfiles of open source projects and observed that .
exhibit flakiness behavior.
based on the observed instances of flakiness we developed a taxonomy for characterizing dockerfile flakiness.
our findings indicate that the most common types of flakiness are related to dependencies web server connectivity and security authentication issues.
second we observe that existing techniques such as p arfum and s hipwright exhibit significant limitations in repairing flaky dockerfiles.
p arfum primarily addresses code smells making it less effective in tackling flakiness issues.
1arxiv .05379v2 feb 2025shipwright on the other hand faces challenges including heavy reliance on human intervention which hinders scalability and introduces variability due to dependence on the supervisor s expertise limited generalizability of repair patterns to diverse or unseen errors reliance on patternmatching and regular expressions which can introduce inconsistencies and the need for ongoing maintenance of the repair database to accommodate emerging failure types.
to overcome these shortcomings we present f laki dock a novel approach that leverages feedback directed retrievalaugmented generation rag with large language models llms to automatically repair dockerfile flakiness.
by integrating static and dynamic analysis similarity retrieval and an iterative llm based feedback loop f laki dock effectively resolves complex flakiness issues.
in this work we make the following contributions the first study of dockerfile flakiness characterization.
we present the first taxonomy of dockerfile flakiness by building dockefiles and analyzing build outputs of dockerized projects.
a dataset called f lake 4dock including and flaky and non flaky dockerfiles.
flaky dockerfiles are accompanied by categorization and build errors.
we also provide repair information for flaky dockerfiles specifically designed to evaluate flakiness detection and repair tasks.
an iterative llm based technique called f laki dock that leverages both static and dynamic information from dockerfiles to repair flakiness.
an empirical evaluation of f laki dock assessing its effectiveness with dockerfile repair tools and baselines such as gpt .
our results show that f laki dock achieves a .
repair accuracy in resolving dockerfile flakiness significantly outperforming p arfum .
s hipwright .
and gpt based prompting with build output .
.
ii.
m otivation listing shows a flaky dockerfile the corresponding build failure and a subsequent repair based on the build error.
according to the build output lines to using a virtual environment is required to install pipfor the specified alpine base image in dockerfile line due to the adaptation of python enhancement proposal pep which addresses externally managed environments.
this specification prevents package managers such as pip from modifying packages in the interpreter s default environment ensuring compatibility and reducing the risk of breaking the underlying operating system managed by external package managers.
as such this dockerfile fails to build whereas previous builds prior to this adaptation were all successful.
the solution here would be to create and activate a virtual environment as shown in the dockerfile context lines and .
while adhering to best practices is essential to mitigate errors and vulnerabilities in dock erfiles and in some cases to prevent potential failures from happening we argue that this alone is insufficient to address flakiness.
for example existing tools such as hadolint recommend pinning the exact version of the base image e.g.
rule dl3006 or dependencies e.g.
rules dl3007 dl3008 dl3013 dl3016 dl3018 to prevent errors caused by their internal changes.
this practice can be applied to listing by using old or outdated alpine images as a solution.
however it does not provide a viable solution for the problem applying such rules without considering the static and dynamic nature of dockerfiles can introduce other types of flakiness such as outdatedness and compatibility issues in the future.
build output ... run pip3 install r requirements.txt 88error externally managed environment if the package in question is not packaged already and hence installable via apk add py3 somepackage please consider installing it inside a virtual environment e.g.
... hint see pep for the detailed specification.
error process bin sh c pip3 install r requirements.
txt did not complete successfully exit code repaired dockerfile 1from alpine latest 2run apk add update python3 py3 pip git tcpdump 3run git clone memcrashed 4workdir memcrashed ... run pip3 install r requirements.txt run python3 m venv venv run .
venv bin activate pip install r requirements .txt 13entrypoint listing base image internal change listing demonstrates another flaky dockerfile that clings to the version pinning rule for the base image.
as depicted in the dockerfile line although the base image version is explicitly mentioned inconsistent behavior is plausible due to using a relatively old base image.
this flakiness is evident inside the build output line where the expression pre go17 is located.
the error stems from the compatibility issue of a stale golang base image i.e.
older than .
with existing dependencies utilized in the dockerfile line failing the compilation and build of the project.
accordingly a base image version upgrade is required line .
furthermore updated golang images require a different approach for handling executables lines and due to the adoption of new techniques.
build output ... run cd src go build ldflags linkmode external extldflags static o proxy go src golang.org x net context pre go17.go background redeclared in this block ... error process bin sh c cd src go build ldflags linkmode external extldflags static o proxy did not complete successfully exit code repaired dockerfile from golang .
.
as build env from golang .
as build env workdir src run go mod init my module 5run go get d v github.com armon go socks5 ... 8run cd src go build ldflags linkmode external extldflags static o proxy final stage 10from scratch 11workdir app ... 15cmd listing compatibility issues with stale base image dockerfiles depend on various elements such as operating systems packages environments commands and project source code making them susceptible to diverse forms of flakiness.
listings and demonstrate that understanding and resolving such flaky behavior requires analyzing both the static context dockerfile and dynamic context build output along with its temporal changes.
iii.
c haracterization of dockerfile flakiness in this section we present our longitudinal investigation of dockerfile builds which addresses the following research questions rq1 how prevalent is flakiness in dockerfiles?
rq2 what are the main categories of dockerfile flakiness?
the entire analysis including project checkouts and dockerfile builds was conducted on an infrastructure comprising four intel xeon .50ghz machines each with gb of ram.
a. data collection for our study we started with the s hipwright dataset which contains docker projects with ten or more stars from github repositories.
the dataset includes docker projects created up to june and focuses exclusively on projects with a single dockerfile located in the root directory.
we cloned the most up to date version of all the repositories from the s hipwright dataset.
however some repositories were no longer publicly accessible had been removed from github or no longer contained the root dockerfiles.
consequently our initial pool of projects comprised repositories.
in our study we analyze dockerfiles along with their build outputs which we generate by building the dockerfiles within our infrastructure.
given that some docker projects can be time consuming to build we set a minute build timeoutfor each repository.
this resulted in of builds completing without a timeout.
to ensure the reliability and efficiency of our large scale docker build system we use the docker build command with the no cache option to eliminate failures stemming from cached docker data.
additionally we develop a systematic docker cleaning technique to prevent environmental and internal errors ensuring a fresh docker environment.
to enhance time efficiency and prevent internal errors we clean the docker system after every four consecutive builds a frequency determined through trial and error.
the cleaning process involves removing all the cache images and any other peripheral leftover data during the builds alongside uninstalling and reinstalling docker with a steady version to prevent working with a corrupted docker system.
this pipeline ensures the freshness of the docker system throughout the builds.
using this approach we stored rounds of builds for the initial docker projects capturing dockerfile build outputs in our infrastructure machines from april to december .
b. flakiness extraction the detection of flakiness within test suites has been extensively explored in the prior work .
these efforts revolve around static and dynamic test code analysis pattern recognition rerunning tests multiple times and checking code changes through times in repositories.
considering the complexity and variety of dockerfile commands external dependencies and configurations directly checking the dockerfile context for flakiness detection would require an extensive endeavor.
furthermore due to the dynamic nature of dockerfiles characterizing flakiness utilizing only the static analysis approaches would fail to address all aspects.
filtering phase.
to start our flakiness study we initiated anin context docker build for all the dockerized github projects in our dataset that completed the build within minutes.
this resulted in .
successful and .
failed docker builds.
we consider only the successful ones as valid candidates for our flakiness analysis due to their initial stability.
over a period of nine months we rebuilt the candidate projects weekly totaling times.
the reason for conducting builds over an extended timeframe was two fold.
first building dockerfiles is a time consuming operation.
the average time to build a single dockerfile in our dataset is around eight minutes.
despite distributing our candidates across four different machines with similar operating systems and configurations and employing multiprocessing on each machine to enhance build speed some degree of delay was unavoidable.
second we expected that such an extended timespan could allow us to investigate temporal fluctuations in project stability.
pre processsing phase.
dockerfile build outputs can range from a few lines to thousands detailing the progress of each execution step.
diagnosing and extracting critical failure points from these outputs is essential but challenging especially when error logs are lengthy or the failure point is distant from 3the error s manifestation.
for instance the run pip install r requirements.txt command can produce hundreds of lines of output often cluttered with warnings or unrelated messages obscuring the root cause.
to address this we implemented a rule based pre processing approach that divides build outputs into stages each corresponding to a specific dockerfile command.
each stage includes lines containing the stage number execution time and log information.
by analyzing each stage we capture lines with error related expressions likeparseerror orerr!
along with adjacent lines sharing the same execution time to provide additional context for diagnosing failures.
c. flakiness categorization a taxonomy of dockerfile flakiness is critical for systematically addressing inconsistencies and complexities enabling developers to identify and resolve related challenges.
we employ similarity analysis to remove duplicates or identical errors within dockerfile build outputs.
this is followed by a detailed examination of pre processed outputs leveraging gpt .
to interpret and summarize the results.
finally manual analysis is performed to address potential inaccuracies.
clustering phase.
during the rebuild period we encountered failing build outputs while building the candidate projects.
to streamline our analysis and minimize redundancy within dockerfile build outputs we conduct a clustering process using sentence similarity assessment within each project.
to identify unique build errors in a single project we measure the cosine similarity between the build output embeddings extracted from the all mpnet base v2 sentence transformer which is trained over billion sentences in different domains.
using the similarity scores we cluster them into distinct groups.
in our clustering approach each new build output is evaluated for its similarity to existing clusters.
based on the average similarity with all current clusters we decide whether to incorporate it into an existing cluster or create a new one.
we apply this clustering method within individual projects rather than across all projects due to the intricate nature of dockerfiles and their build outputs which complicates the accurate clustering of errors when applied globally.
to improve accuracy we use pre processed build outputs for similarity comparison rather than raw outputs.
this approach resulted in an reduction in failing build outputs leaving remaining simplifying subsequent analysis steps.
labeling phase.
we employed gpt .
to extract error descriptions encountered during builds.
given the dockerfile context alongside the corresponding build error the model is prompted to extract a list of contributing factors to the error and an initial label indicating the category of error.
we then used these build errors alongside the information generated by the language model to construct a taxonomy of dockerfile build flakiness.
our objective was to create a comprehensive hierarchical classification that captures the diverse and dynamic behavior of dockerfiles.
to achieve this a brainstorming session among authors was conducted todesign a pipeline for analyzing context and refining the labels suggested by the language model.
two authors reviewed and resolved discrepancies in the labels generated by the model based on the dockerfiles and build errors.
any differences in interpretation were discussed among the authors to reach a consensus.
this systematic analysis resulted in the generation of category hierarchies requiring approximately personhours of effort.
d. rq1 prevalence of dockerfile flakiness while categorizing we selectively omitted failures stemming from our infrastructure docker servers and project source code issues to hone in on genuine instances of dockerfile flakiness.
infrastructure failures accounted for of the builds highlighting the effectiveness of our systematic docker cleaning method in ensuring reliability.
issues stemming from docker servers and project specific errors accounted for and failures respectively and were also excluded from the flaky build outputs.
for instance a project specific error could involve a command such as run build script.sh which executes a script exhibiting non deterministic behavior due to race conditions or reliance on external services.
similarly run npm install can result in project specific errors when dependencies listed in package.json exhibit flaky or inconsistent behavior caused by misconfigurations version mismatches or outdated packages.
in such cases the dockerfile itself is correct but the failure stems from issues within the external dependency definitions.
after filtering out these non flaky failures we were left with build outputs originating from .
dockerfiles out of candidate projects as some dockerfiles exhibited multiple distinct flaky behaviors throughout our longitudinal analysis.
this number would likely be even higher in realworld scenarios as our candidate dockerfiles were sourced from high quality projects.
this percentage is significant when compared to the prevalence of flaky tests in practice.
according to an empirical analysis on flaky tests .
of all test failures across test executions at google s continuous integration ci system named tap were reported to be due to flaky tests during a month window.
another study by microsoft reported that .
of individual test cases monitored over a month were flaky.
our finding of .
flaky dockerfiles aligns with the prevalence of flaky tests in other large scale systems highlighting the importance of investigating and developing tools to address dockerfile flakiness.
e. rq2 taxonomy of dockerfile flakiness figure illustrates our hierarchically structured taxonomy of dockerfile flakiness.
the left side shows the main categories of flakiness while the right side lists the associated subcategories.
the numbers within each box indicate the frequency of occurrences.
for each subcategory we indicate its nature deterministic non deterministic or mixed where mixed refers to cases that exhibit both deterministic and 4server access issues timeout issues internal w eb server issues dns configuration issues access control issues certificate v erification issues authentication authorization issues ssl tls issues gpg key issues licence issues permission denied issues internal cache issues undefined package manager issues environment management issues environment configuration issues copy command issues i o issues add command issues dependency related errors server connectivity errors security authentication errors package manager related errors miscellaneousenvironment errors filesystem related errorsdockerfile flakiness taxonomy retrieval import issues base image availability issues extraction invalid format issues versioning issues compatibility issues hash mismatch issues compilation syntax issues runtime issues undefined command issues vulnerability issues modification update issues deterministic non deterministic mixedfig.
dockerfile flakiness taxonomy non deterministic behaviors.
the rest of this section provides an overview of the primary categories of flakiness identified in our taxonomy.
detailed information including examples for each category and sub category can be found in our replication package .
dependency related errors dep .
this is the most prevalent category accounting for .
of all errors.
it encompasses subcategories of errors that occur during the retrieval installation or post installation operations of dependencies specified in dockerfiles.
these three steps of errors are shown in the first second and third rows of dependencyrelated error subcategories in figure .
we define a dependency as a base image or any external software package or library explicitly mentioned in the dockerfile.
availability and retrieval errors these errors happen when previously available dependencies are not found or cannot be accessed e.g.
r etrieval import issues temporarily or permanently or decompressed due to e xtraction i nvalid format issues .
as an example of b ase image availability issues one of the docker projects we studied mistserver uses from phusion baseimage master leading to a failure because this specific version of the image is currently unavailable.
installation errors during the installation phase flaky errors can occur due to different reasons including v ersioning issues or c ompatibility issues where specific dependencies with altered versions or configurations may conflict or be incompatible with one another causing the build process to fail.
these errors can also involve h ash mismatch issues and m odification update issues where changes in dependencies lead to inconsistencies.
for instance consider a scenario where package p1requires package p2with a version greater than or equal to v2to be installed properly but the existing p2version is older than v2.
post installation errors after installation flakiness canarise from the dependencies themselves such as v ulner ability issues compilation syntax issues or r untime issues .
additionally improper installations can lead to undefined command issues in the dockerfile resulting in build failures.
as an example we have observed flakiness in a dockerfile using symphony a php framework which is known to have vulnerability issues within its codeextension filters and using those filters may cause flakiness.
server connectivity errors con .
this category is the second most prevalent among all the categories comprising .
of the errors.
these errors occur when there are issues while connecting to previously stable external servers.
these errors are typically non deterministic except when servers are permanently out of service or entirely unreachable.
server access issues arise when the dockerfile cannot reach the target server due to invalid urls or temporary server downtimes.
t imeout issues occur when connections to servers take too long to establish or complete often caused by overloaded servers or the massive size of transferred data.
internal webserver issues refer to errors within the accessed server typically denoted with http status codes 500s .
dns c onfiguration issues arise when the dockerfile temporarily fails to resolve the server s domain name resulting in failed connections.
security and authentication errors sec .
this category contains errors related to changes or deprecation of previous security protocols and authentication processes making up .
of the total errors.
a ccess control issues arise when the dockerfile does not have the necessary permissions to access required internal resources caused by the base image s internal changes.
a uthentication authorization issues manifest when there are problems verifying the identity of the user or service which can result from incorrect or expired credentials or misconfigured authentication authorization services.
5this subcategory is mixed as such errors can be affected by transient factors like token expiration or permanent external service instability.
ssl tls i ssues encompass a range of problems related to the secure transmission of data including protocol mismatches and outdated cryptographic algorithms.
gpg k eyissues arise when there are problems with the cryptographic keys used to verify the integrity and authenticity of downloaded items which can prevent the successful retrieval and installation of necessary dependencies.
the nature of these errors is mixed as they can result from invalid keys or temporarily unavailable key servers.
lastly l icence issues occur when the dockerfile attempts to use software with new licensing restrictions.
package manager related errors pmg .
package manager related errors constitute of the flakiness instances and refer to the changes applied to the package manager configuration during the build process.
the most common subcategory of this class is i nternal cache issues with .
of total flakiness.
these errors arise from inconsistency or unreliability in the package manager s internal system during its installation or utilization resulting in failed operations.
this subcategory is mixed as deterministic failures can stem from corrupted caches while nondeterministic failures may result from transient issues with the package manager s internal operations.
as an example the command run npm install registry r where ris no longer a reliable registry for npm would cause an internal issue within the package manager.
another subcategory ispermission denied issues which occur when the dockerfile does not have the necessary permissions to interact with the package manager to install or update packages.
this sort of error can happen due to permission changes within the base images or other infrastructures within the dockerfile.
lastly u ndefined package manager issues encompass errors caused by improper installation of package managers resulting in a corrupted package manager within the system.
environment errors env .
environment manage ment issues and e nvironment configuration issues fall into this category representing .
of the errors corresponding to interactions with virtual environments.
these environment errors often arise from changes made to the base images or other underlying infrastructures specified in the dockerfile.
such changes enforce developers to strictly adhere to the new rules to minimize vulnerabilities and enhance the system s robustness.
a detailed example of this type of error is illustrated in listing where an externally managed environment is required to alleviate the risk of disrupting the os package management system.
filesystem related errors fs .
this category representing the smallest portion of our study on dockerfile flakiness accounts for less than of the total failures.
these errors include challenges in handling file system operations within dockerfiles such as copy and add command errors and i o issues generally stemming from the base image internalfile system updates.
miscellaneous.
during our analysis of flaky dockerfiles and their build outputs we categorized .
of the instances of flakiness as miscellaneous.
this group includes builds with highly complex errors or those executed in silent mode without informative execution logs making it challenging to pinpoint the issues and classify them.
iv.
f laki dock as demonstrated in section iii dockerfile flakiness presents various complex symptoms in the build output.
leveraging the ability of llms to solve programming tasks across different domains and the effectiveness of retrievalaugmented generation rag techniques we propose f laki dock an automated approach using llms to repair dockerfile flakiness.
our insight is that by providing llms with demonstrations containing static dockerfile and dynamic build outputs information along with repair patches from similar examples the model can resolve flakiness in new dockerfiles.
figure provides an overview of our approach.
a. demonstration dataset creation we first need to create a demonstration dataset for our approach.
to this end we randomly sample dockerfiles from our dataset of flaky dockerfiles and manually provide repairs for them.
to provide a robust demonstration of error categories in our repair dataset we maintain a minimum of coverage for categories that exhibit less than distribution of dockerfile flakiness such as pmg env and fs categories.
however within each category we randomly sample the dockerfiles.
if flakiness is not observed in a dockerfile at the time of analysis we randomly select another dockerfile from our dataset for repair.
we repair flaky dockerfiles using static dockerfile dynamic build outputs and extracted categorization information.
if a repair solution is not apparent using this information similar to s hipwright we perform a human inspection of the top five web pages from search engine results based on querying the error keywords to find potential solutions.
repairing dockerfile flakiness is a complex and timeconsuming task because it involves several intricate steps.
first one must understand the execution steps of the dockerfile and the overall workings of the project.
then the specific problem must be pinpointed and finally the suggested repair should be verified.
we verified the suggested repairs using the docker build command with the no cache option.
to confirm the reliability of the proposed repairs we test them as many times as the longest consecutive failure streak observed in our build history.
additionally if a dockerfile has exhibited different types of flakiness throughout the flakiness extraction phase iii b we only consider the types of flakiness that can be observed during the repair step.
some instances of flakiness may be difficult to reproduce or may have been resolved due to external dependency updates.
table i shows the distribution of repairs per category.
we spent approximately person hours generating 6flaky dockerfile flakiness demonstration datasetflakidock dynamic flakiness build outputfrom alpine latest run apk add update python3 py3 pip git tcpdump ... run pip3 install r requirements.txt entrypoint similarity retriever llm task description similar record repair similar record repair similar record repair flaky dockerfile and build info cot repair stylerepair validatorfalse repair feedbackfeedback repair ed flaky dockerfilefrom alpine latest run apk add update python3 py3 pip git tcpdump ... run python3 m venv venv run .
venv bin activate pip install r requirements.txt entrypoint static flaky dockerfile query flaky dockerfile build output response similar records run pip3 install r requirements.txt error externally managed environment this environment is externally managed ... please consider installing it inside a virtual environment ... dockerfile builder dockerfile build repair dockerfile build repair ... run pip3 install r requirements.txt error externally managed environment this environment is externally managed ... please consider installing it inside a virtual environment ... run pip3 install r requirements.txt error externally managed environment this environment is externally managed ... please consider installing it inside a virtual environment ... top k dockerfile from alpine latest run apk add update python3 run python3 m ensurepip run pip3 install upgrade pip setuptools ... build output run python3 m ensurepip error externally managed environment ... please consider installing it inside a virtual environment ... repair from alpine latest run apk add update python3 run python3 m venv venv env virtual env venv env path virtual env bin path run pip install upgrade pip setuptools ... dockerfile from alpine latest run apk add update python3 run python3 m ensurepip run pip3 install upgrade pip setuptools ... build output run python3 m ensurepip error externally managed environment ... please consider installing it inside a virtual environment ... repair from alpine latest run apk add update python3 run python3 m venv venv env virtual env venv env path virtual env bin path run pip install upgrade pip setuptools ... dockerfile from alpine latest run apk add update python3 run python3 m ensurepip run pip3 install upgrade pip setuptools ... build output run python3 m ensurepip error externally managed environment ... please consider installing it inside a virtual environment ... repair from alpine latest run apk add update python3 run python3 m venv venv env virtual env venv env path virtual env bin path run pip install upgrade pip setuptools ...fig.
overview of our proposed approach f laki dock dockerfile repairs.
notably the low occurrence in the server connectivity category is due to the fact that most errors in this category are temporary server issues resolved by the time of analysis.
category dep con sec pmg env fs total repairs table i number of repairs by category in our demonstration dataset a dockerfile is denoted with d and every record is defined as tuple sd dd cd rd id containing several elements of the flaky dockerfile.
the sd component contains the static information i.e.
dockerfile context.
the identifier ddindicates the pre processed build output of the flaky dockerfile which is referred to as the dynamic information.
cddefines the category label for the current dockerfile based on the taxonomy illustrated in fig .
elements rdandiddenote the repair patch proposed for the dockerfile and the number of iterations required for the repair to be tested to ensure its correctness respectively.
in case more than one repair is offered for a flaky dockerfile rdandidform a list of values.
b. dockerfile building the first step of f laki dock is to build a given flaky dockerfile to elicit the failing build output.
the purpose of this building stage is two fold.
first based on the build output extracted we classify the dockerfile as non flaky if no failure is detected over niterations.
conversely if a failure occurs we identify it as flaky behavior and proceed to address it.
nis determined based on our demonstration dataset ensuring it is at least greater than or equal to of idin our dataset which corresponds to a minimum of two iterations.
this approach isdesigned to encompass most flaky behaviors while optimizing time efficiency.
c. static and dynamic similarity retrieval phase few shot learning has shown remarkable efficacy when applied to llms .
while randomly selected examples can enhance performance recent studies indicate that choosing examples based on their similarity to the input context can lead to even more significant improvements.
in the domain of dockerfiles we argue that both static and dynamic information are required to resolve flakiness.
to this end upon completing the build phase the captured information along with the original dockerfile is used to retrieve similar examples from the flakiness demonstration dataset.
formally the input given to the similarity retriever is a tuple sq dq where sqanddqrepresent the static dockerfile and dynamic build output features respectively.
then the retriever uses the pre processing technique elaborated in section iii b to extract error related features from the build output.
the combination of sqanddqis the input query qto the demonstration dataset.
given that our input encompasses both code segments and natural language descriptions we utilize embedding based search via text embedding ada embedding from openai .
this model is pretrained on extensive datasets across various domains can process up to tokens and outputs a vector of dimensions.
using this transformer model we compare qwith the records in our demonstration dataset only seandde by applying cosine similarity to retrieve the top se de combinations that are closest in embedded space to the input query along with the corresponding repair snippets refor those retrieved dockerfiles.
7d.
repair generation this step contains the prompt design for dockerfile flakiness repair generation.
as shown in figure the prompt comprises a natural language task description the flaky dockerfile along with its build output and a chain of thoughts cot explanation to guide the model through the repair process.
the prompt is then augmented with demonstration examples retrieved from the similarity retriever.
each example econsists of a triple se de re represents the dockerfile build output and repair repairs suggested for the flaky dockerfile.
if previous attempts have generated incorrect repairs for the current flaky dockerfile a feedback message is included in the prompt as false demonstrations to help the model avoid similar mistakes.
it encompasses the history of proposed repairs each recorded as a false repair fr rfr dfr .
here rfrelement denotes the false repaired dockerfile and dfrshows the pre processed build output corresponding to the false repair.
e. repair validation the validation phase serves as a heuristic approach to determine whether the repair suggested by the llm is effective.
the structure of this stage is elaborated in algorithm .
in the beginning the repaired dockerfile is built ntimes and build outputs are captured similar to the dockerfile builder module described in iv b. if all build outputs are successful the validator confirms the repair s correctness and finalizes it as a result.
otherwise it identifies the most common error type observed from the feedback generated thus far.
the feedback comparison relies on the similarity of build outputs assessed using sentence transformation models.
through a manual evaluation of our demonstration dockerfiles we found that after three incorrect repair attempts with the same error llms tend to continue proposing flawed repairs due to hallucination or model deficiency in addressing that specific problem even with the augmented information provided.
therefore we establish a threshold denoted by t set at a constant value of to determine the stopping point for repair generation.
if a specific error type appears ttimes we interpret it as an indication of the model s hallucination or inability to resolve the issue resulting in the output unable to resolve!
.
if no error occurs three or more times new feedback consisting of the false repair and its build output is created appended to the existing feedback list and then incorporated into the llm s prompt to generate a new dockerfile flakiness repair.
v. e valuation to assess the effectiveness of f laki dock we address the following research question rq3 how effective is f laki dock and how does it compare to state of the art techniques?
a. implementation flaki dock is developed in python.
for our experiments we use the gpt model gpt as the llm algorithm repair validation input rd repaired dockerfile fd previous feedbacks it n t threshold output repair feedback unable to resolve!
buildoutput getbuildresults rd it ifallsuccessful buildoutput then return rd repair else failures countsimilarfailures buildoutput f d iffailures tthen return unable to resolve!
else fd appendnewfeedback rd buildoutput return fd feedback end if end if with the temperature parameter set to to ensure deterministic and well defined outputs.
chroma db which is an open source embedding database serves our need for vector similarity search.
for embedding generation we use text embedding ada from openai .
the temporal analysis including project checkouts and dockerfile builds is performed on an infrastructure consisting of intel r xeon r cpu .50ghz machines with gb ram each.
for repair we use aws machines of type t2.2xlarge each with cpus and gb ram.
b. experimental setup we initially identified dockerfiles exhibiting flaky behavior.
out of these dockerfiles were reserved for repair demonstration purposes.
this left us with dockerfiles showing signs of flakiness during our nine month longitudinal study.
however for the evaluation phase we focused only on those dockerfiles that continued to exhibit flakiness at the time of evaluation.
consequently we evaluated flakidock on dockerfiles as some causes of flakiness had been resolved over time.
c. baselines we compare f laki dock with p arfum s hipwright and llm only prompting to repair dockerfile flakiness.
we chose p arfum as it is a recent work offering automated repairs for dockerfile smells.
s hipwright uses repair pattern rules to automatically repair dockerfiles that fail to build.
in contrast other techniques such as hadolint and binnacle focus on detecting error patterns or smells and require manual intervention for their operation.
for gpt4 dockerfile only we invoke the gpt model to generate repairs based solely on the dockerfile content.
following that we include build output to provide more context for the llm to generate repairs.
we measure the effectiveness using the repair accuracy metric which represents the percentage of genuine repairs produced.
a proposed dockerfile is considered a genuine repair if its build is successful across nbuilds.
8table ii results for dockerfile flakiness repair tool and strategy dep con sec pmg env fs total parfum .
.
.
shipwright .
.
gpt dockerfile .
.
.
.
.
gpt dockerfile build output .
.
.
.
.
.
flaki dock w o feedback loop .
.
.
.
.
.
flaki dock w feedback loop .
.
.
.
.
.
d. results table ii presents the repair accuracy of each method across flakiness categories.
f laki dock with feedback loop achieves the highest success rate of .
demonstrating the effectiveness of iterative refinement.
in comparison p arfum has the lowest accuracy at .
and s hipwright achieves .
both highlighting their limitations in addressing complex errors.
gpt dockerfile only achieves .
while gpt dockerfile build output improves significantly to .
emphasizing the importance of incorporating build output context.
dependency related errors dep .
the repair accuracy for dep errors with p arfum is as it relies on predefined rules that fail to address the complex and dynamic nature of dependencies such as version mismatches or missing libraries.
shipwright achieves .
which is notable as this is the only category it can handle highlighting its limitations in addressing broader flakiness issues.
gpt dockerfile only achieves .
accuracy while gpt dockerfile build output improves to .
by leveraging build output context enabling the llm to better identify and resolve dependency issues.
f laki dock without a feedback loop achieves .
accuracy significantly outperforming other methods.
with the inclusion of feedback loop f laki dock yields the highest accuracy of .
demonstrating the effectiveness of iterative refinement in resolving dependencyrelated errors.
server connectivity errors con .
parfum achieves an accuracy of .
for addressing server connectivity errors.
gpt dockerfile only improves this to .
while the inclusion of build output further increases the accuracy to .
leveraging additional context for a more effective resolution.
f laki dock incorporating its feedback loop achieves an equivalent accuracy of .
demonstrating performance comparable to the most effective llm based approach for this category.
security authentication errors sec .
security and authentication errors pose significant challenges due to their complexity often requiring nuanced approaches beyond static rules.
gpt dockerfile achieves a .
success rate reflecting limited effectiveness due to its reliance on general llm capabilities without detailed context.
incorporating build output increases accuracy to .
highlighting the value of additional contextual information.
without a feedback loop f laki dock also achieves .
underscoring theimportance of iterative refinement.
with the feedback loop flaki dock attains the highest repair accuracy of .
demonstrating its ability to effectively address these intricate issues.
package manager related errors pmg .
parfum achieves a modest success rate of .
reflecting its limited ability to handle this category.
gpt dockerfile only performs better with a success rate.
this improvement is due to the llm s general knowledge of package management which enables it to address some common package related issues based on dockerfile content.
incorporating build output raises the accuracy to .
as the additional context enables better understanding of package manager related problems.
f laki dock without a feedback loop matches this .
accuracy.
however when the feedback loop is incorporated the highest accuracy achieved is .
environment errors env .
gpt dockerfile achieves a .
success rate demonstrating limited effectiveness due to its reliance solely on dockerfile content.
incorporating build output raises the success rate to .
as the additional context allows the llm to better understand and resolve environmental issues.
f laki dock outperforms all other methods achieving an .
success rate even without a feedback loop demonstrating its strong performance in addressing environmental errors.
however incorporating a feedback loop does not provide additional improvement.
filesystem related errors fs .
for this flakiness category all techniques including f laki dock fail to resolve any flakiness.
the primary challenge lies in the inability of existing tools and llms to account for changes in the updated image s filesystem such as a modified workdir .
although feedback or similar examples could potentially aid in addressing these issues our evaluation is limited to a single example making it difficult to draw generalized conclusions about this category.
vi.
d iscussion non deterministic dockerfile flakiness.
dockerfile flakiness can manifest as deterministic or non deterministic temporal failures each requiring tailored repair approaches.
deterministic flakiness results in persistent and reproducible build errors caused by specific external changes such as the deprecation of a dependency or removal of a required resource.
for example in listing a deterministic failure occurs due to the unavailability of the npm.taobao.org host causing the 9wget command to fail.
f laki dock analyzes the static and dynamic build information identifies the issue and proposes a repair by substituting the unavailable url with a valid one as shown in the repaired dockerfile.
however even after resolving a deterministic error it is important to note that new issues may arise in the future due to the evolving nature of dockerfile dependencies and environments.
build output summary wget unable to resolve host address npm.taobao.org repaired dockerfile run wget node v8.
.
linux x64.tar.gz run wget tar c usr local strip components xzf node v8 .
.
linux x64.tar.gz rm node v8.
.
linux x64.tar.gz listing host resolution error deterministic in contrast non deterministic flakiness arises sporadically due to transient factors such as server connectivity interruptions or temporary package manager caching inconsistencies.
these failures lack a consistent pattern complicating root cause analysis and repair validation.
for instance listing demonstrates a timeout error caused by a transient network issue during a yarn install command.
to address this f laki dock adjusts the network timeout configuration in the dockerfile to ensure stability as shown in the repaired version.
while f laki dock can propose an initial repair based on observed data a single successful repair validation is insufficient.
instead repairs for non deterministic failures must be tested iteratively over time to ensure reliability and prevent reoccurrence.
the repair validator in f laki dock facilitates this by running repeated builds monitoring outcomes across multiple iterations and confirming the robustness of the repair.
build output summary an unexpected error occurred com material ui icons icons .
.
.tgz esockettimedout .
repaired dockerfile from node .
.
... copy from deps tmp deps.json .
package.json copy yarn.lock .
run yarn config set network timeout run yarn install production listing timeout error non deterministic in f laki dock deterministic flakiness is repaired with greater certainty due to its consistent root cause.
nondeterministic flakiness however requires iterative testing and extended validation to ensure repair effectiveness.
f laki dock addresses both by offering immediate repairs for deterministic flakiness and incorporating a time based validation process for non deterministic cases adjusting parameters such asnfor iterative validation.threshold nfor determining a successful repair.
the parameter n representing the number of build iterations used to validate repairs is crucial for ensuring repair accuracy in addressing dockerfile flakiness.
in our study nwas set to two based on empirical analysis of the demonstration dataset capturing over of flaky behaviors.
for temporal deterministic errors this value is sufficient as these errors are resolved once the root cause is addressed.
once a deterministic error has been repaired successfully in a single build it is unlikely to reoccur so additional iterations have little effect on repair accuracy.
non deterministic flakiness presents a more complex challenge.
since these errors can occur unpredictably passing two rounds of validation may not suffice to reliably capture and resolve the flakiness requiring a higher nto ensure robustness.
a potential enhancement to f laki dock would be the inclusion of a detector that identifies the type of dockerfile flakiness deterministic or non deterministic .
based on this classification and based on the retrieved similar records the parameter ncould be adjusted accordingly.
for deterministic flakiness a lower nis sufficient while non deterministic flakiness would require a higher nto ensure a reliable repair.
this would prevent premature validation of repairs for nondeterministic errors.
dynamic nature of dockerfile flakiness.
dockerfiles rely on evolving components such as base images package managers libraries external urls and infrastructure.
changes in these dependencies such as deprecated libraries broken urls or updated environment variables can introduce flakiness causing builds to fail.
conversely flakiness can be resolved as dependencies stabilize without dockerfile modifications highlighting the temporal and dynamic nature of dockerfile flakiness.
our nine month study revealed the temporal nature of dockerfile flakiness where initially stable dockerfiles became flaky due to dependency updates and flaky ones stabilized as external issues were resolved.
static analysis tools fail to detect such failures as they lack awareness of dynamic dependency changes e.g.
listings and .
we propose a taxonomy to help developers systematically diagnose and address flakiness while preparing for future instability.
this underscores the need for f laki dock which dynamically adapts to evolving dependencies by providing context aware repairs.
limitations of existing tools for dockerfile flakiness.
existing tools for dockerfile repair such as s hipwright and p arfum exhibit significant limitations when addressing the dynamic and multifaceted nature of dockerfile flakiness.
shipwright achieved only repairs .
in our evaluation.
however this represents an upper bound as a repair is deemed successful if s hipwright generates an output dockerfile using its predefined patterns irrespective of whether it fully addresses the underlying flakiness.
this tool relies on repair patterns heuristically designed by its authors through a clustering approach.
these patterns must be maintained and updated to remain effective as new failure types emerge.
with10out regular updates the effectiveness of the tool is likely to decline given the dynamic and evolving nature of dockerfile dependencies which often introduce novel and unforeseen failure scenarios.
s hipwright was capable of handling only dependency related errors dep likely because such errors often align with its predefined patterns such as missing or incorrect dependencies.
similarly p arfum focuses on repairing dockerfile smells but lacks mechanisms to address dynamic flakiness achieving only a .
repair accuracy.
in contrast our proposed tool f laki dock integrates both static and runtime contexts using retrieval augmented generation and an iterative feedback loop achieving a significantly higher repair accuracy of .
.
these results highlight the shortcomings of static heuristic driven tools and emphasize the need for dynamic context aware approaches to effectively handle the complexities of dockerfile flakiness.
however f laki dock is not without limitations.
it relies on llms which may struggle with uncommon flakiness issues that fall outside their training scope.
its effectiveness depends on the diversity and quality of the demonstration dataset limiting performance in addressing rare error categories.
additionally the iterative repair process while effective can be computationally intensive and timeconsuming.
vii.
t hreats tovalidity choice of subjects.
the choice of dockerfiles for our study can inherently introduce a bias potentially influencing the results of our research.
to address this we employed a dataset from a prior study encompassing dockerfiles.
however the dataset includes dockerfiles from repositories with ten or more stars which one might find in popular github repositories addressing the generalizability of our findings to a broader range of dockerfiles.
duration of the study.
the duration of our study could potentially influence our findings especially with respect to detecting dockerfile flakiness and temporal failures.
to address this we conducted our study over a nine month period.
this allowed us to observe the dockerfiles over a significant period during which updates and changes are likely to occur potentially affecting their behavior.
this extended period provided us with sufficient data to identify non deterministic behaviors and temporal inconsistencies effectively.
host operating system.
the choice of operating system for docker can affect the results.
we used a stable version of redhat to ensure consistency but this may limit the generalizability to other systems.
different linux distributions or versions might show varying flakiness due to differences in package management and system libraries.
non linux hosts such as windows or macos could exhibit different flakiness not captured in our study.
by focusing on redhat we minimized environmental variability isolating dockerfile specific flakiness.
future research could explore dockerfile flakiness across diverse operating systems and versions.
repair construction bias.
as we generate the repair dataset we might be biased in providing the repairs in a way that helpswith other repairs.
this bias could stem from the tendency to create repair patterns that are more easily generalizable potentially overlooking unique or less common solutions.
to alleviate this bias we used repairs found from existing knowledge sharing websites such as stack overflow github discussions and the official docker website.
viii.
r elated work test flakiness.
there is a wide array of techniques that have been proposed focusing on characterizing detecting and repairing flaky tests .
continuous integration research such as has a strong overlap with test flakiness literature evaluating the prevalence and impacts of test flakiness in systems that involve test executions.
flaky tests are also a concern in user interface testing .
we refer to a recent survey for a more comprehensive discussion on flaky tests .
in contrast we are the first to examine flakiness from the perspective of dockerfiles.
dockerfile analysis.
in sections i and ii we discussed recent work on dockerfile analysis .
f laki dock differentiates itself from existing dockerfile smell detection tools and repair tools such as by not only addressing static issues within dockerfiles but also targeting the dynamic errors caused by the flakiness of dockerfiles.
shipwright introduces a human in the loop approach for repairing broken dockerfiles.
s hipwright begins by clustering broken dockerfiles to identify common failure patterns.
this is achieved by embedding build log text into vector representations using a modified bert language model followed by clustering with the hdbscan algorithm.
representative dockerfiles from each cluster are then presented to a human supervisor who searches for solutions to the identified failures.
discovered solutions are evaluated for applicability across the cluster and successful fixes are formalized into a database of repair patterns.
each pattern comprises a regular expression to identify issues and a corresponding repair function detailing the fix.
in contrast f laki dock is fully automated leveraging llms retrieval augmented techniques and a feedback loop to refine repairs without requiring manual oversight.
learning based program repair.
learning based program repair has been extensively studied in the literature .
unlike these approaches which involve training task specific models f laki dock uses a general purpose llm without the need for model training.
llm based program repair.
there has been increasing focus on applying llms to program repair tasks.
early studies focused on using prompts and error messages to generate source code repair in a single interaction with the model .
more recent techniques involve iterative approaches querying the llm multiple times and refining repairs based on feedback from previous attempts to repair source code .
in contrast in this work we leverage both static and dynamic information from dockerfiles to provide the llm enhancing its ability to repair flakiness more effectively.
by integrating 11retrieval augmented generation techniques we further ensure that the llm is equipped with relevant examples and contextual knowledge leading to more accurate and reliable repairs.
ix.
c onclusion we present the first comprehensive study on dockerfile flakiness identifying that .
of dockerfiles exhibit flaky behavior significantly impacting the reliability of ci cd pipelines.
to address this issue we introduce a novel taxonomy of dockerfile flakiness and propose f laki dock that leverages language models retrieval augmented generation dynamic analysis and an iterative feedback loop for automatic repair.
our evaluation shows that flakidock achieves a .
repair accuracy outperforming p arfum shipwright and gpt based prompting by and respectively.
these results highlight the effectiveness of f laki dock in addressing dockerfile flakiness.
x. d ata availability we have made our dataset model comparison framework and f laki dock s implementation available for the reproducibility of results.