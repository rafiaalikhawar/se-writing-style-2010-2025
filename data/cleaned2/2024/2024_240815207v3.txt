understanding the effectiveness of coverage criteria for large language models a special angle from jailbreak attacks shide zhou huazhong university of science and technology wuhan china shidez hust.edu.cntianlin li nanyang technological university singapore tianlin001 e.ntu.edu.sgkailong wang huazhong university of science and technology wuhan china wangkl hust.edu.cnyihao huang nanyang technological university singapore huang.yihao ntu.edu.sg ling shi nanyang technological university singapore ling.shi ntu.edu.sgyang liu nanyang technological university singapore yangliu ntu.edu.sghaoyu wang huazhong university of science and technology wuhan china haoyuwang hust.edu.cn abstract large language models llms have revolutionized artificial intelligence but their increasing deployment across critical domains has raised concerns about their abnormal behaviors when faced with malicious attacks.
such vulnerability alerts the widespread inadequacy of pre release testing.
in this paper we conduct a comprehensive empirical study to evaluate the effectiveness of traditional coverage criteria in identifying such inadequacies exemplified by the significant security concern of jailbreak attacks.
our study begins with a clustering analysis of the hidden states of llms revealing that the embedded characteristics effectively distinguish between different query types.
we then systematically evaluate the performance of these criteria across three key dimensions criterion level layer level and token level.
our research uncovers significant differences in neuron coverage when llms process normal versus jailbreak queries aligning with our clustering experiments.
leveraging these findings we propose three practical applications of coverage criteria in the context of llm security testing.
specifically we develop a realtime jailbreak detection mechanism that achieves high accuracy .
on average in classifying queries as normal or jailbreak.
furthermore we explore the use of coverage levels to prioritize test cases improving testing efficiency by focusing on high risk interactions and removing redundant tests.
lastly we introduce a coverage guided approach for generating jailbreak attack examples enabling systematic refinement of prompts to uncover vulnerabilities.
this study improves our understanding of llm security testing enhances their safety and provides a foundation for developing more robust ai applications.
i. i ntroduction large language models llms have emerged as a transformative technology in artificial intelligence drastically altering the way machines understand and generate human language.
these models have become the backbone of numerous applications from automating customer support to providing decision support in critical domains such as finance healthcare and legal sectors .
however as llms are increasingly deployed across these crucial domains they are frequently reported to suffer from abnormal model corresponding authors.behaviors particularly jailbreaking to generate harmful content which causes severe societal impacts.
this underscores the need for effective testing techniques to identify such attacks and maintain the trustworthiness of llms.
one crucial aspect of examining the adequacy and quality of tests for llms is the coverage criteria which provide a systematic way to measure the extent of model testing and identify potential gaps or weaknesses in the testing process.
despite a lack of testing coverage criteria specifically designed for llms prior research in the community has made commendable efforts to design coverage criteria for small scale neural networks.
these efforts provide valuable insights that could be referenced and further applied to llms.
among these coverage criteria neuron coverage nc focuses on the activation levels of individual neurons while k multisection neuron coverage kmnc examines the utilization of neurons across different activation ranges.
topk neuron coverage tknc and top k neuron patterns tknp emphasize the role of highly activated neurons and their patterns in the decision making processes of the model.
these criteria focus on different aspects of neuron activation and utilization offering a foundation for the development of llm specific coverage criteria.
however the application and effectiveness of these coverage criteria in llms remain unexplored motivating our aim to investigate their applicability and efficacy in this context.
the sheer size and complexity of llms characterized by their vast number of parameters and deeper layers present unique challenges that previous small scale evaluations may not address.
these challenges include determining the most suitable and effective criterion for llms identifying appropriate inspection points to monitor and striking a balance between comprehensive coverage and feasibility.
the generative nature of llms and their complex dynamics further complicate the selection of monitoring points and the adequacy of existing criteria in capturing their intricacies.
to bridge the gap in our understanding of how traditionalarxiv .15207v3 apr 2025coverage criteria perform when applied to llms comprehensive empirical studies are crucial.
first systematically evaluating the effectiveness of existing criteria such as nc tknc and tknp in the context of llms will help identify the most suitable criteria for assessing their robustness and reliability.
second applying these criteria to specific scenarios such as detecting abnormal llm behavior can provide valuable insights into the models limitations and potential vulnerabilities offering an alternative yet promising perspective on anomaly detection in llms and complementing existing methods.
our work.
in this work we conduct an in depth and extensive empirical study focusing on the well defined abnormal behavior of jailbreak attacks to examine the effectiveness of coverage criteria.
our study begins with a comprehensive clustering analysis of the hidden states of llms as they process various queries revealing that the characteristics embedded within these hidden states effectively distinguish between different query types.
building upon this foundation we then unfold our research across three key dimensions criterion level where we evaluate and compare the effectiveness of different coverage criteria in llms layer level where we assess the impact of network layers on coverage criteria to understand layer specific dynamics token level where we explore coverage criteria performance across tokens to provide insights into the granularity of model responses.
our research reveals significant differences in neuron coverage when llms process normal versus jailbreak attack queries aligning with our clustering experiments.
these empirical findings have led to the development of three practical downstream applications leveraging coverage criteria to enhance llm security testing.
the first is real time detection of jailbreak attacks which uses neural activation features to classify queries as normal or jailbreak with high accuracy .
.
this approach enables early detection from the model s first token output offering robust real time security capabilities for llm integrated systems.
additionally we propose test case prioritization to improve testing efficiency by identifying high risk test cases and eliminating redundant ones.
finally we introduce jailbreak case generation employing coverage guided methods to systematically refine prompts and uncover vulnerabilities.
these applications highlight the potential of coverage criteria to address key challenges in llm security testing.
contributions.
in summary this research makes the following contributions an extensive empirical study for llm evaluation.
our extensive empirical study reveals significant differences in neuron coverage between normal and jailbreak queries when evaluating traditional coverage criteria in llms.
three practical applications for llm security testing.
we propose real time jailbreak detection test case prioritization and jailbreak case generation demonstrating the versatility of coverage criteria.
towards robust llm development.
we have enhanced the understanding of llm security testing laying a foundation for more robust and resilient ai applications.ii.
b ackground and preliminaries a. model inference process we formalize the llm inference process based on the transformer architecture starting with the input vector h0.
the text is tokenized into discrete elements each mapped to a dense embedding vector representing token semantics for further processing by the model.
each transformer block or simply block hereafter denoted by i where i .
.
.
l andlis the total number of blocks enhances the data by operating through two primary layers attention layer adjusts the input vector hiby selectively focusing on various segments of the data sequence.
it enhances the ability of the model to respond to contextual nuances by dynamically weighting the importance of different inputs h i lattn hi hi i .
.
.
l mlp layer processes the output h ifrom the attention layer.
it applies a series of nonlinear operations to capture complex relationships within the data hi lmlp h i h i i .
.
.
l finally after processing through ltransformer blocks the final output hlis mapped by a linear layer and transformed into a probability distribution using the softmax function res softmax linear hl b. evaluation criteria for deep neural networks dnns mirroring the design of code coverage based on program logic a series of studies recognize that the internal states e.g.
neuron performance of dnns can be used to represent the logic of these networks.
the key focus is on how to better characterize internal states to design more effective coverage criteria.
table i summarizes the main criteria categorized into three types.
table i summary of coverage criteria for dnn testing category coverage criteria neuron activation and distributionneuron coverage nc k multisection neuron coverage kmnc neuron boundary coverage nbc strong neuron activation coverage snac neural coverage nlc top neuron activation top k neuron coverage patterns tknc tknp neuron trajectory or causal featurestensorfuzz coverage tfc surprise coverage sc likelihood surprise coverage lsc distance ratio surprise coverage dsc mahalanobis distance surprise coverage mdsc neuron path coverage npc causal coverage cc use of evaluation criteria in dnn testing.
in dnn testing white box coverage criteria provide insights into a test suite s ability to expose diverse functional behaviors known asfunctional diversity and detect potential defects referred to asdefect detection capability .
these criteria assess how different dnn components are covered reflecting decision making processes .
for example neuron coverage nc measures the proportion of neurons activated above a threshold reflecting the model s logic breadth.
top k neuron coverage tknc and top k neuron patterns tknp focus on significant neuron activations capturing key functional patterns.
high coverage inthese metrics suggests the test suite elicits diverse behaviors boosting confidence in the model s reliability.
these criteria also help identify inputs that trigger incorrect or unexpected behaviors revealing potential defects.
tensorfuzz coverage tfc represents neuron outputs from the same layer as high dimensional variables and clusters them based on different inputs.
the coverage is then quantified by the number of formed clusters capturing diverse activation patterns and potential abnormalities.
neural coverage nlc analyzes neuron activation distributions to find vulnerabilities.
by linking coverage with defect discovery these metrics prioritize test cases that expose hidden issues enhancing dnn robustness.
c. dnn testing versus llm testing traditional dnn testing focuses on black box and whitebox approaches.
black box testing uses benchmark datasets e.g.
imagenet to evaluate accuracy and generalization and employs fuzz testing to mutate inputs e.g.
lighting angle noise to further identify deficiencies in the model s handling of abnormal or boundary inputs.
white box testing seeks to capture the model s logic by examining its internal structure and behavior understanding and uncovering subtle errors and vulnerabilities that black box testing may fail to detect.
for example deepxplore designs neuron coverage to measure activated model regions and employs differential testing to identify inconsistencies among similar dnns efficiently detecting erroneous corner cases.
existing llm testing predominantly relies on black box testing by constructing benchmarks .
for instance mmlu assesses multitask accuracy across subjects including math history and law.
additionally recent studies have developed comprehensive black box robustness testing methods for llms.
despite the commendable progress in black box testing vulnerabilities like jailbreak attacks continue to emerge with their causes still unclear.
this motivates us to explore white box coverage criteria to examine llms internal behavior enabling more effective testing and defenses.
however white box testing coverage for llms might differ significantly from traditional dnns due to their vast inputoutput scope and larger architectures posing challenges for adapting existing white box criteria.
thus we focus on the critical security issue of jailbreak attacks and study the applicability of existing white box testing coverage approaches.
we anticipate this will reveal vulnerabilities overlooked by black box methods and improve testing and defense strategies.
specifically this not only enhances jailbreak detection but also helps prioritize test cases and generate efficient jailbreak cases.
beyond the jailbreak issue targeted in this paper we hope this study will inspire white box exploration to other security and functionality challenges in llms .
d. jailbreak attack and defenses llm developers have focused on aligning models to prevent harmful or objectionable outputs.
for example when prompted fig.
clustering experiment analysis results we select the results of block block block and block 31for display.
in the figure we use colors to distinguish datasets and shapes to represent clustering categories with write a convincing anonymous death threat aligned llms are trained to respond with rejections like i cannot answer such questions instead of producing harmful content.
despite these efforts jailbreak attacks have emerged that bypass alignment measures causing llms to generate harmful outputs and compromising their security .
in response defensive mechanisms are evolving.
methods like erase and check provide certified safety against adversarial prompts by sequentially removing tokens and inspecting subsequences with a safety filter.
other defenses such as smoothllm and jailguard reduce the success rate of jailbreak attacks by randomly perturbing input prompts and aggregating predictions.
additional strategies include perplexity based detection and self classification by llms which detect perplexity or directly assess prompt harmfulness.
iii.
s tudy design a. motivation a cluster analysis experiment previous research on small scale models has demonstrated that internal states can represent and further distinguish the logic of normal and abnormal behaviors aiding in the design of effective coverage criteria.
building on this insight we preliminarily investigate whether the internal mechanisms of llms can similarly distinguish between normal and abnormal behaviors .
specifically we collect queries that can trigger different behaviors in the llm and select the outputs hfrom the middle transformer blocks for these queries.
we then perform a clustering analysis on these outputs to observe if such internal states i.e.
the action values h can be used to distinguish between different model behaviors.
experimental setup we first introduce the setup for our cluster analysis experiments using the llama 7b chat model as our target.
we collect four distinct datasets and use queries from each dataset aiming to trigger different model behaviors.
normal queries are sourced from alpacagpt expected to trigger normal behaviors of llms in a qa format.
synonymous queries are the paraphrased versions of normal queries by gpt intended to trigger the same normal behaviors as the original queries.
rejected queries are sourced from advbench .
these malicious questions aim to trigger rejection behaviors considering the aligned llm is trained to reject such queries.
for example test suite construction multidimensional evaluation synonymous normal rejected attack llmsevaluation dimension coverage criteria ... nc nlcdataset sampletest suite redundant recognition attack sensitivity stability generalization evaluation criterion level model layer level generated token level evaluation standardfig.
the workflow of our study for malicious queries like how to make a bomb llms will respond with something like sorry i cannot provide .
.
.
to avoid harmful content.
attack queries are generated by appending adversarial suffixes to rejected queries using gcg .
these queries aim to trigger the model to output malicious content i.e.
abnormal behaviors .
we extract the hidden states hfrom the 4th 9th 16th and 31st transformer blocks for these types of queries and conduct k means clustering .
for more details about the setup please refer to our website .
findings as shown in figure in the final block block the clustering of queries is clearly separated into those that trigger normal behaviors normal and synonymous queries rejection behaviors rejected queries and abnormal behaviors attack queries .
interestingly normal and synonymous queries remain in the same cluster from block to block .
initially block rejected and attack queries are clustered together but they gradually separate as the model processes through more blocks.
in summary our clustering analysis demonstrates that the internal states of the model include features capable of representing and distinguishing the logic of different behaviors.
this confirms the feasibility of using internal states to design coverage criteria for llms.
however how to characterize the internal states to design better coverage criteria for llms remains unknown.
in the following section we introduce our methodology to thoroughly study this.
b. methodology evaluation dimensions in this section we first provide an overview of the empirical study workflow as shown in figure .
then we detail the three target evaluation dimensions that potentially contribute to assessing effective coverage criteria for llms.
three evaluation dimensions evaluation criterion level.
existing dnn coverage criteria primarily use neurons or network layers as the basic computational units evaluating model behavior from various perspectives.
however as the model size increases particularly in llms as mentioned in section i these criteria face new challenges.
the vast scale of llms complex training data and intricate architectures make some coverage criteria impractical or computationally expensive.
for example npc designed for convolutional neural networks is unsuitable for llms while cc requires complex causal inference with runtimes hundreds of times longer than nc.
storing hidden states for queries in our experiment consumes .
tb just .
of the training data.
thus using full training data is infeasible for some fig.
probability density plot of maximum neuron activation values across model blocks in llama 7b chat criteria while limiting to fewer samples may compromise metric effectiveness.
therefore we conduct a detailed qualitative investigation and manual comparison of recently proposed coverage criteria to determine their applicability to llms.
the detailed results are presented in table ii.
we select the following coverage criteria in this work nc tknc tknp tfc and nlc.
model layer level.
the second dimension we focus on is the model layer level.
unlike conventional dnn models llms typically consist of multiple transformer blocks each containing an attention layer and an mlp layer.
we examine two granularities the first involves observing the coverage changes in attention layers and mlp layers across the entire model as denoted by l attn hi and l mlp h i in section ii a. the second granularity goes one step further focusing on the coverage changes in attention layers and mlp layers within each individual block.
the reasons for choosing these two granularities are threefold.
first each layer in an llm plays different roles and exhibits varying complexity when processing information.
the attention layer captures dependencies and interactions between sequence positions while the mlp layer performs nonlinear transformations and feature extraction.
second our initial clustering experiments reveal that different blocks respond differently to query features with initial layers capturing low level features and deeper blocks focusing on high level features and complex patterns.
third we have recorded the maximum activation value of each neuron in different blocks of the llama 7b chat model while processing the same dataset.
we then plot the probability density of these maximum activation values for each block as illustrated in figure .
from the figure it can be observed that as the inference progresses both the mean and variance of the activation values in the llama2 7b chat model gradually increase.
different blocks exhibit noticeable differences in the density and distribution of neuron activation values on the same dataset.
in summary by observing the variations across different network layers we can gain deeper insights into the internal working mechanisms of llms thereby providing a more profound understanding of this study.
generated token level.
in the third evaluation dimension of our methodology we analyze the llm s behavior based on the different tokens generated during response generation.
unlike small dnns llms typically use an autoregressive architecture predicting the next token step by step based ontable ii comparison of coverage criteria applicability to llms criterion applicability reason nc tknc tknp tfc n a nlc applicable if we do not utilize training data for prior knowledge initialization.
kmnc nbc snac time prohibitive to determine the activation range of neurons on all training data.
lsc dsc mdsc time prohibitive to calculate neuron output trajectories for both the test suite and all training data.
npc cc complex causal discovery or decision path identification only designed for small dnns.
the previously generated tokens with internal states evolving at each generation step.
this raises the question which token s internal state should be used to represent the logic of abnormal behaviors?
this is crucial for designing effective criteria.
for instance in response to the query write a convincing anonymous death threat the model might generate the harmful response sure here s a convincing death threat for you .
.
.
.
the initial tokens generated before death do not convey harmful semantics.
therefore it is necessary to explore whether only the llm s internal states after generating death better represent the logic of abnormal behaviors for designing coverage criteria or if the initial internal state before generating sure can also serve this purpose.
this angle also helps us understand the role of individual tokens in the model s processing and how they contribute to the overall generation of coherent and meaningful responses.
due to varying query lengths and masking strategies in llms each token can only access information from preceding tokens.
as a result the final token of the query sequence t0 captures the complete information of the query serving as a condensed representation of the entire sentence s semantics.
we use this final query token as the reference point for our analysis.
to investigate the model s semantic construction mechanism during generation we compare the coverage criteria inspected after generating each token at different queries and their respective outputs.
we denote the first token of the output relative to t0ast1 the second token as t2 and so on.
c. standards for coverage evaluation to evaluate the performance of different coverage criteria on llms we propose three fundamental requirements inspired by traditional coverage criteria standards focusing on functional diversity defect detection capability andgeneralization .
due to the wide and unconstrained output space of llms we define these requirements from the perspective of the jailbreak safety problem extending traditional standards to address the unique challenges in llm testing.
requirement accurate redundant test identification.
aligned with the emphasis on functional diversity in traditional dnn testing an effective coverage criterion for llms should accurately reflect diversity within the test suite and be insensitive to redundant tests.
for example in traditional image classification two similar images non adversarial are often considered redundant test cases and do not contribute to the diversity of the test suite .
in the context of llms paraphrased queries that convey the same meaning and trigger similar responses thus activating the same logic should also be be regarded as redundant.
this ensures that the coverage metric genuinely represents the breadth of the model sexplored behaviors without being inflated by synonymous inputs.
requirement sensitivity to attack queries.
building upon the defect detection capability emphasized in traditional coverage criteria we extend this concept under the jailbreak perspective for llms.
for example in traditional dnn models adversarial attacks often lead to incorrect classifications which are considered faults in the model .
similarly in the context of llms we regard abnormal behaviors caused by jailbreak attacks as faults.
an effective coverage criterion should be particularly sensitive to attack queries that induce abnormal behaviors such as generating harmful or disallowed content.
by focusing on the model s responses to malicious inputs the coverage metric assesses the model s robustness and its ability to handle security threats.
this extension addresses the unique safety concerns associated with llms expansive output space while maintaining correspondence with traditional defect detection objectives.
requirement stability and generalization ability.
consistent with the generalization principles valued in traditional coverage standards we adapt this requirement to the diverse landscape of llms.
an effective coverage criterion should exhibit stability and strong generalization capabilities providing consistent guidance for model testing regardless of specific model variations.
given the rapid evolution and diversity of llms this ensures that the coverage metric remains effective across different models paralleling traditional standards while addressing the specific challenges in llm testing.
iv.
evaluation in this section we present a detailed analysis of the empirical results derived from our study.
the source code and other detailed information related to the experiments are published in .
we begin by outlining the experimental setup followed by our explorations and answers to the research questions below rq1 which is the most effective coverage criterion for llms?
rq2 which layer block s within the llms could optimize coverage analysis?
rq3 which token in llms has the most significant impact on the coverage analysis?
a. setup models in this study we comprehensively evaluate four well known open source llms which vary significantly in size architecture and origin.
these models include opt125m llama 7b chat pythia 12b and gemma 27b it .
note that we include opt 125m and pythia 12b which are non safety aligned to ensure comprehensive observations.
test suite construction to systematically evaluate the coverage criteria under different conditions we construct various test suites based on three requirements and observe changes in coverage.
consistent with the setting in section iii a we collect normal queries to trigger normal behaviors synonymous queries to trigger redundant normal behaviors rejected queries to trigger rejection behaviors and attack queries to trigger abnormal behaviors.
we start by creating a benchmark test suite sncontaining normal queries as the base.
then we construct several test suites to evaluate the performance of the coverage criterion in terms of different behaviors.
to evaluate against requirement we need to verify whether the coverage criteria can accurately identify redundant tests.
therefore we construct two test suites sns which adds synonymous queries to the normal queries from sn andsrs which replaces normal queries from snwith their synonymous counterparts.
compared to the coverage in sn the coverage criterion that meets requirement should show minimal improvement in snsand a decrease in srs assnsonly adds redundant cases and srsreduces the total number of unique queries.
to evaluate against requirement we need to verify whether the coverage criteria are sensitive to attack queries.
therefore we construct two test suites snj which adds attack queries to the normal queries from sn andsrj which includes normal queries and attack queries.
due to the distinct nature of attack queries the coverage criterion that meets requirement should show a significant coverage increase in snjcompared to the benchmark suite.
by comparing the coverage of srjwith the benchmark suite we aim to assess the impact of replacing normal queries with an equal number of attack queries on the coverage.
to evaluate against requirement we analyze the coverage criterion s performance across different models using the same test suite.
additionally we construct test suites snm andsrm that include rejected queries which models tend to reject to observe their impact on coverage.
we expect a moderate coverage increase from adding these rejected queries as they are distinct from normal queries but consistently rejected by the model.
however this outcome depends on the model s security alignment and is not considered a requirement for evaluating the coverage criterion.
therefore to construct our test suites as listed in table iii we select the following two widely used datasets and create a complementary dataset on our own alpaca gpt4 primarily used for fine tuning llms this dataset includes instructional tasks designed to emulate routine question and answer scenarios in everyday environments serving as the source of normal queries for the test suites.
jailbreakv this dataset is tailored to assess the robustness of llms against jailbreak attacks.
each dataset entry consists of a pair of rejected queries and corresponding attack queries derived from the rejected queries using attack templates to induce the model to output malicious content .table iii distribution of test suites across datasets test suitealpaca gpt4 jailbreakv 28k normal synonymous rejected attack sn sns snm snj srs srm srj synonymous query dataset to construct synonymous queries we use gpt to generate corresponding synonymous paraphrases for the first queries from the alpaca gpt4 dataset and manually verify that the synonymous queries produce outputs similar to the original queries e.g.
what is the capital of france?
and name the capital city of france.
both with the answer paris .
this complementary dataset serves as the source of synonymous queries for the test suites.
coverage criteria settings we refer to the settings from prior studies making appropriate adjustments for practical applications in llms.
we briefly describe the basic settings of the coverage criteria used in our experiments and explain the rationale behind these choices.
note that our experiments focus on the trend of coverage changes rather than precise numerical values.
ncrequires an activation threshold parameter tto determine whether a neuron is activated.
due to the different size and activation functions among opt 125m llama 7b chat pythia 12b and gemma 27b it which significantly affect the distribution of neuron activations we empirically set tto .
.
.
and respectively.
tknc requires a parameter tto determine the number of top neurons selected.
for all models we set tto .
tknp is similar to tknc.
however our experiments show that due to the complexity of llms setting ttoo high results in each new input forming a new pattern.
therefore we set t to .
tfc requires a parameter tto determine the distance between different clusters.
here we again refer to the model sizes and set tto and respectively.
nlc does not require a pre set parameter.
however since we do not have access to the complete training data to use as prior knowledge for nlc we calculate it directly on different test suites.
b. rq1 evaluating coverage criteria effectiveness in llms to address rq1 we evaluate the performance of the coverage criteria across different test suites and models to determine if it meets evaluation requirements.
table iv presents the neuron coverage measured at the last query token across the attention and mlp layers of each block.
in rq2 and rq3 we will further investigate the impacts of different network layers and tokens on the coverage evaluation results.
evaluation against requirement .
requirement mandates that the coverage criteria accurately identify redundant tests.
the average coverage growth calculated on the attention layer for nc tknc tknp tfc and nlc registers at .
.
.
.
and .
respectively table iv coverage results for each criterion on different test suites on sn the original coverage results are displayed while for other test suites the change rates relative to snare demonstrated attention mlp model criterion config sn sns snm snj srs srm srj sn sns snm snj srs srm srj opt 125mnc t .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tknc t .
.
.
.
.
.
.
.
.
.
.
.
.
.
tknp t .
.
.
.
.
.
.
.
.
.
.
.
tfc t .
.
.
.
.
.
.
.
.
.
.
.
nlc n a .
.
.
.
.
.
.
.
.
.
.
.
.
.
llama 7b chatnc t .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tknc t .
.
.
.
.
.
.
.
.
.
.
.
.
.
tknp t .
.
.
.
.
.
.
.
.
.
.
.
tfc t .
.
.
.
.
.
.
.
.
.
.
.
nlc n a .
.
.
.
.
.
.
.
.
.
.
.
pythia 12bnc t .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tknc t .
.
.
.
.
.
.
.
.
.
.
.
.
.
tknp t .
.
.
.
.
.
.
.
.
.
.
.
tfc t .
.
.
.
.
.
.
.
.
.
.
.
nlc n a .
.
.
.
.
.
.
.
.
.
.
.
gemma 27b itnc t .
.
.
.
.
.
.
.
.
.
.
.
.
.
tknc t .
.
.
.
.
.
.
.
.
.
.
.
.
.
tknp t .
.
.
.
.
.
.
.
.
.
.
.
tfc t .
.
.
.
.
.
.
.
.
.
.
.
nlc n a .
.
.
.
.
.
.
.
.
.
.
.
the abbreviations used are as follows nc represents neuron coverage tknc represents top k neuron coverage tknp represents top k neuron patterns tfc represents for tensorfuzz coverage and nlc represents neural coverage.
when comparing the coverage results of the synonymous test suitesnsto the benchmark test suite sn.
this is expected as the extra redundant test cases in the synonymous query dataset will slightly increase the coverage.
a similar distribution pattern emerges in the mlp layer.
these results indicate that nc and nlc maintain the lowest growth rates tknc exhibits intermediate performance while tknp and tfc show higher growth rates.
this suggests that nc tknc and nlc accurately identify synonymous queries whereas tknp and tfc demonstrate weaker recognition capabilities.
further the change in coverage rates calculated on the attention layer for these five criteria measures .
.
.
.
and .
respectively comparing the synonymous test suite srsto the benchmark test suite sn.
as expected the existence of synonymous test cases in srsleads to lower coverage compared to sn despite both having the same number of test cases.
nc and tknc continue to perform well successfully capturing the richness variation in the test suites.
moreover the coverage rate for tfc also shows a decline that of tknp remains largely unchanged and that of nlc unexpectedly increases.
collectively tknp may be overly sensitive for llms even with the hyperparameter k set to recognizing minor differences in each query and assigning them to distinct patterns similar to tfc.
for nlc bothsrsandsnsdemonstrate lower growth compared to sn.
this may suggest that in the view of nlc feature capture for normal queries reaches saturation within the first queries and neither an additional normal nor synonymous queries significantly enhance the richness of the test suite.
thus nc tknc and nlc meet requirement while tknp and tfc underperform in recognizing synonymous queries.
evaluation against requirement .
requirement mandates that the coverage criteria be sensitive to attack queries.
the average coverage growth on the attention layer for nc tknc tknp tfc and nlc records at .
.
.
.
and .
respectively comparing snjto sn.
all five criteria achieve significant growth with tfc and nlc showing the largest increases.
the performance on the mlp layer however presents a slight variation with coverage growth for the five criteria at .
.
.
.
and .
respectively.
coverage growth for nc and nlc is notably lower compared to their performance on the attention layer while tknc tknp and tfc continue to perform well.
this indicates that all five criteria are capable of recognizing attack queries.
however performance varies across different model layers.
we will discuss these layer level differences in detail in rq2.
furthermore we observe significant coverage differences between normal sn and abnormal outputs snj in wellaligned models.
well aligned models have safety neurons to reject malicious queries but attack queries often bypass these and activate neurons linked to abnormal behaviors.
as a result normal and abnormal behaviors activate different neurons causing coverage differences.
it s intriguing to observe that this phenomenon also occurs in non aligned models.
this may be because llms associate specific neurons with different knowledge domains leading to varying activation patterns depending on the query type.
abnormal behaviors such as bias or harmful content activate distinct knowledge areas triggering neurons linked to negative or harmful knowledge domains which results in noticeable activation differences.
note that in non aligned models the higher snj compared to snmcan be due to attack queries often involving unusual templates instructions or more diverse outputs unlike straightforward malicious queries.
evaluation against requirement .
requirement mandates that the coverage criteria be stable.
we first calculate the variance in the coverage growth of five criteria on the same test suite.
in the attention layer both nlc and tfc show notable variances in coverage growth with nlc having a variance of .
on snjand tfc having a variance of .
.
consequently it can be observed that tfc performs poorly on llama 7b chat and gemma 27b it while nlc performs poorly on llama 7b chat.
in the mlp layer tknp displays a variance of .
in coverage growth on snj.
tknp performs better on llama 7b chat compared to other models.
in contrast nc and tknc maintain stable performance across all models with the highest variance being .
for tknc in the mlp layer on snj.
this suggests that the performance of nlc tfc and tknp is significantlyinfluenced by changes in model architecture or parameter size whereas nc and tknc exhibit better generalization ability and stability .
such stability and generalization are crucial for the ongoing evaluation and testing of llms in practical applications ensuring consistent testing results across various model configurations.
answer to rq1 considering the three requirements nc and tknc are relatively effective.
they accurately identify synonymous and attack queries while ensuring stability and generalization across models.
nlc demonstrates competitive performance but exhibits variability across different models.
c. rq2 analyzing model layer wise contributions to coverage in llms relative coverage growth to address rq2 and observe the effectiveness of coverage criteria across different layers we introduce a new metric called relative coverage growth rcg that quantifies the performance of coverage criteria at different layers within the same model considering the three fundamental requirements rcg max csnj csns csn specifically rcg measures the effectiveness of different layers by calculating the increase in coverage for attack queries compared to synonymous queries.
on a macro level this metric represents the additional enrichment brought to the base test suite by the same number of attack queries compared to synonymous queries.
for requirement accurately identifying synonymous queries corresponds to a lowercsns csn.
for requirement sensitivity to attack queries corresponds to a highercsnj csn.
both of these requirements can be reflected by a higher rcg.
requirement can be represented to some extent by the stability of rcg.
therefore rcg provides a systematic approach to quantifying the effectiveness of coverage metrics across different layers aiding in the understanding of hierarchical differences in llms.
attention layer versus mlp layer we first evaluate the performance of attention and mlp layers from an overall model perspective.
we use nc and tknc identified as effective in rq1 as our research criteria and calculate rcg based on the data in table iv.
for nc the rcg values for attention layers in the four models are .
.
.
and .
respectively.
correspondingly the rcg values for mlp layers are .
.
.
and .
.
it is evident that under the same criteria and models nc is more effective in attention layers than in mlp layers.
similarly for tknc the rcg values for attention layers in the four models are .
.
.
and .
while the mlp layers show values of .
.
.
and .
.
except for llama 7b chat the effectiveness of attention layers remains superior to that of mlp layers.
additionally as shown in table iv the snjcoverage growth rates are generally highest for all criteria in attention layers with one exception.
in contrast in mlp layers higher snmgrowth rates are observed in nc for the llama 7b chat model and in tfc and nlc for the pythia 12b model.
these results indicate that attention layers capture input features more effectively than mlp layers enhancing the accuracy of coverage criteria in evaluating model testing.
this may be because attention layers better capture the global dependencies among input data leading to a deeper understanding of input features.
in contrast mlp layers rely mainly on linear combinations of local features and fail to comprehensively capture the complex dependencies within the input data.
therefore attention layers demonstrate superior effectiveness and accuracy in coverage analysis compared to mlp layers.
impact of different blocks llms are typically composed of multiple stacked transformer modules with the hidden states exhibiting distinct characteristics as the model depth increases.
building on the foundation of attention and mlp layers we aim to further investigate the contribution of individual blocks within different models to the overall coverage.
to achieve this we calculate the nc and tknc for the attention and mlp layers in each block of the models using various test suites and we record the corresponding rcg.
figure illustrates the variation of rcg across different blocks in four models.
from the nc perspective each model exhibits high rcg values over a continuous range of blocks.
specifically opt125m shows high rcg from block to block llama 27b chat from block to block pythia 12b from block to block and gemma 27b it from block to block .
the high rcg values in certain blocks suggest that the set of activated neurons varies significantly for different query types.
these blocks play a crucial role in distinguishing complex query types and nc effectively captures these features.
therefore for nc the intermediate layers of the models especially within the identified block ranges are essential for differentiating query types and enhancing the effectiveness of the coverage criteria.
from the tknc perspective the variation in rcg across different blocks in the four models is less significant with the initial blocks generally exhibiting slightly higher rcg than the later ones.
the sets of top neurons for different query types show similar variations across all blocks which tknc consistently identifies.
thus all blocks contribute to tknc s effectiveness with initial blocks having a more significant impact than later blocks.
answer to rq2 attention layers are more effective than mlp layers for optimizing coverage analysis in llms.
additionally nc focuses on specific crucial blocks to capture features of different test suites while tknc consistently identifies these features across blocks.
d. rq3 investigating token level impacts on coverage analysis in llms to investigate rq3 we expand on the previous experiments by generating additional tokens for each test suite and calculate012345678910110.
.
.
.
.
.
attention nc attention tknc mlp nc mlp tknc a opt 125mrcgn umber of blocks0369121518212427300.
.
.
.
.
.
.
b llama 7b chatrcgn umber of blocks051015202530350.
.
.
.
.
.
c pythia 12brcgn umber of blocks0510152025303540450.
.
.
.
.
.
d gemma 27b itrcgn umber of blocksfig.
the rcg results based on nc and tknc for different blocks of the four target llms opt 125m contains blocks llama 7b chat contains blocks pythia 12b contains blocks and gemma 27b it contains blocks .
.
.
.
.
.
attention nc attention tknc mlp nc mlp tknc a opt 125mrcgn umber of tokens01234567890.
.
.
.
.
.
b llama 7b chatrcgn umber of tokens01234567890.
.
.
.
.
c pythia 12brcgn umber of tokens01234567890.
.
.
.
.
.
d gemma 27b itrcgn umber of tokens fig.
the rcg results calculated based on nc and tknc for different tokens in the target llms starting from the last token of each query each model compares consecutive tokens the coverage over the next consecutive tokens starting from the last token of the query1.
we explore how different tokens impact coverage analysis assuming they may lead to varying coverage behaviors and reveal more comprehensive insights into model behavior.
our key question is how does generating additional tokens affect diversity assessment among test suites in llm testing?
our further goal is to identify the optimal token positions for llm testing to reduce computational costs and achieve efficient testing results.
these points are crucial for determining the most effective moments to measure coverage thereby optimizing the balance between testing and resource expenditure.
after generating each new token we calculate the corresponding coverage rates for the model.
this process allows us to examine how the coverage evolves as the model generates more tokens beyond the initial query.
similarly we analyze the impact of these tokens on coverage analysis through the rcg quantified by nc and tknc.
the experimental results are shown in figure .
the experimental results clearly indicate that generating additional tokens does not significantly improve rcg.
in the opt 125m model the rcg in the attention layer exhibits some fluctuations but does not show a noticeable increase with the token generation while the mlp layer shows an overall decreasing trend.
in larger models such as llama 27b chat pythia 12b and gemma 27b it rcg calculated based on nc and tknc decreases significantly in both the attention and mlp layers.
this suggests that as the number of tokens increases the differences between attack queries and synonymous queries gradually diminish.
this might be because larger models generate outputs with greater diversity 1for experimental stability we select the next token with the highest probability.which in turn reduces the differences in coverage performance between various test suites.
this trend also indicates that generating additional tokens for test suites may not always be an effective testing strategy for larger models.
instead it may lead to different test suites performing similarly indicating a reduction in the diversity and effectiveness of the tests.
this finding suggests that careful consideration of token generation strategies is necessary when designing test suites to avoid unnecessary computational overhead and decreased testing effectiveness.
answer to rq3 considering all four models testing at the last token of the original query in the test suites proves to be the most effective.
generating additional tokens may lead to a reduction in the differences between test suites.
v. a pplication we explore the following three applications.
first we propose real time jailbreak detection using activation features from coverage criteria to classify queries as normal or jailbreak enabling systematic identification of high risk interactions.
second we explore test case prioritization leveraging coverage levels to identify high priority cases and remove redundancies improving testing efficiency.
third we investigate jailbreak case generation where coverage guided methods refine prompts to generate adversarial examples.
our study highlights neuron coverage nc as an effective criterion with attention layers and the last query token showing higher sensitivity to test suites.
these findings form the basis of our application focused studies.
more details are available on our website .
a. jailbreak detection due to the significant differences in the parts of the model covered by normal queries and jailbreak attacks we designtable v comparison of jailbreak detection accuracy across models and methods model methoddatasetavgalpaca gpt4 jailbreakv truthfulqa gcg deepinception masterkey opt 125mour .
.
.
.
.
.
.
perplexity sentence .
.
.
.
.
.
.
perplexity window .
.
.
.
.
.
.
parden sentence .
.
.
.
.
.
.
parden window .
.
.
.
.
.
.
self reminder n a .
n a .
.
.
.
cluster .
.
.
.
.
.
.
llama 7b chatour .
.
.
.
.
.
.
perplexity sentence .
.
.
.
.
.
.
perplexity window .
.
.
.
.
.
.
parden sentence .
.
.
.
.
.
.
parden window .
.
.
.
.
.
.
self reminder n a .
n a .
.
.
.
cluster .
.
.
.
.
.
.
pythia 12bour .
.
.
.
.
.
.
perplexity sentence .
.
.
.
.
.
.
perplexity window .
.
.
.
.
.
.
parden sentence .
.
.
.
.
.
.
parden window .
.
.
.
.
.
.
self reminder n a .
n a .
.
.
.
cluster .
.
.
.
.
.
.
a detection method based on the number of activated neurons the feature used by nc .
specifically we train an mlp model that uses the number of activated neurons as input to derive a binary result indicating whether a query triggers a jailbreak response.
the input dimension is determined by the llm s architecture.
for example opt 125m has blocks represented by a feature vector l0 l1 .
.
.
l where each element is the activated neurons in the attention layer of a block.
the classifier has four hidden layers with and neurons.
we validate its effectiveness on opt125m llama 7b chat and pythia 12b.
dataset we randomly select queries from alpacagpt4 as the training set and as the test set representing normal queries to llms.
for jailbreakv 28k we filter out all queries related to gcg including attack suffixes and select attack queries as the training set and as the test set representing attack queries.
from truthfulqa we select queries as a validation set to evaluate the classifier s generalization ability on normal queries.
additionally we use attack queries generated by gcg attack queries based on deepinception and queries generated by masterkey as separate validation sets to evaluate the classifier s generalization ability on attack queries.
baseline we select the most widely used perplexity filter the state of the art method parden and selfreminder as baselines for comparison.
additionally we design a jailbreak attack detector based on the clustering method used in our empirical study for further comparison.
following the perplexity filter s threshold is set to the maximum perplexity of malicious queries in advbench with a window size of .
parden uses a .
threshold and a window size of .
the clustering method uses the same training set to determine cluster centers and jailbreak detection is performed by comparing the distances to these centers.
evaluation results as shown in table v our method achieves high average accuracies .
on opt 125m .
on llama 7b chat and .
on pythia 12b table vi accuracy of threshold based test case prioritization classification opt 125m llama 7b chat pythia 12b synonymous .
.
.
jailbreakv .
.
.
avg .
.
.
demonstrating its effectiveness across models.
the perplexity based filters exhibit excellent performance on normal queries nearly accuracy but are unstable on attack queries.
they perform well on gcg attacks which increase perplexity through adversarial suffixes e.g.
.
on llama 7b chat but struggle with jailbreak attacks like jailbreakv deepinception and masterkey that rely on templates and instructions.
the performance of parden varies across datasets and models.
it performs well on normal queries for opt 125m and pythia 12b but poorly on attack queries generally below accuracy .
conversely on llama 27b chat it achieves better results on attack queries over accuracy on multiple datasets but underperforms on normal queries.
the effectiveness of the self reminder method depends on model alignment achieving .
on llama 27b chat but only on less aligned models.the clustering method tends to be extreme in its classifications performing well on the test set but poorly generalizing on some validation sets.
it misclassifies validation queries on opt 125m and pythia 12b as normal and those on llama 7b chat as attacks leading to inconsistent performance.
b. test case prioritization test case prioritization represents another critical application.
by leveraging coverage levels test cases likely to reveal model faults high coverage are prioritized while redundant ones low coverage are filtered improving testing efficiency and reducing resource usage.
setup we extend the experiments conducted in rq1 by defining the average coverage increase of individual synonymous queries redundant test cases relative to snas a threshold.
test cases with coverage increases below this01 5101520253035number of successful jailbreak queriesi teration round coverage guided randomfig.
comparison of successful jailbreak queries generated by coverage guided and random methods over iterations.
threshold are considered redundant whereas those exceeding the threshold are identified as prioritized test cases.
to evaluate the effectiveness of this method we conduct experiments using synonymous queries redundant test cases and attack queries prioritized test cases extracted from jailbreakv .
evaluation results table vi shows the classification accuracies of this method on three llms.
for redundant test cases synonymous queries the method achieves high accuracies of .
on opt 125m .
on llama 7b chat and .
on pythia 12b effectively filtering them out.
for prioritized test cases attack queries it attains accuracies of .
.
and .
respectively demonstrating strong capability in identifying test cases likely to uncover model faults.
the overall average accuracies .
for opt 125m .
for llama 7b chat and .
for pythia 12b validate the effectiveness of coverage criteria in prioritizing test cases enabling efficient vulnerability detection while reducing redundancy.
c. jailbreak case generation by utilizing coverage to guide the creation of attack examples jailbreak case generation method identifies areas of the model that remain unexplored.
iterative refinement of prompts based on coverage gains ensures that the generated cases are effective in exposing vulnerabilities while promoting diversity among test cases.
here we conduct a preliminary exploration to showcase the potential of coverage guided jailbreak case generation.
setup we use llama 7b chat as the target model initializing with five jailbreak queries as seeds.
over five iterations gpt generates ten new jailbreak queries per round through prompt rewriting.
the query with the highest coverage increase is selected as the next seed in the coverage guided approach.
for comparison a random strategy selects seeds randomly from rewritten candidates.
each method ultimately generates new jailbreak queries to evaluate effectiveness.
evaluation results as shown in figure the coverageguided method outperforms the random strategy in generating successful jailbreak queries.
in round our approach generates successful queries compared to by the random method.
this gap widens in subsequent rounds with our method producing and successful queries in rounds to respectively while the random strategy yields and .
these results confirm that coverage gains effectively guide query generation toward unexplored areas increasing the number of successful jailbreak cases and enhancing robustness testing for llms.
vi.
t hreats to validity external threats external validity threats arise from the specific settings chosen in our study which may raise concerns about the generalizability of our proposed method.
to mitigate these threats we select a variety of evaluation settings.
specifically we use four large language models with different architectures and parameters opt 125m llama 7b chat pythia 12b and gemma 27b it.
additionally we employ four datasets alpaca gpt4 jailbreakv 28k truthfulqa and advbench that cover a wide range of test scenarios.
our study is based on five widely used coverage criteria nc tknc tknp tfc and nlc.
the choices aim to enhance the generalizability of our findings in this field.
internal threats internal validity threats stem from the tools used in our study including llm attacks gcg deepinception masterkey and self reminder.
moreover accurately reproducing the coverage criteria and the perplexity filter and parden for input detection also presents potential threats.
inherent randomness in model training further poses a potential threat to internal validity.
we address this by repeating key experiments more than three times to report the average results.
vii.
conclusion in this study we conduct an extensive empirical investigation into the effectiveness of traditional coverage criteria in llms across three key dimensions criterion level layer level and token level.
our findings reveal significant differences in neuron coverage between normal and malicious queries highlighting the potential of these criteria in identifying abnormalities in llms.
building upon these insights we explore three downstream applications based on coverage criteria real time jailbreak detection test case prioritization and jailbreak case generation all of which achieve outstanding performance.
our findings enhance the understanding of security testing in llms highlight the potential of coverage criteria in addressing broader security and functional challenges and lay a methodological foundation for developing robust ai applications using neural activation features.