faster configuration performance bug testing with neural dual level prioritization youpeng ma1 tao chen2 ke li3 1school of computer science and engineering university of electronic science and technology of china china 2ideas lab school of computer science university of birmingham united kingdom 3department of computer science university of exeter united kingdom myp std.uestc.edu.cn t.chen bham.ac.uk k.li exeter.ac.uk abstract as software systems become more complex and configurable more performance problems tend to arise from the configuration designs.
this has caused some configuration options to unexpectedly degrade performance which deviates from their original expectations designed by the developers.
such discrepancies namely configuration performance bugs cpbugs are devastating and can be deeply hidden in the source code.
yet efficiently testing cpbugs is difficult not only due to the test oracle is hard to set but also because the configuration measurement is expensive and there are simply too many possible configurations to test.
as such existing testing tools suffer from lengthy runtime or have been ineffective in detecting cpbugs when the budget is limited compounded by inaccurate test oracle.
in this paper we seek to achieve significantly faster cpbug testing by neurally prioritizing the testing at both the configuration option and value range levels with automated oracle estimation.
our proposed tool dubbed ndp is a general framework that works with different heuristic generators.
the idea is to leverage two neural language models one to estimate the cpbug types that serve as the oracle while more vitally the other to infer the probabilities of an option being cpbug related based on which the options and the value ranges to be searched can be prioritized.
experiments on several widely used systems of different versions reveal that ndp can in general better predict cpbug type in cases and find more cpbugs with up to .
testing efficiency speedup over the state of the art tools.
index terms performance bug testing software debugging testing prioritization configuration testing sbse.
i. i ntroduction modern software systems typically have a high degree of configurability wherein the configuration options directly e.g.
certain optimization or indirectly e.g.
resource allocation affect software performance such as throughput and latency .
as software configurability continues to improve they are also more likely to be buggy.
we refer to these performance bugs caused by configuration errors as configuration performance bugs cpbugs .
it is worth noting that cpbugs differ from the typical misconfigurations that concern user induced configuration errors instead they are the errors of the configuration design in the source code that are unintentionally introduced by the developers of the systems .
a typical example of cpbugs has been illustrated in table i. here we can see that the option read buffer size in m ysql is tao chen is the corresponding author.
youpeng ma is also supervised in the ideas lab.table i a real world example of cpbugs for m ysql.
id mysql cpbug related option read buffer size expected performance each thread that does a sequential scan for a myisam table allocates a buffer of this size in bytes for each table it scans.
if you do many sequential scans you might want to increase this value which defaults to ....... actual performance the performance decreases if the option read buffer size is set to be larger than 256k...... mainly used to change the size of the read buffer allocated for each sequential table scan request.
in the developers expectation increasing this option value should allow m ysql to cache more results hence a larger buffer should improve performance.
however the performance actually drops when increasing the value beyond 256k.
this is because in the code logic myisam initializes an io cache for writing and usesread buffer size for bulk inserts.
my malloc is called with the my zerofill flag which causes memset to be called on the size of read buffer size hence mistakenly restricting the permitted memory quote for processing sql commands and resulting in a large performance decrease.
cpbugs can lead to devastating outcomes .
for example there have been several large scale flight delays which were mainly caused by problematic configuration designs of the systems .
systems from google and meta have also suffered performance degradation or outage due to configuration issues leading to a huge loss of revenue.
however testing and finding cpbugs are challenging due primarily to the fact that there are simply too many configurations to examine m ysql has hundreds of options with more than millions of configurations measuring configuration performance is highly expensive e.g.
it can take up to minutes to merely measure one configuration on maria db and the test oracle is often unclear i.e.
we do not know when a cpbug occurs.
while some tools exist for testing cpbugs they are limited in the efficiency of testing and the accuracy of oracle estimation.
that is they have not effectively handled the discriminative importance of the options and their value range with respect to the cpbugs together with restricted rule driven oracle inference.
therefore those tools suffer from issues such as long running times or are ineffective in detecting cpbugsarxiv .15392v3 apr 2025table ii categorization of cpbugs types from he et al.
.
anti performance implies better performance at the cost of lower security consistency integrity and etc pro performance means otherwise.
their value change can be in any direction.
cpbug type option purpose source option value target option value expected performance actual performance type optimization on off off on rise drop type non functional trade off ant performance pro performance rise drop type non functional trade off pro performance anti performance drop drop beyond expectation type resource allocation small large rise drop type functionality trade off on off rise drop type functionality trade off off on drop drop beyond expectation type non influential option any any keep drop when the testing budget is limited while can be largely mislead by incorrect oracle.
in this paper we propose to test cpbugs with what we call neural dual level prioritization dubbed ndp a framework that can be paired with different heuristic generators.
ndp leverages neural language models for estimating test oracle and more importantly for prioritizing cpbug testing which is motivated by our observations that only a small proportion of the options are responsible for cpbugs and there are specific ranges of the numeric options values that are more cpbugs prone.
as such by leveraging on the probabilities of being cpbug related to the options we prioritize the test at two levels at the options level and at the level of search depth for numeric options aiming to significantly accelerate the detection of cpbugs.
specifically our contributions are instead of leveraging on rule mining we build a neural language model i.e.
roberta that predicts the cpbug type which serves as the oracle in testing.
we fine tune the other roberta model for estimating the probabilities of an option being cpbug related which prioritizes the options to be tested.
for testing numeric options we design three search depths that bound an underlying heuristic generator with different search spaces.
during the actual testing those depths and hence their corresponding search spaces are prioritized according to the commonality of the cpbugrelatedness and code semantic of an option.
we evaluate ndp over several widely used systems with various versions workloads containing known cpbugs and against state of the art testing tools.
the results show that compared with state of the art tools approaches ndp more accurately predicts the oracle of cpbug type in types metrics tests cpbugs with up to .
speedup by prioritizing the tested options while finding more cpbugs with from .
to .
speedup through prioritizing the search depths of numeric options.
all data and source code are publicly accessible via our repository .
this paper is organized as section ii presents the preliminaries.
section iii delineates the known and newly discovered characteristics of cpbugs which derive our designs.
section iv illustrates ndp.
section v presents the experiment setup followed by the results in section vi.
sections vii viii and ix present the discussion threats to validity and related work respectively.
section x concludes the paper.ii.
p reliminaries a. cpbugs in configurable systems in general cpbugs naturally incur from the mismatch between the expected performance as specified in the documentation and the actual performance observed by changing a configuration option.
therefore measuring the performance deviation between the source and target option value serves as a strong oracle for identifying the cpbugs.
in particular the performance deviations that cause the cpbugs can be mainly observed from a common scenario the direction of expected and actual performance changes is different e.g.
the expectation is performance raises but the actual effect is a performance drop1under at least one workload implying defects in the code segments of the configuration option.
b. cpbugs types we follow the categorization of the cpbug types proposed by he et al.
as articulated in table ii and below optimization switch when enabled an optimization strategy is activated and the performance is expected to improve.
yet a performance drop implies a likely cpbug.
non functional trade off configuration options are used to balance the performance and other non functional needs such as the acid properties.
whether the option needs to be increased or decreased is case dependent.
this involves two subtypes see type in table ii .
in this work we do not distinguish these two as the threshold for the drop beyond expectation is highly subjective.
instead for an option under this type there is a cpbug as long as a performance drop is observed2.
resource allocation options influence resource allocation more resources are expected to boost performance.
functional switch options control non performance functionalities but indirectly affect the system s performance.
when an option disables a function system performance usually improves.
this also involves two situations see type in table ii .
we do not distinguish those two cases due to the same aforementioned reason.
1we follow the de facto standard that a drop is significant only when the change is greater than on any concerned performance attribute .
2distinguishing the subtypes does not affect the testing designs of the approach.
this is because if an option is classified into either subtype then what we seek to find during testing is mainly whether there is an actual performance drop for the two subtypes regardless of the expected performance.
as such a cpbug can be found as long as we see a performance drop between configurations with the changes in the option s value.
non influential option these options should not affect the system s performance i.e.
performance is expected to remain unchanged after adjusting the values.
each pattern in the above cpbug types determines the oracle of identifying whether there is a cpbug.
for example with type we can interpret it as if a resource allocation related option is changed from a small value to a larger value then we expect the performance to be improved or otherwise there is a cpbug .
therefore it is essential to estimate which cpbug type is the most relevant to a tested option.
c. testing cpbugs in essence cpbug testing aims to generate diverse test cases represented as a pair of configurations a source csand a target ct which differ only on the configuration option to be tested i.e.
oat index highlighted in red cs ct an automated cpbug testing tool would perturb the values of the option o such that the performance deviation from the source configuration to the target one under at least one workload matches with a cpbug type from table ii which serves as the oracle.
for example if changing from cstoct from a smaller value of a resource option to a larger value under a workload causes a performance drop while in the documentation it should have been a rise then we find a cpbug of type .
yet due to the large number of options and their values testing cpbugs is extremely expensive.
iii.
c haracteristics of cpb ugs cpbugs naturally come with certain characteristics that can help us design more effective testing.
from the systems versions options tested in this work which are taken from a prior study and it is worth noting that the number of total options per system we tested has already exceeded what is considered for them.
we have discovered in table iii3that characteristic overall only .
of the configuration options can trigger cpbugs.
this means that although cpbugs can be devastating testing on all unique options to find them is not cost effective.
the numeric configuration options4also have known characteristics.
for example he et al.
have shown that characteristic the majority of the numeric configuration options studied can trigger cpbugs when they are changed to near one extreme of their values.
from table iv we have identified a similar pattern from the systems tested when fixing the source of an option as close to either its maximal or minimal values all the numerical options can trigger cpbugs when the option in the target is 3due to the scale of systems and limited resources for each system we conducted a preliminary study to identify the most recent designed discussed options for actual testing instead of examining all options.
4note that the numeric options are often discretized by a set of values e.g.
cache size can be 8m 16m 32m etc.table iii percentage of unique options that cause cpbugs.
system all options unique cpbugs related unique mysql .
maria db .
apache .
gcc .
clang .
total .
table iv ranges in the numeric options in the target that cause cpbugs when fixing the source of an option as close to either its maximal or minimal values.
cpbug range cpbug range mysql .
mysql .
mysql mysql .
mysql mysql mysql .
mysql mysql mysql .82e mariadb .
mariadb .
mariadb .
mariadb mariadb .
apache .
apache apache .
table v number of cpbugs triggered under extreme and middle value of numeric options based on their categorization.
category of numeric option trigger at extreme trigger at middle buffer memory network thread loop different values of an option on the same version might trigger the same cpbug.
changed to of the values at the opposed extreme.
further to the above we have additionally found that characteristic .
out of of the numeric configuration options can trigger cpbugs when they are changed to their middle values.
table iv shows that a considerable proportion of the numeric options can trigger cpbugs when their values are changed to be within the middle and the opposed extreme.
the above is because while most values of numeric options impact the data flow they usually do not change the control flow.
that is changes in the numeric configuration options need to hit certain critical values that trigger new execution paths hence more likely to reveal cpbugs.
to further understand the cpbugs related numeric options we manually analyze their source code.
inspired from a recent work we classify those options based on the main type of performance sensitive operations that they can control i.e.
operations related to buffer memory network thread or loops exclude the other types .
from table v we found that characteristic numeric options can trigger cpbugs at extreme and middle values most commonly when they control operations related to buffer.
this is because the buffer operations often cause immediate implication to many parts in the system hence the corresponding numeric options are highly performance sensitive.while characteristic have been known characteristic 4are newly discovered information for cpbugs in this work.
iv.
d ually prioritized cpb ugtesting with neural language model ndp seeks to expedite the cpbug testing via dualprioritization at two levels the option level that determines which option to test earlier and the search space level of the numeric options which sets the order of search space to explore.
this is supported by two fine tuned neural language models one for estimating the probability of an option being cpbug related and the other for predicting the most relevant cpbug type that determines the test oracle.
similar to the other tools ndp tests the system s configuration option one by one in which all the combinations of workloads and related versions are also examined in turn.
specifically we design the two phases in ndp as shown in figure .
for initialization ndp focuses on a one off process that fine tunes two neural language models using existing data from different systems cpbug types prediction here the goal is for a neural language model to parse the documentation and predict which cpbug type is most relevant to an option.
this then serves as the essential oracle for cpbug testing.
option cpbugs relevance estimation we fine tune another neural language model that takes both the description of options from the documentation and the related code snippet as inputs and estimates the probabilities of those options being cpbug related.
this allows us to handle the identified characteristics of cpbugs.
in the testing phase ndp contains four components options prioritization high level the probabilities of whether the options are cpbug related are used to prioritize their testing order due to characteristic .
exhaustive generator this is mainly for non numeric options in which all the possible pairs will be covered under all workloads and related versions considered.
search prioritization low level for numeric options the actual testing would also need to be conducted via a certain search depth.
in ndp we design three search depths which are prioritized differently depending on the commonality of the probabilities for being cpbugrelated.
each of the search depths would trigger an independent run of the heuristic generator which can be any search algorithm to generate the test cases.
this fits with characteristic andcharacteristic .
according to taint analysis of code semantic buffer related numeric options are specifically handled given characteristic .
heuristic generator a stochastic search algorithm that samples the values of numeric options in cpbug testing under all workloads and related versions.
for each option under a version if its value alteration and the performance change on any concerned performance attribute in both configurations of a pair match with the pattern in the predicted cpbug type which serves as the oracle under at least one workload then we found a cpbug option cpbugs relevance estimationcpbug types prediction options prioritizationsearch prioritizationnumeric option?exhaustive generator taint tracking extrememidmostcomprehesiveconfigurationdocumentationconfiguration codeall optionsall workloads and related system versions for the current optioncpbugs initilizationtesting logical flowdata flow yesno heuristic generator fig.
workflow overview of ndp for cpbug testing.
table vi an exampled option s description from m ysql.
option innodb flush log at trx commit documentation partial theinnodb flush log at trx commit controls the balance between strict acid compliance for commit operations and higher performance that is possible when commit related i o operations are rearranged and done in batches.
you can achieve better performance by changing the default value...... otherwise we stop testing the option for a version when all pairs workloads have been explored or a budget has been exhausted.
in all cases ndp then switches to test the option under the next related version if any.
that is we only need to find the cpbugs caused by the option on at least one workload under a version but all the related versions would be examined regardless of how many cpbugs are found on the said option.
when all related versions have been tested for an option we move to the next option as prioritized by ndp.
a. neural cpbug types inference an essential task in cpbug testing is to determine the oracle i.e.
identifying what types of cpbugs an option is most likely to be associated with hence triggering the corresponding way to verify whether such an option can trigger cpbugs.
to that end we leverage a single modal roberta denoted ms a particular type of neural language model to predict the cpbug type of a given option to be tested.
in ndp we fine tune the roberta using the data collected from previous work such that the inputs are the natural description of an option from the documentation with a known label from the five cpbug type or a label of no cpbug since cpbugs are mainly related to the deviation from the expected performance of an option specified in the documentation e.g.
table vi .
notably the fine tuning process is naturally cross project since the naturalness of the documents ensures its generalization.
in particular roberta is chosen for three reasons compared with the rule mining approach it exhibits a stronger generalization ability that can learn hidden information in the documentation in the latent space.
in section vi a we will experimentally verify this.
in contrast to llm roberta fits our problem better we need a classification of cpbugs type rather than text generation.
further roberta is more cost effective .
it has been reported that roberta is the generally most promising bert variant for software engineering .table vii an example of an option s texts from the documentation and the mapped code snippet from m ysql.
option innodb buffer pool size documentation partial theinnodb buffer pool size system variable specifies the size of the buffer pool.
if your buffer pool is small and you have sufficient memory making the pool larger can improve performance by reducing the disk i o as queries access innodb tables...... code snippet mapped partial i f s r v d e d i c a t e d s e r v e r s y s v a r s o u r c e s v c !
n u l l p t r s t a t i c c o n s t c h a r v a r i a b l e n a m e i n n o d b b u f f e r p o o l s i z e enum e n u m v a r i a b l e s o u r c e s o u r c e i f !
s y s v a r s o u r c e s v c g e t v a r i a b l e n a m e s t a t i c c a s t u n s i g n e d i n t s t r l e n v a r i a b l e n a m e s o u r c e i f s o u r c e compiled d o u b l e server mem get sys mem b. neural multi modal option cpbugs relevance estimation from characteristic we note that only a small number of options can potentially be the cause of cpbugs.
as a result a natural idea is to estimate which options are more related to cpbugs.
ndp leverage both documentation and the corresponding code of an option see table vii together with the corresponding label of whether the option is cpbug related to fine tune another multi modal roberta model mm in a binary classification problem.
our goal here however is not to use the model to make a binary prediction but to extract its probability related to the likelihood of an option being cpbug related based on which we can rank those options.
as such forming this binary classification to train yet another new roberta model has the benefit of simplicity without producing much noise to fulfill our goal.
to that end we locate the code for a corresponding option in the documentation using a pattern matching based heuristic direct way some systems have a centralized file or a few files to maintain all configuration options such as mysql.
in those cases we look at the variable with a similar name to those in the documentation and identify the relevant code snippets from the centralized file s .
indirect way other systems might not have a file s that share the same name as those in the documentation.
we consider two cases there are mechanisms that allow access to those configuration variables via setter andgetter .
in those cases we can write a script that searches through the relevant files and outputs the similarity of the setter andgetter to each option in the documentation.
we can then manually identify the corresponding code snippets.
there are nosetter getter in which case we scan all variables and related functions in the related files.
once the code snippets and the texts of an option are mapped our heuristic uses the rules below to clean the code remove useless comments e.g.
those with timestep certain license information etc.
remove duplicated comments or code snippets.
remove usage examples of the options in the comments.
e.g.
formats or order of changes.
remove code snippets of incomplete functions extracted.
inndp the texts from documentation and the code snippets of an option are concatenated together e.g.
table vii and we use standard steps such as text cleaning tokenization and serialization to parse the data.
those inputs together with a label of whether the option is cpbug related form the data to fine tune the roberta model.
to make roberta work for our simplify binary classification problem we add a taskspecific classification layer with a cross entropy loss function in the fine tuning process.
upon predicting a given option the probability of being a true label cpbug related extracted from the softmax layer is what we are interested in.
again we use the cpbugs data that has been reported previously .
c. all options prioritization high level inndp at the high level we firstly leverage the probabilities of all the options produced by mmto determine their order in cpbug testing.
this is important as if an option is more likely to cause the cpbugs then prioritizing it beforehand would help us to identify the bugs quicker.
here although we do not distinguish the type of options in this prioritization e.g.
numeric and non numeric ones their actual testing strategies can be different for non numeric options we generate and test all the combinatorial values of the configurations in the pair using an exhaustive generator since often those possible values are of limited range .
notably all workloads and related versions are considered we at first pick a version and test all workloads therein in turn if a cpbug is found for a nonnumeric option under a workload then the remaining untested workloads would be skipped and we switch to the next related version.
finally ndp moves to the next option when all related versions have been tested for the current option.
in contrast for numeric values we need a stronger way to prioritize their sampling which we will describe as follows.
d. search prioritization for numeric options low level when the option to be tested is a numeric option we propose three different search depths that bound the search spaces of the underlying heuristic generator extreme search as in figure 2a this is the search with the most restricted search space the search for test cases happens within of the upper lower bounds range of values5for both configurations in the pair.
yet we ensure that the two configurations in the pair are searched over the opposed bounds characteristic .
midmost search here in figure 2b one configuration in the pair is searched within of the upper or lower bound range values while the other can be changed within the middle of the values characteristic .
5for those options without explicitly defined upper lower bounds we set them using our understanding of the domain e.g.
the capacity of our hardware or the extreme values that are commonly set in practice.permitted rangenon permitted range?numeric option to be tested ?
...... ?
...... a extreme ?
...... ?
...... b midmost ?
...... ?
...... c comprehensive fig.
illustrations of the search space bounded by different search depths for cpbug testing with ndp.
options probabilities of cpbugs relateddensity functionlow densitymedium densityhigh density fig.
exampled kernel density function on the numeric options probabilities of being cpbug related for a system.
comprehensive search this is the search that basically means all possible values of the configurations in the pair can be explored figure 2c .
those search depths differ in terms of the number of tests for the pairs required.
according to the probabilities produced from mmfor the numeric options we can then prioritize how the above three search depths are used on them.
in ndp the idea is to divide the probabilities of all numeric options into three divisions based on which different prioritization of the search depth is used.
to systematically perform such a division we leverage the gaussian kernel density estimation gkde .
in essence gkde serves as a one dimensional binning algorithm that divides the probability density of options being cpbug related into three bins with no thresholds.
this is achieved by dividing the options into the top three peaks6 which are separated by a local trough based on their closeness of probabilities to those peaks.
figure shows an example we see that the numeric options are divided into three divisions according to their commonality on the probabilities of being cpbug related.
these divisions derive three prioritizations of the search depths high density for the numeric options belonging to the most frequent bin we prioritize the more restricted search depth starting from extreme search midmost search and finally comprehensive search.
this will speedup testing if cpbugs can be detected within an extreme middle value.
6given the complexity of configurable systems we have not seen a case with less than three peaks.
medium density here we prioritize the midmost search first followed by the extreme search and then the comprehensive search.
the reason is that since the numeric options are of medium density we start from the midmost search that also assumes a medium size of search space.
low density for the least frequent bin of numeric options we adopt the comprehensive search only.
according to characteristic numeric options that control buffers are most likely to cause cpbugs at their extreme or middle values.
hence in ndp we adopt taint tracking7using the option as the source while the buffer related operations as the sink e.g.
release sysvar source service for m ysql hence analyzing the code semantic to identify whether an option controls buffer.
these sinks which are system dependent are domain knowledge specified by software engineers.
for all buffer related numeric options we force their search to follow the depth order of high density.
for a given numeric option ndp follows the steps below pick a related version of the system under test.
if the numeric option controls buffer then make it uses the order of search depths for high density otherwise following the order of the assigned density level.
test the option with the order of search depths via the heuristic generator for all workloads see section iv e .
if a cpbug is found then jump to otherwise return to and move to the next search depth.
repeat from for the next related version if any otherwise move to the next option.
e. heuristic generator ndp can be paired with any heuristic algorithms for generating test cases for the numeric options.
in this work we use the population based genetic algorithm ga but it can be easily replaced by other algorithms.
since ndp tests one numeric option under a version each time the solution representation is a pair of values for the tested option.
to determine which pairs to preserve we use the fitness function below to compare the pairs fitness max i ...m f c1 wi f c2 wi whereby c1and c2are the configurations in a pair with different values on the numeric option to be tested widenoted theith workloads out of a total of mones.
since based on the cpbug types either configurations in the pair can be the source and the options would trigger cpbugs if the performance drops this fitness reflects the maximum performance deviation between the two paired configurations with different values of the tested numeric option across different workloads the larger the deviation the higher possibility of triggering more cpbugs which should be preserved in testing.
under each of the above search depths the search space of ga is bounded correspondingly.
whether a configuration in the pair starts from the upper or lower sides for extreme 7the tracking built on libastmatchers for c c is highly efficient it takes a few seconds to around one minute for a system studied.search or whether it is searched on the middle range for midmost search is decided randomly.
when ga consumes all of its budget or all pairs within the bound have been explored ndp terminates the ga and checks whether a cpbug has been found according to the estimated cpbug type.
f .
handling dependency when changing the tested options their dependencies need to be complied .
for example in m ysql there is a dependency that option innodb buffer pool size the buffer pool size must be set as an integer product of that of the option innodb buffer pool chunk size the granularity of buffer pool resizing while being greater.
ndp leverages gptuner a large language modelbased tool that predicts configuration dependency based on the documentation.
if when a value of the tested option violates any dependency we then randomly change the other affected option correspondingly.
for example if we change the value ofinnodb buffer pool chunk size to 128mb then we should also set the innodb buffer pool size to a value that is an integer product of 128mb e.g.
128mb 256mb or 384mb.
note that in that case if either of the two options triggers cpbug then both are cpbug related with the same cpbug type.
we chose gptuner for two reasons it is highly flexibility and can be conveniently used without any fine tuning.
thanks to the gpt3.
it is generalizable to different systems.
this is the key advantage compared with other rule based tools such as cdep .
v. e xperiments setup a. research questions in this work we answer the following research questions rq1 how well can ndp estimate the cpbug types?
rq2 how effective dose ndp in options prioritization against the state of the art tools?
rq3 how well dose the prioritized search in ndp perform over the state of the art tools?
rq4 canndp discover unknown cpbugs?
b. systems versions workloads and known cpbugs in this work we use the datasets of systems provided by he et al.
for assessing the cpbug type prediction.
for the actual testing we conduct experiments on five widely used configurable systems therein with known cpbugs as shown in table viii.
the reason is that we have not been able to reproduce the cpbugs for all systems used by he et al.
because e.g.
the related versions are discarded or the cpbugs have not been documented clearly.
yet the five systems used for testing are still of diverse domains and scales including database systems i.e.
m ysql and m aria db web servers i.e.
a pache and compilers i.e.
g ccand c lang .
to reproduce the cpbugs in testing we test the options of each system under various versions.
note that not all the options would go through the same versions since some do not exist in certain versions hence ndp maintains a mappingtable viii configurable software with reproduced cpbugs.
software version w cpbugs type type type type type n n mysql .
.
maria db .
.
apache .
.
gcc .
.
clang .
.
an option might trigger multiple cpbugs e.g.
different values across different versions two options might also lead to a cpbug due to dependency.
nandncount the number of nonnumeric and numeric cpbug related options respectively.
wcounts the number of workloads.
between the options and related versions.
we selected the related versions that can run successfully including those that can produce the cpbugs in the ground truth and used previously as well as other stable versions that have not been discarded.
in practice we believe that software engineers would come with some domain knowledge about which versions are more likely to have cpbugs or use all deployable versions that are of interest.
therefore the selection of versions is case dependent.
ndp does not make assumptions on the nature and number of versions to be tested.
each system is tested under different workloads generated by standard benchmarks.
for m ysql and m aria db we use s ysbench a powerful multi threaded benchmark that is frequently employed to generate workloads that are of various data scales number of concurrent threads and test duration.
for a pache we use a pachebench to create workloads of different types.
for g ccand c lang we use standard programs with different types and scales.
all above are important for revealing the cpbugs and have been used in prior work .
the workloads combined with the versions led to a high number of cases in the cpbug testing.
derived from prior work table viii shows that all systems versions studied contain various known cpbugs which are sufficiently complex to challenge cpbug testing tools.
c. compared approaches our experiments make comparisons with respect to the following state of the art cpbug testing prediction approaches cp detector cpd a state of the art tool that uses rule mining and keyword search to estimate the cpbug types.
during the actual testing it follows the greedy method with a random order of the tested options fixing each tested option of a configuration in the pair at its minimal value and exponentially increasing the value of the same option for the other configuration.
keyword searching ks a baseline that predicts cpbugs type by keyword matching in the documentation.
uniform sampling us a tool that samples uniformly on the values of the option in a pair with randomly sorted options to be tested.
we set the same budget for each option as the ga in ndp i.e.
tests and the same way as ndp for cpbug type prediction.
like ndp when testing an option under a version cpd andusalso consider all workloads stop whenever a cpbug is found or cover all pairs exhaust the budget then move to the next related version option.
we have omitted some other tools e.g.
toddler as they have been shown to besignificantly inferior to cpd .
for rq1 we use cpd and ks while both cpd andusare used for the remaining rqs.
note that indeed various sampling methods exist for testing other configuration issues however cpbug testing differs from those as it considers different versions and workloads making it too expensive to be tested by current sampling approaches which more or less favor diversity .
d. testing budgets and other settings inndp when testing numeric options we set a budget of tests for the heuristic generator ga in this work .
this means that under a search depth if the heuristic generator has consumed tests i.e.
testing a pair under a workload for a system version would consume one test then ndp would stop testing for the corresponding option.
this is the same budget for usbut not for cpd since it leverages a greedy search method.
in contrast the testing of non numeric options is always exhaustive.
all other settings of the compared approaches are left as default specified in their work.
for setting the ga we use a mutation and crossover rate of .
and .
respectively together with a soft population size capped at i.e.
the number of pairs to explore might be less than on the more restricted search depth .
the crossover operator is a uniform crossover i.e.
one of the tested option s values in a pair might be swapped with that of the other the mutation is a random mutation that randomly changes the tested option s value to a different permissible value.
all above are standard settings from prior studies .
as for gkde we set all parameters as their default values.
for training the two neural language models in ndp we use all the cpbugs data including cpbug types that have been previously reported from different systems except the system and its versions under test unless otherwise stated.
this is the same setup for the rule mining process in cpd .
vi.
e xperimental evaluation a. rq1 cpbugs type estimation method to examine oracle prediction via rq1 we compare ndp withcpd andksunder the same samples from systems used by he et al.
with no sampling method change following the same training fine tuning testing splits for fold cross validation.
he et al.
state that those are randomly sampled from the systems but they have ensured data quality and representative nature.
the mean recall precision and f1 scores for each of the five cpbug types are reported i.e.
a total of types metrics.
results from table ix we clearly see that the neural language model in ndp achieves considerably better results than the others particularly on the f1 score leading to superior results on out of types metrics.
in particular the ksis clearly insufficient due to the limitation of a human defined keywords sets cpd is also restricted by the rule mining capability due to the naturalness the vast ways of describing the potential cpbugs in the documentation cannot be fully captured by the rules identified.
indeed cpd marginally0 tested options cpbugs foundcpd ndp us a m ysql0 tested options cpbugs foundcpd ndp us b m aria db0 tested options cpbugs foundcpd ndp us c a pache tested options cpbugs foundcpd ndp us d g cc0 tested options cpbugs foundcpd ndp us e c lang fig.
effectiveness of testing cpbugs over all options.
performs better than ndp on the precision of type and type4.
however this is mainly due to the fact that cpd tends not to include the samples in those two types as naturally their descriptions can be more complex.
this has led to better precision better false positive but serenely comprised recall worse false negative which together have worsened the f1 score in general.
ndp in contrast can handle complex cases with good performance over both false positives negatives thanks to the reasoning ability in the latent space provided by the neural language model roberta.
overall we say ndp better predicts cpbugs type than the state of the art approaches over types metrics.
b. rq2 tested option prioritization method to verify high level option prioritization in rq2 we use five systems and their versions for which we have successfully reproduced the cpbugs.
we compare ndp against cpd andus which test the options in random order.
the mean deviation of the cumulative number of cpbugs found with respect to the number of options tested for each system over runs are reported.
we also calculate the speedup of ndp viao o where ois the number of options tested to find the most cpbugs by the other tool and o is the number of tested options tested for ndp to achieve the same.
results as can be seen in figure ndp can reveal more cpbugs for m ysql and a pache due to the prioritization in testing numeric options if we compare the last point which we will evaluate in rq3 .
more importantly it runs cpbug testing with much better efficiency we see that for all systems ndp exhibits much stepper slops meaning that many more cpbugs are discovered in an earlier stage of the testing a significant contribution made by the prioritization at the tested options level.
in particular ndp achieves speedup range from .
to .
against both cpd andus.
notably testing a single option can be rather expensive i.e.
hours on average some can be days since we need to go through many versions workloads hence there will be significant savings if we can find the same or more cpbugstable ix effectiveness of estimating cpbugs types.
red cells denote the best performing approach.
cpbug type option purpose sample optionsprecision recall f1 score ndp cpd ks ndp cpd ks ndp cpd ks type optimization .
.
.
.
.
.
.
.
.
type tradeoff .
.
.
.
.
.
.
.
.
type resource .
.
.
.
.
.
.
.
.
type functionality .
.
.
.
.
.
.
.
.
type non influence .
.
.
.
.
.
.
.
.
table x the least average tested options clock time required to find per cpbug red cells denote the best.
system tested options time min ndp cpd us ndp cpd us mysql .
.
.
.
.
.
maria db .
.
.
.
.
.
apache .
.
.
.
.
.
gcc .
.
.
.
.
.
clang .
.
.
.
.
.
by testing even slightly fewer options.
it can be seen from the table x which shows the least tested options clock time required to find per cpbug that ndp only needs to test .
options .
minutes against the .
.
tested options .
.
minutes for the state of the art tools.
the reduced improvement of ndp for g ccis due to its larger cpbugs ratio out of options can trigger cpbugs.
indeed since ndp speedups testing by prioritizing the options clearly a high ratio of cpbugs can blur the benefits.
all those results suggest that ndp produces significantly better efficiency than state ofthe art tools by prioritizing the order of tested options on all systems achieving up to .
speedup.
c. rq3 search prioritization for numeric options method inrq3 we examine the search prioritization when testing numeric options on the systems versions from rq2 only m ysql m aria db and a pache contain numeric options against others.
since the number of tests testing a pair of configurations is one test is crucial for testing numeric options for all systems we report on the mean deviation of the cumulative number of cpbugs found along with the number of tests for numeric options across runs.
all tools follow the same order of testing the numeric options prioritized by ndp among all the numeric options of each system ndp remarkably prioritizes the cpbug related ones before the others.
we measure the cumulative cpbugs found for every tests rounded when the number of tests required is greater than otherwise we report every test.
we calculate the speedup of ndp via the same way as for rq2 .
results figure shows the traces of testing numeric options.
clearly we see that ndp exhibits remarkably better results compared with the others it discovers the same m aria db or more numeric options related cpbugs mysql and a pache than cpd andus e.g.
for ndp while the other two can only find cpbugs on m ysql.
ndp tests cpbugs found a ndp mysql0204060800510 cpd tests cpbugs found b cpd mysql02004006000510 us tests cpbugs found c us mysql 4024ndp tests cpbugs found d ndp maria db0 20024cpd tests cpbugs found e cpd maria db0 100024us tests cpbugs found f us maria db 012340123ndp tests cpbugs found g ndp apache051015200123cpd tests cpbugs found h cpd apache0204060801000123us tests cpbugs found i us apache fig.
testing cpbugs over numeric options.
in particular ndp achieves such with significantly less number of tests for all three systems ndp does so with as few as tests while cpd andusneed tests and tests to reach their maximum number of cpbugs respectively.
notably to find the same maximum number of cpbugs as achieved by others ndp has .
to .
and .
to .
speedup over cpd andus respectively.
since a single test run is highly expensive the saving is thereby significant.
table xi shows the least number of tests clock time required to find per cpbug ndp only needs test runs as small as .
.
minutes against the .
.
test runs .
.
minutes for the state of the art tools.
all above demonstrate the effectiveness of the search level prioritization for numeric options in ndp.
thus we conclude for all systems ndp finds considerably more numeric options related cpbugs than the state of the art tools with .
to .
speedup by prioritizing the search.
d. rq4 detecting new cpbugs method to verify whether ndp can reveal unknown cpbugs we apply ndp to further extended sets of versionstable xi the least average test counts clock time required to find per cpbug on numeric options red cells are the best.
system test counts time min ndp cpd us ndp cpd us mysql .
.
.
.
.
.
maria db .
.
.
.
.
.
apache .
.
.
.
.
.
table xii new cpbugs discovered by ndp.
cpbug system version performance degradation cpbug type pending link g cc v12 .
execution time type pending link g cc v9 .
execution time type pending link g cc v12 .
execution time type pending link g cc v12 .
compiling time type pending link g cc v12 .
execution time type pending link g cc v9 .
compiling time type pending link g cc v12 .
compiling time type pending link g cc v9 v12 .
.
execution time type pending link g cc v9 v12 .
file size type c lang v14 .
compiling time type c lang v9 v14 .
compiling time type c lang v9 v14 .
.
execution time type we published the new g ccbugs on our repository since g cchas stopped bug reporting.
compared with those used for rq1 rq3 and left the testing runs.
for any cpbugs discovered we also compute the measured performance drop by setting the target option value against the performance obtained via the source option value.
results from table xii we see that ndp has successfully discovered cpbugs that are previously unknown on gccand c lang which we have reported.
these cpbugs can lead to significant performance impact e.g.
ranging between .
.
and .
.
degradations on the execution time and compiling time respectively.
as such we say that ndp can discover previously unknown cpbugs given sufficient resources and versions workloads.
vii.
d iscussion w hyndp works ?
rq1 rq3 serve as the ablation analysis of ndp.
here we further explain why ndp work with a qualitative analysis.
a. predicting cpbugs types a key benefit of the neural language model in ndp is the significant reduction of false negatives compared with cpd andks.
for example option innodb fill factor for mysql has the description of innodb fill factor defines the percentage of space on each b tree page that is filled during a sorted index build with the remaining space reserved for future index growth.
for example setting innodb fill factor to reserves percent of the space on each b tree page for future index growth... .
this option should belong to type since both a too small or a too large value could downgrade the performance as the former creates many recursions while the latter processes too many pages.
yet for consistency a smaller value is preferred since fewer pages need to be maintained hence there is a trade off.
however the description has no clear pattern to indicate such hence both cpd andkshave wrongly classified it as type due to the presence of the word space .
ndp in contrast has .
.8pr c mysql .
.
.
1pr c mysql .
.
.8pr c maria db .
.
.
.4pr c maria db .
.
.
.
2pr c apache .
.
.
3pr c maria db .
.
2pr c gcc .
.
.
1pr c gcc .
.
.
.
1pr c clang .
.
.
.
1pr c clang .
.
a prioritization in ndp b random in cpd andus fig.
order of options to be tested for all systems left to right .
pr c denotes the probability of being cpbug related.
correctly estimated the option since it has learned that texts with b tree and page are likely to be related to trade offs.
b. prioritizing options to understand why prioritizing at the options level helps ndp to significantly improve the testing efficiency figure plots the first few options to be tested by all approaches.
we see that with ndp the prioritized options generally have higher probabilities of being cpbug related than those of the other two within which up to options can trigger cpbugs for m ysql while only one option from cpd anduscan do so for g cc .
this considerably impacts the cpbug testing.
c. prioritizing search we also analyze why prioritizing the different bounds of search space when testing the numeric options can help.
we found that the extreme search and midmost search are of great benefit therein.
for example innodb buffer pool size is a cpbug related numeric option on m ysql.
yet such a cpbug can only be discovered when we change it from a near minimal value i.e.
10mb to one that is closer to its maximum value i.e.
256gb.
with ndp such an option is categorized as the high density region characteristic and4 thus ndp would prioritize its bounds as extreme search first.
this fits perfectly with its range of values that causes a cpbug since with the extreme search a configuration in a pair would be explored within close to its minimum value while the other would take a value close to of its maximum extreme.
in contrast cpd would fix one configuration to the option value of 1mb while increasing the other as 2mb 4mb and 8mb etc each pair of which needs to be tested.
unlike the others usdoes not use a heuristic as it aims to sample randomly and uniformly.
therefore for options like innodb buffer pool size ndp needs significantly less number of tests to reveal the cpbugs compared with the others which might even fail to find the cpbugs due to exhaustion of budget.
viii.
t hreats to validity threats to internal validity we set the parameters either adopting pragmatic values or following widely used defaults e.g.
the inner budget of tests for ga under a bound is a pragmatic setting achieving a good balance between quality and cost.
for confirming performance drop in the oracle we set a minimum of change as prior work .
however we agree that some settings might not be the best.
threats to external validity for evaluating the estimation of cpbugs types we use prior datasets of systems .
for testing the cpbugs we use five systems with reproduced cpbugs.
in both cases the systems are of diverse languages domains and scales.
we have also considered a wide range of workloads and versions which are the most commonly used ones from existing work .
indeed more subjects might strengthen the conclusion.
threats to construct validity we use several metrics including precision recall and f1 score together with the trajectory of finding cpbugs and the best efficiency of each approach.
yet unintended programming errors or misconsiderations are always possible.
ix.
r elated work a. implication of configuration to performance issues a vast amount of early work has been conducted to understand the implications of configurations for performance issues.
for example jin et al.
and han et al.
reveal that of the performance problems can be traced back to configuration errors.
xiang et al.
further suggest that configuration option documentation is a significant resource for analyzing configuration related performance expectations which serve as a foundation for identifying cpbug oracle.
those studies provide insights into how configuration caused performance issues while ndp automatically testing cpbugs.
b. performance bug testing there exist tools that detect general performance bugs using a fixed set of patterns such as loops and memory access .
to tackle unforeseen bottleneck patterns shen et al.
propose a ga based testing framework with contrast data mining.
however they are not related to configurations.
among configuration related testing approaches ctest is a tool that leverages existing regression testing code to prioritize the execution of test cases for misconfiguration related performance issues.
diagconfig leverages static code analysis and machine learning to detect performance bugs caused by misconfiguration.
yet they aim for misconfiguration which is user induced performance issues while ndp reveal cpbugs the configuration performance issues that are unintentionally introduced by the developers of configurable systems.
this work also advances cpd a state of the art cpbug testing tool in several aspects we additionally summarize characteristic on the commonality of median range value for cpbug related numeric options and characteristic on the more detailed categorization of cpbug related numeric options which have not been revealed by the work of cpd.
cpd predicts the oracle using rule mining and keyword search while ndp does so via a roberta fine tunedby configuration documentation.
this as shown in section vi a has led to much superior accuracy.
cpd does not prioritize the options to be tested and a numeric option is tested by fixing it in one configuration as maximal minimal value while exponentially changing the value of the same option in the other configuration.
in contrast through exploiting the other roberta finetuned by both documentation and code ndp designs dual level prioritization that prioritizes the options that are more likely to cause cpbugs to be tested first while stochastically exploring the values of a numeric option in the pair using differently prioritized search bounds according to the likelihood of the option being cpbugsrelated and the observations from the characteristics .
this has resulted in considerably improved efficiency.
c. configuration performance tuning unlike testing for configuration related performance bugs configuration performance tuning aims to find the best configuration that reaches the optimal performance for deployment time benchmarking or runtime selfadaptation .
among others flash and boca are tuners based on bayesian optimization to find optimal configuration.
chen and li propose mmo an alternative way to tune configuration via tuneragnostic multi objectivization.
yet configuration tuning differs from the testing that ndp focus on in several aspects the representation in configuration tuning is often a single configuration while for cpbug testing we need to test a pair of configurations for revealing whether the actual performance matches the expectation.
further cpbug testing examines each option in turn while configuration tuning changes several options simultaneously.
x. c onclusion this paper presents ndp a general framework aiming to expedite cpbug testing via neural dual level prioritization.
ndp builds two neural language models for estimating the cpbugs types oracle and inferring the probabilities of the options being cpbug related respectively.
these models serve as the foundation for prioritization at two levels prioritizing the order of tested options and the order of search bounds for numeric options.
experiments on several real world systems and against state of the art tools approaches reveal that ndp estimates more reliable oracle of cpbug types while significantly expedites the testing at both the options level and the search level for numeric options with up to .
and .
speedup respectively.
for future work the static handling of workloads in ndp can also be prioritized placing the more vulnerable ones to be tested first.
extending ndp to detect cpbugs by testing multiple options simultaneously is also fruitful.
acknowledgement this work was supported by a nsfc grant and a ukri grant .