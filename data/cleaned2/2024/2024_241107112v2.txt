rocode integrating backtracking mechanism and program analysis in large language models for code generation xue jiang yihong dong key lab of high confidence software technology moe peking university beijing china jiangxue dongyh stu.pku.edu.cnyongding tao university of electronic science and technology of china chengdu china yongd.tao gmail.comhuanyu liu key lab of high confidence software technology moe peking university beijing china huanyuliu stu.pku.edu.cn zhi jin key lab of high confidence software technology moe peking university beijing china zhijin pku.edu.cnwenpin jiao key lab of high confidence software technology moe peking university beijing china jwp sei.pku.edu.cnge li key lab of high confidence software technology moe peking university beijing china lige pku.edu.cn abstract large language models llms have achieved impressive performance in code generation recently offering programmers revolutionary assistance in software development.
however due to the auto regressive nature of llms they are susceptible to error accumulation during code generation.
once an error is produced llms can merely continue to generate the subsequent code conditioned on it given their inability to adjust previous outputs.
existing llm based approaches typically consider post revising after code generation leading to the challenging resolution of accumulated errors and the significant wastage of resources.
ideally llms should rollback and resolve the occurred error in time during code generation rather than proceed on the basis of the error and wait for postrevising after generation.
in this paper we propose r ocode which integrates the backtracking mechanism and program analysis into llms for code generation.
specifically we employ program analysis to perform incremental error detection during the generation process.
when an error is detected the backtracking mechanism is triggered to priming rollback strategies and constraint regeneration thereby eliminating the error early and ensuring continued generation on the correct basis.
experiments on multiple code generation benchmarks show that r ocode can significantly reduce the errors generated by llms with a compilation pass rate of .
.
the test pass rate is improved by up to .
compared to the best baseline approach.
compared to the post revising baseline the token cost is reduced by .
.
moreover our approach is model agnostic and achieves consistent improvements across nine representative llms.
index terms code generation large language models backtracking mechanism program analysis.
i. i ntroduction as modern software architectures continue to increase in size and complexity the burden on developers to construct and maintain these systems has become substantial.
given that programs serve as the fundamental carriers of software functionality the automation of their generation is of paramountimportance.
code generation technology which seeks to automatically produce programs that align with human intentions has emerged as a focal area of interest within both academia and industry fields .
in recent years large language models llms have rapidly advanced and achieved significant success in the domain of automated code generation .
a well known tool for code generation based on llms is copilot which has demonstrated its utility by generating code that can be accepted by more than of its users .
fig.
.
statistics on the types of errors in code generated by llm.
the statistics are conducted based on the results generated by codellama 7b and codegen 6b on humaneval and mbpp benchmarks using greedy decoding.
typically llms adopt an auto regressive approach where the output at each step is conditioned on the outputs of previous steps.
once an error occurs during the generation process at any step for example the selection of an inappropriate token due to hallucinations1 this error will be included in the context of the subsequent steps.
this 1the hallucination in code generation manifests as generated code that violates programming principles resulting in code that cannot be compiled or executed or that is inconsistent with user requirements or context leading to failed tests .
recent research has demonstrated that all computable llms cannot prevent themselves from hallucinating .arxiv .07112v2 mar 2025phenomenon can cause errors to accumulate and amplify their impact potentially causing the generated content to completely deviate from the expected path .
moreover the generation process of llms differs significantly from the common practice of reviewing and adjusting existing code in human coding.
in practice developers are able to adjust their code whenever necessary based on its quality and its alignment with requirements while llms can merely proceed based on the output generated so far and are unable to adjust previous outputs spontaneously.
recent studies have attempted to utilize the llms to revise their output after generation in a post revising manner.
however this type of approach faces difficulties in revising the accumulated errors and can result in resource wastage .
ideally through incorporating a backtracking mechanism into the generation process we can expose potential errors early and resolve them effectively preventing error propagation.
however to effectively implement backtracking three key issues ought to be addressed when to roll back.
during the generation process the rollback is triggered depending on when errors are detected.
error detection during the generation of llms should satisfy the following conditions.
first it must be capable of performing real time checks on incomplete code second it is required to cover common errors produced by llms which are shown in figure finally its running speed would be better to fast enough so as not to affect the efficiency of llm significantly.
where to roll back to.
simply rolling back to the last error free state of the generated code usually does not address the issue.
we should identify the initial decision point that caused the error and roll back to that point.
determining the rollback point is a complex decision making process because the meaning and behavior of the erroneous code depend not only on itself but also on interactions with preceding code which are influenced by factors such as variable scopes state dependencies and logical dependencies within the program.
how to avoid previous errors.
after the rollback the key task during regeneration is to prevent the recurrence of previous errors.
however completely prohibiting the llms from generating previously erroneous code may inadvertently block benign tokens.
thus it is essential to impose appropriate constraints on the regeneration process.
to address the preceding three issues we first implement incremental error detection using program analysis which enables the examination of incomplete code to identify potential errors.
compilers can be used not only in code transformation for execution but also as an effective tool for program analysis.
it is capable of performing numerous key and common analyses such as syntax parsing type checking and dependency analysis and they have been optimized for speed over many years.
moreover by using compilers we can design new analyses for specific errors in llms generated code such as checking for code repetition problems.
second for determining rollback points program analysis serves as an external inspection during the generation of llms providing essential error information.
however this error informationmay not directly pinpoint the root cause of the error.
in contrast the inherent uncertainty of llms is proven to be usable for self assessment during generation which can aid in tracing the root cause of errors.
therefore combining these two sources of information facilitates determining rollback points.
third in regeneration with constraints we decay the generation probability of the paths leading to error progressively.
moreover by modeling the entire generation process with tree structures it is feasible to comprehensively account for all historical errors and to effectively superimpose penalties for them.
in this paper we propose r ocode a novel code generation approach that integrates backtracking mechanism and program analysis to llms.
the core of our approach the backtracking mechanism detects errors in real time rolls back and regenerates with constraints during the generation process of llms thus preventing error accumulation and enhancing the performance and efficiency of code generation.
specifically we employ program analysis to perform incremental error detection during the code generation process to discover errors timely.
based on the results of program analysis and the observation of uncertainty in the generation of llms we design a series of rollback strategies to determine the rollback point.
to constrain the process of regeneration we strategically penalize the likelihood of tokens that have contributed to previous errors.
further given that the introduction of rollback and regeneration makes code generation no longer follow a linear path we use a trie tree to model the whole generation process of r ocode.
importantly our approach is modelagnostic and requires no additional training.
our experimental results demonstrate that r ocode consistently outperforms all baselines across six code generation benchmarks.
r ocode achieves a compilation success rate of .
and surpasses the best performing baseline by .
in pass rate.
to further demonstrate its utility we apply r ocode to multilingual code generation tasks and achieve a relative improvement of .
in pass rate.
we also explore generalizability of r ocode across various llms revealing significant enhancements in the performance of both general llms and code llms with an average improvement of .
in pass rate.
in terms of cost and performance r ocode reduces token costs by .
compared to the post revising approach.
furthermore the ablation studies reveal that incremental error detection rollback strategies and constraint regeneration in rocode all contribute to performance improvement.
to the best of our knowledge this work is the first to introduce and implement the rollback approach for code generation during the decoding process in llms2.
ii.
m ethodology a. overview for a code generation task given the requirement x we propose to perform r ocode for llms to generate code y. rocode consists of three key steps 2code is available at error detection focuses on continuously checking the generated code during the generation process to discover errors early.
by implementing program analysis we can detect potential errors in the generated code such as compile errors and runtime errors.
strategic rollback upon detecting an error rolls back the generated code to an earlier error free state.
in this step we design a series of specific rollback strategies to determine the rollback point.
constraint regeneration formulates error related constraints and combines them with the llm decoding process to prevent previous errors from happening again.
this step involves strategically penalizing the likelihood of the generated tokens that contributed to the errors.
to track the code generation progression of r ocode we employ the structure of trie tree and and integrate operations of incremental error detection strategic rollback and constraint generation within the trie tree.
this structure helps organize non linear tree like code generation trajectories allowing us to efficiently handle multiple rollback and regeneration cycles.
b. incremental error detection considering llms are generated in an auto regressive way once an error occurs during the generation process the llms will continue to generate content on the basis of the errors leading to the propagation of errors.
since the occurred errors are inevitable in the final outputs the subsequent generation derived from these erroneous contents can be almost considered redundant.
therefore we employ incremental error detection to detect errors during generation in a timely manner and substantially reduce the cost of long rollbacks.
incremental error detection employs the program analysis tool to incrementally detect errors following the generation of each detectable unit.
specifically we use the statement as the smallest unit for detection each representing the smallest code unit with independent functionality.
the llm mincrementally generates these statements step by step.
upon completion of each statement we employ the program analysis tool cto conduct error detection.
this process can be formulated as follows si m x s i ei c s i si where siis the i th statement generated by m s i denotes the concatenation of statements andeiis the report of incremental error detection for si which is defined as ei result type lineno offset where result indicates the detection result of whether the generated code passes with possible values being success failure .
if result is success the remaining items are not applicable otherwise eireturns failure along with its type lineno and offset .
among them type indicates the typeof error detected lineno represents the line number where the error occurs and offset represents the specific position of error within the lineno .
the program analysis tool determines the types of errors that can be detected during error detection.
there are various tools designed for different errors and programming languages.
in this paper we choose the compiler to support our program analysis.
the reason is that the compiler integrates some key and mature analysis techniques which can effectively detect errors commonly found in llms shown in fig.
.
moreover compilers support almost all programming languages and run fast.
in the generation process we use a compiler either without executing or with executing test input to check the generated code.
without executing we can check for syntax errors type mismatches declaration errors scope errors and linking errors.
with executing test input we can further increase checks for runtime errors including timeouts recursion errors division by zero errors memory access errors index out of bounds errors and resource not found errors.
moreover in practical scenarios developers usually have access to publicly available test cases to better understand and validate requirements we take this part into account.
once the code is completely generated we execute the complete set of test cases if available which include both input and output to thoroughly verify the program s logic.
furthermore we observe that repeat patterns problem occurs during the code generation process characterized by the repetitive output of the same syntactic structure but meaningless code constructs like if elif elif... print etc.
resulting in failure to generate a termination symbol eos .
this problem typically does not result in syntax and compile errors during generation but it can significantly affect the semantics of the generated code thereby introducing potential logic errors.
therefore we design an additional analysis to detect repeat patterns problem.
specifically we utilize the syntax parsing module of the compiler to extract the syntactic structure and identify repetitive patterns.
according to abstract syntax definition language asdl if the same type ofstmt appears consecutively more than a specified number of times it is considered as an error with the error report including type as repetition and lineno as the line number where the first repeated stmt occurs.
c. strategic rollback when the error is detected it is necessary to undo a part of the previously generated code to rectify the issue.
to identify the specific point that requires to roll back to we design a series of strategies to determine the rollback point.
generally for detected errors incremental error detection can provide an error report including the location where the error occurs offering an initial clue to resolve the error.
therefore we first attempt to resolve the error by rolling back directly to this specific location.
the rollback point ris defined as a two dimensional value re s!s s s s s s s eoss!s s s s .
incremental error detection2.
rollbackmechanisms!s s s s .
constraintregeneration program analysis llms!s s s s s s s s !high uncertainty generate the next statementrollback pointerror detection resultss y!
y!y !
.
.
.
checkthe statement nodes with penaltyfig.
.
the overview of r ocode with trie tree.
where e.lineno refers to the line number of error report eand e.offset represents the offset within that line used to precisely locate the error.
however merely reverting to remay not be sufficient for some complex errors since the root cause of these errors might not actually originate from the reported location instead of an early location.
these errors usually involve dependencies and semantics.
given that llms are probabilistic models i.e.
llms predict the next token by calculating the conditional probability of each possible subsequent token given the preceding context llms may exhibit high levels of uncertainty at certain points during the generation process leading to fluctuating outputs .
although high uncertainty increases the likelihood of erroneous decisions it also facilitates the redistribution of probabilities to alter the output.
therefore we can infer rollback points by analyzing the model s display of uncertainty.
we can calculate the entropy at each position using the following formula ht v x j 1p yt vj y t x logp yt vj y t x where p yt vj y t x denotes the probability of generating the t th token ytasvjgiven the context xand previously generated tokens y t. the summationp v j 1iterates over all possible tokens vjin the vocabulary vthat can be generated at this position.
we roll back to the beginning of the statement containing the token with the highest entropy.
t argmaxt ht rh where converttolineno is a function that converts the token position to the corresponding line number within the code and y denotes the length of generated code y. this strategy allows for an opportunity to refresh the most relevant context in the next generation thereby avoiding the recurrence of this high entropy point.
the algorithm for the strategic rollback is shown in algorithm .
algorithm algorithm of strategic rollback require error detection reports e ei nand generated statements s si n. ensure rollback point r. assert en.result is failure .
initialize y s1 sn.
ifen.lineno and en en 1then r .
else en.lineno is none or the error recurs.
r where t is computed via eq.
and eq.
.
end if return r d. constraint regeneration after error detection and rollback we perform constraint regeneration to prevent the llm from reproducing the same error.
constraint regeneration involves two parts constructing constraints and integrating these constraints into the llm s decoding process thereby influencing the model s output behavior.
constraint construction we define constraints as penalties applied to the llms output probabilities for previouslygenerated erroneous code.
in the process of code generation the generated code can be considered as an output path of llms.
to avoid the model generating incorrect paths a naive approach is to set the probabilities of tokens on erroneous paths to zero completely blocking those paths.
however this approach can penalize some benign tokens.
instead we adopt a milder penalty approach which applies an exponentially decaying penalty to each token from the point of error back to a rollback point pn v y t t r ifv yt otherwise where is a decay factor between and and t rdenotes the number of time steps from the rollback point rto the current token yt.
this approach not only penalizes the tokens that directly cause errors but also applies lighter penalties to preceding tokens that may have indirectly contributed to the mistake thereby preventing the model from repeating erroneous generation paths.
decoding with constraints to avoid errors in the previous generation path penalties are applied to the probability distribution of llms adjusting the generation likelihood of each token.
then this modified probability distribution is renormalized.
specifically for each token y t its constrained probability distribution pc y t y t is given by pc y t y t p y t y t pn y t y t p vp v y t pn v y t e. trie tree modeling the generation process of r ocode involves rollbacks and regeneration resulting in a non linear structure.
therefore we use trie tree to model the entire process as illustrated in figure .
in the trie tree t u e each node u u represents a generated token in this process and each edge u v indicates that the token sequence from the root node to node userve as the context to generate node v. during the generation process of r ocode as each statement is generated its corresponding tokens are sequentially appended to the trie tree.
this addition is immediately followed by incremental error detection.
if an error is identified the affected path within the tree is flagged and the strategic rollback is activated identifying the precise node to revert to.
subsequently all descendant nodes of this rollback point representing the erroneous sequence are used to impose constraints.
this penalization process effectively discourages the regeneration of the same erroneous sequences during subsequent iterations of code generation.
each new errorfree statement is integrated into the tree as a distinct branch aligning with existing paths that share a common prefix.
this integration not only consolidates the tree structure but also accumulates the penalties associated with each erroneous path reinforcing the deterrent against repeating past mistakes.
it ensures that the generation process dynamically adapts minimizing the recurrence of similar errors and optimizing code output over time.ultimately each path from the root node to any terminal node represents an attempt at the generation process of rocode and the last path of trie tree represents the final generated code y. the pseudocode of r ocode during code generation is shown in algorithm .
algorithm the pseudocode of r ocode require input requirement x llm m. ensure generated code y. initialize trie tree t and index i .
statement si m x t.update stmt si .
while sidoes not include eos token do incremental error detection ei c t.stmts via eq.
.
t.update report ei .
strategic rollback ifei.result is failure then r rollback t.stmts t.reports via alg.
.
t.rollback to r .
end if constraint generation t.update pn t.stmts r via eq.
.
sample si m x t. stmts t.pn via eq.
.
i i .
t.update stmt si .
end while return t.getfinal gen code iii.
e valuation rocode aims to effectively prevent error accumulation in the code generation process of llms and improve the quality of generated code by integrating backtracking mechanism and program analysis into llms.
in this section we present extensive experiments that span six representative code generation benchmarks two program languages and nine llms of varying series or sizes.
we aim to investigate six research questions rq1 how does r ocode perform compared to baseline approaches on code generation benchmarks?
rq2 how effective is r ocode in improving llms in code generation tasks across different programming languages?
rq3 how does r ocode perform when applied to different llms?
rq4 how about the cost and efficiency of r ocode?
rq5 how does each component of r ocode contribute to the effectiveness?
rq6 how does the hyperparameter decay factor affect the effectiveness of r ocode?
a. evaluation setup benchmark we perform a comprehensive evaluation on six code generation benchmarks to demonstrate the superiority and generality of r ocode.humaneval consists of handwritten programming tasks proposed by openai.
each task includes a function signature a requirement use cases a function body and several unit tests average of per task .
we use the use cases as public test cases for our approach and baseline approaches while unit tests are used as private test cases for evaluation.
mbpp contains python programming tasks covering programming fundamentals standard library functionality and more.
the mbpp dataset does not specify public vs. private test cases.
following previous work we use one input of the test cases for all baseline approaches and do not involve any ground truth test case output.
codeforces2305 comprises of the competitionlevel programming problems collected from the codeforces website.
on average each problem is accompanied by three public test cases and three private test cases.
these problems are created after may which is after the training data cutoff of most llms such as codellama and codegen mitigating the impact of data contamination on evaluation.
humaneval et andmbpp et are expanded versions of humaneval and mbpp with over additional test cases per task.
this updated version includes edge test cases that enhance the soundness of code evaluation compared to the original benchmark.
humaneval cpp is constructed based on the humaneval benchmark to evaluate the code generation ability of llms on c programming language.
baselines our approach works on the decoding phase of llms that does not require modification and training of the model.
we use the three most common decoding approaches of llms and set them as baselines.
specifically temperature sampling controls the randomness of the token selection process higher temperatures tlead to more uniform distributions while lower temperatures tmake high probability tokens even more likely.
p w exp log p w w t t p w exp log p w w t t when tis p w is equivalent to w arg max wp w w t which means greedy sampling.
topk sampling limits the next word selection to the top k most likely candidates as determined by the model.
p w p w w t ifw top k otherwise.
nucleus sampling involves choosing from a smaller set of plausible candidates by dynamically selecting a variablesized subset of tokens the nucleus that cumulatively make up a certain probability mass e.g.
top .
p w p w w t ifp w sp w w t p otherwise.
we also implement two baselines representing the execution based sampling approaches and thepost revising approaches to demonstrate the efficiency of r ocode specifically sampling filtering utilizes llms to generate a vast number of codes which are then filtered by executing test cases.
post revising conducts testing after code is generated by llms and further revises codes that fail these tests based on error messages.
additionally we also compare four state of the art sota code generation approaches that operate during the decoding process specifically pg td employs monte carlo tree search during the llm decoding process formulating rewards based on testing results to guide the generation of code.
mbr exec introduces the execution result based minimum bayes risk decoding to select code from the samples generated by llms.
mgd utilizes static analysis tools to perform type analysis at pre defined trigger points specifically at dereference operations during the code generation process of llms enabling the selection of type consistent variables.
adapt dynamically adjusts the temperature during the llms generation process applying a higher temperature at points of low generation probability challenging tokens and a lower temperature at points of high generation probability confident tokens .
metrics we used three metrics to evaluate our approach including passrate avgpassrate and compiler correctness percentage.
passrate metric can measure the functional correctness of the generated code by executing private test cases.
for each task n 1samples of code are generated and the number of samples c n that pass the test cases are counted.
the passrate is then calculated using the following estimator passrate e problems n c n .
avgpassratio calculates the average proportion of test cases that generated codes y pspass which is a milder metric than passrate allowing to assess the partial correctness of the generated codes.
p x p p1 cp x c cpi eval yp ip c op c where prepresents a task within the test set p and ip c op c cp c 1is the set of test cases for p i is an indicator function which outputs if the condition is true and otherwise and eval yp ip c represents an evaluation function that obtains outputs of code ypby way of executing it with ip cas input.
compiler correctness percentage ccp measures the proportion of generated code samples that are compilable i.e.
free of syntax errors and compilation errors .
it is defined as ccp ncompilable ntotal table i the comparison of rocode and baseline approaches on different code generation benchmarks .
thebold text indicates the highest value for a particular metric within a given dataset regardless of the baseline or its configurations .
approaches humaneval et mbpp et codeforces2305 passrate avgpassrate ccp passrate avgpassrate ccp passrate avgpassrate ccp pg td .
.
.
.
.
.
.
.
mgd .
.
.
.
.
.
.
.
.
.
.
.
.
mbr exec .
.
.
.
.
.
.
.
.
.
.
.
.
adapt .
.
.
.
.
.
.
.
.
.
.
.
.
temperature sampling t .
.
.
.
.
.
.
.
.
.
.
.
.
.
post revising .
.
.
.
.
.
.
.
.
.
.
.
.
rocode .
.
.
.
.
.
.
.
.
.
.
.
.
temperature sampling t .
.
.
.
.
.
.
.
.
.
.
.
.
.
filtering .
.
.
.
.
.
.
.
.
.
.
.
.
post revising .
.
.
.
.
.
.
.
.
.
.
.
.
rocode .
.
.
.
.
.
.
.
.
.
.
.
.
temperature sampling t .
.
.
.
.
.
.
.
.
.
.
.
.
.
filtering .
.
.
.
.
.
.
.
.
.
.
.
.
post revising .
.
.
.
.
.
.
.
.
.
.
.
.
rocode .
.
.
.
.
.
.
.
.
.
.
.
.
top k sampling k .
.
.
.
.
.
.
.
.
.
.
.
.
filtering .
.
.
.
.
.
.
.
.
.
.
.
.
post revising .
.
.
.
.
.
.
.
.
.
.
.
.
rocode .
.
.
.
.
.
.
.
.
.
.
.
.
top k sampling k .
.
.
.
.
.
.
.
.
.
.
.
.
filtering .
.
.
.
.
.
.
.
.
.
.
.
.
post revising .
.
.
.
.
.
.
.
.
.
.
.
.
rocode .
.
.
.
.
.
.
.
.
.
.
.
.
nucleus sampling p .
.
.
.
.
.
.
.
.
.
.
.
.
.
filtering .
.
.
.
.
.
.
.
.
.
.
.
.
post revising .
.
.
.
.
.
.
.
.
.
.
.
.
rocode .
.
.
.
.
.
.
.
.
.
.
.
.
nucleus sampling p .
.
.
.
.
.
.
.
.
.
.
.
.
.
filtering .
.
.
.
.
.
.
.
.
.
.
.
.
post revising .
.
.
.
.
.
.
.
.
.
.
.
.
rocode .
.
.
.
.
.
.
.
.
.
.
.
.
where ncompilable is the number of compilable code samples andntotalis the total number of generated codes.
implementation details in the evaluation we use codellama 7b as base model by default.
the decay factor for constraint regeneration is set at .
.
the maximum generation length of our approach and baselines is set to on all benchmarks except for codeforces2305 where it is set to .
to mitigate the instability of the model sampling we report the average results of three trials in the experiments.
due to space limits we only present the results on the humaneval dataset other benchmarks follow similar trends for rq3 rq4 and rq5.
b. rq1.
comparing rocode to baseline approaches to evaluate the effectiveness of r ocode on code generation we evaluate test correctness and compile correctness across various representative code generation benchmarks including humaneval mbpp humaneval et mbpp et and codeforces2305.
settings we compare our approach with nine baselines including temperature sampling topk sampling nucleus sampling sampling filtering post revising pg td mbrexec mgd and adapt.
for the humaneval mbpp humaneval et and mbpp et benchmarks codellama 7b serves as our base model while for the more challenging codeforces2305 benchmark we employ codellama 34b as our base model.
since temperature sampling top k sampling and nucleus sampling are sensitive to their parameter settings we evaluate their performance under different settings.
for the temperature t in temperature sampling we use values of .
.
and .
.
for the k value in top k sampling we use and .
for the p value in nucleus sampling we use .
and .
.
our approach sampling filtering and post revising can be combined with these three decoding methods.
we set the token budget of r ocode during generation to be twice the maximum generation length.
sampling filtering and post revising maintain the same token budget as r ocode.
results the experimental results are shown in table i. these results demonstrate that our approach outperforms all baseline approaches across three metrics on five datasets demonstrating the superior performance of r ocode.
notably our approach shows the best performance at .
in pass rate under the nucleus sampling p .
setting on humaneval benchmark exceeding the direct generation with llms by .
in the same setting.
specifically our approach exceeds those of sampling filtering and post revising across three commonly used decoding methods temperature sampling top k sampling and nucleus sampling.
the fact that our approach significantly surpasses the sampling filtering approach proves that the improvement in performance is not merely due to repetitive sampling but is greatly aided by the backtracking mechanism.
compared to post revising our approach can resolve errors in real time during the generation process which helps enhance the quality of generated code and prevents the accumulation of errors that can complicate error resolution.
among all baselines pg td performs the best however it requires both test inputs and outputs for execution limiting its applicability to benchmarks like mbpp that do not provide public test cases.
it is also worth noting that all approaches generally perform worse on the codeforces2305 dataset compared to other benchmarks.
this may be due to two reasons firstly the code generation task in codeforces2305 is inherently challenging with even the powerful chatgpt achieving only a .
pass rate in the original paper secondly potential data contamination issues might have caused the llms to perform exceptionally well on other benchmarks creating a significant disparity with codeforces2305.
despite this r ocode successfully attains a performance level of pass rate up to .
which represents a substantial improvement over the baselines on the codeforces2305 benchmark.
this enhancement underscores the significant potential of our approach to elevate the capabilities of llms in addressing complex problem solving tasks.
c. rq2.
performance on multilingual code generation for different programming languages due to the unique characteristics of each language and the distribution of training data there are variations in the performance of llms when generating code in different languages.
in this evaluation we examine the performance of our approach on multilingual code generation tasks.
settings in addition to python language we also evaluate our approach on c language utilizing humaneval cpp benchmark.
the baseline approaches include temperature sampling sampling filtering and post revising all of which employ the best performing configurations of passrate as shown in table i. table ii the performance of rocode on different programming languages pl .
pl approaches passrate avgpassrate ccp c temperature sampling .
.
.
sampling filtering .
.
.
post revising .
.
.
rocode .
.
.
pythontemperature sampling .
.
.
sampling filtering .
.
.
post revising .
.
.
rocode .
.
.
results the experimental results in table ii show that our approach significantly improves performance in both languages.
our approach achieves greater improvement onpython which is a language where llms excel compared to c .
nevertheless our approach still outperforms all baselines in c with a relative increase of .
over the bestperforming baseline i.e.
sampleing filtering in pass rate.
moreover our approach achieves a .
compilation pass rate on c code generation tasks significantly higher than other baselines.
utilizing compiler based program analysis for error detection proves effective across various languages ensuring the robustness and versatility of our approach.
d. rq3.
performance on different llms rocode is model agnostic and can be applied to a variety of llms.
in this evaluation we explore how r ocode enhances code generation performances across different llms.
settings we employ several different series and sizes of representative general llms and code llms to perform rocode.
the general llms used are from the llama series llama 7b 13b and 34b while the code llms include the multi lingual codegen series codegen 2b 6b and 16b and the codellama series codellama 7b 13b and 34b .
llama 7bllama 13bllama 34bcodegen 2bcodegen 6bcodegen 16bcodellama 7bcodellama 13bcodellama 34bpassrate temperature samplingrocode fig.
.
the performance of r ocode on different llms.
results from the experimental results shown in figure we can observe that r ocode achieves significant improvements over temperature sampling across all series and on llms of various sizes.
our approach achieves higher performance on code llms compared to general llms with a pass rate exceeding .
furthermore we observed a trend in the enhancement across different llms the stronger the base model the greater the improvement brought by r ocode.
this might suggest that more powerful llms have greater potential for enhancements through rollback corrections.
e. rq4.
cost and efficiency of rocode besides performance cost and efficiency also influence whether a code generation approach will be widely adopted.
therefore we discuss the cost and efficiency of r ocode.
settings we measure the costs by the number of tokens consumed since the computational resource usage for llmsscales with the number of tokens and services that provide llm access typically charge based on token usage.
we also measure the efficiency by the speed of the running time min .
we compared r ocode with seven baseline methods pg td mgd mbr exec adapt temperature sampling sampling filtering and post revising.
for temperature sampling sampling filtering and post revising we configure them according to the parameter configurations that exhibit the best performance passrate shown in table i. table iii the cost and efficiency of rocode where the bold italic indicates the highest value other than rocode which is also the baseline of the relative improvement .
approaches passrate token consumption time pg td .
.
.
mgd .
.
.
mbr exec .
.
.
adapt .
.
.
temperature sampling .
.
.
sampling filtering .
.
.
post revising .
.
.
rocode .
.
.
.
results the evaluation results on humaneval benchmark are presented in table iii.
in terms of cost token consumption our approach shows clear advantages compared to most baselines.
compared to temperature sampling that is directly generated with llms our cost increases by less than .
times.
notably our approach is substantially more efficient compared to post revising with a cost reduction of .
.
more importantly the cost of our approach is significantly lower than the state of the art sota approach pg td.
in terms of time efficiency although our approach is slightly slower than sampling filtering and post revising it is still faster than pg td.
the additional time cost primarily stems from calling the compiler for incremental checks.
considering the generated code is in python language which is an interpreted language suitable for just in time execution and dynamic typing we can perform incremental execution rather than starting from scratch each time to further optimize the speed of checks.
f .
rq5.
ablation study rocode consists of three key components incremental error detection strategic rollback and constraint generation.
we evaluate the effectiveness of each component through ablation experiments.
settings we modify or remove different components while keeping the rest of r ocode unchanged for error detection we replace the original program analysis based detection with an entropy based detection which aligns with our rollback strategy reporting errors at locations with the highest entropy entropy based error detection .
for the strategic rollback we explore four other rollback strategies respectively roll back directly to the beginning and generate from scratch full restartrollback .
roll back only to the statement of the reported error error statement rollback .
roll back only to the statement with the highest entropy high entropy statement rollback .
roll back to the token with the highest entropy and disable that token high entropy token disable rollback .
for constraint generation we remove the constraints during generation but instead resample an output constraint free resampling .
table iv ablation results .
variants passrate avgpassrate cpp entropy based error detection .
.
.
full restart rollback .
.
.
error statement rollback .
.
.
high entropy statement rollback .
.
.
high entropy token disable rollback .
.
.
constraint free resampling .
.
.
rocode .
.
.
results the experimental results on the humaneval benchmark are shown in table iv.
from the experimental results it is evident that all components of our approach are effective.
in contrast to the entropy based error detection approach our program analysis based error detection avoids the bias of labeling tokens as erroneous merely due to their high entropy as not all high entropy tokens lead to errors.
the full restart rollback cannot achieve the same performance as our approach under the same token budget as it lacks in efficiency.
the performance decline observed in both error statement rollback and high entropy statement rollback further validates the effectiveness of combining program analysis with llm based entropy assessments in rollback strategies.
additionally approaches that simply block high entropy tokens have failed to effectively alter the entropy of the code thus offering limited performance enhancement.
removing constraints during decoding also leads to a noticeable decline in performance which confirms the efficacy of our constraint regeneration approach.
g. rq6.
effect of decay factor since r ocode involved one hyperparameter the decay factor we evaluate the impact of different values of this hyperparameter on the performance to analyze its sensitivity.
settings we choose .
.
.
.
.
.
.
.
.
as test values for .
we conduct experiments on humaneval benchmarks under the setting of greedy sampling.
results the experimental results of this evaluation are shown in figure .
from the results we can observe that as the hyperparameter increases the metrics passrate and avgpassrate show a slight downward trend although the decline is not significant.
on the other hand the ccp metric while fluctuating across different values of r still maintains a high level overall averaging over .
these observations suggest that our approach demonstrates strong robustness to adjustments in the hyperparameter .
the downward trend in40 .
.
.
.
.
.
.
.
.99pass 1avgpassratioccpfig.
.
the performance of r ocode with different values of the hyperparameter .
we use the gray dashed line to represent the employed hyperparameters.
passrate and avgpassrate could be due to higher values of meaning looser constraint penalties during code generation which decays the likelihood of previous errors less.
specifically a larger value reduces the immediate penalty for errors requiring more iterations to correct mistakes which may affect the performance of generating correct code within a limited token budget.
iv.
t hreats to validity there are three major threats to the validity of our work.
threats to external validity concern the quality of experimental datasets and the generalizability of our results.
first we use six public code generation datasets for evaluation which are mainstream benchmarks and have been used in many related works .
moreover to prevent the evaluation dataset from being affected by data contamination i.e.
the test data may have been included in the training data of llms we used problems from codeforces that were published after the cutoff date of llm s training data for the assessment.
second r ocode can be applied to any llms and we choose nine well known llms of different series and sizes for our experiments.
threats to internal validity involve the impact of hyperparameters.
for our approach we introduce a hyperparameter i.e.
the decay factor in constrained regeneration.
for this hyperparameter we intuitively selected a specific value and observed that it enhances performance across multiple benchmarks.
to further explore the impact of this hyperparameter we conducted detailed experimental studies which showed that this hyperparameter effectively improves experimental results over a broad range.
as for other hyperparameters such as maximum generation length and temperature to ensure fairness in comparison we maintained these parameters consistent with the baseline approaches.
threats to construct validity pertain to the reliability of evaluation metrics.
we use the test pass rate as the primary evaluation metric.
however due to the limited number of test cases this method cannot fully assess the functionalcorrectness of the generated code.
to mitigate this issue we adopted extended versions of some benchmarks which significantly expanded the number of test cases to provide a more comprehensive functional evaluation.
for passrate metrics we employ the unbiased version of passrate to diminish evaluation errors that arise from sampling.
on this basis each experiment is run three times and its average result is reported.
v. r elated work a. code generation with llms general llms represented by chatgpt have demonstrated significant potential in software engineering tasks such as code generation.
this led to the development of specialized llms for code generation such as alphacode codegen incoder codegeex starcoder wizardcoder and codellama .
these specialized llms are typically developed by further training general llms or by training them from scratch using code corpus.
furthermore there is a series of research efforts for code generation that propose improvements to the decoding stage of general llms or code llms.
zhang et al.
proposed a planning guided decoding algorithm to generate higher quality programs.
this algorithm is based on monte carlo tree search mcts and explores different branches of the search tree to examine various possibilities for program generation.
after generating a complete program it is evaluated by executing test cases to obtain rewards.
shi et al.
and chen et al.
generate a large number of program samples from llms and subsequently reranking them using public or generated test cases.
zhang et al.
introduced self edit which involves training another model to modify the programs generated by llms based on the results of executing test cases.
similarly cheng et al.
also developed a post processing technique for modifying the outputs of models.
those approach leverages the capabilities of llms to debug and correct their own errors.
b. combining program analysis and llms combining emerging llms with traditional program analysis techniques to overcome existing technological limitations has become a new trend.
currently there have been some efforts in this direction which have been applied to various software engineering tasks including program synthesis formal verification and defect detection.
jain et al.
proposed jigsaw an approach that performs several transformations and checks during the processing steps thereby enhancing the program synthesis capabilities of llms and validating it through the synthesis of the python pandas api.
agrawal et al.
incorporated type based static analysis into the code generation process enabling the provision of a candidate list that constrains llms to produce type correct identifiers.
wen et al.
utilize static analysis techniques to decompose programs thereby facilitating incremental specification generation for program verification.
li et al.
designed llift a framework that enables interaction between static analysis tools and llms using use before initialization ubi bugs asa case study to demonstrate its effectiveness.
wang et al.
proposed a resource leak detection approach that combined llms with static program analysis.
this approach utilizes llms to infer the resource oriented intentions resource acquisition release and reachability verification in code instead of matching predefined apis and then inferred intentions are applied to enhance static resource leak detection techniques.
vi.
c onclusion in this paper we introduce r ocode a novel code generation approach based on llms that integrates backtracking mechanism and program analysis tools to eliminate errors in the code generation process.
our approach enables llms to generate programs incrementally followed by incremental error detection through program analysis.
when an error is detected we perform rollback strategies which provide an opportunity for llms to make modifications during the generation process.
furthermore we impose constraints on the regeneration process to avoid repeating historical errors.
our approach is model agnostic and does not require training allowing for direct integration with llms.
experimental results show that our approach consistently outperforms baselines across various benchmarks providing stable improvements for different decoding approaches and various llms.