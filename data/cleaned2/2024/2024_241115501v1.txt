instruct or interact?
exploring and eliciting llms capability in code snippet adaptation through prompt engineering tanghaoran zhang yue yu xinjun mao shangwen wang kang yang yao lu zhang zhang and yuxin zhao college of computer science and technology national university of defense and technology changsha china zhangthr yuyue xjmao wangshangwen13 yangkang luyao08 zhangzhang14 yuxinzhao nudt.edu.cn abstract code snippet adaptation is a fundamental activity in the software development process.
unlike code generation code snippet adaptation is not a free creation which requires developers to tailor a given code snippet in order to fit specific requirements and the code context.
recently large language models llms have confirmed their effectiveness in the code generation task with promising results.
however their performance on code snippet adaptation a reuse oriented and context dependent code change prediction task is still unclear.
to bridge this gap we conduct an empirical study to investigate the performance and issues of llms on the adaptation task.
we first evaluate the adaptation performances of three popular llms and compare them to the code generation task.
our result indicates that their adaptation ability is weaker than generation with a nearly decrease on pass and more contextrelated errors.
by manually inspecting cases we further investigate the causes of llms sub optimal performance which can be classified into three categories i.e.
unclear requirement requirement misalignment and context misapplication .
based on the above empirical research we propose an interactive prompting approach to eliciting llms ability on the adaptation task.
specifically we enhance the prompt by enriching the context and decomposing the task which alleviates context misapplication and improves requirement understanding.
besides we enable llms reflection by requiring them to interact with a human or a llm counselor compensating for unclear requirement.
our experimental result reveals that our approach greatly improve llms adaptation performance.
the best performing humanllm interaction successfully solves out of the identified defects and improves the pass and pass by over compared to the initial instruction based prompt.
considering human efforts we suggest multi agent interaction as a tradeoff which can achieve comparable performance with excellent generalization ability.
we deem that our approach could provide methodological assistance for autonomous code snippet reuse and adaptation with llms.
index terms code snippet adaptation large language models prompt engineering interactive workflow i. i ntroduction with the thriving growth of the open source community software reuse is widely adopted to efficiently deliver high yue yu is the corresponding author.
tanghaoran zhang xinjun mao kang yang yao lu zhang zhang and yuxin zhao are with the key laboratory of software engineering for complex system.quality software products.
besides component based reuse reusing online code snippets has become a common practice in modern software development .
these public available snippets from various platforms e.g.
github and stack overflow are widely reviewed and proofed by a large number of open source contributors.
compared to writing the code from scratch leveraging the recognized knowledge to build software has lower cost and less risks .
however online code snippets often fail to meet the specific needs of developers.
hence apart from simple copy andpaste developers are usually required to adapt these code snippets according to their development contexts to ensure the correctness and maintainability of the code .
over the years several code snippet adaptation techniques and tools have been proposed to facilitate this daily activity but it is still a pending issue for its automation.
recent advancements in artificial intelligence have been marked by the emergence of large language models llms such as chatgpt .
these llms are distinguished by their large scale of parameters and emergent abilities in processing natural language which stems from extensive training on diverse data sources.
this training empowers them with abilities applicable to numerous software engineering tasks e.g.
code generation code summarization and automated program repair .
code snippet adaptation can also be performed with llms generation ability when the task is properly described.
therefore it is imperative to investigate the potential of llms to perform adaptation.
llms are utilized through the pre train prompt and predict paradigm which requires users to engage with them through a set of textual inputs i.e.
prompt.
prompts enable us to teach llms unseen tasks with no need for fine tuning them or modifying their architectures known as programming in natural language .
for instance alice could ask llms to debug her code by simply entering please help me find the bugs in the following code code as an input prompt.
besides the prompt selection could significantly influence the capabilities of llms .
therefore crafting appropriate prompts is the way of eliciting the ability of llms toarxiv .15501v1 nov 2024perform the corresponding task which is known as prompt engineering .
however it is challenging to design an optimal prompt for code snippet adaptation.
the reason is that performing adaptations requires an accurate understanding of its context.
llms should be instructed to identify and strictly adhere to the constraints of the context e.g.
dependencies on specific fields and methods like dancing in the fetters .
therefore we focus on the prompt engineering of code snippet adaptation to explore and elicit llms capabilities.
to this end we first conduct an empirical study to investigate the effectiveness of llms and their limitations on code snippet adaptation.
specifically we evaluate the adaptation performances of three popular llms based on the classeval benchmark .
the results show that the best performing llm i.e.
gpt .
achieves .
.
and .
on pass pass and codebleu.
however their adaptation performance is inferior in pass to generation.
therefore we further investigate the issues of llms adaptations on sampled cases adapted by gpt .
.
for each case we inspect the failed test cases and identify defects from the adapted code.
we find that adaptation includes more contextrelated errors than generation indicating llms unawareness of the context.
then we annotate the origins and causes of above defects.
of them are pre existent and overlooked by llms and significantly fewer adaptations are made actually than required highlighting llms laziness on adaptation.
besides we summarize three categories of the root causes that lead to llms failures including unclear requirement requirement misalignment andcontext misapplication .
motivated by our observations we propose an interactive prompting approach to addressing identified llms issues in adaptation.
our approach enriches the prompt with more information to avoid llms context misapplication.
it decomposes the adaptation task with a multi turn conversation style to alleviate llms burden of understanding.
then we integrates an interaction workflow allowing llms to flip their roles to refine the requirements by asking questions.
the interaction is implemented with two schemes one through a human in the loop supervision and the other through a multiagent collaboration.
the interaction compensates for unclear requirements and enables llms reflection to identify their confusion.
the result demonstrates that human llm interaction achieves better performances which solves out of the previously identified defects and elevates the performance by .
.
and .
on pass pass and codebleu.
however human interventions may incur labor costs.
as a trade off our proposed multi agent interaction could achieve comparable performance only about decrease in pass and also have promising generalization ability on both conversational and instruction tuned llms.
in summary this paper makes the following contributions to the best of our knowledge we conduct the first study to evaluate the effectiveness of llms on the code snippet adaptation task.
our results demonstrate that the adaptation task is more challenging for llms than generation.
we find that llms are lazy adaptation makers and have weak context awareness.
furthermore we summarize three categories of nine causes of their failures in adaptation revealing their current limitations.
we propose a novel interactive prompting approach to utilizing llms in code snippet adaptation.
it provides an effective use of llms in software reuse tasks supporting current reuse oriented software engineering methodology.
our accessible source code and annotated data1will facilitate the replication and application of our study.
the rest of this paper is organized as follows section ii describes our empirical study.
section iii introduces our interactive prompting approach.
section iv evaluates our proposed approach.
section v discusses the related work of this study.
section vi presents threats to validity and section vii concludes the paper.
ii.
e mpirical study a. research questions to evaluate the performance and issues of llms in code snippet adaptation we structure the goal of our empirical study in the following research questions.
rq1 how effective are llms on the adaptation task?
existing studies have evaluated llms performance on a wide spectrum of software engineering tasks.
however their effectiveness on the code snippet adaptation task remains unexplored.
to this end we investigate the adaptation performance of three widely used llms in different settings.
rq2 what are the current issues of llms adaptations?
to better utilize llms for code snippet adaptation it is necessary to understand their current limitations from their adaptation results.
to this end we analyze the test results of the adapted code and their failure inducing defects by inspecting gpt .
adapted snippets in cases.
rq3 what are the root causes of llms adaptation failures?
this rq aims to understand why llms fail to adapt snippets to their context.
to achieve this goal we conduct a thematic analysis to summarize the underlying reasons of llms failures.
the answer is of great importance to understanding their nature of performing adaptations.
b. study design our empirical study follows a mixed method research methodology.
fig.
describes its framework.
as there is no benchmark for code snippet adaptation we first supplement a code generation benchmark classeval with a simulated snippet retrieval process in which a group of retrieved snippets are generated as the adaptation source.
the core task for llms is to adapt these snippets correctly to their class context.
to this end we design a code snippet adaptation prompt to instruct llms to complete the task.
finally through quantitative and qualitative test analysis we evaluate llms adaptation performance and summarize their issues and root causes from failed cases.
snippet retrieval ii.
prompt design iii.
test analysis llm simulated retrievalcode retrieval prompt llm adaptationcode snippet adaptation prompt defadd current status new status if not isinstance current status str or not isinstance new status str raisetypeerror parameters must be of type str returncurrent status new statusretrieved snippet requirement retrieved snippetdefadd self states int stat int int ifnotisinstance states int or notisinstance stat int raisetypeerror parameters must be of type int returnstates statadapted snippets run test suite failed test info test results failed test case typeerror add missing required positional argument stat .
assertionerror !
.failed test case defect identification defect wrong method signature.
defadd self states int stat int defect wrong calculation logic.
returnstates statmanual annotation defect type unexpectedly adapted cause method signature misalignment defect type overlooked cause operational logic misalignment benchmark staticmethod defadd states stat add a status to the current status and check the parameters whether they are legal.
requirement this is a utility class that ... classbitstatusutil staticmethod defhas args ... staticmethod defcheck args ...class context class bitstatusutiltestadd deftest add self ... deftest add 2 self ...test suiteclass context requirementfig.
.
the framework of our empirical study.
snippet retrieval.
to support the evaluation of code snippet adaptation we supplement classeval with retrieved snippets.
typically developers retrieve the snippets for reuse by searching and selecting from online open source communities.
however this process is traditionally labor intensive requiring precise query formulation and answer selection.
to streamline this we leverage gpt .
to simulate snippet retrieval by only providing the method name and its description as requirement.
for each method in the benchmark we obtain a general snippet as the source and llms will further adapt it to the specific class context.
our prompt used in snippet retrieval is discussed below and shown in fig.
.
prompt design.
in line with the established practices for instructing llms we develop the prompt skeleton comprising two parts a general system prompt and an instruction prompt detailing the specific requirements for the task.
our prompts for code retrieval data preparation code generation baseline and code snippet adaptation follow this two part structure and are differentiated by their instruction contents as shown in fig.
.
for code retrieval its prompt includes only the task description without additional context while the code generation prompt also incorporates class context and the target method description at the end.
the adaptation prompt further includes the retrieved snippet.
our design aligns with current guidelines which advocate for clear separation of different prompt components using modelfriendly markers like .
this approach not only aids in clarity but also enhances llms ability to process the prompts.
below is an instruction that describes a task.
write a response that appropriately completes the request.
instruction please write out the generated adapted method completely in the response section.
response please complete the method in the following class class context for member methods in the following class context only their signatures are retained.
please adapt the provided method method name to the class context of class name .
the adapted method should perform the function in the following description please write a python method to complete the function .
retrieved snippet you are a helpful assistant .
class context for member methods in the following class context only their signatures are retained.
system prompt instruction prompt instruction body i. code retrieval prompt data preparation ii.
code generation prompt baseline iii.
code snippet adaptation prompt fig.
.
the prompt design of code retrieval code generation and code snippet adaptation.test analysis.
we perform manual test analysis to identify the issues and root causes of llms adaptations based on theclasseval benchmark see section ii c .
to this end we randomly select of methods which exceeds the sample size required for a confidence level and a margin of error.
leveraging classeval s test suites the first and fifth authors identify defects in the adapted methods from the failed test cases.
given that defects are not necessarily introduced by adaptations e.g.
the retrieved snippet does not satisfy the requirement we annotate all identified defects into three types based on their origins overlooked the defect exists before adaptation and has not been adapted by llm invalidly adapted the defect exists before adaptation and it is adapted incorrectly by llm unexpectedly adapted the defect emerges after adaptation due to incorrect llm s adaptations.
disagreements are initially discussed between the two annotators and unresolved cases are further reviewed by the second author for a majority decision.
eventually the identified defects and their types are approved by all three annotators.
the cohen s kappa value of the classification is .
which indicates a strong agreement between annotators.
moreover we employ thematic analysis to investigate root causes of our identified defects.
the same two authors independently annotate all sampled methods with their root cause descriptions.
this labeling process focuses on discrepancies between the adapted snippets and canonical solutions.
subsequently the annotators re read and group the codes with similar descriptions and generate the initial themes for their root causes.
then they iteratively re evaluate and group the themes until they are established.
the final themes are consolidated and refined by the authors ensuring they accurately reflect the underlying issues.
to support our annotation we build an interface for each adaptation which displays the original requirement reused code snippet llm adapted code canonical solution and test results.
all participants in this study have over five years of python programming experience.
eventually we obtain three categories of causes i.e.
unclear requirement requirement misalignment and context misapplication which are further explained in section ii f. c. experiment setting dataset.
our study utilizes the classeval benchmark to evaluate llms adaptations.
classeval originally a class levelcode generation benchmark comprising python classes and their associated test suites is apt for our context dependent adaptation task.
besides classeval is a manually crafted dataset covering diverse topics which simulates real software development scenarios.
it was released in and hence could mitigate the training data exposure for llms.
based onclasseval we obtain the class level context by excluding the target method and all other methods dependent on it i.e.
caller methods for each class.
finally we derive methodlevel adaptation cases by pairing our retrieved snippets with their corresponding context.
studied models.
we select three widely studied llms including one conversational llm gpt .
and two instruction tuned code llms codellama llama .
these llms are chosen for their capability to interpret natural language prompts which allows us to instruct them for code snippet adaptation.
for gpt .
we use gpt .
turbo checkpoint through the openai api.
as for instructiontuned llms we select the 7b 13b and 34b versions for codellama and the 8b version for llama .
baseline.
as there is not a general purpose predictive approach for code snippet adaptation we utilize code generation with llm as our baseline to evaluate the current situation of llms adaptation.
the prompt used is shown in fig.
.
our design ensures a fair comparison between code generation and code snippet adaptation prompts by providing the same level of details in the context according to the taxonomy outlined by santu et al.
.
their difference is that adaptation requires llms to perform the task based on the retrieved snippet.
evaluation metrics.
we use the pass kas our primary metric to evaluate the correctness of the generated adaptations by llms.
it measures the likelihood of problem solving within kattempts based on unit test performance.
pass k eproblems n c k n k where krepresents the number of candidates sampled from all results with the total number of n.cis the number of samples that pass the tests.
considering the generation cost we set n to in line with previous work .
specifically we calculate pass 1and pass 5for each adaptation case reflecting both the accuracy and practical solution finding efficiency i.e.
whether a solution can be found by skimming through at most snippets generated by llms.
furthermore we also adopt codebleu as a complementary evaluation metric.
it considers the n gram match and syntactic and semantic similarity via abstract syntax trees asts and data flow.
we use it to evaluate similarities between generated snippets and canonical solutions offering insights beyond mere test pass rates.
implementation details.
to alleviate the impact of llms response randomness we employ nucleus sampling according to previous studies .
for each task five responses are randomly generated and collected for evaluation.
our experiments also explore the impact of temperature settings to at .
intervals on llms performance.
we set the maximum token window to for all llms ensuring consistent context lengths.
all experiments are conducted with two geforce rtx 24g gpu.
d. rq1 llms adaptation performance table i illustrates the performance of our selected llms in different temperature settings and parameter sizes.
for the adaptation task gpt .
performs the best achieving .
and .
in pass and pass respectively.
llama 8b ranks the second with a competitive pass score .
when the temperature is .
but its pass is much lower than gpt3.
.
the performance of codellama on all parameter sizes are similar and inferior to the above two llms.
its best pass and pass are .
and .
.
specifically codellama34b achieves the best pass and codebleu scores while its 7b version behaves better when the temperature rises.
as for the temperature parameter its optimal setting of gpt .
is .
on the adaptation task as evidenced by a marginal improvement in pass and a significant improvement in pass p .
mann whitney u test .
for instruction tuned llms there is a similar trend.
the lower temperature leads to better pass and codebleu scores.
a slightly higher temperature e.g.
.
or .
improves the pass score.
the reason behind is that a higher temperature introduces more variability in llms outputs facilitating a broader exploration of potential adaptations.
in contrast a temperature setting of stabilizes the generated code structure resulting in higher codebleu scores.
in all we adopt the optimal temperature setting i.e.
.
for gpt .
in the following experiments.
taking the best performing llm i.e.
gpt .
as an example its performance in code snippet adaptation exhibits a decrease of .
.
and .
in pass pass and codebleu compared to that of code generation.
as introduced in section ii b their prompts contain the same contextual information.
the reason behind the performance gap may be that gpt .
is a generative model designed for predicting the next token making it well suited for code generation from scratch.
however adaptation tasks require the comprehension of multiple fragments of a compound corpus and context based modifications to existing code snippets.
this poses a challenging task for current generative llms.
in addition to the model type size and its temperature setting which can be seen as factors from the model aspect factors from the task aspect may also impact llms adaptation performance e.g.
the complexity of the task.
in our study we use the adaptation size a.k.a.
the number of the required ast edits from retrieved snippet to the canonical solution as the measure for task complexity.
fig.
illustrates the distribution of the adaptation size and its relationship with the pass score of gpt .
.
all adaptation cases are grouped into seven by the adaptation size with an interval of .
the majority of the cases have the adaptation size below .
there is a decreasing trend of gpt3.
s pass with the rising of adaptation size.
two obvioustable i adaptation performance of llm s in different temperature settings modeltemperature temperature .
temperature .
temperature .
temperature .
temperature p p cb p p cb p p cb p p cb p p cb p p cb gpt .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
codellama 7b .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
codellama 13b .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
codellama 34b .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
llama 8b .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gpt .
gen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
drops in the pass occur when the adaptation size exceeds and .
the trend indicates that llms ability to accurately complete adaptations is negatively correlated with the scale of adaptations.
uni00000013 uni00000010 uni00000014 uni00000013 uni00000014 uni00000013 uni00000010 uni00000015 uni00000013 uni00000015 uni00000013 uni00000010 uni00000016 uni00000013 uni00000016 uni00000013 uni00000010 uni00000017 uni00000013 uni00000017 uni00000013 uni00000010 uni00000018 uni00000013 uni00000018 uni00000013 uni00000010 uni00000019 uni00000013 uni00000021 uni00000020 uni00000019 uni00000013 uni00000024 uni00000047 uni00000044 uni00000053 uni00000057 uni00000044 uni00000057 uni0000004c uni00000052 uni00000051 uni00000003 uni00000036 uni0000004c uni0000005d uni00000048 uni00000013 uni00000016 uni00000013 uni00000019 uni00000013 uni0000001c uni00000013 uni00000014 uni00000015 uni00000013 uni00000014 uni00000018 uni00000013 uni00000006 uni00000003 uni00000026 uni00000044 uni00000056 uni00000048 uni00000056 uni00000006 uni00000003 uni00000026 uni00000044 uni00000056 uni00000048 uni00000056 uni00000033 uni00000044 uni00000056 uni00000056 uni00000023 uni00000014 uni00000013 uni00000011 uni00000013 uni00000013 uni00000011 uni00000015 uni00000013 uni00000011 uni00000017 uni00000013 uni00000011 uni00000019 uni00000013 uni00000011 uni0000001b uni00000014 uni00000011 uni00000013 uni00000033 uni00000044 uni00000056 uni00000056 uni00000023 uni00000014 uni00000013 uni00000011 uni00000019 uni00000015 uni00000013 uni00000011 uni00000018 uni00000015 uni00000013 uni00000011 uni00000018 uni00000018 uni00000013 uni00000011 uni00000017 uni00000017 uni00000013 uni00000011 uni00000017 uni00000019 uni00000013 uni00000011 uni00000017 uni00000015 uni00000013 uni00000011 uni00000015 fig.
.
the distribution of the adaptation size and its relationship with the pass score of gpt .
model on the adaptation task.
finding gpt .
with the temperature of .
achieves the best adaptation performance.
however there is still a gap compared to generation.
besides llms adaptation performance decreases when the adaptation size rises.
e. rq2 issues in llms adaptations to obtain an in depth understanding of the issues of llms sub optimal adaptation performance we perform test analysis on the results of the most advanced model gpt .
with its best settings in rq1.
among selected cases there are a total of cases where all five adapted snippets passed all the tests.
there are cases where at least one adaptation passed the tests and cases where all adaptations failed.
uni00000024 uni00000056 uni00000056 uni00000048 uni00000055 uni00000057 uni0000004c uni00000052 uni00000051 uni00000028 uni00000055 uni00000055 uni00000052 uni00000055 uni00000031 uni00000044 uni00000050 uni00000048 uni00000028 uni00000055 uni00000055 uni00000052 uni00000055 uni00000037 uni0000005c uni00000053 uni00000048 uni00000028 uni00000055 uni00000055 uni00000052 uni00000055 uni00000024 uni00000057 uni00000057 uni00000055 uni0000004c uni00000045 uni00000058 uni00000057 uni00000048 uni00000028 uni00000055 uni00000055 uni00000052 uni00000055 uni00000056 uni00000054 uni0000004f uni0000004c uni00000057 uni00000048 uni00000016 uni00000011 uni00000032 uni00000053 uni00000048 uni00000055 uni00000044 uni00000057 uni0000004c uni00000052 uni00000051 uni00000044 uni0000004f uni00000028 uni00000055 uni00000055 uni00000052 uni00000055 uni00000032 uni00000057 uni0000004b uni00000048 uni00000055 uni00000028 uni00000055 uni00000055 uni00000052 uni00000055 uni00000003 uni00000037 uni0000005c uni00000053 uni00000048 uni00000013 uni00000014 uni00000018 uni00000013 uni00000016 uni00000013 uni00000013 uni00000017 uni00000018 uni00000013 uni00000019 uni00000013 uni00000013 uni0000001a uni00000018 uni00000013 uni00000006 uni00000003 uni00000028 uni00000055 uni00000055 uni00000052 uni00000055 uni00000056 uni00000019 uni00000017 uni0000001a uni00000003 uni0000000b uni00000016 uni0000001b uni00000011 uni00000017 uni00000008 uni0000000c uni00000015 uni0000001c uni00000013 uni00000003 uni0000000b uni00000014 uni0000001a uni00000011 uni00000015 uni00000008 uni0000000c uni00000015 uni00000019 uni00000018 uni00000003 uni0000000b uni00000014 uni00000018 uni00000011 uni0000001a uni00000008 uni0000000c uni00000015 uni00000016 uni0000001a uni00000003 uni0000000b uni00000014 uni00000017 uni00000011 uni00000014 uni00000008 uni0000000c uni00000018 uni0000001c uni00000003 uni0000000b uni00000016 uni00000011 uni00000018 uni00000008 uni0000000c uni00000014 uni0000001b uni0000001a uni00000003 uni0000000b uni00000014 uni00000014 uni00000011 uni00000014 uni00000008 uni0000000c uni00000018 uni00000014 uni00000013 uni00000003 uni0000000b uni00000018 uni0000001b uni00000011 uni00000019 uni00000008 uni0000000c uni0000001a uni00000017 uni00000003 uni0000000b uni0000001b uni00000011 uni00000018 uni00000008 uni0000000c uni0000001b uni00000014 uni00000003 uni0000000b uni0000001c uni00000011 uni00000016 uni00000008 uni0000000c uni00000017 uni0000001a uni00000003 uni0000000b uni00000018 uni00000011 uni00000017 uni00000008 uni0000000c uni00000014 uni00000013 uni00000003 uni0000000b uni00000014 uni00000011 uni00000014 uni00000008 uni0000000c uni00000014 uni00000017 uni0000001c uni00000003 uni0000000b uni00000014 uni0000001a uni00000011 uni00000014 uni00000008 uni0000000c uni0000002a uni00000033 uni00000037 uni00000010 uni00000016 uni00000011 uni00000018 uni00000010 uni00000024 uni00000047 uni00000044 uni00000053 uni00000057 uni0000002a uni00000033 uni00000037 uni00000010 uni00000016 uni00000011 uni00000018 uni00000010 uni0000002a uni00000048 uni00000051 fig.
.
the distribution of test error types of gpt .
s adaptation in total and generation in total .
errors with fewer occurrences are in the other category.table ii identified defects and their types regarding the origins defect defect inst.defect type inv ove une avg.
.
.
.
.
.
total ove inv andune denote overlooked invalid adapted and unexpected adapted respectively.
we first compare the distribution of test errors during the adaptation to that in generation as depicted in fig.
.
the total number of errors in the adaptation and generation task are and respectively.
the most prevalent error in both tasks is the assertionerror which indicates requirements are not fully satisfied in most failed cases.
it is worth noting that failed adaptations include more nameerrors typeerrors and attributeerrors accounting for .
of all adaptation errors.
specifically nameerrors and attributeerrors are caused by using undefined identifiers in the context.
typeerrors contain illegal operands access violations and method calls inconsistent with their signatures due to the misapplication of elements in the context.
the high proportion of these contextrelated errors highlights that adaptation exhibits less awareness of the target class context compared to generation.
through test analysis we obtain defects with instances from gpt .
adaptations across methods.
their types are illustrated in table ii.
in general each adaptation case contains an average of .
defects and .
instances.
among defect instances the overlooked category constitutes with instances where gpt .
overlooked preexisting defects in the given snippet.
invalid adapted defects account for which indicates gpt .
could not always resolve identified defects completely during the adaptation.
it is worth noting that there are also defect instances categorized as unexpected adapted e.g.
gpt .
wrongly transformed a static method to a non static one.
the above result indicates that gpt .
is less capable of addressing the pre existing defects in retrieved snippets that do not conform to requirements.
furthermore we compare the number of adaptations done by gpt .
with the required adaptation size i.e.
the number of ast edits needed to obtain the canonical solution by mann whitney u test.
as illustrated in fig.
the number of adaptations done by gpt3.
is significant smaller than required adaptations p .
mann whitney u test .
it only makes about half of the requiredtable iii causes forfailures in llm s adaptations category subcategory defect unclear requirementambiguous literal unspecific instruction requirement misalignmentmethod signature operational logic error edge case handling context misapplicationfield misapplication method misapplication environment related misapplication internal context misapplication adaptations on average.
the result implies that gpt .
is lazy and tend to maintain the original implementation in the given snippet by only making small scale adaptations leaving a number of overlooked defects.
therefore the primary challenge when adapting code with llms lies in effectively promoting them in identifying potential defects in previously memorized code snippets.
uni00000013 uni00000014 uni00000013 uni00000015 uni00000013 uni00000016 uni00000013 uni00000017 uni00000013 uni00000018 uni00000013 uni00000006 uni00000003 uni00000024 uni00000047 uni00000044 uni00000053 uni00000057 uni00000044 uni00000057 uni0000004c uni00000052 uni00000051 uni00000056 uni00000003 uni0000000b uni00000006 uni00000003 uni00000024 uni00000036 uni00000037 uni00000003 uni00000048 uni00000047 uni0000004c uni00000057 uni00000056 uni0000000c uni00000030 uni00000044 uni00000047 uni00000048 uni00000035 uni00000048 uni00000054 uni00000058 uni0000004c uni00000055 uni00000048 uni00000047 uni00000026 uni00000044 uni00000057 uni00000048 uni0000004a uni00000052 uni00000055 uni0000005c fig.
.
comparison between the number of adaptations gpt .
actually made and the required adaptation size.
finding among selected cases gpt .
s adaptations made more context related errors than generation indicating its context unawareness in adaptation.
the distribution of defect types and the actual adaptation size highlight its laziness on the adaptation task.
f .
rq3 root causes of llms failures though thematic analysis we further summarize the root causes of our identified defects.
as shown in table iii three major categories and nine subcategories are obtained.
unclear requirement refers to the adaptation failures where developers describe their requirements vaguely or ambiguously in the prompt.
llms can hardly identify the potential issues in the retrieved snippet and perform intended adaptations without a specific and accurate clarification.
under this category we identify two subcategories.
ambiguous literal developers requirement may include key concepts with multiple interpretations.
limited by the training data llms are prone to be misled by these ambiguous expressions and generate erroneous adaptations.
for instance the requirement of the calculate sector area method classeval specifying a parameter angle as angle of sector without indicating whether it is measured in degrees or radians.
likewise the fidelitypromo method classeval requires llms to calculate the discount without indicating whether the returned discount is a percentage arate or a numerical value.
llms failed in both cases as they misinterpreted the above concepts.
this subcategory indicates llms are sensitive to certain literals thus ambiguous ones may prevent llms from correctly adapting the snippet.
unspecific instruction developers may use overly concise language to describe their requirement making it difficult for llms to determine the specific details of the task or the desired outcome.
this issue is more serious in highly customized and complex task.
for instance the filter method classeval describes its requirement as filter the incoming request based on certain rules and conditions.
it is hard for llms to make adaptations without the specific constraints.
requirement misalignment refers to llms failures when aligning the function in the retrieved snippet to the requirement during the adaptation.
different from the unclear requirement category developers explain the instructions clearly in the requirement part.
this pitfall highlights llms preferences to overgeneralization instead of being restricted.
method signature this subcategory describes the misalignment of the signature of adapted method.
although we provide the correct and complete signature through the instructions llm s adapted method may mismatch the provided signature.
the issues include changing a static method to a non static one adapting the method with a new name wrongly adapting the parameter types or numbers returning a wrong type of value etc.
it indicates that llms inability to subject to the basic constraints for code.
operational logic this subcategory refers to llms failures to infer and adapt the specific operations the snippet performs including algorithms conditionals and how the code processes the inputs or achieves the desired outputs.
hence the mismatch of the adapted logic and the requirement leads to failed tests.
for instance the previous song method classeval requires the llm to switch to the previous song in the playlist and return false if there was no previous song.
the llm retained the looping logic through the playlist as shown in fig.
.
additionally llms may autonomously apply string case insensitivity i.e.
lower or round off numerical computations i.e.
round during the adaptation.
above cases indicate llms reasoning relies heavily on existing knowledge and statistically frequent solutions even when they conflict with proposed new requirements.
gpt .
adaptation example filtering rule ifrequest.get param allowed value filtered request request canonical solution ifcurrent index self.current song self.playlist gpt .5adaptation operation logic misalignment previous index current index len self.playlist self.current song self.playlist gpt .5adaptation mishandle the edge case ifinner radius outer radius return error inner radius must be smaller than outer radius.
inputorder.cart product product quantity price .
canonical solution n products len item for item in order.cart gpt .5adaptation field misapplication n products len set order.cart typeerror canonical solution formove inself.get possible moves current state new state self.move current state move gpt .5adaptation method misapplication fornext state inself.get possible moves current state canonical solutionpage reader.pages gpt .5adaptation environment related misapplication page reader.getpage page num deprecated api error information reader.getpage pagenumber is deprecated and was removed in pypdf2 .
.
.
use reader.pages instead.
canonical solutionself.cursor.execute update books set available where id ?
book id gpt .5adaptation wrong column name in table self.cursor.execute update books set status borrowed where id ?
book id fig.
.
a failed adaptation example for misalignment in operational logic .
error handling and edge cases this cause refers to llms inability to handle unexpected inputs and edge cases correctly focusing on the robustness aspect of their adapted code.
llms may ignore handling mishandling or overly handling the special case which caused the adapted method cannot pass all tests.
for example in the methodcalculate annulus area the llm mishandled the special case when the inner radius of the sector is equals to the outer radius.
it returned an error string instead of zero.
context misapplication refers to llms misuse of the context knowledge i.e.
data code internal representations.
we further divided it into four subclasses including field misapplication method misapplication environment related misapplication and internal context misapplication.
field misapplication this refers to llms misinterpretation and misuse of fields.
as shown in fig.
the cart field is a list of dictionaries representing different products.
the llm misinterpreted the semantics of the field and converted the list to a set leading to typeerror because the dict type is unhashable in python.
gpt .
adaptation example filtering rule ifrequest.get param allowed value filtered request request canonical solution ifcurrent index self.current song self.playlist gpt .5adaptation operation logic misalignment previous index current index len self.playlist self.current song self.playlist gpt .5adaptation mishandle the edge case ifinner radius outer radius return error inner radius must be smaller than outer radius.
inputorder.cart product product quantity price .
canonical solution n products len item for item in order.cart gpt .5adaptation field misapplication n products len set order.cart typeerror canonical solution formove inself.get possible moves current state new state self.move current state move gpt .5adaptation method misapplication fornext state inself.get possible moves current state canonical solutionpage reader.pages gpt .5adaptation environment related misapplication page reader.getpage page num deprecated api error information reader.getpage pagenumber is deprecated and was removed in pypdf2 .
.
.
use reader.pages instead.
canonical solutionself.cursor.execute update books set available where id ?
book id gpt .5adaptation wrong column name in table self.cursor.execute update books set status borrowed where id ?
book id fig.
.
a failed adaptation example for field misapplication .
method misapplication similarly method misapplication indicates llms method misuse e.g.
invoking wrong methods invoking them with wrong parameters misinterpreting the return value etc.
for instance in the solve method classeval the llm mistook the return value of getpossible moves method as the next state rather than the move for next state calculation leading to a typeerror .
gpt .
adaptation example filtering rule ifrequest.get param allowed value filtered request request canonical solution ifcurrent index self.current song self.playlist gpt .5adaptation operation logic misalignment previous index current index len self.playlist self.current song self.playlist gpt .5adaptation mishandle the edge case ifinner radius outer radius return error inner radius must be smaller than outer radius.
inputorder.cart product product quantity price .
canonical solution n products len item for item in order.cart gpt .5adaptation field misapplication n products len set order.cart typeerror canonical solution formove inself.get possible moves current state new state self.move current state move gpt .5adaptation method misapplication fornext state inself.get possible moves current state canonical solutionpage reader.pages gpt .5adaptation environment related misapplication page reader.getpage page num deprecated api error information reader.getpage pagenumber is deprecated and was removed in pypdf2 .
.
.
use reader.pages instead.
canonical solutionself.cursor.execute update books set available where id ?
book id gpt .5adaptation wrong column name in table self.cursor.execute update books set status borrowed where id ?
book id fig.
.
a failed adaptation example for method misapplication .
environment related misapplication this refers to llms misinterpretation of the environment i.e.
the scope boundary of the context and its available resources.
for instance llms may use unimported packages non existent methods or deprecated apis.
without the precise perception of the environment llms could also omit the package name leading to a series of nameerrors .
internal context misapplication this refers to llms inability to comprehend and operate the internal context e.g.
tables in the database.
as illustrated in fig.
the llm failed to identify the schema of the books table through its creation and wrongly applied an update operation to the table and caused sqlite3.operationalerror .
it raises the concerns for the implicit context when using llms to make adaptations in certain domain specific scenarios.
gpt .
adaptation example filtering rule ifrequest.get param allowed value filtered request request canonical solution ifcurrent index self.current song self.playlist gpt .5adaptation operation logic misalignment previous index current index len self.playlist self.current song self.playlist gpt .5adaptation mishandle the edge case ifinner radius outer radius return error inner radius must be smaller than outer radius.
inputorder.cart product product quantity price .
canonical solution n products len item for item in order.cart gpt .5adaptation field misapplication n products len set order.cart typeerror canonical solution formove inself.get possible moves current state new state self.move current state move gpt .5adaptation method misapplication fornext state inself.get possible moves current state canonical solutionpage reader.pages gpt .5adaptation environment related misapplication page reader.getpage page num deprecated api error information reader.getpage pagenumber is deprecated and was removed in pypdf2 .
.
.
use reader.pages instead.
canonical solutionself.cursor.execute update books set available where id ?
book id gpt .5adaptation wrong column name in table self.cursor.execute update books set status borrowed where id ?
book id fig.
.
a failed adaptation example for internal context misapplication .
finding the main causes for gpt .
s adaptation failures are requirement misalignment and context misapplication highlighting llms nature of overgeneralization and inattention to constraints.
besides unclear requirements may also influence their adaptation performance when necessary information are missing.
iii.
o urprompting approach our empirical results demonstrate that the adaptation performance of llms is sub optimal when using current instructionbased prompt denoted as initial prompt .
therefore to address the current pitfalls of llms we propose an interactive prompting approach to utilizing llms in code snippet adaptation.
we first enhance our prompt by enriching the context and decomposing the task.
the resulting prompt is denoted as enhanced prompt .
additionally we integrate an interactive workflow to the prompt based conversation through a flipped interaction process to utilize llms reflection ability.
it is implemented with two schemes one through a human llm collaboration and the other through a multi agent collaboration.
the resulting prompts are denoted as humanllm prompt andmulti agent prompt .
the detailed design is described in the following.
a. prompt enhancements enrich the context.
in real adaptation scenarios developers may possess complete method code in their context rather than merely a class skeleton.
therefore we first consider expanding the class context in the initial prompt to alleviate the context misapplication issue.
specifically we provide docstrings input output descriptions and complete implementations for all the methods independent from the target.
this information suggests the function and correct usage of contextual elements.
furthermore we extract and specify dependencies of the target method to alleviate the requirement misalignment issue.
it pushes llms to adapt the misaligned requirements with explicit dependency constraints.
we implement this by adding the following statements to the end of the instruction body it should be implemented using libraries fields methods .
or it should be implemented without using any external libraries member variables or methods.
decompose the task.
the adaptation prompt encompasses requirements the reused snippet and the class context.
its overwhelming information leads to llms misinterpretation of the requirements and the context.
we consider decomposing the adaptation task into context understanding and adaptationprediction process to further resolve the requirement misalignment andcontext misapplication issues.
specifically we re organize our prompt design as a multi turn conversation as described in the fig.
a .
in the first turn we only address the context understanding task by simply providing the class context.
the followed instruction makes llms understand the context but do not generate explanations to reduce costs.
in the second turn we require llms to predict adaptations.
splitting the lengthy prompt to shorter ones may alleviate llms burden of handling extremely long context and make them solve the task step by step.
remembering the target class context before adaptation could also refresh their pre existing knowledge hence addressing their overgeneralization nature.
b. interactive workflow integration our empirical findings suggest it is challenging for llms to adapt code snippets accurately in a single iteration particularly with unclear requirement .
drawing inspiration from the communication process between users and developers in software requirement elicitation we introduce a flipped interaction process into the prompting process.
its core idea is to utilize the reflection ability of llms.
specifically we require llms to assess the sufficiency and clarity of existing information for the adaptation task.
if llms are aware of any missed information or any confusion they could ask questions for more information in the subsequent conversation.
this process encourages llms to comprehend the adaptation task actively and to refine their memories with information they concern about.
to answer the raised questions we implement this interaction with the following two schemes.
human llm interaction.
the first scheme human llm prompt requires developers to provide feedback for llms questions as shown in fig.
b .
to enable a fair comparison with automated prompting approaches we provide theenhanced prompt for our participants to understand the requirement snippet and the target context.
similar to the automated prompting process our participants should repeatedly interact with llms times on each adaptation task to eliminate randomness.
to reduce the bias introduced by human repetition we required participants to provide consistent answers to the same or similar questions asked by llms during the experiment.
considering the communication overhead we conduct the human llm interaction on the selected cases with the best gpt .
model which costs human hours.
all participants have over five years of python programming experience which is qualified for the interaction.
multi agent interaction.
although experienced human developers can pinpoint the problems for adaptation it is timeconsuming for them to employ diagnoses and interactions in practices.
to alleviate the human overhead our second scheme multi agent counselor mac prompt enables the interaction based on a multi agent framework.
as illustrated in fig.
c we introduce another llm as the counselor.
in the first turn it is also initialized with the context understanding prompt.
then the counselor llm generates answers based ontable iv adaptation performance with enhanced prompt model pass pass codebleu gpt .
.
.
.
gpt .
enhanced .
.
.
w odocstring code .
.
.
w odependency .
.
.
w odecomposition .
.
.
the retrieved snippets and predefined instructions.
finally the executor llm accepts the answers and makes adaptations.
apart from the executor counselor interaction we implement an executor evaluator interaction workflow as a baseline denoted as multi agent evaluator mae prompt leveraging llms ability to assess generated code .
fig.
d illustrates its process.
an evaluator llm also initialized with the context understanding prompt reviews the adapted method generated by the executor llm.
then it generates a list of issues based on its assessment and instructs the executor to regenerated an adaptation to address the issues.
all agents above are profiled using role playing system prompts without further training or fine tuning.
configurations of the interactive workflow.
as we require llms to assess the sufficiency of information in the interactive workflow of the human llm and mac prompt it is uncertain when llms will terminate the conversation.
therefore we conducted a preliminary experiment to determine two relevant configurations the number of iterations and the number of questions.
to this end we randomly picked methods from outside of our selected cases and conducted the interaction with gpt .
where the question number was not restricted.
in all cases gpt .
generated code right after an iteration in which all the answers were provided.
they could ask up to questions with the average number is .
.
therefore as illustrated in fig.
our prompt limits llms to ask at most questions and extracts the code block after one iteration.
if no code block is provided the interaction will still be terminated and return an empty string.
iv.
e valuation in this section we evaluate the effectiveness of our prompt enhancements and interactive workflow on the adaptation task.
a. effectiveness of the enhanced prompt table iv presents the adaptation performance of prompting gpt .
with the enhanced prompt .
it achieves a pass score of .
and a pass score of .
which represents an improvement of .
and .
compared to theinitial prompt .
furthermore its codebleu increases from .
to .
marking a .
relative improvement.
the result indicates that enhanced prompt substantially enhances the performance of llms in the adaptation task.
we also conduct an ablation study to examine the effects of three prompt enhancements within the enhanced prompt .
among them enlarging the code context offers the most significant assistance to gpt .
.
it results in an .
gain in pass 1initial prompt class contextretrieved snippetinstruction enhanced promptdefadd states stat ...here istheadapted method add instructionclass context yes iunderstand .
instructionmulti agent prompt retrieved snippetinteract with counselor instructionclass context provided method i would like you to ask me at most questions to... q1 ... q2 ... the answers to your questions are listed below a1 ... a2 ... please write outtheadapted method .human counselor executor llmyes iunderstand .
defadd states stat ...here istheadapted method add defadd states stat ...here istheadapted method add instructionclass context provided method i would like you to ask me at most questions to... q1 ... q2 ... counselor llmyes iunderstand .
human llm prompt instructionclass context yes iunderstand .
instructionprovided method the answers to your questions are listed below a1 ... a2 ... please write outtheadapted method .
defadd states stat ...here istheadapted method add the issues of your adapted method are listed below i1 ... i2 ... please adapt themethod again based ontheissues .
defadd states stat ...here istheadapted method add defadd states stat ...here istheadapted method add evaluator llm multi agent prompt interact with evaluator executor llmexecutor llm a initial enhanced prompt initial prompt class contextprovided methodinstruction enhanced promptdefadd states stat ...here istheadapted method add instructionclass context yes iunderstand .
instructionprovided methodmulti agent prompt interact with counselor instructionclass context i would like you to ask me retrieved snippet at most questions to... q1 ... q2 ... the answers to your questions are listed below a1 ... a2 ... please write outtheadapted method .human counselor executor llmyes iunderstand .
defadd states stat ...here istheadapted method add defadd states stat ...here istheadapted method add instructionclass context provided method i would like you to ask me at most questions to... q1 ... q2 ... counselor llmyes iunderstand .
human llm prompt instructionclass context yes iunderstand .
instructionprovided method the answers to your questions are listed below a1 ... a2 ... please write outtheadapted method .
defadd states stat ...here istheadapted method add the issues of your adapted method are listed below i1 ... i2 ... please adapt themethod again based ontheissues .
defadd states stat ...here istheadapted method add defadd states stat ...here istheadapted method add evaluator llm multi agent prompt interact with evaluator executor llmexecutor llm b human llm prompt initial prompt class contextprovided methodinstruction enhanced promptdefadd states stat ...here istheadapted method add instructionclass context yes iunderstand .
instructionprovided methodmulti agent counselor prompt instructionclass context provided method i would like you to ask me at most questions to... q1 ... q2 ... the answers to your questions are listed below a1 ... a2 ... please write outtheadapted method .human counselor executor llmyes iunderstand .
defadd states stat ...here istheadapted method add defadd states stat ...here istheadapted method add instructionclass context i would like you to ask me at most questionsretrieved snippet to... q1 ... q2 ... counselor llmyes iunderstand .
human llm prompt instructionclass context yes iunderstand .
instructionprovided method the answers to your questions are listed below a1 ... a2 ... please write outtheadapted method .
defadd states stat ...here istheadapted method add the issues of your adapted method are listed below i1 ... i2 ... please adapt themethod again based ontheissues .
defadd states stat ...here istheadapted method add defadd states stat ...here istheadapted method add evaluator llm multi agent prompt interact with evaluator executor llmexecutor llm c mac prompt initial prompt class contextprovided methodinstruction enhanced promptdefadd states stat ...here istheadapted method add instructionclass context yes iunderstand .
instructionprovided methodmulti agent prompt interact with counselor instructionclass context provided method i would like you to ask me at most questions to... q1 ... q2 ... the answers to your questions are listed below a1 ... a2 ... please write outtheadapted method .human counselor executor llmyes iunderstand .
defadd states stat ...here istheadapted method add defadd states stat ...here istheadapted method add instructionclass context provided method i would like you to ask me at most questions to... q1 ... q2 ... counselor llmyes iunderstand .
human llm prompt instructionclass context yes iunderstand .
instructionretrieved snippet the answers to your questions are listed below a1 ... a2 ... please write outtheadapted method .
defadd states stat ...here istheadapted method add the issues of your adapted method are listed below i1 ... i2 ... please adapt themethod again based ontheissues .
defadd states stat ...here istheadapted method add defadd states stat ...here istheadapted method add evaluator llm executor multi agent evaluator prompt llmexecutor llm d mae prompt baseline fig.
.
illustrations of our proposed prompting approaches.
table v adaptation performance with interactive workflow on selected cases model pass pass codebleu gpt .
.
.
.
gpt .
enhanced .
.
.
gpt .
human llm .
.
.
gpt .
mac .
.
.
gpt .
mae baseline .
.
.
and an .
and pass .
the decomposition strategy is also effective marking a .
improvement in pass .
the dependency information exhibits a slight improvement in llms adaptation performance.
b. effectiveness of the human llm prompt the adaptation performance of the human llm prompt on our selected cases is shown in table v. it achieves the best performance among all prompt design.
guided with the human written response gpt .
obtain .
in pass and .
in pass respectively which outperforms the initial prompt by .
and .
.
however its codebleu value is slightly lower than the enhanced prompt .
the reason is that the executor tends to make adaptations corresponding to various questions that the counselor has asked leading to differences in the code structure.
the decrease in this heuristic metric does not harm the accuracy of adaptation results.
we further inspect how our identified defects are mitigated by our prompt enhancements and interactive workflow.
as shown in table vi the human llm prompt solves out of defects which accounts for .
.
our approach is effective in resolving defects across most categories particularly for method signature field misapplication andinternal context misapplication .
however two defects caused by unspecific instruction are still unresolved even with human feedback.
the reason may be that the task is highly customized and contains a wealth of contextual knowledge which could be hard to explain in the interaction.
as for the communicationtable vi mitigation of defects in adaptation cause gpt .
gpt .
human llm ambiguous literal .
unspecific instruction .
method signature .
operational logic .
error edge case handling .
field misapplication .
method misapplication .
environment related misapplication .
internal context misapplication total .
overhead totally and selective close ended and open ended questions are asked by the llm respectively.
for each case developers spend over minutes .
on average to review the context and synthesize an effective instruction which introduces immeasurable overhead in real scenarios.
therefore we investigate the possibility of enabling automatic interaction based on the multi agent workflow.
c. effectiveness of the multi agent prompt as illustrated in table v the mac prompt achieves .
.
and .
in pass pass and codebleu.
it could further improve the pass score by .
compared to the enhanced prompt .
for the mae prompt baseline it is inferior to the mac prompt on all metrics and obtains an extremely low pass even lower than the enhanced prompt .
it indicates that the evaluator tends to provide inaccurate feedback to the executor leading to extra erroneous adaptations.
note that although the human llm prompt still hits the ceiling with the best adaptation performance its human in the loop interaction may limit the practical use of this approach.
the mac prompt could be an excellent trade off between performance and overhead as supported by our experimental results.
to further explore the application of the mac prompt we evaluate its effectiveness with our instruction tuned llms on the whole classeval dataset.
we choose llms with the best performing settings i.e.
codellama 34b temp0.
and llama table vii adaptation performance with multi agent counselor prompt oninstruction tuned llm s model pass pass codebleu codellama 34b .
.
.
codellama 34b enhanced .
.
.
codellama 34b mac .
.
.
llama 8b .
.
.
llama 8b enhanced .
.
.
llama 8b mac .
.
.
8b temp0.
.
as shown in table vii our enhanced prompt also brings a clear benefit for instruction tuned llms.
our proposed mac prompt could further improve the pass pass and codebleu score of codellama 34b by .
.
and .
respectively.
for llama 8b the mac prompt results in a .
increase in pass but with a slightly decrease in the other two metrics.
the result highlights the generalization ability of our prompting approach.
both our prompt enhancements and interaction workflow are effective for the adaptation task regardless of the model.
finding our proposed prompt enhancements and interactive workflow greatly improve llms adaptation performance.
human llm interaction achieves the ideal performance and resolves most identified defects while our mac interaction can fully automate this process with a similar performance and no human intervention.
v. r elated work a. code snippet adaptation prior studies on adaptation mainly focus on improving the efficiency.
cottrell et al.
present jigsaw to integrate snippets into developers code which reduces their efforts on simple adaptations such as renaming.
wightman et al.
develop a lightweight eclipse plug in snipmatch.
it supports the search and integration of code templates in the code context.
zhang et al.
develop a chrome plugin examplestack to generate templates from developers historical modifications on code snippets.
reid et al.
propose nlp2testablecode to reduce the compilation errors during adaptation and generate tests based on input output types in the context.
terragni et al.
present apizator to transform code snippets on stack overflow to well formed methods.
however there is not a general purpose predictive approach for automated adaptation.
the emergence of llms provides opportunities for this task because of their strong natural language processing ability.
this paper explores their adaptation capabilities to provide insights for this research field.
b. prompt engineering for software engineering tasks modern llms have demonstrated their capabilities in various software tasks including code generation program repair and code maintenance .
enhancing llms performance in these domains often involves prompt engineering.
this includes handcraftedprompt design the chain of thought cot strategy and constructing effective demonstrations .
specifically liu et al.
improve code generation prompts using the cot strategy with multi step optimization.
cao et al.
explore various prompt templates for deep learningbased program repair.
rodriguez et al.
boost llms performance in software traceability by guiding them to perform intermediate reasoning.
gao et al.
focus on constructing effective demonstrations for code intelligence tasks.
these strategies have shown significant impact on their respective tasks but their applicability to other tasks i.e.
code snippet adaptation needs further exploration.
furthermore prior work has presented reusable prompting patterns for llms in software engineering .
white et al.
introduce a structured prompt framework with general patterns including the flipped interaction pattern which enables llms to gather information actively.
this pattern is further extended in our work to support requirement refinement in code snippet adaptation.
vi.
t hreats to validity internal validity.
the inherent randomness in llm outputs particularly in gpt .
can lead to various adaptations.
we mitigated this by requesting results five times from the llms and analyzing them using pass pass and codebleu metrics aiming for a more reliable assessment of their performance our study only considers using three popular llms due to the expense.
involving more and newer models could provide more insights and potentially improve the performance this paper focuses on utilizing llms for software reuse.
this paradigm could be changed when generative ais are powerful enough to build any software satisfying developers needs from scratch.
external validity.
in the snippet retrieval phase we use llm generated code instead of real snippets from opensource communities which may not fully represent real world adaptation scenarios.
to better understand llms adaptations future studies could build a comprehensive dataset based on developers adaptation practices e.g.
adaptations from stack overflow to further validate the generalization of our findings in this paper we construct the adaptation cases based on the handcrafted classeval dataset with only python methods.
however they may not fully capture the complexity and diversity of real world adaptation scenarios.
to support adaptations in a broad context future research could integrate an effective context retrieval module to our approach in real application scenarios our empirical study and experimental evaluation only focus on three representative llms.
different llms could have different distributions of their adaptation issues and root causes.
it is also worth investigating whether our approach is effective for other series of llms.
however our identification of llms failure reasons is actually independent of the model and our inspection on adequate samples could reveal useful findings to llms adaptations.
construct validity.
the human designed adaptation prompts in our study might not represent the optimal perfor mance for adaptation tasks.
there is potential for alternative possibly more effective prompts including those generated automatically by llms as suggested in other studies e.g.
liu et al.
.
this highlights a need for further exploration of prompt design methodologies the subjective nature of our manual analysis process could introduce biases.
to mitigate this we conduct our manual analysis in a rigorous manner.
our reported cohen s kappa indicates a high agreement between annotators and hence mitigate this threat to an extent.
nevertheless the potential for subjective interpretation remains a factor to be considered in the evaluation of our results.
vii.
c onclusion in this paper we first conduct an empirical study to explore llms capabilities in code snippet adaptation.
due to their sub optimal performance compared to code generation we further investigate the problems and causes by analyzing the adapted snippet along with their test results.
based on our empirical findings we propose an interactive prompting approach to mitigating current problems.
it enables the reflection ability of llms to improve their context awareness.
our evaluation result shows the effectiveness of our approach.
human llm interaction could achieve the best performance but introduce human efforts.
we propose a multi agent interaction that could achieve comparable performance as a trade off.
its generalization ability is also validated.
our research findings provide insights for llms current limitations and highlight the effectiveness of interactive prompting.
we believe that our approach could facilitate the practical application of llms in real world snippet reuse and adaptation.