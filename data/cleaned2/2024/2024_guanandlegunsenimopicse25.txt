instrumentation driven evolution aware runtime verification kevin guan cornell university ithaca ny usa kzg5 cornell.eduowolabi legunsen cornell university ithaca ny usa legunsen cornell.edu abstract runtime verification rv found hundreds of bugs by monitoring passing tests against formal specifications specs .
rv first instruments a program to obtain relevant events e.g.
method calls to monitor.
a hindrance to rv adoption especially in continuous integration is its high overhead.
so prior work proposed spec driven evolution aware techniques to speed up rv.
they use complex analysis to re monitor a subset of specs related to code impacted by changes.
but these techniques assume that rv overhead is dominated by monitoring time and their designs often sacrifice safety ability to find all new violations for speed.
we present imop the first instrumentation driven evolutionaware rv framework.
imop leverages a recent observation that rv overhead during testing is often dominated by instrumentation not monitoring.
imop embodies a family of techniques that aim to safely speed up rv by simply re instrumenting only changed code.
instrumentation from the old revision is re used for unchanged code and all specs are re monitored in the new revision.
we implement imop as a maven plugin and evaluate it on revisions of projects using specs of correct jdk api usage.
imop is safe by design.
it is up to .2x faster than rerunning rv from scratch after each change and .8x and .7x faster than safe and unsafe spec driven techniques respectively.
imop is faster than just applying regression test selection to rv.
i. i ntroduction runtime verification rv monitors executions of possibly buggy programs against formal specifications specs of correct or safe behavior.
practically rv checks if traces sequences of program actions such as method calls or field accesses satisfy the specs.
to do so rv first instruments a program to signal relevant program actions as runtime events .
then monitors usually automata are dynamically synthesized from the specs to check the traces.
a monitor raises a violation if a trace does not satisfy a spec.
each spec definition includes a handler user provided e.g.
errorrecovery code to run if violations occur.
thanks to decades of research rv is now being used to monitor deployed software .
so is appealing preemptive violation detection and sound error recovery can make deployed software always satisfy the specs .
so most rv research targets deployment time rv.
our work is on rv during testing before deployment.
researchers showed that using rv during testing amplifies the bug finding ability of tests.
they used handlers that print violations during rv of passing tests against specs of correct jdk api usage.
by inspecting those violations these researchersfound hundreds of confirmed bugs that testing alone missed in many projects .
increased bug finding ability occurs because specs provide additional test oracles that may be hard to express as test assertions.
ii has examples.
despite its bug finding benefits a main hindrance to rv adoption during testing especially in continuous integration is that it incurs high runtime overheads.
those overheads persist despite advances on algorithms and data structures for speeding up rv.
prior work proposed evolution aware techniques to speed up rv during testing of evolving software by focusing monitoring effort on code impacted by changes .
these techniques are spec driven use complex program analysis and work in three main steps.
given new and old code revisions and a set of specs multiple specs are monitored simultaneously i find code impacted by changes ii find a subset of affected specs that are related to impacted code and iii re monitor only affected specs in the new revision.
spec driven evolution aware rv techniques have two drawbacks.
first they assume that rv overhead is dominated by monitoring time to signal events create monitors process events etc.
.
so they may provide sub optimal speedups if rv overhead is not dominated by monitoring.
second of of them provide good speedups but they are designed to be unsafe i.e.
they may miss some new violations after code changes .
the other two are safe by design but slower.
we present imop the first framework for an alternate instrumentation driven approach to evolution aware rv.
mop m onitoring o riented p rogramming the rv style that we use.
imop is inspired by a recent study which found that over of rv overhead during testing in of projects is due to instrumentation.
in deployment time rv instrumentation is a one time start up cost.
but during testing these instrumentation costs should be reduced so that they are not entirely re incurred after every code change.
the idea behind imop is that amortizing instrumentation costs across code revisions can speedup rv during testing .
imop embodies a family of techniques that aim to speed up rv by simply re instrumenting only changed code.
the old revision s instrumentation is re used for unchanged code and all specs are re monitored in the new revision.
that way imop reduces costs of unnecessarily re instrumenting unchanged code in the new revision.
ieee acm 47th international conference on software engineering icse .
ieee first identifies changed code then it re instruments only changed code using all specs.
lastly an rv tool monitors the instrumented code.
imop techniques differ in i the granularity level at which they find changes ii whether they are specific to an instrumentation framework or work with any framework and iii if they re instrument all changed code in 3rd party libraries or only changed library code that is used.
imop techniques are agnostic orspecific to instrumentation frameworks.
we propose agnostic techniques and realize a 12th.
the other two techniques are specific to aspectj which is used in javamop the rv tool in this paper we are the first to evaluate them for rv.
separately eight techniques are usage unaware they re instrument changed library classes even if the monitored program does not use them.
the other six techniques are usage aware and aim to avoid re instrumenting changed but unused library classes.
we implement imop as a maven plugin.
our evaluation ofimop involves using it to monitor the execution of developer written tests in revisions of projects using specs of correct jdk api usage protocols.
imop is up to .2x mean 10x faster than full rv rerunning rv from scratch after each change and up to .8x mean .8x and .7x mean .4x faster than the fastest safeby design and fastest unsafe by design spec driven techniques respectively.
across all projects imop saves up to .
hours compared to full rv and .
hours and .
hours compared to safe and unsafe spec driven techniques respectively.
to evaluate safety we compare sets of new violations from imop full rv and spec driven techniques.
usage unaware imop techniques are as safe as full rv usage aware ones are at least as safe as safe spec driven techniques.
lastly we compare and combine imop with regression test selection rts which speeds up regression testing by only re running tests impacted by changes .
we integrate two rts tools ekstazi and starts with imop and compare speedups from combining rts with i full rv ii safe and unsafe spec driven techniques and iii the best imop technique in projects.
imop is faster than just applying rts to full rv but imop plus rts provides more speedup than imop alone on some projects.
this paper makes the following contributions framework.
imop is the first instrumentation driven evolution aware rv framework and realization of the idea to speed up rv by amortizing instrumentation costs .
techniques.
we propose of imop s techniques and we are the first to evaluate two of the other three for rv.
implementation.
we implement imop for java as a maven plugin that integrates easily with open source projects.
combination.
we compare and combine rts with instrumentation driven evolution aware rv techniques.
evaluation.
we conduct the largest evaluation of evolutionaware rv and the first evaluation of imop s safety and applicability to multiple instrumentation frameworks.
our plugin scripts and experimental data are available at i 2event hasnexttrue after stringtokenizer st returning boolean b call boolean stringtokenizer.hasmoretokens call boolean stringtokenizer.hasmoreelements target st condition b 4event next before stringtokenizer st call stringtokenizer.nexttoken call stringtokenizer.nextelement target st 6ltl next hasnexttrue violation print violation fig.
sthm spec written in an aspectj based dsl.
1synchronizedcollection collection c iterator i 2collection c 3event sync after returning collection c 4call collections.synchronizedcollection collection this .c c 5event syncmakei after collection c returning iterator i 6call collection .iterator target c condition thread.holdslock c 7event asyncmakei after collection c returning iterator i 8call collection .iterator target c condition !thread.holdslock c 9event usei before iterator i 10call iterator.
.. target i condition !thread.
holdslock this .c 11ere sync asyncmakei sync syncmakei usei match print violation fig.
csc spec written in an aspectj based dsl.
ii.
e xamples and background specs and how rv monitors them .
to monitor the stringtokenizer hasmoreelements sthm spec in figure rv first instruments the monitored program based on events defined on lines .
each definition includes i an event name like hasnexttrue on line that is used to specify properties ii relevant program actions for each event e.g.
hasnexttrue captures calls to hasmoretokens orhasmoreelement on a stringtokenizer st that return true while next captures calls to st.nexttoken or st.nextelement and iii whether to signal events before orafter these calls.
at runtime rv synthesizes monitors to process events that are signaled from the instrumented code.
sthm s monitors check if traces satisfy the linear temporal logic ltl safety property on line always a next event on stimplies that the previous event on stwas hasnexttrue .
if a trace does not satisfy this property the handler on line is invoked.
handlers can be any user provided code.
but for rv usage during testing we print a message to aid debugging.
sthm helped find bugs in code that can crash by calling nexttoken ornextelement on an empty st .
the monitored tests always pass because all input stwere not empty but inspecting sthm violations helped find the bugs.
we need at least two specs to explain spec driven techniques.
so figure shows the synchronizedcollection csc spec whose safety property on line is violated if a trace matches one of two cases.
i a synchronized collection c is created sync lines but an iterator i is then created from code that does not hold the lock on c asyncmakei lines .
ii after a sync event one correctly creates i from code that holds the lock on c syncmakei lines but then later uses iin code that does not hold the lock on c usei lines .
code producing such traces can be nondeterministic .
cscalso helped find several bugs .
1041public class a 2public static string a list string list 3collection string c 4collections.synchronizedcollection list instr csc.sync 5iterator string i c.iterator instr csc.asyncmakei 6boolean b instr csc.usei !i.hasnext 7return b ?
null instr csc.usei lib1.lower i.next 9class atest test public void testa list string l arrays.aslist new string foo assertequals foo a.a l 14public class b 15public static string b string s string out none string out nil 18stringtokenizer t new stringtokenizer s 19if t.hasmoretokens instr sthm.hasnexttrue instr sthm.next out t.nexttoken lib2.process out return out 23public class btest test public void testb assertequals f b.b f b fig.
example of instrumented code and unit tests.
instrumentation .
figure shows old and new revisions of example code classes aandb and tests classes atest and btest .
the code uses library classes lib1 line and lib2 line which have call sites for csc andsthm events respectively that we elide.
the new revision assigns nil to outinstead of none .
before monitoring the tests against csc andsthm in both revisions full rv first instruments the code based on csc andsthm event definitions violet comments .
spec driven evolution aware rv techniques .
the main idea in spec driven techniques is that specs that are not affected by changes need not be re monitored in the new revision.
so yields the same monitoring outcome as in the old revision for those specs assuming deterministic tests .
so in figure the class level change impact analysis used by specdriven techniques first finds only bandbtest as impacted by the change.
csc is unrelated to bandbtest sosthm is the only affected spec that is re monitored in the new revision.
if rv overhead is dominated by monitoring csc then rv can be much faster in the new revision.
fast spec driven techniques are unsafe by design their less conservative change impact analysis can make them miss affected specs.
iv gives more details on the two spec driven techniques in this paper.
instrumentation driven evolution aware rv techniques .
in figure suppose full rv instruments only cscinaandlib1 and only sthm inbandlib2 .
also assume that the only change is the one shown.
then our imop techniques aim to only re instrument bafter the change.
so only of classes are re instrumented.
by re monitoring all specs in the new revision these imop techniques are safe by design.
iii.
imop a. overview figure is a high level overview of imop it abstracts away individual techniques details.
conceptually imop s inputs are i old and new revisions of the code under test cut including source code and tests ii a list of required 3rd party library e.g.
jar paths and their declared versions e.g.
.
.
that the cut uses in both revisions iii checksums of .class fig.
imop s high level workflow.
files in the old revision iv the specs and iv a config file with the imop technique to use whether to ignore changes to debug information line numbers comments space etc.
thread count to use whether to check if the cut uses changed library classes and the instrumentation framework to use.
imop works in five main steps.
the diff engine step takes both revisions of the cut and the library paths and finds .class files that changed.
if so configured the diff engine can use bytecode cleaner step to find only changed .class files where non debug information changed and compute their checksums for the next revision.
files where only debug information changed need not be re instrumented but reasoning about debug information incurs a cost .
if bytecode cleaner is used changed classes are .class files whose bytecode checksums after ignoring debug information in the new revision differ from those in the old revision.
diff engine can also be configured to call usage checker step which checks if changed library classes are used by the cut.
unused changed classes need not be re instrumented.
so is wasteful the new revision s monitoring outcome cannot depend on unused classes.
but checking usage incurs a cost.
instrumentation engine step re instruments in sequence or in parallel only diff engine s output using the configured framework default aspectj .
instrumentation from the old revision is re used for all other unchanged classes.
finally imop invokes an rv tool step to monitor the instrumented cut and libraries and report any violation.
to bootstrap all cut and library classes are treated as changed in the first revision.
note that figure is conceptual e.g.
the old and new revisions may not be explicit inputs iii b .
b. techniques design rationale .
realizing the simple idea behind imop requires addressing the technical challenge of simultaneously i speeding up rv by finding and re instrumenting ideally only changed code ii preserving safety and iii aiming for overheads that approach a lower bound of full rv minus instrumentation costs.
meeting all three goals requires carefully balancing the tradeoffs that they induce.
in brief the tradeoff space is as follows.
more precise change identification can reduce re instrumented classes and help goal i but its analysis can be more costly and hurt goal iii .
also analyzing libraries is necessary for safety and helps goal ii but so increases analysis cost and hurts goal iii .
coarse grained analysis of libraries e.g.
by treating a jar as changed if any of its contents changed can be faster and help goals ii and iii .
but such analysis can lead to unnecessary re instrumentation hurting goal i if whole jar instrumentation is costly.
lastly using more threads can speed upimop but it requires more hardware resources.
105table i imop techniques and the notation that we subequently use for them.
table ii explains the notation.
instrumentation target notation usage unaware agnostic of instrumentation framework iii b1 whole changed jars online sequential ujs o all class files in changed jars online parallel ujp o changed class files in changed jars online sequential ucs o changed class files in changed jars online parallel ucp o changed bytecode in changed jars online sequential ubs o changed bytecode in changed jars online parallel ubp o changed bytecode in changed jars stored hashes sequential ubs h changed bytecode in changed jars stored hashes parallel ubp h usage aware agnostic of instrumentation framework iii b2 changed bytecode used by cut at runtime sequential absd h changed bytecode used by cut at runtime parallel abpd h changed bytecode reachable statically by cut sequential abss h changed bytecode reachable statically by cut parallel abps h usage aware specific to aspectj instrumentation framework iii b3 compiler determined changed class files default loader ajcdef compiler determined changed class files shared loader ajcone design justification .imop embodies a family of simple techniques of which we propose at different points in the tradeoff space.
most of these techniques perform best in at least one project iv suggesting that there is no one sizefits all technique that works for all projects and justifying our design of imop to have several techniques.
running example .
we will use figure to illustrate how fig.
running example.some imop techniques work.
there classes c1 c2 and t a test class are in the cut while classes l1 l4are in libraries.
edges show usage e.g.
the arrow from c2toc1means c2uses c1 .
purple colored classes changed.
l1is colored pink because its .class file changed but its bytecode did not.
for any code change full rv re instruments all classes in figure .
imop aims to reduce wasted re instrumentation.
design details .
for ease of presentation we organize imop s techniques into three groups in table i. these techniques primarily differ in how they handle libraries they all reinstrument only changed cut classes in sequence which is fast few cut classes typically change at once .
techniques that check for changed bytecode in changed jars also check for changed bytecode in cut classes.
we next discuss how each technique handles changes in 3rd party libraries.
usage unaware framework agnostic techniques eight imop techniques are usage unaware u they reinstrument changed library code without incurring the cost to check if the cut uses such changed code.
these techniques are also agnostic and can work with any instrumentation framework.
two of these techniques re instrument an entire changed library j .imop treats a library as changed if it i was not on the old revision s classpath ii has different declared versions in both revisions or iii has changed contents.
one technique ujs o table ii explains the notation re instruments changed libraries sequentially.
the othertechnique ujp o re instruments all changed library classes in parallel.
in figure ujs oandujp owill re instrument table ii notation key.
meaning first uppercase letter u usage u naware a usage a ware second uppercase letter j finds changed j ars c finds changed c lass files b finds changed b ytecode first superscript position s re instruments s equentially p re instruments in p arallel second superscript position d checks usage d ynamically s checks usage s tatically subscript o checks changes o nline h checks changed h ashesclasses t l1 l2 l3 and l4because at least one library class changed.
ujs oand ujp ocan be fast if library changes are small or occur infrequently.
otherwise reinstrumenting whole libraries can be expensive .
to reduce wasted reinstrumentation in libraries six usage unaware imop techniques aim to reinstrument only changed library classes without incurring the cost to reason about whether the cut uses those classes.
these techniques are as follows ucs ouses diff to compare .class files in both versions of libraries and re instruments only those that differ.
in figure though the library changed ucs oonly re instruments t l1 l2 and l3 it does not re instrument the unchanged l4.
ubs ofirst cleans changed .class files to ignore their debug information then it checks if the resulting bytecode was modified.
changing only debug information modifies .class files but not the bytecode that is run.
lastly only modified .class files with changed bytecode are re instrumented.
ubs his similar to ubs o but it pre computes some steps in the old revision to reduce analysis time in the new revision.
in the first run ubs hstores a checksum of bytecode in each .class files on disk.
then for each changed .class file in a new revision ubs hcomputes and compares the checksum of its cleaned bytecode with the one it loads from disk.
if the checksums differ then ubs hre instruments the .class file and updates the corresponding checksum on disk.
ubs oandubs honly re instrument t l2 and l3 they do not re instrument l1 whose .class file changed but its cleaned bytecode did not.
ucs o ubs o andubs hre instrument all such .class files in sequence.
their parallel analogs ucp o ubp o andubp h respectively use multiple threads.
usage aware framework agnostic techniques four agnostic techniques are usage aware a they aim to only re instrument bytecode that changed and that the cut uses.
such used .class files with changed bytecode can be fewer than those in iii b1 saving re instrumentation time .
but to achieve end to end speedup checking for usage must be fast.
absd hfinds used classes loaded as those that the jvm loads.
then it re instruments only .class files in loaded whose cleaned bytecode changed.
using loaded from an old revision to choose what to re instrument in a new revision is unsafe changes can cause more classes to be loaded in the new revision.
so absd hruns tests twice in the new revision i run tests without rv to update loaded ii find clean 106table iii features in each imop technique.
feature is present.
feature is absent.
n a not applicable.
ujs oujp oucs oucp oubs oubp oubs hubp habsd habpd habss habps hajcdefajcone incremental cut instrumentation incremental lib instrumentation framework agnostic one cache per loader n a n a n a n a n a n a n a n a n a n a n a n a usage aware check usage statically parallel re instrumentation lib check bytecode difference check class file difference store old hashes n a n a n a n a and re instrument changed .class files in loaded whose bytecode changed and iii re run tests with rv.
abss hfinds used classes reachable as those reachable from cut nodes in a statically computed class dependency graph cdg .
in brief cdg nodes are types .class files in code tests or libraries.
there is a directed edge from node a to node bifacan use b. also bis reachable from aif there is a path from btoa.
first abss hgenerates cdg.
for new jars abss hinstruments .class files that are in reachable .
if a jar is updated then the .class files to re instrument are obtained as those in reachable whose cleaned bytecode changed.
lastly even if a jar did not change changes to the cut can alter the control flow such that previously unused and un instrumented library classes are now used in the new revision.
in this case abss hfinds and instruments all .class files that are not in the old cdg s reachable but are in the new cdg s reachable .
the new cdg is saved to disk.
in figure abss handabsd hwill only re instrument tandl2 they will not re instrument l3 which changed but is not used by any cut class.
absd handabss hre instrument all identified .class files in sequence.
their parallel analogs abpd hand abps h respectively use multiple threads.
abss handabps hare safe by design.
but in practice their safety depends on the soundness of the static analysis used to build the cdg.
usage aware framework specific techniques some instrumentation frameworks e.g.
aspectj s ajc are compilers.
so they may already support incremental instrumentation that can be exploited for evolution aware rv.
native framework specific incremental instrumentation can be fast.
but there are disadvantages .
supporting incremental compilation is hard and can make imop slower if there are many classes to re instrument or unsafe if bugs in the compiler make it fail to re instrument some changed classes .
.
rv tool developers may not have expertise to fix compiler bugs or integrate better with rv so the resulting instrumentation driven techniques may become reliant on compiler developers who are already pressed for time.
.
some general purpose e.g.
asm bcel disl javassist and rv inspired e.g.
bism frameworks do not support incremental instrumentation.
others e.g.
bytebuddy support incremental instrumentation of cut but not libraries.
.
compiler specific incremental instrumentation could makeit harder for rv tool developers to switch among these instrumentation tools leading to vendor lock in .
two imop techniques are aspectj specific javamop the rv tool that we use in this paper uses aspectj.
also of rv tools for java in a publicly available list that is crowdsourced by the rv research community also use aspectj for instrumentation.
so our results may generalize beyond javamop.
lastly we discovered experimental support for incremental instrumentation in the aspectj compiler s ajc source code .
this support is not part of aspectj s public or advertised apis or options.
the advertised support does not work for libraries so it is unfit for imop.
we next describe these two ajc specific imop techniques.
ajcdefstores checksums of all loaded .class files cut plus libraries that it instruments in the old revision.
then in the new revision it compares checksums of loaded .class files with those from the old revision.
if a .class file s checksums in both revisions are the same then the instrumented .class file from the old revision is fetched from a cache and re used in the new revision.
if the checksums differ then the .class file in the new revision is re instrumented added to the cache and its checksum is updated for use in the next revision.
ajcdefuses one cache per classloader.
ajconeworks like ajcdef but it uses one cache for all classloaders.
ajcone s caching also uses a slower data structure.
in figure ajcdefandajconewill re instrument t l1 and l2even though l2 s cleaned bytecode did not change.
that is these framework specific techniques would imprecisely reinstrument a changed .class file even if its bytecode has not changed since the old revision.
summary of imop techniques .
table iii summarizes imop techniques main features for ease of reference.
c. implementation we implement imop s workflow figure and techniques iii b in a maven plugin for easier integration with mavenbased java projects.
after installation users only need to change a few lines in a maven configuration file pom.xml .
we only implement imop for maven to focus our evaluation on the techniques which are not maven specific.
future work can support other build systems.
we choose javamop because it was evaluated at scale during testing of open source projects .
it is not clear that other rv tools can simultaneously monitor specs during software testing.
some rv tools 107table iv summary statistics on projects that we evaluate no.
of test methods tests test time w o rv in seconds t lines of code sloc statement coverage covs branch coverage covb no.
of github commits shas years since first commit age and no.
of stars .
tests t sloc covscovb shas age mean .
.
.
.
.
.
.
.
med .
.
.
.
.
.
.
.
min .
.
.
max .
.
.
.
sum .
.
105n a n a n a n a can only check one spec at a time which would mean at least a 160x overhead in our case.
others require some manual setup that would not be feasible at our scale.
imop uses the same code for checking bytecode level changes that is used in several open source rts tools and emop .
also imop uses jdeps and starts to build the cdg iii b2 .
but we extend starts to also include library classes in the cdg starts only reasons about changed libraries at the coarsegrained level of jars.
to find loaded classes absd handabpd h imop first runs tests with the verbose class jvm flag and post processes the output.
imop only invokes javamop for monitoring preventing it from re instrumenting the code.
lastly to integrate imop with ajc iii b3 we runajc with the aj.weaving .cache .enabled true and aj.weaving .cache .impl shared options.
iv.
e valuation we answer the following research questions rq1 .
how do the runtime overheads of imop s techniques compare with those of existing approaches?
rq2 .
how does the safety of imop s techniques compare with those of existing techniques?
rq3 .
how do imop s speedups compare to those from just applying regression test selection rts to full rv?
rq4 .
how do internal metrics of imop s techniques compare with those of existing techniques?
rq1 measures imop s overheads comparing it with those of full rv and two spec driven techniques.
rq2 measures imop s safety and compares it with those of two spec driven techniques.
rq3 combines and compares imop with regression test selection rts .
rq4 assesses imop s internals.
a. experimental setup evaluated projects and specs .
we evaluate imop on revisions of open source projects using specs of correct jdk api usage.
table iv shows summary statistics on the evaluated projects the caption describes the columns and n a are meaningless sums.
full per project statistics are in our appendix.
projects are from the instrumentationdominated having the largest differences in total rv time minus monitoring time ones used in guan and legunsen s study to evaluate a proof of concept vii compares with that work in more detail .
we exclude one of the37 projects from guan and legunsen s study because of a limitation which caused our bytecode cleaning infrastructure to fail on that excluded project.
evaluated projects are from the instrumentation dominated ones from emop s evaluation that we can run we exclude others because their tests failed during our experiments.
finally we select an additional projects from guan and legunsen s study they are the next most instrumentation dominated ones that were not used to evaluate the prototype in that study.
for all projects from prior work we use the same github revisions as those prior works per project.
for the other we select up to historical revisions from github where at least one java file changed code compiles and tests pass with and without javamop and imop.
the specs that we use are from prior work they were used to evaluate rv during testing and helped find many bugs that testing alone missed.
baselines .
we compare imop to full rv re running javamop s evolution unaware rv from scratch after every change two spec driven techniques and trv the best possible theoretical lower bound on rv overhead which assumes an ideal instrumentation time of zero measured as full rv time minus instrumentation time.
we next summarize the two specdriven techniques that we compare with using the names psc andpscl that their authors use see full details in .
psc 1is the faster of two safe by design spec driven techniques.
psc 1first finds classes impacted by code changes as those i whose cleaned .class file changed ii that transitively depend on dependents iii that transitively depends on and iv that and its dependents can pass data to.
then psc 1finds affected specs as those related to impacted classes.
lastly psc 1re monitors only affected specs but it does not instrument them in un impacted classes.
the idea is that if the set of impacted classes is small then affected specs are likely to be a small subset of all available specs.
in contrast to psc pscl 3is the fastest of unsafe by design techniques that are deliberately designed to trade safety for speed.
an evolution aware rv technique is safe if it finds all new violations after a code change .
pscl 3can miss new violations after a code change because it i only finds impacted classes as and its dependents and ii does not instrument 3rd party libraries not even used library classes .
we use the psc 1andpscl 3implementations in emop .
running experiments .
we write maven extensions to integrate javamop imop emop and a profiler rq4 into evaluated projects.
we write scripts to run tests run rv and analyze results.
we run all experiments in docker containers to aid reproducibility.
our artifact has our docker files and how to use them.
we use an intel xeon gold machine cores with 512gb of ram running ubuntu .
.
lts and java to run experiments that report absolute time.
b. rq1 runtime overheads aggregated results .
figure shows the results of our performance evaluation.
there we show absolute times and relative 108fig.
absolute and relative overheads across all projects.
blue bars safe by design techniques.
olive bar unsafe by design spec driven pscl .
red bar a safe by design framework specific ajcdefthat fails in of projects.
table v summary statistics on speedups per project by the best performing framework specifc and framwork agnostic imop technique relative to full rv mop psc pscl and full rv minus instrumentation time trv .
mop agnosticmop specificpsc agnosticpsc specificpscl agnosticpscl specificagnostic trvspecific trv mean .
.
.
.
.
.
.
.
med .
.
.
.
.
.
.
.
min .
.
.
.
.
.
.
.
max .
.
.
.
.
.
.
.
overheads when times are summed across all projects excluding the initial revision in each project.
absolute time is the end to end time from maven invocation to termination.
relative overhead is the ratio of time to run evolution aware rv to time to run tests without rv the lower the better.
the yellow line in figure marks the time to run tests without rv.
the red line marks trv time.
the relatively small time difference see legend between the red and yellow lines shows that instrumentation not monitoring dominates rv overhead during testing in these projects.
figure shows that all simple framework agnostic safe bydesign imop techniques speedup full rv mop and outperform both psc 1andpscl .
in aggregate these imop techniques are .1x .6x faster than full rv .7x .9x faster than safe psc and .2x .1x faster than unsafe pscl despite the fact that we did not sacrifice safety in their design.
across all projects and their revisions imop saves up to .
hours compared to full rv and saves .
hours and .
hours compared to safe and unsafe spec driven techniques respectively.
figure also seems to show that framework specific ajcdef provides good speedups compared to full rv psc 1andpscl and that ajcdefseems to be faster than of agnostic imop techniques.
but these results are inconclusive ajcdef s instrumentation fails in projects.
ajcone the other safe framework specific technique does not fail in any project but it is slower than all imop s agnostic techniques.
however ajconeis .5x faster than psc 1and .3x faster than full rv.
we asked ajc developers if ajcdeffailures are due to bugs .
their response reinforces our sense that frameworkspecific incremental instrumentation is hard to get right and may be unreliable.
an ajc maintainer i pointed us to a similar bug report whose solution did not fix our issues ii confirmed that the problem was in ajcsince at least and iii said if incremental instrumentation ever worked ... and just broke a long time ago or if it never worked ... is yet to be established .
worse the maintainer has now quit the aspectj project and may no longer contribute without financial support .
we therefore exclude ajcdef s result from timed experiments if its instrumentation fails on a project.
more detailed results .
table v shows summary statistics on speedups per project our appendix has more data e.g.
bestperforming technique per project .
there agnostic techniques are up to .2x mean 10x .8x mean .8x and .7x mean .4x faster than full rv psc and pscl respectively.
the corresponding numbers for framework specific techniques are .8x mean .2x .8x mean .9x and .4x mean .5x .
so on a per project basis agnostic techniques tend to provide more speedups than framework specific ones.
the .1x minima in table v are for a project where psc 1andpscl outperform the best framework specific technique ajcdeffails andajconeis very slow on that project .
the two rightmost columns in table v show how much slower imop s best performing techniques are compared to trv the best theoretical lower bound on rv overhead that assumes zero instrumentation cost .
there min is how closely imop approaches trv.
at best imop is faster than trv which is evolution unaware and may run tests with monitoring even if changes do not modify cleaned bytecode.
on average the best performing agnostic imop technique is max .2x slower than trv.
these trv related results show how closely imop approaches theoretical evolutionunaware rv with no instrumentation cost.
figure shows how often the speedup achieved by each technique is among the top three darker colors mean higher rank and each row sums up to the number of evaluated projects .
such ranking is not visible from the aggregated results figure .
our appendix has a full ranking and all techniques rank per project.
we make five main observations .
there is no universally best imop technique imop techniques provide the best speedup in at least one project.
also each imop technique except ajconeis in the topthree at least three times.
this result justifies having several imop techniques and exploring the tradeoff space iii .109fig.
heat map showing how often a technique provides one of the top three speedups per project.
the top middle and bottom rows show no.
of projects where a technique provides the best 2nd best and 3rd best speedup respectively.
table vi safety results for two spec driven techniques and imop before pre and after post our manual inspection.
psc 1pscl 3ujs oujp oucs oucp oubs oubp oubs hubp habss habps habsd habpd hajcdefajcone missed new violations pre of missed new violations post of unsafe revisions pre of unsafe revisions post of unsafe projects pre of unsafe projects post of .
agnostic techniques provide the best speedups in projects.
this result may be affected by ajcdef s failures but it suggests that continued improvement of agnostic techniques would be worthwhile.
.
when agnostic techniques provide the best speedup usageunaware ones perform best in projects.
so the added complexity of checking if changed library code is used by the cut is not needed in a good fraction of projects.
.
surprisingly absd handabpd h which run tests twice provide the best speedup in projects.
.imop outperforms spec driven techniques in all but two projects where imop is just two and six seconds slower.
the important question of how users should choose what imop technique to use requires more research.
v discusses initial observations from our qualitative analysis.
c. rq2 safety table vi shows the results of our safety evaluation.
a safe evolution aware rv technique finds all new violations after a code change .
in coming up with this definition of safety legunsen et al.
assume a setting where users are aware of violations in the old revision and are more interested to see new violations after code changes .
to find new violations we run violation message suppression vms an evolution aware rv technique that reduces human time to inspect violations it does not reduce runtime overhead.
vms hides violations in unchanged lines of code users can view hidden violations but only new ones are shown by default.
we run emop s vms implementation on full rv in a separate un timed experiment and report numbers of missed vms reported violations before pre rows and after post rows our manual inspection.
the 1st 3rd and 5th rows show numbers of missed vms reported violations number of revisions with a missed violation and number of projects with an unsafe revision before inspection respectively.
the 2nd 4th and 6th rows show these numbers after inspection.
our inspection shows that of vms reported violations are not related to changes difference between the 1st and 2nd rows in the first column of table vi .
rather they are due to non deterministic test executions violations false positives or bugs in vms violations or falsepositives due to bytecode cleaning in imop misleading vms about line numbers violations .
precisely matching lines of code locations across revisions is hard leading to vms false positives.
we have reported two related vms bugs to the emop developers .
after inspection we find that imop techniques all eight usage unaware imop techniques and three of six usageaware ones are safe in our experiments.
among the three usage aware techniques that miss a new violation the overall ratio of unsafe revisions is small .
.
.
these safety results are encouraging.
also imop finds violations that spec driven techniques miss.
if all imop s techniques find a violation but at least one spec driven technique does not and we find no evidence of test non determinism we count that violation as being missed by that spec driven technique.
we analyze why new violations are missed to better understand how to make imop s techniques safer in practice.
abss handabps huse static analysis and miss new violations related to using reflection to load classes.
ajcdefmisses new violations that are due to ajc failures during instrumentation.
note that these techniques are safe by design unlike the unsafe by design techniques in we did not deliberately design them to be unsafe .
future work is needed to also make the implementations of three of techniques safe.
unsurprisingly pscl spec driven and unsafe by design is the most unsafe in our experiments it misses new violations .
are due to pscl s use of a less conservative than psc static analysis to find affected specs to re monitor.
the other seven are due to two bugs in emop s implementation that we have reported .
psc safe by design misses violations due to the same emop bugs that affect pscl .
we conclude that usage unaware imop techniques should be used when safety is critical they are safe faster than unsafe pscl simple and often provide the best speedups.
other settings can use faster usage aware techniques two of them are imop s fastest techniques figure but they show very small degrees of unsafety that should be improved in the future.
d. rq3 comparison with rts evolution aware rv re runs all tests in a new revision while regression test selection rts a regression testing 110fig.
comparing rts full rv mop with best performing imop technique psc pscl and their combinations with rts.
technique aims to speed up testing by only re running affected tests .
we compare the runtime overhead and safety of combining rts with full rv with those of the bestperforming agnostic and framework specific imop technique per project psc pscl and their combinations with rts.
we are the first to evaluate rts with instrumentation driven techniques others evaluated rts with spec driven techniques .
due to the many combinations we run rts experiments only on the top table iv projects in decreasing order of speedups that we could successfully run with ekstazi and starts two open source rts tools that use dynamic and static analysis respectively to find affected tests.
we could not simply pick the top projects because ekstazi failed for some of them due to a known problem .
the projects that we use in rq3 have a total of revisions.
we seamlessly integrate both ekstazi and starts into imop so running rts with imop does not require additional setup from the users.
figure shows the rts related results.
speedups from these techniques with and without rts are shown as ratios of each technique s time to full rv time the .
line the further below .
the better.
starts selects mean of all tests while ekstazi selects mean .
we make several observations from figure .
i in all projects rts speeds up full rv but rts full rv never yields the best speedup.
ii rts speeds up psc 1in all projects ekstazi psc 1is slower than psc 1in four projects .
but rts psc 1never yields the best speedup.
iii rts starts speeds up pscl 3in only project.
pscl 3is already fast so rts analysis time becomes an overhead.
also rts pscl 3never provides the best speedup.
iv for the same reason as with pscl combining rts with imop often causes slowdowns.
but rts speeds up an imop technique in projects.
combining imop and psc 1with starts did not miss any new violation.
but pscl 3misses two violations when combined with ekstazi because of limitations of pscl s static analysis.
overall imop outperforms rts full rv but rts imop is faster than imop alone in evaluated projects.
so we conclude that imop and rts are orthogonal but complementary approaches to speeding up rv during testing of projects where instrumentation time dominates rv overhead.
fig.
profiler statistics on where mop psc pscl and the bestperforming framework specific and agnostic imop techniques spend their runtimes across all project revisions.
fig.
results from profiling rts runs in projects.
e. rq4 internal imop metrics profiler data .
figure shows the profiler reported proportions of time spent on instrumentation instr.
running the cut project and rv monitoring synchronization lock to process events without races and printing violations which can be costly .
we use the same procedure as using async profiler .
profiler related runs are not timed.
figure shows that i monitoring accounts for very little proportion of rv time across all evaluated projects ii imop techniques provide more speedups than psc 1and pscl 3because they reduce more instrumentation time and iii agnostic techniques spend no runtime on instrumentation.
agnostic techniques perform instrumentation at compile time that time is included in rq1.
framework specific techniques and full rv perform instrumentation during class loading.
figure shows the results of profiling the rts runs colors mean the same as figure .
there some reasons for the 111table vii no.
of cut classes jars and library classes reinstrumented by five imop techniques across all projects.
ujs oucs oubs oabss habsd h cut classes jars library classes trends in rts results rq3 is clearer.
for example rts full rv is faster than full rv because it spends less time on cut and instrumentation.
but rts full rv still spends more time on instrumentation than imop techniques alone or in combination with rts explaining why it is slower.
similar trends hold for other combinations with rts.
re instrumented class counts .
table vii shows counts of cut classes jars and library classes that ujs o ucs o ubs o abss h andabsd hre instrument across all projects.
we only show these techniques to save space they showcase differences among i usage unawareness u and usage awareness a ii finding changes at jar j .class c and bytecode b levels and iii checking usage statically 2nd superscript iss and dynamically 2nd superscript is d .
we add a jar to the second row if one of its classes is re instrumented.
in table vii ujs ore instruments the most classes it reinstruments all classes in a jar if any of the jar s contents changed .
by re instrumenting only changed .class files in changed jars ucs ore instruments much less than ujs o. also by re instrumenting only changed .class files whose bytecode changed ubs ore instruments fewer cut and library classes thanucs o.abss handabsd hare usage aware so they reinstrument even fewer library classes than these usage unaware techniques.
overall absd hre instruments the least it is the most precise but it incurs overhead to run tests twice .
v. d iscussion when does each imop technique tend to perform best?
we perform an initial qualitative analysis of program characteristics that tend to hold when each imop technique performs best.
we find that framework specific ajcdeftends to perform better than agnostic techniques when few classes change.
when libraries change frequently abps htends to perform best if the test running time is long.
for such projects if the testrunning time is short then abpd h s higher precision enables it to outperform others.
ujp otends to perform better than ucp o andubp owhen a project switches major versions in the semantic versioning sense of libraries often and each such switch modifies many library classes.
in such cases all three techniques re instrument almost all library classes involved.
but ujp odoes not have the overhead of comparing each .class file or cleaning the bytecode as ucp oandubp odo.
for projects that frequently change the cut but not the libraries ubs handubp htend to be the best techniques.
this initial analysis can be the first step towards more detailed qualitative analysis and future work on automated prediction of which imop technique to use for a project or code change.
can imop work beyond aspectj?
imop also supports bism a recently proposed instrumentation fig.
imop overheads relative to test time when using bism with and without evolution awareness in projects.
framework for rv.
bism aims to address some drawbacks e.g.
runtime overhead and learning curve of aspectj the dominant java instrumentation framework in the rv literature.
we evaluate imop s bism support on the rq3 projects by comparing i the overhead relative to running tests without rv of using bism to re instrument all cut and library classes in each revision with ii the overhead of using bism to re instrument only the changed .class files or bytecode that the best performing agnostic imop technique finds as changed.
we cannot evaluate bism with monitoring as it was not yet integrated with an rv tool to our knowledge and re engineering javamop to use bism could take years.
we observe from the bism results in figure that i bism also incurs high overheads to instrument all classes in these projects so high instrumentation overheads are not specific to aspectj.
ii evolution awareness reduces bism overhead.
but bism crashes on jars that it encountered.
bism was only recently proposed and it is not yet open sourced.
so we report these crashes to the bism authors to help improve the tool.
what if imop trades safety for speed?
pscl 3is unsafe but fast and can perform well on some projects table vi .
so we experiment with four techniques in imop that trade safety for speed by design and evaluate them on all projects.
these experimental techniques are not part of imop details about them are in our artifact .
they are as unsafe as pscl but much slower than the best performing safe imop technique per project and barely faster than pscl .
sensitivity to thread counts .
by default imop uses threads in its parallel techniques but users can change this thread count via the command line.
we use after performing a preliminary analysis of the sensitivity of these imop techniques to the thread counts.
for this analysis we run the bestperforming parallel usage aware and usage unaware imop technique per project on all revisions of the rq3 projects using and threads.
table viii shows the results using threads saves more time than threads but using instead of threads does not save much.
vi.
t hreats to validity and limitations threats to validity .
to reduce the threat of poor generalization to other instrumentation frameworks imop supports 112table viii imop times with and threads.
threads threads threads usage unaware best .6s .7s .7s usage aware best .1s .6s .9s aspectj and bism.
our results may not generalize beyond the projects and their historical github revisions that we evaluate.
but we show that amortizing instrumentation costs can provide more savings than existing approaches on projects which is the largest set evaluated with evolutionaware rv to date.
our manual inspection to check safety may miscategorize some violations.
to reduce this threat a co author checked the results multiple times.
these manual inspections were needed in the first place because of test nondeterminism as well as vms bugs and limitations.
future work can target how to mitigate these problems.
limitations .
we address high rv overheads which is only one of several problems to be solved towards broader rv adoption.
we do not e.g.
address the difficulty of finding or improving specs reduce tedium of violation inspection or check if violations are true bugs.
these problems are subjects of other research .
our work may be limited to the kind of api level specs we use but these are the largest publicly available set.
we make no claims beyond the popular rv style in javamop other styles exist .
future work can investigate instrumentation driven techniques for other kinds of specs e.g.
project specific ones and rv styles.
the projects on which we evaluate imop are those where instrumentation dominates the rv time.
prior work shows that rv overhead in more than of evaluated projects is dominated by instrumentation not monitoring.
we do not expect imop to provide similar speedups in projects where monitoring time dominates rv overhead.
vii.
r elated work the most relevant work are spec driven evolution aware rv techniques which we discuss and compare with in several parts of the paper.
here we put imop in context with respect to the empirical study that inspired it and discuss other related work.
motivating study .imop is inspired by guan and legunsen s recent study which found that rv overheads during testing is often dominated by instrumentation .
they also provided preliminary evidence that amortizing instrumentation costs can speed up rv psc 1and pscl .
but we are the first to realize instrumentation driven evolution aware rv techniques in a tool evaluate its performance on a larger scale compare and combine instrumentation driven techniques with rts and evaluate its safety.
their study evaluates two proofs ofconcept one of which assumes a non existent repository where all jars are pre instrumented for rv.
we refine and implement their other proof of concept into ujs o and add techniques.
instrumentation in rv and other program analyses .
cassar et al.
survey instrumentation approaches in rv.
other works distribute instrumentation costs across users or develop instrumentation for sampling events .
these works are not concerned with rv during testing of evolving software.
reducing instrumentation costs has not received a lot of rv research attention perhaps because most prior work i target deployed software where instrumentation is a onetime cost or ii were evaluated on dacapo benchmarks and measured performance after system warm up.
for rv during testing especially in continuous integration reducing high instrumentation overhead as imop does is critical.
reducing rv overhead .
many works reduce rv s overhead but they often target the reduction of monitoring not instrumentation costs.
imop is the first framework that reduces instrumentation costs in an evolution aware manner.
regression testing .imop is related to regression testing which aims to speed up testing during software evolution.
rts is a regression testing technique that aims to speed up regression testing by re running only affected tests after a code change.
we compare and combine imop with rts iv d .
in the future we plan to further speed up this integration by building the dependency graph only once in some cases where certain imop techniques build their own dependency graph and rts separately builds its own graph.
also we leave as future work the evaluation of rv with other regression testing techniques such as test suite minimization or test suite prioritization .
viii.
c onclusions we present the first instrumentation driven evolution aware rv framework imop and its in depth evaluation.
the idea behind imop is simple in a new code revision re instrument only changed code and re use the old revision s instrumentation for unchanged code.
on projects where instrumentation dominates rv overhead imop provides more speedup and is safe compared to the state of the art spec driven evolutionaware rv techniques that use complex program analysis.
imop is faster than just combining regression test selection rts with rv but imop and rts are complementary.