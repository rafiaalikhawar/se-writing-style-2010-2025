automated accessibility analysis of dynamic content changes on mobile apps forough mehralian university of california irvine fmehrali uci.eduziyao he university of california irvine ziyaoh5 uci.edusam malek university of california irvine malek uci.edu abstract with mobile apps playing an increasingly vital role in our daily lives the importance of ensuring their accessibility for users with disabilities is also growing.
despite this app developers often overlook the accessibility challenges encountered by users of assistive technologies such as screen readers.
screen reader users typically navigate content sequentially focusing on one element at a time unaware of changes occurring elsewhere in the app.
while dynamic changes to content displayed on an app s user interface may be apparent to sighted users they pose significant accessibility obstacles for screen reader users.
existing accessibility testing tools are unable to identify challenges faced by blind users resulting from dynamic content changes.
in this work we first conduct a formative user study on dynamic changes in android apps and their accessibility barriers for screen reader users.
we then present t imestump an automated framework that leverages our findings in the formative study to detect accessibility issues regarding dynamic changes.
finally we empirically evaluate t imestump on real world apps to assess its effectiveness and efficiency in detecting such accessibility issues.
index terms android accessibility screen reader dynamic content changes i. i ntroduction dynamically changing visual content of screen e.g.
through animation is a commonly used technique for enhancing the visual aesthetics of an app and to guide users attention to specific parts of the app.
however these visually appealing techniques should not come at the cost of making apps inaccessible.
in adherence to legal frameworks established guidelines and ethical principles the digital realm should be inclusive and accessible to all.
this is especially crucial for the approximately of the global population with some form of disability including more than million users that are blind or visually impaired .
visually impaired users rely on assistive technologies like screen readers to interact with mobile apps.
these tools enable users to navigate to a specific element on the screen and listen to the content in focus.
however the tunnel like focus provided by screen readers may lead to unawareness of dynamic changes occurring elsewhere on the screen.
a known example of such dynamic content is error notifications.
when an app assesses user inputs and provides feedback such as an error message through a notification these changes may go unnoticed by screen reader users.
mobile platformslet developers designate these dynamically changing parts of a screen as live regions assisting screen readers to detect and announce such changes to users.
unfortunately developers often neglect using proper accessibility attributes posing significant accessibility challenges for the blind.
earlier studies and guidelines addressing software accessibility have only scratched the surface of this critical issue.
the related accessibility guidelines on this matter primarily center on designating live regions for screen reader announcements.
specifically in scenarios involving error messages web content accessibility guidelines wcag success criterion .
.
emphasizes the crucial need for users to be informed about errors and comprehend what went wrong and recommends techniques such as annotating error notifications as live regions .
however the challenge extends beyond these scenarios.
dynamic changes have been neglected from prior studies and tools that rely on screen captures from an app to detect accessibility issues .
gui crawlers and app explorers typically capture screenshots of an app under test after it is in stable conditions by waiting for certain amount of time .
unfortunately these approaches fail to capture app states during the entire rendering process overlooking changes that occur over time on the screen.
consequently they are not capable of detecting accessibility issues caused by dynamic contents.
to bridge this gap we initiated a formative study aimed at identifying various types of dynamic changes and assessing their impact on screen reader users.
this study revealed characteristics of accessibility issues related to dynamic content changes that negatively impact blind users.
building on these insights we developed t imestump an automated framework designed to detect such issues in android apps.
t imestump comprises an automated crawler randomly exploring diverse app states and capturing data before during and after each action.
subsequently this data undergoes processing using the identified patterns from our initial study to pinpoint problematic dynamic changes for screen reader users.
the identified issues are then reported and visualized for developers.
this paper makes the following contributions the first study on accessibility issues arising from dy1user double tapsevents a b c d e type view clicked type windows changed type window content changed time f fig.
.
evolution of content loading on the screen across various states over time a represents the initial screen state before the user initiates an action b captures the moment when the user interacts with the app by clicking on a button and c to f illustrate the gradual appearance of new screen content over time.
notably in f the close button indicated by a dashed red circle appears above the accessibility focus.
since it is not tagged with liveregion attribute it is also not announced and a screen reader user does not notice it.
namic content changes in android apps.
the introduction of the first automated crawler capable of capturing dynamic content changes complemented by the creation of the initial dataset cataloging such behaviors.
the development and public release of the first automated tool named t imestump designed for localizing and detecting accessibility issues related to dynamic content changes in android apps .
an empirical evaluation on real world apps corroborating the effectiveness of t imestump in detecting accessibility issues induced by dynamic screen changes.
a user study involving blind participants to assess the impacts of dynamic screen change on app accessibility.
the remainder of this paper is organized as follows.
section ii provides the background information.
section iii describes our formative user study that motivated this work.
section iv presents t imestump an automated approach for detection of problematic dynamic content changes.
section v details the evaluation of t imestump on real world apps and in collaboration with blind participants.
the paper concludes with a discussion of threats to validity related research and future work.
ii.
b ackground mobile platforms offer the possibility of dynamic content changes allowing developers to alter the screen content in real time.
figure displays an android app called i am that provides daily affirmations for users and has more than5 million downloads.
when the screen reader focuses on the continue button as shown in figure b the user can double tap to perform the click gesture.
soon after clicking the button the window changes and some promotional content appears gradually such as text buttons and other elements.
for example the already a member button dotted in blue in figure e and the close button dashed red circle in figure f appear after the bullet points are displayed.
this kind of screen rendering can pose severe challenges to screen reader users.
blind users utilize screen readers to interact with apps and when encountering an unfamiliar app they navigate through the on screen elements sequentially to understand the app s layout.
the swipe right and left gestures allow the screen reader to move to the next or previous element respectively highlighting it with a green box as shown in figure b .
when an element is focused the screen reader vocalizes its textual description enabling blind users to gauge its functionality in a manner analogous to how sighted users depend on the visual cues of an element.
should the textual description align with their expectations blind users execute a double tap mirroring the single tap action typical of sighted users.
the following example illustrates the challenges blind users can face when dealing with dynamic changes.
in figure as the user navigates to screen c the top element which is the text view component receives the accessibility focus.
screen reader users explore the screen by moving through the elements sequentially from top to bottom using a swipe right gesture.
however the close button annotated in 2dashed red is not recognizable as it appears on top of the screen and users are less likely to traverse backward to the area they already visited.
such barriers can lead to unintentional interactions with ads or difficulties navigating away from them.
in android the guidelines suggest using an attribute called liveregion to help screen readers recognize the appeared content.
when an element is annotated as liveregion it is announced by the screen reader.
android system utilizes an event based model to inform screen readers of changes in live regions.
a gui element emits an accessibilityevent when there are changes to its state which is received by assistive technologies such as a screen reader.
figure illustrates several different types of events that can be triggered during the loading of app content with each color representing a distinct event.
for example type view clicked events occur after a view is clicked type windows changed events happen when the app transitions to a different window andtype window content changed events take place after the content inside a window changes.
assistive technologies can also identify the element that is the source of events.
in android gui elements are represented by a tree of accessibilitynodeinfo objects that mirror the xml hierarchy of elements and their attributes.
accessibilitynodeinfo tree can be likened to the document object model dom tree in the case of web pages offering a hierarchical representation of rendered elements on a web page.
prior studies on exploring various states of web apps for testing purposes have characterized dynamic content changes as modifications to the dom that occur without reloading the page .
these changes include updating or disappearing content reordering elements and inserting specific elements as outlined in the wcag guidelines.
similar to wcag guidelines android suggests using accessibility attributes to notify screen reader users of such changes .
however these guidelines only scratch the surface of the issues that may arise as a result of dynamic contents.
for instance when a temporary button like an undo button pops up on the bottom of the screen users may struggle to locate it within the brief time frame of its visibility.
this challenge intensifies when content disappears before users become aware of its existence.
merely relying on accessibility attributes does not fully resolve this issue.
iii.
f ormative study we conducted a formative study to investigate the impact of various dynamic content changes on screen reader users.
a. study design prior studies and guidelines on web defined dynamic content changes as modifications to the dom that occur without reloading the page .
consequently in android apps dynamic content changes encompasses any modifications tothe hierarchical representation of elements i.e.
a tree of accessibilitynodeinfos in a rendered window.
these modifications include adding removing or changing attributes of elements.
to have a better understanding of different types of dynamic content changes in android two authors conducted an empirical analysis of android apps.
these apps were randomly chosen from the google play store representing various app categories.
additionally to ensure the significance and popularity of the apps studied each app selected had a minimum of million downloads.
for each app two authors manually explored the app screen using a combination of actions such as clicking scrolling and typing to observe if that would trigger dynamic content changes.
if so a recording from the screen is taken with a brief description of the dynamic content change.
following this two authors engaged in an iterative open coding process to categorize the types of dynamic content changes identified.
through our empirical analysis we identified types of dynamic content changes.
appearing content.
this content change type is characterized by an element that initially is not present on a loaded window but appears a few moments later and remains on the screen.
for example in figure f the close button marked by a red circle appears after a few seconds.
disappearing content.
this content change type describes an element that disappears either after a set period or as a result of user interaction.
for example in figure i the navigation bar at the bottom including element aas well as the more button on top element b disappear when users navigate through the list of items.
short lived content.
this content change type relates to an element that initially is not present on the screen but appears and remains on the screen only for a brief duration.
due to its transient nature we refer to this as short lived content.
for example as illustrated in figure iii when users save a restaurant a notification message annotated as eappears to notify them that they have successfully saved the store and to offer an option to view all saved stores.
this message disappears after a few seconds.
moving content.
this content change type refers to an element that is initially visible on the screen but subsequently gets relocated to a different part of the screen.
for instance in figure ii the app related information marked as c is shifted to the bottom of the screen and goes out of screen bounds after user presses the install button.
users must locate that information at a different position within the sequence of elements on the screen as perceived by screen readers.
content modification.
this content change type pertains to an element that remains on the screen but its attributes change.
for example in figure ii the textview annotated as d continuously refreshes its text to display the progress of the app installation process.
3e dc i ii iii abfig.
.
examples of dynamic content changes i the add button annotated as a and the more button annotated as b disappear when users continue exploring the screen ii the app information marked as c moves to the bottom of the screen after hitting the install button the text annotated as d constantly changes to indicate installation progress iii the short lived notification annotated as e at the bottom after saving a restaurant.
having identified different types of dynamic content changes in android our objective was to understand their impacts on screen reader users.
to this end we selected apps that collectively represented all identified types of dynamic content changes.
we then designed specific tasks that would involve interactions with these dynamic changes.
our objective was to understand whether the users can perform the tasks whether they can perceive the dynamic changes in the apps and to generally develop a better understanding of how the dynamic changes impact app accessibility.
to recruit participants we leveraged the fable platform which connects tech companies with disabled users for accessibility testing.
each user interview session was conducted over a one hour period.
during these sessions we requested participants to share their phone screens and perform our designed tasks while vocalizing their thoughts and actions aka think aloud .
this thinkaloud method combined with in situ questioning enabled us to observe their understanding of the dynamic content changes and assess their ability to complete the tasks successfully.
our blind participants included one female and two males all of whom demonstrated a high proficiency in using the talkback.
b. results the user interviews focused on all the apps depicted in figures and .
to generate a comprehensive list of accessibility issues related to dynamic content changes two authors thoroughly examined each interview session.
initially they independently identified areas where screen reader users faced confusion and attempted to ascertain the underlying reasons.
then they engaged in discussions to reach a consensus.
the following list outlines the dynamic content changes that proved challenging for screen reader users in our study.latent appearing content.
when content appears without being annotated as a live region and is situated in an area previously explored by the user it remains latent or unknown.
for instance the close button on an app s promotional page as shown in figure f emerges after a few seconds without alerting blind users.
during the interview blind users had already navigated past it possibly interacting with elements located lower on the screen.
this led to confusion when attempting to exit the promotional page requiring users to employ various strategies such as using the talkback back gesture or re navigating the screen.
latent disappearing content.
content that vanishes before the user explores that region of the app stays undiscovered.
in figure i annotated buttons bandadisappear as users swipe through the list of items.
the disappearance of the addbutton element a presented specific challenges for blind participants as the button disappears in an unexplored area.
as a result they were unable to locate the element to add a new cost entry to the list.
conversely the more button element b remains accessible as users had already visited that element before its disappearance and when navigating backward the more button becomes visible again.
latent short lived content.
when an element appears temporarily it may be inaccessible to the user especially if the element is actionable.
the time it takes for the user to navigate to that element and perform the action might exceed the visibility period of short lived content leading to accessibility issues.
in figure iii we observe a brief notification annotated as ethat emerges after users save a restaurant.
our user interviews revealed that participants were aware of this notification understanding that they had successfully saved the restaurant and that the app offered an option to view all saved stores.
however this notification disappeared within a 4few seconds.
for this type of dynamic content participants only partially grasped the situation.
while they recognized the appearance of the notification thanks to the live region annotation they did not fully understood its transient nature and were unable to click on the view saved stores button.
one interviewee expressed it was a flash or pop up and it went away.
i would expect to be able to navigate to that button but when i move back and forth it is gone.
latent moving content.
when the location of a previously visited element changes it can cause confusion for blind users.
as illustrated in figure ii the app related information including app rating and download number relocates to the bottom of the screen after pressing the install button.
in our study blind users were assigned the task of installing an app and finding its download number.
after installation they navigated backward relying on the previous announcement by talkback about the download number during their journey to the install button.
however to their surprise upon navigating back the information they sought was no longer present resulting in confusion and a period of being stuck on the page.
none of the participants completed the task with one participant believed that he could eventually locate the download number by navigating further down acknowledging it would take more time.
latent content modification.
changes in attributes of elements that are noticeable by sighted users may go unnoticed by users relying on screen readers.
during the formative study the textview element d in figure ii continuously updated its text to reflect the progress of the app installation.
the proper implementation of the liveregion feature ensured that changes in the textview content were effectively announced to blind participants enabling them to accurately comprehend the status of the installation process.
conversely this suggests that if the liveregion feature is not correctly implemented it becomes challenging for screen reader users to understand content modification such as the installation status.
in addition.
changes in attributes such as size and color which are not perceptible by screen readers do not impact their perception of the app.
iv.
a pproach relying on the insights gained from formative interviews with screen reader users we developed an automated framework called t imestump designed to identify accessibility issues associated with dynamic content changes.
figure provides an overview of t imestump highlighting the three distinct phases of its operation.
in the initial phase we install an android app on a virtual machine vm and utilize a gui crawler to automatically explore the app generating a diverse set of states in an app.
the snapshot recorder tracks app states and records snapshots of distinct screens.
in the second phase we extract the list of actionable elements apkapp crawler interaction automator accessibilityreport captured datasnapshot recorder screen analyzerphase 1phase 2phase 3localizerfig.
.
t imestump s approach overview.
in each recorded snapshot.
then the interaction automator systematically executes each action capturing information before during and after the action.
this rich dataset is passed to the third phase where the localizer component assesses the gathered information precisely flagging accessibility issues stemming from dynamic content changes.
we now describe the details of each phase.
a. phase capturing unique app screens the main goal of this phase is to navigate through an app and explore its different states for subsequent examination.
interacting with the app leads to various state changes ranging from subtle modifications in attributes such as selecting a checkbox on the screen to more significant changes like transitioning to an entirely new screen resulting in a completely different hierarchical structure of elements.
in this phase our focus is on identifying a diverse set of screens from each app that have undergone significant changes.
detailed assessment of minor changes is reserved for subsequent phases.
to facilitate the testing of gui apps a variety of tools such as stoat monkey spaienze and ape have been specifically designed to traverse the expansive domain of an app s different states.
t imestump seamlessly integrates with any existing app exploration tool providing the flexibility to traverse various app states.
additionally timestump allows manual testers to explore the app with diverse scenarios in mind or leverage existing gui test cases.
the snapshot recorder plays a pivotal role in tracking alterations.
as the crawler interacts with the app snapshot recorder keeps track of the screen structure and activities i.e.
an android component representing a single screen.
it then captures vm snapshots from app states involving changes to activity names or the hash value of hierarchical structure of 5elements.
similar to previous studies the hash function excludes nodes that are not important for accessibility i.e.
those not notified by screen readers as well as attributes such as checked orenabled that do not contribute to recognizing a different screen in an app.
vm snapshots enable us to load the app from the exact state and perform further analysis without concerns about the impacts of prior interactions.
b. phase monitoring apps in action during this phase each potential interaction within a given app snapshot is automatically executed all while monitoring the app for dynamic content changes.
to achieve this we first load a vm snapshot.
the screen analyzer employs an accessibility service to extract and dump the hierarchical structure of elements on the screen.
the outcome is a tree structure wherein each node represents an element accompanied by various attributes such as clickability.
parsing this node tree the screen analyzer identifies all interactable elements and enumerates the types of actions they support such as click type or swipe.
every element is uniquely identified by its resource id and a set of other attributes such as text content description and class name.
the resource id serves as a distinctive marker for locating each element.
in instances where developers have not assigned a resource id the combination of other attributes can help in locating the element.
the interaction automator receives the comprehensive list of actions identified by the screen analyzer and executes them on the app while collecting certain data before during and after each action.
the interaction automator consists of two main components controller and accessibility service.
the controller functions as a server sending commands to the client the accessibility service which operates in the background.
the accessibility service is responsible for interacting with elements on the device.
the client captures two frames of the app first frame and last frame .
the first frame corresponds to the initial state of the window while the last frame corresponds to the app s state once all the content has finished rendering.
the first frame primarily reflects the state of the app before any action takes place.
however if an action triggers a window change this first frame then denotes the app s status immediately following the action.
to accomplish this t imestump tracks accessibility events that signal either the loading of a new window or shifts in accessibility focus.
when a window change occurs the first frame is recorded immediately after detecting the event that indicates a change in the window.
for example in figure the type windows changed event highlighted in purple signifies a window transition.
consequently figure c is identified as the first frame.
in the absence of such events the first frame defaults to the state of the app before executing the action.for the last frame t imestump listens for accessibility events indicating window content changes and if none occur for more than seconds it captures that final state.
for instance figure f is designated as the last frame indicating that all changes on the app screen have been finalized.
this practice is common in prior studies and automation tools ensuring app stability before data capture.
the waiting time can be configured to be as long as necessary or even adaptive to the specific app to optimize efficiency .
in instances of continual changes such as animations or ads a timeout period is implemented to bypass waiting.
the controller stores these frames as well as real time logs of accessibility events generated by the accessibility service throughout the entire action execution period.
leveraging this extensive dataset empowers the localizer to pinpoint accessibility issues arising from dynamic content changes.
c. phase localizing problematic dynamic changes timestump analyzes the collected data to identify various categories of latent content changes for screen reader users.
this analysis is conducted across captured frames of the app as well as the accessibility events captured during the execution of each action on the screen.
when a screen element undergoes a change it triggers an event of type window content changed .
timestump identifies sources of such events within the captured frames of the app forming the initial set of candidate elements within a window that undergo a problematic change.
the localizer then compares elements in the final frame against those in the first frame to pinpoint the problematic changes.
as explained in section iv b if the execution of an action results in a window transition the first frame is the newly loaded window i.e.
the frame captured immediately after performing the action similar to figure c .
to detect window transitions localizer examines accessibility events of typewindows changed andwindow state changed which are also used in the android source code to detect the appearance of a new window .
subsequently we elaborate on the logic employed for detecting various types of problematic changes.
due to space limits we provide an intuitive explanation of how t imestump localizes each issue here and provide the detailed algorithms on the companion website .
latent appearing content as explained in section ii and section iii if certain content appears in previously explored areas i.e.
above the accessibility focus in default navigation order and is not designated as a live region it remains unknown to the screen reader user.
the localizer classifies elements in the final frame that trigger a content change event as latent appearing content if they do not appear in the first frame are not designated as live regions and are positioned before the current accessibility focus.
6latent disappearing content when an element disappears from the screen a change event is triggered similar to the case of appearing content.
however in this scenario the event s source is the container of the vanishing element.
for example if a button within a linear layout disappears the event source will be the linear layout potentially covering the entire screen.
consequently the localizer evaluates all the children of an event publisher node in the first frame to verify their presence in the final frame.
a child node is categorized as latent disappearing content if it is not observed in the last frame it is not designated as a live region and it is positioned after the current accessibility focus.
latent short lived content elements that appear and disappear have a brief visibility period.
even if this content is announced navigating to them and interacting with them using screen readers is challenging.
the localizer identifies these elements by searching for pairs of change events and localizing their sources denoted as s1 s2 in two consecutive frames checking whether s2 is the container of s1.
for any such found pair an element s1 is categorized as latent short lived content if s1 is not present in the first frame its container s2 is observed in the second frame and s1 is not designated as a live region or is actionable.
latent moving content the localizer examines elements displaying a shift in their position on the screen across different frames while maintaining consistent identifiers such as resource id and content description.
elements are flagged as problematic if their changed position is above the accessibility focus or if they move beyond the screen boundaries.
latent content modification the change of attributes in an element refers to any modification in the properties that define an element s behavior or metadata within a ui.
localizer uses a hash function to detect such modifications across different frames.
the hash function encodes the element attributes that are important in exploring the app with screen readers.
a discrepancy in the hash values of an element between any two frames signifies a modification in the element s content.
when theliveregion attribute is absent the change remains unknown to screen reader users.
v. e valuation we evaluated t imestump on real world apps and with the help of several blind users to answer the following questions rq1.
how accurate is t imestump in detecting dynamic content changes and different categories of accessibility issues?
rq2.
how do the issues reported by t imestump impact the screen reader users?
rq3.
what is the performance of t imestump ?
a. rq1.
accuracy of timestump experimental setup for this experiment we utilized stoat as the app exploration tool.
we evaluated ourapproach on real world android apps.
our test set consists of two groups of apps group1 apps with manually verified dynamic content changes from different categories of google play store group2 randomly selected apps with known accessibility issues from a prior study .
for apps in group1 the authors installed top rated apps in different categories of google play store and manually explored each app looking for dynamic content.
they captured a vm snapshot of each app at that state with the accessibility focus set on the target element such that performing the action on the target element results in the dynamic change.
for apps in group2 we set the crawler to automatically get vm snapshots from two random unique states of the app.
the tool then explores the actionable elements in each state to get the real time data.
the precision of the captured data directly impacts the ability of t imestump to detect changes in dynamic content.
before evaluating t imestump s effectiveness we manually reviewed the captured data from a test set to confirm alignment with our definitions of the first and last frames and encountered no issues.
for this experiment we chose unique app states from random apps from a prior study encompassing a range of app transitions such as implicit loading explicit loading and transitions.
additional information about this study can be found on the companion website .
all experiments were conducted on a typical computer setup for development macbook pro apple m1 max gb memory .
we used the most recent distributed android os sdk34 and the latest versions of android screen reader.
results to answer this question the authors manually examined the issues reported by t imestump and tagged them as false positive fp if the reported issue is not correct and true positive tp if the reported issue correctly detects and categorizes problematic dynamic content changes.
the authors used an emulator to load the captured snapshot and manually interacted with the app using talkback.
this process allowed for the identification of legitimate dynamic elements in exploring the app with screen readers.
we then report precision as the ratio of the number of tps to the number of all detected issues.
as shown in table i the overall precision over all the elements in actions of apps is .
.
to compute recall we manually reviewed apps in both group and group to identify dynamic changes and establish the ground truth.
in group snapshots were captured during manual exploration of the app revealing states with dynamic content changes.
in contrast for group apps we manually inspected automatically captured snapshots of random app states for dynamic content changes.
dynamic elements missed by t imestump were identified and manually labeled as false negatives fn .
the overall recall across actions is .
as depicted in table i. figure presents examples of problematic dynamic elements detected by t imestump .
in figure a the four 7elements highlighted by orange boxes emerge above the accessibility focus after tapping on the plus button.
figure b illustrates short lived elements including a button indicated by blue boxes appearing after adding a song to favorites.
as all of those elements are actionable t imestump reports them as problematic.
in figure c a textview annotated by the black box is updated following the tap on the calculate button.
since this element is not tagged as live region it remained unannounced while exploring the app with talkback.
thus t imestump reports it as problematic.
we analyzed the failures of t imestump and identified issues falling into two main themes resulting in both false positives and false negatives.
the first pattern relates to inadequate identifiers assigned by developers to elements.
for instance in the fuelio app aframelayout serves as a container for its child elements lacking essential identifiers such as resource id text andcontent description .
as a result its unique identification relies solely on its screen bounds.
however when an action triggers a layout modification the element s screen bounds also change leading t imestump to mistakenly interpret this as an appearing element thus generating a false positive.
moreover the absence of sufficient identifiers can result in false negatives.
in the espn app certain elements possess identifiers that are neither empty nor unique.
t imestump primarily depends on these identifiers to match an element but since they are not distinctive t imestump fails to differentiate between elements on the screen consequently failing to report associated issues.
another category of failures occurs when the screen displays multiple windows such as step by step guidelines overlaid on the main app.
adb allows us to capture the accessibilitynodetree of the foremost window only thereby missing content in other windows.
this limitation contributes to both false positives and false negatives.
b. rq2.
qualitative study to assess the impact of the issues detected by t imestump on screen reader users we conducted user studies.
we randomly selected three apps from rq1 representing various types of dynamic content changes corresponding to ids p8 g1 and g7 as listed in table i. our qualitative study consisted of self guided tasks and user interviews with blind testers recruited through the fable platform .
in the selfguided tasks testers were given concise task descriptions to execute offline on apps while recording their screens and articulating their thoughts aloud.
this approach without a moderator present during sessions helped mitigate interviewer bias.
additionally user interviews were conducted to explore incidents in different states of one app g7 and ask follow up questions.
due to the limited size of the tester pool on the platform some tasks involving different apps were assignedto the same tester.
however no tester evaluated the same app multiple times.
in total distinct testers participated in this study males females with identifying as white and as asian.
participant ages ranged from to .
below we first outline the issues that users confirmed.
we then discuss the observed shortcomings and insights gained.
user confirmed issues of the issues identified users directly confirmed yielding a confirmation rate of .
.
appearing elements in explored areas.
figure a depicts an instance from this category.
blind testers were tasked with locating the gas entry button which appears after tapping the plus button.
the target button along with three other elements highlighted with orange boxes on figure a emerged in areas previously explored by users without any notification.
consequently users felt as if nothing had changed after tapping the plus button.
one participant expressed it s very confusing and disorienting when the screen changes without any audio feedback from the screen readers another noted usually new elements appear below but in this case they appeared above.
the appearance of elements in previously explored areas caused confusion for screen reader users resulting in longer times to locate the desired element.
two out of five interviewees were unable to find the targeted button and complete the task while others had to explore the screen multiple times to do so.
a similar issue in self guided tasks resulted in confusion for all the participants.
for elements that appear dynamically blind testers recommended setting theliveregion attribute appropriately.
they suggested moving the talkback focus to the first new element on the screen in cases of significant window changes.
for minor window changes introduce dynamic elements in unexplored screen areas.
disappearing elements in unexplored areas.
in one of the test apps activating a switch at the top caused some form entries to disappear.
testers interacting with the switch were not informed of the changes and were confused as to why they could not find certain elements.
four out of five interviewees were unable to complete the task concluding that the required element was not present on the screen.
conversely one interviewee managed to find the desired element by turning off a switch leveraging his prior experience with such controls.
among the interviewees who failed to perform the task one person remarked thought the recurrence section was either not on the screen or not visible to talkback.
i just couldn t find it.
the tester expressed a preference for receiving a notification indicating that new controls are available or shown once the checkbox is ticked.
this would enable them to recognize that the layout of the app has changed on the same screen and understand how to revert the layout to its original configuration.
short lived buttons.
as depicted in figure b when users 8table i the accuracy of timestump on subject apps .
id app category installs issues tp fp fn precision recall p1 autozone auto vehicles 5m .
p2 duolingo education 500m .
.
p3 forest productivity 10m .
p4 gratitude lifestyle 1m p5 motivation health fitness 5m p6 starbucks food drink 10m .
p7 ticketmaster events 10m p8 spotify music audio 1b .
p9 h m lifestyle 50m p10 file manager tools 1b .
g1 booking.com travel local 500m .
g2 easy bills reminder finance 100k g3 burn education na .
g4 dictionary.com books reference 10m g5 espn sports 50m .
g6 calorie counter by fatsecret health fitness 50m .
g7 fuelio auto vehicle 1m .
.
g8 life360 lifestyle 100m g9 master lock vault enterprise lifestyle 100k .
g10 nike shopping 50m .
g11 weee!
asian grocery delivery food drink 1m g12 norton secure vpn tools 10m g13 tripit travel local 5m .
g14 toonme photo cartoon maker photography 50m g15 vimeo entertainment 10m g16 yelp food drink 50m g17 the clock productivity 10m .
.
g18 king james bible books reference 50m .
.
g19 lyft maps navigation 50m g20 to do list schedule planner productivity 10m .
.
overall .
.
add a song to their favorites a notification pops up and let them revert the action by tapping on the change button.
three of the users became aware that they could potentially use this element.
two participants missed the button because talkback simultaneously announced three short lived elements which overwhelmed them.
moreover during selfguided tasks none of the participants could interact with the change button as it disappeared quickly.
as a result three participants could not accomplish the task for removing a song from the favorites.
two participants were able to remove the song through an alternative method using the ticked button annotated by a green box in figure b .
therefore short lived elements should not overwhelm blind users with excessive information.
additionally it is recommended to avoid including clickable elements in a short lived manner as blind users navigating sequentially with a screen reader are likely to miss them before they vanish.
unannounced short lived elements.
in the spotify app when users removed a song from their favorites a shortlived notification with the text removed from liked songs appeared signaling this change providing immediate feedback to sighted users.
however talkback did not announce the change to the screen reader user leading to confusion.only two participants advanced to the step of removing a song from the favorites in our self guided tasks.
for those screen reader users they were uncertain if the song had been successfully removed and felt compelled to navigate through the entire screen to verify that.
when a song has not been added to favorites the plus button is labeled with the content description add item.
conversely when the song is in the favorites its description changes to item added.
as a result the blind users need to navigate the screen to check if the content description has reverted to add item.
in order to confirm that their action was successful.
their experience suggested that the liveregion attribute should be appropriately configured for short lived notifications.
unannounced content modification in figure c tapping thecalculate button triggers an update of the result indicated by the black box appearing above the button.
however this change is not communicated to screen reader users forcing them to navigate back to check the calculation result.
although all participants in our self guided tasks managed to find the calculation result by navigating back and forth they reported it as confusing and inconvenient.
additionally if users press the calculate button without providing any input for prior entries they receive an error 9message advising them to input values before proceeding.
one participant noted for the sake of consistency having the calculation result announced just like the error message would not disappoint me.
proper utilization of the liveregion attribute would alleviate such issues.
observed shortcomings the user study also shed light on t imestump s shortcomings and enhancement opportunities.
reverting changes.
timestump evaluates the changes resulting from each action.
however a series of actions may have counteractive impacts.
for instance for example in the spotify app top views move up as users navigate toward the bottom.
as soon as they attempt to navigate back to those top elements the views are restored to their original position and users do not perceive any problem.
our manual exploration of our test set reveals elements with similar issues that may not be problematic for users.
however for users who rely on alternative interaction modes such as explore by touch where talkback shifts its focus to the coordinates of the touch gesture these cases can still be confusing.
severity of issues.
the dynamic elements identified as problematic exhibit varying degrees of severity and impact on blind users with t imestump unable to prioritize them by severity.
factors such as the frequency of the issue among different apps and users familiarity with it contribute to its severity.
for instance during interactions with the booking.com app switching tabs changes the content of the window without altering the screen reader focus or providing any notification.
while this issue caused confusion for participants they relied on their intuition and manually adjusted the talkback focus to the top of the screen to access the new content.
however all participants expressed that it would be helpful if the focus were automatically moved to the newly appeared content.
another factor influencing the severity of the issues is the distance of the changed element from the accessibility focus.
in figure c navigating one element back and forth could help users find the results while if the appearance of the result is far from the current focus it may become impossible for users to locate it.
navigation order.
timestump relies on the default navigation order of elements for talkback to determine if a dynamic change is problematic.
however users may have their own interaction preferences when using screen readers.
in our study some users rely on their prior knowledge and tap on specific parts of the app to find the requested element.
one interviewee mentioned that it would be helpful if the change was announced but he could still locate the dynamically updated textview .
additionally although customization of the navigation order of elements was not observed in the apps used in our experiments it is important to note that developers can override the default talkback navigation order e.g.
allowing the topmost element to be designated as fig.
.
examples of detected issues by t imestump a appearing content b short lived content and c content modification the last element focused by talkback on a screen.
if so the button in figure e circled in red would not trouble blind users as it would be in an unexplored area.
c. rq3.
performance the performance evaluation of our tool t imestump is structured into three phases app screen capturing phase monitoring apps in action phase and localizing problematic dynamic changes phase .
in rq1 phase involves automated capturing of two distinct app states from group2 apps requiring an average of seconds using stoat .
phase s analysis of each state for the number of actions is rapid however executing each action capturing data and transferring it to the server consumes about seconds per action on average.
the bulk of this time approximately seconds is dedicated to dumping and transferring data especially the captured video for each action.
developers can opt to disable video capturing in the tool relying instead on screenshots to significantly improve the tool s performance.
in phase the post analysis of the technique includes analysis of collected frames as well as the accessibility events completing in approximately .
seconds for each action.
10vi.
t hreats to validity external validity.
in this study we examined dynamic content changes following action execution or screen transition.
however ad related pop ups or random rating requests may appear without user actions.
investigating these requires analyzing the source code and library calls to find them.
future research could focus on identifying and understanding these instances.
another concern is the completeness of our work both in terms of the types of dynamic content changes and the challenges they pose.
we carefully selected and manually explored a diverse range of apps to identify the types of dynamic change ensuring these aligned with web testing definitions related to element structure and attribute modifications.
moreover we utilized interviews to pinpoint scenarios where different types of dynamic content change might pose issues for screen reader users.
although our initial findings were extracted from three interviews the subsequent user study in rq2 reaffirms the validity of our conclusions.
similarly a concern related to rq1 is the completeness of the identified accessibility issues.
the ground truth was manually created due to the lack of preexisting datasets.
to validate the manual construction of the ground truth two authors independently reviewed the snapshots including the accessibilitynodeinfo tree and accessibilityevents to identify problematic dynamic changes.
subsequently they engaged in discussions to ensure agreement in their evaluations.
internal validity.
timestump integrates various libraries and tools including stoat adb a vd and accessibilityservice raising potential risks of defects.
additionally there is a possibility of defects in our prototype s implementation.
to counteract we utilized the latest version of third party tools conducted github code reviews and tested on varied apps.
we also assessed data capture accuracy on apps with different transitions detailed on our website .
for rigorous testing we used different sets of apps for our formative studies accuracy evaluations and tool assessments.
vii.
r elated works automated accessibility testing includes various tools and studies for both web and mobile app accessibility analysis.
web pages web accessibility testing primarily relies on the wcag guidelines .
these guidelines have led to the development of tools assessing web page accessibility compliance .
however the guidelines overlook various accessibility challenges encountered by assistive technology users especially in the context of dynamic changes.
while a few criteria mandate developers to ensure dynamically displayed error success messages are accessible to all they fail to address other issues arising from dynamic content changes.
existing tools cover only a fraction of the standards thus inadequately detecting these issues on web pages.to address limitations of guidelines dynamic techniques have been proposed to assess apps while interacting with them.
they resulted in studies that detect accessibility issues during interactions with web pages or evaluate and infer correct accessibility attributes like aria labels for web content .
in the evaluation of interaction issues recent studies have attempted to utilize assistive technologies similar to how an end user explores the app.
they also account for changes introduced by javascript by evaluating multiple states that a single web page can take .
these studies focus on interaction failures which are only a subset of the challenges posed by dynamic changes.
while exploring the app dynamically they overlook real time changes like unnannounced buttons appearing in previously explored areas.
furthermore these studies miss changes like content modification that does not involve altering the dom structure.
mobile apps similar to web accessibility testing various automated tools are designed for mobile apps to assess specific app states and report their adherence to accessibility guidelines .
recognizing the limitations of accessibility guidelines and the unique interaction modes of assistive technologies recent studies have focused on identifying inaccessible content by utilizing assistive technologies to navigate various app states and comparing it with exploring the app without assistive technologies .
however no technique tackles the challenges of dynamic content changes.
viii.
c onclusion the broad impacts of dynamic content changes on accessibility issues have not been thoroughly examined in prior research.
we presented t imestump an automated framework identifying accessibility issues due to dynamic screen changes.
timestump navigates through app states collects data before during and after each action and applies a set of rules to detect dynamic screen changes that may lead to accessibility problems for the blind.
an empirical study on real world apps and a user study with blind participants prove its efficacy.
future directions involve extending our work to ad related pop ups and unexpected rating requests that may appear without user actions and expanding our implementation to other platforms such as web and ios.
our research artifacts are available publicly .
acknowledgment this work has been supported in part by award numbers and from the national science foundation.
we thank fable for their collaboration in making this research possible.
we are grateful for the detailed feedback from the anonymous reviewers of this paper which helped improve this work.
11references u. d. of justice americans with disabilities act a guide to disability rights laws u.s. department of justice last accessed february .
w3c wcag overview w3c last accessed december .
apple accessibility on ios ios apple last accessed may .
android build more accessible apps guide topics ui accessibility google last accessed may .
who world report on disability who last accessed july .
wai understanding sc .
.
error identification level a html text providing 20information 20about 20input 20errors icons 20and 20other 20visual 20cues.
w3c last accessed march .
t. f. liu m. craft j. situ e. yumer r. mech and r. kumar learning design semantics for mobile apps in proceedings of the 31st annual acm symposium on user interface software and technology pp.
.
a. mathur g. acar m. j. friedman e. lucherini j. mayer m. chetty and a. narayanan dark patterns at scale findings from a crawl of 11k shopping websites proceedings of the acm on human computer interaction vol.
no.
cscw pp.
.
b. deka z. huang c. franzen j. hibschman d. afergan y .
li j. nichols and r. kumar rico a mobile app dataset for building data driven design applications in proceedings of the 30th annual acm symposium on user interface software and technology pp.
.
n. salehnamadi f. mehralian and s. malek groundhog an automated accessibility crawler for mobile apps in 37th ieee acm international conference on automated software engineering ieee.
rochester michigan usa acm new york ny usa .
s. feng m. xie and c. chen efficiency matters speeding up automated testing with gui rendering inference in ieee acm 45th international conference on software engineering icse .
ieee pp.
.
f. mehralian and z. he timestump companion website seal last accessed aug .
monkey taps llc i am daily affirmations com store apps details?id com.hrd.iam hl en us gl us accessed .
n. f. malik a. nadeem and m. a. sindhu achieving state space reduction in generated ajax web application state machine.
intelligent automation soft computing vol.
no.
.
k. j. koswara and y .
d. w. asnar improving vulnerability scanner performance in detecting ajax application vulnerabilities in international conference on data and software engineering icodse .
ieee pp.
.
w3c understanding success criterion .
.
understanding wcag .
w3c last accessed december .
reordering page sections using the document object model w3c last accessed december .
inserting dynamic content into the document object model immediately following its trigger element w3c last accessed december .
wai using aria role alert or live regions to identify errors https w3c last accessed march .
f. t. labs fable digital accessibility powered by people with disabilities fable tech labs last accessed december .
m. van someren y .
f. barnard and j. sandberg the think aloud method a practical approach to modelling cognitive london academicpress vol.
pp.
.
t. su g. meng y .
chen k. wu w. yang y .
yao g. pu y .
liu and z. su guided stochastic model based gui testing of android apps in proceedings of the 11th joint meeting on foundations of software engineering .
paderborn germany acm new york ny usa pp.
.
google ui application exerciser monkey google last accessed may .
k. mao m. harman and y .
jia sapienz multi objective automated testing for android applications in proceedings of the 25th international symposium on software testing and analysis .
saarbr ucken germany acm new york ny usa pp.
.
t. gu c. sun x. ma c. cao c. xu y .
yao q. zhang j. lu and z. su practical gui testing of android applications via model abstraction and refinement in ieee acm 41st international conference on software engineering icse ieee.
montreal canada ieee pp.
.
google dumpcommand frameworks testing jb mr2 release uiautomator cmds uiautomator src com android commands uiautomator dumpcommand.java google last accessed feb .
clickandwaitfornewwindow platform frameworks base refs heads main cmds uiautomator library core src com android uiautomator core interactioncontroller.java google last accessed feb .
g. broccia m. manca f. patern o and f. pulina flexible automatic support for web accessibility validation proceedings of the acm on human computer interaction vol.
no.
eics pp.
.
g. gay and c. q. li achecker open interactive customizable web accessibility checking in proceedings of the international cross disciplinary conference on web accessibility w4a .
raleigh usa association for computing machinery pp.
.
a. m. agency access monitor plus administrative modernization agency last accessed december .
c. benavidez examinator .
.
available http examinator.net webaim wave web accessibility evaluation tool webaim last accessed december .
accessibe accessscan website accessibility checker free instant accessibe accessibe last accessed december .
h. takagi c. asakawa k. fukuda and j. maeda accessibility designer visualizing usability for the blind acm sigaccess accessibility and computing no.
pp.
.
j. p. bigham j. t. brudvik and b. zhang accessibility by demonstration enabling end users to guide developers to web accessibility solutions in proceedings of the 12th international acm sigaccess conference on computers and accessibility .
orlando usa association for computing machinery pp.
.
f. durgam j. grigera and a. garrido dynamic detection of accessibility smells universal access in the information society pp.
.
w3c accessible rich internet applications wai aria .
world wide web consortium w3c tech.
rep. .
.
available c. duarte a. salvado m. e. akpinar y .
yes ilada and l. carric o automatic role detection of visual elements of web pages for automatic accessibility evaluation ser.
w4a .
new york ny usa association for computing machinery .
.
available m. bajammal and a. mesbah semantic web accessibility testing via hierarchical visual analysis in ieee acm 43rd international conference on software engineering icse .
ieee pp.
.
w. m. watanabe r. p. fortes and a. l. dias acceptance tests for validating aria requirements in widgets universal access in the information society vol.
pp.
.
n. fernandes d. costa s. neves c. duarte and l. carric o evaluating the accessibility of rich internet applications in proceedings of the international cross disciplinary conference on web accessibility pp.
.
n. fernandes d. costa c. duarte and l. carric o evaluating the accessibility of web applications procedia computer science vol.
pp.
.
l. sensiate h. lidio antonelli w. massami watanabe and r. pontin de mattos fortes a mechanism for identifying dynamic components in rich internet applications in proceedings of the 38th acm international conference on design of communication ser.
sigdoc .
new york ny usa association for computing machinery .
.
available p. t. chiou a. s. alotaibi and w. g. j. halfond detecting and localizing keyboard accessibility failures in web applications ser.
esec fse .
new york ny usa association for computing machinery p. .
.
available https p. t. chiou a. s. alotaibi and w. g. halfond bagel an approach to automatically detect navigation based web accessibility barriers for keyboard users in proceedings of the chi conference on human factors in computing systems pp.
.
detecting dialog related keyboard navigation failures in web applications in ieee acm 45th international conference on software engineering icse .
ieee pp.
.
android improve your code with lint checks google last accessed december .
accessibility scanner apps on google play apps.accessibility.auditor hl en us google last accessed december .
s. hao b. liu s. nath w. g. halfond and r. govindan puma programmable ui automation for large scale dynamic analysis of mobile apps in proceedings of the 12th annual international conference on mobile systems applications and services .
bretton woods new hampshire usa acm new york ny usa pp.
.
android espresso android developers google last accessed december .
robolectric android unit testing framework robolectric last accessed december .
m. m. eler j. m. rojas y .
ge and g. fraser automated accessibility testing of mobile apps in ieee 11th international conference on software testing verification and validation .
v aster as sweden icst pp.
.
s. chen c. chen l. fan m. fan x. zhan and y .
liu accessible or not an empirical investigation of android app accessibility ieee transactions on software engineering vol.
pp.
.
kif keep it functional an ios functional testing framework kif last accessed december .
h. n. da silva s. r. vergilio and a. t. endo accessibility mutation testing of android applications journal of software engineering research and development vol.
pp.
.
l. li r. wang x. zhan y .
wang c. gao s. wang and y .
liu what you see is what you get?
it is not the case!
detecting misleading icons for mobile applications in proceedings of the 32nd acm sigsoft international symposium on software testing and analysis pp.
.
m. taeb a. swearngin e. school r. cheng y .
jiang and j. nichols axnav replaying accessibility tests from natural language arxiv preprint arxiv .
.
f. mehralian n. salehnamadi s. f. huq and s. malek too much accessibility is harmful!
automated detection and analysis of overly accessible elements in mobile apps in 37th ieee acm international conference on automated software engineering ieee.
rochester michigan usa acm new york ny usa .
n. salehnamadi a. alshayban j. w. lin i. ahmed s. branham and s. malek latte use case and assistive service driven automated accessibility testing framework for android in proceedings of the chi conference on human factors in computing systems .
virtual okohama japan acm new york ny usa pp.
.
a. s. alotaibi p. t. chiou and w. g. halfond automated detection of talkback interactive accessibility failures in android applications in ieee conference on software testing verification and validation icst .
ieee pp.
.
a. alshayban and s. malek accessitext automated detection of text accessibility issues in android apps in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering pp.
.
n. salehnamadi z. he and s. malek assistive technology aided manual accessibility testing in mobile apps powered by record andreplay in proceedings of the chi conference on human factors in computing systems pp.
.