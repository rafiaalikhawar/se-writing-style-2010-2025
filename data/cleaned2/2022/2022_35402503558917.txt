python by contract dataset jiyang zhang jiyang.zhang utexas.edu the university of texas at austin austin usamarko ristin rist zhaw.ch zurich university of applied sciences winterthur switzerlandphillip schanely pschanely gmail.com independent researcher new york usa hans wernher van de venn vhns zhaw.ch zurich university of applied sciences winterthur switzerlandmilos gligoric gligoric utexas.edu the university of texas at austin austin usa abstract design by contract as a programming technique is becoming popular in python community as various tools have been developed for automatically testing the code based on the contracts.
however there is no sufficiently large and representative python code base with contracts to evaluate these different testing tools.
we present python by contract dataset containing python functions annotated with contracts using icontract library.
we show that our python by contract dataset can be easily used by existing testing tools that take advantage of contracts.
the demo video can be found at ccs concepts software and its engineering software maintenance tools .
keywords design by contract automatic testing tools dataset acm reference format jiyang zhang marko ristin phillip schanely hans wernher van de venn and milos gligoric.
.
python by contract dataset.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
https introduction python is now one of the most popular programming languages in the world due to its simple syntax extensive support modules and active community.
nevertheless python s relatively dynamic nature is likely to be one of the factors that contribute to it being deemed less suitable for the backbone of software systems.
design by contract which requires developers to write precise and verifiable specifications for software components is one of the techniques able to improve code robustness.
though interest in contracts for python dates back to early 2000s fully permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
libraries for python contracts such as dpcontracts icontract and deal sprout out only in about last five years.
the library support for writing contracts in python was lacking and changed only recently with libraries such as icontract .
consequently there are a few tools to help developers confirm or refute code contracts in python e.g.
crosshair and icontract hypothesis .
while various datasets capture python programs with bugs to the best of our knowledge there exist no dataset of python programs annotated with contracts that can be used to evaluate or benchmark these python specific tools due to little python code with contracts in open source projects.
in this paper we present the python by contract dataset a novel collection of python programs annotated with contracts.
the programs solve problems spanning a wide range of computer science domains from simple string manipulation to file operations.
the dataset contains both correct implementations and ones with bugs that violate a contract.
besides we carefully curate the bugs so that the correct and the incorrect programs have only minimal differences which makes it easier to confirm the presence of a genuine bugs and debug problems in testing tools.
furthermore we show that our python by contract dataset can be used to evaluate and help the development of existing testing tools.
our python by contract dataset is publicly available at the contribution of this work is thus three fold we manually write python solutions to exercises to construct the python bycontract dataset.
we explicitly annotate the python functions and classes with contracts.
we carefully curate the bugs detected during developing to make tracing downstream defects easier and include them in the dataset.
dataset construction in this section we first introduce the collection of programming exercises that underlie our python programs.
then we describe our development of the python programs and contracts as well as how we remold the bugs recorded during the development into the incorrect programs .
.
data source as the python programs in our dataset serve as the benchmark for different testing tools they should not involve complicated dependencies.
it should be easy for users to reason about them and trace the potential bugs.
due to the recency of the library support for contracts in python publicly available programs with contracts esec fse november singapore singapore jiyang zhang marko ristin phillip schanely hans wernher van de venn and milos gligoric are scarce complex and involve many dependencies thus making them unsuitable as a dataset.
we resort to manually writing python programs as solutions to two public collection of programming exercises advent of code aoc and the exercises for the lecture introduction to programming at eth zurich in fall ethz eprog .
aoc .
advent of code is an annual set of computer programming challenges that follow an advent calendar since .
the programming puzzles include a variety of skill sets and skill levels and can be solved using any programming language .
ethz eprog .
introduction to programming course at eth zurich aims to teach students to systematically develop simple programs in java.
the exercises cover a wide scope of programming concepts such as basic data structures iterative and recursive algorithms file operations etc.
.
these two sources are chosen because they are publicly available cover a wide enough spectrum of problems and sufficient amount of alternative solutions can be easily obtained for comparison.
more importantly the solutions do not have complicated dependencies and thus are easy for tracing of bugs.
.
selection of ethz eprog exercises not all problems from ethz eprog were suitable for our dataset.
we evaluated the problems and selected only the most relevant ones according to the following steps.
we exclude non programming exercises exercises which do not require writing code are removed such as exercises that introduce students to version control systems.
exercises specific to java since we want to build a python dataset exercises focusing on java specific topics such as java specific constructors are removed.
trivial exercises problems considered too trivial are removed such as those about basic input output operations.
technology specific exercises this includes e.g.
exercises about the graphical user interfaces guis .
although contracts are useful in the gui programming we consider gui programming to be too technology specific and thus outside the scope of the dataset.
additionally some exercise statements are simplified to make for a more pointed code.
we explicitly mark the corresponding changes in the description of the problem in python files.
we provide the complete list of removed and simplified exercises with the rationale on our dataset website1.
.
dataset construction process all the programs in our dataset are written by experienced developers with years of python programming experience.
each python file is the solution to one programming exercise with functions annotated with contracts using icontract library.
following the common practice in industry both the code and the contracts were written by the same developer.
figure demonstrates the data construction process.
for each exercise we iteratively develop the solution and the contracts ethz eprog 2019 details.html write program with contracts crosshair icontract hypothesis unit testsrun finalize the solutionno obvious errorsok record bugs fail fix re introduce the bugs adaptfigure the flow of our data construction process.
with the help of two testing tools cross hair andicontracthypothesis as well as manually written unit tests.
specifically we first write the solution as python functions or classes together with the contracts for them.
we follow general software engineering advice on writing contracts we fully specify the preconditions while we specify the postconditions and class invariants based on best effort.
then we check the correctness of our python code either by the automatic testing tools or the unit tests.
the solutions that violate the contracts or fail to pass the tests are recorded as bugs.
the developer keeps modifying them to get the final correct solutions which pass all the checks and contain no obvious errors.
the bugs are further adapted by re introducing them to the final correct solution to obtain a minimally different incorrect programs.
note that although the contracts may have mistakes i.e.
they may not correctly encode the problem description our expected use cases for this dataset do not depend on full contract correctness.
.
incorrect programs as we develop the solutions to the exercises we record bugs detected by the automatic testing tools or manually written unit tests.
the buggy programs captured during the development often blur the cause of errors and diverge substantially from the final correct solution.
this is suboptimal since we need to clearly distinguish between expected collateral bugs and the possible errors of testing tools we use.
to provide a better and more precise testbed we convert the recorded bugs into minimal changes of final correct solutions.
specifically we first manually inspect each recorded bug to ensure that it is not caused by a defect in the tools.
then we re introduce the bug into the final correct solution such that the buggy program is curated to be minimally different to the final correct solution.
this makes it easier to confirm the presence of a genuine bug and provides succinct test cases for the testing tools.
the resulting curated bugs are kept in the dataset as the incorrect programs .
we provide an example to illustrate the process of curating a recorded bug to an incorrect program in figure .
although we are able to re introduce most of the recorded bugs some cases are not suitable for re introduction.
this is either because the recorded bugs are not informative enough or because the final correct solution ends up diverging too much from the buggy one to be re introduced in a meaningful manner.
namely 1653python by contract dataset esec fse november singapore singapore a error bus id and min time should be reversed .
wait time bus id min time return min time wait time b correct missed last bus by min time bus id ifmissed last bus by return min time else return min time missed last bus by bus id c error bus id and min time should be reversed .
missed last bus by bus id min time ifmissed last bus by return min time else return min time missed last bus by bus id figure an example how a the recorded error wrong mod.py from aoc day is combined with the b final solution to produce a minimally different c incorrect program.
evidently the renaming of the variable wait time tomissed last bus by as well as the non zero check if missed last bus by have been added after the recorded error but replicated in the incorrect program.
this makes the incorrect program minimally different from the final solution while we keep the relevant bug.
table statistics of the python by contract dataset.
func.
represents python function pre c. represents precondition post c. represents postcondition inv.
represents class invariant.
files loc class func.
pre c. post c. inv.
table distribution of preconditions and postconditions.
univ.
q. bound pattern misc.
precondition postcondition the initial and the final solutions pursue different directions as we had to completely change the approach and re model the problem with different abstractions.
in other cases the bugs result from the under specification of the exercise itself.
we consequently ignore such cases though they represent valid bugs.
python by contract dataset our dataset contains python solutions to the aoc annotated with contracts python solutions to the ethz eprog annotated with contracts python incorrect programs with minimal difference to the solutions to aoc and ethz eprog .table shows the statistics of the correct programs in the pythonby contract dataset.
since a precondition is given as a set of conjunctions the total number of preconditions is calculated as the sum of all the conjunctions.
our dataset consists of python files as the solutions to the exercises and python files as the incorrect programs.
there are more incorrect than correct programs since for each exercise we find zero one or multiple bugs during the development.
the correct programs are broken down into manageable chunks so a file on average contains .
functions.
for a large fraction of the functions we could write the contracts.
among them .
are annotated with at least one precondition or postcondition.
the remaining functions dealt with general inputs so no preconditions were necessary or no postconditions could be defined with meaningful effort or sufficient readability.
we specified very few class invariants because the natural solutions did not usually employ mutable classes.
we classify the preconditions and postconditions in the correct programs into four categories and show the distribution in table .
univ.
q. means the condition involves universal quantifiers for all .
bound means the condition specifies the boundaries on a value.
pattern means the condition defines a matching of a regular expression pattern.
the remaining are regarded as miscellaneous.
as shown in table our dataset covers different kinds of preconditions and postconditions evenly.
this contrasts previous datasets where the basic checks e.g.
non null check dominate .
moreover the complexity shifts from the preconditions with a substantial mass in bound and pattern to postconditions with much less respective mass .
this is expected as the functions and the underlying problems in our dataset are general.
restricting the inputs of a general function is often easier than checking the validity of the result of the function.
use cases while different uses of our dataset are possible we demonstrate its utility by examining how it is used to evaluate and aid the development of two testing tools crosshair and icontract hypothesis .
.
use case crosshair crosshair is a concolic testing tool.
it uses a constraint solver to confirm or refute properties for symbolic inputs over concrete execution paths.
unlike most concolic execution tools that analyze binary executables crosshair models the python language itself.
crosshair natively checks contracts in a variety of formats including the contract format used in our dataset icontract.
application .
we ran the crosshair check command both over the solution files and the files with recorded bugs.
this revealed bugs in both crosshair and the dataset and provided valuable insight into crosshair s performance.
insights .
the python by contract dataset helps improve the stability of crosshair .
in particular some contracts triggered fatal errors in crosshair .
we diagnosed and fixed two crosshair bugs before completing a fully successful check of the solutions.
the two bugs pertained to regular expression matching on sliced strings and directive parsing for some multi line strings.
1654esec fse november singapore singapore jiyang zhang marko ristin phillip schanely hans wernher van de venn and milos gligoric after applying the fixes above we checked the correct solution files.
though one might expect to find no failures crosshair found counterexamples.
with extended timeout settings crosshair is able to find additional counterexamples.
the counterexamples largely pointed to omitted preconditions rather than bugs in the solution itself.
that said in many cases the problems are under specified and a reasonable fix can have been made to either the contracts or the code underneath.
finally the dataset includes python files that contain known bugs most of which are revealed by contracts.
since crosshair is presently able to find counterexamples in some correct solutions we limit our analysis to incorrect programs for which the corresponding correct solution passes crosshair s checks of those .
crosshair successfully found counterexamples in out of those .
.
use case icontract hypothesis theicontract hypothesis is a testing tool that infers strategies for random generation of function s input.
the generated input is supplied to the function under test while the function s postconditions serve as a test oracle checking the correctness.
the hypothesis library is used to generate the data given the inferred strategies.
at current version .
.
the strategies are inferred based on a basic set of patterns matched against the preconditions lower upper bounds and regular expressions .
the generated data is further filtered by unmatched preconditions i.e.
reduced through rejection sampling .
application .
we manually selected function points i.e.
functions or methods of classes for which the tool can infer a feasible generation strategy for the input.
out of total function points in the dataset we are able to cover points for which icontract hypothesis can directly be applied.
we can test further points by wrapping them in more restrictive preconditions since their original preconditions were too permissive and resulted in valid but practically inexecutable strategies e.g.
functions on strings with a length argument for which the strategy generates excessively large numbers .
the remaining points can not be tested as the inferred strategies are computationally prohibitive since the generated data are almost constantly rejected.
insights .
we are positively surprised that such a small testing surface results in a high code coverage.
we can thus cover of code statements with negligible standard deviation over runs .
as it turned out simple preconditions were enough to narrow down the generation strategies such that consequent rejection sampling by the further complex preconditions did not incur too high computational cost.
it is important to note that we heavily apply the recipe for deduplicating the preconditions by refactoring them into separate classes in the dataset instead of writing conditions with all .
quantifiers.
this generalizes well throughout the programs and largely explains the simplicity of the preconditions.
hence as long as this recipe can be applied to keep the preconditions simple we expect other code bases to achieve similar levels of code coverage with icontract hypothesis .
related work contracts.
thinking about program correctness in terms of contracts goes back to seminal works of sir hoare floyd andnaur .
eventually the theory flowed into practice of writing the contracts in the code to be checked either statically at compiletime or at runtime.
this approach found wide popularity with eiffel language followed by java c and others.
contracts in python.
libraries for writing contracts for python likedpcontracts icontract and deal appear in the recent five years.
because of few libraries for python contracts there is also only a nascent community around tools for ensuring correctness of practical python programs based on contracts such ascrosshair andicontract hypothesis .
datasets of programs with contracts in python.
because of the recency of the library support there is impractically little python code with contracts in the wild that can be collected by researchers.
while various datasets capture programs with bugs such as bugsinpy bugswarm quixbugs they contain no contracts.
this makes them thus impractical for tool developers which need insights into kinds of contracts used in practical programs as well as an appropriate testbed see below .
corpora of programs with contracts in other languages.
in contrast to python there are many large program datasets with contracts in other languages.
notably eiffelbase the eiffel s standard library has been meticulously written contracts first .
since contracts are a core feature of the eiffel language solutions to school exercises usually contain contracts similar to our dataset .
others looked into datasets to assess how programmers write contracts in practice.
chalin analyzed a dataset of eiffel projects and 8m lines of code loc .
estler et al.
combed a suite of projects in eiffel c and java with high contract usage totaling 260m loc.
shiller et al.
compiled a dataset of c programs listed on openhub of around .5m loc while dietrich et al.
studied most popular java projects in maven central and casalnuovo et al.
looked into most popular c c projects on github.
nie et al.
proposed a framework deuterium for implementing java methods as executable contracts and created a new benchmark for evaluating the executable contracts.
though our dataset is smaller in scope and volume we see it as a valuable family member of the aforementioned corpora in other languages and hope it to be a first step towards this goal for python community.
as the design bycontract gains more traction in the community we hope that larger and more complex code bases with contracts will emerge.
conclusion in this paper we present the python by contract dataset containing both correct python programs and curated incorrect python programs with contracts.
the python programs in the dataset cover a wide variety of programming concepts with different types of contracts.
we show that it can be utilized by researchers and practitioners for developing and evaluating correctness and testing tools.
our dataset is the first step in this direction and we plan to keep expanding it in the future.