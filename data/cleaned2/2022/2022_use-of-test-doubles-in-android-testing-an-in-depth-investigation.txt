use of test doubles in android testing an in depth investigation mattia fazzini chase choi juan manuel copia gabriel lee yoshiki kakehi alessandra gorla alessandro orso university of minnesota minneapolis mn usa mfazzini umn.edu choix698 umn.edu gnlee umn.edu imdea software institute madrid spain juanmanuel.copia imdea.org alessandra.gorla imdea.org georgia institute of technology atlanta ga usa yoshikikakehi gatech.edu orso cc.gatech.edu abstract androidappsinteractwiththeirenvironmentextensively which canresultinflaky slow orhard to debugtests.developersoftenaddress these problems using test doubles developer defined objects that replace app or library classes during test execution.
although testdoubles are widelyused there islimitedunderstanding ofhow theyareusedinpractice.tobridgethisgap wepresentanin depth empiricalstudythataimstoshedlightonhowdeveloperscreate andusetestdoublesinandroidapps.inourstudy wefirstanalyzeadatasetof1 006appswithpubliclyavailabletestsuitestoidentify which frameworks and approaches developers most commonly use tocreatetestdoubles.wetheninvestigateseveralresearchques tions by studying how test doubles defined using these popular frameworksarecreatedandusedinthetenappsinthedatasetthat define the highest number of test doubles using these frameworks.
our results based on the analysis of test doubles that replace a total of classes provide insight into the types of test doubles used within android apps and how they are utilized.
our resultsalso show that test doubles used in android apps and traditional java test doubles differ in at least some respect.
finally our results show that test doubles can introduce test smells and even mistakes in the test code.
in the paper we also discuss some implications of ourfindingsthatcanhelpresearchersandpractitionersworkingin this area and guide future research.
ccs concepts softwareanditsengineering softwaretestinganddebugging.
keywords test mocking mobile apps software environment acm reference format mattiafazzini chasechoi juanmanuelcopia gabriellee yoshiki kakehi alessandragorla alessandroorso .
.useoftestdoublesin androidtesting anin depthinvestigation.in 44thinternationalconference on software engineering icse may pittsburgh pa usa.
acm newyork ny usa 13pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
introduction most android apps have rich interactions with their environment.
android devices for instance provide built in motion location information and position sensors that apps can use to offer a rich setoffeaturestousers.ingeneral appsinterfacewithexternalweb services theunderlyingandroidsystem third partylibraries as well as content providers exposed by the device.
such extensive interactions complicate the testing of an app as exploring specific behaviors may require complex configurations of the environment and test execution may become slow and result in flakiness.
to mitigate these issues developers can rely on test doubles tds classes that mimic the structure of other classes but offer alternative implementations that are fully controlled by the developerforthepurposeoftesting.inthecontextofandroidapps tds canreplaceclassesdefinedintheappitself classesfromthejava library classesdefinedinthird partylibraries andclassesfromthe androidframework.furthermore dependingontheirpurpose tds maybeclassifiedasfollows i dummies whichareoftenusedto simplyfill inparametersthataremeaninglessforaspecifictest ii stubs whicharesimpleobjectsthatreturnhard codedvalueswhen their methods are invoked iii mocksandspies which are more complexobjectsthatcanverifyinteractionswithotherclasses and iv fakes which consist of partially working implementations that are more efficient than the actual class es they are replacing.
because creating and maintaining tds can involve considerable manual effort researchers have started investigating techniques to supportdevelopersinthistask e.g.
.unfortunately however there is limited understanding of how tds are used in practice whichhindersourabilitytodefineeffectivetechniquesinthisspace.
severalpreviousempiricalstudiesaimedtoidentifygeneraltestingpracticesinthedevelopmentofandroidapps buttheyeither ignored or didnot specifically focus ontds.
other related studies analyzed howjava developers use mockswhen testing traditional i.e.
non mobile software .however someoftheirfindings may not directly apply to android apps or new findings might arise from the peculiarities of the android platform.
tobridgethisgap wepresentanin depthstudyofhowdevelopers create and use tds when developing and testing android apps.
specifically thegoalofourstudyis to getabetter understanding of howtdsareusedintheandroidecosystem and whether tds developed for android apps differ from traditional tds.
in our study we first analyzed a dataset of apps with publicly available test suites to collect information on the frameworks andapproachesusedtocreatetds.thisanalysisshowsthatmockitoandmockito kotlinarethemostpopularframeworksforcre ating tds with .
of the apps in the dataset using either one ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usamattia fazzini chase choi juan manuel copia gabriel lee yoshiki kakehi alessandra gorla alessandro orso of these two frameworks.
we then investigated several research questions by studying how tds defined using these popular frameworksarecreatedandusedinthetenappsinthedatasetthatdefine the highest number of tds using these frameworks.
our results based on the analysis of tds that replace a totalof784classes provideinsightonthetypesoftdsusedwithin androidappsandhowtheyareutilized.inparticular theyshow thatdeveloperscreatetdstoreplacebothclassesintheappand external classes and that different kinds of tds are indeed created includingstubs mocks anddummies.ourresultsalsoshow thattdsusedfortestingappsdifferinatleastsomerespectfrom tds used in traditional java software.
specifically our study found that there are different categories of tds that are prevalent in this context namely tds replacing classes in the android framework configuration classes and gui components.
whereas the first category is not surprising the latter two provide evidence that within android apps configurations are more common and classes are more tightly coupled with gui elements than in traditional java software.
finally our results show that tds can introduce test smells and even mistakes in test code which motivates developing techniques to detect and eliminate these problems.
contributions and significance.
to the best of our knowledge this isthe first studythat classifies how developersuse tds categorizingthembasedontheirpurposeandthroughbothqualita tiveandquantitativeanalyses.webelievethatourfindingsandtheirimplicationscaninformfutureresearchinthisareaandhelpdefine automated or semi automated techniques for better supportingdevelopers in creating and maintaining tds ultimately improv ing the process of testing android apps.
furthermore our study infrastructure and experimental data are publicly available .
background androidappsandtheirtestsaremainlywritteninthejavaorkotlin programming languages .
these tests can run on either the jvm jvm tests or a device device tests .
generally jvm tests can include unit and integration tests while device tests can includeunit integration system and gui tests .
both jvm and devicetestscanusetdstofacilitatetestingactivities1.wedefinea tdasadeveloper definedobjectthatprovidesa possiblypartial replacementforaclassintheapporinanexternallibraryduring testing.
within android apps tds can replace classes defined in the app classes from the java library classes defined in third party libraries and classes from the android framework.
based on thefunctionality that the tds provide to the test code they can beclassified into five main types i dummies ii stubs iii mocks iv spies and v fakes.
app developers can create tds using test mocking2frameworks or by extending implementing classes interfaces.amongtheframeworksthatallowforcreating tds therearebothgeneric e.g.
mockito mockito kotlin powermock andspecialized e.g.
okhttp retrofit 1in this work we discuss tds of jvm and device tests as this grouping is readily available through the source code of android apps generally jvm tests are in the testfolderanddevicetestsareinthe androidtest folder.weleaveasfuturework theanalysisoftdsinrelationtohowjvmanddevicetestscanbedividedintounit integration system and gui tests.
2althoughtheseframeworksareinformallycalled mockingframeworks developers actually use the frameworks to create different types of tds.android test mock test mocking frameworks.
the former allowforreplacingclassesofvaryingfunctionality whilethelatter target classes offering a specific functionality e.g.
classes that connecttoawebserver .wenowdescribehowdeveloperscanusegenerictestmockingframeworkstocreatetdsandthensummarize the characteristics of the different types of tds.
.
generic test mocking frameworks when developers create a td usinga generic test mocking framework theymustfirstspecifytheclassbeingreplacedbythetd.to thisend developerscanuseinitializationmethodsorannotations provided by the framework api e.g.
the mockmethod from the mockitoapi .afterthisstep developerscandefinestubbed methodimplementationsforthetdandspecifywhichmethodcalls madetothetdshouldbeverifiedduringtestexecution.tostuba method developers must specify i the method that should be stubbed ii theargumentstowhichthestubbedmethodshouldre spond and iii thevalue exceptionreturnedbythestubbedmethod.
generictestmockingframeworksofferapimethodsthatcanbe combined to implement this functionality.
for example developers can use when td.m arg .thenreturn val based on the mockito api to specify that the td tdshould return valwhen the method mis called with argument argon the object.
developers can also usetheframeworkapitospecifythemethodcallsthatshouldbe verified.forexample developerscanuse verify td .m arg based on themockito api to checkthat method mwas calledduring test execution on the object tdand the argument passed to the methodwas arg.finally developerscanusetheapisoftheseframeworkstocreatedifferenttypesoftds.inourwork thetypeofa td is not identified by the api method used to create it e.g.
mock in mockito but rather by the functionality it provides.
.
test doubles types thissectionreportsthedefinitionsweusetocharacterizethedifferent types of tds as formulated in related work .
due to space limitations we do not provide here code examples for the differenttypesbutmakethemavailableinouronlineappendix .
dummy a dummy is an object that a test uses to exercise the componentundertest cut butsuchthatneitherthetestcodenor the cut access the object s state during test execution.
tests tend tousedummiestoprovidemethodparametersthatareirrelevant for a specific test.stub astubisanobjectprovidinghard coded i.e.
stubbed answers when its callers invoke the object s methods during test execution.astubmightprovidehard codedanswersonlyforsome ofitsmethods andtheanswersareoftenspecifictotheintentof the particular test using the stub.mock a mock is an object that offers a replacement for a class and suchthat some of theinteractions with theobject are verified during test execution.
the verification task is defined in the test code but carried out within the mock object.
a mock object might also provide hard coded answers for some of its methods.spy a spy is similar to a mock object in that some of the interactionswiththeobjectareverifiedduringtestexecution.however differentlyfromamockobject theprimaryoperationsforverifying the behavior of the spy are defined in the test code rather than authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
use of test doubles in android testing an in depth investigation icse may pittsburgh pa usa within the td.
usually these operations are encoded as developerdefined assertstatements.asinthecaseofamockobject aspy might also provide hard coded answers for some of its methods.
it is worth noting that this definition is consistent with related work but differs from the use of the term within mockito .specifically inmockito aspyisanobjectforwhichreal method implementations are invoked during test execution unless they are stubbed.
because the two definitions focus on different aspects ourfindingsshouldnotbedirectlymappedtomockito s spiesand shouldbe insteadinterpreted basedon thefunctionality provided by the td.fake a fake is an object that provides a working implementation for some of its methods but such that the implementation is made more efficient through shortcuts not suitable for production.
methodology toshedlightonhowandroiddeveloperscreateandusetds we investigated the following research questions rqs rq1 which frameworks and approaches are most commonly used to create tds?
this rq aims to identify the most commonly used frameworks and approaches for creating tds in thedomainofandroidapps.weusethefindingsfromthisrq to scope the analyses of the remaining rqs.
rq2 whattypesofclassesdodevelopersreplacewithtds?
thegoalofthisrqistocategorizethetypesofclassesthatare commonlyreplacedbytds.intherq wealsoprovideadetailed analysisoftheandroidframeworkclassesthatarereplacedby tds.
rq3 what tdtypes dodeveloperscreate?
thisrq investigatesthetypesoftdsusedinthecontextofandroidapptesting.
this rq also analyzes whether developers use different types of tds for different types of classes.
rq4 how do tests use tds?
while rq2 and rq3 characterize tds through a manual inspection of the code associated with tds this rq aims to characterize the runtime properties of tds.
specifically itinvestigateshowtestsusestubbedmethodsand how often interactions with tds are verified.
rq5 whatproblemscantdsintroduce?
becausetdsare usuallymanually created theymayintroducetestsmellsoreven errorsinthetestcode.thisrqinvestigatesissuesemergingfrom the use of tds.
the overall goal of these rqs is to inform researchers and practitioners and provide insights that can guide them in developing techniquesandtoolsforcreating using andmaintainingtds.to answer our rqs we divided our study into two parts.
first we identifiedwhichframeworksandapproachesdevelopersmostcommonly use to create tds rq1 .
then we studied how the tdsdefined with the most popular frameworks and approaches are createdandused rq2 rq3 rq4andrq5 .therestofthissection describesthequalitativeandquantitativeanalysesweperformed to answer the rqs.
.
frameworks and approaches for tds inthissection wedescribeourmethodologyforansweringrq1.
specifically wedescribethedatasetweused theframeworksand approaches we considered and the analysis we performed.
.
.
dataset.
to answer rq1 we needed a dataset containing android apps with a publicly available test suite.
to the best of our knowledge thedatasetreleasedbylinandcolleagues isthe most recent one satisfying this requirement as it contains appswithtests.theseappswereminedfromgithub andeachappis available on at least oneof app markets including the google playstore .whenweclonedtheapprepositories 972ofthe apps were still available on github.
to ensure our dataset doesnotincludepossiblytrivialapps wefurtherfilteredthedataset to only contain apps available on the google play store.
after this step the dataset contained apps.
weperformedasanitychecktoverifythattheappshavetestsin their testand androidtest directories whicharethedefaultlocations used to store jvm and device tests respectively.
for this purposewebuiltanautomatedanalysisontopofjavaparser and ktlint to traverse the abstract syntax tree ast of the test files looking for methods annotated with test smalltest mediumtest largetest o r uithreadtest we classified a test as any method having any of these annotations.
note that by op erating at the ast level the analysis avoids considering tests incommented code.
the analysis also excludes tests automaticallycreated by android studio which can be identified based on thename convention used by the ide.
our analysis identified someapps without any meaningful test.
manual inspection confirmed that atthetimeweretrievedthem thoseappshadnotestsatall had tests that had been commented out or only had tests automaticallycreatedbyandroidstudio.afterremovingtheseapps apps remained in the dataset.
after manually inspecting the list of remaining apps we observedthatcertainwidelyusedapps suchasankidroid overfivemilliondownloads werenotpresentinthedatasetdespitebeingavailableinthecuratedlistofopen sourceappsprovidedbyf droid whichwasconsideredin .wenoticedthatthese apps have multiple androidmanifest.xml files and that apps with these characteristic were excluded by lin and colleagues .
therefore to avoid missing relevant apps we decided to add apps i listed on f droid ii available on github iii present on the googleplay store and iv having meaningfultests.
thisresultedintheadditionof173appstothedataset foratotalof1 006apps.
we used this dataset to answer rq1.
.
.
frameworks and approaches considered.
in rq1 we investigated how oftendevelopers create tds usingeither generic or specialized test mocking frameworks or extending implementingclasses interfaces.toensureweconsideredacomprehensive setofrelevantframeworks weperformedagooglesearchusing androidtestmocking 3asthesearchtermsandanalyzedthefirst results.
our online appendix contains the complete search results.
based on the search results we considered the generic test mocking frameworks easymock jmock mockito mockito kotlin mockk andpowermock whichall allow for creating tds as described in section .
wealsoconsideredandroidtestmock mockserver okhttp retrofit robolectric andrxandroidble as additional specialized frameworks.
android test mock provides 3we used the word mocking because developers and the documentation of multiple frameworks use this term to refer to test doubles in general.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usamattia fazzini chase choi juan manuel copia gabriel lee yoshiki kakehi alessandra gorla alessandro orso stubs and mocks for ten specific classes of the android framework.
mockserver okhttp and retrofitsupport the creation of tdsfor classes communicating with a web server.
robolectric allows for running tests interacting with the android framework on the jvm byusingalargesetofclassesthatofferasimplifiedimplementation ofandroidframeworkclasses.robolectricalsoallowsappdeveloperstoimplementtheirownreplacementsforandroidframework classes thesedeveloper definedreplacementclassesarethosewe consider in this study.
finally rxandroidble is a library that facilitatesbluetoothcommunicationsandofferssupportforreplacing the framework s classes during testing.
.
.
rq1 which frameworks and approaches are most commonly used to create tds?
analysis.
to identify the general and specialized test mocking frameworks used by a certain app we firstidentified all the relevant importstatements for each framework e.g.
org.mockito for mockito and then checked the import statementsintheastsoftheapp stestfiles ifatestfileusedanimport statement of a certain framework we considered the app as usingthat framework.in that case theanalysis also computedthe numberoftestfilesusingthatframework soastoprovideanindicative measure of the extent to which the framework was used by theproject.
it is worth noting that this measure could be computeddifferently and possibly in a more accurate way e.g.
by consideringall theapimethodsin theframeworksandidentifying calls to these methods in the test code .
however we believe that this approximationissufficient as weusethisinformationonlyas asecondarymeasure withtheprimaryonebeingthenumberof apps using the framework and this measure does not affect the mainfindingsofthestudy.todeterminewhetheranappextends implements classes interfaces for creating tds we analyzed the asts of the app s test files and looked for classes that i contain dummy stub mock spy or fake intheirname ii have anamethatdoesnotendwith test or tests and iii arepart ofafilethatdoesnotusetheimportstatementsfromthegeneral and specialized frameworks we considered.
this strategy is in line with an approach previously used in related work .
if an app hadsuchaclass weconsideredtheappasextending implementing classes interfaces for creating tds.
.
detailed analysis of tds after investigating which frameworks and approaches developers usetocreatetds weidentifiedmockitoandmockito kotlinasthe most popular frameworks for creating tds in java and kotlin code see details in section .
consequently we focused the remaining partofourstudyonthesetwoframeworks.thispartincludesboth manual qualitative analyses and automated quantitative analyses.
we nowdescribeour methodologyto select theten appsand detail the analyses we performed to answer the remaining rqs.
.
.
apps.
our qualitative analysis focused on the ten apps with thehighestnumberoftdscreatedusingmockitoormockito kotlin and whose tests are maintained.
we focused on ten apps due tothe significant amount of manual effort involved in this part of the study for both preparing the apps and performing the analysis.
for example even simply building the apps can be extremely timeconsuming .asfortheanalysis therearemanytasksthatinvolve a significant manual work including classifying the types ofclassesreplacedbytdsandmanuallyidentifyingthetypesof tds.
although focusing on a smaller set of apps may hinder the generalizability of our results as we also discuss in section it allowed us to perform a detailed analysis of how developers create and use tds and get valuable insights.
to identify the number of tds in an app we analyzed the mockito and mockito kotlin apis identified api methods e.g.
mock and annotations e.g.
mock that can be used to createtds parsedtheastsofthetestfilesintheapptocollect the locationsusing such methods orannotations and counted the number of such locations.
to identify whether an app s tests were maintained we analyzed the app s repository counted the number of commits of the test files in the year preceding the beginning ofour study august andconsidered the teststo be maintainediftheapphadonecommitpermonthonaverageonthe test files.
the rationale for using this second criterion is that tests that are maintained are more likely to be relevant.
table reports thetenappsweselectedbasedonthisstrategy.foreachapp the table provides an identifier id a the app s name name the app s category as listed on the google play store category the app s version considered version the lines of code in kloc for the app s source files sl k the lines of code in kloc for the app s testfiles tl k andthenumberoftdsintheappcreatedusing mockitoormockito kotlin total underthe testdoubles header .
itisworthnotingthatsixofthetenappsalsouseadditionaltestmocking frameworks beside mockito or mockito kotlin.
specifically sixapps a02 a04 a06 a08 a09 anda10 create12class replacements using robolectric two apps a08 and a09 create tds using powermock and one app a06 creates one td using okhttp.
since our analysis is based on mockito mockitokotlin tds we believe that considering the few tds created using other frameworks would impact the results only marginally.
.
.
rq2 what types of classes do developers replace with tds?
analysis.
to answer rq2 we performed four analyses.
first we characterized the functionality provided by the classes.
second we identified whether the classes belonged to the app the java library third party libraries or the android framework.
third we studied thedependenciesofthoseclassesthataredefinedintheapp.finally weperformedacategorizationoftheclassesthatarereplacedby tds and are part of the android framework.
thefirstoneisaqualitativeanalysisthatcombinesdeductive inductive andaxialcoding .deductivecodingisasystematic approachformanuallycoding i.e.
labeling textualcontentstartingfromanalreadyavailablesetofcodes i.e.
labels .inductivecoding derivesnewcodesbasedonasystematicanalysisofthetextdata.
axial coding relates codes to one another and finds higher level codes that represent abstractions of the original codes.
inouranalysis acodeisalabelthatcategorizesthefunctionality providedbyaclass whichweinferredbyanalyzingthesourcecode and the documentation of the class.
we also analyzed any class dependenciesthat mayhelp clarifythe classfunctionality andthe codeofthetdreplacingtheclass.specifically wefirstlookedat the test code using the td to identify the part of the app being tested.
we then focused on the class being replaced by the td and inspectedthenameoftheclass importeddependencies declared authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
use of test doubles in android testing an in depth investigation icse may pittsburgh pa usa table characteristics of the ten apps and their tests considered in the second part of our study.
ida name category versionsl k tl k test doubles pc analysis tdt analysis tests totaljvmdevice total cbsample cbtotaljvmdevice a01andfhem personalization .
.
.
.
a02ankidroid education .
.
.
a03anysoftkeyboard tools .
.
.
a04nextcloud productivity .
.
.
.
a05opensrp medical .
.
.
.
a06streetcomplete travel local .
.
.
a07travel weather travel local .
.
.
.
a08wifi analyzer tools .
.
.
.
a09wikimedia commons photography .
.
.
a10wordpress productivity .
.
.
.
methods used variables and provided code comments.
we also used the same procedure to inspect the classes used by the class in the case that this operation was necessary to better understand the functionality provided by the class.
overall we analyzed classes.
table reports the number of classes analyzed for each app column totalunder the pc analysis header .thesearealltheclassesassociatedwiththetdsweconsidered whichweidentifiedbystaticallyanalyzingthecompiled code of the tests.
specifically we compile the tests retrieve the locations where developers initialized tds e.g.
where developers usethe mockmethod andextracttheclasstypesassociatedwith the objects.
we built this analysis on top of soot .
ourqualitativeanalysisisdividedintothreepartsandperformed by two raters which are two of the paper authors.
in the first part oftheanalysis thetworatersanalyzedasampleof259classesto define the analysis codebook a document detailing for each code thesetofrulesspecifiesthecharacteristicsthatshouldbeobserved to assign a code to a class.
the set of rules also includes typical examples of classes having a specific code.
the sample size used to create the codebook was created using stratified random sampling and is statistically significant with a confidence level cl and a5 marginoferror me .table1reportsthesamplesizesweused to create the codebook column cbunder the pc analysis header .
thetworatersusedthecategoriesidentifiedbyrelatedwork astheinitialsetofcodesforthecodebook deductivecoding .
in the process of analyzing the classes in the sample the raters increased the number of categories to inductive coding andthen grouped the categories into five main groups axial coding .
thisiterativepartoftheanalysistooktheratersaroundtwopersonmonths to complete.
table reports the codes produced by this partoftheanalysis.theentirecodebookweusedisavailableinour online appendix .
our analysis produced two categories that arenotpresentinrelatedwork configuration andguicomponent.
webelievethatthesenewcategoriesemergedbecausethesoftware domainwetargetischaracterizedbyaspects e.g.
guicomponents that are not a key part of the software domains analyzed in related work .
conversely our codebook does not include some ofthecategoriesidentifiedinrelatedwork javalibrary andexternal dependencies becausewedistinguishbetweenclassesintheapp the java library third party libraries or the android framework laterinanorthogonalcategorization.finally ourcodebookcontains category generic for classes whose functionality did not fall into a bigenoughcategoryduringtheaxialcodinganalysis.thiscategory includesclasseslabeledas domainobjects inrelatedwork table2 codesusedtocategorizetheclassesreplacedbytds.
code summary description configuration class used to manage the app s settings.
database class that performs database operations.
gui component class that is part of the app s gui.
networking class that perform network operations.
generic class that provides a functionality not falling in the other categories.
and can also include classes from the android framework or externallibrariesthatcanbeconsideredasdomainobjectswhen the framework or libraries are considered in isolation.
after creating the codebook the two raters analyzed of the remaining classes using the codebook i.e.
they used the codebook rulestocategorizetheclasses andwemeasuredtheirinter rater reliability i.e.
thedegreeofagreementamongratersintheanalysis usingthekrippendorff salphacoefficient .basedon the codes assigned by the two raters the alpha value was .
which indicates high reliability.
after discussing and resolving mismatching codes the two raters proceeded with the last part of the analysis and coded the remaining classes.
given the high value of their inter rater reliability they equally split the remaining classes and coded them independently.
after finishing the coding process the raters also identified whethereachanalyzedclassbelongedtotheapp thejavalibrary a third party library or the android framework.
then for each of the classes in the app we identified whether the class was directly coupled with the android framework by checking its dependen cies using an ast parser that analyzes the import statements inthe class.
finally we identified the most recurring classes from the android framework replaced by tds and performed a detailed categorization based on their containing package.
.
.
rq3 what td types do developers create?
analysis.
to characterize the types of tds that appear in the test code we conducted a qualitative analysis based on deductive coding where the codeindicatesatypeoftd.toassignacodetoatd westudiedthe functionality of the td by inspecting the test code by focusing on themethodsinthemockitoapiandonassertionstatements.forex ample ifthetestcodeonlycreatesthetdobjectwithoutspecifyinganyadditionalbehaviorforit wewouldclassifythetdasadummy.
asanotherexample ifthetestcodecreatesthetdobjectandstubs oneofitsmethods e.g.
usingthe when x.m .thenreturn y construct frommockito wewould classifythe tdas astub.
because different tests might define a different behavior for the same td authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usamattia fazzini chase choi juan manuel copia gabriel lee yoshiki kakehi alessandra gorla alessandro orso table codes used to categorize the types of tds.
code summary description dummy the behavior of the test double is not stubbed nor verified.
stub the test double offers stubbed method implementations.
mock the interactionswith the test double are verified.
spy the test verifies the test double s interactions using assertions.
fake the test double provides a simplified implementation.
object e.g.
when the td is created as a test class attribute our analysis might assign multiple codes to the same object.
wesplitthiscodingprocessintothreeparts aswedidforthe qualitative analysis of rq2 and the same two authors that performed the analysis of rq2 performed this analysis as well.
in the firstpartoftheanalysis theratersanalyzedastatisticallysignificantsample cl andme of331tdstodefinetheanalysis codebook.
table reports the sample sizes we used to create the codebook column cbunder the tdt analysis header .
table reportsthecodesusedinourcodebookandtheirsummarydescriptions.
the entire codebook is available in our online appendix .
aftercreatingthecodebook thetworaterslabeledastatistically significant cl andme sampleoftdsforeachapp excludingsamplesalreadylabeledwhencreatingthecodebook for atotalof1 192tds.thesamplesizesperapparereportedintable1 samplecolumn .weanalyzedstatisticallysignificantsamples instead of the whole dataset because the effort required to do so wouldbeconsiderable estimatedataroundfourperson months .
inthesecondpartoftheanalysis theraterscoded10 ofthetdsinthesamples andwemeasuredtheirinter raterreliability.basedon the coding results the krippendorff s alpha value was .
which indicateshighreliability.asforrq2 afterdiscussingandresolving mismatching codes the two raters split the remaining tds and coded them independently.
after categorizing the types of tds we combined the results fromrq2andthisrqtounderstandhowthetypesoftdsrelate to the type of class they replace.
.
.
rq4 how do tests use tds?
analysis.
to further characterize key properties of tds we analyzed how tests use tds byrunningthetestsoftheappswithaninstrumentedversionof mockito4while collecting various data.
as the tests ran our instrumentation logged the calls made to the methods of the tds identifiedwhichcallsweremadetostubbedmethods andrecorded how many of these calls were being verified during test execution.
the instrumentation also computes various properties of these methods how many unique methods were being stubbed the locationinwhichthesemethodswerestubbed andwhethermethods return hard coded values or intended exceptions.
table in thetestssection on the right reports the number of executed tests both overall total and grouped by test type jvm ordevicetests .
.
.
rq5 what problems can tds introduce?
analysis.
toanswerrq5 ouranalysisidentified unnecessarystubs stubbedmethod never called during test execution and mismatched stubs stubbed methods called with arguments that differ from those specified for the stub e.g.
a stub tdspecified as when td.m .thenreturn andthencalledbyatestas td.m .althoughtheseissuesmight 4becausemockito kotlin internallyrelieson mockito ourmockito instrumentation worked for it transparently.table4 frameworksandapproachesconsideredinourstudy together with their occurrences in our dataset of apps.
type framework approach name appsoccurrences generic test mocking frameworkseasymock jmock mockito mockito kotlin mockk powermock specialize test mocking frameworksandroid test mock mockserver okhttp retrofit robolectric rxandroidble extend implement classes interfaces not lead to test failures these problems often indicate potential issuesintheunderliningtestcode.unnecessarystubs inparticular mayindicatesuperfluous dead oroutdatedcodeinthetests.furthermore both unnecessary and mismatched stubs may indicatetests that are not checking for the intended behavior of the cut.
to identify these kinds of stubs we ran the tests with the stubbing hintsoptionofmockitoenabled byaddingatestruletothe tests.
it is worth noting that the next major release of mockito will notify developers when these problems occur which indicates that they are perceived as potentially relevant issues.
results in this section we present the results of our study on how developers create and use tds when testing android apps.
.
rq1 which frameworks and approaches are most commonly used to create tds?
table4showshowmanyofthe1 006appsinourdatasetusethe frameworksandapproachesweconsidered.foreachframework ap proach thetablereportsitsname framework approachname the numberofappswithteststhatusetheframework approach apps and the number of files using the framework approach occurrences .forrobolectricandtheapproachbasedonextending implementingclasses interfaces thenumberofoccurrencesidentifiesthenumberof developer definedtdclasses.ofthe1 006appsconsidered apps use either a framework or an alternativeapproach to create tds.
adding the number of apps in column appsresults in a higher number because some apps use more than oneapproachtocreatetds andthusappearinmorethanonerow.
mockito is the most used framework with apps and testfilesusingit.thisresultisinlinewiththefindingsfromrelated work whichidentifiedmockitoasthemostpopularframework for java based projects.
our results also highlight that mockitokotlinfindsasignificantadoptioninandroidapps with55appsand605testfilesusingthatframework.webelievethatthisresultisdue tothefactthatkotlinisgainingpopularityamongthelanguages used to develop android apps .
the total numberof apps using either mockito or mockito kotlin is which accounts for .
oftheappsinourdataset.afterfurtheranalyzingthetestcode of these apps we found that developers use the two frameworks authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
use of test doubles in android testing an in depth investigation icse may pittsburgh pa usa morefrequentlyin jvmteststhanindevicetests.specifically we observed that .
of the apps with jvm tests use one of the twoframeworkswithinthesetests.thisisincontrastwithwhat happens for the apps with device tests where only the .
oftheappshaveteststhatuseeitheroneofthetwoframeworks.furthermore among the apps using mockito or mockito kotlin thereare7 303tdsdefinedacross18 747jvmtests and315tds definedacross3 524devicetests.thisbiggapseemstoindicatethat tds are a relevant aspect of jvm based testing of android apps whereas they play a smaller role in the context of device tests.
ourresultsalsoshowthatgenerictestmockingframeworksfind awideradoptionthanspecializedtestmockingframeworks.specifically .
of the apps use a generic test mocking framework while only .
of them use a specialized one.
note that although developers do not often use robolectric to create manually defined tds only .
of the apps defines such tds they use the tds already provided by the framework more extensively .
of the apps in our dataset have tests that rely on those tds.
when we analyzed apps with tests that create tds by extending implementingclasses interfaces wefoundthatonly6.
oftheappsinour dataset use this approach.
our analysis also revealed that .
of themalsouseagenerictestmockingframework.thisresultseems to suggest that at least in some cases developers find it necessary to create ad hoc tds in addition to those they create using test mockingframeworks whichmay indicatetheneed foradditional features within these frameworks.
finally by comparingapps thatusea frameworkorsome alternativeapproachtocreatetdsandappsthatdonot weobserved that the average number of tests for the apps in the former category is .
andthe median is while forthe latter category the averageis13.9andthemedianis5.amann whitneyutest cl shows the difference between the two groups to be significant.
aswefurtherdiscussinsection5 webelievethisisapotentially interesting result that deserves further investigation.
rq1 answer mockito and mockito kotlin are the most widely used frameworks with .
of the apps using either one of thetwo frameworks.
furthermore generic frameworks find a wider adoption than specialized frameworks or approaches.
finally some apps use multiple approaches which may indicate the need for extending the individual approaches.
.
rq2 what types of classes do developers replace with tds?
figure figure and table present the main results of the analysesweperformedtoanswerrq2.fig.1reportsthecategorization forthetypesofclassesreplacedbytds showingthepercentage of each category for each app and the number of classes in each category.fortheappsweconsidered thegenericcategoryincludes the highest number of classes replaced by a td.
this result is in line with related work as we included domain objects in this category and is expected as this category is the broader category among those we considered.
the remaining categories account for .
of the classes we analyzed with the gui component category being the most fre quent and including .
of the classes.
all the classes in thiscategorywerereplacedby tdsinjvmtests.theremainingthree categories database networking andconfiguration includeclassesthatprovideaccesstoexternalresources.alltheappscreatingtds for either one of these categories do so for multiple classes e.g.
wordpress a10 createstdsfor31classesaccessingthenetwork .
after analyzing the types of classes replaced by tds we investigated whether those classes are defined in the app the java library third partylibraries ortheandroidframework.figure2illustrates the results of this analysis.
across all apps there is an approxi mately equal balance between the classes defined in the sourcecode of the apps and those defined in either third party librariesor the android framework.
specifically .
of the classes that arereplacedbytdsaredefinedintheapps sourcecode and43.
of them are defined in external dependencies.
our analysis alsorevealed that of the classes defined in the app s source codeand replaced by tds have external dependencies and for .
of those the dependencies involve the android framework.
this resultdiffersfromrelatedworkanalyzingmockingintraditional java programs where the percentage of classes replaced by tds and with external dependencies is lower than furthermore .
of the classes replaced by tds belong to the android framework.
table reports for the ten most recur ring packages that contain those classes the number of unique classesfromthepackages column classes andthenumberof times that those were replaced by a td column occur.
.
the package containing the highest number of classes and occurrences isandroid.content which contains classes used to share content betweenapplicationcomponentsthroughtheframework.forexample classes android.content.context and android.content.intent werereplacedbytdstoallowtestcodetoretrievespecificapplication data during test execution.
the top packages also include android.location which provides classes for location based services.
the classes from this package that were replaced by tds provide specificlocation information orfacilitate access to theinformation during testing.
amongtheandroidframeworkclassesreplacedbytds none arefromthe android.hardware package whichcontainscameraand sensorclasses evenifthreeapps a02 a06 anda10 useclasses from thispackage.
we findthis resultinteresting andbelieve that suitably replacing those classes might help in producing bettertest suites.
we additionally observed that the six apps that use robolectric a02 a04 a06 a08 a09 anda10 alsoreplaceclasses defined in the android framework suggesting that better robolectricmodelsmaybeneededbecauseeithertheydonotincludesome commonly used classes or if they do they are not used.
rq2 answer developers replace classes that fulfill domain logic .
model gui components .
access the network .
perform database operations .
and provide appconfigurations .
.inalargenumberofcases developerscreatetdsforclassesthatareexternalorcoupledwith external dependencies.
developers also replace android classes to be able to access specific app data during testing.
5we computed this number by aggregating the results from rq1 in .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usamattia fazzini chase choi juan manuel copia gabriel lee yoshiki kakehi alessandra gorla alessandro orso figure types of classes replaced by tds.
figure location of the classes replaced by tds.
table packages of classes from the android framework frequently replaced by tds.
idppackage classes occur.
p01android.content p02android.widget p03android.view p04android.app p05androidx.lifecycle p06android.os p07android.location p08androidx.fragment.app p09android.net p10android.content.res .
rq3 what td types do developers create?
figure shows the different types of tds in the apps we considered.
figure displays the relative frequency for each type andis based on the statistically significant samples of table tdt analysissection .acrossallapps weidentified28unusedtds e.g.
attributes annotated with mockbut never used by any test which are not reported in figure .
for this reason and because we might assign more than onetype to a single td e.g.
when a td is used differentlybydifferenttests thetotalnumberoftypesinthefigure mightdifferfromthesamplesizereportedintable1.ourresults showthattheappsdousedifferenttypesoftds andthatdummies stubs and mocks are the most prevalent types of tds.
specifically .
of the tds are dummies .
are stubs are mocks andonly1.
arespies.notably ouranalysisdidnotidentifyanyfakes inthetenappsweconsidered.thisresultwasexpected asthese apps rely on mockito and mockito kotlin which do not support the creation of fakes.
overall these numbers show that developers oftendefinestubbedimplementationsformethodsbutalsoverify interactions between components under test and the tds.
to provide a different view on these data the first part of table6reportsthenumberofdummies stubs mocks andspiesforeach type of class identified in rq2.
a chi squared test at a significance level of rejected the null hypothesis that tds types are independent from thetypes of classes.
thesecond part of table presents td types with respect to the classes grouped based on where they are defined.
also in this case a chi squared test at a significance level of rejected the null hypothesis that tds types are independent from classes grouped by location.
amongthe twocategories thatare notpresentin relatedwork gui component and configuration the most frequent types of tds aremocks andstubs respectively.mocksfortheguicomponentsaremostlyusedtoverifyinteractionsthatshouldor shouldnothappen whereasstubsfortheconfigurationcomponents allow the tests to retrieve specific configuration values.
rq3answer dummies .
stubs .
and mocks frequently occur in the tests of the android apps we considered.
this seems to indicate that although a large number of tds are trivialclassescreatedsimplytoallowtheteststorun developers also make extensive use of stubbed implementations and frequently use tds to verify interactions.
.
rq4 how do tests use tds?
table reports the results of the dynamic analysis described in section .
.
.
the table shows the characteristics of the calls made by the tests on both stubbed and verified methods.
for each app it reports the following information number of tds whose methods arecalledatleastoncebythetests td forbothstubbedandverified methods total number of calls to stubbed methods made by the tests smc totalnumberoflocationsintheteststhatmakecallsto stubbed methods cl number of unique methods that are stubbed at least once whether they are called or not by the tests sm number of different locations in which any method is stubbed sl total number of stubbed methods returning values vr total number of stubbed methods returning exceptions er and total authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
use of test doubles in android testing an in depth investigation icse may pittsburgh pa usa figure types of tds percentages .
number of method calls verified vmc .
in total the tests made 111callstostubbedmethods.analyzingthe1 493codelocations making these calls and the unique methods being called we noticed that tests tend to rely heavily on a small subset of the stubbedmethods.forexample forthreeoftheapps a01 a03 and a04 a single stub accounts for over of the calls to stubbed methods.wealsoinspectedthecodedefiningandusingthethree most called stubbed methods for each app and observed that themajorityofthesemethodsarestubbedtoimprovetestexecution performance e.g.
to avoid reading from configuration files .
table7alsoshowsthatdevelopersstubbedthesamemethods at different code locations.
specifically the unique stubbed methodsarestubbedin2 174differentlocations and423ofthese methods are stubbed more than once which seems to indicate thattestsusestubbedmethodsfordifferentpurposes.furthermore althoughthemajorityofstubbedmethodsreturnvalues column vr some of them return exceptions column er .
the numbers in the table for the verified methods show that tds were used to verify method calls.
consideringthat the total number of test execution is see table this roughly correspond to oneverified method call for every other test execution onaverage .thisresultfurtherconfirmsourfindings from rq3 that tds are frequently used to verify interactions.
rq4 answer tests perform a large number of calls to stubbed methods 111callsacross6 553testexecutions .manyofthesecallsinvolvestubscreatedto improveperformance andspeedup test execution.
methods are often stubbed at multiple locations indicatingthattestsmaystubthesamemethoddifferentlyfor different purposes.
.
rq5 what problems can tds introduce?
the analysis we discussed in section .
.
revealed that all the apps we considered contain unnecessary stubs.
in many cases this happens becausethe test code that createsstubs is overlygeneral and stubsare created alsoby tests thatdo not actuallyneed them.
the most extreme example of this issue is in app andfhem a01 table td types for the different class types abs.
values .
category dummy stubmockspy configuration database gui component networking generic app java third party lib.
android table7 characteristicsofthecallsmadebythetestsonboth stubbed and verified td methods.
idastubbed verified tdsmcclsmslvrertdvmc a01368155747358484055 a0213039546356054636133 a0359611104974112812176261445 a042083779553776742139236 a059559929244868604648 a06405711796421018129180206 a071131855538696183544 a0840665923014440439311497781 a09115135434312311677086 a10174079875493019349322374508 in which a method in the test code defines a stub for each of the 767resourcestrings oftheappandiscalledby135teststhat do not actually need the stubs.
overall in the tests we considered unnecessary stubs are created at test code locations.
it is worth noting that this problem can be seen as an instance of the general fixture test smell .
although not as prevalent as unnecessary stubs our analysis alsorevealed19issuesrelatedtomismatchedstubsin4different apps a02 a07 a08 and a10 .
mismatched stubs are problematic because a test may exercise a behavior different from the intended oneandstillpass.forexample inankidroid a02 atestmeant to exercise specific lines in the code never reaches them becausethe call to a mismatched stub returns a value different from theexpected one which causes the execution of a different controlflow without affecting the outcome of the test.
we provide a full discussion of this issue in our online appendix .
rq5answer the106 545unnecessaryand19mismatchedstubs reported by our analysis provide evidence that tds can lead to testsmellsandtothetestingoffunctionalitythatdiffersfrom the intended one.
discussion and actionable insights inthissection wesummarizethemainfindingsofourstudyand discuss some insight and actionable items derived from them.
importanceoftdsinandroidtesting.
beforethisstudy it was not known how frequently android apps use a framework or some alternative approach to create tds.
our study shows that authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usamattia fazzini chase choi juan manuel copia gabriel lee yoshiki kakehi alessandra gorla alessandro orso aconsiderablepercentage roughly40 oftheappsthatcontain automatedtestsuseatleastoneofthoseframeworksorapproaches.
thisresultmotivatestheinvestigationanddevelopmentoftechniques that support developers in creating and maintaining tds .
the study also finds that these apps tend to have a larger test suite as compared to apps that do not use tds.
we believe that it is worthwhile to perform additional studies possibly including interviews to developers to assess whether this is just a correlation or it instead indicates that extensive testing of an app is likely to require the use of tds.
the latter would provide an even stronger motivation for the development of techniques that support the creation and maintenance of tds.
supporting mockito and mockito kotlin.
similar to what wasfoundbystudiesonjavaprojects weidentifythatmockito and mockito kotlin which are used by one third of the apps inour dataset are the most frequently used frameworks.
however comparingtheadoptionofthesetechnologiesbetweenandroidand javaprojects ourresultsshowthatthesetwoframeworksaremore widelyusedwithin androidappsthanmockitowithin traditional javaprojects adoptionrate .onepossibleexplanationfor this difference is that android apps are more tightly coupled with their external dependencies and it is therefore necessary toaccountforthesedependenciesduringtesting.infact amongthe tenappsweconsideredinourdetailedanalysis amajority ofclassesreplacedbytdseitheraredefinedinexternaldependencies or use external dependencies.
this is in contrast with what was identified by related work in the domain of java programs wherethis percentagewas .theseresults inaddition tomotivating the development of techniques for creating and maintaining tds also indicate that the techniques would be mostly useful if they would support mockito and mockito kotlin.
helpingdeveloperscreatetds.
whencreatingtests developers must decide which parts of a system to replace with tdsand which tds to use .
we believe that the results of our study and possibly further studies along similar lines can help guide the development of recommender systems that help developers identify classes that should be replaced by tds.
as a first observation our results show that android developers usedifferenttypesoftds andthatstubbedimplementationsand mocks that verify interactions between code under test and tds are prevalent.
as far as stubs are concerned we observe recurring patterns.
in particular developers stub methods for data communications that are hard to setup e.g.
communications with classes inthe android.content package orforspecifictypesofdata e.g.
data associated with classes in the android.location package .
developersalsocreatestubstoimprovetestexecutionperformance.
asfortdsthatverifyinteractionsbetweentdsandcomponents undertest wefindthatthisisdoneforallthetypesofclasseswe analyzed and that both interactions that should and should not happenareverified.basedontheresults webelievethat techniques that support creating and maintaining tds should focus on stubs helpingdevelopersidentifywhichmethodsrequirestubbingandwhat values should be returned by these stubs but also on mocks helping developers also decide which interactions to verify.
identification of which methods to stub could be done by analyzing how the data is generated within the method e.g.
whether itislocationdependent orbyexaminingtheperformancecostofdifferent methods called during testing.
this latter case is partic ularly important to ensure that jvm tests run quickly as that isone of the goals of those tests .
as for the values or exceptions that should be returned by the created stubs test carving techniques couldbeusedtoidentify record andsuggest values flowing between the boundaries of tests and code under test.
similarly approaches that analyze the interactions between testsandcodeundertestcouldbeusedtoidentifyinteractionsthat shouldandshouldnothappen createcorrespondingchecks and suggest them to developers.
android specific tds.
an additional way in which our results could be leveraged to develop techniques that support android developers isby analyzing theandroid specific tds thatare used intheapps.specifically ouranalysisofthedifferenttypesofclassesthatarereplacedbytdsidentifiestwocategoriesofclassesthatare characteristic of androidapps configuration and guicomponent.
because configuration and gui component classes are typically part of the android framework or inherit from classes therein they can beeasilyidentifiedandproposedtothedeveloperaspossiblecandidates for replacement by tds.
furthermore our study found thata large percentage of classes replaced by tds consists of classes that either are external dependencies or use external dependencies andthatthishappensmorefrequentlythanfortraditionaljavaprograms .
one possible explanation is that android apps tend to have a tighter coupling with their external dependencies .additionalstudies focusedon thecoupling informationbetween apps and their external dependencies may help identify which classes should be replaced by tds.
tdsinjvmanddevicetests.
androiddeveloperscanusetds in both jvm and device tests .
our study identifies a noticeably larger number of tds in particular mockito and mockitokotlintds injvmtestsascomparedtodevicetests.althoughthis is not surprising as jvm tests are run without a complete android framework and might therefore need to account for the missingelements even when robolectric is used as the library provides apartialimplementationoftheandroidframework itis interesting to observe such a large difference.
based on these findings we recommend prioritizing the design of automated techniques for supporting the creation and integration of tds in jvm tests a s those are likely to find larger adoption in practice.
furthermore future workcould investigate the reasons behind thesedifferences.analyzingthe25tdsinthedevicetestsforthe apps in table in particular we found that all of them occur within integration tests none is used within gui tests and of themarecheckingforinteractionshappeningwiththetds.this was lessexpected because forinstance gui testswould typically interactwithexternalservices e.g.
abackendserveroradatabase andwouldthereforebenefitfromtheuseoftds.basedonthesepreliminary data we hypothesize that developers may prefer to avoidtdsindevicetests inordertohavehigher fidelitytests and only use them for specific purposes e.g.
verifying that some calls happen during testing rather than replacing components in the system .interviewswithappdevelopersmayhelpconfirmorrefuse thesehypothesesand moregenerally shedlightonwhytdsare less used in device tests.
supporting debugging of tds.
like all activities that involve aconsiderableamountofmanualeffort creatingandmaintaining authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
use of test doubles in android testing an in depth investigation icse may pittsburgh pa usa tds in android apps is error prone.
in fact our study identifies cases of faulty tds and instances of test code smells related to the usageoftds seesection4.
whichmotivatesthedevelopment of techniques that support developers in debugging tds.
based on ourresults astartingpointcouldbethedevelopmentoftechniques that identify obsolete tds which could be done by identifying tds that are not actually exercised during testing and by analyzing code andtestsco evolution.itisworthnotingthat althoughourstudy highlights these issues in tds for android apps they might alsoappear in other types of software so other application domains could also benefit from these techniques.
threats to validity as it is the case for most empirical studies there are threats to validity associated with the results we presented.
in terms of externalvalidity ourresultsmightnotgeneralizetootherandroid appsandcorrespondingtests.inrq1 wemitigatedthisthreatby considering the largest to the best of our knowledge dataset of appswithpublicly availabletestsuitesinthe literature withapps thatvarywidelyintermsofsizeandcategory.forrq2 rq5 we chose to perform our in depth analysis based on the ten apps with the highest number of tds due to the significant manual effort involved in preparing the apps for the analysis and performing the analysis as we discussed in section .
.
.
although this allowed us to perform a detailed investigation on over tds and carefully inspecttheresultsandthe correspondingcode we acknowledge thatthispartoftheanalysisisacasestudy.additionalstudiesbasedonmoreapps possiblyselectedusingadifferentsamplingstrategy are needed to confirm the validity of our results and gather further insights into how developers create and use tds.
intermsofconstructvalidity ourresultsmightbeaffectedby errorsintheimplementationofthetoolsweusedtoperformour analyses.
to mitigate this threat we extensively tested our toolsand manually inspected our results.
finally we also performedqualitative analyses which might be characterized by divergent understandingamongtheraters.weareconfidentinthereliability of our analysis as the inter rater reliability we measured was considerably high.
related work otherresearchersperformedempiricalstudiesonandroidapptesting .specifically someworkobservedthatdevelopersuse testingframeworkssuchasjunit robolectric androbotium .
other work confirmed that most apps are still poorly tested although test automationand test quality areimproving along with the increasing success and wide adoption of mobile apps .
yetotherworkshowedthatmanyappshadatleastoneflakiness issue in their lifetime and that the environment is one of the main causes of flakiness together with concurrency .
none of this body ofwork focuseson how androiddevelopers usetds within their test suites.
other researchers however have studied test mocking practices in non mobile projects .
spadini and colleagues analyzeover2 000mocksobjectsin4javaprojectsand reportthattheusageofmockshighlydependsontheresponsibilityoftheclass andthatdevelopersfrequentlymockdependenciesthatmaketestingdifficult.theirstudyalsoshowsthatmockstendto existsincetheveryfirstversionofthetestclassandtendtostay foritswholelifetime.pereiraandhorafurtherexplorethistopicby analyzing12popularjavasoftware projects distinguishingmock objects from mock classes and further classifying which classesdevelopers mock .
similarly zhu and colleagues study over tests in open source projects and propose a tool mocksniffer foridentifyingandrecommendingmocksforunittests .
additionally theworkfromtrautschandcolleagues focuses on mocking practices in python projects.
to the best of our knowledge noneofthestudiesonmockingpractices differentiates uses of tds as we do in this paper focuses on mobile apps or aimstoidentifypossibleissueswithtds.ourresults show for instance thatandroid apps replace types of classes that werenotcategorizedbeforeandhighlightthatbothstubbingand operationsto verifymethodcalls arefrequentand important.our study also shows the need for better techniques for debugging and maintaining tds.
finally related work also focused on generating using or maintainingtestmocksautomatically .ourpaperprovides specific insights for researchers who want to define approaches along these lines for in the context of android.