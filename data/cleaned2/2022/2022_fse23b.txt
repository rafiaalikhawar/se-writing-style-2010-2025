api knowledge aware search based software testing where what and how xiaoxue ren zhejiang university china xxren zju.edu.cnxinyuan ye australian national university australia xinyuan.ye anu.edu.auyun lin shanghai jiao tong university china lin yun sjtu.edu.cn zhenchang xing csiro s data61 australian national university australia zhenchang.xing anu.edu.aushuqing li chinese university of hong kong china sqli21 cse.cuhk.edu.hkmichael r. lyu chinese university of hong kong china lyu cse.cuhk.edu.hk abstract search based software testing sbst has proved its effectiveness in generating test cases to achieve its defined test goals such as branch and data dependency coverage.
however to detect more program faults in an effective way pre defined goals can hardly be adaptive in diversified projects.
in this work we propose kat a novel knowledge aware sbst approach to generate on demand assertions in the program under test put based on its used apis.
kat constructs an api knowledge graph from the api documentation to derive the constraints that the client codes need to satisfy.
each constraint is instrumented into the put as a program branch serving as a test goal to guide sbst to detect faults.
we evaluate kat with two baselines i.e.
evosuite and catcher with a close world and an open world experiment to detect api bugs.
the close world experiment shows that kat outperforms the baselines in the f1 score .
vs. .
and .
to detect api related bugs.
the open world experiment shows that kat can detect .
and .
more bugs than the baselines in practice.
ccs concepts security and privacy software and application security .
keywords software testing test case generation knowledge graph acm reference format xiaoxue ren xinyuan ye yun lin zhenchang xing shuqing li and michael r. lyu.
.
api knowledge aware search based software testing where what and how.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
introduction search based software testing sbst as the most practical software testing solution has proved its success in effectively covering predefined test goals e.g.
branches data dependencies lines etc.
.
by measuring the distance on how far a test case is away from achieving a specific goal sbst can evolve the test case to minimize such a distance.
state of the art sbst tools such as evosuite and randoop are highly effective in generating diversified test cases regarding branch coverage line coverage and data dependency coverage in practice .
they are widely used in detecting software bugs in the industry and serve as popular baselines to evaluate many fault detection techniques in academia .
however to detect real world software faults in practice a test generator needs to be enhanced with the specified oracle to be effective.
to this end many researchers propose approaches to enhance test generation with oracles for fault detection .
generally the oracles are derived to validate either the final test results or the internal execution states .
the approaches targeting the final test results usually derive project specific oracle from the comments of the target method and the machine learning or deep learning based models .
in contrast the approaches targeting the internal execution states focus on general oracles such as the manifestation of runtime exceptions and the violation of pre defined heuristics e.g.
memory access and null value access .
generally existing solutions that infer the internal execution states often rely on heuristics to derive a general oracle.
while these solutions are practical for locating pre defined types of faults e.g.
null value access and invalid array access their rules are not easily expandable.
additionally defining the granularity of these rules involves a tradeoff.
the more general the rules e.g.
the program terminates with runtime exception have faults the more likely that the rule is imprecise for a specific project e.g.
some programs may expect a runtime exception on some invalid inputs .
the less general the rules the more likely we miss detecting some program faults.
inspired by previous work developers can effectively resolve the oracle problem by adhering to api usage specifications.
the api usage specifications provide a standardized framework that enables accurate and reliable inference of internal execution states.
this framework presents a notable advancement overcoming theesec fse december san francisco ca usa xiaoxue ren xinyuan ye yun lin zhenchang xing shuqing li and michael r. lyu limitations associated with heuristic based approaches and offering a more adaptable and scalable solution.
in this work we propose knowledge aware search based software testing kat a knowledge extraction based approach to generate on demand assertions in the put program under test validating the internal execution states when interacting with api frameworks.
our rationale is based on the understanding that well documented descriptions particularly the exception handling knowledge of apis serve as informative oracles specifications when apis are utilized in the put.
moreover the in consistencies between api specification and their usage in the code can be transformed into test goals to further facilitate sbst to discover the faults.
specifically given a target program by parsing the description of api and library documentation kat aims to identify where in the code to test based on the in consistencies between api specification in the documentation and the api usage in the code what api specification in the code to test and how to test the specification i.e.
manipulate the source code to facilitate state of the art test generators .
technically kat is designed to construct an api exception handling knowledge graph which is done by extracting knowledge triples from api exception triggers in the documentation e.g.
string.charat index throw indexoutofboundsexception and will be extracted from string.charat index throws indexoutofboundsexception if the index argument is negative or not less than the length of this string see part i in fig.
transform the knowledge graph into program constraints instrumented as additional program branches e.g.
if startoffset throw new indexoutofboundsexception andif startoffset signature.length throw new indexoutofboundsexception see part iii in fig.
for more details and convert those instrumented branches as test goals for sbst tools e.g.
evosuite to generate test cases to cover.
the instrumented program constraints and their covering test cases serve as both the fault detection results and explanations.
to further improve the performance kat also schedules the testing budget for different test goals regarding our measured roi return on investment metrics for each goal.
we conduct extensive experiments to evaluate both the quality of api exception handling knowledge graph construction and the performance of kat to detect software faults in experimental settings and in practice.
to evaluate the constructed knowledge graph we manually check the min computed by a statistical sampling method samples from the total api usage constraints which are extracted from the exceptions also called exception triggers of java se jdk api classes.
the results demonstrate that kat achieves an impressive average accuracy of .
in extracting exception triggers and successfully transforming them into knowledge triples.
to evaluate the performance of kat to detect software faults we compare kat with two baselines i.e.
catcher and evosuite in a close world experiment and an open world experiment.
in the close world experiment we would like to assess the effectiveness of katin detecting api related bugs as it is designed to be api knowledge aware.
we gathered a close world dataset comprising real world bugs that violated api specifications.
these bugs were reported fixed and accompanied by corresponding patches in the github repository.
this dataset allowsus to compare kat with other baselines in detecting api related bugs using evaluation metrics i.e.
precision recall and f1 score .
by executing these baselines on the close world dataset we can assess their performance.
the results indicate that kat achieves an impressive overall f1 score of .
surpassing the state of the art baseline catcher by an outstanding margin of .
in terms of f1 score.
this comparison demonstrates the superior performance ofkat in accurately detecting api related bugs when compared to existing approaches.
in the open world experiment we run kat and baselines on apache projects which have been used in other related work .
as the open world dataset does not have the ground truth reported by developers we compare kat to baselines by counting the number of bugs found.
the results show kat discovers real world bugs in total within two days outperforming the baselines by finding .
and .
more bugs respectively.
we summarize our contributions as follows we propose kat an sbst approach to detect bugs by translating the api specifications into on demand assertions in put.
these generated assertions serve as oracles for evaluating the internal execution states.
we conduct comprehensive experiments to evaluate the effectiveness of kat.
the results demonstrate that kat outperforms the state of the art approaches in detecting bugs.
specifically it achieves an impressive .
improvement in f1 score and identifies .
more bugs compared to catcher.
we report new bugs in the apache open source projects.
in addition the dataset and tutorial to run kat are available at motivation fig.
shows a buggy code example from the easymock project where line part ii can throw an indexoutofboundexception when the string length of signature is smaller than the value of startoffset .
to detect such a bug existing sbst approaches e.g.
evosuite and catcher define test goals guiding the searchbased approach to synthesize a test case to trigger such an exception.
however we run each approach on signaturereader class of the easymock project for minutes failing to report the bug.
generally both approaches suffer from the limits of brute force search or lack of knowledge.
challenge of evosuite.
it is a big challenge for evosuite to discover the fault because it has abundant test goals e.g.
line coverage branch coverage etc.
to diverge its computation resource from the goals with actual bugs.
in this example signaturereader class has branches lines and four methods.
treating all test goals with equality is computationally exhaustive.
more specifically evosuite lacks the knowledge of where to test .
challenge of catcher.
catcher is an sbst approach built upon evosuite to detect exception triggered faults by localizing the call site with the potential to trigger unexpected exceptions.
by investigating how the approach can work on the example we find catcher can effectively identify that line is a potential call site with an unexpected exception.
however catcher is challenging to synthesize a test case to confirm the exception.
since there is no guidance e.g.
branch distance to synthesize the two specific java objects into signaturereader and signaturewriter with fieldsapi knowledge aware search based software testing where what and how esec fse december san francisco ca usa public void accepttype signaturevisitor signaturevisitor parsetype this.signaturevalue signaturevisitor private static int parsetype string signature int startoffset signaturevisitor signaturevisitor int offset startoffset char currentchar signature.charat startoffset target line switch currentchar case b ... 68part ii program under test part iii program after instrumentation public void accepttype signaturevisitor signaturevisitor parsetype this.signaturevalue signaturevisitor private static int parsetype string signature int startoffset signaturevisitor signaturevisitor if startoffset throw new indexoutofboundsexception error message if the index argument is negative.
else if startoffset signature.length throw new indexoutofboundsexception error message if the index argument is not less than the length of this string.
else int offset startoffset char currentchar signature.charat startoffset switch currentchar case b ... part iv test case by kat test timeout public void test9 throws throwable signaturereader signaturereader0 new signaturereader signaturewriter signaturewriter0 new signaturewriter undeclared exception!
try signaturereader0.accepttype signaturewriter0 catch indexoutofboundsexception e error message if the index argument is not less than the length of this string.
verifyexception org.easymock.asm.signature.signaturereader e 155exception string.charat index throws indexoutofboundsexception trigger if the index argument is negative or not less than the length of this string.part i exception of string.charat index index is not less than the length of this string string.charat index throw indexoutofboundsexception extracting extracting linking linkingextracting figure example of a bug in signaturereader class of easymock project of specific value for test inputs see part iv .
as a result catcher has to randomly generate test cases regarding the method calls of the signaturereader class with a slim chance of satisfying the specific constraints when synthesizing the java objects.
more specifically catcher lacks the knowledge of how to test.
to address the aforementioned challenges we propose kat which is a knowledge aware approach to extract constraints from the api documentation and construct an exception handling knowledge graph to validate call sites of apis in the put translate the constraints as program conditions instrumented in the put and guide sbst to synthesize the test cases covering test goals of the instrumented program conditions.
specifically kat statically detects the in consistencies between api exception handling knowledge and the put.
in fig.
the api in the target line i.e.
line of part ii is string.charat index which has two constraints that may trigger indexoutofboundsexception i.e.
and .
with static analysis kat transforms the above two constraints into triples and seepart i in fig.
.
considering what and how to test kat transforms the inconsistencies into programs and instruments additional branches into the put i.e.
lines in part iii .
with the instrumented branches kat searches with branch coverage to find bugs.
also kat computes the confidence score of the code instrumented by considering both knowledge confidence and instrumentation confidence see section .
.
and .
.
.
with the confidence score kat can tell sbst how to allocate time budget to detect bugs.
in this case kat is with a pretty high score and is confident in finding bugs.
part iv is the test cases generated by kat which can catch indexoutofboundsexception in the put by setting signaturereader0 as a null object which existing sbst methods cannot simulate.
approach fig.
presents the overview of kat which consists of three main phases i.e.
construction of api exception handling knowledge graph phase i static detection of potential bugs phase ii and specification violation as test goals phase iii .
in phase i we first extract api exception handling knowledge from java se jdk api documentation and then construct them into a knowledge graph.
in phase ii kat performs static analysis to detect potential bugs by checking whether the put violates the constraints in api handling knowledge for where .
in phase iii kat transforms the violations into test goals to generate and validate test cases via code instrumentation for what .
besides kat also schedules the testing budget for different test goals for how .
more details are described as follows.
.
knowledge graph schema kat aims to generate on demand assertions in the put according to the knowledge defined in the official api documentation.
thus we construct an api exception handling knowledge graph based on the official java se jdk api documentation which with relatively complete contents and high quality .
the entities of the api exception handling knowledge graph include api components module package class method parameter return value and exception declared in java official documentation and value literals null true and range like negative or extracted from textual usage directives in documentation.
the relations between entities include declaration relation and constraint relation .
the declaration relations are between api components including hasclass hasmethod hasparameter return andthrow .
the constraint relations include constraint enriched return andthrow which are attached with conditions extracted from return contents and exception triggers in the documentation.
for instance part i in fig.
shows an exception handling sentences of string.indexof index which has the following two exception triggers i.e.
the index argument is negative and the index argument not less than the length of this string .
.
construction of api exception handling knowledge graph the official java se jdk api documentation contains semi structured api specifications including api hierarchies i.e.
api declaration graph in this paper and textual usage directives.
to detect bugs violating api specifications we focus on exception triggersesec fse december san francisco ca usa xiaoxue ren xinyuan ye yun lin zhenchang xing shuqing li and michael r. lyu api documentatiaon api usage directivesapi declaration graphapi exception handling knowledge grpahprogram under test program after instrumentation time budget allocating real bugcfg dfgstatic analyzing api constraint solverformulating searching optimizing phase ii static detection of potential bugs phase i construction of api exception handling knowledge graph phase iii specification violation as test goals potential bug code formula kg formulaformulating return tripleextracting extracting entity linked triple entity linking in consistencies checking code instrumenting exception triplefunctionality parameter description exception triggerreturn content api knowledgealigning aligning knowledge triplepreparing figure the overall framework of kat and build an api exception handling knowledge graph to represent the semantics of api usage in the put.
the api exception handling knowledge graph consists of two parts the api declaration graph which can be accessed directly from the documentation and knowledge triples extracted from textual usage directives.
by aligning triples into the api declaration graph we can finally obtain the api exception handling knowledge graph.
the api declaration graph needed by us is the same as the generic api knowledge graph in and we follow their treatments to obtain the api declaration graph.
therefore the central part of knowledge graph construction lies in knowledge triple extraction and alignment.
details are as follows .
.
api knowledge preparation.
we first do some preliminary work for constructing the knowledge graph including knowledge collection and pre processing.
knowledge collection.
we collect three types of textual api usage directives descriptions both functionality and parameter description return contents and exceptions .
descriptions are the basic knowledge of apis which are usually composed of several descriptive sentences.
we focus on the first sentence commonly recognized as the most helpful knowledge .
it is usually a functionality summary or overall description.
return contents and exceptions are critical knowledge to triple extraction which may contain essential conditions triggers causing potential bugs.
knowledge pre processing.
we pre process the collected knowledge as follows.
first we resolve coreferences including both general coreferences e.g.
itandthem and domain specific coreferences e.g.
the arguments .
we use neuralcoref for general coreferences which is a state of the art coreference resolution method.
we use self defined patterns to resolve domain specific coreferences.
our observation is that conditions triggers in return contents exceptions often use any either all of the parameter s argument s to represent their parameters.
for example the trigger of nullpointerexception inenumset.of e1 e2 if any parameters are null means either e1ore2are null.
thus this trigger should be resolved into ife1ore2are null .
then we split clauses by parsing the syntax dependency tree of trigger sentences with spacy .
we detect conjunctions of the sentencesand complete the omitted parts in the subordinate clause based on the elements in the main clause.
in the example above the trigger after resolution can be further split into two triggers i.e.
ife1is null and ife2is null and the relation between triggers is or.
.
.
knowledge triple extraction alignment.
to construct the api exception handling knowledge graph we first represent the knowledge in the format of triples via entity relation extraction approaches and then align the triples into the declaration graph by linking entities.
triple extraction.
return contents and exceptions we collected from api documentation often come with constraints which are called return conditions and exception triggers respectively.
return contents are helpful when analyzing the data flow and exceptions are closely related to bugs violating api specifications.
hence we need to extract knowledge triples from return contents and exceptions as well as their constraints.
to extract knowledge triples from textual sentences we employ spacy to parse sentences into semantic dependency trees from which we identify entities and relations.
since official documentations usually have a relatively fixed expression we summarize three common sentence structures of exception triggers and return conditions including subject verb s v e.g.
if the character does not occur subject verb predicative s v p e.g.
the beginindex is negative and subject verb object s v o e.g.
beginindex is larger than endindex .
when extracting knowledge triples we first detect the main verbs and categorize the sentences into the corresponding structures.
then by detecting nouns linked by the verbs which are the entities we can obtain the entity relation triples from sentences.
note that compound nouns and noun phrases often appear in the documentation.
we need to merge them into one noun with spacy before extracting triples.
for example the length of the string should be merged into one entity.
inspired by to make the knowledge graph better serve bug detection with specific bug types we further classify exception triggers into four types i.e.
t1 nullness prohibition t2 range limitation t3 call dependency and t4 other restriction .
they correspond to four types of bugs violating api specifications i.e.
b1 missing null check b2 missing range check b3 missing call and b4 missingapi knowledge aware search based software testing where what and how esec fse december san francisco ca usa try catch .
after observation t2andt3triggers are consistent in expression which can be identified by detecting key patterns.
we compare the two pattern sets defined in and obtain key patterns available in related to our categories for trigger classification e.g.
null negative and less than .
t3andt4cannot be identified through pattern matching due to the absence of templated expressions.
however they can be resolved by linking entities with semantic similarities referring to the triple alignment part for details.
more specifically the knowledge triples of triggers in fig.
both belong to t2 i.e.
and index is not less than the length of this string which may cause missing range check bugs.
triple alignment.
as api usage directives are organized in unstructured natural language which has different formats from structured knowledge in the api declaration graph we perform entity linking over api usage directives to align the extracted triples to the entities in the api declaration graph.
for preparation we train a domain specific word embedding model to evaluate the similarity between entities sentences.
specifically we use gensim to fine tune google s pre trained word2vec model with all texts from official java documentation.
for alignment we compute a confidence score for a triple with respect to the entity to judge whether to link.
the confidence score is calculated with the following steps direct url linking check whether there is a direct url link with the entity.
if any match the entity to the object pointed by the link and denote the knowledge confidence as .
intra method linking compute the similarity between the entity in the triple and the parameters in the same method considering parameter names first and then descriptions.
once the similarity score is larger than .
stop matching and the similarity score is denoted as the knowledge confidence.
intraclass linking compute the similarity between the entity in the triple and methods in the same class similar to strategy .
stop matching when similarity is more than .8and denote its knowledge confidence score.
inter class linking compute the similarity between the entity in triple with related methods in other classes.
the related methods include inherited methods declared in other classes or the parameter s functionality methods.
selecting the matched entity with the highest score .
which is also denoted as its knowledge confidence score.
the threshold here is different from .
because the expressions in the same class are more similar although they may not be related while the expressions in different classes are more different although they may be related.
to avoid mismatching we choose different thresholds.
we also identify t3 andt4triggers in this step.
after detecting t1andt2triggers by matching key patterns we continue to identify types of the rest triggers by linking entities after extracting triples.
if the entity in a triple can be linked with another method and the trigger is to check the state of the linked method this triple can be identified ast3 otherwise t4.
for example the triple iterator.hasnext true extracted from iterator.next throws nosuchelementexception if the iteration has no more elements is identified as t3 because has no more elements is linked with the false state of iterator.hasnext .
we finally align all knowledge triples into the api declaration graph by the linked entities which forms our api exception handling knowledge graph.
to better display the knowledge graph weuse heuristic rules to symbolize relations.
take the trigger the index argument is negative of string.charat index as an example the entities the index argument are ideally linked with the parameter of a .0confidence score.
thus the knowledge triple is index is negative which can be further represented as .
.
static detection of potential bugs after constructing the api exception handling knowledge graph we use static analysis to detect the in consistencies between the knowledge graph and put to find potential bugs referring to where to test .
specifically it includes the following two steps programs parsing the put to obtain flow information and in consistencies checking to detect potential bugs.
.
.
programs parsing.
to obtain flow information we adopt soot a popular framework for analyzing and transforming java programs to parse the put.
first we use soot to transform the put into an intermediate representation as jimple which can essentially simplify flow analysis .
then we construct control flow and data flow graphs from jimple files.
with the flow graphs we can traverse and record various flow information about the put e.g.
value assignment variable type handled exceptions method invocations and conditional branch which can help transform the knowledge graph into program constraints.
.
.
in consistencies checking.
with the flow graphs we first use the knowledge graph to detect target apis in the put.
the target apis refer to the apis with exception triples in the knowledge graph.
then we collect corresponding arguments and constraints of target apis in the put according to entities and relations in exception triples which form the code formula i.e.
fcode .
after that we also transform constraints of target apis in the knowledge graph into program constraints by replacing entities with arguments in the put which forms the kg formula i.e.
fkg .
take the put in fig.
as an example it shows a process of accepttype calls parsetype .
the target api is string.charat index in line and we can traverse the flow graphs and obtain its code formula and kg formula i.e.
fkg as follows fcode index setoffset string.length signature.length this.signature.length fkg or index index string.length then to check the in consistencies of the two formulas we adopt an smt solver i.e.
z3 to check whether there is a solver that can trigger the exception namely whether there is a solver infcode can meet one of the constraints in fkg.
therefore we feed the arguments in fcode intofkg obtaining a series of formulas under in consistencies checking.
for example when feedingfcode of the put in fig.
into its corresponding fkg we can get the in consistencies checking formula or this.signature.length .
by evaluating the in consistencies checking formula with z3 we can find whether there is a potential bug or not.
the output of z3 should be satorunsat .unsat means the api usage in the put meets the corresponding constraints in api specifications and does not trigger any exceptions while satmeans potential bugs may happen and will be marked as where to test.
specifically in the put of fig.
if this.signature.length esec fse december san francisco ca usa xiaoxue ren xinyuan ye yun lin zhenchang xing shuqing li and michael r. lyu indexoutofboundsexception might be thrown in line see the test case by kat part iv .
hence the solver of the in consistencies checking formula should be sat marking a potential bug in line .
note that we also compute a confidence score for detecting potential bugs called bug confidence which has three levels .
means no potential bugs because no target apis are found .
means perfect confidence it is when the determined inferred argument value can meet the constraints .5is borderline confidence it is when the argument is an uncertain input and its value cannot be inferred from the knowledge graph.
specifically the in consistencies checking formula of put in fig.
is with borderline confidence .
because the occurrence of the exception largely depends on the input of signature which may be possible to trigger an exception.
.
specification violation as test goals after finding potential violations by checking in consistencies between the put and knowledge triples we transform the violations into code snippets for instrumentation which serve as additional branches to cover.
.
.
code instrumentation.
considering the different types of triggers we extracted from the documentation we first summarize the general expression of human patches and design different instrumentation patterns for each which reflect what to test.
then we use javassist a java bytecode engineering toolkit to instrument code snippets into the class files of projects.
the instrumented code snippets serve as additional branches for sbst to generate test cases covering test goals.
specifically the instrumentation patterns are as follows for nullness prohibition and range limitation we translate the violation into if throw new e.g.
the violation of triple in fig.
is converted into if index throw new indexoutofboundsexception .
for call dependency different from specific range and null we add a state checking to check the state of the dependent api call i.e.
if throw new .
for example if the violate knowledge triple can be converted into if hasnext false throw new nosuchelementexception .
for other restrictions we wrap the target line with try catch e .
note that the or and relationship exists among different violations so the positional relationship between instrumented code snippets should be considered.
for example the instrumented code snippets in fig.
see lines in part iii check two potential violations with the orrelationship.
.
.
time budget allocation.
according to the previous study time budget is important.
we design a strategy to allocate different time budgets concerning the confidence of the additional branch instrumented which is how to test.
this confidence is an average of knowledge confidence in section .
.
and bug confidence in section .
.
.
for each class under test we allocate a total time and each method in the class is allocated with a minimum time.
then we continue to allocate the remaining time for methods according to their confidence in the additional branch instrumented.
as a result the time budget of method mistm cm n i 0ci t tmin n tmin wheretis the total time budget allocated to each class under testand the default value is seconds tminis the minimum time allocated to each method in the class seconds by default nis the number of methods in a class and cmrefers to the confidence score of method m. .
implementation we implemented katon top of evosuite a state of the art java testing framework.
many search algorithms have been proposed for evosuite and we choose dynamosa as the search algorithm ofkat which optimizes multiple coverage targets simultaneously.
dynamosa stands as the current state of the art and has been integrated into the evosuite tool .
search algorithms have various parameters to set but previous work shows that parameter tuning sbst is extremely expensive and not necessary compared to default parameter values.
thus we use the default settings of dynamosa.
moreover considering kat works by instrumenting additional branches we choose branch coverage as the optimization objective.
experiment setup .
baseline methods to investigate the overall performance of kat we select two stateof the art sbst approaches as baselines catcher similar to kat catcher also combines static exception propagation analysis with automatic search based test case generation to detect crash prone java api misuses.
the primary focus of catcher is to narrow down the search space for automatic test case generation by honing in on api call locations that are prone to triggering exceptions at runtime.
to enhance its effectiveness catcher optimizes the search objective function by considering various coverage metrics including branch coverage line coverage input coverage and output coverage.
evosuite it is a cutting edge search based software testing sbst approach designed specifically for generating test cases for java classes.
with its advanced techniques evosuite has been shown to achieve remarkable code coverage and improved bug detection capability.
to illustrate the effectiveness of kat s different design choices we design two variants as follows katstatic this variant of kat keeps only the static analysis technique to detect bugs i.e.
phase i and phase ii in fig.
.
by comparing kat tokatstatic we evaluate the effectiveness of dynamic checking by generating a series of test cases i.e.
phaseiii in fig.
in finding real bugs.
katdynamic this variant of kat keeps only the test case generation part of kat i.e.
removing static detection with knowledge graph and specification violation as test goals .
thus this variant is the same as evosuite.
by comparing kat tokatdynamic we evaluate the effectiveness of detecting potential bugs and converting them into additional branches i.e.
phase i and phase ii in fig.
in finding api related bugs.
.
experimental datasets to evaluate the performance of kat both close world and openworld datasets are used to compare different evaluation metrics.api knowledge aware search based software testing where what and how esec fse december san francisco ca usa .
.
close world dataset.
the close world dataset refers to some api related bugs with fixed patches which means they have the ground truth and can be used to compute precision recall and f1 score for evaluation.
given that kat is designed as an apiknowledge aware approach we leverage the close world dataset to conduct experiments specifically focused on evaluating the performance of api related bug detection.
however upon manual inspection of defects4j a popular benchmark for bug detection only three bugs are related to java se jdk api.
consequently we followed the bug collection procedure outlined in defects4j searching for fixed bugs from historical commits on github.
this process resulted in the discovery of an additional nine fixed apirelated bugs.
overall our close world dataset comprises a total of reported bugs that have corresponding fixed patches.
this dataset enables us to evaluate kat s performance accurately and reliably in detecting api related bugs.
.
.
open world dataset.
the open world dataset refers to opensource projects that may contain unreported bugs.
we reuse the dataset released by catcher which consists of large scale projects from apache.
with this dataset we can investigate the generalizability of kat in the large scale dataset by comparing the total number of detected bugs with catcher and evosuite.
.
research questions we investigate the following research questions rq1 what s the quality of the knowledge graph?
we assess the accuracy of the triples extracted from the api documentation and evaluate the quality of the knowledge graph constructed.
rq2 what s the overall performance of kat?we utilize a close world dataset to compare the overall performance of kat with other sbst approaches in finding api related bugs.
rq3 what s the effectiveness of kat s different design choices?
we compare the performance of kat with its variants on the close world dataset to evaluate the effectiveness of our design choices.
rq4 what s the generalizability of kat on an open world dataset?
we quantitatively and qualitatively analyze the performance of kat and other baselines on an open world dataset.
evaluation .
quality of knowledge graph rq1 .
.
evaluation strategy metric.
the api exception handling knowledge graph is used to guide generating test oracles in this work so its quality can directly affect the performance of kat in detecting bugs violating api specifications.
we need to evaluate whether the knowledge graph is highly qualified to be used.
as we consider four types of exception triggers in the knowledge graph we adopt a statistical sampling method to examine the quality of the minimum number min of triggers in each type see section .
.
concerning their classified types and extracted triples.
this sampling method ensures that the estimated accuracy is in a certain error margin at a certain confidence level.
this min is calculated by min n0 n0 populationsize .
in the equation n0depends on the selected confidence level and the desired error margin n0 z2 .
e2 wherezis a confidencelevel s z score and eis the error margin.
we use the error margin .05at the confidence level in our evaluation.
given a large number of triggers min is approximately in this statistical setting.
two authors are invited to independently evaluate the accuracy i.e.
number of correct triples number of sampled triples for the sampled triggers.
they judge two aspects whether or not the triggers are classified into the appropriate types and whether the triples extracted from corresponding triggers are correct.
we compute cohen s kappa to evaluate the inter rater agreement.
if there is a disagreement between the above two judgments authors must discuss and come to a consensus.
based on the consensus annotations we evaluate the quality of each type of extracted information.
.
.
results of rq1 quality of knowledge graph.
table shows the statistics of triggers and their corresponding triples extracted.
table reports the accuracy of all sampled triggers evaluated by us.
the columns acc.
1andacc.
2show the accuracy determined by two annotators independently and the column acc.f is the final accuracy after resolving disagreements.
column kappa shows the inter rater agreement.
the statistics of triggers show that we collect a total of triggers with four types covering java se jdk apis.
for the accuracy of different trigger types in table the final accuracy values are all above .
and the cohen s kappa values are over .
.
these results demonstrate substantial agreement between the annotators and highlight the high quality of the extracted triples.
this in turn reflects the quality of our api exception handling knowledge graph.
note that t4has the most significant number of triggers and t3has the least and both of them show relevant low accuracy and kappa.
the reason is different from t1andt2 which can be identified by explicit patterns e.g.
null less than etc.
we cannot extract patterns to identify t3andt4.
we identify them by computing sentence similarity when linking entities in triples see section .
.
for details .
thus we sacrifice the quantity oft3for the high quality of the knowledge graph.
although the accuracy of t3is the lowest it still achieves high performance with a final accuracy of .
answer to rq1 kat is supported by sufficient high quality knowledge covering a wide range of apis which can be reliably used in detecting potential bugs generating and validating test cases.
.
performance of kat rq2 .
.
evaluation strategy metric.
forrq2 andrq3 we apply kat and other baselines to generate test cases and validate them with ground truth for all the buggy classes in the close world dataset.
forrq4 we apply kat catcher and evosuite in the open world dataset and compare how many bugs they can detect respectively.
on the close world experiments we compute precision recall and f1 score to evaluate the performance of finding bugs among our kat the other two baselines i.e.
catcher and evosuite to answer rq2 and the variants of kat i.e.
katstatic andkatdynamic to answer rq3 .
precision tp tp fp represents the proportion of bugs that are correctly classified as bugs among all bugs detected by the methods.
recall tp tp fn represents the proportion of all bugsesec fse december san francisco ca usa xiaoxue ren xinyuan ye yun lin zhenchang xing shuqing li and michael r. lyu table four types of exception triples in knowledge graph trigger type of triggers of covered api trigger example triple t1 method.getannotation annotationclass throw nullpointerexception if the given annotation class is null.nullpointerexception t2 list.remove index throw indexoutofboundsexception if the index is out of range index index size indexoutofboundsexception or t3 sortedset.first throw nosuchelementexception if this set is emptynosuchelementexception t4 certificate.getencoded throw certificateencodingexception if an encoding error occurscertificateencodingexception table quality of api exception handling knowledge graph trigger type min acc.
acc.
acc.f kappa t1 .
.
.
.
t2 .
.
.
.
t3 .
.
.
.
t4 .
.
.
.
average .
.
.
.
that are correctly classified as bugs.
f1 score precision recall precision recall is the harmonic mean of precision and recall which is a balanced metric of them.
the four statistics appear above are as follows fp false positive represents the number of bug free programs that are classified as bugs fn false negative represents the number of bugs that are classified as bug free programs tp true positive represents the number of bugs that are correctly classified as bugs and tn true negative represents the number of bug free programs classified as bug free.
on the open world experiments to answer rq4 we follow the evaluation metrics of catcher i.e.
counting the total number of real bugs detected by kat catcher and evosuite to demonstrate the generalizability of kat.
for experiments on the two datasets with sbst methods i.e.
kat catcher evosuite katdynamic we repeat each of the experiments times the repeat times is determined by since such approaches employ optimization strategies to search.
we allocate seconds for each class to generate test cases in individual execution and run each execution on gnu linux system ubuntu .
.
lts with .
.
generic linux kernel core .60ghz intel r xeon r gold cpu and 1tb ram.
note that the variantkatstatic does not require repeated experiments as it is based on static code analysis.
.
.
results of rq2 overall performance of kat.table presents the comprehensive results obtained from the close world dataset highlighting the effectiveness of different approaches in identifying api related bugs.
the table consists of three columns catcher evosuite and kat representing the outcomes of two baselines and our proposed method respectively.
each column indicates the ability of the corresponding method to detect bugs and the number of times it correctly identified the ground truth out of executions.
for instance see the first row of column catcher signifies that catcher accurately detected the bug on seven occasions during executions.
the total row represents the total number of bugs identified among all the bugs present in the close world dataset.
for example see the last row of column catcher means that catcher successfully identified five bugs out of the total bugs in the close world dataset.table overall performance of bug detection on the closeworld dataset source type bug id project name catcherevosuite katdynamic katstatic kat defects4jb1 csv5 commons csv b4lang13 commons lang lang37 commons lang githubb1 02f519e commons cli 48f0e90 hibernate orm b2 899f2f4 rumble 2d0436e sphinx4 d88d7a1 jmeter b3 5787fe0 jstyleparser jmeter 9ed8de3 msgraph sdk 586d1ed tabula total from the total row of catcher evosuite and kat we can observe an overall better performance of kat in detecting bugs violating api specifications.
specifically katcan find six more bugs than catcher andseven more bugs than evosuite after repeating times experiments.
such a significant achievement can be attributed to the fact that kat can specifically point out where to test based on the in consistencies between the api knowledge graph and the api usage in the put.
kat then transforms the in consistencies into programs and instruments them into the put as test goals.
both catcher and evosuite show poor performance especially when no test goals are found because they can only search randomly for test goals in this case.
such randomness is also shown by the hit times in executions.
the bugs detected by catcher and evosuite often have a few hit times in all executions such as three times hitting the bug for sphinx4.
however as long as the bug is a little more complicated it can be detected by neither catcher nor evosuite.
for an example of the bug 586d1ed in tabula which is a b3bug about checking iterator.hasnext before iterator.next it can be detected by neither catcher nor evosuite.
unlike catcher and evosuite kat can add test goals to the put by adding additional branches.
in this case kat can avoid randomness and always hit the bugs and more complex bugs can be detected.
the put in fig.
is a complicated example of missing test goals.
both catcher and evosuite cannot detect it because it is difficult for them to generate a null object to trigger the bug randomly.
moreover table shows the performance of each method from the aspects of different bug types by measuring precision recall and f1 score.
the bug types are corresponding to the types of exception triggers.
the results illustrate that b2 b3 b4 i.e.
missing null check missing range checking and missing call show better performances than b4 i.e.
missing try catch .
it is because the correspondingapi knowledge aware search based software testing where what and how esec fse december san francisco ca usa table results of precision recall and f1 score on the close world dataset bug typecatcher evosuite katdynamic katstatic kat f1 improvement prec.
rec.
f1 prec.
rec.
f1 prec.
rec.
f1 prec.
rec.
f1 catcher evosuite katstatic b1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
b2 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
b3 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
b4 .
.
.
.
.
.
.
total .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
triggers i.e.
t1 t2 t3 have more specific api constraints which can be easily converted into test goals to help search algorithms optimize with branch coverage.
in contrast t4provides limited knowledge to guide test case generation because it is vague.
kat just instruments try catch e into the put considering t4 triggers.
answer to rq2 kat can find six and seven more api related bugs than catcher and evosuite respectively.
moreover kat shows great performance in detecting missing null check missing range missing call bugs.
.
.
results of rq3 effectiveness of kat.to evaluate the effectiveness of kat we compare it with its two variants i.e.
katstatic andkatdynamic .
table and table report the performance of kat and its variants i.e.
katstatic andkatdynamic in the closeworld dataset.
in table we present the performance of kat and its variants katstatic andkatdynamic on the close world dataset.
the column labeled katdynamic evosuite provides information on whether the bug can be detected by katdynamic and how many times it successfully detects bugs out of executions.
column katstatic reports whether the bug can be detected by katstatic and how many bugs in total it can detect in the programs.
for example see the first row of column katstatic means the static approach i.e.
katstatic reports eight potential bugs and contains the ground truth bug.
see the last row of column katstatic means katstatic reports a total of potential bugs which covers all the ground truth bugs.
in table we measure the precision recall and f1 score of kat and its variants.
note that once the bug is detected among executions the result is denoted as positive otherwise negative.
results of the close world experiment in table show although katstatic can find all bugs in the closeworld dataset it suffers from an extremely high false positive rate.
because katstatic uses static analysis to detect bugs and naively assumes that programs violating constraints in knowledge graphs are bugs.
thus bugs detected by katstatic require manual verification which cannot effectively help in bug detection and even increases the burden of verification.
for katdynamic as discussed in section .
.
it uses a random search strategy to generate test cases for bug detection automatically.
the strategy makes it with acceptable results in the quality of the bug detected but poor performance in the number of bugs in the close world dataset.
table shows that the design of kat is very effective outperforming both variants with the improvement of f1 score by .
and .
respectively.
kat is able to achieve better performance because it considers the characteristics of both variants.table performance on the open world dataset total reports the number of all unique bugs detected from the openworld dataset.
id project name version kat catcher evosuite bcel bcel .
cli commons cli .
codec commons codec .
coll commons collections .
comp commons compress .
lang commons lang .
math commons math .
.
easy easymock .
gson gson .
.
hamc hamcrest core .
jack jackson databind .
.
javs javassist .
.
jcom jcommander .
jfch jfreechart .
.
joda joda time .
jopt jopt simple .
.
natt natty .
neo4 neo4j java driver .
.
shiro shiro core .
.
xjob xwiki commons job .
xtex xwiki commons text .
total kat designs an effective strategy to integrate both variants advantages by converting constraints in the knowledge graph to program constraints and instrumenting them into the put as additional branches.
answer to rq3 the design choices can contribute to the effectiveness of kat which improve the the f1 score from .
.
.
.
.
results of rq4 generalizability of kat.table shows the total number of bugs detected by kat and the other two baselines i.e.
catcher and evosuite with executions of experiments in the open world dataset.
overall kat exhibits remarkable performance in bug detection surpassing both catcher and evosuite.
with a total of unique bugs identified across all executions kat showcases superior effectiveness and remarkable generalizability in the large scale open world dataset.
in more specific terms kat outperforms catcher by discovering additional bugs and surpasses evosuite by detecting additional bugs .
these findings further emphasize the significant advantage and robustness of kat over the baselines.esec fse december san francisco ca usa xiaoxue ren xinyuan ye yun lin zhenchang xing shuqing li and michael r. lyu table overlap between kat and catcher regarding the unique bugs detected across executions.
porject id kat catcher kat catcher catcher kat bcel cli codec coll comp lang math easy gson hamc jack javs jcom jfch joda jopt natt neo4 shiro xjob xtex total table presents a comprehensive summary of bug detection results for both kat and catcher.
the table highlights the number of bugs detected by both approaches as well as the distinct set of bugs identified exclusively by each tool.
the analysis reveals that unique bugs were detected by both kat and catcher indicating a considerable overlap in their bug detection capabilities.
additionally kat identified unique bugs that were not detected by catcher demonstrating its ability to uncover specific bugs that might have been overlooked by the other tool.
conversely catcher discovered nine unique bugs that were not detected by kat showcasing its effectiveness in identifying a subset of bugs missed by the alternative approach.
compared with evosuite both kat and catcher take absolute advantages because both methods utilize external exception information from documentation source code to identify bugs.
catcher first detects potential bugs and then optimizes searching objectives by combining four coverage i.e.
branch line input and output .
differently kat transforms api exception handling knowledge into program constraints and instruments them into put as additional branches.
as a result it can guide search algorithms to cover more branches and detect more bugs.
for example fig.
is a bug from the class signaturereader in easy project that can only be detected by kat.
the bug happens in the method accepttype in line of put because it can trigger the exception of string.charat index in line of the method parsetype .
this case shows a bug without test goals and catcher cannot easily synthesize a test case to trigger the exception because there is no guidance such as branch distance to synthesize the two specific java objects.
when considering the bugs exclusively detected by catcher our observations indicate that these cases primarily fall into the category of b4bugs which are triggered by t4.
the reason behindcatcher s success in detecting these bugs lies in its utilization of various coverage techniques allowing it to address the challenge posed by such transformations effectively.
on the other hand kat handles this transformation by introducing try catch as an additional branch.
however covering this branch within a reasonable branch distance can pose challenges for search algorithms.
nonetheless catcher s approach proves effective in overcoming these challenges.
answer to rq4 kat can detect more and more bugs than catcher and evosuite in the open world dataset which indicates better generalizability.
discussion .
effectiveness and efficiency of kat .
.
effectiveness.
with extensive experiments our kat can outperform static analysis and other dynamic sbst approaches in finding bugs.
compared to static analysis i.e.
katstatic kat demonstrates significant improvements in addressing false positive api related bugs and achieving automated bug detection.
by incorporating search strategies in phase iii as depicted in fig.
kat effectively generates test cases to verify the existence of bugs reported by static analysis.
this capability leads to a considerable reduction of false positive instances for example a decrease of cases .
furthermore when compared to existing sbst approaches i.e.
catcher and evosuite katdynamic kat exhibits the ability to discover a greater number of bugs within a limited search time.
specifically kat can detect more and more bugs than catcher and evosuite respectively.
this advantage stems from the utilization of an api exception handling knowledge graph which enables kat to identify potential bugs and transform the corresponding violation constraints into instrumented branches.
consequently kat effectively improves branch coverage and enhances the bug detection process.
while the advancements achieved bykat may be considered relatively modest compared to the stateof the art sbst approaches it is important to recognize that even modest progress can have significant implications.
such advancements contribute to the cumulative progress within the sbst field and lay the groundwork for further developments and improvements.
.
.
efficiency.
when optimizing searching strategies sbst requires setting a time budget.
kat allocates a maximum of seconds for each class under test which is the same time set in catcher.
for the same class under test all of catcher evosuite and kat are allocated the same time i.e.
200s but kat can find more bugs.
note for kat we do not consider the time consumption of constructing the api exception handling knowledge graph static bug detection and instrumentation.
first the construction of the knowledge graph occurs offline meaning it is not performed in real time during the bug detection.
as a result any time consumed during this process does not impact the overall efficiency of kat.
second regarding the static bug detection and instrumentation for each class it is crucial to note that these operations are highly efficient and completed within a very short duration typically within one second.
when considering the overall time budget allocated for the evaluation or execution of kat which is around seconds api knowledge aware search based software testing where what and how esec fse december san francisco ca usa the negligible time consumed by static bug detection and instrumentation becomes inconsequential.
therefore it is appropriate to disregard this time when comparing the performance of kat within the allocated time budget.
.
threats to validity .
.
internal validity.
the internal threats to validity refer to the quality of the api exception handling knowledge graph which plays a pivotal role in our bug detection approach.
to reduce personal bias when evaluating the knowledge graph quality we employed a method that involved two authors independently annotating the data instances.
to assess the agreement between the annotators and ensure reliability we computed cohen s kappa coefficient which indicates a substantial or almost perfect agreement between the two annotators.
.
.
external validity.
the external threats to validity arise from two aspects limited knowledge from the api documentation and the small scale close world dataset.
first considering the quality of api knowledge is critical to the performance of kat we prefer selecting the high quality java official documentation to construct a knowledge graph inspired by the previous studies .
although the official documentation provides a limited number of apis we design our api exception handling knowledge graph and open information extraction pipeline to be adaptable and extendable allowing us to incorporate additional knowledge from diverse sources.
by continuously expanding our knowledge graph we aim to enhance the comprehensiveness of the information available.
second the small scale of our close world dataset can be attributed to two key factors our research primarily focuses on a specific subset of api knowledge i.e.
java se jdk api knowledge .
consequently the number of bugs directly associated with these apis is naturally limited.
our adherence to the rigorous strategy employed by defects4j has led us to conduct an exhaustive search for high quality bugs.
this meticulous approach is time consuming and demands significant effort and resources.
nevertheless we remain dedicated to ongoing efforts aimed at expanding and enriching our close world dataset.
this commitment entails actively collecting more bugs in the future.
hence we aim to broaden the scope of our dataset enhance its representativeness and strengthen the validity and reliability of our research findings.
related work .
search based software testing search based software testing sbst is a powerful technique for automating test generation showing promising results .
sbst relies on specific heuristics for different coverage criteria guiding the generation of test cases to achieve higher coverage.
initially the single target approach aimed to satisfy one coverage target e.g.
one branch at a time through multiple search iterations e.g.
genetic algorithms .
however multi target approaches have emerged as superior using many objective search techniques to achieve higher code coverage .
catcher related to our work employs a two step approach.
it first uses exception propagation to identify potential api misuses in the program under test statically put narrowing the searchspace.
then it uses coverage based heuristics to guide a manyobjective search to cover the identified api call sites and expose propagated exceptions primarily focusing on api related bugs.
in contrast our approach called kat goes beyond static detection of api misuses.
we leverage api exception handling knowledge gathered from api usage specifications to create test oracles enhancing kat s effectiveness by incorporating domain specific api exception handling into the process.
.
test oracle automation to effectively detect real world software faults we must improve generated tests with accurate test oracles .
these oracles significantly impact testing quality and software system reliability .
constructing test oracles automatically is a challenging task often considered a bottleneck in automated software testing .
recent efforts have approached this problem from three angles implicit oracles derived oracles and specified oracles .
implicit oracles rely on domain expert knowledge to determine test pass fail.
for example segment faults are typical errors and frame rate drops in game applications may indicate performance issues .
derived oracles use existing information to distinguish correct from incorrect software behavior.
techniques include metamorphic relations version comparisons and metadata analysis .
specified oracles require formal specifications or contracts to define expected behavior or contracts .
the quality and completeness of these specifications are critical .
in contrast our approach focuses on converting exception handling documentation knowledge into test oracles.
conclusion search based software testing sbst has proved its effectiveness in generating test cases to achieve its defined test goals such as branch and data dependency coverage.
however to detect more program faults in an effective way pre defined goals can hardly be adaptive in diversified projects.
we propose kat a knowledge extraction based approach to generate on demand assertions in the put validating the internal execution states when interacting with api frameworks.
with evaluations on both close world and open world datasets we illustrate kat performs better than other baselines i.e.
catcher and evosuite in finding more bugs violating api specifications.
additionally kat also shows good generalizability in a large scale dataset.
in the future we will extend our work in the following two aspects.
first we will extend the knowledge graph to include more knowledge to guide test case generation.
second we will further develop kat and apply the idea to program repair.
data availability all experimental data are available at our github repository.