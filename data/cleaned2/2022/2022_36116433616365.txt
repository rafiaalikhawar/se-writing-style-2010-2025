understanding the topics and challenges of gpu programming by classifying and analyzing stack overflow posts wenhua yang college of computer science and technology nanjing university of aeronautics and astronautics nanjing china ywh nuaa.edu.cnchong zhang state key lab for novel software technology nanjing university nanjing china nju zc smail.nju.edu.cnminxue pan state key lab for novel software technology nanjing university nanjing china mxp nju.edu.cn abstract gpus have cemented their position in computer systems not restricted to graphics but also extensively used for general purpose computing.
with this comes a rapidly expanding population of developers using gpus for programming.
however programming with gpus is notoriously difficult due to their unique architecture and constant evolution.
a large number of developers have encountered problems of one kind or another and many of them have turned to q a sites for help.
unfortunately there has been no prior work to comprehensively study the topics discussed and challenges encountered by developers in gpu programming.
to fill this knowledge gap we conduct a comprehensive study to understand the topics and challenges of gpu programming using stack overflow.
we collect relevant posts from stack overflow propose a novel approach that combines automatic techniques and manual thematic analysis to extract topics and build a taxonomy of topics with detailed discussions of the popularity difficulty and changing trends of these topics.
in addition we analyzed relevant posts through extensive manual efforts to understand the challenges of each topic and to summarize them for future research.
ccs concepts general and reference empirical studies software and its engineering parallel programming languages .
keywords gpu programming stack overflow topic taxonomy acm reference format wenhua yang chong zhang and minxue pan.
.
understanding the topics and challenges of gpu programming by classifying and analyzing stack overflow posts.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
introduction graphics processing technology has evolved to deliver unique benefits in the world of computing.
graphics processing units gpus have become one of the most important types of computing technology for both personal and business computing .
designed for parallel processing gpus provide incredible acceleration in workloads that take advantage of their highly parallel nature and are originally used in applications such as graphics and video rendering.
because of their remarkable computational power developers have also started to harness the power of gpus to accelerate additional workloads in high performance computing deep learning and more .
gpus have become an indispensable part of modern computing.
gpu programming has seen success recently as gpus have become more flexible and programmable.
the number of developers using gpus for programming and software development is also expanding.
take cuda one of the most widely used gpu computing platforms developed by nvidia as an example since being introduced in it has been supported by an installed base of over million cuda enabled gpus in notebooks workstations compute clusters and supercomputers .
nowadays a large number of developers are programming with gpus.
however gpu programming is difficult.
on the one hand gpu programming poses specific challenges to developers compared to sequential programming.
gpu programming requires developers to take additional data movement data synchronization and data precision into account compared to traditional programming.
on the other hand even for experienced developers it can be challenging to keep pace with the rapid evolution of gpu technologies as gpu platforms and hardware advance and the application areas of gpus expand.
not surprisingly many developers have encountered challenges when programming with gpus.
these challenges are evidenced by the questions frequently raised in developers q a forums.
observing this van den haak et al.
conducted an analysis of opencl and cuda related questions on stack overflow with the aim of determining whether the raised concerns in those sampled questions could be addressed by current formal verification tools.
while their study offers a targeted perspective of the challenges that developers may encounter and provides valuable insights into the capabilities and prospects of formal verification tools in resolving opencl and cuda programming related issues a gap remains for a comprehensive study that provides an expansive understanding of the wide spectrum of challenges that developers face in gpu programming.
esec fse december san francisco ca usa wenhua yang chong zhang and minxue pan to fill this knowledge gap this paper presents a comprehensive empirical study to understand the topics discussed and challenges encountered by developers in gpu programming.
in light of the surge of interest in gpu programming and the extensive applications of gpus this study can help developers quickly understand fundamental difficulties avoid common pitfalls in gpu programming and enable researchers and gpu platform vendors to better help software engineers conduct gpu programming in a more targeted way.
considering that developers often ask questions about their problems and confusion on professional q a forums e.g.
stack overflow so it has been a common practice for researchers to understand the topics and challenges in dealing with different engineering tasks by analyzing q a posts .
therefore to understand the topics discussed and the challenges faced by developers in gpu programming we analyze the relevant posts on so which is one of the most popular q a forums for developers and allows developers to seek technical advice from other developers and experts.
in summary our study collects and analyzes so posts regarding gpu programming to understand topics discussed and challenges encountered by developers in gpu programming.
based on these posts we focus our study on the following research questions.
rq1 topics and taxonomy.
what gpu topics do developers ask about and what is the taxonomy of those gpu topics?
rq2 characteristics of topics.
how are the gpu topics characterized in terms of popularity difficulty and changing trends?
rq3 challenges.
what are the challenges faced by developers for each gpu topic in the taxonomy?
as gpu programming covers a broad range of topics the premise for the success of this study is the effective identification of the topics.
widely used unsupervised approaches such as latent dirichlet allocation lda can extract topics directly from an entire corpus of posts but require the number of topics to be determined prior to topic extraction and may produce variations of topics over different runs.
gpu programming is an emerging concept and lacks of a topic taxonomy making the lda inapplicable to the task.
to address this problem we propose a novel bottom up approach to topic extraction by first extracting a set of keywords from each post and then using selected representative keywords to manually extract meaningful topics.
such an approach combines automatic techniques and manual analysis and can achieve a balance between efficiency and effectiveness.
we organized the extracted topics into a hierarchical taxonomy and classified posts into their corresponding topics.
we then analyzed the topic characteristics in terms of popularity difficulty and changing trends as well as the challenges faced by developers in each topic.
our study leads to the following primary findings topics and taxonomy.
the gpu related posts cover a wide range of topics up to in total indicating the complexity of gpu programming.
most of them fall into the programming category but the categories ofenvironment and application also occupy a substantial share indicating that as a new class of programming its programming environment and target applications are challenging for developers.
characteristics of topics.
gpu topics are popular overall and among them the topics related to basic concepts installing gpu development environments and especially the deep learning framework tensorflow are the most popular indicating thatgpu programming is attracting new developers and ai programmers.
difficulty peaks with tensorflow installation and configuration topics suggesting stringent demands in deploying gpu programming frameworks.
challenges.
for those topics we have identified a list of challenges most of which are not seen in traditional programming but are specific to gpu programming.
the majority of these revealed challenges remain unresolved pointing researchers and developers to possible future work.
in summary our study delivers the following key contributions we construct a taxonomy of challenges in gpu programming by leveraging a blend of automated methods and manual analysis on a large collection of so posts we not only undertake a quantitative exploration of topic popularity difficulty and trends but also reveal the specific challenges within each topic through a qualitative analysis we discuss the implications of our findings from both research and practice perspectives and provide a curated dataset of gpu programming posts to foster future research.
methodology here we describe step by step the methodology used in the study.
figure shows an overview of the methodology of our study.
step download stack overflow dataset.
in this step of our study we download the so dataset from stack exchange data dump .
the metadata of each post is composed of its identifier post type i.e.
question or answer creation date title body tags view count score favorite count and the identifier of the accepted answer for the post if the post is a question.
besides one to five tags can be attached to a post specifying its topics.
the contributor who posted a question can mark an answer as accepted to the question.
our so dataset denoted as s covers posts from july .
step identify relevant questions.
to identify gpu related questions from so we utilize the tags of questions.
we build a set of tags related to gpu to extract relevant questions from so.
we first select the questions whose tag fields include gpu froms as our initial dataset t. then we construct a candidate tag set by extracting all tags of questions in t. since not all of the tags in are significantly relevant to gpu we further refine to exclude irrelevant tags.
to determine which tags are significantly relevant to gpu we leverage two heuristics i.e.
and commonly used in existing work .
the heuristic i.e.
the number of questions with tag zintdividing the number of questions with tag zins measures the relevance of a tag zin to gpu and the heuristic i.e.
the number of questions with tag zintdividing the number of questions int measures the significance of a tag zin .
we consider a tag zsignificantly relevant to gpu if its and values are higher than or equal to specific thresholds.
to decide the appropriate thresholds for and we first set a series of thresholds to be selected for each of them which are set by referring to existing work .
specifically we have both six candidates for .
.
.
.
.
.
and .
.
.
.
.
.
.
this resulted in a total of distinct configurations for creating the final set of tags.
these various configurations led to containing between and elements.
the range in size was manageable enough to allow for a manual inspection and the first two authors collaborated to determine which configuration provided the most 1445understanding the topics and challenges of gpu programming by classifying and analyzing so posts esec fse december san francisco ca usa construct topics taxonomy classify questions inductively construct and refine taxonomy determine characteristics of topics popularitydifficultytrends extract gpu topics combing automatic techniques and manual thematic analysis3.
automatically extract and select representative keywords3.
aggregate posts with similar representative keywords... .
manually extract meaningful topics from grouped posts identify challenges for gpu topics content analysis download stack overflow dataset identify relevant questions figure an overview of the six steps employed in the study methodology.
relevant and representative tags based on a careful review.
in the end we selected the configuration where takes .
and takes .
as this configuration yields the most adequate results.
the final tag set includes cuda gpu gpgpu opencl nvidia thrust .
using these tags we identified the final set of questions f i.e.
selecting those questions from sthat contain at least one of the above tags.
as a result we obtained questions in f forming the final dataset to be analyzed.
step extract gpu topics.
to obtain gpu topics from f we first preprocess the question set to reduce the noise for the next step of the analysis similar to existing work .
specifically we remove code snippets url address html tags stop words numbers punctuation marks and non alphabetic characters.
then we use porter stemmer to reduce words to their stemmed representations e.g.
synchronous is reduced to synchron .
in particular performance remains unchanged to prevent the potential confusion with perform .
then we can extract topics from the posts.
since there are many research efforts studying what developers are discussing on so researchers have proposed various methods to extract topics from so posts.
we can roughly divide them into two categories automatic extraction techniques and manual thematic analysis methods .
automatic topic extraction techniques are represented by lda along with some machine learning methods such as random forests conditional random fields and support vector machines .
manual thematic analysis relies on manual processing.
these methods provide us with a very valuable reference however they all have apparent drawbacks when applied to our problem.
specifically automatic techniques are essentially unsupervised algorithms and it is difficult to obtain generated topics with good quality and granularity.
taking lda for example as described in lda may produce meaningless topics with ambiguous and confusing words which is confirmed in .
meanwhile it is necessary to specify the total number of topics with lda which is hard to decide in advance.
having this number too large or small can both negatively affect the granularity and quality of generated topics.
despite efforts to improve lda problems persist.
the unsupervised nature of automatic extraction techniques can lead to variable results impairing reproducibility.
manual thematic analysis becomes too time consuming and labor intensive if a sufficient number of posts are to be selected.
therefore we propose a novel approach to extracting topics by combining automatic techniques and manual thematic analysis.
wefirst use yake!
a feature based keyword extraction tool used by many researchers to extract the top ten keywords for each question.
the higher the keyword ranks the more relevant it is to the question.
for a very few posts .
fewer than ten keywords are generated due to overly short question body text contents.
we have acquired keywords from our dataset f and of them that occur in more than questions are selected for further analysis considering their representativeness.
then we manually extract meaningful topics from the posts based on these keywords.
the extraction process follows a bottom up manner i.e.
we first aggregate posts with the same or similar keywords together and then manually determine the topics from these posts and their keywords.
it can be seen that our extraction approach differs from the idea of lda which first determines a fixed number of topics and then divides the dataset into each topic.
our approach is to extract topics based on the posts and to keep expanding the topics without first fixing all the topics.
the advantage of our approach is that we can obtain a finer granularity of topics by considering both the content of posts and the relationships between them in the manual extraction process.
in the manual analysis process we discard common and generalized keywords that are frequently used in various so posts but do not belong to any specific domain such as work and overly coarse grain keywords such as opencl and nvidia .
we finally selected representative keywords and extracted specific topics from them.
we provide the details of these topics and keywords in section .
step construct topics taxonomy.
few studies have systematically explored the questions developers may have in the emerging field of gpu development.
recognizing this we believe it is necessary to provide further analysis of the topics.
therefore after extracting the topics we construct the topic taxonomy to help readers understand the hierarchy of topics more clearly.
we first determine to which topics the questions belong since in the previous step we only aggregated similar questions together and did not classify them by the topic.
we can use the posts to better construct the topic hierarchy which is also needed for the subsequent analysis of topic popularity and difficulty.
we use a multi stage matching method to classify questions into these topics.
in the first stage since the title of a question consists of several words and properly summarizes the main content of the question we classify questions with the help of titles i.e.
if a keyword of a topic appears in the title of a question we classify the question into that topic.
if the title of the question does not contain any keyword corresponding to a topic we leave them for the next stage.
in the 1446esec fse december san francisco ca usa wenhua yang chong zhang and minxue pan second stage we leverage the ten keywords generated by yake!
for each question in the previous step to classify it.
we traverse the ten keywords in the order from high to low of the relevance for each of the questions and once the keyword matches with a topic keyword we classify the question into the corresponding topic.
in the third stage since we selected keywords with more than occurrences among questions in f in step there exist a small number of questions that are not covered by these keywords so we manually classify these questions.
these questions are mainly general questions e.g.
is it possible to use opencl via ssh?
basic conceptual questions and other unclassified questions.
thus we introduce three other classes general basic concept and others for classification.
the first two stages of classification are automatic and they successfully handle .
questions and the remaining questions .
are manually classified.
in this process there are cases where a question is classified to more than one topic which is also in line with the reality as a question can involve more than one topic.
the distribution among posts is as follows to one topic to two to three to four and to five topics.
following existing studies the topic taxonomy is inductively constructed and refined by grouping similar topics and categorizing lower level into higher level ones.
two authors collaborate and engage in discussions to form groups with a third arbitrator to facilitate consensus in conflicts.
reliability analysis.
to validate the question classification results of questions two of the authors experienced in gpu programming independently verify the outcomes of randomly sampled questions for reliability.
we refer to to determine the sampling size for each topic.
in the end we sampled classified questions in total to conduct reliability analysis.
each of the sampled questions is labeled with true orfalse to indicate the correctness of our classification method s results.
the inter rater agreement during the independent checking is .
measured by cohen s kappa indicating almost perfect agreement and they reach agreement on conflicting questions with the help of a third arbitrator.
based on the manually labeled results we conducted a hypothesis testing whose null hypothesis is that fewer than questions of the topic are classified correctly with a confidence level of .
the result of hypothesis testing rejects the null hypothesis demonstrating the reliability of our classification method.
details are in the supplemental materials c.f.
section .
to ensure the reliability of selected keywords and the constructed taxonomy two authors independently classified the topics then aligned their results.
disagreements were resolved through discussion with a third party for adjudication when needed.
step determine characteristics of topics.
for the topic popularity we first use three metrics that have been used by existing work to measure the popularity of gpu topics based onf.
the first metric is the average number of views for all the questions of a topic.
the second metric is the average number of questions of a topic that are marked as favorites by users.
the third metric is the average score of questions of a topic.
meanwhile in addition to the mean values we also calculate the medians for these three data values such as the median number of views.
we measure the difficulty of gpu topics using three metrics adopted from previous works .
the first one is the percentage of questions with no accepted answer.
the second metric is thepercentage of questions with no answer i.e.
these questions have not been answered.
the third metric is the median response time needed for a question to receive an accepted answer.
since gpus are evolving rapidly it is of significance to explore the trends in these gpu topics.
we investigate the trends of these topics since so was proposed.
specifically to track the trend of each gpu topic we count the number of questions related to that topic in each year and the percentage of questions related to that topic among questions of all gpu topics.
these two metrics can provide a straightforward representation of the trend of change for a topic.
step identify challenges for gpu topics.
questions related to gpu programming have been extensively asked on so indicating that developers are encountering a spectrum of difficulties in gpu programming.
this step aims to understand the challenges in gpu programming by analyzing the questions classified to each gpu topic in step .
to select representative questions for each topic we adopt the metric i.e.
accumulated post score which considers the up votes down votes comment count answer count and favorite count of the questions.
for the questions classified under each topic we sort them by the accumulated post score of the questions and select the top questions for analysis if the percentage of questions under that topic is less than otherwise the top questions are selected for manual analysis.
as a result we obtain a dataset of questions used for identifying challenges.
the size of this dataset is larger than those used in existing studies which also require manual analysis of so posts.
we then follow a common qualitative analysis procedure i.e.
content analysis to inspect and identify challenges from the selected posts.
two of the authors independently validated the results and reached agreement by discussion.
rq1 gpu topics and taxonomy table shows the gpu topics extracted from ffollowing step as discussed in section .
in total we obtained meaningful and fine grained gpu topics whose stemmed representative keywords are given in column of table .
for example the first topic array and the second topic matrix both concern specific data structures in programming.
developers ask questions about a broad spectrum of topics on gpu such as application in multimedia e.g.
image and graphic processing and gpu related hardware e.g.
driver and card .
in general these topics can be divided into three main categories which are programming environment and application.
figure illustrates the hierarchical taxonomy of topics in gpu development.
the innermost ring presents these three main categories of topics classified at the highest level of the hierarchy.
programming is concerned about a series of basic programming issues in gpu development such as data structures and the grammar of programming language.
environment refers to various software and hardware environment factors that affect whether gpu programs can run smoothly for example configuration and drivers.
application is concerned with how gpus are used in various domains since modern gpus are engaged in many complex computations such as multimedia and deep learning.
a hierarchy for gpu topics that developers ask questions about on so is constructed by grouping of similar topics into categories and lower level categories into higher level categories as discussed 1447understanding the topics and challenges of gpu programming by classifying and analyzing so posts esec fse december san francisco ca usa array4.
matrix2.
schedule2.
algorithm2.
vector1.
data frame1.
data structure algorithm14.
kernel thread13.
kernel8.
thread5.
memory9.
api library8.
grammar5.
debug4.
performance3.
api4.
library4.
function1.
variable1.
pointer0.
class0.
struct0.
header0.
template0.
basic concept1.
general question0.
deployment12.
compile5.
install2.
configure2.
build1.
link0.
device5.
card1.
architecture1.
driver1.
hardware0.
monitor2.
tool0.
multimedia9.
deep learning framework6.
others1.
image processing4.
graphics programming3.
tensorflow4.
video0.
pytorch1.
keras0.
theano0.
programming62.
docker0.
environment21.
application16.
figure taxonomy of gpu topics their categories and percentages of their questions.table gpu topics and their stemmed keywords.
topic name representative keywords array arrai matrix matrix matric schedule parallel synchron queue data frame int doubl float integ vector vector algorithm algorithm optim kernel kernel thread thread block warp grid memory memori buffer api api cudamemcpi cudamalloc library librari thrust cufft cubla function function variable variabl pointer pointer class class struct struct header header template templat debug error wrong fail debug crash warn fault performance speed slow faster slower performance acceler compile compil nvcc gcc install instal build build cmake link link configure configur card card gtx geforc tesla architecture architectur sm core ram cach driver driver hardware hardwar monitor measur monitor profil smi tool toolkit sdk image processing imag opencv draw pixel textur graphics programming render shader opengl video video ffmpeg tensorflow tensorflow tf pytorch pytorch keras kera theano theano docker docker in section .
the largest share among these three categories are questions related to programming.
more than three fifths .
of the questions asked by developers fall into the programming category followed by the category of environment at .
and lastly the category of application at .
.
the dark gray sector blocks in the outermost circle correspond to the extracted topics.
it is worth mentioning that other three classes i.e.
general basic concept and others introduced in step of section for manual classification of questions are also shown in the outermost circle.
the upper level of the bottom level topics are the categories e.g.
deep learning framework and deployment that we have grouped for related bottom topics which in turn can be further categorized into each of the three categories at the highest level.
in particular some of the topics e.g.
debug and monitor are already standalone and instead of grouping them further we categorize them directly to the highest level.
in the category of programming we have topics on data structure algorithm the largest share among programming kernel thread memory api library grammar debug performance basic concepts and general questions .
the topics in the category of environment include deployment device monitor and tool.
in the category of application the topics are divided into multimedia deep learning framework and others according to their application domains.
rq2 characteristics of topics popularity.
we investigate the popularity of the gpu programming topics on so to understand which topics developers are more likely to be confused about.
as described by step in section the popularity of gpu topics is measured by the average and median values of views favorites and scores.
among them we use the average number of views as the main metric since a popular question tends to attract more developers to view it.
still the other metrics are also informative to estimate the popularity of a topic.
table gives the results of topics popularity sorted by the average number of views.
due to space limitations we have filtered out topics whose number of questions accounts for less than of f the percentage of questions for each topic is given in figure but we provide the complete results for all topics in our supplementary materials c.f.
section .
as we can see from table install basic concepts card tensorflow and driver are the top five most popular topics being asked.
these topics draw an average view count that exceeds three thousand and their median view counts also hold relatively high positions in the ranking with the first two being notably prominent.
the first two topics are so popular mainly due to the fact that they are about getting started with gpu programming such as how to install gpu development environments and basic 1448esec fse december san francisco ca usa wenhua yang chong zhang and minxue pan table popularity measures of gpu topics.
topicviews favorites scores avg.
med.
avg.
med.
avg.
med.
install .
.
.
.
.
.
basic concepts .
.
.
.
.
.
card .
.
.
.
.
.
tensorflow .
.
.
.
.
.
driver .
.
.
.
.
.
monitor .
.
.
.
.
.
build .
.
.
.
.
.
compile .
.
.
.
.
.
library .
.
.
.
.
.
configure .
.
.
.
.
.
thread .
.
.
.
.
.
architecture .
.
.
.
.
.
api .
.
.
.
.
.
debug .
.
.
.
.
data frame .
.
.
.
.
.
function .
.
.
.
.
.
performance .
.
.
.
.
.
memory .
.
.
.
.
.
algorithm .
.
.
.
.
.
schedule .
.
.
.
.
.
graphics programming .
.
.
.
.
.
kernel .
.
.
.
.
.
image processing .
.
.
.
.
.
array .
.
.
.
.
vector .
.
.
.
.
.
matrix .
.
.
.
.
.
overall average .
.
.
.
.
.
concepts of gpu programming.
since an ever increasing number of developers are learning about and getting started with gpu programming questions related to these topics receive a high number of views.
we can also observe that questions explaining basic gpu concepts to developers receive the highest average favorites .
and many of these questions are for novice gpu programmers.
topics card and driver are both about gpu devices and it is easy to understand why they are more popular since unlike traditional software development gpu programming requires developers to know more about the devices and hardware.
after all to start gpu programming developers first need to get their gpu hardware and software environments set up.
in addition as gpus continue to expand application use in ai and deep learning the topic tensorflow receives increasing attention.
in comparison topics related to specific programming details e.g.
topics belonging to data structure and algorithm are less popular.
this is primarily due to the large number and diversity of questions related to these topics.
we also analyzed all question views on so based on s revealing an average and median of and views respectively.
by contrast the average view for gpu topics is lower which might be due to that gpu questions were asked more recently in comparison to many longstanding questions on so that accrue views over time e.g.
a question posted years ago has over million views .
however the median view for gpu topics is higher than for all questions on so indicating an elevated interest in this field.
furthermore gpu topics average views exceed those of well studied subjects such as concurrency big data and security .
the average and median values for favorites and scores of gpu questions were .
.
and .
.
respectively contrasted with .
and .
for all so questions.table difficulty measures of gpu topics.
topic w o acc.
w o ans.
hrs to acc.
tensorflow .
.
.
install .
.
.
configure .
.
.
performance .
.
.
driver .
.
.
image processing .
.
.
build .
.
.
graphics programming .
.
.
monitor .
.
.
architecture .
.
.
card .
.
.
schedule .
.
.
debug .
.
.
algorithm .
.
.
memory .
.
.
compile .
.
.
api .
.
.
kernel .
.
.
matrix .
.
.
basic concepts .
.
.
library .
.
.
vector .
.
.
data frame .
.
.
thread .
.
.
array .
.
.
function .
.
.
overall average .
.
.
difficulty.
identifying the most difficult topics enables developers to prioritize challenging ones especially if a topic is both popular and difficult warranting increased attention.
as described in section the difficulty of gpu topics is measured using the percentage of questions with no accepted answers w o acc.
the percentage of questions with no answers w o ans.
and the median time to get an accepted answer hrs to acc.
.
to put it intuitively a topic is considered more difficult if most of its related questions do not have accepted answers.
in the meantime the other metrics can also help us understand the difficulty of the topic.
table presents the results of the difficulty measures of gpu topics sorted by the percentage of questions with no accepted answers.
similar to popularity we have also filtered out topics whose number of questions is less than of fdue to space limitations.
also a small number of questions is likely to produce a random bias in the metrics.
nevertheless the complete results of all topics are also included in our supplementary materials c.f.
section .
from table we can see that among the first few topics the percentage of no accepted answers for the first topic tensorflow .
is relatively high compared to the other ones and the remaining ones do not differ too much.
on the one hand tensorflow is a relatively new technology and thus not many developers fully understand this technology in the early stage which makes fewer developers able to provide accepted answers.
on the other hand tensorflow is constantly being updated making it necessary for developers to keep learning.
additionally ensuring tensorflow running on the gpu poses particular challenges for developers which has been raised by many developers e.g.
questioners complained that i am having a hard time trying to run a tensorflow program in the gpu .
and i have been trying to run some tensorflow training on some machine with gpus...whenever i try to do so i get some type of error... .
similarly topics related to gpu 1449understanding the topics and challenges of gpu programming by classifying and analyzing so posts esec fse december san francisco ca usa a api library b basic concepts c data structure algorithm d debug e deep learning framework f deployment g device h general questions i grammar j kernel thread k memory l monitor m multimedia n others o performance p tool figure the trends of topics over the years.
the blue lines represent the number of questions and the red lines represent the percentage of topic specific questions relative to all gpu related questions.
deployment e.g.
configure and build and devices e.g.
driver and card that enable programming environments are ranked relatively high on the list.
for example configure has the second fewest answers .
and build has the longest time to receive accepted answer .
hours .
it implies that developers are likely to encounter a variety of problems when they get started with gpu programming and prepare their programming environments.
then questions related to the performance of gpu are also considered relatively difficult followed by some application specific topics such as image processing and graphics programming .
in contrast some common topics related to parallelism e.g.
kernel and thread and basic operations e.g.
data structures and grammar in gpu programming are ranked lower in difficulty.
for reference we also calculated the three metrics for all questions on so yielding .
.
and .
respectively.
these values suggest that while the proportions of questions without accepted answers and unanswered questions for gpu topics are similar to those for all so questions the duration to receive an accepted answer for gpu topics is notably longer.
after analyzing topic popularity and difficulty we naturally examined their interrelation using kendall correlation analysis however the results indicate no significant correlation.
trends.
figure shows the results for these gpu topics.
here we present the results by the upper level category to which the topic belongs the hierarchy is given in figure except for those topics that are stand alone such as debug and performance their upper level is the highest level .
two reasons inform thischoice.
first space limitations preclude detailing numerous bottomlevel topics.
second a topic s upper level category better indicates field trends as some bottom level topics are too narrowly focused e.g.
template in grammar or have too small a percentage e.g.
header in grammar to adequately reflect trends.
each sub figure s blue line represents question trends while the red line depicts the question percentage trend.
as shown in the figure since so s inception in questions in almost all categories initially grew differing in growth onset.
most categories began growing around while the deep learning framework reflecting its recent development saw a rapid increase starting in peaking in and maintaining a high percentage thereafter.
this aligns with deep learning s evolution and current popularity corroborating the results of popularity measures.
similarly deployment related questions have also stayed at a high level which is consistent with the results in popularity and difficulty further illustrating the prevalence and challenging nature of deployment in gpu programming.
differently we can observe that the percentage of multimedia related questions was the highest at the very beginning more than after which the percentage of questions decreased and then remained at a relatively stable level.
this is because gpus originally designed to accelerate graphics rendering have evolved into other more varied application domains.
questions on basic concepts declined after initial growth but despite the low question count the high number of views suggests 1450esec fse december san francisco ca usa wenhua yang chong zhang and minxue pan these questions have become classic to some extent.
this reflects a maturation and stabilization of gpu related concepts.
the general trend of most other categories e.g.
data structure algorithm follow a similar trend of initially rising and then stabilizing peaking around as with kernel thread during gpus rapid growth period.
the trend curves of categories general questions tool and others are quite different from other categories but they maintain a low question count possibly biased by the low number.
categories like deep learning framework deployment data structure algorithm and api library have maintained a relatively high number or percentage of questions recently showing questions in these categories are encountered by many different developers.
rq3 challenges .
programming data structure algorithm.
the topics in this category include array matrix schedule algorithm vector and data frame which are ranked in descending order by the percentage of questions.
array despite being basic in traditional programming arrays pose challenges in gpu programming.
most so queries about arrays deal with routine operations like creating arrays in cuda dynamic allocation and sorting.
besides the use of 2d 3d arrays is particularly challenging for developers and we have observed many questions concerning the allocation and representation of 2d 3d arrays.
matrix one of the main challenges for developers here is to distinguish the difference between matrix operations on cpus and gpus.
for instance developers need to understand the differences in computational precision and speed of matrix multiplication between cpus and gpus such as numpy on cpus versus gnumpy on gpus.
implementing and optimizing matrix transposition efficiency on gpus is a common issue as is the operation of large sparse matrices like multiplication on gpus.
schedule the most significant challenge in schedule is about parallelization e.g.
parallelization of loops especially for nested loops which has attracted the attention of many developers.
on the other hand parallel reduction which is used in parallel programming to reduce the elements of an array into a single result is also a challenge that developers often struggle with e.g.
the problem of memory management in parallel reduction with cuda.
algorithm a term that appears a lot in algorithm related questions is optimization which mainly involves the time and space efficiency of the algorithm.
it is also concerned about various algorithms such as sorting and recursion.
in particular how to implement classical algorithms in gpu attracts much attention e.g.
triangulation algorithm aes algorithm and dijkstra s algorithm.
hence developers need more help in choosing the suitable implementation of different algorithms and in comparing the differences between the algorithms implemented in gpus and cpus.
vector a vector can be regarded as a specific dynamic array and the most frequent questions are concerned with vector types data transfer and operations such as the summation and multiplication of vectors.
it is challenging for developers to fully understand the differences e.g.
float2 float3 and float4 in cuda and advantages e.g.
unit2 and unit4 in cuda among various vector types.
passing vector data between programs is also troublesome for developers for example how to pass vectors from c to the opencl kernel.data frame it covers challenges in performing operations on specific data types such as type conversion and bitwise operation with the most prevalent questions regarding the operations of float points.
in addition comparisons between unsigned and signed data and precision issues e.g.
opencl floating point precision management are also highlighted concerns for developers.
kernel thread.
questions in this category have been one of the most widely discussed ones for gpu developers accounting for .
.
kernel the questions are mainly about the launch of kernel parameters of kernel and the nesting of kernel.
many developers have doubts about the understanding e.g.
how the kernel reads parameter values and using of kernel parameters e.g.
how to pass two dimensional arrays as kernel parameters so errors are often reported in the kernel calls.
whether kernel calls are synchronous or asynchronous and how to call another kernel from one kernel are also common questions from developers.
thread there are two types of challenges that stand out in this category.
one is about the organization of threads and the other is about the synchronization of threads.
threads are organized in blocks and multiple blocks form a grid.
the question of the size of threads blocks and grids e.g.
what is the maximum number of blocks per grid and how to set the appropriate size for them has confused developers.
memory.
among topics questions related to memory constitute the largest number .
reflecting the complexity of managing different types of memory in gpu programming.
for example there are host memory global or device memory local memory constant memory and shared memory in cuda and host memory global memory private memory in opencl.
it is a challenge for developers to distinguish between these memory differences.
besides developers have asked a number of questions about memory management e.g.
opencl correct results on cpu not on gpu how to manage memory correctly?
memory allocation e.g.
cuda memory allocation accessible for both host and device and some specific memory issues about shared memory e.g.
bank conflicts and local memory e.g.
limitation of size .
api library.
in gpu programming there are many libraries with numerous apis provided by different frameworks to help developers perform various computations conveniently.
however their sheer volume and functional similarity pose challenges in selecting and using suitable ones.
api developers are more concerned about the combinatorial use of apis and what apis are available in gpu programming that have the same functionality as their counterparts in traditional programming.
there are also many questions about comparing differences between similar apis e.g.
cudamallocmanaged andcudamalloc and complaints from developers about the api documentation e.g.
lack of examples and pitfall prevention instructions .
library the most prominent challenges related to libraries are the selection of libraries and the comparison of similar libraries.
furthermore developers are often confused about the use of some specific libraries.
examples of libraries that are often asked for include thrust a parallel algorithms library cufft a fast fourier transform library and cublas an implementation of basic linear algebra subprograms .
grammar.
with gpu programming rapidly advancing numerous languages now offer extended support attracting more developers.
consequently developers face challenges associated with 1451understanding the topics and challenges of gpu programming by classifying and analyzing so posts esec fse december san francisco ca usa the syntax of these varied programming languages.
the category ofgrammar involves questions on many aspects of a programming language including function variable pointer class struct template and header .
these questions are basically about the language s own mechanisms such as the use of inline functions and the instantiation of templates and many of them currently are not specifically related to the features of gpu programming.
debug.
debugging is an essential part of programming.
the most highlighted term in this category is error which indicates that gpu programming is error prone.
debug concerns the questions about locating and fixing bugs during gpu program development e.g.
identification of the cause of crash and warning .
there are many types of errors several of which are often mentioned such as errors caused by device driver and import errors.
performance.
it is common for developers to struggle with the disappointing running speed of their programs as explained by the developer in .
in particular developers are interested in maximizing gpu potential computation power to improve the speed of program execution which is challenging .
there are several common classes of challenges in this category.
the first class is about performance comparisons e.g.
between geforce gpus and quadro gpus between gpus and cpus and between cuda and opencl.
the second class concerns performance and memory such as using texture memory to improve performance access speed of opencl private memory and local memory and the performance bottleneck of cuda memory allocation.
the third class is how to monitor and evaluate gpu performance which overlaps slightly with the topic monitor but focuses only on performance.
basic concepts andgeneral questions.
these two categories are added during the manual classification of questions and their shares are small .
and .
respectively .
basic concepts includes questions about background knowledge of gpu development such as what does simd mean?
.
the number of questions in this category is small but popular especially in the early days of gpu programming.
this is mainly because many beginners learn and understand gpu programming by browsing these questions and answers on so.
the second category is about general questions that are not related to other specific topics in gpu programming e.g.
how to create llvm structure value?
.
.
environment deployment.
this category focuses on issues related to the deployment of gpu development platforms such as cuda and opencl.
it covers questions on six topics compile install configure build link and docker the first five of which correspond to the different tasks and the last of which is about enabling and using gpus inside a docker container.
each topic s questions basically depict the challenges developers face when undertaking the associated task.
compile many questions in this category are concerned with the use of commands gccandnvcc .
this is because different gpu computing platforms have limited support for gcc and nvcc versions making it easy to run into compatibility issues when compiling.
in addition when compiling gpu programs under different operating systems it can be a challenge for some developers to select and configure the compiler to avoid compilation errors especially compatibility issues .
install as we can see from the resultsof rq2 this topic ranks high in terms of difficulty.
gpu programming requires the installation of various platforms and software.
however different platforms and software are constantly being updated which raises many compatibility issues.
therefore there are many questions about how to confirm that a software platform or driver is installed or successfully installed and how to uninstall and install a specific version.
configure configuring the cuda kernel is the most frequently mentioned issue such as not knowing how to configure its parameters or configuring parameters that cause errors.
some developers complained that the cuda kernel startup parameters are not clearly explained.
in addition there are many configuration questions related to visual studio mainly about what configuration is needed to perform gpu programming in visual studio.
build the questions in this category are mostly developers asking how to solve problems they encounter when building gpu programs the most common of which are errors related to cmake.
link anddocker are basically questions or errors that developers encounter when linking and using docker e.g.
how to link cuda code to c c projects but there are many types of questions errors and no particular focus.
however the number of questions in them is significant.
furthermore we can learn from rq2 that deployment has been a notable struggle for developers of gpu programming.
therefore researchers are expected to propose automated deployment techniques to simplify deployment tasks e.g.
eliminating compatibility issues for developers.
device.
questions in this category are mainly about gpu devices.
card given the variety of gpu card versions from different vendors developers grapple with issues like distinguishing card differences compatibility with gpu platforms and uncertainty about the appropriate apis for gathering card information when programming.
architecture it is concerned about the whole hardware architecture e.g.
fermi kepler and maxwell and its concrete components such as stream multiprocessor core and cache.
these questions focus on the characteristics of these architectures and how to understand them.
driver the most common term in this category is version and many of the challenges developers face are related to driver version such as not having enough driver version for the cuda runtime version.
another challenge is that some developers are unclear about how to obtain information about drivers in programming.
hardware the most highlighted issue in this category is about hardware emulation i.e.
how to simulate gpus without gpu hardware support.
another requirement of interest to developers is the use of gpus for hardware acceleration but many questions actually tie back to the configuration of operating systems.
monitor.
gpu monitoring can help developers track gpu performance or overall gpu resource usage so many developers use it and raise a number of questions about it accounting for .
off .
the use of the monitoring tool nvidia smi leaves many developers with doubts and the questions related to it are the most pronounced in this category.
there are also some questions about getting specific execution information such as gpu temperature gpu computation gpu usage history and gpu flops floating point operations per second .
tool.
most of the questions are about installing and configuring the cuda toolkit and opencl sdk but the number is small and developers do not find it difficult.
1452esec fse december san francisco ca usa wenhua yang chong zhang and minxue pan .
application multimedia.
in the early days of the development of modern gpus the number of multimedia related questions on so is very high and now the number is relatively small.
this indicates that developers are becoming more familiar with the use of gpus for multimedia.
however there are still challenges for developers in this area.
image processing many of the early questions in this category are about opencv and opencl such as image format conversion and image manipulation in opencv.
currently there are not many such questions but more questions about the new features brought by opencv updates and how to combine opencv with other programming tools.
graphics programming the trend of questions in this category is similar to that of image processing but the difference is that opengl is the focus here.
shading and rendering are among the most frequently mentioned features and questions relatd to them are often asked as opengl is being updated.
video there are relatively few questions here most of which are related to video streaming and ffmpeg a video and audio converter .
deep learning framework.
recently we are seeing more questions about gpus and deep learning on so.
this category deals with questions about deep learning frameworks that provide a bridge for developers to use gpus to train deep neural networks.
there are several frameworks such as tensorflow pytorch keras and theano .
tensorflow is based on theano while pytorch is based on torch and keras is the high level api of tensorflow.
the number of questions related to tensorflow dominated followed by pytorch.
this is understandable since tensorflow is the most popular framework for deep learning production environments and has a large community.
since tensorflow has been proposed more recently how to successfully run tensorflow on gpus is the most frequently asked question which includes tensorflow installation configuration and version compatibility.
in addition there are some specific errors reported when running tensorflow code among which errors related to dynamic libraries are very common.
the types of questions under other frameworks are similar to those in tensorflow and the most prominent challenge is also how to get them to run successfully on gpus.
meanwhile gpus impose programming constraints to avoid training anomalies and yet many gpu interfaces and usage scenarios are not well documented causing problems for developers.
one of the most admired characteristics of gpus is their ability to compute processes in parallel and thus gpus can be used for massive distributed computational processes e.g.
training deep learning models.
with deep learning s evolution an increasing number of developers apply it in gpu programming so researchers need to be better equipped to help them overcome the challenges involved as echoed in .
implications our findings offer contributions to gpu development research and also harbor practical implications for both developers and vendors imparting valuable insights into the field.
.
research the implications of our study for researchers are multifaceted.
firstly the taxonomy we have proposed can assist researchers in systematically understanding the challenges in the diverse topicsof gpu programming.
researchers can concentrate on prevalent issues within these topics while simultaneously our detailed analysis of the challenges for each topic presented in section allows every individual challenge to potentially become a research question.
for instance the parallelism challenge within the schedule topic is crucial for heavy computational workloads such as training large models.
however manually writing parallel programs presents its own difficulties.
consequently researchers can explore strategies to identify parallelizable code segments to enhance parallelism whilst ensuring that the automatically generated parallel programs are error free.
secondly our analysis of topic popularity difficulty and changing trends facilitates researchers in prioritizing their research tasks.
a representative example is the deployment topic of which the challenges consistently maintain a high rank whether assessed in terms of popularity difficulty or changing trends.
to the best of our knowledge there is few research on deployment issues indicating a neglected area.
however there are numerous potential research opportunities within this topic such as improving checks for software and hardware compatibility necessary for deployment identifying prerequisite dependencies for deployment automatically locating error causes when they occur or even simpler tasks such as creating clear detailed deployment documentation for systematic learning and troubleshooting by developers.
finally this study indicates that issues related to gpu programming are abundant on so not only highlighting the worthiness of researching challenges in gpu programming but also suggesting that so posts contain a wealth of knowledge regarding solutions to these challenges.
thus researchers can utilize the data on so to design solutions to problems or propose automated solution extraction methods for problem resolution documentation construction and more.
.
practice for gpu program developers the taxonomy of topics could serve as a guide to identify key problem areas and challenges they might face during development.
by referring to the taxonomy and corresponding discussion developers can anticipate potential pitfalls and make informed decisions about the trade offs involved in gpu programming.
furthermore by understanding the challenges compiled from the analysis of posts developers can better equip themselves to preemptively tackle these issues.
for instance the analysis of topics such as data structures algorithm memory and performance underscores the inherent contrasts in computational precision speed and optimal implementation between gpus and cpus thereby illuminating the necessity for distinct strategies in handling matrix operations algorithm implementation and the optimization of memory data layouts and access patterns in gpu programming.
our study provides gpu vendors with practical implications for enhancing their products and services.
the identified challenges faced by developers underline areas for possible hardware and software improvements.
for instance the high ranking of deploymentrelated challenges and the medium high ranking of monitoringrelated challenges in both popularity and difficulty suggest areas for focused attention.
vendors should invest in refining deployment tools or enhancing documentation to increase product ease of use.
1453understanding the topics and challenges of gpu programming by classifying and analyzing so posts esec fse december san francisco ca usa moreover the development of more powerful and intuitive monitoring tools is necessary for mitigating the monitoring related challenges.
by addressing these identified areas vendors can improve product usability and potentially elevate overall user satisfaction.
threats to validity selection of data source.
following previous work we choose so as our sole data source.
this is a potential threat as so may not capture all developer questions and we may miss valuable insights from other sources.
however considering that so is a very active community with many participating developers including novices and experts we believe this threat is reduced.
selection of tags.
the creation of our tag set could introduce bias as the selected tags may not cover all gpu related questions.
to mitigate this risk we followed established approaches and conducted experiments to derive an appropriate tag set.
nevertheless the final selection of tags could be influenced by individual experiences.
to mitigate this we engaged two researchers in the validation process to enhance the reliability and validity of the final tag selection.
construction of topic taxonomy.
during the classification of questions to topics a small proportion of questions .
were manually categorized which could introduce imprecision.
to ensure validity we sampled over questions for reliability testing and conducted hypothesis testing.
the results validated the reliability of our classification.
the creation of the taxonomy is based on topics.
although the number of the topics are manageable the manual effort involved carries potential threats.
to mitigate these risks we strictly adhered to established methods and guidelines for the inductive construction and refinement of the topic taxonomy.
two researchers collaborated to discuss results and reach consensus with the assistance of an arbitrator when necessary thereby enhancing the reliability of the results.
we also provide a detailed account of our manual analysis procedures in section to facilitate an understanding of any potential threats.
related work studies using so data.
so is one of the most popular q a website for professional and enthusiast programmers which has attracted increasing research interest with topics relating to community dynamics human factors and technical issues .
there exist many studies investigating how so knowledge benefits developers daily software development .
in addition researchers also analyze a series of features of the whole so data such as question categories community model topics and trends .
more specifically so has been widely used as data source to explore developers concerns in developing various types of software and facing different programming tasks such as big data docker security concurrency mobile applications web applications privacy deep learning and computer vision .
particularly in so data was utilized to assess formal verification tools for gpu programming issues mainly potential bugs and performance problems.
the study focused on questions explicitly related to cuda and opencl excluding other topics.
so questions were selected and manually categorized via card sorting into three primary themes memory threads andsynchronization and general issues.
each theme contained two subthemes related to bugs and performance.
in contrast to our study aims to derive an understanding of the topics and challenges in gpu programming.
this necessitated a broader analysis of so data and a more sophisticated topic extraction method resulting in a comprehensive taxonomy of gpu programming topics and an in depth discussion of the associated challenges.
research on gpu programming.
over the last few decades many studies have revealed the huge potential and broad prospect of gpu computing because of its highly parallel programmable capacity .
therefore there are many efforts to study gpu computing especially for the comparison of gpu and cpu in performance architecture and specific algorithms .
despite gpus current high capacity researchers are still working on methods to further improve gpus capabilities .
meanwhile there is another large category of studies that focus on applying gpus to non graphics application domains to name a few deep learning cloud computing and automatic driving .
in addition gpu programming itself has attracted increasing amounts of attention from researchers.
for example to help developers get started with gpu programming researchers discussed various guidelines for gpu programming such as thread and memory handling .
the verification of gpu kernel has also been the focus of many researchers.
they have proposed a variety of approaches based on satisfiability modulo theories smt test amplification and symbolic execution to verify the gpu kernel.
these approaches aim to detect bugs such as data races incorrectly synchronized barriers and bank conflicts.
also for debugging hou et al.
present a debugger for gpu stream programs through automatic dataflow recording and visualization.
with dataflow recording the debugger automatically detects common memory errors such as out of bound access uninitialized data access and race conditions.
although there are plenty of research efforts on gpu programming they all focus on a specific type of problem e.g.
gpu kernel and cannot represent all the challenges developers may face in gpu programming.
our work conducts the first study to understand various challenges that developers may encounter in gpu programming using so posts.
conclusion in this paper we conduct a large scale empirical study to understand the topics and challenges of gpu programming based on so posts.
we employ automated methods and invest extensive manual effort to build a taxonomy of topics for gpu programming and analyze the popularity difficulty and changing trends of these topics.
in addition we summarize the challenges organized by topic highlighting potential future work for researchers and developers.
data availability this paper offers a dataset of posts related to gpu programming at acknowledgment this work was partially supported by the national natural science foundation of china nos.
and the natural science foundation of jiangsu province no.
bk20201292 .
1454esec fse december san francisco ca usa wenhua yang chong zhang and minxue pan