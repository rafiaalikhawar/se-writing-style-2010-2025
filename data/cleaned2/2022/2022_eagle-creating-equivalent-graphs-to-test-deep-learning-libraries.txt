eagle creating equivalent graphs to test deep learning libraries jiannan wang purdue university west lafayette usa wang4524 purdue.eduthibaud lutellier university of waterloo waterloo canada tlutelli uwaterloo.cashangshu qian purdue university west lafayette usa shangshu purdue.edu hung viet pham university of waterloo waterloo canada hvpham uwaterloo.calin tan purdue university west lafayette usa lintan purdue.edu abstract testing deep learning dl software is crucial and challenging.
recentapproachesusedifferentialtestingtocross checkpairsof implementationsofthesamefunctionalityacrossdifferentlibraries.
suchapproachesrequiretwodllibraries implementingthesame functionality which isoftenunavailable.
inaddition theyrely on ahigh levellibrary keras thatimplementsmissingfunctionality in all supported dl libraries which is prohibitively expensive and thus no longer maintained.
to address this issue we propose eagle a new technique that uses differential testing in a different dimension by using equiv alent graphs to test a single dl implementation e.g.
a single dl library .
equivalent graphs use different application programming interfaces apis data types or optimizations to achieve the same functionality.
the rationale is that two equivalent graphs executed on a single dl implementation should produce identical outputgiven the same input.
specifically we design new dl equiva lence rules and propose a technique eagle that uses these equivalence rules to build concrete pairs of equivalent graphs and cross checks the output of these equivalent graphs to detect inconsistency bugs in a dl library.
ourevaluationontwowidely useddllibraries i.e.
tensorflow and pytorch shows that eagle detects bugs in tensorflow and in pytorch including previously unknown bugs.
ccs concepts software and its engineering software testing and debugging software reliability.
keywords softwaretesting deeplearning differentialtesting graphequivalence permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage.copyrightsforthird partycomponentsofthisworkmustbehonored.
for all other uses contact the owner author s .
icse may pittsburgh pa usa copyright held by the owner author s .
acm isbn .
reference format jiannanwang thibaudlutellier shangshuqian hungvietpham andlin tan.
.eagle creatingequivalentgraphstotestdeeplearninglibraries.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction testing dl systems is crucial because an increasing number of dl systems e.g.
self driving cars and cancer detection have been deployed.bugsindlsystemscausesevereconsequences forexample when a self driving system incorrectly responds to a traffic sign it causes severe personal injury and economic damage .
whendlsoftwarefailstoimplementamodelfaithfully e.g.
due toabuginthesoftware theoutputfromthesoftwarecanbewrong even if the model is correct .
here dl software includes infrastructure code that performs core neural network computations andapplicationcodethatloadsmodelweights.thus inaddition to testing dl models there is a high demand for testing dl software .
existing techniques such as cradle and audee test a pair of dl libraries to cross check the two implementations of the same functionality to detect inconsistency bugs.
these differential testingtechniquesrequireatleasttwoimplementationsindifferent dl libraries which is often unavailable for dl software.
for example onecould implementa newdl algorithmin onelibrary e.g.
tensorflow which does not have a counterpart in another library e.g.
cntk .
since only one single implementation exists existing cross library testing techniques cannot test it.
in addition differential testing on two libraries requires a high level library such as keras to switch across dl libraries such as tensorflow and cntk.
such a high level library is hard to develop and maintain because it essentially reimplements functionalities that are only available in one library in all other supportedlibraries.thisisoneofthemainreasonswhykerasstopped supporting different dl libraries .
without such a high level library it would be prohibitively expensive to cross check dl libraries because one would need to create separate complex dl implementationsfor other dl libraries.
to address these challenges we propose to leverage differential testinginadifferentdimension ourtool eagle uses equivalent graphstotestasingledlimplementation.forexample theclassificationoutputshouldbeidenticalifadlimplementationuses ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jiannan wang thibaud lutellier shangshu qian hung viet pham and lin tan ruzdug 511wi wudqvsrvh wi wudqvsrvh5hyhuvh uhyhuvh wlph uhyhuvh wlph wi nhudv od huv lgluhfwlrqdo edwfk pdmru udsk a. correct batch major graph ruzdug 5hyhuvh uhyhuvh edwfk uhyhuvh wlph wi nhudv od huv lgluhfwlrqdo wlph pdmru udsk b. buggy time major graph odh ?dh da b o oom n ga ajmr m?
g t m odh h ejm gn gn t m q m q mn t m q odh ?dh t m q m q mn t m q c. developer s fix figure1 equivalentgraphsthatwedesignedtodetectareal bugintensorflow.redbackgroundindicatesthebuggyline.
i1isthetensorinput.
o1ando1 primeareoutputthatisexpected to be identical.
the bug causes o1 o1 prime.
two different but equivalent recurrent neural networks rnn to performaclassificationtask.wedefine equivalentgraphs ascomputational graphs that achieve the same functionality which should produce identical output given the same input.
the equivalence is achieved with different apis data types optimizations etc.
for example an optimized way of representing mostly empty tensorsofdlmodelsisusingsparsetensors.onecangeneratetwo equivalentcomputationgraphs thefirsttakingadensetensoras inputandthesecondtakingasparsetensorasinput.whilethese twographsmayinvokedifferentapifunctions theyareequivalent i.e.
they should produce the same output given the same input represented as a dense tensor in the first graph or a sparse tensor inthesecond.whentheapifunctionscontainbugs theoutputmay be different.
eagle detects seven bugs related to sparse tensors in tensorflow and pytorch using equivalent graphs.
.
our approach a motivating example figure shows a real bug in tensorflow .1detectedbyeagleusingtwoequivalentgraphs.theequivalenceruleusedtogeneratethetwoequivalentgraphsinfigures1a and 1b is inspired by rnn functions that accept two input formats.
acommonformatis calledbatch major whichis the usual input format developers use.
the other format is time batch calledtime major .
the time major format better fits rnn computations because rnns compute batches step by step and similarstepsfromdifferentsequencesarerepresentedcontiguously in flattened time major arrays thus reducing training time.
for example giventhefollowingtwobatchesofthreewords i.e.
threetimesteps and theinputcanbefedtothe rnninbatch majorformat i.e.
bracketleftbiggil i k e d o g sie a ta p p l e s bracketrightbigg ortime major format i.e.
ii like eat dogs apples .
the first matrix is the transpose of the second matrix.
developers use an argument e.g.
parameter time major trueorfalseintensorflow ofrnnfunctionstospecifyinput sformat.bytransposingthecorrectdimension onecan transformatime majorinputmatrixtoabatch majorinputmatrix.
therefore leveragingthetime major batch majorandtranspose properties wecreatetwoequivalentgraphs.thegraphinfigure1a firsttransposesthetime majorinputtensor i1tobatch major feeds it to a batch major rnn tf.keras.layers.bidirectional in this example then transposes the output back to time major.
the graphinfigure1bdirectlyfeedstheoriginaltime majorinputto thetime majorrnntoproduceatime majoroutput.ifthernn api implementation is correct these two equivalent graphs should generate the same output given the same time major input.
figure 1b shows a real bug in the tensorflow api function tf.keras.layers.bidirectional whichimplementsbidirectional rnns and how the bug causes an inconsistency the same functiontf.keras.layers.bidirectional generatesdifferentoutput o1ando1 primegiventhesameinput i1 e.g.
atensorrepresentation of on two equivalent graphs.
the bug is in red ingraph figure 1b since the function reverse should be performed on the timedimension instead of the batchdimension.
the bidirectional rnn consists of two independent rnns a forward rnn and a reverse rnn.
the forward rnn processes the inputinthenormalorder andthereversernninthereverseorder e.g.
i like dogs becomes dogs like i .
since the output of the reversernnisnotinthecorrectorder itneedstobereversed.the api sbatch majormode figure1a corr ectlyusesthe reversefunction on the time dimension but its time major mode figure 1b incorrectly reverses the batch dimension instead of the time dimension i.e.
reverse batch inred isincorrectandshouldbe reverse time resulting in incorrect output o1 prime.
itischallengingtodetectthisbugwithouteaglebecausewithout graph in figure 1a one may not know o1 primein graph in figure 1b is the wrong output for input i1.
the reason is that it is hard to know the expected output o1 given input i1 since the dl calculation e.g.
reverse rnn is complex .
our equivalent graphapproach addressesthischallenge bycomparingthe output from two equivalent graphs to identify inconsistencies to detect software bugs.
figure1cshowsthefixprovidedbytensorflowdevelopers who fixed the bug by setting the appropriate dimension to reverse according tothe input format withthe buggy line inred background and the fixed line in blue background.
such graph equivalence on time major and batch major is generalasmostdllibraries includingtensorflowandpytorch use such representation.
we apply eagle to test rnn functions in tensorflow and pytorch and detect that allbidirectional rnns in tensorflow incorrectly implement the time major functionality.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
eagle creating equivalent graphs to test deep learning libraries icse may pittsburgh pa usa thismotivatingexample demonstrateshowequivalentgraphs enablethediscoveryofhard to findbugsindllibraries.wepresent below the main steps of our approach.
equivalenceruledefinition thefirststepistogeneraterulesto buildequivalentgraphs.therearetwomaincriteriaforgenerating theserules.first therulesshouldbegeneralizabletomultipleapis anddllibraries.second therulesshouldbenon trivialtodetect real worldbugs.tocoverasmanylibrariesaspossible wecarefullyinspectapidocumentationfromtensorflowandpytorchlibraries.
in total we design a list of new equivalence rules that covers apis of these two dl libraries.
equivalent graph construction once we have a set of equivalencerules weconcretizethesegeneralabstractrulesintoconcrete graphs.
specifically we test a concrete dl function with specific configurations e.g.
weights and input.
for example the rule presentedinfigure1appliestoanyrnnfunction e.g.
rnn lstm gru andbilstm .thisresultsin10pairsoftensorflowequivalent graphs each is tested with sets of input configuration .
we follow previous work to generate valid input based on constraints automatically extracted from the api documentation.
bug detection we compare the output from a pair of concrete equivalent graphs to detect inconsistency bugs.
.
contributions in this paper we make the following contribution we design new equivalence rules to create equivalent graphs to test dl libraries.
these rules cover six categories of dl graph equivalence i.e.
optimization apiredundancy datastructure equivalence data format equivalence inverse equivalence and model evaluation equivalence.
we propose a novel idea of using equivalent graphs to detect bugsandimplementthisideaasanewtestingtechnique eagle thatgeneratesequivalentgraphsanddetectsbugsindllibraries.
we evaluate eagle on five of the latest versions of the most popular dl libraries tensorflow and pytorch .
using the 16rules eagle generates pairs of equivalent graphs and detects25bugs 18intensorflowand7inpytorch including previously unknown bugs.
availability data is available in our github repository1.
the rest of the paper is organized as follows.
section presents thedefinitionofkeyconceptssuchasgraphs inputs andconfigurations.
section describes the equivalence rules and eagle simplementation.
section describes our experimental setup.
in section5 weevaluateeagleontwopopulardllibraries describe some bugs that eagle detects compare eagle to state of the art dl testingtechniques and present itsexecution time.sections 6and respectively describe threats to validity and related work.
finally section concludes the paper.
definition and terminology agraphinthispaperrepresentsacomputationalgraphinwhich the nodes are operations performed on variables.
a set of input configuration is required to compute a graph and generate an output.
the input i1 in figure is the object callconfiguration all the other arguments necessary to perform the computation e.g.
weights numberofneurons etc.
.forsimplicity we only list the input iin the equivalence rules but the configuration of the two equivalent graphs is assumed to be identical except when explicitlydescribedin therule.
for example for the batch major time major rule presented in figure the two graphshaveidenticalconfigurations weightsandotherarguments exceptforthe time major argument whichis falseingraph1 andtruein graph .
since it is the only difference it is the only configuration explicitly described in table for this rule.
approach findingbugs especiallynon crashbugs indllibrariesischallengingbecauseitisdifficulttoknowtheexpectedoutput giventhat dl computations are complex.
we cannot use the ground truthas the expected output of dl software since dl models are not accurate .
when a model makes a mistake on input i the expectedoutput oofthesoftwareisdifferentfromthegroundtruth outputo0.eagleusesdifferentialtestingtoaddressthischallenge to find non crash bugs.
figure2presentstheoverviewofourwork whichconsistsof threemainsteps.first wedefinegeneralizablerulesforcreating equivalent graphs step in figure .
second for each rule we obtain applicable apis bycheckingdl api sdocumentation and build pairs of concrete equivalent graphs step .
finally we execute thetwo equivalent graphsby feeding themfuzzed input and compare theiroutput for example o1 ando1 primein figure to detect inconsistency bugs step .
the rest of the approach section describes the equivalence rules section3.
theequivalentgraphconstruction section3.
and the bug detection process section .
.
.
equivalence rules the first step is to create rules to build equivalent graphs.
recall thatequivalentgraphs arecomputationalgraphsthatachievethe samefunctionality whichshouldproduceidenticaloutputgiven thesameinput.inpractice iftheoutputdifferenceisbelowathresholdt we also consider the outputs identical.
such a threshold is neededbecausedlcomputationsaremostlyperformedonfloating numbers and equivalent floating point computations often result in slightly different outputs.
tocreateequivalencerulesthataremorelikelytofindrealbugs in dl libraries we examine the following two sources api documentation the api documentation of neural network functions provides us with information about their implementation.
sometimes the description of several apis providesconnections among these apis that help us create equivalencerules.
for example by reading the description of the function tf.keras.layers.depthwiseconv2d wefoundthatthisfunction could be implemented by multiple invocations of the function tf.keras.layers.conv2d each of which is performed over a singlechanneloftheinputto tf.keras.layers.depthwiseconv2d .
this implementation using tf.keras.layers.conv2d is different fromtheimplementationof tf.keras.layers.depthwiseconv2d in tensorflow.
although tf.keras.layers.depthwiseconv2d authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jiannan wang thibaud lutellier shangshu qian hung viet pham and lin tan xj ghwhfwlrq txlydohqw judsk frqvwuxfwlrq txlydohqfh uxoh ghilqlwlrq txlydohqfh uxohv vsduvh rswlpl hg grfxphqwdwlrq lvvxhv derxw qrq fudvk exjv5hohydqw h wudfwlrq 5hohydqw v rqfuhwh judsk jhqhudwlrqwi nhudv od huv hqvh qsxw jhqhudwlrq txlydohqw judsk h hfxwlrq2xwsxw frpsdulvrq2 hqvh hqvh wrbvsduvh txlydohqw judskv2 hqvh hqvh wrbvsduvh dwlrq lvvxhv derxw qrq fudvk exjv xj ghwhfwlrq txlydohqw judsk frqvwuxfwlrq txlydohqfh uxoh ghilqlwlrq txlydohqfh uxohv vsduvh rswlpl hg hqvh wrb txlydohq hqvh hqvh wrbvsduvh figure overview of eagle canbeimplementedusing tf.keras.layers.conv2d tensorflow choosesamoreefficientimplementationandcomputesthedepthwiseconvolutiondirectlywithoutsplittingitbythechannels.therefore we have two different but equivalent implementations of tf.keras.layers.depthwiseconv2d andwecanusethemtobuild equivalent graphs to detect bugs.
non crash bugs in dl libraries similar to prior work we study non crash bugs in dl libraries to summarize common bugpatternsandequivalencerulesthatcanpotentiallydetectthose bugs.wefirstmanuallyinvestigategithubissuesrelatedtononcrash bugs in tensorflow and pytorch s repositories.
then we reproducethosebugsandbuildapairofequivalentgraphstodetect each bug for the particular buggy api described in the issue.
we thenconvertthegraphstoageneralequivalencerulebyabstracting the inputs api functions and configurations e.g.
metrics and optimizations used .
designingequivalencerules wefirstcreateaconcreteequivalence rule for a specific api for which we read the documentation or that contains a known bug.
then we generalize the rule by abstractingtheinputs apifunctions andconfigurations e.g.
metrics and optimization used .
for example the concrete rule used for theapifunction tf.keras.layers.bidirectional infigure1is bidirectional i1t ... return sequences ... batch major t bidirectional i1 ... return sequences ... time major wherei1 is an input tensor and i1tis the transpose of i1.
this rule requiresthe time major argumenttobe false i.e.
using batchmajor forthegraphinfigure1aand truefortheequivalentgraph in figure 1b.
we generalize the api function bidirectional to all relevant api functions f generalize input i1 to any input i and generalize the configuration return sequences so that the parameter return sequences can be trueorfalse while only truewasusedinthisconcreterule.thegeneralizedequivalence rule is f it batch major t f i time major .
to make the generalized rules look cleaner we generalize but omit in the rule notation all other parameters of the api functions includingreturn sequences whichispartoftheconfigurationsasexplained in section .
based on our study of dl bugs and api documentation we define equivalence rules that can transform a graph into an equivalent graph.
we group these rulesinto categories whereiis a general input often a tensor and fdenotes an api function.
function implement f a fb is a function that uses function fbto implement the functionality of function fa.f2d andf3dare api functions that compute 2d and 3d operations e.g.
tf.keras.layers.conv2d and tf.keras.layers.conv3d respectively.
function densetransfers input ito a dense tensor while function sparsetransfers input ito a sparse tensor.
functions normalize and denormalize transfer image input ifrom float representation in range to integer representation in range andtrasferthefunction f soutputbackfrominteger to float.
function castis a type casting function that converts ito the expected data type while typexandtypeyare two different data types.
functions decodeandencodeare a pair of functions thatdecodeanimagefiletoatensororencodeatensortoanimage file e.g.
tf.io.decode png and tf.io.encode png .
function paddenotesapaddingfunction while unpadisafunctionthatreverses the padding procedure e.g.
tf.image.extract glimpse .
finally mindicatesapretraineddlmodel while evalisthemodel evaluation procedure.
below we first go through a detailed example of one rule then describe the other rules.
.
.
a detailed example optimization equivalence rule.
tensorflow and pytorch include several graph compilation optimizationsthat cause a function to be compiled as a callable graph.
compiling the program into callable graphs enables optimizations such as operationpruningorconstantfolding whichcansignificantlyreduce execution time.
optimization is known to cause many bugs in other domains e.g.
compiler optimization .
dl optimization e.g.
autographtransformation isalsocomplexanderror prone.
forexample wefoundtwonon crashbugsrelatedtotensorflow optimization by looking at github issues github issue .
function tf.math.floordiv behavesdifferentlywithandwithout optimization and so does tf.linalg.eigh.
basedonthisbugreport webuildtwoequivalentgraphs figures3 toreproducethebug.thenwegeneralizetheequivalence rulebyabstractingtheapi tf.math.floordiv theoptimization tf.function anditsinputtobuildrule1intable1.rule1states authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
eagle creating equivalent graphs to test deep learning libraries icse may pittsburgh pa usa udsk udsk wi pdwk iorrugly wi ixqfwlrq wi pdwk iorrugly figure3 exampleofpairofconcreteequivalentgraphsgenerated from tensorflow issue .
table list of rules.
fis an api function iis input and m is a pretrained model.
idequivalence rule optimization 1f i optimized f i api redundancy 2f i padding same f pad i same 3implement f 2d f3d i f2d i 4implement depthwise conv2d i depthwise i 5implement separable depthwise i separable i 6implement dilated conv2d i dilated i 7implement f document f i f i data structure equivalence 8f dense i f sparse i data format equivalence 9f i denormalize f normalize i f it batch major t f i time major 11f i f dataset i 12f cast i typex f cast i typey inverse equivalence 13decode encode i i 14unpad pad i i model evaluation equivalence 15eval m i batch size s1 eval m i batch size s2 16eval m i save m eval load m i thatthecomputationofanarbitraryfunction foninputiisequivalenttotheoptimizedversionofthiscomputationonthesameinput.
using this rule eagle detects ten new bugs including seven of them already confirmed or fixed by the developers.
section .
.
.
.
description of all other rules.
we describe all other equivalence rules that we create category by category.
api redundancy rules to the second category of rules concernsapiredundancy i.e.
generatinganequivalentgraphusing a different api.
we identified several types of api redundancy.some apis have built in functionalities that can be executed externally.
for example many dl functions support built in padding as an argument.
samepadding is a popular padding setting that producesanoutputofidenticalshapetotheinputwhenthestrideisset to one.
therefore using the built in padding argument is equivalent to padding the input using samepadding and then feeding the padded input to the function without using its padding option rule .
many 2d functions e.g.
tf.keras.layers.conv2d can be implemented using the 3d version of the function by adding a dimen sionoflengthonetoboththeinputandkernel settingthestridetoone for this dimension and removing that dummy dimension from theoutput.theselayerscoverdifferentapifunctionsbutshould behave identically rule .
rules4to6 areaboutthereimplementationofadvancedconvolutions.
there are many variants of advanced convolutions e.g.
di lated depthwise orseparable .dllibrariesprovidebuilt inapisfortheseadvancedconvolutions buttheycanbereimplementedusing other convolutions.
for example tensorflow s depthwiseconv2d function can be reimplemented using only conv2d rule b y splitting the input and filters into xslices xbeing the number of channelsoftheinput andcomputingtheconvolutionforeachslice of input and filter.
finally rule 7leverages formulas found in api documentation to reimplement specific functions.
for example tensorflow s tf.keras.layers.batchnormalization sdocumentationstates that the layer function returns gamma batch mean batch sqrt var batch epsilon beta.
from this formula two equivalent graphs can be created.
the first one uses the api call to batchnormalization and the second one contains our reimplementationbasedonthedocumentation sformula.wegeneralize thisexampleto obtainthefollowingequivalence rule whenaformula isavailable inthe apidocumentation usingthe apishould beequivalenttousingtheformula.whiletheformulawilllikelybe implemented in some way in the api the function likely contains additional control flow or conversion to handle exceptions or edge cases that might introduce inconsistencies.
datastructureequivalence rules8 manyapistakedifferent typesofdatastructuresasinput andthefunctionalityofsuchan api is identical regardless of the types of data structures used.
for example dl libraries often use tensors multi dimensional data structures asinput.
thesetensors can berepresented asdense or sparse tensors.
sparse tensors are a tensor representation that is moreefficientwithmostly emptytensors.dllibrariesareexpected to handle both representations either by having an api supporting bothdenseandsparsetensorsorbyprovidinganequivalentapi specificallyforsparsetensors.therefore giventhesameinput any functiontakingdensetensorsshouldproduceidenticaloutputto thesamefunction oritssparseversion takingasparsetensoras input with the only difference being computation time.dataformatequivalence rules9to11 datacanbepresented to dl apis in different formats that can become equivalent with a few transformations.
forexample therearetwoprincipalwaystofeedimagestoadl network.inthefirstone eachpixelisrepresentedasaninteger e.g.
between0and255forthergbfileformat .inthesecondone each authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jiannan wang thibaud lutellier shangshu qian hung viet pham and lin tan pixelisrepresentedasafloating pointnumber e.g.
between0.0and .
.onecannormalizevaluesbetween0and255tovaluesbetween .
and1.
andvice versa.
manydifferent functions aresupposed to support both types of representation without any casting.
given thesameinputinthetworepresentations eithernormalizedornot the outputs one as is and one denormalized of these functionsshould be equivalent given a threshold related to floating pointimprecision .
thus we create rule 9to build equivalent graphs using these two types of image formats.
in addition to images text is another common type of input to dl functions.
textual input can be fed to rnn either in timemajor or batch major format.
thus we create the equivalence rule rule described in the introduction figures 1a and 1b .
while these two figures display two concrete equivalent graphs for a specifictensorflowfunction tf.keras.layers.bidirectional this rule applies to any api that supports time major and batchmajor inputs.
dllibrariesprovideaspecificclasscalled datasetinpytorch andtensorflowtosupportcomplexinputpipelinesformodeltraining and evaluation.
input can be applied to dl functions in two ways the input ican be passed to the dl function fdirectly or theinput canbetransformedto a datasetobjectbeforebeing fedtof.transformingtheinputtoa datasethasseveraladvantages includingmanybuilt inapisthatcanbeusedtointeractwiththe dataset efficiently.wegenerateanequivalencerule rule11 based on these two ways of applying an input to a dl function.
finally dl libraries accept different input data formats that are oftenequivalentforspecificdataranges.webuild rule 12based onthisobservation.wecasttheinputtotwodifferentdatatypes typexandtypey and then feed them to an api function.
the outputsareexpectedtobethesame iftheinputiswithintheintersectionof typexandtypey sranges unlessdataoverflowsoccur.
for example if a function accepts both int8andint16integers as input any int16inputthatfallswithinthe int8range shouldproduceanequivalentoutputtoits int8counterpart scomputation output.
one exception is when the int8computation overflows e.g.
an addition of two int8numbers may not overflow int16but overflow int8 in which case an exception would be thrown.
inverse equivalence rules to many dl apis have inverse functions.
we develop two rules based on two extremely common dl preprocessing steps that can be inversed encoding and padding.
many types of input e.g.
image sound and text have multiple encoding types e.g.
gif and png for images .
many of these encodingsarebuilt inindllibrariesandshouldthereforebetested thoroughly.
any input encoded then decoded with the correct lossless encoding and decoding algorithms should be equivalent to the original input rule .
paddingiswidelyusedtoenlargethesizeofinput.wecanunpad the padded input by extracting a window of the original size from thepadded input.theextracted inputshouldbe equivalenttothe initial input rule .modelevaluationequivalence rules15and16 ininference mode evaluating the same trained model on the same test datashouldresultinthesameoutput e.g.
thesamelabelforaninstance or the same accuracy independently of the batch sizes rule .
a model should behave equivalently in terms of accuracy loss function and weights before and after being saved and loaded independentofhowitwassavedandloaded rule16 .bugsinthe savingandloadingcodecancauseinconsistencies thusenabling eagle to detect such bugs.
.
equivalent graph construction the equivalence rules presented in section .
are general and applicable to many dl api functions.
the next step step in figure2 istoconcretizetheserulesintospecificgraphsbyreplacing abstract elements of the rules e.g.
fandi with concrete apis input and configurations.
for each rule we identify a list of relevant apis for the dl library under test by referencing its documentation.
eagle then concretizes the rules for each applicable api.
for example eagle concretizesrule1toagraphbyreplacing fwiththetensorflow apitf.math.xdivy and optimized with tf.function tensorflow s graph compilation optimization .
it is relatively straightforward to extract applicable apis in the target library by usingheuristics and regular expression matching and then manually verify them.
somerulesapplytomanyapis forexample rule1ofeagle generates equivalentgraphs for 960tensorflowand pytorch apis.
other rules such as rule are only applicable to certainapi functions for example pytorch s documentation lists three mainrnnfunctionsthatcanbetestedwithrule10 torch.nn.rnn torch.nn.lstm and torch.nn.gru .whiletestingonlythreeapis might not seem general these high level apis support multiple configurationsthatwilltestdifferentunderlyingapis.forexample under some configurations the torch.nn.gru function might also callthe dropoutorbidirectional functions.obtainingapplicable apis is a one time cost and it is fast using heuristics.
.
bug detection thefinalstep step3infigure2 istogenerateinput e.g.
toconcretizeiinrule1 andcomparetheoutputoftheconcretizedgraphs given the same input.
we use existing work d2c to generateinputautomatically.forexample eaglefurtherconcretizesthe iof rule for api tf.math.xdivy x y to .e .j .e .e 38j figure .
we then compare the output of each pairofconcreteequivalentgraphs giventhesameinput.tomit igate the impact of non determinism of dl computation we use thesamerandomseedforthetwoequivalentgraphs executions and report all inconsistent output above a threshold.
with the concrete function and input eagle detects a previously unknown bug in tensorflow .
and .
that developers confirmed figure in section .
.
the main contribution of eagle is equivalence rules which can be used together with any other test generation approach.
section .
shows that bugs that eagle detects cannot be detected bythechosentestgenerationtechnique i.e.
d2c withoutequivalentgraphs.sinceourgoalistodetecthard to detectnon crash bugs due to the oracle challenge by detecting inconsistent behaviors as opposed to for example crashes due to mishandling authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
eagle creating equivalent graphs to test deep learning libraries icse may pittsburgh pa usa of invalid input we need a technique that is capable of generating valid input for dl api functions.
instead of manually writing input constraints which is commonly used in testing we leverage d2c that analyzes relevant api documentation to extract input constraints and uses the constraintstoguidethegenerationofinput.forexample giventhe apidocumentsentencefor tf.math.xdivy x y atensor.must beoneofthefollowingtypes half float32 float64 complex64 orcomplex128 it randomly generates a tensor whose elements are of type half float32 float64 complex64 o rcomplex128 .
d2cextractsfourcategoriesofconstraints structuresuchaslist tuple and n dimensional array i.e.
tensor typesuch as int float boolean and string shapesuchastwo dimensional d array andvalid value such as parameter padding can only be one of zeros border and reflection .
d2cuses sequentialpatternmining tominefrequently occurringpatterns e.g.
mustbeoneofthefollowingtypes in api documents and transforms them into rules e.g.
must be one ofthefollowingtypes type1 type2 toextractinputconstraints automatically.
the precision and recall is .
and .
fortensorflowand95.
and93.
forpytorch.wethenmanually verify the extracted constraints and add any missing ones.
for test generation given an api function and its extracted constraints thetechniqueaimstogeneratevalidinputfollowing the extracted constraints.
specifically it chooses a typefrom the list oftypesin the constraints and creates a shapefollowing the constraints.
if the constraints do not specify a list of valid types the test generation selects one from typessupported by the library.
finally the structure constraints are checked.
for example if the generated value is dimensional and the constraints explicitly specifythe structure e.g.
tupleorlist theinputgeneratorconverts the generated value accordingly.
wefinallyexecuteallinputsandreportinconsistenciesbetween equivalent graphs.
experimental setup in total we investigate issues in tensorflow and pytorch.
for tensorflow we focus on issues in tensorflow .x only.
forboth pytorch and tensorflow we use the github search enginefor closed issues labeled as bug with the keywords fix.
then wemanuallycheckalltheissuestofilteroutcrash relatedissues.
out of these issues are relevant non crash bugs from which we create and generalize rules.
many github issues are not relevant because they are not bugs e.g.
user mistakes or feature requests and many issues describe crash bugs.
in total we extract equivalence rules.
for rules we use d2c to generate inputs.
we generate up to inputs per api.
we use d2c to generate inputs for tensorflow apis and pytorch apis.
for rule and rule we save tensorflow keras pretrained models and pytorch pretrainedmodelsfortesting.fortheinput weextract1 000images fromtheimagenetdatasetandpreprocessthemaccordingtothe models.
after we generate inputs we define a list of applicable apis for each rule by referencing the api documents.
eagle uses theserules to generate equivalent graphs for each applicable api and uses the inputs generated to compute the results.
weconsulttheinconsistencythresholdformulathattensorflow andpytorchuseintheirtestsuitetodeterminewhetherthetwo outputsfromtwoequivalentgraphsareequivalent.forexample fortheequivalentgraphs g1andg2withrespectiveoutputs o1and o1 prime giveninput i1 theirresultsareequivalentif abs o1 o1 prime atol rtol abs o1 prime withatol 2andrtol .
weevaluateeagleontensorflow2.
.
and2.3andpytorch .6and1.9sincetheywerethelatestversionsavailablewhenwe startedthisproject.weonlyreportabugtodevelopersifwecan reproducethebugonthelatestversionoftensorflowandpytorch tensorflow .
and pytorch .
at the time of writing.
we obtain the total number of bugs by considering all inconsistencies for each rule and api pair as one bug.
for example in rule if five different models display inconsistencies to load with one api e.g.
load state dict we only count it as one unique bug.
evaluation and results this section presents the results of our five research questions rqs .rq1 section5.
presentsthenumberofbugseagledetects.
rq2 section5.
describessomeofthebugsforeachcategory.rq3 section .
compares eagle to other dl testing approaches and rq4 section5.
exploreshowdevelopersuseequivalentgraphs.
finally rq5 section .
studies eagle s execution time.
.
rq1 how many bugs does eagle detect?
weimplement16rulestotestthetwomostpopulardllibraries tensorflowandpytorch resultingin6 861pairsofconcreteequivalent graphs.
we use previous work to generate up to sets of input configurations per pair of equivalent graphs.
aset of input configuration consists of input to an api and itsconfiguration weights etc.
.
for example when testing the api tf.keras.layers.dense the input is a tensor and the configurations include weights kernel initializer and bias regularizer.for each set of input and configuration values we compare the corresponding equivalent graphs.
table2displaysthenumberofbugsfoundintensorflowand pytorch.overall eaglegenerates6 861pairsofequivalentgraphs and detects inconsistencies automatically.
multiple inconsistencies that are triggered by the same api function with different inputs arecountedasonebug.asaresult theseinconsistenciesmapto25bugs including13previouslyunknownbugs .
most ofthesepreviouslyunknownbugshavebeenconfirmed or fixed by tensorflow or pytorch developers.
eagle also detects crashes for apis among which we have only manually verified fivesinceourfocusisonnon crashbugs whichexistingtechniques have a hard time detecting.
table2alsoshowsthenumberofbugsfoundineachrulecategory.
for example optimization is the category for which eagle finds the most number of bugs with a total of ten bugs found.
all those ten bugs are previously unknown bugs seven of which have been confirmed or fixed by the developers.
section .
describes examples of bugs found by eagle.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jiannan wang thibaud lutellier shangshu qian hung viet pham and lin tan table bugs found by each rule category.
category tensorflow pytorch sum optimization api redundancy data structure equivalence data format equivalence inverse equivalence model evaluation equivalence total qs duud h m gw sh frpsoh h h m udsk udsk 7hqvru m 7hqvru m qfrqvlvwhqf uhyhdolqj lqsxw 2xwsxw 2xwsxw wi pdwk gly wi ixqfwlrq wi pdwk gly figure two equivalent graphs that detect a new inconsistency bug in tensorflow which has been confirmed by developers after we reported it.
summary eagle detects bugs in the most widely used dllibrariestensorflowandpytorch including13previously unknownbugs nine ofwhichhavealreadybeenconfirmed or fixed after we report them.
.
rq2 what bugs are detected by eagle?
we describe non crash bug examples in each category of rules.
optimization eagledetectstenbugsthatarerevealedbyinconsistenciesbetweenastandardgraphandanoptimizedgraph.allof these bugs are previously unknown bugs for which optimized tensorflow apifunctions generate incorrectoutputs.
figure 4shows an example of a new bug in the tf.math.xdivy api detected by eagle that tensorflow developers confirmed after we reported it.
theannotation tf.function ongraph2tellstensorflowthatthe function below should be optimized.
according to tensorflow developers thisbugiscausedbyanoverflowfor complex64 divisions in the optimization.
data structure equivalence with the rules of data structure equivalence eagle detects three bugs in tensorflow and four bugs in pytorch.
figure displays two equivalent graphs that eagle generated which revealed a bug in pytorch.
api functions torch.addmm andtorch.sspaddmm performthesamecomputation fordenseandsparsetensors respectively.giventhreeinputtensors t1 t2 andt3 these functions multiply t2 andt3 then add t1 to the result.
the bug was deep in the c backend code of torch.sspaddmm inalow levelfunction indices.data ptr that wrufk whqvru wrufk whqvru wrufk whqvru udsk wrufk whqvru wrufk whqvru qfrqvlvwhqf uhyhdolqj lqsxw 2xwsxw 2xwsxw wrufk dggpp7 wrbvsduvh wrufk vvsdggpp wrbghqvh7 wrbvsduvh wrbvsduvh udsk figure pair of equivalent graphs that detects an inconsistency bug in pytorch.
assumesrow contiguousstorageoftensors while torch.sspaddmm used another type of storage.
the apis under test torch.addmm andtorch.sspaddmm donothaveadirectcounterpartintensorflow soitwouldbeverydifficulttofindthisbugusingcross library differential testing techniques such as cradle or audee.
data format equivalence eagle detects four bugs in this category includingthebuginfigure1.theotherthreebugsareinconsistencybugsinthreedifferentpytorchapis.in torch.fmod and torch.remainder thereisalargeinconsistencybetweenequivalentint64andfloat64 input while the cosine similarity api hasinconsistenciesbetween int8andint16.thesearebugsinthe c low level tensor library aten used by pytorch.inverse equivalence eagle detects two bugs in this category includingone newbug relatedto the tf.io.decode gif api.
gif encodingissupposedtobelossless butwefoundthatintensorflow forspecificinputs thisencodingisnotlossless i.e.
encoding and then decoding an input instance can result in significantly differentoutputs.theconsequenceofthisbugisseverebecauseimage preprocessingisanessentialpartofmanydlsystems andanybugin thatpreprocessingmay modifythe inputto thedl modelsin anunexpectedwaythatmayleadtoincorrectoutput whichwouldbe hard to debug.
modelevaluationequivalence eagledetectstwobugsinthis category.
those two bugs are inconsistency bugs in model configurations or metrics.
for example rule enables eagle to detect a bugintensorflowapi tf.keras.sequential.from config .tensorflowapis get config andfrom config extractamodel sconfigurationandbuildamodelobjectfromsuchaconfigurationrespectively.
combined with get weights andset weights they canachievethefunctionalityofsavingandloadingamodel.saving themodelusing get config andget weights andloadingitusing from config andset weights cause the model s configuration to be incorrect which leads to the detected inconsistencies.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
eagle creating equivalent graphs to test deep learning libraries icse may pittsburgh pa usa apiredundancy eaglefindsnobugsusingtheapiredundancy rules.afterinvestigatingbothtensorflowandpytorchlibraries we findapossiblereasonisthatdevelopersalreadyimplementedsome rulesfromthiscategoryintheirtestsuiteafterfindingabugina previousversion.forexample aconcretepairofequivalentgraphs thateaglegeneratesfor rule 7withthe batchnormalization apiisincludedinthetensorflowtestsuite.similarly wealsofound reimplementations of depthwise convolutions using conv2din the tensorflow test suite rule .
this demonstrates that developers arealreadyusingsomeequivalencerulestotesttheirlibrariesas an afterthought of relevant bugs.
a comprehensive set of rules and atechniquethatusestherulestogenerateequivalentgraphsand detects bugs would be beneficial for them to improve their testing system further.
false positives out of all inconsistent apis detected by eagle we found one false positive the other are true bugs .
this false positive is revealed by rule in pytorch.
when testing rule in pytorch we evaluate the pretrained model inceptionv3 before saving its internal states and after reloading them using load state dict .
inceptionv3 s input needs to be normalized and the normalization process is included along with the model architecture.whenthepretrainedweightsareused pytorchnot onlyloadstheweightsbutalsoconfiguresthemodelarchitecture byaddingtheinputnormalizationprocessaccordingly.however the input normalization is not configured correctly after model saving and loading which leads to the inconsistencies.generalizabilityoftherules all rules apply to both tensorflow and pytorch and rule finds bugs in both libraries.
while a single rulecanfind bugsin bothtensorflowandpytorch it does not mean that these bugs can be found by cross library differential testing techniques because when the rules are concretized toconcretegraphs theconcreteapisoftenonlyexistinonelibrary.
for example rule finds bugs in both tensorflow and pytorch buttheapiinwhichsomeofthebugsoccur torch.sspaddm only exists in pytorch.
intotal wegenerate6 861pairsofconcreteequivalentgraphs 429pairsofgraphsperruleonaverage thatareeachtestedon400 sets of input configuration .
the largest number of apis covered byauniqueruleis963and464fortensorflowandpytorch respectively.overall the25bugsdetectedbyeagleoccurinverydiverse apis from dl layers tf.keras.layers.bidirectional lowlevel computation libraries torch.smm utility apis tf.keras.sequential.from config optimization tf.function or data preprocessing tf.image.decode gif .
summary the bugs detected by eagle in tensorflow and pytorch are in a very diverse set of dl apis including preprocessing dl layers low level apis and utility functions demonstrating the diversity and generality of our rules.
.
rq3 does eagle detect bugs not detected by other dl library testing techniques?
we compare eagle with two types of techniques that test dl libraries to better understand eagle s contribution.
first we compare eagle with a state of the art fuzzing technique d2c .second wecomparewithtwostate of the artdifferentialtesting techniques for dl libraries cradle and audee .
comparison with d2c we ran d2c on the same pytorch andtensorflowversionsonwhichweevaluatedeagle.although eagle uses d2c s input generation only five of the bugs detected by eagle are also detected by d2c.
d2c cannot detect any of the other bugs because it focuses on crash bugs while the majority out of of the bugs found by eagle are non crash bugs.
comparisonwithcradle andaudee cradleand audee are dl testing approaches that rely on keras high level apito performdifferentialtesting acrosslibraries.audee alsohas non differential testing checkers but since they do not detect inconsistencies we focuson thedifferential testingaspect ofaudee for this rq .
differential testing techniques such as cradle and audee cannotdetectbugsthateagledetectsforthefollowingreasons.keras isahigh levellibrarythatallowsuserstobuilddlmodelsinabackend library independent manner i.e.
one can seamlessly switch thebackenddllibrary.kerasmodelscanthenbeexecutedwithout reimplementation using different dl backends tensorflow theano andcntk .todothat allbackendsmusteitherimplement thesamefunctionalities orkerasmustimplementmissingfeatures of backends.
with theexplosionof dl in thelast few years dllibraries are growing fast and many new types of dl functions are proposed thatarenotimplementedinalllibraries makingitextremelyhardto maintain cross backend execution in keras since functions unique toadllibrarymustbereimplementedforalllibraries .inaddition new dl libraries have grown to be very popular e.g.
pytorch and huggingface stransformer thatarenotsupportedbykeras while libraries theano and cntk supported by keras are no longer maintained.asaresult maintainingcross backendsupportinkeras became unmanageable and keras dropped this feature in making it challenging to run differential testing techniques such as cradle or audee.
reimplementing such a high level library to allowdifferentialtestingwouldbeextremelyexpensiveandtedious.
eagleaddressesthischallengebyrequiringonlyonedllibrary to detect bugs.
it is possible to perform differential testing only on functionalities thatare implementedidentically inboth libraries e.g.
dense layer and conv2d .
however so would miss many bugs i.e.
15ofthe25bugs thateagledetects.forexample thebug displayed in figure occurs in a pytorch api that does not have a direct counterpart in tensorflow.
in addition even if we have a high level library that supports cross backendexecution cradleandaudeemightstillnotfind the remaining ten bugs that eagle detects because they focus on complete system testing i.e.
they take a full dl model as input andmeasureinconsistenciesinaccuracy .incontrast eaglefocuses on single low level api testing unit testing to find bugsburied deep in a dl library.
for example while all the inconsis tencies reported by audee concern incorrectly implemented dllayers thresholdedrelu depthwiseconv2d separableconv2d and padding implementation eagle finds bugs in very low level functionalitiessuch as aten the low level tensor library used by pytorch section5.
.cradleandaudeemightmissthesebugs authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jiannan wang thibaud lutellier shangshu qian hung viet pham and lin tan because they only produce inconsistencies at a system level for specific models and input.
theequivalencerulesareorthogonalcontributions whichcan be combined with cradle or audee to help them generate more dlmodelstotestmoredllibrarycode.forexample cradleand audee may use our rule to test optimization code cross libraries if a high level library such as keras is revamped.
summary themajority ofthe25bugsdetectedbyeagle arenon crashbugs whoserelevantapishavelittlecross library redundancy.thus itwouldbedifficultforexistingtestingapproaches to detect these bugs.
.
rq4 do dl library developers use equivalent graphs?
inthisrq weinvestigateifourrulesarenewbystudyingifandhow developershavebeenusingequivalentgraphstotestdllibraries.
we manually examine tensorflow and pytorch s test suites and checkifanytestcasesimplement orpartiallyimplement ourrules.
most of the rules are not implemented or not fully implementedinpytorchtestcases 13rulesarenotimplementedat all whiletwo rules and are implemented onlyfor a few apis.
only rule is implemented for all the apis tested by eagle.
the majority out of rules are not implemented or not fully implemented in tensorflow test cases nine rules are not implementedatall fourrules and16 areimplementedfor only a few apis and only three rules and are implemented for all the apis tested by eagle for that rule.
such test cases were createdlikelyasanafterthoughtafterabugwasfound.forexample after findinga bug in torch.sspaddmm from githubissue developers implemented a test case to test torch.sspaddmm and its dense version torch.addmm in pytorch .
.
thefactthatdevelopersuseequivalentgraphstomakesurea bugisfixedshowsthatsuchgraphsareusefultotestdllibraries.
however equivalent graphs have not been implemented proactivelytocreatetestcases i.e.
tofindbugs .eagleoffersamore complete list of equivalence rules to generate equivalent graphs that developers have not manually implemented and can therefore improve the reliability of dl libraries.
summary most 13outof16 rulesarenotimplementedindl libraries test suites.
the few test cases that implement equivalentgraphswereonlyimplementedasanafterthoughtaftera bughasbeenreported.thisindicatesthateaglecomplements developers testcasesandcandetectbugsthatwouldbehard to find manually.
.
rq5 what is the run time of eagle?
table shows eagle s execution time.
on average it takes minutes to execute a pair of equivalent graphs with a set of input configuration in tensorflow and minutes in pytorch.
in total eagleexecutes6 861pairsofequivalentgraphs.itiseasyto executegraphsinparallel.forexample onourxeongold5120r cpus cores in total and gb of memory server we execute graphs at a time.
execution time of eagle tensorflow pytorch of pairs of concrete graphs of input config per graph time per pair minutes threats to validity eagledoesnotfindallbugs sincewefocusondetectinginconsistenciesbetweenequivalentgraphs eaglemightmissbugsthatdonotcauseinconsistentoutputs.forexample ifarulegeneratesapairofequivalentgraphsthatusetworedundantapisthatcontain thesamebug eaglewillnotdetecttheinconsistency.however eagleiseffectiveindetecting25bugsintensorflowandpytorch automatically.
manualruleconstruction therulestogenerateequivalentgraphs have been manually designed.
as a result they might not be fully representative of real bugs in dl systems.
to mitigate this issue welookatexistingbugreportsintwopopulardllibraries tensorflowandpytorch whendesigningourrules.ourresultsshowthat the rules designed for eagle find previously unknown bugs showing that they can be used to detect new real world bugs.generabilitytodifferentdllibraries ourapproachmightnot begeneralizabletootherdllibraries.tomitigatethisthreat we evaluate eagle on the two most popular dl libraries tensorflow and pytorch.
eagle finds bugs in both libraries.
in the future we could further extend eagle to test different libraries e.g.
deeplearning4j to show eagle s generalizability.
potential bugs in our implementation our implementations mightbebuggy.ifthatisthecasewewilleither incorrectlydetect inconsistencies or not detect the inconsistency.
we mitigate by manually looking at the inconsistencies we detect before consideringthemasbugs.noneoftheinconsistencieseaglefinds aretheresultofabuginourcode.inaddition developersconfirmednineofthe13newbugseagledetects.for ourapproachmight not detect some bugs because of issues in our implementation.however this can only hurt our results and therefore does notimpact the validity of our findings.
if bugs in our code cause us tomissinconsistencies ourtechniquemightperformevenbetter once we fix them.
nondeterminism not all inconsistencies are bugs because dl apis can be nondeterministic .
we address nondeterminism by fixing the random seed to make api testingreproducible.
we also use a threshold used by popular dl libraries to take into consideration floating point precision inconsistencies.
overall all but one inconsistenciesthat eagle detects are the result of true bugs.
related work dl library testing suffers from the oracle problem.
specifically dl api functionalities are very complex and it is often hard to knoworevenapproximatetheexpectedoutputmanually.previous work shows that such oracle approximations are often usedindllibrariesbutareerror prone resultinginflakytestsor requiring a manual update from the developers.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
eagle creating equivalent graphs to test deep learning libraries icse may pittsburgh pa usa fuzzing and differential testing can be used to mitigate the oracleproblem.fuzzing oftenonlydetectscrashes whiledifferential testinggenerallyrequirestwodifferentlibrariesthatimplementthe same functionality which is difficult to achieve and error prone.
ourworkisdifferentsinceweleveragewithinlibraryequivalences suchasapiredundancyoroptimizationtobuildequivalentgraphs todetectnon crash bugs.sincethegraphs eagleusesare equivalent they both have the same expected output addressing theoracle problem.
to the best of our knowledge we are the first to proposeequivalentgraphsandtousethemtofind25bugsindl libraries.
differentialtestingofdllibraries previouswork uses differential testing to find inconsistencies between dllibraries.suchinconsistenciesareoftentheresultofabugindl libraries.forexample cradle findsbugsinkerasbyrunning thesame modelwithdifferent dlbackends tensorflow theano and cntk .
these approaches require either a high level library that supportsseveraldlbackends e.g.
keras agoodmodelconverter e.g.
mmdnn or heavy engineering to reimplement the samedlcomputationindifferentdllibraries.unfortunately while kerasinitiallysupportedseveralbackendsandwasusedinprevious studies keras now only supports tensorflow.
mmdnn oronnx areframeworksthatallowtransferring models across dl libraries but mmdnn only supports a few popular layers e.g.
rnn layers are not supported and pytorch oneof the most popular dl libraries cannot execute onnx models.
therefore theonlysolutionforthoroughdifferentialtestingacross dl libraries is to reimplement the dl computation in different frameworks which is time consuming and error prone.
for example previous work only reimplemented two ml algorithms k nearestneighboursandnaivebayes whenusingdifferential testing on weka rapid miner and knime.
in contrast eagle uses equivalent graphs to find bugs in dl apis whichisnotlimitedbythird partylibraries converterorhighlevel api support .
for example eagle detects a bug in birnn layersoftensorflow whichwouldnothavebeenfoundbydifferential testing using mmdnn or keras since mmdnn does not support birnnlayersandkerasdoesnotsupportmultiplebackendsanymore.
fuzzingdllibraries fuzzingisanotherpopularapproachtotest dl networks.
classic fuzzing techniques can be used to find some crash bugs but more advanced fuzzing techniques targetting dl systems have been proposed .
we use theapproachdevelopedbyxieetal.
togeneratevalidinputsfor ourapproach however thesefuzzingapproachesstillsufferfrom theoracleproblemandcanonlyfindcrashbugs seesection5.
.
forexample previouswork couldonlyfindfiveofthe25bugs detected by eagle hence our approach complements existing fuzzing techniques.
some of probfuzz s checkers use differential testing and can detect non crash bugs in probabilistic systems.
they use across library differential testing or several implementations of the sameapi in different languages e.g.
py stan and r stan .
similar to other differential testing techniques probfuzz requires multiple libraries implementing the same functionality and has some scope limitations e.g.
probfuzz does not support loops that make it difficult to apply to dl libraries.
eagle tests dl apis generally and aims at finding general bugs that probfuzz does not cover.
other work testing dl libraries static analysis has been used to detect specific types of bugs e.g.
shape related bugs in dl systems .eaglefindsverydiversebugsindlsystems section5.
that are hard to find without equivalent graphs.
metamorphic testing has also been used to test and validate ml classifiers .
these approaches have only found injected bugs in ml systems andpreviousworkshowsthatinjectedbugsoftenonlyhaveaweak correlation with real bugs .equivalent graph generation taso automatically generatesgraphsubstitutionstooptimizeagivendeepneuralnetwork computation graph.
it generates equivalent graph substitutions basedonagivenarchitectureandfindstheonewiththeleastin ference time among all the substitutions.
while taso generates equivalentgraphs itdoesnotusethemtofindbugs instead ituses equivalent graphs to optimize dl computations.
most of the taso equivalencerulesaremathematicalequivalencerulessuchasfor anytensors a b andcofconcreteshape a b c a b c where denotesmatrixmultiplication.weimplementedeightof the taso rules and none detected any bugs.
we focus on building rules that are inspired by real bugs and api documentation.
all oftherulesthatwedesignforeaglearenew differentfromthe ones in taso.
differentialtestingforcompilers differential testing has been usedfortestingcompilers .insteadofequivalentgraphs theseworkgenerate equivalentprogramsmoduloinput emi .the keyinemiistocreateacollectionofcorrectprogramsthathavethesameoutputgiventhesameinput butmighthavedifferentoutputs forother inputs.ourwork isdifferentsince programcompilation is a different problem than dl graph execution which presents its own challenges.
conclusion we propose and evaluate eagle a new differential testing approachthatusesequivalentgraphstotestasingledllibrary.we design16newequivalencerulesthatcangeneratepairsofequivalent graphs.
we evaluate eagle on the two most popular dl libraries tensorflowandpytorch andfound25bugs 13ofthem are previously unknown bugs and nine have already been confirmedorfixedbydevelopers.inthefuture theruleswedescribe couldbecombinedtodetectbugsinmorecomplexapiinteractions within dl libraries.
acknowledgement theauthorsthanktheanonymousreviewersfortheirinvaluable feedback.
the research is partially supported by nsf a j.p.morganaifacultyresearchaward andafacebookresearch award.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jiannan wang thibaud lutellier shangshu qian hung viet pham and lin tan