univ ersity of nebr aska lincoln univ ersity of nebr aska lincoln digitalcommons univ ersity of nebr aska lincoln digitalcommons univ ersity of nebr aska lincoln cse conf erence and w orkshop p apers computer science and engineering depar tment of summer parasol efficient p arallel synthesis of lar ge model spaces parasol efficient p arallel synthesis of lar ge model spaces clay ste vens univ ersity of nebr aska lincoln clay.stevens husk ers.unl.edu hamid bagheri univ ersity of nebr aska lincoln bagheri unl.edu follow this and additional works at https digitalcommons.unl.edu cseconfwork part of the computer engineering commons electrical and computer engineering commons and the other computer sciences commons stevens cla y and bagheri hamid p arasol efficient p arallel synthesis of lar ge model spaces .
cse conf erence and w orkshop p apers .
.
https digitalcommons.unl.edu cseconfwork this ar ticle is br ought t o you for fr ee and open access b y the computer science and engineering depar tment of at digitalcommons univ ersity of nebr aska lincoln.
it has been accepted for inclusion in cse conf erence and workshop p apers b y an authoriz ed administr ator of digitalcommons univ ersity of nebr aska lincoln.
parasol efficient parallel synthesis of large model spaces clay stevens university of nebraska lincoln school of computing lincoln nebraska usa clay.stevens huskers.unl.eduhamid bagheri university of nebraska lincoln school of computing lincoln nebraska usa bagheri unl.edu abstract formal analysis is an invaluable tool for software engineers yet state of the art formal analysis techniques suffer from well known limitations in terms of scalability.
in particular some software design domains such as tradeoff analysis and security analysis require systematic exploration of potentially huge model spaces which further exacerbates the problem.
despite this present and urgent challenge few techniques exist to support the systematic exploration of large model spaces.
this paper introduces parasol an approach and accompanying tool suite to improve the scalability of large scale formal model space exploration.
parasol presents a novel parallel model space synthesis approach backed with unsupervised learning to automatically derive domain knowledge guiding a balanced partitioning of the model space.
this allows parasol to synthesize the models in each partition in parallel significantly reducing synthesis time and making large scale systematic model space exploration for real world systems more tractable.
our empirical results corroborate that parasol substantially reduces by on average the time required for model space synthesis compared to state of the art model space synthesis techniques relying on both incremental and parallel constraint solving technologies as well as competing non learning based partitioning methods.
ccs concepts software and its engineering formal software verification security and privacy logic and verification .
keywords formal analysis bounded verification tradespace analysis parallel acm reference format clay stevens and hamid bagheri.
.
parasol efficient parallel synthesis of large model spaces.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa 13pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore copyright held by the owner author s .
publication rights licensed to acm acm isbn .
.
.
.
introduction formal modeling of software systems has long been a hallmark of rigorous software engineering.
the ability to systematically and formally analyze the properties and behavior of a system can greatly benefit the system s quality security and performance.
formal analysis techniques have been successfully used in a wide variety of applications ranging from more theoretical uses like theorem proving and bounded verification to more practical applications such as configuration selection security analysis and self adaptive systems .
recent advances in the field have also lead to more widespread industry adoption .
however these techniques face well known challenges with scalability when analyzing large scale systems.
as the number of variables in the formal specification of the system grows the number of possible models of the specification grows exponentially the so called curse of dimensionality .
thus formal analysis techniques must search a vast model space to find models that satisfy all constraints in the specification.
in many application domains the problem is further exacerbated by the need to not only find a single satisfying model but to instead explore the entire model space to find all satisfying models.
in the area of tradeoff analysis for example system designers must balance the needs of multiple stakeholders and conflicting objectives to select the best design for a system this necessitates a systematic analysis of the tradeoffs among allpossible designs.
for large scale systems manual exploration of design variants will likely exclude possible design alternatives that would be otherwise optimal candidates leading to a premature fixation on potentially non optimal designs .
the development of efficient formal techniques to model and explore these design tradeoff spaces is therefore an active area of research .
similarly in security analysis analysts must explore large model spaces when identifying and addressing possible security threats to their systems.
the growing popularity of consumer iot systems increases the need for scalable systems to model and identify cyberphysical threats which again necessitates a systematic exploration of a large and ever growing model space of possible security risk models .
in both of these areas systematic model space exploration has been successfully applied within constrained sub domains such as embedded systems or computer hardware design .
however using such techniques faces steep challenges when applied to software systems where the models spaces are often colossal.
in fact the major challenge limiting the application of systematic model space exploration to the software engineering domain is the problem of exhaustive model space synthesis.
while recent researchers have presented systematic approaches which guaranteeesec fse november singapore singapore clay stevens and hamid bagheri acomplete enumeration of the model space for a software system they do not address the scalability of model space synthesis.
exploring the model space for even modestly sized software systems can quickly become intractable for the existing model space synthesis techniques limiting the utility of existing tools for software engineers in practice.
to address the problem of scalable exploration of large model spaces we present a novel approach and accompanying tool suite dubbed parasol for parallel synthesis oflarge model spaces.
parasolleverages unsupervised learning to effectively support systematic model space synthesis in parallel by dividing the model space into smaller non overlapping partitions which can then be synthesized concurrently.
parasol improves upon state of the art model space synthesis techniques by addressing two of the factors currently limiting their scalability in practice.
first in order to ensure synthesis of the entire model space the model space synthesis problem must be incremented after synthesizing each model to exclude previously synthesized models and prevent duplicates.
this self referencing reliance on earlier solutions to avoid duplication of effort forces the existing techniques to operate sequentially.
second using existing approaches additional constraints must be added to the model space synthesis problem to exclude each newly synthesized model.
as more constraints are added to the problem the time required to synthesize each new model grows ultimately requiring greatly increased time to synthesize each of the last models.
parasol overcomes both limitations enabling efficient parallelization of the model space synthesis problem.
parasol first generates a bounded sample of the model space through a rigorous analysis of the system specification and then clusters the models for that sample via unsupervised learning.
the invariants for those clusters are then automatically derived and captured as formal partition definitions such that synthesis of the target model space can be performed in parallel.
by partitioning the problem according to the clusters discovered in the sample parasol allows each parallel worker to synthesize a portion of the model space entirely independently of the other workers improving the efficiency of the process while still avoiding synthesis of duplicate models.
also parasol s parallel synthesis mitigates the increased processing time due to large numbers of constraints by dividing them among multiple smaller problems reducing the impact of each additional constraint.
the results of our experimental evaluation over a diverse set of subject systems corroborate that parasol greatly reduces the total time required for systematic model space synthesis compared to state of the art approaches while introducing very little overhead.
parasol provides an average speedup of over state of the art model space synthesis approaches including the sampling overhead which accounts for less than of the total synthesis time.
to summarize we make the following contributions efficient learning driven parallel model space synthesis we introduce a novel parallel model space synthesis approach backed with unsupervised learning to automatically derive domain knowledge guiding a balanced partitioning of the model space and thereby enabling efficient synthesis.
parasol implementation we realize the presented approach in a tool called parasol which we make available to the research and education community .
experiments we present empirical evidence of the efficiency gains when synthesizing model spaces for real world specifications adapted from prior work.
the following section presents necessary background to describe our technique and running example.
section 3details the approach and section 4describes our empirical evaluation.
we discuss the results and validity of our experiments in section concluding with a review of related research and some remarks on future directions.
background and motivation to further motivate the research and illustrate our approach we provide a running example of developing an efficient database design having to do with a systematic model space synthesis of the possible system specific database design alternatives.
consider object relational database mapping orm tools now provided in many popular software libraries e.g.
hibernate and frameworks e.g.
django .
they map object oriented data models to relational database schemas for managing application data.
these mappings employed by an orm design tool significantly impact data storage and retrieval performance for the enclosing system.
figure 1shows three possible mappings for a partial object model of an e commerce system adapted from lau and czarnecki that allows customer s to place order s within the system with an additional subclass defined for member customers who receive differential treatment.
the full e commerce system incorporates a large tradespace with thousands of possible design alternatives as shown in the scatter plot in figure where each grey circle on the scatter plot represents a unique valid database design alternative.
larger data models will have an even larger tradespace.
as the number of associations or inheritance relations in the domain model grows the number of possible variants will grow exponentially each relationship would multiply the total by the number of possible strategies that could be assigned to that relationship.
picking the best database design and object relational mapping often requires analyzing tradeoffs among candidates e.g.
query vs. update speed necessitating systematic exploration of the entire model space otherwise the designer may only consider suboptimal designs.
however the current state of the practice for orm design tools produces database designs based on a single point strategy considering no limited non functional properties and ignoring the performance ramifications for the system .
the star highlighted in figure 1denotes the point design solution produced by a state of the practice orm design tool.
it is clear from the diagram that the database design generated by state of the practice design tools is not among the pareto optimal designs highlighted by triangles in figure .
the design produced by the state of practice widely used every day by thousands of developers is far away from pareto optimal solutions because such design tools fail to consider the entire model space focusing on a single solution.
the challenge is that generating large numbers of complex variants is expensive.
thus in order to enable the selection of pareto optimal designparasol efficient parallel synthesis of large model spaces esec fse november singapore singapore figure example model space with quality attributes i.e.
tradespace for database designs for an e commerce system comparing insert and select time and required storage space.
a c present partial object relational mappings for three design alternatives indicated in the scatter plot by the arrows gray circles represent individual alternatives .
designs with optimal tradeoffs pareto optimal are indicated by triangles.
state of the practice sotp design generated by a cots orm system indicated with a red dark star.
note that the sotp design is far from optimal and only a small fraction of designs present optimal tradeoffs.
systematic synthesis and evalution of the entire model space is required to find the optimal tradeoffs.
solutions system designers require tools that can systematically andscalably generate the entire model space.
the above example which we use as a running example manifests one of the most prominent and widely used software system engineering problems that requires model space synthesis and exploration to be addressed effectively.
model space synthesis is an indispensable part of practical design.
the motivation for this paper is the current lack of adequate scientific foundations and practical technologies for scalable model space synthesis in software and systems engineering.
the consequences are significant in opportunity costs stakeholder dissatisfaction and in underperforming and failed projects and systems.
we hypothesize and our experimental results confirm the possibility of a parallelized model space synthesis approach backed by unsupervised learning to automatically derive a balanced partitioning of gigantic design spaces.
such a pragmatic synthesis of the entire model space promises revealing designs that greatly outperform those produced by the existing design tools and provides significant performance improvements to both systems designers and their end users.
in the next section we provide an overview of parasol then describe in detail its approach to address these issues and enable the pragmatic and scalable synthesis of large scale software model spaces.
approach this section overviews our approach realized in a tool called parasol1 to effectively parallelize systematic synthesis of large model spaces.
the driving innovation of this approach is to first synthesize a bounded sample of the model space and cluster it using unsupervised learning.
an invariant from each cluster is then automatically to support a balanced partitioning of the large model space prior to exploring the entire set of design variants allowing each partition to be synthesized concurrently and independently by a distinct synthesis engine.
parasol comprises four main steps as depicted in figure .
sampling which automatically synthesizes a bounded subset of modelsmsapropos formulafb derived from the system specification f via declarative slicing clustering which automatically discovers related subsets within the sample using unsupervised learning partitioning which automatically infers an invariant from each cluster i and synthesizes constraints cicorresponding to that invariant then parellel synthesis where each ciis conjoined withfto define a set of independently analyzable partitions of the target model space which can each be explored concurrently to synthesize the entire model space in parallel.
while our goals are broad for concrete exposition of our ideas we use relational logic as an example medium of specification to explain our vision in this paper.
relational logic is shown to be a perfect candidate for software abstraction .
.
sampling the first step in parasol is to synthesize a small bounded subset of the desired model space which can act as a representative sample.
figure 3provides an overview of the sampling process.
to generate this sample parasol accepts as input a formal specification of a system e.g.
in alloy which is then translated into a format f appropriate for consumption by an underlying off the shelf solveresec fse november singapore singapore clay stevens and hamid bagheri figure parasol overview.
a sample set of models is synthesized from a slice of the specification.
the sample set is clustered using unsupervised learning.
an invariant from each cluster is automatically inferred to support sound partitioning of the large model space.
model space synthesis is then performed in parallel greatly reducing the time required to generate the entire model space.
and or model finder.
when the solver finds a model m which satisfiesf that model is added to the model space.
parasol relies on declarative slicing to identify a base slice for its sampling.
specifically parasol first selects a slicing criterion c r and generates a base slice andderived slice of the specification.
the base slice represents a smaller problem than the original due to the removal of all relations that do not appear in the slicing criterion besides all clauses referencing the removed relations.
the formulae for the base and derived slices fbandfd respectively partition the formula for the input such that f f b fd.
from there it is easy to deduce that f f b in other words every assignment of tuples that satisfies fmust also satisfyfb.
this guarantees a mapping between the models of the sample and those of the input specification as each model of the input is a valid extension of a sample model.
parasol selects its slicing criterion based on the complexity of the formula for the base slice derived from the number of clauses appearing in the formula.
the complexity ratio formula compares the number of clauses c in the conjunctive normal form cnf representation of the original formula with the total number of clauses in the cnf for the base and derived slices cbandcd respectively .
the cnf translation process adds additional auxiliary variables and clauses to represent a given formula as a conjuction slice translate f sat?solve msfb ... ms base system specificatio n1sample synthesis sample modelsfigure sample synthesis overview.
input specification is translated into a format suitable for solver then sliced using declarative slicing.
sample is then synthesized from base slicefbusing specification driven model space synthesis.
of disjunctions.
the base and derived slices are each likely to be smaller than the original formula so their translations will include fewer total auxiliaries than the original formula would require allowing for complexity ratios greater than one.
parasol filters the possible slicing criteria to those that would produce unique base slices and selects the criterion with the highest complexity ratio.
complexityratio c cb cd parasol then uses the specification driven model space synthesis process to synthesize a sample of model instances satisfying the base slice formula fb as shown in figure .
iffbis satisfiable the model finder returns the satisfying model ms and adds it to the sample model space ms. a clause representing the negation ofmsis conjoined withfb and the resulting conjunction is then subjected to another round of analysis to produce a different satisfying solution.
this loop continues until the model finder cannot find a satisfying model completing sample model space synthesis.
these sample models satisfy the base slice derived from the original specification.
in view of the logical relationship described above between the base slice and the original larger specification each model in the original model space m is an extension of one of the models inms.
as such parasol can glean frommsinformation about the models of the original specification.
.
clustering for each model ms m s parasol then generates an observation vector os to provide as input for clustering.
this vector is observe os cluster2clustering sample modelsobservation vectorsnext?ms e.g.
k means figure clustering component overview.
for each model ms in the sample parasol constructs an observation vector os see figure .
observations are clustered using unsupervised learning to partition design alternatives in the sample.parasol efficient parallel synthesis of large model spaces esec fse november singapore singapore r t t t ... t t r t t ... t t ... ... ... ... r t t t ... t t r t t ... t t ... ... ... ... m2 m3 concat concat o2 o3 figure example observation vector construction for clustering.
sample models mk ml m scorrespond to observation vectorsokandol respectively.
each vector is constructed by concatenating sub vectors corresponding to each relation ri rj r where each index x is if tuple t x r in the corresponding model or otherwise.
constructed by checking the model against a given set of features which serve to identify the relevant similarities and differences among the observations.
parasol uses a list of features extracted from the tuple assignments in each satisfying model of the sample problem.
specifically it defines one boolean feature for each tuple of atomstin the upper bound of each relation r r. the upper bound denoted r.upperbound represents the set of all tuples that may be assigned to relation rby the solver in a potential model instance off usually defined as the n fold cartesian product of the domains of r. the size of each tuple assignment feature vector is therefore equal to r r r.upperbound .
the observation vector for each sample model msis computed as shown in figure .
first the relations in rand the tuples in each relation s upper bound are ordered into a canonical ordering and indexed.
the assignments of each relation riinmsis then translated into a sub vector according to that indexing setting a value of at each index where the corresponding tuple is a member ofriinmsand a value of otherwise.
for example figure 5depicts two sample models mk ml m sand relations ri rj r with cardinalities nandm respectively.
in mk ri ti ti ... ti n tin andrj tj ... tj m tj m .
in this case the vector okgenerated from mkwould contain a one at indices corresponding to ti 1andti n but would contain a zero at the index corresponding to ti among others.
similarly for ml which has different tuple assignments for riandrj the observation vector olwould contain a one at indices corresponding to ti 1andti but a zero at the index for ti .
the observations are then passed through unsupervised clustering algorithms.
if the desired degree of parallelism is known parasol uses k means clustering to produce the desired number of clusters.
specifically if the degree of parallelism is n parasol will run k means clustering where k min n .
it generates one fewer cluster in order to account for differences between the sample and the original input detailed in section .
.
if the desired degree of parallelism is not specified explicitly parasol uses x means clustering to automatically determine an appropriate value for k. x means clustering determines the best value forkby identifying candidate cluster locations and selecting those that optimize the bayesian information criterion bic for each cluster.
this allows for effective unsupervised clustering of the translate3partitioning sample clustersf specification infer invariant define partitioncnf synthesizer synthesizer synthesizer cfigure partitioning component overview.
invariant iis inferred from cluster i specifying tuples assignments as included excluded neither.
iis transformed into variable clauses and conjoined to the cnf representation of fto generate partition definition cifor each synthesis engine.
algorithm invariant inference algorithm.
input is a set of relations r a set of cluster centroids each comprising an ordered list of tuple assignment features.
returns invariants for each centroid.
input r relations centroids set of ordered lists of or output invariants invariants forc centroids do inv forr rdo fori 1to r .upperbound do t r .upperbound ifc .0then inv inv t r else if c .0then inv inv t r invariants invariants inv return invariants sample models even when a value for kis not given.
the discovered clusters both the metadata and the list of member observations for each are provided as input for the next step of our process.
.
partitioning parasol logically partitions the original model space based on the information derived by the unsupervised learning shown in figure .
it first examines the statistical metadata e.g.
the centroid values for each cluster to infer a set of invariants i.e.
logical statements that are true of every sample model in the cluster based on the features used for the clustering.
each centroid adopts a value for each feature in the closed range between .
and .
summarizing the feature s values in the sample models assigned to the corresponding cluster.
parasol analyzes each centroid and infers an invariant relational assignment of tuples based on the centroid values.
if the value for a particular feature is .
in a given centroid then parasol infers that the assignment of the tuple corresponding to that feature is invariant in the given cluster.
similarly a value of .
indicates that non assignment of the tuple is invariant in that cluster.
alg.
1outlines the invariant inference process.
the algorithm first iterates through a set of centroids representing each clusteresec fse november singapore singapore clay stevens and hamid bagheri 4parallel synthesis synthesizer synthesizer synthesizer c sat?solve mi... mi model space figure parallel synthesis component overview.
each synthesizer performs a model space synthesis loop on the provided partition definition.
models satisfying the definition are added to the shared model space negated and conjoined with the definition to discover new models.
when no more models are found model space synthesis is complete.
line generating an invariant for each.
the inner loops lines iterate through each tuple in the upper bound of each relation by index using the same index to access to the corresponding feature in centroidc lines and .
if the feature value is equal to .
in the centroid it conjoins the constraint that the tuple must be present in the set defining the relation i.e.
the tuple is included if it is equal to .
it asserts the tuple must notbe present i.e.
it is excluded .
for all other values it adds no clause.
once each the invariant for each cluster have been created parasol generates an additional logical definition from the conjunction of the negation of each of the other invariants this additional definition would match for any models that would not match any of the other invariants ensuring thatparasol can enumerate all satisfying models.
the resulting invariants logically define each cluster but would not be directly applicable as constraints for synthesizing models for f each one explicitly checks for the presence or absence of individualtuples inside the previously defined relations but frepresents the relations themselves as free variables.
therefore parasol further translatesfinto conjunctive normal form cnf in order to directly reference variables corresponding to each individual tuple assignment.
in the cnf representation each tuple in the domain of each relation is assigned a primary variable indicating that that tuple is assigned to that relation in a given model.
by finding the primary variable associated with each relation and tuple referenced in the invariant parasol can explicitly add clauses to the cnf requiring the variables for included tuples to be true and excluded tuples to be false .
if the invariant does not imply inclusion or exclusion for a given relation and tuple then no constraint is added for the corresponding primary variable in the cnf.
once every tuple assignment has been checked the emitted clauses are conjoined with the original cnf to generate a partition definition which can be given to an independent synthesis engine.
.
parallel synthesis the last step in our approach cf.
in figure is to distribute each partition definition cifor some partition i to a separate synthesis engine and synthesize the model space for each partition concurrently.
parasol again uses a variant of the model space synthesis process described in section .
as shown in figure .
if a satisfying model miis found for ci the model is added to themodel space ciis extended by conjoining it with the negation of mi and the result is given back to the solver model finder.
this process loops until no satisfying model instance can be found at which point the synthesis terminates.
when the analysis of all the partitions has terminated parasol will have synthesized the same model space as that synthesized by state of the art model space synthesis approaches but in a fraction of the time.
evaluation this section presents the experimental evaluation of parasol.
our evaluation addresses the following research questions rq1.
how well does parasol s learning based parallelized model space synthesis perform vs state of the art techniques?
rq2.
does our learning based partitioning divide the work more evenly than competing model space partitioning methods?
rq3.
how much overhead is introduced by parasol?
experimental setup.
we conducted the experiments using a custom java implementation of parasol2 comprising over lines of code using the built in parallel streaming capabilities of java and above to execute concurrently on multiple threads.
the learning based partitioning algorithms are realized on top of the weka library developed by the machine learning group at the university of waikato.
the specifications used in the experiments were developed in alloy relational logic specification language and executed using the java api of alloy the kodkod model finder which drives that version of the alloy analyzer and the glucose .
sat solver .
all experiments were run on openstack instances running ubuntu .
each with vcpus and 60gb ram.
subject systems.
we collected a set of eight system specifications as our experimental subjects representing model space exploration problems in three different domains database schema design and more specifically as explained in section object relational database mapping orm design role engineering within a role based access control rbac system and security analysis where the threat space of real world iot apps scoped by threat models thereof should be exhaustively explored in order to help discover and address the risks.
all subjects as well as our reference implementation of parasol and experimental data are publicly available online for reuse .
database design.
our first set of subjects evaluates parasol in the context of designing object relational database mapping orm schemas.
the orm tools provide an indirection layer between object oriented data models and relational database management systems and are included in many popular libraries e.g.
hibernate and frameworks e.g.
django .
the design mapping strategies employed by an orm can have a large impact on its performance.
selecting an appropriate design often demands the analysis of tradeoffs among candidates requiring analysis of the entire model space.
we considered the database design problem of two systems adopted from the literature.
the first is the object model of an e commerce system adopted from lau and czarnecki .
it represents a common architecture for open source and commercial 2research artifacts and experimental data are available at efficient parallel synthesis of large model spaces esec fse november singapore singapore table experimental data for each subject system specification.
average total runtime limited to hours for three executions reported for a model space synthesis performed using the approach from trademaker with state of the art incremental and parallel sat solvers and b using parasol.
model space size is the number of models synthesized by the trademaker baseline for the full system specification.
runtime column for parasol includes overhead.
specification domainsystemmodel space sizemodel space synthesis parasol incremental solver parallel solver runtime secs runtime secs runtime secs overhead secs speedup database designe commerce .
.
.
.
csos .
.
.
.
role eng.
rbac .
.
.
.
securityiot threats app bundles .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
e commerce systems.
the other object model is for a cyber social operating system csos to help coordinate people and tasks.
role engineering.
the next subject is centered around model space synthesis and analysis of the tradeoffs in developing roles and their associated permissions within a role based access control rbac system a process known as role engineering.
in such a system a given user has a set of permissions and resources that are required to perform their job as well as a set of roles that have been assigned to that user.
in each satisfying assignment each user must be assigned roles that grant their required permissions resources.
system administrators must then select the roles that provide the best tradeoffs among various non functional properties such as minimizing the number of roles they will need administer or the number of unneeded permissions assigned to users in the system.
the analysis allows administrators to select the role assignment that best satisfies the desired qualities.
security analysis.
our last set of subjects represents discovering and exploring the space of potential security threats in iot systems.
each warning produced denotes a possible threat to the security of the iot system.
fully assessing the risk and mitigating the impact of each threat would require examining every violations.
ensuring the security of the system therefore requires synthesis of the entire threat space to discover and address all possible security risks.
to evaluate parasol s performance in this context we considered real world iot app models drawn from .
we divided the apps collection into five non overlapping groups of each and explored for bundles of apps among each group that violate interaction threat assertions.
each individual model in the model space corresponds to a single possible threat that may arise from interactions among apps within the corresponding bundle.
baselines and measures.
to evaluate parasol in the context of the research questions we synthesized model spaces i.e.
design models role models and threat models for each subject system and measured a the total execution runtime to synthesize the entire model space in seconds b the overhead incurred by parasol in seconds and c the number of models synthesized by each analysisengine during execution used to compute the coefficient of variation to measure partition parity.
to answer rq1 we synthesized the model space for each subject specification with parasol and compared the results against synthesis using the model space synthesis method described in trademaker the state of the art in systematic specificationdriven model space synthesis.
our baseline approach relies upon sat solvers to explore the space of models for various systems specifications provided as input.
to ensure a fair comparison against trademaker we empowered it with state of the art sat solvers.
specifically we studied two classes of sat solvers as the underlying analysis engine for the baseline approach.
first we used an incremental sat solver to directly represent the trademaker approach as described in .
second we used a parallel solver which allows us to compare the high level parallelization approach taken byparasol to lower level cnf based parallelization.
to evaluate rq2 we synthesized the model space for each subject in parallel using two other partitioning methods as our baselines described in more detail in section .
.
lastly for rq3 we measured the overhead for synthesis with parasol against the overhead for the state of the art model space synthesis.
in order to ensure our experiments completed within a reasonable time we limited each execution both for parasol and each baseline to hours.
the model space for each system was synthesized three times with parasol and with each baseline and the mean values are reported.
the resulting model spaces synthesized by each approach are all the same as parasol synthesizes the same models as state of the art approaches in a much shorter time.
.
rq1 parasol in practice to answer the first research question we compared the time taken to synthesize the model space of each experimental subject with parasol to that required to synthesize the same model spaces using trademaker the state of the art model space synthesis technique .
we used two state of the art sat solvers to drive our baseline a glucose an incremental sat solver and b plingeling a parallel sat solver.
using the incremental solveresec fse november singapore singapore clay stevens and hamid bagheri provides a direct comparison with our baseline as an incremental sat solver is used by trademaker as presented in .
the parallel solver allows us to compare our approach against lower level parallelization performed by the sat solver.
we used our reference java implementation of parasol and collected the running time using the bash time command.
to ensure a fair evaluation we used plingeling s default degree of parallelism as the number of partitions in the experiments.
the experimental results are summarized in table .
across the board parasol outperformed the incremental baseline providing an average speedup of .
the largest speedup was obtained on the role engineering model which also had the shortest overall running time.
the iot threat space enumeration subjects fell in the middle with an average speedup of the speedup was more pronounced on app bundles with more potential security risks.
for example parasol shows speedup in the analysis of bundle with over a gigantic number of potential threats detected vs. bundle with only potential threats and speedup.
lastly parasol demonstrates the average speedup of for the two orm database design problems.
as a case in point for csos the system with the most valid database design models parasol saved the most total hours compared to the baseline reducing runtime from .
hours to under hours.
parasol also performed well against the baseline approach driven by the plingeling parallel sat solver.
as shown in table the baseline using the parallel solver was unable to fully synthesize anyof the model spaces within a hour time period.
this is in part due to the fact that the underlying parallel solvers are intended to quickly provide a single sat unsat determination by dividing a given cnf problem into subproblems and executing in parallel.
model space synthesis techniques such as that used by our baseline however repeatedly invoke the underlying solver incrementing the previous formula with a new clause for each discovered design variant.
plingeling treats each such new invocation as an entirely new problem discarding any information discovered during the solve steps from previous iterations.
in contrast parasol extracts specification level domain knowledge from each model to partition the problem at a higher level of abstraction.
because the parallelsat version of the state of the art baseline approach was unable to synthesize any of the subject model spaces within hours we excluded that version from subsequent experiments and used only the incremental sat.
overall the experimental results indicate that parasol provides significant time savings with an overall average speedup of compared to state of the art model space synthesis techniques using an incremental sat solver.
.
rq2 parasol vs. other partitioners to address the second research question we set out to assess how wellparasol s learning based partitioning divides the model space and whether it distributes the work more evenly than competing specification level partitioning methods.
we considered two competing partitioning approaches comparing each against our learning based partitioning c.f.
section random partitioning with random partitioning each free variable in the original specification is with equal probability explicitly included excluded or neither in which case that variable is left to the solver to include or exclude.
to test this method of partitioning we implemented an algorithm where the the random partitioner elects whether to include exclude or defer each variable based on a value drawn from a uniform random distribution rather than setting the variables in the cnf according to the invariants.
scope partitioning scope partitioning relies on information already encoded in the input specification to guide the partitioning.
formal specifications for bounded verification tools like alloy include constraints on the scope of the analysis.
specifically the author of the specification determines the scope by declaring the maximum number of distinct atoms that can be assigned to certain type like unary relations i.e.
sigs .
for example in the orm design specifications the user determines the maximum number of tables that may appear in each model by setting the scope for the tablesig.
for the csos specification the table scope is set to meaning that the solver will explore models containing between and tables.
for the scope partitioning baseline we restrict each partition to synthesize models within a subrange of the original scopes for example one partition might synthesize all models of csos with exactly tables another all models with exactly tables and so on.
we implemented an iterative partitioner that loops through each type like relation in the specification creating partitions by fixing the scope of each relation to a single value until the desired number of partitions has been created.
the boxplots in figure 8show the synthesis time in seconds taken by each of the techniques vs. parasol over the subject systems.
the horizontal axis specifies the synthesis methods trademaker s model space synthesis with an incremental solver glucose parallel synthesis using random partitioning parallel synthesis using scope partitioning and parasol orange right most box .
parasol tends to exhibit significantly lower synthesis time compared to the other techniques.
to determine how each of the three partitioning methods divides the model space among the parallel analysis engines we tracked the number of models synthesized by each distributed worker using each of the three partitioning methods.
we then computed the mean and standard deviation of the number of models synthesized for each partition for each method in order to calculate the coefficient of variation cv the ratio of standard deviation to mean as a measure of the parity among the partitions.
the cvassumes a value between zero and the square root of the number of partitions i.e.
with a lower cvindicating more balanced division of work.
table 2presents the results for each partitioning method and subject specification.
parasol significantly outperformed both the random and scope based partitioning baselines in all but one case where the partitions produced by scope based partitioning are the same as those produced by parasol for the role engineering subject the slicing criterion used by parasol contained only the rolesig from the specification resulting in the same partitions as those created by the scope partitioning baseline.
in terms of partition parity thecvforparasol was less than half of the square root of the number of partitions for each subject system indicating that parasol evenly divides work among the partitions.
furthermore parasol efficient parallel synthesis of large model spaces esec fse november singapore singapore table total runtime in seconds including overhead speedup and coefficient of variation cv across partitions for each subject system specification from each of the three partitioning methods.
note that .
is the maximum value for cv and results when one worker synthesizes the entire model space.
parasol s learning based partitioning produces significantly more balanced partitions lower cv and substantially less runtime than other partitioning methods for all subjects.
partitioning methodmetricsubject system e commerce csos rbac iot threats randomruntime secs .
.
.
.
.
.
.
.
cv .
.
.
.
.
.
.
.
scoperuntime secs .
.
.
.
.
.
.
.
cv .
.
.
.
.
.
.
.
parasolruntime secs .
.
.
.
.
.
.
.
cv .
.
.
.
.
.
.
.
speedup w parasolvs.
random vs. scope parasol had the lowest cvamong all three partitioning methods for all specifications showing that parasol outperforms the baseline approaches in terms of evenly partitioning the model space.
we interpret these data to suggest that parasol improves upon other partitioning methods for a runtime performance and b even partitioning of work among parallel workers.
.
rq3 overhead to determine the overhead incurred by parasol we computed the time in seconds between the start of execution and the start of the exploration of the model space for the original specification for both the state of the art model space synthesis used as a baseline for rq1 and parasol.
that overhead time period includes the sampling and partitioning conducted by parasol before design space exploration which is not performed by state of the art model space synthesis.
the overhead then can be represented as the difference between those two time durations.
table 1summarizes the overhead in seconds for each of subject in the last column.
overall the execution time overhead incurred by parasol accounted for a small fraction of the running time on average making the effect on user experience negligible.
across the board the speedup provided by parasol substantially outweighs the overhead.
discussion overall the results described in section 4demonstrate that parasolcan synthesize a huge model space much more efficiently than state of the art model space synthesis techniques exhibiting an average speedup of over compared to the competing approaches.
parasol also outperforms state of the art parallel solvers by partitioning the model space at a higher level of abstraction than the underlying sat problem.
we interpret our results to show that thevariance among partitions produced by parasol is low overall indicating the effectiveness of our learning based partitioning in evenly dividing work among the parallel workers see table .
finally the overhead required by parasol is minimal considering the multiplicative speedup parasol provides compared to state of the art model space synthesis see table .
for some experimental subjects e.g.
csos the variation among the partitions was higher than the others.
we believe this was due to differences in how well the sample represented the implicit structure of the specification.
parasol samples via declarative slicing using the criteria described in section which measures the complexity ratio of the base slice compared to the original formula see formula .
for some specifications the base slice effectively matched the high level structure of the target model space.
for example the base slice selected for all five iot coordination threat app groups included the relation defining which apps were installed.
each partition was thus defined by the inclusion exclusion of specific combinations of apps rather than by potential security risks resulting in a low coefficient of variation between .
and .
.
in contrast the slice selected for the rbac specification partitioned based on the number of roles included in the models i.e.
one partition synthesized all models with exactly one role another all variants containing exactly two roles etc.
.
this resulted in greater imbalance among the partitions.
for example there are more possible assignments of roles and permissions in a system with five roles than in a system with only two.
this is indicated by the higher cv .
for the rbac system.
it is also worth noting that the slice selected by parasol for that particular system resulted in exactly the same partitioning as the scope based partitioning method hence the two methods have the same cv.
this was the only case among all eight subject specifications where the scope based partitioning provided the same partitions.
in all other cases parasol outperformed the other methods both in terms of runtime performance and allocation of work among partitions.
the formulae selected during declarative slicing also determined the number of models synthesized for the sample which was the largest contributor to the overhead for each subject specification.esec fse november singapore singapore clay stevens and hamid bagheri 020000400006000080000time secs w incr.
solverw randompartitioningw scope partitioningparasol a csos 010000200003000040000time secs w incr.
solverw randompartitioningw scope partitioningparasol b ecommerce 0500100015002000time secs w incr.
solverw randompartitioningw scope partitioningparasol c rbac 0500100015002000250030003500time secs w incr.
solverw randompartitioningw scope partitioningparasol d iot bnd.
050001000015000time secs w incr.
solverw randompartitioningw scope partitioningparasol e iot bnd.
010000200003000040000time secs w incr.
solverw randompartitioningw scope partitioningparasol f iot bnd.
010000200003000040000time secs w incr.
solverw randompartitioningw scope partitioningparasol g iot bnd.
0100002000030000400005000060000time secs w incr.
solverw scope partitioningparasol w randompartitioning h iot bnd.
figure boxplots depicting the synthesis time in seconds taken by each of the techniques vs. parasol over the subject systems.
horizontal axis indicates synthesis method stateof the art model space synthesis with an incremental solver glucose parallel synthesis using random partitioning parallel synthesis using scope partitioning and parasol orange right most box .for example the installed app slice chosen for the iot coordination threat app groups generated more than sample instances increasing the overhead.
on the other hand the base slices generated for rbac produced only the scope of the role signature in the specification despite the large number of models generated for the problem overall.
further research into different slicing algorithms could improve parasol s ability to select smaller and or more representative samples leading to even greater speedups.
threats to validity the main threat to the internal validity of our experimental evaluation is the accuracy of our custom implementation.
our code was debugged and tested thoroughly including unit tests written with junit to ensure our implementation synthesized models correctly.
we also canonicalized and serialized the models synthesized by parasol and each baseline to ensure the same model space was synthesized by each one the de duplicated set of models was the same in each case providing evidence that our implementation works as intended.
to ensure our external validity we have conducted our experiments on real world model spaces drawn from various software engineering domains.
lastly the validity of our construct relies on the use of the coefficient of variation as a proxy for parity among our partitions there may be other possible measures such as standard error of the mean or median absolute deviation.
cv is used in a wide variety of statistical and analytical settings and provides an intuitive understanding of the variation so we believe it is a reasonable metric to use for our analysis.
related work researchers have explored the area of specification driven design space exploration.
kang jackson and schulte employed formal methods for design space exploration using an smt solver but focused the effort on finding one or more satisfying model not necessarily the entire model space.
the focus of more recent research efforts is usually on constraining the model space in order to filter some models during a complete exploration.
sullivan et al.
recently proposed a general abstraction idiom to only synthesize models that satisfy a given abstraction function.
porncharoenwase et al.
presented an approach that finds a representative sample attempting to demonstrate the most syntactic coverage while exploring the smallest fraction of the overall space.
nelson et al.
developed an approach called aluminum that enables users to manually guide exploration which may not be suitable for large scale systematic analysis.
these approaches all seek to limit the model space rather than to effectively explore all variants assuming that the user performing the analysis can determine which variants are irrelevant.
parasol makes no such assumption providing significant speedups while still exploring the entire model space.
rosner et al.
developed ranger to partition a bounded model checking problem based on ranges of bound assignments.
however ranger focuses on finding oneinstance or counterexample rather than parallelizing the model space exploration.
in fact the recursive range partitioning technique used by ranger to ensure parity among the worker nodes which introduces acceptable overhead for finding a single model would be invoked too frequently to be suitable for exploring vast model spaces.
portfolio solvers such asparasol efficient parallel synthesis of large model spaces esec fse november singapore singapore manysat and hordesat attempt many different configurations of sequential solvers in parallel to find the best method of solving the problem.
iser et al.
described an approach that can aid such solvers by using a shared repository of clauses to mitigate memory issues.
as demonstrated in section the techniques used in these parallel but non incremental solvers e.g.
plingling optimize finding a single satisfying model leading to extremely poor performance when searching for subsequent models.parasol avoids these pitfalls by using learning at a higher level to automatically derive domain knowledge guiding the parallelization of exploring the model space.
lastly while other constraint solvers e.g.
smt solvers like z3 have made impressive improvements in recent years they still lag behind sat based solutions when analyzing relational specifications.
meng et al.
developed an approach to use cvc4 as the underlying solver for alloy specifications but the sat based solution still outperformed their implementation for most specifications.
stoel et al.
developed a z3 based tool which was similarly less efficient than the baseline alloy translation to sat.
therefore we implement parasol atop a sat solver as that represents the current state of the art for relational specifications.
conclusion in this paper we presented parasol a novel approach to perform systematic specification driven model space synthesis in parallel leveraging unsupervised learning to extract domain knowledge about specification in order to evenly partition the model space.
the experimental results demonstrated an average speedup of over state of the art model space synthesis possibly saving hours or even days for large system specifications.
the results further corroborated that the division of work guided by our learning based partitioning strategy was more even than competing partitioning strategies.
we also showed that the fractional overhead introduced by the sampling is far outweighed by the improvement in overall runtime.
in future research we would seek to explore some of the components of the approach to improve upon this research.
for example different strategies may be employed to extract samples with declarative slicing rather than using the complexity ratio.
furthermore parallel synthesis of the model space could also enable further optimizations such as conducting dynamic tradespace analysis where each of the design variants is evaluated in parallel as well.
finally we also believe further research could be done using different learning techniques perhaps supervised learning with some form of oracle to better extract domain knowledge.