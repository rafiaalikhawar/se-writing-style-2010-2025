gitor scalable code clone detection by building global sample graph junjie shan shanjunjie westlake.edu.cn westlake university hangzhou chinashihan dou shihandou foxmail.com fudan university shanghai chinayueming wu wuyueming21 gmail.com nanyang technological university singapore hairu wu hrwu20 fudan.edu.cn fudan university shanghai chinayang liu yangliu ntu.edu.sg nanyang technological university singapore abstract code clone detection is about finding out similar code fragments which has drawn much attention in software engineering since it is important for software maintenance and evolution.
researchers have proposed many techniques and tools for source code clone detection but current detection methods concentrate on analyzing or processing code samples individually without exploring the underlying connections among code samples.
in this paper we propose gitor to capture the underlying connections among different code samples.
specifically given a source code database we first tokenize all code samples to extract the pre defined individual information e.g.
keywords .
after obtaining all samples individual information we leverage them to build a large global sample graph where each node is a code sample or a type of individual information.
then we apply a node embedding technique on the global sample graph to extract all the samples vector representations.
after collecting all code samples vectors we can simply compare the similarity between any two samples to detect possible clone pairs.
more importantly since the obtained vector of a sample is from a global sample graph we can combine it with its own code features to improve the code clone detection performance.
to demonstrate the effectiveness of gitor we evaluate it on a widely used dataset namely bigclonebench.
our experimental results show that gitor has higher accuracy in terms of code clone detection and excellent execution time for inputs of various sizes mloc compared to existing state of the art tools.
moreover we also evaluate the combination of gitor with other traditional vector based clone detection methods the results show that the use of gitor enables them detect more code clones with higher f1.
equal contribution yueming wu is the corresponding author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
concepts software and its engineering software maintenance tools .
keywords clone detection node embedding global sample graph acm reference format junjie shan shihan dou yueming wu hairu wu and yang liu.
.
gitor scalable code clone detection by building global sample graph.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
introduction code clone also known as duplicate code or similar code refers to the existence of two or more identical or similar source code fragments.
numerous empirical studies have shown that code cloning widely exists in different open source or closed source code bases.
for example detected .
of code clones in linux system kamiya et al.
found code clones in jdk and even up to code clones in some software systems .
widespread code cloning has helped the development of software systems to a certain extent and can have positive benefits .
however many studies have pointed out that a large number of code clones can have a negative impact on software systems maintenance since it may introduce bugs or vulnerabilities.
therefore the automatic detection of code clones has attracted wide attention in the field of software engineering.
according to the syntactic or semantic similarity of code clones bellon et al.
classified code clones into four types textual similarity type lexical similarity type syntactic similarity type and semantic similarity type .
from type to type the similarity of cloned codes gradually decreases and the difficulty of detection gradually increases.
a number of code clone detection method has been proposed .
for example a state of the art token based method namely sourcerercc is designed to capture the tokens overlap similarity among different methods to detect type to type clones.
in practice token based techniques are unable to handle type clones i.e.
semantic clones due to a lack of respect for program semantics.
to mitigate the issue researchers use program analysis to distill the semantics of codearxiv .08778v2 nov 2023esec fse december san francisco ca usa junjie shan shihan dou yueming wu hairu wu and yang liu fragments into tree or graph representations e.g.
abstract syntax tree and control flow graph and apply tree or graph matching to quantify the similarity between different codes.
empirical studies have shown that tree based and graph based code clone detectors can achieve better performance on semantic code clone analysis.
however due to the complexity of tree and graph structures they are unable to scale to large programs.
given that large scale clone detection is essential to daily software engineering activities such as code search mining library candidates and license violation detection there is an increasing need for a scalable technique to detect code clones.
in this paper we propose a novel code clone detection method leveraging global graph built across code samples.
we find that almost all current code clone detection methods focus on extracting the features from source code directly while ignoring the potential underlying connections among different code samples.
to achieve scalable and accurate code clone detection we consider extracting these connections to build bridges between code samples i.e.
global graph and using them to detect code clones.
specifically we mainly address two challenges in our paper.
how to build the global graph from source code and represent it properly to retain code details?
how to utilize the global graph across different source code samples to efficiently and accurately detect code clones?
to tackle the first challenge we choose keyword tokens along with side information as the individual information to represent the source code samples.
in detail since the programming language of our experimental dataset is java we leverage the reserved words of java as keyword tokens.
meanwhile to better capture the code details we also extract another kind of information i.e.
side information such as the maximum depth of brackets and the number of loops.
because the extraction of keywords and side information can be achieved by simple lexical analysis we can complete scalable code clone analysis.
to address the second challenge we use keywords and side information as the bridge to connect different code samples.
specifically we build a global sample graph to represent the underlying connections between all samples.
each node in the graph represents a code sample or a kind of individual information i.e.
keywords or side information .
each edge indicates whether a code sample contains such individual information.
after constructing the global graph we perform a node embedding technique on it to convert all code samples into corresponding vector representations.
given generated vectors we can calculate the cosine similarity of two samples and quickly identify whether they are clone pairs.
we implement a prototype system gitor and evaluate it on a widely used dataset namely bigclonebench .
our evaluation results show that gitor is superior to six state of the art comparative systems including sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper and nil .
moreover we can also combine the code sample representation vector generated by gitor with feature vector obtained from source code directly by three traditional vector based tools i.e.
word2vec doc2vec and code2vec the results indicate that the combination make them detect more clones with higher f1.
finally we examine the scalability of gitor on various sizes of code.evaluation results report that gitor has the ability to analyze million lines of code with the shortest execution time compared to sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper andnil.
in summary this paper makes the following contributions we propose a novel method to detect code clones by building a global sample graph using keywords and side information.
the constructed global graph can capture the underlying connections between different source code samples.
we design a prototype system namely gitor and conduct evaluations on a widely used dataset i.e.
bigclonebench .
experimental results suggest that gitor outperforms sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper and nilandgitor is adept at handling the challenges posed by the big scale of code.
paper organization.
the remainder of the paper is organized as follows.
section explains the background and motivation.
section introduces our system.
section reports the experimental results.
section discusses the future work.
section describes the related work.
section concludes the present paper.
definition and motivation .
definitions the paper utilizes the well accepted definitions of code clones and clone types as follows 1public static int fib int i int f1 f2 c if i i return i for int j j i j c f1 f2 f1 f2 f2 c return c listing original func 1public static int fib int i int f1 f2 c if i i return i for int j j i j c f1 f2 f1 f2 f2 c return c listing type func 1public static int fib int num int f1 f2 c if num num return num for int j j num j c f1 f2 f1 f2 f2 c return c listing type func 1public static int calfib int num int fib1 fib2 int t if num num return num for int k k num k t fib1 fib2 fib1 fib2 fib2 t return t listing type func gitor scalable code clone detection by building global sample graph esec fse december san francisco ca usa 1public static long calfib long number long f1 f2 c switch number case return case return default break while number c f1 f2 f1 f2 f2 c number return c listing type func in our paper we use the following widely used definitions of code clone types.
type textual similarity identical code fragments except for minor differences in white space layout or comments.
type lexical similarity structurally identical code fragments in addition to type clone differences there might be some differences in identifier names and literal values.
type syntactic similarity modified similar code fragments that differ at the statement level.
besides the type1 and type clone the fragments might have statements added modified and or removed compared to each other.
type semantic similarity dissimilar code fragments with the same functionality but implemented in a syntactically different way.
to elaborate on different types of clones listings to present examples from type to type clones.
the original code is used to compute the fibonacci number given the order.
the type clone starting in line is identical to the original code.
the type2 clone starting in line differs only in identifiers name i.e.
mandninstead ofaandb .
obviously the two types mentioned above are easy to detect.
the type clone starting in line is syntactically similar but differs at the statement level.
the first line in type line is totally different from the origin code.
the method name and types of parameters are all changed.
in addition it calculates the greatest common divisor in a similar but not identical way.
detecting type clones is harder than the previous two types.
finally the type clone starting in line iterates to compute the greatest common divisor which is a completely different way.
its lexical and syntactic are dissimilar to the original method.
therefore it requires an in depth understanding of code fragments to detect type clones.
.
motivation to illustrate the key insight of our proposed method we leverage fun and its corresponding type and type clones i.e.
fun and fun as our analysis targets.
as shown in listing those examples are all used to calculate the fibonacci number of the given order.
according to the definition of code clone the clone pair fib0.java andfib3.java are classified as type clone i.e.
syntactic similarity since they differ at the statement level.
the clone pair fib0.java andfib4.java are classified as a type clone i.e.
semanticclone because they have syntactically dissimilar code to implement the same functionality.
.
.
sourcerercc.
we start with illustrating how the widely used clone detection tool sourcerercc i.e.
one of the state of theart token based clone detectors detects possible clone pairs by calculating the similarity of each pair.
sourcerercc utilizes the overlap of two source code blocks to compute the similarity since it intuitively captures the notion of overlap among different code blocks.
for example given two code blocks c1andc2 the overlap similarity s c1 c2 is calculated as the number of tokens shared by c1andc2.
s c1 c2 c1 c2 given the threshold and the maximum number of tokens t max c1 c2 a pair of code blocks is considered as a clone pair when the ratio of overlap similarity and tis greater than the threshold .
s c1 c2 t .
.
keywords.
to achieve a more accurate clone detection we need to extract reliable information to represent the source code preferably some kind of global information that can reflect the connections between source code samples rather than analyze the information from code samples individually.
so we will extract the individual information from each code sample by extracting keywords and build a global sample graph that connects all code samples.
func func 4func int publicstatic returnif forswitch case1114 while13 1motivation figure a global graph of func func and func .
we first tokenize the source code to get the sequences of tokens of func func and func .
then we choose only the reserved words in java as the keywords instead of all tokens to represent code samples since the reserved words are used in all java source code samples.
after extracting keywords from the above code samples we construct a weighted directed graph with the frequency of keywords as weight as illustrated in figure .
each blue node represents a code sample each red node represents a keyword and the weight from blue nodes to red nodes is the frequency of keyword in the corresponding code sample.
.
.
node embedding.
in order to obtain the similarity of fun fun and fun in figure we first use node embedding methods to convert them into their vector representations.
these nodeesec fse december san francisco ca usa junjie shan shihan dou yueming wu hairu wu and yang liu clone detectora code databaseglobal g raph construction node embedding clone detection keywords side informationunion global graphoverview figure system overview of gitor embedding algorithms typically aim to capture the structural information and relationships between nodes and covert the graph structure and node attributes into representation vectors which can preserve the underlying similarity among nodes .
in this paper we mainly consider two different embedding methods namely node2vec and prone since they support the embedding of weighted graph.
however to achieve the scalability we choose prone as our embedding method because it is faster more scalable and more effective than node2vec .
so we use prone to map the code samples into vectors which can be used to calculate the similarity among different functions.
.
.
similarity evaluation.
we calculate the similarity of above two code blocks using the method mentioned in sourcerercc .
it shows that the number of tokens in func and func is and respectively.
then the same tokens shared by fun and func are obtained for computing the overlap similarity.
we observe that there are same tokens shared by these two code blocks which means the overlap similarity of func and func is .
.
if similarity threshold in sourcerercc is set to which means that sourcerercc reports two methods as a clone pair only when the ratio of number of shared tokens and maximum number of tokens of them is larger than .
in this case sourcerercc will cause a false negative by reporting func and func as a none clone pair.
also the similarity between func and func according to sourcerercc is .
.
now we conduct node embedding on the graph shown in figure and then we get the vector representations of fun fun and fun which are used to calculate the similarity.
after node embedding the similarity between func and func is .
and the similarity between func and func is .
suggesting that the similarity among these clone pairs is significantly improved.
based on the observation we propose a novel code clone detection framework by considering the global relationships between different functions.
approach in this section we introduce our proposed system namely gitor .
.
system overview as shown in figure gitor consists of three main phases global graph construction node embedding and clone detection .
global graph construction we first apply lexical analysis to extract the individual information including keywords andside information of a code sample with correspondingweights.
then a global sample graph is built by using these information where each node represents a sample or a type ofindividual information .
node embedding given a graph of the whole code base we use a node embedding technique on the global graph and output the vectors of each node with chosen dimension.
the input is a weighted global sample graph and the outputs are vectors of all samples in the code base.
clone detection after the generation of vectors we have two ways to detect potential clone pairs.
first we can simply calculate the cosine similarity of a pair of samples to identify code clones.
second we can combine gitor with other vector based clone detection methods which will boost the performance of clone detection.
.
global graph construction .
.
individual information extraction.
in this paper we aim to combine the connection capture capability of graph embedding methods with the scalability of token based methods.
therefore we first conduct tokenization on the source code to extract the keywords and side information from the source code.
since our experiments are done on the bigclonebench dataset we tokenize thejava source code based on a java parse tool namely javalang .
we choose the java reserved words as keywords along with five types of side information asindividual information .
for example take the func from listing the keywords and corresponding weights of func is public static int if return for .
moreover the five different types of side information are as follows maximum nesting depth of the curly brackets mndcb the number of maximum depth of nested curly brackets.
for example the mndcb of func is .
maximum number of parallel curly brackets mnpcb the number of maximum parallel curly brackets with depth .
for example the mnpcb of func is .
loop repetition information lri the number of loop functions used in the code including for loop and while loop.
for example the lriof func is .
flow control information fci the number of flow control functions used in the code including if else and switch case.
for example the fciof func is .
numerical declaration information ndi the number of numeric variables declared in the code including int double float byte short and long declaration.
for example the ndi of func is .gitor scalable code clone detection by building global sample graph esec fse december san francisco ca usa formndcb we utilize a depth counter adjusting it with every encountered curly bracket incrementing for each opening and decrementing for each closing subsequently noting the peak depth.
formnpcb we discern parallel curly brackets at distinct depths by counting sequential opening and closing pairs.
loop related tokens like for and while contribute to the lritally.
similarly flowcontrol tokens such as if and switch are counted for fci.
the ndi is ascertained by enumerating numeric variable declaration tokens like int and double.
this token based methodology offers a nuanced perspective on the code s structure and semantics.
in this paper we chose these types of side information because they can provide additional information about the structure and complexity of the code samples and can help to identify clones that might not have been detected by keyword based methods alone.
also using such information can improve the scalability of code clone since it reflects the code structure without processing and comparing the whole code sample.
for example lrirepresents the number of for loop declarations and while loop declarations since they have similar functionality in java and the substitution of these two loop functions for each other is often found in clone samples.
also the types of side information might differ according to the programming language of code samples.
for instance the functionality of curly brackets in python is different from that of curly brackets in java.
so the types of side information should be carefully selected according to the different programming languages of code samples.
moreover different combinations of side information may affect the detection performance slightly and the main goal of this paper is not about finding the optimal combination of different types of side information so we will use all of these five types in the following paper.
in our study on code clone detection we discern the importance of both keywords andside information .
keywords are the reserved words directly extracted as tokens from the code serving as foundational markers of code content.
on the other hand side information delves deeper encapsulating structural metadata such as bracket depth and loop count.
to maximize the potential of both elements we construct individual graphs for each.
these are then amalgamated into a singular comprehensive global graph establishing diverse connections between code samples.
this method not only merges lexical content with structural nuances but also provides a more robust framework enhancing the precision in detecting code clones by highlighting intricate relationships and similarities between code snippets.
after extracting keywords and side information we can get a sequence of tokens with corresponding weight which is the frequency in this case.
.
.
global graph construction.
nowadays the graph is an important kind of representation to encode relation structure which is used in many domains i.e.
social networks citation networks function call diagrams etc.
.
the nodes and edges can represent the objects and relationships respectively.
evaluation of similarity between two nodes based on the graph structure has a wide range of applications such as social networks analysis knn graph clustering etc.
therefore instead of simply comparing the similarity using the overlap keywords and side information of two samples we first use keywords extracted from the last step to build a graph func 1func func func 4func 0int publicstatic returnif forswitch case1 while131231figure a global graph of func constructed by keywords.
func 1func func func 4func mp fcilrimd ndi4 figure a global graph of func constructed by side information.
representing the whole code base.
to better illustrate this phase ingitor we choose the samples in listing as an example and present a clearer description in figure .
as illustrated in figure the blue nodes represent function and the red nodes represent the keywords.
the weight on the directed edges from functions to keywords is the frequency of keywords appearing in the functions.
to better capture the program details of source code we also select another kind of information.
specifically we construct another graph using side information defined above where the blue nodes represent function as well but the red nodes represent side information types and the weight is the count of corresponding side information as illustrated in figure .
after obtaining two graphs using keywords and side information we merge them by merging the nodes that have the same labels to build one larger global sample graph which will be embedded and used to calculate the similarity of any two functions.
in short the input of graph construction is a code database containing many code samples i.e.
functions and the output is a large global sample graph.esec fse december san francisco ca usa junjie shan shihan dou yueming wu hairu wu and yang liu method application combined with individual information global vector f1 f2v1 v2f4 f3 v3 v4node embeddingglobal graph constructionf1 f2f4f3function 4global graph word2ve c doc2vec code2vec encoder individual vectorv1 v2 v3 v4 detect clones with global features cosinesim v1 v2 cosinesim v1 v1 v2 v2 detect clones with global and individual features figure two applications of gitor .
the first is to detect code clones using global features and the second is to combine global features with individual features to detect code clones.
.
node embedding graph is a commonly used type of information representation in complex systems and can represent many complex relationships in real life scenarios such as social networks crime networks traffic networks etc.
graph analysis is used to dig deeper into the intrinsic features of graph data however since the graph is non euclidean data traditional data analysis methods generally have high computational effort and spatial overhead.
graph embedding is an effective method to solve the graph analysis problem which transforms the original graph data into a low dimensional space and preserves key information thus improving node classification link prediction and graph analysis.
it can improve the performance of the tasks like node classification link prediction and node clustering by retaining key information from the graph.
deep learning based methods among different graph embedding methods have demonstrated promising results due to their capability of automatically discovering underlying connections and identifying useful representations from the complex graph structures.
for instance deep learning with random walk i.e.
deepwalk and node2vec can leverage the neighborhood structure by sampling paths on the graph automatically.
graph embedding methods are feature representation learning methods exploiting the graph structure to transform each node of the graph into a low dimensional vector while preserving neighborhood similarity semantic information and community structure among nodes .
the obtained vector representations can be utilized by a wide range of tasks such as link prediction node classification .
so the node embedding method can capture the global connections among nodes in the graph which means it can capture the underlying similarity property among functions from a holistic perspective than analyzing them individually.
in this paper we choose prone since it is a fast and effective method that combines the benefits of various embedding methods while remaining time efficient .
moreover we conduct the embedding with different vector sizes i.e.
d on our chosen dataset bigclonebench to find the optimal embedding dimension for clone detection.in brief the input of node embedding is the graph constructed before and the outputs are vectors of all nodes in the graph with the pre defined dimension.
.
clone detection after collecting the vectors of all functions we have two applications to use them for code clone detection.
the first is to apply code clone detection by directly computing the similarity of these vectors.
more importantly these vectors can also be used to enhance the detection effectiveness of other vector based code clone detectors.
figure describes an example of the two applications of gitor .
.
.
application detect clones with global features.
cosine similarity is a commonly used metric which measures similarity between two vectors especially in high dimension space.
it measures similarity as the cosine of the angle between two vectors.
two similar vectors are expected to have a small angle between them.
the cosine similarity of two vectors x and y is defined as follows cos d ixiyi d ix2 i d iy2 i our first application is simply calculating the cosine similarity between two vectors if the similarity is greater than a certain threshold e.g.
.
they are identified as a clone pair as illustrated in figure .
.
.
application detect clones with global and self features.
we choose the graph as the representation of the whole code base since the natural structure of the graph can capture the underlying global connections among different code samples better than analyzing them individually.
instead of using the gitor alone we can combine it with other self features based i.e.
individual features based methods which is generated by individual analysis on each code sample.
nowadays there are numerous vector based code clone detection methods such as and and the current methods all focus on detecting clones utilizing individual features.
in other words our proposed global graph based clone detection methodgitor scalable code clone detection by building global sample graph esec fse december san francisco ca usa table detection performance of gitor with different cosine similarity thresholds.
cosine .60keywords side information both t recall t recall vst recall .
.
.
.
.
.
.
.
.
st recall .
.
.
.
.
.
.
.
.
.
.
.
mt recall .
.
.
.
.
.
.
.
.
.
.
.
type recall .
.
.
.
.
.
.
.
.
.
.
.
precision .
.
.
.
.
.
.
.
.
.
.
.
f1 .
.
.
.
.
.
.
.
.
.
.
.
cosine .
t recall t recall vst recall .
.
.
.
.
.
.
.
.
st recall .
.
.
.
.
.
.
.
.
.
.
.
mt recall .
.
.
.
.
.
.
.
.
.
.
.
type recall .
.
.
.
.
.
.
.
.
.
.
.
precision .
.
.
.
.
.
.
.
.
.
.
.
f1 .
.
.
.
.
.
.
.
.
.
.
.
cosine .
t recall t recall vst recall .
.
.
.
.
.
.
.
.
.
.
st recall .
.
.
.
.
.
.
.
.
.
.
.
mt recall .
.
.
.
.
.
.
.
.
.
.
.
type recall .
.
.
.
.
.
.
.
.
.
.
.
precision .
.
.
.
.
.
.
.
.
.
.
.
f1 .
.
.
.
.
.
.
.
.
.
.
.
can be combined with current vector based detection methods to boost the performance of clone detection.
in this paper we choose doc2vec word2vec and code2vec as the vector based detection methods .
word2vec and doc2vec are well known natural language processing baseline methods for extracting feature vectors from source code.
code2vec parses a code fragment into an ast path collection.
to predict the method name the core idea is to use a soft attention mechanism on the paths and aggregate all vector representations into a single vector.
this combined method is illustrated in figure .
the global vector and individual vector are added to calculate the similarity between two code samples.
experiments in this section we aim to answer the following research questions rq1 what is the effectiveness of gitor in detecting different types of code clones when used alone?
rq2 how does the use of global features contribute to the effectiveness of boosting individual features based clone detection?
rq3 what is the effectiveness of gitor compared to other stateof the art code clone detectors?
rq4 what is the runtime performance of gitor compared to other state of the art clone detectors?
.
experimental settings .
.
dataset.
we conduct our evaluations on the dataset bigclonebench which consists of more than labeled clone pairs from systems.
the code granularity of clone pairs in bigclonebench is function level and each clone pair is manually assigned a corresponding clone type.
type and type types are usually further divided into four subcategories based on their syntactical similarity score as follows i very strongly type vst3 with a similarity between .
.
ii strongly type st3 with a similarity between .
.
iii moderately type mt3 with a similarity between .
.
and iv weakly type type wt3 t4 with a similarity between .
.
.
the total number of these clone pairs used in our experiments is including type clones type clones vst3 clones st3 clones mt3 clones and wt3 t4 clones.
in the following experiment results we use type t4 to denote wt3 t4.
.
.
implementation.
forindividual information extraction we leverage a java parser i.e.
javalang to extract the keywords andside information from source code samples.
for global sample graph construction we use a python library networkx to build a weighted and directed graph.
for node embedding we employ aesec fse december san francisco ca usa junjie shan shihan dou yueming wu hairu wu and yang liu widely used embedding method prone to conduct the embedding of the graph.
the output of embedding is a series of vectors of all nodes in the graph.
we also select certain state of the art code clone detection tools as our comparative systems including sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper andnil .
all experiments are conducted on a server with intel xeon e5 v3 .50ghz gig bytes memory geforce rtx ti graphics card and ubuntu .
.
lts.
.
.
metrics.
we make use of the following widely used metrics to measure the detection performance of gitor .
precision is defined asp tp tp fp .
recall is defined as r tp tp fn .
f1 is defined asf1 p r p r .
among them true positive tp represents the number of samples correctly classified as clone pairs false positive fp represents the number of samples incorrectly classified as clone pairs and false negative fn represents the number of samples incorrectly classified as non clone pairs.
.
rq1 effectiveness of gitor used alone to examine the capability of gitor on clode clone detection we conduct experiments from two perspectives one is testing the performance of gitor alone and another is testing the performance of gitor combined with other individual features based methods.
in this part we focus on checking the ability of gitor alone.
specifically we select different cosine similarity thresholds i.e.
.
.
and .
and different dimensions i.e.
and of node embedding vectors to commence our evaluations.
the results are illustrated in table including the recall precision and f1 scores of our experiment on bigclonebench dataset.
as for the measurement of precision similar to other previous works we randomly sample clone pairs from clone reports in each tool and conduct manual analysis to validate them.
each clone pair is checked independently by two experts.
if there is a conflict a final decision will be made after discussion with another expert.
the principle rule for judging is based on the overall similarity between the two clone fragments and on whether they perform similar functionality.
through the results in table we find several interesting phenomena.
first when the similarity threshold is different the detection performance of gitor is also different.
basically the larger the threshold the higher the precision but the lower the recall.
it is reasonable because the larger the threshold the higher the similarity of the detected clones and the higher the similarity is the greater the probability of clones.
but at the same time some pairs whose similarity is slightly lower than the threshold will be filtered out resulting in lower recall.
second when the vector dimensions are different the detection performance of gitor is also different.
this is normal because the dimensions of the vectors are different the degree of retention of graph information will also be different.
basically when we combine keywords with side information the larger the dimension of the vector the higher the precision.
third the features obtained when selecting keywords to construct a sample graph are more accurate than when selecting side information.
in other words when using keywords to construct the global graph the precision of gitor is higher than when selecting side information .
this is because keywords represent the key tokens in the programming language these key tokens are not allowed tobe changed and different key tokens describe different program information.
gitor can preserve more program semantics when all keywords are considered.
forth after combining keywords with side information gitor s precision is mostly improved.
it shows that the combination of the two information allows gitor to retain more program semantics.
at this time when the vector dimension is the average f1 under the three thresholds i.e.
.
.
and .
is the highest.
based on the above findings we suggest that if researchers want to detect more clones they can set the threshold to .
when using gitor with keywords andside information .
in addition if researcher like to detect clones with higher accuracy they can set the threshold to a higher value such as .
or .
.
table detection performance of individual features based detectors methodindividual features based detector doc2vec w2v avg code2vec type recall type recall .
vst recall .
.
.
st recall .
.
.
mt recall .
.
.
type recall .
.
.
precision .
.
.
f1 .
.
.
table detection performance of individual features based detectors combined with gitor methodwith gitor ours doc2vec w2v avg code2vec type recall type recall vst recall .
.
.
st recall .
.
.
mt recall .
.
.
type recall .
.
.
precision .
.
.
f1 .
.
.
.
rq2 combination with other individual features based methods in this part we pay attention to the effectiveness when gitor is combined with other detection methods.
since our system is purely based on global features we first want to explore how would it contribute to current individual features based detection methods.
in order to check the effectiveness of detection using the combination of global features and individual features we pick several widely used methods which have been proved effective on clonegitor scalable code clone detection by building global sample graph esec fse december san francisco ca usa table detection performance of sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper nil and gitor on detecting different types of code clones.
tool sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper nil gitor type recall .
.
.
type recall .
.
.
.
.
.
.
.
very strongly type recall .
.
.
.
.
.
.
.
strongly type recall .
.
.
.
.
.
.
.
.
moderately type recall .
.
.
.
.
.
.
.
.
type recall .
.
.
precision .
.
.
.
.
.
.
.
.
detection then we test the effectiveness when they are combined with gitor .
in this experiment we choose doc2vec word2vec and code2vec as the individual features based detection methods .
we define the average vectors of word2vec as w2v avg and the doc2vec extends the word vectors to entire document vectors.
the code2vec can embed the entire code sample into a single vector.
we choose cosine similarity as the similarity metric in this part of experiments and we use the default parameters for doc2vec word2vec and code2vec.
to evaluate the detection performance of these three methods we test them on the bigclonebench dataset.
we use three methods to get the embeddings of all code samples and compare the cosine similarity to detect possible clone pairs where we set the similarity threshold as .
and embedding dimension as since these tools reach their best performance under this setting .
table shows the detection results including recall precision and f1 score on the bigclonebench dataset.
then we combine the vectors generated by the above methods with gitor generated vectors and conduct the similarity comparison on the bigcodebench dataset where the similarity threshold is set to .
as well and the dimension of gitor is since gitor performs the best with dimension as when the similarity threshold set to .
.
the results are illustrated in table where we can see that the overall detection performance including recall precision and f1 score is significantly improved compared to the original results so it suggests that gitor can boost the effectiveness of other individual features based detection methods.
in short the gitor is not only effective when used alone but also able to boost the performance of other individual features based detection methods.
.
rq3 comparative with other detectors in order to evaluate gitor s performance comprehensively we compare the performance of gitor s clone detection against the latest versions of several publicly available clone detection tools such as sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper and nil .
since most of traditional code clone detection tools e.g.
sourcerercc and nicad select .
as their thresholds to identify code clones we also choose .
as the threshold to commence our comparative evaluations.
through the results in table we observe that gitor can maintain the best overall performance i.e.
f1 when the dimension of node embedding vectors is .
therefore we use thecorresponding detection results as the comparative performance ofgitor sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper and nil where the recall numbers are summarized per clone category.
as table shows gitor outperforms every other tool on most of the clone categories except for st3.
although nicad performs the best on st3 gitor s performance on st3 clone is still quite comparable to the state of art since there is only a percent difference.
the recall results are promising since they suggest that in addition to recognizing easier to find clones like t1 t2 and vst3 gitor also detects clones that other tools miss.
in comparison to other methods where oreo s highest recall is .
.
recall in the mt3 category is a significant improvement.
table also shows the precision results of all tools.
the precision of gitor is .
and only sourcerercc and nicard perform marginally better than gitor by percent .
the recall and precision experiments show that gitor is a reliable and accurate clone detector that can detect type type and type clones efficiently and detect part of type clones.
to address this issue in the future we will improve gitor with better chosen individual information to detect type clones more effectively.
.
rq4 scalability in this section we pay attention on the runtime performance of gitor .
as mentioned before scalability is an important requirement for clone detection methods and gitor is designed as a scalable clone detection system.
so we will evaluate the efficiency and demonstrate the scalability of gitor in two parts training efficiency and classification efficiency.
dataset for scalability experiments we use the whole dataset of bigclonebench i.e.
ijadataset which is a widely used dataset containing about million lines of java source code mined from sourceforge and google code.
the full ijadataset and its subsets are often used for evaluating execution time and scalability of clone detection tools .
we test gitor using inputs with different sizes generated from this dataset.
different sizes for scalability experiments execution time primarily depends on the size of the input in terms of the number of lines of code loc needed to be processed and classified by the system.
so we build the inputs with varying convenient sizes i.e.
1k 10k 100k 1m 10m and 100m loc by randomly selecting samples from ijadataset.
results the execution is finished on a machine with intel xeon e5 v3 .50ghz cores cpu 32gb of memory geforceesec fse december san francisco ca usa junjie shan shihan dou yueming wu hairu wu and yang liu table runtime performance of sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper nil and gitor .
loc sourcerercc ccfinder nicad deckard ccaligner oreo lvmapper nil gitor 1k 3s 2s 1s 1s 1s 1s 1s 1s .03s 10k 5s 5s 2s 4s 2s 3s .18s 100k 7s 10s 5s 32s 3s 6s .26s 1m 37s 39s 12s 27m12s 11m52s 4m34s 29s 10s .10s 10m 12m21s 6m30s 19m49s killed 29m48s 36m6s 13m 38s 1m 38s 2m11s 100m 12h27m 9h49m killed killed 1d13h46m 17h 23m 39s 1h 38m 29s 1h7min killed means the tool fails to parse the code or report out of memory errors means no such data in previous study rtx ti graphics card and system is ubuntu .
.
lts.
for gitor it mainly consists of two phases the first it to apply node embedding to extract all functions vectors and then these vectors will be used to compute cosine similarity one by one.
in practice it takes little time to complete the first phase i.e.
minutes for 100m loc .
however when the code size becomes large the number of functions will also be large resulting in a massive number of code pairs to be analyzed.
to mitigate the issue we adopt matrix computation to calculate the similarity of all code pairs where gpu is used to accelerate the computation process.
the runtime of gitor is the total time of two phases included.
the runtime performance of all the above tools and corresponding loc are listed in table which shows that gitor outperforms the seven state of the art clone detection tools in all sizes of inputs while gitor is a bit slower than nilin 1mloc and 10mloc size but gitor is still more efficient than the state of the art detector nilwhen it comes to larger size 100mloc in this case.
in conclusion gitor is eight times faster than the token based detection tool ccfinder with the input size of million loc which means it is highly scalable.
.
summarization our experimental results demonstrate gitor s effectiveness as a code clone detection method.
it achieves optimal accuracy using a combination of keyword and side information features rq1 .
gitor improves the performance of individual feature based detectors when used jointly rq2 .
in comparative evaluations gitor attains higher recall than eight state of the art tools on the bigclonebench dataset with precision comparable to top techniques rq3 .
moreover gitor analyzes million lines of code efficiently in just hour and is the fastest tool on large code bases running 100x faster than ccfinder rq4 .
in summary through extensive evaluations our results consistently highlight gitor s strengths in terms of effectiveness enhancement capability superior accuracy over current methods and scalability to large code bases.
discussion why gitor outperforms the other approaches .
first currently existing clone detection tools e.g.
ccfinder and sourcerercc focus on analyzing code samples individually without considering the underlying connection among code samples.
however gitor considers the connection among different code samples byextracting the individual information of a code sample as its representation and the extracted individual information is used to build a global graph to represent the whole code base which preserves the underlying connections of all code samples.
why not compare with deep learning based methods .
first of all gitor is not a deep learning based method and the experiment we conduct in section .
is only used to prove that gitor can boost the performance of other detection methods which does not suggest that gitor is a deep learning based.
second deep learning based methods require training a detector on large labeled datasets which is time consuming and limits the practicability and scalability of deep learning based clone detectors.
in contrast gitor does not require time consuming training on large labeled datasets making it more practical for use in real world applications.
future work .
the embedding process of gitor is very efficient since we make use of prone however the code clone classification process is quite time consuming due to its o n2 complexity to get all clones detected.
in future work we consider techniques like filtering to improve our classification speed by filtering most of the unlikely code pairs according to the properties of the sample itself such as lines of a sample and the number of tokens in a sample.
besides to achieve better detection performance we will explore more types of individual information to represent code samples more properly and more accurately.
related work this section introduces related studies on code clone detection which can be classified into five categories text based methods token based methods tree based methods graph based methods and metrics based methods.
the similarity between two code snippets is measured in the form of text or strings for the text based methods .
proposes a fingerprinting technique for detecting code clones.
develops a language independent method for detecting similar codes using only line based string matching.
these two techniques however do not support type clone detection.
to detect more types of clones nicad introduces a two stage approach that consists of i identifying and normalizing potential clones using flexible pretty printing and ii computing similarity by simply text line comparison using the longest common subsequence algorithm.
although nicad can detect a number of type clones it cannot detect type clones because it ignores the program semantics of given code samples.gitor scalable code clone detection by building global sample graph esec fse december san francisco ca usa for the token based techniques tokens are first collected from program code by lexical analysis.
ccfinder extracts a token sequence from the input code and converts it into a regular form for finding type and type clones using numerous rule based transformations and sourcerercc has been developed to support type clone detection which is designed to capture the tokens overlap similarity among multiple approaches for detecting type clones that are close to being detected.
sourcerercc is the most scalable code clone detector capable of detecting million lines of code.
however token based detection methods like text based approaches are unable to handle type clones.
to detect code clones the tree based tools employ abstract syntax tree ast as the code representation.
deckard s core idea is to compute characteristic vectors within asts and use locality sensitive hashing lsh to cluster comparable vectors for clone detection.
cdlh first converts asts to binary trees then uses tree lstm to encode these trees into vector representations.
finally these vectors are utilized to compare distinct codes similarity.
astnn separates each huge ast into a sequence of little statement trees unlike cdlh .
to find semantic code clones after encoding these statement trees into vectors a bidirectional rnn model is utilized to construct the final vector representation of a code fragment.
these tree based methods can detect semantic clones but their scalability is limited due to their long execution times.
for the graph based methods program semantics are first distilled into multiple graph representations such as program dependency graph and control flow graph.
and both extract program dependency graphs from code fragments and locate similar codes by excavating isomorphic subgraphs to represent code clones.
ccsharp employs two strategies to reduce the overall processing cost of and graph structure modification and characteristic vector filtering.
however due to the complexity of graph isomorphism and the heavy weight time consumption of graph matching it still has low scalability on largescale code clone detection.
metrics can be obtained from tree or graph representations of source code or straight from source code for the metrics based techniques .
both and use metrics extracted from the ast to describe the source code and to identify code clones.
in addition detects clones using a variety of metrics collected from source code e.g.
classes coupling and hierarchical organization .
these approaches use code features to determine how similar two code fragments are in terms of semantics.
conclusion in this paper we propose gitor to achieve scalable code clone detection.
given a source code base we first generate a global graph representing the whole code base and then apply graph embedding to extract the vectors of all code samples in the code base.
finally the code sample vectors can be simply used to compute the similarity of different code sample.
we evaluate gitor on a widely used dataset and compare gitor with other widely used code clone detection methods.
the results show that gitor is superior to sourcerercc ccfinder nicad deckard ccaligner and oreo on both effectiveness and scalability.
moreover gitor requires only about one hour to analyze million lines of code and is the most scalable among our comparative tools.
data availability our data are available on our website