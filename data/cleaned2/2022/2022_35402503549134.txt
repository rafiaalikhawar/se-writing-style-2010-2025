avgust automating usage based testgeneration from videosofappexecutions yixue zhao yixuezhao cs.umass.edu universityof massachusetts amherst usasaghar talebipour talebipo usc.edu universityof southerncalifornia usakesina baral kbaral4 gmu.edu georgemason university usa hyojaepark hyoj.p20 gmail.com sharon highschool usaleonyee leon.yee000 gmail.com valley christian highschool usasafwatali khan skhan89 gmu.edu georgemason university usa yuriy brun brun cs.umass.edu universityof massachusetts amherst usanenad medvidovi neno usc.edu universityof southerncalifornia usakevinmoran kpmoran gmu.edu georgemason university usa abstract writingandmaintaininguitestsformobileappsisatime consuming and tedious task.
while decades of research have producedautomatedapproachesforuitestgeneration theseapproachestypically focuson testing forcrashesor maximizing code coverage.by contrast recentresearchhasshownthatdevelopersprefer usage based tests which center around specific uses of app features to help supportactivitiessuchasregressiontesting.veryfewexistingtechniques support the generation of such tests as so requires automating the difficulttask of understanding thesemantics of ui screensanduserinputs.inthispaper weintroduce avgust which automates key steps of generating usage based tests.
avgustuses neuralmodelsforimageunderstandingtoprocessvideorecordings of app uses to synthesize an app agnostic state machine encoding ofthoseuses.then avgustusesthisencodingtosynthesizetest casesforanewtargetapp.weevaluate avguston374videosof common uses of popular apps and show that of the tests avgustgenerates successfully execute the desired usage and that avgust sclassifiers outperform the state ofthe art.
ccs concepts software and its engineering software notations and tools.
keywords testgeneration uiunderstanding ai ml mobile application bothauthorscontributed equally to the paper permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
esec fse november 14 18 singapore singapore associationfor computing machinery.
acm isbn ... .
format yixuezhao saghartalebipour kesinabaral hyojaepark leonyee safwat ali khan yuriy brun nenad medvidovi and kevin moran.
.
avgust automatingusage basedtestgenerationfromvideosofappexecutions.in proceedingsofthe30thacmjointeuropeansoftwareengineeringconference andsymposiumonthefoundationsofsoftwareengineering esec fse november 14 18 singapore singapore.
acm new york ny usa 13pages.
introduction writing ui tests is time consuming and tedious.
the research communityhascontributedalargebodyofworkthataimstoautomaticallygenerateuitests .such testingtechniquesgenerateatest sinputs anduseapre defined criterionasthetest soracle.asignificantportionofrecentwork on ui test generation has focused on mobile platforms and has predominantly aimedto discover crashesor maximize code coverage .
however studies have repeatedly found thatexistingtestingtechniquesinthisdomainfallshortinaddressing developers needs in practice or present challenges for practical adoption .
specifically mobile developers have a strong preference for test cases that are closely coupled to app use cases or features .
in line with recent work we refer to this type of preferred test case as usage based ui test.
a usage based ui test consists of a sequence of ui events that mimic realisticuser behaviors in exercisingaspecificfeatureofagivenapp suchas addinganitem to the shopping cart.
the developer preference for usage based testsisduetothefactthatsuchtestcasessupportspecifictesting goals in practice such as regression or performance testing which inturnrequire orientationto common app use cases .
automating such testing activities is critical for mobile developers who face unique challenges relatedto rapidly evolving platforms pressure for frequent releases and a deluge offeaturerequestsandbugreportsfromuserreviews .
despitetheimportanceoftheseusage basedtestsfordevelopers current automated testing approaches typically do not consider esec fse november14 18 singapore singapore y. zhao s.talebipour k.baral h.park l.yee s.khan y. brun n.medvidovic andk.moran appusagesasagoalortestadequacycriteria andassuchcannot generatethesetests .
a growing body of research on the topic of ui test reuse also sometimescalledtestmigration testtransfer ortestadaption hasbeguntoexplorethepossibilityofautomating the transfer and adaptation of existing usage based tests from a source app to a behaviorally similar target app that contains shared features .
however these test reuse techniqueshave threenotablelimitations thatposechallenges for developers to adopt in practice.
1to generate tests for a target app ui test reuse requires pre existing manually written tests for a correspondingsourceapp.inpractice creatingthesesourcetestsis time consuming and error prone leading many mobile developers to forgo writing them .2test reuse techniques have typicallybeendesignedfor andtaskedwith transferringtestsbetween behaviorally similar applications from similar domains e.g.
betweentwofinanceortwoshoppingapps .however therearemany use cases common across apps from varying domains e.g.
logging in or changing the theme which current test techniques would struggle to effectively transfer.
3many existing techniques rely onexpensiveanddifficulttouseprogramanalyses e.g.
bytecode decompilers soot gator that often require access to an app s source code.
the ease of use and scalability limitations of such underlying utilities have hindered the adoption of test case transfer toolsinpractice.
tohelpbetteralignautomationrelatedtousage basedtesting with developers needs we propose avgust a technique for appvideo based generationof usagetests.avgustisanoveldeveloperin the loop test generation technique that directly addresses the three limitations mentioned above.
1instead of requiring preexisting source tests written by domain experts avgustallows for easy creation of source test scenarios through screen recordings of app usages which are becomingincreasingly commonsoftware artifacts for mobile apps and can be easily obtained via crowd workerswithnotestingexpertise.aftervideocollectionandprocessing avgustoperatesaccordingtotwomainphases.inthefirst phase neuralcomputervision cv andnaturallanguageprocessing nlp techniquesareemployedtoguidedevelopersthroughalightweight screen and gui widget annotation process for video frames that were automatically identified to contain a touch action.
using thisinformation avgustisabletogenerateanapp independent intermediate representationmodel irmodel whichrepresentsabstractstatesandtransitionsofausagethatcanbemappedtomultipleapps.thisprocedureisaone timeeffortfordevelopers andonce theirmodelisgenerated itcanbeusedtogeneratetestsformultipletargetapps.
2thegeneralityoftheirmodelallows avgustto synthesizetestscenariosacrossdomains effectivelyovercomingthe secondlimitationofexistingtest casetransfertechniques.
avgust s second phase automates the synthesis of new ui test scenarios by guidingadeveloperwithsuggestions madebyusingpredictions fromavgust s cv and nlp techniques of which gui elements mustbemanipulatedtoexerciseagivenappfeatureorusage.
3to bolstertheapplicabilityandpracticalityof avgustfromadeveloper sperspective avgustoperatespurelyonvisualinformation encodedintoscreenshotsandvideoframesfromui screenrecordings.assuch itdoesnotrequireaccesstoanapp ssourcecode instrumentation orexpensiveprogramanalyses.notethatsolelyrelying onappvideosasinputisakeyaspectof avgust snoveltyandit hasthreemajoradvantages.first videosarecommonartifactsthat are easily collectible withoutrequiring difficult toolconfiguration andsetup whicharemajorbarriersforadoption .second videos can be collected by crowd workers e.g.
real users with no testingexperience enablingtheopportunityto obtainmuchmore trainingdatatocoverdiverseandrealisticusagescenariosacross different apps.
this can yield more generalized models to generate higher quality tests.
finally videos are agnostic to the underlying device and platform meaning avgust s design is not tied to androidplatforms where avgustisevaluatedon butisapplicable to any apps devices andplatforms e.g.
websites inprinciple.
thekeyresearchchallengethat avgusttacklesistheautomated synthesisofageneralizedmodeloffeatureusagesthatcaneffectively map test scenarios across apps from a variety of domains usingonlyscreenshotsandvideoframesfromscreenrecordings.
thechallengeliesinautomatingtwokeytasks screenunderstandingfrompixelsand designofanirmodelthatisgeneral enough to capture diverseapp usages yet specific enough to allow mapping actions to a given target app for test scenario generation.avgustaccomplishes the first task through the creation of abespokeimageclassificationtechnique builtontopofaneural auto encoderrepresentation andbert basedtextualembeddings .
the classification operates at twogranularity levels i screen level and ii guiwidget level.thisclassificationprocedure helps to provide the mapping to our ir model and makes use of arichscreen representationobtained by training our neuralautoencoder on the public rico dataset .avgustaccomplishes the second task by using the information from our classifiers to buildastatemachinecapableofsimultaneouslycapturingmultiple scenariosfromdifferentusages.thisyieldsarichermodelofapp usage thanpasttest transfer techniques.
in order to build a community resource of usage based tests we conducted a user study to collect video recordings from apps covering usage scenarios wherein each usage scenario isexercisedbythreeassociatedapps foratotalof54uniqueappusage pairs .
using this data we conducted an empirical evaluation to measure the efficacy of avgustin generating usagebased tests that closely mirror those created by humans during our user study.
first we examined avgust s test generation capability bysimulatingadeveloperinteractingwith avgust ssuggestions andmeasuredhowcloselygeneratedtestsmatchedanalogoustests created by human users.
next to gain a better understanding of avgust s performance during test generation we evaluated avgust sclassifierscomparedtostate of the arttechniques.ourresults show that avgustis able to generate tests that effectively exercisetarget appfeaturesandcloselymatchhumantestsinterms ofthescreensvisitedandactionsperformed.additionally avgust s classifiers significantly outperform state of the art techniques and showpromisingperformancefor our generated developer in thelooprecommendations.
we have developed avgustwith open science in mind making it both practical to use for developers and easily reusable by researcherstofosterfutureresearchinthisarea.wemakepublicly 422avgust automatingusage basedtestgenerationfrom videosof app executions esec fse november14 18 singapore singapore availableallofoursourcecode trainedmodels andannotatedevaluationdatacollectedduringouruserstudy .avgust spipeline can be easily adapted to create various usage models of interest bysimply changing the inputvideos such as includingadditional usagesandapps.assuch avgustnotonlylaysafoundationfor futureworkonusage basedtestgeneration butalsorepresentsa living repository for the software engineering community to study relatedproblems.
in summary this paper makesthe following contributions we introduce avgust the firsttechnique capable of generatingusage based tests bylearningfrom app videos.
we develop a novel image classificationtechnique to translate app videos into an app independent intermediate representationbasedonvision onlyinformation whichlargely outperforms the state of the art.
weimplementareusablepipelinetotrainirmodelsbased on app videos that can be applied to various downstream tasks andfurtherprovide125pre trainedmodelsthatcan be usedbydevelopers directly.
we collect app videos and conduct an empirical evaluation to demonstrate avgust s effectiveness in assisting developers withgeneratingusage basedtests.
we provide a public repository that contains avgust s artifactstofosterfutureresearch including avgust ssource code our pre trained models labeled datasets benchmarks used andtheircorresponding results.
the avgust approach avgustis an automated approach that aims to assist developers withthegenerationofusage basedteststomimicrealisticusage scenarios.
avgustoperatesinthreephases.
itprocessesrecorded videos of different apps usages by applying neural cv and nlp to detect user actions in individual video frames.
avgustuses this information to generate anapp independent statemachine based irmodel.
finally avgustleveragestheirmodeltogenerate tests for a new i.e.
target app.
in this section we provide an overviewof avgust sworkflow andthen detailits three phases.
.1avgustoverview avgustfunctionsasahuman in the looptooltoprovidesuggestions of input events for developers in the creation of usage based tests.thisdesigndecisionisguidedbythenatureof usage based tests sinceeachusage scenario may have various correctways of being tested.
for instance there may be different ways toexecute the login scenario in an app such as logging in using username and password or by using user s existing social media accounts.
thus providing suggestions to a developer allows for flexibility in generatingtests thatare tailoredto agivenappusageand testing objective.figure 1depictsavgust sworkflow whichconsistsof threeprincipalphases 1videocollection analysis 2irmodel generation and 3guided test scenariogeneration .
during the video collection analysis phase crowdsourced workers are tasked with collecting videos of app usages.
these videosarethenanalyzedinafullyautomatedprocessthatinvolves deconstructingthevideointoconstituentframes identifyingtouchbasedactionsthatwereperformedontheanapp sui whichbuildsuponpastwork in app videoanalysis andeliminating sensitive information such as userpasswords.
next in the ir model generation phase avgustassists a developer with labeling screens and individual gui widgets from processedvideoframesintocategories which avgustcanthenuse togenerateanapp independentirmodel.thisisasemi automated processwhereinadeveloperispresentedwithascreenand avgust provides top k suggestions for the labels that should be applied to both screens an exercised gui widgets.
these suggestions are made using a combination of visual and text based classifiers that operateuponthevideoframesextractedinthepriorphase.after the labels have been applied by the developer avgustis able to automaticallygeneratethestatemachine basedirmodelforthe usage merging it with other similar usages in a shared database.
thisphaseisintendedtobeaone timecost whereindevelopers contribute their crowdsourced ir models of various app usages to acollective community databasefor future use.
finally in the guided test scenario generation phase avgust assists developers by providing top k recommendations for actions thatshouldbe performedongiven screens of a previously unseen targetapp inordertoexercise aspecifiedappfeature e.g.
adding anitemtotheshoppingcart .thisprocessstartsfromtheinitial screenoftheappandrunsuntilthespecifiedfeatureisexercised.
thisfunctionssimilarlytotheirmodelgenerationphase butin reverse order the model is used in conjunction with avgust s classification techniques to recommend event inputs to developers.
.
video collection analysis givenasetofcollectedvideosofappusages avgust svideoanalysis processes them into frames that serve as the inputs for avgust ai assisted ir model generation section .
.
specifically avgust firstidentifiestheuseractionsinthevideosandextractstheircorresponding eventframes whicharethekeyvideoframesthatcapture the user interactions via the touch indicator .1an example of event frame is shown in figure where the touch indicator points to the user interacting with the app menu button in the top left corner.asafinalstep avgustfilterstheextractedeventframesby eliminating the framesthat contain sensitive userinformation.
.
.
actionidentification eventframeextraction.
avgustbuilds upon the analyses introduced by v2s to identify user actions and event frames.
v2s is a recent technique that leverages neuralobjectdetectionandimageclassificationtoidentifytheuser actions in a video and automatically translates these actions into a replayablescenario.weextendedv2stoworkwithgpuclusters to enable it to process large numbers of videos in parallel.
the outputs of our extended video processing technique are a sequence ofeventframes ofagivenvideoandtheirassociateduseractions i.e.
click long tap and swipe and the coordinates of the touch indicator ineacheventframe .
.
.
event frame filtering.
avgustfilters the extracted event framesbyeliminatingtheframesthatareassociatedwiththe typing action sincetheymayexposeuser sprivateinformationsuchas password.
note that avgustonly eliminates the frames where the 1avgustrequiresenablingthedisplayofthe touchindicator whichcaneasilybedone in both the android and ios settings menus even by inexperienced users.
423esec fse november14 18 singapore singapore y. zhao s.talebipour k.baral h.park l.yee s.khan y. brun n.medvidovic andk.moran crowd testers videos of app usages video collection analysis1 video processing action parsing keyboard detectionir model generation input video frames car data entry password item entry screen developer ir refinement community database of ir modelsguided test scenario generation3 running target app car data entry password item entry screen assisted input generation usagebased scenario ir models ir model database ir model image features textual features ir classifier image features textual features ir classifier figure avgust sthree phase workflow.
usertypesthetextcontentonakeyboard butstillkeepstheframes where the user selects which input field she intends to enter the text content.
for example the sequence of video frames related to typinguserpassword consistsof aframeassociatedwith clickingthepasswordfield and agroupofconsecutiveframes associatedwithtypingeachindividualcharacterinthepassword.
avgustonly eliminates the latter while maintaining the former to represent typing userpassword action inthe usage scenario.
todosoautomatically wetrainedabinaryimageclassifierto recognize whether an event frame contains a keyboard image.
our classifierisbasedonacnnarchitecturewith4blocks eachconsisting of a convolution a batchnorm a relu and a dropout layer .
the cnnis trained on cropped screenshots that depict the area of the screen where keyboard may appear since this area is standard for mobile devices as shown in figure .
we decided to focusontheregionofthescreenwherethekeyboardappears as opposed to the entirety of the screen based on empirical evidence collected while tuning our classifier as the former setting dramatically improved the classifier s accuracy.
we sourced non keyboard training data by randomly selecting app screenshots without the keyboard from the publicly available rico dataset .
the non keyboardtrainingdatadonotcontainanysubjectappsused in our evaluation.
becausescreens thatdisplay a keyboardcannot be automatically identified using the gui metadata provided in the ricodataset weadditionallysourced5 keyboard trainingdata images from the video frames in the dataset collected for avgust s evaluation.
our training data relies on standard android keyboard images but can be easily extendedto additionalkeyboardtypes.
next thecroppedscreenregionwhereakeyboardmayappear foreacheventframeisfedtothetrainedkeyboardclassifier and willbeclassifiedaseithera keyboard ornon keyboard frame.for thekeyboardframes avgustfurtherverifieswhethertheassociated action is typing based on whether the touch indicator falls in the keyboard region.
this is determined by the touch indicator s coordinatesonthescreen whichareobtainedfromv2s.inthe end the eventframesthat contain atyping action are eliminated.
figure2 examplesofthetrainingdatausedin avgust skeyboard classifierduringtheeventframefiltering.note that this frame filtering process not only addresses the privacyissueasdiscussedearlier italsolargelyreducesthenumber ofeventframesusedtorepresentanapp susage.forexample atwominute sign in video from the app 6pm contained over video framesoriginally butonly8 filteredeventframes.these8frames are sufficient to represent all relevant user actions without the duplicated or privacy exposing frames in the original video frames.
.
ai assisted irmodel generation avgustuses the filtered event frames from the previous phase asinputsandtranslatesthemintoapp independentirmodelsof appusages.thekeytechnicalchallengeinthisphasestemsfrom avgust s use of video inputs which forces us to rely solely on visual information encoded into the pixels of the video frames.
we addressthischallengeintwosteps webreakdowneventframes intoguieventsand useimageclassificationtechniquestoassist developers in translating gui events to their corresponding ir models.
asan illustration figure 3demonstrates thekey artifacts in this process using a single event frame extracted from a popular shoppingapp 6pm as an example.we nowdetailthesetwosteps.
.
.
transformingeventframestoguievents.
wedefinea gui eventas a triple s w a wheresis the app screen that shows a snapshot of the app s execution state wis the gui widget the user interactswith and aisthecorrespondingactiontheuserperforms suchasclickorswipe.theguiwidget wisoptionalsincecertain actions e.g.
swipe arenotassociatedwithanywidgets.
avgust converts event frames into gui event triples in a two step process widgetextractionandaction identification.
widget extraction.
extractingindividualwidgetsfromascreen presentstwomajorchallenges.first eachwidget sboundingbox mustbeidentifiedwithoutrelianceonsourcecode levelinformationthatisavailableonplatformslikeandroid .second avgust event frame screen home ......widget menu action click screen s widget w gui event s w a click action astate1transition1 ir modelstate2 figure an example of converting a 6pm s event frame into aguieventtriple and an app independent ir model.
424avgust automatingusage basedtestgenerationfrom videosof app executions esec fse november14 18 singapore singapore needstoisolatethepreciseboundingboxofthewidgetwithwhich the user is interacting such as the app menu button in the top left corner ofthe screen infigure .
to detect the bounding boxes of gui widgets we modified uied astate of the arttoolthatcombinesunsupervised cv and deep learning and applied it on the screens extracted from avgust s previous phase.
given an input screen uied detects textualandvisualguielementsandproducestheirboundingboxes as depicted with solid rectangles in figure .
however uied treats each visual and textual gui element separately which can lose importantsemanticinformation.forexample ifthetouchindicator referstoacheckbox thecorrespondingguielementdetectedby uiedinfigure 4wouldbeoneofthetwocheckboxesonly leaving unclear whether the extracted widget is intended to be associated with showpassword or keepme signedin .
figure4 avgustadjusts the gui element bounding boxes detected by uied depicted by the twodashed rectangles.to remedy this we modified uied to group the visual gui elements together with their surroundingtextualelements ifany.
avgustiterates through all visualelementsdetectedbyuied and identifies their closest gui elements.
if the closest gui element is both a textual element andisinthesamelineasthevisual element defined as being vertically collocated based on a customizablethreshold thenthe bounding box of the visual elementwillbeupdatedtoinclude the textual element as well.
in figure4 this results in the two checkboxesbeinggroupedwith their corresponding labels as depictedbythe dashedrectangles.
next the detected gui elements bounding boxes are used byavgusttoautomaticallycrop out the widget wto which the touch indicator refers.
avgust combinesthewidgetsdetectedbyitsmodifieduiedwiththecoordinates of the touch indicator obtained from the modified v2s recall section .
to identify all candidate widgets for cropping coveringthreepossiblecases thesimplestcaseiswhenonly one widget s bounding box covers the touch indicator in which caseavgustcrops that widget as is.
if no widgets bounding boxescoverthetouchindicator avgustrepeatedlyexpandseach widget s bounding box based on a customizable threshold until asuitablewidgetisfound.
avgust sdefaultthresholdissetat10 pixels.
when multiple widget candidates are found avgust first eliminates the coarse grained candidates whose boundaries completelycoveranyoftheothercandidates e.g.
sign inform that covers username widget and then selects the widget whose centerpointisclosestto the touch indicator scoordinates.
action identification.
to identify the action ain the gui event triple avgustleveragesv2s sactionidentificationprocedure whichhome menu sign in endmenu click account click sign in clickself email click password click up keep signin click figure the ir model generated from a sign in video collected fromtheapp 6pm.
analyzesthecoordinatesoftouchesdetected inconsecutivevideo framesandclassifiesactionsaccordingtoasetofheuristics .
v2sisabletoidentifyclicks longtaps andswipes.wereusedv2s s heuristicsforclickandlongtap andextendeditsswipe detection heuristicto additionallydetectthe directionof the swipe.
.
.
transformingguieventstoirmodels.
avgust sirmodel generationisadeveloper in the loopprocess.thissectionexplains howavgustprovides recommendations to assist developers in translatingguieventsintotheirapp independentirrepresentations recallthe example infigure .
avgust s ir model is defined as a finite state machine fsm that captures app usages.
figure 5shows an example ir model converted from one of 6pm s sign in videos.
each state in the ir model represents a particular app screen and is captured as an app independent canonical screen while each transition represents a user interaction with a canonical widget and its corresponding action.aself transition e.g.
showninthe sign in stateinfigure5 means that the app stays on the same screen during certain userinteractions.
the key challenge in translating a gui event triple s w a into avgust sir model is toproperly abstract away and capture in an app independent manner the app specific screens sand widgets w. eachaction aintheguieventtripleistranslatedas is including click longtap andswipeup down left right.withthetranslated canonicalscreens canonicalwidgets andactions thefinalirmodel canbeconstructedbyiteratingthroughthesequenceofguievents ofaparticularusage.
we formulate the translation of screens and widgets as a classification problem where app specific screens and widgets are classified into their canonical counterparts categories that are sharedacrossdifferentapps.tothisend webuilduponandextend app independent categories definedby previous work resulting in canonical screens and canonical widgets.
example canonical screens are home screen password assistant page and shoppingcartpage .examplecanonicalwidgetsare account help and buy .thecompletesetsofcanonicalscreensandwidgetsareavailable .notethatthesecategoriesarenotdirectly tiedtooursubjectappsusedintheevaluation butcangeneralize across diverse apps.
to facilitate the extensibility of new canonical screens widgets wehavecreatedadatalabelingtoolusinglabel studio allowing future research to further tailor and improve the canonicalcategoriesfor both screens andwidgets.
we note that our classification problem provides a unique challenge as it relies only on information from app screenshots.
there are no existing techniques in the mobile app domain that have previouslyaddressedthisproblem inacontextsimilar to ours.
moran et.al.
were one of the first to use a cnn for widget classification from gui component images.
however their classifier only functioned on general widget categories.
our 425esec fse november14 18 singapore singapore y. zhao s.talebipour k.baral h.park l.yee s.khan y. brun n.medvidovic andk.moran larger number of categories represents a more challenging classificationproblemthatrequirestheuseofbothtextualandvisual features to achieve reasonable accuracy.
another recent technique for screen classification in this domain is screen2vec s2v which aims to produce embeddings for app screens that can be used for downstream classification tasks such as ours.
however s2v cannot be applied on screenshots alone as it requires the ui layout information of an app screen that is specific to the android platform .
obtaining such information requires extraction using third party tools e.g.
appium uiautomator and would sacrificethe practicalityofusage collection throughvideos.
screen classifier.
to classify a given app screen image into its canonical screen avgustleverages both visual and textual features wherein textual features are extracted from the image using thetesseractocrengine .moreprecisely wemakeuseofa pre trained autoencoder model to encode the screen s visual information anda pre trained bert language model to encode the screen s textual information.
avgustuses a three layer convolutionalautoencoderwithmaxpooling andistaskedwith encoding an image into a high dimensional vector space and then decoding the image vector to reconstruct the original image hence employingaself supervisedtraining process.
as past work has shown learning features or patterns directly from the pixels of ui screens can be difficult due to the variability in gui designs across apps.
therefore to train and use our auto encoder to learn app agnostic visual patterns we re implementedthescreensegmentationapproachintroducedby remaui andusethesegmentstogenerateabstractedversions of screens from the rico dataset .
as illustrated in figure in these abstracted screens text components are transformed into yellowboxesandnon textcomponentsintoblueboxes onablackbackground.wetrained avgust sautoencoderon33 000abstractedimagesfromthericodataset andtoclassifyanincomingscreen we run it through this abstraction process and then through the encoder ofour autoencoder network to extract the feature vector.
avgust sscreenclassifierleverageslinearlayerstocombinethe autoencoderandbertembeddingsandclassifythescreens.the architectureforthescreenclassifierconsistsofthreeblocks each containingalinearlayer batchnorm areluactivationfunction andadropoutlayer.theseblocksarefollowedbyafullyconnected outputlayerthatappliessoftmaxfunctiontopredicttheprobability distribution of different screen classes.
we then train the screen classifier onpartitions of data collected for ourevaluation introduced in section .
where individual classifiers for each app were trained on data sourced from other apps.
this process produced pre trained screen classifiers for each of our subject apps and will be reusedin avgust stest generationphase see section .
.
widgetclassifier.
to classify a given app widget image avgust leveragesitstextual visual contextual type andspatialinformation thewidget stextisextractedfromthewidget simageusing tesseract andthenencodedusingthepre trainedbertmodel the canonical screen of the screen image to which the widget belongs is mapped to an idand transformed into a continuous vector via an embedding layer the visual features of the widget areencodedwiththepre trainedresnetmodel widelyused for encoding images the ui widget class type e.g.
edittext original gui screen abstracted gui screen figure avgust sscreen abstractionprocess.
imagebutton isobtainedusingtheclassificationmethodintroduced byredraw andrefinedbys2v thenmappedbyanembeddinglayerintoacontinuousvector and thewidget slocation onthescreenisobtainedbydividingthescreeninto9zonesand then transformedto acontinuous vector viaan embedding layer.
avgust s widget classifier then adapts a similararchitecture to itsscreenclassifier threeblocksoflinearlayersfollowedbyafully connectedoutputlayerapplying softmax tocombine thedifferent featurevectorsdiscussedabove.notethattheembeddinglayersfor thecanonicalscreen widgetlocation andwidgetclasstypefeatures are optimized duringthetraining phase ofthewidget classifierto generatemeaningfulembeddings for eachof theseinputfeatures.
similarly to the screen classifier avgust s widget classifier is trained on our dataset section .
and produces pre trained models that are reusedin avgust stest generationphase.
avgust s screen and widget classifiers are able to provide the standard top k labels with different confidence levels.
the top k labels are then recommended to developers in labeling the screens andwidgetsand inturn theirmodelsareconstructedusingthe specificlabelsselectedbydevelopers.notethattheirlabelsrefined bydevelopersandthegeneratedirmodelscanbereusedbyfuture work.
we have thus created a database to serve as a living repository for this problem domain as alsodepictedinfigure .
.
guided testscenariogeneration avgustassists developers in generating usage based tests for their target apps by leveraging the ir models described above.
given ausageofinterest avgustselectstherelevantirmodel s from the ir model database recall figure and uses them to guide the test generation.
internally ir models of the same usage are represented as a single merged model where multiple scenarios for a given usage populate the same state machine.
specifically the merged model is constructed by using the union of all the edges from all the ir models of the same usage demonstrating all possible transitions .
a simplified example of the merged ir model for the sign in usage is shown in figure .
this unified modelofscenariosforasingleusagegives avgusttheabilityto generate multiple test scenarios for a target usage on an unseen app.avgust stestscenariogenerationphasehasthreeprincipal components state extractor state matcher and event generator.wefirstdescribethetestgenerationworkflow andthen discuss the three components.
426avgust automatingusage basedtestgenerationfrom videosof app executions esec fse november14 18 singapore singapore starthome get startedmenu shopping cart sign in sign upsign in endsign in with amazon initial initialcart tapmenu tap get started tapmenu bookmark tap menu account tap to sign in sign up tap to sign in sign up tapself password tap keep sign in tap sign in tap ... self password tap keep sign in tap back tapby amazon tap sign in tap figure asimplified example ofthemerged ir modellearned fromthree sign invideosofthe 6pmand etsy apps.
avgust stestscenariogenerationphaseisaniterativeprocess that continues to generate the test inputs based on the target app s currentstate untiltheendconditionismet i.e.
thetargetfeatureis executed .
the process begins by launching the target app and runningavgust sscreenclassifiertoretrievethemostlikelycanonical categoriesofthetargetapp sstartingscreen.
avgustthenpresents thedeveloperwiththesetop kclassificationresults andthecanonical category selected by the developer is used to match the target app s current device screen to the canonical screen states in the ir model.
next avgustrecommends the top k app widgets for developerstointeractwithbyusingitswidgetclassifiertomap the canonical widgets in the ir model to the widgets on the target app s current screen.
avgustthen checks whether the test should complete based on whether the widget chosen by the developer will lead to the end state in the ir model.
if not the chosen widget is triggered the target app s next state becomes its current state and this process repeats until the end state in the unified ir model for agiven usage isreached.
.
.
state extractor.
avgust s state extractor extends recent work on the mapit test case transfer tool.
specifically for a given target app avgustextracts the bitmap of the current screen thegraphrepresentationoftheappscreen suilayout hierarchy and theboundariesofeachuiwidgetandtheir corresponding cropped images.
the ui layout hierarchy is an xml filethatcontainstheinformationofalltheuiwidgetsonthetarget app s current screen such as their position size textual attributes e.g.
sign in and class name e.g.
imagebutton .
the extracted informationisusedby avgusttogeneratetests andalsotoexplore differentvariants of avgust sclassifiers asdiscussed insection .
.
.
state matcher.
as discussed previously avgustuses its screen classifier to suggest the top k candidates for the canonical category of a target app s given screen.
once the developer selects from one of the suggested categories avgustmaps the current screen to the corresponding state in the ir model.
since all possibletransitions capturedin their models are known avgust is able to recommend the target app s widget s with which the developer should interact by using a combination of the widget classifier recallsection .
.
informationobtainedfromthestate extractor recallsection .
.
andasetofpre definedheuristics.
the number of widgets to be recommended by avgustis determined by a configurable threshold.
avgustfirst checks whether the target widgets match the expected canonical widgets from theirmodelbasedonasetofheuristicsthatcanbedividedintotwo categories.
the first category are heuristics that infer a widget s typebasedontheuiclassofitsparentwidget.thisallows avgust to bypass the noise that may be present in the data associated with an individual widget.
for example avgustidentifies a widget that represents a menu item not by trying to capture all possible menu items but much more simply by comparing its parent widget s ui class tolistview.
the second category are heuristics that correlate thetextualdataofawidgetwithsimilartermsassociatedwitheach ofthecanonical widgets e.g.
thetermsfromoursetofcanonical widgets discussedinsection .
.2andtheir synonyms .
iftheheuristicsaloneyieldanumberofrecommendationsbelow the set threshold as the next step avgustwill predict the top classification of the canonical category for each interactive widget on the target app s screen.
if the target app widgets that match the expected canonical widgets in the ir model bring the total number ofmatchedwidgetsabovethethreshold theprocessterminatesand the identified widgets are presented to the developer.
otherwise as the final step the matching criteria are relaxed andthe process switchesfromthetop 1tothetop 5classificationsofeachwidget s canonicalcategory.
.
.
eventgenerator.
withachosenwidget avgustgenerates anexecutableeventtotriggerbasedonwhetherthewidgetrequires user input.
this is determined by the widget type.
for example edittext is a widget type that requires an input from the user such as entering the email address.
in such cases avgustprompts thedeveloperfortextinputs asthesetypicallydonotgeneralize across apps.
if the selected widget does not require user input the eventgeneratorautomaticallyexecutesthetouchevent e.g.
tap swipe storedinthe transitionof the ir model.
this event generation process requires minimal effort from the developerandprovidestheflexibilitytotestthesameusagewith different desired text inputs of the developer s choice.
a test scenario is generated when the end condition is met as discussed earlier andeachtestconsistsofasequenceofeventstriggeredby the eventgenerator.
.5avgust simplementation avgustis implemented in python with sloc of which thescreen andwidgetclassifiersarestand alonemodulestotaling sloc and include the autoencoder model we developed.
avgustadditionally extended several research tools including the modifiedv2s 500slocinpython uied 300slocinpython 427esec fse november14 18 singapore singapore y. zhao s.talebipour k.baral h.park l.yee s.khan y. brun n.medvidovic andk.moran and the re implemented remaui sloc in java .
avgust employs the pytransitions library to manipulate its statemachine ir models and uses the appium testing framework for its test generation.
evaluation of avgust todemonstrate avgust seffectivenessatgeneratingusagetests anditsimprovementonthestateoftheart weanswertworesearch questions rq1how effective is avgustat generating tests that exercise the desiredusage?
rq2how accurate are avgust s vision only screen and widgetclassifiers?
.
evaluationcontext to evaluate avgustas a whole app videos are needed as its input.
tocollectthesevideos wereliedontheappsandusagesdefined bythefruiterbenchmark whichcontains20popularapps and18most commonappusages.wethendesignedauserstudy to collect screen recordings of these app usages which resulted in the collection of videos.
to evaluate avgust s image classification component we developed a semi automated pipeline to annotatethevideoframesofscreenrecordingscollectedbyusers withground truthcanonicalcategoriesforbothscreensandgui widgets.this processisdetailedinsection .
.
.
.
.
video collection.
we designed a large scale user study to collect videos of app usages from participants.
we recruited and assignedthe18usagesand20appsto61computersciencestudents inamaster slevelcourseattheauthors institution andaskedthem torecordvideosofthemselvesexercisingscenariosthattriggered thefeaturesassociatedwiththeusages.weassignedusagessuch thateachstudentwasassigned2applications eachwith2different usages for a combination of app usage pairs.
we balanced the assignedappsandusagesevenlyacrossparticipants.wethenasked them to collect two screen recording videos for each app usage pair fora potential totalof8videosperparticipant.weaskedfor twovideos per app usage pair in order to capture different ways of exercisingagivenfeature e.g.
addinganitemtoashoppingcart table the 18usages used in avgust sevaluation.
usage id test casename tested functionalities videos u1 sign in provide username and password tosign in u2 sign up provide required information tosign up u3 search usesearchbar tosearcha product news u4 detail findand open details of the first searchresult item u5 category findfirst categoryand open browsingpage forit u6 about findand open about information of the app u7 account findand open accountmanagement page u8 help findand open help page of the app u9 menu findand open primaryappmenu u10 contact findand open contactpage of the app u11 terms findand open legal information of the app u12 addcart add the first searchresult itemtocart u13 removecart open cart and removethe first itemfrom cart u14 address add a newaddresstothe account u15 filter filter sortsearchresults u16 addbookmark add first searchresult itemtothe bookmark u17 removebookmark open the bookmark and removefirst itemfrom it u18 textsize change text size 23by searching vs. by browsing categories .
however if a participant deemed that there were not two distinct scenarios for exercising a given feature they were allowedto provideonly one usage.
this studywasconductedremotelydue tocovid andparticipants were given detailed instructions for installing and setting up an android emulator nexus 5x api24 the .apkfiles required to install their assigned apps and a short textual description of the assigned use cases illustrated in table .
additionally we providedasmalldesktopapplicationthatallowedparticipantsto record the screens and a usage trace of their scenarios.
this application makes use of the adb screenrecord and linux getevent command line utilities.
we provide these instructions the app .apk files usage descriptions device recording tool and anonymized collecteddatainouronlineappendix .thisstudywasapproved bythe institutionalreviewboard irb attheauthors university irbnet .
thisdatacollectionprocessspannedtwosemesters andintotal 31oftheoriginallyrecruited61studentscompletedthestudy some with partial data hence the imbalance of videos across apps and usagesshownintables 1and2.intheend weobtainedadataset of374screenrecordingsof18usagesfrom18ofthe20apps shown intable2 from the fruiter benchmark discussedearlier.
.
.
ground truth annotation.
recall from section 2thatavgust s classification involves the screen classifier that maps an app screen to an abstract screen ir category and the widget classifierthatmapsacroppedwidgetimagetoanapp independent canonicalwidgetcategory.toestablishtheground truthlabels i.e.
the correct categories needed to generate avgust s ir models wedevelopedapipelinetoimportpairsofscreen widgetimages into label studio and trained four human annotators to label the data.
specifically the screen widget image pairs are sourced from thegui event frames thatavgustconverted during its video analysisphase recallfigure .
toestablishourgroundtruthcategorizations weprovideddetailedinstructionstoandtrainedthefourannotatorstolabelthe data based on the screen and widget canonical categories wedefined recallsection .
.
.eachimageislabeledbyatleast twoannotators anddiscrepanciesareresolvedbynegotiatedagreement withthe annotators andone author.
table the 18subject appsused in avgust sevaluation.
appid appname downloads mil videos a1 aliexpress a2 ebay a3 etsy a4 dailyhunt .
a5 geek a6 groupon a7 home a8 6pm .
a9 wish a10 the guardian a11 abc news a12 usatoday a13 zappos .
a14 buzzfeed a15 foxnews a16 bbcnews a17 reuters a18 news break .
428avgust automatingusage basedtestgenerationfrom videosof app executions esec fse november14 18 singapore singapore this data collection process was time consuming and intensive spanning 8person monthsofeffort.attheendoftheprocess we derivedacomprehensivelabeleddatasetcontaining2 478groundtruth labels for screens and labels for widgets across apps.
given these labels avgustwas able to automatically generate the ir models for the usages needed for our evaluation.
our labeled dataset as well as the annotation pipeline we developed can be easily reusedorextendedbyfuture work inthis area .
.
rq1 avgust stestquality avgust smaingoalistogenerateatestforatargetappthataccomplishes the usage encoded by the videos of other apps.
to evaluate how well avgustaccomplishes that goal for each of the app usages werandomlyselected3appsundertest auts asthetarget apps.
for three of the usages we selected only apps because wewere unabletoextractdata fromcertaincommercialapps due to security reasons or limitations of the underlying used testing framework .
foreachofthoseapps weusethemergedirmodel avgustlearnedfromalltheother17appstoguide avgust stest generation aiming to demonstrate avgust s ability to generate tests forunseenapps.
as discussed in section .
avgust s test generationisadeveloper in the loopprocess.specifically fourof the authorsserved as the developers interacting with the tool during this process.
we use the first test avgustgenerates for the evaluation resultinginatotalof51testsacross18appusages.
we limit our evaluation to a single test per usage per app due to the significant manual effortinvolvedinthe evaluation process.
we examined each of the tests manually to consider whether it accomplished the intended usage.
note that this judgement is objective.forexample itisstraightforwardandunambiguousto determine whether the generated test accomplishes the sign in usage either the tests signs into the app or it does not.
we found that35ofthe51tests .
accomplishedtheusage meaningthat avgustsuccessfully generatedacorrecttest.
for theremaining tests we measuredhow similareachgenerated test was to the closest human test to evaluate whether it would potentially save human effort in writing the test.
the is due to the nature of usage based tests as there are usually multiple correct paths of exercising the same usage.
thus to enable fair comparison wecompare avgust stestwiththe closesthumantest.
we measuredsimilarityusing two metrics precision and recallin matchingthehumantest sbehavior.precisionmeasuresthefraction of the states and transitions in the generated test that occur in the most similar human test from the relevant videos.
recall measuresthefractionofthestatesandtransitionsinthemost similar human test that occur in the generated test.
the closesthuman test ischosenusing the precision similaritymetric.
table3lists the similarity results for the tests across usagesthatdonotsatisfythatusage andthecloesthumantest.on average ofthestatesand47 ofthetransitionsinthegeneratedtestsiscapturedbythemost similarhumantest.thismeans thatavgustrarely visited an incorrect state but often triggered inputs for gui widgets not triggered by humans.
meanwhile on average thegeneratedtestscapture68 ofthestatesand37 of the transitions in the closest human test.
this means that avgust wasabletovisitamajorityofthescreensseeninthehumantest table we compare the avgust generated tests that do not satisfy their intended usage with the most similar humantest toindicatehowmuchworkthesetestsmaysavea developer.
precision recall usage states transitions states transitions u4 search .
.
.
.
u5 terms .
.
.
.
u9 about .
.
.
.
u10 contact .
.
.
.
u11 help .
.
.
.
u12 addcart .
.
.
.
u13 removecart .
.
.
.
u14 address .
.
.
.
u15 filter .
.
.
.
u17 removebookmark .
.
.
.
u18 textsize .
.
.
.
average .
.
.
.
but correctly exercised comparatively fewer expected gui widgets thattriggerpropertransitions.thissuggeststhatwhilethe31.
of the tests avgustgenerates do not fully exercise the intended usage they may be at least partially helpful for developers writing tests.ourfuture workwillexaminetheeffortreduction avgust s tests produce for developers.
ra1 wefindthat69 of avgust sgeneratedtestssuccessfullyaccomplishthedesiredusage savingthedeveloper fromhavingtomanuallywritethetestfromscratch.for theremaining31 ofthetests wefoundthatthosetests capture significant portions of the behavior in the mostsimilartestahumanwouldwrite again potentiallysaving human effort.
.
rq2 avgust sclassification accuracy rq2 compares avgust s vision only screen classification and widget classification accuracy to the state of the art s2v .
first section3.
.1evaluates avgust s classification independently as a stand alone tool.
then section .
.2evaluates avgust s classificationinthe contextoftest generation.
.
.
evaluating avgust s stand alone classification.
to evaluate avgust svision onlyclassificationmoduleasastand alonetechnique we use our labeled dataset from section .
.
.
we use leaveone out cross validation to evaluate the accuracy of avgust s screen and widget classifiers.
for each of the apps we train our modelonthe data from allthe otherapps andtest onthat app.
screen classification we evaluate three variants of avgust s screen classifier.
the first the standard avgustas introduced in section2 and two other classifiers that use only avgust s autoencoder ae modelandclassifywithtwowidely adoptedmethods knn ae knn andmlp ae mlp respectively.as avgust saemodelonlyencodesthescreen svisualfeatures the resultsaimtodemonstratetheimpactofvisual onlyinformation on the classification tasks.
we did not evaluate the text only model since it contains app specific noises e.g.
news content product 429esec fse november14 18 singapore singapore y. zhao s.talebipour k.baral h.park l.yee s.khan y. brun n.medvidovic andk.moran .
.
.
.
.
s2v knns2v mlpae knn ae mlp avgustmin avg maxtop accuracy .
.
.
.
.
s2v knns2v mlpae knn ae mlp avgustmin avg maxtop accuracy figure avgust s vision only screen classification outperforms sv2 and the other avgust classifier variants in bothtop andtop accuracy.
description that do not generalize and text only information has already been showninsufficientfor classification tasks .
tocompare avgustwiths2v weadapts2vtolearnfromthe information on the screen images only and obtain the ui layout information that s2v requires as its input.
to do so we reverse engineered appscreen imagesusing remaui a research tool toconvertappscreenimageintoitscorrespondinguilayout .
thisis thesameprocess avgustuses recall section aiming to ensure that s2v and avgustlearn from the same raw information ontheappscreen.wethenapplyknnandmlptos2v sscreenembeddings resulting in two s2v s variants s2v knn s2v mlp .
figure8shows that avgust s classifier consistently outperformsallversionsofsv2andtheother avgustclassifiervariants in both top and top accuracy.
avgust s composite classifier that uses both visual and textual screen features outperforms both autoencoder only variants by more than suggesting that althoughvisualfeaturesareimportantinencodingauiscreen adding textual features significantly improves the quality of the generated embeddings andresults inhigher classification accuracy.
while using s2v s screen embeddings is effective for downstream tasks when the dynamic ui layout information is available wewereunabletoachievehighclassificationaccuracy usingthepre traineds2vmodelbyreverseengineeringappscreen images intos2v s required format.this suggests that the existing pre trained models cannot be used for vision only tasks effectively.
widget classification to compare avgust s widget classificationwiths2v westudieds2v simplementationandisolated its underlying model that encodes the widget s information.
we then appliedboth knn andmlp to s2v s widgetembeddings.
figure9showsthat avgust swidgetclassifieroutperformsboth s2v variants that use the pre trained ui widget encoder for two reasons.first s2v suiwidgetencoderonlyusesawidget stextual information and class type whereas avgust s widget classifier takes into account many other widget features such as its location on the screen and visual features.
second s2v s ui widget encoder istrainedusingthetextualinformationavailableondynamicallyextracteduilayout whichisnotavailableforthewidgetsin avgust s vision onlyclassification task.
.
.
evaluating avgust sclassificationfortestgeneration.
we next evaluate avgust s classification accuracy in the context of testgeneration.duringthetestgenerationphaseinsection .
we recorded avgust stop 1andtop 5recommendationsateachstep andevaluate the accuracyofthoserecommendations.
.
.
.
.
.
s2v knn s2v mlp avgustmin avg maxtop accuracy .
.
.
.
.
s2v knn s2v mlp avgustmin avg maxtop accuracyfigure avgust s vision only widget classification consistentlyoutperforms s2v .
.
.
.
.
.
ae mlp dynamic ae mlp vision only ae knn dynamic ae knn vision only avgust dynamic avgust vision only min average maxtop accuracy .
.
.
.
.
ae mlp dynamic ae mlp vision only ae knn dynamic ae knn vision only avgust dynamic avgust vision only min average maxtop accuracy figure10 theaccuracyof avgust svision onlyscreenclassifiervariationswith vision onlyand dynamic input data.
evaluation avgust s screen classification besidesavgust s built in screen classifier introduced in section we further implemented5variantsthatincorporateapp sruntimeinformation aimingtogetinsightsonwhetherruntimeinformationcanimprove the classification s accuracy.
this is inspired by s2v which relies on the screen s runtime ui layout information such as theactivity name andcontent description of the widgets on the screen .
asavgust s test generation phase interacts with the target app at runtime avgustcan crawl the ui for this layout information.
we thus relaxed the vision only constraint and modifiedavgusttousethisdynamicuilayoutinformation.weterm the modified version avgust dynamic.
note that the fundamental differencebetween avgust dynamicands2visthetrainingphase.
avgust dynamicstillusesvision onlyinformation screenimages to train its models while s2v requires the dynamic ui layout information in the training data.
in practice as classification tasks usually require a large amount of training data avgust dynamic makesthetrainingprocesssignificantlyeasierbyonlyrequiring screen images while s2v requires crawling the uilayout informationat app runtimefor every app screen inthe training set.
figure10showsavgust s screen classifier variants accuracies during the test generation phase.
comparing figures 10and8 we observe that in both cases avgustalways outperforms the two autoencoder only variants.
all the classifier variants are more accurate when using the vision only data compared to also using dynamic app information captured during runtime.
while this mightseemcounterintuitive onepossibleexplanationisthatthe features extracted from the vision only input data are similar to the dataavgust s built in classifier were trained with whereas the dynamically obtained information might expose much more textual information e.g.
content description that is not consistent with the ocr based textual information used in the training phase.
evaluation avgust s widget classification to evaluate avgust s widget classifier duringtest generation we assess whether 430avgust automatingusage basedtestgenerationfrom videosof app executions esec fse november14 18 singapore singapore avgustcanfaithfullyrecommendwidgetstomatchthetransitions suggested by its ir model.
we recorded the next transitions suggested by the ir model at each step of the test generation recall section2.
aswellasthecropsof avgust srecommendedwidgets.
threeannotatorsthenmanuallyinspectedthecroppedwidgetsand determined whether their canonical categories match one of the suggestedtransitions.intotal overallthegeneratedtests avgust s widget classifier correctly recommended widgets .
of the time outof226steps .
ra2 avgust s classifiers consistently outperform the state of the art s2v tool.
we find that using textual and visualfeaturestogetherimprovesaccuracy butaddingruntime features decreases accuracy perhaps because these featuresaretoodifferentfromtheonesusedtotrain avgust svision onlymodels.
related work automated input generationformobile apps existing automated test generation techniques share a complementary objective to ours they mainly focus on generating tests to maximize code coverage and detect crashes as opposed to generating usage based teststotestacertainfunctionality.thelargebodyofexistingwork includes model based testing randomtesting andsystematictesting .recently suetal.proposedgenie whichisthefirstautomated testing technique to detecting non crashing functional bugs in androidapps.however genieisarandom basedfuzzingtechnique thusdoesnotgenerateusage basedtests.besidesthedifferences in testing objectives avgust s model is app independent representing usage scenarios learned from different apps and is derived purelyfromvisualdata whichdiffersfromexistingmodel based testingtechniques.furthermore incomparisontorecenthumanin the looptechniques e.g.navidroid avgust smodeland recommendationsdifferbyprovidingsuggestionsforguiactions thatfulfillagivenusecase asopposedtouncoveringunexplored areas ofan app.
testreuseinmobileapps theareaofresearchthatmostclosely alignswithusage basedtestgenerationistheworkon uitestreuse which has been steadily growing over the past few years .
these techniques can transfer an existing usage based test from a source app to its equivalent test of a target appthat shares the same functionality but cannot generate usagebased tests from scratch.
furthermore as discussed in section existingtest reusetechniqueshavethreeimportantlimitationsthat we directlyaddressinthis paper.
learning patterns from crowdsourced tests similar to our objective another line of work aims to learn patterns from crowdsourcedtestsforautomatedtestgeneration.however whilesuch techniques learn from crowdsourced data their test objectives are to increase coverage or fault finding ability as opposed to generating usage based tests.
for example replica compares existing in housetestswiththeusertracesinthefield andgeneratesnew tests to mimic field traces that are not covered by the in house tests.
replica relies on pre existing in house tests that may not be available aswellasappinstrumentation.ermuthetal.proposedanapproach to generate macro events that group multiple low level events into logic steps performed by real users such as filling and submitting a form.
however these macro events are recurring patterns across allthe user traces collected when exercising the entireapp thus do not capture fine grained user behaviors exercised inspecific usages.
similarly monkeylab and polariz mines users event traces to generate combinations of low level eventsrepresentingnaturalscenarios similarto macroevents as well as untested corner cases similar to replica s objective .
combodroid aims to reach complex app functionality by combining independent short use cases such as toggling a setting or switching to a different screen.
humanoid leverages a deep neural network model to learn input actions based on real user traces.
however the generatedtests fromall theworkmentioned above again focus on maximizing the code coverage but do not aim to generatetests ofspecific usages.
specification basedtestingformobileapps finally thistype of testing aims to generate tests that cover specific functionalities similar to our definition of usages guided by manually written specifications.forexample farlead android requiresthe developer to provide ui test scenarios written in gherkin in order to generate tests using reinforcement learning.
similarly appflow requires the developer to first create a test library thatcoversthecommonfunctionalitiesinacertainappcategory e.g.
shoppingapps usingagherkin basedlanguagethatappflow defines.appflowthensynthesizesapp specifictestsaccordingto thetestlibrary.augusto usesguirippingtoexplorepopular app independent functionalities referred to as aifs and generates functional tests accordingly.
however developers have to manuallydefineuipatternsandalloysemanticmodel todescribetheaifs.
avgustattemptstoadvanceuponsuchworkby simplifyingthespecificationprocessbyrelyingpurelyonvideos that specifydesiredtest behaviors.
contributions wehavepresented avgust amethodforgeneratingusage based tests forthe android platform.
bytargeting usage basedtests avgustsolveswhatmobiledevelopersidentifyasamajorneed butthatthestateofthearthasfailedtoaddress .avgust usesuser generatedvideosofappusagestolearnamodelofausage andthenappliesthatmodeltoanewtargetapptogeneratetests.
evaluatingon374videosofcommonusesof18popularapps we show that69 ofthetests avgustgeneratessuccessfullyexecute thedesiredusage thattheremaininggeneratedtestshavepotential for reducing developer effort in writing tests and that avgust s classifiers outperform the state of the art.
our work suggests a promisingdirectionofresearchintousage basedtestgeneration andoutlinesoutstandingproblemsinclassificationaccuracythat future researchshould address.
acknowledgement this work is supported by the u.s. national science foundation under grant no.
ccf ccf cns ccf1955853 andccf tothecomputingresearchassociation for the cifellows project as well as the u.s. office of naval research undergrantn00014 .
additionally we wouldlike tothankarthurwuforhishelpondatacollectionandannotation.
431esec fse november14 18 singapore singapore y. zhao s.talebipour k.baral h.park l.yee s.khan y. brun n.medvidovic andk.moran