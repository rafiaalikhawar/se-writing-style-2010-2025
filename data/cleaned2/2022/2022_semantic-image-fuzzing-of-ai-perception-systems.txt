semantic image fuzzing of ai perception systems trey woodlief university of virginia charlottesville virginia usa adw8dm virginia.edusebastian elbaum university of virginia charlottesville virginia usa selbaum virginia.edukevin sullivan university of virginia charlottesville virginia usa sullivan virginia.edu abstract perceptionsystems enableautonomoussystemstointerpretrawsensorreadingsofthephysicalworld.testingofperceptionsystems aimstorevealmisinterpretationsthatcouldcausesystemfailures.
current testing methods however are inadequate.
the cost of human interpretation and annotation of real world input data is high somanualtestsuitestendtobesmall.thesimulation realitygap reduces the validity of test results based on simulated worlds.
and methods for synthesizing test inputs do not provide corresponding expected interpretations.
to address these limitations we developedsemsensfuzz a new approach to fuzz testing of perception systems based on semantic mutation of test cases that pair realworld sensor readings with their ground truth interpretations.
we implemented our approach to assess its feasibility and potentialto improve software testing for perception systems.
we used itto generate semantically mutated image inputs for five state of the artperceptionsystems.wefoundthatitsynthesized tests with novel and subjectively realistic image inputs and that it discoveredinputsthatrevealedsignificantinconsistenciesbetween thespecifiedandcomputedinterpretations.wealsofoundthatit producedsuchtestcasesatacostthatwasverylowcomparedto that of manual semantic annotation of real world images.
ccs concepts software and its engineering software testing and debugging computing methodologies perception vision for robotics computersystemsorganization embeddedand cyber physical systems.
keywords semantic fuzzing autonomous systems perception acm reference format trey woodlief sebastian elbaum and kevin sullivan.
.
semantic image fuzzing of ai perception systems.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction the perception implementing layers of software in autonomous systems ass are responsible for mapping raw sensor inputs to semantic interpretations that can inform decisions and actions in the this work is licensed under a creative commons attribution noncommercialsharealike international .
license.
icse may pittsburgh pa usa copyright held by the owner author s .
acm isbn .
figure autonomous system perception pipeline physical world.
figure illustrates a simplified as pipeline where the world is sensed through a camera.
the resulting image is then processed by percepto generate an interpretation that the as will use to inform navigation and other control decisions.
faultyperceptionsystemscanmisinterpretthephysicalworld leading to dangerous even deadly actions.
for example tesla has recently admitted that its ass sometimes misinterpret parked cars and the us national highway traffic safety administration has now opened an investigation into almost a dozen instances where atesla vehiclehascrashedintoaparkedemergencyvehiclewith its lights flashing.
those mishaps have resulted in at least one fatalityandmultipleseriousinjuries .otherexamplesinclude miscalculatingtheexistenceorlocationofavehicle orfailingto detect people in the planned trajectory of a vehicle .
such mishaps point to fundamental shortcomings in current methods of testing as perception software.
a key problem is that thesemachine learnedcomponentstendtobetrainedusingdata fromnormaldriving withfewifanyopportunitiestolearnfrom rare but safety critical events.
when such events do occur perception systems mustaccurately interpret the physical world.
the rarity of safety critical but infrequent events then entails that real world test driving will never be adequate from a testing perspective.
a study by the rand corporation found that autonomousvehicleswouldhavetodrivehundredsofmillionsof milestodemonstratereliability andthat .alongsimilarlines waymo corporation safety validation methods convey opportunities to scaleuptestingusingsimulation butultimatelyconcludethatreliance on real world road driving for validation is required .
augmentation of data captured in the real world has emerged as a potentially viable alternative to reduce the need for real worlddriving .however these techniquesoperateatthe pixel level missinganopportunitytotrulyexploreimagesthatare semantically interesting in challenging the perception pipeline.
what this work proposes is an approach to testing perception systems using sensor reading expected interpretationtest case pairs derived from real world as perception testcases for which we already have ground truth interpreta tions by mutating both sensor readings e.g.
images andtheirexpectedinterpretationsinacoordinatedmanner .our long term aim is to generate test cases that focus on rare safetycriticalinputsthatinclude forexample vehiclesthatarecrashed crossing into oncoming traffic overturned etc.
ieee acm 44th international conference on software engineering icse icse may pittsburgh pa usa trey woodlief sebastian elbaum and kevin sullivan a run the sensor in the real world with human annotations b use simulation to create new test cases c low level mutation of previous tests d semantic mutation of previous tests our approach semsensfuzz figure overview of test case generation approaches for perception layers of autonomous systems thispapertakesthefirststep towardsourlong termvisionby proposingandevaluatinganapproachfornon guidedtestgenerationthatcan forexample incorporatevehiclesandpeopleinto images.theapproachleveragespriortestcasesasrawmaterials mutatingexistingtestinputstoautomaticallyproducerealisticand novel synthetic sensor data and deriving interpretations by also mutating their existing interpretations.
testing with our approach theninvolvescomparingthesepredictedoutputswiththeactual interpretation outputs produced by a given system under test sut .
our contributions are as follows semsensfuzz a new concept in testing of perception software for safety critical autonomous systems based on semanticmutationsappliedto sensorreading ground truth interpretation test case pairs.
semimfuzz ademonstrationsystemtargetingcamera based autonomous vehicle perception.
experiments using our approach to test five state of the art perception systems with results showing that our approach canproducerealisticinputsandoveralltestcasepairsthat reveal problematical perception errors in these systems.
motivation and related work basic definitions.
atest case t r interp for the perception systempercepof an as is a set of input sensor readings r paired with a valid output interpretation interp forr.
figure 3a shows an example of a single sensor reading rfor an autonomous vehicle perceptionsystemandbelowit figure3fshowsthecorresponding ground truth interpretation interp.
the system s performance is thenjudgedbasedonanoraclethatcompares percep r andinterp.
conformity.
ass operate in the physical world and thus a sensor reading rused in a test case tmust conform to the constraints oftherealworld.if rcouldhavebeenacquiredfrom andisthus sufficiently realistic with respect to some configuration of the real world w wesaythat rconforms withw.thisnotionisimportant as a failing twith nonconforming ris likely a false positive a failure that would not occur in the real world.
figure outlines three common existing procedures to generate asuiteof tandourapproach semsensfuzz whichwenowexplore.
.
testing in the real world one common procedure outlined in figure 2a is to operate the as in the physical world while recording the sensor readings.
this procedureisadvantageousinthatitcangeneratealargedatasetreflecting typical operating conditions.
however it is limited in thatproducingspecificdesiredconditions e.g.
haveacarsuddenly turn in front of our fast moving vehicle in the real world can be impractical dangerous and expensive .
crafting the groundtruthinterpretationalsoincursgreatexpense requiringahumanto manually annotate the sensor readings.
in prior studies producing high qualityannotationsofcameraimagesforadrivingbenchmark requiredonaverageover90minutesofhumaneffortperimage .
.
testing in simulation anothercommonprocedure showninfigure2b usesamodelof the world embedded in a simulator to replace operating in the real world.usingthesimulator smodeloftheworldtoautomatically producesensor readingsand ground truthinterpretations enables constructing arbitrary simulated worlds at a lower cost .
however this approach suffers from the simulation reality fidelity gap asw wsim .
this can diminish the value of the tests as the results may be simulation specific which is why they are oftenrevalidatedinthephysicalworld .thatis thesetestsmay not conform to any configuration of the real world.
.
generating tests with low level mutations a third procedure mutates collected sensor readings to produce r interp andisillustratedinfigure2c.naivetechniquesfollow in the vein of standard data augmentation techniques performing global mutations such as affine transforms or adding noise .forexample figure3banditsinterpretationinfigure3g showhorizontallymirroringtheimageanditsinterpretation while figures3cand3hshowtheuseofamaskthatobscurespartsofthe image.moreadvancedstrategiessuchasaddingweather shown infigures3dand3i aredomain specificbutstillgloballyapplied acrossallpixels .mutation basedprocedurescanquickly generatemanyteststhat ifthemutationsaredesignedcarefully canalsobeconforming.thatismuchlesslikely forexample for theboxadditionsin3cthanforthefogadditionin3d.furthermore to automatically provide an oracle this kind of procedure tends to notsemantically affecttheimage.
forexample addingfogshould not affect the entities identified in the image the interpretation of figure3iisthesameastheoriginalinfigure3f.additionally recent work has examined ways to use mutation strategies to generate adversarial changes to the scene that do not change the semantics but are likely to cause changes in the as s perception .
when these mutations do affect the image semantically like in 3c 1959semantic image fuzzing of ai perception systems icse may pittsburgh pa usa a original image b affine edit c coarse edits d global edits weather e our edits car added f original interp g affine edit interp.
h coarse edits interp.
i global edits interp.
j our interp.
car added figure overview of image mutation techniques best viewed on a screen the interpretation of those changes is unknown as shown in 3h where several people are cut off.
.
generating tests with semantic mutations inthisworkweenvisionamoresophisticatedkindofmutationthat incorporatesworldsemanticsandiscognizantofwhatthereadings mean i.e.
what the pixels in an image actually represent in the world .suchamutationcould forexample addacardrivingonthe streetasshowninfigure3ewithacorrespondinginterpretationin figure 3j.
we believe and later show how such semantic mutations havethepotentialtocreatetestcasesthatareconformingbutdo notoccurinexistingtestsuitesduetotheiruncommonoccurrences in the physical world.
figure 2d shows how our proposed approach semsensfuzz differs from prior mutation techniques in the semantic nature of the mutations.
performingthesemutationsrequiresthatmutatedsensorreadingscontinuetoconformtotheconstraints oftherealworld leadingtoseveralchallenges.ontheinterpretation side we must craft domain specific rules to validate potential mutations and determine what types of mutations are likely to yield perception failures e.g.
adding a pedestrian to a roadway.
furthermore wemustincreaseconformitylikelihoodbycrafting preconditions based on the sensor modality.
for example for camera images this may include not just that an entity is in a viable position but alsothat theperspective lighting and shadows are conforming.
sensor reading mutations must be associated with interpretation mutations that will serve as an oracle.
section describes how the approach tackles these challenges.
approach we describe our approach for using semantic mutations to test as perceptionsystemsregardlessofsensormodality.weformalizethe problemdefinition presentthegeneralapproach andinstantiate theapproachforcamera basedperceptionsystemsforautonomous vehicles.
.
problem definition asemantic mutation r interp transforms a test case t r interp whererconformswith someconfigurationof the world w intoanewtestcase t prime t r r interp interp r prime interp prime wherer primealso conforms with some world configuration w prime andinterp primeisavalidinterpretationof r prime.forexample amutation addcarmay add a car to an image while mutating its interpretation to indicate that a car is now there.
we say that perceppassesa mutated test case t if and only ifpercep r r interp interp highlighting the symmetry of themutationfunctions.figure4illustratesthisprocess.inpractice onemightneedto andinourexperimentswedo useapproximate equality percep r r interp interp forasuitablysmall .
at a conceptual level our approach thus constitutes a form of metamorphictesting whereexistingtestcasesareconverted into new ones in which the correct outputs for transformed inputs are deduced using knowledge of properties of the physical world.
t r r r prime annotation arrowbt arrowbtpercep interp interp interp prime?
percep r prime t prime figure4 semanticmutationoftestsforperceptionsystems .
semantic mutations with semsensfuzz a key insight driving semsensfuzz is that prior captured data sets can be leveraged as a source of initial test cases and of resources to designsemanticmutationsthataremorelikelytoresultinconforming tests.
that insight guides the scope of mutations considered in any givendomain includingmeans toensure reasonableconformity of mutated inputs with possible real worlds.
first wescopethespaceofallmutations basedontheentities that appear in the interps of the available tests.
for example if the interpretationsmarkcarsandpeople weonlyallowmutationsthat add remove or change cars and people.
we argue that since those arethecriteriabywhichexistingtestsarejudged itissensibleto focus just on those to try to find unexpected percepbehaviors.
second weassociate aset of preconditions precwith eachmutation specified in terms of the interpthat defines whether isapplicabletoagiven t.ifprec interp isnotsatisfied then is not applicable to that test.
for example for a mutation that adds a car to an image precmay be the existence of a road in interp for changing the color of a car precwould be the existence of at least one car in interp.
the idea is to leverage an existing interpretation to determine mutation applicability.
this is a key distinction 1960icse may pittsburgh pa usa trey woodlief sebastian elbaum and kevin sullivan compared to other strategies that allows for our semantic mutationswhilerespectingconformity.insteadofcraftingmutationsfor sensorinputsandpropagatingthemutationtotheinterpretation without respect for changing semantics we craft our mutations for the interpretation and then propagate to the sensor domain.
third weenabletheparameterizationof rtoemployrealsensor datatoincreasethelikelihoodofconformity.forexample when addingacarto ti ri interp i ifthereexistsa tj rj interp j that contains a car constrained by a similar context as per their interps then addcarrcould put the car from rjintori.
in the case ofimages weusetheentitypose perspective lighting andadjacententitiesintheinterpretationtodefinethecontext.notethat context is sensor modality and domain dependent and that the richness of the resource set will affect the diversity of generated testcases.additionally weexploretheintegrationofdiscriminators to determine conformity.
we discuss this further in section .
.
.
allofthemechanismsinourapproachmakeaconscioustrade off between conformity and a smaller space of available mutations.
.
semantic mutation of images by semimfuzz to further explore our approach we now focus onthe perception systemofanautonomousvehiclethatcontainsasinglefront facing cameraforsensing andweconcretize semsensfuzz tothisspecific sensormodality.werefertothisspecificapplicationas semimfuzz .
asillustratedinfigure3 forthesesystemsthesensorinputconsists ofasinglecameraimageandtheoutputconsistsofaninterpretation of the world in the form of a per pixel semantic annotation.
semimfuzz requiresadatasetofreal worldcameradatatobuild its resource set to serve as the basis of its mutations.
camera based perceptionsystemsarewidelystudied withseveralavailablebenchmarks consisting of thousands of test cases of image and interpretation pairs.
each benchmark targets a different level of precision which affects the strength of the resource set.
we now explore the space of semantic mutations for the domainofcamerasystemsforautonomousvehicles.wefirstdefine thesemanticentitytypes thatcanappearinimages e.g.car bicyclist etc.
each such entity has a state e.g.
orientation color position lighting etc.finallywedefineasetofsemanticactions e.g.
add entity remove entity change entity state.
the space of mutations is then the set of actions each parameterized by an entity and a state e.g.
add action a car entity at location l state .
in practice semantically mutating images can be difficult due totheconformityrequirement.forexample addingacartoalocation in an image requires verifying that a car can exist in that location e.g.
the car cannot intersect another car.
removing an entity requires generating conforming image data with a known interpretation for the vacated space a process known as semantic inpainting .
changing the pose of an entity requires rendering the entity in a conforming manner from a different perspective than it appeared in the original test case.
implementation for the autonomous vehicle domain tostudytheapplicabilityof semsensfuzz wecreatedanextensible pipelineinpythonforfuzzingperceptionsystemsofautonomousvehicles with a single front facing camera semimfuzz that implementsthreemutations changingthecolorofcars addingcars and adding pedestrians1.
we begin with the system architecture and then discuss detailed implementations for the chosen mutations.
.1semimfuzz architecture figure5outlines semimfuzz scomponentsandflow.givenamutation semimfuzz selectsatestcase tandqueriestheresource set for viable resources to perform .
it then selects a resource and checks whether mutatingusing t and theselected resource will generateaconformingtest.ifso itappliesthemutationtogenerate t prime otherwise it selects another resource and repeats.
semimfuzz requires a prior data set as a basis for mutation.
in the autonomous vehicle domain there are several such data sets includingkitti nuscenes andcityscapes .
each provides r interp testcaseswhere risacameraimageand interp isaper pixelannotationthatprovidesaground truthinterpretation basedonthecategoriesprovidedinthedataset.asapreprocessing step semimfuzz parses the prior test set to build a resource set of available data e.g.
a list of all cars and their poses.
eachdatasethasadifferentlistoftrackedcategorieswithdifferinglevelsofprecisionanddesignchoicesforhowtotreatcertain entities.forexample nusceneshas7labelsforhumansdifferentiating between e.g.
adults and children while cityscapes has labels that distinguish between a pedestrian and a person riding a bike or motorcycle.
we developed semimfuzz using the cityscapes data setduetoitspopularityinrelatedliterature thewidenumberof perception systems that have been developed to target the data set and the availability of open sourced tools to evaluate performance.
wenote however thatthedesignchoicesandavailabledataina data set influence the richness and precision of semimfuzz s resource set and thus the mutations available.
for example when we aim to develop a mutation for adding a vehicle that has been involved in a crash to a test case under the theory that a deformed vehicle would be more difficult to perceive the data set s lack of thislabelwillprevent semimfuzz fromleveragingsuchamutation.
weimplementedeachmutationusingnumpy alongwith opencvforpython andpillow twocommonimageprocessinglibrariesforpython.wecreatedtheframeworkinamodular fashion to easily incorporate additional mutations or data sets.
forourfirstimplementationof semimfuzz wechosetoexplore twomutations changingthecolorsofentitieswithinthesceneand addingentitiestothescene.wechosethesemutationsforinitial study ofsemimfuzz due to our ability to perform those mutations using available image manipulation techniques.
although these mutations are relatively simple we conjecture that if the simple mutations yield interesting test cases then this will encourage further research to enable more advanced techniques which can then be incorporated.
we describe the implementation details of each mutation in the following sections.
.
changing object color thesimplestmutationweimplementedchangesthecolorofasingle entity in the test case and was designed with the goal of changing 1codeandhigh levelalgorithmdescriptionsareavailableat 1961semantic image fuzzing of ai perception systems icse may pittsburgh pa usa figure pipeline for semantic mutation with semimfuzz a original car b mutated car figure applying color change mutation best viewed on a screen the color of vehicles to mirror the physical parallel of repainting a vehicle.inthecontextofthe sutsweareexamining thecolorof the vehicle should not change the target perception category and sointerp prime interp.
thus we examine how to produce r primefromr.
.
.
implementation.
for this mutation the test selection step chooses a test case containing a car as the base test tfor mutation andneedsnoadditionalresources.toaffectthecolorchange we manipulatethecolorinthehslcolorspace whichseparatesthe components into hue saturation and lightness in a way that is similar tohuman perception ofcolor .
atthe most basiclevel thismutationperformsahueshiftontheentity changingittoa different color.
however this leads to two concerns.
first if we only want to change the color of the vehicle s paint how do we prevent changing the color of the vehicle s windows?
in this color model high lightness corresponds to white and low to black.
this meansthatsincemostwindowsappeardarkinimages theywill beunaffectedbyahueshift.thisleadstothesecondissue altering the color of white vehicles.
to facilitate this semimfuzz checks for high lightness pixels and decreases the lightness and increases the saturation so that the hue shift applied to the entire vehicle produces another color.
specifically if the average lightness of the vehicleisover100 thenallpixelswithalightnessvalueover100 have their lightness decreased by a random amount between and .
then to prevent the colors from appearing faded pixels withalightnessover100andasaturationlessthan50havetheir saturation increased.
figure showcases an example application of this mutation changing the car s color from red to blue.
as shown in figure the change object color mutation can render results that appear very realistic.
.
.
potential for false positives.
as with all mutations this operationmustensurethat r primeconformstosomeworld w prime.ingeneral sincerconformedtosomeworld w thenthereexistsa w primewiththe a original car b mutated car figure nonconforming color change mutation best viewed on a screen vehiclepaintedthenewcolor.however thecolorshiftcaninadvertentlyaffectotherpartsofthevehicleandmayleadtofalsepositive test cases in which there is no such w prime.
the very observant reader may have identified in figure that not only does the car body appear repainted blue but so do the brake lights.
in the physical world it is possible for a car to have blue brake lights however thisislikelynotplausibleduetoregulationsgoverningthecolor ofthebrakelight.moreadvancedversionsofthismutationcould considerrefinementsinthisarea.anotherissue showninfigure7 occurswhenthereishighglareonthevehicle causingpixelated distortions and thus not conforming with any world w prime.
.
adding an entity addingentitiestoscenesisoneoftheadvancesof semimfuzz .the goalofthismutationistoaddanentitytoasceneinawaythatmay impacttheperceptionsystemsuchasaddingavehicleorpedestrian.
adding an entity to the sensor input produces a corresponding addition in the interpretation and allows us to examine the sut s performance at the semantic level.
.
.
implementation.
for this mutation the test selection step choosesanytestcontainingaroadasthebasetest tformutation.
theresourcequerystepselectsallpotentialentitiesofthespecified class e.g.allcars andfiltersoutthosethatareoccludedbyother entities.toincreasethelikelihoodthataddingtheentityaffectsthe sut vehiclesmusthaveaboundingrectanglethatisatleast100 pixelsonitslongestside or50pixelsforpedestrians.
semimfuzz then randomly selects an entity and checks if adding that entity totwouldresultinaconformingtestbycheckingforcompatible perspective semantics andlightingbetweentheentityand t.these are nontrivial conformity checks as we explore below.
theresourcesetprovidesacollectionofimageswiththepixel boundariesgivingthelocationandoutlineofisolatedentities.when 1962icse may pittsburgh pa usa trey woodlief sebastian elbaum and kevin sullivan a source image b base image r c isolated entity in resources d mutated image with car added r prime figure applying add car mutation best viewed on a screen adding the entity the mutation takes the isolated portion of the imageandoverlaysit atthesamepixelcoordinates onthebaseimage.
figure demonstrates this process.
maintainingaconsistentperspectiveisonekeytoconformity.
if done improperly the added entity will appear out of proportion and misaligned with other image features.
to this end we add theconstraintthattheentitymustbeplacedatthesamerelative physical coordinates to the camera in the new test case as it was in the source test case.
if we want to add a car with pose prelative to the camera from tsto test case tto generate t prime the resulting t primewill consistof twiththecarfrom tsaddedatpose prelativetotheits camera.retaining thesame poseincreases thelikelihoodthat the added car will appear in the correct perspective in t prime.
however addingtheentityatthesamepixelcoordinatesdoes not guarantee that the entity is added at the same physical coordinates relative to the camera.
the relationship between pixel coordinatesandphysicalcoordinatesdependsonthecharacteristics of the camera the vanishing point of the scene and the size of the object.
we assume that the entire resource set consists of images taken with cameras that have consistent characteristics.
additionally since the entity is always added so that it occupies thesameregionofpixels ithasthesamesize.thus ifthesource and destination images have the same vanishing point they will be compatible because adding at the same pixel coordinates will resultinthesamephysicalcoordinatesrelativetothecamera.however finding pixel perfect matches on the vanishing point between images is extremely unlikely due to potential number of scenes.
instead wedividetheimagesintoquadrantsandconsidertwoimages to be compatible if their vanishing points are in the same quadrant.
increasingtheprecisionwhenmatchingvanishingpointsincreases thelikelihoodthattheperspectivewillbeadequatelymaintained butatthecostofallowingfewerpossiblemutationsandmoreexpense in searching for compatible images during mutation.
we utilize an implementation of an algorithm that uses the intersection of hough lines to determine which region of the image likelycontainsthevanishingpoint .iftheimagethattheentity issourcedfromand tanddonothavecompatiblevanishingpoints it fails the conformity check.
the new location of the entity must be physically feasible in ordertoconformtoaworld w prime.tovalidatethis semimfuzz checks if the lower left corner of the entity s bounding box is on the road.lighting also plays an important role in the conformity of a mutatedimage especiallythebrightness.forexample acarfrom an image with bright sunlight cannot be added in the shade.
to addressthis semimfuzz takestheregionofpixelsinthebaseimage that the entity would be placed over and the pixels of the entity and converts them to the hsv hue saturation value color space.
in hsv the value corresponds to the brightness of the pixels.
to ensure that the lighting conditions are similar if the entity does not have a median value within units of the median value of the base image target area then it fails the conformity check.
oncesemimfuzz chooses a base image and entity to add the images are combined into a new test image.
similarly the interpretationofthebaseimageiseditedtoincludetheproperclassification oftheentityatitsposition.thisisshowninfigures3eand3j where the car has been added both in the image and the interpretation.
.
.
potential for false positives.
the previous techniques improve the likelihood to generate images with conforming perspective and brightness but as seen in figure there are several conditions that can lead to false positives.
whilesemimfuzz takesstepstoincreasethelikelihoodofmatching consistent perspectives this does not always happen.
figure 9a shows an example of a car that has been added to an image withaperspectivemismatch causingtheaddedcartoappearmuch smaller than it should compared to the entities around it.
another issue related to entity placement is overlap.
figure 9b shows an instance where a car has been added on top of a person walking their dog.
at first it seems that this could have been avoided by checkingforoverlappingpixels.however thiswouldoverlyconstrainthemutationandp reventmanyinteresting testcasesbecause pixel level occlusion does not imply that the entities overlap in the physical world.
determining overlap involves reasoning about the physicalsizesofentitiesandtheirdistancefromthecamera which future work could explore.
anotherconsiderationisconsistentlighting.inmostautonomous vehicledrivingscenes thepositionofthesunalongwithanyocclusions like cloud coverdetermine entity brightness and reflections.
fortheimagetoconformtoaconfigurationoftherealworld these effects must be consistent with a single lighting configuration.
for example addingacarwithabrightreflectiontoacloudyimagewill result in a nonconforming image as shown in figure 9c.
further in mostlightingconditionsallentitiesinascenewillcastashadow.
determining the characteristics of the shadows requires a detailed model of the scene with information about the physical location of all entities and light sources.
this level of data is not present in the resource set derived from cityscapes andso semimfuzz does not attempttoaddashadowwhenaddinganentity.thiscanleadto nonconforming images as shown in figure 9d.
.
challenges and vision for other mutations currently semimfuzz providesonlytheaforementionedmutations relatedtoentityrecoloringandadditionandthuslacksmutationsin two key areas entity repositioning and removal.
we now examine wherethestate of the artincomputergraphicsandvisionislimited to support such advanced mutations and we comment on our preliminary prototypes and results.
1963semantic image fuzzing of ai perception systems icse may pittsburgh pa usa a incorrect perspective b overlapping entities c inconsistent lighting d missing shadow figure nonconforming add car mutations best viewed on a screen renderingarealisticimageofascenefromaspecificperspective is a widely studied area of computer graphics encompassing all mannerofimagesynthesis.however thegoalofourmutationsisto renderarealisticimageofasceneusingreal worlddata.todosowe need a technique to convert a scene into a rendered image that is sufficiently novel from prior data has a known interpretation and conforms to a world w. we find that although state of thearttechniqueshavemadestridesinalloftheseareas thereisno technique that meets all three criteria.
.
.
repositioning entities.
recent machine learning research attempts to render novel scene compositions distinct from that of sampled data.
originally used to render the same entity from a different perspective the current state of the art can remove orslightlyrepositionentitiesinthescene .whilethisapproach can render very realistic and conforming images with known interpretationusingpriordata itislimitedinhow faraway from the original scene it can operate.
entities can only be removed if they did not occupy that space in a different video frame and repositioningis limitedtoa fewmetersand degreesdifferent thanthe original scene.
while this area is promising it currently does allow for sufficient variation from prior data to use in semimfuzz .
.
.
removingentities.
anotherrelevantthreadofgraphicsresearch is the problem of inpainting the task of filling in regions of animagesuchthatthenewimageisconforming .forexample removingacarfromthescenecanbeachievedbyinpainting over the region of the car with empty road.
although inpainting has potential to produce conforming images for use in mutation in practice such tools satisfy neither our interpretation nor conformityrequirements.theinterpretationoftheinpaintedregionisnot knownandalthoughthesystemistrainedonrealdata itsability toproduceconformingimagesdecreasesastheinpaintedregion grows.wedevelopedaprototypeusing toperformamutation toremoveacarfromanimage.figure10showsanexampleoutput of using inpainting to remove acar from an image taken from the nuscenes data set.
as shown in figure 10b although the car itselfisnolongervisible theregionexhibitsseveralnonconforming distortions and lighting effects which hint at the prior existence of thecar.advancementsin inpaintingtomakethe proceduremore robust would greatly expand the space of feasible mutations.
a original car b car inpainted figure inpainting to remove entities best viewed on a screen .
.
directimagesynthesis.
directimagesynthesissystemswork as the inverse to the perception system of an as taking in an annotatedinterpretationofanimageandrenderingacameraimage that is consistent with that interpretation .
this would remove the need to perform mutations on the sensor inputs allowingsemimfuzz tomutatetheinterpretationdirectlyandusedirect image synthesis to create a matching sensor reading.
this process canrichlycombinedatatoproducenovelscenes butcurrentimplementationsstill donotsatisfy theinterpretationandconformity requirements.
while interpretation is considered during synthesis someregionsareleftunconstrainedandaredelegatedtoinpainting suffering from the shortcomings outlined above.
.
.
discriminators for conformity checking.
in prior sections wedescribethepossibilitiesforfalsepositivesarisingfromnonconforming test cases.
machine learning discriminators present a way toidentifysuchnonconformingtests .thesediscriminatorsare aformofbinaryclassifierthatseektodetermineifaninputbelongs to a distribution so they could preemptively reject mutations that are nonconforming with the real world defined by a training set.
weexploredthisapproach trainingabinaryclassifierbasedona cnnusingover48 000imagestakenfromboththecityscapesdata set and those generated by semimfuzz .
the discriminator learned to differentiate between the classes but could not differentiate conforming versus nonconforming images.
in part the problem is that the generated images contain conforming and nonconforming images butchecking24 000ofthemwasprohibitivelyexpensive.
moregenerally abroaderchallengeisthatdiscriminatorstendto require much larger data sets even for much smaller images.
we suspect that the discriminator requires much more training data to targetaresolutionsuitableforass whichisnotfeasibleduetothe cost to obtain real world data.
future research in this direction has the potential to reduce the false positive rate of semimfuzz .
discussion of trade offs semsensfuzz provides a framework for testing as perception systems distinct from the prior approaches described in section .
we noteherethatthesepriorapproachesarenotsuitablefordirectcomparisonduetothedifferinggoalsandintendedoutputs.simulation low levelmutation and semsensfuzz providedifferenttrade offs intheirabilitytogeneratenoveloutputs costtogeneratetests and conformity of outputs.
we now discuss those trade offs.
in terms of ability to generate novel inputs simulation provides the highest level of utility allowing for practically unlimited environmentgeneration.attheotherend low levelmutationtechniques provide a narrow range of possible test cases based on prior data and the global mutation strategies employed being limited 1964icse may pittsburgh pa usa trey woodlief sebastian elbaum and kevin sullivan inthenoveltyofthemutateddatacomparedtotheoriginaldata.
semsensfuzz builds from the low level mutation strategy in terms ofutility providingnewdimensions forthenoveltyof themutated data.
although still limited by the availability of prior data the richer semantic mutation strategies allow for the generation of more meaningful novel test cases that contain a substantive and human understandable semantic change.
although simulation provides the highest level of utility for generatingnovel inputs itsefficiency ismore nuanced.simulated environments may be re used between testing different systems butbuildinganewenvironmentcomesatahighcostintermsof timeandexpertiserequired.onceanenvironmentisinplacefor testing adapting the environment can be achieved at a lower cost.
for example given an existing scenario the simulator carla providesanautomatedwaytovaryweatherconditions.forboth low level mutation and semsensfuzz there is an initial cost to collect the baseline data to mutate however readily available data sets can ameliorate these costs to the end user.
using available data the low level mutation strategies are likely the most efficient in producing new test cases.
given the additional machinery thatsemsensfuzz uses to leverage multiple facets of the prior datawhilealsoperformingconformitychecks thecomputational cost is likely significantly higher than the low level approaches.
asdiscussedinsection2 oneofthekeylimitationsofsimulation testingisthesimulation realityfidelitygapthatcandiminishthe applicability of the tests and require revalidation in the physical world as they may not be conforming with any real world .
the mutation based strategies are designed to avoid this limitation by using real world data as the baseline and ensuring thatthemutationspreservetheconformityoftheoriginaldata.we note that semsensfuzz specifically identifies this need to preserve conformity as a fundamental part of the framework.
assarecomplexsystemsthatrequireavariedcomplementof testingtechniques.thevalidationprocessforanyasshouldinclude multipletypesoftesting.
semsensfuzz providesavaluableaddition tothevalidationtoolboxbyprovidingsemanticmutationsabsent in the low level mutation strategies while maintaining conformity to ensure it avoids the pitfall of the simulation reality gap.
evaluation we have developed semimfuzz a test generation tool that can efficientlyidentifyperformanceinconsistenciesinasperception systems using semantic mutations.
to evaluate the potential of our approach semimfuzz in thesedimensions weseek toanswerthe following research questions rq1.how effective is our technique in uncovering inconsistencies defined at different levels of severity?
rq2.howefficientisourtechniqueintermsofthetimetaken to generate the mutation and to detect the inconsistencies?
rq3.which mutations are the most effective?
.
suts to assess semimfuzz we evaluate it on five highly competitive perception systems submitted to the cityscapes benchmark for the pixel level semantic labeling task .
these suts were the five highestperformingsutsforwhichcodeandpre trainedmodelstable cityscapes benchmark scores for suts evaluated rank yearsut iou overall with code 12020nvidia semseg .
32021efficientps .
62020decouplesegnet .
72018sdcnet .
92019hrnetv2 ocr .
were publiclyavailable.
each projectwas forked fromthe original repository editedifnecessarytoprovideaconsistentoutputformat andpackaged torunin adocker containerforreplicability.table1 listssutsrankedbytheirperformance overallandamongtheones withcode ontheoriginalcityscapesdatasetasperthedefaultiou class metric.
intuitively this is the percentage of correctly labeled pixels withaminimumscoreof0andamaximumof100.pixelsthat do not belong to a class are marked as do not care like the hood of the ego vehicle meaning that they are excluded from scoring regardless of the sut assigned label.
.
tests generated weusedthecityscapesdatasetasthebasisforourtesting serving as the original test suite and basis for building the resource set.
we pruned testcases thataretoo difficultfor the sutsto prevent mutating test cases where the mutation will not be the focus of the test ifthesutstruggleswiththeimageasawhole themutation will not provide any additional utility.
to perform this filter we ran the highest performing sut on the baseline as determined by itsrankingonthecityscapesleaderboard ontheoriginaltest cases in the data setto establish the baseline performance of each test case.
any test case on which the best sut performs below the thresholdisremovedfromconsideration.forourtesting wesetthis minimumscoreparameterat95 resultingintheremoval42ofthe total images in the data set.
semimfuzz then performs a onetimepreprocessinganalysisoftheremainingtestcases asdescribed insection4 tobuildtheresourcesetbyfindingallavailableentities across the test cases to include in future mutations.
forevaluation weraneachsuton150 000testsgeneratedby semimfuzz comprised of add car mutations add person mutations and change car color mutations.
.
metrics an effective mutation one that finds a potential sut failure mode rendersaconformingimagethatcausesthesuttoperformpoorly.
tocapture thatnotionwe relyonthe cityscapesbenchmarkevaluationtool eval whichscoreseachsut sperformancebasedon thepercentageofcorrectlyclassifiedpixels.weevaluatetheperformance of the mutation strategies by calculating the percentage point p.p.
difference betweenthe sut s scoreon the originalimage and its score on the mutated image.
any drop in the sut s 1965semantic image fuzzing of ai perception systems icse may pittsburgh pa usa figure inconsistencies found per sut score on the mutated image compared to the original image was induced directly by the mutation itself allowing us to gauge the strength of the mutations to find inconsistencies.
moreformally foragivensut percep testcase r interp and corresponding mutation r prime interp prime the drop is given by drop eval percep r interp eval percep r prime interp prime the larger the value the more error the mutation induced in the sut.wejudgedropsoflessthan1p.p.tobeinthenoiseasmost tests result in suts misclassifying a few pixels around the edges of objects leading to small drops compared to the baseline.
we select p.p.
as the cut off to reduce the likelihood that we deem an inconsistency noteworthy when it is not and as a filter to maintain the feasibility to complete the manual reviews we conduct for evaluation.we categorizedrops between1 and5p.p.
asmoderate inconsistencies between and as significant and those greater than10asextremeinconsistencies.foradditionalcontext thehood of the car visible at the bottom of all images in the cityscapes data set see fig.
occupies roughly .
of the image a drop of more than5p.p.meansanarealargerthanthehoodwasmisclassified.
we note that there is no additional filtering at this step based on howwellthesutperformedontheoriginaltestcase.forexample ifthesutscoredonly85 ontheoriginaltestandthenscored78 onthemutatedtest thenthiswouldresultinadropof7p.p.and be classified as a significant inconsistency.
future work may examine usingspecificperformance thresholdsinstead ofperformance drops specifically as this technique applies to testing a single sut.
however by measuring deterioration of performance we are able to use this metric to compare across the various suts even though they show different levels of absolute performance.
wealsomeasurethetimetoperformeachmutationandthetime to run the suts to assess efficiency.
.
results .
.
rq results finding inconsistencies.
figure shows the counts of inconsistencies found in each category per sut note the log scale on the y axis.
we first remark that semimfuzz foundmoderate .
p.p.
drop a orig.
percep1significant .
p.p.
drop b orig.
percep2extreme .
p.p.
drop c orig.
percep3 d mutation e mutation f mutation g percep1 h percep2 i percep3 figure visualizing sut inconsistencies across severities best viewed on a screen sut inconsistencies resulting from mutations and that eachsuthadover100inconsistencies.further eachofthesuts exhibited at least one significant inconsistency and of the suts combined to exhibit a total of extreme inconsistencies.
the distribution of inconsistencies among the suts is unexpected.
nvidia semseg and efficientps the two highest scoringonthecityscapesbenchmark hadthehighestnumberof inconsistencies in all three categories with and respectively.
efficientps revealed more than three times the number of inconsistencies of the sut with the fewest inconsistencies.
for contextualizing the magnitude of the inconsistencies figure shows three mutations produced by semimfuzz and their interpretationsbytheefficientpssutbeforeandafterthemutation.the leftmost column shows a moderate inconsistency an added person occludesabus causingefficientpstothenclassifythebusasatrain.
themiddlecolumnshowsasignificantinconsistency anaddedcar occludes a train causing efficientps to correctly identify only part ofthetrain labelingtherestas donotcare .therightmostcolumn shows an extreme inconsistency an added car occludes a truck causingefficientpstomisclassifythetruck labellingportionsas do not care and the rest as building.
we also assess effectiveness of semimfuzz in terms of inconsistencies found over time.
figure shows the number of significantandextremeinconsistenciesfoundversusthenumberof mutated tests executed.
while semimfuzz generated tests thegraph showstheaverage of10permutationsto controlforparameter selection randomness.
figure shows that the number of inconsistenciesfoundcontinuestoincreaseevenat150 000tests indicatingthatfuzzinghasnotsaturated.againwenotethatthe twostrongestsutsonthebenchmarkyieldsignificantandextreme inconsistencies at a much higher rate than the other suts.
further analysisofthespecificsutsisneededtounderstandthefactorsinvolved in this performance but these data suggest that the highest performing suts may be more brittle under certain conditions.
sincesemimfuzz usesrandomtestandresourceselection we computed the number of duplicate tests generated as an indication ofsaturation.only1228 .
ofthe150 000testswereduplicates 1966icse may pittsburgh pa usa trey woodlief sebastian elbaum and kevin sullivan figure inconsistencies found over time table false positive rate for inconsistencies found sut false positive rate nvidia semseg efficientps decouplesegnet sdcnet hrnetv2 ocr suggesting that fuzzing was not near saturation.
this further highlightstheabilityofourapproachtogenerateordersofmagnitude moredatathantheoriginaltestsuitewhichcontained3 433tests suitable for mutation rendering a more than fold increase.
we have shown that semimfuzz can generate test cases that induce inconsistencies in the suts.
however one potential issue is thepresenceoftestcasesthatarenonconforming whichleadsto false inconsistencies.
as highlighted in section there are several factors that can result in a nonconforming test case and determining conformity is subjective.
still to gain a better grasp on the rate offalsepositiveswemanuallyinspectallthegeneratedtestcases that led to p.p.
drop and sample of the test cases that led to a drop between and p.p.. the process entailed each author examiningeachimageandclassifyingthemaseitheratruepositive or false positive.
if any of the three authors deemed an image a false positive it was conservatively recorded as such.
tofurtherconveythequalityofourassessment figure14showcases true positive and false positive test cases that induced inconsistencies in our study.
the false positive rates are shown in table2.thehighfalsepositiveratereflectsthechallengingapplication domain to achieve conformity.
still this high rate is mitigated bythenumberofinstancesonwhichitapplies.generating150 test cases produces a few hundred tests with inconsistencies of interest which developers can examine to understand performance orselectfuturetestingdirections.inthisexamination determining ifanimageisnonconformingtakesafewsecondsoftime meaning encounteringafalsepositiveincursarelativelylowcost.furthermore the number of inconsistencies found per sut is small and can be prioritized by the drop measure.
.
.
rq2results efficiency.
weconsiderefficiencybycomparing thetimefor semimfuzz tomutateatestwiththetimeforthesuts to run a test.
table shows the average time to generate each type of mutation 2nd row compared to the average time to run each sut on those tests 3rd 7th row in milliseconds with standard deviationinparentheses.foreachtablecell wegenerated100tests times and averaged the times across these trials.
the color change mutation was the fastest taking less than thetimeoftheaddmutations.thisisbecausetheconformitycheck for the color change mutation always passes so it spends less time selecting viable resources.
the add car mutation was slightly faster than the addperson mutation.
this is likelybecause it is easier to satisfy the conformity constraints it is more likely for a randomly sampledcartoappearontheroadthanarandomlysampledperson meaning fewer samples are needed to find a suitable car.
as expected wefoundthatforeachsutthetimeittakestoexecute the test is not different based on the mutation.
while the fastest sut hrnetv2 ocr takes about as much time to execute a test as semimfuzz does to generate a test we note that three of the suts take more than double that time and one nvidia semseg takesmorethan5timesaslong.further onceasetof mutationshavebeengenerated theycanbeusedinthefutureto testadditionalrevisionsofthesutatnoadditionalcosttoprepare.
table average time to generate and execute a test in milliseconds with the standard deviation in parenthesis.
activity add add color car person car test generation .
.
.
nvidia semseg .
.
.
efficientps .
.
.
decouplesegnet .
.
.
sdcnet .
.
.
hrnetv2 ocr .
.
.
.
.
rq results mutation types.
in this section we examine more carefullythe resultsper mutationtype.
figure 15shows the inconsistenciesfoundforeachsutbasedonthemutationtype note the log scale on the y axis.
the add car mutation induced the most inconsistencies followedbytheaddpersonmutation andthenthemutationtochangethecarcolor .theseresults reflect what we may expect adding a car affects a large portion of theimage leadingtoahigherlikelihoodofthemutationyielding an inconsistency.
h owever even though recoloring a car affects the same number of pixels as adding that car to another image we find that the suts are robust against changing the color of the car.
this suggests that editing large regions of the image even in a conformingmanner isinsufficient.thisfurthersupportsournotion thathighlevelsemanticmutationssuchasaddingacararerequired to exercise these perception systems and find inconsistencies.
.
threats to validity the external validity of our findings for semimfuzz are affected byourchoiceofdatasetandsuts.weselectedcityscapesforits 1967semantic image fuzzing of ai perception systems icse may pittsburgh pa usa a true positive b true positive c true positive d true positive e true positive f false positive overlapping g false positive lighting h false positive incorrect coloring i false positive perspective overlap j false positive incomplete entity figure sample of true and false positives best viewed on a screen figure inconsistencies by mutation type popularity as a benchmark of perception systems and for suts we selectedthetopfivethatmadetheirsourceavailableforreuseinthe cityscapescompetition.extendingthescopetodatasetssuchas nuscenes kitti andwaymo wouldhelpgeneralizethe findings.morebroadly theproposedapproachismoregeneralthan semimfuzz being applicable to other sensor data such as the commonplace lidar light detection and ranging for remote sensing.
this level of generalization remains to be tested empirically.
the internal validity of our findings may be affected by several factors.topamongthemistheimplementationofthemutations which is complex and includes external components and many parameters.inspiteofourvalidationefforts theycouldhavefaults.
wesharethecodetomitigatethatthreat.also byrestrictingthe initial tests to thoseon which the suts didwell we helped isolate the effect of the mutations.
however this constraint may have leftoutopportunitiestomaketeststhatrenderpoorresultseven worse.
we also attempted to control for the randomness of several nondeterministic components through repeated executions.
intermsofconstructvalidity althoughwehavequantitatively shown that semimfuzz can generate many test cases that yield inconsistencies our examination of false positives for conformity exhibits inherent bias.
we share the code to reproduce the test suite to mitigate this threat.
further the inconsistencies we found in terms of the percentage point drop may not extend to causefailures in real ass.
while section .
showcases several serious inconsistencies furtherstudyisneededtounderstandifandhow these inconsistencies would affect the entire as.
conclusion and future work we introduced a novel approach that automatically generates testcaseswithsensorreadingandground truthinterpretationpairsfor as perception systems.
the approach leverages domain specific semanticsandpriortestcasesbasedonreal worldsensordatato generatemutatedsensorreadingsthatstillconformtothephysical world.
our experimental prototype for images showed that lowcost and high level semantic mutations such as adding a car can uncover inconsistencies in state of the art perception systems.
semsensfuzz and our implementation semimfuzz set several directions for future work.
following standard software fuzzing wewillexaminehowtousesutperformancetoguidemutation type and parameterselection to more quickly findinconsistencies.
we willalso investigatehow to expandto other sensormodalities andaggregatereadingsfrommultiplesensorstomoreholistically test as perception systems.
this work also encourages several directions of research in computer graphics advances in which would likely translate quickly into improvements in semimfuzz .
testingasperceptionsystems requiresexaminingrare safetycritical scenarios which cannot be obtained practically from the realworld.wewilldevelopmoreadvancedmutationsthatincorporate these elements such as cars driving in the wrong direction damagedcars orpeoplesittingoncars.althoughthecurrentimplementation has the opportunity to generate some of these elements e.g.acardrivingthewrongdirection makingsuchmutationsan explicitdesign goalwill requiretheintegration ofricher datasets andthedevelopmentofmoresophisticatedmechanismstocheck conformity.
the ability to systematically generate these scenarios willfurtherbolstertheutilityofourapproachbygeneratingconformingsensorreadingsofeventsthatareimpracticaltootherwise obtain and have exhibited problems for real world deployed ass.