sapientml synthesizing machine learning pipelines by learning from human written solutions ripon k. saha akira ura sonal mahajan chenguang zhu linyi li yang hu hiroaki yoshida sarfraz khurshid mukul r. prasad fujitsu research of america inc. fujitsu ltd. the university of texas at austin university of illinois at urbana champaign rsaha ura.akira smahajan hyoshida mukul fujitsu.com cgzhu huyang khurshid utexas.edu linyi2 illinois.edu abstract automaticmachinelearning orautoml holdsthepromiseoftruly democratizingtheuseofmachinelearning ml bysubstantially automating the work of data scientists.
however the huge combinatorialsearchspaceofcandidatepipelinesmeansthatcurrent automl techniques generate sub optimal pipelines or none at all especially on large complex datasets.
in this work we propose an automl technique sapientml that can learn from a corpus of existing datasets and their human written pipelines and effi ciently generate a high quality pipeline for a predictive task ona new dataset.
to combat the search space explosion of automl sapientml employs a novel divide and conquer strategy realized as athree stage programsynthesis approach thatreasons on successively smallersearch spaces.
the firststage uses meta learning topredictasetofplausiblemlcomponentstoconstituteapipeline.
in the second stage this is then refined into a small pool of vi able concrete pipelines using a pipeline dataflow model derived fromthecorpus.dynamicallyevaluatingthesefewpipelines inthe third stage provides the best solution.
we instantiate sapientml as part of a fully automated tool chain that creates a cleaned la beled learning corpus by mining kaggle learns from it and uses the learned models to then synthesize pipelines for new predictive tasks.wehavecreatedatrainingcorpusof1 094pipelinesspanning 170datasets andevaluatedsapientmlonasetof41benchmark datasets including new large real world datasets from kaggle and against state of the art automl tools and baselines.
our evaluationshowsthatsapientmlproducesthebestorcomparable accuracy on27 of thebenchmarks while thesecond best toolfails to even produce a pipeline on of the instances.
this difference isamplifiedonthe10mostchallengingbenchmarks wheresapientml wins on instances with the other tools failing to produce pipelines on or more benchmarks.
these authors contributed to this work as interns at fujitsu research of america.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
concepts software and its engineering automatic programming.
keywords program synthesis machine learning automl program analysis introduction the explosive growth in machine learning ml applications over the past decade has created a huge demand for data scientists ds and ml practitioners to develop real world ml solutions.
the linkedin workforce report showed a shortage of ds nationwide thathadgrownto250 000by2020 .automatic machine learning or automl holds the promise of addressing this shortfall .
automl can improve productivity of data science teams and cover gaps in expertise.
given a dataset and a predictive task e.g.
classification or regression automl aims to create an ml pipeline that trains an optimized ml model for the given task.
simply put the pipeline is a sequence of ml operators that processes data to make it suitable for learning feature engineering fe fits a suitable ml model on it modelselection andcalculatesthepredictiveperformanceof the model.
one of the prominent instances of automl the subject of much research recently is creating supervised ml pipelines for tabular data .
this paper also focuses on this formulation of automl.
automl has been traditionally solved as a search and optimization problem selecting the best pipeline from a space of candidates .
however ml pipelines are also programs infactrelativelysmall highlystructureddomain specificprograms thatcouldbeamenabletoprogramsynthesis.further publicreposi torieslikekaggle andgithubcontainhundredsofthousandsof human written ml pipelines that could serve as starting points for synthesizingnewpipelines.indeed programsynthesisbymining orlearningfromexistingprogramcorporahasbeensuccessfully deployedforotherendpointsofsynthesis .emergingresearch demonstratesthepromiseofthisperspective formlpipelinesynthesis.ourworkalsofollowsthisphilosophy but offers a novel take on the core challenge of automl.
the central challenge of automl is the massive combinatorialsearchspaceofcandidatemlpipelinesitexposes compositions of different potential fe operators each applied on different columnsofthesubjectdataset composedwithoneofseveralpotentialmodelsortheirensembles.further eachpipelinecomponent may have its own space of hyper parameters.
previous automl ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa saha et al.
techniques adopt several approaches to combat this combinatorial explosion.
some try to search a restricted search space byexcluding fe from consideration searching specific pipelinetopologies orapre compiledexplicitcorpusofsyntheticpipelines .otherstrytoprunethesearchspaceby usinglearnedlanguagemodelscoupledwithaggressivedynamic evaluationof partialpipelines orbywarm startingsearchusing constraints mined from human written pipelines .
however navigatingthehugecombinatorialsearchspaceofautomlremains an open problem.
in fact noneof the above techniques apply fe transformstospecificdatasetcolumns asahumandswould.instead theyareblindlyappliedtothecompletedataset ostensibly to avoid injecting another set of hyper parameters into the search space.
insight.
our key insight is that the root cause of the automl search space explosion is because previous automl techniques reasononcompletemlpipelines combinations ofvariousmlcomponents as a single entity ostensibly to capture dependencies betweenmlcomponents.however weobservethatinmanypractical instances thedecisiononwhethertoincludeaparticularcomponent say an imputer in a pipeline can be made based primarily on properties of the dataset whether or not it has missing values independent of other components.
indeed human ds often employ suchbestpractices whenmanuallyconstructingmlpipelines.once thesetof plausiblecomponents touseforagivendatasetareknown theycanbeusedtoassembleatargetpipelineorasmallpopulation of plausible target pipelines to choose from.
this would substantially mitigate the combinatorial explosion coming from exploring arbitrary combinations of components.
further we hypothesizethat these ds best practices are represented in publicly available human written mlpipelines sayon kaggle .
thus these pipelines can potentially be mined to learn and then replicate human ds decision making to create viable pipelines for new datasets.
proposed approach.
pursuant to the above insight we propose an automl technique sapientml1 that can learn from a corpusofexistingdatasetsandtheirpipelines andgenerateahighqualitypipelineforapredictivetask onanewdataset.tocombat thesearchspaceexplosionofautoml sapientmlemploysanoveldivide and conquerstrategy realizedasathree stageprogramsynthesis approach that reasons on successively smaller search spaces.
the first stage uses meta learning to train a meta model offline phase which is then used to independently predict the suitabilityof each ml component with respect to the given dataset in the online phase .
specifically this meta model captures the re lationship between features of the dataset e.g.
the presence of missingdatavalues anddesiredcomponentsinthepipeline e.g.
adatainterpolationcomponent .thispredictionyieldsarankedlistofpipelineskeletons.eachpipelineskeletonisan unordered set of plausible ml components to constitute a pipeline each component mapped to specific or all dataset columns on which itshould be applied.
in the second stage the skeletons are then instantiated into a small pool of viable concrete pipelines using a pipelinedataflowmodel minedfrom thecorpus and asmalllibrary of standard implementations for each ml component.
for each candidate skeleton the pipeline components are correctly ordered 1anautomlapproachharnessingthewisdom sapere ofhuman sapien datascientists.and incompatible components discarded using the dataflow model and each component instantiated using code templates from the library.dynamicallyevaluatingthesefewpipelines themostexpensive operation in the third stage yields the best pipeline.
the concept of a multi stage approach employing more expensive analysesonsuccessivelysmallerspaceshasbeensuccessfullyusedin otherdomains includingautomaticprogramrepair andcode search among others.
our specific design is customized for ml pipeline synthesis.
weinstantiatesapientmlaspartofafullyautomaticend toend tool chain that mines datasets and corresponding pipelines from kaggle automatically cleans and labels each pipeline learns from this corpus and then synthesizes ml pipelines for predictive tasks on new datasets.
we evaluate sapientml on a set of 41benchmarkdatasets including10new large real worlddatasets fromkaggleandagainst3stateoftheartautomltools al auto sklearn tpot and4baselines.ourevaluationshows thatsapientmlproducesthebestorcomparableaccuracyon27 of the benchmarks while the second best tool al fails to evenproduce a pipeline on of the instances.
further on the most challenging10benchmarkssapientmlwinson9instanceswith the other automl tools failing on or more benchmarks.
this paper makes the following main contributions technique a learning based automl technique sapientml thatcanefficientlysynthesizehigh qualitysupervisedmlpipelines using a novel divide and conquer approach to circumvent the combinatorial state space explosion of automl.
tool animplementationof sapientmlaspartofanautomated tool chain that creates a cleaned labeled learning corpus bymining kaggle learns from it and uses the learned models to then synthesize pipelines for predictive tasks on new datasets.
evaluation asubstantialevaluationof sapientmlonabenchmark of datasets including new large real world datasets from kaggle comparing it to state of the art automl tools and baseline techniques for creating ml pipelines.
problem definition atabular dataset d x y dis sampled from a distribution overadomain x ywherexandydenoteaninputdomainandan outputdomainrespectively.
xiscomprisedof nrowsanddcolumns calledfeatures whereeachrowrepresentsanobservationconsisting ofdvaluesfrom x.similarly yiscomprisedof nrowsand tcolumns whereeachrowisa t tupleofvaluesorlabelsfrom y.asupervised predictivetask ondistolearnapredictionfunction h x ysuch thaty h x .
a predictive task is called a classification task when theyisdiscreteandcalleda regression taskwhen yiscontinuous.
for multi label classification and multivariate regression t .
applying supervised machine learning ml to a predictive task requires a training version of the dataset dtrainto train an ml model andaheldouttestdataset dtesttoevaluateitsperformance.
a single dataset dcan also be split into dtrainanddtest.
given a dataset d a nml pipeline p p is a sequence of fe componentsfollowedbyamodelcomponentthatrealizesagiven predictivetask.hence p c1 f c2 f .. ck f cm representsapipeline withkfe components and one model.
a pipeline component c c is comprised of one or more api calls and associated glue code thattogetherperformsanatomicdata specificpipelinetask e.g.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sapientml synthesizing machine learning pipelines by learning from human written solutions icse may pittsburgh pa usa angbracketleftfe ordinalencoder card4 .
.
.
.
angbracketright c prime f angbracketleftfe onehotencoder card4 .
.
.
.
angbracketright angbracketleftfe imputer card2 card3 .
.
.
.
angbracketright angbracketleftfe linearscaler x .
angbracketright angbracketleftfe databalancer x .
angbracketright angbracketleftmodel catboostclassifier x angbracketright angbracketleftmodel extratreesclassifier x angbracketright c prime m angbracketleftmodel xgbclassifier x angbracketright a predicted fe and model components by the skeleton predictor with their probability scores and rank respectively c prime f angbracketleftmodel catboostclassifier x angbracketright c prime f angbracketleftmodel extratreesclassifier x angbracketright c prime f angbracketleftmodel xgbclassifier x angbracketright b three skeletons generated by the pipeline seeding phase angbracketleftfe imputer card2 card3 .
.
.
angbracketright angbracketleftfe ordinalencoder card4 .
.
.
angbracketright angbracketleftfe linearscaler x angbracketright angbracketleftfe databalancer x angbracketright angbracketleftmodel catboostclassifier x angbracketright c first skeleton after ordering and redundancy removal figure artifacts of pipeline seeding and pipeline instantiation phases for ieee cis fraud detection example filling missing values or transforming a categorical column to a set of numeric columns.
there are two kinds of components i the fe components cf that transforms a feature x or a set of features x prime x includingdatawranglingtasks andii themodel components cm that performs the actual learning and prediction.
given dataset d dtrain dtest a predictive task on d and an accuracy metric e.g.
f1 score for classification and r2for regressionproblemsrespectively ouraimistocreateanexecutablemachinelearningpipeline pforthisdatasetandtaskthatmaximizes ondtest.weposethis pipelinesynthesis problemasaprogram synthesis problem with quantitative objectives akin to .
motivating example inthissection weillustratetheuse caseandmechanicsofour technique using a real world dataset ieee cis fraud detection providedbythecompanyvestaandhostedonkaggle.itcontains 591k rows of data each corresponding to an e commerce trans action represented by a rich set of features.
the features aremainly numeric e.g.
transaction amount and string categorical values e.g.
device type .
some features are missing in some transactions.thepredictivetaskistolabelatransactionasfraudulent or not based on its features i.e.
a binary classification task.
use case.
creating a pipeline for a predictive task may take a long time for a ds.
the ds needs to decide on the appropriateset of feature engineering fe cf and model cm components touse therightdatasetcolumns features toapplyeachofthem on and then instantiate them in the right order so the pipeline executesonthedataset d withouterrors.giventhehugespace of possibilities forthese decisions data scientiststypically rely on their understanding of d past experience and often brute forcetrialanderror tocompletethislaborioustask .automltools can accelerate this process substantially especially for a novice ds byprovidingherwithagood quality executablepipelinefor potential last mile optimization.
keychallenge.
real world large complexdatasetslike ieee cis fraud detection present particularly challenging cases for current automl tools.
in order to navigate the huge combinatorial searchspaceofpossiblecandidatepipelinestoolssuchastpot andauto sklearn restrictthemselvestonumericdata whichensures smaller simpler pipelines.
thus they cannot even run on the givendatasetsinceithasstringcategoricalfeatures.thestate ofthe art tool al uses a combination of learned language model andaggressivedynamicevaluationofpartialpipelinestosearchfor a viable solution.
however in this case it evaluates partial and1 310completepipelinesin1.5hours ona8vcpuand32gb memorymachine andfinallycrashesduetoaninternaltimeout without producing any pipeline.
sapientml s three stageprogramsynthesisapproachproves to be quite effective on this example.
in the first stage section .
sapientml uses a machine learned model trained on its metalearningcorpus ofhuman writtenpipelines togeneratearankedlistofpipelineskeletons toconstructviablepipelines.forthepresent example sapientml first predicts five potential fe components andthe topthree mostappropriatemodels infigure1a togenerate three pipeline skeletons in figure 1b.
the predicted components broadly agree with human intuition.
for instance ordinalencoder andonehotencoder are reasonable transforms to encode the stringbasedfeaturesinthedatasetandtheuseof databalancer comports withthe significantimbalance betweenthenumber offraudulent and valid transactions in the dataset.
further the choice of the catboost model is consistent with the previous research showingthat catboost performswellforclassificationonlarge imbalanceddata.
sapientml furtheruses thedecisionrules learnedby theskeletonpredictortoinfertherelevantfeaturesinthedataset where each fe transform will be applied.
for example figure 1a shows that sapientml targets card2 .
.
.
forsimpleimputer .
in the second stage section .
sapientml concretizes the pipeline skeleton into a set of executable pipelines.
to this end it uses the confidence scores included in the skeleton as well asapipeline dataflow meta model mined offline from the learning corpus to discard redundant fe components and order the componentsinasyntacticallycorrectfashion toproduceorderedskeletons as shown in figure 1c.
for instance the analysis concludesthat both ordinalencoder andonehotencoder are to be applied on thesamedatasetcolumnsbutcannotbesimultaneouslyused.thus onehotencoder whichhasalowerconfidencescore isdiscarded.as anotherexample imputerisorderedbefore ordinalencoder followingtheminedcomponentorderrelation.nexttheorderedskeletons are transformed into a set of concrete pipelines three in this case .
inthefinalstage sapientmlevaluatesthesecandidatepipelines on a held out validation dataset derived from only the trainingdataset notthetestingdataset andreturnsthehighestaccuracy pipeline.figure2showsanabridgedversionofthispipeline.the pipeline implements a rich set of five fe components each applied to its appropriate columns and paired with a catboost gradientboosting classification model.
sapientml takes only mins to produce this pipeline and produces a respectable .
f1 score.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa saha et al.
import pandas as pd load data train dataset pd.read csv training.csv delimiter test dataset pd.read csv test.csv delimiter from sklearn.impute import simpleimputer fe transform import numpy as np numeric cols with missing values for col in numeric cols with missing values imputer simpleimputer missing v alues np.nan strategy mean train dataset imputer.
fit transform train dataset .values.reshape test dataset imputer.transform test dat aset .astype train dataset .dtypes .values.reshape string cols with missing values fe transform ... apply simpleimputer forstring columns similar to the fe transform s hown above from sklearn.
preprocessing import ordinalencoder fe transform ... apply ordinalencoder to categorical columns feature train train dataset.
drop axis detach target target train train dataset feature test target test test dataset.
drop axis test dataset from sklearn.
preprocessing import standardscaler fe transform ... apply standardscaler to feature train and feature test from imble arn.over sampling import smote fe transform feature train target train s mote .fit resample feature train target train from catbo ost import catboostclassifier model model catboostclassifier model.fit feature train target train y pred model.predict feature test from sklearn import metrics evaluation print metrics.f1 score target test y pred a verage macro figure abridged version of pipeline generated by sapientml for the ieee cis fraud detection prediction task approach .
overview figure3presentsahigh leveloverviewofthesapientmlsystem.it has an offline and an online phase.
in the offline phase sapientml creates a corpus of human written pipelines and their datasets calledthe meta learningcorpus byminingdata sciencerepositories kaggleinourcase andautomaticallycuratingthedataforlearning through denoising augmentation and labeling.
the meta learning corpus is then used to build two meta models namely the skeleton predictor meta model and the pipeline dataflow meta model.
in the onlinephase givenanewdatasetandapredictivetask classificationorregression definedonit sapientmlusestwometa models to synthesize a supervised ml pipeline for the given dataset and task which maximizes some accuracy metric e.g.
f1 or r2 .
sapientml navigates the huge combinatorial search space of automl through a novel three stage program synthesis approach that reasons on successively smaller search spaces.
the first stage calledpipeline seeding uses the skeleton predictor derived through meta learning on the meta corpus to independently predict the suitability ofeachmlcomponenttoappearinanmlpipelinefor thegivendataset basedonthemeta featuresofthedataset.this predictionyieldsa pipelineskeleton anunorderedsetofplausible components toconstituteasolutionpipeline.inthesecond pipeline instantiation stage this skeleton is concretized into a small pool of viablecandidate pipelines using the dataflow meta model mined fromthecorpus tocorrectlyorder minimize andinstantiatethepipelinecomponents.thefinal pipelinevalidation stageselectsthe highest accuracy ml pipeline among the candidate pipelines by dynamically evaluating them.
the following sub sections describe the meta corpus creation and the three pipeline synthesis stages.
.
creation of the meta learning corpus thisstepautomaticallyminesandcuratesahigh qualitycorpusthat includes human written ml pipelines and their datasets to power themeta learningof sapientml.thesepipelinesnaturallycapture theexpertiseanddomainknowledgeofhumandsasopposedto creating a relatively small homogeneous synthetic ml pipeline corporausedbysomeotherautomltechniques thatincurs significantcomputationalcost.tobuildthecorpus wefirstmine the datasets and their pipelines from kaggle apopular datascience repository.
specifically we collected top datasets based on user votes and up to top voted pipelines per dataset giving us around initial pipelines.
these raw pipelines and datasets arefurtherdenoised augmented andlabelledtomakethemsuitable for learning by sapientml.
our final corpus is comprised of pipelines across datasets.
.
.
denoisingpipelines.
human writtennotebooksonkaggle oftencontain noiseintheformofexploratorydataanalysis visualization and debugging code that while useful for human comprehension areirrelevanttomlmodelexecution.further some pipelinesmaynolongerbeexecutableduetovariousissuessuch asdeprecatedapisanddifferencesintheruntimeenvironment.to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sapientml synthesizing machine learning pipelines by learning from human written solutions icse may pittsburgh pa usa figure overview of sapientml system.
constructacleanmeta learningcorpus wefirstdiscardanypipeline that fails to run successfully on our environment.
then to remove the noise in each executable pipeline p we first heuristically identify a criteria line lcr which performs the final prediction task.
inpipelinesusingthepopularpythonmllibrariessuchasscikitlearn and xgboost this is typically a call to the predict api function.
then we compute a forward slice pfo rwand a backward slice pbackfromlcr by applying standard dynamic program slicing and concatenate pfo rw lcr andpbackto yield the clean pipelinepclean.
we compare the accuracy scores of pandpclean and discard pcleanif it obtains a lower score than p. .
.
augmentingpipelines.
thisstepismotivatedbytheobservation that human written pipelines may not contain the best representativemlmodelchoiceforeachdataset.thiscouldhappen in pipelines written by novice data scientists or because of the availability of newer better models after thepipeline was written.
presenceof sub optimalmlmodelsinour meta learningcorpus inturndegradesthequalityofthepipelinessynthesizedbysapientml.
to alleviate this problem we employ a data augmentation technique to systematically replace sub optimal models in metacorpus pipelines with better i.e.
higher accuracy models.
dataaugmentation is commonly employed in machine learning flows to improve the predictive quality of training data.
generation of candidates.
to improve the performance score ofadenoisedpipeline pcleanwithmodel cm ourdataaugmentation techniquesystematicallyreplacesthemodel cminpcleanbyeach viable model in the corpus cm c1m ... cbm one at a time t o create a set of candidate pipelines pmutated p1 clean...pb clean .
toidentifythecodefor cm westartwith lcr definedinsection4.
.
andcomputeabackwardsliceuptothemodeldeclaration.nextweidentifythevariablenamesofthemodelobject xtrain ytrain xtest andytestthroughstaticanalysis.finallywereplacethedeclaration of the old model cmwith a new model cimto generate pi clean.
selection.
each mutated pipeline in pmutatedis run on the corresponding dataset and the best mutated pipeline pbest clean showing the highest improvement in the performance score replaces the original pipeline in the corpus.
.
.
creationofabstractpipelinesformeta learning.
theobjective of creating a meta learning corpus is to provide sapientml necessarytrainingdatatolearntherelationshipbetweenvarious dataset properties and ml comp onents.
however since humanwrittenmlpipelinesarediverseintermsofimplementation itis challengingtolearntherelationshipsbetweenvariousdatasetpropertiesandrawcodesnippets.tokeepthemeta learningtractable we represent a pipeline at an abstract level as a sequence of ml components p c1 f c2 f .. ck f cm whereci fandcmrepresent the labels of fe and model components respectively.
to this end first we automatically annotate each component with a label that has two pieces of information angbracketleftcomponent type api name angbracketright.weprimarilydistinguishtwotypes of components feature engineering fe andmodel.
the automatic labelingprocessinvolvestwosteps i extractingtheapiname and ii identifyingwhetheraparticularapiisan feoramodelcomponent.
we perform an ast analysis to extract api names from each statement ignoring any apis that are part of boilerplate code.
for example almostevery feengineeringapis inscikit learn library areaccompaniedbyatemplatecodethatcontains fit transform orfit transform apis.
once we have all the api names we first annotate the model component already identified in section .
.
for each pipeline in our corpus .
all components appearing before the model component are labeled as fe components.
atthispoint theabstractpipeline pispresentedattheapilevel.
however there are many labels in the corpus that are functionallysimilaracrosspipelines.forexample adatascientistcanuse either the fillnaapi from pandasorsimpleimputer fromsklearn to fill out the missing values in a dataset.
to learn meaningfulpatterns of meta features with respect to these labels we have togroupthecomponentsthataresemanticallysimilar.applying domain knowledge in ml is a standard practice and meta learning isnoexception.therefore weinvestigatedthelabelsinourproject corpus and group them based on their functionality by studyingthe api documentation.
then we assigned each group a func tional label.
for example we grouped fe fillna fe interpolate fe simpleimputer andfe knnimputer togetherandmappedtoaunified label fe imputer since they all are used to impute missing values in a dataframe.
.
stage pipeline seeding givenadataset d andpredictivetask theobjectiveofthepipeline seedingstageistoproduce aranked listof pipelineskeletons s .
this is used to constitute concrete candidate pipelines in the subsequent pipeline instantiation stage section .
.
a pipeline skeleton s is a unordered set of plausible ml components that includes zero or more fe components and one model component definition .
.
to predict the ml components in s sapientml uses a meta learning model called the skeleton predictor trained during the offline meta training phase.
the skeleton predictorisarchitectedasasetofsub models eachofwhichlearns amappingbetweenproperties meta features ofadataset dand authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa saha et al.
table summary of meta features high level property meta features shape of dataset number of rows features and targets missing entries presence of missing values feature types presenceand features whosedatatypeisnumeric number category string category text and date.
measure of symmetry skewness and kurtosis normal uniform and tailed measure of distribution normal uniform and poisson distribution for features and target tendencyanddispersion normalized mean standard deviation variation across columns correlated features pearson correlation min max number of correlated features outliers features that contains few or many outliers.
value frequency numberoffeatureswhosevaluesaresparse imbalanced dominant target property imbalanced continuous or categorical.
table meta targets c classification r regression feature engg.
model c r model c r imputer randomforest x x svm x x ordinalencoder extratrees x x linearsvm x x onehotencoder lightgbm x x logisticregression x x textvectorizer xgboost x x lasso x textpreprocessor catboost x x sgd x x datefeaturization gradientboosting x x mlp x x linearscaler adaboost x x multinomialnb x logscaler decisiontree x x gaussiannb x databalancer the likelihood of a specific ml component meta target appearing in a pipeline for d. definition .
meta features .
a set of meta features 1 2 ... l quantifythecharacteristicsofadatasetwhereeach meta featureiscomputedbyafunction i d rthattakesthe dataset as input and outputs a real number.
.
.
designofmeta features.
agoodsetofmeta featuresshould havethreeproperties i theyareexpressiveenoughtocharacterize the dataset ii they are succinct enough so that there exist some meaningful patterns that skeleton predictor can learn with respect tothemlcomponents andiii theyareefficienttocompute.for example thechoiceof feandmodelcomponentoftendependson the meta features such as number of records and features in d and feature types.
based on the existing literature and ourexperience wecompute38meta featurestocharacterizethe datasets in our meta training corpus.
table presents the list of meta features used in sapientml.
definition4.
meta targets .
asetofmlcomponents c cf cmthatdefinethepredictionspaceofskeletonpredictorwhere cf andcmrepresent fe and model components respectively.
.
.
meta targets.
each ml component in the abstract pipelines created in section .
.
is a valid meta target for sapientml.
however tolearnanymeaningfulpatternbetweenmeta features andaparticularmlcomponent c weneedsufficientoccurrences ofcin the meta corpus.
therefore we excluded any ml componentsthatappearedlessthanfivetimesinourcorpus.thisfiltering criteria provided us fe components and model components classification models and regression models as meta targets.
table2summarizesthemlcomponentsthatsapientml smetamodel predicts.
.
.
design of skeleton predictor meta models .
given a setof meta features computedfrom d theobjectiveofskeletonpredictor is to predict a set of plausible fe components and model componentstogeneratepipelineskeletonsdefinedindefinition4.
.
definition .
skeleton .
a skeleton s angbracketleftc1 f x1 1 angbracketright ... angbracketleftcq f xq q angbracketright cm x isasetoftuplescomprised ofqfe components and one model component where angbracketleftci f xi i angbracketright represents that the fe component ci fwill be used in the pipeline with a probability iand applied on xi xfeatures in d. weusethefollowinginsightstodesignourskeletonpredictor.
first apipelinemayrequireseveralfecomponentsandinmany cases the decision of using a particular fe component can be made based on a few meta features without depending on other fe components.although occasionallythere canbesome dependencies betweenthemlcomponents ourexperimentalresultsshowthat this design decision leads to faster generation of pipelines without sacrificing accuracy.
to this end we design the fe component predictorasasetofbinaryclassifiers 1 ... 9 thatpredictswhether aparticularfecomponent ci f cfshouldbeusedinthegenerated pipelineforthetargetdataset d.ontheotherhand sincebydesign sapientml allows only one model cm cmin a skeleton we cast the model selection problem as a ranking problem and design a learning to rank model to rank all the model components for d. definition4.
skeletonpredictor .
theskeletonpredictoriscomprisedofasetofsub models 1 ... 9 m whereeachsubmodel approximates a function i rl y prime iwhere rlis a set of meta featurevaluesand y prime iisaprobabilityscoreofanmlcomponent meta target appearing in a pipeline for d. sub modelstopredictthefecomponents.
fecomponents are generally applied on a sub set of features of d. for example an fe imputer isgenerallyappliedonthefeatureswithmissing values.
therefore sapientml aims to predict not only an fe component ci f fordbut also infers the subset of features x prime x indon which ci fwould be instantiated on.
to facilitate the determinationof x primeforci f adecisiontreeclassifier isanaturalfit since the classifier would learn a set of precise conditions w.r.t.
the meta featurestoselect ci ffordandlaterwecananalyzethoseconditions to infer x primeforci f. however decisiontree models tend to overfit with a large number of features .
to minimize the effect ofirrelevantfeatures wefirstperforma pointbiserialcorrelation analysis between the meta features and each fe component ci f and use only the meta features prime that exceeds a certain correlation threshold to train i. as a result we get a set of binary classifiers 1 ... 9 asthefecomponentspredictorwhere iis used to predict ci f. sub model to rank model components.
unlike the predictionoffecomponents whichoftendependsonafewmeta features it is challenging to determine a few meta features that can predict the performance of a particular model on d .
therefore instead of predicting one model based on a few meta features we design a learning to rank sub model that considers all the meta features to rank all the model components in our corpus.
considering the size of our meta training dataset which is not very authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sapientml synthesizing machine learning pipelines by learning from human written solutions icse may pittsburgh pa usa largeandthefactthattheensemblemodelsarebetterthanasingle model for complex learning task we designed an ensemble oflogisticregression andsupportvectormachine to rank the model components.
more specifically these meta models first compute a probability score for each model component and use the average score to sort the target model components.
.
.
trainingtheskeletonpredictor offline .
wetrainedallthe sub modelsintheskeletonpredictorusingthemeta trainingcorpus.
since the proportion of pipelines having and not having a ml component is not equal in the corpus we used balanced weighting strategytosolvethe classimbalance problem.further wetunedthe hyper parameters through5 fold crossvalidation andgrid search.
.
.
generation of pipeline skeletons online .
during pipeline generation sapientmlfirstcomputesthesetofmeta features fromdand passes it to the skeleton predictor which returns a set of plausible fe components c1 f...cq f with probability scores and a ranked list of the model components c primem .
inferringrelevantfeatures.
foreachci finthepredictedset sapientml infers the relevant features x prime i xindon which ci f canbesuccessfullyappliedandcreatethesemi instantiatedsetoffe components c prime f angbracketleftc1 f x1 1 angbracketright ... angbracketleftcq f xq q angbracketright .suchinference is important to help avoid pipeline failures caused by infeasible transforms suchas stringvectorizer appliedtoanumericcolumn.
further ithelpspreciselyidentifythecolumnsmostsuitableforthe fetransform e.g.
applying simpleimputer toonlythosecolumns that have missing values.
to infer relevant features for ci f first sapientml access the thesub model i whichisadecision treeclassifierthatpredicted ci fford.
then sapientml extracts the decision path that led to the prediction.
a decision path is a list of conditions in form of where op andvcorrespond to a metafeature or and a real number respectively.
then sapientml iterates over each feature xi xand selects xionly if it satisfies at least one of the conditions in the decision path.
for example sapientmlcorrectlyappliesthe ordinalencoder oncard4 which is a string categorical feature whereas it marks the transactionamt feature as irrelevant which is indeed a numeric feature.
generation.
finally sapientml selects top kmodels from c primem and adds one by one to the selected fe components to generate k number of pipeline skeletons s c prime f c1m ... c prime f ckm .
.
stage pipeline instantiation this stage synthesizes a set of concrete pipelines for the given user dataset d and its predictive task.
given a ranked list sof pipeline skeletons produced by pipeline seeding section .
this stage instantiates each skeleton sinto a concrete pipeline pby firstcreatinganorderedskeleton sorepresentingasyntactically viable data flow and then instantiating the components in sointo apipelinetemplate alongwithnecessarygluecode.thisyieldsa set ofkcandidate pipelines pcand p1 p2 ... p k .
.
.
create ordered skeleton.
the goal of this step is to order thecomponentsof s anddiscard incompatiblecomponents ifany to produce an ordered skeleton so such as the one shown in figure1c.thisoperationusesapipeline dataflowmeta model extracted bysapientml fromthemeta learningcorpus duringtheoffline phase.wedevelopthedescriptionusingthefollowingterminology.
definition .
dataflow dependence .
there exists a dataflow dependence between components ciandcjof a pipeline pfor a datasetdiff there exists feature xiofdon which both ciandcj are applied in p. there exists a dataflow from citocjinp denoted cip cj i ff thereisadataflowdependencebetween ciandcjandciprecedes cjinp.
dataflow dependence as defined above can be inferred throughasimplestaticanalysis.thedetailsareelidedforbrevity.
although neither sound nor complete this definition provides a simple efficientwaytocapturedataflowinallbutthemostcomplicated pipelines.
the dataflow meta model is a partial order relation capturing the dataflow between pipeline components as observed in the corpus pipelines.
specifically ci cj c c p p l cip cjand nexistsp prime p l cjp prime ci the dataflow meta model is represented as a directed acyclic graph dag g whosenodesarethecomponents canddirected edges ci cj .
askeleton sproducedbypipelineseedingistransformedinto anorderedskeleton sousingthefollowingsteps.first alldataflow dependenciesarecapturedbetweenpotentialskeletoncomponents usingdefinition4.
.ifthereisanycomponentpair ci cjthathas a dataflowdependence butno edgebetween ci cjing thisindicates anincompatiblecomponent.
hencethe componentwith the lowerpredictedprobabilityisdiscarded.inourmotivatingexample figure1 components onehotencoder andordinalencoder which happen to be semantic substitutes of each other e.g.
convert categoricalcolumns tonumeric presentsuch aninstance.hence the lower probabilitycomponent onehotencoder is discarded.discarding all such components yields a reduced skeleton s prime.
next a sub graph of the dataflow meta model g with only the nodes in the reduced skeleton s primeis extracted.
finally a topologicalsortonthis sub graphprovidesacomponentorderforthe reduced skeleton s primeconsistent with g .
this order is to create the ordered skeleton so.
for our motivating example imputerprecedesordinalencoder inso.reversingtheorderforacolumnwith missing values would result in a pipeline crash.
.
.
generate concrete pipeline.
each ordered skeleton sois converted into a concrete pipeline pby instantiating each component c soin order into a pipeline template of the kind shown in figure .
specifically each c c f cmis instantiated using a parameterized snippet drawn from a small pre compiled library ofstandardcomponentimplementations byappropriatelyfilling the parameter holes.
for example ordinalencoder is instantiated by filling the columns hole with relevant columns productcd card4 ... .sapientmlcanalsohandletype basedinstantiationof components.
for example simpleimputer is instantiated differently for filling missing values in numeric vs. string columns.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa saha et al.
.
stage pipeline validation each candidate pipeline p p candis dynamically evaluated to computeanaccuracyscore f1 r2 tofindthebest pipeline pbest.
sapientml internally splits the user provided training data dtrain intointernaltraining and validation sets which are used for the training and validation of candidate pipelines within this stage.
therefore the held out testdataset dtest shown as test.csv in figure is completely unseen to sapientml.
finally pbestis used to train on dtrainand evaluated on dtestfor the accuracy score returned to the user.
evaluation our evaluation addresses the following research questions rq1 how does sapientml perform compared to the existing state of the art techniques?
rq2 how robust sapientml is in producing good quality pipelines across trials?
rq3 doessapientmluseitssearchspacewelltopredictadiverse set of fe and model components?
rq4 does each of the novel technology components of sapientml contribute to its effectiveness?
.
experimental set up .
.
implementation.
sapientmlisimplementedinthepython programming language using approximately lines of code.
it includes a crawler to download ml projects a set of tools for requiredstaticanddynamicanalysissuchasminingtheorderof ml components from a corpus denoising pipelines a meta feature extractor and machine learning models for the skeleton predictor.
sapientmluseskagglepublicapis forautomaticallydownloading data the python pllibrary to instrument sourcecode for dynamic program slicing the scikit learn library to implementmeta modelsfortheskeletonpredictor andlibcst for static analysis.
sapientml uses pandas numpy and scipy for computing meta features and its own data analysis.
.
.
benchmarks.
weuseasetof41benchmarkdatasetstoevaluate sapientml.
this includes the set of datasets used in al .
they include datasets from the openml suite from pmlb from mulan and from kaggle.
however since most of these datasets are small and simple in nature we have added new datasetsfromkaggleasrepresentativesoflarge real worlddatasets whichmodernautomltoolsshouldhandle.tosystematicallyselectthe10newbenchmarkdatasetswecollectedallthe featured andplayground kagglecompetitionscompletedsincetheyear2015.
from these we selected ones operating only on tabular data and wherethelicensepermitsacademicresearchanduseoutsidethe competition.
finally we selected datasets based on size either in termsoflargenumberofrowsorcolumns orhavevarioustypes ofcolumns.table3presentsthesize predictiontask andsource repository for each benchmark dataset.
.
.
experimental methodology.
sapientml is trained on our meta learning corpus of pipelines and corresponding cleaned datasets.
therefore the benchmark datasets are completely unseento sapientml.
similar to al and auto sklearn we performed10trialsofeachexperimentforeachbenchmarkwitha one hour time out.
for each trial we randomly split the userprovideddatasetinto trainingandtestingdataina75 25split.then sapientmlgeneratedapipelineusing onlytheuser provided trainingdataandthenreporteditsaccuracyonthe user provided testing data.allthebaselinesandexistingtoolswererunusingthesame train test split of data in each trial to ensure a fair comparison.
we usestandard macrof1scoresand r2scoresforclassificationand regressiontasksrespectively andusedthemeanscoreof10runsto comparetheresults followingexistingliterature .weran all tools on vcpus of xeon e5 2697a v4 .60ghz with 16gb memory for openml pmlb and mulan datasets and on vcpus with 32gb memory for kaggle datasets.
.
rq1 sapientml versus state of the art we compared the performance of sapientml to three state of theart automl systems auto sklearn ver.
.
.
tpot v e r .
.
.
and al from its public distribution using the same configurationsasin .auto sklearnisanactivelymanagedopensourceprojectongithubwithmorethan6kstars.alrepresents the most recent automl technique that also learns from humanwritten pipelines to generate supervised pipelines.
in addition we implementedtwobaselinetoolsbasic mlanddefault representingbasicmltechniques followingthemethodologydescribedin .
specifically basic ml applies simpleimputer to fill numeric and string missing values with and empty string respectively countvectorizer to transform all string columns to token counts and thenuses the logisticregression andlinearregression modelsforclassificationandregressiontasksrespectively.defaultalways predicts the most frequent label for classification tasks or the mean value for regression tasks.
.
.
quantitative comparison.
table presents the evaluation results in terms of average macro f1 and r2scores over runs for classification and regression tasks respectively.
highest scores for each benchmark are marked as bold.
we call them as champion.
furthermore weperformedapair wisewilcoxon signed ranktest .
toseewhetherthescoredifferencebetweenthechampion and another tool for a benchmark is statistically significant across trials.
the underlined numbers represent the scores that are statistically similar to the champion.
we call them as winners.
we start by comparing the two baseline tools basic ml and default to all other tools.
as expected default s simplistic prediction performedtheworst.interestingly basic mlisthechampionon 4datasets sincesomeofthedatasetsaresimpleanddonotneed any sophisticated pipelines.
however basic ml s overall performance is poor compared to any other automl tools in terms of meanf1 r2scores.therefore thisresultsupportsthe nofreelunch hypothesis that no single pipeline is good for every dataset.
comparing the performance of sapientml to other automl tools table shows that sapientml outperforms the state of theartautoml toolsintermsof successfulpipelinegeneration number of champions and winners.
sapientml generated a successful pipelineforeachbenchmarkandtrial whereasal auto sklearn andtpotfailedon9 and12datasetsrespectively.there are several reasons for failures including not being able to handle various types of data unexpected exceptions applying fe components on inappropriate columns or timeout.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sapientml synthesizing machine learning pipelines by learning from human written solutions icse may pittsburgh pa usa table effectiveness of sapientml compared to the state of the art automl tools on the benchmark datasets.
bold numbers indicatethebestscores underlinednumbersarenotstatisticallydifferentfromthebestscoresaccordingtoawilcoxon signedrank test .
.failedmeans the tool has failed on all the trials whereas f means the tool has failed on ntrials.
dataset sapientml al auto sk.
tpot basic ml default base.
base.
metric source rows cols .
.
.
.
.
.
.
.
f1 openml .
.
.
.
.
.
f .
f1 openml .
.
.
.
.
.
f .
f1 openml .
.
failed failed .
.
f .
f1 openml .
.
failed failed failed .
.
.
f1 openml .
.
.
.
.
.
.
.
f1 openml .
.
failed failed .
.
.
.
f1 openml .
.
.
.
.
.
.
.
f1 openml .
.
failed failed failed .
.
.
f1 openml .
.
.
.
.
.
.
.
f1 openml .
.
.
.
.
.
.
.
f1 openml .
.
.
.
.
.
.
.
f1 openml hill valley with noise .
.
.
.
.
.
.
.
f1 pmlb hill valley without noise .
.
.
.
.
.
.
.
f1 pmlb breast cancer wisconsin .
.
.
.
.
.
.
.
f1 pmlb car evaluation .
.
.
.
.
.
.
.
f1 pmlb glass .
.
.
.
.
.
.
.
f1 pmlb ionosphere .
.
.
.
.
.
.
.
f1 pmlb spambase .
.
.
.
.
.
.
.
f1 pmlb wine quality red .
.
.
.
.
.
.
.
f1 pmlb wine quality white .
.
.
.
.
.
.
.
f1 pmlb detecting insults in social comm... .
.
failed failed .
.
failed .
f1 kaggle housing prices .
.
failed failed .
.
failed f r2 kaggle mercedes benz .
.
failed failed .0e .
.
failed r2 kaggle sentiment analysis on movie rev... .
.
failed failed f .
failed .
f1 kaggle spooky author identification .
.
failed failed .
.
.
.
f1 kaggle titanic .
.
failed failed .
.
failed .
f1 kaggle enb .
.
.99failed .
.
.
.
r2 mulan jura .
.
.
failed .
.
.
.
r2 mulan sf1 .
f failed failed failed .
.
.
r2 mulan sf2 .
f failed failed failed .
.0e .6e r2 mulan costa rica .
.
failed failed .
.
.
.
f1 kaggle categorical feature enc... chal... ii .
.
failed failed failed .
failed failed f1 kaggle porto seguros safe driver pred... .
f .
.
.
.
.
.
f1 kaggle kobe bryant shot selection .64failed failed failed .
.
failed .
f1 kaggle whats cooking .71failed failed failed .
.
.
.
f1 kaggle pubg finish placement prediction .93failed .
.
.
.
.
.
r2 kaggle santander value prediction chal... .
failed .
.
.2e .
.
failed r2 kaggle ieee cis fraud detection .82failed failed failed .
.
failed failed f1 kaggle quora insincere questions class... .
.
failed failed failed .
failed .
f1 kaggle donorschoose.org app... screening .
f failed failed failed .
failed failed f1 kaggle champions winners failures intermsofperformancescore sapientmlischampionfor18 subjects whereas the second best tool al based on the number of successful pipelines is champion for only datasets.
on theother hand although auto sklearn failed on highest number of datasets itischampionfor9datasets.theseresultsindicatethat auto sklearnperformswellinalimitedscope.however although al has a broader scope it has overall performed moderately.
interestingly sapientml outperforms them both in terms of scope and performance.
the same findings also hold in terms of number of winners.
sapientml performed the best or comparable to the best for datasets which is the highest among all tools.
for the more difficult datasets marked with a in table the largest row columns datasets requiring at least one fe component sapientml performs even better relative to other tools.sapientmlproducesbestorcomparableperformanceon9 of them with al failing to produce a pipeline on of them and tpot auto sklearn on most of them.
these results illustrate the value of sapientml s divide and conquer synthesis to produce viable pipelines especially for large complex datasets.
.
.
qualitative analysis.
we analyze the results qualitatively using a few concrete examples.
benchmark openml presents an interesting case where every tool produced a pipeline since thedataset contains only numeric values.
al predicted and selected xgboostclassifier through dynamic evaluation which achieved a macro mean f1 score of .
.
al s prediction may suffer sinceit uses language model which depends on the previous two com ponents for prediction.
however there is no need for fe compo nents for this dataset.
auto sklearn selected a pipeline based on datasetsimilaritythatperformsstandardscalingfirstandthenuses gradientboostingclassifier .
it achieved an f1 score of .
better than al.
however sapientml predicted an even better model randomforestclassifier which achieved the best f1 score .
.
for the sentiment analysis on movie reviews dataset autosklearnsimplyfailedsinceitcannothandletextualdata.incontrast al and sapientml both successfully generated pipelines by using atextvectorizer componenttoconverttexttonumericcolumns.
however al selected the linearsvc model that resulted in an f1 scoreof0.
.ontheotherhand sapientmlselectedanadditional authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa saha et al.
sd standard deviation et execution time figure robustness of sapientml0 .
.
.
.
.
.
.35ordinalencoderonehotencoderimputerlogscalardatabalancerstringvectorizertextpreprocessinglinearscalardatefeaturization figure distribution of fe predictionsextratreesregressorcatboostregressorlinearregressiongradientboostingregressorlgbmregressorrandomforestregressor .
.
.
.
.
figure distribution of model predictions text preprocessing components that performs some basic cleaning and normalization of text.
further it selected a better model catboost that provided an f1 score of .
.
finally the juradatasetpresentsanegativeexampleforsapientml where al achieved a significantly better score.
on investigating the reason we found that al selected a model called ridge whichisnotusedinourprojectcorpus.evenforal thisparticular model was not highly ranked by its meta model.
however since al set a beam size of for this dataset i.e.
it evaluated different models to select the best model al was successful in this case.
al could afford to perform such extensive evaluation for this dataset simply because the dataset is small and hence the dynamic evaluation is fast.
however for this extensive dynamic evaluation alfailedtoproduceanypipelineforlargedatasetssuchas ieee anddonorsdue to timeout.
in contrast sapientml uses only top models based on its meta model and performs overall the best.
.
rq2 robustness of sapientml weanalyzetherobustnessof sapientmlingeneratingpipelines in terms of variation of performance scores and execution timeacross trials.
to investigate how much sapientml fluctuates across trials we calculated the standard deviation of performance scores and execution time across trials for each benchmark dataset.figure4presentsthedistributionofthestandarddeviations across10trialsfor41benchmarkdatasets.theresultsshowthat sapientmlisoverallverystableacrossthe10trialsintermsofboth accuracyand execution time.boththe50th percentile mean and 75th percentile standard deviation for macro f1 r2 scores across allthebenchmarkareonly0.
whichismorestable thanthatof al whichare0.03and0.04respectively.thesameistrueforthe executiontime.the50thpercentileand75thpercentilestandard deviationofexecutiontimeareonly3and9secondsrespectively for sapientml which are and seconds respectively for al.
finally weinvestigatewhetherthegeneratedpipelinesareoverfitted to the corresponding training data.
to prevent overfitting we already made sure that sapientml generates pipeline only using75 data andthegeneratedpipelineistestedon25 held out test data.
however in this rq we investigate even further.
gen erally overfitting happens when a model performs very good onthe validation data but performs poorly on the test data .
to this end we compute the internal validation score based on whichsapientmlselectedthebestpipeline.thenwecomparethevalidation accuracy with held out test accuracy.
as the fifth boxplot in figure shows the 50th and 75th percentile difference between test and validation accuracy are .
and .
respectively.
andinterestingly the differences are positive which means that thefinal test scores are better than the validation scores for most of the subjects.
we could not compare this result with any other tools since we do not have access to their validation scores.
.
rq3 diversity in meta prediction figure 5presentsthe distributionof predictedml components in pipelines skeletons for all benchmarks and trials.
the results show thattheskeletonpredictorwasabletopredictallthe9fecomponentssuccessfully.amongthesecomponents accurateprediction ofimputer ordinalencoder oronehotencoder textvectorizer and datefeaturization isimportantsinceanyfalsenegativepredictions may lead to a crash during pipeline execution.
since sapientml is abletoproduceasuccessfulpipelineforeachtrialineachbenchmark dataset it isevident thatthe skeletonpredictor accurately predicted these components.
similarly as figure shows the skeleton predictor is able to predict a wide range of model components.morespecifically itpredicted11differentclassification and regression models for classification and regression tasks respectively.
as expected some models such as catboost and randomforest are dominant since they are fundamentally better.
however traditionalmodelssuchas logisticregression orsvcare alsopredicteddependingonthedataset.theoverallresultssuggest that the predictions were effective for most of the datasets.
.
rq4 impact of novel components this research question investigates the contribution of sapientml s two main components i pipeline seeding and ii pipeline instantiation.
to this end we create two baselines baseline1.
thisbaselineusestheskeletonpredictedbypipeline seeding but instantites each fe component on the entire dataset.
baseline2.
inthisbaseline wefurtherrelaxbaseline1byreplacingthe pipelineseeding bya commonskeletonto understandthe combinedeffectofpipelineseedingandinstantiation.tocreatethe default skeletons we take three most frequently used fe componentsinourcorpus oneatatime withthemostfrequentmodel.
thus we try with three skeletons and take the best accuracy.
table3showstheresultsofbaseline1andbaseline2 columns and .
from the results it can be seen that the two baselines authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sapientml synthesizing machine learning pipelines by learning from human written solutions icse may pittsburgh pa usa failon6and12datasets respectively.further theirperformance is poor due to the use of fe components on all columns in the dataset.baseline1achievescomparableperformancetosapientml for datasets that are simple and do not require any fe components.
however theoverallresultsshowthatbothpipelineseedingand pipeline instantiation are important for sapientml to succeed.
limitations threats to validity external validity.
our framework has only been instantiated for ml pipelines in python and evaluated on our benchmark datasets.thusourresultsmaynotholdoutsidethisscope.wetried to mitigate this risk by using standard benchmarks from previous work augmentedwithlarge diverse real worlddatasets used on public data science competitions hosted on kaggle.
qualityofdata.
beingadata driventechniquesapientml s performanceisinherentlylimitedbythequalityofitstrainingdata.
itisawellknownproblemthatmostnotebooksavailableonkaggle orgithubcannotbelocallyre executed .thus wecould also mine only a fraction of the data i.e.
pipelines potentially available on kaggle.
further the notebooks we did obtain vary significantlyinqualityandtheiruseofspecificlibrariesversuscustom code.
these differences manifest as noise in our analysis.
we tried tomitigatetheseissuesbydevelopingsimplebuteffectivecorpus augmentation section .
.
pipeline denoising section .
.
and by using semantic components classes section .
to canonical ize pipelines.
however using a larger cleaner data corpus could significantly strengthen our results.
simple skeleton predictor model.
currently our skeleton predictor uses a rather simple model that prioritizes features of thedatasetandignorescorrelationsbetween predicted pipeline components.
this approximation allows the model to perform well withlimiteddata asitdidonourbenchmarks.however generating muchmoredeeperorsophisticatedpipelinesmightnecessitatea moreexpressivemodeltrainedonsubstantiallylarger cleanerdata.
manual definition of the pipeline space.
currently we use a manual methodology to define the synthesis space of sapientml includingcreatingtheclustersofapisconstitutingthesemanticfeclasses section4.
.wenotethatthisisconsistentwiththepractice of previous automl techniques .
however we follow a transparentandsystematicprocess section4.
sothatsapientml can be easily generalized to other ml components once viablepipeline data demonstrating their use is available.
however this wouldstill belimitedtoapi based mlcomponents.the problem ofminingandre usingarbitrary custommltransformsinpipeline synthesis remains a very interesting open problem.
hyper parameteroptimization hpo .
sapientmlfocuses on ml component selection and end to end pipeline instantiation.
hpo is currently out of its scope.
however standard bayesian optimization hpo could be added as a post processing step.
related work automlfortabulardata.
previousautomltechniquesusedifferenttechniquestoexplorethehugecombinatorialsearchspaceof potential candidate pipelines.
tpot uses evolutionary search while reinbo uses reinforcement learning combined with bayesian optimization .
auto weka and later autosklearn employ meta learning on a corpus of syntheticoptimized pipelines to selectthe most appropriate pipeline and then tune hyper parameters using bayesian optimization.
ten soroboe builds on this approach using low rank tensor decomposition as a surrogate model for efficient pipeline search.
al uses language models learned from human written pipelines incombinationwithaggressivedynamicevaluationofpartial pipelines to explore the pipeline space.
ams mines constraintsfromcorporaofhuman writtenpipelinestohelpwarmstartsearch basedautomlliketpot.sapientmlsharesaland ams s goal of learning from human written pipelines.
however unlike all of the above approaches which essentially reason oncomplete pipelines sapientml combats automl combinatorial statespaceexplosionthroughanoveldivide and conquerapproach of first reasoning on individual ml components and subsequently assembling a small pool of candidate pipelines for final analysis.
automlfordlmodels.
thisareaisreviewedextensivelyin .
this research focuses on synthesizing the neural network models themselves through neural architecture search nas oronhyper parameteroptimization hpo .bycontrast sapientml addresses ml component selection and end to end pipeline instantiation treating ml components as black boxes.
program synthesis for data wrangling.
these techniques typically use input output examples of data frames as an input specification to synthesize programs implementing data wrangling operations datapre processing cleaning transformation forthe given dataset.
they prune or navigate the synthesis program space by manually specified api constraints coupled with constraintsolving automatically learning lemmas during synthesis or using more general neural network backed program generators .
however the pbe paradigm common to these techniques is not applicable to ml pipeline synthesis.
ml based program synthesis.
one class of approaches such as use probabilistic models trained on programs extracted from large open repositories e.g.
github and stackoverflow to rank the space of candidate programs generated by the synthesizer.
anotherbodyofwork leveragesuser providedinputoutputexamples ornaturallanguagedescription tocreateasearch spaceforneuralprogramsynthesis typicallyforsimpledomains suchasstring manipulatingprograms.bycontrast oursynthesis techniqueisspecificallyengineeredtouseagivendatasetandits predictive task as the only specification for synthesis.
conclusions in this work we proposed a learning based automl technique sapientml togeneratesupervisedmlpipelinesfortabulardata.
sapientml combats the huge combinatorial search space of au toml through a novel divide and conquer three stage programsynthesis approach that reasons on successively smaller searchspaces.
we have instantiated sapientml as part of a fully auto mated tool chain that creates a cleaned labeled learning corpusby mining kaggle learns from it and uses the learned models tothensynthesizepipelinesfornewpredictivetasks.weevaluated sapientmlonasetof41 benchmarkdatasetsandagainst3stateof the art automl tools and baselines.
our evaluation showed thatsapientmlproducedthebestorcomparableaccuracyin27ofthebenchmarkswhilethesecondbesttoolfailedtoevenproducea pipeline on of the instances.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa saha et al.