diagconfig configuration diagnosis of performance violations in configurable software systems zhiming chen sun yat sen university guangzhou chinapengfei chen sun yat sen university guangzhou chinapeipei wang bytedance us infrastructure system lab seattle usa guangba yu sun yat sen university guangzhou chinazilong he sun yat sen university guangzhou chinagenting mai sun yat sen university guangzhou china abstract performance degradation due to misconfiguration in software systems that violates slos service level objectives is commonplace.
diagnosing and explaining the root causes of such performance violations in configurable software systems is often challenging due to their increasing complexity.
although there are many tools and techniques for diagnosing performance violations they provide limited evidence to attribute causes of observed performance violations to specific configurations.
this is because the configuration is not originally considered in those tools.
this paper proposes diagconfig specifically designed to conduct configuration diagnosis of performance violations.
it leverages static code analysis to track configuration option propagation identifies performance sensitive options detects performance violations and constructs cause effect chains that help stakeholders better understand the relationship between configuration and performance violations.
experimental evaluations with eight real world software demonstrate that diagconfig produces fewer false positives than a state of the art documentation analysis based tool i.e.
vs in the identification of performance sensitive options and outperforms a statistics based debugging tool in the diagnosis of performance violations caused by configuration changes offering more comprehensive results recall .
vs .
.
moreover we also show that diagconfig can accelerate auto tuning by compressing configuration space.
ccs concepts software and its engineering software configuration management and version control systems software performance .
keywords configuration diagnosis program analysis performance violation taint tracking permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
reference format zhiming chen pengfei chen peipei wang guangba yu zilong he and genting mai.
.
diagconfig configuration diagnosis of performance violations in configurable software systems.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
introduction modern software systems are highly configurable to meet users requirements in various scenarios.
take the popular open source database management system mysql as an example.
its latest version has reached around configuration options.
it is always challenging to make the proper configurations for software deployment.
studies have shown that misconfiguration is one of the primary culprits responsible for production system failures and performance problems .
as system performance is becoming more and more critical in enterprise business misconfiguration can lead to millions of dollars cost .
it is of essence to quickly find out the improperly configured options when slos service level objectives violations occur.
however diagnosing and pinpointing configuration related performance problems is time consuming due to its huge search space.
search based techniques are exploited to change the value of configuration options by trial and error to resolve performance violations and to find the optimal configurations.
but without explicit cause effect relationships between options and performance search based techniques could be easily trapped in the massive configuration space generated by too many options .
this motivates us to explore other techniques to tame the cause effect relationships for eliminating the effort of trial and error and figuring out the crucial options.
the cause effect relationships between configuration options and performance help understand which where how andwhy configured options influence system performance behind the screen.
but such studies are still in the early stage and rely greatly on experts and domain knowledge.
one human centric approach to diagnose performance problems is to collect software hotspots with cpu profiling identify related options and locate option hotspots with performance influence models.
then they manually investigate how related configuration options affect the performance.
this approach is non trivial and cannot guarantee to find the correct root cause for the following reasons the relationship betweenesec fse december san francisco ca usa zhiming chen pengfei chen peipei wang guangba yu zilong he and genting mai global performance m1 m2 m3 latencyaa d f e c etraditional profiling techniques profiling with options tracking global performance m1 m2 m3 latencywhich options are root cause ?b figure the weakness of traditional profiling techniques for configuration related performance violations diagnosis.
hotspots detected by profilers and configuration options is complex and uncertain not all options need to be tuned when a performance violation occurs some options are continuous values making it difficult for performance modeling and options evolve with software updates.
thus we seek to diagnose and restore the evidence for performance violations via automatic cause inference.
when performance violations occur there are substantial monitoring and profiling techniques whose goal is to locate performance hotspots .
however hotspots only imply performance bottlenecks but not always performance violations.
for example some code logic is destined to occupy more execution time than others and thus are highlighted as hotspots by the profilers.
on the other side which options to tune remains an open problem in performance analysis with traditional monitors and profilers given that those profiling and monitoring tools consider only one instance of all configuration options at a time to evaluate their performance effects.
as illustrated in figure in a configurable system with six options method m1contains complex computational logic and is highlighted as a hotspot by profilers when a performance violation occurs.
however traditional profilers cannot dive into the option level and it totally depends on stakeholders users developers and site reliability engineers to navigate the source code and then to find the options a d f are relevant to m1.
but in fact option bis the critical option causing the performance violation.
performance influence models help understand the influence of options on system performance .
the accuracy of performance models heavily depends on the selected model and the subset of the configuration space generated by various sampling strategies .
to make it trickier for sampling based performance modeling software systems are sensitive to configuration changes meaning that systems with similar configurations would have dramatic performance differences .
previous attempts at building white box performance models of configurable systems are deficient for generalpurpose dynamic workloads and environments.
besides as the software evolves and the number of options increases it is becoming more expensive to keep the performance models up to date.
given the discussion above our goal is to devise a general lowcost high precision technique for configurable software systems that can not only interpret cause effect relationships between options and performance violations but also infer which configured options are responsible for those violations.
to achieve our goal we propose diagconfig a white box diagnosis tool to identify performance sensitive options tame cause effect relationships between the options and performance violations figure out the options that are responsible for performance violations.
diagconfigleverages both static code information from taint tracking andruntime profiling information to build cause effect chains which can help stakeholders explain performance issues.
we evaluated diagconfig with eight real world open source projects and the results show that diagconfig produced fewer false positives than safetune i.e.
vs a documentation analysis based tool in the identification of performance sensitive options.
moreover diagconfig is fast and supports a more comprehensive diagnosis of performance violations compared to unicorn recall .
vs .
a statistics based debugging tool.
we also integrated diagconfig into an auto tuner and demonstrated its feasibility of underpinning prior works on configuration performance tuning.
our key contributions are as follows.
a summary of information needed for configuration diagnosis of performance violations including identification of performance sensitive options localization of performance violations and root causes inference.
a white box approach and prototype diagconfig for building cause effect chains between configuration options and profiled hotspots to diagnose performance violations.
a dataset of performance sensitive options on eight realworld configurable software systems in diverse domains which can be used to evaluate diagconfig and its comparable alternatives.
background and research questions in this section we first introduce basic concepts of profiling and taint tracking which are exploited in the white box analysis of configurable software systems.
after that we introduce important information needed to diagnose performance violations according to which we define and describe our research questions.
.
background profiling.
profiling aims to reveal the runtime behavior of program execution with regard to resource consumption .
profiling investigates how much of a resource each program element consumes and reports performance critical program elements as hotspots .
a program element refers to a statement or method function in a program.
it is a basic sampling unit in profiling.
there are many approaches to detect performance problems caused by resource consumption such as cpu time profiling and unnecessarily high memory consumption profiling .
these approaches track how hotspots are invoked in particular stakeholders follow the traces e.g.
call chains to diagnose unexpected performance behavior.
however limited evidence in the profiling clarifies the relationships between options and hotspots.
stakeholders have to navigate the source code to find hotspot related options which is not efficient and could go beyond the scope of human reasoning due to the complexity in the dependencies of program elements.
taint tracking.
taint tracking is typically used in information security detection to track the information flow from user inputs sources to specific security sensitive locations sinks .
from the perspective of performance analysis in configurable systems the configuration is equal to user inputs.
well designed systems have standard apis for loading configuration option values to programdiagconfig configuration diagnosis of performance violations in configurable software systems esec fse december san francisco ca usa variables .
these variables are then propagated along the program s data flow paths via assignments string operations and arithmetic operations until they are consumed in program elements that change runtime behavior.
taint tracking with configuration as a source helps understand different attributes of configurable software systems including performance attributes.
.
research questions the performance of a configurable software system can be defined aspi p ci wi vi wherec is a valid configuration ois an option wis a specific workload vis a specific production environment and iis used to distinguish between cases.
in this paper our ultimate goal is to find the set of options c responsible for the performance violation pi pslo to help configuration performance tuning and cause effects explanation where pslo denotes the predefined slo and is a significant factor.
specifically a configuration diagnosis needs sufficient information to answer the following research questions.
rq1 which options are performance sensitive?
not all options are performance sensitive.
stakeholders usually identify and interpret performance sensitive options based on documentation rather than source code .
however any option that affects performance during runtime must have a data or control flow dependency with performance related operations .
performance related operations refer to code snippets in a program contributing positively to execution time time expensive and memory consumption memory expensive .
in this paper we follow the prior work and consider four types of performance related operations one type of memory expensive operations and three types of time expensive operations .
the memory expensive operations are heap or static array allocation operations.
and the three types of time expensive operations are i o operations lock synchronization and threads start pause operations and operations that affect system concurrency e.g.
creation of threads or thread pools .
these operations are computationally expensive and potentially need paging or swapping with low speed devices or context switching.
and the data and control flow dependencies between an option and a performance related operation can be grouped into three categories.
a direct data dependency where program variables derived from the option s value are used in the operation and affect every dynamic execution of the operation.
an if switch related control dependency where program variables derived from the option s value determine whether the operation is executed by influencing control flow decisions of the if switch statement.
a loop related control dependency where program variables derived from the option s value determine the number or frequency of the operation executions.
to answer this question we first treat configuration as the source and mine the information flow paths that record the dependencies between performance related operations and options via taint tracking.
since not all performance related operations have a significant performance impact we characterize the dependency information and then utilize the random forest to identify performancesensitive options.
the details of this process are presented in .
and the evaluation of its effectiveness is discussed in .
.rq2 which hotspot functions are performance violating?
end to end performance metrics can tell when performance violations occur but could not help explain the reason.
in contrast profilers report hotspot functions within the program concerning execution time memory consumption invocations etc.
to answer this question we do a profiling comparison between poor executions and normal baseline execution.
the former has significantly deteriorated performance while the latter is a high performance execution that meets slo usually given by domain experts.
by comparing hotspot functions in poor execution to those in the normal baseline execution profiling can help locate performance violating hotspot functions under poor execution.
rq3 how do performance sensitive options lead to performance violations?
rq1discovers performance sensitive options and rq 2identifies hotspot functions causing performance violations.
rq 3tries to build connections between those two in order to explain the causeeffect relationship between options and performance violations.
to answer this question we use performance related operations as the intermediary.
once the options are used in statements that influence the hotspot functions e.g.
branch loop conditions invocations both performance sensitive options and performanceviolating hotspot functions become traceable.
we build cause effect chains by correlating information flow paths between options and operations in .
and call chains between operations and hotspot functions and evaluate the effectiveness of this approach in .
.
methodology in this section we first briefly introduce our prototype tool diagconfig and then describe the workflow steps in each subsection.
diagconfig is a white box configuration diagnosis system and is general enough to adapt to software systems under different configurations workloads and environments.
figure shows the overview of diagconfig .
it consists of two parts offline analysis and online diagnosis .offline analysis .
identifies performance sensitive options by revealing the dependencies between configuration options and performance related operations.
this procedure requires two inputs the target system s source code and a list of specific prerequisites.
the prerequisites contain statements that load configuration option values as sources and performance related operations as sinks in the source code.
it builds information flow paths from option values to performancerelated operations via taint tracking extracts options static performance properties and then classifies performance sensitive options and information flow paths.
online diagnosis .
and .
continuously monitors system runtime behavior locates performance violating hotspot functions and collects call chains for the performance violating hotspot functions from the profiling.
it builds cause effect chains with information flow paths and call chains which further reveals the data or control flow dependency between individual options and performance violating hotspot functions.
when a new performance violation occurs diagconfig can apply these cause effect chains to guide diagnosis and to recommend crucial configuration options for performance tuning.
it can work as a daemon process that continuously analyzes performance violating configuration options for auto tuning.esec fse december san francisco ca usa zhiming chen pengfei chen peipei wang guangba yu zilong he and genting mai source code sources sinkscharacterizationtaint trackingsinks expansion perf.
sensitive options with info.
flow paths running systemhotspots comparison call chains constructionviolation monitoringvariation call chainssorting rules significant variation factorselected hotspots with call chains recommended options cause effect chains cause effect chain buildingrandom forest modeltree perf.sensitive perf.insensitive tree 2perf.insensitive perf.sensitive ... performance violation localizationidentification of performance sensitive optionsonline diagnosisonline diagnosis offline analysis explanation turning figure overview of diagconfig .
identification of performance sensitive options the identification of performance sensitive options is the goal of the offline analysis.
for each option diagconfig first computes the information flow paths that record the data and controlflow dependencies between variables derived from the option and performance related operations via taint tracking.
subsequently diagconfig characterizes these paths as performance property i.e.
feature vector which is utilized as input for a random forest model to determine whether the option is performance sensitive or not.
the training process of the random forest is presented in .
.
taint tracking.
taint tracking tracks the propagation of variables in source code with a coloring technique.
it first tags each program variable that stores an option value and then analyzes the dependencies between the colored variables and performancerelated operations.
the initial taints are program variables obtained from standard configuration loading statements which are called sources .
taints are then propagated and transformed along the program s data flow paths until they are consumed in sink statements.
besides pre defined performance related operations i.e.
sinks diagconfig marks if switch statements with branches containing performance related operations and loop startup jump out statements with the body containing performance related operations asexpanded sinks see .
once the taints reach sinks diagconfig builds the information flow paths for the corresponding options that record performance related operations taints propagation paths and location e.g.
source code file name source code line number of code snippets where the dependencies between options and performance related operations occur.
example.
as shown in figure .
a diagconfig captures the ifrelated control and loop related control dependencies between the option jobsandthread related operations i.e.
call invokeall via taint tracking.
then diagconfig builds information flow paths for the option jobsthat records the thread related operations and the location where the dependencies occur including method signature if statement loop startup statement and source code line number.
note that not all performance related operations significantly affect system runtime performance.
to identify performance sensitive compressedoutputstream.
processblock publiccompressedoutputstream ... map string object ctx ... inttasks integer ctx.getordefault jobs ...this.jobs tasks ... private void processblock throwsioexception ... list callable status tasks newarraylist this.jobs ... if tasks.size ... status status tasks.get .call ... else for future status result this.pool.invokeall tasks status status result.get ... ... taint flowdivsufsort.
ssmultikeyintrosort iiii v divsufsort.
sssort iiiiiiiz v divsufsort.
sorttypebstar i ii i divsufsort.
computebwt b b iiii ii i compressedoutputstream encodingtask.
encodeblock slicebytearr ay slicebytearray ijii inf d i r e c t c a l l the call ignores some callee a information flow path b call chainfigure example of building a cause effect chain using an information flow path a and a call chain of the performanceviolating hotspot ssmultikeyintrosort to diagnose where how and why the option jobscausing a performance violation in kanzi .
diagconfig backtracks the call chain b and analyzes each callsite.
in the method processblock it identifies the program dependencies between the option jobsand thread related operations that invoke encodeblock the callee of the processblock .
then it connects the information flow path and the call chain to a cause effect chain.
options we still need to characterize the information flow paths of the configuration options as performance properties and build a random forest classification model with the labeled configuration options performance properties.
characterization.
given information flow paths for one configuration option we count the number of performance related operations and characterize the performance property of the option by constructing the counter vector v. the original performance property is a high dimensional e.g.
at least classes and their methods under the java.nio package belonging to i o operations for java applications and sparse vector where each count is relatively small.
it influences the splitting decision for the random forest and makes the random forest struggle to generalize well.
inspired by the best practices of feature abstraction for sparse highdimensional feature spaces in text classification we study the information flow paths of configuration options and concludediagconfig configuration diagnosis of performance violations in configurable software systems esec fse december san francisco ca usa code snippets classcolumnfamilystore implements ... ... threadpoolexecutor flushexecutor new jmxenabledthreadpoolexecutor databasedescriptor .getflushwriters ... ... jmxenabledthreadpoolexecutor extends threadpoolexecutor threadpoolexecutor corepoolsize maximumpoolsize keepalivetime unit workqueue threadfactory defaulthandler memtable flush writers cassandra .
.
code snippets intwrite ... writebuffer buff ... ... intcompressionlevel store.getcompressionlevel ... if compressionlevel compressor store.getcompressorfast compresstype datautils .page compressed else ... ... intcomplen compressor.
compress ... if complen plus explen buff .put ... ... ... compress h2 database .
.
code snippets voidprocessblock throws ... ... list callable status tasks newarraylist this.jobs ... for future status result this .pool .invokeall tasks wait for completion of next task and validate result status status result.
get ... kanzi .
.
jobs a direct data dependency b if switch related control dependency c loop related control dependency figure real world examples of three target systems see table for more details to illustrate the dependencies between performancerelated operations and options.
the arrows show the data flow of option propagation.
configuration options are quoted in the figure and the performance related operations are shaded.
four heuristic strategies for dimensionality reduction and transformation.
we cluster the counts based on performance related operations and dependency categories that we mentioned in .
.
we first introduce c1 4aggregated features by clustering counts based on performance related operation categories.
as an illustration we cluster all performance related operations that pertain to the java.io orjava.nio packages for java applications in our implementation.
we next introduce c2 6aggregated features by clustering counts according to the pair wise combination of performancerelated operations categories.
this strategy is motivated by our observation that one information flow path of options influences two categories of performance related operations at the same time.
figure .
c shows a real world example that the option jobsin kanzi determines the concurrency and synchronization of tasks the operation invokeall creates threads for tasks execution and holds for them to complete .
we then introduce one aggregated feature by accumulating the counts of four performance related operations categories.
we finally introduce c1 c1 12aggregated features by categorizing the dependencies between performance related operations and options.
figure shows three real world examples of the dependencies.
figure .
a shows that the option memtable flush writers directly determines the core pool size of a thread pool figure .
b gives an example that the option compress decides whether writebuffer.put is executed by anifstatement and figure .
c shows that the option jobs determines the task synchronization via loop control.
these aggregated features would prompt the random forest to learn fine grained information about dependencies between options and performance related operations.
these heuristics are set to mitigate the risk of overfitting caused by the sparse high dimensional feature space for random forest classification model building.
random forest.
random forest is an appropriate algorithm for our binary classification task.
it combines multiple tree predictors and distinguishes classes by aggregating their predictions.
it is also more robust than a single tree predictor and more interpretable than deep learning models because of explicit decision inference paths in a tree.
besides training a random forest model only needs a small sample data which is readily satisfied in our scenario.
given these to identify performance sensitive options we train a randomforest model which approximates the following function.
g performance property performance sensitive or not the training data are performance properties of the configuration options with class labels .
namely performance sensitive i.e.
or not i.e.
.
then diagconfig characterizes the informationflow paths of a new option as the performance property and feeds it to the trained model.
the random forest determines whether the option is performance sensitive or not.
all performance sensitive options and their corresponding information flow paths are persisted in a file for cause effect chains building in the online diagnosis.
.
performance violation localization performance violation localization is the first step of the online diagnosis.
the goal of this step is to detect the performance violating hotspot functions based on performance measurements for the selected metrics.
diagconfig first leverages an off the shelf profiler jprofiler to continuously monitor the end to end performance of a system in sampled based mode see .
.
when an slo violation is detected in the end to end performance measurement it collects hotspot functions from the profiler.
by comparing the execution time of hotspot functions in the performance violated situation and the normal baseline execution diagconfigcalculates the performance variation of each hotspot function.
most off the shelf profilers are capable to measure the execution time of each hotspot function excluding the callee s performance influence.
thus diagconfig determines that a hotspot function with a significant performance variation is performance violating.
here we choose the significant variation factor to be see .
.
besides the measurement of performance variations we also extract call chains for each hotspot function from the profiler.
the call chains of a hotspot function can provide trace information about how the hotspot function is triggered and impacts the system performance.
since a system has many hotspot functions and a hotspot function can be associated with multiple call chains we use some rules to filter and sort the hotspot functions and their call chains.
we pre set a significant variation factor and those hotspot functions whose performance variations under the factor will be discarded.
then we sort the hotspot functions and call chains according to performance variation and performance contribution to the system performance.
example.
a call chain is shown in figure .
b each box is a hotspot function and the corresponding performance variation isesec fse december san francisco ca usa zhiming chen pengfei chen peipei wang guangba yu zilong he and genting mai marked in the upper right corner.
hotspot functions with significant performance deterioration are culprits of performance violation.
.
cause effect chain building despite information flow paths showing how performance sensitive options affect performance related operations not all performancerelated operations lead to performance violations at runtime.
besides quantifying the importance of options for system performance violations is still an open question which cannot be answered by static code analysis alone.
moreover some function calls are dynamic binding e.g.
thread invocation reflection callbacks that static analysis tends to miss.
therefore our approach leverages the call chains of performance violating hotspot functions from the profiler to complement the runtime information of a system that is missing from static code analysis.
diagconfig backtracks the call chains of hotspot functions and analyzes the callsite at the statement block level to determine whether there are programdependencies between the performance violating hotspot functions and performance related operations.
when a hotspot function in the call chains involves performance related operations or is called by the operations diagconfig correlates the corresponding information flow paths and the call chains to construct trackable cause effect chains i.e.
conditional pairs consisting of informationflow paths and call chains .
associating performance variations of hotspot functions with options corresponding to information flow paths allows for quantifying and ranking options importance.
algorithm describes how we build cause effect chains based on information flow paths and call chains.
the information flow path records the configuration option source and the location of performance related operation sink .
for each call chain of the selected hotspot function line we backtrack it from callee to caller and check whether the caller is contained by the information flow paths line .
if all callers in the call chain of a hotspot function are not contained by the information flow paths this means that the hotspot function is not influenced by the options.
since the branch or loop body is involved in if switch or loop related dependency we get the code snippet where dependency between the option and the performance related operation occurs line .
then we build a cause effect chain by connecting the call chain and informationflow path if the caller directly invokes the performance related operation or the callee is invoked by the performance related operation based on the call graph line .
example.
figure shows that diagconfig builds a cause effect chain between the option jobsand the hotspot function ssmultikeyintrosort .
it backtracks the call chain and finds that the option jobs influences the frequency of the hotspot function ssmultikeyintrosort by thread related operation and if loop related control dependency in the method processblock .
then it builds a cause effect chain by connecting the call chain and the information flow path.
implementation our prototype tool diagconfig is built on the top of the soot compiler infrastructure flowdroid scikit learn and jprofiler and specially targets configurable java applications.
to ensure its scalability we focus on the standard library apis and bytecode instructions that contribute positively to executionalgorithm cause effect chains building input perf.
sensitive info.
flow paths p selected hotspots with call chains h output cause effect chains c 1c emptyset 2forh hdo get the call chains for each hotspot 3callchains parse h forcallchain callchains do backtrack the call chain from callee to caller.
caller doesn t appear in p indicating that no option related performance operations involved forcaller callchain pdo paths p.get caller cg scene.v .getcallgraph callee prev caller forpath paths do block getperfoprelatedblock path check whether caller invokes perf.
operations or callee is invoked by perf.
operations ifisinfluenced cg caller callee block then c.add link callchain path end end end end 17end 18return c time and memory consumption.
these are the basic applicationindependent performance related operations in the java ecosystem.
diagconfig treats these performance related operations as sinks through method signatures and type analysis based on jimple the intermediate representation provided by the soot.
for example the array allocation related operations are represented by jnewarrayexpr andjnewmultiarrayexpr and the i o related time expensive operations are usually prefixed with java.io orjava.nio for their standard library api signatures.
in the offline analysis we utilize the popular static taint analysis framework flowdroid to support configuration options taint tracking.
by treating configuration loading statements as sources and performance related operations as sinks it reveals the direct data dependency between the configuration options and the performance related operations.
but the if switch related and loop related control dependencies are missed out.
therefore we slightly modified the sink manager component of flowdroid with program dependence graphs for our purposes to mark if switch statements with branches containing performance related operations and loop startup jump out statements with body containing performance related operations as expanded sinks .
then if the conditions of if switch statements or loop startup jump out statements have a direct data dependency with an option there is if switch related or loop related dependency between the option and the operations inside the branches or loop body.
we also customized flowdroid s source manager component to support those systems without standard configuration loading operations.
additionally we set the depth of alias analysis at five for flowdorid to balance the taint tracking precision and computational overhead.
this is the default value provided by flowdroid and the larger the depth the higher the taint tracking overhead required.
next we build the random forest with scikit learn for identification of performance sensitive options.
in the online diagnosis we use adiagconfig configuration diagnosis of performance violations in configurable software systems esec fse december san francisco ca usa table overview of target systems system domain opt.
kloc v id overhead batik svg rasterizer .
6h cassandra database .
.
10h catena password hashing .
9c89da4 1h dconverter image density converter 491bdf1535 1h h2 database .
.
3h kanzi data compressor .
.
.
1h prevayler database .
.
3h sunflow rendering engine .
.
.
1h includes source code for several libraries invoked by image processing the system targets at low execution time latency the system targets at high throughput opt the number of options v id version commit id overhead time required for static configuration options taint tracking profiler well known in the industry for its low overhead jprofiler to monitor the execution time of each method in the system.
we consider a performance violation occurs when the system suffers a performance degradation over compared to the baseline under its benchmark.
then we compute performance variation for each hotspot method by hotspot comparison built within the profiler and collect call chains of the hotspot methods with performance variation over for root cause inference.
the is our empirical unacceptable value based on the measurement variation see .
which is up to known from the prior work .
we implement an inter procedural callsite analysis using the call graph provided by the soot to build cause effect chains.
evaluation in this section we evaluate the effectiveness of our summarized information above .
to help stakeholders diagnose the performance violations of configurable software systems.
moreover we further answer the following research questions to evaluate the effectiveness of our approach.
rq4 the performance of diagconfig .candiagconfig work well for performance violation diagnosis of configurable systems?
can diagconfig speed up the existing auto tuning process?
.
experiment setup hardware.
we used two environments one with 128gb of ram cores and threads of intel xeon silver processor running ubuntu .
which was only used for static taint analysis and the other with 48gb of ram cores and threads of intel core i7 processor running ubuntu .
desktop version.
target systems.
we selected eight configurable real world open source java systems from various domains shown in table .
all of them satisfied the following criteria systems with binary enumerated and continuous configuration options systems used for evaluation by previous research on performance modeling.
we reused the workloads and benchmarks evaluated in the existing literature for each target system.
measurement and configuration variation.
to confirm the measurement stability in our environment we chose one configuration with normal execution i.e.
normal configuration for each of the four target systems according to their artifacts e.g.
documentation release notes benchmark results and repeated times in the benchmarks.
figure .
a shows that execution time variations of batik h2 database kanzi and throughput variation of cassandra .
.
.
.
.
.
cdf measurement variation a normal configurationbatik cassandra h2 database kanzi .
.
.
.
.
.
cdf configuration variation b problematic configurationsfigure performance variation of normal configuration and problematic configurations in repetitions.
in repetitions with normal configuration are all below .
the measurement variation pi mean mean wherei piis the performance of the i th execution and mean is the average performance of repetitions.
each point in figure .
a represents the performance variation of a single repetition compared to the average performance.
moreover to capture the variation in a system s performance due to loading problematic configuration we first randomly generated configurations derived from the normal configuration for each system repeated measurement times and filtered out the configurations with average performance variation below compared to the normal configuration.
this leaves us with and configurations for batik cassandra h2 and kanzi respectively.
then we randomly selected problematic configurations i.e.
average performance variation over from these filtered configurations to understand the sensitivity of performance violations.
figure .
b shows that the performance degradation i.e.
configuration variation caused by problematic configurations with repetitions varies from .
in batik to in kanzi.
the configurationvariation cj normal normal wherej cjis the average performance for the j th problematic configuration and normal is the average performance for the normal configuration.
each point in figure .
b represents an average performance variation of repetitions for one problematic configuration.
the dashed vertical line denotes the minimal configuration variation i.e.
.
.
from figure we can conclude that in our environment the performance variation under repeated executions is below and the configuration variation is above .
.
therefore we regarded the measurement result of repetitions as approximate to the result of repetitions and use as the threshold of performance violation conservatively.
note that measurement and configuration variation is the rationale for our derived performance violation threshold.
.
rq accuracy of diagconfig in identifying performance sensitive options in this section we describe how we labeled data for random forest classification modeling and the details about the identification of performance sensitive options followed by the result analysis.
note that we also conduct data labeling for cassandra and use the labeled data as the ground truth for the evaluation of identification results.
data labeling.
to label performance sensitive options accurately we conducted experiments to study the performance influence of each option.
for each option in each system we changedesec fse december san francisco ca usa zhiming chen pengfei chen peipei wang guangba yu zilong he and genting mai perf.
sensitive safetunediagconfig ground truth figure results of performance sensitive options identification.
its value re deployed the system followed common practices to measure five repetitions and calculated the average performance variation before and after the value change.
then the options with any observed variation larger than were labeled as performance sensitive.
specifically for options of binary and enumerated types we explored all possible values and for continuous options we obtained a set of their values by plackett burman sampling .
for some continuous options that were not identified as performance sensitive in the sampling space we further tried our best to analyze their influence in small incremental steps e.g.
we used 2mb as a step from 1mb to 4096mb to analyze the influence of the option file cache size in mb of cassandra .
random forest modeling.
to build a well generalized random forest classification model we simulated a scenario where the model is trained on existing systems and tested on unseen systems.
given this we used batik catena h2 prevayler and sunflow i.e.
options as the training set and dconverter kanzi i.e.
options as the test set.
our classification model constructed from the training set figured out .
of performance sensitive options on the test set so our model is valid and used for further evaluation.
comparison.
the remaining target system cassandra was used to further evaluate the effectiveness of our classification model.
we chose cassandra since it was evaluated in another state ofthe art tool safetune which identifies performance related parameters by building learning based models and analyzing on system configuration related documentation.
safetune made its dataset publicly available so we used it to compare with our results.
result and analysis.
we collected the set of performancesensitive options by running cassandra in nosqlbench tlpstress cassandra stress and the ycsb benchmark.
we fed options to taint tracking of which influence pre defined performance related operations.
and we identified performancesensitive options based on the random forest model.
in comparison safetune identified performance related parameters.
the results are shown in figure .
the circled area labeled perf.
sensitive provides the ground truth for the comparison analysis.
among the reported performance sensitive options by diagconfig are true positives i.e.
region region and are false positives i.e.
region region having a precision of .
and a recall of .
.
safetune reported performance sensitive options.
among them are true positives i.e.
region region and are false positives i.e.
region region having a precision of .
and a recall of .
.
both approaches produce false negatives.
diagconfig missed performance sensitive options i.e.
region region andsafetune missed i.e.
region region .
we studied the performance sensitive options that we misclassified and summarized some of the sources that resulted in the misclassification as follows the considered performance related operations are not complete e.g.
the option ideal consistency level dependent on consistency maintenance related operations that are not included in the java standard library performance property is a simple count which does not fully reflect runtime performance behavior e.g.
the performance property of the option periodic commitlog sync lag block in ms indicates that it is threadrelated but the small count causes it to be misclassified.
diagconfig andsafetune are complementary to each other since each has identified new options missing in the other.
diagconfig identified performance sensitive options i.e.
region missed by safetune and safetune identified performancesensitive options i.e.
region that were missed in diagconfig .
summary forrq1 for performance sensitive option identification our static code analysis based approach introduces fewer false positives i.e.
vs than the documentation based approach.
this is because the data and control flow dependencies between options and performance related operations in source code can better reflect the runtime behavior of the system than documentation.
.
rq 2and rq effectiveness of cause effect chains identified by diagconfig in this section we focus on the diagnosis of performance violations caused by configuration changes and evaluate our code analysisbased approach by comparing it with a statistic based approach.
diagnosis of configuration changes.
first we selected a baseline or default configuration based on the relevant document and treated the application performance under this configuration as the slo for each system.
then we mutated the configuration to produce scenarios of performance violations for further diagnosis.
similar to the sampling strategy for accurate performance modeling which is described in weber et al we selected feature wise and pair wise sampling for options of binary type and plackett burman sampling for enumeration and continuous types.
we first manually filtered out the invalid configurations derived from sampling loaded only valid ones into the system and got corresponding performance measurements in a specific benchmark.
those configurations with an average performance in five repetitions over compared to the slo would be fed to the process of diagnosis.
note that in the evaluation the goal is not to find the optimal configurations but to diagnose performance violations.
the effectiveness of diagnosing performance violations was reported via precision and recall metrics.
precision is the ratio between the set of correctly identified options and the set of predicted options while recall is the percentage of correctly identified options causing a performance violation and the set of options whose values had changed compared to the baseline.
comparison.
we ran diagconfig to obtain the set of configuration options responsible for performance violations and compared our results to unicorn a statistics based approach for configurable systems performance debugging and optimization via causal performance models.
in debugging mode unicorn repeatedly generates new configurations to replace the loaded one for the system in thediagconfig configuration diagnosis of performance violations in configurable software systems esec fse december san francisco ca usa table average precision and recall of comparison.
system batik catena h2 kanzi prevayleraverageconfigurations precisionunicorn .
.
.
.
.
.
diagconfig .
.
.
.
.
.
recallunicorn .
.
.
.
.
.
diagconfig .
.
.
.
.
.
configurations the total number of valid and performance violating configurations invalid ones are filtered out obtained by sampling which is traded off against the performance measurement overhead.
deployed environment measures the performance then pinpoints the critical options related to performance issues.
result and analysis.
table summarizes the average precision and recall of unicorn anddiagconfig for each system in diagnosing performance violations.
catena has a much bigger configuration size because in the fixed time duration sampling runs faster due to its small source code size and number of options.
it also uncovers the reason for unicorn s exception recall in catena since a small number of options means that the correlation between options and performance metrics is easier to learn during training.
the relatively low recall of unicorn reveals its limitations.
when generating one new configuration to debug unicorn only considers one crucial option at a time changes its value deploys and measures the system and targets normal metrics.
the list of candidate options is short and relies on the accuracy of causal correlations between options and performance metrics captured by causal performance models resulting in an incomplete diagnosis.
in contrast diagconfig captures the cause effect relationships between options and performance behaviors and supports a more comprehensive diagnosis via code analysis.
however diagconfig also produced false negatives and false positives.
for the reasons of false negatives we double checked the offline analysis corresponding to the missed options and concluded that a some information flow paths of options are lost due to the level of variables indirectly referencing the options exceeding the depth of alias analysis we set i.e.
in taint tracking b a few options influence compute intensive operations e.g.
operations of primitive numeric types and hash computation without involving the performance related operations we have agreed upon leading to incomplete information flow paths.
also we found more options responsible for performance violations which lead to loss of precision that deserve further tuning.
summary forrq2andrq3 treating the system as a white box and taking advantage of performance related operations diagconfig effectively diagnoses performance violations by building cause effect chains.
in addition the cause effect chains achieve finegrained interpretability like figure which helps stakeholders understand the root causes of performance violations.
.
rq performance of diagconfig overhead.
as figure shows diagconfig consists of offline analysis and online diagnosis.
the offline analysis overhead includes data labeling static configuration options taint tracking classification model building and performance sensitive options classification with their information flow paths filtering.
among them data labeling and classification model building are only required in the preparation stage so that when a new system is fed into diagconfig it can directly apply the classification model after taint .
.
.
.
.
.0batik svg rasterizercdf execution time s non profiling sample based instrumentation based .
.
.
.
.
.
.0cassandracdf throughput ops sec .
.
.
.
.
.
.
.
.0h2 databasecdf execution time s .
.
.
.
.
.
.
.
.
.
.0kanzicdf execution time s .
figure performance distribution of four software systems in non profiling sample based profiling and instrumentation based profiling.
the small top left plot reports the average performance degradation caused by sample based profiling for each system while instrumentation based profiling incurs unacceptable overhead.
tracking and characterization.
thus data labeling and classification model building are conducted only once and used forever.
the performance sensitive options classification with their informationflow paths filtering are comparatively negligible compared to the static taint tracking which is required for each new system.
table lists the overhead for static taint tracking of each target system in our evaluation.
it is relatively heavy but acceptable because we only need to run static taint tracking once.
moreover the software vendors generally can provide the results of this part.
the overhead of online diagnosis includes profiling overhead and cause effect chain building overhead.
to check the overhead incurred by our chosen profiler we selected configurations for each of the four target software systems.
we measured these software systems with repetitions using non profiling sample based profiling and instrumentation based profiling respectively.
we visualized the performance distribution of these software systems loaded one configuration in figure to show the variation of the results.
each point in figure represents the performance of a single repetition.
for all four software systems the performance degradation incurred by sample based profiling i.e.
means meann meann wheremeannis the average performance under non profiling and meansis the average performance under samplebased profiling is below .
additionally the performance distribution is similar for all configurations indicating that the configuration does not impact the measurement stability which is consistent with the insight of weber et al .
despite the extensive research on lightweight online monitoring tools and sophisticated industrial profilers our experimental profiling results suggest that the overhead of sample based profiling is acceptable and diagconfig may not need to replace industry class profilers but build on them to achieve performance violation detection in online diagnosis.esec fse december san francisco ca usa zhiming chen pengfei chen peipei wang guangba yu zilong he and genting mai table overhead of cause effect chains building.
batik catena h2 kanzi prevayler total time .
s .
s .
s .
s .
s cold start maximum .
s .
s .
s .
s .
s second largest .
s ms .
s ms ms minimum .
s ms ms ms ms mean .
s .
ms .
ms .
ms .
ms standard deviation .
ms .
ms .
ms .
ms .
ms 2506000800010000120001400016000180002000022000throughput ops sec tuning time minutes options options th latency us tuning time minutes figure tuning example.
comparison of ottertune tuning process with options and without options diagconfig aid.
regarding the overhead of the building of cause effect chains we recorded the execution time of each diagnosis when diagnosing performance violations .
.
a summary of the metrics is shown in table .
the cold start is that diagconfig loads the necessary program static information to build the call graph when constructing the cause effect chains for the first time.
it is a one shot cost.
the acceptable cost shows that our approach is suitable for the vast majority of online production environments and can be integrated into the existing auto tuners for diagnosis before tuning starts.
case study.
diagconfig can recommend crucial options to guide tuning tools e.g.
smartconf ottertune dac bestconfig to reduce the huge configuration space.
we conducted a case study with ottertune a representative auto tuner to show the effectiveness of diagconfig s recommendation.
ottertune supports mysql and postgresql but neither of them is a java system.
thus we extended ottertune to work for the java database cassandra.
we applied diagconfig to figure out the crucial options when a performance violation occurs and then ran ottertune to improve performance.
we recorded ottertune s tuning time spent to validate how much diagconfig accelerates the tuning process.
in the case study we simulated a situation where cassandra suddenly suffered significant throughput and latency degradation under the ycsb benchmark.
the stakeholders pointed out the options related to this performance violation and then leveraged ottertune to improve the system s performance.
by contrast we ran diagconfig to select crucial options before tuning.
result and analysis.
diagconfig recommended options while the stakeholders offered relevant options according to their experience.
we fed these two sets of options to ottertune separately.
the tuning process is shown in figure .
ottertune got stuck in the configuration space that consists of the options.
tuning with diagconfig required only minutes to achieve of the throughput obtained by tuning without diagconfig through minutes.
this was an almost acceleration.
moreover after the 87th minute the tuning with diagconfig further achieved better throughput.
similarly the acceleration of ottertune by diagconfigwas also manifested in the latency.summary forrq4 the auto tuners can be stuck in a huge configuration space leading to a slow tuning speed diagconfig with acceptable overhead is complementary to them which accelerates the tuning process by compressing configuration space.
limitations and threats to validity limitations of the static taint analysis.
diagconfig computes information flow between options and performance related operations in the offline analysis may produce inaccurate results.
the main source of inaccuracy is that static taint analysis requires a trade off between accuracy and overhead when confronted with path explosion and alias analysis leading to over tainting or loss of taint.
if the analysis misses all information flow then diagconfig will fail to construct cause effect chains.
in contrast if the analysis falsely reports too many information flow paths resulting in many redundant cause effect chains.
additionally while flowdroid holds a high accuracy the analysis is challenged by the explosion of paths between source and sink as well as the size of the call graph.
as a result these challenges limit the scale of the target system thatdiagconfig can analyze.
our evaluation demonstrates the overhead of diagconfig based on flowdroid for static taint tracking in the target system.
although the cost of analyzing large scale configurable software systems is relatively heavy it is acceptable.
threats to validity.
the selection of the profiler for performance violation detection is a threat to construct validity.
profiling generally indicates an overhead resulting in performance degradation of the software system.
we mitigated this threat by selecting a lightweight profiler jprofiler for performance violating hotspot functions detection and localization.
besides the setting of the profiler is also a threat.
our evaluation of the target system batik svg rasterizer valid configurations generate 51gibcall chains showed that persisting profiling information for each hotspot function leads to expensive storage costs.
mitigating this threat requires the user to understand the target system well enough and set the profiler blacklist to ignore specific program elements.
the selection and setting of the profiler are threats to internal validity.
the choice of target systems threatens external validity on which we evaluate the effectiveness of our approach.
to alleviate this threat we introduced various systems with multiple options from different areas in our evaluation.
they were collected from previous work and were usually used to evaluate sampling strategies and performance modeling methods.
we further ran our approach with ottertune on the cassandra database to show the feasibility of large scale configurable software systems.
discussion interpretability of documentation and source code.
accurately identifying performance sensitive options requires understanding the relationship between configuration options and performance behaviors.
this information can be obtained from system documentation and source code analysis.
safetune is a documentation analysis based tool while diagconfig emphasizes source code analysis.
the information that documentation can provide is mostly systematic and macroscopic while the information provided by the source code is mostly rational logical and microscopic.
both safetune anddiagconfig can identify performance sensitive optionsdiagconfig configuration diagnosis of performance violations in configurable software systems esec fse december san francisco ca usa that the other has missed.
therefore the information provided by documentation and source code is complementary to each other.
dynamic workload and environment.
dynamic workloads and environments are non trivial for evaluating system performance.
for rq both safetune and our evaluation were limited by the workload and environment.
in our evaluation we first confirmed the measurement and configuration variation .
then tried our best to identify performance sensitive options in multiple rich workloads.
in contrast previous work only considered multiple workloads without accounting for measurement and configuration variation thus may lead to inaccurate results.
for rq and rq due to the wide variety of workloads and environments the performance violations caused by dynamic workloads and environments migration are out of the scope of this paper.
multiple metrics for performance issues troubleshooting.
a wide range of metrics has been spawned for monitoring various aspects of systems runtime behaviors.
while diagconfig focuses on the diagnosis of single objective most prior works also target single objective performance violations we will accommodate multiple and mixed metrics with the appropriate modification of monitoring components for in depth performance issues diagnosis in the future.
for instance thread activity and concurrency metrics e.g.
thread on cpu cycles synchronization delays for unusual thread behavior and cpu contention detection and lock contention metrics e.g.
the level of locks for problematic code sharing designs uncover.
related work generally speaking software configuration tuning has three steps namely detection of performance violations identification of root causes and searching for optimal configurations.
diagconfig mainly targets the second step.
performance violations occur frequently due to changes in workload and environment as well as misconfigurations.
there is substantial literature on detecting testing diagnosing and fixing misconfigurations.
specifically configx employs a tailored static analysis of configurationrelated code snippets to extract the specification constraint among options.
it does not consider runtime performance behaviors and is therefore well suited for detecting misconfiguration that may result in unexpected and hard to observed functional behavior rather than performance behavior before the configuration is loaded in.
while these solutions help reduce misconfigurations introduced by users mistakes interpretability is still an open problem.
our goal is to restore the cause effect relationships between performancesensitive options and performance violations based on the program logic.
in particular stakeholders want a clear explanation of why there was a performance violation when they had set up a configuration that seems better according to the documentation.
there is no silver bullet to finding a configuration that performs well in all situations.
off the shelf profilers targeted profiling techniques and visualizations help detect performance problems and locate performance bottlenecks.
however there is not enough evidence to explain why options cause performance violations particularly to determine which options are responsible for performance violations.
diagconfig strives to recommend crucial options by cause effect chains.similarly most previous works aim to stakeholders understand why where and how options and their interactions affect the performance behavior of configurable software systems by building white box performance influence models .
configcrusher first relies on static taint analysis to determine which options affect which code regions.
then it leverages optionaffected code region expansion and merging with instrumentation to reduce the cost of measurement and construct interpretable performance influence models.
however the instrumentation is overhead and does not support numeric options and multi threaded programs.
comprex builds white box performance influence models based on expensive dynamic taint analysis and incomplete configuration specific local code performance measurement.
weber et al.
propose an approach based on splconqueror to build white box performance models over binary and numeric options at the method level for understanding options and their interactions.
it achieves relatively high precision because it combines coarse and fine profiling to reduce the influence of performance variance on the models.
all approaches based on performance models involve repeated performance measurements of the system in specific workloads and environments.
in addition to the difficulty of model transfer the performance of the models themselves varies depending on the sampling strategy and learning tricks.
optimizers for configuration tuning that treat the system as a black box and contain limited interpretable information about the relationship between options and performance behavior.
they can be classified into two categories control theory based and machine learning based approach.
conclusion we propose a white box static code analysis based approach to diagnose performance violations of configurable software systems.
this approach combines static configuration related performance information from source code and runtime performance behaviors from profiling.
moreover we implement a novel prototype diagconfig to diagnose performance violations.
it performs option tracking performance violation localization and construction of cause effect chains.
our evaluation with eight open source systems demonstrates the effectiveness and efficiency of diagconfig .
more importantly diagconfig can restore the complete evidence chain of performance violations highlight the configuration options for performance violations help stakeholders explain the causes of performance violations and accelerate the configuration tuning process regardless of workloads and environments.
data availability statement all implementation and data can be found in archived repository .
acknowledgment we thank the anonymous reviewers for their feedback.
the research is supported by the key area research and development program of guangdong province no.
2020b010165002 the guangdong basic and applied basic research foundation no.
2023b1515020054 the natural science foundation of china no.
the tencent rhino bird joint research program and the fundamental research funds for the central universities sun yat sen university no.
22qntd1004 .
the corresponding author is pengfei chen.esec fse december san francisco ca usa zhiming chen pengfei chen peipei wang guangba yu zilong he and genting mai