psychologically inspired unsupervised inferenceof perceptual groups of guiwidgets from guiimages mulong xie mulong.xie anu.edu.au australiannationaluniversity australiazhenchang xing zhenchang.xing anu.edu.au csiro s data61 anu australiasidong feng sidong.feng monash.edu monashuniversity australia xiweixu xiwei.xu data61.csiro.au csiro s data61 australialiming zhu liming.zhu data61.csiro.au csiro s data61 unsw australiachunyang chen chunyang.chen monash.edu monashuniversity australia abstract graphical user interface gui is not merely a collection of individual and unrelated widgets but rather partitions discrete widgets into groups by variousvisual cues thus forming higher order perceptualunitssuchastab menu cardorlist.theabilitytoautomatically segment a gui into perceptual groups of widgets constitutes afundamentalcomponentofvisualintelligencetoautomategui design implementationandautomationtasks.althoughhumans canpartitionaguiintomeaningfulperceptualgroupsofwidgetsin ahighlyreliableway perceptualgroupingisstillanopenchallenge for computational approaches.
existing methods rely on ad hoc heuristics or supervised machine learning that is dependent on specificguiimplementationsandruntimeinformation.research inpsychologyandbiologicalvision hasformulatedasetofprinciples i.e.
gestalttheoryofperception thatdescribehowhumans groupelementsinvisualscenesbasedonvisualcueslikeconnectivity similarity proximity and continuity.
these principles are domain independent and have beenwidely adopted bypractitioners to structure content on guis to improve aesthetic pleasantness andusability.inspiredbytheseprinciples wepresentanovelunsupervised image based method for inferring perceptual groups of guiwidgets.ourmethodrequiresonlyguipixelimages isindependent of gui implementation and does not require any training data.
the evaluation on a dataset of guiscollected from mobile apps and ui design mockups shows that our method significantly outperforms the state of the art ad hoc heuristics based baseline.
our perceptual grouping method creates opportunities forimprovingui relatedsoftware engineeringtasks.
ccsconcepts software and its engineering keywords graphicaluserinterface widget grouping perceptualgrouping esec fse november 14 18 singapore singapore copyright held bytheowner author s .
acm isbn978 .
referenceformat mulongxie zhenchangxing sidongfeng xiweixu limingzhu andchunyang chen.
.
psychologically inspired unsupervised inference of perceptual groups of gui widgets from gui images.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november14 18 singapore singapore.
acm newyork ny usa 12pages.
introduction wedonotjustseeacollectionofseparatedtexts images buttons etc.
onguis.instead weseeperceptualgroupsofguiwidgets such ascard list tab and menu showninfigure .
formingperceptual groupsisanessentialsteptowardsvisualintelligence.forexample it helps us decide which actions are most applicable to certain gui parts such as clicking a navigation tab expanding a card scroll the list.
this would enable more efficient automatic gui testing .
as another example screen readers help visually impaired users access applications by reading out content ongui.recognizingperceptualgroupswouldallowscreenreaders to navigate the gui at higher order perceptual units e.g.
sections efficiently .lastbutnotleast guirequirements designsand implementationsaremuchmorevolatilethanbusinesslogicand functionalalgorithms.withperceptualgrouping modular reusable gui code can be automaticallygeneratedfrom guidesign images whichwouldexpediterapidguiprototypingandevolution .
although humans can intuitively see perceptual groups of gui widgets current computational approaches are limited in partitioning a gui into meaningful groups of widgets.
some recent work relies on supervised deep learning methods e.g.
image captioning to generate a view hierarchy for a gui image.thistypeofmethodisheavilydependentonguidataavailabilityandquality.toobtainsufficientguidataformodeltraining they use gui screenshots and view hierarchies obtained at application runtime.
a criticalquality issue of suchruntime gui data is that runtime view hierarchies often do not correspond to intuitive perceptual groups due to many implementation level tricks.
for example intheleftguiinfigure thetwolistitemsinalistview hasnovisualsimilarity alargeimageversussometexts sotheydo not form a perceptual group.
in the right gui a grid of cards form a perceptual group but is implemented as individual framelayouts.
such inconsistencies between the implemented widget groups and thiswork islicensedunderacreativecommonsattribution4.0international license.
esec fse november14 18 singapore singapore mulong xie zhenchang xing sidongfeng xiweixu liming zhu chunyang chen a card b list c list multi tab d menulistmulti tab listmenu card card figure1 examplesofperceptualgroupsofguiwidgets perceptualgroupsare highlighted inpinkbox inthispaper the human s perceptual groups makethe trainedmodelsunreliable to detectperceptualgroupsofgui widgets.
decadesofpsychologyandbiologicalvisionresearchhaveformulatedthegestalttheoryofperceptionthatexplainshowhumans seethewholeratherthanindividualandunrelatedparts.itincludes asetofprinciplesofgrouping amongwhich connectedness similarity proximity andcontinuity are the mostessentialones .
although these principles and other related ui design principles such as crap greatly influence how designers and developers structure gui widgets they have never been systematically used to automatically infer perceptual groups from gui images.
rather currentapproaches relyonad hocandcase specific rulesandthus are hardto generalize ondiversegui designs.
in this work we systematically explore the gestalt principles of grouping and design the first psychologically inspired method for visual inference of perceptual groups of gui widgets.
our method requiresonlyguipixelimagesandisindependentofguiimplementations.ourmethodisunsupervised thusremovingthedependence on problematic gui runtime data.
as shwon in figure our methodenhancesthestate of the artguiwidgetdetectionmethod uied to detect elementary gui widgets.
following the gestaltprinciples themethodfirstdetectscontainers e.g.
card list item withcomplexwidgetsbytheconnectednessprinciple.itthen clustersvisuallysimilartexts ornon textwidgets bythesimilarity principleandfurthergroupsclustersofwidgetsbytheproximity principles.
finally based on the widget clusters our method correctserroneouslydetectedormissingguiwidgetsbythecontinuity principle notillustratedinfigure but can be seen infigure .
at the right end of figure we show the grouping result by the state of the art heuristic based method screen recognition .
screenrecognitionincorrectlypartitionsmanywidgetsintogroups such as the bottom navigation bar andthe four widgetsabove the bar thecardon theleftand thetextabove thecard.
italsofails to detecthigher order perceptualgroups suchasgroupsofcards.in contrast our approach correctly recognizes the bottom navigation bar and the top and middle row of cards.
although the text label above the left card is very close to the card our approach correctly recognizes the text labels as separate widgets rather than as a part of the left card.
our approach does not recognize the two cards justabovethebottomnavigationbarbecausethesetwocardsare partiallyoccludedbythebottombar.however itcorrectlyrecognizesthetwoblocksofimageandtextanddetectsthemasagroup.
figure2 implementedviewhierarchydoesnotnecessarily correspond to perceptual groups clearly the grouping results by our approach correspond more intuitively to human perception than those by screen recognition.
fortheevaluation weconstructtwodatasets onecontains1 gui screenshots from android apps and the other contains 20uiprototypesfromapopulardesigntoolfigma .toensure the validity of ground truth widget groups we manually check all theseguisandconfirmthatnoneoftheseguishastheperceptionimplementation misalignment issues shown in figure .
we first examine our enhanced version of uied and observe that the enhancedversion reachesa0.626f1scoreforguiwidget detection whichismuchhigherthantheoriginalversion .524f1 .withthe detected gui widgets our perceptualgrouping approach achieves thef1 scoreof0.593onthe1 091appguiscreenshotsand0.
f1 score on the ui design prototypes.
to understand the impact of gui widget misdetections on perceptual grouping we extract the gui widgets directly from the android app s runtime metadata i.e.
ground truthwidgets andusetheground truthwidgetsasthe inputs to perceptual grouping.
with such perfectly detected gui widgets ourgroupingapproachachievesa0.672f1 scoreonapp guis.
in contrast screen recognition performs very poorly .
f1 on the ground truth widgets and .
f1 on the detected widgetsfor app screenshots and0.
f1 onthe detectedwidgets foruidesignprototypes.althoughourgroupingresultssometimes do not exactlymatch the ground truth groups ouranalysis shows thatsomeofourgroupingresultsstillcomplywithhowhumans perceivethewidgetgroupsbecausetherecanbediversewaysto structure gui widgetsinsomecases.
tosummarize this paper makes the following contributions arobust psychologically inspired unsupervisedvisualinference method for detecting perceptual groups of gui widgetsongui images the code isreleasedongithub1.
a comprehensive evaluation ofthe proposedapproach and the in depthanalysisof the performance withexamples.
ananalysis of howourperceptual groupingmethodcan improveui relatedsetasks suchasuidesign implementation andautomation.
333psychologically inspired unsupervisedinference of perceptual groups of gui widgets from gui images esec fse november14 18 singapore singapore visualization of each step of our approach screenrecognition input gui image .
connectedness container recognition .
similarity widget clustering .
proximity recursive group pairingwidget perceptual groups widget detection perceptual grouping grouping result figure left our approach overview enhanced uied for gui widget detection gestalt principles inspired perceptualgrouping.
right grouping resultofthestateofoftheartheuristic based approachscreenrecognition gui widgetdetection ourapproachisapixel onlyapproach.itdoesnotassumeanygui metadataorguiimplementationaboutguiwidgets.instead our approach detects text and non text gui widgets directly from gui images.
to obtain the widget information from pixels it enhances thestate of the artguiwidgetdetectiontechniqueuied .in order to fit with subsequent perceptual grouping our approach mitigatestheincorrectmergingofguiwidgetsinthecontainers byuied andsimplifies the widgetclassification ofuied.
.
uied basedgui widgetdetection uied comprises three steps gui text detection non text gui widget detection and merging of text and non text widgets.uiedusesanoff the shelfscenetextdetectoreast to identify text regionsin thegui images.east isdesigned for handling nature scene images that differ from gui images such as figure backgroundcomplexityandlightingeffects.althougheast outperforms traditional ocr tool tesseract we find the latest ocrtooldevelopedbygoogle achievesthehighestaccuracy ofguitextrecognition seesection .
.therefore inouruseof uied we replace eastwiththe google ocrtool.
forlocatingnon textwidgets ourapproachadoptsthedesign ofuiedthatusesaseriesoftraditional unsupervisedimageprocessingalgorithmsratherthandeep learningmodels e.g.
faster rcnn oryolo .thisdesignremovesthedatadependence onguiimplementationorruntimeinformationwhileaccurately detecting gui widgets.
uied then merges the text and non text detectionresults.thepurposeofthismergingstepisnotonlyto integrate the identified gui widgets but also to cross check the results.becausenon textwidgetdetectioninevitablyextractssome text regions uied counts on the ocr results to remove these false positive non text widgets.
specifically this step checks the boundingboxofallcandidatenon textwidgetregionsandremoves thoseintersectedwithtextregionsresultingfrom the ocr.
.
improvementandsimplification ofuied wefindthattheuieddetectionresultsoftenmisssomewidgetsina container e.g.card .thereasonisthat inordertofilteroutinvalidnon text regions and mitigate over segmentation that wrongly segmentsaguiwidgetintoseveralparts uiedchecksthewidgets boundingboxesandmergesall intersectedwidgets regionsintoa big widget region.
this operation may cause the wrong neglection ofvalidguiwidgetsthatareenclosedinsomecontainers.therefore we equip our gui widget detector with a container recognition algorithm see section .
to mitigate the issue.
if a widget is recognizedasacontainer thenallitscontainedwidgetsarekept andregardedas proper gui widgetsratherthannoises.
the original uied classifies non text gui widgets as specific widgetcategories e.g.
image button checkbox .incontrast our gui widget detector only distinguishes text from non text widgets.
although gui involves many types of non text widgets there is no need of distinguishing actual classes of non text widgets for perceptualgrouping.
guiwidgetclassesindicatedifferentuserinteractionsandguifunctionalities butwidgetswithdifferentclasses can form a perceptual group as long as they have similar visual properties suchassize shape relativepositionandalignmentwith other widgets.
therefore we do not distinguish different classes of non textwidgets.however weneedtodistinguishnon textwidgetsfromtextwidgets astheyhaveverydifferentvisualproperties andneedto be clusteredbydifferentstrategies see section .
gui widgetperceptualgrouping afterobtainingtextandnon textwidgetsonaguiimage thenext stepistopartitionguiwidgetsintoperceptualgroups orblocks ofitems according to their visual andperceptualproperties.
.
gestalt laws andapproach overview ourapproachisinspiredbypsychologyandbiological visionresearch.
perceptual grouping is a cognitive process in which our minds leap from comprehending all of the objects as individuals to recognizing visual patterns through grouping visually related elementsasawhole .thisprocessaffectsthewaywedesign guilayouts fromalignment spacingandgroupingtoolsupport to ui design templates and gui frameworks italsoexplainshowweperceiveguilayouts.forinstance inthe examplesinfigure wesubconsciouslyobservethatsomevisually 334esec fse november14 18 singapore singapore mulong xie zhenchang xing sidongfeng xiweixu liming zhu chunyang chen similarwidgetsareplacedinaspatiallysimilarwayandidentify themas inagroup e.g.acard list multitabormenu .
previousstudiesrelyonad hoc rigidheuristicstoinferuistructurewithout asystematic theoreticalfoundation.
ourapproachis the first attempt to tackle the perceptual grouping of gui widgets guided by an influential psychological theory named gestalt psychology that explainshow thehumanbrainperceives objects and patterns.
gestalt psychology s core proposition is that human understands external stimuli aswholes rather than as the sums of theirparts .basedontheproposition thegestaltistsstudied perceptualgrouping systematicallyandsummarizedasetof gestaltlawsofgrouping .inourwork weadoptthefourmost effectiveprincipleswhichgreatlyinfluenceguidesign inpractice as the guideline for our approach design connectedness similarity proximityand continuity.
we define a group of related gui widgets as a layout block of items.atypicalexampleisa listoflistitems inthegui ora card displaying an image and some texts.
the fundamental intuition is if a setofwidgetshave similar visual propertiesandare placed inalignmentwithsimilarspacebetweeneachother theywillbe perceived as in the same layout block by our approach according to the gestalt principles.
in detail our approach consists of four groupingsteps inaccordancewithfour gestalt principles.first it identifiescontainersalongwiththeircontainedwidgetsthatfulfil the connectedness law.
second it uses an unsupervised clustering methoddbscan toclustertextornon textguiwidgetsbased on their spatial and size similarities.
next it groups proximate and spatially aligned clusters to form a larger layout block following the proximity law.
finally in line with the continuity principle ourapproachcorrectssomemistakesofguiwidgetdetectionby checking the consistency ofthe groups compositions.
.
connectedness container recognition in gestalt psychology the principle of uniform connectedness is thestrongestprincipleconcernedwithrelatedness .itimplies that we perceive elements connected by uniform visual properties as beingmorerelatedthanthosenotconnected.
theforms ofthe connection can be either a line connecting several elements or a shapeboundarythatenclosesagroupofrelatedelements.inthe gui the presentation of the connectedness is usually a box containerthatcontainsmultiplewidgetswithinit andalltheenclosed widgetsare perceivedasinthesamegroup.
thus thefirststep of our grouping approach isto recognizethe containersinagui.
in particular we observe that a container is visually a round rectangularwireframeenclosingseveralchildrenwidgets.thecard is a typical example of such containers as shown in figure a .
therefore withthedetectednon textwidgets thealgorithmfirst checks if a widget is of rectangle shape by counting how many straightlinesitsboundarycomprisesandhowtheycompose.specifically we apply the geometrical rule that a rectangle s sides are made of straight lines perpendicular to each other.
subsequently ourapproachdeterminesifthewidget sboundaryisawireframe border by checking if it is connected with any widgets inside its boundary.ifawidgetsatisfiestheabovecriteria itwillbeidentified asacontainer andallwidgetscontainedwithinitarepartitioned intothe same perceptualgroup.
clusternon text areaconflicts resolving clusternon text horizontal clusternon text vertical clustertext horizontal clustertext vertical conflicts resolvingclustering result final goups figure widget clustering cluster conflict resolving and finalresultinggroupsinwhichweusethesamecolortopaint thewidgetsinthesamesubgroupandhighlighthigher order groupsinpinkboxes .
similarity widgetclustering the principle of similarity suggests that elements are perceptually grouped together if they are similar to each other .
generally similaritycanbeobservedinaspectsofvariousvisualcues such as size color shape or position.
for example in the second gui of figure1 theimagewidgetsareofthesamesizeandalignedwith each other in the same way i.e.
same direction and spacing so we visually perceive them as a group.likewise the text pieceson therightoftheimagewidgetsareperceptuallysimilareventhough theyhavedifferentfontstylesandlengthsbecausetheyhavethe same alignmentwithneighbouringtexts.
.
.
initial widget clustering.
our approach identifies similar guiwidgetsbytheirspatialandvisualpropertiesandaggregates similarguiwidgetsintoblocksbysimilarity basedclustering.it clusters texts and non text widgets through different strategies.
ingeneral similarnon textwidgetsinthesameblock e.g.a list usually have similar sizes and align to one another vertically or horizontally with the same spacing.
texts in the same block are alwaysleft justifiedortop justified assumeleft to righttextorientation but their sizes and shapes can vary significantly because of different lengths of text contents.
thus the approach clusters thenon textwidgetsbytheircenterpoints centerx center y and areas anditclusterstextsbytheir top left corner top left our approach uses the dbscan density based spatial clustering of applications with noise algorithm to implement the clustering.intuitively dbscangroupsthepointscloselypackedtogether points with many nearby neighbors while marking points whose distance from the nearest neighbor is greater than the maximumthresholdasoutliers.intheguiwidgetclusteringcontext the point is the gui widget and the distance is the difference between thevaluesofthewidgets attributethattheclusteringisbasedon.
figure4illustrates the clustering process.
for non text widgets ourapproachperformstheclusteringthreetimesbasedonthree attributesrespectively.itfirstclustersthewidgetsby centerxfor the horizontal alignment then by centeryfor the vertical alignment and finally by area.
these operations produce three clusters clusternon text horizontal clusternon text verticalandclusternon textarea.
our approachthenclustersthetextwidgetstwicebasedontheirtopleft 335psychologically inspired unsupervisedinference of perceptual groups of gui widgets from gui images esec fse november14 18 singapore singapore b misclassified widget a missed widget widget detection group pairing subgroup of widgets missed widget misclassified widget figure examples of widget detection error correction.
1st column green box non text red box text 2nd column same color higher order perceptual group 3rd column samecolor subgroup ofwidgets cornerpoint top left forleft justified vertical andtop justified horizontal alignment.it produces the clustertext horizontalbased on thetexts top andtheclustertext verticalbasedonthetexts left.the resultingclustersarehighlightedbydifferentcolorsandnumbers infigure .weonlykeeptheclusterswithatleasttwowidgetsand discardthosewithonly one widget.
.
.
cluster conflicts resolving.
it is common that some widgets canbeclusteredintodifferentclustersbydifferentattributes which causes cluster conflicts.
for example as illustrated in figure several non text widgets e.g.
the bottom left image are both in a verticalcluster markedinblue andahorizontalcluster marked in red .
the intersection of clusters illustrates the conflict.
the approach shall resolve such cluster conflicts to determine to which groupthewidgetbelongs.thisconflict resolvingstepalsocomplies withthe similarityprinciple thatsuggests the widgetsin the same perceptualgroup should share more similar properties.
the conflict resolving step first calculates the average widget areas of the groups to which the conflicting widget has been assigned.
in accordance with the similarity principle the widget is morelikelytobeinagroupwhoseaveragewidgetareaissimilar to the conflicting widget sarea.
in addition anotherobservation isthatrepetitive widgets ina grouphave similarspacingbetween each other.
so for a widget that is clustered into multiple candidate groups the approach checks the difference between the spacing of thiswidgetanditsneighboringwidgetsinagroupandtheaverage spacingbetweenotherwidgetsinthatgroup.itkeepsthewidgetin the group where the conflicting widget has the largest widget area similarity and the smallest spacing difference compared with other widgets inthe group.forexample the bottom leftimagewidget willbeassignedtotheverticalclusterratherthanthehorizontalone according to our conflict resolving criteria.
after conflict resolving ourapproachproducesthefinalwidgetclusteringresultsasshown in the right part of figure .
we use different colors and indices to illustrate the resultingnon text nt andtext t clusters.
.
proximity iterativegrouppairing sofar guiwidgetsareaggregatedintogroupsaspertheconnectedness and similarity principles.
some groups are close to each other and similar in terms of the number and layout of the contained widgets which may furtherform a larger perceptual group even though these groups may contain different types of widgets.
for example intheclusteringresultoffigure wecanobservethat the clusters nt t t 1andnt 2are proximate and have the same or similar number of widgets aligned in the same way.
we canseethisfeatureintentionallyorsubconsciouslyandperceive them as in the same large group as a whole.
gestalt psychology states thatwhen peoplesee anassortment ofobjects theytend to perceive objects that are close to each other as a group .
the close distance also known as proximity of elements is so powerful thatit canoverridewidget similarityand otherfactorsthat might differentiateagroupofobjects .thus thenextstepisbasedon widgetclusters proximityandcompositionsimilaritytopairthe clustersintoalarger group i.e.
layoutblock .
if two groups groupaandgroupbare next proximate to each other i.e.
no other groups in between and they contain the same number of widgets and the widgets in the groupaand thegroupb share the same orientation vertical or horizontal our approach combines groupaandgroupbinto a larger block.
a widget in groupaanditsclosetwidgetin groupbwillbepairedandforma subgroup of widgets.
our approach first combines the two proximate groups containing the same type of widgets and then the groups containing different types of widgets.
the formed larger block can be iteratively combined with the proximate groups until nomore proximate groups are available.
sometimes there are different numbers of widgets in the two proximate groups but the two groups may still form one larger perceptualblock.
for example thecluster nt 2infigure 4has one less widget compared to nt t 0andt 1because the bottom widgetintherightcolumnisoccludedbythefloatactionbutton andthusmissedbythedetector.anothercommonreasonforthe widget number difference is that widgets in a group may be set as invisibleinsomesituations andthustheydonotappearvisually.
therefore ifthedifferencebetweenthenumberofwidgetsinthe two proximate groups is less than empiricallydetermined from theground truthgroupsinourdataset ourapproachalsocombines the twogroupsintoalarger block.
asshowninthefinalgroupsinfigure ourapproachidentifies a set of perceptual groups blocks including the multitab at the top and the list in the main area.
each list item is a combined widget of some non text and text widgets highlighted in the same color .theseperceptualgroupsencodethecomprehensionofthe guistructureintohigher orderlayoutblocksthatcanbeusedin further processing andapplications.
.
continuity detectionerror correction the gui widget detector may make two types of detection errors missedwidgetsandmisclassifiedwidgets.missedwidgetsmeans thatthedetectorfailstodetectsomeguielementsonthegui e.g.
the bottom right icon in figure a .
misclassified widgets refer to the widgets that the detector reports the wrong type for example 336esec fse november14 18 singapore singapore mulong xie zhenchang xing sidongfeng xiweixu liming zhu chunyang chen detection based grouping for screenshot metadata based grouping for screenshot detection based grouping for desgin group groupgroupgroup group group group group group group groupgroup groupgroup groupinput gui detection groups input gui metadata groups input gui detection groups figure examples of gui widget detection and perceptual grouping results red box text widget green box non text widget pinkbox perceptualgroup .metadata based meansgrouping theground truthwidgets directlyfromguimetadata.
the top right small icon i.e.
a non text widget in the middle card in figure b is misclassified as a text widget due to an ocr error.
itishardtorecognizeandcorrectthesedetectionerrorsfromthe individual widget perspective but applying the gestalt continuity principle to expose such widget detection errors by contrasting widgets in the same perceptual groups can mitigate the issue.
the continuityprinciplestatesthatelementsarrangedinalineorcurve areperceivedtobemorerelatedthanelementsnotinalineorcurve .thus somedetectionerrorsarelikelytobespottedifagui areaorawidgetalignswithallthewidgetsinaperceptualgroup inalinebut isnot gatheredintothat group.
our approach tries to identify and fix missed widgets as follows.
it first inspects the subgroups of widgets in a perceptual group and checksifthewidgetsinthesubgroupsareconsistentintermsofthe numberandrelativepositionofthecontainedwidgets.ifasubgroup contains fewer widgets than its counterparts then the approach locates the inconsistent regions by checking the relative positions andareasofothersubgroups widgets.next theapproachcropsthe located ui regions and uses the widget detector upon the cropped regionswithrelaxedparameters i.e.doubleoftheminimumarea threshold for valid widgets to try to identify the missed widget if any.
for example the tiny icon at the bottom right in figure a is missed because its area is so small that the detector regards it asanoisyregionandhencediscardsitintheinitialdetection.by analyzingtheresultingperceptualgroupanditscomposition our approach finds that seven of the eight subgroups have two widgets marked in the same color while the subgroup at the bottom right has only one widget.
it crops the area that may contain the missed widgetaccordingtotheaveragesizesandaveragerelativepositions ofthetwowidgetsintheotherseven subgroups.themissedtiny icon can be recovered by detecting the widget with the relaxed valid widget minimumarea threshold inthe missingarea.
ourapproachusestheexactmechanismthatcontraststhesubgroups to identifythe misclassifiedwidgets but here itfocuses on widget type consistency.
as shown in figure b our approach groups the three cards in a perceptual group.
by contrasting the widgetsinthethreecards itdetectsthatthemiddlecardhastext widgets at the top right corner while the other two cards have a non text widget at thesame relative positions.
based on thecontinuityprinciple ourapproachre classifiesthetop rightwidgetin the middlecardas non textwithamajority winstrategy.
evaluation weevaluateourapproachintwosteps examinetheaccuracy of our enhanced version of uied and compare it with the original uied examine the accuracy of our widget perceptual grouping approach and compare it with the state of the art heuristic basedmethodscreen recognition .
.
accuracyofgui widgetdetection compared with the original uied our gui widget detector uses the latest google ocr tool and improve the text and non text 337psychologically inspired unsupervisedinference of perceptual groups of gui widgets from gui images esec fse november14 18 singapore singapore table overallresults ofwidgetdetection iou .
our enhancedrevision originaluied type precision recall f1 precision recall f1 non text .
.
.
.
.
.
text .
.
.
.
.
.
allwidgets .
.
.
.
.
.
widget merging by container analysis.
we evaluate gui widget detectionfromthethreeperspectives textwidgetdetection nontext widget detection and the final widget results after merging.
to beconsistentwiththeevaluationsettingintheuiedpaper we runexperimentsonthesamericodatasetofandroidappguis and regard the detected widgets whose intersection over union iou with the ground truth widget is over .
as true positive.
the ground truth widgets are the leaf widgets i.e.
non layout classes extractedfrom the gui s runtimeviewhierarchy.
table1showsthewidgetdetectionperformanceoftheenhanced and the original uied.
our enhanced version achieves a much higher recall .
for non text widgets than the original uied .
andmeanwhile italsoimprovestheprecision .589over .
.
this significant improvement is due to the more intelligent container awaremergingoftextandnon textwidgetsbyourenhanced version.
as the original uied is container agnostic it erroneously discards many valid widgets contained in other widgets as noise.
for gui text the google ocr tool used in the enhanced version achieves muchhigher precision .
thanthe eastmodel used in the original uied .
with a slight decrease in recall .693versus0.
.theimprovementsinbothtextandnon text widgets result in a much better overall performance .
f1 by the enhancedversionversus0.
bythe originaluied .
.
perceptual grouping performance we evaluate our perceptual grouping approach on both android appguisanduidesignprototypes.figure 6showssomeperceptual groupingresultsbyourapproach.theseresultsshowourapproach can reliably detect gui widgets and infer perceptual groups for diversevisual andlayoutdesigns.
.
.
datasets.
our approach simulates how humans perceive the gui structure and segment a gui into blocks of widgets according to the gestalt principles of grouping.
to validate the recognized blocks we build the ground truth dataset from two sources androidappsanduidesignprototypes.thegroundtruthannotates thewidgetgroupsaccordingtotheguilayoutandthewidgetstyles andpropertiesas showninfigure .
android app gui dataset the ground truth of widget groups canbeobtainedbyexaminingthelayoutclassesusedtogroupother widgetsintheimplementations.however asshowninfigure the layoutclassesdonotalwayscorrespondtotheperceptualgroups of gui widgets.
therefore we cannot use the gui layout classes directly as the ground truth.
instead we first search the guis in the rico dataset of android app guis that use certain android layoutclassesthatmaycontainagroupofwidgets e.g.
listview framelayout card tablayout .thenwemanuallyexaminethe candidateguistofilteroutthosewhoseuseoflayoutclasseshas obvious violations against the gestalt principles.
furthermore the ricodatasetcontainsmanyhighly similarguiscreenshotsforan gui annotated with widget group gui group group item imageview imageview textviewtextviewitem item ...item textviewitem textviewitem textview imageview imageview textviewtextviewimageview imageview textviewtextviewview hierarchy ground truthandroid app gui ui design prototype gui group item frame textitem item ... frame textframe textitem frame text figure examples of android app gui and ui design prototype view hierarchyand groundtruth application.
to increase the visual and layout diversity of guis in our dataset we limit up to three distinct gui screenshots per application.distinctionisdeterminedbythenumberandtypeof guiwidgetsandtheguistructure.weobtain1091guiscreenshots from772androidapplications.usingthisdataset weevaluateboth detection based and metadata based grouping.
detection based grouping processes the detected widgets while metadata based grouping uses the widgets obtained from the gui metadata i.e.
assumesthe perfectwidgetdetection .
ui design prototypes we collect ui design prototypes sharedonapopularuidesignwebsite figma .theseuidesign prototypesarecreated byprofessionaldesigners forvariouskinds ofappsandreceivemorethan200likes.this smallsetofuidesign prototypesdemonstrateshow professionaldesignersstructure the guisandgroupguiwidgetsfromthedesignratherthantheimplementation perspective.
as a domain independent tool figma supports only elementary visual elements i.e.
text image and shape .designerscancreateanywidgetsusingtheseelementary visualelements.duetothelackofexplicitanduniformwidgetmetadata in the figma designs we evaluate only the detection based grouping ontheseuidesignprototypes.
.
.
metrics.
theleftpartoffigure 7showsanexampleinourandroidappguidataset.weseethatthelayoutclasses e.g.
listview tablayout intheviewhierarchymaptothecorrespondingperceptualgroups.inourdataset specificlayoutclassesaregeneralized 338esec fse november14 18 singapore singapore mulong xie zhenchang xing sidongfeng xiweixu liming zhu chunyang chen figure performanceat differenteditdistance thresholds toblocks asweonlycareaboutgenericperceptualgroupsinthis work.followingthework forgeneratingguicomponenthierarchy from ui image we adopt the sequence representation of aguicomponenthierarchy.
through depth firsttraversal aview hierarchy can be transformed into a string of gui widget names andbrackets and correspondingtotheblocks .thisstring representstheground truthperceptualgroupsofanappgui.as discussedinsection .
perceptualgroupingisbasedonthewidgets positional and visual properties while the actual classes of non textwidgets are not necessary.thus the ground truth string onlyhastwowidgettypes textandnon text.specifically itconvertstextviewintheviewhierarchytotextandallotherclasses asnon text.similarly asshownintherightpartoffigure the designers organize texts and non text widgets images or shape compositions referred to as frames into a hierarchy of groups.
basedonthedesign sgrouphierarchy weoutputtheground truth string of perceptual groups.
the perceptual groups perceived by our approach are outputinthe same format for comparison.
we compute the levenshtein edit distance between the two strings ofa ground truthblockand aperceivedblock.thelevenshtein edits inform us of the specific mismatches between the two blocks which is important to understand and analyze grouping mistakes.iftheeditdistancebetweentheground truthblockand the perceived block is less than a threshold we regard the two blocksasacandidatematch.wedeterminetheoptimalmatching between the string of ground truth blocks and the string of the perceived blocks by minimizing the overall edit distance among all candidate matches.
if a perceived group matches a ground truth group it is a true positive tp otherwise a false positive fp .
if aground truthgroupdoesnotmatchanyperceivedgroup itisa false negative fn .
based on the matching results we compute precision tp tp fp recall tp tp fn and f1 score precision recall precision recall .
.
performance on android app guis.
we experiment with five edit distance thresholds .
the distance means the two blocks have the perfect match and the distance means as long as the unmatched widgetsin thetwoblocks areno morethan the two blocks can be regarded as a candidate match.
as shown in figure fordetection basedgrouping theprecision recallandf1 scoreis .
.520and0.475atthedistance0.asthedistancethresholdincreases i.e.
thematchingcriterionrelaxes theprecision recalland f1 scorekeepsincreasingto0.
.776and0.709atthedistance threshold .
as shown in figure 8and table the metadata based grouping with the ground truth gui widgets achieves a noticeable improvement over the detection based grouping with the detectedtable performancecomparison editdistance widgets approach bock precision recall f1 metadataour approach .
.
.
screenrecog .
.
.
detectionour approach .
.
.
screenrecog .
.
.
widgets intermsofallthreemetrics especiallyforrecall.thissuggests that improving gui widget detection will positively improve the subsequent perceptualgrouping.
as the examples in figure 6show our approach can not only accuratelyprocessguiswithclearstructures e.g.
thefirstrow butitcanalsoprocessguiswithlargenumbersofwidgetsthatare placedinapackedway e.g.
thesecondandthirdrows .furthermore our approachis fault tolerant to gui widget detection errors to a certain extent for example the second row of detection based groupingforscreenshotanddesign.themapandthepushed aside partial gui result in many inaccurately detected gui widgets in thesetwocases.however ourapproachstillrobustlyrecognizes the proper perceptualgroups.
we compare our approach with the heuristic based grouping method screen recognition proposed in zhang et.al.
which received the distinguished paper award at chi2021 .
the results in table2shows that screenrecognition canhardlyhandle visually and structurally complicated guis based on a few ad hoc and rigid heuristics.
its f1 score is only .
on the detected widgets and .
on the ground truth widgets.
this is because its heuristics are designed for only some fixed grouping styles such as cards and multi tabs.
in contrast our approach is designed to fulfil generic gestaltprinciplesofgrouping.
we manually inspect the grouping results by our approach against the ground truth groups to identify the potential improvements.figure 9presentsfourtypicalcasesthatcausetheperceived groups to be regarded as incorrect.for the detection based grouping themajorissueisguiwidgetover segmentation awidgetis detectedasseveralwidgets orunder segmentation severalwidgets are detected as one widget .
in the first row the detector segments the texts on the right side of the gui into several text and non text widgets.
as indicated by the same color in the grouping result column ourapproachstillsuccessfullypartitionsthewidgetsonthe samerowintoablock andrecognizesthelargegroupcontaining these row blocks.
but as shown in the group comparison column onewidgetinthesecond thirdandfourthdetectedblocksdonot match those in the corresponding ground truthblocks.in the second row the gui widget detector merges close by multi line texts asasingletextwidget whilethesetextwidgetsareseparatewidgetsinthegroundtruth.again ourapproachrecognizestheoverall perceptual groups correctly but the widgets in the corresponding blocksdo not completely match.
whileusingtheground truthwidgetsfromtheguimetadata tomitigatetheguiwidgetmisdetection thegroupingresultssee the improvement but suffer from two other problems.
first the widgets in the metadata contain some widgets that are visually occludedorhidden.thethirdrowinfigure 9illustratesthisproblem where some widgets are actually occluded behind the menu on the left but they are still available in the runtime metadata and are 339psychologically inspired unsupervisedinference of perceptual groups of gui widgets from gui images esec fse november14 18 singapore singapore ground truth grouping result ground truth grouping result ground truth grouping result ground truth grouping resultwidget information grouping result ground truth group comparisondetection metadata figure typical causes of grouping mistakes red box text widget green box non text widget pink box perceptual group red dashed box unmatched ground truthwidget extracted as the ground truth widgets.
this results in a completely incorrectgrouping.theissueofwidgetocclusionormodalwindow couldbemitigatedasfollows trainanimageclassifiertopredict the presence of widget occlusion or modal window then follow thefigure ground principle to separateforeground modalwindow from the background and finally detect the perceptual groups on the separated model window.
second alternative ways exist to partitionthewidgetsintogroups.forexample fortheguiinthe fourthrow thegroundtruthcontainseightblocks eachofwhich hasoneimageandonetextwhileourgroupingapproachpartitions theseblocksintofourrowsofalargegroup andeachrowcontains twoblocks asindicatedbythesamecoloringroupingresult .perceptually bothwaysareacceptablebutthegroupdifferencescause the grouping result byour approach to be regardedas incorrect.
.
.
performance on ui design prototypes.
tested on the ui design prototypes our approach achieves the precision of .
therecall0.818andthef1 score0.
.thethirdcolumninfigure shows some results of our grouping approach for the ui design prototypes where we see it is able to infer the widget groups well for different styles of gui designs.
gui widget detection is morerobust on ui design prototypes due to the more accurate gui widgetdetection whichleadstotheimprovementofthesubsequent grouping of detected widgets.
as shown in figure the widgets in a ui design prototype is usually scattered while the real app guis are packed.
both gui widget detection and perceptual grouping become relativelyeasier onless packedguis.
.
.
processingtime.
astheguiwidgetgroupingcanbeusedas apartofvariousautomationtaskssuchasautomatedtesting the runtimeperformancecanbeaconcern.werecordtheprocessing time while running our approach over the dataset to get a sense of its efficiency.
our experiments run on a machine with windows os intel i7 7700hq cpu and 8gb memory.
our approach comprises two major steps widget detection and perceptual grouping.
we improved and refactored the original uied to boost the run performance ofthewidgetdetection and now it takesanaverage of .1s to detect thewidgets in a gui which significantlyexceeds the originaluied that takes onaverage 9s per gui.
the grouping process is also efficient which takes an average of .6s to process a gui.
in total the average processing time of the entire approach is .7s per gui image.
furthermore as our approach does not involveanydeeplearningtechniques itdoesnotrequireadvanced computing support such as gpu.
related work our work falls into the area of reverse engineering the hidden attributesofguisfrompixels.therearetwolinesofcloselyrelated work gui widgetdetection andgui to text code generation.
guiwidgetdetectionisaspecialcaseofobjectdetection .
earlier work uses classic computervision cv algorithms e.g.
canny edgeand contouranalysis todetectguiwidgets.recently white et al.
apply a popular object detection model yolov2 to detect gui widgets in gui images for random gui testing.
feng et al.
apply faster rcnn to obtain gui widgetsfromappscreenshotsandconstructasearchableguiwidget gallery.
chen et al.
proposed an approach to complete icon labelinginmobileapplications.arecentstudybyxieetal.
shows thatbothclassiccvalgorithmsandrecentdeeplearningmodels have limitations when applied to gui widget detection which has different visual characteristics and detection goals from natural sceneobjectdetection.theydesignahybridmethoduiedinspired bythe figure ground characteristicof gui which achievesthe start of the art performance for gui widgetdetection.
gui to text code generation also receives much attention.
to improve guiaccessibility chenet al.
propose atransformerbased image captioning model for producing labels for icons.
to implementguiviewhierarchy remaui infersthreeandroidspecificlayouts linearlayout framelayoutandlistview based on hand craft rules to group widgets.
recently screen recognition developssomeheuristicsforinferringtabsandbars.however theseheuristic basedwidgetgroupingmethodscannothandle visually and structurally complicated gui designs e.g.
nested perceptualgroupslikeagridofcards .alternatively imagecaptioning models have been used to generate gui view hierarchy from gui images .
although these image captioning based methods get rid of hard coded heuristics they suffer from gui data availability and quality issues as discussed in introduction 340esec fse november14 18 singapore singapore mulong xie zhenchang xing sidongfeng xiweixu liming zhu chunyang chen and illustrated in figure .
these methods also suffer from code redundancy and no explicit image code traceability issues see section6.
.
the perceptual groups recognized by our approach could helpto addresstheseissues.
none of the existing gui widget detection and gui to code approaches solve the perceptual grouping problem in a systematic way as our approach does.
redraw and faceoff solves the layout problem by finding in the codebase the layouts containing similar gui widgets.
some other methods rely on source code or specific layout algorithm e.g.
android relativelayout to synthesizemodularguicodeorlayout orinferguiduplication .
all these methods are gui implementation oriented and hardtogeneralizeforotherapplicationscenariossuchasuidesign search uiautomation roboticguitestingoraccessibilityenhancement.incontrast ourapproachisbasedondomain independent gestalt principles and is application independent so it can support differentdownstream se tasks see section .
inthecomputervisioncommunity somemachinelearningtechniques havebeenproposedtopredictstructureinthe visualscene i.e.
so calledscenegraphs.thesetechniquescaninfer therelationshipsbetweenobjectsdetectedinanimageanddescribe theserelationshipsbytriplets subject relation object .however such relationship triplets cannot represent complex gui widget relations in perceptual groups.
furthermore these techniques also requiresufficienthigh qualitydataformodeltraining whichisa challenging issuefor guis.
perceptualgrouping applications our perceptual grouping method fills in an important gap for automatic ui understanding.
perceptual groups together withelementary widget information wouldopenthedoorto someinnovative applicationsinsoftware engineeringdomain.
.
ui design search uidesignisahighlycreativeactivity.theproliferationofuidesign dataontheinternetenablesdata drivenmethodstolearnuidesigns and obtain design inspirations .
however this demands effective ui designsearch engines.existing methodsoften rely on the gui metadata which limits their applicability as most gui designsexistinonlypixelformat.gallerydc buildsagallery of gui widgets and infer elementary widget information e.g.
size primarycolor tohelpwidgetsearch.unfortunately thissolution doesnot applyto thewhole and complex uis.chen etal.
and rico useimageauto encodertoextractimagefeaturesthrough self supervised learning which can be used to find visually similar gui images.
however the image auto encoder encodes only pixellevelfeatures butisunawareofguistructure whichisverycritical tomodelandunderstandguis.assuch giventheguiintheleft offigure theseauto encoderbasedmethodsmayreturnagui liketheoneontherightoffigure becausebothguishaverich graphic features and some textural features.
unfortunately such searchresultsaremeaningless becausetheybearnosimilarityin terms of gui structure and perceptual groups of gui widgets.
our approach can accurately infer perceptual groups of gui widgets frompixels.basedonitsperceptualgroupingresults auidesign search would become structure aware and finds not only visuallybutalso structurallysimilarguis.forexample astructure aware uidesignsearchwouldreturnaguiliketheonein2nd row 1stcolumn offigure 6for the left gui infigure .
.
modular gui to codegeneration existing methods for gui to code generation either use hand craft rulesorspecificlayoutalgorithmstoinfersomespecificimplementation layout or assume the availability of a codebase to search layout implementations .
image captioning based gui to codemethods aremoreflexibleastheylearn howtogenerateguiviewhierarchyfromguimetadata ifavailable .however thenatureofimagecaptioningistojustdescribe theimagecontent butitiscompletelyunawareofguistructure during the code generation.
as such the generated gui code is highly redundant for repetitive gui blocks.
for example for the card basedguidesigninfigure a itwillgenerateeightpieces of repetitive code one for each of the eight cards.
this type of generated code is nothing like the modular gui code developers write.
so it has little practicality.
another significant limitation of image captioningisthatthegeneratedguilayoutsandwidgetshaveno connection to the corresponding parts in the gui image.
for a gui withmanywidgets e.g.
thoseinthe2ndand3rdrowsinfigure itwouldbehardtounderstandhowthegeneratedcodeimplements thegui.withthesupportofourperceptualgrouping gui to code generationcanencapsulatethewidgetgroupinginformationinto the code generation process and produce much less redundant and more modular reusable gui code e.g.
extensible card component .
.
ui automation automating ui understanding from pixels can support many ui automation tasks.
a particular application of ui automation in software engineering is automatic gui testing.
most existing methods for automatic gui testing rely on os or debugging infrastructure .
in recent years computer vision methods have alsobeenusedtosupportnon intrusiveguitesting .
however thesemethodsonlyworkattheguiwidgetlevelthrough eithertraditionalwidgetdetection ordeeplearningmodelslike yolo .
furthermore they only support random testing i.e.
randominteractionswithsomewidgets.somestudies show that gui testing would be more effective if the testing methods wereawareofmorelikelyinteractions.theyproposedeeplearning methods to predict such likely interactions.
however the learning is a completely black box.
that is they can predict where on the guisomeactionscouldbeapplied buttheydonotknowwhatwill be operated and why so.
our approach can inform the learning with higher order perceptual groups of gui widgets so that the model could make an explainable prediction for example scrolling isappropriate becausethispartofguidisplaysalistofrepetitive blocks.itmayalsoguidethetestingmethodstointeractwiththe blocksinaperceptualgroupinanorderlymanner andensureall blocks are tested without unnecessary repetitions.
such support foruiautomationwouldalsoenhancetheeffectivenessofscreen readers which currently heavily rely on accessibility metadata and use mostly elementary widgetinformation.
341psychologically inspired unsupervisedinference of perceptual groups of gui widgets from gui images esec fse november14 18 singapore singapore conclusion and futurework thispaper presentsanovel approachfor recognizingperceptual groups of gui widgets in gui images.
the approach is designed around the four psychological principles of grouping connectedness similarity proximity and continuity.
to the best of our knowledge this is the first unsupervised automatic ui understanding approach with a systematic theoretical foundation rather than relying on ad hoc heuristics or modeltraining with gui metadata.
throughtheevaluationofbothmobileappguisanduidesignprototypes we confirm the high accuracy of our perceptual grouping methodforvisuallyandstructurallydiverseguis.ourapproach fills the gap of visual intelligence between the current widget level detection and the whole ui level gui to code generation.
as a pixel only and application independent approach we envision our approachcouldenhancemanydownstreamsoftwareengineering taskswiththevisualunderstandingofguistructureandperceptual groups such as structure aware ui design search modular andreusablegui to codegeneration andlayout sensitiveuiautomation for gui testing and screen reader.
although our current approachachievesverypromisingperformance itcanbefurther improvedbydealingwithwidgetocclusionormodalwindow.moreover we will investigate semantic grouping that aims to recognize both interaction andcontentsemantics ofperceptualgroups.