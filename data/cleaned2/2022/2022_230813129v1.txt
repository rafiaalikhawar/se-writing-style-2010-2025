accelerating continuous integration with parallel batch testing emad fallahzadeh concordia university department of computer science and software engineering montr al qu bec canada e falla encs.concordia.caamir hossein bavand concordia university department of computer science and software engineering montr al qu bec canada a bavand encs.concordia.capeter c. rigby concordia university department of computer science and software engineering montr al qu bec canada peter.rigby concordia.ca abstract continuous integration at scale is costly but essential to software development.
various test optimization techniques including test selection and prioritization aim to reduce the cost.
test batching is an effective alternative but overlooked technique.
this study evaluates parallelization s effect by adjusting machine count for test batching and introduces two novel approaches.
we establish testall as a baseline to study the impact of parallelism and machine count on feedback time.
we re evaluate constantbatching and introduce batchall which adapts batch size based on the remaining changes in the queue.
we also propose testcasebatching enabling new builds to join a batch before full test execution thus speeding up continuous integration.
our evaluations utilize ericsson s results and million test outcomes from opensource chrome assessing feedback time execution reduction and providing access to chrome project scripts and data.
the results reveal a non linear impact of test parallelization on feedback time as each test delay compounds across the entire test queue.
constantbatching with a batch size of utilizes up to fewer machines to maintain the actual average feedback time and provides a constant execution reduction of up to .
similarly batchall maintains the actual average feedback time with up to fewer machines and exhibits variable execution reduction of up to .
testcasebatching holds the line of the actual average feedback time with up to fewer machines and demonstrates variable execution reduction of up to .
we recommend practitioners usebatchall andtestcasebatching to reduce the required testing machines efficiently.
analyzing historical data to find the threshold where adding more machines has minimal impact on feedback time is also crucial for resource effective testing.
ccs concepts software and its engineering software testing and debugging .
keywords batch testing parallel large scale feedback execution reduction copyright held by the owners authors.
publishing rights licensed to acm.
this is the author s accepted version of the work.
it is posted here for your personal use.
not for redistribution.
the definitive version will be published in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa introduction testing is both time consuming and resource intensive.
to reduce both resource consumption and provide earlier feedback test selection has been widely adopted in the industry and extensively studied .
test selection s inherent trade off is that not all tests are run and some test failures may be missed.
on the other hand test prioritization guarantees that all tests will be run but those that are more likely to reveal faults will be run first reducing feedback time on test failures but not reducing the resource usage in testing .
in contrast batch testing which groups builds for testing and bisects on failure is conceptually better than both test selection and prioritization because all the tests are run with less resource consumption and much faster overall feedback times .
most changes require similar test sets and the saving in batch testing is achieved because batching groups changes and tests to reduce the number of redundant test runs among builds.
for example if we are testing four builds in a batch that request the same tests and the batch passes we will save three build test executions.
however when a batch fails a bisection algorithm must be run to identify the culprit build that is causing the failure.
bisection can slow individual builds but when fewer than of builds fail batching and bisection effectively reduce overall feedback time .
despite its effectiveness only few studies examine batch testing.
najafi et al.
studied batching and bisection techniques at ericsson and found that constant batch sizes can reduce the resource usage i.e.execution time necessary to run all the required tests by up to .
beheshtian et al.
evaluated open source travis torrent projects and proposed batchstop4 which can reduce build test executions on average by .
bavand et al.
used a dynamic batch size approach using the historical failure rate of the projects and reduced the execution time by about against their baseline.
previous batch testing works make three assumptions that are unrealistic on large software systems.
first they do not run tests in parallel and implicitly use a single machine.
second after the failure of a batch they rerun all tests.
this is inefficient because we know which tests failed on a batch and we do not need to bisect and re run the passing tests.
third previous researchers only focus on reducing resource consumption and do not investigate the feedback time outcomes for different batching algorithms.
in this study we address the limitations of prior work and study systems with a much larger scale of ci builds and tests ericsson and chrome.
to understand the impact of parallelization on testing we replicate the testall algorithm which simply runs all tests without applying any batching technique but unlike prior work we vary the number of machines available for testing and run tests in parallel.
our outcome measures are the feedback time i.e.wall time per test and total test execution time reduction for all the tests.
wearxiv .13129v1 aug 2023emad fallahzadeh amir hossein bavand and peter c. rigby replicate constantbatching from the beheshtian et al.
s study which uses a constant batch size for batching and we introduce two novel batchall andtestcasebatching techniques.
batchall algorithm adapts the batch size to the number of remaining changes inside the queue to batch them all at each time.
testcasebatching approach works the same as batchall except that it also accepts new changes while running the batch.
we adopt different numbers of machines on these batching algorithms and evaluate their performance by using feedback time and execution reduction.
we provide results for the following research questions rq1 how does parallelization affect the feedback time performance of testall with varying numbers of machines?
rq2 how effective is constantbatching in terms of feedback time and execution reduction when executed in parallel with varying numbers of machines?
rq3 how effective is batchall in terms of feedback time and execution reduction when executed in parallel with varying numbers of machines?
rq4 how effective is testcasebatching in terms of feedback time and execution reduction when executed in parallel with varying numbers of machines?
our major contributions to this study are as follows.
parallelism in batching we study the impact of parallelization on testing in general and batching.
datasets we use two large scale ericsson and chrome datasets which run millions of tests per day and are suitable to run our batching algorithms and apply parallelism.
simulation we replicate testall and constantbatching algorithms and introduce two novel batchall andtestcasebatching approaches.
outcome measure we use feedback time and execution reduction measures to evaluate the performance of batching algorithms.
results we reach the following conclusions.
the impact of parallelism on the performance testing algorithms exhibits a non linear relationship.
constantbatching with a batch size of utilizes up to fewer machines to maintain the actual average feedback time and provides up to in execution reduction regardless of the number of machines utilized.
batchall maintains the actual average feedback time with up to fewer machines and exhibits variable execution reduction of up to depending on machine utilization and the dataset.
testcasebatching holds the line of the actual average feedback time with up to fewer machines and demonstrates variable execution reduction of up to depending on machine utilization and the dataset.
background and methodology we study a proprietary project at ericsson and the google led open source project chrome.
the project we examine at ericsson tests the software that runs on cellular base stations.
in this context the machines used for testing are extremely expensive and limited in number.
ericsson spends millions on testing infrastructure and still needs to batch tests in order to test all the changes.
test resourcesare scarce and managers discuss the tradeoff of buying new test machine resources for having slower feedback or removing more tests through selection and risking failures slipping through.
testing at ericsson involves a multistage process including various testing levels from unit tests to integration tests before changes are integrated into the released product.
our study focuses on confidence levels and primarily consisting of integration tests which significantly contribute to the overall testing costs at ericsson compared to other levels like unit testing.
thus we capture the test results execution time and change timestamps for each test case during integration testing to gain insights and optimize this critical stage.
to generate our sample dataset we evaluate the integration testing of a project at ericsson.
we capture the test results for the period of six weeks from january to february .
for this duration we observe over changes.
for confidentiality reasons we do not disclose other data or aspects of the testing process and use the data to simulate batching scenarios where machines are very expensive and highly utilized leading to strong resource constraints.
chrome is one of the most popular browsers in the world and it is representative of a large scale project.
there are millions of tests run each day and there are a massive number of builds and tests running in parallel.
the testing process used by chrome was described in detail by fallahzadeh et al.
we summarize briefly below.
a change list i.e.pull request is committed to the gerrit code review tool for revision.
reviewers may suggest changes to the change list to improve the code or when they find issues.
if the change is satisfactory to the reviewers it will be sent for testing on the try bot builders.
after being approved by the builders the change is merged into the main chrome repository.
for the google chrome case we use the chrome test results published by fallahzadeh et al.
.
this publicly available dataset is captured by calling the gerrit code review apis from chrome.
this dataset consists of million test cases for the month of january for chrome.
these test runs are for changes across distinct test suites for an average of .
million test case runs per day.
the rate of failures for the builds in this project is about .
.
we describe how this data is used in our simulation below.
for both ericsson and chrome the data of interest are the test id test name build id build start time build end time status final result and test duration.
we use these attributes to implement our various batching algorithms which will be discussed in the following.
this methodology can be applied to any project that collects this basic data.
we release our scripts and data for chrome in the supplemental material in an anonymized replication package.
.
simulation method and outcome measures in this study we use the record of real historical test runs and only vary the number of machines to evaluate different batching algorithms.
we do notre run any tests.
instead the process involves determining tests for a batch based on the historical test results of the included builds selecting the maximum execution time among the corresponding builds for each test to capture the worst case execution time.
the simulated batch is then dispatched across available machines optimizing test allocation for parallelism and resourceaccelerating continuous integration with parallel batch testing utilization considering the varying number of machines in different scenarios.
during the simulation we assume that a test will fail in the simulated batch if it failed in any of the builds included in the batch and a test is considered to pass in the simulated batch only if it passed in all the builds.
this approach ensures an accurate reflection of test behavior and outcomes in the simulation.
we preserve the order of test runs and discuss the limitations of simulation in section .
the data necessary to conduct the simulation is not company specific and the simulations can be applied to the test results of the other projects as well.
the data includes the code change under test the time the change was available for testing the requested tests for the change and the duration that each test took to run.
the changes are then queued based on their arrival time and simulated using the batching algorithm i.e.how efficiently would we have been able to process the same changes and requested tests?
feedback time one of the most important factors in designing a continuous integration testing infrastructure is giving fast feedback on test outcomes for each change.
the time between committing a change and receiving all test verdicts is defined as feedback time.
feedbacktime time testverdicts time commit for example if a developer commits a change at am and receives the feedback that the tests passed successfully on that change at am the feedback time will be hour for that change.
in contrast if the change was queued for hour then the feedback time would be hours a doubling in feedback time.
in the examples we use a unittto represent time but in the study we use the actual time each test takes to run.
the time a test will be queued depends on the available resources and batching algorithm.
to contrast batching algorithms we use the avgfeedback as the sum of the feedback times for each change in the project divided by the total number of changes for the project.
the equation below shows the avgfeedback for batching algorithm aacrosscchanges withmmachines.
avgfeedbackm a c c 1feedbacktime c a m c to contrast batching algorithms we calculate the feedbackreduction as the percentage decrease in avgfeedback of batching algorithm a1 compared to the avgfeedback of the algorithm a2 withmmachines.
feedbackreduction m a1 a2 avgfeedbackm a1 avgfeedbackm a2 execution reduction theexecutionreduction metric quantifies the performance of different batching algorithms in terms of saving execution time with varying numbers of machines.
it is calculated using equation .
executionreduction m a k t 1test execution time a m n t 1test execution time testall this formula calculates the execution reduction in test executions achieved by a batching algorithm a with m machines compared to running all tests in their original order testall .
here k represents the number of tests executed by the batching algorithm a with m machines and nis the total number of tests executed bytestall .
the formula calculates the percentage of time required for running the tests using approach a with m machines relative to testall .
subtracting this percentage from provides the percentage of execution time that was reduced.
for example if approach a with m machines takes less time to run tests than testall the executionreduction by a with m machines is calculated as indicating that approach a with m machines saves of the time in test execution compared to testall .
by using this formula as a metric we can compare the performance of different batching algorithms and determine their efficiency in saving time during test execution.
simulation setup and plateau thresholds.
to evaluate the batching algorithms performance in terms of feedback time we compare them to the actual average feedback time as the baseline.
due to the complexity and unavailability of the exact number of machines required to achieve the actual average feedback time in both ericsson and chrome we use the baseline number of machines needed to maintain the actual average feedback time for testall .
our simulations vary the available resources machines from to for ericsson and from to for chrome where the average feedback time for all algorithms reaches a plateau.
determining a plateau often involves the expertise of domain experts who suggest appropriate thresholds.
for ericsson we establish a threshold of percent improvement from the actual feedback baseline indicating that beyond this point the improvement in feedback time becomes insignificant with a unit increase of machine.
in the case of chrome the threshold is set at percent improvement from the baseline considering a unit increase of machines.
these thresholds are carefully determined to account for the specific requirements and trade offs in each domain.
ericsson with its high cost machines necessitates a more stringent plateau criterion while chrome benefiting from machine farms adopts a lower threshold to optimize performance.
batching algorithms although parallel testing can help to reduce the feedback time even at large companies using farms of servers to run tests in parallel they still need batch changes to further reduce resources .
in the following we describe the definitions and formulations for each batching algorithm.
.
testall ideally each change would be tested immediately and in isolation running all the requested tests independently of other changes.
this approach works well on small projects that are not resource constrained.
the feedback time for each change varies and depends on the time that a change waits in the queue.
figure describes the testing process for testall algorithm with and machines scenarios.
there are two changes that arrive att 0andt 1times respectively.
when there is only one machine available all tests are running on a single machine andemad fallahzadeh amir hossein bavand and peter c. rigby ab act t t t t t t t t t 9change1 change2m1 a b a cchange1m1 a am2 b c change1 change2 change2 figure a sample of testall algorithm.
in this example there are two subsequent changes and their requested tests a b and c. the sequence of events is displayed by t and the machines are shown by m. subsequent changes have to wait in a queue.
at the time t the tests belonging to the first change are executed with a feedback time equal to units of time.
test execution for change is finished at t 4resulting in the feedback time of units of time.
in the machines scenario the tests belonging to the changes are distributed between the two machines.
at the time t 1both tests a and b for change are executed by the machines m1 and m2 leading to unit of feedback time.
at the time t tests are run for all changes making the average feedback time of in comparison with the previous average feedback time of .
units of time.
.
batch testing and batchstop4 testall is expensive and sometimes infeasible at large companies e.g.
ericsson or google .
instead of testing every change individually we can combine multiple changes and run the union of their requested tests in a batch.
if a batch passes we save resources and provide feedback more quickly.
however if a test fails we need to find the culprit change s that are responsible for the failure.
if the intersection of the requested tests for the batched changes is large and most tests pass the saving could be substantial.
in an extreme example if we batch changes and each change requests the same tests when the batch passes we save build test executions.
however when the batch fails we need to find the culprit change s responsible for the failure.
out of different culprit finding approaches like dorfman and bisection we use the batchstop4 which has been shown both mathematically and empirically to be the top performing approach .
figure displays the batching process of changes consisting of different tests with the same execution time.
to create the batch a union of the tests across all the changes is used which gives distinct tests of a b c d e and f to run.
executing the batch fails leading to the culprit finding process that requires additional test executions.
since we know that test a failed we only run this test in the subsequent builds.
this ends up running test runs which is less than the testall approach that requires test executions.
abc acd ade aeb acf adb afe fbcchange1 abcdef change1 aa change change batchstop4 a a a achange2 change3 change4 change5 change6 change7 change8 change1 change2 change3 change4 figure a sample of batch testing using the batchstop4 culprit approach.
in this example there are eight subsequent changes and their requested tests a b c d e and f. the failing test a is determined by a gray colour.
ab abt t t t t t t t t t 9change1 change2m1 a b b bchange1 m1 a bm2 b b change1 change1 change2 abchange4abchange3 a bchange3 change3 abc1 c1 c1 c2 c3 c3 figure a sample of constantbatching algorithm i.e.batch2 .
in this example there are four subsequent changes and their requested tests a and b. the sequence of events is displayed by t and the machines are shown by m. .
constantbatching prior works have selected a constant batch size for testing .
in the constantbatching technique we group nchanges together and test them in a batch.
for example with n we batch every changes together for testing.
figure shows an example of batch2 using a single machine as well as having two parallel machines.
there are in total changes.
the time of committing the changes is equal to t t t and t respectively.
for simplicity we assume each test execution takes unit of time.
in a single machine configuration the feedback time for each build would be and units of time respectively.
by using two machines the feedback time would be and unit of time respectively.
we can see when using two parallel machines there is a time when machines are free and no test has been assigned to them for execution as they have to wait for changes to be available.
this affects the feedback time for change .accelerating continuous integration with parallel batch testing abc abc abc abc abct t t t t t t t t t 9change1 change2 change3 change4 change5 m1 a b c a b c a b cchange1 change2 change2 change2 change5 change5 change5 change5 finished change2 finished change1 finished change1 change1 figure a sample of batchall algorithm.
in this example there are five subsequent changes and their requested tests a b and c. the sequence of events is displayed by t and the machines are shown by m. .
batchall the assumption of a constant batch size introduces problems.
first the rate of committed changes varies over time.
for example during the peak of the workday there may be s more commits than at night.
we need to vary the batch size based on the change queue.
inbatchall when there are resources available all the waiting changes are grouped and the union of required tests is run for the batch.
when the testing process of the batch finishes and the corresponding resources are free another batch is created using all the current waiting changes and the resources are allocated to the new batch.
figure shows an example of batchall with a single machine.
we assume that there is no failure and all the changes pass the tests.
using batchall after committing the first change the resources are immediately allocated to it for testing.
change arrives first and only after it finishes testing change it batches all the changes that are now waiting i.e.changes and .
after testing the second batch of size it runs the tests for change in a batch of size because no other changes are waiting for testing.
the feedback time for each change will be and respectively.
.
testcasebatching batchall can decrease the feedback time by reducing the idle time of resources.
however when all resources are utilized for testing new changes must be queued until all the tests for the current batch are complete.
with testcasebatching new changes are added to the batch when any test finishes rather than having to wait for all the tests to finish.
this approach requires the requested tests to be queued.
to manage the test queue the requested test cases for each change are added to the queue i.e.the changeid and testid.
when a test finishes any new changes are added to the batch and the next test in the queue is run.
once a change has had all its tests run the results are reported.
in figure we provide an example of testcasebatching .
after each test finishes testcasebatching includes any waiting builds and abc abc abc abc abct t t t t t t t t t 9change1 change2 change3 change4 change5 m1 a b c a b c achange1 change1 change1 change2 change3 change4 change5 change1 finished change2 finished change3 finished change4 finished change5 finished figure a sample of testcasebatching algorithm.
in this example there are five subsequent changes and their requested tests a b and c. the sequence of events is displayed by t and the machines are shown by m. runs the next requested test in the test queue.
testcasebatching has to run test a three times because it has finished for change before changes and and the algorithm has to run it independently for change .
in contrast testcasebatching must only run b and c twice as they overlap when more changes are available.
we see that the average feedback time is reduced to compared to the needed for batchall meaning that we get feedback to developers sooner.
results this section presents the results of our evaluation comparing the performance of different batching algorithms in terms of feedback time the number of machines utilized and the extent of execution reduction achieved.
we conduct these evaluations using the ericsson and chrome datasets considering various numbers of machines.
.
rq1 parallelization with testall in the testall approach we simulate testing each change individually to understand the impact of parallelization on the testing process.
the curves in figure and show that increasing the number of machines has a nonlinear impact on feedback time.
we see that testall needs machines to achieve the actual average feedback time of .
hours for ericsson.
for chrome we see testall needs available machines to achieve the .
minutes average feedback time that is actually observed on chrome.
substantial improvement is seen by adding additional parallel machines but the return on investment diminishes at some point.
for instance in ericsson when we increase from to machines there is a speedup of .
times in testall algorithm but the increase from to machines only adds .
times of improvement in feedback time.
in chrome testall algorithm runs times faster when we use machines instead of machines while when we increase it from to machines it only gets .
times faster.emad fallahzadeh amir hossein bavand and peter c. rigby 3456789improvement against actual average feedback average feedback time in hourspeak number of machinestestallbatch2batch4batchalltestcasebatching figure average feedback time and percentage change relative to actual average feedback time for each approach with varying numbers of machines at ericsson.
we see that testall with machines has plateaued for ericsson and we see testall with machines has plateaued for chrome.
figure displays the confidence intervals for the average feedback time values of all the algorithms analyzed in chrome.1for thetestall algorithm the confidence interval range becomes narrower decreasing from to less than of the actual average feedback time as the number of machines increases from to and beyond.
this reduction in the width of the confidence interval indicates a decrease in the range of the feedback time distribution.
to compare the feedback time distributions of different batching algorithms for chrome we utilize the wilcoxon rank sum test which is suitable for comparing two independent samples without relying on distribution assumptions.
to address the issue of multiple comparisons we apply the bonferroni correction by dividing the desired overall p value of .
by the number of comparisons.
this adjustment results in a p value cutoff of .
for each comparison ensuring a stringent threshold for statistical significance.
the obtained p values are all significantly lower than the cutoff value indicating significant differences in the feedback time distributions between most algorithm comparisons.
however the comparison between testall andbatch2 at machines yields a p value of .
suggesting a lack of significant difference in only this case.
we also calculate cliff s delta effect size to measure the magnitude and direction of differences between feedback time distributions.
in table we present the effect sizes between various algorithms at different machine counts.
this data further supports the observed trend and the significance of the differences depicted in the average feedback time plot shown in figure .
1we are unable to add confidence intervals or compute statistical tests because we no longer have access to the ericsson data.
0255075100125150175200225250275300325350375improvement against actual average feedback average feedback time in minutespeak number of machinestestallbatch2batch4batchalltestcasebatchingfigure average feedback time with colorful confidence intervals and percentage change relative to actual average feedback time for each approach with varying numbers of machines in chrome.
.
rq2 constantbatching batching reduces the number of test executions when the changes request the same tests.
prior works used a constant batch size and we replicate the state of the art approach on a project at ericsson.
we report the results for batch sizes and in this paper.
when large batches pass common tests requested by changes are only run one time dramatically reducing the amount of testing.
as noted by prior work the reduction is limited by the number of failing tests because a failure requires additional executions to find the culprit changes.
however on most large projects there are relatively few test failures making batching highly effective .
prior works have focused on resource savings and largely ignored or simplified feedback time .
if we strictly follow a constant batch size then we see that commits can wait for extended periods of time.
figure and clearly reveal that constant batching algorithms batch2 andbatch4 outperform testall in the majority of cases except in highly resource available environments where the number of machines significantly exceeds the baseline.
as the number of resources increase they plateau with a relatively high feedback time and testall outperforms them.
however they are simpler to implement than other batching algorithms.
table shows that batch2 effectively maintains the actual average feedback baseline of .
hours for ericsson using machines resulting in a .
reduction in machine usage compared to the baseline.
however batch4 achieves the same average feedback time using machines resulting in a negative reduction .
in machine usage compared to the baseline.
for chrome batch2 can maintain the actual average feedback baseline of .
minutes using machines resulting in a .
reduction in machine usage compared to the baseline.
similarly batch4 achieves the same average feedback time using machines resulting in a .
reduction in machine usage compared to the baseline.accelerating continuous integration with parallel batch testing table number of machines required to maintain average feedback time in ericsson and chrome along with percentage reduction compared to baseline.
algorithm testall batch2 batch4 batchalltestcase batching ericsson .
.
.
.
chrome .
.
.
.
table the number of machines and the average feedback time in hours where each batching algorithm plateaus for ericsson.
algorithmtestcase batchingbatchall testall batch2 batch4 feedback time .
.
.
.
.
machines table shows that batch2 andbatch4 plateau for ericsson at .
and .
hours by using machines respectively.
this means that batch2 andbatch4 reach a plateau with and longer average feedback time compared to the baseline respectively.
consequently increasing the number of machines for both algorithms provides a limited scope for improvement compared to the baseline.
for chrome table displays that batch2 andbatch4 plateau at .
and .
minutes using and machines.
this results in and .
longer plateaued feedback time compared to the baseline respectively indicating limited room for improvement relative to the baseline.
the confidence interval values displayed in figure for the batch2 algorithm and chrome reveal that the average feedback time has a range of around when utilizing machines.
notably as the number of machines increases to this range significantly decreases to less than .
conversely for the batch4 algorithm the confidence interval values indicate a range of about when using machines.
while increasing the number of machines reduces the range this reduction is constrained and even with machines the range remains at .
figures and illustrate the percentage of executionreduction achieved by various batching algorithms on ericsson and chrome respectively.
it is worth noting that the executionreduction for the constant batching algorithms remains constant irrespective of the number of machines used.
for ericsson batch2 achieves an executionreduction of while for chrome it achieves an executionreduction of .
similarly batch4 achieves aexecutionreduction of for ericsson and for chrome.
.
rq3 batchall constantbatching excels in conserving resources and reducing feedback time in highly resource constrained environments characterized by limited machine availability compared to the baseline and a significant backlog of commits.
however the queue size varies over time with peak changes happening during working hours.
totable the number of machines and the average feedback time in minutes where each batching algorithm plateaus for chrome.
algorithmtestcase batchingbatchall testall batch2 batch4 feedback time .
.
.
.
.
machines better utilize the available resources we suggest batchall which batches all available changes in the queue.
figure and figure show that batchall approach always outperforms testall andconstantbatching algorithms in both ericsson and chrome cases.
this algorithm performs promisingly both in high resource constrained and high resource available conditions compared to the baseline number of machines.
table illustrates that batchall is capable of maintaining the feedback baseline at .
hours for ericsson by utilizing machines leading to a .
reduction in machine usage.
similarly for chrome batchall achieves the feedback baseline at .
minutes with machines resulting in an impressive .
reduction in machine utilization.
table shows that batchall approach plateaus for ericsson at .
hours by using machines.
this represents a .
resource reduction relative to the plateaued feedback baseline.
for chrome table displays that batchall plateaus for chrome at .
minutes using machines.
this is a .
reduction in resources to reach the plateaued feedback baseline.
the confidence interval for the average feedback time values depicted in figure for the batchall algorithm and chrome indicates a range of approximately compared to the actual average feedback time when using machines.
as the number of machines increases to this range narrows significantly approaching zero which suggests a more concentrated distribution of the feedback time values.
figure and demonstrate that the batchall algorithm s executionreduction varies with the number of machines used decreasing as the number of machines increases.
for ericsson the executionreduction ranges from to when utilizing to machines.
similarly for chrome the executionreduction ranges from to when employing to machines.
figure depicts the average batch sizes utilized by the batchall andtestcasebatching algorithms in chrome with varying numbers of machines.
the figure is displayed on a logarithmic scale to accommodate the substantial difference in batch sizes between a few machines and larger numbers of machines.
the average batch sizes for the batchall algorithm range from approximately batches to nearly batch as the number of machines increases from to .
notably a significant reduction in average batch sizes is observed when the number of machines increases from to resulting in a drop from to batches for batchall .
.
rq4 testcasebatching batchall processes all available changes.
however any change that arrives has to wait until all the tests for a batch have been completed.emad fallahzadeh amir hossein bavand and peter c. rigby table the cliff s delta effect size values for pairwise comparisons of different batching algorithms for chrome at different numbers of machines.
machines ta vs b2 ta vs b4 ta vs ba ta vs tcb b2 vs b4 b2 vs ba b2 vs tcb b4 vs ba b4 vs tcb ba vs tcb .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
please refer to the following abbreviations used in this table ta testall b2 batch2 b4 batch4 ba batchall tcb testcasebatching .
123456789percentage of execution reductionpeak number of machinesbatch2batch4batchalltestcasebatching figure the percentage of executionreduction achieved by different batching algorithms relative to the testall was calculated for different peak numbers of machines for ericsson.
in background section .
we introduced testcasebatching that queues the requested tests across all changes and includes any new change after each test completes rather than waiting for all tests to complete .
except when there is an extreme resource constraint the testcasebatching approach performs more effectively than other algorithms in terms of feedback time as shown in for ericsson in figure and chrome in figure .
the reasons for the algorithm s poor 050100150200250300350percentage of execution reductionpeak number of machinesbatch2batch4batchalltestcasebatchingfigure the percentage of executionreduction achieved by different batching algorithms relative to the testall was calculated for different peak numbers of machines for chrome.
performance under high resource constraints as depicted by the parallel line in figure at machines will be discussed in detail in the discussion section.
table presents that testcasebatching achieves the feedback baseline at .
hours for ericsson by utilizing machines resulting in a .
reduction in machine usage.
similarly for chrome testcasebatching achieves the feedback baseline at .
minutesaccelerating continuous integration with parallel batch testing using machines leading to a remarkable .
reduction in machine utilization.
table shows that the testcasebatching approach plateaus for ericsson at .
hours by using machines.
this presents a .
resource reduction to reach the plateaued feedback baseline.
for chrome table displays that the testcasebatching plateaus for chrome at .
minutes using machines.
this is a .
reduction in resources to reach the plateaued feedback baseline.
the confidence interval ranges depicted in figure for the testcasebatching algorithm and chrome tend to stabilize at approximately of the actual average feedback time as the number of machines increases to .
beyond this threshold the range of confidence intervals decreases significantly approaching nearly zero.
this narrowing range suggests a more concentrated distribution of feedback time values.
figures and illustrate the varying percentages of executionreduction achieved by the testcasebatching algorithm using different numbers of machines.
in the context of ericsson testcasebatching achieves an executionreduction ranging from to when employing to machines.
on the other hand in the case of chrome testcasebatching initially exhibits negative performance in executionreduction with fewer than machines as further discussed in the subsequent section.
however with to machines testcasebatching achieves an executionreduction ranging from to outperforming the results of batchall .
figure illustrates the batch size utilization of the testcasebatching algorithm on chrome covering a range of to machines.
the average batch sizes vary from approximately to .
.
in the range of to machines the average batch size remains relatively high ranging from to .
however at machines a significant drop occurs resulting in an average batch size of around .
beyond this point the number of average batch sizes continues to decrease gradually reaching .
at machines.
discussion regarding the impact of parallelization on testing with resource constraints an increase in machine count non linearly improves feedback time.
initially limited resources lead to significant delays as subsequent changes compound the delay.
for instance with just one machine the queue grows substantially causing wait times to surpass processing times.
as the queue size decreases improvements become smaller with test execution time becoming the key factor.
eventually feedback time plateaus offering negligible gains from further machine increases due to the small queue size.
the results for the constantbatching algorithms of batch2 and batch4 reveal that running these algorithms in a highly resourceconstrained environment can boost their feedback time in comparison with the testall approach.
moreover the more resourceconstrained the environment is the more effective larger batch sizes would be.
however in a highly resource available situation using a larger constant batch size will deteriorate the feedback time.
this is because of the fewer changes remaining in the queue as a result of the faster processing time of the changes.
consequently constantbatching with large batch sizes becomes a disadvantage since it increases the wait time for processing the changes.
this is also the reason why constantbatching algorithms reach a plateau 050100150200250300350average batch size logarithmic scale peak number of machinesbatchalltestcasebatchingfigure the average batch size used by the batchall and testcasebatching algorithms was calculated for different peak numbers of machines in chrome represented on a logarithmic scale.
at higher feedback time values leaving little room for improvement with the utilization of additional machines.
batchall on the other hand uses the fast unloading advantage of a bigger batch size in a high resource constrained environment and the low wait time benefit of a smaller batch size in a high resource available environment.
when we simulate a high resourceconstrained environment with few machines it makes large batches that can rapidly reduce the queue leading to a higher executionreduction .
conversely being in a high resource available condition with enormous machines it may reduce the batch size to eliminating build waiting time but resulting in a lower executionreduction .
this makes batchall highly effective in terms of feedback time in both of these scenarios.
testcasebatching algorithm has the highest performance in terms of feedback time except in an extremely high resource constrained environment with few machines specifically in the chrome case with fewer than machines.
this is because the batchall algorithm puts some changes in the queue while it is running the current batch and then it runs all its tests as a batch.
still the testcasebatching method always accepts new changes and does not adopt a queue.
since it runs the tests of a change in the absence of potential subsequent changes when the next changes become available it has to run some of these tests again as a penalty.
when there are enormous overlapping builds these penalties add up and deteriorate the feedback time and the executionreduction of the testcasebatching algorithm in comparison with the batchall method.
this specifically is the case in chrome test results as there are more overlapping builds in the dataset.
the implications of these results for practitioners would be as follows.
we recommend using batchall andtestcasebatching as the best batching algorithms among all the approaches under the study.emad fallahzadeh amir hossein bavand and peter c. rigby in a very high resource constrained environment batchall produces a better feedback time and executionreduction otherwise testcasebatching performs the best.
despite the testing approach being used there is a threshold in which increasing the number of machines does not improve the feedback significantly.
hence it makes sense to recognize this plateau point by exercising the batching approach being used on the corresponding project.
this way they can reduce feedback time while saving the number of machines being used.
threats to validity external validity.
the outcomes from this study are from applying various batching techniques on the test results of two real largescale ericsson and chrome projects and we may not be able to generalize them to all other applications.
the performance of these batching algorithms might differ by applying them to various other projects and using different numbers of machines.
this is because they probably have different numbers of changes builds and test cases.
however the algorithms adopted in this study are not tied to a specific project and the non linear relationship between the number of machines and the feedback time in other projects would likely be the same.
another issue that may threaten the external validity of this work is the failure rate.
the failure rate can be different among various applications and the higher the failure rate is the higher the cost of culprit finding would become which in turn can make the batching algorithms ineffective.
however beheshtian et al.
show that the batching algorithms can produce savings on the projects with a build failure ratio of below and among travis ci projects under their study .
of them could take advantage of batching techniques.
the build failure rate in chrome dataset is .
which is well below the threshold making batching an effective approach for this project.
meanwhile the focus of this study is more on the impact of parallelism on various batching algorithms and on two very large scale ericsson and chrome projects.
at the time of this study we could not recognize any other available testing datasets for the experiment which are comparable in testing scale with these datasets.
internal validity.
one of the aspects of test optimization which can compromise the process is test dependencies.
reordering or running tests in parallel when they were not designed to be run in this manner can introduce dependency flaky failures .
therefore we only batch tests that ericsson guarantees are independent.
in the case of chrome we only run tests in parallel and independently if chrome developers were already running these in parallel on multiple shards.
the historical simulation simplified parts of the ericsson s and chrome s testing processes.
for example developers can stop testing a build or manually batch select changes for testing.
since we cannot model these manual interventions we exclude them from our simulation.
in our experiment we assumed that all changes can be batched and none lead to merge conflict.
since each must be ultimately merged into the main branch we do not introduce any new conflicts because any conflict would have been dealt with when the developer ensures that the code can be merged.
however the batching processmay bring this conflict to the developer s attention earlier as we batch different combinations of changes.
construct validity.
to simplify the measurement of the feedback time we ignored the compile times of the changes.
this is because we could not have any assumptions for the compile time of the batches.
in the case that the batch contains no failing change this can save on compile time.
otherwise it might cause some extra compile time for the failing changes.
considering the failure rates in our study we can suggest that calculating the compile time can even save more on the feedback time of the batching techniques.
we leave this simulation parameter to future work.
using the average value to compare the feedback time of the different batching algorithms can be a threat to the construct validity of this study.
although the feedback time distribution of each test batching experiment is a more accurate way of showing the results for each batching algorithm and for each number of machines we need a single value to compare the performance.
this along with having an approximately normal distribution lead us to determine the average feedback time to compare the outcomes.
related work continuous integration and delivery ci cd is a crucial part of modern software development .
it enables developers to automatically build and test changes ensuring software functionality remains intact .
however testing every commit individually in large software systems is often impractical .
in the following we investigate approaches to accelerate ci.
test selection and prioritization.
to reduce both resource consumption and provide earlier feedback test selection has been widely adopted in the industry and extensively studied .
however test selection s inherent trade off is that not all tests are run and some test failures may be missed.
in contrast test prioritization guarantees that all tests will be run but those that are more likely to reveal faults will be run first reducing feedback time on test failures but not reducing the resource consumption in testing .
however batching offers both feedback and execution reduction without missing any failures.
to provide an industrial comparison we contrast our results with those obtained at microsoft.
herzig et al.
reported improvements of .
.
and .
in testing feedback time for windows office and dynamics using association rule mining for selection.
however they noted slipthrough rates of and at the first branch level and at the second and and at the third branch level.
at ericsson the same approach resulted in a .
reduction but with .
slipthroughs .
in contrast batchall andtestcasebatching reduced testing time by .
and .
respectively at ericsson without allowing any slip throughs.
test parallelization.
tests are distributed across machines using this technique to reduce feedback time.
previous works widely studied the impact of test parallelization on software testing and introduced algorithms to run tests in parallel .
for example arabnejad et al.
investigated using gpus for running tests in parallel.
the most popular algorithms for parallelizing tests are scheduling tests across the machines based on their ids and their historical execution time .accelerating continuous integration with parallel batch testing candido et al.
analyzed over java projects discovering that less than of major projects utilize test parallelization due to concurrency concerns.
they recommended strategies like test refactoring and grouping based on dependencies to aid parallel testing.
bell et al.
investigated test dependency s impact on parallelization introducing the electrictest approach.
ding et al.
proposed behavior oriented test parallelization.
nagy et al.
designed a parallel architecture for test case dispatching to reduce idle nodes and enhance execution time.
in the context of ericsson and chrome we exclusively batch tests at levels designed for parallel execution.
notably none of these prior studies explored test parallelization within batch testing.
build prediction and skip.
another line of work aimed at expediting continuous integration ci processes includes build prediction and build skip techniques.
build prediction techniques leverage machine learning methods to predict the result of a build with a particular focus on reducing the cost of builds that are likely to pass .
on the other hand build skip techniques aim to identify builds that do not require execution typically due to the absence of source code changes.
there are different approaches for build skip including manual configuration and rule based or learning based methods .
while build prediction and build skip techniques offer potential benefits for accelerating ci processes they have limitations.
build prediction techniques struggle with accurately predicting failing builds leading to costly misidentifications and their practical use cases are often ill defined .
on the other hand build skip techniques risk skipping builds that may contain relevant changes or introduce failures.
in contrast batching combines multiple changes into a single build eliminating the risk of skipping builds entirely.
it enables efficient debugging and failure resolution within the batch providing a reliable approach for managing complex software changes in continuous integration as employed by major companies like google.
batch testing.
this technique employed in resource constrained environments reduces feedback time.
instead of testing each change individually changes are batched and tested simultaneously.
gitbisection a well known culprit finding technique conducts a binary search to identify the culprit typically requiring log n executions.
however when multiple culprits exist gitbisection finds only the first.
to address this najafi et al.
introduced a bisection with a divide and conquer algorithm capable of identifying all culprits.
the total executions range from 2log n to2n when all batch changes are culprits.
beheshtian et al.
showed that for batches of or fewer bisection increases executions.
they propose batchstop4 testing each change individually in batches of or fewer.
batchstop4 consistently outperforms batch bisection mathematically.
their study also examines failure rate effects on various batching algorithms.
bavand et al.
implemented a complex dynamic batch size approach based on historical failure rates resulting in a modest .
reduction in test execution time compared to batch4 with a single machine.
in the ericsson context batchall andtestcasebatching achieved more significant executionreduction with .
and .
reductions respectively compared to batch4 .
for chrome batchall showed a substantial .
improvement overbatch4 with a single machine while testcasebatching had negative results with less than machines.
overall batchall andtestcasebatching consistently outperformed constantbatching in feedback time across different machine configurations.these previous works focused on batch testing at the change level and with a single machine without exploring the effects of parallel testing.
in our study we investigate the combined impact of batching and parallel testing for the first time examining how varying the number of parallel machines affects two extensive projects ericsson and chrome.
conclusions and future work in this study we aimed to investigate the impact of parallelization on different batching techniques addressing the limitations of prior single machines studies.
our evaluation yielded the following findings.
testall experience compounded delays in subsequent builds and the effect of changing the number of machines on feedback time is non linear.
the performance of constantbatching is better in high resource constrained setups and it plateaus at a longer feedback time.
it provides a consistent executionreduction across different machine counts.
batchall is effective in both high resource constrained and highly available resource environments being able to maintain actual average feedback time and attain plateaued feedback baseline with .
and .
fewer machines than the baseline respectively.
testcasebatching performs poorly in extreme resource constraint conditions but effectively in high resource available environments utilizing .
of baseline machines to maintain the actual average feedback time and .
to reach the plateaued feedback baseline.
both batchall andtestcasebatching exhibit variable executionreduction .
notably this study utilized simulated parallel test execution based on historical test results.
future research should confirm and extend these findings through experiments conducted in practical settings.
data availability the data for ericsson is not available as this is a proprietary project and cannot be released due to confidentiality.
the data for chrome is publicly available from fallahzadeh et al.
.
we provide our scripts used to simulate the batching algorithms for chrome at