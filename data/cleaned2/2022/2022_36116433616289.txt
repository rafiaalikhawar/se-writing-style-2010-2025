contextual predictivemutation testing kush jain carnegiemellonuniversity unitedstatesurialon carnegiemellonuniversity unitedstates alex groce northernarizona university unitedstatesclaire le goues carnegiemellonuniversity unitedstates abstract mutation testing is a powerful technique for assessing and improving test suite quality that arti f icially introduces bugs and checks whetherthetestsuitescatchthem.however itisalsocomputationally expensive and rarely scalesto large projects.
one promising recent approach to tackling this problem uses machine learning to predict whether the tests will detect the synthetic bugs without actually running those tests.
however existing predictive mutationtestingapproachesstillmisclassify33 ofarandomlysampled setofmutant testsuitepairs.weintroducemutationbert anapproachforpredictivemutationtestingthatsimultaneouslyencodes thesourcemethodmutationandtestmethod capturingkey context in the input representation.
thanks to its higher precision mutationbert saves of the time spent by prior work to verify livemutants andimprovesprecision recall andf1scoreinboth same project and cross project settings.
mutationbert not only enhances the state of the art in predictive mutation testing but also presents practical bene f its for real world applications both in savingdevelopertime and f indinghardtodetect mutants.
ccsconcepts software and its engineering dynamic analysis software testing and debugging .
keywords test oracles code coverage mutation analysis acm referenceformat kush jain uri alon alex groce and claire le goues.
.
contextual predictive mutation testing.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of softwareengineering esec fse december3 sanfrancisco ca usa.
acm newyork ny usa 12pages.
introduction mutation testing is a well established technique for evaluating test suite quality .
mutation testing works by introducing synthetic bugs based on a f ixed set of rules mutation operators rangingfrominvertingconditionalstatementstochangingunary esec fse december sanfrancisco ca usa copyright held bytheowner author s .
acm isbn979 .
copy also referred to as a mutant of the original program.
if the test suite fails on a mutant the mutant is considered detected or killed thisisthedesiredoutcome otherwisethemutantis undetected a live mutant .
empirically mutation testing has been shown to improve test suites in ways correlated with real world fault detection .
however one of its major limitations is its computational cost test suites must be run on each mutant in principle.
large scale systems commonly have hundreds of thousands of mutants since mutants scale with size of the codebase and mutation operators considered.
myriad approaches including weak mutation meta mutation mutation sampling and mutant prioritization havebeenproposedtotacklethiscomputationalcost.
however theytypicallyrequirestillintractablyexpensiveinstrumentationorstaticanddynamicanalyses andusuallyrelyonsome kindofrandomsampling compromisingtheir usefulnessinpractice.mutationtestinghasbeguntoachieveindustryadoption atcompanieslikemetaandgoogle leveragingadditionalheuristics and idle compute time.
however current industrial practice is focused on identifying undetected mutants in newly committed code.thisis inessence thetipoftheiceberg thevastunderwaterdomainofundetectedmutants and thus testweaknesses in existingcodepre datestheadoptionoflimitedmutationanalysis.
runningallmutantsonexistinglargecodebasestosurfacethese problems is stilltooexpensive.
research on predictive mutation testing1 takes a different approach to scalable mutation testing using machine learningto predict whetheramutant will be detected ornot withoutactuallyrunningthetests.
theinitialpmtwork empirically demonstratedacorrelationbetweenstaticanddynamiccodefeatures and mutant detection but falls short of practical utility in termsofactualf1oraccuracyoftheresultingmodel.seshat improvesontheoriginalpmtmodelbyusing naturallanguage channels including the modi f ied code pre and post mutation andkeywordsfromthetestmethodandsourcemethodname.this eliminatestheexpensivedynamicanalysesfromthepmtapproach andprovidesmoredetailedpredictionofwhichtestsdetectamutant inparticular themutant testmatrix .however althoughseshat outperformstheoriginalpmtmodel itstillsuffersfromsigni f icant false postives with a precision of .
on our test set section costingvaluable developertime.
1the f irst publication both named the problem predictive mutation testing and introducedamodel approachtosolveitnamed pmt .ingeneralinthispaper weuse pmt to refer to the problem of predicting whether a test suite will detect a mutant rather than thespeci f icmodelproposed in that paper.
thiswork islicensedunderacreativecommonsattribution4.0international license.
esec fse december3 san francisco ca usa kush jain uri alon alexgroce andclaire le goues code files test filesm1 m2 t1 t2 mutant test matrix mutation testing tooldata preprocessingmutationbert model mutated method covered test suite pairsmutant test method file pair1 figure an overview of mutationbert s work f low.
step provides source and test f iles to a mutation testing tool.
in step the mutation tool generates mutants and correspondng covering tests which are preprocessed tokenized and formatted.
instep3 mutationbert takesthese inputs to produce step thefullmutant testmatrix.
weobservethatthereissigni f icantadditional contextual information embedded in bothsource and test code well beyond simply themutatedlineandmethodnamesconsideredinpriorwork.by context we mean both the method surrounding a modi f ied line for a given mutant as well as the body of the test method in their entirety.thisintuitionissupportedbythefactthatcodeandtest context are strongly correlated with how useful a mutant is in termsofwhetheramutantisredundant equivalent ortrivial .
inthispaper webuildonthisinsighttoenableeffectiveandefficient contextual predictive mutation testing.
weintroducemutationbert amodelforpredictivemutation testing that takes as input the mutated source method and corresponding test method.
mutationbert learns the relationship between them to predict whether the test will fail on that modi f ied method.
to this end we introduce a novel input representation that encodes each mutation as a token level diff applied to a source method followed by the corresponding test.
we then use a pretrained transformer architecture to encode source and test methods andfurther f inetune itfor our task.
a transformer maps a sequence of tokens to a contextual embeddingthatcansubsequentlybe f inetunedtodownstreamtasks.
transformershavebeenshowntobehighlyeffectiveacrossawide rangeofsoftwareengineeringtasks rangingfromcodecompletion tomergecon f lictresolution .theirhighlyparallelarchitecturemeansthatinferencetimeislow ascomparedtornnsused inpriorworkinpredictivemutationtesting .toourknowledge ourworkisthe f irsttoapplythisrecentadvancementtothisdomain.
asimpliedbythename mutationbertbuildsonrecentadvancementsinpretrainedcodemodelsby f inetuningcodebert for mutationtesting.duetohavingseensomuchcode pretrainedmodels have a better representation and understanding of source code syntax and semantics and thus are better equipped for tackling source intensive taskssuch as mutation testing.
like seshat mutationbert requires no computationally expensivestaticordynamicanalysis norinstrumentation asmutationbert operates entirely on source text.
mutationbert can also generatethefullmutant testmatrix.generatingthefullmatrixis essential for many applications of mutation testing.
for example if amutantispredictedtobedetectedbyonlyaverysmallnumberof tests thepredictioncanbecon f irmedbyrunningjustthosetests.
mutants predicted to be undetected can similarly be checked byrunningthetestsconsideredmostlikely thoughstillunlikely to detectthem.importantlyinpractice adeveloperwhowantstoadd testing to cover an undetected mutant will certainly want to know whichexistingtestswouldbemostlikelytodetectthemutant since oftenthewayto f ixsuchaproblemistostrengthentheoracleor extend the behaviorofan existing test.
tosummarize our core contributionsare as follows an extensive empirical evaluation of predictive mutation testingtools measuringbothinferencetimeandtheruntime costsavings.weconsiderthetradeoffbetweenprecisionand recall and discuss its impact on the end user f inding that mutationbert shigherprecisionsaves33 ofthetotaltime spentcheckingmutantsoverpriorwork.wealsoevaluate ability to detect non trivial mutants f inding mutationbert hasa30 improvementinaccuracyoverthestate of the art.
weintroducemutationbert the f irstpredictivemutation testing model to incorporate source and test code context.
mutationbertcanpredictentiremutant testmatricesalong with whether mutants are detected or not by test suites.
mutationbert has a improvement in f1 score when predicting test matrices and over a improvement in f1scoreoverthestate of the artbaselinewhenpredicting whetheramutantisdetected.whilerecallremainsrelatively stable precision improves by meaning that mutants labeledasundetectedbymutationbertaremuchlesslikely to be false postives.
weperformanextensiveanalysisofthedesigndecisions including an examination of alternative input representations thatleveragebothsourceandtestmethodcontext.we f ind thattoken leveldiffisthemosteffectiveinputrepresentation for mutant prediction.
wereleaseourdataset sourcecode andmodelcheckpointsat includingdetailedinstructions on how to reproduce all of our results and use our model.
we hope that this will enable the community to deploy our model and further builduponour work.
contextualpredictive mutation testing figure1overviews the mutationbert work f low.
our work f low takesaprojectandtestsuiteasinput andusesagivensource level 251contextual predictive mutationtesting esec fse december3 san francisco ca usa 1public regulartimeperiod next 2hour result if this.hour!
last hour in day if this.hour last hour in day result newhour this.hour this.day ... 10public void testnext 11hour h newhour 12h hour h.next 13assertequals h.getyear ... a motivating example1 cls 2public regulartimeperiod next 3hour result 4if this.hour before !
after enddiff last hour in day result newhour this.hour this.day ... sep 11public void testnext 12hour h newhour 13h hour h.next 14assertequals h.getyear ... b model encoding of example figure2 asnippetofcodefromthepopularjfreechartjavaproject whereamutationchanging !
to isapplied figure 2a .
theprovidedtestfailstodetectthismutant.figure 2bshowshowweencodethismutantinourapproach.newlyaddedspecial tokens are marked in brown .
mutation testing tool step section2.
to generate a set of mutants and tests that cover them step .
most mutation testing tools provide coverage out of the box as a way to prune uncovered mutants which will always be undetected.
we encode the method test pairsin an input representation step section2.
to be passed as input to our trained model step section .
.
the model predicts whether the test will detect or fail to detect themutant step .overallmutant testpairs thesepredictions comprisethe mutant testmatrix forthe program.thisoutputcan be optionally post processed to aggregate predictions across the wholetestsuite.thisproduces fortheuser asetof mutantslikely undetected by the test suite these can be inspected directly or ranked by existing mutant prioritization algorithms .
as thedeveloperaddstests moreinterestingmutantsareidenti f ied leadingto bettertest suites over time.
as an illustrative example consider figure 2a which shows a simpli f ied code and test snippet from jfreechart.2thenext method returns the next hour for a given regulartimeperiod .
thetestnext methodchecksthatitworkscorrectlyfor23 00on december1st .althoughthistestmethod maylookcomprehensive note that it does not fail if we change the !
operator to on line .
a better test suite would include another method that includes a time that is not the last hour of a day which would correctly fail on the mutated code.
we will refer to this example throughout subsequent sections to clarifyour contribution.
.
predictive mutation testing mutation testing is the process of synthetically introducing faults into programs and measuring the effectiveness of tests in catchingthem.asetofprogramtransformations knownas mutation operators take regular code and create buggy copies of it.
these operators vary but some common operators includenegatingconditions if a toif !a replacingarithmetic operators a btoa b replacingrelationaloperators a b toa b and f lipping conditionals a btoa b .
each time of these rules is applied to a program a new mutantis created each differing only slightly from the original program.
the change infigure 2acreates one such mutant for the next method.
test adequacy is measured by running the entire test suite on each mutant the goal is a test suite that detects all mutants increasing con f idence that the suite would detect unintentional bugs as well.
the test suite corresponding to the single test testnext in figure 2adoes not detect the mutant presenting this mutant to a developer would ideally motivate them to create the necessary additional tests.
mutation score or the ratio of detected mutants tototalmutants providesaroughmeasureoftestadequacy outperformingcodecoverageintermsofcorrelationwithreal world fault detection .
mutation testing has seen some industry adoption .
prominent recent uses at facebook and google apply it only to changed code at commit time which still requires large amounts of idle compute because of the massive computational expense of running it over an entire codebase.
tackling this scalability problem isthe core motivation of our work.
ourapproachisparametricwithrespecttoexistingsource level mutationtestingtoolandcanintegratewithexistingapproaches likemajor anduniversalmutator .forourevaluationwe use a set of mutants collected by major on the defects4j .
dataset providedbykimetal.
withthe seshatexperiments.
techniquesforpredictivemutationtesting usemachinelearningtopredictwhetheratestoratestsuitewilldetect a mutant without actually running those tests.
we provide more detailedcomparisoninsection .forthepurposesofunderstanding our technique however note that one limitation of the f irst ml based approach for mutation testing prediction isthat its performancedegradessigni f icantlywhenitisnottrained evaluated onmutantsthatarenotcovered executed byanyofthetestsin the test suite .
uncovered mutants are trivially undetected by a test suite since a test cannot fail due to a bug on a line it does notexecute.theyarethusnotinterestingforthetaskofpredictive mutation testing.
we therefore follow precedent set in subsequent work andexclude uncoveredmutants from the task.
252esec fse december3 san francisco ca usa kush jain uri alon alexgroce andclaire le goues .
input representation our goal is to train a model that predicts whether a given test will detect a given mutant.
concretely a mutant is a typically small modi f icationtoatypicallymuchlargercode f ile.prioreffortstorepresentcodechangesforthepurposeofml fallintothreemaincategories de f iningasetoffeaturesrelatedtothemodi f ication representing the modi f ication with a graph or representingthe before and after ofthemodi f icationwithmultiple embeddings .
for earlier pmt models that did not use pretrained transformers de f iningasetoffeaturesandaggregatingthemintoa singlevectormadesense.however toleveragethegainsfromusing a pretrained model like codebert we need to represent our inputsinthesamewayasthepretrainedmodel makingthefeaturebased approach unviable.
following best practices in pretrained transformers we use the same input embeddings for encoding the mutatedcode andthe tests.
thus we represent each mutant test pair as a token level diff to mutationbert using the special tokens before after and enddiff .
for example if the line ...if a b ... is changed to...if a !
b ... weencodeitinthefollowingmanner ...if a before after !
enddiff b ... .thisencodediffs compactly whilepreservingoriginalcode structure.
figure2bshowshowourmodelencodesthemotivatingexample.
we provide the model with the source method encoded as a token level diff followed bythetestmethod.ourmodelthenoutputswhethersuchamutantisdetectedorundetected.wefollow codebert intheiruseofspecialtokens cls and sep .codebertuses cls and sep to denote codeandnaturallanguage input using cls tokenfordownstreamclassi f icationtasks we discuss this in more detail in section .
.
similarly we separate code and test with the special sep token.
we take the hidden representationof the cls tokenas the vectorwhich we train the modelto classifywhether this mutant isdetectedornot.
.
model our model can predict either the entire mutant test matrix for a project or whether a single mutant is detected by an entire test suite.ourmodelisapre trainedcodebertmodel f ine tunedtothe mutationtestingtask withanovelinputrepresentation.codebert isapretrainedmodelthatleveragesthetransformerarchitecture .
it was trained to predict maskedtokens code or natural languagetokensreplacedwith mask forbothsourcecodeand natural language.
codebert uses special cls and sep tokens to denote code and natural language using the cls token for classi f ication in downstream tasks.
codebert was pretrained on a corpusof6.4millionfunctionsacrosssevendifferentprogramming languages largepretrainedmodelslikecodebertareapplicable toavarietyofdownstreamtasksrangingfromcodecompletion tomergecon f lictresolution andcodesummarization .to thebestofourknowledge wearethe f irsttoleveragepretrained models for the taskofpredictive mutation testing.
weformulatemutationanalysisasabinaryclassi f icationtask to codebert.
we provide codebert with both the source method encoded as a token level diff and the test method section .
.
after feeding the inputto codebert we pass the encoding of the cls token through a linear layer which is then used to make the f inal classi f ication.
the model is called for each mutant test pair to constructthe entire mutant test matrix.
we use the probability output of the model to aggregate predictionsacrosseachmutant ssetofcoveredtests andconsidera mutanttobe detected ifthecon f idenceofthemodelonatleast oneofthe tests isgreater than0.
pred u1d440 u1d447 braceleftbigg detected u1d45a u1d44e u1d465 u1d461 u1d447 u1d440 u1d462 u1d461 u1d44e u1d461 u1d456 u1d45c u1d45b u1d435 u1d438 u1d445 u1d447 u1d440 u1d461 .
undetected otherwise where u1d440corresponds to the mutant and u1d447corresponds to the set of tests that cover the mutant.
we chose .
as our con f idence threshold as it was able to reduce the number of false positives when evaluated on our validation dataset with a precision of .
whilenot reducing the overall f1score of .
.
experimentalsetup wecompare mutationbertwithseshat the currentstate ofthe artmodelforpmt usingthedatasetfromthatpaper.weask the following researchquestions rq1 effectiveness how well does mutationbert perform inasameproject setting?
inasameproject setting apmtmodel istrainedonpreviousversionsofaproject andthenusedtopredicttestmatrices unkilledmutants ormutationscoresforsubsequent versions.
we compare mutationbert to seshat on a withinprojecttask evaluatingthemodels correctnesswhenpredicting test mutant matrices andover the test suite level aggregation.
rq2 generality how well does mutationbert perform in acrossproject setting?
inacrossproject setting apmtmodelis trainedusingdatafromoneprojectandthenusedtopredicttestmutant behavior for a different project.
this is much more difficult than the same project setting but could be especially applicable whenstartinganewproject forexample.wecomparemutationbert to seshat on the cross project task using the same metrics as thesameproject task.
rq3 design decisions how do different input representationsandaggregationapproachesaffectour f inalmodel?
we analyze and compare severalinput representations as well asaggregationapproachestovalidatethedesigndecisionsunderlying mutationbert.
rq4 qualitativeanalysis whatarecausesofmutationbert mispredictions?
wemanuallyexamine100caseswhereourmodel misclassi f iesamutantasdetectedorundetectedtoidentifycommon reasons for failures andbetterunderstandlimitations.
rq5 efficiency how efficient is mutationbert compared to priorwork andregular mutation testing?
we address how mutationbert compares to seshat and characterize the performance improvement itprovidesover regularmutation testing.
rq6 mutantimportance howeffectiveismutationbertat predictingdifficult to detect mutants?
weaddresshowmutationbertcomparestoseshatwithregards to howmanytests detectamutant aproxyfor mutant difficulty.
253contextual predictive mutationtesting esec fse december3 san francisco ca usa table our datasetcomprisingof6 defects4j .
projects.
project date loc tests commons lang jfreechart gson commons cli jackson core commons csv .
baseline we compare against the seshat baseline .
seshat is a stateof the art model for mutation testing which has been shown to outperformpmt by0.14to0.
f1scoredependingonproject.
similarto our model seshathas no overhead in static ordynamic analysis operatingentirelyonsourcelevelfeatures unliketheprior modelpmt whichrequiresbothstaticanddynamicanalysistorun.
however unlikeour model seshat operates over a set offeatures thesourcemethodname thetestmethodname themutatedline before and after and a one hot encoding of the mutation operator.
seshat f irst encodes the source and test method names with a bidirectional gru.
it then concatinates the resulting embeddings with a one hot encoding of the mutation operator to classify the mutant as detectedorundetectedbythe test.
like our model seshat outputs a con f idence score for each mutant testpair whichweaggregatetopredictwhetherthemutant is detected or not by the entire test suite.
we aggregate seshat s predictions across each mutant s set of covered tests by comparing con f idencetoathreshold.wesetthisthresholdto0.
whichin ourexperiments producedthe highest f1score for seshat invalidation seshatdoesnotmentionaathresholdintheirpaper sowe performthesameoptimizationaswedidformutationbert .we thus aggregate as follows pred u1d440 u1d447 braceleftbigg detected u1d45a u1d44e u1d465 u1d461 u1d447 u1d446 u1d452 u1d460 uni210e u1d44e u1d461 u1d440 u1d461 .
undetected otherwise wheremcorresponds to the mutant and tcorresponds to the set of tests that cover the mutant.
.
dataset we reuse the dataset released with the seshat experiments .
this dataset consists of a full mutation analysis in major of six large scale java projects with extensive testing across multiple versions takenfromdefects4jv2.
.
statisticsshownintable .
this dataset considers only mutants that are actually covered by sometest since uncoveredmutantscannot be detectedbya given test suite andcan be discardedwithasimplecoverageheuristic .
note that the seshat evaluation analyzed the cross version setting in detail training models on previous versions of programs to predict matrices for subsequent versions.
the models remain effective across versions many years apart.
this is likely a function of the fact that code and mutation behavior is quite stable over time as showninthe dataset descriptioninkimetal.
.table tests mutants and mutant test pairs pairs for bothsameprojectandcrossprojectsettings acrosstraining train validation val andtest test sets.notethatmutanttestpairsonlyinclude tests that coveragiven mutation.
split tests mutants pairs sameprojecttrain6 val5 test5 crossprojecttrain4 val1 test thus intheinterestofspaceandcomputationaleffort werestrict ourattentiontosingleversionsperprojectforallrqs.weselect thelatestversionsofthesixprojectsindefects4j2.0andperform a split between train validation and test sets.
in the same projectsetting wesplitbymutant testsuitepair.thisisincontrast tothepriorevaluation thatis mutant testpairsfromthe sametest suitemustbepartofthesamesubset.practically ourenvisioned application does not include a situation where a pmt model could be trained on data corresponding to whether half the tests in a given test suite detect a given mutant and then used to predict the behavior of the other half.
this explains why we reran seshat and whyour numbersmaynotmatchthoseinthe originalpaper .for the cross project setting we split by project where each project consistsofasetofmutant testsuitepairs.weusetheexactsame splitsforourmodelandforseshat.table 2showsstatisticsabout our same projectandcrossprojectsplits.
.
preprocessing andtraining weusethepretrainedrobertatokenizer bpetokenizer with vocabularysizeof50 000tokensforallprogramminglanguagesthat isprovidedwithcodebert.
we f inetune codebertwithcontext window size of tokens and thus only provide mutationbert the f irst tokens of the code and test combinations.
such cases account for .
ofallmutant test pairs.
wefollowthesamestepsthatkimetal .
tooktotrainseshat.
wetrainseshatfor10epochs withabatchsizeof512 andlearning rateof3e .wetrainmutationbertforeightepochswithlearning rate of1e 5and batch size of .
we use a weighted loss function according tothedistribution ofdetectedandundetectedmutanttest pairs.
we use a linear warmup to steps followed by a cosineannealing decay inaccordancewithbest practicesfor f ine tuning transformers .
both models loss functions converge using these settings.
we f ine tuned our model on a nvidia geforce rtx for one weekfor atotal of 115k steps.
.
metricsandsettings onewaytousemodelsforpredictivemutationtestingistocomputemutant testmatrices whichpredict foreachmutant whether each test passes or fails.
in general most tests pass on most mutants.thatis atestdetectingamutantistheminorityclass.inthis 254esec fse december3 san francisco ca usa kush jain uri alon alexgroce andclaire le goues setting model precisionrefers to how accurately mutants are identi f ied asdetected while recallreferstothe proportionofdetected mutants labeled correctly.
in the mutant test matrix setting of mutant test pairs are undetected.
we care that our model is able to accurately predict the remaining of detected mutants the goal isto identifythe fewtests that detecteachmutant.
anotherwaytousethesemodelsistopredictwhetheranentire test suite detects a particular mutant.
here the majority class is detectedmutants ofmutantsaredetected.thecoregoalhereis to accurately identify the undetected mutants to guide developers to improve test suites.
therefore we de f ine precision and recall differently than in the the mutant test matrix setting.
in the test suite setting model precisionrefers to how accurately mutants are identi f ied as undetected while recall refers to the proportion of undetected mutants that are classi f ied correctly.
precision is thus importantinunderstandingthepotentialcostofapmtmodelin termsoftimeneededtoeitheractualrunthetestsuitetocon f irmits predictions ortimewastedbyadeveloperinspectinganultimately uninteresting mutant.
recallis also important to overall model usefulness ifamodelmissesalargenumberofundetectedmutants key gaps intest suite qualitycould remain.
we report precision recall and f1 score which balances the two for all models in the f irst three research questions.
for rq1 sameproject andrq2 crossproject weevaluateperformance both on the base test set mutant test pairs .
for efficacy of prediction over the entire test suite we evaluate mutationbert on thesamedataset aggregatedatthetestsuitelevel 8648testsuites .
forrq3 we evaluate different aggregation thresholds and input representationchoicesonthevalidationsetconsistingof120 mutants again reporting precision recall and f1 scores we evaluate both mutant test predictions and mutant test suite predictions.
due to compute constaints associated with a larger context window we use the token context window to evaluate different thresholds andinputrepresentations.
for rq4 to ensure a representative sample of misclassi f ications we randomly select examples where our model misclassi f ies amutantasbeingdetectedorundetected.wemanuallyexamine each example and try to understand the cause of the misprediction.
finally webucketthesemispredictionsinaseriesofcategoriesand discuss theseindetail.we dothis to informa general assay ofthe limitationsofourtechnique wedo notmakestrongclaimsabout the generalizabilityofthis qualitative assessment.
for rq5 we run iterations of seshat and mutationbert with a batch size of one on a workstation with an nvidia geforce rtx3080gpu with100warmupiterations.wereporttheaverage time taken over these iterations as the inference time for each model.
to compute comparative time and speedups against regular mutation testing we use numbers from previous work inconjunction withour inference time numbers.
for rq6 we report accuracy of seshat and mutationbert with respect to percentage of tests that kill a mutant.
the goal is to measurewhethermutationbertisonlycorrectlyclassifying easy to detect or trivial mutants where the majority of tests detect the given mutant or whether mutationbert is capable of correctly classifying mutants that are more difficult to detect.
results and analysis we report results for all f ive rqs anddiscuss their implications.
.
rq1 same project performance table3shows the results of mutationbert and seshat on the test setforthe sameproject setting.thecentercolumnsshowresults in predicting whether a test will detect a particular mutant relevant to constructing the overall mutant test matrix.
mutationbert outperforms seshat across all metrics mutationbert s f1score is .
comparedtoseshat s0.
.interestingly mutationbertand seshat have similar precision .
for seshat vs .
for mutationbert the models report similar numbers of false positives cases wherethemodelsmisclassifyatestasdetectingamutant .however mutationberthashigherrecall .
versus0.
meaning that mutationbert is more likely to correctly identify cases where atest detectsamutant.
when the predictions are aggregated into test suite level predictions right hand columns recall that undetected mutants are the minority class f lipping the meaning of precision and recall section3.
.seshatandmutationbertboth f indsimilarnumbersof undetectedmutants butmutationberthasmuchhigherprecision .
comparedtoseshat s0.
.falsepositivesarecostly asthey costdevelopersvaluabletimeexaminingmutantsthatareinreality detectedbytheirtest suite.
another way of viewing these results is in terms of the differencebetweenthemutationscoreestimatedbyapredictivemutation model and the actual mutation score.
recall that mutation score isthetrueratioofdetectedmutantstototalmutants empirically mutation score provides a better measure of test adequacy than code coverage and thus is useful albeit usually expensive to compute.
the gold mutation score true mutation score on our testsetis0.
.seshatestimatesamutationscoreof0.40overthe entire dataset an error of .
.
mutationbert computes a mutation score of .
a difference of only .
from the true answer.
mutationbertthushasmuchlowererror inestimatingmutation score onthis dataset as comparedto seshat.
.
rq2 cross project performance table3also shows the cross project setting bottom rows where a model istrained on one set ofprojects and evaluated on another.
again mutationbert outperforms seshat .
precision and .
recallformutationbertand0.58precisionand0.29recallforseshat .
that said in the mutant test predictions both precision and recall drop signi f icantly for both approaches this suggests that trainingdatacontainingproject speci f icvocabularyandmethods contributesubstantiallytothesameprojectperformance.thisis consistent with other results showing that projects have distinct vocabularyandstyle makingcrossprojectpredictiondifficultfor manytasks .precisioncontinuestobequiteabithigherthan recallinthe crossprojectsetting for both models.
at the test suite level we f ind that mutationbert outperforms seshatonallmetrics.precisionisverylowforbothtools seshat and mutationbert both misclassify a signi f icant proportion of undetected mutants however mutationbert has a signi f icantly higherprecision.recallisalsolowinthecrossprojectsetting at .
for seshat and .
for mutationbert.
however this indicates 255contextual predictive mutationtesting esec fse december3 san francisco ca usa table3 comparisonbetweenseshatandmutationbertonbothsameprojectandcrossprojectsettingsintermsofprecision recallandf1score.inbothsameprojectandcrossprojectsettings mutationbertoutperformsseshatacrossallmetrics with anf1score differenceof12 on thesameprojectsettingand f1score differenceof28 on the cross project setting.
setting modelmutant test matrix test suite precision recall f1 precision recall f1 sameprojectseshat .
.
.
.
.
.
mutationbert .
.
.
.
.
.
crossprojectseshat .
.
.
.
.
.
mutationbert .
.
.
.
.
.
thatinacrossprojectsettingmutationbertiscapableof f inding more undetectedmutants thanseshat.
on the cross project test set the gold mutation score is .
.
seshatdiffersfromthisvaluesigni f icantly withamutationscore of0.
errorof0.
.mutationbertismuchcloser predictinga mutation score of0.
errorof0.
.
.
rq3 input representations and aggregationapproaches weproposedanewinputrepresentationforthemutationpredictionproblem.here wedescribeseveralalternativesthatwethen experimentally evaluate.we alsodescribe alternative aggregation approaches.
then we evaluate these alternatives all on the validation set to motivate the input representation and aggregation approachesinour f inal model.
.
.
input representations.
we outline various input representations that incorporate source and test context for our model.
for allinputrepresentations weseparatemethodcodeandtestcode witha cls token whichwe use for classi f ication.
no diff binary task our simplest approach is to directly applythemutationandfeedthemodelboththemutatedversionof the code and unmutated version of the code.
for example when changing to!
in...if a b ... wefeedthemodelboth ...if a b ... and...if a !
b ... figure3b .
since we have likelihood scores for both the mutated and unmutated versions of the code we try two modes of evaluation.
our f irst mode feeds the model the mutated code and takes its prediction.oursecondmodefeedsthemodelboththemutatedcode andunmutatedcodeandobtainsitsprobabilityofbeingdetected.
then it subtracts these two probabilities from each other since we know the f irst datapoint is always undetected and compares this differenceagainstadynamicallysetthreshold.wetryallthresholds between0.01and0.99inincrementsof0.01onthevalidationset andselectthe bestperformingthreshold.
tokenleveldiff werepresenteachmutationasatokenleveldiff.
forexampleifaline ...if a b ... ischangedto ...if a !
b ... weencodeitinthefollowingmanner ...if a before after !
enddiff b ... figure3c .thisallowsforthe mostcompactfootprintinencodingthediffs allowingourmodel tolearnhowcertaindiffscoupledwiththesurroundingcodeand test are correlatedwithamutant being detectedornot detected.
lineleveldiff for line level diffs we represent diffs in terms of changetosourcelines.thisinputrepresentationissimilartotokentable precision recall and f1scores of all models at predicting the mutant test matrix on the validation set.
token diffandlinediffarethebestperformingmodels withanf1 score of0.
.
model precision recall f1 seshat .
.
.
tokendiff .
.
.
linediff .
.
.
nodiff normal .
.
.
nodiff threshold .
.
.
.
level diff.
in our example we encode the mutation as ... before if a b after if a !
b enddiff ... figure3d .
wehypothesizethatthismightperformbetterthantokendiff as codebertwaspretrainedfor taskssuch as nextlineprediction.
.
.
aggregationapproaches.
weoutlineaggregationapproaches thatwetriedforourtestmatrixmodel.practically thisaggregation holdsvalue asundetectedmutants mutantsnotdetectedbythe entire test suite are ones of interest to developers as they indicate testing inadequacy.
speci f ically in order to use such a model aggregate predictions need to be accurate otherwise undetected mutants willbe identi f iedincorrectly.
threshold aggregation we aggregate the predictions of both predictive mutation testing models by using various probability thresholds .
.
.
.
and .
.
speci f ically we only label a test as detecting a mutant if the model predicts the test detects the mutant with probability above the de f ined threshold.
we vary thresholds to observe their effect on precision recall and f1 score.
learnedaggregation wealsotriedlearninganaggregationbased offoftheembeddingsofthe cls tokenaftercodebertencoding.
weuseatransformerwiththreelayerstotaketheseembeddings andaggregatethem.wethenusealinearlayertoclassifybasedoff of this learned aggregate embedding whether the test suite detects or fails to detect the mutant.
we evaluate this learned aggregation both using a weighted loss function according to the data distribution andusing anormal lossfunction.
.
.
experimental results.
we evaluate input representations on our validation set for defects4j .
.
the data distribution is undetected and detected for test matrices.the no diffmodel 256esec fse december3 san francisco ca usa kush jain uri alon alexgroce andclaire le goues if a b ... if a!
b ... a example sourcemutation cls ... if a b ... sep ... cls ... if a !
b ... sep ... b no diff cls ... if a before after !
enddiff b ... sep ... c tokendiff cls ... before if a b after if a !
b enddiff ... sep ... d linediff figure input representations for encoding mutations applied to source code.
each sub f igure shows a different input representation on the same example of changing to!
.
token diff and line diff were the best performing input representations andwe chose to use token diff as the f inalinput representation inmutationbert.
requires two examples per mutant making an even more unbalanced distribution undetected detected .
therefore in training thesemodels we use a weighted loss function thatpenalizesmissclass f icationsof detectedmutantsmorethanundetected mutants.
the weights are different for the token diff andline diff models andthe nodiffmodel.
table4compares our novel input representations against the baseline seshat model.
token diff andline diff perform almost identically with approximately a improvement in f1 score over baseline weusethetokendiffmodelforourotherresults .somewhatsurprisingly whenthediffisnotexplicitlyspeci f ied inthe nodiffmodels themodelfailstoreasonabouthowcoderelates totestspassingorfailingthisisfurthersupportedbythethresholding in the no diffmodels having no effect on validation f1 score regardless of what the threshold is from .
to .
.
we hypothesize that knowing the mutation applied is a key piece of contextforaccuratepredictions.bothourtokenandlinediffmodels have tokens that specifythe startandend ofthe appliedoperator.
wesimilarlyevaluateaggregationstrategiesonthevalidation set atthetestsuitelevel thegoaloftheaggregationstrategiesis to predict over test suites .
table 5shows results of all aggregation strategies we triedonthe validation set.
we f indthatevenwiththesmallchangeinf1scorebetweenthe twomodelsfortestmatrixprediction thereissigni f icantchange in f1 score when it is aggregated at the test suite level.
this is dueto thecompounding effectof errors asan errorin anyone of the tests inthe test matrixcan cause the wholesuite to be labeled incorrectly making even a small difference in f1 score equate to large differences inthe aggregatedmatrix.
toselectthresholds weusethevalidationsetandthef1score followedbyprecision.precisionismoreimportantthanrecallhere because the cost of a false postive is high.
speci f ically a false positivemeansthatadeveloperwillseeamutantthatissupposedto indicatetestinadequacywheninrealitytheirtestsareadequate.we f indthatthebestthresholdforseshatis0.10andthebestthreshold for mutationbert is0.
.
.
rq4 toolmisclassi f ications to understand our model s limitations we examined randomly sampled examples of mutationbert misclassi f ications from ourtable threshold and aggregation approaches predicting test suites on the validation set.
the best threshold for seshat is .
for mutationbert .
.
we f ind that the transformer aggregation approaches have lower precision than the selected threshold approach meaning more false positives.
model threshold precision recall f1 seshat0.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mutationbert0.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
trans weighted n a .
.
.
trans unweighted n a .
.
.
table reasons mutationbert incorrectly classi f ies mutants.
in cases mutationbert lacks sufficient context while in the remaining cases mutationbert misses acontextualclue.
category case count not enough contexthelper test method method class missedcluecode methodname validation set.
we categorize causes of failures in table .
upon inspection we classi f ied each example into two high level buckets not enough context andmissed clue .not enough context refers to cases where the model was missing context that even a human would need to classify the case correctly.
the large majority of 257contextual predictive mutationtesting esec fse december3 san francisco ca usa ourexamples fellunderthisbucket.thesecondcategory consists of missed clue s where the model missed some crucial clue to mutant behavior .
wewereabletosubdividethehigh levelbucketsintocommon subcategories.
for not enough context these are helper test method methodandclass.helper test method refers to cases where the test methodconsists primarily ofinvocationstoanothermethod.one example isas follows public void testjava2dtovalue checkpointstovalue edge plotarea this.axis.setrange .
checkpointstovalue edge plotarea ... testmethod testjava2dtovalue invokeshelpermethod checkpointstovalue multipletimes.withoutthehelpermethodcode mutationbert lacks the context or even knowledge of relevant test assertions to make an accurateprediction onany mutant.
themethodcategory refers to the model lacking necessary sourcecontext.for example public t typeadapter t create ... public void testdeserializenullfield throws ioexception truck truck truckadapter.fromjson ... ... this example shows a test that invokes the fromjsonmethod which theninvokes create.withoutthecodefor fromjson mutationbert cannot reason about how a mutant in createwould affect a test calling fromjson.
finallyclassreferstocaseswheretheconstructorofaclassis mutated but the test invokes a subclass and thus is missing the subclass constructorcontext.the following example showsthis public strokemap public void testcloning pieplot p1 newpieplot ... inthisexample testcloning isinvokingtheconstructorof pieplot which is a subclass of strokemap.
without seeing the constructor ofpieplot mutationbertcannotunderstandhowmutantstothe strokemapconstructoraffectthe test.
missedclue isdividedinto codeandmethodname .coderefers to cases where the model missed a context clue in the source code that indicatedthat mutant detetion.for example 1public boolean hasnext throws ioexception ... return p!
peeked end object p!
peeked end array return true p!
peeked end array 8public void testdoublearraydeserialization 9double values gson.fromjson ... 10assertequals .
values ... in this example the mutant on line replaces the object check with true but the test is only for arrays.
thus the mutant will not bedetectedbytheprovidedtest sincetheobjectcheckisnotbeingtested.
mutationbert misses the correlation between the object checkandthe test assertsalllookingat arrays.
finally method name refers to cases where the model fails to detect an important context clue in the method name.
for example 1public bufferedimage createbufferedimage ... chartrenderinginfo info ... if info!
null if true info.setrenderingsource ... 9public void testdrawwithnullinfo thisexampleshowsamutantthatreplacesanullcheckon infowith true.sincethetestisacasewhere infoisnull onthemutatedcode there will be a null pointer dereference.
thus a nullpointerexception willbethrownandthemutantwillbekilled.mutationbertfailsto seethecorrelation betweenthetestnameand themutantapplied.
.
rq5 efficiency finally we discusstheefficiencyand performance bene f its ofmutationbert as compared to major or seshat.
table 7shows time to run eachtool includingmajor for allmutants inaproject center column and time to run including a con f irmatory check for the predictive techniques right handcolumns .
seshat and mutationbert have comparable inference time in our experiments ms for mutationbert and ms for seshat.
in termsofpracticalimpactonauserinterestedinper mutantprediction the difference between and ms is negligible.
meanwhile as table7shows the time required to compute a full mutation score for a given project is the same order of magnitude 10s of minutes whileboth an order of magnitudefaster thanmajor.
however despitebeingslowerthanseshatonaper prediction basis mutationbert stilloffers signi f icant computational savings for the end user aiming to improve a test suite the original goal ofmutationtesting andconsistentwithitsuseatcompanieslike googleandmeta .inthissetting theuserreceivesalistofundetectedmutantstoinspectandusetocreatenewtests.apractical applicationforpredictivemutationtestingshouldincludea check ofeachpredicted undetectedmutantbeforepresentingthelistto thedeveloperto f ilterincorrectpredictions thisensuresthatthe tool is presenting truly actionable information and saves the developertimeandfrustrationincon f irmingthetool sresults.the right hand sideoftable 7showsthatbecausemutationberthas higherprecisionthanseshat andsimilarrecall itspredictionscan beveri f iedandthusputtousebythedevelopermuchmorequickly.
.
rq6 mutantimportance figure4shows model accuracy ofboth seshat and mutationbert withrespecttopercentageofdetectingtestsinagivenmutant stest suite.mutantswithahighproportionofdetectingtestsarelikely tobetrivial whilemutantswithfewdetectingtestsaremorelikely tobeinteresting.wecomparemutationberttoseshatindetecting trivial vshard to detect mutantsby reporting modelaccuracy as a functionofpercentageofdetectingtests.mutantsthatarekilledby all testsare trivial andwe hypothesizetheyareeasier formodels 258esec fse december3 san francisco ca usa kush jain uri alon alexgroce andclaire le goues table time to run major mutationbert and seshat over all mutants center columns or incorporating a con f irmation checkbefore presenting unkilled mutantsto theuser right handcolumns .
nochecking checking project major s mutationbert s seshat s mutationbert s seshat s commons lang jfreechart gson commons cli jackson core commons csv .
.
.
.
.
.
percentage of killing tests0.
.
.
.
.8average accuracyaverage accuracy vs percentage of killing tests a accuracy vs. percentage of killing mutantsfor seshat .
.
.
.
.
.
percentage of killing tests0.
.
.
.
.
.
.
.95average accuracyaverage accuracy vs percentage of killing tests b accuracy vs. percentage of killing mutantsfor mutationbert figure accuracy vs. percentage of killing mutants for seshat andmutationbert to detect while mutants with fewer detecting tests are more likely to be interestingandmore difficult for models to detect.
as expected both approaches are less accurate at detecting mutantsthatfailfewertests.importantly however mutationbertoutperformsseshatconsiderablyonharder to detectmutants thosefailing1 ofthetestsuite by30 .althoughseshatisslightly more accurate at classifying mutants that fail no tests at all .
accuracyvs.
.
mutationbert s overallaccuracyishigher by .overall mutationbertismoreaccuratethanpriorworkin predictingmutant behavior especiallythe hard to detectcases.
discussion practically mutationbertisusefulforbothofthecoreenduser tasks in mutation testing as a more complete measure of testing adaquacy computing mutation score and to identify undetectedmutantsthatindicatepotentialinadequaciesinexisting testingefforts .
in the classical sense mutation testing serves to evaluate test suite quality .
mutation score or the proportion of detected mutants to total mutants provides a powerful measure of howwelltested includingintermsofactualoraclestrength agiven pieceofcodeis.mutationbertdrasticallyreducestheamountof timeneededtocomputemutationscore takingapproximately30 ms per mutant test pair substantially lower than the actual cost of executinga test and compilingmutants .
the errorrate of mutationbert is also low with mutationbert having below a error in predicting mutation score for both same and cross project settings substantiallylowerthanseshat.furthernotethatastable7shows itisplausiblethatusingmutationberttoapproximate mutation score will be faster in our data about twice as fast as even approximating score by samplingasfew as10 ofmutants.
sampling of mutants is likely to be no more accurate than mutationbert andadditionallyprovides nodataonmutants notsampled whileourapproachprovidesagoodapproximation ofthe result for allmutants.
morerecently companieslikegoogle andfacebook use mutation testing to pinpoint undetected mutants that reveal issues withtestadaquacy.mutationbertsubstantiallysavestimehere as unlike seshat it still achieves over accuracy in predicting hard todetectmutants.whenshownasetofundetectedmutants adeveloperwouldbeabletotrustmutationbert soutput.evenverifying theoutputofallmutantsclassi f iedasundetectedbymutationbert f irst saves of time when compared to regular mutation testing signi f icantly more than seshat s time savings.
we note that withveryhighactual mutationscores whereexaminingunkilled mutants is most useful the time required to discover u1d45bundetected mutants using mutationbert is likely to be muchbetter than with seshatortraditional mutation testing.
259contextual predictive mutationtesting esec fse december3 san francisco ca usa limitationsand threats limitations mutationbert depends on gpu availablity to efficientlymakepredictions.onacpu mutationberttakes84millisecondsperprediction or12mutant testpairspersecond afar cry from the mutant test pairs per second on a gpu .
note that boththesecpuandgputimesaretheoreticalworstcases since thesetimeswerecomputedusingabatchsizeofone.manycurrent cipipelinesarelargelycpu based potentiallycompromisingpractical utility.
however cloud providers increasingly provide gpu access recently githubactionsannouncedplanstodothesamefor ci.3indeed gpusarebecomingmorebroadlyaccessible including via idle gpu time or services like google colab.
future testing approachesare thus increasingly realistic to deploy inpractice.
threats to validity the main internal threat to validity is our implementationofmutationbert.weusedwidelyavailableand popular libraries such as pytorch and pandas for managing data and building the model to help mitigate this threat.
we release our modelsandimplementationforinspectionandextensionbyothers.
the external threats to validity lie in our dataset of mutants and tests.wereusedthedataproducedbypriorworkonalargedataset defects4j that has been used and validated in many other studies insoftwareengineering.sincethisdatasetissourcedfrommultiple differentprojects the results are more likely to generalize.
finally threats to construct validity lie primarily in our evaluationmetrics.wereportwidelyusedmetricsinmachinelearning i.e.
precision recall and f1 score.
we also practically discuss how thesemetrics translate to the real world use case.
related work severalapproacheshavebeenproposedtotacklethecomputational costofmutantexecution includingweak mutation meta mutation mutation sampling and mutant prioritization.
offutt et.
al proposereducingthesetofmutationoperatorsinordertoprune the seach space of mutants.
gopinath et al .
demonstrate that with a small fraction of mutants randomly sampled one can easily approximatemutationscore.metamutation combinesmultiple mutants into one larger combined mutant and executes the test on this combined mutant.
kaufman et.
al focus on computing the probabilitythatmutantsadvancetheadequacyofagiventestsuite.
google andmeta applymutationtesting onlytochanged code at commit time and display undetected mutants as part of code review.
developers can quickly identify potential testing gaps before code reaches production.
google further uses heuristics toavoidmutatingaridlines linesthatwhenmutatedcreate unproductivemutants suchasloggingstatements whilemetauses a learned targeted set of mutation operators .
however even this more narrow application just to changed code in a commit restricted to one mutant per line or a small set of operators is expensive requiring large amountsofidle compute .
approaches to reducing the cost of mutation analysis were categorized as do smarter do faster anddo fewerby offutt et al.
.
thedo smarter approaches include space time trade offs weak mutation analysis and parallelization of mutation analysis.
the do fasterapproaches include mutant schemagenerationandother dofewerapproaches include selective mutation andmutant sampling.
recently predictivemutationtesting proposedanewmeans of tackling these problems through the use of machine learning.
pmtde f inesasetoffeaturesandusesthesetopredictwhethera given mutant is detected or not by the test suite.
the original pmt approachrequirescostlyinstrumentationtocollectfeatures.seshat achiveshigheraccuracywithloweroverheadbyexclusively usinginformationaboutthesourcecodeandmutationitself source method test method andmutatedline .
similar to seshat we also exclusively use information about the source code and mutation itself however we exploit codebert amodelpre trainedonsourcecode overthecontextofboththe sourceandtestmethodsalongwitharepresentationofthemutation applied.we f indthatthisadditionalcontextishelpfulinpredicting theoutcomeofwhetheramutantisdetectedorundetected inboth same projectandcross projectsettings.
conclusion in this paper we present mutationbert a tool for predicting both test matrices and aggregating these predictions.
we perform an extensive evaluation of our model f inding that we save of seshat stimeifadeveloperweretoverifyallmutantsthateither model predicted as undetected.
we also outperform seshat the state of the art model by f1score in predicting test matrices and12 f1scoreinpredictingtheaggregatedtestsuiteoutcome.
we also achieve similar performance in the cross project setting outperformingseshatby10 f1scoreinpredictingtestmatrices and f1score in predicting test suites.
finally we analyze cases whereourmodelfailstoclassifythemutantasdetectedorundetected.
from this analysis we f ind that in the majority of cases where our model incorrectlyclass f ies a test as detecting or failing todetectamutant itlackssufficientcontext.thiscontextoftenlies intesthelpermethods ormethodsthatareinvokedbythetestthat invokethe source method.
mutationbert hasa relatively limited context window of tokens so incorporating this additional informationwouldlikelyrequireusingalargelanguagemodelwith larger contextwindowsizes such as codex.
data availablity we make all data modeling checkpoints and code publically available at .
we include steps required to reproduce our results in the readme f ile both from scratch and using our provided checkpoints.
the scripts to run our preprocessingareunder preprocessing scriptstotrainourmodel are under runtime and scripts to run our evaluation on the test setareunder evaluation .fullinformationonhowtoreproduce our results isavailable in readme.md .