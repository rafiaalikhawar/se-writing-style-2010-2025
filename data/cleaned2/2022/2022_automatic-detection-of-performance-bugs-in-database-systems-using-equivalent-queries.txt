automatic detection of performance bugs in database systems using equivalent queries xinyu liu qi zhou joy arulraj alessandro orso georgia institute of technology atlanta ga usa liuxy gatech.edu arulraj gatech.edu orso cc.gatech.edu meta seattle w a usa zhouqi fb.com abstract because modern data intensive applications rely heavily on database systems dbmss developers extensively test these systems to eliminate bugs that negatively affect functionality.
besides functionalbugs however there is another important class of faults that negatively affect the response time of a dbms known as performance bugs.
despite their potential impact on end user experience performance bugs have received considerably less attention than functional bugs.
to fill this gap we present amoeba a technique and tool for automatically detecting performance bugs in dbmss.
the core idea behind a moeba is to construct semantically equivalent query pairs run both queries on the dbms under test and compare their response time.
if the queries exhibit significantly different response times that indicates the possible presence of a performance bug in the dbms.
to construct equivalent queries we propose to use a set of structure and expression mutation rules especially targeted at uncovering performance bugs.
we also introduce feedback mechanisms for improving the effectiveness and efficiency of the approach.
we evaluate amoeba on two widely used dbmss namely postgresql and cockroachdb with promising results amoeba has so far discovered potential performance bugs among which developers have already confirmed bugs and fixed bugs.
ccs concepts software and its engineering maintaining software software verification and validation information systems query optimization.
keywords differential testing database testing query optimization acm reference format xinyu liu qi zhou joy arulraj alessandro orso .
.
automatic detection of performance bugs in database systems using equivalent queries.
in44th international conference on software engineering icse may pittsburgh pa usa.
acm new y ork ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
introduction database management systems dbmss play a critical role in modern data intensive applications .
for this reason developers extensively test these systems to improve their reliability and ac curacy.
for instance they leverage tools such as sqlsmith and sqlancer to discover crash inducing or logic bugs in dbmss.
however the same level of scrutiny has not been applied toperformance bugs bugs that affect the time taken by the dbms to process certain queries.
detecting performance bugs is just as crucial as detecting functional bugs as delayed responses from the dbms can dramatically affect the user experience .
challenges .to retrieve the results for a given sql query the dbms invokes a pipeline of complex components e.g.
query optimizer execution engine .
the overall performance of the dbms may be reduced due to sub optimal decisions taken by any of these components and the complex interactions among them .
therefore performance testing on individual components of the dbms is in general insufficient to detect performance bugs .
another key challenge for detecting performance bugs in dbms is defining a test oracle that specifies the correct behavior i.e.
response time of a performant dbms for a given sql query.
there are two lines of research that attempt to address this challenge both focusing on performance regressions.
one approach uses a pre determined performance baseline as the oracle and reports a performance bug if there is a significant deviation.
while potentially effective in detecting some performance bugs this approach is human intensive and error prone as it is challengingto construct an accurate performance baseline and to account for variability in dbms performance to reduce false positives .
furthermore this approach relies on a fixed limited set of queries from standard benchmarks that only cover a subset of the sql input domain .
the second approach leverages differential testing to discover performance regressions by using an oracle to compare the execution time of the same query on two versions of the dbms.
while this technique does not require a developer provided pre determined baseline it is only able to detect regressions as it requires two versions of the dbms with and without the performance bugs and focuses on structurally simple queries specially tailored for uncovering regressions.
ourapproach .to address the limitations of existing techniques we present amoeba a new approach for discovering performance bugs in dbmss.
amoeba addresses the challenges discussed above along three dimensions.
first it constructs a performance oracle by comparing the execution time of semantically equivalent queries i.e.
queries that always return the same result .
when ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh p a usa xinyu liu qi zhou joy arulraj alessandro orso the target dbms exhibits a significant difference in execution time on a pair of semantically equivalent queries this may indicate the presence of a performance bug.
second it constructs queries tailored to the discovery of performance bugs by supporting complex structures and computationally expensive sql operators.
further because of the large space of sql queries that amoeba can explore we introduce a feedback mechanism that lets it focus on the subset of the query space that is more likely to uncover performance bugs.
third it introduces two types of semantic preserving query mutation rules that are also tailored to performance bugs detection structural mutations which transform an input query using a setof query rewrite rules derived from the query optimization literature and expression mutations which modify expressions within an input query without changing their semantics.
to evaluate our technique we implemented it and applied it to two widely used dbmss cockroachdb and postgresql .
our results are promising in that amoeba found potential performance bugs among which developers have confirmed bugs and fixed5 bugs.
we also compared amoeba against two other sources of equivalent queries that could be used for detecting performance bugs a manually written test suite in a widely used query optimization framework and the ternary logic partitioning tlp approach .
our results show that the equivalent queries generated by amoeba are more likely to detect performance bugs.
contributions .this paper makes the following contributions a performance bug detection technique with three new aspects the use of query equivalence to generate performance oracles.
two types of query mutations that preserve the semantics of queries structural mutations and expression mutations.
a feedback mechanism that improves the effectiveness and efficiency of the approach.
an implementation of the technique that is publicly available .
an evaluation of the technique that shows that it can detect real and relevant previously unknown performance bugs in two widelyused dbmss.
motivating example figure shows a motivating example that we use to illustrate how semantically equivalent queries can be leveraged for detecting performance bugs in dbmss and show the significant impact performance bugs can have on the end user experience.
the example consists of a pair of equivalent queries q1 figure 1a and q2 figure 1b that our technique actually generatedbased on the scott schema and that detected a real performance bug.
we also show in figure the logical query plans for q1and q2 i.e.
the sequence of logical operations performed when exe cuting the two queries .
although q1 and q2 are equivalent q1 runs slower than q2 on the same database in cockroachdb v20.
.
alpha .
the difference in performance in the two cases is caused by how theemp table which contains million rows is processed.
for q1 the dbms ignores that the maximum number of result tuples is and processes the entire emp table anyway.
for q2 conversely the dbms considers the limit directive processes the table by row and stops after fetching the first qualifying entries.
as a result while q1 takes seconds to execute q2 only takes milliseconds.select job deptno from emp where job technical group by job deptno limit a original query q1 execution time s select cast technical as varchar as job deptno from emp where job technical group by job deptno limit b mutated query q2 execution time 9m s figure query rewriting example of application of the projection column mutation rule.
a logical query plan for q1 b logical query plan for q2 figure logical query plans sequence of logical operations performed when executing the queries in figure .
the developers have acknowledged that this is a previously unknown performance bug and have produced a fix for it.
amoeba can detect this performance bug because it uses the execution time of equivalent queries as performance oracles.
furthermore by so amoeba can provide a concrete performance bug report which allows developers to reproduce and investigate the potential performance bug.
background and terminology this section provides some relevant background information and introduces the terminology used in the paper.
performance bugs and related concepts .aperformance bug is a bug that affects the time taken by the dbms to process certain queries.
before reporting it to the dbms developers we refer to a performance discrepancy identified by amoeba as a potential performance bug ppb which can be unique or not depending on whether its root cause differs from that of other bugs discovered by amoeba based on manual analysis .
after we report a ppb depending on the feedback we receive from the developers we classify the ppb according to the following taxonomy confirmed the developers acknowledge that the issue reported indicates an actual performance bug.
confirmed performance bugs can further be classified as either previously unknown if the developers do not refer us to a previous duplicate bug report or an already planned fix or previously known otherwise.
a confirmed performance bug whether previously known or not can also be classified as fixed if the developers plan to fix the it already fixed it or have a fix in progress or not fixed otherwise.
backlogged if the developers respond to the report and state that they will analyze the ppb at a later time.
unconfirmed if the developers do not acknowledge that the issue reported is a performance bug.
this can happen for two reasons.
either the developers disagree that two reported queries are equivalent in which case we refer to the issue as a false positive o r they acknowledge the performance discrepancy but consider it a future missing optimization rather than a bug.
unknown if the developers ignore the report.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
automatic detection of performance bugs in database systems using equivalent queriesicse may pittsburgh p a usa figure architecture of amoeba genera tor constructs a set of base sql queries based on feedback from other components.
muta tor performs semantic preserving structural and expression mutations on the base queries.
v alida tor executes a pair of semantically equivalent queries using the target dbms and reports query pairs that exhibit a significant difference in runtime performance.
semantic equiv alence .two queries are semantically equivalent if they always produce the same result on any input database instance.
query equivalence is a well studied topic used in many applications such as testing dbmss for correctness educating developers and automatically grading student assignments .
unlike prior efforts we seek to leverage semantic equivalence of queries to find performance bugs in dbmss.
query rewriting .amoeba constructs equivalent queries by rewriting them using a set of rules that preserve equivalence .
for example a rule could mutate projection columns i.e.
the columns the query should return using information from the filter predicate i.e.
the predicate that specifies which rows are to be returned .
we illustrate how this rule transforms its projection columns while preserving semantic equivalence using query q1 figure 1a and its logical query plan figure 2a .
since the filter clause i n q1 selects tuples such that the job attribute is equal to a specific value the rule replaces the final projection column job with a literal column that takes the same value.
figure 1b and figure 2b show the transformation result that is q2 and its logical query plan.
the a moeba technique .
system overview amoeba helps developers uncover performance bugs in a dbms.
the key idea is to compare the runtime performance of the dbms on two semantically equivalent queries which we would normally expect the dbms to execute in a similar amount of time.
if thatis not the case and the difference in the query execution time exceeds a developer specified threshold e.g.
then amoeba has found a ppb.
such a performance oracle allows us to detect performance bugs in a single dbms i.e.
without resorting to comparative analysis against another dbms .
figure illustrates the architecture of a moeba which contains three main components genera tor muta tor and va l i dat o r .
1genera tor leverages a domain specific fuzzing technique to generate sql queries from scratch based on a database schema.
we refer to these queries as base queries.
genera tor is tailored to generate queries that are more likely to trigger performance bugs in dbmss.
in particular it receives feedback from the latter components of a moeba to guide the query generation process.
2muta tor takes a base query as input and seeks to generate equivalent queries by applying a set of semantics preserving queryrewriting rules to the query.
we refer to the resulting set of equivalentqueries as mutant queries.
the output of this component is the base query and a set of equivalent mutant queries.
3va l i dat o r takes a set of equivalent queries as input and generates a list of performance bug reports.
it runs each pair ofequivalent queries on the target dbms and observes whether any pair exhibits a significant difference in runtime performance.
if so it first verifies whether this behavior is reproducible across mul tiple runs.
if it can confirm the discrepancy it generates a reportthat consists of the pair of equivalent queries that exhibit the performance discrepancy and their query execution plans.
we next present the three components of a moeba in detail.
.
query generator amoeba uses a grammar aware genera tor that randomly constructs given a database schema a set of base queries from scratch i.e.
without using any seed query .
as shown in algorithm genera tor takes a target database as input generates base queries as output and uses two key procedures for generating queries that aremore likely to trigger performance bugs g enera te query .
.
uses a top down grammar aware approach to generate queries that are compatible with the schema of the input database and upda te prob tablewith feedback .
.
leverages feedback from prior runs of muta tor .
and va l i dat o r .
to guide the g enera te query procedure.
amoeba relies on this feedback mechanism to improve the probability of generating queries that trigger performance bugs.
next we provide more details about these two procedures.
.
.
grammar aware query generation.
researchers have extensively explored techniques for grammar aware query generation .amoeba s query generation approach differs from prior work in that it is geared towards generating queries that aremore likely to trigger performance bugs in dbms.
this part of the approach is based on two main components a grammar for generating queries with different structures and operators and a probability table defined with respect to the grammar to guide the query generation process.
grammar .amoeba uses a grammar based on the sql standard .
the grammar is expressed in backus naur form bnf which consists of both terminal and non terminal symbols.
we show a subset of the grammar in table .
for instance the non terminal symbol table refmay either be a base table i.e.
table simple from the target database or a derived table i.e.
table joined resulting from a join operator.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh p a usa xinyu liu qi zhou joy arulraj alessandro orso table sql grammar a subset of the sql grammar that allows amoeba to generate queries with a variety of structures and operators.
query spec colonequal select column ref from table ref group clause limit clause table ref colonequal table simple table joined table joined colonequal table ref join spec table ref join spec colonequal join type on join cond join type colonequal left cross inner join cond colonequal bool expr t r u e table probability table probability values that amoeba uses to generate table