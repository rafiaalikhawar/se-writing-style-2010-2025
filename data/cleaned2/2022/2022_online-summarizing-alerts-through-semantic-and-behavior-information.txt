online summarizing alerts through semantic and behavior information jia chen fudan university shanghai china chenj17 fudan.edu.cnpeng wang fudan university shanghai china pengwang5 fudan.edu.cnwei wang fudan university shanghai china weiwang1 fudan.edu.cn abstract alerts which recorddetails aboutsystem failures arecrucial data formonitoringaonlineservicesystem.duetothecomplexcorrelation between system components a system failure usually triggers alargenumberofalerts makingthetraditionalmanualhandling ofalertsinsufficient.thus automaticallysummarizingalertsisa problem demandingprompt solution.this papertackles thischallenge through a novel approach based on supervised learning.
the proposedapproach oas onlinealertsummarizing first learns two types of information from alerts semantic information and behavior information respectively.
then oas adopts a specificdeep learning model to aggregate semantic and behavior repre sentations of alerts and thus determines the correlation betweenalerts.
oas is able to summarize the newly reported alert online.
extensive experiments which are conducted on real alert datasets fromtwolargecommercialbanks demonstratetheefficiencyand the effectiveness of oas.
ccs concepts software and its engineering maintaining software.
keywords alert summary online service systems system maintenance acm reference format jia chen peng wang and wei wang.
.
online summarizing alerts through semanticand behaviorinformation.
in 44th internationalconferenceonsoftwareengineering icse may21 pittsburgh pa usa.
acm newyork ny usa 12pages.
introduction online service systems such as online banking and search engine have become indispensable parts in our daily life.
organizations ofall sizesstrugglewith acommonproblem ininfrastructureand operationalmanagement.thousandsofautomatedalertswithsemistructured text are generated every day from hundreds of infrastructure tools .
peng wang is the corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
complexityofonlineservicesystemsincrease rapidly failuresareinevitableinpractice.therearemanyfactors thatcausefailures suchasnetworkfailures hardwareproblems softwarebugs temperature humidity andevenhumanerrors.in addition to affecting customer satisfaction failures can even cause hugeeconomiclosses especiallyforonlinesystemsinvolvingfinancial services such as banking systems online supermarkets and stocktradingsystems.in2019 theestimatedcostoftheone hour downtime for amazon on prime day which is the biggest sale event of the year for amazon is up to million dollars .
to detect the failure timely maintenance engineers monitor various data of online service system in real time such as kpis logs andtraces .whenthe monitoring datais abnormal corresponding alertswill be reported which describes the phenomenon of the underlying failure and thenmaintenanceengineerswillbenotifiedimmediatelytohandle the alerts and fix the failure.
thus alerts are essential data for engineers to maintain the service system.
in a real scenario a failure usually triggers a large number of alerts duetotheinteractionbetweensystemcomponents resulting inalargenumberofalertsinaday orevenanalertstormduetothe overwhelmingnumberofalertsinashortperiodoftime .although maintenance engineers commonly define correlation rules to summarize alerts of the same failure thereby reducing the in tensity of their maintenance work.
however manually defining correlationrulesisalaborintensiveandtime consumingprocess and it is hard to cover all correlations between alerts.
in consequence designingapproachtoautomaticallysummarizealertsinto incidents is an urgent requirement.
there are a few works focusing on automatically summarizing alerts .
such works claim that since correlated alerts describe the same failure their contents may be similar and thepropagation of a failure within the system follows the topology ofsystemcomponents thusthetopologicalrelationshipbetween systemcomponentsmayrevealthecorrelationbetweenalertsof thefailure.therefore existingworkssummarizealertsaccording totwofactors thejaccardsimilaritybetweenalertcontents and the topological relationship between system components .
however these approaches have following drawbacks.
first alertstriggeredbyonefailuremayhavetotallydifferentcontents.
forexample asshownintable1 althoughthesealertsareallcausedbythefailure ntpstarterror thefirsttwoalertshavenocommon words.inthiscase thejaccardsimilarity cannotcorrelatethese alertssuccessfully.second thetopologyofsystemcomponentsmaybeinaccurateandhardtoutilize.ingeneral thetopologyisderived from the cmdb system configuration management database .
however theupdateofcmdbisatediousandchallengingwork.
ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jia chen peng wang and wei wang even worse in a cloud based system there usually exist many servicecontainersrunningononeserver andcorrespondingsystem topology changes frequently.
in addition to above issues existing works are all unsupervised.
however manycompaniessavealargenumberofworkordersand failurereports whicharenaturalsourcesoflabelsforalertsummarizing.specifically amaintenanceengineerisusuallyrequiredto writeareportafterfixingafailure.suchfailurereportrecordsallfix actions performed by the engineer the root cause of the failure as well as alerts triggered by the failure.
these data contain a wealth ofvaluableexpertexperienceandknowledge.therefore instead of blindly extracting the correlation from original alerts a more robustchoiceistolearnthealertcorrelationfromsuchreportsina supervised fashion.
inthispaper weproposeanovelsupervisedframework oas online alert summarizing to summarize alerts.
oas leverages two types of alert information semantic information and behav ior information.
two deep learning models asr and abr are proposedtoextracttheseinformationrespectively.asr alertsemantics representation extracts the semantics of alerts whichaggregates the contextual information of alert words according theirimportance.meanwhile abr alertbehaviorrepresentation mines the common behavior pattern between alerts from the alert occurrence series.
then to deal with the complexity of the alertcorrelation insteadofdeterminingthecorrelationbysimplysettingafixedthreshold wedesignadeeplearningmodel act alert correlation to combine above two types of alert information and determine the correlation between alerts automatically.
in summary the core research problem in this paper is how toautomaticallysummarizealertsofaservicesystemonline.we adoptdesignscienceresearch asourresearchmethodology.
weinvestigatetheprosandconsofexistingapproachesandpropose anewsolution oas tosolvetheresearchproblem.furthermore a prototypeofoasisimplementedandwevalidateitonrealalert datasets from two large commercial banks.
the contributions of this paper are as follows weproposeoas onlinealertsummarizing toautomat ically summarize alerts online which contains four main components asr abr act and online summarizing.
asr integrates the contextual information of alert words according to their importance.
abr is able to capture the underlyingcommonbehaviorinformationbetweencorrelatedalerts.
act utilizes the strengths of asr and abr to determine thecorrelationbetweenalerts.onlinesummarizingadopts these trained models to summarize the newly reported alert online by a time window.
weevaluateourapproacheswithalertsfromtwolargecommercialbanks aandb andcompareourapproacheswith thestateoftheart.experimentalresultsverifytheefficiency and effectiveness of our approach.
wesharetheprototypeofourapproach andanalertdataset of a large commercial bank b in which the confidential information and some sensitive alert types are removed.
since thealertisusuallyconfidentialforacompany thereisfew public alert datasets of a service system yet.significance.
the significance of this paper is as follows.
first tothebestofourknowledge thisisthefirstsupervisedapproach of alert summarizing that tries to learn knowledge from failure reports.
second this isthe firsttime todirectly minethe behavior information of alerts from the alert occurrence series.
third wedesign three deep learning approaches asr abr and act toautomatically summarize alerts and experimental results show that our approaches can achieve the best effectiveness.
therestofthispaperisorganizedasfollows.wefirstpresent therelatedwork insection2.themotivationof ourstudyissummarizedinsection3.then insection4 wegivethepreliminary ofourapproaches.section5 7presentdetailsofourapproaches.
we demonstrate the effectiveness and efficiency of our approaches by experiments based on real dataset in section .
in section we proposelessonswelearnedfromthisstudy.finally insection10 we conclude our work and discuss its future extension.
related work in recent years as alerts become the main data for maintenance engineerstodetectandanalyzesystemfailures tremendouseffortshavebeendevotedintoalertanalysisinbothacademiaandindustry.someworksfocusonalertsummarizing somefocuson alertprioritization andsomefocusonincidentprediction .
for alert summarizing lin et al.
try to correlate alerts by alert contents to gain some insights of the system failure and thus improve the efficiency of maintenance engineers.
since alert storm whichbringsanoverwhelmingnumberofalerts isagreatchallenge for maintenance engineers zhao et al.
propose alertstorm to combinealertcontentsandsystemtopologytocorrelatealertsof thesamefailure.bothofthemadoptjaccardtomeasurethetextual relationshipbetweenalerts whichonlyconsidersthenumberof common words of alerts and fails to capture the hidden semantics ofalerts.xuetal.
exclusivelyrecognizeapiperformanceproblemsinacloudplatformandcorrelateapialertsbythedependency of apis.
however the system topology and api information are usuallyinaccurateandhardtoutilize becausemaintainingthese information is a tedious and challenging work.
inadditiontoaboveapproachesthatarespecificforalerts there aresomegenericeventsummarizingapproaches .based on mdl minimum description length principle such approaches try to find a set of frequent patterns which can represent thesystembehaviormodelandwellsummarizetheeventsequence.
seqkrimp is a two step approach.
it first generates a set of candidatefrequentpatternsandthengreedilyselectsasetofpatternsthatminimizethedescriptionlengthoftheeventsequence.
gokrimp directly summarizes the event sequence by patterns composed of frequent event types.
csc is similar to gokrimp butitsupportsthe overlapbetweendifferentpatternoccurrences.
swift isanonlineapproachtosummarizetheeventstream by mining frequent patterns with a sliding window.
since many alerttypesmayhavequitelowfrequenciesinreal worldsituations such approaches based on frequent patterns are not suitable for summarizingalerts.inthispaper experimentsconductedonreal alertdatasetsdemonstratethattheseapproachesarenotapplicable to real scenarios.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
online summarizing alerts through semantic and behavior information icse may pittsburgh pa usa for alert prioritization jiang et al.
propose a peer review mechanismtoranktheimportanceofalerts.theirworkhelpsmaintenanceengineerstodeterminewhichalertshouldbeanalyzedfirstintheproblemdeterminationprocess.zhaoetal.
presentalertrank anautomaticandadaptiveframeworkforidentifyingsevere alerts.
specifically alertrank first extracts a set of interpretable features such as alert content and alert frequency and then adopts xgboost ranking algorithm to identify severe alerts out of all incomingalerts.accordingtoexperiments alertranksignificantly save troubleshooting time on non severe alerts for maintenance engineers.
forincidentprediction chenetal.proposeairalert topredict theoccurrenceofoutagesanddiagnosetherootcauseafterthey indeed occur.
airalert analyzes relationships between outages and alertingsignalsbyleveragingbayesiannetworkandpredictoutages using a robust gradient boosting tree based classification approach.
byforecastingoutagesbeforetheyactuallyhappenanddiagnosingtheirrootcause airalertisabletominimizeservicedowntimeand ensure high system availability.
zhao et al.
propose ewarn to online forecast whether an incident will happen in the near future basedonalerts.ewarnfirstextractsasetofalerttextualfeaturesand statistical features to represent omen alert patterns for an incident then ewarn incorporates the multi instance learning to reduce the influenceofnoisyalerts.finally ewarnbuildsaclassificationmodel via machine learning and generates an interpretable report for its prediction.
ewarn has been applied to two large commercial banks in practice which proves its practicability and effectiveness.
motivation in this section we use an illustrative example to motivate ourapproach.
table shows an alert snippet of a large commercialbank a in which the alerts e1 e2 e5 are all caused by the samefailure ntpstarterror .byremovingvariableparameters and stop words from contents these alerts can be classified into three types e1 e2 ande3.
alerts ofthe same type havethe same parsed content.
in table e1ande3belong to e1 e2ande4belong toe2 ande5belongs to e3.
our study aims to automatically summarize such alerts into a group namedas incident therebyreducingthenumberofalertsanalyzedbymaintenanceengineers.tominethecorrelationbetween alerts in this paper we leverage two types of alert information semantic information and behavior information.
.
semantic information as shown in table contents of the alert of e2ande3have some commonkeywords suchas ntp and start whichrevealsthe commonsemanticinformationbetweenalerts.however mining suchcommonsemanticinformationisnottrivial becauseitisoften that correlated alerts have only a few common words and most wordsintheircontentsaredifferent.therefore popularapproaches like jaccard and word2vec may fail to capture such faint common semantic information.
toattacksuchproblem inthispaper weproposeadeeplearning based model named asr alert semantics representation to extract the semantic information of alerts.
asr not only mines thecontextualinformationofeachalertword butalsoconsidersthecontributionofeachwordtotheoverallalertsemantics.asa result thecontextualinformationofalertwordsisintegratedbased ontheirsemanticcontribution.inthepreviousexample asrwill pay more attention to the words ntp and start than the other words in the alert of e2ande3.
.
behavior information comparedtocorrelatingalertsof e2ande3 correlatingthoseof e1 is more challenging since there are no common words between e1 ande2 ore3 .
thus we leverage the behavior information lurking inco occurrencesofalerts.therationaleisthatcorrelatedalerts should occur together in higher probability.
for example figure shows the occurrence series for alerts of e1ande2in one day whichareformedbycountingalertoccurrencesofeachtypeper oneminuteinaday.itcanbeseenthat1 alertsof e1ande2always occurinthe sametimeperiods and which correspond to three distinct failures the fluctuations of these two series are similar.
0occurrences time 5 figure the occurrence series of correlated alerts.
the straightforward approach is to measure the similarity of twooccurrenceseriesusingeuclideandistance ed ordynamic timewarping dtw .however althoughthetwooccurrenceseriesinfigure1aresimilarin and theyhavedifferent shapesin .thisisbecausetheoccurrenceofalertsisaffected by many factors like alert detection mechanism failure severity failure duration and so on.
another alternative is to mine frequent patterns orsequences .buttheycanonlyfindincidents with frequentalert types.
theinfrequent ones althoughmore important will be missed.
in this paper we propose a data driven model abr alert behaviorrepresentation torepresentthebehaviorinformationofan alert.inspiredbyskip gram abrcapturethecommonality between the occurrence series of correlated alerts.
moreover abr utilizes the supervised learning to leverage theexpert knowledge.
theadvantageisthateventheoccurrenceseriesofcorrelatedalerts is not intuitively similar abr is still able to capture their common behavior information.
.
combining semantic and behavior information afterextractingthesemanticinformationandthebehaviorinformation of the alert it is challenging to effectively combine them authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jia chen peng wang and wei wang table a snippet of an alert sequence no.
id timestamp content e1e12018 there isn t effective configuration in var opt conf bank name check.conf please retouch the file.
e2e22018 running ntp start up check script failed tried time s .
e3e12018 there isn t effective configuration in var opt conf bank name check.conf please retouch the file.
e4e22018 running ntp start up check script failed tried time s .
e5e32018 the ntpdaemon server has not been startcorrectly.
tofinallydeterminethecorrelationbetweenalerts.thenaiveapproachistoconsidersemanticinformationandbehaviorinformationseparately.giventwoalerts computingthesimilaritybetween their semantic information or behavior information as long as one similarity exceeds the threshold these two alerts are considered as correlated.
howev er due to the complexity and variety of the alert mechanism it is infeasible to manually set the appropriate threshold for alerts of all possible failures.
weproposeaneuralnetwork calledact alertcorrelation to combinethetwotypesofalertinformationfromasrandabr and determine the correlation between alerts.
in the training stage we generateasetofalertpairs eachofwhichhasalabel correlatedor uncorrelated.theactnetworkautomaticallylearnstheoptimal combination mechanism from the labelled data.
.
supervised vs. unsupervised approach unlikethestateofarts weutilizesupervisedlearningapproachestosummarizealerts.wemakethischoiceduetofollowingreasons.first inmanycompanies thelabelleddataiseasytoobtain.
failure reports are natural labelled data .
each failure report includesrelatedalerts thefailureinformation andsoon.therefore any two alerts belonging to one failure report can be consideredascorrelated.second incidentrecognitionisasubjectivetask.it mayhappenthatdifferentexpertshaveoppositeopinionsaboutthecorrelationbetweenalerts whichisinfluencedbythemaintenance system and mechanism.
thus the supervised approach is more appealing to maintenance engineers.
background and approach overview inthissection wepresentthenecessarybackgroundknowledge and give the approach overview.
.
alert preprocessing given an alert sequence we first preprocess alerts in four steps.in the first step we remove variables in the alert content.
thereare numerous works on parsing alerts .
as drain i s a popular online parser we adopt it as the parser of oas.
in the second step we further remove stop words from the alert content sincestopwords suchas the a and and donotcarrymuch specific semantic information.
in the third step according to alert contents wegroupalertsintodifferenttypes andthusalertsofthe same type have the same alert content.
in the last step for an alert weformits occurrenceseriesbycounting thenumberofalerts of the same type per minutes in the past minutes .
as aresult thealertcontentcontainsthesemanticinformationofthe alert and the occurrence series contains the behavior information of the alert.
for convenience we define the parsed alert sequence as s .foranalert ei i n thetimestampisdenoted asti.
we have a set of alert types e1 e2 em and each alert belong to one alert type.
wi wi li records the words in the contentof ei.theoccurrenceseriesof eiisreferredtoas fi r .
.
overview the objectiveof oas isto utilize thesemantic and behaviorinformationofalertstosummarizealertsonline.asaresult alertsare groupedintodifferentincidentsbyoas andeachincidentcontains alerts of the same system failure.
in addition to reduce the number of alerts compared to a single alert that only focuses on a local phenomenon of a failure an incident can reflect the whole impact of the failure thereby helping maintenance engineers efficiently locate and fix the failure.
figure shows an overview of oas.
oas contains four main components alertsemantics representation asr alert behavior representation abr alertcorrelation act andonlinesummarizing.
oas has two stages training stage and summarizing stage.
in the training stage oas trains the alert representation models asrandabr andthealertcorrelationmodel act offlineaccordingto the history alert sequence.
in the summarizing stage based on the trainedmodels oassummarizesthenewlyreportedalertonline by a time window.
.
.
training stage.
asshownintheleftpartoffigure2 alerts in training dataset are first parsed to get alert contents and alertoccurrences series.
for each eiin the training dataset we obtain otheralertsinwindow thatbelongtothesamefailure withei.
suppose there exist cialerts correlated to eiduring ti w ti which are denoted as ri eri eri erici ri j n j ci .
alerts correlated to eican be collected from history failure reports.
it should be noted that rimay not be a complete set that contains all the alerts correlated to ei.
in fact even an experienced domainexpert can notguarantee that ineach of his failurereports allalertsbelongingtothereportedfailurearefound.ourapproachestrytolearngeneralrelationshipsbetweenavailable correlated alerts and apply them to the newly reported alert in online alert stream.
then we train the semantics representation model asr and the behavior representation model abr.
since asr and abr have nodependency theycanbetrainedseparately.finally wetrainthe alertcorrelationmodel act tomeasurethecorrelation between authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
online summarizing alerts through semantic and behavior information icse may pittsburgh pa usa raw alert raw alert raw alert ...... raw alert history alerts ... ... online summarizingtime wndow newly reported alerttrain modelsalert content words alert occurrence seriessummarizing stagetraining stageasr alert semantics representation abr alert behavior representation act alert correlation alert parsingalert parsingalert content words alert occurrence series r a w a l e r t ...... r a w a l e r t r a w a l e r t r a w a l e r t r a w a l e r t ... ... figure the architecture of oas.
alerts bythe mined semanticand behavior informationfrom asr and abr.
.
.
summarizing stage.
asshownintherightpartoffigure2 for the newly reported alert in the summarizing stage ei after it is parsed we can directly extract its semantic and behavior informationbytherepresentationmodels asrandabr whicharetrained in the training stage.
then we measure the correlation between thenewlygeneratedalert ei andpreviouslyreportedalertsduring aspecifiedtimewindow .accordingtoalertcorrelations found by act we propose a summarizing strategy to online group thenewlyreportedalert ei anditscorrelatedalertintoanincident.
alert representation we propose two approaches asr alert semantics representation and abr alert behavior representation to represent the semantic and behavior information of alerts respectively.
as shown infigure extracting the semantic representation and the behav ior representation are independent thus there is no dependency between asr and abr.
.
semantics representation alertsbelongingtothesamesystemfailurearelikelytohavesimilar semanticinformation.althoughtherearesomeexistingapproaches that can be used to represent the semantic information of alerts such as jaccard word embedding and topic distillation theycan not extractthe complete semanticsof the alert.
the jaccard based approach naively correlates alerts with same words ignoringthecommonsemanticsbetweendifferentwords.
the word embedding based approach simply sums up embedding results of words in an alert neglecting varying contributions of words to the overall semantics.
the topic distillation based approach only distills the general topic of the alert which are too crude to capture distinctive semantic details.
to represent the alert semantic information we propose asr alertsemanticsrepresentation whichextractsthecompletealert semantics based on the respective semantic contribution of each word in the alert content.
for words in the alert content asr first minesthecontextualinformationofeachword andthencalculatesthecontributionofeachwordtotheoverallalertsemantics.finally asraggregatesthecontextualinformationofalertwordsaccording to their contributions to the overall alert semantics.
therefore the key issue is how to mine the contextual information of the alertwordandhowtocalculatethecontributionofthealertwordtothe overall alert semantics.
as shown in figure for each word in the alert content asr adopts a word embedding model named cbow continuous bagof words to mine the contextual information of the word andutilizesidf inversedocumentfrequency tocalculate thesemanticcontributionoftheword.morespecifically incbow aneuralnetworkistrainedtominethecontextualinformationof a word by extracting the common semantics between the word and its adjacent words.idf is a widely used factorto measure the semantic importance of a word to the document which is calculated by dividing the total number of documents by the number of documentsthatcontainthetargetword.inasr thedocumentis referred to the concatenate contents of correlated alerts in history alerts.
cbow idf alert content words sum semantic representation ......contextual informationsemantic contribution figure the process of representing the semantic information of the alert.
in the training stage we separately train cbow and idf by contents in history alerts.
then as shown in figure we can straightforwardly extract the semantic representation for an alert.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jia chen peng wang and wei wang for each word in the alert ei i n we get the contextual informationofthewordbycbow denotedas vi j j li andthe semantic contribution of the word by idf denoted as ui j. it should benotethatinordertoensure summationtext.1li j 1ui j ui jisnormalized.atlast accordingtoequation wecanaggregatethesemanticsofwords in the alert content to obtain the complete semantic representation of the alert denoted as si.
si li summationdisplay.
j vi j ui j .
behavior representation inadditiontosemantics alertsbelongingtothesamesystemfailure usually also have common behavior information.
mining frequent patternsisawidelyusedapproachtocapturebehaviorcorrelations betweenalerts .becausefrequentpatternsindicatecooccurrence correlations between alerts.
in practice however some alert types have quite lowfrequencies to whichfrequent pattern mining approach is not applicable.
to represent the alert behavior information we propose abr alert behavior representation which for the first time learns the commonalitybetweenalertoccurrenceseries.abrisinspiredby thewordembeddingmodel skip gram .skip gram captures the common semantics between a target word and its adjacent words via a shallow neural network which converts the encoding of the target word to the encoding of its adjacent words in a linearfashion.similarly asshowninfigure4 abrtrainsashallow neural network to converts the occurrence series of a targetalert to the occurrence series of its correlated alerts.
as a result the trained neural network can capture the underlying common behavior information between alerts.
sum ...hidden layer figure the process of representing the behavior information of the alert.
to train abr in the training stage for each history alert ei i n by equation we aggregate the occurrence series of alerts correlated to ei and denote the result as fi.
thus since fi contains the behavior information of eiand ficontains the behaviorinformationofitscorrelatedalerts thecommonalitybetween fiand firepresents the same behavior information between ei anditscorrelatedalerts.specifically asshowninfigure4 wetry to transform fito fiby a neural network whose loss function is defined in equation .
in equation f prime iis the transformedresultoffi equation measuresthedifferencebetween f prime iand fi.
after training the result of the hidden layer in the neural network denoted as bi is able to reserve the common behavior information between the occurrences series of eiand its correlated alerts.
fi ci summationdisplay.
j 1fri j labr n summationdisplay.
i 1log exp f prime i fi alert correlation with asr and abr we can represent the semantic information and the behavior information of the alert respectively.
we thusproposeamodel act alertcorrelation tomeasurethecorre lation between alerts by aggregating the semantic and behavior representations of the alert.
before formally introducing act let s consideramotivatingquestion fortwoalerts e1ande2 whenboth theirsemanticandbehaviorrepresentationsaresingle dimensional howtodetermineiftheyarecorrelated.generally forthesemanticrepresentationsof e1ande2 thedifferencebetweenthemshouldbe lessthanathreshold andthesameistrueforthebehaviorrepresen tations.formally wedefineasimpleauxiliaryfunction fdis x y z inequation whichfirstcalculatesthesquaredifferencebetween xandy and measure the difference between the square difference andz.
therefore if e1ande2are correlated both fdis s1 s2 thrd1 andfdis b1 b2 thrd2 arepositive where thrd1andthrd2arethe thresholds for the semantic difference and the behavior difference respectively.
identically to ensure e1ande2are correlated we can getrelu fdis s1 s2 thrd1 relu fdis b1 b2 thrd2 .
fdis x y z z x y act shown in figure is a generalization of the above motivating example in a multi dimensional situation.
for two alerts eiandej i j n inspired by the above example act first calculatesthe squaredifference between eachdimensionof each type of alert representations.
for the semantic representation the result is denoted as si j and for the behavior representation the result is denoted as bi j. in above example fdis s1 s2 thrd1 and fdis b1 b2 thrd2 actuallycanberegardedastwolineartransformation of square differences between each type of alert representa tions where thrd1andthrd2arebiases.thus actcorrespondingly performs linear transformation on si jandbi j respectively.
in addition since relu fdis s1 s2 thrd1 relu fdis b1 b2 thrd2 whene1ande2are correlated act similarly activates the transformation results by relufunction and then aggregates the two typesofalertrepresentationsbyelement wiseproduct.afterfurthertransformationanddimensionreduction actfinallypresents the correlation degree between eiandej pi j pi j pi j latticetop.
pi j is a two dimensional vector in which pi j 1is the probability that the two alerts are correlated and pi j 2is the probability that the twoalertsareuncorrelated.thesumof pi j 1and pi j 2is1 whichis ensured by the softmax function.
to train act in the training stage for a history alert ei i n previous alerts during can be divided into two authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
online summarizing alerts through semantic and behavior information icse may pittsburgh pa usa ...... ...... linearlinear linearlinearrelu relutanhlinearlinear softmax inputlinear transformationfeature aggregationdimension reductionoutputsemantic representations behavior representations figure the structure of act.
groups correlated alerts to ei denoted as ri ri ci and remaining uncorrelated alerts denoted as hi hi oi .
then the real relationship between two alerts eiandej j n is formallydefinedas pi j latticetopifeiandejarecorrelated otherwise pi j latticetop.finally weadoptequation whichmeasuresthe differencebetweenthedeterminationofactandthegroundtruth as the loss function of act.
lact nn summationdisplay.
i bracketleftbig1 ci summationdisplay.
ej ri pi j pi j oi summationdisplay.
ej hi pi j pi j bracketrightbig online summarizing inthetrainingstage allmodelsforalertrepresentationandalert correlation are well trained offline.
therefore in online summarizing stage for the newly reported alert ei and the previously reported alert ej in the time window we can easily represent their semantic information and behavior information by asr and abr respectively.
then according to act we can obtain the correlation degree between the two alerts straightforwardly which is defined as pi j pi j pi j .
specifically pi j 1indicates the probability that the alerts are correlated and pi j 2indicates the probability that the alerts are uncorrelated.
if pi j pi j eiand ejmay belong to the same system failure.
therefore we use the equation tofindthealertmostcorrelatedto eiduring .
qi argmax j i pi j pi j pi j ti tj w then asshowninfigure6 if qiexists weadd eiintotheincidentof eqi.otherwise weformanewincidentfor ei.suchstrategyavoids modifying previous alerts and ensures that each alert is processed only once in the online summarizing stage.newly reported alert add to incident 2incident incident time figure the process of alert summarizing.
evaluation to evaluate the effectiveness of our approaches we exploit realworld datasets from two large commercial banks to address the following research questions rq1 how does oas perform in summarizing alerts?
rq2 howdoesthesamplegranularity inabraffectthe summarizing performance?
rq3 how does the sample length in abr affect the summarizing performance?
rq4 how doesthe timewindow winonline summarizing affect the summarizing performance?
.
datasets we conduct experiments on real world alerts from two large commercial banks a and b. as shown in table alerts of bank aand bank b have different characteristics.
the definition of thealert in bank a is not strictly standardized thus there are thousandsofalerttypesinitsdataset.inbankb thedefinitionofthe alert is quite rigorous thus bank b has a much smaller numberof alert types than bank a. due to the information privacy wecan only share the alert dataset of bank b which is available at in which all sensitive information is anonymized.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jia chen peng wang and wei wang table details of experimental datasets datasets time span alerts alert types bank a bank b .
baselines as shown in table we compare our approaches with seven approaches seqkrimp gokrimp csc swift jaccard word2vec and lda.
seqkrimp gokrimp csc and swift are all frequent patternminingapproaches.theygenericallysummarizeanevent sequencebyminingfrequentpatternsthatminimizethedescription length of the event sequence .
seqkrimp gokrimp andcsc areofflineapproaches whileswift isanonline approach.asfrequentpatterns revealco occurrencerelations between alerts we consider csc seqkrimp gokrimp swift as a type of approaches that summarize alerts by behavior information.
table information of experimental approaches approachsemantic informationbehavior informationonline seqkrimp gokrimp csc swift jaccard lda word2vec asr abr oas sincejaccard word2vec andlda arewidely used to measure the semantic relevance of alerts we thus compareourapproacheswithsuchthreeapproaches.inaddition we also individually evaluate the ability of asr and abr respectively.
specifically tosummarizealertsonlinebyasr weadopttheonline summarizingstrategyinsection7.forthenewlygeneratedalert ei insteadofact wefinditsmostrelevantalertduring bythecosinesimilaritybetweensemanticrepresentations.then if the maximum cosine similarity is larger than a fixed threshold we then add eiinto the incident of the most relevant alert.
otherwise we form a new incident for ei.
the same is true for abr.
.
setup we implement asr abr act oas jaccard lda and word2vec with python .
and pytorch .
.
.
for lda and word2vec we use a popular open source nlp toolkit gensim .
as for seqkrimp gokrimp csc andswift weuseajava basedopensource toolkit .
all experiments are conducted on a .20ghz intel i7 7700k pc with gb memory running ubuntu.
the source code of our approaches is available at zenodo.
.inlda thenumberoftopicsissetto9.forthecbowmodelin asr and word2vec the size of the word embedding is and the epochissetto100.forabr thesizeofthebehaviorrepresentation is the sample granularity for the occurrence series i ss e t to minute the sample length for the occurrence series i ss e t to hours for bank a and hours for bank b and the epochis set to .
for act in linear transformation the first layer has50 neurons and the second layer has neurons.
in dimension reduction thefirstlayerhas20neurons andthesecondlayerhas2fixedneurons.theepochofactissetto60.thewindowsize w in onlinesummarizing issetto5minutes.forapproachesthatrequire training table demonstrates their time cost in the training stage.
although our approaches require the longest training time they all take less than minutes to finish training which is actually acceptable since the training stage is conducted offline.
table training time of experimental approaches banktraining time s asr abr act word2vec lda bank a .
.
.
.
.
bank b .
.
.
.
.
thresholdsforexperimentalapproachesarealladjustedtoachieve the maximum valid compression ratio.
for each dataset according tothetimestamp wetakethefirst80 asthetrainingdata andthe last as the testing data.
.
metrics forasystemfailure ifanapproachonlygroupsapartofitstrig gered alerts into an incident we do not consider the incident to be wrong since the incident still groups correlated alerts correctly.
only when an incident contains an uncorrelated alert we consider the incident tobe wrong.
after correctness verification incidents canbedividedintothreegroups correctincidents wrongincidents and isolated incidents.
an isolated incident contains only one alert andhasnocontributiontoalertsummarizing thusthereisnoneed to judge its correctness.
weusetheincidentaccuracy acr thevalidcompressionratio vcr andthetimecost tc insummarizingstagetoevaluatethe performance of experimental approaches.
the incident accuracy is definedas acr nc nc nw where ncisthenumberofcorrect incidentsand nwisthenumberofwrongincidents.theincident accuracy represents the proportion of correct incidents in nonisolated incidents.
the valid compression ratio is defined as vcr nc nw ni n where nwandnirespectively indicate the number of alerts in wrong incidents and in isolated incidents.
the valid compression ratio represents the true summarizing ability of the approach and it ignores the contribution of wrong incidents andisolatedincidents.thehigherthesummarizingabilityofthe approach thehigherthevalidcompressionrate.moreover foreach approach we record its time cost tc in summarizing stage to evaluate its efficiency.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
online summarizing alerts through semantic and behavior information icse may pittsburgh pa usa a incident accuracy acr .
b valid compression ratio vcr c summarizing time cost tc figure experimental results of summarizing performance.
a incident accuracy acr b valid compression ratio vcr c summarizing time cost tc figure experimental results of varying sample granularity in abr.
a incident accuracy acr b valid compression ratio vcr c summarizing time cost tc figure experimental results of varying sample length in abr.
a incident accuracy acr b valid compression ratio vcr c summarizing time cost tc figure experimental results of varying time window win online summarizing.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jia chen peng wang and wei wang .
evaluation results to answer the proposed research questions we evaluate our approachesfromfouraspects thesummarizingperformanceofour approaches compared with the state of arts the influence of the sample granularity in abr the influence of the sample length in abr and the influence of the time window win online summarizing.
.
.
rq1 summarizing performance.
inthefirstexperiment we compare the performance of approaches for each dataset.
figure showstheresult.fromfigure7 a andfigure7 b wecanfindthat in terms of the semantic information asr has higher acrand vcrthan jaccard word2vec and lda in terms of the behavior information abr has higher acrandvcrthan csc gokrimp seqkrimp andswift.furthermore oashasthebestperformance among experimental approaches.
this is because asr integrates the contextual information of wordsinanalertaccordingtotheirsemanticcontributions.however jaccardonlyconsidersthenumberofthesamewordsbetween alerts ignoring the common semantics between different words word2vec equally treats thewords in an alert neglectingvarying contributionsofwordstotheoverallsemantics andldadistillsthe generaltopicofanalert failingtocapturethedistinctivesemanticsforalertsofthesametopic.moreover abrminesthecommonality betweenalertoccurrenceseries whileseqkrimp gokrimp csc andswifttryto findnaivefrequentpatternsof alerts.
nevertheless it is rare that the exact same failure recurs in a short period of time thus correlated alerts may not have frequent co occurrences.
since oas further has a better performance than asr and abr the experiment demonstrates that both asr and abr have their owncontributionstoalertsummarizing andoascaneffectively aggregatethesemanticinformationandbehaviorinformationby act.inaddition inbothdatasets asrcontributesthemosttoalert summarizing.
as show in figure c to capture the deep semantic informationandbehaviorinformationofthealert asr abrand oas have higher tcin summarizing stage than other approaches.
however asr abr and oas can still process the alert withinacceptable time.
in case of oas which has the maximum tcfor each dataset its tcfor bank a is 26s which corresponds to more than alerts per second and its tcfor bank b is .73s which corresponds to more than alerts per second.
.
.
rq2 varying sample granularity in abr.inthisexperiment we evaluate the influence of the sample granularity for the occurrence series in abr.
we vary from to minutes.
for each we train a new abr model and evaluate its performance by the dataset of bank b. although there are some fluctuations infigure8 a andfigure8 b whichrevealsthattherelationship between andsummarizingperformanceisnotstronglylinear a smaller stilltendstogetbettersummarizingperformance.because whenthesamplelength isunchanged asmaller cangeneratea longeroccurrenceseries whichisabletoretainmoredetailedalertbehavior information.
as shown in figure c since a larger can generate a shorter alert occurrence series abr is more efficient with a larger .
however even with the smallest minute abr still can process alerts in about minutes more than810 alerts per second .
thus in conditions permit we recommend choosing the smallest possible .
.
.
rq3 varying sample length in abr.as the sample length in abr determines the time range of the alert occurrence series weevaluateitsinfluence byvarying from1 to24 hours.similar to the above for each we train a new abr model by the dataset of bank b. from figure a and figure b we can find that when the sample granularity is unchanged as increases acrand vcralso increase at first and then they both gradually stabilize.
a larger results in a longer time range of the alert occurrence series whichcontainsricherbehaviorinformation.however when reachesacertainthreshold thetimerangeofthealertoccurrence series can already reveal the complete behavior information of the alert.
more specifically in figure a and figure b when hours vcrstabilizes at about while acris greater than .
moreover as shown in figure c tcof abr in summarizing stage has a linear relationship with .
when hours tcis about2minutes morethan809alertspersecond .therefore we recommend choosing a small that achieves a stable summarizing performance.
.
.
rq4 varying time window win online summarizing.
sincethe timewindow w inonlinesummarizingcontrolsthemaximumtime span between two correlated alerts we thus evaluate its influence onasr abr andoasbyvarying wfrom1to60minutes.same as above we adopt the dataset of bank b as the experimental data.
asshowninfigure10 a andfigure10 b oasalwayshasabetter performance than asr and abr proving that act can effectively integrate asr and abr.
for asr as wincreases acrdecreases at first and then slowly increase until it stabilizes.
such phenomenon indicates a trade off between the number of alert correlations inresult incidents and the accuracy of result incidents.
a small w can find a small number of alert correlations with high acrwhile a largewcan find a large number of alert correlations with low acr.nevertheless fordifferent w bothabrandoashavetheir acrstable above .
because abr concentrates on the robust historicalbehaviorinformationofalerts andoasintegratesthe strengths of asr and abr.
itshouldbenotedthatweuseafive minute wfortheexperiment ofsummarizing performanceinsection .
.
which seemsnotto bethebestchoiceinfigure10 b .thisisduetothatduringthecommunicationwithfront linemaintenanceengineers theypropose thatalthoughasmall wcanleadtoahigh acr italsosplitsafailure intomultiplefragmentedincidents andalarge wispronetomerge independentfailuresofthesametypeintooneincident.bothcases aredetrimentaltothefailureanalysisworkofmaintenanceengineers.
according to the experience of maintenance engineers they presentthat5minutesisusuallythemaximumintervalbetween twocorrelatedalertsfortheirbankservicesystems.inaddition for asr abr andoas thereisalinearrelationshipbetween wand tc.thus tochoosethethetimewindow w werecommendthat bothexperimentalresultsandthepracticalmaintenanceexperience should be taken into consideration.
.
threats to validity we identify following threats to validity in our study.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
online summarizing alerts through semantic and behavior information icse may pittsburgh pa usa noises in labeling we obtain alert correlations from history failure reports written by domain experts.
a failure report records therootcauseandtheimpactofafailure aswellascorrelatedalerts.
sincecorrelatedalertsinafailurereportaremanuallylabeledby experts mislabeling is hard to avoid during the manual process.
however asourexpertsareallfront linemaintenanceengineers with rich domain knowledge we are confident that the amount of noises in labeling is small if it exists .
generalizability in our experiments we use alerts from systems of two large commercial banks a and b. the performance of our approaches depends on the number of alerts and the quality of alert correlation data failure reports .
in our study bank a and bank b have accumulated many historical alerts and their engineersarerequiredtowritefailurereports whichweusetolabelthe alert correlation.
similarly in most commercial companies both historical alerts and failure reports are maintained for a long time.
in addition bank a and bank b are two very large scale banks providingserviceformorethanabillionusersfromhundredsofcountries.
thus we believe our experimental results can demon strate the value of our proposed approaches and our approaches can be generalized to alerts of other companies.
measurements to demonstrate the summarizing performance of our approaches we use acr accuracy and vcr valid compression ratio as measurements which are defined in section .
.
although f measure is a widely used measurement it is unsuitable for our study.
because the correctness verification in f measure is dichotomous.
however in alert summarizing if an incident notisolated contains no uncorrelated alerts then even if it does notcontain all alerts of its corresponding failure it is still correct inpractical production.
therefore after a discussion with domain experts we propose acrandvcrto measure the effectiveness of our approaches.
acrmeasures the proportion of correct incidents and it ignores the impact of isolated incidents that only contain onealert.
vcrmeasurestheabilityofminedincidentstosummarizealerts anditignoresthe contributionofwrongincidentsand isolated incidents to summarizing.
lessons learned in our study after we cooperated with some commercial companies we found that the alert management system of a large online servicesystemneedsatoplayerorglobaldesign.first thetoplayerdesignisusefultocombinealertsfromvarioustool likezabbix prometheus andetc.second toplayerdesignishelpfultoavoid themonitoringblindspot.wecannotfindtherootcauseifitisnot monitored.
moreover we found that many large commercial companieshaveaccumulatedalargenumberoffailurereports orworkorders .inourstudy weusetheknowledgeinthesefailurereportstosummarizealerts.however wesuggestthatthesefailurereports can not only be used to correlate alerts but also be considered as a knowledgebase.thesefailurereportscontainvaluableexpertexperience such as the root cause of the failure the alert correlation and the troubleshooting process.
therefore these failure reports should have a more important role to be explored.
conclusion inthispaper weproposeaframeworkoastoefficientlysummarize alertsonline.inoas torepresentthealertsemanticinformation wepresentasr whichaggregatesthecontextualinformationof alert words according to their semantic contributions.
to representthealertbehaviorinformation wepresentasr whichcapturesthe commonalitybetweentheoccurrenceseriesofalerts.inaddition wepresentanovelmodel act tocombinethesemanticandbehavior information of the alert and summarize the newly reported alert online by a time window.
we conduct extensive experiments onrealdatasetsfromtwolargecommercialbanks andtheresult demonstratesthatourapproachesoutperformthestateoftheart.
infuture weplantoprovidetheabilityforoastosuggesttheroot cause of the system failure based on the mined alert information.