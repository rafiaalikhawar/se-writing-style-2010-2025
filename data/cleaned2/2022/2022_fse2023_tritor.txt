tritor detecting semantic code clones by building social network based triads model deqing zou huazhong university of science and technology china deqingzou hust.edu.cnsiyue feng huazhong university of science and technology china fengsiyue hust.edu.cnyueming wu nanyang technological university singapore wuyueming21 gmail.com wenqi suo huazhong university of science and technology china suowenqi hust.edu.cnhai jin huazhong university of science and technology china hjin hust.edu.cn abstract code clone detection refers to finding the functional similarities between two code fragments which is becoming increasingly important with the evolution of software engineering.
numbers of code clone detection methods have been proposed including treebased methods that are capable of detecting semantic code clones.
however since tree structure is complex these methods are difficult to apply to large scale clone detection.
in this paper we propose a scalable semantic code clone detector based on semantically enhanced abstract syntax tree.
specifically we add the control flow and data flow details into the original tree and regard the enhanced tree as a social network.
then we build a social network based triads model to collect the similarity features between the two methods by analyzing different types of triads within the network.
after obtaining all features we use them to train a machine learning based code clone detector i.e.
tritor .
our comparative experimental results show that tritor is superior to sourcerercc rtvnn deckard astnn tbcnn cdlh and scdetector are equally good with deepsim and fcca .
as for scalability tritor is about times faster than another current state of the art tree based code clone detector astnn .
ccs concepts software and its engineering software maintenance tools .
keywords semantic clones abstract syntax tree social network triads hubei key laboratory of distributed system security hubei engineering research center on big data security national engineering research center for big data technology and system services computing technology and system lab cluster and grid computing lab school of cyber science and engineering hust wuhan china yueming wu is the corresponding author school of computer science and technology hust wuhan china permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
reference format deqing zou siyue feng yueming wu wenqi suo and hai jin.
.
tritor detecting semantic code clones by building social network based triads model.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
introduction as the field of software engineering is constantly evolving the demand for software is increasing.
as a result many software developers choose to build or maintain software code by code cloning to save time and effort.
in reality code clones are divided into syntactic and semantic clones.
syntactic clones are usually found when copying and pasting code and are divided into three types in descending order of similarity namely type textual similarity type lexical similarity and type syntactic similarity .
semantic clones are usually introduced when using different code syntax to implement a same functionality which is type semantically similarity .
although code cloning facilitates software development it also increases maintenance costs and even causes the propagation of vulnerabilities which can have a negative impact on software security .
therefore code clone detection is more and more important in the field of software engineering.
a number of code clone detection techniques have been proposed.
for example the token based detection technique ccfinder performs lexical analysis of the code to extract the token sequence which is then converted into a rule form to detect type and type clones.
token based approaches can also detect a fraction of type clones such as sourcerercc .
it detects type clones by calculating the overlapping similarity between the tokens of two methods.
however as only the program syntax is considered these token based methods cannot detect semantic clones.
to solve this problem researchers intend to capture semantic information by extracting intermediate representations of programs thus equipping these methods with the ability to detect semantic clones.
graph based approaches extract graph structures e.g.
control flow graph containing semantic details of programs and then use graph analysis to implement code clone detection.
however graph based approaches usually have a high time overhead and thus are not scalable to large datasets.
this is slightly mitigated by tree based methods which detectesec fse december san francisco ca usa deqing zou siyue feng yueming wu wenqi suo and hai jin semantic clones by obtaining a tree representation of the program and using tree matching.
however the problem of the lack of high scalability has not been completely solved because although the tree analysis algorithm is lighter than the graph comparison algorithm the tree structure is still complex .
for example all the nodes and the child edges in figure are the original abstract syntax tree ast generated for the code in figure .
we can see from the figure that a simple function with only lines generates a complex subtree of nodes not to mention more complex programs.
as a result the tree analysis also incurs a significant overhead and is difficult to be applied to large scale code clone analysis.
in this paper we implement a novel system for scalable semantic code clone detection.
specifically we address two main challenges challenge ast has complex tree structure which results in a high time overhead if only a simple tree matching algorithm is used to measure similarity.
then how to design a lightweight model that can process the complex tree in a succinct way?
challenge ast only contains the syntactic features of the code and lacks the semantic information to handle semantic code clones.
then how to design an effective model that can handle semantic code clones?
to tackle the first challenge we build a novel triads model to represent the tree details of a complex ast.
specifically we first add the control flow and data flow details of codes into the original ast to enrich the code semantics.
after obtaining the semantically enhanced ast se ast we treat it as a social network and build a network based triads model to process the tree structures.
a type of triads describes a type of relationship among three nodes within a network and it can well represent the nature of node s relationships.
in our approach we extract types of triads and leverage them to complete the model building.
by this we can achieve scalable tree analysis while maintaining the program semantics.
to solve the second challenge we compute the similarity scores of each type of triads and use them to train a code clone detector.
specifically we first use the built triads model to divide all triads into different groups according to their corresponding node types.
after completing the triads grouping we then extract the similarity of all groups between two methods and leverage them to construct feature vectors.
these vectors will be used to train a machine learning classifier for code clone detection.
by this we can achieve effective semantic code clone analysis.
we implement a prototype system namely tritor and conduct comparative experiments with other nine state of the art code clone detection systems on two widely used datasets google code jam gcj and bigclonebench bcb .
the nine code clone detection systems include two token based methods i.e.
sourcerercc and rtvnn four tree based methods i.e.
deckard astnn tbcnn and cdlh and three graphbased methods i.e.
scdetector deepsim and fcca .
experimental results show that our system not only has good detection performance but also has ideal scalability.
although it takes more time than the token based approach i.e.
sourcerercc it is much faster than other tree based and graph based techniques.
for example compared to another recent state of the art tree based code clone detector i.e.
astnn tritor only requires secondsto accomplish the analysis on one million code pairs while astnn consumes about seconds.
overall our contributions to this paper are as follows we extract the semantically enhanced ast to maintain the program details and build a novel social network based triads model to represent the tree details.
we implement a prototype system namely tritor by using the built model to construct feature vectors and train a semantic code clone detector.
we evaluate tritor with other nine tools on the gcj and bcb datasets.
the experimental results show that tritor has great detection performance and strong scalability on semantic code clone analysis.
definitions and preliminary study .
definitions we first give some formal definitions of the terms we used in the paper.
.
.
clone types.
code cloning can be classified into four types according to the degree of similarity.
in our paper we use the following definitions of code cloning types type textual similarity identical code fragments except for different white space layouts and comments.
type lexical similarity identical code fragments except for differences in identifier names and lexical values in addition to the differences in type clones.
type syntactic similarity syntactically similar code snippets that differ at the statement level.
in addition to type and type clone differences the fragments have statements added modified and or removed with respect to each other.
type semantically similarity syntactically dissimilar code fragments that implement the same functionality.
.
.
triads.
in the field of social networks triad is a census algorithm for networks and represents the relationships between three nodes in the absence of cyclic relationships which can well represent the properties of the relationship between nodes .
therefore in our paper triad means triples of three nodes.
as illustrated in figure according to the relationship between the three nodes triads are divided into categories.
021d 021u 021c 111d 111u 030t 030c 120d 120u 120c 021d 021u 021c 111d 111u 030t 030c11 120d13 120u14 120c figure categories of triads in a social network .
.
jaccard similarity.
the jaccard similarity coefficient also known as the jaccard index is used to compare the similarity between finite sample sets.
given two sets aandb the jaccard index is defined as the ratio of the size of the intersection of aandbto the size of the union set.
it is calculated as j a b a b a b a b a b a b tritor detecting semantic code clones by building social network based triads model esec fse december san francisco ca usa .
preliminary study triads are widely used in the analysis of social networks and have a wide range of applications in fields like network structure analysis population census and social systems analysis .
for code clone detection ast is a type of intermediate representation of code and its structure can reflect the syntactic information of the code well.
since ast extraction does not require compilation it is more lightweight and often used in code clone detection compared to program dependency graph pdg and control flow graph cfg .
methods that implement different functionalities have different ast structures while methods with the same functionalities have similar ast structures.
however no researchers have attempted to apply triads to the code clone detection field to analyse the structure of ast.
therefore we do not know whether triads are suitable for code clone detection or not.
to answer the question we conduct a preliminary study to figure out whether triads can reflect the structural information of ast resulting in a significant difference between clone pairs and non clone pairs.
.
.
.
.
.
.
clonenonclone clonenonclone clonenonclone 021d 021c all0.
.
.
.
.
.
.
.
.60jaccardsimilarymean figure jaccard similarity of clone pairs and non clone pairs specifically we perform experiments on clone pairs and non clone pairs on the gcj dataset.
at first we conduct static analysis to obtain the asts of all methods.
the nodes in the ast are regarded as nodes of the social network and the relationship between the three connected nodes is extracted to obtain triads.
there are only two types of relationships between three nodes in ast since ast is a tree structure.
one is that one node points to the other two nodes i.e.
021d in figure and the other is that one node points to the second node which in turn points to the third node i.e.
021c in figure .
for a code pair we compute the jaccard similarity between the triads of two methods.
first we extract all the triads in the two methods separately and compute the concatenation and intersection of the two sets.
the set consisting of triads shared by two methods is considered to be the intersection and the set consisting of all triads occurring in both methods is considered to be the concatenation.
then we calculate the value of the intersection divided by the concatenation as the result of computing jaccard similarity.
after obtaining all similarities we apply statistical analysis to study whether the similarity is higher for clone pairs and lower for non clone pairs.
in detail we conduct experiments on similarity differences between clone and non clone pairs in three cases 021d 021c and all of these two types.
through the results in figure we observe three findings first the similarity between clone and non clone pairs has obvious differences which indicates that triads can accurately reflect the structural information of ast making higher similarities of clone pairs and lower similarities of non clone pairs.
second the average similarity of both clone and non clone pairs is not high neither exceeding .
so we cannot directly extract triads and simply calculate the similarity based on the number to perform semantic code clone detection.
third the discrepancy of the similarities between clone and non clone pairs obtained by different types of triads differs.
according to these findings we know that triads can reflect the differences between clone and non clone code pairs but cannot be directly used to detect semantic code clones.
however different types of triads have different similarities.
if we can learn the differences between various categories of triads and find the most representative triad in detecting semantic clones it will be a great candidate to use triads for semantic clone analysis.
in this paper we propose to use machine learning to learn the differences and design a novel triads based semantic code clone detector.
system in this section we present our proposed system namely tritor .
ast generation and enhancementtriads extraction feature extractionclassification ast generation and enhancementtriads extractionprogram program clone not clone input tritor detecting semantic code clones by building social network based triads model output ast generation and enhancementtriads extraction feature extraction ast generation and enhancementtriads extractionprogram program 2input a social network triads based semantic code clone detector output classification1 clone not clone figure system architecture of tritor .
overview figure shows that tritor consists of ast generation and enhancement triads extraction feature extraction and classification .
ast generation and enhancement the purpose of this phase is to perform static analysis to extract the ast and add the control flow and data flow details to the ast to enrich the semantic information incorporated in the ast.
the input of this phase is a method and the output is a se ast.
triads extraction the purpose of this phase is to partition the se ast into different types of triads and group them according to the node types.
the input is an se ast and the output is the number of various triads in each group.
feature extraction the purpose of this phase is to extract the similarity scores of triads in the same group one by one.
the input of this phase is the triads of two methods and the output is the similarity vector.
classification the purpose of this phase is to determine whether two methods are a clone based on the machine learning model trained in advance.
the input of this phase is a similarity vector of two methods and the output is whether they are a clone pair.
.
ast generation and enhancement in this paper our objective is to detect semantic clones between programs.
therefore we need to extract the semantic information of the program and use it as the basis for judging whether they are clones.
ast is the common intermediate representation that contains syntactic information about the code.
so we perform static analysis on the method to obtain the asts of the methods.
there are different static analysis tools for different programming languagesesec fse december san francisco ca usa deqing zou siyue feng yueming wu wenqi suo and hai jin method declaration if statement binary operation member referencestatement expression assignmentformal parameter basictypelocalvariable declaration variable declaratorbasictype literal member referencemember referenceblock statement assignment member referenceliteralreturn statement member reference member referencenextstmtcondtrue condfalse statement expressionstatement expressionbasictypemodifier private modifier int basictype func identifierint basictype a identifierint basictypenum identifier operator0 decimal integer a identifier num identifiera identifier operator num identifier0 decimal integerchild nexttoken controlflownextuse nextstmt operatornum identifier operator a identifier method declaration if statement binary operation member referencestatement expression assignmentformal parameter basictypelocalvariable declaration variable declaratorbasictype literal member referencemember referenceblock statement assignment member referenceliteralreturn statement member reference member referencenextstmtcondtrue condfalse statement expressionstatement expressionbasictypemodifier private modifier int basictype func identifierint basictype a identifierint basictypenum identifier operator0 decimal integer a identifier num identifier a identifier operator num identifier0 decimal integerchild nexttoken controlflownextuse nextstmt operatornum identifier operatora identifierprivate int func int a int num if a num a else num a return num figure the semantically enhanced ast of the code on the left that can be utilized.
for example if the programming language is java we can use javalang to extract the asts of the methods.
ast is rich in syntactic information but lacks semantic information.
by adding data flow and control flow to the original ast we can enrich the semantics contained in ast .
to this end we adopt the method of flow augmented abstract syntax tree in a recent work to maintain the program semantics.
however we do not add all the edges but make trade offs according to our needs.
for data flow we add nexttoken andnextuse edges in addition to the child edges that are already in the ast.
the nexttoken edge concatenates the terminal nodes that belong to the same statement in token order which reflects the sequence of tokens well.
the nextuse edge connects the node where the variable is located to the next occurrence of that variable which reflects the information of the data flow.
we do not add the parent andnextsib edges because thechild edge is sufficient to represent the relationship between parent and child nodes for our purposes.
moreover the relationship between sibling nodes contained in the nextsib edge does not have great significance for the increase of semantic information.
therefore we do not add these two edges.
basictype modifier private modifierint basictypemethod declaration4 021d basictype modifiermethod declaration 021c modifierprivate modifiermethod declaration basictypeint basictypemethod declarationmodifier private modifierint basictypebasictype private modifierint basictype5 021u modifierprivate modifiermethod declaration basictypeint basictypemethod declarationmodifier private modifierint basictype method declarationmodifier basictype figure categorize the triads of one subtree in figure for control flow we add sequential execution if statements while andforloops.
sequential execution adds edges between the children nodes of a blockstatement pointing from the previous child node to the subsequent child node to indicate the sequential execution of the statement.
the ifedge adds a condtrue edge between the conditional statement and the statement when the condition is true and a condfalse edge between the conditional statement and the statement when the condition is false if there is no else statement itis not added .
both while andforedges add two bidirectional edges between the condition and the body.
figure shows a graphical representation of the se ast corresponding to the code on the left that is generated by javalang .
algorithm triads extraction input graph the se ast to be analysed.
output triadslist all triads included in the se ast.
triadslist foreach node vingraph do v nbrs pred nodes v succ nodes v foreach node uinv nbrs do ifid id then u nbrs pred nodes u succ nodes u neighbors v nbrs u nbrs foreach node winneighbors do ifid id or id id id and v not inpred nodes w and v not in succ nodes w then add the u v w into thetriadslist end if end for end if end for end for .
triads extraction after semantic enhancement of the ast relationships other than parent child relationships are found between nodes.
in the preliminary study section we mention that only two types of triads could be extracted from the ast 021d and 021c.
however with the enrichment of node relationships in se ast i.e.
the variety of edges increases it is possible that triads types other than 021d and 021c could be presented in the se ast.
in order to determine the types of triads used in the model we calculate the se asts generated by all files in our open source projects where the open source projects come from the top java projects in github in terms of criticality score.
this score can be used to describe the impact and importance of an open source project .
excluding the first three cases where there is no connection between the nodes we find that there are a total of categories of triads i.e.
021d 021u 021c 111d 111u 030t 030c 120d 120u and 120c .
they are marked in red in figure .
therefore we use these types in our model.
if we treat the resulting se ast as a network the similarity between two networks can be measured by analyzing the relationships between nodes in the network.tritor detecting semantic code clones by building social network based triads model esec fse december san francisco ca usa therefore compared to the traditional graph matching method to compare the similarity of two graphs we count all the triads appearing in the se ast and classify them.
the extraction of triads from se ast will be divided into three steps first as described in algorithm we traverse each node vin a se ast from top to bottom finding the first level neighbor nodes v nbrs using the edges it connects as indices line in algorithm and then using these nodes in turn as criteria to find the secondlevel neighbor nodes neighbors line in algorithm .
in this way we get all the triads from se ast.
line and line are designed to avoid duplicate searches by a criterion that only nodes with an id greater than the benchmark node can be used as neighboring nodes.
pred nodes and succ nodes are methods to get the predecessor nodes and successor nodes of a node.
for the same tree the triads obtained by different traversal methods are the same so using different traversal methods will not affect triads extraction.
second as similarity can only be calculated between triads of the same category so we count all the triads that appear in each se ast and categorize them into one of the ten categories.
as shown in figure the top left part of the picture is a part of figure .
for this subtree we can get a total of five triads i.e.
the part in the dashed box of figure and we can see that these five triads belong to three categories namely 021d 021u and 021c.
basictype modifier private modifierint basictypemethod declaration4 021d basictype modifiermethod declaration 021c modifierprivate modifiermethod declaration basictypeint basictypemethod declarationmodifier private modifierint basictypebasictype private modifierint basictype5 021u modifierprivate modifiermethod declaration basictypeint basictypemethod declarationmodifier private modifierint basictype3 method declaration3 021c method declarationmethod declarationnode types node types 4modifier modifierbasictype basictypebasictypenode types 3modifier 45groups figure group the triads of type 021c in figure finally different triads in each category may have completely different nodes.
if we calculate the similarity between triads categories directly as we did in our preliminary study it may not give the ideal similarity score.
therefore for each triads they are grouped according to the types of the three nodes in the triads.
as we can see in figure two kinds of nodes appear in the ast one being non leaf nodes and the other being leaf nodes.
the types of non leaf nodes can represent the code syntax of a method while the leaf nodes of an ast are tokens obtained by parsing the source code of a method.
for the non leaf nodes to obtain a determinate result of node types we extract the asts of all methods in our open source projects which consists of more than 300m lines of code to analyze the code syntax types from these trees.
eventually we obtain a total of code syntax types.
for the leaf nodes i.e.
tokens in asts we cannot extract an exact number.
in order for these tokens to be assigned to a fixed group we intend to represent them by their token types.
for example the token int is replaced by its type basictype .
the blue texts in figure are leaf nodes represented by token types.
we still choose the open source projects for the collection of token types as we did for the analysis of non leaf nodes.
after our statistical analysis we find that types appearin most of asts.
in fact the proportion of these types accounts for more than .
of all nodes.
therefore we choose these types as the final token types and add a null type to represent other types.
in final we collect a total of types which consists of code syntax types and token types.
for each triads we group them according to the types of the three nodes in the triads.
for example the three triads of type 021c in figure can belong to three groups according to their node types methoddeclaration modifier and basictype .
for the first triads of 021c in figure since the node types consist of methoddeclaration and modifier it belongs to these two groups respectively.
since there are a total of node types one type of triads will contain at most groups.
after these three steps all triads contained in each se ast will be assigned to specific groups.
021d 021u 120cmethoddeclaration modifierformalparameter referencetype tryresource... ... methoddeclaration modifier tryresource... modifier tryresource......... ... ... ... ... ... ... 021d 021u 120cmethoddeclaration modifierformalparameter referencetype tryresource... ... methoddeclaration modifier tryresource... modifier tryresource......... ... ... ... ... ... ...jaccard similarity .
.
... ... ... ... ... ... ... ... ...method1method2 021d 120cmethoddeclaration modifierformalparameter referencetype tryresource... ... modifier tryresource...... ... ... ... 021d 120cmethoddeclaration modifierformalparameter referencetype tryresource... ... modifier tryresource...... ... ... ...jaccard similarity .
.
... ... ... ... ...method1method2 021d 120cmethoddeclaration formalparameter referencetype... ... modifier ...... ... ... 021d 120cmethoddeclaration formalparameter referencetype... ... modifier ...... ... ...jaccard similarity .
.
... ... ... ...method1method2 md1234567 fp ... ... rt mo ... ... ... 021d 120c md fp ... ... rt ... mo ... ... 021d 120c .
.
... ... ... ...jaccard similarity method method md methoddeclaration fp formalparameter rt referencetype mo modifier figure obtain the similarity vector of two methods .
feature extraction after obtaining the specific grouping information we obtain their similarity vectors by sequentially calculating the jaccard index of the groups corresponding to the two methods.
as shown in figure after the previous steps all triads in the se ast are divided into different categories according to triads types and the triads in each category are divided into different groups according to the types of nodes.
we then calculate the jaccard index between the corresponding groups and each group will output a similarity score.
after collecting all similarity results we concatenate them to construct a feature vector.
after our statistical analysis on our open source projects the number of groups contained in each type of triad can be obtained with 021d containing groups 021u containing groups 021c containing groups 111d containing groups 111u containing groups 030t containing groups 030c containing two groups 120d containing groups 120u containing seven groups and 120c containing seven groups.
as a result the feature vector has a total of dimensions.
.
classification machine learning divides the knowledge structure by simulating the human learning method of the existing content which effectively improves the learning efficiency.
since it can accurately and efficiently predict once trained it has both accuracy and scalability .
in our paper we choose certain widely used algorithms i.e.
k nearest neighbor knn random forest rf decision tree dt adaptiva boosting adaboost and gradient boosting decision tree gdbt to commence our evaluations.
we perform feature extraction on all clone pairs and non clone pairs to obtain similarity vectors.
all the similarity vectors with labels are put into a machine learning model for training and the obtained model is saved.
two methods to be detected are processed in the above three phases and their similarity vector will be fed into the model to obtain an output of zero non clone or one clone .esec fse december san francisco ca usa deqing zou siyue feng yueming wu wenqi suo and hai jin experiments in this section we discuss the following five questions rq1 what is the detection effectiveness of tritor when using different machine learning algorithms?
rq2 can tritor outperform other code clone detectors?
rq3 does semantic enhancement on ast improve clone detection?
rq4 what is the runtime overhead of tritor when detecting clones?
rq5 why is tritor effective in detecting semantic code clones?
.
experimental settings .
.
datasets.
similar to previous work we conduct experiments on two datasets gcj and bcb.
the programs in the gcj dataset are derived from an online programming competition held by google and contain projects from different competition problems which are written by different programmers.
so projects of the same competing problem are almost syntactically different but semantically similar and we treat them as clone pairs.
projects that solve different problems are not similar and we regard them as non clone pairs.
as a result we obtain semantic clone pairs and non clone pairs.
we randomly select pairs from all non clone pairs to balance our dataset.
the second dataset is the popular large code clone benchmark bcb dataset which contains over eight million labeled clone pairs from systems.
the reason why we choose the bcb dataset is that the code granularity of their clone pairs is functionlevel which is in line with the detection granularity of tritor .
moreover the clone pairs in bcb are assigned different clone types to facilitate our observation of the effectiveness in detecting different types of clones.
however due to the unclear boundary between type and type it is further divided into three subclasses by similarity scores measured by line level and token level as follows i strongly type st3 with the similarity between ii moderately type mt3 with the similarity between and iii weakly type type wt3 t4 with the similarity between .
we randomly select clone pairs from the eight million clone pairs since the number of non clone code pairs is .
the clone pairs we select include clone pairs of type t1 clone pairs of type t2 clone pairs of st3 clone pairs of mt3 and clone pairs of wt3 t4.
256919293949596979899f1scoreonbcb parametersrf dt adaboost gdbt 256808284868890929496f1scoreongcj parametersrf dt adaboost gdbt figure the f1 scores by using different depth parameters of different machine learning algorithms .
.
implementations.
we use javalang to obtain ast in the ast generation and enhancement phase as the programming language of our dataset is java.
in the classification phase we use sklearn to implement knn rf dt adaboost and gdbt classification algorithms.
we run all experiments on a server with coresof cpu and a gtx gpu.
for recording the experimental effects we adopt ten fold cross validations for training and validation.
.
.
comparative systems.
in order to make our evaluation more comprehensive we select some representative work from a large number of code clone detection tools to conduct comparative experiments.
specifically we select two token based code clone detectors i.e.
sourcerercc and rtvnn four tree based methods i.e.
deckard astnn tbcnn and cdlh and three graph based methods i.e.
scdetector deepsim and fcca .sourcerercc is a popular token based code clone detector which can scale to big code.
rtvnn is a popular rnn based code clone detector which encodes source code tokens and asts.
deckard is a popular ast based code clone detector which clusters the vectors of ast subtree.
astnn is a popular ast based code clone detector which splits a large tree into certain statement trees and trains an rnn model to detect code clones.
tbcnn is a popular ast based clone detection detector by using a convolutional neural network.
cdlh is a popular ast based clone detection tool with a long short term memory network.
scdetector is a popular graph based code clone detector which extracts the control flow graph of a method and applies centrality analysis to detect code clones.
deepsim is an advanced graph based clone detection tool by using a deep neural network.
fcca is an advanced graph based clone detection tool by using hybrid code representations with high accuracy.
for the parameter settings of these tools we select the parameters reported in their published papers since they can perform best with these parameters.
.
.
metrics.
to measure the detection effectiveness of all detectors we adopt widely used metrics such as precision p recall r andf measure f1 .
these metrics are described on our website .
.
rq1 comparison of different methods to achieve higher precision and recall in detecting semantic clones we measure the classification performance of different machine learning algorithms and select the best one for subsequent experiments.
we choose five commonly used machine learning algorithms i.e.
knn rf dt adaboost and gdbt for training and testing.
they are popular algorithms that are often used in classification problems and can achieve good results in previous work .
for knn there has been a lot of work demonstrating that neighbor parameter selects one and three are the most widely used and can achieve good results .
therefore we first select the parameters that allow other machine learning models to obtain the best results.
the f1 scores achieved by rf dt adaboost and gbdt machine learning algorithms on the bcb and gcj datasets with different depth parameters are presented in figure .
we can see that rf adaboost and gdbt achieve the highest f1 scores with depth parameters of and respectively.
however dt does not have the same parameter value for achieving the highest f1 score on both datasets.
since dt is more stable when the parameter is we choose as the parameter for dt.
therefore the neighbor parameters of knn are selected as one and three because they are the most commonly used.
the depth parameter of rf dt adaboost and gdbt is selected as and respectively as they can achieve the highest f1 scores.
observing the f1 score precision and recall shown in figure we see that the gdbt algorithm has the best results on the bcbtritor detecting semantic code clones by building social network based triads model esec fse december san francisco ca usa f1 precision recall858687888990919293949596979899f1score precision andrecallonbcb f1 precision recall858687888990919293949596979899f1score precision andrecallongcjrf dt knn 1 knn 3 adaboost gdbt figure f1 score precision and recall of tritor using different machine learning classification methods dataset with rf algorithm being the next best.
for example the gdbt algorithm and rf algorithm have an f1 score of .
and .
while the other four scores are .
.
.
and .
on the bcb dataset.
however the detection effectiveness of all models decreases on gcj dataset some algorithms such as dt decrease even more.
this is due to the fact that dt does not handle more complex semantic clone classification very well.
as an improvement to dt rf algorithm is relatively outstanding.
because rf consists of multiple decision trees actually.
a test sample can obtain the most probable classification among the classification results of each decision tree in the random forest.
gdbt has the best results but the time overhead of gdbt is much higher than that of rf for instance .
times higher on bcb.
so we choose the rf algorithm for the subsequent experiments.
summary the difference in f1 scores between gdbt and rf is small but the time overhead of gdbt is much higher than that of rf so we choose the rf algorithm for the subsequent experiments.
.
rq2 overall effectiveness .
.
results on google code jam.
first we conduct experiments on the gcj dataset to evaluate the effectiveness of tritor .
as we mentioned earlier clone pairs on the gcj dataset are naturally semantically similar and almost unlikely to be syntactically similar.
therefore we treat all similar pairs as semantic clones i.e.
type clone and run experiments on these pairs to evaluate the effectiveness of tritor in detecting semantic clones.
table presents the detection results of nine comparative systems and tritor .
table results of clone detection on gcj and bcb datasets group methodgcj bcb r p f1 r p f1 token basedsourcerercc .
.
.
.
.
.
rtvnn .
.
.
.
.
.
graph basedscdetector .
.
.
.
.
.
deepsim .
.
.
.
.
.
fcca .
.
.
.
.
.
tree baseddeckard .
.
.
.
.
.
astnn .
.
.
.
.
.
tbcnn .
.
.
.
.
.
cdlh .
.
.
.
.
.
our tool tritor .
.
.
.
.
.
for token based approaches sourcerercc has both low recall and precision.
this is because sourcerercc is a token based code clone detector which only considers the overlapping similarity of tokens between two methods i.e.
the ratio of the number of identical tokens shared by two methods to the maximum number of tokens of the two methods and lacks the consideration of anysemantic information so it does not perform well on a dataset with all semantic clones like gcj.
the recall of rtvnn is high but the precision is low.
this is because rtvnn computes a simple euclidean distance metric for only the tokens and asts of a code by using recurrent neural networks to measure the similarity of code pairs.
however the distances between most pairs computed by this method do not differ significantly i.e.
only between .
to .
.
changing the threshold can increase the precision but decrease the recall.
therefore rtvnn cannot have a high f1 score.
for tree based approaches compared to other tree based methods the detection results of deckard andcdlh are not satisfactory.
this is because deckard uses vectors to carry syntactic information in the parse tree it finds the vectors nearest neighbors by clustering which requires the feature vectors at the root of the parse tree to be very close.
however most code clone pairs have different parser tree structures leading a poor precision and recall on the gcj dataset.
cdlh learns hash functions structural information and code fragments by using an ast based long short term memory network.
but the representations are all lexical and syntactic leading to low detection performance.
the other two tree based methods astnn andtbcnn have a comparatively good capability of detecting semantic clones.
astnn splits each large ast into lots of small sentence trees and encodes these sentence trees as vectors.
then astnn selectively stores more important node information by using bigru and rvnn encoders so astnn has a high precision.
but the segmentation of the ast may lead to some semantics loss which in turn results in a relatively low recall.
tbcnn has good detection results because it captures the structural features of the ast very well by sliding the convolutional kernels.
however one weakness of the convolutional layer is that it cannot capture long range contextual information.
in this way if the ast is deep or has many nodes the operation of converting the ast into a binary tree exacerbates the problem of a long term dependence on the original semantics of the source code.
for graph based approaches scdetector converts the cfg of the method into semantic tokens with graph details and then feeds these semantic tokens into a siamese network to train a model to detect code clone pairs so scdetector is good at detecting semantic clones.
deepsim uses a deep learning model to learn binary matrix abstracted from the variables basic blocks of cfg and the relationships between them.
as these representations contain code semantics deepsim is proficient at detecting semantic clones.
fcca feeds the comprehensive hybrid code representation into a deep learning model with an attention mechanism.
the combination of structured representations i.e.
tokens and unstructured representations i.e.
ast and cfg enables fcca to detect most semantic code clones with a high degree of precision.
.
.
results on bigclonebench.
in this subsection we analyze the effectiveness of detecting all types of clone pairs on the bcb dataset and make a comparison with our comparative tools.
table presents the detection results.
as can be seen from the performance of the results shown in table tritor outperforms most of the other detectors in precision and f1 score indicating that tritor is also good at detecting code clones on bcb dataset.
different from the results on gcj sourcerercc deckard and rtvnn all have high precision and low recall.esec fse december san francisco ca usa deqing zou siyue feng yueming wu wenqi suo and hai jin this is because these tools can only detect code clones that are textually or syntactically similar.
thus they are only able to detect syntactically similar clone pairs i.e.
t1 and t2 in bcb but not semantic similarity.
moreover we also observe that the detection results on bcb are almost always better than those on gcj.
this is because the clone pairs in the bcb dataset are constructed by experts deliberately.
apart from minor differences the code structures are very similar and can be easily detected.
on the other hand the clone pairs in the gcj dataset are answers given by different programmers to the same competition question and have a completely different code structure which makes them difficult to detect.
table f1 for each clone type on bcb group method t1 t2 st3 mt3 t4 token basedsourcerercc .
.
.
.
.
rtvnn .
.
.
.
.
graph basedscdetector .
.
.
.
.
deepsim .
.
.
.
.
fcca .
.
.
.
.
tree baseddeckard .
.
.
.
.
astnn .
.
.
.
.
tbcnn .
.
.
.
.
cdlh .
.
.
.
.
our tool tritor .
.
.
.
.
next we analyze how the clone detector performs in detecting each of the five types of clones and compare it to the advanced code clone detection technique in terms of f1 scores.
we select the number of clone pairs and non clone pairs for each type as described in the experimental dataset in subsection .
.
table shows the f1 scores for tritor and nine comparative systems for detecting five types of code clones.
we can see that tritor is superior to other clone detectors in detecting each type of code clones.
particularly when detecting wt3 t4 the f1 scores of sourcerercc rtvnn deckard tbcnn and cdlh are and respectively while tritor can reach an f1 score of .
this demonstrates that tritor can detect semantic clones comprehensively and precisely.
scdetector deepsim fcca and astnn also perform well in detecting wt3 t4 clones.
however they all require gpus to complete the complex deep neural network training.
for tritor we only need cpu to train simple machine learning models for classification which means that tritor requires less computational resources than scdetector deepsim fcca and astnn .
the reason for tritor s good ability to detect semantic clones lies in three aspects.
first the semantically enhanced ast contains more semantic information thus enhancing the tritor s ability to detect semantic clones.
second we regard the enhanced ast as a social network and measure the similarity between two methods by analyzing the relationship among three nodes in the network avoiding the high overheads associated with tree matching while preserving the details of the tree structure.
thirdly instead of detecting code clones directly by threshold after obtaining similarity our method puts the similarity vector into a machine learning classifier for clone detection.
the use of machine learning algorithms allows our approach to be highly accurate and scalable.
summary compared to most code clone detectors tritor performs well in detecting code clones on both gcj dataset and bcb dataset especially in detecting semantic clones.
moreover tritor only needscpu for classification which means that tritor has a much faster speed than those graph based approaches.
.
rq3 the significance of se ast to check whether the augmented data flow and control flow on ast can contribute to tritor or not we perform an ablation experiment.
in the experiment we perform the same feature extraction operation on both the original ast and the se ast with the added data flow and control flow then they are both fed into the rf machine learning algorithm for training and testing.
we record their respective detection results in table .
table recall precision and f1 of original ast and semantically enhanced ast in detecting clones dataset ast r p f1 gcjse ast .
.
.
original ast .
.
.
bcb allse ast .
.
.
original ast .
.
.
bcb wt3 t4se ast .
.
.
original ast .
.
.
table illustrates the recall precision and f1 scores on the two datasets respectively.
for bcb dataset we not only record the comparative results when analyzing the whole dataset i.e.
bcb all but also collect the results when detecting semantic code clones i.e.
bcb wt3 t4 .
it can be seen that se ast has better results in detecting clones on both bcb and gcj datasets.
for example on the gcj dataset when we use the original ast for clone detection the f1 score is only .
after enhancing the ast the f1 score can increase to .
the main reason for this improvement is that asts contain mainly syntactic information about the program and the added data flow and control flow enrich the semantic information of the ast to a large extent.
since semantic clones are almost syntactically different their asts are likely to be different.
the semantically enhanced ast can contain the same semantic information in the type clones which is more similar.
the second reason is that there are only two kinds of triads 021d and 021c in figure in the original ast while the semantically enhanced ast contains kinds of triads.
the increase in the types of triads also allows the similarity of the two graphs to be measured from more perspectives.
the response in the dimension of the feature is that the original ast obtains an dimensional feature vector while the semantically enhanced ast obtains a dimensional feature vector.
the increase of this dimension can measure similarity from more angles which improves the effect of clone detection to a certain extent.
summary se ast has better results in detecting clones on both bcb and gcj datasets.
the two reasons for this improvement are that the added edges enrich the semantic information of the ast to a large extent and the increase in the types of triads also allows the similarity of the two graphs to be measured from more perspectives.
.
rq4 scalability in this subsection we run all experiments to compare the running overhead of tritor on a server with an cores cpu and a gtx gpu to test its scalability.
similar to previous work we randomly select one million code pairs from the gcj dataset for the experiment.
a total of random selections are made recording the time overhead each time and using the averagetritor detecting semantic code clones by building social network based triads model esec fse december san francisco ca usa as the final time overhead.
the time overhead for each method is presented in table including training time and prediction time.
fortritor the training time consists of the processing time for the preliminary steps and the time to train the model.
table runtime on analyzing one million code pairs group method training prediction token basedsourcerercc 16s rtvnn 206s 35s graph basedscdetector 937s 139s deepsim 545s 34s fcca 769s 91s tree baseddeckard 72s astnn 096s 894s tbcnn 168s 86s cdlh 317s 90s our tool tritor 467s 20s for clone detectors that are not based on deep learning algorithms i.e.
sourcerercc anddeckard their prediction time is zero and the prediction time is the time for all processes to detect clones.
for other seven comparative systems their training phases require gpus as they are deep learning based methods.
however even though they have gpus to accelerate the training phase and the testing phase their time overheads are still higher than that of tritor using only cpus.
such results demonstrate that tritor is more scalable than rtvnn scdetector deepsim fcca astnn tbcnn and cdlh .
for astnn which is also tree based and has good capability for code clone detection it takes a total of seconds seconds for training and seconds for testing to complete the entire training and testing phase.
while tritor consumes only seconds seconds for training and seconds for testing to complete the whole procedure.
overall tritor is about i.e.
.
times faster than astnn .
summary tritor spends more time than sourcerercc because of the consideration of ast construction.
however because of social network based triads model and the use of a machine learning algorithm tritor is more scalable than rtvnn scdetector deepsim fcca astnn tbcnn and cdlh.
.
rq5 interpretability to explore why tritor is effective in detecting semantic clones we extract the importance of each feature of the similarity vector.
due to the interpretability of the rf algorithm we extract the weight of each feature in the vector and sort them according to the weight so that we can clarify which features are more important in detecting semantic code clones.
due to space limitations we only show the top features in the dimensional vector obtained on the gcj dataset in table .
by observing the ranking of feature importance we find two obvious phenomenons the first is that different types of triads have different levels of importance.
according to our observations only type 021c type 021u type 021d type 111u and type 030t appear in the top features in terms of importance and the number of occurrences is uneven.
for example type 6021c appears most frequently ten times followed by type 5021u which appears four times.
this phenomenon suggests that the structure of these five types of triads is more important for preserving program semantics in se ast.
this is because the triads of type 021c and type 021d are typical structures that alreadytable top features of tritor in detecting semantic clones r feature name w r feature name w binaryoperation 6 .
operator 5 .
decimalinteger 6 .
memberreference 4 .
literal 6 .
memberreference 5 .
operator 6 .
blockstatement 9 .
decimalinteger 5 .
binaryoperation 8 .
memberreference 6 .
forcontrol 4 .
7statementexpression 6 .
forstatement 6 .
blockstatement 6 .
forstatement 8 .
basictype 6 .
forcontrol 6 .
binaryoperation 4 .
basictype 5 .
exist in the ast these two structures support the entire framework of the ast and therefore carry a large number of program details contained in the ast.
the triads of type 021u usually contain additional data flow edges.
decimalinteger 5 021u and operator 5021u which occur in table are usually the type of leaf node and contain additional nexttoken edges indicating that the addition of data flow is significant in detecting semantic clones.
the triads of type 111u contain the two bidirectional edges we add between the conditions and the body of while andforloops and the triads of type 030t usually contain the edges we add between the subnodes of a blockstatement node to indicate the sequential execution of the statement.
the high importance of these two types of triads indicates that the addition of edges to these two types of control flow plays an important role in detecting semantic clones.
the second phenomenon is that three node types are more important among the top weighted features with binaryoperation andmemberreference appearing three times each and decimalintegerappearing twice in the top five features.
this suggests that these three node types are particularly important for detecting semantic code clones because they can well reflect the semantic information of the code.
binaryoperation represents a binary operation e.g.
i which is usually found in conditional judgments such as if statements while andforconditional judgment statements.
the functionalities implemented by these three statements are important for the embodiment of semantics in the methods and therefore binaryoperation has a high importance.
memberreference is usually linked to the identifier node type.
it is associated with the use of variables and carries information about the data flow to a large extent.
therefore it plays an important role in detecting code clones.
decimalinteger is a kind of constant.
it is possible to be in the position of the leaf node so it will be related to the data flow.
it may also appear in statements such as assignment statements or conditional judgment statements which are related to control flow.
therefore having both data flow and control flow information is extremely important for detecting semantic clones allowing decimalinteger to appear twice in the top five ranking of importance.
to give a more visual representation of the effectiveness of these features we reorder the similarity vectors according to the importance of the features from highest to lowest.
then we sequentially take the top n n from to features and record the f1 scores for vectors of different lengths in figure .
it can be seen that when only one feature of highest importance is used for classification the f1 score can reach .
.
as the number of features continues to increase the detection effect is getting better and better and when the number of features reaches around less than theesec fse december san francisco ca usa deqing zou siyue feng yueming wu wenqi suo and hai jin .
.
.
.
.
.
.
.
.
.93f1score thenumberofselectedfeatures figure f1 scores of tritor when selecting different numbers of features f1 score can already be maintained at a relatively high level.
this phenomenon indicates that the first features can well meet the needs of clone detection.
in the future we plan to apply different feature selection algorithms to select the most important features to improve scalability without compromising accuracy.
similar to the distribution of the top weighted features we find that the distribution of the top weighted features is also consistent with the two phenomena described above.
first the importance of triads types is also in accordance with that in the top in terms of weight.
type 021c and type 021d appear most frequently in the top weighted features with occurrences.
type 021u type 111u and type 030t appear and times respectively which is relatively balanced.
moreover we also find type 120d which does not appear in the top weighted features appearing four times among the top weighted features.
similar to type 111u the structure of type 120d comes from the addition of two bidirectional edges between the condition and the body of while andforloops.
the reason that type 120d is not as important as type 111u is that the structure of type 12120d only includes the parent node that points to both the condition node and the body node but not the subsequent nodes of them.
as a result the semantic information in the subsequent nodes is not included in the type 120d so the type 120d contains relatively little semantic information and is less important.
second the importance of node type is also consistent with the top weighted features.
binaryoperation andmemberreference continue to be of high importance with five occurrences respectively.
besides them forstatement andblockstatement also appear five times respectively.
these two node types also appear quite frequently in the top weighted features.
this is because forstatement embodies control flow information and the nodes and edges it connects to reflect semantic information explicitly.
blockstatement adds sequential execution edges between its child nodes also reflecting control flow information and enhancing semantic entailment.
in contrast to the fact that decimalinteger appears twice in the top five features decimalinteger appears only three times in the top weighted features not continuing its previous importance.
we suspect that this is because decimalinteger is usually a leaf node and leaf nodes are the edges of the tree which are inherently limited in frequency of occurrence.
as a result decimalinteger does not appear frequently in the top weighted features.summary according to the features importance the top important features can well meet the needs of clone detection.
some specific types of triads and nodes have a higher degree of importance.
this phenomenon applies commonly to features in the top in importance as well as to features in the top in importance.
discussions .
threats to validity the first threat comes from the dataset.
the code pairs in the bcb dataset are constructed by experts deliberately.
apart from minor differences the code structures are very similar and can be easily detected.
it would be biased if we only use the results on the bcb dataset to represent the effectiveness of the detection of the whole open source project.
to alleviate the impact we add experiments on the gcj dataset which contains projects from different competition problems that are written by different programmers.
the second threat comes from the token type.
a total of token types were chosen to allow tokens to be grouped into fixed groups.
if the number of token types parsed by javalang is not clear the selection of these types may be variable and lead to inaccurate groupings.
to alleviate the impact we analyze all the token types in the bcb dataset and the gcj dataset to select the token types that occur frequently and add a null type to represent the remaining types that occur rarely.
the third threat comes from the time overheads.
when calculating the time overhead of tritor we cannot obtain absolutely accurate data due to the different machine statuses such as cpu usage.
to alleviate the impact of this threat we evaluate our tool ten times and report the average runtime overhead in the paper.
the fourth threat comes from the interpretability.
all analyses in rq5 are run on the gcj dataset and to alleviate the impact we add experiments on the bcb dataset.
the results show that the distribution of both triads types and node types in the top important features are generally consistent with the results of the experiments on gcj.
only some minor deviations are due to differences in code between datasets.
the detailed data comparison has been placed on our website for page limitation reasons.
the fifth threat comes from the ratios of test sets.
the project codes to be detected in real world do not have a balanced test set i.e.
equal number of cloned pairs and non cloned pairs .
biases may exist by using different proportions of the test set.
to alleviate the impact of this threat we perform experiments on seven test sets with different ratios of clone and non clone pairs to investigate the sensitivity of tritor .
the results show that as the proportion of non clone pairs increases the precision and f1 scores become progressively lower recall remains a relatively stable score.
but even so when the ratio of clone to non clone pairs is tritor is still able to achieve a high f1 score of .
with only fluctuation demonstrating that tritor still has stable performance against variations in the ratio of the test set.
due to space constraints the results of the experiment are not presented in the paper and can be found on our website .
.
limitation and future work in our paper we mainly focus on code clone detection in the java language.
however with a little modification our method can be extended to other programming languages.
for example in the ast extraction phase we can use pycparser or joern totritor detecting semantic code clones by building social network based triads model esec fse december san francisco ca usa extract ast for c source code.
we can count the types of nodes and triads complete the extraction of triads and then extract similarity features to detect code clones in c source code.
in the future work our method will be extended to c code to detect code clones.
in this paper we use jaccard similarity to obtain the feature vectors of the two methods and use the random forest algorithm to train the classifier.
in our future work we will try other similarity calculation methods and other machine learning algorithms to achieve better detection results.
for the comparison system since many of the advanced tools are not open source we only select nine open source tools for comparison.
in the future work we will select more tools for more intensive comparison.
furthermore we can observe from figure that using only the top features in terms of importance is sufficient to achieve a high level of effectiveness in detecting semantic code clones.
the detection is slightly reduced again due to the interference caused by the inclusion of less important features.
therefore in our future work we may use different feature selection techniques to find the most suitable combination of these features to make tritor more scalable and effective for semantic code clone detection.
in addition to ensure the comprehensiveness of our experiments we choose five common machine learning algorithms.
these machine learning models have many parameters leading to a wide range of parameter combinations that are challenging to comprehensively cover in the experiments.
among them the depth parameter has attracted considerable attention.
therefore we focus on assessing the influence of depth parameters on detection performance.
in the future work we plan to conduct testing of other parameters to explore the optimal parameter combinations that yield better results.
in addition it is important to note that the experiments for parameter selection are conducted on the bcb and gcj datasets.
however we are uncertain about the performance of these parameters on other datasets.
in the future work we intend to conduct testing on diverse datasets to select parameter configurations that are more suitable and applicable.
finally tritor may not be superior to some baselines such as tailor and fa ast .
due to the fact that our model lacks some automatic extraction of semantic information compared to graph neural network gnn our results do not surpass them.
however the results of our tool are sufficient to outperform the majority of semantic clone detection methods.
furthermore as our tool is based on machine learning it does not require gpu and supports interpretability.
in contrast neither tailor norfa ast support interpretation and also require a gpu to train and test.
therefore the advantage of tritor is higher scalability and interpretability.
in the future we intend to use ensemble learning approach to improve the effectiveness of our tools striving to achieve higher results.
related work in this section we introduce the related works of code clone detection techniques.
among them text based and token based methods are mostly scalable while tree based and graph based tools are mostly capable of detecting semantic clones.
text based and token based approaches require little runtime overhead and can be extended to large scale clone detection as they do not involve much analysis of the source code.
for text based clone detection methods the coreidea of them is to treat the code as normal text to compare the similarity.
ducasse et al.
use a string matching method to calculate the similarity of code lines .
roy et al.
use a similarity calculation method of the longest common subsequence to detect clones .
the token based approaches perform lexical analysis of source code to obtain tokens and detect clones by finding common tokens.
sourcerercc detects clones by calculating the proportion of overlapping tokens.
the text based and token based methods rarely consider the program semantics and the logic of the code fragment as a result these methods do not have the ability to detect semantic clones.
code clone detectors which can detect semantic clones are essentially tree based and graph based.
these methods detect clones by analysing intermediate representations e.g.
pdgs cfgs and asts with semantic information.
the tree based clone detection techniques perform static analysis of source code to extract parse trees or abstract syntax trees then use tree matching to detect similar tree structures and thereby detect clones.
deckard clusters the similar vectors obtained from ast using locality sensitive hashing to detect clones for any language with grammatical regulations.
cdlh normalizes the ast into a binary tree before encoding the tree representations to vectors using tree lstm .astnn encodes each subtree that is divided according to predefined rules into vectors and integrates these vectors into a final vector using the bidirectional rnn model.
the graph based clone detection techniques represent the programs to graph representations such as cfg and pdg.
most techniques use subgraph matching to detect clones e.g.
and but the subgraph matching usually spends a lot of time to detect so ccsharp reduces the overhead by modifying the graph structure and filtering the feature vectors.
ccgraph uses some numerical features to categorize pdg and compute the similarity of the strings to reduce the runtime overhead.
compared with these methods our method regards the semantically enhanced ast as a social network and extracts similarity features by analyzing the different relationships among three nodes in the network.
the use of triads and the machine learning model makes our code clone detector has both accuracy and scalability.
conclusion in this paper we propose a scalable semantic code clone detector based on semantically enhanced ast.
to avoid the high overhead of tree matching we regard the semantically enhanced ast as a social network and build a novel triads model to represent the tree details.
we design a code clone detector i.e.
tritor with accuracy and scalability by training a machine learning classifier.
we evaluate tritor and other nine state of the art code clone detection systems on gcj and bcb datasets.
the experimental results show that tritor has ideal detection performance and strong scalability.
in analyzing code clones tritor is about times faster than another current state of the art ast based code clone detector astnn .