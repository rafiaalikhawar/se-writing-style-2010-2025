if a human can see it so should your system reliability requirements for machine vision components boyue caroline hu boyue cs.toronto.edu university of toronto toronto ontario canadalina marsso lina.marsso utoronto.ca university of toronto toronto ontario canadakrzysztof czarnecki kczarnec gsd.uwaterloo.ca university of waterloo waterloo ontario canada rick salay rsalay gsd.uwaterloo.ca university of waterloo waterloo ontario canadahuakun shen huakun.shen mail.utoronto.ca university of toronto toronto ontario canadamarsha chechik chechik cs.toronto.edu university of toronto toronto ontario canada abstract machinevisioncomponents mvc arebecomingsafety critical.
assuring their quality including safety is essential for their successfuldeployment.assurancereliesontheavailabilityofprecisely specified and ideally machine verifiable requirements.
mvcs with state of the art performance rely on machine learning ml and training data but largely lack such requirements.
inthispaper weaddresstheneedfordefiningmachine verifiable reliabilityrequirementsformvcsagainsttransformationsthatsimulate the full range of realistic and safety critical changes in the environment.usinghumanperformanceasabaseline wedefinere liabilityrequirementsas ifthechangesinanimagedonotaffectahuman sdecision neithershouldtheyaffectthemvc s. tothisend we provide a class of safety related image transformations reliabilityrequirementclassestospecifycorrectness preservation and prediction preservation for mvcs a method to instantiate machine verifiablerequirementsfromtheserequirementsclasses usinghumanperformanceexperimentdata humanperformance experiment data for image recognition involving eight commonly used transformations from about human participants and a method for automatically checking whether an mvc satisfies our requirements.
further we show that our reliability requirementsarefeasibleandreusablebyevaluatingourmethodson13 state of the art pre trained image classification models.
finally we demonstrate that our approach detects reliability gaps in mvcs that other existing methods are unable to detect.
ccs concepts software and its engineering requirements analysis computing methodologies computer vision .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
software engineering for artificial intelligence requirements engineering software analysis acm reference format boyue caroline hu lina marsso krzysztof czarnecki rick salay huakun shen and marsha chechik.
.
if a human can see it so should your system reliability requirements for machine vision components.
in 44th internationalconferenceonsoftwareengineering icse may21 pittsburgh pa usa.
acm new york ny usa pages.
.
introduction theuseofmachinevisioncomponents mvcs insafety critical systems such as self driving cars creates major safety concerns sinceundesiredbehaviorscanleadtofatalaccidents .forexample recently tesla self driving cars misclassified emergency vehiclesandcausedmultiplecrashes .knowinghowtoanalyze these components provide safety assurance and ensure their qualitybecomesamustfortheirusabilityinsafety criticaldomains.
particularly in systems that automate tasks normally performed by humans such as driving the vision task is performed by mvcs which represent a critical function for the overall system safety.
however vision tasks are difficult to specify thus they are usually performed using machine learning ml .
defining requirements for ml is not trivial because the inability to specify clear requirements is the reason to use ml in the first place .
yet such requirements are necessary for verification and providing safety guarantees.
as a first step towards safe mvcs one needs to definewhatitmeansforanmvctobecorrectandthencheckits correctness prior to system deployment.
inthispaper wefocusononeaspectofcorrectness reliability whichmeasurestheabilityofasystemorcomponenttoperform itsrequiredfunctionsin aspecifiedenvironment asit enables ensuring the quality of the deployed system.
we are specificallyinterested in whether the performance of an mvc remains reli ably unaffected by image transformations that commonly occur inreal worldscenarios.thisquestionhasbeenstudiedinseand mlliteratureas modelrobustness includingtesting andverification techniques.
yet given the lack of detailed reliability requirements these approaches are limited to checking the models withinasmallneighbourhoodoftheoriginalinputimage i.e.
by applying perturbations that are almost imperceptible to humans.
ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa boyue caroline hu lina marsso krzysztof czarnecki rick salay huakun shen and marsha chechik a original image b original image not car grille car jeep c rgb d contrast e defocus blur f brightness car limousine not car grille not car eu salamander car jeep g frost h color jitter i jpeg compression j gaussian noise car minivan car minivan car jeep not car shovel figure image recognition on original and transformed images.
the top row displays original images containing cars from the ilsvrc dataset .
the transformation applied to the image is specified under the image.
images from c to j present all thesafety related transformations considered in this paper.
the classi fication result of a state of the art mvc resnet50 is shown inbrackets in italics under each image.
we further specify whetherthepredictedcategoryisconcideredasacar ornot basedonthe ilsvrc class hierarchy.
transformations are implementedby albumentations and imagenet c .
while consideringonly the small perturbationsallows for requirementanalysisofmodelreliability itsapplicabilityislimited in the real world scenarios with a much broader range of possible changes.
for example consider the problem of recognizing cars inimages seeafewexamplesinfig.
.weareinterestedinbeing able to recognize cars under such transformations as frost see fig.
1g and different brightness levels fig.
3d and fig.
3g .
the range of transformation magnitudes in images in fig.
is not considered small or imperceptible.
while humans have no problemrecognizingcarsintheseimages thestate of the artimage classification model resnet50 failed to do so on the examples infigs.1d 1eand1j.sincemvcsareusedinsystemsthatautomate tasks normally performed by humans mvcs like resnet50 areat the minimum expected to consistently classify objects across range of changes that do not affect human perception.
thus we seekamethodtoestablishhumanperformanceasareferencefor definingreliability andanautomatedmethodtocheckmvcagainst a justified range of changes that do not affect human performance.
inthispaper weformallydefinetwoclassesofmachine verifiable reliabilityrequirementsformvcs correctness preservation andpredictionpreservation.
for both requirements classes the range of image changes we consider i.e.
the human tolerated range is a parameter estimated using experiments with human participants.
intuitively withinthehuman toleratedrangeofchanges correctnesspreservation requires that the mvc s predictions after changes in images should be correct and prediction preservation requires thatthepredictionsonoriginalimagesandonimagesthatunderwenttransformationsshouldbethesame.specifically thispapermakesthefollowingcontributions weidentifyaclassofsafety relatedimagetransformations weprovideaformalspecification oftwoclassesofinput outputreliabilityrequirementsformvcs with parameters representing human performance we present a method to instantiate our requirements classes into machineverifiable requirements.this method estimatesranges of changes toimagesthatdonotaffecthumanvisionusingresultsofexperiments with human participants we provide human experiment performance data for image recognition we provide an automated method for checking mvcs against our machine verifiable requirements.
while our criteria are defined for any computer vision task including object detection and semantic segmentation in this paper we demonstrate the feasibility of our approach on the image classification task.
we show that our approach captures reliability gaps that existing methods are unable to detect using state of the art pre trained image classification models on two image classification datasets imagenet and cifar .
significance to the best of our knowledge we are the first to definereliabilityrequirementsformvcsusingahuman justified range of changes over realistic safety related transformations.
our requirements and the method for checking their satisfaction can be reused by software engineers for analyzing system reliability of mvcs before deployment.
the rest of the paper is organized as follows sec.
gives an overview of our approach for creating and checking our reliability requirements.sec.3presentsthesafety relatedimagetransformations and a generic metric for measuring changes in images.
sec.
presentsaformalspecificationofourreliabilityrequirementclasses.
sec.5presentsourexperimentformeasuringhumanrecognition performance with human participants and demonstrates an automatedapproachforestimatingparametersoftherequirements using data from this experiment.
sec.
introduces an automated method for checking mvc s against our reliability requirements.
we evaluate our approach in sec.
.
sec.
compares our work with related approaches and we conclude in sec.
.
approach overview fig.
gives an overview of our approach.
given i a vision taskfor the mvc ii a safety related transformation and iii experimental data for estimating the ranges of visual changes that do not affecthumanperformance weprovideaprocessforinstantiating machine verifiablereliabilityrequirementsformvc requirement instantiation and a process for checking whether an mvc satisfies these instantiated requirements requirement checking .
thevisiontaskandthetransformationneedtobeselectedbased on the application of the mvc.
to help with the selection of transformationsthatrepresentchangeslikelytohappenintheoperating environment we identified a class of safety related image transformations that representpotentially risky input modificationsin real world situations.
for example frost shown in fig.
is a safetyrelatedtransformationbecauseitcanreducelightinginthescene which in turn can cause machine vision errors.
note that since transformations have different parameter domains and can have differentvisualeffectsondifferentimagestohumans wedefined agenericmetriccalleda visualchange anddenotedby v which authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
if a human can see it so should your system reliability requirements for machine vision components icse may pittsburgh pa usa legend i.requirement instantiation ii.requirement checking step artifactvision tasksafetyrelated transformation experiment data of human performancei.a.
estimate human tolerated range of changes with experiment results for the vision task and for each transformationparameters for requirement classesi.b.
instantiate the reliability requirementsmachine verifiable requirementsii.a.
generate tests for checking the satisfaction of requirementsimages sets set of test images original and transformed ii.c estimate confidence of requirements satisfaction reliability distance ii.b.
run the tests on the mvc under validation mvc prediction results requirements satisfaction results figure a process for instantiating two reliability requirements classes for mvcs requirement instantiation and a process for checking their satisfactions requirement checking .
decouples the perceptible visual change to the image from the transformationparametersandthusallowsstatingthereliability requirements on the mvc more abstractly.
requirement instantiation thisautomatedstepenablesusers toinstantiatethereliabilityrequirementsforthevisiontaskwith human tolerated range of visual changes for each selected transformation.thehuman toleratedrangeistherequirementparameter that describes the range of changes from a transformation that should not affect the mvc s behavior.
this requirement pa rameter is measured with vand estimated using results from experimentswithhumanparticipants.theoutputofthisstepisa setofmachine verifiablerequirements.theresultingcorrectnesspreservation requirementstates for a vision task and a transformation if the changes in the imagesare within the estimated human tolerated range then an mvcshould preserve the correctness after applying the changes to its input from before.
for example for the transformation adding frost artificially our resulting requirements are as follows therecognitionaccuracyofanmvcshouldnotdecreaseif thevisualchangeintheimagesiswithintherange v .
correctness preservation and the percentage of labels the mvc can preserve after adding frost should not decrease if visual change in the images is within the range v .
prediction preservation .
note that our requirements do not depend on the state of art ml techniques since they treat the mvc as a black box.
requirementchecking thisautomatedmethodcheckswhether an mvc satisfies the instantiated reliability requirements.
given a set with original images our process generates test cases step ii.a bytransforming theoriginalimages withintherange specifiedin theinstantiatedrequirements runsthetestsonthemodel stepii.b and checks whether the mvc satisfies our requirements step ii.c .
tosummarize ourproposedapproachcanbeusedtoautomatically generate machine verifiable reliability requirements for a vision task and a list of transformations given human experimentresults and then automatically evaluate whether an mvc satisfies these requirements.
in the above example the requirement checking method will generate a set of test case images within the ranges .
and .
to check whether an mlc satisfies these requirements.
animplementationofourmethodisavailableonline.1forthe purposeofdemonstrationandevaluation weconductedimageclassification experiments with human participants for the vision taskofrecognizingcarimagesfor8transformations rgb contrast defocusblur brightness frost colorjitter jpegcompression and gaussian noise see images in fig.
c j .
in the rest of the paper we describe the technical details of each step of fig.
using this experiment.
visual changes in images in this section we start with establishing the definition of the metric v which measures human visual changes in images caused bytransformations.then weidentifyaclassofsafety relatedimage transformations that are used to instantiate our correctnesspreservation andprediction preservation requirements see sec.
.
a key idea in our work is to define reliability requirements relative to vranges rather than the transformation parameter ranges to be tolerated.
this is important since each transformation may haveoneormoreparameters andeachparametermayaffectthe transformed image to a different degree also depending on theinput image.
for example brightening an already bright image makes the objects harder to see on the other hand making a dark imagebrighterwillhavetheoppositeeffect.further smallchanges to one parameter may cause small changes or large changes to thetransformedimagedependingonthevaluesofotherparameters.
the visual change metric vallows us to abstract from these complexities of the transformation parameter space.
also a simple imagedistancemetricsuchasmean squarederror whichisoften used to define robustness e.g.
does not adequately reflect thehuman perceivedvisualchangeinimages .thus webase von image quality assessment metrics.
background image quality assessment iqa .
iqa metrics arequantitativemeasuresofhumanobjectiveimagequality .
given the original image the iqa metrics automatically predict the perceived image quality by measuring the perceptual distance between the two images .
this distance is different from pixel distanceanditscalculationdependsonthedesignoftheiqametric.
vsnr visual signal to noise ratio checks the visibility of the changesinimagesandreturnsinfinity iftheyarenotvisible tohumans .vif visualinformationfidelity measuresthe informationfidelitybyanalyzingthestatisticsofthenaturalscenes intheimages.vifreturnsavaluebetween0and1ifthechanges degradeperceivedimagequality with1indicatingtheperfectquality compared to the original image and it returns a value 1i f the changes enhances image quality .
vif is empirically shown to be the closest to human opinions when compared to all other iqametrics andvsnrhasbeenshowntobeeffectivetodetectnon visiblechanges .vifisapplicabletotransformations 1see .github.io automating requirementsforimplementation more results and information.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa boyue caroline hu lina marsso krzysztof czarnecki rick salay huakun shen and marsha chechik that can be described locally by a combination of signal attenuationandadditivegaussiannoiseinthesub bandsinthewavelet domain .
measuring visual change in images.
we now use iqa metrics to define a generic metric v. our definition of vshares the same applicability characteristics as vnsr and vif.
for transformations that satisfy this characteristic e.g.
noise blur brightness and contrast changes color change etc.
the definition is as follows definition visual change v let an image x an applicable transformation txwith a parameter domain cand a parameter c c s.t.x prime tx x c begiven.
v x x prime isafunctiondefinedasfollows if vsnr x x prime or vif x x prime vif x x prime otherwise basing von iqa metrics means that it provides a generalized quantitative measure for visual changes in the images that isindependent ofparticular imagesand transformations.we split this definition into two cases.
the first corresponds to changes imperceptible to humans when vsnr x x prime and changes that enhance the visual quality when vif x x prime .
in this case v because such changes do not impacthuman recognition of the images negatively.
the other case deals with visible changes thatdegrade visualquality.since vifreturns1 forperfectquality comparedtotheoriginalimage thedegradationisoneminusthe image quality score.
for example the visual change of the example in fig.
1f compared to its original image in fig.
1b is .
.
the visual change of the example in fig.
1e compared to the one in fig.
1b is .
.
this suggests that the transformation in fig.
1e causes more change visually than the one in fig.
1f.
safety related image transformations.
wesaythatatransformation is safety related if it can lead to a hazard in a real world machine vision application scenario.
to assess this in a systematic manner we utilize the cv hazop checklist .
this checklist comprehensively identifies the potentially hazardous impacts of differentmodesofinterferenceinthecomputervision cv process whichiscomprisedoflightsources transmissionmedium object observer andalgorithm.atransformationthatcanproducesuch impacts is considered safety related.
for example contrast adjustment defocusblur andaddedgaussiannoiseshowninfig.1are safety related transformations because they can reduce lighting in thescene causeblurring andaddnoiseintheimages whichcan cause machine vision errors and subsequent system failures.
since the scope of cv hazop is broader than the image transformation assessment task we remove non image related hazard scenarios entriesfromthechecklist.inparticular entriesrelatedto algorithm in the vision process are not relevant because they modify the cv algorithm and not the images.
entries concerned with the number ofobservers arealsonotrelevantsincetheyfocusontheinteraction between the observers and cannot be represented by single imagetransformations.finally imagetransformationscannotmake temporal changes therefore entrieswhich dealwith timeare notrelevanteither.todeterminewhetheragivenimagetransformation belongstooursafety relatedclass oneshouldfirstidentifytheloca tioninthevisionprocesstowhichthetransformationcorresponds thenthepropertyoftheprocesslocationthatthetransformation is affecting cv hazop parameters and finally how the transformation is changing the property cv hazop guide words .
for example defocus blur is changing the focus of the observer cvhazopentryno.
i.e.
camera andthereforebelongsinour class.
supplementary material1includes the full list of cv hazop safety related entries entries chosen from the overall .
inthispaper weconsidertransformationsprovidedbythestateof the artlibraryalbumentations andthemlrobustnessbenchmark imagenet c which consist of unique transformations.
ofthese 45aresafety related.wefurtherremovethosetransformations that cannot produce a continuous range of transformed images yielding transformations see supplementary material1 forthefulllist.sincemultipletransformationscancorrespondto a single cv hazop entry we only instantiate our approach onone transformation per cv hazop entry resulting in the eight transformations illustrated in fig.
1c j rgb contrast defocus blur brightness frost color jitter jpeg compression andgaussian noise addition.
specification of reliability requirements classes inthissection weprovideaformalspecificationofourtworeliability requirements classes correctness preservation andpredictionpreservation.
letusassumethatwearegivenanmvc f adistributionofinput imagespx aground truthlabelingfunction f atransformation txwithparameterdomain candparameterdistribution pc.our requirementsusethejointdistributionofpairsoforiginalandtrans formedimages definedas ptx x x prime px x summationtext.
c c x prime tx x c pc c .
wefirstintroduceour correctness preservation reliabilityrequirement class.
it assumes a performance measure m f f px which is typically a measure of similarity between the output of fandf giventhattheinput x px.notethat mshouldbeadequateforthe vision task such as classification accuracy for image classification intersection over union iou for image segmentation and average precision for object detection.
we define the marginal distribution oftransformedimageswithchangeswithinthehumantoleratedrange v tcasptx tc x prime summationtext.
x xptx x x prime v x x prime tc .
definition correctness preservation requirement with parameters txandtc intuitively for the range of changes in images that do not affect human performance v tc theperformance of machine visioncomponent fshould not beaffected as well.
note that ground truth isrequired.
formally we require the performance mofffor transformedimagestobeequaltoorlargerthanthatfororiginal images m f f ptx tc m f f px .
example forthetransformationbrightness correctness preservation requiresmtc m f f ptx tc theclassificationaccuracyofresnet50 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
if a human can see it so should your system reliability requirements for machine vision components icse may pittsburgh pa usa onalltransformedimages whichisthepercentageof correctpredictions in fig.
3d 3i to be at least m0 m f f px the classificationaccuracyofthemodelonalloriginalimages whichisthe percentage of correctpredictions in fig.
3a 3c.
both accuracies are and the requirement is satisfied.
we then introduce our prediction preservation requirement class.
given a distance measure d f x f x prime which measures distance betweentheoutputof fontwoinputimages wedefinea predictionsimilarity measures f px x e x x prime px x which measures the expected similarity between the output of f on two images drawn from px x a distribution of image pairs.
notethat dshouldalsobeadequateforthevisiontask forexample for image classification d f x f x prime 0i ff x f x prime and otherwise.
we define the distribution of pairsof original and transformed images that are within the human tolerated range for prediction preservation v tpby conditioning the joint distributionptxas follows ptx tp x x prime ptx x x prime v x x prime tp .
sincescompares outputs with the original outputs sof original images would always be which is not necessarily achievable.
as an alternative we estimate sof original images with sof images with minimal image changes v .
more precisely we rank theimagepairs by v determine asalo w er q thquantilein the ranking and define the distribution of image pairs with v as ptx x x prime ptx x x prime v x x prime .
definition prediction preservation requirement with parameters txandtp intuitively for the range of changes in images that do notaffecthumanpredictions v tp thepredictions of machine vision component fshould stay unaffected as well.
note that ground truth is notrequired.
formally werequirethepredictionsimilarity sofffor alltransformedimagestobeequaltoorlargerthanthatof imagestransformedwith v whichis s f ptx tp s f px .
example forthetransformationbrightness prediction preservation requiresstp s f ptx tp thepredictionsimilarityofresnet50for alltransformedimagesvs.originals whichisthepercentageofpredictions in images in fig.
3d 3i preserved from images in fig.
3a 3c andthus5 tobeatleastequalto s0 s f px thepredictionsimilarityofthemodelforimagestransformedwith v .
given the very small sample we set to the median and thus s0 is the percentage of predictions preserved for images in fig.
3d 3f ands0 .
thus the requirement is not satisfied.
definitions ofthe two reliabilityrequirements aresimilar with twomaindifferences.first correctness preservationreliesonaperformance metric to compare predictions to ground truth whereas prediction preservationusespredictionsimilaritytocomparepredictions on transformed images vs. originals.
second correctnesspreservation compares performance on the full range of trans formed images with that on the originals whereas predictionpreservationcomparesthepredictionsimilarityforthefullrange of transformed images vs. originals to that for the minimally transformed images i.e.
v vs. originals.
the design choices for a original image b original image c original image car not car not car d brightness e brightness f brightness car not car not car g brightness h brightness i brightness car not car car figure image recognition on original and transformed images.
images from d to i display the same transformation brightness appliedwithdifferentmagnitudes.theclassificationresultofresnet50 is shown in italics under each image.
the prediction preservation requirement completely remove the needforhumanlabelsontestimages andmakethisrequirement applicable in environments where such labels are unavailable.
finally wedefine reliabilitydistance asthedifferencebetween thetargetandtheactualcorrectness orprediction preservation i.e.
m m0 mtcand s s0 stp respectively.
this distance indicateshowwellthemvcsatisfiestherespectiverequirement zerodistanceindicatesjustmeetingit negativedistanceindicates performingbetterthanthetargetbyamargin andpositivedistance indicates how far the mvc is from meeting the target.
instantiating reliability requirements toobtainthereliabilityrequirementsrangeparameters tc andtpin defs.2and3 weperformtwoexperimentswithhumanparticipants and then estimate the parameters from the experimental results to obtain threshholds at which the human performance drops statistically significantly step i.a of fig.
.
this section first presents the experimentalsetupandprocedure andthenintroducesourmethod for instantiating the requirements from the experimental results requirement instantiation steps i.a b .
experiments with human participants.
the objective of the humanexperiments oneperdataset istoobtainhumanpredictions on original and transformed images to be used to estimate tc and tpinstep i.a.the experimentinputs arethe taskto bepreformed thetransformation tx thedatasetoforiginalimages xi xi px with their ground truth labels f xi and distributions pcfor each transformation parameter.
given these inputs we generate a authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa boyue caroline hu lina marsso krzysztof czarnecki rick salay huakun shen and marsha chechik sample of original transformed images xi x prime i j xi x prime i j ptx by randomly selecting xifrom xi andcj pc and transforming x prime i j tx xi cj .toobtainthehumanpredictionsforeachimage in xi x prime i j for imageclassification wefollow theexperimental designofgeirhosetal.
.theexperimentisa forced choiceimage categorisation task humans are presented with the images with transformationsapplied for200ms andaskedtochooseoneofthe twocategories e.g.
carornotcar .betweenimages anoisemaskis shown to minimize feedback influence in the brain .
the tasks aretimedtoensurefairnessinthecomparisonbetweenhumansandmachine .however incontrasttotheworkbygeirhosetal.
we ensure that the full range of achievable vvalues is covered when samplingfrom pc andwealsocollecthumanpredictionsforthe original images so that we can estimate prediction preservation.
agiven subject is never shown more than one version of xi whether original or transformed.
note that human predictions for originals are different from their ground truth labels labelers take as long asneededperimagetoclassifyit butoursubjectshaveonly200 ms to see each image.
the human data is specific to a task an image distribution and a class of transformations and thus has to becollectedforthecombinationofthethree.inotherwords the data is reusable for different samples from the same distribution or intuitively for images sharing the same characteristics e.g.
the same image resolution the same objects etc.
for example it is reusableacrossdifferentsetsofimagesofroadscenestakenwithin the same geographic area using cameras with same the resolution and image quality.
togeneratepredictionsforourevaluation weperformtheexperimentontwodatasets ilsvrc andcifar .while cifar has images of much lower resolution than ilsvrc weincludethisdatasettocompareourmethodtotheexistingwork onrobustnesschecking whichusescifar .wealsoselectthe eight safety related transformations seeimages from fig.
1c j as discussed in sec.
and set pcto be uniform.
to fit our labeling budget welimitthetasktoabinaryclassificationproblemofrecog nizingcarinstances.also whileweapplytheeighttransformations toilsvrc we limittheexperimenton cifar 10tofourtransformations that are also used in the works we compare with.
to differentiatebetweencarandnon carinstances weusetheclass hierarchy from the ilsvrc dataset.
for each of the selected transformations we sample pairs xi x prime i j and have each image originalortransformed labeledbyfivehumans.toachieve this wedividethe1 pairsamples considered transformationsintobatchesof20images.eachbatchisshownfivetimesto different participants using the platform amazon mechanical turk.
we include qualification tests and sanity checks aimed to filter out participants misunderstanding the task and spammers and onlyconsiderresultsfromparticipantswhopassbothtests.asa result fortheilsvrc 12imageclassificationtask weuse xi with car images and same number of non car images and collect human predictions for transformed images andthesamenumberoftheoriginalimages foratotalof80 000predictions.
note that the effort required for measuring human performanceissignificantlysmallerthanthethedatasetlabeling effort needed for model training.
for example we collect human predictions for transformed images per transformation with0.2s timebox per image for a total of 1000s.
training sets are typicallyover100 000images withatleastthreegroundtruthlabels assignedindependentlytoeachimage forqualitycontrol andeachtakesmultipleseconds e.g.
000x3x2s 000s.thehuman experiment results can be found in supplementary material1.
estimatingtoleratedrangeparametersandinstantiatingre quirements.
we propose the following procedure to estimate tcandtpfrom the experimentally obtained human predictions step i.a .
the key idea is to group and order the image pairs by v compute the human performance mkand human prediction similarity skineachgroup anduseastatisticaltesttodetermine thetc value of vat which mk drops significantly from the human performance m0for the original images .
recall that s0is the the humanpredictionsimilarityforimagestransformedwith v vs. originals we set to the lower 5th percentile.
more precisely we determine threshold t l candt l pfor a given transformation tx lfrom the image pairs xi x prime i j the human predictions for these images and their ground truth f .
first we compute vfor each pair and sort the pairs by their vintorintervals definedby r 1equidistancedthresholds tk witht0 0and tr .
we then process the result using smoothing splines toreducerandomnessandremoveoutliers.then toestimate t l c foreachk wecomputetheprobability pkthatmkonthe transformedimagesinthe k thinterval isbelowm0.this probabilityisobtainedusingthesingle sidedbinomialtest.wethendeterminetheintervalwiththesmallest tkforwhich pk .
and return this tkast l c. similarly for t l p we compute the probability pkthatskfortheoriginal transformedimagepairsin is belows0.
thent l cis the smallest tkfor which pk .
.
with the above procedure we can now estimate the parameters for the task of recognizing cars for each of the eight selected transformations using our experimental results.
the instantiated parameters are shown in tbl.
.
with these parameters we obtain the instantiated machineverifiablereliabilityrequirementsforeachtransformation stepi.b .
for example for the transformation brightness given an mvc that recognizes cars in images the correctness preservation requirement says that the mvc s recognition accuracy should not decrease if thevisualchangeintheimagesiswithintherange v .
and theprediction preservation requirement says that the percentage of labels humans can preserve after a brightness change should not decrease if the visual change in the images is within the range v .
.
to obtain the instantiated requirements for other transformations onlytheparametervaluesneedtobereplacedwiththe estimated values in tbl.
.
checking reliability requirements in thissection wedescribe amethod forautomatically checking whether mvcs satisfy our machine verifiable requirements see stepsii.a c requirementchecking infig.
.requirementchecking takes as inputs a list of images a set of transformations and anmvc under validation.
it generates test cases step ii.a withinthe specified range of v tcortp runs the tests on the mvc step ii.b and checks whether the mvc satisfies the requirements by estimating the reliability distance step ii.c .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
if a human can see it so should your system reliability requirements for machine vision components icse may pittsburgh pa usa table1 estimatedparametersforcorrectness tc andpredictionpreservation tp requirementsusinghumanexperimentresultsfor the task of recognizing car instances.
transformation tctptransformation tctpimagenetrgb .
.
brightness .
.
contrast .
.28gaussian noise .
.
defocus blur .
.
color jitter .
.
frost .
.91jpeg compression .
.94cifar 10brightness .
.
contrast .
.
frost .
.61jpeg compression .
.
wetesttherequirementssatisfactionbyestimatingmvcperformance or prediction preservation through sampling.
this is necessarily sincewedonothavedirectaccessto pxbutonlyitssamples.
our test case generation is based on the bootstrap method which estimates the metrics m0 mtc s0 andstpthrough sampling thetestdatawithreplacement.sincethesemetricsaredefinedas expected values or means by central limit theorem the values of thesemetricscomputedforsamplebatches denotedforeachbatch ias m0 i mtc i s0 i and stp i respectively are normally distributed.
followingthebootstrapmethod weobtainthepopulationestimates bycomputingthemeans m0 mtc s0 and stpandthestandarddeviations m0 mtc s0 and stpof the respective batch value sets m0 i mtc i s0 i and stp i .todoso foreachtransformation txandalistoforiginalimages x wesample nbatchesof kimages fromxand thengenerate a transformedimage by applying txto each sampled original image with randomly sampled parameter valueswhileensuringtherequired vrange i.e.
n kpairsintotal.
sincesamplingispartoftheprocess nandkshouldbedetermined based on x and the bigger they are the more accurate the estimatedresultswouldbe .althoughthelower boundnumbers fornandkare hard to determine one can check whether the samplingissufficientasthebootstrapmethodalwaysconvergeswith enoughbatchesofsamplesfornormaldistributions .achoiceof nisconsideredsufficientlylargeiftwoseparaterunswithdifferent random seeds result in similar estimated values.
aftergeneratingthetests ourmethodrunsthemonthemvc under validation and obtains the mvc predictions for all the originalimagesandforeachbatch ioftransformedimages.wethen computethesamplebatchestimatesofthefourmetrics i.e.
m0 i mtc i s0 i and stp i and take mean m s and standard deviation m s of each set as the population estimates.
finally we want to show that the reliability distance for each requirement is zero or negative i.e.
m for correctnesspreservation and s for prediction preservation.
since our estimates from the previous step are normally distributed their differencesarealsonormallydistributed.thus thereliabilitydistance estimates have the following means and standard deviations m m0 mtcand m radicalbig 2 m0 2 mtc and s s0 stp and s radicalbig 2 s0 2 stp.
to ensure that the reliability distances are zero or negative with a confidence we use the right handedconfidenceinterval.thus m 0withconfidence iff m z m where z isthez valuecorresponding toanarea intherighttailofastandardnormaldistribution withz0.
.
for confidence.
similarly s with confidence iff s z s .
for example to check whether resnet50 satisfies our instantiated requirements for the transformation gaussian noise see tbl.
forthetaskofrecognizingcars thetestingmethodfirstgenerates tests with the original and the transformed images within the vrange specified in the requirements.
the original images are sampled from the ilsvrc validation dataset using bootstrapwith n k 50andthegaussiannoisetransformation.
then we run the generated tests on resnet50 compute the four sets of metrics m0 i mtc i s0 i and stp i over the batches and then compute m .
m .
s .
and s .
.
we check for correctness preservation with confidence m z0.05 m and prediction preservation with confidence s z0.05 s .
therefore resnet50 does not satisfy eitheroftherequirements.notethatbyestimatingthereliability distance we provide engineers with a quantitative measure of howmuchimprovementisneededtomeettherequirementsincasethey are not met.
evaluation while our approach is defined for any computer vision task in this paper we demonstrate its feasibility on a particular domain image classification using parameters instantiated via human performance data collected for this domain as explained in sec.
.
first weevaluatethegeneralityofourinstantiatedimageclassificationrequirements.foraspecifictransformation ourinstantiated requirements contain the tolerated range of changes that do not affecthumanperformance seesec.
estimatedfromexperiments with human participants.
since such experiments are costly we aim to minimize the number of experiments that need to be conducted.toachievethisgoal wewouldliketoreusethecollected humanperformanceresultsfornewsetsofimagesfromthedataset different from the ones presented to the humans during the experiments.
we expect the images to come from the same dataset to share the underlying data generating distribution px.
crucially to be reusable our requirement parameters should not be affected by the choice of the images included in the experiments with human participants.
since our requirements are defined on a particular distribution of images we aim to answer rq1 how reusable are thethresholds tcandtpoverdifferentsamplesfromthesameimage distribution?
second existingmethodsforevaluatingreliabilityofimageclassificationmvcsconsidereithersmall imperceptibleimagechangesoranarbitraryrangeofperceptiblechangesinimages.inthiswork ourfocusisonameaningfulrangeofchangesinimages theone that does not affect human vision which includes both imperceptible and perceptible changes.
since our goal is to use human performance as a baseline i.e.
if humans can see it so should an mvc weareinterestedinunderstandinghowwelltheexistingreliability evaluation approaches already cover the human tolerated range.
wearealsointerestedincomparingthedistributionoftestcases generated by our method step ii.a in fig.
with those from the other reliability methods to see whether our method addresses the range better.
therefore we aim to answer rq2 how well do the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa boyue caroline hu lina marsso krzysztof czarnecki rick salay huakun shen and marsha chechik existing reliabilityevaluation methods cover thehuman tolerated range of changes?
finally we would like to determine whether checking the reliability of image classification mvc models with our method inthe human tolerated range of changes reveals reliability gaps instate of the art image classification models.
to do so we aim to answer rq3 how effective is our requirement checking method in identifying reliability gaps compared to existing approaches?
rq1.to answer rq1 we compare human tolerated ranges of transformations parameters tcandtp estimatedusingourrequirementinstantiationmethodwith differentsetsofimagesfromthe ilsvrc 12experiment.werandomlyselectedtwosubsetsofour resultscontaining60 ofalltheimagesincludedintheexperiment.
we compared the similarity of the spline models obtained using these two subsets with all experiment results.
as suggested by koenkeretal.
twosplinemodelsareconsideredsimilariftheir confidence intervals overlap.
following this for each of the eight transformation included in our experiment we compared the confidenceintervalsoftheestimatedsplinemodelsrepresenting thetwosubsetsandtheentiresetofexperimentresults.asaresult for all transformations we observed that the spline models are unaffected.for example the splinemodelsobtained forthe frost transformationareshowninfig.
.duetopagelimit weinclude theplotsanddatainsupplementarymaterial1.sincetheparameters are derived using the spline models unaffected spline models suggestthattheparametersestimatedarealsounaffected.toconclude different subsets of experiment results do not affect the parametersestimated.
therefore we show evidence that our estimated humantoleratedrangescan bereusedforimages thatarenotincludedin theexperimentwithhumanparticipants answeringrq1.notethat ourrequirementsaredefinedononeimagedistribution thusthe thresholdscannotbereusedfordifferentimagedistributions.we cancheckthisbycomparingthevaluesof tcandtpestimatedusing images from cifar and ilsvrc shown in tbl.
sec.
.
rq2.existing methods for evaluating the reliability of mvcs with image transformations imperceptible and perceptible changes includemetamorphictesting andbenchmarking .
metamorphictestingisbasedonmetamorphicrelations thus instead of finding a range that does not affect human judgment itconsider all possible parameter values for each transformationincluded .
for this rq we compare with existing work that considers a broader range of changes the state of the art imagecorruption benchmark datasets imagenet c and cifar c .
these benchmark datasets include images transformed with five pre selected parameter values for arbitrarily chosen transformations.
due to the low resolution of cifar images they look blurry to humans and thus do not share the same characteristics withtheilsvrc 12dataset .therefore toevaluateourmethod weconductanadditionalexperimentwithhumanparticipantusing cifar images for four transformations contrast brightness frost andjpegcompression andestimatedthecorresponding human tolerated ranges as described in section .
we answer rq2 and rq3 using six transformations considered by the other works brightness contrast defocusblur frost gaussiannoise andjpeg compression.
figure4 acomparisonofdifferentsubsetsofexperimentalresults for estimating t cfor the frost transformation.
toanswerrq2 wefirstcompareourhuman toleratedranges withtherangesofchangesincludedintherobustnessbenchmark datasets toseewhetherexistingmethodsalreadycoverthem.infig.
weshow foreachtransformation therangeofchangesin images included in imagenet c cifar c 2in blue and our human toleratedrangesforbothrequirementsinyellowandgreen.
theoverlappingofrangesindicatesthedegreetowhichourranges are covered by imagenet c cifar c. the ranges in imagenet c and cifar c are either larger e.g.
brightness and frost for cifar c brightnessforimagenet c orsmaller e.g.
contrastand jpeg compression of cifar c gaussian noise defocus blur and frostforimagenet c thanthehuman toleratedrange.
theimages includedinimagenet c cifar caretransformedbyusingapre selectedlistoffiveparametervaluespertransformation.thisresultshowsthatsimplygeneratingimagesthiswaydoesnotaddressthefullrangeofrealisticchangesthatdonotaffecthumanperformance.secondly wecomparethedistributionofthetestcases transformed images within the human tolerated range generated from our requirement checking method and from cifar c and imagenet c. ourrequirementcheckingmethodforgeneratingtestcasessamplestheparameterspaceuniformlyandthentransformstheimages.
as the number of parameters for a transformation increases so doesthepossiblenumberofcombinationsofparametervaluesthat can lead to the same degree of visual change in the images.
therefore sampling the parameter space uniformly allows us a better coverage of possible transformed images resulting in a fairer reliability evaluation compared with transformations with pre selected parametervalues asdoneincifar candimagenet c .in fig.
we show the distributions of transformed images generated with our requirement checking method and images in cifar c andimagenet c.aswecanobservefromtheplots thetransformedimagesfromcifar candimagenet ceitherfavorcertainranges 2notethatduetothelargesizeofimagenet c thedistributionisobtainedbyuniformly sampling the entire benchmarking dataset.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
if a human can see it so should your system reliability requirements for machine vision components icse may pittsburgh pa usa a cifar c and our ranges.
b imagenet c and our ranges.
legend range of changes in cifar c imagenet c our range our range figure a comparison of our human tolerated ranges for correctness preservation and prediction preservation requirementsandtherangeofchangesincludedinrobustnessbenchmarkdatasets imagenet c and cifar c .
of vscore fig.
6b 6c 6d or are discontinuous and therefore biased.
this also suggests that the approach of generating transformed images in the benchmark datasets does not guarantee a fair evaluation of reliability within the human tolerated range of changes because of the biased distribution of tests.
thus the human toleratedrangesof changesarenotaddressed orproperly tested by existing methods answering rq2.
rq3.to answer rq3 we aim to determine whether checking our requirementsenablesustodiscoverreliabilitygapsthatwerenot identifiedwithexistingreliabilitybenchmarks.weevaluatedthe reliability of state of the art image classification models with thevisiontaskofrecognizingcarsinimagesusingbothourrequirementcheckingmethodandtheexistingbenchmarkscifar c andimagenet c.resultsareshownintbl.
.notethatnomodels satisfy our requirements with confidence which is not surprising since they were not trained with data covering the humantolerated range.
however several models pre trained on imagenet ilsvrc images have negative reliability distance s0 stp for ourprediction preservation requirements whichsuggeststhatthese models are close to satisfying these requirements.
foreachtransformation themodelsintbl.2arerankedbased ontheevaluationresults accuracy ofbenchmarkimages.ahigher ranking means that the model is more reliable.
we compare the reliability ranking of these models using our reliability distance for both of our requirements see sec.
with the benchmark ranking indicating the differences in blue.
the tests included in the cifar c andimagenet c benchmarks arebiased toward imageswithsmalltransformationmagnitudes resultinginsignificant differenceswithourrankingforbrightness frost fig.6c and 6h jpeg compression and defocus blur transformations.
therefore if a model is lower on the ranking of our reliabilitydistancethanonthebenchmarkranking itislessreliablethanpredictedbythebenchmark meaningthatourmethoddiscov eredanewreliabilitygap.belowwesummarizethemainreliability gapsidentifiedbyourmethod.
i rlatisrankedbycifar c withinthethreelastmodelsforthetransformationscontrast brightness and frost but the first for jpeg compression.
however ourmethod ranks rlat at the bottom for all the transformations includingjpegcompression indicatingthatthetestsgeneratedbyourmethodareabletodetectthereliabilitygapmissedbythebenchmark.
ii for jpeg compression rlataugmixnojsd is ranked second both by the cifar c benchmark and by our correctnesspreservationreliabilitydistance.however rlataugmixnojsdis rankedlastbyourprediction preservationreliabilitydistance.simi larly forgaussiannoise resnext101 a disrankedfirstbybothour correction preservation and imagenet c benchmark but it is ranked second last by our prediction preservation reliability distance.
this showsthatbothrlataugmixnojsdandresnext101 a dhavea high accuracy for transformed images but their predictions arenot consistent.
therefore checking our prediction preservation requirementenabledustoidentifynewreliability gapsthatcould not be detected by only checking accuracy on transformed images answering rq3.
summary.
through answering rq1 we show that parameters of the requirements estimated with our requirement instantiation method are reusablefor different images sharing the same class and images distribution.
through answering rq2 we show that existing work does not adequately cover the range of changes that donotaffecthumans.finally throughansweringrq3 weshowthat ourrequirementcheckingmethodisuseful sinceitcandiscover reliabilitygapsthataremissedbytheexistingmethods.also notice thatourprediction preservation isclosetobeingsatisfiedbyseveral models pre trained on imagenet ilsvrc images this indicatesthatourrequirementsaresatisfiable.thus ourevaluationsuggeststhattheproposedrequirementsareusefulandreusableforchecking reliability of mvcs.
threats to validity.
for the correctness preservation requirement thehumanperformancemayseemtoohardformvcstomatch.ho wever followingguidelinesprovidedbyfirestone we choose to keep the requirements for a fair comparison between a human and an ml performance.
further training with data augmentationthatcoverstherangeofvisualchangesforeachtransformationasperourrequirementsmightenableanmvctomeet them.
checking this hypothesis is future work.
we as sumed that the parameter values for any transformation should beuniformlydistributed.thismaybedifferentdependingonthe applicationofthemvc e.g.
heavysnowmaybelessrelevantfor autonomouscarsdeployedintropicalregionsthanotherregions.
due to budget considerations we included a limited setoftransformationsandimageclassesinourexperimentswith humans.
experiments for other visual tasks are also future work.
related work in this section we first review the software engineering se approachesdefiningreliabilityofmvcs thentheseandthecomputer vision cv approachesforevaluatingreliabilityofmvcsand finally those comparing human performance against mvcs.
specifying reliability of mvcs.
the inductive data driven nature of machine learning creates several challenges for requirements specification and verification in mvcs.
yet multiple recent studies explored this area .
while they agree on the necessity of requirements elicitation in mvcs they fail to provide a systematic approach for inferring the requirements.
several authors attempted to specify the expected behaviour of mvcs indirectlythroughspecifyingasetofqualitycharacteristicsfortraining authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa boyue caroline hu lina marsso krzysztof czarnecki rick salay huakun shen and marsha chechik a contrast with cifar images b brightness with cifar images c frost with cifar images d jpeg compression with cifar images e gaussian noise with imagenet ilsvrc images f brightness with imagenet ilsvrc images g defocus blur with imagenet ilsvrc images h frost with imagenet ilsvrc images legend cifar c imagenet c images images generated within images generated within figure6 acomparisonoftherangeanddistributionof vscoresintestimagesofrobustnessbenchmarkdatasets cifar candimagenetc and test images generated with our requirement checking method.
the x axis is the vscore.
the y axis is the number of images.
table2 acomparisonofreliabilityevaluationofmvcsusingourmethodandusingstate of the artbenchmarks cifar candimagenetc .foreachtransformationandthevisualtaskofcarrecognition themvcmodelsarerankedw.r.t.theiraccuracyonallbenchmarkimages.
m0 and s0are resp.
the required accuracy and percentage of labels preserved in our requirements.
mtcand stpare resp.
the resulting accuracy and perception preservation percentage through checking the models against our requirements.
the differences between the benchmark ranking and our ranking using the reliability distance are highlighted in blue.
checking our correctness preservationchecking our prediction preservationchecking our correctness preservationchecking our prediction preservationdatasetmodel nameaccuracy on all benchmark imagesrequired and estimated accuracy m0 mtcreliability distance m0 mtc rank required and estimated percentage s0 stpreliability distance s0 stp rank model nameaccuracy on all benchmark imagesrequired and estimated accuracy m0 mtcreliability distance m0 mtc rank required and estimated percentage s0 stpreliability distance s0 stp rank cifar 10contrast brightness augmix resnext .
.
.
.
.
.
.
augmix resnext .
.
.
.
.
.
.
augmix wrn .
.
.
.
.
.
.
augmixnojsd .
.
.
.
.
.
.
augmixnojsd .
.
.
.
.
.
.
augmix wrn .
.
.
.
.
.
.
standard .
.
.
.
.
.
.
rlataugmixnojsd .
.
.
.
.
.
.
rlataugmixnojsd .
.
.
.
.
.
.
standard .
.
.
.
.
.
.
gauss50percent .
.
.
.
.
.
.
rlat .
.
.
.
.
.
.
rlat .
.
.
.
.
.
.
gauss50percent .
.
.
.
.
.
.
frost jpeg compression augmix resnext .
.
.
.
.
.
.
rlat .
.
.
.
.
.
.
rlataugmixnojsd .
.
.
.
.
.
.
rlataugmixnojsd .
.
.
.
.
.
.
augmix wrn .
.
.
.
.
.
.
gauss50percent .
.
.
.
.
.
.
augmixnojsd .
.
.
.
.
.
.
augmix resnext .
.
.
.
.
.
.
rlat .
.
.
.
.
.
.
augmix wrn .
.
.
.
.
.
.
gauss50percent .
.
.
.
.
.
.
augmixnojsd .
.
.
.
.
.
.
standard .
.
.
.
.
.
.
standard .
.
.
.
.
.
.0595imagenetgaussian noise frost resnext101 a d .
.
.
.
.
.
.
resnext101 a d .
.
.
.
.
.
.
aug deep .
.
.
.
.
.
.
aug deep .
.
.
.
.
.
.
deepaugment .
.
.
.
.
.
.
ant3x3 sin .
.
.
.
.
.
.
ant sin .
.
.
.
.
.
.
ant sin .
.
.
.
.
.
.
speckle model .
.
.
.
.
.
.
deepaugment .
.
.
.
.
.
.
resnet50 .
.
.
.
.
.
.
resnet50 .
.
.
.
.
.
.
brightness defocus blur resnext101 a d .
.
.
.
.
.
resnext101 a d .
.
.
.
.
.
.
aug deep .
.
.
.
.
.
aug deep .
.
.
.
.
.
.
deepaugment .
.
.
.
.
.
.
deepaugment .
.
.
.
.
.
.
ant3x3 sin .
.
.
.
.
.
.
ant sin .
.
.
.
.
.
.
ant sin .
.
.
.
.
.
.
ant3x3 sin .
.
.
.
.
.
.
resnet50 .
.
.
.
.
.
resnet50 .
.
.
.
.
.
.
note accuracy is calculated with true positive true negative all images all the accuracy values are closed to because of the binary classification task.
all numbers are rounded.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
if a human can see it so should your system reliability requirements for machine vision components icse may pittsburgh pa usa datasets specifying additional ml related requirements for each phase of software development processes specifying higher levelrequirements orspecifyinghowmvcsaddress thetargetapplications .yettheseapproachescannotbeused tocheckreliabilityof mvcsautomatically whereasourreliability requirements are machine verifiable.
checkingreliability.
metricsfortestingmvcsrobustnessagainst image transformations have been defined using metamorphic testing .incontrast wefocusonadifferentsetoftransformations the ones that do degrade the image quality while preservingthehumanopinionintheimageratherthantransformations that can be covered with equivariant relations.
existing works also use testing to generate corner cases or corner case tests to increasemvcsrobustness .incontrast ourapproachdoesnot focusoncorner cases butratherontypicalcasesthatcanbefound in real world deployments while preserving the human opinion about the content.
several works evaluated safety of mvcs through assessing their robustness against adversarial examples either by providing a testingapproachtogenerateadversarialexamples inthese area providingrobustnessbenchmarks orverifyingthe presence of adversarial examples in a given range of image modifications in the cv area.
in contrast our focus is on definingboundariesofimagemodificationsusinghumanperformance within which the mvcs are expected to maintain their robustness.
also wedonotconsideranarbitraryrangeofimagemodifications ourapproachestimatestherangeoftransformationlevelsthatdoes notaffecthumanperformance.previously wepresentedtheidea ofdefiningadversarialexamplesusingiqamodels focusing onlyonnon visiblechanges.incontrast ourcurrentapproachconsidersbothvisibleandnon visiblechangesinabroaderrangeof real world scenarios.comparinghumanagainstmachines.
priorstudiesalsoreferred tohumanperformanceasthebenchmarkfortheevaluationoftheir proposed methods to better study the existing differences betweenhumanandneuralnetworks tostudyinvarianttransformations to compare recognition accuracy or to compare robustness .incontrast ourfocusisnotoncomparinghumans performancewithmvcs butratherontherangesoftransformation magnitudes that do not affect human performance.
conclusion in this paper we defined reliability of machine vision components mvc as ifahumancanseeit soshouldthemvc .moreprecisely we specified two classes of reliability requirements correctnesspreservationandprediction preservation.ourrequirementsspecify that an mvc should be reliably unaffected by safety related image transformations at least within the range of changes that does not affect humans.
we showed through an evaluation with state ofthe art pre trained image classification models that our approach captures reliability gaps that state of the art reliability methods are unable to detect.
therefore we conclude that checking thishuman tolerated range is important to help software engineers ensure quality and reliability of mvcs.
while not discussed in the paper our requirements can be used for other se tasks such as checkingrefinementfromhigher levelsystemrequirements andcheckingconsistencyandcompatibilitywithrequirementsofother connected components.
inthefuture weaimtoimproveofourrequirement checking process by providing reliability diagnosis that would help software engineersunderstandthereliabilitygapsintheirmvcs.wealso aim to validate through additional experiments our assumptionthat our approach can be applicable beyond image classification models e.g.
to handle object detection.
finally we aim to use our reliability requirements for mvcs to provide evidence for building safety assurance cases for the overall system.