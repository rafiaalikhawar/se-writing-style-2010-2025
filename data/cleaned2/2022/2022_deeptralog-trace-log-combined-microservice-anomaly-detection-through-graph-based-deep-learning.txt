deeptralog trace log combined microservice anomaly detection through graph based deep learning chenxi zhang fudan university chinaxin peng fudan university chinachaofeng sha fudan university china ke zhang fudan university chinazhenqing fu fudan university chinaxiya wu fudan university china qingwei lin microsoft research chinadongmei zhang microsoft research china abstract a microservice system in industry is usually a large scale distributed system consisting of dozens to thousands of services running in different machines.
an anomaly of the system often can be reflected in traces and logs which record inter service interactions and intra service behaviors respectively.
existing trace anomaly detection approachestreat a trace asa sequence of serviceinvocations.
theyignore the complex structureof a tracebrought by its invocationhierarchyandparallel asynchronousinvocations.on the otherhand existing loganomaly detectionapproaches treata log as a sequence of events and cannot handle microservice logs that are distributed in a large number of services with complex interactions.inthispaper weproposedeeptralog adeeplearning based microservice anomaly detection approach.
deeptralog uses a unified graph representation to describe the complex structure of a trace together with log events embedded in the structure.
based on the graph representation deeptralog trains a ggnns based deepsvddmodelbycombingtracesandlogsanddetectsanomalies in new traces and the corresponding logs.
evaluation on a microservicebenchmarkshowsthatdeeptralogachievesahigh precision .
and recall .
outperforming state of the art trace log anomaly detection approaches with an average increase of0.37inf1 score.italsovalidatestheefficiencyofdeeptralog thecontributionoftheunifiedgraphrepresentation andtheimpact of the configurations of some key parameters.
c.zhang x.peng c.sha k.zhang z.fuandx.wuarewiththeschoolofcomputer scienceandshanghaikeylaboratoryofdatascience fudanuniversity chinaand the shanghai collaborative innovation center of intelligent visual computing china x. peng is the corresponding author pengxin fudan.edu.cn .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
concepts softwareanditsengineering computersystemsorganization reliability maintainability and maintenance cloud computing keywords microservice anomaly detection log analysis tracing graph neural network deep learning acm reference format chenxi zhang xin peng chaofeng sha ke zhang zhenqing fu xiya wu qingweilin anddongmeizhang.
.deeptralog trace logcombined microservice anomaly detection through graph based deep learning.
in 44thinternationalconferenceonsoftwareengineering icse may21 pittsburgh pa usa.
acm new york ny usa pages.
https introduction microservice architecture is an approach to developing a single application as a suite of small services each running in its own process and communicating with lightweight mechanisms .
a microservice system in industry is usually a large scale distributed systemhavingdozenstothousandsofservicesrunningindifferent machines.
running in a highly uncertain and dynamic environment amicroservicesystemoftenfailsduetovariousinfrastructure problems or application faults such as hardware failures improper configurations implementationfaults andincorrectcoordination inserviceinteractions .toallowengineerstotimelyreactto potentialfailures itisdesirablethattheanomaliesofamicroservice system can be automatically detected at runtime.
powered by specifications like opentracing and related infrastructureslikeskywalking distributedtracing hasbeen widely adopted in industrial microservice systems.
each produced trace describes the execution process i.e.
invocation chain of a request through service instances and each operation i.e.
service invocation initiscalledaspan.atthesametime logginghasalsobeenwidelyusedbythedeveloperstorecordthebehaviorsofeachservice.alogrecordssignificantmessagesatvariouscriticalpoints forthepurposeofdebuggingandrootcauseanalysis .atrace canincludeseveraltohundredsofserviceinvocations i.e.
spans ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa chenxi zhang xin peng chaofeng sha ke zhang zhenqing fu xiya wu qingwei lin and dongmei zhang andduringeachinvocationaseriesoflogmessagesareproducedby the invoked service instance.
industrial distributed tracing systemscanlinkthelogmessagesofthesametracebyinjectingthetraceid andspanidsintothelogmessagesproducedbydifferentservice instances.
recentresearches usedeeplearningbasedtraceanalysismethodstodetectruntimeanomaliesofmicroservicesystems.
these approaches treat a trace as a sequence of service invocations.
however a trace can have a complex structure formed by the hierarchy of service invocations and parallel asynchronous invocations.
existing trace anomaly detection approaches ignore the complexstructuresoftraces.moreover theydonotconsiderthelog messages which describe the behaviors of individual service instancesinvolvedinatrace.therefore theseapproachescannot well capture microservice anomalies.
ontheotherhand logshavebeenwidelyusedinanomalydetection for distributed systems.
existing log anomaly detectionapproaches learn log patterns from normal execution anddetectanomalieswhenlogpatternsdeviatefromthetrained model.
these approaches treat a log as a sequence of log events whicharetheabstractionofagroupofsimilarlogmessages .
for a distributed system a log is produced for each request by sortinglogmessagesfromdifferentnodesinvolvedintherequest bytimestamp.foramicroservicesystem however arequestcorresponds to an invocation chain that may involve many service instancesandcomplexinvocationsamongthem.ifweproducea logforarequestinasimilarway itcannotwellcapturethecomplex structure of its invocation chain.
inthispaper weproposedeeptralog adeeplearningbasedmicroservice anomaly detection approach.
deeptralog uses a unified graphrepresentation whichiscalledtraceeventgraph teg to describe the complex structure of a trace together with log events embedded in the structure.
it takes traces and logs as input andtrains a graph based deep learning model for trace anomaly detection.
first it parsesthe inputtraces and logsand extractsspan relationshipsandlogeventsfromthemrespectively.second itgenerates vector representations for span events and log events and at the same time constructs a teg for each trace.
third it trains a gated graph neural networks ggnns based deep svdd support vectordatadescription model whichlearnsalatentrepresentation for each teg and a minimized data enclosing hypersphere.
when used for anomaly detection deeptralog analyzes a trace and the related logs in a similar way and uses the trained model to generate a latent representation for the trace.
it then determines whetherthetraceisanomalousbasedonitsanomalyscore i.e.
the shortest distance from the latent representation of the trace to the hypersphere.notethatdeeptralogdoesnotrelyontracelabelling and just requires that the majority of traces in the training set are produced in normal execution of the system.
moreover it is able to capture different types of anomalies.
toevaluatetheeffectivenessandefficiencyofdeeptralogwe conduct a series of experimental studies on a microservice benchmarksystem.theresultsshowthatdeeptralogoutperformsexisting trace and log based anomaly detection approaches by .
and101.
onaverageintermsofprecisionandrecallrespectively.
the unified graph representation significantly contributes to the improvement of deeptralog making it outperform the variant of figure trace span and log figure timeline of spans in figure deeptralogusingsequencerepresentationby7.
and26.
on averageintermsofprecisionandrecallrespectively.deeptralog isefficientinmodeltrainingandtestinganditsresponsetimein anomaly detection increases linearly with the size of the trace.
in summary this paper makes the following contributions a unified graph representation of traces and logs that facili tates the combined analysis of them aggnnsbaseddeepsvddmodelformicroserviceanomaly detection a series of experimental studies validating the effectiveness andefficiencyofdeeptralogtogetherwiththecontribution of the unified graph representation and the impact of the configurationsof some key parameters.
significance.
our work provides a new and effective way for combining traces and logs for microservice anomaly detection whichoutperformsexistinglog traceanomalydetectionapproaches.
it defines a unified graph based representation for inter serviceinteractions and intra service behaviors.
the representation can facilitate avariety of differentmicroservice analysis taskssuch as anomalydetection rootcauseanalysis andarchitecturecomprehension.
background and motivation in this section we first introduce the background about traces and logs then motivate our work with an example.
.
background as a kindof large scale distributedsystems microservice systems widely use distributed tracing to profile and monitor their executions.atraceisthedescriptionoftheexecutionprocessof authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeptralog trace log combined microservice anomaly detection through graph based deep learning icse may pittsburgh pa usa arequestasitmovesthroughadistributedsystem .foramicroservice system a trace describes the execution process of a requestthroughserviceinstances i.e.
aserviceinvocationchain.
the service invocations in a trace are initially recorded by individual service instances and then collected and restored to a trace.
as shown in figure a trace consists of a set of spans in a tree structure and each spancorresponds to a service invocation.
each trace has a unique trace id and each span has a unique span id.
a span records the invoker and the invoked service instance and has anoperationnameindicatingtheoperationtobeperformed.for example the operationname of a spanof rest invocation canbe post api v1 foodservice orders.
each span except the root span has a parent span which initiates the current span.
for example in figure span a is a synchronous invocation and during its executionitinitiatestwosynchronousinvocationscorrespondingto span b and span d respectively.
therefore span a is the parent of span b and span d. distributed tracing has been an important part of microservice infrastructures and supported by open source solu tions e.g.
zipkin jeager andskywalking andcloud service providers e.g.
amazon s x ray and alibaba cloud s arms .
asynchronousinvocationsandparallelinvocationsarewidely used in microservice systems for better performance and availability.atracecanincludeseveraltohundredsofspans i.e.
serviceinvocations .
therefore synchronous invocations are often consideredharmfulduetothemultiplicativeeffectofdowntime .
asynchronousinvocationsareusuallyimplementedbymessagebased communication and are thought to be a way for achieving high availability systems as the invoker does not block while waiting.
parallel invocations mean to invoke multiple services at thesame time to reduce the overall response time.
they are usually implemented by making service invocations in multiple threads.
as shown in figure log messages are produced during each serviceinvocation.theselogmessagesareproducedbythelogging statements written by service developers.
they record the internal statesandbehaviorsoftheinvokedserviceinstance.alogmessage is an unstructured sentence which contains a constant part log event andseveralvariableparts logparameters .forexample a log message requested seat type is t1 and number is containsalogevent requestedseattypeis and number is and two log parameters seattype andseatnumber.
log event extraction has been a standard step in log parsing.
after log parsing a log is converted into a sequence of log events.
traces and logs can be combined for analyzing the runtime behaviors of microservice systems.
a trace describes the service interactions for a request while the logs record the internal states and behaviors in individual service instances.
as a service instance mayserveformultiplerequestsatthesametime itslogfileinterleaveslogmessagesfordifferentrequests.tosupportthecombined analysis somedistributedtracingsystems e.g.
skywalking alibaba arms inject trace ids and span ids into log messages andthusthelogmessagesofaserviceinstancecanbeassociated with different requests.
for example skywalking uses the mapped diagnosticcontextmechanismofjavaloggingframeworks e.g.
log4j logback to inject trace ids and span ids to log messages.
.
motivation figure2showsthetimelineofthespansinfigure1.spanbandspan daretwoparallel invocationsgeneratedbyspana sotheyhave someoverlapinthetimeline.spanfisanasynchronousinvocation generated by span d so it ends after span d. existingtraceanomalydetectionapproaches treatatrace asasequenceofserviceinvocations whileexistingloganomalyde tectionapproaches treatalogasasequenceoflogevents.
these approaches cannot well support the anomaly detection of microservice systems due to the following two reasons.
first the logs of different service instances need to be combined foranomalydetection.existingtraceanomalydetectionapproaches do not consider logs thus can only detect anomalies that are reflected intrace structures.figure1 showsan example oflog level anomalies.thelogmessagesinspand showthatthetrainticket order does not need food but those in span f show that a food orderiscreatedforthistrainticketorder.thisanomalycanonly be detected by combing the log messages of span d and f. second a trace may have a complex structure involving invocation hierarchy and parallel asynchronous invocations.
a trace hasatreestructure.ifallthespansaresynchronousinvocations thetracecanberepresentedbyasequenceofserviceinvocations orderedbytheirstarttime.evenso sequence basedrepresentationcannotreflectthecausalrelationshipsbetweenparentandchildren spansandtemporalrelationshipsbetweenlogeventsofthesame spans.forexample twoadjacentlogeventsinspanamaybefarin the sequence based representation as the log events of the descendantspansofspanaareinsertedintothem.moreover atracemay include parallel or asynchronous invocations.
the trace shown in figure1andfigure2includestwoparallelinvocations spanband spand and anasynchronousinvocation spanf .
therefore the log events in span b and span d and their descendant spans can interleave in any order similarly the log events in span f and a partlogeventsinspandcaninterleaveinanyorder.ifwecombinethelogeventsofdifferentspansintoasequence e.g.
bystarttime the characteristics of parallel or asynchronous invocations will be lost.
basedontheanalysis wecanseethatthelogeventsofdifferent spans of a trace need to be combined in a way that the structureof the trace can be kept.
therefore we propose a unified graphrepresentationthatcandescribethestructureofatracetogether withthelogeventsembeddedinthestructuretofacilitateanomaly detection.
approach the objective of deeptralog is to automatically and accurately detectanomaloustracesofmicroservicesystems.ittakestracesand logs as input and trains a graph based deep learning model.
when usedforanomalydetection itanalyzesatraceandtheassociated logsinasimilarwayandusesthemodeltogeneratearepresentation for the trace to calculate its anomaly score.
an overview ofdeeptralogis presented in figure3 which includessixsteps.
logparsing parsestheinputlogsandextractslog eventsfromthelogmessages.
traceparsing parsestheinputtraces andconvertstheirspansintospanevents whichwillbeanalyzed authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa chenxi zhang xin peng chaofeng sha ke zhang zhenqing fu xiya wu qingwei lin and dongmei zhang figure deeptralog overview together with log events.
event embedding generates vector representations for span events and log events.
graph construction constructsatraceeventgraph teg foreachtracetorepresentvarious relationships between the span log events of the trace.
model training trains a gated graph neural networks ggnns based deepsvdd supportvectordatadescription model whichlearns a latent representation for each teg and a minimized hypersphere that encloses the representations of the tegs.
anomaly detectiondetermineswhetheratraceisanomalousbasedonitsanomaly score i.e.
theshortestdistancefromthelatentrepresentationof its teg to the hypersphere .
.
log parsing following existing researches on log anomaly detection we adopt a state of the art log parsing approach drain .
it can parse logs in a streaming and timely manner with high parsing accuracy and efficiency.
to support the combined analysis with traces weextract and recordthe trace idand spanid of eachlog messagebeforelogparsing.afterlogparsing atraceidandaspan id are attached with each of the extracted log events for further analysis.
.
trace parsing thelogeventsofaserviceinstanceconstituteaneventsequence.to combine traces and logs for anomaly detection we need to convert the spans of a trace into span events.
span events are a special kindofeventsthatrepresenttherequestandresponseofservice invocations.
when analyzed together with log events span events can indicate the starts and ends of service invocations.
for each span of a trace we convert it into multiple span events ofrelatedspansaccordingtoitstype client server orproducer consumer .
aclient server span represents a synchronous invocation while aproducer consumer span represents an asynchronous invocation.
for a client server span we generate a request event and aresponseeventforthecurrentspan server anditsparentspan client respectively.therequesteventandtheresponseeventof the client server represents the sending receiving of the service invocationandthereceiving sending oftheinvocationresponse respectively.fora producer consumer spanwegenerateaconsumer event for the current span consumer and a producer event for the parent span of the current span producer .
the producer eventand the consumer event represent the sending and receiving of the message respectively.
thecontentofaspaneventincludestwoparts aneventtypeand anoperationname.forexample fora client server spanwiththe operationname post api v1 foodservice orders wegeneratetwo span events server request post api v1 foodservice orders and server response post api v1 foodservice orders for the current spanandtwospanevents clientrequestpost api v1 foodservice orders and client response post api v1 foodservice orders for the parent span of the current span for a producer consumer span withtheoperationname rabbitmq topic queue email sendemail we generate a span event consumer rabbitmq topic queue email sendemail forthecurrentspanandaspanevent producer rabbitmq topic queue email sendemail fortheparentspanof thecurrentspan.eachspaneventhasatimestampobtainedfrom the span record.
for example the timestamp of a client request event is the time when the client service instance sends the service invocation.
.
event embedding logeventembeddingiswidelyusedinloganomalydetection.itgenerates a vector representation for each log event.
the vector representationcanidentifysemanticallysimilarlogeventsandalsodistinguishdifferentlogevents .indeeptralog spaneventsare analyzedtogetherwithlogeventsforanomalydetection.therefore our event embedding generates vector representations for both log events and span events.
each log event or span event is a sequence of english words thus can be treated as a sentence.
following the commonpracticeoflogeventembedding deeptralogimplements event embedding in three steps.
step .
preprocessing.
log events and span events contain non character tokens e.g.
separators such as and ip ad dresses stop words e.g.
a the is and compound words e.g.
verifycode tripid .
following previous works we preprocess log events and span events by removing non verbalsymbols and stop words and splitting compound words into in dividual words.
for example a span event client request post api v1 foodservice orders ispreprocessedinto clientrequestpost api v1 food service orders .
step .
word embedding.
we use the widely used pre trained glovemodel togenerateavectorrepresentationforeachword authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeptralog trace log combined microservice anomaly detection through graph based deep learning icse may pittsburgh pa usa figure an example of trace event graph teg inlogeventsandspanevents.particularly weusetheglove300dimensional word vectors trained on wikipedia and gigaword data .thusforeachwordwecanobtaina300 dimensionalvector as its representation.
step3.
sentenceembedding.sentence embeddinggenerates a vector representation for each log event and span event based on word embedding.
the words in these events are not equally important.somewords e.g.
api get aremorecommon thus arelessimportantthanothers e.g.
food submit insentence embedding.
therefore we follow previous works and use tfidf tomeasuretheweightofeachwordinsentenceembedding.
tf term frequency of a word win an event e which measures its importance in e is calculated by tfw e lw e le where lw eis theoccurrencesof wineandleisthenumberofwordsin e.idf inverse document frequency of a word w which measures its frequency in all events is calculated by idfw logl lw where lis the total number of events and lwis the number of events containing w. then the weight of a word win an event ecan be measuredbyitstf idfscoreas ww e tfw e idfw.thus the vectorrepresentationofanevent ecanbecalculatedastheweighted sum of the vector representations of all its words as following whereneisthenumberofdifferentwordsin eandvwisthevector representation of a word w. ve nene summationdisplay.
w 1ww e vw notethatlogeventsandspaneventshavequitedifferentcharacteristics so we calculate the tf idf scores and word weights for log events and span events separately.
.
graph construction atraceeventgraph teg consistsofthelogeventsandspanevents ofatraceandtheirrelationships.arelationshipinategcanbe one of the following four types.
sequence a sequence relationship represents the predecessor successor relationship between two sequential span log events of the same span.
synchronousrequest asynchronousrequestrelationship representsasynchronousrequestfromaparentspantoits child span.
synchronousresponse asynchronousresponserelationship represents the response of a synchronous request from a span to its parent span.
asynchronous request an asynchronous request relationship represents an asynchronous request from a parent span to its child span.
given a trace we construct a teg in three steps.
step connection of log events.
for each span of the trace obtainallthelogeventsthatbelongtothespan.thenorderthelog eventsbytheirtimestampsandaddasequencerelationshipfrom each log event to the one next to it.
step2 insertionofspanevents.foreachspanofthetrace obtain all the span events that belong to the span.
then for eachobtained span event insert it into the log event sequence of the currentspanbasedonitstimestampandaddasequencerelationship between it and its predecessor successor event.
step3 connectionofspans.foreachspanconnectitwithits parentspaninthefollowingway.ifthespanisa client server span add a synchronous request relationship from the corresponding client request event of its parent span to the corresponding server request event of the current span and a synchronous response relationshipfromthecorrespondingserverresponseeventofthe currentspantothecorrespondingclientresponseeventofitsparentspan.ifthespanisa producer consumer span addanasynchronous requestrelationshipfromthecorrespondingproducereventofits parent span to the corresponding consumer event of the current span.
figure shows an example of teg which corresponds to the trace shown in figure and figure .
in the graph colored rect angles and uncolored rectangles represent span events and log events respectively.
span events of different colors are of different types includingclient serverrequest client serverresponse and producer consumer.notethatthedottedroundedrectangleswhich represent spans in figure are not the nodes of the teg but arejust used for illustration.
the spans are implicitly represented in thetegbytheeventsequencesstartingfromserverrequestevents.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa chenxi zhang xin peng chaofeng sha ke zhang zhenqing fu xiya wu qingwei lin and dongmei zhang arrowsofdifferentcolorsrepresentdifferenttypesofrelationships.
the graphcan well describe thestructure of thetrace and various relationships in it.
the log events and span events in the same spanformasequencebytheirtimestamps.therefore thetemporal relationshipsbetween inter serviceinteractions spanevents and intra servicebehaviors logevents canbedescribedandconsidered inanomalydetection.theeventsofdifferentspansareseparated and only connected via request response relationships between span events.
the structure of the trace is embodied in these request response relationships a synchronous invocation is reflected byapairofrequestandresponserelationships anasynchronous invocation is reflected by a request relationship without the corresponding response relationship.
for example it can be seen that spanbandspandareparallelsynchronousinvocationsastheir request response ranges in span a overlap span f is an asynchronousinvocationinitiatedbyspandasthereisnoresponsefrom span f to span d. .
model training we frame the task of trace log combined microservice anomaly detection asan one classclassificationproblem.
one classclassification problem aims to learn a model that can accurately describe the train data which is considered belong to the same class.
foranomalydetectiontask mostofthetrainingsamplesarenormal oneswhichcanberegardedasthesameclassandtheotherscan identified as outliers e.g.
anomalous traces in our work .
deeptralog uses deep svdd to train a one class classification model for detecting anomalous traces.
deep svdd learnsuseful feature representations of the training data together with aminimizedhyperspherethatenclosesthelatentrepresentations of the data.
thus the data that is distant from the center of the hypersphere can be considered anomalous.
existing deep learning basedanomalydetectionapproaches usuallyusedeepautoencoder to detect anomalies based on the reconstruction errorof the data.
thus the anomaly detection relies on an empiricallydetermined threshold of the reconstruction error which is often challenging.incontrast deepsvddjointlylearnsthelatentrepresentations of the data and a classification boundary without a threshold.
standard deep svdd uses multi layer perception mlp or convolutional neural networks cnn to learns the latent representations of the data.
however in our work a trace is represented byagraph teg whichcannotbewellhandledbymlporcnn.
therefore weusegatedgraphneuralnetworks ggnns tolearn thetracerepresentationsandjointlytraintheggnnswithdeep svdd.ggnnsisimplementedbasedontheneuralmessagepassingmechanismandcanworkwellwithavarietytypesofgraphs such as directed graph bipartite graph and undirected graph.
in deeptralog a trace is represented by a teg which is a directedattributedgraph g v a x where visasetofnodes i.e.
events ais adjacency matrix of the graph and x r v dis thenode attributematrix whereeachrow xvofxisthe attribute i.e.
event vector of a node v v dis the dimension of the event vector.
ggnns represents the nodes in a graph as units of a neural network and the units are linked to each other according to the adjacencymatrixofthegraph.ggnnspassesthenodeattributesasthemessagesbetweentheunitsineveryiterationandusesgru to determine which messages to remember or forget during the messagepassing.
thefinal representationofa nodeis determined by a combination of its own state and the state of neighbouring nodes.therepresentationofanodeafterthe t thiterationisdefined by the following equations h v xv m t v at v h t t ...h t t v t b h t v gru m t v h t v whereh i vis the representation of a node vafter the i th iteration xvistheinitialeventvectorofnode v av isthe row and column in the adjacency matrix a which represent the incoming edges and outgoing edges of v gruis the gru function.
finallyafter titerationseachnodeinategcanhave avectoras the latent representation.
ggnns calculates the vector representationofthetegbasedonthenodevectorrepresentationsusing asoft attentionmechanism.thesoft attentionmechanismtakes the vector representations of the nodes as input and calculates the weight attentionscore ofeachnodethroughanattentionfunction to give higher weights to the nodes that contribute more to the graphclassification.thegraphrepresentationofteg giscalculated by the following equation hg tanh parenleftbigg summationdisplay.
v v parenleftbig fi h t v xv parenrightbig tanh parenleftbig fj h t v xv parenrightbig parenrightbigg wherehgisthevector representationofateg g fi hv t xv isthesoft attentionmechanism fiandfjareneuralnetworks tis the number of layers of ggnns is element wise multiplication.
readers can refer to for more details about ggnns.
deeptralogtrainstheggnnsusingthefollowinglossfunction whichexpressestheobjectiveoflearningaminimizedhypersphere to enclose the vector representations of tegs loss r2 ngng summationdisplay.
g 1max hg c r2 2nl summationdisplay.
l l f wherecis the center of the hypersphere ris the radius of the hypersphere hg c 2is the distance fromthe latent representationofateg gtoc ngisthenumberoftegs nlisthenumber of network layers in ggnns the hyperparameter controls the trade off between the hypersphere volume and the violations of the boundary which allows some training data mapped outside thehypersphere i.e.
allowingsomeanomalydatainthetraining set summationtext.1nl l l fisaweightdecayregularizerontheggnns parameters with hyperparameter .
inthetrainingphase wejointlyoptimizetheggnnsparameters andthehypersphereradius rinequation6.weuseadam to optimizetheggnnsparameters ineachepoch.astheradius ris not an inner parameter of ggnns we optimize it using a different method as follows.
we optimize with a fixed rin the first few epochsandafterevery kepochswecalculateanoptimizedvalue forrby linear search.
each time when ris updated its value is authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeptralog trace log combined microservice anomaly detection through graph based deep learning icse may pittsburgh pa usa figure visualization of an anomalous teg calculated as the percentile of the distances of all the tegs inthecurrentepoch.thehyperspherecenter cissettothemeanof thevectorrepresentationsofallthetegsafteraninitialforward pass.
.
anomaly detection deeptralog trains a ggnns based deep svdd model for anomaly detection.
given a new trace and the corresponding log foranomaly detection deeptralog follows the same process as thetraining phase i.e.
log parsing trace parsing event embedding andgraphconstruction toproduceategtogetherwithitsevent embedding for the trace.
then deeptralog feeds the teg into the trainedmodeltogeneratealatentrepresentationofthetegand usesthelatentrepresentationtocalculateananomalyscore.the anomaly score is defined as the shortest distance from the latentrepresentation of the teg to the learned hypersphere which is calculated by the following equation ans hg hg c r2 wherehgis the vector representation of a teg g cis the center of the learned hypersphere ris the final radius of the learned hypersphere.
forateg gofatrace ifitsanomalyscore i.e.
ans hg isgreater than it is treated as anomalous.
tohelptheuserstounderstandtheresultsofanomalydetection deeptralog provides a visualization of the tegs of anomaloustraces.
figure presents an example of the visualization of an anomalousteg.specifically deeptraloghighlightsthenodesin thetegthathavehighattentionscorescalculatedusingequation5 which helps the users to quickly locate the anomalous parts of the trace.
evaluation weimplementdeeptralogusingpython3.
.
pytorch1.
.
and pytorchgeometric1.
.
forggnnslearning .toevaluateitwe conduct aseries ofexperimentalstudies toanswerthe following research questions table fault types in the trainticket dataset faulttype faultcases example asynchronous interactionf1 f2 f13 f1 asynchronousmessagedelivery without sequence control multi instance f8 f11 f12 f12 service states not synchro nized among different instances of the service configuration f3 f4 f5 f7 f4 improper configurations of ssl monolithic f6 f9 f10 f14f14 wrong calculating process of train ticket price rq1 how effective is deeptralog in microservice anomaly detectioncomparedwithbaselineapproaches?howmuch does theunified graph representation contribute to the effectiveness of deeptralog?
rq2 how efficient is deeptralog in model training and anomalydetectioncomparedwithbaselineapproaches?how doesdeeptralogscalewiththesizeoftraceinonlineprediction?
rq3 how do different configurations of the ggnns baseddeep svdd model impact the effectiveness of deeptralog?
.
experimental design .
.
benchmarksystemanddataset.
ourstudiesareconducted on the latest release v0.
.
of trainticket1 .
it is a mediumscale open source microservice system for train ticket bookingand has been widely used in researches on microservice archi tecture infrastructure and aiops artificial intelligence for it operation .ithas45serviceswrittenbydifferentlanguages e.g.
java javascript python and communicating with synchronous rest invocations and asynchronous messaging.
trainticketreplicates avarietyofdifferent typesoffaultcases fromindustrialmicroservicesystemsandprovidesthefaultcasesin different fault branches.
the latest release of trainticket provides compatible fault cases of different types as shown in table .
each fault case may include multiple fault instances in different services.
the fault types include asynchronousinteraction faultscausedbymissingor improper coordination of asynchronous service invocations multi instance faults related to the existence of multiple instances of the same service at runtime configuration faultscaused byimproper orinconsistent configurations of services and or environments e.g.
containers and virtual machines monolithic faults caused by internal implementations of individual services which can cause failures even when the application is deployed in a monolithic mode.
thus we can have a normal version of trainticket and faulty versionseachcorrespondingtothebranchofafaultcase.wedeploy different versions of trainticket on a kubernetes cluster with virtualmachines eachofwhichhasa16 core3.0ghzcpuand32gb ram.weusepythontoimplementanexecutioncontrollerthatcanexecuteautomatedtestcases.foreachversionweusetheexecution 1trainticket project authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa chenxi zhang xin peng chaofeng sha ke zhang zhenqing fu xiya wu qingwei lin and dongmei zhang controller to simulate user requests by executing automated test cases.weuseapacheskywalking asthedistributedtracing frameworktocollecttracesandlogsanduseelasticsearch to store the collected traces and logs.
the resulted dataset includes traces and log messages.
among the traces .
are anomalous ones causedby73faultsofthe14faultcaseswhicharelocatedindifferent services.thisdatasetisusedthroughoutthewholeexperimental studies.
it is available in our replication package .
.
.
baselines.
we use the following four state of the art logbasedortrace basedanomalydetectionapproachesasthebaselines.
traceanomaly is a trace anomaly detection approach that only considers service level traces operations not considered .
it adopts posterior flow based variational autoencoders vae to detect anomalous traces.
multimodaltrace is a trace anomaly detection approach that treats a trace as a span sequence and a response timesequence.itadoptsamulti modallstm longshortterm memory model to learn the sequential patterns of normal traces.
deeplog isaloganomalydetectionapproachthattreats a log as an event sequence.
it adopts an lstm model to predict the next log event in the sequence and identify possible anomalies.
loganomaly isaloganomalydetectionapproachthat treatsalogasaneventsequenceandconsidersthecounts ofdifferent logeventsasan additionalfeature.it adoptsan lstmmodeltolearnsequentialandquantitativepatterns.
similartodeeplog itdetectsanomaliesbypredictingthe next log event.
as traceanomaly and multimodaltrace only consider traces we feed them with only the traces when using them.
loganomaly anddeeplogonlyconsiderlogsandtreatthemaseventsequences.
therefore we combine all the events including span events and logevents ofdifferentspansofatraceintoasingleeventsequence orderedbytimestampandprovidetheeventsequencesofallthetraces as the input for these two approaches.
traceanomaly and deeplogprovideopen sourceimplementations andweuse themdirectly.theothertwoapproacheshavenopubliclyavailable implementations sowedevelopourownimplementationsbased on their papers.
to evaluate the contribution of the unified graph representation of traces and logs i.e.
teg we derive a variant of deeptralog calledgru based deep svdd which represents all the events of atrace asan eventsequenceordered bytimestamp andusesgru instead of ggnns.
for all these baseline approaches we experimentally choose the best parameters and use their optimal results for comparison.
.
.
metrics.
weusetheprecision recall andf1 scoretomeasure the effectiveness of anomaly detection based on tp true positive fp false positive and fn false negative .
precision the percentage of anomalous traces out of alltraces detected as anomalies represented as precision tp tp fp.table effectiveness of different approaches approach precision recall f1 score traceanomaly .
.
.
multimodaltrace .
.
.
deeplog .
.
.
loganomaly .
.
.
gru base d deep svdd .
.
.
deeptralog .
.
.
a deeptralog b gru based deep svdd figure distribution of latent representations of traces recall thepercentageofallanomaloustracesthataredetected as anomalies represented as recall tp tp fn.
f1 score the harmonic mean of precision and recall represented as f1 precision recall precision recall.
.
.
settings.
alltheexperimentsareconductedonalinuxserver withintelcorei9 10900x3.70ghzcpu 128gbram rtx3090 with 24gb gpu memory and running ubuntu .
.
.
the setting of deeptralog are the following the embedding size of each event set to the hidden layer of ggnns set to the hidden sizeof each hidden layer set to the and in equation set to .
and .
respectively and the batch size set to .
following thepracticein weemployasimpletwo phaselearningrate schedulewithaninitiallearningrate0.0001inthefirst60epochs and subsequently .
in the last epochs.
for each approach we leverage of the normal traces as the training set of the normal traces as the validation set and the rest of the traces include the rest of the normal traces and all the anomalous traces as the test set.
.
rq1 effectiveness table2showstheeffectivenessevaluationresultsofdifferentapproaches.deeptralogoutperformsallthebaselineapproachesandachievesahighprecision .
recall .
andf1 score .
.
the two trace based approaches i.e.
traceanomaly and multimodaltrace achieve low precision and recall.
these two ap proaches do not consider logs thus cannot detect anomalies inlog events.
as they use sequence based trace representation and haveaspecialfocusonresponsetime theycanonlydetectanomaliesthathavesignificantimpactonspansequencesordistribution of response time.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeptralog trace log combined microservice anomaly detection through graph based deep learning icse may pittsburgh pa usa table training and testing time of different approaches methods training time testing time traceanomaly 30m 137s multimodaltrace .4m 148s deeplog .6m 278s loganomaly 816m 136s gru base d deep svdd .8m 105s deeptralog .1m 77s the two log based approaches i.e.
deeplog and loganomaly achievehighrecallandlowprecision.thesetwoapproachesconsider events within spans we provide both span events and log events for them thus can detect anomalies in span sequences and log event sequences.
however they rely on the prediction of the next event in a sliding window of the event sequence thus haveno global view of the trace and its structure.
therefore they arelikely to falsely report unseen event subsequences as anomalies.
actually this kind of log anomaly detection approaches usually work on a single log event sequence such as the hdfs dataset .
thus theycannotwellworkformicroserviceanomalydetection whichinvolvesmanyserviceinstancesanddistributedlogevents in parallel and asynchronous service invocations.
gru baseddeepsvddachievesbetterprecisionandrecallthan thefourbaselineapproaches.itconsidersallthespaneventsand log events of a trace thus performs better than log anomaly detection approacheswhich relyon slidingwindow based loganalysis.
however its sequence based representation of span events andlog events ignores the complex structures of traces brought by theirinvocationhierarchiesandparallel asynchronousinvocations.
therefore it does not perform as well as deeptralog.
figure shows the comparison of the results produced by deeptralog and gru based deep svdd.
we use t sne to visualize the latent representations of the traces in the test set by projectingthemto2dspace.itcanbeseenthatdeeptralogcanlearna hypersphere that can better enclose normal traces and distinguish anomaloustracesfromnormalones.webelievethattheimprovement is broughtby the unified graph representationof traces and logs.
in conclusion deeptralog is effective in microservice anomaly detectionandoutperformsexistingtrace andlog basedanomaly detectionapproachesby64.
and101.
onaverageinterms of precision and recall respectively.
the unified graph representationsignificantlycontributestotheimprovementofdeeptralog makingitoutperformthevariantofdeeptralogusingsequence representation by .
and .
in terms of precision and recall respectively.
.
rq2 efficiency usingeachoftheapproaches wetrainananomalydetectionmodel with the training set including traces and test the model withthetestset including56 080traces .table3showsthetraining time and testing time of each approach.
these approaches take minutes to train the models and seconds to finishthe test.
in general all the approaches except loganomaly are efficient forexampletrainingamodelinabout30 138minutesandfinishingthetest thewholetestset in77 278seconds.deeptralog is slower than the two trace based approaches i.e.
traceanomaly and multimodaltrace but much faster than the others in model training.
it is much faster than all the other approaches in testing.
thetwotrace basedapproaches i.e.
traceanomalyandmultimodaltrace are much faster than deeptralog in training as they onlyconsidertraces.deeptralogconsidersbothtracesandlogs thus uses more time in training.
however deeptralog is much faster than them in testing.
the reason is that the network parameters completelycharacterizetheanomalydetectionmodeland no data has to be stored for anomaly detection .
thetwo log based approaches i.e.
deeplog and loganomaly useslidingwindowstosegmenteventsequences thusproducea largenumberofsubsequencesfortrainingandtesting.moreover loganomaly uses an additional count vector sequence for each subsequence and the dimension of the count vectors is determined by the number of log events.
public log datasets usually have a smallnumberoflogevents.forexample thehdfslogdataset contains only about log events.
in contrast our dataset has morethan800log spanevents causingthecurseofdimensionality forloganomaly.thelargenumberoflog spaneventsispopular in microservice systems thus traditional log anomaly detection approaches cannot work well for microservice systems.
gru baseddeepsvddusesmuchsimplersequencerepresentationfortracesandlogs butisslowerthandeeptraloginboth trainingandtesting.thereasonisthatggnnstreatsnodes events in the graph as network units and conducts message passing inparallel while gru serially processes every event in a very long sequence.
theresponsetimeofonlinepredictionisimportantforachieving timelyanomalydetection.ithighlydependsonthesizeofthetrace i.e.
the number of span log events in it.
to evaluate the scalability ofdeeptralogwithtracesize weconductanexperimentonthe changesofresponsetimewiththeincreaseofeventnumber.wedivide the event number into nine ranges e.g.
andforeachrangerandomlysample100traceswhoseevent numbers are within the range.
for each trace we run the anomalydetectionmodel300timesandcalculatetheaverageresponse timeofprediction.wecomparetheaverageresponsetimeofdeeptralog and gru based deep svdd for traces of different sizes.
figure shows the results.
it can be seen that the response time of both approaches increases linearly with the size of the trace and deeptralog is always faster than gru based deep svdd.
inconclusion deeptralogisslowerthantrace basedapproaches by122.
andfasterthanlog basedapproachesby52.
intraining it is faster than trace based approaches by .
and faster thanlog basedapproachesby84.
intesting.moreover theresponsetimeofdeeptralogincreaseslinearlywiththesizeofthe trace and it costs deeptralog around milliseconds to make a prediction when the trace includes events.
.
rq3 impact of configurations the hyperparameter in the loss function see equation and the hidden layer number of ggnns are two important parameters of the ggnns based deep svdd model.
as stated in section .
controlsthetrade offbetweenthehyperspherevolumeandthe authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa chenxi zhang xin peng chaofeng sha ke zhang zhenqing fu xiya wu qingwei lin and dongmei zhang figure changes of response time with the increase of event number a hyperparameter in equation b hidden layer number of ggnns figure impact of different configurations violations of the boundary.
the hidden layer number of ggnns determines the iterations of message passing between the nodes in a teg thus has great impact on the latent representation the teg.
the regularization parameter in equation usually can be empirically set e.g.
.
in our implementation as previous work .
figure a shows the impact of on the precision recall and f1 score of deeptralog.
in deep svdd usually can take a value between0.01and0.
.bigger usuallyleadstolowerprecisionand higher recall as it makes a smaller hypersphere enclosing less normal traces andanomalous traces.
according to theresults .07achievesthebesttrade offin termsoff1 score.notethatthe bestconfigurationof highlydependsonthecharacteristicsofthe dataset.
it usually can be determined based on the preference on precision and recall.
figure b shows the impact of the hidden layer number of ggnns.itisusuallysettotwotofour.itcanbeseenthatbothrecall and f1 score decrease with the increase of hidden layer number.
it is usuallybecause thatmore hiddenlayers are morelikely tolead toover smoothing whichmakesthefeaturesindistinguishableand thus hurts the classification accuracy .
.
threats to validity thethreatstotheinternalvaliditymainlylieintheimplementation andconfigurationofbaselineapproachesandtheprocessofdataset generation.weimplementmultimodaltrace andloganomalyby ourselvesastheyhavenopubliclyavailableimplementations.these twoapproachesarebasedonstandarddeeplearning e.g.
lstm andlogeventextraction e.g.
ft tree components.wefollowtheir papers and assemble the components in the same way.
regarding the impact of configuration we experimentally choose the best configurations for all the baseline approaches.
for deeptralog we experimentallyinvestigatethe impactofsomekeyparameterson its effectiveness and report the results.
the normal and anomalous traces in our dataset are generated by automatically executing the normalandfaultyversionsofthebenchmarksystemrespectively.itisthuspossiblethatthenormaltracesmayincludelatentanomalies.
toalleviatethethreat wecarefullytesttheinvolvedscenariosof thenormalversionbeforeexecutionandmanuallycheckthequality of a set of sampled traces after execution.
the threats to the external validity mainly lie in the benchmark system and fault cases.
our approach is only evaluated on trainticket and its fault cases.
it is unclear whether it can be effectively used formore complex industrial microservicesystems and fault cases.
these threats are alleviated from two aspects.
first the dataset we construct includes complex traces including about eventsandinvolvingparallelandasynchronousserviceinvocations.
typicallyatraceinindustrialmicroservicesystemsinvolvesdozens ofserviceinvocationsandhundredsoflogevents.therefore the sizeoftraceiscomparable.second thefaultcasesoftrainticket arereplicatedfromrealfaultsinindustrialsystemsandcoverdifferent types of typical faults .
therefore the fault cases used in the evaluation are representative.
related work traditional software anomaly detection approaches are mainly based on logs .
typically log anomaly detectionconsistsoftwostages.first itextractslogeventsfrom log messages via log parsing.
widely used log parsing approaches includedrain andspell .second itconductsanomalydetectiononlogeventsequences.earlystudiesusenumericvectorsto representlogsequences whichareusuallygenerated bycounting thenumbersofvariouslogeventinlogsequences.louetal.
propose an approach that mines the invariant relationships among authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeptralog trace log combined microservice anomaly detection through graph based deep learning icse may pittsburgh pa usa log events for anomaly detection.
xu et al.
use principal componentanalysis pca todetectloganomalies.linetal.
use the hierarchical clustering technique to identify log anomalies and he et al.
extend their work by identifying the correlations between logs and system metrics.
recently therearesomeapproachesusingdeeplearningtodetect log anomalies.
du et al.
propose a log anomaly detection approachcalleddeeplog whichdetectsanomaliesbypredicting the next log event using lstm.
similarily meng et al.
propose a log anomaly detection approach called loganomaly.
it combines semanticvectorsproducedbywordembeddingandnumericvectors for the prediction of the next log event using lstm.
zhang et al.
alsousesemanticvectorstorepresentlogeventsanduse bilstm to detect anomalies of the whole log sequence in an supervised manner.
yang et al.
extend to a semi supervised approach which estimates the labels of log sequences using pu learning.
these log anomaly detection approaches are based onsequence representations of log events thus cannot well detect anomalous traces that involve complex structures.
inmicroservicesystems tracesarewidelyusedinanomalydetectionandrootcauseanalysis .traditional approaches rely on the visualization of traces to support manual trace analysis.
zhou et al.
conduct an empirical study onindustrialpracticesofmicroservicefaultanalysisanddebuggingandproposeanimprovedtracevisualizationmethod.guoetal.
presentan approachthatuses traceaggregationandvisualization to help the analysis of error propagation chains.
recently someresearchersproposeautomatedapproachesfor trace anomaly detection.
zhou et al.
propose a supervised approach to detect anomalous traces based on a set of featuresextracted from traces.
it relies on fault injection to produce alarge number of normal and anomalous traces for training and asetofpredefinedtracefeaturesextractedfromdifferentaspects.
other approaches detect various types of anomalies by learning patterns from the traces produced by normal execution .
nedelkoskietal.
detectresponsetimeanomaliesinmicroservicesystemsbytraininganauto encodingvariationalbayesmodel.
nedelkoski et al.
represent each trace as a span sequence and a response time sequence and design a multimodal lstm modelto detect anomalous traces.
liu et al.
use a service trace vector to represent each trace which treats each possible path as a dimensioninthevector.thesetraceanomalydetectionapproaches do not consider logs.
moreover they usually represent a trace as a sequence and do not consider the complex structures of traces.
conclusion inthispaper wehaveproposeddeeptralog adeeplearningbased microserviceanomalydetectionapproach.itusesaunifiedgraphrepresentationtodepictthecomplexstructureofatracetogether withlogeventsembeddedinthestructure.basedontherepresentationwedesignaggnnsbaseddeepsvddmodelwhichcanlearnalatentrepresentationforeachtraceandaminimizeddata enclosing hypersphere.weusethemodeltodetectanomaloustracesbycalculating their distancesto the center of thehypersphere.
we have evaluateddeeptralogonamicroservicebenchmark.theresults showthatdeeptralogsignificantlyoutperformsstate of the arttrace loganomalydetectionapproaches.ourfutureworkwillextenddeeptralogtosupportmoredifferentkindsofanomaliesof microservice systems such as response time anomalies and on the otherhandevaluatedeeptralogwithdifferentkindsofmicroservice systems.
data availability all the data and results of the work can be found in our replication package .