design bycontract for deep learningapis shibbir ahmed shibbir iastate.edu iowa stateuniversity usasayem mohammad imtiaz sayem iastate.edu iowa stateuniversity usasamantha syedakhairunnesa skhairunnesa fsmail.bradley.edu bradley university usa brenodantascruz bdantasc iastate.edu iowa stateuniversity usahridesh rajan hridesh iastate.edu iowa stateuniversity usa abstract deeplearning dl techniquesareincreasinglybeingincorporated incriticalsoftwaresystemstoday.dlsoftwareisbuggytoo.recent workinsehascharacterizedthesebugs studiedfixpatterns and proposed detection and localization strategies.
in this work we introduceapreventativemeasure.weproposedesignbycontract for dl libraries dl contract for short to document the properties ofdllibrariesandprovidedeveloperswithamechanismtoidentify bugsduringdevelopment.while dlcontract buildsonthetraditional design by contract techniques we need to address unique challenges.
in particular we need to document properties of the trainingprocessthatarenotvisibleatthefunctionalinterfaceof thedllibraries.tosolvetheseproblems wehaveintroducedmechanisms that allow developers to specify properties of the model architecture data and training process.
we have designed and implemented dlcontract forpython baseddllibrariesandusedit to document the properties of keras a well known dl library.
we evaluatedlcontract intermsofeffectiveness runtimeoverhead and usability.
to evaluate the utility of dl contract we have developed sample contracts specificallyfor training problemsand structuralbugs.wehaveadoptedfourwell vettedbenchmarksfrom priorworksondlbugdetectionandrepair.fortheeffectiveness dlcontract correctlydetects259bugsin272real worldbuggyprograms fromwell vettedbenchmarks providedinprior workondl bug detection and repair.
we found that the dl contract overhead isfairlyminimalfortheusedbenchmarks.lastly toevaluatethe usability we conductedasurvey oftwenty participantswhohave useddl contract to find and fix bugs.
the results reveal that dl contract can be very helpful to dl application developers when debuggingtheircode.
ccsconcepts softwareanditsengineering specificationlanguages computing methodologies machine learning .
esec fse december san francisco ca usa copyright heldby theowner author s .
acm isbn .
deeplearning api contracts specification language acm reference format shibbir ahmed sayem mohammad imtiaz samanthasyeda khairunnesa breno dantas cruz and hridesh rajan.
.
design by contract for deep learning apis.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december3 sanfrancisco ca usa.
acm newyork ny usa 13pages.
introduction deep learning is a popular tool for solvingcomplex software development problems such as nlp and vision but research has shown thatdeeplearningmodelsalsohaveuniquebugs .to address this se researchers have focused on detecting and localizingthesebugs .
in thiswork we explore analternative approachtoimprovethereliabilityofdeeplearningsoftware design by contract dbc .
traditional dbc provides supportforwritingpreconditionsandpostconditionsatapis.however prior work does not provide mechanisms for documenting properties of the model architecture data and training process whicharecrucialforapplyingdbctodeeplearningapis.recent researchhasproposedtechniquesforinferringtheseproperties but dbc aims toprovidespecification mechanisms for programmers.
we propose a dbc methodology for deep learning libraries calleddlcontract .itexposesmeta levelpropertiesofthedltrainingprocessandmodelstructureasvariables called mlvariable for useinwritingcontracts.unlikegrey boxcontracts thatexpose partoftheprogram mlvariable providesahigher levelabstraction of the training process and model structure.
they are similar to specification onlyfields inobject oriented programs but abstract away from the details of the dl model.
we have developed dl contract for python and a runtime assertion checking framework for dl contract .
we have applied contracts to key api methods of the keraslibrary and evaluated them using four benchmarks for deep learning bug detection from prior works comprising272 kerascodes.ourresultsshow that thekeraslibrary with contracts can identify of such bugs duringruntimechecking.additionally wehaveevaluatedtheannotation overhead of dl contract and found it to be zero for users of dllibraries.thismeansthatusersdonotneedtoaddanycontract annotationstotheircodeinordertobenefitfromourapproach.we havealsoadded15contractstothemodelcompilationandtraining thiswork islicensedunderacreativecommonsattribution4.0international license.
esec fse december3 san francisco ca usa shibbirahmed sayem mohammad imtiaz samantha syeda khairunnesa breno dantas cruz andhrideshrajan xjj rgh zlwk srru uhvxow 7udlqlqj ffxudf rqwudfw dqqrwdwhg .hudv oleudu rxu prgho vwloo kdv wudlqlqj sureohpv h sorgh duh vwloo h lvw rx fdq wu rwkhu vroxwlrqv 8vh khbxqlirup dv wkh nhuq ho lqlwldol hu 8vlqj wdqk dfwlydwlrq lq hdfk od huv dfwl ydwlrq 8vh dwfk1rupdol dwlrq od huv diwhu hdfk hqvh od huv l q wkh prgho vhfrqgv 1hxud lqw hduqhu !
odvw od hu dfwlydwlrq lv uhtxluhg wr wudqviru p orjlwv lqwr suredelolwlhv iru fodvvlilfdwlrq sureohp plvvlqj vl jprlg rvv vkrxog eh fruuhfwo ghilqhg frqqhfwhg wr od hu dffrugl qj wr lqsxw frqglwlrqv l h vkdsh dqg w sh srvwbdfwlydwlrq vhfrqgv dwfk od hu uuru lq howd hljkwv whuplqdwlqj wudlqlqj vhfrqgv 6wdwh ri wkh duw ghexjjlqj wrrov srfk v pv vwhs orvv dffxudf ydoborvv ydob dffxudf vhfrqgv.hudv zlwkrxw dq ghexjjlqj wrrov hhs rfdol h rqwudfw 9lrodwlrq frpsloh dfwlydwlrqbixqfwlrq iru pxowlfod vv vkrxog qrw eh uhox rqwudfw 9lrodwlrq frpsloh dfwlydwlrqbixqfwlrq iru pxowlfodv v vkrxog eh vriwpd orvv vkrxog eh fdwhjrul fdobfurvvhqwurs rqwudfw 9lrodwlrq iru 6htxhqwldo ilw gdwd vkrxog eh qrupdol hg wudlqlqj gdwd vkrxog qrw eh zlwklq dqg vhfrqgv dwfk od hu uuru lq howd hljkwv whuplqdwlqj wudlqlqj kdqjh wkh dfwlydwlrq ixqfwlrq dw od hu vhfrqgv hhs ldjqrvlv ulwlfdo 0lvvlqj 6riwpd od hu ehiruh orvv!
duqlqj dvw p rgho od hu kdv qrqolqhdu dfwlydwlrq!
vhfrqgv figure1 buggycode achieves .
trainingaccuracy.
similarcorrectcode achieves trainingaccuracy.
methodsofthe kerasapiandevaluated257correctprograms finding false positives due to the randomness effect during training.
toevaluatethe usabilityofthecontract enabled keraslibrary we conducted a user study with participants with varying levels of expertiseindlapplicationdevelopment.wefoundthat dlcontractenabledkerasis veryhelpful to developers in debugging dl software.
also writing dl contract and integrating dl contract withkerasisaneasierprocessfortheapidesigners.ourevaluation also shows that the runtime overhead of checking contracts is fairlyminimal.weobtainedthattheruntimeoverheadincreasesby around compared to the baseline.
dl contract can be disabled duringproduction to result inzerooverhead.
our contributionsare as follows anovelmethodologyforwritingandcheckingcontractsfor deeplearninglibrariesbyspecifyingdlapiswithpreconditions andpostconditions.
aframework thatisextensibleandgeneralizedtodifferent classes of dl bugs and maps contract violation as a bug symptoms as the constraint to check and contract violation messagesas suggestionsto fixbugs.
thenotionofspecifyingdl specificcontractsbyabstracting thedlmodelarchitecture itsdataproperties andtraining behavior.
a collection of contracts that prevents prevalent training problems andstructuralbugsindl programs.
an annotated version of keraswith the dl contract as a virtual environment keras .
developers can use this kerasenvironment for debugging without any annotation overheadandminimal runtimeoverhead .
motivation to highlight the difficulty in specifying deep learning apis and the need for dl contract consider a simple convolutional neural network cnn code shown in fig.
.
this code is intended for digit classification when implemented correctly as outlined in the kerasdocumentation it achieves training accuracy on themnistdataset.inthecorrectversion imagesarenormalized to the range before being processed by a sequential model with a specific layer architecture.
the model is configured using thecompile api and trained using the fitapi and the evaluate api isusedto calculatethe lossandaccuracy.
however as shown in fig.
the code snippet contains three bugs on lines and which result in low accuracy and high training time.
these bugs are specific to dl programs andmaynotcausecrashes.forexample online19 theincorrect activation function relu is used in the last layer of the dense api .
additionally on line the incorrect loss function of binary crossentropy isappliedinthe compile api .lastly on lines and the data is not normalized before being fed into thefitapi .
this example also illustrates another challenge for specifying dl apis.
all dl apis work on a shared dl model where early apisconstructthemodelandlaterapis suchas fit compile and evaluate make use of it.
to write pre postconditions for dl apis havingaccesstoonlytheformalparametersandreturnvaluesof theapisisnotsufficient.correctusagedependsonthemodelstate at the point of the api call.
dl contract addresses these challenges and canhelp preventsuch bugs byprovidingaclearspecification ofthe intendedbehaviorof deep learningapis.
95designby contract fordeep learning apis esec fse december3 san francisco ca usa deeplearningcontracts in thedl contract approach we abstract the data properties expected output model architecture and training behavior of a dnn model and specify the properties of dl apis connected via a computationgraph.wegatherandinspectnecessaryconditionsfrom three sources details in .
.
we filter out the obligations from the dl app developer as preconditions and expectations from dl softwareinas postconditions .here weuseanovelruntimeassertion check in dl computation.
in the contract checker modules firstparsethosecontractsandtranslatethemintotemplates.those templates are validated to handle the exception if it occurs.
if a contract is violated the user receives a contract violation message otherwise the api returns the normal execution output.
thus our proposedsolution generalizestootherbugsandmodel categories inthisway.itwouldbeeasyforlibrarydeveloperstospecifythe contracts for other types of bugs following these procedures of dl contract.
next wepresentthedesignandusageof dlcontract including examplesandour approach for abstractingdl relatedproperties.
.
writingdeeplearning contract dl contract uses an annotation based approach to add contractsto dlapis which allowslibrary developersto addcontractswithoutmodifyingcompilersandbuildtools.thismeansthat softwareusingdlapisdoesnotneedtobemodified.dllibrary developerscanadd preconditions thatmustbesatisfiedbeforethe api iscalled and postconditions that theapiguarantees tobe true uponcompletion.
.
.
syntax.
to use contracts in a deep learning library it is necessary to annotate the api with contract and new contract .
thisallowslibrarydeveloperstocreateexpressionsforchecking specified contracts.
dl contract can check types such as tensors andmodelobjects aswellassimpledatatypeslikestrings floats numbers arrays and booleans.
it utilizes logical operators like and andor andallowsforarithmeticandcomparisonexpressions.additionally dlcontract canbeusedtocheckconstraints ofvariousmodelpropertiesduringtraining andabstraction.
.
.
illustrative example.
to create a contract a library developer annotates a dl api using contract and new contract .
inside contract the developer defines types and functions for checking contracts.
using new contract the developer writes functions for performing computations necessary for a contract andforcheckingpreconditionsandpostconditions.forinstance in example .
a contract is imposed as a precondition on the kerastraining function fitto ensure that data is within a specifiedrangebeforetraining.topreventthistypeofbug afunction data normalization isdeclaredasacontractdefinitionusingthe contract annotation line using the parameter x. inside the contract annotation in the data normalization function line thedeveloperfurthercomputestogettherangeoftrainingdata declared as normalization interval as aml variable line .
thedevelopercanspecifytheappropriaterangeofthe mlvariable withinthe contract checker function.
the condition ischecked on line and if the contract is violated a suggestion to fix the issue is raisedonline7.
new contract 2defdata normalization x 3normalization interval np.max x np.min x 4if normalization interval .
msg data should be normalized before training train and test data should be divided by value str np.max x raisecontractexception msg contract x data normalization 9deffit self x none y none ... example .
acontract on fitapiinside keraslibrary whenabuggydlprogrammakesuseofthisannotatedapi dl contractwillthrowthe following error.
contractviolated data should be normalized before training train and test data should be divided by value .
.
example .2illustratestheuseof dlcontract topreventoverfittingbugs inwhichamodelhas hightraining accuracybut low test accuracy.
a contract is specified on the validation loss and traininglosstocheckforincreasingdifferencesinvalidationloss anddecreasingdifferencesintrainingloss whichisacommon causeofoverfitting.thisexpectationisencodedasapostcondition.
new contract 2defoverfitting history 3i 4whilei len history.epoch epochno i diff loss history history diff val loss history history i if diff val loss .
if diff loss .
msg after epoch str epochno diff val loss str .4f diff val loss anddiff loss str .4f diff loss causes overfitting raisecontractexception msg contract returns overfitting 17deffit self x none y none ... return self.history example .
overfitting contracton fitapi to prevent overfitting a contract can be added to the output ofthefitmethodin kerasusing contract andapostcondition can be checked using the overfitting function specified with returns line .
in this function the contract writer uses the obtained history object to compute diff loss anddiff val loss line and checks if the difference between validation loss of consecutive epochs tends to increase while the difference between training loss continues to decrease.
if this condition is not met a contract violation message is thrown and when a buggy dl program usesthis annotated api dl contract will throwan error.
contractviolated after epoch diff val loss .
and diff loss .
causes overfitting.
.
dl contract approach next we present our approach and describe the technical challengesindlcontractchecking suchastheneedforcontext aware mlvariable .
.
assertiontechniques .
.
andsupportfor contracts across multiple apis in the ml pipeline .
.
.
also we discussourtechnique ssupportforpost trainingcontractchecking .
.
.
.
.
abstractionofdl specificpropertiestocontracts.
toenforce dbctechniquefordeeplearningapis amechanismisneededto capturemodelabstraction dataproperties andtrainingbehavior beyondjusttheformalparametersandreturnvaluesofthedlapis.
standardcontractsonlyenforceconstraintsonthevaluesofformal 96esec fse december3 san francisco ca usa shibbirahmed sayem mohammad imtiaz samantha syeda khairunnesa breno dantas cruz andhrideshrajan parameters and return values of an api method or attributes of an api class.
additionally machine learning apis are not isolated but connected through a computational graph .
therefore specifying contracts on one api with its formal parameters alone is not sufficient inthe dl specific settings.
fig.2describesascenarioinwhichthedeveloperwantstoadda contracttothemethod densetoensurethattheactivationfunction for the last layer is not relu .
additionally the developer wants tochecktheappropriatelossfunctionparameterforthe compile api fig.
.
the problem with this scenario is that the conventional designbycontract dbc techniquecannotspecifythiscontracton amodel sapiwithoutcausingfalsealarmsincorrectcodesbecause itonly allowsfor checking contracts oneachapi ofamodel.
to solve such problem we design a way to write dl contract using functions that allows to compute subset of meta information withmlvariable abstractingmodelarchitecture dataproperties training behavior.
fig.
2shows one way to solve this challenge usingdl contract .
in this solution activation andloss func are computed in specified new contract contract checker functionswhere activation istheparameteroflastlayer denseapi andloss func istheparameterof compileapi.thisishow dl contractmechanismenablesspecifyingandcheckingcontractwith abstractedmodelpropertieswhich worksonanystageofcomputationgraph pipeline.
.
.
dl contract runtime assertion technique.
a model is more than what the configuration script defines.
many properties of the modelonlybecometractableduringtraining.asaresult a dlcontractmust enable a runtime assertion technique that allows enforcingcontractsbeyondformalparameters unliketraditionalcontract checkers.
furthermore it must be possible to impose contracts on differentpipelinestagesofthemodeling i.e.
datapreprocessing duringmodelbuilding andtraining etc.tothatend wepropose adl contract checker with such capabilities by enabling library developers to annotate apis.
eventually dl contract annotations benefitend userstochecktheirmodel dataproperties andtraining behaviorat differentstagesinthe dl pipeline.
ourmethodoutlinedinalgorithm 1showsthestepsinvolvedin parsing and checking contracts in a library.
it consists of two steps registeringnewcontractsdefinedbythelibrarydeveloperandparsingandvalidatingnewlydefinedcontractsappliedtothefunctions definedbythelibrarydeveloper.theframeworkinspectsthelibrary codebasetofindcustomuser definedcontractsdefinedasfunctions withthe new contract annotation.theusageof new contract onafunctioninvokesthe register new contract method which storesareferencetothefunctioninadictionary.thiswayofannotating contracts allows writing contracts using abstracted dl properties as discussed in section .
.
.
for instance if a library developer writes a contract with any of the properties of u1d45a u1d45c u1d451 u1d452 u1d459 objectandchecksasapreconditionbeforemodelcompilationor before model training our technique allows that in this way moredetailsinexample .
whichisdifferentthanthetraditional way of writing contract.
the contract checker method is used to intercept and validate such contracts applied to user defined functions with the contract annotation before the function is executed.themethodparsestheannotationreference obtainsaalgorithm1 dl contract checker procedure contract checker userfref annoteref fargs u1d453 u1d45c u1d45f u1d45a u1d44e u1d459 u1d44e u1d45f u1d454 u1d462 u1d45a u1d452 u1d45b u1d461 u1d460 u1d462 u1d460 u1d452 u1d45f u1d439 u1d445 u1d452 u1d453 argcontrdict u1d45d u1d44e u1d45f u1d460 u1d452 u1d450 u1d45c u1d45b u1d461 u1d45f u1d44e u1d450 u1d461 u1d44e u1d45b u1d45b u1d45c u1d461 u1d44e u1d461 u1d452 u1d445 u1d452 u1d453 for each farg cond inargcontrdict do aarg u1d44e u1d450 u1d461 u1d462 u1d44e u1d459 u1d44e u1d45f u1d454 u1d462 u1d45a u1d452 u1d45b u1d461 u1d460 farg userfref template u1d45d u1d44e u1d45f u1d460 u1d452 u1d461 u1d452 u1d45a u1d45d u1d459 u1d44e u1d461 u1d452 cond template.
u1d450h u1d452 u1d450 u1d458 u1d450 u1d45c u1d45b u1d461 u1d45f u1d44e u1d450 u1d461 aarg returncondition u1d45d u1d44e u1d45f u1d460 u1d452 u1d450 u1d45c u1d45b u1d461 u1d45f u1d44e u1d450 u1d461 annoteref aargs u1d44e u1d450 u1d461 u1d462 u1d44e u1d459 u1d44e u1d45f u1d454 u1d462 u1d45a u1d452 u1d45b u1d461 u1d460 userfref result u1d462 u1d460 u1d452 u1d45f u1d439 u1d445 u1d452 u1d453 aargs returntemplate u1d45d u1d44e u1d45f u1d460 u1d452 u1d461 u1d452 u1d45a u1d45d u1d459 u1d44e u1d461 u1d452 returncondition returntemplate .
u1d450h u1d452 u1d450 u1d458 u1d450 u1d45c u1d45b u1d461 u1d45f u1d44e u1d450 u1d461 result returnresult procedure register new contract funcref new contract identifier u1d454 u1d452 u1d461 u1d439 u1d462 u1d45b u1d450 u1d441 u1d44e u1d45a u1d452 funcref newcontregister funcref procedure parse template cond iflen cond 1then multiple conditions subclauses forc conddo subclauses u1d45d u1d44e u1d45f u1d460 u1d452 u1d461 u1d452 u1d45a u1d45d u1d459 u1d44e u1d461 u1d452 c returnand subclauses ifistype cond then if it is cond type returnchecktype cond ifcond u1d716newcontregister then if it is callable returncheckcallable newcontregister dictionaryofconditionsappliedtothefunction sarguments and validates the conditions using the visitor designpattern.
consideracontract contract loss str contract func .
it validates the loss function and the validation takes place inside a user defined contract contract func .
the contract body is storedinargcontrdict as loss str contract func .then it obtains the value for the argument loss.
the method parse template isusedtoobtainavalidationtreefortheconditionsby composing validation classes in algorithm .
in the example of losscontract an andclassisobtained witheachconditionasasubclause.ifthefirstcondition str issatisfied a checktype validation class is returned.
if the second condition is a user defined function acheckcallable validationclassisreturned.thecomposedvalidation tree is returned in a template variable.
each validation class implementsthemethod check contract .tovalidatethetemplate check contract isinvokedontherootvalidationclass whichis and.
if validation fails for any subclause andraises an exception.
theargumentonwhichacontractisimposedisvalidated.ifpreconditions are satisfied the postconditions are validated.
the returned result ofthe userfunction isvalidatedas per written contracts.
.
.
contextualized inter api call contracts.
the next challenge istoensurethat dlcontract canbewritteninvolvingmultipleapis atdifferentstagesofthedlpipeline.tosolvethisproblem dlcontractis designed to write multiple functions using new contract annotationsthattakeformalparametersacrossmultipledlapis.
forexample whenthenumberofthetargetclassis2 i.e.
binary classification theactivationfunctionofthelastlayershouldnot besoftmax orrelu which is a type of contract within the same denseapi and loss function should be binary crossentropy which is an inter argument contract with different apis i.e.
between last layer and compileapi .althoughthe best activationfunctionforhiddenlayersisrelu ifreluisused on the last layer it will set all the negative output to zero thus 97designby contract fordeep learning apis esec fse december3 san francisco ca usa compile loss binary crossentropy compile api has loss parameter computation graph for dl model compilationdl contract annotation using activation loss functions buggy dl code dense api has activation parameter figure dl contract approachusing activation andlossfunctions involving multiple apis indlcomputation graph algorithm2 checkcontract classcheckcontract procedure abstractcheck contract value endclass classcheckcallable checkcontract procedure init funcref callable funcref procedure check contract value ifcallable value u1d45f u1d44e u1d456 u1d460 u1d452 u1d451 u1d452 u1d465 u1d450 u1d452 u1d45d u1d461 u1d456 u1d45c u1d45b then raise u1d450 u1d45c u1d45b u1d461 u1d45f u1d44e u1d450 u1d461 u1d438 u1d465 u1d450 u1d452 u1d45d u1d461 u1d456 u1d45c u1d45b endclass classand checkcontract procedure init subclauses subclauses subclauses procedure check contract value forsc subclauses do ifsc.
u1d450h u1d452 u1d450 u1d458 u1d450 u1d45c u1d45b u1d461 u1d45f u1d44e u1d450 u1d461 value u1d45f u1d44e u1d456 u1d460 u1d452 u1d451 u1d452 u1d465 u1d450 u1d452 u1d45d u1d461 u1d456 u1d45c u1d45b then raise u1d450 u1d45c u1d45b u1d461 u1d45f u1d44e u1d450 u1d461 u1d438 u1d465 u1d450 u1d452 u1d45d u1d461 u1d456 u1d45c u1d45b endclass classchecktype checkcontract procedure init type expected type type procedure check contract value actual type u1d454 u1d452 u1d461 u1d434 u1d450 u1d461 u1d462 u1d44e u1d459 u1d447 u1d466.alt u1d45d u1d452 value ifactual type expected typethen raise u1d450 u1d45c u1d45b u1d461 u1d45f u1d44e u1d450 u1d461 u1d438 u1d465 u1d450 u1d452 u1d45d u1d461 u1d456 u1d45c u1d45b endclass leadingtoanaccuracyproblem.topreventsuchkindsofproblems in model architecture library developers can write dl contract usingtheactivationandlossfunctionforthebinaryandmulti class classificationaccordingtotheexperts suggestion .ourinsight isthatsuchtypesofcontractscanbeaddedtodeeplearningmodelcompilation api i.e.
kerascompile exposing objects capturing the entire modelproperties.
new contract 2defcontract checkerfunc1 model last layer output int str model.layers len model.l ayers .output shape .split .pop .strip activation func str model.layers .
getattribute activation .split if last layer output if activation func not in softmax msg1 for multiclass classification activation func should be softmax raisecontractexception msg1 new contract 13defcontract checkerfunc2 loss 14if lossnot in categorical crossentropy msg2 loss should be categorical crossentropy raisecontractexception msg2 contract self model contract checkerfunc1 contract loss str contract checkerfunc2 19defcompile self optimizer rmsprop loss none metrics none ... example .
last layer activation and loss function contract onkerascompile api example .3shows lastlayeractivationandlossfunction contract appliedto kerascompileapi whichassertsbefore compileapi execution.
here contract checker1 has been annotated with modelobject type on line and contract checker2 has been annotated using lossparameter with string type on line .
here last layer output andactivation func are computed on line 3andline5from modelobject.thelossfunctionhasbeenaformal parameterof compileapi and contract checkerfunc2 checks the condition on line and shows a message with suggestions to fix if a contract violation occurs for both denseandcompile apis.
as those specified contacts are anded one after another for one contract last layer activation and loss function contract checkerfunc2 is only executed if contract checkerfunc1 is executed.
since contract checkerfunc1 checks whether the number of classes then checkerfunc2 would also know if the programrunsamulticlassclassification.inexample .
onlines contract checkerfunc1 and contract checkerfunc2 have been enforcedtogether.
a caseof that contract violationisshown below contractviolated for multiclass classification activation func should be softmax loss should be categorical crossentropy.
98esec fse december3 san francisco ca usa shibbirahmed sayem mohammad imtiaz samantha syeda khairunnesa breno dantas cruz andhrideshrajan .
.
post training contracts.
the challenge of capturing dnn trainingbehavioratdifferentstagesofthedlpipelinecanbeaddressed with our proposed dl contract .
library developers can specifydesiredtrainingbehaviorfortheirdlsoftwarebyadding training relatedcontractsonpropertiessuchas gradientsrate gradientspercentageetc.trainingbehavior relatedpropertiesindicate the expected output from the dl model so this is a postcondition.
therootcausebehindatrainingproblemcouldbeclientobligation in hidden layers apis such as activation function which is a parameter of denseapi this is a precondition we might encounter suchtypesofpreconditionsandpostconditionsindl specificsettings and contracts can be specified using new contract and contract annotations in our proposed approach.
to handle such cases dlcontract advocatesspecifyingcontractsaspostconditions ondltrainingapis e.g.
kerasfitapi whichprovidesdetailed training history.
based on the supplied contract checking function in new contract wecomputerelevanttrainingpropertiesfrom thehistoryobjectsuchas validationaccuracy lossvalue gradient rateetc.
algorithm lines describes how we check and validatepostconditionsinourframework.example .2demonstrates this type ofpostconditioncontract.
evaluation in this section we aim to answer the following research questions rq1 effectiveness howeffectiveis dlcontract inreal world programs?
rq2 applicability isdl contract enabledkerasapplicabletofindperformance i.e.
lowaccuracy hightraining time bugs?
rq3 efficiency howefficientis dlcontract fordetecting dl performance bugsinterms ofprecision andrecall?
rq4 overhead whatistheoverhead ofthe dl contract comparedto relatedworks interms ofruntime?
rq5 usability how useful is the dl contract enabled kerasindevelopingdl apps?
first in order to evaluate our approach we collect contracts by following the procedure described in .
.
we implemented dl contract in .
using ourproposed approach in .
.thenwe conductedexperimentsusingthesetups in .
.finally wereport results andanalysis in .
.
.
deeplearning contractscollection in this section we describe the process of contract collection used intheevaluation.wehaveidentifiedcontractsrelatedtothemodel data andtrainingproperties.thesecontractspreventstructureand training bugs which lead to performance issues i.e.
low accuracy hightraining time .dllibrarieslike kerasdoesnot provideerror messagesforsuchtypesofbugsyet.fig.
3showshowwecollected theconditionsof dlcontract .
in1 weabstractthedataproperties expectedoutput modelarchitecture trainingbehaviorofadnn model.
in we gather and inspect necessary conditions from three sources.
we used the official keraslibrary documentation .
in particular we followed the selection criterion from dl bugs frompriorworks whilefocusingontheapisusedfor model compilation and training.
again we collected a list of stateof the art research articles and their benchmarks of buggy andtable collected contracts targeting dnn structural and logicalbugs improperdata and training problems classof bugs dlcontractdata bugsdatanormalization problem precondition normalization interval postcondition truestructuraland logic bugsincorrect activation and loss function regressionprecondition activation linear tanh loss func mse postcondition true incorrect activation and loss function binary classificationprecondition activation sigmoid loss func binary crossentropy postcondition true incorrect activation and loss function multiclass classificationprecondition activation softmax loss func categorical crossentropy postcondition true incorrect activation and loss function multilabelmulticlass classificationprecondition activation sigmoid loss func binary crossentropy postcondition true incorrect activation in hidden layersprecondition activation !
linear postcondition true incorrect hyperparameter precondition learn rate .
.
postcondition truetrainingproblemoverfitting precondition true postcondition diff val loss diff loss high validationaccuracy precondition true postcondition val acc threshold .
diff val acc train acc .
high dropoutrate precondition dropout rate .
dying relu precondition activation!
tanh exponential relu sigmoid postcondition zero gradients percentage u1d706 vanishing gradient precondition activation!
tanh exponential relu sigmoid postcondition gradients rate u1d6fd1 norm kernel u1d701 explodinggradient precondition activation!
tanh exponential relu sigmoid postcondition gradients rate eg u1d6fd2 gradient value!
nan oscillatingloss precondition true postcondition accuracy fluctuation rate u1d702 val acc diff u1d6ff slow convergence precondition true postcondition acc diff u1d6ff expected output model architecture gather inspect2api documentation research articles collected benchmark of buggy and correct dl programs training behavior variables conditions abstracted precondition obligations from dl app developerexpectation from dl software3 postcondition1data properties dl contract figure methodologyto collect deeplearning contracts correctdlprograms .theselectioncriterionforthese articles is that if the work in question solves dl performance bugs and renders the conditions that lead to these bugs.
we filter out the obligations from dl app developer as preconditions in3 and expectationfromdlsoftwareas postconditions in4 .thisprocess resulted in the collection of contracts.
a detailed table table with collected contracts with corresponding bugs are shared in the supplementary material .
.
implementation to implement dl contract we extended the open source package pycontracts .pycontracts allows developers to declare constraintsonmethodparametersandreturnvalues.wehaveextended pycontracts to support tensor model types as existing dl apis require additional preconditions and postconditions .
we have addressedallthe technical challenges describedin .
.
.
experimentalsetup to evaluate dl contract onkeras we modify the library by importingtheextended pycontracts packageinlibrarycodes.wealso decorate respective kerasapis with relevant implemented contracts that prevent performance bugs in .
.
we have conducted all the experiments on a machine with a ghz quad core intel corei7and32gb1867mhzddr3ramrunningthemacos11.
.
99designby contract fordeep learning apis esec fse december3 san francisco ca usa table effectiveness of dl contract inreal world programs targeting differentclass ofbugsusingcollected benchmarks deeplocalize umlaut autotrainer neuralintdl contracts targetingclass of bugsso ghcif fmnist blob circle mnist cif sogh contract violation improperdata data normalization problem incorrectactivation loss function incorrectactivation inhidden layers structural bugs incorrectlearningrate overfitting highvalidationaccuracy highdropout rate dying relu vanishing gradient exploding gradient oscillating loss 6trainingproblem slow convergence numbersrepresented totalcontract violations in realworldbuggy programsfrom deeplocalize umlaut autotrainer neuralint benchmarks so gh cif indicates benchmarkfrom stackoverflow github cifar 10respectively indicates contractsaresatisfied and did not trigger a violation in buggy programs.
table applicabilityof dl contract comparing against kerascallbacks deeplocalize anddl contract full table deeplocalizebuggycode correct code benchmark original tonnan es loss es accuracy union tonnan es deeplocalize dlcontract original dlcontract rt source rt rtbug rtbug rtbug rt bug rtbug rtbug rt rtoverhead stackoverflow .
.
.
.
.
.
.
.
.
.
github .
.
.
.
.
.
.
.
.
.
total detected bugs in buggy and correct codes kerasdebuggingterminateonnan tonnan earlystopping monitor loss es loss earlystopping monitor accuracy es accuracy table applicabilityof dl contract runtimecomparison between umlaut callback anddl contract benchmarkbuggy code correct code original umlaut dl contract original umlaut dl contract umlaut dl contract runtime bug runtime bug runtime runtime runtime runtime runtimeoverhead runtimeoverhead a1 cifar .
y .
y .
.
.
.
.
.
a2 cifar .
y .
y .
.
.
.
.
.
a3 cifar .
y .
y .
.
.
.
.
.
b1 cifar .
y .
y .
.
.
.
.
.
b2 cifar .
y .
y .
.
.
.
.
.
b3 cifar .
y .
y .
.
.
.
.
.
a1 f mnist .
y .
y .
.
.
.
.
.
a2 f mnist .
y .
y .
.
.
.
.
.
a3 f mnist .
y .
y .
.
.
.
.
.
b1 f mnist .
y .
y .
.
.
.
.
.
b2 f mnist .
y .
y .
.
.
.
.
.
b3 f mnist .
y .
y .
.
.
.
.
.
benchmark selection to answer the rqs we compare and contrastdl contract against four recently published dl performance bug localization benchmarks .
thedeeplocalize s benchmark proposed by wardat et al.
consists of executable kerascodes with buggy and correct versions of dl programs from stack overflow and github .
for the umlaut benchmark wefollowedtheirprocedure.autotrainer reportedtheirtool sresultson495dlprogramswhere262have training problems here we have utilized out of datasets which are comprised of sequential models.
neuralint utilized a total of63buggyprogramsofcrashandperformancebugs.wehaveused 16buggyprogramsfromthebenchmarkwhichdoesnotyieldcrash bugs.
we have considered all of these benchmarks as unseen because wehavenot seentheir buggyandcorrect programsbefore writing andimplementingcontracts.
metrics we recorded the total execution time utilization for all techniques when analyzing buggy and correct programs from the benchmarksandcomputedoverhead.also werecordedhowmany bugsweredetectedbyeachapproach.forcomputingtheefficiencyofdl contract we utilize performance metrics as precision recall following prior work .
we consider the benchmarks as ground truth for buggy and correct programs.
here a false positive indicates that a bug was detectedinthecorrectprogram.truepositiverepresentsifabugis detected in a buggy program.
a false negative indicates that there is no bug detected in a buggy program.
lastly if there is no bug detected in acorrectprogram we consider that asatrue negative.
we collectedthereal worldtimeelapsedbetweentheprogram entryandprogramexitusingthepythontimemodule.wecollected this information for both correct and buggy programs five times to reduce randomness following .
to isolate the other process and void interference in this experiment we executed only one programunderanalysisinastandaloneenvironmentinsidetheide.
westartrecordingthetimefromthebeginningofadlprogram untilthefirstcontractviolationhasbeenthrown andtherestofthe execution is halted in the buggy program.
for the correct program andifthereisnocontractviolation weobtainedtheelapsedtime until the complete executionof the program.
100esec fse december3 san francisco ca usa shibbirahmed sayem mohammad imtiaz samantha syeda khairunnesa breno dantas cruz andhrideshrajan .
results andanalysis .
.
rq1 effectiveness .
to demonstrate the effectiveness of dl contract in real worldprograms we have utilized 4benchmarks of dl performance bugs.table 2shows the results of dl contract targetingdifferentclassofbugs.
we have developed a totalof15 contractsand annotatedonmodelcompilationandtraining keras apisusing dlcontract approachtargetingdifferentclassesofbugs relatedtoimproperdata structuralbugs and trainingproblems.
in particular eachrowrepresentsthenumberofcontractviolations in buggy programswhere dl contract successfullydetectedbugs and terminated the program execution.
we observe that in the last contract violation column those contracts trigger a total of contract violation messages in buggy programs.
in table indicates contracts were used but did not trigger a violation for that class of bugs.
for example autotrainer mainly focuseson trainingproblems whichiswhythereisnocontractviolationinvolving structural and improper data related bugs.
those contracts postcondition violationshavebeentriggeredby dlcontract using abstracted trainingproperties.
deeplocalize umlaut neuralint benchmarks consist of structural and data bugs that precondition violationtriggersusing mlvariable relatedtomodelabstraction.
dlcontract didnotdetectbugsin13outof272programs.wehave investigated these undetected bugs and discussed in .
.
.
we also evaluated that the same contracts were used in correct programs in benchmarks.
we found contract violations as false positives mainlyduetorandomnessfactor duringtraining.
in summary dl contract is efficientin real world dl programs.
.
.
rq2 applicability .
table3 and6showtheapplicability ofdl contract on real world benchmarks comprising of performance bugs in dl software.
each table highlights and summarizes the results of buggy and correct programs.
table3shows the summary of the results of deploying thedeeplocalize benchmark.pleaserefertosupplementarymaterial formoredetails.table 3showsthat dlcontract candetect out of buggy programs with precise contract violation messages.outoftheseresults 29arefrom stackoverflow and9out fromgithub.also whencomparedwith kerasanddeeplocalize callbacks.
kerasdebugging techniques terminateonnan earlystopping monitor loss earlystopping monitor accuracy anddeeplocalizecan detect and respectively .
again out of were not detected from deeplocalize benchmark.
so52800582 and gh were missed because generalized contracts cannot be applied on weight initialization and optimizer.
finally regardingbugdetectionspeed dlcontract is200timesfasterthan deeplocalize and11 times fasterthan kerascallbacks.
table4shows that dl contract applies to all buggy programsfrom the umlaut benchmark.
in terms of computation overhead we observed dl contract has lower runtime than umlaut in .
.
.
lastly we have manually verified the contract breaches reported by dl contract and found no false alarms for buggy programs.
table5showsthat dlcontract hasdetected 195bugsin203 buggyprograms intheautotrainerbenchmark.while autotrainer reportsthesymptomsof5trainingproblems dlcontract detects bugs as postcondition violations.we observedthat both approaches detect the slow change in accuracy sc more often thantheotherfoursymptoms.8outof203buggyprogramsinautotrainer benchmarkwerenotdetectedduetotherandomness in dnn training.
in terms of runtime dl contract is slightly faster thanautotrainer .inparticular dlcontract takesonaverage .19seconds while autotrainer .43seconds.lastly outof 188correctprograms dlcontract misdetected3programs .
furtherinvestigationrevealedthatthosemisdetectionsweredue to data normalization issues unsupportedby autotrainer .
table6shows how dl contract performs on bugscompared totheneuralint tool.dlcontract detected13outof16bugs in theneuralint benchmark.3outof16fromthe neuralint benchmark were missed because we investigated that we had no layer properties related contracts written.
neuralint detects outof16bugsbut dlcontract requireslesstimethan neuralint .
inparticular dlcontract onaveragerequired5.10secondswhile neuralint9.80seconds.thesebuggyprogramsusecommonapi methods such as compile andfit which were annotated with dlcontracts.these272buggyprogramshavecommonrootcauses and symptoms.
for instance autotrainer benchmark consists of buggy programs with different training problems.
by writing contracts on the fit method targeting those problems dl contractdetects195outof203bugs.
insummary dlcontractis applicable to detect performance bugs in real worldbuggy programs withgood accuracy.
.
.
rq3 efficiency .
we have measured the efficiency of dl contract using benchmarks deeplocalize umlaut autotrainer neuralint in table .
we have evaluated257correct clean real worldprogramsandfound18false positives.
we have found fps in deeplocalize inumlaut inautotrainer and in neuralint benchmark.
in terms of efficiency ourevaluationresultsshowthat dlcontract hassimilar accuracy to umlaut tps and no fps but has lower time consumption in fig.
.
regarding the autotrainer benchmark dl contractcouldnotdetectbugsduetotheaccuracythreshold .
due to randomness factor during training.
regarding the neuralintbenchmark weobserved3fn.as dlcontract doesnothave contracts on layer properties yet.
compared to other tools using deeplocalize benchmark wefound deeplocalize autotrainer umlaut neuralint deepdiagnosis resultedin tpand22 6fnrespectively .deepdiagnosis reported fp and fn in correct codes from autotrainer benchmark.
in summary dl contract efficiently detects performance bugs in real world buggyprograms.
superiorityofdlcontract priorworkspecificallydeeplocalize umlaut autotrainer deepdiagnosis and neuralint are not comprehensive enough to detect differentclassesofstructuralandtrainingbugs.furthermore these approaches depend on specific implementations such as model format .h5 semantic change in model architecture and rely upon additional debugging or verification facilities e.g.
kerascallbacks deeplocalize umlaut autotrainer andgroovemodelchecker neuralint .
also deeplocalize umlaut neuralint didnot computefpandfn.
autotrainer computedfp fnonlywith autotrainer benchmark.
all baseline techniques did not compareagainstanyotherbenchmarksexcepttheirownbenchmarks.
deeplocalize invokescallbacksaftereachepochandcomputes 101designby contract fordeep learning apis esec fse december3 san francisco ca usa table applicabilityof dl contract runtime rt comparison with autotrainer at and dl contract dlc buggy correct benchmark at dlc original at dlcoverhead overhead datasetdetected symptoms postcondition violation at dlc vgegdrscol rtvgegdrscolrt rtsym rtviol rt runtime runtime blob .
.
.
.
.
.
.
circle .
.
.
.
.
.
.
cifar .
.
.
.
.
.
.
mnist .
.
.
.
.
.
.
total avg .
.
.
.
.
.
.
count vanishing gradient vg explodegradient eg dyingrelu dr slowchange in accuracy sc oscillatingloss ol symptom sym contract violation viol table applicabilityof dl contract runtimeoverheadcomparison with neuralint anddl contract benchmarkbuggy code correctcode original neuralint dlcontract original neuralint dlcontract runtimeoverhead runtimeoverhead runtime bug runtime bug runtime runtime runtime runtime neuralint dlcontract .
y .
y .
.
.
.
.
.
.
y .
y .
.
.
.
.
.
50079585 1 .
y .
y .
.
.
.
.
.
.
y .
y .
.
.
.
.
.
.
y .
y .
.
.
.
.
.
.
y .
y .
.
.
.
.
.
.
y .
n .
.
.
.
.
.
.
y .
y .
.
.
.
.
.
.
y .
y .
.
.
.
.
.
gh1 .
y .
y .
.
.
.
.
.
gh2 .
y .
n .
.
.
.
.
.
gh3 .
y .
y .
.
.
.
.
.
gh4 .
y .
n .
.
.
.
.
.
gh5 .
y .
y .
.
.
.
.
.
gh6 .
n .
y .
.
.
.
.
.
gh7 .
n .
y .
.
.
.
.
.
total average .
.
.
.
.
.
.
.
table7 dlcontract efficiencyondifferentbuggyandcorrect benchmarks dlcontract benchmark fptpfntnprecision recall deeplocalize .
.
umlaut .
.
autotrainer .
.
neuralint .
.
metrics to detect numeric bugs which take lots of time.
autotrainer requires the model in a specific format and needs tofinishthetrainingtodetectbugsandthenprovidesolutionsas fixes.inthecaseofumlaut withoutasemanticchangeof model the tool will report a false alarm.
neuralint requires graphcomputationfromthemodelandperformsstaticchecking withsomespecifiedruleswhichyieldalonger runtime.
.
.
rq4 overhead .
wehavecomputedtheruntimeoverhead ofdl contract usingumlaut deeplocalize neuralint andautotrainer benchmark.figure 4showstheruntimeoverheadof dl contract .dl contract dlc runtime overhead is lower than the one of all approaches.
in particular dl contract is .
.
.
and .
times more efficient in terms of runtime overhead thandeeplocalize umlaut autotrainer andneuralint .
the runtimeoverheadofdlcontractisminimalbecausethetechnique only checks model structure related preconditions before model compilationapiandtraining relatedpostconditionsbeforetraining.
unlike techniques deeplocalize umlaut autotrainer that rely on kerascallbacks dl contract does not invoke model dloc dlc um dlc at nl dlc dlc deeplocalize dloc benchmarkumlaut um benchmarkautotrainer at benchmarkneuralint nl benchmark00.
.
.
.
.
.
.5runtime overheadfigure comparisonofruntime overhead compilation or training apis multiple times to monitor metrics periodicallyduring orafter training.specifically neuralint requires graph computation from model and performs static checking with somespecified rules yieldinglonger runtime.
also we measured that the runtime overhead increases by around compared to the baseline keras.in summary dl contract incurs less runtime overheadcompared to existingdeep learning debuggingtools.
.
.
rq5 usability .
we have evaluated the usability of dl contractannotated kerasin terms of its usefulness to find and fix bugs while developing dl programs.
also we evaluate separately the efforts of api designers to write and integrate dl contract .
to that end weperformauserstudyfollowingirbguidelinesandcollected feedbackonusing dl contract annotated keras.
102esec fse december3 san francisco ca usa shibbirahmed sayem mohammad imtiaz samantha syeda khairunnesa breno dantas cruz andhrideshrajan rq5.
usefulness how useful is the dl contract enabled kerasindevelopingdl apps?
rq5.
easiness howeasyistowrite dlcontract andintegrateitwithdl library apis?
participants afterfollowingsimilarprocedure from priorworkwerecruited20participantsfromuniversitymailinglists forourstudy 17ph.d.
2msstudents andapost doc .participants were asked to self classify their level of expertise from beginner to5 expertandweobtainedtheirexpertiselevel programming u1d707 .
u1d70e .
debugging u1d707 .
u1d70e .
using existing neural networks u1d707 .
u1d70e .
and developing new dnns u1d707 .
u1d70e .
and developing other ml algorithms u1d707 .
u1d70e .
.
so the average mean u1d707 of the expertise levels is more than .
in allofthe selectedparticipants.
studydesign procedureandtasks participantscompleted anhour longonlinestudyontheirmachines.eachparticipantcompletedtwosessionswithcorrespondingtasks.aftereachsession participantscompletedsurveyquestionsonlineviaqualtrics.for rq5 in session we provided the necessary environment to execute buggy programs in regular keras baseline condition and dlcontract enabledkeras.weprovided3buggyversionsofrandomlychosenreal worldprogramswith3differentperformance bugs related to model architecture data properties and training behavior.thebuggyprogramshavelowaccuracyandhightraining time issues.
we asked the participants to execute the buggy programs using both regular kerasanddl contract enabledkeras.
then weaskedparticipantstodetectandfixthebuggyprograms by using the outputs from both regular kerasand dl contractenabledkeras.
finally we asked participants the survey questions regardingtheirexperienceusing dlcontract .forrq5 insession2 wefirstprovidetutorialtoparticipantsonhowtowritecontracts onkerasapi.
then we asked them to write similar contracts with instructions.
after completing the sessions participants filled up a survey indicating their experience while using dl contract enabledkerasto detect and fix bugs as a dl application developer.
inthatsurvey participantsalsosharedtheirexperienceaboutthe writingprocessof dlcontract asalibrarydeveloper.thedetails of the survey questions for session and session are provided in the supplementary material .
results and discussion rq5.
usefulness for all buggy programs in session none of the participants was able to find any of the bugs in the baseline condition regular keras .
that is becausekerasdoes not inform users about such types of performance bugs.
however participants were able to detect and fix the bugsbyfollowing dlcontract enabledkeras scontractviolation messages.furthermore surveyresponsesindicatethat dlcontract enabledkerashelpsparticipantstodetectandfixbugsefficiently.
in particular on a point likert scale questions not helpful to very helpful participants rated their experience on questions.
participants indicated that dl contract enabledkeraswas very helpfulto65 u1d707 .
u1d70e .
indetectingbugsindeeplearning programs that yield unexpected performance low accuracy high training time .
rated helpful rating and of participants rated reasonablyhelpful rating .
therefore of the participantsrespondedpositively rating regardingthiscriteria.
likewise ofparticipantsratedpositively rating aboutthe message from dl contract fixing those bugs u1d707 .
u1d70e .
.
q1 rate how dl contract enabled keras helped you to detect bugs in deep learning programs that yield unexpected performance low accuracy high training time q2 rate how well do the messages from dl contract enabled keras helped you to fix those bugs.
q3 rate how useful would dl contract enabled keras be to help you develop dl applications.q4 if you are involved in a class or research project that requires dnns rate how useful would dl contract enabled keras be for you.figure survey results with participants ratings on how usefulis dl contract enabled kerasindeveloping dlapps again oftheparticipantsrated positively rating specifically of the participants indicates that it would be very useful todevelopdlapplications u1d707 .
u1d70e .
.ifparticipantsare involved in a class orresearchproject that requires dnns rated positively especially of the participants rated dl contractenabledkerasas very helpful u1d707 .
u1d70e .
.
rq5.
easiness regarding how easy is to write dl contract on top ofkerasapis we have obtained that of the participants ratesthewritingprocessofacontractto keraspositively rating .
regarding the rating of the writing process of a contract tokeras the participants rating u1d707 .
u1d70e .
is moderate easy very easy as illustrated in fig.
.
about the integration of the written contract with keraslibrary of theparticipantsratedpositively u1d707 .
u1d70e .
.thedetailed breakdown rating of integration of the written contract with keras library the participants ratings is moderate easy very easy asshowninfig.
.insummary wehaveevaluatedthat dl contract enabled keras is very helpful to developers in debugging dl software and writing and integrating dl contract is very easy to api designers.
q5 rate how difficult it was to write a contract to dl contract enabled keras.q6 rate how difficult it was to integrate the written contract for keras library.
figure6 surveyresultswithparticipantsratingsonhoweasy isto write dl contract on dllibrary apis .
limitations our proposed dl contract approach has been evaluated primarilyonproblemsrelatedtomultilabel multiclass binaryclassification and regression with various structural and logical bugs in the sequentialdnnmodelarchitectureandcommontrainingissues.
further research is needed to apply and evaluate our approach for other types of bugs and model categories.
despite this the concept of using contracts in deep learning isnot limited to kerasand can 103designby contract fordeep learning apis esec fse december3 san francisco ca usa beextendedtootherdllibraries.whileourpaperillustratesthe ideaofdeeplearningcontractsfor keras ourcontributioncanbe generalized to other dl libraries like tensorflow pytorch.
we focused on kerasto keep the implementation effort manageable andleveragethis library s large body ofbenchmarks.
.
threatsto validity ourproposedapproachmaybeaffectedbyexternalthreats such asimprecisepreconditionandpostconditiondefinitionsobtained fromlibrarydocumentation stackoverflow posts andgithubcommits.however wehaveadopteddefinitionsfromrecentresearch studies tomitigatethis.thresholdparametersmayalso causefalsepositivesinsomenewreal worldprograms.additionally implementationusing pycontracts mayhaveunforeseeninternal threats butourgeneralopen sourceframeworkcanbeextended using reproduciblepackage withdetailedresults.
related work specification of deep neural networks the closest related ideasinthespecificationofdnnsinclude .while provides an overview of the opportunities and challenges of formalizing and reasoning about dnn properties it does not propose any methodology for writing and checking specifications for deep learning libraries.
in contrast presents a technique for computing input and layer properties from a feed forward network using input output characterizations as formal contracts.
additionally introduces a method for repairing neural network classifiersbyinferringthecorrectspecifications.both and proposeinferencetechniques whileourtechniqueproposesaspecificationandcheckingtechniquethatenablesthespecificationof dllibrariesandchecksthosecontractsinclientcodeusingthose libraries thuspreventingbugsandprovidingfixsuggestions.recently anempiricalstudy reportscategoriesofrequiredml contracts whichmayhelpdesigners ofcontract languages.
deep learning testing debugging and repairing prior work on dl testing debugging and repairing includes deeplocalize mode autotrainer deepdiagnosis deepfd ariadne lagouvardos nikanjam etal.
shapetracer and tensfa .
these approaches focus on detecting and localizing bugs but dl contract supports documentation of expected behavior.
while dl contract checker can also double as abug detection tool in the long term developers would alsobenefitfromthedocumentationandwritemorecorrectdlprograms.
empirical studies have motivated the need for dl bug repair but none propose a dbc methodology likedl contract .
existing dbc methodology existing dbc frameworks for python suchaspycontracts pylint andpyta donot have the capability to check contracts for properties of models and data ormonitortrainingbehaviorofdlmodels.theseframeworks donotaddressthetechnicalchallengesofcheckingcontractsbeyondapiparameters contractsinvolvingmultipleapisatdifferent stagesofthemlpipeline andcontractsonintermediateproperties tospecifydesiredtrainingbehavior.additionally dlcontract suse of runtime assertions is distinct from checking runtime properties such as interpreting statecharts .
to the best of our knowledge theconceptofapplyingdbcoverthedlcomputationalgraphand specifying dl specific contracts isnovel.
api misuse detection there have been some api misuse detection techniques such as which examines the usage of machinelearning ml cloudapisinopen sourceapplications.this work finds that many of these applications contain api misuses that degrade their functionality and performance leading to the developmentofautomatedcheckersforidentifyingsuchmisuses.
tacklesapimisuse apim bugsstaticallybysomerulesthat occurwhenpractitionersmisunderstandtheusageofdeeplearning apis.
such misusage leads to inconsistencies between the designed dlprogramandtheapi susageconditions potentiallyresulting inreducedeffectivenessorruntimeexceptions.existingapimisusedetectionmethodsmaynotbesuitableforcheckingcontracts written by library api designers that capture properties of models data andtrainingbehavioratvariousprogrampointsduringruntime.
to address this limitation our approach overcomes technical challenges associated with checking contracts beyond formal api parameters handlingcontractsinvolvingmultipleapisatdifferent stagesofthemlpipeline andspecifyingintermediateproperties for desiredtraining behavior.
conclusionsand futurework inthiswork weproposedanovelmethodforcheckingcontractsfor deeplearninglibrariesbyspecifyingdlapiswithpreconditions andpostconditions.ourapproachisextensibleandgeneralizable allowing for the abstraction of model architecture data properties andtrainingbehavior.wedeveloped15sampledlcontractstargeting common bugs and found they effectively prevented structural bugsandtrainingproblems.additionally ouruserstudyshowedthe usabilityof dlcontract whenappliedtothekeraslibrary.wehave submitted an api design proposal for its incorporation in future releases of keras.
possible future work includes static validation unittesting andinferringcontractsforadditionallibraries.with ongoingresearchondecomposingdnnintomodules weintendtowritecontractsfortheexpectedbehaviorofadnn module effectively.
we want to explore writing contracts to preventnonfunctionalbugssuchasfairnessbugs .wewould also like to extend our approach to prevent additional types of bugs in different stages of the ml pipeline .
we can adapt techniques for collecting contracts from mined models with improvedperformance interms of accuracyandtraining time.
data availability the replication packages and results are available in this repository that can be leveragedbyfurther research.