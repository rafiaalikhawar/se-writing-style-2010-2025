uncertainty aware transfer learning to evolve digital twins for industrial elevators qinghua xu simula research laboratory and university of oslo oslo norway qinghua simula.noshaukat ali simula research laboratory oslo norway shaukat simula.no tao yue simula research laboratory oslo norway tao simula.nomaite arratibel orona san sebastian spain marratibel orona group.com abstract digital twins are increasingly developed to support the development operation and maintenance of cyber physical systems such as industrial elevators.
however industrial elevators continuously evolve due to changes in physical installations introducing new software features updating existing ones and making changes due to regulations e.g.
enforcing restricted elevator capacity due to covid etc.
thus digital twin functionalities often built on neural network based models need to evolve themselves constantly to be synchronized with the industrial elevators.
such an evolution is preferred to be automated as manual evolution is timeconsuming and error prone.
moreover collecting sufficient data to re train neural network models of digital twins could be expensive or even infeasible.
to this end we propose uncertainty aware transfer learning enriched digital twins rise dt atransfer learning based approach capable of transferring knowledge about the waiting time prediction capability of a digital twin of an industrial elevator across different scenarios.
rise dt also leverages uncertainty quantification to further improve its effectiveness.
to evaluate rise dt we conducted experiments with versions of an elevator dispatching software from orona spain which are deployed in a software in the loop sil environment.
experiment results show that rise dt on average improves the mean squared error by .
and the utilization of uncertainty quantification further improves it by .
.
ccs concepts software and its engineering empirical software validation software evolution maintaining software embedded software .
keywords digital twin transfer learning uncertainty industrial elevators permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
reference format qinghua xu shaukat ali tao yue and maite arratibel.
.
uncertaintyaware transfer learning to evolve digital twins for industrial elevators.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
introduction elevators are commonly used in our daily lives especially in highrise buildings.
consequently their incorrect operations or poor performance affect user experiences to various extents and in extreme cases may compromise users safety .
to ensure robust and safe operations of elevator systems digital twin technologies dt are promising solutions .
el saddik defined a dt as a digital replica of a living or non living physical entity .
several researchers extend this concept and equip dts with neural network models .
however elevator systems are prone to changes continuously due to for instance the variability in physical installation conditions software updates and configurations caused by regulations performance enhancements etc .
therefore to maintain its evolution one of the key characteristics of dt technologies a dt has to evolve its own functionalities to be able to continuously keep synchronized with its counterpart i.e.
the industrial elevator .
such an evolution is expected to be automated because it is error prone and time consuming thus expensive to manually update the dt.
moreover it is well known that neural networks require a large amount of labeled training data to be effective however it is often expensive if feasible to collect sufficient data to re train neural network models of the dt due to its evolution.
thus there is an indispensable need for transferring knowledge gained in one operating scenario of an elevator to another for important dt functionalities built with neural network models.
to this end we propose rise dt a novel approach that utilizes transfer learning for evolving the passengers waiting time prediction capability of dts of industrial elevators across various elevator operating scenarios.
our industrial partner is orona1 a spanish company that manufactures elevators for different types of building configurations and setups.
data required for transfer learning were systematically collected via a software in the loop sil simulation setting of an esec fse november singapore singapore qinghua xu shaukat ali tao tue and maite arratibel industrial elevator dispatching software from orona and a commercial software elevate2.
elevate has been successfully applied in the literature for supporting validations of elevator systems .
to further improve the performance of transfer learning we also employ uncertainty quantification uq which was initially designed to evaluate the robustness of machine learning models .
current uq methods e.g.
bayesian methods or ensemble methods mostly quantify the uncertainty of either a dataset or a model itself.
researchers have also developed several open source uq tools such as uncertainty wizard and uncertainty toolbox .
especially uncertainty toolbox is a pytorch based tool which can be easily integrated into our pytorch based implementation of rise dt .
we therefore employ uncertainty toolbox to calculate the calibration and sharpness metrics for the purpose of selecting the most uncertain samples from the source dataset.
calibration demonstrates the consistency between the prediction distribution and the observation while sharpness shows the concentration of the prediction distribution .
however directly picking these samples from the source dataset leads to the missing of context information.
therefore we feed selected uncertain samples into a multi head attention module aiming at preserving context information in new sample vectors.
as previously said we evaluated rise dt with versions of an industrial dispatching software from orona in a sil setting enabled with elevate which simulates elevator hardware buildings etc.
we performed experiments on four different elevator scenarios and dispatchers.
results show that on average rise dt improves mean squared error mse by .
with transfer learning and the uq further improves its performance by .
.
our key contributions are that we propose a novel model rise dt which takes advantage of both neural networks and dts.
neural networks help us to learn complex patterns in elevator data while dts simulate the elevator in real time.
combining neural networks and dts allows rise dt to make accurate predictions in unforeseen situations e.g.
long waiting times for elevator passengers we mitigate the data scarcity problem of neural networks by introducing transfer learning.
transfer learning transfers knowledge across different elevator scenarios which differs in dispatching algorithms or traffic templates and we employ the uncertainty toolbox to perform uq for each data sample i.e.
properties for passengers such as destination and mass and a multi head attention mechanism for preserving context information i.e.
information of previous passengers.
we present the industrial context in section .
section introduces rise dt section describes experiment design and section presents results.
we present the related work in section and conclude the paper in section .
industrial context orona a spanish company develops various types of vertical transportation systems for buildings.
each building is typically installed with a set of elevators.
a dedicated controller controls the movements of an elevator.
all the controllers are linked to a component called traffic master with a dedicated software component called dispatcher deployed which is responsible for optimal scheduling the elevators by providing the best possible quality of service qos e.g.
the minimized average waiting time awt .
awt for instance tells how much on average passengers have to wait for an elevator in a given time period.
elevator installations vary from one building to another.
how the elevators are used i.e.
traffic also varies based on various parameters such as the building type time of the day and day of the week.
to be cost effective in supporting new installations new types of traffic of elevators and new versions of dispatchers dts of the elevators should adapt to such new changes timely.
thus it is needed to learn knowledge gained e.g.
from one installation to another installation one traffic type to another or one version of a dispatcher to another.
collecting operating data from physical elevators is expensive as physical data collection devices need to be set up.
so we collect data in a software in the loop sil setting with industrial dispatchers from orona situated in the commercial simulator elevate.
elevate allows you to create various operating scenarios via configuring building types passengers etc.
a notable feature is traffic template which simulates traffic of a specific elevator scenario.
for example thelunch peak template simulates traffic in an office building where passengers are taking elevators to go to the floor where the canteen is located.
in this paper we focus on predicting waiting times of passengers.
for convenience we first define the concept of elevator scenario .
an elevator scenario chas two parts an elevator dispatcher and its traffic template.
first an elevator dispatcher is usually deployed in practice in a particular setting such as a configured sil or real operation with particular settings e.g.
building setup .
the dispatcher schedules passenger calls of elevators by ensuring optimal qos e.g.
minimal waiting time and deals with various traffic patterns specified as traffic templates for sil.
such traffic templates correspond to the real passenger traffic in the real operation configuration.
data generated from any of these configurations can be used for the construction of a neural network based dt which consists of two components dt model dtm and dt capability dtc .
dtm is a live simulation of the elevator scenario while dtc is built with machine learning algorithms for specific tasks i.e.
predicting waiting time wtfor passengers in this context.
we aim to address three main challenges.
first like in any other domain the good performance of neural network models comes from training on sufficient labeled data in our case which is about elevator data with waiting time for each passenger.
however sufficient labeled data for certain elevator scenarios can be unavailable.
for example if we have a newly upgraded elevator dispatcher it is impossible to get operational data before it is actually deployed in the real environment.
our solution to this challenge is to transfer knowledge from other elevator scenarios with data ready to use.
second manually transferring knowledge across elevator scenarios requires significant time and expertise.
to do this transfer learning manually one needs to distill common knowledge shared among scenarios e.g.
passenger properties that potentially lead to unexpected long waiting time.
if this is successful expertise is required to apply this knowledge in the target scenario which is about building a new model for the target scenarios.
in comparison our solution is to develop a neural network based transfer learning architecture that can accomplish this transfer automatically.
1258uncertainty aware transfer learning to evolve digital twins for industrial elevators esec fse november singapore singapore third potential elevator scenarios that can be used as transfer learning sources are insufficient.
to make full use of transfer learning we expect source elevator scenarios to be abundant and preferably heterogeneous so that the final model can generalize well.
however this cannot be guaranteed in our case as we have limited elevator scenario data.
hence rise dt uses uq to select the most uncertain samples whose shannon entropy tends to be higher and thus contains more information which motivates us to take full advantage of these uncertain samples.
thus we perform uq to select most uncertain samples.
however elevator scenario samples are interdependent given their time series nature so selecting such samples without considering their dependencies could potentially lose context information.
to overcome this problem we employ a multi head attention module to preserve context information.
we use the output of attention module as new vectors for each sample.
in short we aim to improve the effectiveness of transfer learning with the help of uq and multi head attention.
approach the core of rise dt is transfer learning which transfers knowledge from one elevator scenario to another.
we use two types of transfer learning pretraining and domain adaptation.
accordingly we divide the training process of rise dt into two phases pretraining phase and fine tuning phase figure .
in both of the phases the model takes the elevator data as the input and performs transfer learning from source scenarios to target scenarios.
let s be the source elevator scenario and tbe the target elevator scenario.
the goal is to improve twith knowledge transferred from s. in the pretraining phase we first pretrain the original model ofrise dt with source elevator scenarios s1pre s2pre ... snpreand target elevator scenarios t1pre t2pre ... tnpre instead ofsandt.
in the fine tuning phase we perform transfer learning from stot with the pretrained rise dt .
figure overview of rise dt as shown in figure the design of rise dt mainly involves three main techniques dt transfer learning anduq and the overall process builds two separate dts for the source and target elevator scenarios.
for the source dt we first perform uqto select mostuncertain samples and feed them into the source dt.
we then usetransfer learning to train the target dt.
in the following subsections we provide details about dt in section .
followed by the use of transfer learning and uq in sections .
and .
.
figure architecture of rise dt .dtm dtc andwtdenote dt model dt capability and waiting time respectively.
.
digital twin as shown in figure rise dt s dt has two key components thedtm and the dtc.
the goal of the dtm is to simulate the real world elevator scenario by predicting generating passenger properties e.g.
destination weight while the dtc tries to predict waiting time with the input of both real world passenger properties and generated passenger properties from the dtm.
the generated passenger proprieties can provide the dtc with more information because these two types of inputs are different despite of the same format due to two main reasons discussed below.
first the dtm is trained with historical data while the dtc is trained with only real time data.
after training the parameters of the dtm converge at local optimal.
this process incorporates information of the historical data into these trained parameters and in turn passes to the generated passenger properties.
as a result using generated passenger properties as input introduces more information from the historical data into the dtc.
second the dtm simulates the elevator s behavior.
ideally it should accurately predict how the elevator should operate at any given time if it is in a normal state.
this process inevitably introduces a learning bias which induces the dtm to assume the elevator system is operating normally.
however the real passenger properties may lead to abnormality causing a discrepancy between 1259esec fse november singapore singapore qinghua xu shaukat ali tao tue and maite arratibel real and generated passenger properties.
therefore we argue that generated passenger properties focus on different aspects compared to real passenger properties.
the dtc takes both generated and real passenger properties as input and makes predictions based on their own features as well as the discrepancy between them.
given that elevator scenario data is in a time series form the literature has shown the superiority of sequence models for handling such data .
examples include recurrent neural networks rnns and gated recurrent unit networks grus .
we performed a preliminary analysis comparing rnn and gru with a subset of swat as the validation dataset and observed that gru outperforms rnn in predictive performance.
hence we employ grus in both the dtm and dtc to capture temporal characteristics of a scenario.
the gru based dtm simulates the real world operation of elevator scenarios by predicting generating passenger properties containing information about a passenger s loading unloading time weight capacity arrival floor destination floor etc.
such a generated profile along with real time elevator scenario data are fed into the gru based dtc component of rise dt which hence predicts waiting time for each passenger.
.
.
digital twin model.
dtms are often built as behavior models .
however considering that sequence models e.g.
gru have shown their successes in various domains we design our dtm as a gru based neural network.
this model consists of four layers the linear layer activation layer gru layer and prediction layer.
letutbe the passenger s property vector at time point t. linear layer transforms the passenger s property ut vector into hidden vectors xt .
in equation wandbare the weight matrix and bias vector.
xt wdtm ut bdtm activation layer applies the relu activation function to add nonlinearity on the hidden vectors as in equation .
xt relu xt gru layer introduces two types of gates into the dtm update gatezand reset gate r. letht rhbe the hidden state vector of gru andw u b are all weight matrices.
the update rules of gru are as follows zt g wzxt uzht bz rt g wrxt urht br ht h whxt uh rt ht bh ht zt ht zt ht prediction layer transforms the hidden vectors into the label space.
a single passenger has multiple properties.
we build a separate prediction layer for each property figure .
but they are trained at the same time in a multi task learning manner.
loading time prediction .
loading time denotes time needed for a passenger to get in an elevator.
predicting loading time as a regression task potentially leads to over fitting due to limited data volume.
we simplify this prediction by discretizing loading time into categories and convert this problem into a classification problem.
equation shows the linear prediction layer for loadingtime.wloading rh 10is the weight matrix.
loadingt wloadinght bloading unloading time prediction .
unloading time denotes time needed for a passenger to get off an elevator.
similar to loading time we also discretize unloading time into categories.
equation shows the linear prediction layer for unloading time.
wunloading rh is the weight matrix.
unloading t wunloadinght bunloading weight prediction .
similar to loading time prediction we convert this continuous prediction task into a less fine grained classification task with only category labels to avoid over fitting.
equation shows the linear prediction layer for passenger weight.
wweight rh 5is the weight matrix.
weightt wweightht bweight capacity prediction .
the capacity denotes passengers willingness to get in an elevator based on the percentage of the elevator occupied with passengers.
for example a passenger with a capacity value of .
will not enter when an elevator or more full.
to prevent over fitting we convert it into a category classification task.
equation shows the linear prediction layer for the passenger capacity.wcapacity rh 5is the weight matrix.
capacityt wcapacityht bcapacity arrival floor prediction .
the arrival floor denotes which floor a specific passenger arrives and makes a call.
this property is discrete by nature.
this prediction layer is designed as a ncategories classification problem where ndenotes the number of floors this building has.
equation shows the linear prediction layer for the arrival floor.
warrival rh nis the weight matrix.
arrivalt warrivalht barrival destination floor prediction .
the destination floor denotes the floor a specific passenger intends to go.
this property is also discrete and can been designed as a ncategories classification problem similar as the arrival floor prediction layer.
equation shows the linear prediction layer for the destination floor.
wdestination rh nis the weight matrix.
destination t wdestinationht bdestination combining all these properties we acquire complete passenger properties xtwith the help of the dtm.
then we feed xtalong with real time data into the dtc for the prediction of waiting time.
.
.
digital twin capability.
the dtc of rise dt predicts the waiting time of a passenger by employing gru.
as for the dtm the dt capability has four layers the linear activation gru and waiting time prediction layers.
linear layer concatenates the generated passenger profile vector xtand real time profile xtas an input vector ut rh then transforms it into the hidden space ut wdtc ut bdtc activation layer increases the dtc s non linearity with relu ut relu ut 1260uncertainty aware transfer learning to evolve digital twins for industrial elevators esec fse november singapore singapore gru layer captures temporal characteristics of elevator data and introduces updating rules in equation .
prediction layer makes predictions about waiting time for each passenger which is a continuous task.
.
uncertainty quantification dt section .
can potentially perform well with sufficient labeled data.
however we rarely have access to abundant labeled data from the target elevator scenario.
therefore rise dt has to learn from a source elevator scenario where data are not all valuable in terms of improving the prediction performance of rise dt in target scenario.
this inspires us to utilize uqfor selecting the most uncertain samples for transfer learning.
the overview of the uq component of rise dt is presented in figure which contains two types of modules uncertainty toolbox modules andmulti head attention modules .
uncertainty toolbox is a tool for predictive uq.
in rise dt we use it to calculate two metrics for each sample calibration cand sharpnesss.
we normalize these two metrics into the range of making the addition of these metrics feasible.
we define a new metricmas the weighted sum of these two metrics as shown in equation where is a hyperparameter.
m normalize c normalize s with this metric we can rank all the samples we have and select msamples with the highest uncertainty scores with equation u top multi head attention.
though with uq we identify high uncertain therefore most valuable samples in the source domain we cannot completely ignore other samples.
so will lose information about context and time.
therefore we use a multi head attention module to encode this information into sample vectors.
this attention module has two sub modules attention module and feed forward module.
attention module takes most uncertain samples u as the input and uses positional encoding to incorporate position information as shown in equation .
u u position encoding u we duplicate this vector into three identical vectors and perform a linear transformation on them.
the outputs of this transformation are uk uvanduq.ukanduvare for calculating the attention weight of each vector.
with this weight we then calculate a weighted sum of uq.
equation shows the calculation of attention.
attention weight uvut v uattention attention weightuv then a residual connection between the input vectors and the output of attention module is built as shown in equation .
uattention normalize u uattention feed forward module takes the output of attention module as its input and feeds it into a feed forward network equation .
u wattentionuattention battention ufeed relu u then a residual connection between the attention output and the feed forward output is built equation .
uout normalize uattention ufeed .
transfer learning with the encoded samples generated in section .
transfer learning transfers knowledge from the source elevator scenario to the target one by aligning vectors.
as shown in figure transfer learning calculates two types of losses marginal and conditional distribution loss which align data distributions and prediction distributions respectively.
reducing these two losses brings both the source and target vectors into an intermediate space which represents the common knowledge shared between the two elevator scenarios.
for marginal distribution loss we calculate the kl divergence of the output vectors from the gru layers of the source and target domains as shown in equation .
losskl usource ilogutarget i for conditional distribution loss we calculate the maximum mean discrepancy mmd of the prediction layer outputs from the source and target domains as shown in equation .
lossmmd nsns i 1us i ntnt i 1ut i tr umut these two losses are then summed as the final loss equation .
loss losskl lossmmd experiment design to evaluate rise dt we propose four research questions rqs as discussed in section .
followed by the introduction of the subject system employed section .
.
section .
presents the evaluation metrics and statistical tests used in this paper.
section .
discusses how we chose hyperparameters and about experiment execution.
.
research questions the four rqs are described in table .
rq1 evaluates if rise dt is effective in terms of transferring knowledge from a source traffic template to a target traffic template.
with rq2 we aim to see if rise dt is effective in handling cases in which we only have access to data generated with an earlier version of an industrial elevator dispatcher but need to learn a prediction model for the latest version of the dispatcher.
the application contexts of both rq1 and rq2 are commonly seen in the real world operation of elevators.
rq3 evaluates the effectiveness of introducing uq to rise dt i.e.
using uq to select uncertain samples from the source data and input them to transfer learning.
rq4 considers the practical usefulness ofrise dt by evaluating its time cost.
.
subject system the subject system is from orona who provided us with versions of an elevator dispatcher.
each version is considered as an individual dispatcher in the rest of the paper.
we deployed them in elevate which simulates the procedure of passengers arriving at 1261esec fse november singapore singapore qinghua xu shaukat ali tao tue and maite arratibel table experiment design scenarios rq metric type instance rq1 how effective isrise dt when transferring knowledge across scenarios with different traffic templates?mse upbest lunchbest lunchbest upbest1 rq2 how effective isrise dt when transferring knowledge across scenarios with different versions of an elevator dispatcher?mse upworse upbest lunchworse lunchbest10 rq3 is uq effective in transfer learning?mse upbest lunchbest lunchbest upbest upworse upbest lunchworse lunchbest11 rq4 isrise dt practically useful in terms of time cost?time upbest lunchbest lunchbest upbest upworse upbest lunchworse lunchbest11 floors making calls boarding arrived elevators making car calls and arriving destinations.
elevate provides interfaces that allow us to simulate various elevator scenarios.
we consider the following four elevator scenarios lunchbest orlunchworse denoting the scenario of the best or a worse elevator dispatcher operating during lunch peak 15pm 15pm while upbest orupworse denoting the best or a worse elevator dispatcher operating during up peak 30am 30am .
.
metrics and statistical tests .
.
mean squared error mse .
since rise dt predicts the waiting time for each passenger we employ mse a commonly used metric for regression prediction tasks which computes the average square of errors.
let ybe the vector of observed values and ybe the predicted value.
mse is defined as in equation .
mse nn i yi yi .
.
uncertainty.
to answer rq2 we need to calculate the uncertainty of each neural network model of the dt corresponding to each dispatcher with equation .
uncertainty dispatcheri n j 0mj n wheremjdenotes the uncertainty value for sample jas in equation .
the uncertainty of each sample is calculated based on the prediction distribution produced by the neural network model of the dt of each dispatcher.
hence the calculated sample uncertainty can also reflect the uncertainty of the dispatcher.
.
.
training time.
we used training time for the evaluation of cost.
to this end we consider two types of training time pretraining time and fine tuning time as rise dt has these two phases figure .
let sbe the source elevator scenario and tbe the target elevator scenario for transfer learning.
pretraining of rise dt is performed on nscenarios that do not include sandn.
we define convergence time for one transfer as in equation .
timeconvergence timeearly stopping end timestart in equation we calculate the pretraining time by summing the convergence time on each single transfer.
timepretrain n i 0timeconvergence si ti wheretimeearly stopping enddenotes the early stopping time point no improvement for consecutive epochs and timestart denotes the starting time point of training.
equation defines the finetuning time as convergence time on source sand targett.
timefinetune timeconvergence s t .
.
statistical testing.
to deal with randomness in neural network training we repeat each experiment times and perform the mann whitney u test to study the statistical significance of the improvements.
we test all the pair wise comparisons method aandmethod b in each rq.
the null hypothesis is that there is no significant difference between the two methods.
if the null hypothesis is rejected we conclude that method a andmethod b are not equivalent.
furthermore we follow the suggestions in and choose the vargha and delaney s a12 as the effect size.
a12 shows the chances that method a will get better results than method b .
if a12 is greater than .
we can conclude that method a has a higher chance of getting better results than method b and vice versa.
we also use the spearman s rank correlation coefficient to evaluate the correlation between dispatcher uncertainty and mse section .
.
spearman correlation is a non parametric measure which is calculated with the rankings of two variables.
the correlation coefficient tends to be high if observations from the two variables have a similar rank relative position label and vice versa.
this value takes values between 1and1.
.
settings and execution manually assigning hyperparameter values can introduce bias.
to reduce such bias we performed a fold cross validation to select a best hyperparameters splitting the dataset into chunks sequentially with the first of them used for training and the last for validation.
as a result we set the weight of calibration and sharpness as .
the hidden size as and used the bidirectional layers gru in both of the dtm and dtc of rise dt .
the neural network layers were built with the pytorch framework .
the experiments were performed on one node from simula research laboratory s ex3 infrastructure with 2x intel xeon platinum 1x nvidia v100 gpus.
1262uncertainty aware transfer learning to evolve digital twins for industrial elevators esec fse november singapore singapore results and analyses in this section we provide results and analyses for answering each rq followed by the threats to validity.
.
rq1 transferring knowledge across scenarios with different traffic templates we compare rise dt with and without transfer learning in two setups from scenario upbest to lunchbest and from lunchbest to upbest.
we observe from table that transfer learning from upbest to lunchbest improves mse by .
.
.
whereas from lunchbest to upbest the mse improvement is .
.
.
.
the p values for both scenarios are smaller than 1e 3suggesting that rise dt with transfer learning is significantly better than rise dt without transfer learning in the context of transferring across traffic templates which we call traffic template variant transfer in short.
the a12 values show that rise dt with transfer learning has a higher probability of yielding better results than rise dt without transfer learning since both a12 values are less than .
.
furthermore with uq mse is further reduced see table for both scenarios.
the top two boxplots in figure show the mse distributions of the two traffic template variant transfers.
we observe that the distributions with transfer learning have less variance than those without transfer learning suggesting that with uq the transfer of knowledge seems more reliable.
conclusion rq1 we observe an improvement in terms of mse and a reduction of variance when comparing rise dt without and with traffic template variant transfer learning.
thus rise dt with transfer learning can effectively transfer knowledge across elevator dts built for different traffic templates.
table results for traffic template variant transfer learning for two scenarios rq1 .
w oandwdenote without and with.
upbest lunchbest lunchbest upbest mean p value a12 mean p value a12 w o transfer .
.
w transfer .
.
.
w uq .
.
.
.7e .
.
rq2 transferring knowledge across scenarios with different dispatchers table shows the results of transferring knowledge across scenarios with different dispatchers which we call dispatcher variant transfer learning in short.
we performed experiments on elevator scenarios with worse performance than our best dispatcher.
the third row in table presents the mse metric of rise dt on the uppeak .
and lunchpeak .
traffic templates of the best dispatcher.
we performed separate experiments transferring knowledge from worse performing dispatchers to the best one.
by so the best dispatcher can gain knowledge about worseperforming dispatchers specific cases that are rarely seen in their own scenario data.
we can observe from table that transfer learnfigure mse results in boxplots of the runs of the traffictemplate transfer learning rq1 and the dispatcher variant transfer learning the bottom two figures rq2 .
ing from all the dispatchers to the best one brings a reduction of mse with the uppeak traffic template by .
.
.
and lunchpeak traffic template by .
.
.
on average.
with uppeak transferring from dispatcher reaches the lowest mse as .
while transferring from dispatcher reaches the lowest mse as .
with lunchpeak.
statistical testing results for these dispatcher variant transfers show that most p values are smaller than 1e except for dispatcher with lunchpeak indicating that transfer learning from the worst performing dispatchers to the best one improves mse significantly.
most of the a12 results are also strong i.e.
much lower than .
.
one plausible explanation is because of the increased data volume.
more specifically with transfer learning rise dt takes advantage of data from elevator scenarios that are previously unavailable which as similar to data augmentation increases data volume and hence potentially improves the performance of deep neural networks .
moreover in our context best performing dispatchers refer to newer versions of dispatchers which does not necessarily mean that a best performing dispatcher has all the information of a worst performing dispatcher.
conclusion rq2 we observe an improvement of mse for both the uppeak and lunchpeak traffic templates when comparing rise dt with and without dispatcher variant transfer learning.
thus rise dt can effectively transfer knowledge across different elevator dts built corresponding to different dispatchers.
.
rq3 effectiveness of uq we evaluate the effectiveness of uq in both traffic template variant and dispatcher variant transfer learning.
from the last row of table we can observe that for traffic template variant transfer learning uq improves transfer learning from upbest to lunchbest by 1263esec fse november singapore singapore qinghua xu shaukat ali tao tue and maite arratibel .
.
.
and from lunchbest to upbest by .
.
.
respectively.
statistical test results show that both improvements are statistically significant with confidence level equal to p values smaller than 1e and strong a12 values being .
and .
respectively which are lower than .
.
table shows that uq generally improves dispatcher variant transfer learning on average by .
.
.
and .
.
.
for the uppeak and lunchpeak respectively.
transferring from dispatcher to our best dispatcher reaches the lowest mse as .
for uppeak while for lunchpeak dispatcher achieved the lowest mse.
the results are statistically significant for most of the cases except for dispatcher with lunchpeak.
this means that uq is effective in boosting transfer learning s performance in dispatchervariant transfer learning.
moreover the a12 values mostly are much lower than .
except for dispatcher with lunchpeak telling that rise dt with uq has a better chance of yielding better mse.
conclusion rq3 we observe significant improvement of mse hence the benefit of introducing uq to transfer learning across traffic templates and dispatchers.
table results for dispatcher variant transfer learning rq2 and rq3 .
the lowest values are highlighted in bold.
disp denotes dispatcher w oandwdenote without and with uq.
uppeak lunchpeak disp uq mse p value a12 mse p value a12 best w o .
.
1w o .
1e .
1e w .
1e .
.
3e .
2w o .
1e .
1e w .
1e .
.
1e 3w o .
1e .
1e w .
1e .
.
1e .
4w o .
1e .
1e w .
1e .
1e .
5w o .
1e .
.
.
w .
1e .
1e .
6w o .
1e .
.
1e w .
1e .
1e .
7w o .
1e .
1e w .
1e .
.
1e .
8w o .
1e .
1e w .
1e .
1e .
9w o .
1e .
1e w .
.
.
.
1e 10w o .
1e .
1e w .
1e .
1e averagew o .
.
w .
.
.
rq4 time cost we measure the time cost of the pretraining and fine tuning phases ofrise dt .
table shows results for the four transfers upbest to lunchbest and lunchbest to upbest for traffic template variant transfer learning and upworse to upbest and lunchworse to lunchbest for dispatcher variant transfer learning.the pretraining times for all the four transfers are between .
and .
hours which are practically acceptable considering that pretraining is performed only once.
in the fine tuning phase column w o transfer shows the time required to build the dt directly from elevator scenario data.
columns transfer andtransfer uq show the time spent on transferring knowledge of the dt with and without uq.
rise dt without transfer learning took the maximum of .
hours lunchbest upbest while rise dt with transfer learning but without uq took only .
hours in the worst case lunchworse lunchbest .
we argue that this reduction of time cost is due to the transferred knowledge from other elevator scenarios which helps rise dt find the optimal parameters faster compared to random initialization.
the time cost for transfer learning with uq is increased as applying it introduces a complex neural network module i.e.
the multi head attention module figure .
conclusion rq4 time cost of rise dt is practically acceptable and lower than time required for building dts from scratch i.e.
without using transfer learning.
thus deploying rise dt in real world is feasible in terms of time cost.
table results of time cost in hours rq4 pretraining fine tuning transfer time w o transfer w transfer transfer uq upbest lunchbest .3h .7h .2h .5h lunchbest upbest .4h .1h .2h .5h upworse upbest .5h .9h .1h .3h lunchworse lunchbest .1h .7h .4h .9h .
discussion transfer learning an effective mechanism to transfer knowledge across dts.
the results of rq1 and rq2 section .
and section .
showed that rise dt is effective on performing both traffic template variant and dispatcher variant transfer learning.
there are two main reasons.
first transfer learning introduces more data for training which to a certain extent alleviates over fitting in neural networks due to insufficient training data.
we have access to several elevator scenarios but each elevator scenario differs in either dispatcher or traffic template.
as a result this difference leads to discrepancies in elevator scenario data distribution.
directly training target rise dt with data from other elevator scenarios can cause a reduction of performance due to this discrepancy.
transfer learning elegantly tackles this challenge by aligning the source and target data distribution in an intermediate space section .
.
in particular we align the data by reducing both marginal and conditional loss which as a result generates a new set of vectors with minimal discrepancy between the source and target data.
these vectors identify the common knowledge shared between source and target data and thus complete the transfer learning.
second the source elevator scenario is different from the target elevator scenario but related therefore transfer learning can find common knowledge shared between them.
such common knowledge increases the generalization ability in our model as 1264uncertainty aware transfer learning to evolve digital twins for industrial elevators esec fse november singapore singapore figure correlations of mean mse and uncertainty learning from multiple sources of data prevents models from converging quickly on a single dataset .
uncertainty quantification uq an effective mechanism to improve the accuracy of knowledge transfer across dts.
the results of rq3 section .
show that uq further improves the effectiveness of transfer learning.
though uq was mainly developed to evaluate a model s robustness we use it to select the most uncertain samples since such samples contain important in terms of uncertainty information that can improve the effectiveness of transfer learning.
this idea is very similar to importance sampling in statistics which has been applied in deep learning for optimizing rnns cnns etc.
where weights are assigned based on the variance of each sample.
in the future in addition to uq we will investigate other importance sampling mechanisms to further enhance the effectiveness of transfer learning.
strong correlation between mse and uncertainty.
we noted that the mse values vary from dispatcher to dispatcher.
we make an assumption that this difference is correlated with dispatchers uncertainties.
to test the assumption we calculated the uncertainty for each dispatcher with equation and plotted the correlation in figure .
the spearman s correlation rank values for uppeak and lunchpeak are .
and .
respectively indicating a strong positive correlation between uncertainty and mse.
the p values are .
and .
which indicate that the correlations are statistically significant.
the grey areas in both figures present the confidence interval.
in both figures only two data points fall out of the grey area.
based on this result we can then recommend to calculate the uncertainty of a dispatcher with experimental data before its deployment which could potentially indicate its mse in operation and thus improve the safety and security of the elevator system at an early stage.
practical implications.
first our work is valuable for orona since the dts developed with rise dt can be used as a prior knowledge to test or assess a new dispatcher before deploying it in the real operation.
thus dts built with transferred knowledge will facilitate the evolution and maintenance of new dispatcher versions.
second transferring knowledge of dts for different elevator scenarios will reduce the development and maintenance cost of dts as our experiments also demonstrated.
third our results with uq provide evidence showing that uncertainty can affect the predictions made with dts thus the industry shall consider uncertainties explicitly during the design development and operation of elevator systems and their corresponding dts.
.
threats to validity we identify four key threats to the validity.
first our experiments were conducted on a simulator of elevator.
though the interfaces provided by this simulator allow us to choose from real industrial elevator dispatcher and elevator scenarios it is sil thus different from elevator systems operating in the real world.
however using elevate is the current practice of our industrial partner orona and sil is a common practice in many domains.
second we use transfer learning and uq.
for transfer learning we align data from the source and target elevator scenario.
for uq we use uncertainty toolbox.
we are aware that there are other methods and techniques that could accomplish transfer learning e.g.
bayesian methods and uq e.g.
uncertainty wizard .
in the future we will experiment with such techniques.
third we use only mse for evaluating the effectiveness of the waiting time prediction.
we choose this metric because this is a commonly used metric in regression prediction tasks.
however we are aware of other metrics such as root mean square error rmse and coefficient of determination r2score which will be investigated in the future.
fourth the core neural network used in our dt building is gru.
we know that there are other sequences models e.g.
rnn and lstm .
we performed preliminary experiments on these sequence models but results show that gru performs better.
related work we discuss the related work from three aspects cps and dts section .
transfer learning section .
and uq section .
.
.
cyber physical systems and dts passenger waiting time has already been an important qos indicator of elevators there have been several works proposed for reducing it by optimizing elevator scheduling algorithms with dynamic fuzzy logic evolution algorithm etc.
to compare with these works our goal is about predicting passenger waiting time not reducing optimizing it which we consider is about evolving industrial elevators themselves.
when looking at cps in general they are typically susceptible to risks from the physical and cyber spaces.
to mitigate such risks many security and safety enhancement techniques have been proposed e.g.
.
along with the increased deep learning use to enhance cps security and safety more and more researchers and practitioners realize that obtaining labeled data for real world cps is very expensive even infeasible in some contexts.
the scarcity of labeled data hinders the training process of deep learning models.
thus in this paper we follow this research line by designing rise dt as a deep learning method.
rise dt introduces transfer learning and uq to mitigate the challenge of the scarcity of labeled data in the cps domain.
moreover security and safety risks evolve over time.
the literature mostly focus on statically training models with offline cps log data e.g.
which is vulnerable to previously unknown attacks or faults .
cps in operation continuously generates data which can potentially evolve a statically generated method to identify emerging security and safety issues.
however most existing methods can not take advantage of this newly generated data without full scale retraining.
dt technologies bring a novel 1265esec fse november singapore singapore qinghua xu shaukat ali tao tue and maite arratibel way to overcome this challenge by synchronizing with cps in realtime .
particularly b cue et al.
proposed to use dts for analyzing how cps should be engineered under attack.
eckhart et al.
equipped dts with logic and network features for analyzing if an attacker can compromise programmable logic controllers.
bitton et al.
proposed to perform tests on a dt instead of real cps.
damjanovic behrendt used dts for privacy assessment of real smart car systems.
these works show the superiority of dt technologies.
but to the best of our knowledge we are the first to focus on building dts for elevator systems waiting time prediction.
.
transfer learning there are four strategies for transfer learning.
the model control strategy performs transfer learning at the model level.
for instance duan et al.
proposed domain adaptation machine dam which uses multiple source domain data builds a classifier for each domain and adopts regularizers to control the complexity of the final model.
the parameter control strategy assumes that the parameters of a model reflect the knowledge it has learned.
for instance zhuang et al.
proposed a transfer learning approach for text classification which shares parameters directly between the source and target models.
the model ensemble strategy performs transfer learning by combining several source models together.
for example gao et al.
proposed to train several weak classifiers of different model structures on multiple source domains and compute the final model as a weighted vote of these weak classifiers.
deep learning transfer techniques transfer knowledge between two deep learning models by aligning the representations of corresponding layers from the source and target models.
along this line zhuang et al.
proposed transfer learning with autoencoder which aligns reconstruction distribution and regression representations.
tzeng et al.
extended this method by adding an adaptation layer.
long et al.
performed this alignment in multiple layers in their model deep adaptation networks.
in conclusion model control and parameter control strategies are early strategies that perform knowledge transfer with intuitive methods such as adding regularizer and sharing parameters.
their performance is as good as model ensemble and deep learning transfer techniques.
model ensemble works the best with multiple heterogeneous source domains and requires a lot of computing resources.
deep learning transfer techniques works for transferring knowledge between two neural network models.
since our rise dt is a neural network based dt we follow this research line and align the representation of the gru layer and prediction layer.
.
uncertainty quantification and analyses many uq methods are based on bayesian techniques.
for instance wang et al.
proposed to use the probability theory to interpret parameters of neural networks.
later on srivastava et al.
used monte carlo dropout as a regularization term for the prediction uncertainty computation to avoid posterior probability calculation.
salakhutdinov et al.
proposed a stochastic gradient markov chain monte carlo sg mcmc method which only needs to estimate the gradient on small sets of mini batches requiring far less computing than estimating the posterior distribution directly.neural networks are also being used for estimating the posterior distribution.
for instance ghosh et al.
proposed a variational autoencoder vae with an encoder and decoder both having the neural network structure.
other uq methods include deep gaussian processes and ensemble based uq .
several open source uq tools are available to use.
uncertainty wizard is a tensorflow keras plugin supporting common quantification methods e.g.
bayesian and ensemble based methods.
uncertain toolbox is built on pytorch also providing commonly applied bayesian and ensemble uq methods along with other metrics such as calibration sharpness and accuracy.
we opted for uncertainty toolbox because our model is coded with the pytorch library which makes it easier to use a pytorch based tool like uncertainty toolbox.
generic uq methods encourage researchers to employ them in specific application domains.
for instance catak et al.
proposed nirvana for prediction validation of deep learning models based on uncertainty metrics.
in addition in the domain of cps some methods have been proposed to enable uncertainty aware analyses.
for instance han et al.
proposed an approach to systematically classify uncertainties with the cynefin framework and assess the robustness of industrial elevator systems based on uncertainty classification results.
zhang et al.
proposed a series of methods in dealing with cps uncertainties.
conclusion and future work we propose rise dt to build dts of industrial elevators with neural networks to support the evolution of dts.
rise dt employs transfer learning with uncertainty quantification uq to learn knowledge from source elevator scenario and perform accurate predictions on target elevator scenario with dt.
we conducted experiments with four different types of scenarios and different dispatchers.
the results showed an average reduction of mean square error of .
with transfer learning and a further reduction of .
with uq which proves the effectiveness of both transfer learning and uq.
in the future we will employ adversarial samples for transfer learning which can potentially further improve the performance since more data will be included in the source domain.
moreover we want to explore additional transfer learning techniques dt construction methods and uq techniques followed by performing more comprehensive experiments.