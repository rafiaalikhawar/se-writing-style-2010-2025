see discussions st ats and author pr ofiles f or this public ation at .researchgate.ne t public ation testing coreference resolution systems without labeled test sets conf erence paper no vember .
.
citations 3reads author s including jialun cao hong k ong univ ersity of scienc e and t echnolog y publica tions citations see profile ming wen huazhong univ ersity of scienc e and t echnolog y publica tions citations see profile all c ontent f ollo wing this p age was uplo aded b y jialun cao on januar y .
the user has r equest ed enhanc ement of the do wnlo aded file.testingcoreferenceresolutionsystemswithoutlabeledtestsets jialuncao the hong kong universityof scienceand technology guangzhouhkust fok yingtungresearchinstitute hong kong china jcaoap cse.ust.hkyaojielu chinese informationprocessing laboratory institute of software chinese academy of sciences beijing china luyaojie iscas.ac.cn ming wen schoolof cyberscienceand engineering huazhonguniversityof scienceand technology wuhan china mwenaa hust.edu.cnshing chi cheung the hong kong universityof scienceand technology guangzhouhkust fok yingtungresearchinstitute hong kong china scc cse.ust.hk abstract coreferenceresolution cr isatasktoresolvedifferentexpressions e.g.
namedentities pronouns thatrefertothesamereal worldentity event.itisacorenaturallanguageprocessing nlp component that underlies and empowers major downstream nlp applications suchasmachinetranslation chatbots andquestion answering.despiteitsbroadimpact theproblemoftestingcrsystemshasrarely been studied.
a major difficulty is the shortage of a labeled dataset fortesting.whileitispossibletofeedarbitrarysentencesastest inputs to a cr system a test oracle that captures their expected test outputs coreference relations is hard to de f ine automatically.
to address the challenge we propose crest an automated testing methodology for cr systems.
crestuses constituency and dependencyrelations to construct pairs of test inputs subject to the same coreference.theserelationscanbe leveragedto de f inethemetamorphicrelationformetamorphictesting.wecompare crestwith f ivestate of the arttestgenerationbaselinesontwopopularcr systems and apply them to generate tests from sentences randomlysampledfromconll apopulardatasetforcoreferenceresolution.experimentalresultsshowthat crestoutperforms baselines signi f icantly.
the issues reported by crestare all true positives i.e.
precision compared with to achieved bythe baselines.
ccs concepts softwareanditsengineering consistency softwaredefect analysis computing methodologies information extraction .
keywords coreference resolutiontesting metamorphictesting se4ai corresponding author permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forpro f itorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe f irstpage.copyrights forcomponentsofthisworkownedbyothersthanthe author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspeci f icpermission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright heldby the owner author s .
publicationrightslicensed to acm.
acm isbn ... .
format jialun cao yaojie lu ming wen and shing chi cheung.
.
testing coreferenceresolutionsystemswithoutlabeledtestsets.in proceedingsof the31stacmjointeuropeansoftwareengineeringconferenceandsymposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa 13pages.https introduction coreference resolution cr is a core natural language processing nlp taskthatresolvesareal worldentity eventtowhichapronoun or phrase in a text refers .
the f irst example in figure2illustratesanapplicationofcr resolvingthepronoun him tojohn andshereferstosally.crbringscohesionandcoherent presentation style to natural language expressions and also permeates manyaspectsof daily life.
cr isanessentialcomponentthat empowersmanydownstream nlpapplications.thesecondto f ifthexamplesinfigure 2illustrate theuseofcrresultsinfourtypicalnlpapplications.example2 shows a user talking with her ai assistant siri asking it to send a message to john.
siri needs to resolve the pronoun itosally andhimtojohnbefore correctly sending john a message.
the googletranslateinexample3needstoresolvethepronoun itto the funeral before correctly translating the english itto french ellein the feminine singular form.
the question answering qa system in example needs to resolve the pronoun shetosally in the context in order to return the correct answer.
a recent study even pointed out that chatgpt is limited in handling coreference .
indeed various applications such as questionanswering qa machine translation chatbots andautomaticsummarization performpredictions basedonthe cr results.
given the wide impact of cr systems their quality assurance is crucialtotheperformanceofnlpapplications.arecentstudy benchmarkedexistingcrsystemsandrevealedthepotentialbias in the reported evaluation of these systems.
in particular the evaluation is based on the commonly used dataset i.e.
conll dataset onwhichexistingcrsystemsareexpectedtohave been tuned.
as such high precision and recall are reported.
the resultsarebelievedtobesatisfactoryinthisdataset whiletheevaluationresultsaredifferentwhenthesesystemsaretestedusingother datasets or those that involve infrequent tokens.
the precision and esec fse december3 san francisco ca usa jialun cao yaojielu ming wen shing chi cheung sentence .the fish in thelakeate the worm because itwas hungry .
sentence .the fish inthelakeate the worm because itwas tasty.
thefishnp in lakenn thedt clean in wormthe istastyprpnps it becauseinsbar atevbdnp np dtvp nnppvp np nn dependencystructure coreferenceresolution constituentstructure dt jj jjvbzadjps figure1 illustrationofcoreferenceresolution dependency structure andconstituentstructure.
recallcandropto66.
and72.
respectively.thestudyindicates the needfor adiversetest setto evaluate cr systems reliability.
indeed a de f icient cr system can greatly jeopardize the performance of its downstream applications .
as pointed out by google microsoft and many other companies an unreliable cr system has been one of the major reasons for the unsatisfactory performanceof downstreamapplications such as knowledge graph construction andneuralmachinetranslation .forinstance example in figure 2shows a dialog where a chatbot failed to resolve the pronoun himtojohn.
it repeatedly sought clari f ication aboutthe message sreceiver resultinginapooruserexperience.
metamorphictesting isreportedtobethemostpopulartestingapproachforarti f icialintelligencesystems .metamorphic testingrelieves theconstructionofatestoraclebetweenaninput and its output which is difficult for stochastic computation and alabeledtestset whichisexpensivetocollect.nopriorwork hasstudiedthedeploymentofautomatedmetamorphictestingto cr systems despitetheir impact.suppose fis the programunder test f u1d465 andf u1d465 are the program outputs based on an input u1d465 and a follow up input u1d465 .
the deployment of metamorphic testing needs to address three key problems p1 de f ining an effective metamorphicrelation mr r u1d465 u1d465 f u1d465 f u1d465 forcrsystems p2 generating a follow up input u1d465 that observes the de f ined mr from a source input u1d465and its outputf u1d465 and p3 devising a mechanismto checkif f u1d465 andf u1d465 violaterautomatically.
p1.to address the f irst problem a natural mr is that the cr system should produce consistent results for a source input and its follow upinputwhen both share the same coreference.
p2.the mr requires constructing a follow up input that preserves the coreference of its source input.
the construction is however challenging.
first existing word token replacement techniques do notguarantee the preservationof coreference after replacement.
indeed the coreference in a sentence could be easily changed with the replacement of one word.
for example in figure with one adjacent word i.e.
hungryandtasty the coreferenceof itischangedfrom the f ishtotheworm .also apart fromword replacement adversarial techniquescould also be used for data augmentation typo insertion or random character deletion .
yet the design of these techniques cannot guarantee the coreference that should be preserved.
second coreference may also be changed by replacing a word with its synonyms antonyms.
forinstance considerthesentence thecitycouncilmenrefusedthesally hisiri.
siri hello.
how canihelp you?
sally i dliketosend amessage tojohn .
siri sure.
what message?
sally please tellhimcome tohave thecakeibaked together.
siri ok.message hasbeen sent tojohn .sally toldjohn to tasteherhomemade cake whenhecomes home.
clusters text clusters index range example1.
coreference resolution example2.
chatbot sally iwant tosend amessage tojohn .
robot sure.
what message?
sally please tellhimcome tohave thecake withme.
robot copy that.
buttowhom should the message besent?
sally ......example5.
chatbot with anill trained coreference resolver thelines depicted thecoreference relations for i i and i me were omitted forsimplicity.
example4.
question answeringcontext sally toldjohn to taste the cakeshemade.
user who hasbaked acake?
robot sally.english the funeral of the queen mother will take place on friday.
itwill be broadcast live.
french les fun railles de la reine m re auront lieu vendredi .
ellesera retransmise endirect.
bygoogle translate example3.
machine translation figure examples of coreference resolution and its downstreamapplications.
demonstratorsapermitbecausethey violence .
ifthewordis feared then they likelyrefersto thecitycouncilmen whereas if it is advocated then they likely refers to the demonstrators .
third as revealed by our study see section existing semantic similarity metrics are incapable of distinguishingwhether twosentences have the same coreference.
p3.validatingtheconsistencyoftworesultsmadebycrsystems canbetricky.intuitively directlycheckingtextconsistencycould leadto ambiguity .
for example considering the sentence thequeenmotherasked queenelizabeth ii totransform her sister princess margaret intoaviableprincessbysummoning a renownedspeech therapist nancylogue to treat her speech impediment.
inthisexample therearetwopronouns herreferringtodifferent referents i.e.
queenelizabethii andprincessmargaret respectively .
sosimplydeterminingtheconsistencyoftextscouldleadtofalse negatives.
alternatively if we use the clusters of index range as shown in figure 2example to determine the consistency the indexcouldeasilyshiftduetowordreplacement.forexample if we replace the word homemade with its synonym home baked the index range of hewould shift from to because the synonym home baked will be tokenized to three tokens so the indices of home baked are respectively pushing the index ofhimforward to .
in other words simply checking the absoluteequivalenceofeithertextorindexrangecouldresultin imprecise judgements.
inthispaper weintroduceametamorphictestingframework crest for cr systems.
our key insight is that replacing tokens thatarerelatedtothecoreferenceinthetextislikelytochangethe coreference of the text.
thus accordingly we generate the followup inputs by mutating the phrases or tokens that are unrelated to the coreference in the text.
in particular we identify the crrelated tokens phrases according to the syntactic information i.e.
constituentstructureanddependencystructure ofthetext then generatethefollow upinputsbyreplacingtokensintherestofthe 108testingcoreference resolutionsystems without labeledtestsets esec fse december3 san francisco ca usa sourceinput.forexample forsentence1infigure afteridentifyingthecoreferenceinthetext i.e.
theworm andit andparsingthe textto itsdependencyandconstituentstructures wecanidentify thatnotonlythetokens phrases theworm andit butalsotheadjectivetasty whichdependsontheprecedingnominalsubject nsubj itfromthedependencystructure arecr relatedtokens phrases.
replacingthesetokens phrases is highly likely to affect the text s coreference.
so we leave these tokens phrases unchanged.
instead we replace the rest tokens phrases in the source input.
speci f ic to this example it is safe to replace the tokens in the phrase in the clean lake without affecting the coreference.
after the word replacement we also check the consistency of the constituency of thecr relatedtokens phrases ensuringthatthewordreplacement would not change the coreference accidentally.
finally to validate theconsistencyoftheoutputs wechecktheclustersofindexrange andthecorrespondingclustersoftextsatthesametime.also to betterquantifytheoutputconsistency wecalculatetheprecision andrecallusingapopular usedlink basedmetricblanc bilateral assessment ofnoun phrase coreference so that the desired thresholdscanbecustomizedfor f inerconsistencyrequirements.
in summary our work makesthree majorcontributions weintroduce crest ametamorphictestingmethodologyforcr systems.inparticular weformulatethetestingproblemoncr systems demonstratethechallengesoftestingthem anddevelop afeasible methodology to addressthe challenges.
we propose a metamorphic relation for testing cr systems.
it addresses the difficulty in automatically constructing test inputs duringgeneratingfollow upinputsinaidofsyntaxanalysis.a subsequenttest selection process further ensures thequalityof test inputs.
the experiment reveals the effectiveness of crest.
it reaches precision in issue detection outperforming baselines with at best .
moreover regarding the quality of test inputs only oftestinputsgeneratedbybaselinesarevalid leadingtohighfalsepositiverates.incomparison testinputs generatedby crestarevalidandareabletorevealtruepositives.
preliminaries .
technology andterminology ofcr cr is a fundamental task and a long researched area in the nlp areatowardsnaturallanguageunderstanding .toautomate cr tasks a variety of techniques have been proposed including deterministic statistical andneural crsystems.besides recentend to endtechniques have madeabigstepbymakinguseofthepre trainedlanguagemodel plm external world knowledge and efficient learning algorithms .
yet as a recent study has pointed out that theperformanceofstate of the artcrsystemsisstillunsatisfactory when infrequent test setsare used.
adesiredcrsystemisexpectedtoidentifyalltheexpressions e.g.
names pronouns phrases thatco referringtoan entity event in the given text .
these expressions are known as mentions.thementionsaregroupedinto clusters1accordingtothe 1thereareotheralternativenamesfor clusters including coreferencechains andsubjects.
in thispaper weuse clusterconsistently.entity eventstheyreferto.allthementionsinoneclusterareexpected to refer to the same entity event.
for instance in the text the f ishinthelakeatethewormbecauseitwastasty.
acrsystem isexpectedto f indallmentions the f ish thelake theworm it from thetext.next thecrsystempartitionsthemintosingletons the f ish and the lake and a cluster the worm it and then outputs the three clusters.
.
outputcluster consistencychecking givenatextsequence x amention u1d45a u1d460 u1d452 where u1d460and u1d452are respectively the start and end token position of u1d45asuch that u1d460 u1d452 u1d441.
let u1d450denote a cluster u1d45a1 u1d45a2 ... u1d45a u1d457 where u1d457 .
given a cr system f x c it takes a textxas input and outputs a set of clusters c u1d4501 ... u1d450 u1d45e where u1d45e .
take example in figure 2as an example mentions include i.e.john and i.e.he the cluster of these two mentions is .
forclusters u1d4501and u1d4502 wesay u1d4501and u1d4502areconsistent if u1d45a u1d4501 u1d45a u1d4502such that u1d45a u1d45a and u1d45a u1d4502 u1d45a u1d4501such that u1d45a u1d45a.
note that the equivalence relation i.e.
of mentions describes the equivalence beyond the exact index equivalence.
for instance fortheexampleinfigure 2example1 althoughtheindex ofheisshiftedfrom to afterreplacing homemade tohomebaked these two mentions are still equivalent because they both use the same pronoun i.e.
heto refer to the same entity john .
to evaluate the coreference consistency we then adopt blanc bilateral assessment of noun phrase coreference a popular used metric to calculate the precision and recall of the coreference.formally suppose gisthegroundtruthcoreferenceof the given inputxconsisting of a set of clusters cis the predicted coreference ofx.
let u1d43f u1d454and u1d43f u1d450represent the sets of coreference linksinthe ground truthclusters gandpredictedclusters c. u1d443 u1d43f u1d454 u1d43f u1d450 u1d43f u1d450 u1d445 u1d43f u1d454 u1d43f u1d450 u1d43f u1d454 we considerciscorrectif both p and r are higher than the customizedthresholds.oppositely ifanyofpandrlowersthan the threshold an issueisdetected.
.
constituentanddependency structures constituent and dependency structures are two ways to analyze the syntactic structure of sentences using constituency and dependency parsing respectively.
the constituent structure represents each sentence as a hierarchical phrase tree where each noderepresentsaconstituent suchasnounphrases np verb phrases vp andprepositionalphrases pp .forexample infigure1 themainconstituentsofthesentenceare the f ishintheclean lake ate the worm because it is tasty .
speci f ically the noun phrase np the f ish is the subjectof thesentence and the prepositional phrase pp inthecleanlake modi f iesthenounphrase the f ish ate the worm is the verb phrase vp of the sentence with ate as the verb and the worm as the direct object and because it is tasty is the subordinate clause sbar that explains the reason for the f ish eating the worm.
the dependency structure represents a sentence as a directed graphwiththewordsasnodesanddependencytypesasedges .
2most cr systems do not output singletons.
so in the evaluation we assume each output clusterof the cr systemcontains at least twomentions.
109esec fse december3 san francisco ca usa jialun cao yaojielu ming wen shing chi cheung each dependency represents the relationship between a headword and its dependents which are words that depend on the headword for their meaning.
as shown in figure f ishdepends on the verb ate wormisthedirectobjectoftheverb ateanddependsonit clean modi f ieslakeanddepends onit becauseintroducesa subordinate clause and depends on ate tastyis an adjective that modi f ies worm anddepends onit.
approachand implementation this section introduces the work f low of crestand describes its implementation.
the input of crestis a list of unlabeled texts and the output is a list of suspicious cr issues.
for each input crestgenerates a set of follow up inputs pairs each follow up inputwithitssourceinput andreportsanissueifanyinconsistency isfound.areportedissuecontainsasourceinput afollow upinput and the coreference of them resolved by the cr system under test.
notethattheissuemayoccurinthecoreferenceofthesourceinput the coreference of the follow up input or both.
figure 3illustrates the overviewof crest.setcrestcomprisesthree main steps follow upinputgeneration foreachsourceinput crestgenerates a set of follow up inputs by modifying a single token at a time whilepreservingthe coreference.
follow upinputselection crestfurtherselectsthegenerated texts according to the syntactic information of the source and follow upinputs.
inconsistency detection the predicted coreference of the sourceand follow upinputsare compared.ifthe predictionsare inconsistent crestreports an issue.
.
follow up input generation crestdesignsthemethodologyfollowingageneralwork f lowof metamorphictesting.
to startwith it generates aset of follow up inputs from a source input according to the mr. the mr in this work is that a cr system should produce consistent results for the sourceandfollow upinputswhentheysharethesamecoreference.
thefollow upinputcanbesoconstructedthatitdiffersfromthe sourceinputbyatleastonetoken.however mosttokenreplacementmechanismsinnlptestingapproaches do notconsideriftherearecoreferencechangesinthefollow upinputs.
the follow up inputs constructed in this way may not satisfy theimmutabilityrequirementofthecoreferenceinthemr.though several approaches consider coreference they manually de f ine several templates e.g.
is a to generate tests.
while these approaches are limited in diversifying the generatedsentencestructures itisimpracticaltode f inetemplatesforall sentence structures.
itmotivatesustodesignagenerationalgorithm algorithm which observes the immutability requirement of coreference as follows.
the input of the algorithm includes a source input x e.g.
asentence thegoldencoreference cinthedataset thecrsystem under testf and the maximum number of generated follow up inputs u1d440.givena source input x e.g.
a sentence and thegolden coreferencec at the beginning the source input is tokenized and parsedtothedependencytreeandconstituenttree lines2 obtainingtheconstituentlabelsandthedependencyrelationsoftokens.
examples of parsed constituent structure and dependencystructure are illustrated in figure .
then according to theidenti f iedcoreferenceandthedependencystructure weobtaintheindex oftokensthatarerelatedtothecoreference line4 seenextparagraph for details .
then each token xlooks up its replacement iteratively unless the token is coreference related lines .
for each candidate token we f ind the corresponding synonym and antonym sets lines using wordnet .
furthermore in ordertoincreasethediversityofthegeneratedfollow upinputs we alsoinvolve off the shelfmaskedlanguagemodelstoperform word perturbation.
in particular we mask the corresponding token in the original sentence one by one and use a pre trained language model to predict a possible token as a replacement line .
after obtainingasetofwordsthatcanbereplaced wethentrytoreplace itinorder to generateasetof follow upinputs line13 .
speci f ically to obtain the index of coreference related tokens algorithm line we utilize dependency structures of texts.
givenasourceinput x itscoreferencecanddependencystructure u1d451 u1d452 u1d45d u1d461 ititerativelyobtainsclustersin c andbreaksdowntoeach mention in every cluster.
for every mention we add all the indices of the mention as well as that of the phrases tokens that have dependencyrelationswiththeseindices.theformalequationfor obtainingthe setofcr relatedindices n isshownas follows n u1d457 u1d456 m u1d457 ... u1d44b uni210e u1d44e u1d460 u1d437 u1d452 u1d45d u1d452 u1d45b u1d451 u1d452 u1d45b u1d450 u1d466.alt u1d456 u1d457 where u1d457iterates all the indices in the sentence u1d44bwith x tokens mdenotes the set of indices of tokens in the coreference u1d456denotes any index in m uni210e u1d44e u1d460 u1d437 u1d452 u1d45d u1d452 u1d45b u1d451 u1d452 u1d45b u1d450 u1d466.alt u1d456 u1d457 represents a function which checks whether there are dependency relations4between the indices u1d456and u1d457 which returns a boolean value.
we add the index u1d457into the returned set nif there are dependency relations with u1d456and u1d457.
speci f ically for the dependency relations we considernsubj i.e.
nominal subject a nominal which is the syntactic subject and the proto agent of a clause andamod i.e.
adjectivalmodi f ier theadjectivalphrase wordthatservestomodifythe noun pronoun of pronouns in the sentence because they are two majordependency relations thatrelate to noun noun phrases.
finally we return asetof indices n. furthermore afteratokenthatcouldbeusedforreplacement is identi f ied the word replacement should go with a double check utilizing the constituent structure.
in particular the procedure works as follows see algorithm .
given a set of candidate tokens u1d45f u1d452 u1d45d u1d459 u1d44e u1d450 u1d452 u1d451 u1d446 u1d452 u1d461 i.e.
synonymsorantonyms thesourceinput x theindexoftokenunderreplacement u1d456 theconstituentstructureof x u1d450 u1d45c u1d45b u1d460 u1d461 andthemaximumreplacementtimesofthegivenposition i.e.
u1d456 u1d440 the algorithm deals with every candidate token in the u1d45f u1d452 u1d45d u1d459 u1d44e u1d450 u1d452 u1d451 u1d446 u1d452 u1d461 onebyone.afterreplacingthe u1d456 thtokeninthesource textwitheverycandidatetoken line6 itparsesthenewtextto its constituent structure line to check whether the candidate texthasthesameconstituentlabelasthe u1d456 thtokeninthesource text line .
if the label remains the same then the new text is regardedasafollow upinputandaddedintotheoutputset.this 3in the implementation we use a popular model i.e.
bert large cased to perform word perturbation and to ensure the naturalness of the sentence we set the minimal probabilityofeachcandidatewordas .
.onecouldeasilyreplacethelanguagemodel with more advanced models and set up different thresholds.
since it is not the core of ourmethodology wefollowthe same settingas adopted by the existingwork .
4in the implementation of crest we use the dependency parser provided by stanfordcorenlp .
110testingcoreference resolutionsystems without labeledtestsets esec fse december3 san francisco ca usa generate dependency parsing constituent structuredependency structure source inputcr system original coreference constituency parsing...... follow up input new coreference report an issue if any inconsistency is found source input original coreference follow upinput new coreference constituent structure follow up input generation follow up input selection inconsistency detection nkeep?y compare coreference related tokens inconstituent structure discard the follow upinputparse coreference related tokens crsyste m figure work f low of crest.
given a source input e.g.
a sentence crest f irst generates a set of follow up inputs e.g.
sentences that are similar to the source input while differing in a few tokens in the f irst phase.
the follow up inputs are fed tothe secondphase validatingtheirsyntactic propertyconsistencywith thesourceinput.afollow upinputifconsistentis pairedwithitsconcernedsourceinputtoformatest otherwisediscarded.
anissueisdetectedandreportediftheconsistency oftheoutputcoreferenceisbelow aprede f ined threshold.
algorithm1 generatefollowupinput input asourceinputx thegoldencoreference cofx cr systemundertestf the number ofmaximum generatedfollow upinputs u1d440 output a setofgeneratedfollow upinputs u1d45b u1d452 u1d464 u1d44b u1d460 u1d45b u1d452 u1d464 u1d44b u1d460 emptyset u1d451 u1d452 u1d45d u1d461 dependencyparser x u1d450 u1d45c u1d45b u1d460 u1d461 constituentparser x u1d450 u1d45f u1d456 u1d45b u1d451 getcrfrelatedindex c u1d451 u1d452 u1d45d u1d461 5for u1d456in ... x do 6if u1d456in u1d450 u1d45f u1d456 u1d45b u1d451then continue 8else u1d450 u1d44e u1d45b u1d451 u1d456 u1d451 u1d44e u1d461 u1d452 u1d460 emptyset u1d450 u1d44e u1d45b u1d451 u1d456 u1d451 u1d44e u1d461 u1d452 u1d460 .add getsynonym x u1d456 u1d450 u1d44e u1d45b u1d451 u1d456 u1d451 u1d44e u1d461 u1d452 u1d460 .add getantonym x u1d456 u1d450 u1d44e u1d45b u1d451 u1d456 u1d451 u1d44e u1d461 u1d452 u1d460 .add getwordperturb x u1d456 u1d45b u1d452 u1d464 u1d44b u1d460.add replaceandcheck u1d450 u1d44e u1d45b u1d451 u1d456 u1d451 u1d44e u1d461 u1d452 u1d460 x u1d456 u1d450 u1d45c u1d45b u1d460 u1d461 u1d440 see algorithm 14return u1d45b u1d452 u1d464 u1d44b u1d460 checkensuresthereplacementdoesnotchangetheconstituencyof the token under replacement.
the replace and check iterates until thenumberofgeneratedfollow upinputsreachesthemaximum number u1d440 lines3 or all tokensin thecandidate sethave been replaced line10 .
.
follow up input selection we further analyze the generated follow up inputs and exclude thosethatarenotlikelytopreservetheirsourceinput scoreference.
yet checkingwhethercoreferencehasbeenchangedisasdifficultas asserting whether it is correct.
checking the coreference manually is however notaviablesolutionbecauseitcanbesubjectiveandnot scalable.ourinsighttotacklethisproblemisinspiredbyrule based crworks whichleveragethedepthofthetoken phrase in a syntactic tree to determine discourse prominence and resolve coreference.
therefore we check if the coreference related tokens in a follow up input s constituent structure have a depth that differs from that of their counterparts in the source input sstructure.ifso thefollow upinputisunlikelytopreserveitssource input s coreference andshould be excluded.
inparticular amentioninaclustercouldbeeitherasingletoken e.g.
him it oraphrase e.g.
the f ish executivesatbackerspielvogel clientavisinc.
.sowhencalculatingthedepthofcoreference related tokens phrases wetreateachmentionaccordingly.ifamentionisa singletoken wecalculatethedepthfromtheroottothistokeninthe constituentstructure.whileifamentionisaphrase wecalculate the depth from the root to the closet nested phrase outside the mentionphrase.forexample seefigure 1constituentstructure forthesingletoken it thedepthis5 s sbar s np prp while for the mention the f ish its depth is calculated from the root to the nestednoun phrase s np np resultingin3.
algorithm 2works as follows.
given a source input xand a follow upinputx thealgorithmdetermineswhetherthefollowupinputshouldbeexcludedornot.ifthecoreference relatedtokens residedifferentlyintwoconstituencystructures thenthefollow up inputshouldbeexcluded.
speci f ically the algorithmiteratesevery mention in clusters of the coreference in x line .
if a mention appearinginxalsoexistsinthefollow upinput then crestparses x toobtainitsconstituentstructure line3 .thenitcalculates the depth of the token or the closet phrase that nests the mention intheconstituent structures u1d450 u1d45c u1d45b u1d460 u1d461and u1d450 u1d45c u1d45b u1d460 u1d461 ofbothxandx line5 .ifthedepthvaries thenwediscardthefollow upinput line7 .otherwise ifnomentionsbreaktheconditiontilltheend ofthe iteration we then keep this follow upinput line9 .
.
inconsistency detection after the follow up inputs are selected each of them are paired withitssourceinput.foreachpairofsourceinputandfollow up input x x atestis conductedby obtainingthe coreference ofxresolved by the cr system under test f x obtaining the coreference ofx resolved by the cr system under test f x and checkingif f x andf x areconsistent.thetestfails if inconsistencyoccurs.
yet validating the coreference consistency of two outputs by a cr system is tricky because there can be more than one equivalent token phrase in a sentence.
thus we use the token indices to represent the mentions in coreference to avoid ambiguity.
for instance for the examplein section 1p3 instead of using the text herto represent themention we use to represent the f irst herreferring to queen elizabeth ii and use to represent 111esec fse december3 san francisco ca usa jialun cao yaojielu ming wen shing chi cheung algorithm2 selectfollowupinput input a sourceinputx ageneratedfollow upinput x the constituent structure u1d450 u1d45c u1d45b u1d460 u1d461 the coreferencec output a boolean valueindicating whether the generated follow upinputshould be kept ornot 1for u1d450 u1d459 u1d462 u1d460 u1d461 u1d452 u1d45fincdo 2for u1d45a u1d452 u1d45b u1d461 u1d456 u1d45c u1d45bin u1d450 u1d459 u1d462 u1d460 u1d461 u1d452 u1d45fdo if u1d45a u1d452 u1d45b u1d461 u1d456 u1d45c u1d45binx then u1d450 u1d45c u1d45b u1d460 u1d461 constituentparser x u1d451 u1d452 u1d45d u1d461 uni210e caldepth u1d45a u1d452 u1d45b u1d461 u1d456 u1d45c u1d45b u1d450 u1d45c u1d45b u1d460 u1d461 u1d451 u1d452 u1d45d u1d461 uni210e caldepth u1d45a u1d452 u1d45b u1d461 u1d456 u1d45c u1d45b u1d450 u1d45c u1d45b u1d460 u1d461 if u1d451 u1d452 u1d45d u1d461 uni210e!
u1d451 u1d452 u1d45d u1d461 uni210e then returnfalse 9returntrue algorithm3 replaceandcheck input a sourceinputx the index ofthe token under replacement u1d456 asetofcandidate tokens that could be usedfor wordreplacement u1d45f u1d452 u1d45d u1d459 u1d44e u1d450 u1d452 u1d451 u1d446 u1d452 u1d461 the constituent structure u1d450 u1d45c u1d45b u1d460 u1d461 andthe maximum number offollow upinputs u1d440 output a setoffollow upinputs u1d45b u1d452 u1d464 u1d44b u1d460 u1d45b u1d452 u1d464 u1d44b u1d460 emptyset 2for u1d45b u1d452 u1d464 u1d447in u1d45f u1d452 u1d45d u1d459 u1d44e u1d450 u1d452 u1d451 u1d446 u1d452 u1d461 do 3iflen u1d45b u1d452 u1d464 u1d44b u1d460 u1d440 then return u1d45b u1d452 u1d464 u1d44b u1d460 5else u1d45b u1d452 u1d464 u1d44b replacetoken x u1d456 u1d45b u1d452 u1d464 u1d447 u1d45b u1d452 u1d464 u1d436 u1d45c u1d45b u1d460 u1d461 constituentparser u1d45b u1d452 u1d464 u1d44b if u1d45b u1d452 u1d464 u1d436 u1d45c u1d45b u1d460 u1d461 u1d45b u1d452 u1d464 u1d447 u1d450 u1d45c u1d45b u1d460 u1d461 x then u1d45b u1d452 u1d464 u1d44b u1d460.add u1d45b u1d452 u1d464 u1d44b 10return u1d45b u1d452 u1d464 u1d44b u1d460 the second herreferring to princess margaret .
the use of indices allowseachmentionto be uniquely referenced.. finally crestdetectsinconsistencyasfollows.givenafollowup inputx crestfeedsx to the cr system to obtain the output coreferencec .
to avoid ambiguity of text comparing crestuses token indices to represent mentions in coreference.
then an inconsistency is detected if c differs fromc.crestdetermines inconsistencyaccordingtotheircomputedblanc bilateralassessment of noun phrase coreference score a widely used link basedmetricforcoreferencemeasurement.iftheblancscore is less than .
an inconsistency is detected.
crestreports the sourcexand follow up inputs x of the detected inconsistency togetherwiththeircoreference candc .
evaluation fourresearchquestions rqs are designedto evaluate crest rq1.areissuesreportedby cresttruepositives?
crestdetects issues of cr systems when the metamorphic relation is violated.weinvestigatehowlikelyanissuereportedby crestisa truepositive.
we showthe numberoftests generated detected issues and the true positive rates of each approach.
we also report the overheadandgeneralizabilityof crest.
rq2.canfollow upinputsgeneratedby crestpreserve thecoreferencewell?
sincethemetamorphicrelationin crest assumesthegeneratedfollow upinputspreservethecoreference as the source inputs we thus check whether this assumption holdswell.wecomparethenumberoffollow upinputsthatpreservedornotpreservedcoreferenceforeachapproach andpoint outthatthehighfalsepositiveratescouldlargelybeattributed to the coreference changedfollow upinputs.
rq3.whatkindsofcoreferenceissuescan crestreveal?
weanalyzetheissuesfoundby crestandcategorizedtheminto six types.
we explain each issue type with examples reported by crestandillustrate the statisticsof the reportedissues.
rq4.
what is the impact of each step in the crest?we conduct experiments using different setups and thresholds to showthe impact ofeachstep inthe designedmethod.
.
evaluationsetup we implement crestin python and conduct experiments on a macbook pro with .
ghz quad core intel core i7 cpu .
ghz 16gbmemory.foreachsourceinput wesetthemaximumnumber ofgeneratedfollow upinputsforeachgivensourceinputto20.one could enlarge this number to f ind more inconsistencies.
moreover we set the threshold for both precision and recall of blanc i.e.
u1d461 uni210e u1d45f u1d45dand u1d461 uni210e u1d45f u1d45f to1.
.
dataset.
weuseconll theconferenceonnaturallanguage learning for evaluation because it is the most widely usedevaluationbenchmarkforcoreferenceresolution .5this dataset could also be used for other natural language processing taskssuch as semanticrolelabeling name entityrecognition and so on.
we use the english annotation in the dataset for evaluation.speci f ically conll 2012providesthetrainingset 965sentences thevalidationset 791sentences andthetestset sentences separately.
in evaluation source inputs are randomly selected from the test set.
in addition in this paper we refer to thegroundtruthprovidedbythedatasetannotatedfollowingthe ontonotes or determine the correct coreference following the same annotation standard.
baselines.
for comparison since there is no available testing approach for cr system we adapt three recent testing approaches sit patinv and cat for other nlp tasks i.e.
neural machinetranslation asbaselines.theseapproachesareselected becausetheyalsogeneratetextsbyreplacingafewtokensofthe original text and pairing the generated and the original texts to compare their output results.
in particular sit generates new texts using bert by replacingone noun and adjective token with itssynonyms.cat considersthecontextwhenreplacingthe synonyms and replaces tokens regardless of the part of speech.
patinv ontheotherhand replacestokenswithnon synonyms aiming to diversify the generated texts.
besides for behavioral correctnessandrobustness checklist andtextattackgenerate 5thereareintra andcross sentencecoreferenceannotations.thedifferenceiswhether thementionsofcoreferencecrossthesentenceornot.inourevaluation weusethe intra sentence coreference data to conduct the evaluation for simplicity while our methodologyisapplicableto both typesof coreference.
112testingcoreference resolutionsystems without labeledtestsets esec fse december3 san francisco ca usa textsby transformationsuch astypoinsertion e.g.
replacing his withhi sbyaddingaspace andchangingnamedentities.wealso includethemasbaselines.inparticular forchecklist weuseallthe transformation methods provided except negation.
this is because the metamorphic relation may no longer hold after negating the originaltext ssemanticmeaning.fortextattack whichbundles variousadversarialattackanddataaugmentationtechniques we excludethosemethodsthathavebeenusedinchecklisttoavoid duplication includingrandomcharacterdeletionandaugmentation techniques based on word embedding.
for comparison we run these baselines based on their artifacts using their default settings.
cr system under test.
we evaluate the effectiveness of crestontwocrsystems.oneisaneural basedcrsystemproposed by clark and manning .
for implementation we use the neuralcoref implementation provided by spacy .
the other is a mention ranking statistical cr system using the implementation provided by stanford s corenlp library .
for both systems we use the defaultcon f igurations.
.
rq1.
effectiveness ofissue revealing to evaluate the effectiveness of crest we randomly sample1 sentencesfromthetestsetofconll andadoptvariousapproachestogeneratefollow upinputsbasedonthesesourceinputs.
for each source input we set an upper bound of to limit the numberofgeneratedfollow upinputsforfairness.amongthe1 source inputs of them are correctly resolved using spacy withthe neuralcoref algorithm while465ofthemare not.
the number of generated follow up inputs gen the number of detected issues issue are shown in table .
we can see that the number of issues generated and detected by crestalmost doubles than those by most of the baselines.
in particular the baselines f indthousandsofissues .althoughtextattack reports the most issues nearly of them are false alarms.
two factors contribute to the inferior performance of the baselines.
first somebaselinesrestrictthecandidatereplacementtokensto speci f ic part of speech tags and such a restriction limits the number of test input candidates that can be generated.
for example sitconsidersnounsandadjectivesforreplacement whilepatinv mainly considers verbs and adverbs for replacement.
second some baselinesadoptastricttestinputselectioncriterion.forexample catrequireshighsyntacticandsemanticsimilaritybetweenthe source and generated sentences thus excluding many sentences that are valid test inputs.
note that it is true that adjusting the parameters in baselines may probably yield more follow up inputs whileexploringbetterparametersofbaselinesisnotourmaingoal thus we leave itfor future exploration.
fortherecallevaluation itisimpracticaltogothroughallthe source and follow up inputs.
so we check the hits based on source inputs i.e.
whetherthe465wrongly resolvedsource inputscould bereportedbyanyofthepairsthattheseinputsinvolve.theresult isshownintable hits .itshowsthatthebaselinesrecall230 to463ofthewrongly resolvedsourceinputs withanaverageof349.
cresthits wrongly resolved source inputs which approaches theaverage.
besides itisnoteworthythattextattackachievesa 6spacy nerualcoref 7stanford corenlp effectiveness of issuerevealing on neuralcoref test generation error detection src p n gen issues hits time tp fp prec sit1 .
.
.
patinv .
.
.
cat1 .
.
.
checklist .
.
.
textattack .
.
.
crest1 .
.
.
hit rate of .
.
yet a high hit rate could be trivially achieved by raising alarms for every test.
therefore we further evaluate the baselines and crestby examining the number of true positives andfalsepositivesofthedetected issuesto assess its effectiveness intermsofprecision.inparticular atruepositivemeansthatthe pairofsentencesreportedbytheapproachhasatleastoneerrorin thepredictedcoreference.afalsenegativemeansthereportedpair ofsentences turnoutto have nocoreference errors.
table1 error detection shows that the precision prec of baselinesrangesfrom64 to74 ascomparedto100 achievedby crest.itisclearthatthefalsepositiveratesofbaselinesarehigh.
especially thehighhitrateachievedbytextattackisatthecost of low precision .
essentially the unsatisfactory results are attributed to the change of the coreference during follow up input generation makingthe inconsistencyafalse alarm.
wefurtherelaborateonthedetectedissuesusingthreeexamples.
first we use an issue on neuralcoref revealed by crestafter replacingitwithsynonyms.inexample6 afterreplacing f irstwith its synonym initiative no coreference inthe follow up input such constructedcan be identi f ied.
crestreports itas an issue.
example .
an issue found by crestby synonym replacement.
replace f irst initiative just before christmas break therural township of linpien onthepingtung plain at themouth ofthe linpien river heldits f irst ever waxapple festival.
justbeforechristmasbreak the ruraltownship oflinpien onthe pingtungplainat themouth ofthe linpien river held its initiative ever waxapple festival.
alternatively ifwereplaceacoreference unrelatedtokenwith its antonym the coreference should also preserve.
as shown in example after replacing differentwith an antonym same the coreferenceinthetextisstillpreserved.however thecrsystem under test fails to identify the second cluster in the text.
crestreports an issueaccordingly.
example .
an issue found by crestby antonym replacement.
replace different same we havehearda different signofsirpaulmccartneyplaying to enthusiastic crowds in red square and we have been enthralledbythecelebrationsof yourown city inpetersburg .
we have heard a same sign of sir paul mccartney playing to enthusiastic crowds in red square and we have been enthralled bythecelebrationsofyour own city in petersburg .
the third example is a false positive reported by a baseline.
in example without considering the coreference during word replacement sitsubstitutes heartforpair whichisamentionin the coreference cluster.
in that case the cr system fails to identify anycoreferencefromthesecondsentence thusaninconsistencyis 113esec fse december3 san francisco ca usa jialun cao yaojielu ming wen shing chi cheung figure analysison test qualityanddistribution ofinconsistencies.
reported.yet itisactuallyafalsealarm becausethesubstitution changesthecoreference notonlytheco referringentity butalso themultiplicity where theheartinsingularformcannotbereferred to bythemunlikethepair.
example .
afalsealarm replace pair heart she asks anyone who f inds the pair to givethem back.
sheasksanyone who f inds the heart to givethem back.
in addition an issue could be induced by the incorrect coreference of the source input the follow up input or both so we furthercategorizetheinconsistenciesreportedbyeachapproach onneuralcorefaccordingtowheretheissuesoccur.theanalysisis conductedonthe100pairssampledfromeachbaseline.figure a showsthedistribution.theblackbars source showthenumber of inconsistencies in which the coreference of the source inputs is wronglyresolved whilethecoreferenceofthefollow upinputis correct.likewise thegraybars follow up meansthenumberof inconsistencies where the coreference of the follow up input goes wrong.thesilverbars both meanbotharewrong.whilethewhite bars false alarm show the number of false positives.
figure a shows that the sourcecontributes less than the follow up meaning that more issues are revealed only by the follow up inputs than bythesourceinputsintheevaluation.patinvgeneratesthemost issue revealing follow up inputs followed by our work .
also apartfromourwork thenumberoffalsepositivesreported bybaselinesishigh.we analyze the reason insection .
.
overhead .
we present the overhead of generating follow up inputs for each approach.
as shown in table time the average timetogenerateafollow upinputrangesfrom0.01to0.96seconds.
on the one hand an approachcould be quick if it only f inds and replaces wordsusing patternmatching orrules.
onthe otherhand theoverheadcomesmainlyfromthesyntacticandsemanticanalysis.
for example it takes cat around second to generate one follow up input because cat f ilters them by checking whether the substitutedtokensaresemanticallysimilartotheoriginaltokens.
similarly cresttakes around .
second to generate a follow up inputbecause itrequires syntactic andcoreference analysis.
generalizability .
to investigate if the results can be generalized to other cr systems we repeat the previous experiments ofcreston a popular statistical cr system .
the results are shown in table .
among source sentences of them canbecorrectlyresolvedbystatisticalcr while365cannot.the number of generated follow up inputs is similar to that in table .
regardingthenumberofhits .
to99.
incorrectlyresolved source inputs are included in the inconsistencies detected.
besides crestoutperforms baselines signi f icantly in precision reachingtable effectiveness of issuerevealing on statisticcr testgeneration error detection src p n gen issues hits time tp fp prec sit .
.
.
patinv .
.
.
cat .
.
.
checklist .
.
.
textattack .
.
.
crest .
.
.
precision comparedwith75 atbestreachedbybaselines.the experimentshows thegeneralizabilityof crestinhighprecision inissuerevealingonboth neuralandstatisticalcr systems.
to explore why crestmisses some wrongly resolved source sentences weincreasetheupperboundoffollow upinputsto50 butnomorehitsarefound seetable .we f indtworeasonsfor thissituation.first thecrsystemisincapabletoresolveortendsto ignorecertaintokens e.g.
rarewords orstructures e.g.
sentences with noun phrases with long attributives .
for such defects it is potential to use these sentences as templates for training data augmentation in order to f ine tune the cr system.
second the span of output coreference differs from that in the ground truth.
for example onementioninapredictedcoreferenceis powersuppliers while thegroundtruthis powersuppliers in the west .thedifferencesin output spans may arise from the different boundary annotations thatcr systemsadopt .for such defects one may either stick to an annotation standard or relax the criteria on inconsistency detection e.g.
lower the thresholds for recallorprecision .
.
rq2.
quality offollow up inputs wefurtheranalyzethequalityoffollow upinputsbycomparing the number of follow up inputs that preserve the coreference as the source input.
in particular since the results on the two cr systems are similar inthe following we illustrate the analysison neuralcoref due to space limitation.
the full experiment results can be foundonline .
the result is shown in figure b .
the gray bars represent thenumberoffollow upinputsthatpreservetheirsourceinputs coreference whilethewhitebarsmeantheopposite.wecansee that the baselines only preserve to among all the generated follow up inputs.
in comparison of the follow up inputs generatedby crestpreservethecoreference indicatingthehigh f idelity ofthe test inputsgeneratedby crest.
althoughsomebaselines checkcertainconstraints suchassemanticsimilaritywithinthegivencontexts andsyntacticinvariants they do not consider the preservation of coreference in test input generation.
patinv aims to generate dissimilar text which could be effective when the generated text preserves thecoreference.baselinesusingadversarialattacks however could 114testingcoreference resolutionsystems without labeledtestsets esec fse december3 san francisco ca usa easilychangecoreferenceinthetext.forexample transformations like random character deletion e.g.
perturbing theytothe and typo insertion e.g.
changing histotheir country toheir country change coreference in the text leading to invalid follow up inputs.
we further analyze whether coreference changes in a text are correlated to the changes in its semantics or naturalness.
the analysishelpsustoanswerwhetherexisting approachesdesignedfor the similarity of semantics or preservation of naturalness could be deployed togenerate effective test inputs for cr systems.
note that in order to better measure the semantic similarity at a f iner granularity weadoptthelatesttool tocapturethesubtlesemantic difference between twotexts.in particular for naturalness measurement we adopt the following equation u1d441 u1d44e u1d461 u1d462 u1d45f u1d44e u1d459 u1d45b u1d452 u1d460 u1d460 u1d44b u1d44b radicaltp radicalvertex radicalbt u1d44b productdisplay.
u1d456 u1d443 u1d44b u1d456 u1d44b u1d456 whichmeasurethenaturalnessofsentence xinlengthof u1d44b tokens.
x u1d456represents the u1d456 th token in the sentence x and u1d44b u1d456represents the tokens exceptthe u1d456 th token.
thestatisticsareshowninfigure c .
thesemanticsimilarity rangessimilarlyregardlessofwhetherthecoreferenceischanged.
in particular the average similarity between coreference changed pairs is0.
while that between coreference preserved pairs is .
whichisquitecloseto .
withonly .003difference.also the similarity between coreference changed pairs is a bit higher thanthecounterpart indicatingthatahighsemanticsimilaritydoes notnecessarilyleadtoahighpossibilitytopreservethecoreference.
thus itisimpracticaltodistinguishwhetherthecoreferencehas been changedusing semantic similarity.
similarly we also show the change in naturalness to investigate whether the change in language f luency could provide hints to detectcoreferencechanges.asshowninfigure d therangesof coreference changed .000to0.
and preserved .00to0.
arequiteclose averagingat .0316and0.
respectively.such subtledifferencesinnaturalnesscouldnotbeusedtodistinguish whetherthecoreferenceischanged.ouranalysissuggeststhattest generationtechniques basedoncoreference are needed.
humanevaluation.
tobetterevaluatethesoundnessof crest weconductedahumanstudyonthegeneratedfollow upsentences.
we published thetaskonproli f ic acrowd sourcingplatform that connects researchers with study participants for online researchstudies.werecruited f iveparticipantsandsetthenationsof participants within the usa uk australia canada and singapore in order to ensure the participants are native speakers.
we set f ive participants following existing patterns .
in addition we also invited two experiencedand professional english communication tutors.inparticular oneisanexperiencedtrainerinlinguisticsand methodology andtheotherhasover30 yearexperienceinteaching english.toselectthesentencestobelabeled werandomlysampled pairs of original and follow up sentences from the pairs intable1 generatedby crestfor labeling.
thelabelingresultsareshowninfigure b .eachbarrepresents thestatisticsfromoneparticipant.
ct1andct2refertotwoenglish 8toavoidrepeatedlyselectingthesameoriginalinputsentence we f irstsample100 original sentences then randomly select one follow up from all the follow ups for eachoriginalsentence.communication tutors user1 refer to f ive participants hired from proli f ic.
the result the dashed line in figure b shows that more than half .
of the source sentences are considered morenaturalthantheirfollow upcounterparts whichisreasonable becausethesourcesentencesaretakenfromnewsletters wikipedia andotherreadingresourcesthatprofessionalwritersauthored.the resultsalsoshowthat33 ofthefollow upsentencesareconsidered equallyormorenaturalthantheoriginalsentences.indeed .
of thefollow upsentencesareconsideredtobemorenaturalthanthe sourcesentences.furtheranalysisoftheresultrevealsthatonly21 sourcesentencesareconsideredconsistentlybyalltheparticipants to be more natural than their follow ups.
in other words most follow upsentences areconsiderednaturalorequallynatural byatleastoneparticipant.thestudydemonstratesthenaturalness ofthegeneratedfollow upsentences thusindicatingthesoundness ofour methodology.
.
rq3.
issues reportedby crest crestiscapableto f indcrissuesofdiversetypes.inourevaluation crest f inds six major types of cr issues from neuralcoref includingspanerror se missingentity me extraentity ee missingmention mm extramention em andcon f latedentities ce .
the issue types are derived from the error types of cr systems .toeasetheunderstanding weprovidethecorresponding examples ofthe uncoveredissuesineachtype.
.
.
extraentity ee .
ifacrsystemidenti f iesanextraentity i.e.
cluster inthegiventext itisanextraentityissue.theexample below shows that a cr system identi f ies additional co referring clusterthe artsandthe art.
though they look similar they are referringto differentabstract concepts.
example .
anexample ofextraentity ee thecongressman wasknownasaferventliberalandsupporter ofthearts andhe wasnotedfor his successingetting congress to f inancefornationalendowmentfor theart .
.
.
missingentity me .
oppositeto extraentity missingentity describes an issue where the entity should have been identi f ied yet ismissed.examplesare omitteddueto spacelimitation.
.
.
conflatedentity ce .
ifacrsystemmistakenlymergestwo ormoreclustersofentitiesintoone aceissueoccurs.seeexample there are three clusters of entitiesin thesentence while in the output clusters the cr system mistakenly merges the second and the thirdclusterstogether causing aceissue.
example .
anexample ofcon f lated entity ce thescotts ran it past their vet andthe vet assured them as long as the hen lefther crate to do business she wasnohurtto the pup.
thescotts ran it past their vet andthe vet assured them as long as thehen lefther crate to do business she wasnohurtto the pup.
.
.
extramention em .
ifaclustercontainsoneormore mentionsthatarenotco referringtotheentityastheremainingmentionsinthatcluster itisregardedasanextramentionissue.forexample inthefollowingsentence thename tanshuianditspronoun 115esec fse december3 san francisco ca usa jialun cao yaojielu ming wen shing chi cheung a numbers of issue types found by each approach.
b humanevaluation result s figure5 barchartsoferrortypedistribution a andnaturalnessofgenerated sentences b .
herare correctly identi f ied while the giant beast of development is unrelatedto tanshui letalone referringto it.
example .
anexample ofextramention em loversoftanshui whilekeepingwatchover her arefearful thatthegiantbeast of development may eventuallycome and bulldozetanshui away one pieceofland at atime.
.
.
missingmention mm .
oppositetoem ifanymentionin anyclusterismissing thenitisamissingmentionissue.mmissues usuallyhappeninlongsentenceswheretherearemorethantwo mentions referringto one entity event.
.
.6span error se .ase issuedescribes the situation where the span of the identi f ied mention is larger or smaller than the ground truth mention.
for example in example the ground truthcris suchafeverchip it whilethecrsystemidenti f iesthe wrongspan for the f irstmentionas follows.
example .
anexample ofspan error se however panpointsoutthattheusefulnessof sucha feverchip is still limited so that it cannot yet bewidely promoted.
however panpointsout that theuseful ofofsucha fever chip u1d446 u1d45d u1d44e u1d45b u1d438 u1d45f u1d45f u1d45c u1d45f is still limited so that it cannot yet be widely promoted.
furthermore weshowthestatisticsofissuetypesfoundbyeach approach in figure a .
notethat an incorrect coreference could beattributedtomorethanoneissuetype andthecoreferenceof both source and follow up inputs could be wrong.
from the f igure we can see that crestcould reveal issues in diverse types and the number of each issue type keeps a better balance than baselines.
on the contrary baselines tend to reveal more missing mention mm and extra mention em issues than other issue types and are ineffective inrevealingcon f latedentity ce issues.
besides divided entity could not be revealed by any of the approaches.
the reason is that this issue type usually occurs in document level coreference i.e.
the coreference across sentences whileweusetheintra sentencecoreference i.e.
thecoreference occurs within asentence for evaluation.
.
rq4.
impactofeach step there are three main steps in crest.
to explain the impact of each step we conduct the following experiments.
.
.1impactofstep1 follow upinputgeneration .
the f irst stepofcrestistogeneratefollow upinputsofagivensourceinput.
inthisstep theparameter u1d440prescribesthemaximumnumberof follow up inputs for one source input.
to quantify the importancetable impact of steps and of crest.
the con f iguration u1d440meansthenumberofmaximumgeneratedfollow upinputs inalgorithm in step1of crest.
the con f iguration filter denotes whether step of crestis conducted w or not w o .thevaluesthataresensitivetothecon f iguration are highlighted inyellow.
con f iguration test generation error detection coref preserving u1d440select gen issues hits tp fp prec w .
.
.
w .
.
.
w .
.
.
w .
.
.
w o .
.
.
w o .
.
.
w o .
.
.
w o .
.
.
ofstep1 weset u1d440as10 and50 respectively toshowthe impact on the effectiveness.
the experiment settings and the cr system undertestarethesameasthat intable .theexperiment is shown in table .
as u1d440increases the entry m the number of follow up inputs increases accordingly ranging from to and more inconsistencies issues are reported from to .
besides note that the hit rate stays stable meaning that with at most follow ups generated around incorrect coreferenceinthesourceinputscanbesuccessfullyidenti f ied while afterthat simplyincreasingthenumberofgeneratedfollow ups can hardly hit more faults in the source coreference.
regarding the precision wecanseethatwithstep2 i.e.
follow upinputselection enabled the precision of creststays at regardless of how manyissuesarereported.therefore weconcludethattheimpact ofstep1mainlyliesinthenumberofrevealedissues andwould not affectthe precision of crest.
.
.
impactofstep2 follow upinputselection .
step2further f ilters out the follow up inputs according to the cr related tokens in thegrammar structure.in particular we showtheresults when step is enabled or disabled.
the result is shown in table the entry select .
we can see that when step is disabled i.e.
w o the precision dropsto around91 compared with when it is enabled i.e.
w and the ratio of coreference preserved follow ups dropsfrom to around .
also when step isdisabled the number of true positives decreases by accounting for .
.
percentdecrease.tosumup theresultvalidatesthesigni f icanceof step2fromtwoaspects.first by f ilteringoutabout13 coreferencechanged follow ups step makes sure the precision of error detectionreaches100 a10 increasefromthatwithouttheselection.
second step keeps a high precision with slightly fewer true positives detected andwithouthit ratedecreases.
.
.
impactofstep3 inconsistencydetection .
instep3 crestreports an inconsistency if any of the precision and recall of the coreferenceislowerthan1.
i.e.
u1d461 uni210e u1d45f u1d45d u1d461 uni210e u1d45f u1d45f .
.weusetwo examplestoshowtheirimpacts.example13showsthatwhen u1d461 uni210e u1d45f u1d45d drops while the u1d461 uni210e u1d45f u1d45fremains to be .
there are extra coreferencelinksaremistakenlyidenti f iedfromthesentence.inparticular there is only one link in the ground truth while three links are identi f ied sothe precision of coreference is .
.
while fortherecallofcoreference sinceallthecoreferencelinksinthe ground truth are identi f ied the recall is .
.
example shows 116testingcoreference resolutionsystems without labeledtestsets esec fse december3 san francisco ca usa thatwhen u1d461 uni210e u1d45f u1d45fdropswhilethe u1d461 uni210e u1d45f u1d45dreserves therearecoreference links thatshouldbe identi f iedyetmissed.example 14shows the situation.
in the ground truth there are seven coreference links whileonlysixofthemarerecalled sotherecallofcoreferenceis .
whilethe precision staysat .
.
example .
example .
tosumup ahigher u1d461 uni210e u1d45f u1d45drequiresmorecorrectcoreferencelinks regardlessofthenumberofmissinglinks while u1d461 uni210e u1d45f u1d45frequiresmore linkstobeidenti f iedthoughtheremaybeincorrectlinksinvolved.
related work .
testingtechniques fornlpsystems varioustestingmethodologieshavebeenproposedforspeci f icnlp taskssuchasneuralmachinetranslation codeanalysis andqa .arecentsurvey pointsout thatmetamorphictesting isthemostpopulartestingapproach for ai systems.
a recent study benchmarks state of the art metamorphic testing approaches and f inds that a large proportion oftheirgeneratedinputsviolatethemetamorphicrelations leadingtohighfalsepositiverates.thereareafewrecentworksthat couldbeusedforcrsystemtesting.checklist listsamatrixof linguisticcapabilities e.g.
robustness and testtypes e.g.
invariancetest .inthiswork whetherthecoreferencecanbecorrectly resolvedisconsideredalinguisticcapabilityto betestedinupperstreamapplicationssuchasmachinecomprehension.testsarethen generatedeitherbytemplatesorbytextualtransformations e.g.
inserting typos .
yet text transformations have high probabilities tochangecoreferenceinthesentence.textflint providesamultilingualrobustnessevaluationplatformthatincorporatesuniversal texttransformation adversarial attack etc.for cr systems transformations such as random sentence deletion in a paragraph are proposed.
these transformations are only suitable for coreference acrosssentences paragraph levelcoreference whileourworkis suitable for both sentence and paragraph level coreference.
another testing technique astraea targets the fairness of nlp tasks such as cr .
it generates sentences by changing occupations andmale femalepronounstotestthefairnessofthenlpsystem under test.
our work complements existing works.
it focuses on effectivelygeneratingtestinputsthatrespectcoreference which has not been exploredbyprior techniques.
.
adversarialtechniques fornlpsystems adversarial attack techniques aim to produce adversarial examples to confuse ai systems.
they perturb benign inputs by applying certainadversarial perturbations so thatthe generated adversarialexamplessuccessfullyconfusetheaisystemmaking wrongpredictions.inparticular therearevariousadversarialattack approachestargetingnlpsystems includingcharacter level word level sentence level andmultiple level attacks.severalstudiessummarizethestate of the artadversarial attack algorithms and defending algorithms .
besides severaloff the shelftool kits areavailableto generateadversarialattacksongeneral orcertain nlp tasks.popularperturbationssuchaswordreplacementhavebeen incorporatedinthebaselinesinourevaluation.anadversarialattack technique which assumes all input data to be labeled was recentlyproposedforcrsystems.thistechniqueissubsumedby thebaselinesit withonlythewordin themention replaced withits semantic relatedsubstitutions e.g.
synonym .
threats ofvalidity wediscussthreethreatsinthiswork.first theexperimentalprocedures involve random sampling which may induce randomness in the results.
to mitigate this threat we sampled samples as seeds whichis f ivetimesthesamplesizeofpriorwork .
also the experimental results show that our work outperforms thebaselinessigni f icantly.thedegreeofoutperformancesurpasses randomness.two thenumberoftestsgeneratedbythebaselines may be sensitive to parameter settings.
to accommodate the variation experiments are designed to evaluate the quality of generated testsrather thanthe numberof testsgenerated.
inthecurrent evaluation weadoptthedefaultparametersettings e.g.
parameters languagemodels ofthebaselinestofacilitatecomparison.third the human evaluation of sentence naturalness is conducted over a crowd sourcingplatform wheretheeducationleveloftheparticipants varies.
to mitigate the threat we involve two professional english tutors as participants as well.
conclusion in this paper we introduce crest ageneralmethodologyfor validating cr systems.
it tackles the difficulty in automatically constructing test inputs by considering the coreference during test generation in aid of syntax analysis.
the experiment reveals the effectivenessof crestbyachieving100 precisionininconsistency detection and100 ofthe generatedtests are of high quality.