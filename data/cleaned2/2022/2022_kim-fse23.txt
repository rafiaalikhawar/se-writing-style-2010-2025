funprobe probing functions from binary code through probabilistic analysis soomin kim softsec lab.
kaist daejeon korea soomink softsec.kaist.ac.krhyungseok kim softsec lab.
kaist daejeon korea hskim softsec.kaist.ac.krsang kil cha softsec lab.
kaist daejeon korea sangkilc softsec.kaist.ac.kr abstract current function identification techniques have been mostly focused on a specific set of binaries compiled for a specific cpu architecture.
while recent deep learning based approaches theoretically can handle binaries from different architectures they require significant computation resources for training and inference making their use less practical.
furthermore due to the lack of interpretability of such models it is fundamentally difficult to gain insight from them.
hence in this paper we propose funprobe an efficient system for identifying functions from binaries using probabilistic inference.
in particular we identify architecture neutral hints for function identification and devise an effective method to combine them in a probabilistic framework.
we evaluate our tool on a large dataset consisting of real world binaries compiled for six major cpu architectures.
the results are promising.
funprobe shows the best accuracy compared to five state of the art tools we tested while it takes only seconds on average to analyze a single binary.
notably funprobe is faster on average in identifying functions than xda a state of the art deep learning tool that leverages gpu in its inference phase.
ccs concepts software and its engineering software testing and debugging .
keywords binary code analysis function identification probabilistic analysis acm reference format soomin kim hyungseok kim and sang kil cha.
.
funprobe probing functions from binary code through probabilistic analysis.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
https introduction function identification is a pivotal task in binary analysis.
major decompilation techniques such as variable recovery type recovery and high level control flow restructuring permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for third party components of this work must be honored.
for all other uses contact the owner author s .
esec fse december san francisco ca usa copyright held by the owner author s .
acm isbn .
at a function level assuming control flow graph cfg of a function is given.
binary level control flow integrity approaches such as adopt a function level protection mechanism too.
conventional approaches to binary level function identification employ various target specific heuristics which are often specifically devised to handle specific types of binaries to overcome the intrinsic difficulty of binary analysis.
for example ghidra and fetch identify functions by leveraging c exception handling information which does not necessarily exist in all binaries.
similarly ddisasm and funseeker leverage target specific syntactic patterns and jima harvests function pointers from analyzing specific data sections.
while such approaches are effective in identifying functions in certain binaries they are not generally applicable to all binaries.
learning based approaches have been proposed to overcome the limitations of conventional approaches.
particularly deep learning based approaches recently demonstrate high accuracy in identifying functions.
while these approaches do not require target specific heuristics they still suffer from three critical limitations.
first their detection performance is highly dependent on the training dataset used.
second they require significant computation resources for both training and inference.
thus applying them to large scale binary analyses is not trivial in practice.
furthermore those models are notinterpretable making it difficult to gain useful insight into the learned models.
as such one cannot easily understand why a particular function is misclassified hence further improving the model is challenging.
therefore in this paper we seek to develop a function identification algorithm that is general efficient and interpretable .
our approach should work for a wide range of binaries compiled for various cpu architectures should run fast on a regular desktop machine and should not rely on a deep learning model that is difficult to understand.
to this end we identify architecture neutral hints and combine them to form a probabilistic model for function identification.
the key intuition of our approach is that every function identification heuristic has a certain level of uncertainty which can naturally be represented as a probability.
for example many tools heuristically regard a target of a call instruction as a function entry point but call targets are not always a function entry point in reality.
such a heuristic is not always correct but does provide a probabilistic hint for function identification.
hence we combine those hints to form a bayesian network bn representing causal relationships between them.
our bn based approach naturally allows us to reason about why a particular address is identified as a function entry point because the posterior probabilities let us know the influence of each hint on the address.esec fse december san francisco ca usa soomin kim hyungseok kim and sang kil cha there are mainly two challenges in designing our algorithm.
first our approach should be generally applicable to any type of compiler generated binaries built with varying compilers compiler options and target architectures.
second our model i.e.
a bn naturally includes cyclic dependencies which is expensive to handle if not impossible .
hence we should devise an efficient way to perform probabilistic inference on our bn.
we address the first challenge by carefully selecting architectureand compiler independent heuristics such as those found in control flows between functions and basic blocks .funprobe employs intuitive function identification hints obtained either from existing work or from our own observations.
we also tackle the second challenge by exploiting the fact that our bn includes many unnecessary edges.
specifically we devise a novel approach named bogus dependency pruning which heuristically removes edges as well as loops from a bn.
our technique enables .
faster function identification with negligible accuracy drop as shown in our experiments.
to realize these ideas we implement funprobe a novel function identification tool that runs on raw i.e.
stripped binaries.
it leverages our bogus dependency pruning technique to quickly decide whether every instruction in the target binary should be considered to be a function entry point or not.
we evaluate funprobe on a large scale benchmark that includes real world binaries compiled for six major cpu architectures.
our evaluation confirms thatfunprobe shows the best accuracy compared to the five stateof the art binary analysis tools including ida pro ghidra and xda while it takes only seconds on average to analyze a single binary.
notably funprobe is faster than xda a state of the art deep learning tool without the need for gpu resources.
we also demonstrate that funprobe is complementary to xda.
by simply feeding the output of xda into funprobe we were able to achieve .
of f1 score on our benchmark.
overall this paper makes the following contributions.
we present a novel function identification algorithm that leverages a bn.
we propose bogus dependency pruning to efficiently derive solutions from a bn.
we design and implement funprobe that incorporates our novel function identification algorithm.
we publicize our tool to support open science ub.com b2r2 org funprobe.
background and motivation this section describes the basic concept of bayesian network bn and belief propagation and motivates our research.
notation.
in this paper p x denotes the probability distribution of a boolean random variable x. for simplicity we let p x be the probability of xbeing true i.e.
p x p x .
.
bayesian network belief propagation bayesian network bn is a set of directed acyclic graphs dags each of which represents causal dependencies between random variables .
each node in a bn is a random variable and eachdirected edge represents a dependency between two random variables.
for example an edge x ymeans thatxcausesy oryis dependent on x .
we use a bn to model the relationships between probabilistic statements such as the probability of an address being a function entry point .
consider a basic block located at address .
letf be a boolean random variable indicating whether or not is a function entry point and let c be a boolean random variable denoting whether or not is a target of a call instruction.
we can then represent a causal relationship between f andc with an edge c f in a bn ifc is true there is a call instruction whose target is thenf is likely to be true is a function entry point .
such a relationship can be denoted by a conditional probability p f c and we call it a hint throughout this paper because it provides a hint for identifying functions.
notice not every random variable in a bn is observable.
in the above example f is ahidden random variable whose value cannot be directly observed from analyzing a binary.
on the other hand c can be easily observed we can disassemble a binary and see if there is acall instruction whose target is .
therefore our goal in this paper is to compute the marginal probabilities of hidden random variables e.g.
p f based on the probability distributions of the observed variables.
this process is often referred to as probabilistic inference which does notscale well with the number of random variables the number of terms to consider for marginalization grows exponentially to the number of hidden variables.
belief propagation is a technique that addresses the scalability challenge with a dynamic programming method.
when a bn contains a loop however belief propagation cannot compute the exact solution .
thus loopy belief propagation is used as an alternative which iteratively runs belief propagation until it converges or reaches a fixed time limit.
however when a graph is large and highly connected loopy belief propagation is still computationally expensive .
in this paper we propose an efficient way to perform belief propagation on a large size cyclic bn by reducing the graph size see .
.
.
motivation while hints are useful to identify functions they do notprovide a definite answer.
in this section we motivate the need for a probabilistic method by illustrating how one can combine various hints collected from a binary to make a precise decision.
to support our claim we ran nucleus on dir a binary taken from gnu coreutils to identify functions from it.
figure 1a shows the disassembled code snippets of the binary.
to ease the explanation we explicitly mark function entry points in figure 1a with symbols although we used a stripped binary when we ran nucleus.
in this example nucleus identifies functions using two hints the target of a call instruction is likely to be a function entry point and a no op like instruction is unlikely to be a function entry point as it is often a padding sequence .
unfortunately both hints suffer from a certain level of uncertainty.
the first hint seems legitimate as call instructions are designed to call a subroutine in a program.
however there are cases where a call instruction is used to retrieve the current program counter pc .
for example a code pattern call pop ebx where the target of call isfunprobe probing functions from binary code through probabilistic analysis esec fse december san francisco ca usa 0x3bb0 main 0x3bb0 push r15 0x3bb2 push r14 0x3bb4 mov r14d edi 0x3bb7 push r13 0x3bb9 push r12 ... 0x4944 mov edi 0xd 0x4949 call 58b0 is colored ... 0x5830 dev ino free 0x5830 jmp 1b770 rpl free ... 0x58b0 is colored 0x58b0 mov edi edi 0x58b2 lea rax 0x58b9 shl rdi 0x4 0x58bd add rdi rax 0x58c0 xor eax eax 0x58c2 mov rdx qword ptr 0x58c5 test rdx rdx 0x58c8 je 58df ... a disassembled x86 binary code.
0000f4 0000c8 fde cie pc 000058b0 .. dw cfa nop ... b frame description entry fde for is colored .
figure our motivating example taken from dir a gnu coreutils binary compiled with gcc.
thepopinstruction is often used to obtain the current pc.
similarly the latter hint is not always correct compilers sometimes emit a no op like instruction at a function entry point.
the primary challenge here is that there are cases where two hints are in conflict.
conventional approaches such as nucleus would simply follow one of them.
in our example the function at 0x58b0 is a target of the call instruction at 0x4949 .
thus nucleus can correctly identify the function with the first hint.
however the function begins with a no op instruction which is deemed as an invalid instruction by nucleus based upon the second hint.
note that mov edi edi does not change the cpu state except for the program counter and is often used as a padding byte.
the second hint makes nucleus disregard the function thereby causing a false negative error.
funprobe handles such an intrinsic challenge with a probabilistic framework.
intuitively each different hint provides a different clueabout identifying function entry points and we can represent their relationships with a bn.
if we collectively consider the observed hints in the bn we can make a decision in a more systematic andholistic way.
for example let us consider an additional heuristic developed by fetch which leverages exception handling information stored in the .eh frame section of elf binaries.
the section stores a sequence of frame description entries fdes each of which corresponds to a consecutive code chunk in the binary.
typically each code chunk represents a function although there are exceptional cases .
therefore in our example the fde shown in figure 1b indicates that there is a code chunk located at 0x58b0 and it is likely that the address indicates a function entry point.
with such an additional hint we can say that 0x58b0 is more likely to be a file alt binary programhint collectormodel builderinferencer list function entry pointshints bn figure funprobe architecture.
f58b0 f1b770c58b0 n58b0e58b0p f58b0 c58b0 .
p f58b0 n58b0 .4p f58b0 e58b0 .
p f1b770 f58b0 .
figure illustration of the bn generated from our example.
function entry point two positives vs. one negative .
as we will discuss funprobe provides a way to systematically make an informed decision by gathering all the observed hints.
overview in this section we first present the overall architecture of funprobe and describe its workflow with a running example shown in figure .
we then discuss several technical challenges in designing funprobe .
.
funprobe architecture figure illustrates the overall architecture of funprobe which takes in a binary as input and produces a set of function entry points as output.
funprobe consists of three components hint collector model builder and inferencer .hint collector harvests hints by analyzing the given binary.
model builder constructs a bn using the collected hints.
inferencer runs belief propagation on the bn to infer the marginal probabilities for each address in the binary can be a function entry point.
we now demonstrate the component wise workflow of funprobe using the example binary shown in figure .
note our system runs on a stripped version of the binary.
.
hint collector first hint collector takes in a binary as input and outputs a set of hints taken from the binary.
formally a hint is a conditional probability for an address being a function entry point.
let f be a hidden boolean random variable indicating whether or not is a function entry point.
we can then define a hint as a conditional probability of the form p f x wherexis a boolean random variable and xis a shortcut for x 1as we defined in .
hint collector analyzes the given binary to construct an inter procedural cfg .
and it collects different types of hints from the cfg as well as the metadata stored in the binary .
.
from our example binary shown in figure hint collector outputs a variety of hints including the following four p f58b0 c58b0 p f58b0 e58b0 p f58b0 n58b0 andp f1b770 f58b0 esec fse december san francisco ca usa soomin kim hyungseok kim and sang kil cha wherec58b0indicates that 0x58b0 is a call target e58b0means that there is an fde for the instruction located at 0x58b0 andn58b0 shows that the instruction located at 0x58b0 is semantically a no op instruction it does not change any cpu state except for the pc.
note that two hidden random variables e.g.
f1b770andf58b0 can also have a causal relationship.
let us consider the tail call heuristic used by many tools which regards a jump as a tailcall when it crosses over a function entry point.
this strategy is based on the observation that compilers usually emit a function body in a consecutive region.
therefore if a jump instruction passes over another function entry point it means the jump target is likely to belong to another function.
in our example binary there is a jump instruction located at 0x5830 and there is another function entry point at 0x58b0 in between the jump instruction and its target 0x1b770 .
therefore if there is a function entry point between 0x5830 and0x1b770 then 0x1b770 is also likely to be a function entry point.
this observation provides at most distinct hints p f1b770 f5831 p f1b770 f5832 p f1b770 f1b76f in case the addresses are filled with single byte instructions which can easily bloat up the bn rendering our probabilistic inference inefficient.
thus we reduce the number with a novel technique named bogus dependency pruning .
.
.
model builder model builder first builds a bn from the observed hints.
specifically each hint forms an edge in the resulting bn.
figure illustrates the bn obtained from our example binary.
the bn only shows four hints i.e.
edges for simplicity.
next model builder assigns probabilities for each edge based on the characteristic of each corresponding hint.
specifically we use two user configurable probability values one for positive hints and another for negative hints.
we say a hint is positive if it increases the likelihood of the corresponding address being a function entry point and negative if otherwise.
for example p f58b0 c58b0 increases the likelihood of 0x58b0 being a function entry point because it is used as a call target thus it is a positive hint.
on the contrary p f58b0 n58b0 decreases the likelihood of 0x58b0 being a function entry point because there is a no op instruction at 0x58b0 thus it is a negative hint.
obviously positive hints such as p f58b0 c58b0 should have a high value close to and negative hints such as p f58b0 n58b0 should have a low value close to in order for them to respectively give a positive and negative influence to the probability of 0x58b0 being a function entry point.
we introduce two user configurable parametersp andp in order to assign the probability values for positive and negative hints.
in our current implementation we use p .65andp .4by default which are empirically chosen best parameter values see .
.
thus in the previous example we assign .
to p f58b0 n58b0 and .
to the other edges.
the marginal probabilities i.e.
p f58b0 andp f1b770 are then computed in the next step based on the assigned probabilities.
.
inferencer inferencer takes in as input the initialized bn and performs belief propagation on the bn to compute the marginal probabilities.that is our goal here is to obtain p f58b0 andp f1b770 shown in figure .
once we have the marginal probabilities we can decide whether each address is a function entry point or not.
in our current implementation we say an address is a function entry point if p f .
.
in our example using belief propagation inferencer returnsp f58b0 .
andp f1b770 .
.
since these probabilities are higher than our threshold .
we regard both of them as a function entry point.
recall from .
that a tail call detection strategy can easily produce thousands of hints which makes the resulting bn complex and highly connected with loops.
therefore inferencer does not scale well with large binaries with many functions.
we overcome this challenge by introducing a novel technique named bogus dependency pruning as we detail in .
.
4funprobe design this section details the design of funprobe .
we first show how funprobe prepares an inter procedural cfg to extract hints from the binary .
.
next we present all the function identification hints that funprobe utilizes and discuss how we make them general .
.
finally we present bogus dependency pruning a technique to simplify bns to make probabilistic inference efficient .
.
.
control flow graph construction to collect hints from binaries in architecture independent and compiler independent manner we mainly focus on structural features that can be obtained from a cfg instead of observing instruction patterns.
one can leverage existing binary analysis frameworks such as ghidra and angr to obtain cfgs from a binary but those tools typically involve heavy cost analyses.
thus we perform our own lightweight analysis to quickly recover cfgs so that we can apply our function identification strategies to them.
note that our cfg recovery is a preprocessing step for function identification and our goal is far from constructing precise cfgs.
our analysis runs in the following four steps.
linearly disassemble the given binary .
.
.
detect non returning function calls .
.
.
resolve indirect branch targets .
.
.
build inter procedural cfg .
.
.
.
.
linear sweep disassembly.
hint collector first linearly disassembles instructions from a given binary.
one could use superset disassembly to completely recover all possible instructions in the binary but linear sweep disassembly is widely known to be efficient in achieving high instruction coverage without many false positives .
therefore we chose linear disassembly a simpler technique for our implementation.
one challenge here is to avoid disassembling embedded data in code sections which are commonly found in armv7 binaries.
to distinguish code and data we examine every memory load from the disassembled instructions and filter out instructions that are referenced from another instruction.
.
.
non returning function call detection.
not every function call returns.
thus we cannot simply connect a cfg edge from a call instruction to its fall through instruction.
having a bogus edgefunprobe probing functions from binary code through probabilistic analysis esec fse december san francisco ca usa table function identifcation hints that funprobe used.
function identification hints r. v. influence used bydata1pointers in known pointer array sections e.g.
.init array refer to a function entry point.
p 2non strippable function symbols point to a function entry point.
d 3relocation entries can specify a function entry point.
r 4an fde frame description entry can point to a function entry point.
e 5pointer like values in data sections e.g.
.data can refer to a function entry point.
v code6call targets can be a function entry point.
c all 7when a jump edge crosses a function entry point then the jump is likely to be a tail call.
f 8if a call target is a jump instruction then the jump target is likely to be a function entry point.
w new 9unreachable basic blocks are likely to be a function.
u 10an unreachable basic block surrounded by two connected basic blocks is unlikely to be a function.
s new 11padding sequences such as no op are unlikely to be a function entry point.
n 12if there are only no op instructions between a jump instruction and its target then the jump is likely to be a no op.
i new 13inlined pc getters are unlikely to be a function.
g 14conditional jump targets are unlikely to be a function entry point.
j 15basic blocks before the main entry point of a binary are unlikely to be a function.
a new 16basic block leaders are unlikely to be a function entry point.
b all r. v. stands for random variable.
can be problematic especially when a new function starts immediately after a non returning function call.
for example a function may start right after a call toexit because exit will never return.
thus it is imperative to identify non returning function calls to obtain precise cfgs.
hint collector employs a widely used mechanism for detecting non returning functions which simply finds calls to a known non returning function name .
this is possible because even a stripped binary maintains the symbols of imported functions.
in our implementation we use the same list of non returning function names used by ghidra .
.
.
indirect branch resolution.
it is crucial to resolve indirect branch targets to improve the coverage of a cfg.
for example when an edge from an indirect branch to a basic block is missing one may falsely identify the missing block as a function.
to recover the targets of indirect jumps we leverage a pattern based heuristic used by ghidra .
specifically we find the corresponding jump table based on the instruction patterns near the indirect jump instruction and parse the jump table to recover the indirect jump targets.
.
.
inter procedural cfg building.
given a list of disassembled instructions .
.
a set of non returning function call sites .
.
and a set of jump targets for each indirect branch .
.
hint collector finally builds an inter procedural cfg.
additionally we parse exception handling information and connect edges from a tryblock to its corresponding catch block s .
.
function identification hints funprobe gathers kinds of hints listed in table .
the first column shows the information source.
the second column describes each hint.
the third column shows which random variable is used to represent each hint.
for example a random variable x for an address can represent a hint p f x .
the fourth column indicates how each hint influences function identification whether it is a positive hint or a negative hint .
and the last column specifies which tool is using the corresponding heuristic.
we mark with all when it is used by every tool that we studied and new when we are unaware of a tool that employs a similar heuristic.we note that all these hints rely on architecture neutral metadata and cfg structural features.
such a design choice makes funprobe perform well across various binaries obtained from different architectures and compilers as we will show through our experiments.
.
.
hints from data.
hints 1and 2are derived from elf metadata.
first elf binaries have special sections that contain function pointers such as .init array and.fini array .1states that those values are always function addresses i.e.
p f p .
.
second there are function symbols that remain intact even after stripping e.g.
got based indirect jump targets in mips .2suggests collecting such function addresses by analyzing symbols.
both and 2provide definite evidences for a function located at so we assign the probability .
i.e.
p f .
.
for other hints we assign probability values based on the parameters p andp .
hint 3provides a positive prediction for a code address if it is pointed to by a relocation entry p f r p .
relocation entries often contain function pointers.
for example when a pie position independent executable has a global function pointer it should be relocated at runtime by the loader.
hence a relocation section e.g.
.rela.dyn of the binary should store a relocation entry for the function pointer.
hint 4states that addresses found in .eh frame are likely to be a function address.
modern compilers have recently started to provide exception handling information for every c function in order to support c interoperability .
particularly the .eh frame section contains a list of frame description entries fdes to support stack unwinding when an exception occurs and such information allows us to infer function addresses .
hint 5suggests that a data value is likely to be a function address if it is within a valid code address range.
this heuristic is employed by several reassemblers such as ramblr and ddisasm .
the intuition is that a constant value in a data section is likely to be a function pointer if it is within a valid address range.
.
.
hints from code.
hint 6says that a call target is likely to be a function entry point.
hint 7states that a jump target is likely to be a tail call i.e.
the target is a function entry point if the jump crosses over a function entry point.
both hints are discussed in .
.esec fse december san francisco ca usa soomin kim hyungseok kim and sang kil cha hint 8handles a special case where a function body solely consists of a single unconditional jump instruction see line of figure 1a .
such functions usually act as a trampoline passing arguments to another function.
hint 9helps discover functions from unreachable parts of our cfg.
since our cfg reconstruction .
is incomplete it may leave several basic blocks within the range of a function unreachable.
such a code chunk is often referred to as a gap and this hint says that every basic block found in a gap is likely to be a function entry point.
however not every unreachable basic block is a function entry point and 9alone can produce many false positives.
thus we have to employ several negative hints to filter out false cases.
hint 10says that gaps surrounded by connected basic blocks in our cfg are unlikely to be a function entry point.
this is because a function body is usually a consecutive chunk of code.
thus such a gap is unlikely to be another function.
compiler generated padding bytes may form a gap too.
thus hint 11helps disregard padding bytes from being considered a function entry point.
compilers can also use jump instructions to fill a gap.
for example consider a code pattern ret jmp lbl nop lbl push ebp .
in this example theretinstruction is the end of a function and push ebp is the start of the next function.
the jmpinstruction between these two functions is unreachable and it merely acts as a dummy padding.
12helps detect such a pattern to disregard the gap from being considered as a function entry point.
recall from .
there are cases where a call instruction is used to retrieve the current pc.
hint 13helps prevent a call target of a pc getter from being considered as a function entry point.
hint 14states that jump targets of a conditional jump are unlikely to be a function entry point because a conditional jump is rarely a tail call .
hint 15suggests that basic blocks before the main entry point i.e.
start are unlikely to be a function entry point.
this is because gcc often puts rarely executed parts of a function named with the suffix .cold in the separate text sections.
and the sections are often relocated before the main entry point.
hint 16says that while a leader of a basic block is a potential function entry point most leaders are not.
this is the nature of a cfg only the root node is a function entry and the rest are not.
.
.
generality of function identification hints.
we claim that our function identification hints in table are general enough to analyze various kinds of binaries.
hint 4use metadata commonly found in elf binaries.
although our current implementation handles only elf binaries other file formats provide similar information and supporting them should be straightforward.
hint 5exploits a general characteristic of function pointers found in binaries.
hint except 11and are based on structural properties found in cfgs.
11and 12are based on semantic properties of instructions which can be captured by lifted intermediate represent ir .
it is worth noting that modern compilers tend to put regular functions after the entry point i.e.
start .
we found that gcc often puts a part of a function such as .part and.cold snippets before the entry but the main body of the function is mostly after the entry.
we confirmed that this is also the case for clang too.algorithm bogus dependency pruning algorithm.
1function bogusdenpendencypruning g 2g v e removeobservednodes g 3gt computepolytree g 4g t restoreobservednodes gt v e returng t .
bogus dependency pruning although funprobe employs only hints they can produce an extremely large bn with many loops which makes traditional belief propagation significantly slow if not impossible.
in our dataset funprobe builds a bn of 46k nodes and 255k edges per binary on average.
therefore we devise a novel approach to reduce the size of a bn while not sacrificing much the accuracy.
we note that hint 7is the major source of complexity.
first it produces too many bogus dependencies as we discussed in .
.
formally we say a hint p f f isbogus if or is not a function entry point.
from our dataset we found that about of dependencies introduced by 7were indeed bogus dependencies.
second 7can create cyclic dependencies i.e.
loops in the resulting bn.
for example three hints f f f f andf f form a loop which prevents us from using the traditional belief propagation.
therefore we propose a novel method named bogus dependency pruning to find out and exclude such bogus dependencies as well as loops so that the resulting graph becomes simple and loop free allowing us to use the traditional belief propagation.
algorithm describes the overall process of bogus dependency pruning.
it takes in as input a bn g which is a set of dags and returns a modified bn g t which is a set of polytrees as output.
in lines and observed nodes in the given bn are temporarily removed g and restored g t in order to make the polytree calculation efficient .
.
.
in line we reduce each dag in the modified bn to a polytree .
.
.
.
.
removing and restoring nodes.
removeobservednodes and restoreobservednodes are respectively preprocessing and postprocessing steps of our dependency pruning process .
.
.
when removeobservednodes temporarily removes all the observed nodes and their outgoing edges removed nodes v and edges e are returned and they are restored in restoreobservednodes .
note that our polytree computation .
.
is not affected by removing observed nodes because each of those nodes has a degree of one.
therefore the removed nodes and edges will always be included in the resulting polytree anyways.
by temporarily removing all the nodes of degree one we can make our polytree computation fast.
.
.
computing polytree.
given the modified bn g a function computepolytree transforms each dag in g into a polytree.
the transformation runs in three steps.
first we convert a dag into an undirected graph.
second we run kruskal s minimum spanning tree algorithm using our custom weight that prefers edges with more positive hints.
formally we define a weight w for an edgef f as w m i 1w xi n i 1w xi !
funprobe probing functions from binary code through probabilistic analysis esec fse december san francisco ca usa wherexi means thei th observed boolean random variable with regard to the address andmandnare the numbers of observed boolean random variables for and respectively.
the function woutputs when the given random variable represents a positive hint and for a negative hint respectively.
for example consider the edge f58b0 f1b770shown in figure .
we can compute the weight of the edge as below.
w 58b0 1b770 w c58b0 w e58b0 w n58b0 .
this way we can prefer edges that provide more positive influence in detecting functions.
notice that we negatize the sum as kruskal s algorithm prefers a smaller weight.
.
implementation funprobe is written in .5k sloc of f .
to parse elf file headers and disassemble instructions for various architectures we used b2r2 which provides an efficient binary analysis front end.
evaluation in this section we evaluate funprobe to answer the following research questions.
rq1.
how do the probability parameters affect the effectiveness of function identification?
.
rq2.
how much performance gain does bogus dependency pruning provide?
.
rq3.
how well does funprobe perform against the conventional function identification tools?
.
rq4.
how well does funprobe perform against the learning based function identification tools?
.
rq5.
canfunprobe and learning based approaches be complementary to each other?
.
.
evaluation setup .
.
benchmark.
we build our benchmark by compiling three popular packages gnu coreutils v9.
programs gnu binutils v2.
programs and spec cpu2017 programs written in c and c languages.
we consider the following compiler configurations to build our benchmark target architectures position independence and code optimization levels.
these configurations can largely affect the shape of resulting binaries thereby impacting the function identification results.
specifically we chose popular cpu architectures x86 x86 armv7 aarch64 mips and mips64 major compilers gcc v8.
.
and clang v13.
.
both pie and non pie options and six different compiler optimization levels o0 o1 o2 o3 os and ofast .
this gives us a total of different configurations.
as a result our benchmark consists of binaries.
to the best of our knowledge this is the largest benchmark used to evaluate function identification algorithms .
.
.
ground truth.
to evaluate function identification tools we need to obtain the ground truth of our benchmark i.e.
a set of function entry points for each binary.
specifically our ground truth data deal with functions located in the .text section.
we mainly leveraged debugging information to gather ground truth data.
also table f1 scores achieved with different parameter values.
p .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
p .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
we manually filtered out several function symbols with .cold or .part suffixes from gcc compiled binaries .
additionally we manually added the addresses of compiler intrinsic functions to our ground truth data as they do not have debugging information.
.
.
comparison target.
we selected five state of the art tools for comparison.
four of them use conventional binary analyses ida pro v7.
.
binary ninja v3.
.
ghidra v10.
.
and nucleus commit e3ab49d .
one of them uses a deep learning model to identify functions xda commit 068007c .
we finetuned xda on a subset of our benchmark following the recommendation of the authors .
specifically we randomly selected binaries of x86andx86 binaries in our benchmark to create about 640k training byte sequences.
xda is a representative ml based solution that is publicly available.
to our knowledge it had demonstrated the best function identification accuracy so far in the literature.
while there is another noteworthy tool named deepdi it is closed source hence we were not able to train a model using our benchmark.
.
.
our environment.
we used a server machine with intel xeon e5 cores gb of ram and titan xp gpus to run our experiments except for fine tuning xda as discussed in .
.
we used docker .
.
for running comparison targets.
we used ubuntu .
containers for funprobe binary ninja and ghidra and a ubuntu .
container for nucleus as the authors suggested.
lastly we used a windows vm but not a docker container for ida pro due to the license issue.
.
probability parameter selection recall from .
funprobe provides two user configurable parametersp andp to assign probabilities for positive and negative hints respectively.
how do these parameters affect the accuracy offunprobe ?
which values should we use to maximize the accuracy?
to answer these questions we ran funprobe on a subset of our benchmark with varying parameter values and measured the accuracy f1 score for each setting.
we picked random binaries from gnu coreutils for each build configuration out of build configurations with varying compilers architectures and compiler options .
this gives us a totalesec fse december san francisco ca usa soomin kim hyungseok kim and sang kil cha x86 gcc x86 clang x86 gcc x86 clang armv7 gcc armv7 clang aarch64 gcc aarch64 clangmips gcc mips clangmips64 gcc mips64 clangavg.
time s funprobe funprobe lbp a average execution time per subset of benchmarks.
x86 gcc x86 clang x86 gcc x86 clang armv7 gcc armv7 clang aarch64 gcc aarch64 clangmips gcc mips clangmips64 gcc mips64 clangavg.
f1 score funprobe funprobe lbp b average f1 score per subset of benchmarks.
figure comparison between funprobe and funprobe lbp in terms of both execution time and accuracy.
of binaries corresponding to of the entire benchmark.
we then ran funprobe on these binaries with different combinations ofp andp values.
note that we chose to use only a small number of binaries to show that our parameter selection was not biased to any specific configuration.
table presents the measured f1 scores for each parameter combination.
the x axis shows p values and the y axis shows thep values.
each cell is filled with a grey scale color where the darker color indicates a higher f1 score.
the results show that p andp are negatively correlated.
the biggerp value is chosen the smaller p value needs to be selected to make funprobe perform well.
therefore the diagonal part of the table shows higher accuracy results.
in addition f1 scores shown in the table indicate that the performance of funprobe is not too sensitive to the choice of parameters.
since the highest value was achieved by p .
p .
we chose them as our default parameter values.
our experimental results on the entire benchmark see .
also show that our choice of default parameters is adequate.
we leave it as future work to find a better combination of parameters with more fine grained values.
.
impact of bogus dependency pruning recall from .
bogus dependency pruning simplifies the given bn to be loop free which enables us to use traditional belief propagation.
to measure the impact of bogus dependency pruning we modified funprobe to run loopy belief propagation without bogus dependency pruning which is dubbed funprobe lbp and compared its performance against it of the original funprobe .
although loopy belief propagation is designed to handle bns with loops the solution may not converge in some cases.
therefore it typically runs the algorithm only for a fixed number of iterations.
in our implementation of funprobe lbp we use the following convergence criteria for loopy belief propagation for maximum iterations for all basic block address in the given binary if pi f pi f .
holds then we consider the algorithmis converged where pi f is a marginal probability obtained after iiterations of the algorithm.
the algorithm stops when i .
we ran funprobe andfunprobe lbp on the same benchmark shown in .
.
using docker containers assigned with one cpu core.
each binary in the benchmark was analyzed for maximum hours.
figure reports both their running time as well as f1 score for different architecture compiler combinations.
each bar in figure 4a represents the average running time in seconds and each bar in figure 4b represents the average f1 score in percentage.
overall funprobe was .
faster than funprobe lbp.
the graph shows the computation cost of funprobe is almost negligible.
moreover funprobe lbp failed to run binaries within hours of timeout.
on the contrary funprobe was able to analyze all the binaries in our benchmark without any timeout.
the average f1scores were nearly the same for both.
the total average difference was only .
funprobe andfunprobe lbp recorded .
and .
of f1 score respectively.
these results confirm the impact of bogus dependency pruning it makes funprobe scalable while not sacrificing much of the accuracy.
.
comparison with conventional tools to see how well funprobe performs compared to conventional approaches we selected four state of the art tools binary ninja ida pro ghidra and nucleus.
we ran each tool on our entire benchmark .
.
.
we set a timeout of one hour for each binary.
when reporting the final accuracy results we excluded those binaries that did not meet the timeout requirement.
table shows the precision p recall r f1 score f1 execution time et and the number of binaries failed to analyze due to the timeout to .
each row summarizes the results for each architecture and compiler combination.
a dash mark indicates that the tool does not support the architecture.
overall funprobe achieves the best performance for all the criteria.
on average funprobe showed .
precision .
recall and .
f1 score.
notably funprobe outperformed all our comparison targets for every architecture and compiler combination in terms of f1 score.
it is also noteworthy that funprobe shows consistent performance on every architecture and compiler combination we tested.
this result aligns well with our design principle that funprobe should be architecture andcompiler agnostic .
for example on x86 every other tool except funprobe shows better performance on gcc compiled binaries than on clang compiled binaries.
we can also note how existing tools are fine tuned to handle gcc compiled binaries which are more common in practice.
notably ghidra showed the highest precision on mips binaries.
by investigating those function addresses falsely identified by funprobe we found that most of them are due to the imprecise cfg recovery of funprobe .
since mips binaries extensively use the got base address to compute relative addresses which can be temporarily stored on the stack or registers precisely recovering cfg requires a sound data flow analysis.
since funprobe relies only on a lightweight analysis it could miss out on many true edges.
in terms of execution time et funprobe spent only .
seconds on average for analyzing a binary in our benchmark.
moreover funprobe was able to analyze all the binaries without hittingfunprobe probing functions from binary code through probabilistic analysis esec fse december san francisco ca usa table function identification performance in terms of precision p recall r f1 score f1 execution time et and of binaries failed due to timeout to .
arch.
compilerfunprobe binary ninja ida pro ghidra nucleus p r f1 et s to p r f1 et s to p r f1 et s to p r f1 et s to p r f1 et s to x86gcc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
clang .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
x86 64gcc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
clang .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
armv7gcc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
clang .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
aarch64gcc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
clang .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mipsgcc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
clang .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mips64gcc .
.
.
.
.
.
.
.
.
.
.
.
clang .
.
.
.
.
.
.
.
.
.
.
.
total .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
the numbers in bold represent the best result per row.
table performance of funprobe and xda in terms of precision p recall r f1 score f1 and execution time et .
arch.
compilerfunprobe xda p r f1 et s p r f1 et s x86gcc .
.
.
.
.
.
.
.
clang .
.
.
.
.
.
.
.
x86 64gcc .
.
.
.
.
.
.
.
clang .
.
.
.
.
.
.
.
total .
.
.
.
.
.
.
.
the numbers in bold represent the best result per row.
the timeout.
although nucleus records the best performance .
seconds on average the difference is less than seconds while funprobe significantly outperforms nucleus in terms of function identification accuracy.
while binary ninja ida pro and ghidra show significantly slow running time overall it is important to note that those tools perform not only function identification but also other complex analyses making the comparison not entirely fair.
however we argue that our technique can practically be used to improve binary analysis results as a preprocessor of other binary analyzers because funprobe can correctly find more function entry points in a reasonable amount of time.
.
comparison with learning based tools how does funprobe compare to an existing learning based tool?
we now compare the performance of funprobe against xda to answer this question.
the comparison is made by running the tools onx86andx86 architecture binaries as xda only supports these architectures.
in addition we excluded the binaries that we used to fine tune xda for a fair comparison.
in total we used binaries for the comparison.
we downloaded the pre trained model of xda from the official repository and then used it to fine tune our own model using our training dataset see .
.
.
we used a separate machine with a powerful gpu geforce ti but the fine tuning process took more than .
days .
on the other hand funprobe does not requireany training process and this makes funprobe more practical to use on any benchmarks.
for the inference process we used our server machine described in .
.
.
specifically we assigned a single cpu of our server machine to run both funprobe and xda but we had to additionally assign a single gpu to run xda as it also uses gpu in the inference phase.
table summarizes the comparison between funprobe and xda on x86 and x86 binaries.
overall both tools show comparable performance but funprobe had a slightly better f1 score than xda.
it records .
f1 score on average whereas xda shows slightly a low .
f1 score.
in terms of execution time funprobe was considerably faster than xda even though xda utilizes additional gpu resources.
to analyze a single binary funprobe spent .
seconds on average whereas xda spent .
seconds on average.
that is funprobe was overall .
faster than xda without regard to the training cost.
therefore we conclude that funprobe is more scalable than xda while being as precise as xda.
.
combining funprobe and xda canfunprobe benefit deep learning based approach or vice versa?
to answer this question we conduct an additional experiment by simply using funprobe as a post processor of xda.
specifically we first ran xda on the binaries used in .
.
we then created a positive hint with p for each function entry point identified by xda and fed in those hints to funprobe .
this means funprobe will consider those xda generated hints as positive evidence to find function entry points within the same probabilistic framework we used.
as a result the combined tool achieved .
.
and .
in precision recall and f1 score respectively.
given that both funprobe and xda already accomplished high accuracy it is surprising that the combined tool achieves phenomenal performance.
xda supplies function entry points that are not covered by funprobe .
at the same time funprobe provides precision based on our probabilistic hints.
the synergy increases f1 score by .
.
additionally running funprobe as a post processor of xda is a matter of a few seconds for each binary.
this result confirms thatesec fse december san francisco ca usa soomin kim hyungseok kim and sang kil cha funprobe and the state of the art deep learning approaches are indeed complementary to each other.
we further analyzed what kind of functions that the combined tool was able to identify while the original xda failed.
the most common error cases corrected by the combined tool were where a function contains only a few instructions.
for example a tiny function containing two instructions movfollowed by ret was not identified by xda.
although we cannot directly understand the reason for failure due to the lack of interpretability of the model we conjecture that this is because such a function is considered to be a function epilogue than a prologue by xda.
discussion and future work supporting other file formats.
currently funprobe only supports elf binaries.
however extending our support for more binary types such as mach o and pe is straightforward because all the hints we leveraged summarized in table are derived from common information that can be found in any binary format.
for example we can apply 4for pe binaries by analyzing runtime function entries instead of fde entries because exception handling information should be stored in any binary format.
parameter tuning.
although funprobe currently uses empirically chosen probability parameters .
for positive hints and .
for negative hints one may use different probabilities for each different hint.
this is because each hint may have a different impact on function identification.
we believe fine tuning probability parameters for each different hint will further improve the performance of funprobe and it is a promising direction for future research.
better pruning strategy.
while our bogus dependency pruning significantly improves the performance of funprobe it can potentially remove critical i.e.
non bogus dependencies in our model.
although it is beyond the scope of this paper to find a better pruning strategy one may consider using a more sophisticated pruning strategy that can identify true bogus dependencies.
obfuscation.
funprobe does not consider obfuscated binaries.
we leave it as future work to combine funprobe with existing deobfuscation techniques such as .
integration with other binary analysis tools.
funprobe can enhance other binary analysis tools by serving as a preprocessor.
for instance modern binary analysis frameworks such as ida pro or ghidra provide apis for creating a function at a specific address.
with such apis one may feed in the results from funprobe to those frameworks to accurately construct cfgs for each function because more accurate function identification will enable more precise cfg reconstruction.
furthermore having precise cfgs is crucial for complex binary analysis tasks such as reassembly and type recovery .
related work .
binary function identification there has been significant research effort on binary level function identification for more than two decades.
early research focuses on systematically recovering cfgs thereby naturally identifying functions by following call edges from recovered cfgs.
forexample jakstab performs data flow analyses to determine indirect call edges.
there are several recent papers following this direction .
for example.
nucleus constructs interprocedural cfgs to find call targets as well as unreachable targets.
rev.ng converts a binary to an llvm ir and performs a static analysis on top of ir code to recover cfgs.
all these approaches suffer from the accuracy of the analyses and thus employ various heuristics to improve the effectiveness of their analyses.
however such heuristics are inherently architecture and compiler dependent.
pattern based approaches are widely adopted in mainstream binary analysis tools .
for example bap and dyninst utilize pre trained decision trees to identify functions.
ida pro and ghidra provide their own pattern databases to match well known function patterns.
recently funseeker shows that one can precisely detect functions from intel cet binaries by leveraging the usage patterns of endbr instructions.
however all these techniques rely on previously known patterns and thus inherently suffer from handling binaries with unknown patterns.
on the other hand the hints that we use are notspecific to an architecture nor a compiler.
there is a recent metadata based function identification technique named fetch which leverages exception handling information to identify functions.
their technique significantly outperforms existing techniques except for binaries without exception information such as c binaries generated from clang.
there also have been various deep learning based approaches .
shin et al.
use a bi directional and multi layer rnn to predict function boundaries.
fid leverages symbolic execution to extract feature vectors from binaries to make its model robust against highly optimized binaries.
xda first pre trains a transformer model using masked language modeling and selfattention layers and fine tunes the model for specific disassembly tasks such as function identification.
deepdi uses the r gcn model to learn instruction embeddings on instruction flow graph and identifies function entry points with trained instruction patterns near the function.
although those approaches usually show good accuracy they suffer from the generalization problem that is their performance relies on their training dataset .
moreover they consume a lot of computational resources during both training and inference stages.
they often require the use of gpus for efficiency and even more resources when the model size is large.
on the other hand funprobe does not have any dependency on training data or need for computation resources.
.
probabilistic binary analysis there are also diverse probabilistic model based approaches on binary code analysis .
rosenblum et al.
find function entry point idioms which are instruction patterns of function prologues.
while they use a probabilistic model to learn a probability distribution of such patterns funprobe directly analyzes various hints in order to compute the probability of each instruction being a function entry point.
byteweight creates a weighted prefix tree based on the patterns of function start instructions or bytes .
miller et al.
suggest a probabilistic disassembly algorithm.
they collect probabilistic hints for valid instructions to disassemble truepositive instructions.
osprey utilizes a probabilistic graphfunprobe probing functions from binary code through probabilistic analysis esec fse december san francisco ca usa model to recover variables and their type information from stripped binaries.
.
probabilistic inference various approaches to derive the desired distribution from a given probabilistic graphical model are suggested.
belief propagation can solve tree like graphs to get an exact solution.
however it may fail to converge or converge to the wrong solution if the graph contains loops.
to handle loopy graphs loopy belief propagation iteratively runs belief propagation algorithm until it converges or a certain number of iterations is reached.
to approximate the solution from loopy graphs junction tree algorithm transforms the graphs into junction trees and solves the graph.
however it does not scale to handle large graphs.
variational bayesian inference finds an alternative distribution to approximate the complicated distribution.
it is known to converge fast but it requires heavy computation.
monte carlo method is another approach to approximate the exact distribution based on random sampling.
despite its simplicity it is hard to apply to our system because it does not work well if the space is high dimensional.
conclusion in this paper we introduced a novel way to identify function entry points from a stripped binary.
the key idea was to regard a function identification heuristic as a producer of a probabilistic hint.
we can then combine those hints in a graphical model i.e.
a bayesian network and compute the probability of each address in the binary being a function entry point.
to boost the speed of our probabilistic inference we proposed a novel approach named bogus dependency pruning and empirically proved its effectiveness.
we implemented funprobe to realize these ideas and showed its practical impact by comparing its performance against five state of the art tools in terms of both speed and accuracy.
our experiments were performed based on the benchmark consisting of binaries compiled for major cpu architectures which is to our knowledge the largest benchmark used in the field.
as a result funprobe outperformed all of the state of the art tools we tested.
data availability our tool is available at