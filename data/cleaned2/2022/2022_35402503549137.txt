fault localization to detect co change fixing locations yi li new jersey institute of technology new jersey usa yl622 njit.edushaohua wang new jersey institute of technology new jersey usa davidsw njit.edutien n. nguyen university of texas at dallas texas usa tien.n.nguyen utdallas.edu abstract fault localization fl is a precursor step to most automated program repair apr approaches which fix the faulty statements identified by the fl tools.
we present fixlocator a deep learning dl based fault localization approach supporting the detection of faulty statements in one or multiple methods that need to be modified accordingly in the same fix .
let us call them co change cc fixing locations for a fault.
we treat this fl problem as dualtask learning with two models.
the method level fl model methfl learns the methods to be fixed together.
the statement level fl model stmtfl learns the statements to be co fixed.
correct learning in one model can benefit the other and vice versa.
thus we simultaneously train them with soft sharing the models parameters via cross stitch units to enable the propagation of the impact of methfl and stmtfl onto each other.
moreover we explore a novel feature for fl the co changed statements.
we also use graph based convolution network to integrate different types of program dependencies.
our empirical results show that fixlocator relatively improves over the state of the art statement level fl baselines by locating .
.
more cc fixing statements.
to evaluate its usefulness in apr we used fixlocator in combination with the state of theart apr tools.
the results show that fixlocator dear the original fl in dear replaced by fixlocator and fixlocator cure improve relatively over the original dear and ochiai cure by .
and .
in terms of the number of fixed bugs.
ccs concepts software and its engineering software testing and debugging .
keywords fault localization deep learning co change fixing locations acm reference format yi li shaohua wang and tien n. nguyen.
.
fault localization to detect co change fixing locations.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
corresponding author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore association for computing machinery.
acm isbn .
.
.
.
introduction to assist developers in the bug detecting and fixing process several approaches have been proposed for automated program repair apr .
a common usage of an apr tool is that one needs to use a fault localization fl tool to locate the faulty statements that must be fixed and then uses an apr tool to generate the fixing changes for those detected statements.
the input of an fl model is the execution of a test suite in which some of the test cases are passing or failing ones.
specifically the key input is the code coverage matrix in which the rows and columns correspond to the statements and test cases respectively.
each cell is assigned with the value of if the statement is executed in the respective test case and with the value of otherwise.
an fl model uses such information to identify the list of suspicious lines of code that are ranked based on their associated suspiciousness scores .
in recent advanced fl several approaches also support fault localization at method level to locate faulty methods .
the fl approaches can be broadly divided into the following categories spectrum based fault localization sbfl mutationbased fault localization mbfl and machine learning ml and deep learning dl fault localization .
for sbfl approaches the key idea is that a line covered more in the failing test cases than in the passing ones is more suspicious than a line executed more in the passing ones.
to improve sbfl mbfl approaches enhance the code coverage matrix by modifying a statement with mutation operators and collecting code coverage when executing the mutated programs with the test cases.
the mbfl approaches apply suspiciousness score formulas in the same manner as in sbfl approaches on the matrix for each original statement and its mutated code.
finally ml and dl based fl approaches explore the code coverage matrix and apply different neural network models for fault localization.
despite their successes the state of the art fl approaches are still limited in locating all dependent fixing locations that need to be repaired at the same time in the same fix.
in practice there are many bugs that require dependent changes in the same fix to multiple lines of code in one or multiple hunks of the same or different methods for the program to pass the test cases .
for those bugs applying the fixing change to individual statements once at a time will not make the program pass the test case after the change to one statement.
this capability to detect the fixing locations of the co changes in a fix for a bug let us call them co change cc fixing locations is crucial for an apr tool.
such capability will enable an apr tool to make the correct and complete changes to fix a bug .
the state of the art fl approaches do not satisfy that requirement.
from the ranked list of suspicious statements returned from an existing fl model a naive approach to detect cc fixing locations would be to take the top kstatements in that list and to consider them as to be fixed together.
this solution might be ineffective esec fse november singapore singapore yi li shaohua wang and tien n. nguyen because the mechanisms used in the state of the art fl approaches have never considered the co change nature of those fixes.
our empirical evaluation also confirmed that section .
.
detecting all the cc fixing locations at multiple statements in potentially multiple methods is challenging.
a naive solution would be detecting the potential methods that need to be fixed together and then detecting potential statements that need to be changed together in each of those methods.
however so will create a confounding effect from the inaccuracy of the detection of the co fixed methods to that of the co fixed statements.
we propose fixlocator a fault localization approach to derive the co change fixing locations in the same fix for a fault i.e multiple faulty statements in possible multiple faulty methods .
to avoid the confounding effect in that naive solution we treat this problem as dual task learning with two dedicated models.
first themethod level fl model methfl learns the methods that need to be modified in the same fix.
second the statement level fl model stmtfl learns the co fixed statements in the same or different methods.
the intuition is that they are closely related which we refer to as duality .correct learning for a model can benefit the other and vice versa .
if two statements in two methods are fixed together for a bug those methods are also co fixed.
if two methods are co fixed some of their statements are also co fixed.
exploring this duality can provide useful constraints to detect cc fixing locations for a bug.
thus instead of cascading the two models methfl and stmtfl we train them simultaneously with the soft sharing of the models parameters to exploit this duality.
specifically we leverage the cross stitch units to connect methfl and stmtfl .
in a cross stitch unit the sharing of representations between methfl and stmtfl is modeled by learning a linear combination of the input features from the two models.
the cross stitch units enable the propagation of the impact of methfl and stmtfl on each other.
in addition to the new solution in dual task learning we utilize a novel feature for this cc fixing location problem co changed statements which have never been exploited in fl.
the rationale is that the co changed statements in the past might become the statements that will be fixed together in the future.
finally since the co fixed statements are often interdependent we use graph based convolution network gcn to integrate different types of program dependencies among statements e.g.
data and control dependencies execution traces stack traces etc.
we also encode test coverage and co changed co fixed statements in the graph.
the gcn model learns and predicts the bugginess of the statements.
we conducted several experiments to evaluate fixlocator on defects4j v2.
.
our empirical results show that fixlocator improves the baselines cnn fl deepfl deeprl4fl and dear s fl by .
.
.
and .
respectively in terms of hit i.e.
the percentage of bugs in which the predicted set overlaps with the oracle set for at least one faulty statement and by .
.
.
and .
in terms of hit i.e.
the percentage of bugs in which the number of overlapping statements between the predicted and oracle sets is .
.
.
and .
in terms of hit respectively.
fixlocator also improves those baselines by .
.
.
and .
in terms of hit all i.e.
the predicted set exactly matches with the oracle set for a bug .
to evaluate its usefulness in apr we combined it with the apr tools dear and cure .
we replaced dear s fl module1 public void tosource final codebuilder cb int inputseqnum node root ... string code tosource root sourcemap string code tosource root sourcemap inputseqnum if !code.isempty cb.append code ... override string tosource node n initcompileroptionsiftesting return tosource n null return tosource n null true private string tosource node n sourcemap sourcemap private string tosource node n sourcemap sourcemap boolean firstoutput ...... builder.setsourcemapdetaillevel options.sourcemapdetaillevel builder.settagasstrict builder.settagasstrict firstoutput options.getlanguageout a languagemode.ecmascript5 strict builder.setlinelengththreshold options.linelengththreshold ...... figure co change fixing locations for a fault with fixlocator for a variant dearfixl.
our result shows that dearfixlandfixlocator cure improve relatively dear and ochiai cure by .
and .
in terms of numbers of fixed bugs.
through our ablation analysis on the impact of different features and modules of fixlocator we showed that all designed features modules have contributed to its high performance.
specifically the proposed dual task learning significantly improves the statementlevel fl by up to .
in terms of hit .
the designed feature of co change relations among methods and statements has also positively contributed to fixlocator s high accuracy level.
the contributions of this paper are listed as follows fixlocator advancing dl based fault localization to derive the co change fixing locations multiple faulty statements in the same fix for a bug.
we treat that problem asdual task learning to propagate the impact between the method level and statement level fl.
novel graph based representation learning with gcn and novel type of features in co changed statements for flenable dual task learning to derive cc fixing locations.
extensive empirical evaluation.
we evaluated fixlocatoragainst the recent dl based fl models to show its accuracy and usefulness in apr.
our data tool are available .
motivating example .
example and observations let us start with a real world example.
figure shows a bug fix in the defects4j dataset that require multiple interdependent changes to multiple statements in different methods.
the bug occurred when the method call to settagasstrict did not consider the first output in its arguments.
therefore for fixing a developer adds a new argument in the method tosource at line and uses that argument in the method call settagasstrict firstoutput ... at line .
because the method tosource at line was changed the two callers at line of the method tosource line and at line of the method tosource line need to be changed accordingly.
660fault localization to detect co change fixing locations esec fse november singapore singapore .
.
observation .
in this example the changes to fix this bug involve multiple faulty statements that are dependent on one another.
fixing only one of the faulty statements will not make the program pass the failing test s .
fixing individual statements once at a time in the ranked list returned from an existing fl tool will also not make the program pass the tests.
for an apr model to work an fl tool needs to point out all of those faulty statements to be changed in the same fix.
for example all four faulty statements at lines and need to modified accordingly in the same fix to fix the bug in figure .
.
.
observation .
as seen this bug requires an apr tool to make changes to multiple statements in three different methods in the same fix tosource ... at lines and tosource ... at line and tosource ... at line .
thus it is important for an fl tool to connect and identify these multiple faulty statements in potentially different methods.
traditional fl approaches using program analysis pa e.g.
execution flow analysis are restricted to specific pa techniques thus not general to locate all types of cc fixing locations.
spectrumbased mutation based statistic based and machine learning ml based fl approaches could implicitly learn the program dependencies for fl purpose.
however despite their successes the non pa fl approaches do not support the detection of multiple locations that need to be changed in the same fix for a bug i.e.
co change cc fixing locations .
the spectrum based and ml based fl models return a ranked list of suspicious statements according to the corresponding suspiciousness scores.
in this example the lines and the other lines e.g.
and are executed in the same passing or failing test cases thus assigned with the same scores by spectrum and mutation based fl approaches.
a user would not be informed on what lines need to be fixed together.
those non pa especially ml based fl approaches do not have a mechanism to detect cc fixing locations.
in this work we aim to advance the level of deep learning dl based fl approaches to detect cc fixing statements .
however it is not trivial.
a solution of assuming the top ksuspicious statements from a fl tool as cc fixing locations does not work because even being the most suspicious those statements might not need to be changed in the same fix.
in this example all of the above lines with the same suspiciousness scores would confuse a fixer.
moreover another naive solution would be to use a methodlevel fl tool to detect multiple faulty methods first and then use a statement level fl tool to detect the statements within each faulty method.
as we will show in section the inaccuracy of the first phase of detecting faulty methods will have a confounding effect on the overall performance in detecting cc fixing statements.
.
key ideas we propose fixlocator an fl approach to locate all the cc fixing locations i.e.
faulty statements that need to be changed in the same fix for a bug.
in designing fixlocator we have the following key ideas in both new model and new features .
.
key idea .
to avoid the confounding effect in a naive solution of detecting faulty methods first and then detecting faulty statements in those methods we design an approach that treats this fl problem of detecting dependent cc fixing locations as dual task learning between the method level and statement level fl.
first the method level fl model methfl aims to learn the methods that need to be modified in the same fix.
second the statement level fl model stmtfl aims to learn the co fixing statements regardless of whether they are in the same or different methods.
intuitively methfl and stmtfl are related to each other in which the results of one model can help the other.
we refer to this relation asduality which can provide some useful constraints for fixlocator to learn dependent cc fixing locations.
we conjecture that the joint training of the two models can improve the performance of both models when we leverage the constraints of this duality in term of shared representations.
for example if two statements in two different methods m1andm2were observed to be changed in the same fix then it should help the model learn that m1and m2were also changed together to fix the bug.
if two methods were observed to be fixed together then some of their statements were changed in the same fix as well.
in our model we jointly train methfl and stmtfl with the soft sharing of the models parameters to exploit their relation.
specifically we use a mechanism called cross stitch unit to learn a linear combination of the input features from those two models to enable the propagation of the impact of methfl and stmtfl on each other .
we also add an attention mechanism in the two models to help emphasize on the key features.
.
.
key idea co change representation learning in fault localization .
in detecting cc fixing locations in addition to a new dual task learning model in key idea we use a new feature cochange information among statements methods which has never explored in prior fault localization research.
the rationale is that the co changed statements methods in the past might become the statements methods that will be fixed together for a bug in the future.
we also encode the co fixed statements methods in the same fixes.
the co changed co fixed statements methods in the same commit are used to train the models.
.
.
key idea graph modeling for dependencies among statements methods .
the statements methods that need to be fixed together are interdependent via several dependencies.
thus we use graph based convolution network gcn to model different types of dependencies among statements methods e.g.
data and control dependencies in a program dependence graph pdg execution traces stack traces etc.
we encode the co change co fix relations into the graph representations with different types of edges representing different relations.
the gcn model enables nodes and edges attributes and learns to classify the nodes as buggy or not.
3fixlocator approach overview .
training process figure summarizes the training process.
the input of training includes the passing and failing test cases and the source code under study.
the output includes the trained method level fl model detecting co fixed methods and the trained statement level fl model detecting co fixed statements .
the training process has three main steps feature extraction graph based feature representation learning and dual task learning fault localization .
661esec fse november singapore singapore yi li shaohua wang and tien n. nguyen figure fixlocator training process .
.
step .
feature extraction.
section .
we aim to extract the important features for fl from the test coverage and source code including co changes.
the features are extracted from two levels statements and methods.
at each level we extract the important attributes of statements methods as well as the crucial relations among them.
we use graphs to model those attributes and relations.
fora methodm we collect as its attributes method content the sequences of the sub tokens of its code tokens excluding separators and special tokens and method structure the abstract syntax tree ast of the method.
for the relations among methods we extract the relations involving in the following execution flow the calling relation i.e.
mcallsn stack trace after a crash i.e.
the order relation among the methods in the stack trace the dynamic information in execution and stack traces have been showed to be useful in fl co change relation in the project history two methods that were changed in the same commit are considered to have the cochange relation co fixing relation among the methods two methods that were fixed for the same bug are considered to have the co fixing relation similarity we also extract the similar methods in the project that have been buggy before in the project history.
we keep only the most similar method for each method.
fora statement s we extract both static and dynamic information.
first for static data we extract the ast subtree that corresponds tosto represent its structure.
we also extract the list of variables instogether with their types forming a sequence of names and types e.g.
name string price int ... .
second for dynamic data we encode the test coverage matrix for sinto the feature vectors.
at both method and statement levels we use graphs to represent the methods and statements and their relations.
let us call them the method level and statement level feature graphs .
.
.
step .
graph based feature representation learning.
this step is aimed to learn the vector representations i.e.
embeddings for the nodes in the feature graphs from step .
the input includes the method level and statement level feature graphs.
the output includes the embeddings for the nodes in the method statementlevel feature graphs.
the graph structures for both feature graphs are un changed after this step.
for the content of a method or statement we use the embedding techniques accordingly to feature representations section .
for the method s content and a list of variables in a statement the representation is a sequence of sub tokens.
we use glove to producethe embeddings for all sub tokens as we consider a method or statement as a sentence in each case.
we then use gated recurrent unit gru to produce the vector for the entire sequence.
for the structure of a method or statement the representation is a sub tree in the ast.
for this we first use glove to produce the embeddings for all the nodes in the sub tree considering the entire method or statement as a sentence in each case.
after obtaining the sub tree where the nodes are replaced by their glove s vectors we use treecaps which captures well the tree structure to produce the embedding for the entire sub tree.
for the code coverage representation we directly use the two vectors for coverage and passing failing and concatenate them to produce the embedding.
the embedding for the most similar buggy method is computed in the same manner as explained with glove and treecaps.
finally the embeddings for the attributes of the nodes are used in the fully connected layers to produce the embedding for each node in the feature graph at the method level.
similarly we obtain the feature graph at the statement level in which each node is the resulting vector of the fully connected layers.
.
.
step .
dual task learning fault localization.
after the feature representation learning step we obtain two feature graphs at the method and statement levels in which a node in either graph is a vector representation.
the two graphs are used as the input for dual task learning.
for dual task learning we use two graph based convolution network gcn models for the method level fl model methfl and the statement level fl model stmtfl to learn the cc fixing methods and cc fixing statements respectively.
during training the two feature graphs at the method and statement levels are used as the inputs of methfl and stmtfl .
the two gcn models play the role of binary classifiers for the bugginess for the nodes i.e.
methods statements .
we train the two models simultaneously with soft sharing of parameters.
details will be given in section .
.
predicting process the input of the prediction process figure includes the test cases and the source code in the project.
the steps of the process is the same as in training.
in step the feature graph gmat the statement level built from the source code is used as the input of the trained stmtfl model which predicts the labels of the nodes in that graph.
the labels indicate the bugginess of the corresponding statements in the source code which represent the cc fixing statements.
if one aims to predict the faulty methods the trained methfl model can be used on the feature graph to produce the cc fixing methods.
662fault localization to detect co change fixing locations esec fse november singapore singapore figure fixlocator prediction process figure method level feature extraction gmform1 feature extraction .
method level feature extraction gm figure illustrates the key attributes and relations that we collect.
for each method m1 we extract the following attributes the method s content we remove special characters and separators in the method s interface and body and use naming convention to break each code token into the sub tokens.
for example in figure the node m1represents the method computegeometricalproperties in figure .
for the content for m1 the extracted sequence of sub tokens is protected void compute geometrical properties etc.
the method s structure the corresponding parser is used to build the ast of the method e.g.
jdt for java code .
most similar faulty method we keep the most similar faulty methodmbwithm1.
note that we keep mbas an attribute of m1 rather than representing mbin the feature graph.
the rationale is thatmbmight be in the past and might not be present in the current version of the project.
two methods are similar when they have similar sequences measured by the cosine similarity of the sub tokens represented by the glove embeddings .
formb we build its ast and keep it as an attribute for m1.
we encode as the edges three types of relations calling relation in a stack trace we encode into the feature graph the calling relations in a stack trace of a failed test case as we ran it.
in figure a blue edge connects mitomjfor that relation.
since the stack trace can be long from the failing crash point we collect only part of the stack trace with nlevels of depth from that point.
following a prior work in our experiment n .
calling relations in an execution trace similar to the stack trace an execution trace needs to be encoded in the feature graph.
it can be very long from the failing crash point.
thus we keep the methods with only mlevels of length in calling relations from that point.
in our experiment we use m .
figure illustrates a few calling relations in green color in execution traces.
figure stmt level feature extraction gmform1in figure co change co fixing relation such a relation exists between two methods that were changed fixed in a commit.
such an edge is made into two one directional edges e.g.
m5 m6in figure .
.
statement level feature extraction gm for each statement we extract the following attributes .
code coverage we run the test cases and collect code coverage information.
for each statement s we use a vector c c1 c2 ... ck kis the number of test cases to encode code coverage in which ci 1if the testticoverss andci 0otherwise.
we use another vector r r1 r2 ... rk to encode the passing failing of a test case in which ri 1if the test case tiis a passing one and ri 0otherwise.ris common for all the statements.
we concatenatecandrfor each statement to obtain the code coverage feature vectorvcov c1 c2 ... ck r1 r2 ... rk .
we used deeprl4fl s test ordering algorithm as the ordering of test cases is useful in fl.
for the different numbers of test cases across files we perform zero padding to make the vectors have the same length.
ast structure we extract the sub tree in the ast that corresponds to the current statement.
list of variables we break the names into sub tokens.
in figure the sequence for the variable list is .
we encode the following types of relations among statements program dependence graph pdg as suggested in the relations among statements in an pdg are important in fl thus we integrate them into the feature graph.
in figure the blue edges represent the relations in the pdg for the given code.
the statement at line has a control data dependency with the one at line which connects to the ones at lines and to the ones at lines .
execution flow in an execution trace if two statements are executed consecutively in an execution trace we will connect them together.
in figure we have the execution flow s5 s7 s7 s8.
co change co fixing relation we maintain the co change cofixing relations among statements.
in figure s4ands5have been changed in a commit thus two co change edges connect them.
feature representation learning the goal of this step is to learn to build the vector representations for the nodes in the feature graphs at the method and statement levels.
at either level the input includes the attributes of either a method or a statement as in figures and .
the output is each feature graph in which the nodes are replaced by their embeddings.
.
method level representation learning figure shows how we build the vectors for a method s attributes.
663esec fse november singapore singapore yi li shaohua wang and tien n. nguyen figure method level feature representation learning figure statement level feature representation learning the method s content the method s content is represented by the sequence seqcof the sub tokens built from the code tokens in the interface and the body of the method.
to vectorize each subtoken inseqc we use a word embedding model called glove and treat each method as a sentence.
after this vectorization for the method we obtain the sequence v1 v2 ... vn of the vectors of the sub tokens in seqc.
we then apply a sequential model on the sequence v1 v2 ... vn to learn the summarized vector vmc that represents the method s content.
specifically we use gated recurrent unit gru a type of rnn layer that is efficient in learning and capturing the information in a sequence.
the method s structure we first treat the method as the sequence of tokens and use glove to build the embeddings for all the tokens as in .
we then replace every node in the ast of the method with the glove s vector of the corresponding token of the node figure .
from the tree of vectors we use a tree based model called treecaps to capture its structure to produce the summarized vector vastrepresenting the method s structure.
most similar faulty method for a method we process the most similar buggy method mbin the same way as the method s structure via glove and treecaps to learn the vector vmsbm formb.
finally for each method m1 we obtainvmc vast andvmsbm .
.
statement level representation learning figure shows how we build the vectors for a statement s attributes.
code coverage we directly use the vector vcov c1 c2 ... ck r1 r2 ... rk computed in section .
for the next computation.
the statement s structure we process the ast subtree representing the statement s structure in the same manner via glove and treecaps as for the method s structure to produce vsubtree .
list of variables as with the method s content we run glove on the sequence of sub tokens to produce a sequence of vectors and use gru to produce the summarized vector vvarfor the list.
finally for each statement s we obtainvcov vsubtree andvvar.
figure dual task learning fault localization .
feature representation learning after computing the three embeddings for three attributes of each method we use three fully connected layers to standardize each vector s length to a chosen value l. similarly we use three fully connected layers for the three embeddings for each statement.
then for a method or a statement we concatenate the three output vectors from the fully connected layer to produce the vector vmfor the method and the other three vectors for vsfor the statement with the length of l .
after all for a method m we have the method level graph gm and the statement level graph gmwith its statements.
the nodes in gm figure now are the vectors computed for methods and the nodes ingmare the vectors vsfor the statements in m figure .
dual task learning for fault localization figures and illustrate our dual task learning for fault localization.
in the training dataset for each bug b to ensure the matching of a method and its corresponding statements we build for each faulty methodmthe pairs gm gm gm the method level graph figure with nodes replaced by vectors and gm the statement level graph figure containing all the statements belonging to m.to ensure the co fixing connections among the buggy methods for the same bugb we model the co fixed methods ofmvia co fixed relations ingm figure .
at the output layer we label those methods asfaulty co fixing .
the co fixed statements withingmfor the bug bare also labeled as faulty co fixing .
the non buggy methods or statements are labeled as non faulty .
the pairs gm gm are used as the input of this dual task learning model figure .
we process all the faulty methods mfor each bug b and non buggy methods.
in prediction for each method m in the project we build the pair gm gm and feed it to the trained dual task model.
in the output graphs each node for a method or a statement will be classified as either faulty co fixing ornon faulty .
the nodes with faulty co fixing labels ingm are the co fixing statements for the bug.
let us explain our dual task learning in details.
.
graph convolutional network gcn for fl first fixlocator has two gcn models each for fl at the method and statement levels.
gcn processes the attributes of the nodes vectors and their edges relations in feature graphs.
each gcn model has n 1pairs of a graph convolution layer conv and 664fault localization to detect co change fixing locations esec fse november singapore singapore figure dual task learning via cross stitch unit a rectified linear unit relu .
they are aimed to consume and learn the characteristic features in the input feature graphs.
the last pair of each gcn model is a pair of a graph convolution layer conv and a softmax layer softmax .
the softmax layer plays the role of the classifier to determine whether a node for a method or a statement is labeled as faulty co fixing ornon faulty .
.
dual task learning with cross stitch units in a regular gcn model those above pairs of convand reluare connected to one another.
however to achieve dual task learning between method level and statement level fl methfl and stmtfl we apply a cross stitch unit to connect the two gcn models.
the sharing of representations between methfl and stmtfl is modeled by learning a linear combination of the input features in both feature graphsgmandgm.
at each of the relulayer of each gcn model figure we aim to learn such a linear combination of the output from the graph convolution layers conv of methfl and stmtfl .
the top sub network in figure gets direct supervision from methfl and indirect supervision through cross stitch units from stmtfl .
cross stitch units regularize methfl and stmtfl by learning and enforcing shared representations by combining feature maps .
formulation.
for each pair of the gcn model the outputs of the relulayer called the hidden states are computed as follows a d 2a d hi axiwi wherea is the adjacency matrix of each feature graph d is the degree matrix wiis the weight matrix for layer i xiis the input for layeri hiis the hidden state of layer iand the output from the relulayer and is the activation function relu.
in a regular gcn hiis the input of the next layer of gcn i.e.
the input of conv .
in figures and a cross stitch unit is inserted between the relu layer of the previous pair and the convlayer of the next one.
the input of the cross stitch unit includes the outputs of the two relu layers hi mandhi s i.e.
the hidden states of those layers in methfl and stmtfl .
we aim to learn the linear combination of both inputs of the cross stitch unit which is parameterized using the weights .
thus the output of the cross stitch unit is computed as xi m xi s mm ms sm ss hi m hi s is the trainable weight matrix xi mandxi sare the inputs for the i thlayers of the gcns at the method and statement levels.
xi mandxi scontain the information learned from both methfl and stmtfl which helps achieve the main goal for dual task learning to enhance the performance of fault localization at both levels.
in general s can be set.
if msand smare set to zeros the layers are made to be task specific.
the values model linear combinations of feature maps.
their initialization in the range is important for stable learning as it ensures that values in the output activation map after cross stitch unit are of the same order of magnitude as the input values before linear combination .
if the sizes of the hi mandhi sare different we need to adjust the sizes of the matrices.
from formula we have xi m mmhi m mshi s xi s smhi m sshi s we resizehisin formula and resize himin formula if needed.
we use the bilinear interpolation technique in image processing for resizing.
we pad zeros to the matrix to make the aspect ratio .
if the size needs to be reduced we do the center crop on the matrix to match the required size.
fixlocator also has a trainable threshold for softmax to classify if a node corresponding to a method or a statement is faulty or not.
empirical evaluation .
research questions for evaluation we seek to answer the following research questions rq1.
comparison with state of the art deep learning dl based approaches.
how well does fixlocator perform compared with the state of the art dl based fault localization approaches?
rq2.
impact analysis of dual task learning.
how does the dual task learning scheme affect fixlocator s performance?
rq3.
sensitivity analysis.
how do various factors affect the overall performance of fixlocator ?
rq4.
evaluation on python projects.
how does fixlocator perform on python code?
rq5.
extrinsic evaluation on usefulness.
how much does fixlocator help an apr tool improve its bug fixing?
.
experimental methodology .
.
dataset .we use a benchmark dataset defects4j v2.
.
with bugs from java projects.
for each bug in a project p defects4j has the faulty and fixed versions of the project.
the faulty and fixed versions contain the corresponding test suite relevant to the bug.
with the diffcomparison between faulty and fixed versions of a project we can identify the faulty statements.
specifically for a bug in p defects4j has a separate copy of pbut with only the corresponding test suite revealing the bug.
for example p1 a version ofp passes a test suite t1.
later a bug b1inp1is identified.
after debugging p1has an evolved test suite t2detecting the bug.
in this case defects4j has a separate copy of the buggy p1with a single bug together with the test suite t2.
similarly for bug b2 defects4j has a copy of p2together with t3 evolving from t2 and so on.
we do not use the whole t of all test suites for training testing.
for within project setting we test one bug biwith test suite t i by 665esec fse november singapore singapore yi li shaohua wang and tien n. nguyen training on all other bugs in p. we conducted all the experiments on a server with core cpu and a single nvidia a100 gpu.
in defects4j v2.
regarding the statistics on the number of buggy fixed statements for a bug there are bugs with one buggy fixed statement bugs with two bugs with three bugs with four bugs with five and bugs with buggy statements.
regarding the statistics on the number of buggy fixed methods hunks for a bug there are bugs with one method onestatement bugs with one method multi statements bugs with multi methods one statement for each method bugs with multi methods multi statements for each method and bugs with multiple methods each has one or multiple buggy statements.
thus there are out of bugs with cc fixing statements .
.
.
experimental setup and procedures.
rq1.
comparison with dl based fl approaches.
baselines.
our tool aims to output a setof cc fixing statements for a bug.
however the existing deep learning based fl approaches can produce only the ranked lists of suspicious statements with scores.
thus we chose as baselines the most recent state of theart dl based statement level fl approaches cnn fl deepfl and deeprl4fl then we use the predicted ranked list of statements as the output set.
for the comparison in ranking with those ranking baselines we convert our tool s result into a ranked list by ranking the statements in the predicted set by the classification scores i.e.
before deriving the final set .
we also compare with the cc fixing statement detection module in dear a multi method multi statement apr tool.
procedures.
we use the leave one out setting as in prior work i.e.
testing on one bug and training on all other bugs .
we also consider the order of the bugs in the same project via the revision numbers.
specifically for each buggy version bof project pin defects4j all buggy versions from the other projects are first included in the training data.
besides we separate all the buggy versions of the project pinto two groups one buggy version as the test data for model prediction and all the buggy versions of the same project pthat have occurred before the buggy version b are also included in the training data.
if the latter group is empty only the buggy versions from the other projects are used for training to predict for the current buggy version in p. we tune all models using automl to find the best parameter setting.
we directly follow the baseline studies to select the parameters that need to be tuned in the baselines.
we tuned our model with the following key hyper parameters to obtain the best performance epoch size i.e.
batch size i.e.
learning rate i.e.
.
.
.
.
vector length of word representation and its output i.e.
the output channels of convolutional layer the number of convolutional layers .
deepfl was proposed for the method level fl.
for comparison following a prior study we use only deepfl s spectrum based and mutation based features applicable to detect faulty statements.
evaluation metrics.
we use the following metrics for evaluation hit n measures the number of bugs that the predicted set contains at leastnfaulty statements i.e.
the predicted and oracle sets for a bug overlap at least nstatements regardless of the sizes of both sets .
both precision and recall can be computed from hit n. hit all is the number of bugs in which the predicted set covers the correct set in the oracle for a bug.
hit n top kis the number of bugs that the predicted list of the top kstatements contains at least nfaulty statements.
this metric is used when we compare the approaches in ranking.
rq2.
impact analysis of dual task learning model.
baselines.
to study the impact of dual task learning we built two variants of fixlocator statement only model the method level fl model methfl is removed from fixlocator and only statementlevel fl stmtfl is kept for training.
cascading model in this variant dual task learning is removed and we cascade the output ofmethfl directly to the input of stmtfl .
procedures.
the statement only model has only the statementlevel fault localization.
we ran it on all methods in the project to find the faulty statements.
we use the same training strategy and parameter tuning as in rq1.
we use hit n for evaluation.
rq3.
sensitivity analysis.
we conduct ablation analysis to evaluate the impact of different factors on the performance every node feature co change relation and the depth limit on the stack trace and the execution trace .
specifically we set fixlocator as the complete model and each time we built a variant by removing one key factor and compared the results.
except for the removed factor we keep the same setting as in other experiments.
rq4.
evaluation on python projects.
to evaluate fixlocator on different programming languages we ran it on the python benchmark bugsinpy with bugs from different projects.
rq5.
extrinsic evaluation.
to evaluate usefulness we replaced the original cc fixing location module in dear with fixlocatorto build a variant of dear namely dearfixl.
we also added fixlocator and ochiai fl to cure to build two variants curefixl fixlocator cure and cureochi ochiai cure .
empirical results .
rq1.
comparison results with state of the art dl based fl approaches table shows how well fixlocator s coverage is on the actual correct cc fixing statements recall .
the result is w.r.t.
the bugs in the oracle with different numbers kof cc fixing statements k cc stmts and .
for example in the oracle there are bugs with faulty statements.
fixlocator s predicted set correctly contains all buggy statements for bugs hit all of them for bugs and faulty statement for bugs.
as seen regardless of n fixlocator performs better in any hit nover the baselines for all ks.
note that hit all hit nwhenn overlaps k cc stmts .
table shows the summary of the comparison results in which we sum all the corresponding hit nvalues across different numbers kof cc fixing statements in table .
as seen fixlocator can improve cnn fl deepfl deeprl4fl and dear by .
.
.
and .
respectively in terms of hit i.e.
the predicted set contains at least one faulty statement .
it also improves over those baselines by .
.
.
and .
in terms of hit .
.
.
and .
in terms of hit .
.
and .
in terms of hit .
note any hit nreflects the cases of multiple cc statements.
for example hit might include the bugs with more than one buggy fixed statement.
importantly our tool 666fault localization to detect co change fixing locations esec fse november singapore singapore table rq1.
detailed comparison w.r.t.
faults with different of cc fixing statements in an oracle set recall cc stmts in oraclemetrics cnn fl deepfl deeprl4fl dear fixlocator bugs hit bugs hit hit bugs hit hit hit bugs hit hit hit hit bugs hit hit hit hit hit bugs hit hit hit hit hit hit table rq1.
comparison results with dl based fl models metrics cnn fl deepfl deeprl4fl dear fixlocator hit hit hit hit hit hit hit all produced the exact match sets for bugs .
relatively improving over the baselines .
.
and .
in hit all.
it performs well in hit all when the number of cc statements k .
however producing the exact matched sets for all statements whenk 5is still challenging for all the models.
table shows the comparison on how precise the results are in a predicted set.
for example when the number of the cc statements in a predicted set isk there are bugs in which all of those faulty statements are correct there might be other statements missing .
there are bugs in which two of the predicted faulty statements are correct.
there are bugs in which only one of the predicted faulty statements are correct.
as seen regardless of n fixlocator is more precise than the baselines for all k s. table shows the comparison as ranking is considered hitn top k .
as seen in the ranking setting fixlocator locates more cc fixing statements than any baseline.
for example fixlocator improves the best baseline deeprl4rl by .
in hit2 top .
in hit top .
in hit top and .
in hit top respectively.
the same trend is for hit n top .
we did not compare with the spectrum mutation based fl models since deeprl4fl was shown to outperform them.table rq1.
detailed comparison w.r.t.
faults with different of cc fixing statements in a predicted set precision stmts in predicted setmetrics cnn fl deepfl deeprl4fl dear fixlocator bugs hit bugs hit hit bugs hit hit hit bugs hit hit hit hit bugs hit hit hit hit hit bugs hit hit hit hit hit hit table rq1.
comparison with baselines w.r.t.
ranking hit n top hit n top n cnn fl deepfl deeprl4fl dear fixlocator table overlapping analysis results for hit fixlocator unique baseline overlap unique fixlocator cnn fl deepfl deeprl4fl dear we also performed the analysis on the overlapping between the results of fixlocator and each baseline.
as seen in table fixlocator can detect at least one correct faulty statement in bugs that cnn fl missed while cnn fl can do so only in bugs thatfixlocator missed.
both fixlocator and cnn fl can do so in the same bugs.
in brief fixlocator can detect at least one correct buggy statement in more unique bugs than any baseline.
.
rq2.
impact analysis results on dual task learning table shows that fixlocator has better performance in detecting cc fixing statements than the two variants statement only and cascading models .
this result shows that the dual task learning helps improve fl over the cascading model methfl stmtfl .
667esec fse november singapore singapore yi li shaohua wang and tien n. nguyen table rq2.
impact analysis of dual task learning variant hit hit hit hit hit hit stmt only cascading fixlocator table rq3.
sensitivity analysis of method and statementlevel features.
ml method level sl statement level model varianthit n mlw o method content w o method structure w o similar buggy method w o ml co change rel.
slw o code coverage w o ast subtree w o variables w o sl co change relation fixlocator table rq3.
sensitivity analysis depth of traces depthhit n moreover without the impact of method level fl methfl the performance decreases significantly indicating methfl s contribution.
.
rq3.
sensitivity analysis results .
.
impact of the method level ml features and ml co change relation.
among all the method level features attributes of fixlocator the feature of co change relations among methods has the largest impact .
specifically without the co change feature among methods hit is decreased by .
.
moreover the method structure feature represented as ast has the second largest impact .
without the method structure feature hit is decreased by .
.
among the last two method level features with least impact the method content feature has less impact than the similar buggymethod feature.
this shows that the bugginess nature of a method and similar ones has more impact than the tokens of the method itself .
.
.
impact of the statement level sl features and sl co change relation.
among all the statement level features code coverage has the largest impact .
without code coverage feature hit is decreased by .
.
the co change relations among statements have the second largest impact among all sl features attributes.
specifically without the co change relations among statements hit is decreased by .
.
.
.
impact of the depth level of stack trace.
as seen in table fixlocator can achieve the best performance when depth .
the cases with depth or can bring into analysis too few or too many irrelevant methods causing more noises to the model.
thus we chose depth for our experiments.
public univariaterealpointvaluepair optimize final func f goaltype goal double min double max throws functionevaluationexception return optimize f goal min max return optimize f goal min max min .
max min public univariaterealpointvaluepair optimize final func f goaltype goal double min double max double startvalue throws func...exception ... try final double bound1 i ?
min min generator.nextdouble ... final double bound2 i ?
max min generator.nextdouble ... optima optimizer.optimize f goal fastmath.min bound1 bound2 ... final double s i ?
startvalue min generator.nextdouble ... optima optimizer.optimize f goal min max s ... figure an illustrating example table ranking of cc fixing locations for figure loc cnn fl deepfl deeprl4fl dear fixlocator line no rank line no rank line no rank line no rank table rq4.
bugsinpy python projects versus defects4j java projects .
p located bugs total bugs in datasets metricsbugsinpy python projects defects4j java projects p cases p cases hit .
.
hit .
.
hit .
.
hit .
.
hit .
.
hit .
.
.
illustrating example.
table displays the ranking from the models for figure .
fixlocator correctly produces all cc fixing statements in its predicted set lines and in two methods .
the statement only model detects only line as faulty.
it completely missed lines of the optimize method.
in contrast the cascading model detects lines however its methfl considers the first method optimize ... at line as non faulty thus it did not detect the buggy line due to its cascading.
the baselines cnn fl deepfl deeprl4fl and dear detect only and faulty statements bold cells in their top resulting lists respectively.
in brief the baselines are not designed to detect cc fixing locations thus their top klists are not correct.
.
rq4.
evaluation on python projects as seen in table fixlocator can localize faulty statements with hit .
this shows that the performance on the python projects is consistent with that on the java projects.
specifically at the statement level the percentages of the total python and java bugs that can be localized are similar e.g.
.
vs. .
with hit .
.
rq5.
extrinsic evaluation usefulness in automated program repair in table with its better cc fixing locations fixlocator can help dearfixlrelatively improve over dear in auto fixing .
668fault localization to detect co change fixing locations esec fse november singapore singapore table rq5.
usefulness in apr running on defects4j bug meth meth m meths m meths m meths total types stmt m stmt stmt m stmts mix stmts dear dearfixl69 cureochi84 curefixl79 table rq5.
detailed results on usefulness in apr projects in defects4j dear dearfixlcureochicurefixl chart cli closure codec collections compress csv gson jacksoncore jacksondatabind jacksonxml jsoup jxpath lang math mockito time total x y are the numbers of correct and plausible patches dataset defects4j table running time models cnn fl deepfl deeprl4fl dear fixlocator training time hours mins hours hours hours prediction time seconds second seconds seconds seconds more bugs bugs across all bug types.
moreover curefixl fixlocator cure can fix .
relatively more bugs bugs than cureochi ochiai cure .
especially curefixlfixed more bugs with multi statements or multi methods .
the bugs with single buggy statements that curefixlmissed are due to fixlocator incorrectly producing more than one fixing locations.
table shows thatfixlocator can help dear and cure improve both correct and plausible patches passing all the tests across all projects.
.
further analysis .
.
running time.
as seen in table except for deepfl using a basic neural network the other approaches have similar training and prediction time.
importantly prediction time is just a few seconds making fixlocator suitable for interactive use.
.
.
limitations.
first our tool does not detect well the sets with cc fixing statements since it does not learn well those large co changes.
second it does not work in locating a fault that require only adding statements to fix neither do all baselines .
third if the faulty statements methods occur far from the crash method in the execution traces it is not effective.
finally it does not have any mechanism to integrate program analysis in expanding the faulty statements having dependencies with the detected faulty ones.
.
.
threats to validity.
we evaluated fixlocator on java and python.
our modules are general for any languages.
we compared the models only on two datasets that have test cases.
forcomparison we use only deepfl s features applicable to statementlevel fl although it works at the method level.
other baselines work directly at the statement level.
in bugs in bugsinpy the third party tool cannot process of them.
we focus on cc fixing statements instead of methods due to bug fixing purpose.
related work several types of techniques have been proposed to locate faulty statements methods.
however none of the existing fl approaches detect cc fixing locations .
a related work is dear which uses a combination of bert and data flows to locate cc statements.
hercules apr tool can detect multiple buggy hunks of code.
it can detect only the buggy hunks with similar statements replicated fixes while our tool detects general cc fixing locations.
in comparison fixlocator and hercules detect and multi hunk bugs respectively among bugs in defects4j v1.
.
the spectrum based fault localization sbfl and mutation based fault localization mbfl have been proposed for statement level fl.
their key limitations are that they cannot differentiate the statements with the same scores or cannot have effective mutators to catch a complex fault.
among the learning based fl models learning to rank fl approaches aim to locate faulty methods.
statistical fl has been combined with casual inference for statement level fl .
all of those models do not locate cc fixing statements.
machine learning has also been used for fl.
early neural networkbased fl mainly use test coverage data.
a limitation is that they cannot distinguish elements accidentally executed by failed tests and the actual faulty elements .
deep learning based approaches grace deepfl cnnfl deeprl4fl achieve better results.
grace proposes a new graph representation for a method and learns to rank the faulty methods.
in contrast fixlocator is aimed to locate multiple cc fixing statements in a fix for a fault.
deepfl and deeprl4fl can outperform the learning based and early neural networks fl techniques such as multric trapt and fluccs .
in our empirical evaluation we showed that fixlocator can outperform those baselines under study in detecting cc fixing statements.
conclusion we present fixlocator a novel dl based fl approach that aims to locate co change fixing locations within one or multiple methods.
the key ideas of fixlocator include a new dual task learning model of method and statement level fault localization to detect cc fixing locations a novel graph based representation learning with co change relations among methods and statements a novel feature in co change methods statements.
our empirical results show that fixlocator relatively improves over the state of the art fl baselines by locating more cc fixing statements from .
to .
and help apr tools improve its bug fixing accuracy.