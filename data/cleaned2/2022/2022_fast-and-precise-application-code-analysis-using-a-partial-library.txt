fast and precise application code analysis using a partial library akshay utture university of california los angeles u.s.a. akshayutture ucla.edujens palsberg university of california los angeles u.s.a. palsberg ucla.edu abstract long analysis times are a key bottleneck for the widespread adoptionofwhole programstaticanalysistools.fortunately however auserisoftenonlyinterestedinfindingerrorsintheapplication code whichconstitutesasmallfractionofthewholeprogram.current application focused analysis tools overapproximate the effect ofthelibraryandhencereducetheprecisionoftheanalysisresults.
however empirical studies have shown that users have high expectations on precision and will ignore tool results that don t meet these expectations.
inthispaper weintroducethefirsttool querymax thatsignificantlyspeed supanapplicationcodeanalysiswithoutdroppingany precision.
querymax acts as a pre processor to an existing analysis tooltoselectapartiallibrarythatismostrelevanttotheanalysis queries in the application code.
the selected partial library plus the application is given as input to the existing static analysis tool with the remaining library pointers treated as the bottom element in the abstract domain.
this achieves a significant speedup over a whole programanalysis atthecostofafewlosterrors andwithno lossinprecision.weinstantiateandrunexperimentson querymax foracast checkanalysisandanull pointeranalysis.foraparticular configuration querymax enables these two analyses to achieve relative to a whole program analysis an average recall of a precisionof100 andageometricmeanspeedupof10x.
ccs concepts softwareanditsengineering automatedstaticanalysis .
acm reference format akshay utture and jens palsberg.
.
fast and precise application code analysisusingapartiallibrary.in 44thinternationalconferenceonsoftware engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction motivation.
long analysis times are a key bottleneck for the widespreadadoptionofwhole programstaticanalysistools.several recent papers for both java and c c report that a whole program analysis on their largest benchmarks can takeseveralhours.analyzingalargecollectionofbenchmarkslike this work is licensed under a creative commons attribution international .
license.
icse may pittsburgh pa usa copyright held by the owner author s .
acm isbn .
app store takes even longer with a total compute time of many years for the largest app stores.
hence a speedup in analysis time cansave significantcomputetime andenergy and enableus touse more precise and expensive algorithms.
whole programanalysesmaybeslow butauserisoftenonly interested in finding errors in the application code which constitutes a small fraction of the whole program.
in the njr dataset application code excluding third party libraries constituteslessthan1 ofthewholeprogramonaverage.hence an application focusedanalysishasthepotential foralargespeedup.
ideally anapplication focusedanalysisshouldcomputethesame set of errors for the application code as a whole program analysis.
however this is hard to achieve because errors can both originate in or propagate through the library.
we use the singular libraryto refer to the aggregate of the third party libraries and the standard library.thequalityofanapplication focusedanalysistool sresults can be quantified using precisionandrecall.precisionis the ratio of true positivesinthetool sresults withthewhole programanalysis results serving as the ground truth.
recallis the ratio of wholeprogram analysis errors caught by the tool.
thus any applicationfocusedanalysistoolcanbejudgedbyitsperformanceonthethree metricsofprecision recallandspeedup.
thecurrentbesttoolforanapplication focusedanalysisisaverroes .
averroes overapproximates the effect of the library with a compact summary.
the overapproximation ensures high recall and the small size of the summary compared to the whole library gives a large speedup.
however this summary is created by merging the analysis information from all the library pointers into a single set resulting in significantly worseprecision than the whole program analysis.
in our experiments averroes gets an average precision of relative to the whole program analysis.
this precision drop is problematic because empirical studies show that users have a very high bar for precision.
for example christakis and bird find that in practice static analysis users care much more about precision than recall.
they concludethatpracticalanalysistoolsmustaimforaminimumof user perceived precision.
failing to meet this value results in users ignoringthe tooloutput entirely.other empirical studies also arrive at similar conclusions.
whole program analyses themselves often get much less than user perceived precision .hence anapplication focusedanalysisthatgetslessthan precision relative to a whole program analysis will almost certainlyfailtomeetthe80 user perceivedprecision target.this defines the goal of our paper.
ourgoalinthispaperistocapturethespeeduppotentialofan application focused analysis while maintaining precision relative to the whole program analysis.
ieee acm 44th international conference on software engineering icse icse may pittsburgh pa usa akshay utture and jens palsberg partial libraryapplication code analysis queries errorsquerymaxexisting static analysis toolapplication code analysis querieslibrary recall 10x speedup figure overview of the querymax workflow our technique.
in this paper we introduce a new applicationfocused analysis tool called querymax that achieves our goal of precision and gets both good speedup and good recall.
figure1givesanoverviewoftheworkflow.
querymax actsasapreprocessor to an existing static analysis by selecting a small subset ofthelibrary i.e.partiallibrary whichisrelevanttothesetofanalysis queries in the application.
to decide which part of the library is most relevant querymax uses a new static analysis called the externalsourceanalysis.once querymax picksthepartiallibrary the existing static analysis tool is run on the application code plus thepartiallibrary withallexternallibrarypointerstreatedasthe bottom element in the abstract domain.
theanalysisqueriesusedinfigure1areexactlylikethequeries in a demand driven analysis and they represent all the instructions of interest in the application code.
for example in a cast checkanalysis theanalysisquerieswouldbeallthedown cast instructions in the application code.
the complexity of querymax iso a3 p2 whereais the size ofthe application codeand pisthe sizeofthe application code partial library .thisismuchlessthanthecomplexityofawholeprogram analysis like 0cfa which has complexity o n3 where nis the size of the whole program.
here we assume n p and n a both of which are true for our benchmarks.
ourexperimentsfocusonjavabytecodeprogramsfromthenjr1 dataset but our approach applies to other object oriented languages as well.
we implemented querymax in wala and ran experiments on it with an existing cast check analysis and null pointer analysis.
our contributions.
we introduce a new static analysis the external source analysis which computes the set of external library pointers affecting each pointer in the application code.
we describe the querymax tool which uses the external source analysisand picks a partial library which issmall yet sufficient to yield a good recall.
weshowexperimentallythat querymax successfullyspeeds uptwodifferentanalyses.inaparticularconfiguration querymaxachievesa97 recall onaverage relativetoawholeprogram and an .7x geometric mean speedup for a castcheckanalysis anda recall .2xspeedup foranull pointer analysis.
both analyses get precision.whole program a b c .
.
.
.
.
.
.
.
.
.
cast cast cast cast cast cast cast cast cast cast application coded .
e .
figure schematic of a cast check analysis on applicationcode significance.
the impact of this research contribution is that the 10x analysis speedup without any loss in precision will help us meet user expectations on both speedup and precision.
further the speedup will enable us to use expensive and precise analysis algorithmsaswellasanalyzelargeprogramsorlargecollectionsof programs likeanapp store thatpreviouslycouldn tbeanalyzed in a reasonable amount of time.
example in this section we show an example of how querymax picks a partiallibrarytoanalyze andcomparethiswithaverroes approach.
wealsodiscusstwootherbaselineswhichcanbeadaptedtoprovideaspeedupoverawhole programanalysis ademand driven analysis and an application only analysis.
figure2showstheschematicofaprogramwewishtoanalyze forcast errors.theapplicationcode representedbythecircle is the part in which we wish to catch the cast errors and everything outsideisthelibrary.thegreyboxes labeled a b c ontheedge of the circle show library methods with pointers that influence the valueofcastinstructionsintheapplicationcode.theaccompanying number in the grey box tells us how many cast instructions are affected by that method.
the application code has a total of cast instructions and each cast instruction is considered an analysis query.
we say that an application focused analysis coversa castqueryifitoverapproximatestheresultofthatquery.inotherwords a query coveredby a tool is guaranteed to mark it as a cast error if the whole program analysis does.
the first baseline technique is to run a demand driven analysis for every analysis query in the application.
the demand driven analysisexhaustivelytracesthebackwardsliceofall10castinstructions.castsnumbered7 10atthebottomoftheapplicationcircle gettheirvaluefrominsidetheapplication andhenceareansweredquickly.thecastsaffectedby bandc castsnumbered3 arealso answeredquicklybecausethebackwardsliceshaveonly2and0 caller methods respectively.
however the demand driven analysis faces a significant slowdown when answering the two cast queries influencedby a cast1andcast2 .theirbackwardtraceinvolves the10callersofa eachofwhichcouldresultinalongtrail making 935fast and precise application code analysis using a partial library icse may pittsburgh pa usa this approach expensive because of these two queries.
in total the demand driven analysis analyzes all the library methods in the figure.
it gets precision and covers all cast instructions since its output is identical to the whole program analysis.
note thatthedemand drivenanalysisistheonlyonewhichrequiresa newdemand drivendesignofanexistinginter proceduralanalysis the others use the existing interprocedural analysis as is.
the second baseline is an application only analysis.
such an analysis analyzes the code inside the application circle in isolation and assumes the bottom element of the abstract domain for alllibrary pointers outside.
hence it analyzes zero library methodsand only coversthe casts that get their values from inside the application that is the casts numbered .
the application onlyanalysisgets100 precisionbecauseitserrorsarethesubsetofthe whole program errors that do not involve the library.
averroes improves upon the application only analysis by modeling the whole library with a small summary.
in figure everythingoutsidethe applicationcircleisrepresented usingthis summary.
the summary primarily consists of a single summarypointertorepresentalllibrarypointers andasinglesummary nodetoperformalltheobjectinitializationsandapplicationcall backs.ausualinter proceduralcast analysisisperformedontheapplicationcode plus this summary.
averroes s summary is sound for someanalyses the cast check being one them.
hence it covers all cast instructions while only analyzing the summary.
however the analysis information merged in the common summary pointer and summary node drops precision relative to the whole program analysis.
querymax s approach differs from averroes primarily in that it selects a small part of the library to fully analyze instead of modelingthelibraryusingasummary.
querymax keepsexpanding thepartiallibrarytobeuseduntilitreachessomestoppingcriterion.
let usassume thatwe use querymax with astopping criterionof querycoverage.thismeansthatwewillhavetopicka fragment consistingoftheapplication codeplusapartiallibrary suchthatat least of the queries i.e.
casts are coveredwithin this fragment.
querymax startsoutbyperformingan externalsourceanalysis on the application code to find out which library pointers affect the cast instructions.
this information is marked by the arrows insidetheapplicationcircle.
querymax thenassignsprioritiesto eachexternallibrarymethodbasedonthenumberofcastsitaffects.
in figure this is denoted by the numbers in the grey boxes.
next querymax expandsonthemethodwiththehighestpriority method b to look at its callers callees and field reads.
method bhas callers dande.
we estimate that each of dandeaffects half as many casts as b and hence each of them get half its priority i.e.
.
each .
now the method with the highest priority is a which on expansion leads to different caller methods and we assign a priority of to each of them.
the next methods with the highest priorityare dande followedby method c. eachof these methods are expanded in turn.
at this point our fragment consists of the application code plus a partial library consisting of methods a b c d e .
performing anotherexternal source analysis on this fragment shows that now ofthecasts castsnumbered3 arecoveredwithinthisfragment.
recallthatwestarted querymax withastoppingcriterionof80 querycoverage orinotherwords wewouldliketoterminatewhenanalysis tool casts coveredlib methodsanalyzedprecision application only querymax demand driven averroes summary low figure3 numberofcastscovered librarymethodsanalyzed and precision relative to the whole program analysis foreach of the competing tools of the casts i.e.
queries are covered.
hence querymax stops expandingatthispoint andanexistinginter proceduralcast check analysis is now performed on this fragment.
by terminating the expansionearly querymax avoidedexploringthe10callersofmethod a andtheirsubsequentcallerswhichcouldpotentiallyexpandlarge sectionsoftheprogram whileonlyansweringthequeriesfor cast1 andcast2.
in total by using querymax we analyzed only library methodsandcovered8casts.
querymax justlikeanapplicationonlyanalysis reportsasubsetofthewhole programerrors thereby getting precision.
figure summarizes the number of library methods analyzed lessisbetter thecast instructionscovered moreisbetter and precision moreisbetter foreachofthefourtechniques.
querymax the demand driven analysis and the application only analysis each get100 precision.fortheothertwometrics querymax obtains a useful trade off point in between the application only analysisand the demand driven analysis.
note that the differences in li brary methods analyzed is rather small for this example but the differencesaremuchlargerinrealprograms.averroescoversall casts and analyzes just the small summary but gets low precision thereby falling short of our precision goal.
this example illustrates the core insight underlying querymax s speedup few queries in the application code require large sections of the library for their analysis like cast1andcast2 whereas the remaining queries need a much smaller subset of the library.
byidentifyingtheseexpensivequeriesandassigningthemalow priority querymax can pick a small partial library that is sufficient to cover all the remaining queries.
the downstream client can nowuse this partial library in its analysis which is a fraction of the sizeofthewholelibrary.thetrade offisthatthefewexpensivequeries likecast1andcast2intheexample arenotfullycoveredbythe partial library resulting in a few missed errors.
approach in this section we describe in detail how querymax works to pick the partial library to analyze.
.
overview querymax picks its partial library by finding the library classes mostlylikelyrelevanttothequeriesintheapplicationcode.
querymaxaccomplishes this by using a new static analysis called an external source analysis.
querymax expands its partial library in agreedyfashiontomaximizethenumberofqueriesansweredin theapplicationcodeuntilsomestoppingcriterionisreached.we 936icse may pittsburgh pa usa akshay utture and jens palsberg no stmt condition constraint x y x is not an array ext y ext x x y x is an array ext y ext x and ext x ext y x y.f field f is internal ext f ext x y.f x field f is internal ext x ext f x foo z target foo p .. ret q is internalext q ext x and ext z set p x y.f field f is external f ext x y.f x field f is external no constraint x foo z target foo p .. ret q is external q ext x n a foo x hasanexternal caller y.foo z z ext x figure constraints for the external source analysis discusstwostoppingcriteria a class budget iftheuserwantstoset a limit on the number of classes analyzed proxy for analysis time and aquery coverage if the user wants to set a goal for the number of queries covered proxy for recall .
.
external source analysis esa theexternalsourceanalysis or esaforshort takesaprogramand a subset of its classes called the fragment and computes for every pointerinthefragment thesetofexternalpointersthatpassvalues to it.
for example defining the application code as the fragment would make the library pointers the external pointers and an esa would tell us which library pointers directly pass values to each pointerintheapplicationcode.anexampleofapplyingtheesa was illustrated in the example in figure where we computed the library methods affecting cast instructions in the application code.
theesaisdesignedtobecontext flow andfield insensitive because it s primary application is partial program analysis which istime sensitive.anyoverheadofperforminganesaduringpartial program analysis eats into the speedup that we may get over a whole program analysis.
figure outlines the core constraints used for esa.
the second columnlistsastatement thethirdcolumnlistsanaccompanying condition and the fourth column gives the corresponding constraint.
the third column in the figure uses the words internaland external.apointerisconsideredinternalifitiswithinthefragment andexternalotherwise.theabstractdomainfortheesaconsistsofall possible subsets of external pointers.
hence the notation ext y inthefourthcolumnrepresentsthesetofexternalpointerspassing valuestothefragmentpointer y.thisisdifferentfromthenotation z which is a singleton set consisting of the external pointer z. rows1 5infigure4areidenticaltoastandardcontext flowand field insensitive pointer analysis such as and we assume that the reader understands them well.
rows deal with the different types of external pointers external fields external return values andexternalfunction arguments.theconstraintsfortheserows are similar to what one would expect for a newstatement in a pointer analysis.
row says that for the read of an external field f theexternalfield fshouldbeaddedtothe extsetoftheassigned variablex.
row says that writes to external fields produce noconstraint.row8saysthatforeveryexternaltargetofamethod call thereturnpointerofthetargetshouldbeaddedtothe extsetof theassignedvariable x.therearenoconstraintsforthearguments inthiscase.row9saysthatifamethodinthefragmenthasacaller outside the fragment then the external caller s argument should be added to the extset of the method s parameter.
thegeneratedconstraintscanbesolvedusingstandardstaticanalysis constraint solving techniques.
the complexity of solving theesaconstraintsonafragmentofsize piso p3 .thecomplexity calculationsareverysimilartothatofacontext insensitivepointer analysis.
in addition to the esa we define a faster version of it called the fast esa with the primary change being to the abstract domain.
insteadofmaintainingthesetofexternalsourcesforeveryfragment pointer fast esa only maintains whether or not the set is nonempty.
hence there are only two elements in the fast esaabstractdomain thetopelementisusedwhenthefragmentpointermaybepassedavaluebyanexternalsource andthebottomelementisused whenthepointerisguaranteedtonotgetanyvaluesfromexternal sources.theconstraintsarethesameasinfigure4 exceptforrows using the top element instead of the external pointer names.
duetothesmallersizeoftheabstractdomain thecomplexityof fast esaonafragmentofsize piso p2 whichislesserthanthe cubic complexity of esa.
hence fast esa allows us to compute whetherafragmentpointerisaffectedbyexternalsourcesmuch quicker than an esa.
.
querymax algorithm thequerymax algorithm is used to pick a fragment to analyze consisting of the application and the partial library with a best efforttocatchasmanyofthewhole programerrorsaspossible.theexampleinsection2showedhow querymax runsforoneparticular case.here wedescribethealgorithm giveninfigure.
indetail.
the figure has three main procedures the main algorithm the class budgetstoppingcriterionandthequery coveragestopping criterion.
themainalgorithm line1 takesasinputtheapplicationclasses setofallclasses andthequeriestobeanswered.forinternalbookkeeping querymax uses the set fra ment to mark the classes that are to be analyzed finally a visitedset for the methods and a priority queue pqueuetokeeptrackoftheprioritiesoftheexternal library methods to be explored.
the intuition behind the priority valuesisthattheyrepresenttheestimatednumberofqueriesansweredby thatmethod and querymax will explore methodswith a higher priority earlier.
the main algorithm starts off by performing an esa line withtheapplicationclassesasthe fra ment .theesacomputes the set of external library pointers affecting each pointer in the applicationclasses.usingtheesaresult wecomputeitsinverse information thenumberofqueriesaffectedbyeachoftheexternal librarypointers line6 .now themethodofeachoftheexternallibrary pointers is added to pqueuewith a priority equal to the number of queries it affects.
for external field pointers we add the methodswhichwritetothatfield.eachoftheexternallibrarypointers methodsareaddedtothe visitedset.afterthisinitialization phase we move into the main algorithm loop.
937fast and precise application code analysis using a partial library icse may pittsburgh pa usa procedure querymax appclasses allclasses queries fragment appclasses visited new set pqueue new priorityqueue esa esa allclasses appclasses extlibptrs computeaffectedqueries esa queries forexternallibrarypointer e in extlibptrs do pqueue.setpriority e.method e.affectedqueries visited.add e.method end for whilenot pqueue.empty criterion do method m pqueue.poll analysisfragment.add m.declaringclass methodslice getmethodslice m newpriority m.priority methodslice.size formethod n in methodslice do ifvisited.contains n then pqueue.addtooldpriority n newpriority else pqueue.setpriority n newpriority visited.add e end if end for end while returnfragment end procedure procedure budgetcriterion fragment percentanalyzed fragment.size allclasses.size return percentanalyzed budget end procedure procedure coveragecriterion fragment queries coveredqueries fastesa allclasses fragment queries coverageratio coveredqueries fragment.totalqueries return coverageratio goal end procedure figure querymax algorithm the main algorithm loop starts at line .
it keeps looping until eitherpqueueis empty or we satisfy the stopping criterion described below .
inside the loop we remove the method mwith the maximum priority in pqueue and add its class to the fra ment .
thisstepisagreedymovetoexpandtheclassthatisexpectedto affect the largest number of queries.
the next step is to find the method slice ofm line .
this is similar to computing one step in the backward slice of a pointer but is performed at the granularity ofmethodsinsteadofpointerstoreducetheoverhead.the methodsliceconsists of callersand callees of m as wellas methods which write to fields that are read in m. each method in the method slice gets a new priority which is the priority of mdivided by the size ofitsmethod slice.theintuitionbehindthispriorityassignment is that if maffectskqueries and has tcallers callees then each caller callee is expected to affect k tqueries.
if a method from the method sliceisalreadyin pqueueweaddthenewprioritytoitsoldpriority elseweaddthemethodto pqueuewiththenewpriority.finally oncetheloophasterminated the fra ment whichhastheset of classes to be analyzed is returned.
an existing inter procedural static analysis is performed on the set of classes returned with all external pointers assumed to be the bottom element.
querymax uses a stopping criterion to know when to stop expanding the fragment and return and we experiment with two such criteria class budget andquery coverage goal.
class budget.
the class budget stopping criterion line is used when the user wants a handle on the analysis time.
the class budgetisaproxyforatimebudget andweprefertousethenumber of classes instead of analysis time because it can be accurately computed in advance without running the actual analysis.
thiscriterion simply checks if the percentage of classes used in the fragmentisgreaterthanacertainbudget.thebudgetisassumedto bespecifiedasaglobalvariableforreadability.forthispaper we experimentwitha3 and30 class budget.abudgetofunder2 will have no space for library methods in some programs and a budget of over will analyze a large partial library resulting in onlyasmallspeedup.
query coverage goal.
the query coverage criterion line is usedwhentheuserwantsahandleontherecall.query coverageis a proxy for recall because the number of errors found is expected to be proportional to the number of queries covered.
the querycoveragecriterionusesa fast esa line34 tofindthenumberof queries covered by the fragment classes and computes a coverageratiowhich is the percentage of queries covered.
finally if the coverage ratio exceeds the query coverage goal then we return true.
the goal is assumed to be specified as a global variable forreadability.
the coverage criterion is not used at every iterationof the main loop because the fast esaadds significant overhead.
instead weonlyevaluatethiscriterionatsomesetcheckpoints.for this paper we experiment with and query coverage goals.
a goal of less than gives recall close to that of a applicationonly analysis and a goal of greater than requires too many classestobeaddedtothepartiallibrary therebyresultingintoo small a speedup.
theoverallcomplexityfor querymax iso a3 p2 whereaisthe sizeoftheapplication codeand pisthesizeofthe application code partial library .the o a3 termcomesfromtheesaperformed onthe application codeon line5 and the o p2 termcomes from thefast esaperformed for the coverage criterion on line .
.
applicability of querymax to client static analyses nowthatweunderstandhow querymax worksasapreprocessorto select a partial library we can discuss what kind of client analyses querymax can be applied to.
firstly since querymax trades off recall for analysis speedup itsclientanalysisshouldbeabletoaffordtolosesomerecall.for example compileroptimizationclientsthatpreferthestaticanalysisbesound orsoundy willnotuse querymax .secondly querymax isrestrictedtoclientanalysesthatonlycareabouterrors 938icse may pittsburgh pa usa akshay utture and jens palsberg client analysis analysis queries cast check analysis cast instructions null pointer analysis method calls and field accessestaint analysis taint sink instructions type state analysis state change instructionspointer analysis client analysis queries figure analaysis queries for different client analyses manifestingintheapplicationcode.itcannotspeedupaclientanalysisthataimstocatcherrorsmanifestinginboththeapplication code and the library.
on the plus side querymax makes no assumptions about the flow context andfield sensitivityoftheclientanalysisthatitispreprocessingfor.henceitcanbeappliedregardlessoftheclient analysis sensitivities.
further unlike it makes no assumptions aboutthedemarkationbetweenapplicationandlibrarycode.hence theusercanchooseanysubsetofclassesastheapplicationcodeto focus on and get everything outside the subset treated as the library.
figure lists some analysis clients that querymax could be appliedtoandshowsthecorrespondinganalysisqueriesforsucha client analysis.
this is not an exhaustive list of client analyses and itsmainpurposeistogiveexamplesofwhattheanalysisqueries wouldbefordifferentkindsofclientanalyses.typically ananalysis query would be any instruction in the application code where aparticular kind of error could potentially manifest.
for example for a cast check analysis the queries are cast instructions.
for a null pointeranalysistheyarealldereferenceinstructions including methodcallsandfieldaccesses.forataint analysiswhichisdefinedintermsofvulnerablesource sinkpairs theanalysisquerieswould beallthesinks.foratype stateanalysis likeonethatchecksfor thecorrectnessoffile operations allthestate changeoperations likefile open file close etc.
willbetheanalysisqueries.apointer analysisitselfdoesnothaveanystatementsorvariablesofinterest and hence cannot define analysis queries for itself.
ho wever if the pointer analysis is used by a particular client like cast check or taint analysis we can defineits analysisqueries as thequeries of that client.
implementation the wala framework for java bytecode analysis is used to implement querymax and the esa analysis.
the actual analysis is performed on the wala ir which is in ssa form and hence automaticallygrantspartialflow sensitivity.weusethecha callgraph for all the analyses since computing a whole program cfa callgraph would defeat the purpose of a partial library analysis.
weignorecall graphedgesinvolvingasinglecall sitewithmore than targets since the likely root cause of this is severe imprecision and it results in mostly false positives.
we also exclude the java utilpackage since it is well known for introducing too many false positives unless one uses high context sensitivity .
client analyses.
querymax accepts any inter procedural analysis to run with as long as the analysis can be run on a subset of the classes in the program.
we experiment with two such analyses a cast check analysis and a null pointer analysis.
the cast checkanalysis is based on the vta algorithm for pointer analysis.
the null pointer analysis based on focuses on catching nullpointer exceptions resulting from uninitialized instance fields.
the two analyses vary significantly in their constraints abstract domains designdecisions numberofanalysisqueries andnumber of errors per program.
hence the two analyses offer considerable diversityforexperimentation.weleavetofutureworktoexperimentwithotherclientanalysis includingotherimplementations of cast check and null pointer analysis such as nullaway .
for the analysis sensitivities we choose to be context flowandfield insensitiveasfaraspossible.thecast checkanalysisis insensitiveonallthreeaxes.thenull pointeranalysisiscontextand field insensitive but flow sensitive because a flow insensitive version of the analysis trivially marks all fields as null.
our choice of sensitivities are different from other papers such as becausetheirtaskistoimprovepre cision whereasoursis toimprove analysisspeed .forthetaskofimprovingprecision aflow contextand field sensitive analysis is the hardest baseline because it is the mostprecise.incontrast forourtaskofimprovinganalysisspeed acontext field and flow insensitive analysis is the hardest baseline because it is the fastest.
demand drivenanalysis.
wechoosetowriteourowndemanddriven cast check instead of using an existing tool like o r .
this ensures that thewhole program analysis and demand driven analysis are identical in their various sensitivities analysis design decisions constraint solvers and errors generated.
this normalization helps to make a fair timing comparison between the demanddrivenanalysis andothertechniqueslike querymax averroesand the application only analysis.
for the demand driven cast check we implement caching across queries to reuse computations done for a previous query.
mostpriorresearchondemand drivenanalysisdealswithpointer analysis which can be used to implement the cast check.
however a design of the demand driven version of the null pointer analy sis isnotpubliclyavailableandisnon trivialtodesignfrom scratch.
hence for the demand driven analysis we only report experiments for the cast check analysis.
averroes.
averroes takes as input the original jar file and the setofapplicationclasses andproducesmodifiedjarfilesconsisting of the application classes and the librarysummary.
wedo not count the time taken to produce the modified jar files since it is aone timecostwhichisamortizedacrossallclientanalyses.the averroes library summary also has the java utilpackage excluded from it.finally thesame null pointerand cast checkanalyses describedabovearerunonthemodifiedjarfiles therebymakinga fair comparison between averroes and the other techniques.
reflection.
we do not use wala s inbuilt reflection support for the client analyses because this would worsen the analysis time of the baseline thereby making querymax look better.
further we also do not use reflection support for the esa.
while reflection support may help the esa find external sources reachable through reflection its overhead is too high and this reduces the effective speedup provided by querymax .
939fast and precise application code analysis using a partial library icse may pittsburgh pa usa statistic mean std dev lines of application code number of application classes number of 3rd party library classes 5220percentage of application classes .
.
figure statistics about the benchmark programs statistic cast check null pointer total number of programs mean errors per program .
std dev errors per program programs with non zero errors mean analysis time sec sec std dev analysis time sec sec figure8 statisticsaboutthewhole programcast checkandnull pointer analysis on the benchmark set precision recallandspeedup.
tomeasurethequalityofananalysisusingquerymax oranyofthebaselinetechniqueslikeaverroes demand driven analysis etc.
we evaluate it on the three axes of speedup precision andrecall.herearethestandardformulaefor computing these metrics speedup whole program analysis time application focused analysis time precision a w a recall a w w whereais the set of errors given by querymax andwis the set of errors given by the whole program analysis which we consider as the ground truth .
dataset description weusethenjr 1dataset availablehere asourbenchmarkset.
we chose njr because its java bytecode programs run successfullywithwala andeachprogramexplicitlylistsitssetofapplicationandthird partylibraryclasses.outofthe293programs we remove programs that crash the averroes tool.
the crash reportshavebeenfiledwiththedevelopers.another4programs whichrunoutofmemoryforthewhole programnull pointeranalysis are removed leaving us with a total of programs.
figure lists some statistics about the benchmark programs.
on average each benchmark program has almost 10k lines of java sourcecodeintheapplication withanaverageofalmost100classes each.thethird partylibraryclassesaremuchlarger withanaverageof2608classesperbenchmark andthesecorrespondtoan estimated lines of java source code.
the application classes constitute just .
of the program with the remaining being the java standardlibrary and third partylibrary classes.
the large standard deviation for all these metrics implies that they vary significantly acrossbenchmarks.
amongthe benchmarks use reflectionintheapplicationcodeand130usereflectioninthethirdparty libraries.figure lists some statistics about the benchmarks when analyzed with a whole program null pointer analysis and the castcheck analysis.
the cast check analysis gets .
errors per program on average whereas the null pointer analysis gets .
this large difference is expected since down casting is rare whereas method calls and field accesses are common.
the table also shows thatonly of the programs have nonzerocasterrorsandonly177ofthemhavenon zeronull pointer errors.theprogramswithzeroerrorsinthewholeprogramanalysisareaproblemfortheevaluationbecausetheirrecallisundefinedfor all of the techniques.
hence the experimental results are reported intwoparts thosewithzeroerrorsandthosewithnon zeroerrors.
wereporttherecallandspeedupforthenon zeroerrorcasesand onlyspeedupforthezeroerrorcases.
theanalysistimesforthetwoanalysesalsovarywidely with the cast check taking seconds per program and the null pointer analysistaking293secondsperprogram.thestandarddeviation for analysis times is large especially for the cast check analysis implying that a few outliers have large analysis times.
experimental results in this section we discuss our experimental results which validate the following claims.
c1 querymax gets a significant speedup full precision and reasonablerecallascomparedtothewhole programanalysis with trade off points that none of the existing techniques can achieve.
c2 thedistributionofspeedupsandrecall scoresareuniform across the benchmarks.
the experiments were carried out on a machine with intel r xeon r silver4116cpucoresat2.10ghzand188gbram.for the jvm the default heap size of 32gb and default stack size of 1mb was used.
the artifact for the paper is available here .
thefirsttwosub sectionsvalidatetheclaimsmade andthese experimentsfocusontheprogramswithnon zeroerrors.thethird subsection evaluates the programs with zero errors the fourth examines the querymax analysis time split up the fifth compares the correlation between class budget and analysis time and the sixth subsection outlines the threats to validity.
.
c1 main result figures and show the various recall and speedup trade off points for the cast check analysis and null pointer analysis respectively.
the x axis gives the recall plotted on a linear scale and the y axis gives the speedup plotted on a logarithmic scale.
there is actuallyathirdaxisforprecision butwedonotshowitbecauseall the techniques except for averroes get a precision.
we mark averroes precision directly in the figure.
whole programanalysis.
thewhole programanalysis marked by the black circle is considered as the ground truth and the reference for all speedup calculations.
hence it trivially gets recall and 1x speedup.
demand drivenanalysis.
thedemand drivenanalysis marked bythegreentriangle computesthesameresultasawhole program analysisandhencegets100 recall butitmanagesa5.1xgeometric 940icse may pittsburgh pa usa akshay utture and jens palsberg figure9 recallandspeedupforthevarioustechniquesfor the cast check analysisfigure recall and speedup for the various techniquesfor the null pointer analysis mean speedup for the cast check analysis because it avoids analyzingthewholeprogram.thismeanspeedupisnotrepresentativeof theaveragebenchmark.oneportionofthebenchmarksgetalarge speedupbecausetheyanalyzeasmallpartoftheprogram while othersexperienceaslowdownbecausetheyanalyzealargesection oftheprogramandthedemand drivenanalysisaddssomeoverhead.
thereasonforthisdifferenceinspeedupsisthatsomeprograms either have expensive queries like the example in section or a largernumberofqueries andothersdon t.thisobservationisin line with previous experiments on demand driven analyses .
a demand drivenversionofthenull pointeranalysisdoesnotexist seewhyinsection4 butweexpectittoperformworsethanin thecast checkanalysisbecausetherearesignificantlymorequeries in the null pointer analysis and the demand driven analysis works on a per query basis.
application onlyanalysis.
attheotherendofthespectrumisthe application onlyanalysis markedbyagreystar whichisorders of magnitude faster but gets a significantly lower recall.
for the cast checkanalysisitgetsa254xspeedupanda56 recall whereas forthenull pointeranalysisitgets1222xspeedupand58 recall.
the large speed up is attributed to the fact that the application constitutes only .
of the whole program on average figure .
an application onlyanalysis isa goodoption for use caseswhere analysisspeed issignificantlymoreimportantthanrecall butwhen bothareimportant it doesn tstrikeasgoodofa balancebetween the two.
averroes.
the point closest to this is averroes marked by a red plus whichgetsa 179xspeedup recall precision forthe cast check analysis and a 913x speedup recall precision for the null pointer analysis.
this is the only tool for which we report the precision because the other tools get precision.themassivespeedupofaverroesisattributedtothefactthatits summaryis tinycompared tothesize ofthelibrary.
however the tinysizeisalsowhatcausesanalysisinformationtobemergedandprecisiontodrop.the47 and71 precisionvaluesaresignificantly lower than our target of precision.
averroes should theoretically get recall for the cast check butnotforthenull pointeranalysisbecauseitslibrarysummary includes information about object initialization but not about fieldinitialization.theobservedrecallislowerthanexpectedbecause of a bug in its dealing of inner classes which causes any error propagating through a java inner class to be dropped.
the bug has been reported to the developers.
querymax.
finally querymax gives some points in between these two extremes.
the points marked with crosses are for the class budgets and the points marked with with squares are for the query coverage goals.
for the cast check analysis figure9 querymax performs very well.the3 budget purplecross getsa24xspeedupand92 recall and this strikes a really useful balance between the two metrics.
the10 budget blue cross gets an .7x speedup and a recall thereby favoring therecall alittle more than the speedup but still a great trade off between the two metrics.
the budget pink cross gets3.9xspeedupanda99.
recall.
thequery coveragestoppingcriterion representedbythesquares forthecast checkanalysisgetssimilarlygoodresults.the70 goal brown square gets 12x speedup recall and the goal yellow square gets .7x speedup recall .
the speedups for the coverage goals are slightly lower than the class budgets.
forexample the yellow square in figure is directly below the bluecross.
this happens because calculating the query coverage involvestheoverheadofatleastone fast esa whichtheclass budget versionavoids.however thecoverage goalgivesaguaranteeon 941fast and precise application code analysis using a partial library icse may pittsburgh pa usa the number of queries covered which could be more valuable than a guarantee on the number of classes analyzed.
forthenull pointeranalysis figure10 weseeasimilarspeedup vsrecalltrade offfor querymax .the3 class budget markedby thepurplecrossgets 34xspeedup recall the10 classbudget marked by the blue cross gets 11x speedup recall and the class budget marked by the pink cross gets .2x speedup recall .thequery coveragepoints markedbysquares liein between these three points.
unlike the cast check analysis the coverage goalvariantsarenotmuchworsethantheclass budget variantsforthenullpointeranalysis.wediscussthereasonforthis observation in section .
comparing figures and shows that querymax gets much better recall for the cast check than the null pointer analysis.
the main reason for this is that some dereference instructions get ahigh priority from querymax but are often never null pointer exceptions.
for example in any given program the println call occurs many times and in all cases gets its value from the fieldjava lang system.out.
since this field affects several dereferenceinstructions it ends up getting a high priority and that part of thelibrarygetsaddedtoourpartiallibraryfirst eventhoughthe println callsnevercausenull pointerexceptions.asimilarcase happens to some other common dereference instructions.
to sum up querymax with either stopping criterion provides a useful analysis design point in between the application only analysisandthedemand drivenanalysis justlikeintheexamplefrom section2.further unlikeaverroes itachievesthisspeedupwithoutsacrificingprecision andthuscontinuestomeetthehigh precision expectation of its users.
.
c2 distributionofrecallandspeedup we now understand the recall and speedup trade off points for querymax butwewouldalsoliketoknowtheirdistributionacross thebenchmarkprograms.figures11and12useahistogramtoshowthedistributionoftherecallandspeedupfor querymax witha70 query coverage.
the x axis gives the speedup or recall with the values split into bins and the y axis gives the number of programs in each bin.
just like figures and we use a logarithmic scaling for speedup here.
the recall is still plotted on a linear scale.
therecallfor querymax withthecast checkanalysis figure11 is close to for most of the programs with only a couple of programs getting lower scores.
two programs geta0r e call.
these programs had just and errors each and missing those errorsmeant a recall of .
the null pointer analysis figure has a similarstoryforrecall butithasalargernumberofprogramswith recall.
in most of these cases the null errors are very few and highly related and hence missing one library method could cause all the null errors to be missed.
the speedups for both analyses are consistent with most programs getting closeto the mean speedup value.the cast check has 2programsthatgetlessthana1xspeedup.thishappensbecause ifquerymax cannot guaranteethat coverage has been reached by thetime its chosenfragment expands to30 of theprogram it simply falls back to picking the whole program thereby resulting in no speedup.
.
zero error benchmarks theresultssofarfocusedontheprogramswithnon zeroerrors.figure13liststhespeedupforprogramswithzeroerrorsinthewhole programanalysis.thespeedupsfor querymax areonaveragetwice as much as the non zero error benchmarks.
the demand drivencast check however gets a 42x speedup here as compared to the .1xspeeduponthenon zeroerrorbenchmarks.thishighspeedup forthedemand drivenanalysisonthesebenchmarksstemsfrom thefactthattheseprogramshavemuchfewerdown castinstructionsthanthenon zeroerrorbenchmarks.thus whenthereare very few analysis queries a demand driven analysis gets a higher speedup.
.
split up of analysis time recalltheworkflowof querymax fromfigure1.wefirstrun querymaxwitheitheraquery coveragegoaloraclass budget.forquerycoverage querymax includestheadditionaloverheadofthe fastesa.finally weruntheexistinganalysis.figure14givesasplit up of the time between querymax minus the fast esa the fast esa and the existing static analysis for the query coverage goal.
forthecast check the fast esatakes51 of thetime whereas the other querymax part takes just .
this explains why the query coverage criterion from figure.
is slower than the classbudget one computing the query coverage needs the fast esa but computing the class budget does not.
for the null pointer analysis both the fast esa and the other partofquerymax takeupasmallpercentageofthetime totally .
the contribution of querymax andfast esato the total analysis time is larger for the cast check than the null pointer analysis.
the reason for this is that existing null pointer analysis has a longer absoluteanalysistimethanthecast check buttheabsolute fast esa time is similar in both cases.
.
analysis time vs number of classes as a minor result we show the relationship between the classbudget and the analysis time to justify our use of the former asa proxy for the latter.
figure compares the number of classes analyzed on the x axis with the analysis time on the y axis for both analyses.
each point represents one analysis of querymax with a class budget.
forboth analyses the analysis time isalmost linear but the cast check has more outliers which explains thehigh standard deviation for its analysis time see figure .
the figure also plots a regression line and the equation of this line can be used to convert time budgets into class budgets.
.
threats to validity therearetwomainthreatstovalidity.thefirstisthatoutofthe application third party libraries and standard library the standard library forms the largest part.
even though different programs interactwithdifferentpartsofthestandardlibrary itstillmeansthat the benchmarks are not perfectly independent for a static analysis.
however this issue occurs with any static analysis benchmark set where the programs access the standard library.
thesecondisthatanalysistimemeasurementsforalltheprogramswereperformedusingasinglerun eventhoughexecution times can vary across runs.
however since the speedups are large 942icse may pittsburgh pa usa akshay utture and jens palsberg figure speedup and recall histograms for querymax query coverage on the cast check analysisfigure speedup and recall histograms for querymax query coverage on the null pointer analysis analysis cast check null pointer application only 395x 2196x averroes 230x 1744x querymax class budget 30x 84x querymax class budget 13x 33x querymax class budget .4x 18x querymax query coverage 16x 20x querymax query coverage 12x 10x demand driven 42x n a figure speedup for the various analysis techniques for the zero error benchmarks ri wrwdo wlph dvw khfn 1xoo 3rlqwhu 4xhu 0d plqxv dvw dvw lvwlqj qdo vlv figure14 splitupofthetimetakenbyeachcomponentfor an analysis using querymax with the query coverage goal anorderofmagnitude andthebenchmarksarenumerous these variationsmatterless.further sincethetotalexperiment timeis already ten days performing multiple runs is infeasible.figure class budget and analysis time relationship.
related work the three research directions that focus on speeding up static analysis by avoiding the analysis of the entire program are librarysummary based analysis demand driven analysis and the analysis of program fragments.
we discuss each of these in turn.
library summarybasedanalysis.
themainideabehindtheresearch in this area is to create an analysis summary for the library andusethislibrarysummaryinsteadoftheactuallibrarycodeto analyze the application.
943fast and precise application code analysis using a partial library icse may pittsburgh pa usa averroes heavily compresses the library into a small summary.thissummaryconsistsofasinglesummary pointertorepresentalllibrarypointers stubsformethodscalleddirectlyfrom theapplication andasinglesummary methodtoperformallthe objectinitializationsandapplicationcall backs.sincethissummary is quite small compared to the library using it in place of the libraryresultsinamassivespeedup.however thesmallsizeofthe summary has two downsides precision drops because information is merged in the single summary pointer and some kinds of information like field initialization information for the null pointer analysis getleftoutoutofthesummary.
querymax incontrast leaves out no information in the partial library that it chooses and more importantly preserves the precision.
thecomponent level analysis by rountev et.
al differs from averroes in that its library summary contains all the information necessary to get the same result as a whole program analysis.
the first time an analysis is run the library is separately analyzed andsummarized andthesummaryisintegratedwiththeapplication analysis.
this saves no time in the initial run the overhead causes a slowdown .
however it saves time in subsequent runs when the same library summary is reused across different programsorfutureversionsoftheprogram.
querymax ontheother hand never uses the whole library and itspeedsu p the analysis of each program independently.
further unlike the component level analysis which needs a separate design for each type of analysis querymax can be used off the shelf with any analysis.
demand drivenanalysis.
demand drivenanalyses are well accepted as the most efficient option for single analysis queries and work best for resource constrained environments like idesandjitcompilers.theyalsoperformwellwhenthenumberof queries is small .
however when analyzing entire applications inwhichthenumberofqueriesislarge thedemand drivenanalysiscouldendupanalyzinglargepartsoftheprogramandcauseaslowdown because of their overhead .
we also see this observation in our benchmarks where some programs get huge speedups over a whole program analysis but some experience slowdowns.
unlikethedemand drivenapproach querymax avoidsexpensive queries by assigning them a low priority like in the example from section2.italsoavoidsthedemand drivenoverheadsinceitstill runs a batch analysis thereby performing better when there aremany queries to be answered.
further since querymax is only a preprocessor to an existing whole program analysis it can beused with an existing analysis without requiring a design of a demand driven version of it.
analysis of program fragments.
there has been past research onanalyzingprogramfragmentsinisolation.inouruse case the programfragmentistheapplication code.cousotandcousot describe four techniques for this general approach.
the first is a simplification based separate analysis which analyzes the various fragments of a program separately and then combines their information.
this idea is similar to the library summary based analysis by andhasthedrawbacksasdiscussedabove.thesecondtechniqueisaworst caseanalysis whichmeansrunninganapplicationonly analysis but using the top element of the abstract domain for library pointers.
this introduces additional false positives.
ourexperimentsonthistechniqueshowthatitgetsaprecision averagedoverboth analyses of22 whichisfarbelow our100 target precision.
the third technique is to ask a user to provide stubsfor the library i.e.
information about the library interface and thenperformanapplication onlyanalysisthatincorporatesthese stubs instead of the library.
this can give high recall precision and speedup but it requires a static analysis expert to manually write and update the stubs for each library.
the fourth technique uses arelationalabstractdomainandanalyzesaprogramfragmentby givingsymbolicnamestoexternalpointersandlazilyevaluating the values they pass.
to the best of our knowledge there are norecent implementations or experimental results to compare the effectiveness of this technique in practice.
rountev et.
al introduce a technique to improve the performanceofawhole programflow sensitiveanalysis.theyperform a flow sensitive analysis for the application code and then use a whole programflow insensitiveanalysistooverapproximatethe effect of the library pointers.
the two limitations of this technique arethatitdropsprecisionascomparedtotheoriginalflow sensitive analysis and it cannot be used to s peedupaflo w insensitive analysis.querymax on the other hand maintains the same precision astheoriginalanalysistoolandworkswithanylevelofcontext flow or field sensitivity.
conclusion and future work in this paper we introduce a new application focused analysis tool querymax which achieves alarge speedup over a whole program analysis without losing any precision.
querymax acts as a preprocessor to an existing static analysis to select a partial library that is smallbutsufficienttoanswermostoftheanalysisqueries.
querymaxprovidestheuserwithtwostoppingcriteria aclass budget or aquery coverage goal dependingon whether the userwants a handleontheanalysistimeortherecall.ourexperimentsonthe njr dataset show that querymax provides a significant speedup atthecostofasmallandcontrolleddropinrecall andwithnoloss in precision.
a possible future research direction could be to evaluate querymaxandtheotherbaselinetechniqueswithotherclientanalyses suchastaintanalysisortype stateanalysis.additionally onecould also extend the approach to the android platform with the help of frameworks suchas walathat support android analysis.finally a third direction could be to study how the querymax approach translatestobenchmarksinotherpopularlanguagessuchasc c and javascript.