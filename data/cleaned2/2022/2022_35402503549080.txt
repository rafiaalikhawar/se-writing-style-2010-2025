sediff scope aware differential fuzzing to test internal function models in symbolic execution penghui li chinese university of hong kong hong kong sar china phli cse.cuhk.edu.hkwei meng chinese university of hong kong hong kong sar china wei cse.cuhk.edu.hkkangjie lu university of minnesota minneapolis usa kjlu umn.edu abstract symbolic execution has become a foundational program analysis technique.
performing symbolic execution unavoidably encounters internal functions e.g.
library functions that provide basic operations such as string processing.
many symbolic execution engines construct internal function models that abstract function behaviors for scalability and compatibility concerns.
due to the high complexity of constructing the models developers intentionally summarize only partial behaviors of a function namely modeled functionalities in the models.
the correctness of the internal function models is critical because it would impact all applications of symbolic execution e.g.
bug detection and model checking.
a naive solution to testing the correctness of internal function models is to cross check whether the behaviors of the models comply with their corresponding original function implementations.
however such a solution would mostly detect overwhelming inconsistencies concerning the unmodeled functionalities which are out of the scope of models and thus considered false reports.
we argue that a reasonable testing approach should target only the functionalities that developers intend to model.
while being necessary automatically identifying the modeled functionalities i.e.
the scope is a significant challenge.
in this paper we propose a scope aware differential testing framework sediff to tackle this problem.
we design a novel algorithm to automatically map the modeled functionalities to the code in the original implementations.
sediff then applies scope aware grey box differential fuzzing to relevant code in the original implementations.
it also equips a new scope aware input generator and a tailored bug checker that efficiently and correctly detect erroneous inconsistencies.
we extensively evaluated sediff on several popular real world symbolic execution engines targeting binary web and kernel.
our manual investigation shows that sediff precisely identifies the modeled functionalities and detects new bugs in the internal function models used in the symbolic execution engines.
ccs concepts software and its engineering software testing and debugging security and privacy software security engineering .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
differential testing symbolic execution internal function models acm reference format penghui li wei meng and kangjie lu.
.
sediff scope aware differential fuzzing to test internal function models in symbolic execution.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
introduction symbolic execution is a foundational program analysis technique that symbolically reasons about program behaviors.
it has shown great promise and has been applied to various tasks such as bug detection vulnerability assessment root cause analysis etc.for example recent symbolic execution frameworks are able to detect vulnerabilities in well tested software like openjepg chrome and firefox .
software development often involves internal functions which are provided along with the language systems.
they include library functions and built in functions that offer basic operations like string processing arithmetics bit manipulation etc.similar to normal concrete execution symbolic execution also requires understanding the semantics of the internal functions.
the internal functions however incur two important problems to symbolic execution scalability andcompatibility .
first internal functions are often frequently invoked basic functions e.g.
string processing and arithmetical operations .
our study shows that in modern software around of internal functions are invoked at least twice and many are called for thousands of times see .
for more details .
therefore symbolic execution easily becomes unscalable if it repeatedly runs them.
second internal functions are often implemented in a language e.g.
c different from the one of the main programs e.g.
php .
existing symbolic execution engines typically target only the language of the main program and are unable to handle internal functions in a different language .
to solve the aforementioned problems function modeling is thego to approach that has been widely adopted in common symbolic execution tools.
modeling is to abstract the behaviors of the target function so the analysis does not have to go through the internal details repeatedly.
prior works model the behaviors of internal functions and integrate the models to the underlying symbolic execution engines.
in this work we refer to such interpretation of internal functions in symbolic execution asinternal function models .
for example a popular symbolic execution engine angr defines simprocedure for modeling.
esec fse november singapore singapore penghui li wei meng and kangjie lu the correctness of the internal function models is critical to symbolic execution and its applications.
incorrect internal function models could lead to incorrect reasoning of the programs.
a symbolic execution based bug detector would wrongly determine the path feasibility because of an incorrect internal function model thus the results it outputs would be inaccurate and unreliable.
also an error in symbolic execution based vulnerability assessment may miss critical vulnerabilities and delay the patching.
accordingly the security analysts have to take excessive time to manually verify the results or filter out the false reports.
despite the importance to the best of our knowledge testing internal function models remains an under explored topic.
past practices largely rely on user reports to identify and fix bugs in them which is inefficient.
only a few recent research works have attempted to automatically test them through differential testing which compares the behavior of symbolic execution to that of concrete execution.
however they have several inherent limitations.
they focus on testing symbolic execution engines as a whole whereas the internal function models are not thoroughly studied.
in particular kapus and cadar checked whether the results of symbolic execution conform to concrete execution for programs generated by csmith .
their method explores more on the diversity of overall program syntax.
it fails to probe the semantics of internal functions and their models and as a result does not detect any bugs in the models.
to the best of our knowledge the most relevant work xsym leverages an existing regression test suite to check internal function models in a php symbolic execution engine navex .
however its approach is restricted in both scalability and depth it requires human efforts to extract the models and can only test part of the models.
thereby it could not precisely reveal bugs in internal function models as we will show in .
.
a fundamental problem with existing differential testing works is that they do not attempt to specifically target modeled functionalities that are interpreted in the internal function models.
by its nature modeling focuses on only the most important functionalities and chooses to discard or ignore the rest unmodeled functionalities .
as existing works test symbolic execution engines as a whole they simply report all inconsistencies including the ones out of the modeling scope as bugs.
most of the reported bugs would be false positives.
we believe that a reasonable testing approach should rather focus only on the modeled functionalities.
however automatically identifying the modeled functionalities i.e.
the scope is challenging as neither the developer intention nor the modeling logic is provided.
distinguishing the modeled functionalities from the unmodeled ones requires deep understanding of their semantics and thus is non trivial.
in addition to the scope challenge we identify two other major challenges in developing a differential testing framework for the models.
first it is challenging to scalably support diverse representations of the models in different symbolic execution engines.
symbolic execution engines take distinct ways to construct their internal function models.
as a key component the models closely coordinate with the rest of the engines.
it is thus non trivial to distinguish the models from the other symbolic execution components which however is a required first step for inferring the modeled functionalities.
second generating workloads to efficientlydetect bugs within the scope is hard.
the workloads are expected to extensively exercise the modeled functionalities without wasting resources on testing other unmodeled functionalities.
none of the existing works has ever attempted to consider the scope for generating workloads.
in this paper we design a scope aware differential testing framework sediff .
it incorporates several new techniques to overcome the above mentioned challenges.
first we observe that though the internal function models are implemented diversely within the symbolic execution engines most internal function models are passed to the smt solvers e.g.
z3 in a uniform format smt lib language .
we propose minimal program synthesis for generating the smt lib expressions of internal function models to help us uniformly and accurately extract the internal function models.
second we find that every internal function has its original implementation that realizes all its functionalities including the modeled functionalities.
we define a program path in the original implementations of the internal functions as a functionality.
we develop a mechanism that maps the paths in the models to their original implementations to identify the modeled functionalities and resolve the scope challenge.
to realize the mapping we develop a new technique to recover the data flows from disordered smt lib formulas for the models.
third we leverage the grey box fuzzing technique on the original implementations to thoroughly drive differential testing.
we design a new coverage metric and a feedback mechanism that help generate in scope workloads.
we also develop a tailored bug checker to accurately label bugs during testing.
we thoroughly evaluated sediff on several state of the art symbolic execution engines e.g.
angr that employ internal function models.
we first apply sediff to extract models and identify modeled functionalities.
our manual investigation of the modeled functionalities it reported reveals that sediff can accurately pinpoint modeled functionalities with high precision.
we then use sediff to differentially fuzz the models.
it successfully detected new bugs in the internal function models.
it significantly outperformed the related work xsym by detecting more bugs.
our characterization further demonstrates the importance of identifying modeled functionalities and confirms the benefits of sediff awareness of scope.
we believe that sediff s techniques are generic.
it has huge potential for other application domains that have multiple implementations complying with similar specifications.
we open sourced our prototype implementation to facilitate future research .
in summary we make the following contributions in this paper.
first in depth study.
we propose the first comprehensive study on internal function models and define several key concepts of this problem.
new techniques.
we propose sediff with multiple generic techniques including automated and uniform model extraction through smt lib and minimal program synthesis automated identification of modeled functionalities with data flow recovery in smt lib formulas and scopeaware differential fuzzing for modeled functionalities with new input generation and feedback mechanisms.
58sediff scope aware differential fuzzing to test internal function models in symbolic execution esec fse november singapore singapore numerous new bugs.
with sediff we found numerous new bugs in the internal function models in the state of theart symbolic execution engines.
motivation and problem statement .
internal functions in symbolic execution following the code reuse paradigm programming language systems contain numerous functions that cover basic operations.
they aim to facilitate the use of the language systems and significantly improve programming efficiency.
in this work we name the functions that provide basic operations like string processing arithmetic and bit manipulation as internal functions .
for example the c c language systems include a large number of standard library functions the php system provides numerous built in functions in the php interpreter implemented using c. as a necessary component of the programming language systems internal functions are widely adopted and used by developers .
in a preliminary study we measured the use of internal functions.
we parsed a popular php application wordpress and a widely used c program suite gnu coreutils 1and computed the frequency of direct static function invocations in their source code.
the results showed that .
resp.
.
of function invocations in wordpress resp.
gnu coreutils were about internal functions.
symbolic execution simulates the program execution in a symbolic manner and it naturally has to reason about the semantics and behaviors of internal functions.
two important problems arise when symbolic execution meets internal functions.
the first is the scalability problem.
internal functions are often frequently invoked for basic operations such as string processing and arithmetics.
our preliminary study showed that .
resp.
.
of internal functions in wordpress resp.
gnu coreutils appeared at least twice.
in both cases many internal functions occurred hundreds to thousands of times and some internal functions were among the most frequently invoked functions.
for example wordpress invoked substr for2 211times which accounted for .
of all function calls gnu coreutils called strlen for3 148times which represented .
of all function calls.
therefore symbolically executing those functions repeatedly would significantly slow down the overall performance of symbolic execution.
second symbolic execution would raise compatibility issues due to the cross language nature .
in particular internal functions in a programming language are often implemented in a different language that is incompatible with the symbolic execution engine.
as a result a symbolic engine for one language system can hardly seamlessly analyze the target programs without additional interpretation of internal functions.
for example all php internal built in functions are implemented in c in the php interpreter a typical php symbolic execution engine naturally analyzes the main language php while it is also necessary for the engine to support the internal functions.
interpreting the internal functions however is non trivial .
1we used the latest wordpress v5.
as of mar .
we failed to configure the latest gnu coreutils and used a relatively old version v8.
.
we believe the overall trend could naturally be ported to the latest version.
.
function modeling as a practical solution function modeling which abstracts the relevant semantics and behaviors of a target internal function is the go to approach to addressing the scalability and compatibility issues in common stateof the art symbolic execution engines .
in particular they construct a model for an internal function only once and symbolic execution can reuse it across the whole analysis phase thus resolving the scalability problem the constructed model can be seamlessly integrated into underlying symbolic execution engines thus tackling the compatibility issue .
many well known symbolic execution engines e.g.
angr navex etc.
employ modeling for bug detection and exploitation.
in this work we refer to such models of internal functions in symbolic execution as internal function models .
the modeling process requires the domain knowledge of language systems and symbolic execution engines thus is often completed in a manual manner.
due to the excessive manual efforts modeling requires as a practical implementation choice developers thus choose to model the most important internal functions .
we indeed observe that the modeled functions are normally among the most frequently invoked ones .
for example substr andstrlen are generally modeled in popular symbolic execution engines such as navex and angr.
for the same reason developers model only the most important functionalities of a function instead of all functionalities.
we refer to such functionalities in the models as modeled functionalities in this paper.
.
research goals as symbolic execution is a foundational analysis technique depending on the applications incorrect models can lead to many issues such as failures to detect vulnerabilities delaying the patching of critical bugs or introducing regression bugs .
also the security analysts have to take excessive time to manually verify the results or filter out the false reports.
testing the correctness of the models is thus of great importance.
in this work we aim to automatically apply differential testing to the internal function models.
we want to identify what functionalities are included in the models and test if they are modeled correctly.
more importantly under the progressive evolution of symbolic execution we hope to provide a systematic solution for developers to understand the models probe any mistakes and improve the state of the art symbolic execution engines.
.
research challenges we identify several research challenges that motivate us to propose new techniques.
supporting diverse representations of models.
as the first step we need to uniformly extract the models from a given symbolic execution engine that may target a specific language.
symbolic execution engines for different language systems have a diverse set of internal functions e.g.
the php built in functions and the c c standard library functions realize different functionalities.
manual analysis of the code to pinpoint the models certainly cannot scale and is costly especially because symbolic execution engines are quite complex implemented with millions of lines of code.
the models in them comprise only a small proportion in the huge code 59esec fse november singapore singapore penghui li wei meng and kangjie lu differentiallyfuzzing modelsunmodeled functionality1241253476 data flow analysis map pathsidentifyingmodeled functionalities minimal program extract formulas fuzzing loop symbolic execution enginesmodelsscope guidedinput generatortailored bug checkeroriginal implementationsextracting modelsmodeled functionality figure the architecture of sediff .
base.
besides as a key component the models closely coordinate with other engine components to achieve the overall functionality.
for example the models can closely co work with the memory management component constraint solving component etc.
which are out of our research scope .
it is hard to distinguish the code of the models from the rest components especially when the model code shows little difference from the code of other parts.
identifying modeled functionalities.
as we mentioned earlier developers would include only selected functionalities of the functions into the models i.e.
modeled functionalities and intentionally ignore the rest unmodeled functionalities.
from our own experience and the communications with developers most developers do not appreciate or accept reports concerning unmodeled functionalities because they do not plan to support those functionalities in their tools from the very beginning.
apparently the testing of the models should focus on only the modeled functionalities.
therefore we need to distinguish if the revealed behaviors are related to the modeled functionalities.
it is challenging to identify the model scopes as it requires a deep comprehension of the semantics of the models.
efficiently detecting bugs in modeled functionalities.
differential testing requires test cases to drive the targets for the testing.
none of the existing work has attempted to generate test cases to test the internal function models.
blindly generating test cases in a black box manner is inefficient.
it is hard to design heuristics to thoroughly exercise the models to achieve high coverage.
besides the input generator should be aware of the model scope and construct high quality inputs to exercise the modeled functionalities.
design of sediff in this paper we design a scope aware differential testing framework sediff to facilitate bug detection in internal function models in symbolic execution.
the high level architecture of sediff is depicted in figure .
sediff entails overcoming the technical challenges with several new observations and techniques automated and uniform model extraction.
we observe that regardless of the language of a symbolic execution engine the models are passed to an smt solver at the end in the form of smt lib language .
we thus propose minimal program synthesis to generate the smt lib expressions for the models which greatly helps us extract the models.
we will explain how we extract the models in the uniform smt lib expressions with minimum program synthesis .
.
?php arg post ret 5if abs arg ret check point listing a minimal program that invokes an internal function model .
scope identification.
by its nature modeling is to abstract how a function should behave under different inputs which are essentially the different execution instances i.e.
code paths .
to this end we carefully define the functionalities as distinct program paths in the original implementations of the internal functions.
therefore the task of identifying the model scope is transformed to mapping what program paths are realized in the models.
we first propose new techniques to recover the data flow from disordered smt lib formulas for the models.
we then perform a data flow analysis on both the models and their original implementations to identify common data paths.
scope aware differential fuzzing.
we develop a scope aware grey box differential fuzzer to facilitate bug detection in modeled functionalities.
we propose a new coverage metric to particularly guide exploration towards the identified modeled functionalities in the original implementations we also design a tailored bug checker that can utilize the model scope to distinguish if or not the inconsistencies are associated with the modeled functionalities.
.
model extraction with smt lib and minimal program synthesis we extract the models based on a key observation the uniformity of smt lib .
the smt lib standard is a widely adopted international initiative aiming at facilitating research and development in satisfiability modulo theories smt .
smt lib specifies a general language for input formulas that smt applications work with.
we find that though the models are implemented diversely across engines they are finally passed to smt solvers in the same form of smt lib expressions where their operations are interpreted and captured.
therefore the smt lib language format enables a uniform and accurate analysis of diverse models across engines.
the next question is how to know which parts in the smt lib expressions correspond to internal function models.
our idea is to minimize the smt lib expressions and exclude those that are irrelevant to the models.
to this end we synthesize a minimal program whose purpose is solely to invoke the internal function models.
this way we can reliably extract the smt lib expressions for the models by simply removing the irrelevant invoking expressions.
for example listing presents a minimal program that invokes the php built in function abs which calculates the absolute value of a given argument.
the minimal program invokes the internal function in a conditional statement line .
when a symbolic execution engine analyzes the minimal program to determine the path feasibility it seamlessly interprets the internal function and calls its model for constraint solving which is later recognized and extracted.
sediff automatically synthesizes minimal programs from function signatures.
the step is currently assisted with a manual step 60sediff scope aware differential fuzzing to test internal function models in symbolic execution esec fse november singapore singapore assert ret var1 assert var2 arg assert var1 ite arg arg var2 a internal function model.
argvar1var2ret b data dependencies of variables.
figure the simplified function model of php internal function abs and the data dependency diagram of the variables.
where we manually obtain the corresponding function names of the models from the symbolic execution engines.
this is manageable because the number of modeled functions is usually not large.
automatically extracting all the modeled internal functions is possible for one specific symbolic execution engine but requires a considerable amount of engineering efforts to support multiple engines.
a function signature consists of the parameters and their types.
sediff automatically constructs the code to call the internal function.
the synthesized program includes the code of the function calls together with the argument preparation code e.g.
lines in listing .
note that the synthesized minimal program is required to be presented in the target language of the symbolic execution engine e.g.
php for navex .
to obtain models in the smt lib language representations we first install the symbolic execution engine and use it to analyze the automatically synthesized minimal programs.
today symbolic execution engines commonly use smt solvers such as z3 and cvc4 .
the solvers provide options to dump the input constraint formulas.
therefore we extend the smt solvers to additionally save the constraint formulas when the solvers are invoked.
as the output of this phase the formulas describe the semantics and behaviors of the internal function models.
figure a is a simplified function model for php internal function abs extracted from navex.
the model in the smt lib language contains an argument arg a return variable ret and several intermediate variables var1 and var2 .
it evaluates the value of the argument and accordingly returns the negated value or the original one.
in particular it uses a ternary operator i.e.
ite to evaluate if the argument is positive and returns a value based on the result.
it uses the assertion operator i.e.
assert to enforce the relation e.g.
equality between operands.
.
identification of modeled functionalities we identify the modeled functionalities automatically from the extracted models.
we observe that a model is the abstraction of how a function should behave for different inputs.
it essentially represents the execution instances i.e.
code paths under different inputs.
therefore we define a unique code path from the function entry to a return point in the original implementation of an internal function as a functionality.
such a definition has two benefits.
first it is fine grained enough to capture the modeled functionalities because it can cover all possible execution instances.
second the task of identifying the modeled functionalities is transformed into mapping the model s smt lib formulas to the code paths in the original implementations.
we then propose a path mapping algorithm to identify the code paths of the functionalities included in the models.
the extractedtable data flow representation system.
constant c integer string bool function f f expression e c arg f e e1ope ope argument arg e smt lib formulas mostly describe the model s behaviors as the data relationship among variables using basic boolean and arithmetic operations.
thus a natural way to map the paths is utilizing the data flow information.
a code path processes the function arguments.
because our correctness testing focuses on whether a model produces correct results in the return value or the function arguments the data flow relationship associated to a path with arguments can well represent the semantics and behaviors of the path.
we thus refine the definition of functionality as the data flow formula of the arguments in the code path.
therefore our algorithm tries to map the data flow in a code path of the model to the one in its original implementation.
the mapped data flow pairs then indicate the functionalities included in the models.
we particularly consider the data flows from the function arguments to the return values.
the rationale is that the models preserve the semantics of the internal functions and the same data flow relationships between arguments and return values remain in the models.
.
.
data flow recovery and analysis.
our data flow analysis takes as inputs the source code of original function implementations and the extracted models represented in smt lib.
it infers the data flow relationships between the function arguments and return values in both the original implementations and the models and represents them in the same form.
the uniform representation of the data flow relationships enables sediff to link the original implementation of a functionality with its counterpart in the model.
data flow recovery and analysis on models.
performing dataflow analysis on the smt lib representations of the models is non trivial.
to the best of our knowledge no existing works have ever attempted that.
the smt lib language describes the models as formulas which nonetheless are disordered and do not contain explicit data flow.
the obstacle for the data flow analysis is that the uses of variables in the formulas do not convey explicit data flow relationships.
for example assert ret var1 only implies retandvar1 should hold the same value whereas their data dependency is unclear.
to solve this problem we identify the data dependencies among variables in smt lib formulas to recover the data flow.
our algorithm is based on the fact that data flow can only be propagated from rvalue tolvalue in assignment statements.
lvalue stands for expressions that can be on the left hand side of the assignment operator or that refer to memory locations rvalue represents all other expressions that can be on the right hand side of the assignment operator.
our algorithm first identifies all assignment operations in a smt lib formula.
it then classifies the operands as lvalue and rvalue respectively and discovers the data dependencies between lvalue and rvalue.
smt lib language only defines the equality operator i.e.
which can actually imply either the assignment operation e.g.
61esec fse november singapore singapore penghui li wei meng and kangjie lu ret var1 or the equality operation e.g.
ret var1 in the original implementations.
we use several heuristics to infer the assignment operations and the data dependencies in their operands.
first there are three categories of variables in the formulas namely arguments return variables and the rest intermediate variables.
we can directly identify from the arguments and return variables by their symbolic names.
the data flow in a path should start from arguments and end at return variables.
for example the data flows from argtoretin figure a .
second compound expressions can only appear in the equality operations or in the rvalues of assignment operations.
if an equality operation has only one compound expression as an operand we can determine that operand as its rvalue and the other as its lvalue.
line in figure a is such a case where lvalue is var2 and rvalue is arg .
last we conservatively consider that both operands can be either lvalue or rvalue accordingly for the rest cases.
the analysis thus outputs the data dependencies of variables as shown in figure b .
while being simple our experiments in .
demonstrate that it has high precision of .
.
after identifying the data dependencies our algorithm chains the data dependencies to construct the full data flow of the paths.
in particular it seeks the data origin of rvalue i.e.
arguments and walks to lvalue next in each assignment.
it explores possible paths that can reach the return variables from the arguments.
at the end of the analysis sediff represents the return values as formulas of the function arguments using the form shown in table .
the formulas are later compared to the ones from the original implementations.
as shown in table the simplest form is an expression e which can be either a constant value c a function argument arg a function call f e or an operation above expressions e1op e .
function arguments and return values can also be described as expressions.
in the example of figure a the two possible data flow formulas areret arg and reg arg respectively.
data flow analysis on original implementations.
sediff also performs a data flow analysis on the source code of original function implementations.
it constructs a control flow graph cfg for a function and walks through the cfg from the function entry to the end basically return statements .
it inlines callee functions and creates a single cfg to gather execution information across functions.
following the common practices we set the maximum inlined basic blocks and functions to and thereby limiting the size of intermediate results in our analysis.
similarly this data flow analysis also outputs the return values using exactly the same form shown in table .
.
.
mapping paths.
sediff next maps the data flow formulas of the return values to identify the modeled functionalities code paths .
though represented in the same form the two implementations use distinct intermediate variables and symbols and simply comparing the data flow or variables in code paths would not necessarily work.
to reduce the noises from the symbol names for mapping sediff normalizes the symbol names in the representations.
for example an argument is turned into argifrom its original identifier.
sediff then cross checks the normalized return value representations regarding arguments and matches them from the models to the original implementations.
in particular sediffchecks if a return value is identically represented in both implementations regardless the symbol names.
if a match is found it labels the corresponding path as a modeled functionality and the relevant code on the path as modeled code.
in summary this stage analyzes the data representations of return values in the coherent form shown in table and outputs modeled code locations in the original implementations.
.
scope aware differential fuzzing for models after identifying modeled functionalities from the previous phase sediff employs scope aware differential fuzz testing to detect bugs in the models.
it aims to check the function models conformance to their original implementations.
.
.
scope aware exploration.
given the success of fuzzing a natural choice is to use the coverage feedback to guide the exploration which requires first instrumenting the testing targets models.
however it is hard to design a strategy to instrument the models and capture their coverage information in the smt lib formulas.
it is also difficult to instrument them which are identified yet in the inconsistent form of smt lib in the symbolic execution engines.
we take an alternative approach to collecting the coverage feedback by instrumenting the original implementations.
rather than directly fuzzing the models we instead focus on the corresponding original implementations of the functions.
we can naturally utilize existing fuzzing frameworks like afl and libfuzzer with their instrumentation tools to achieve this goal.
a problem of this approach is that the original implementations cover not only modeled functionalities but also unmodeled ones the latter is not our test target.
traditional fuzzers consider all edges between basic blocks and treat their coverage equally .
as a result they would try to fairly explore all code and waste much effort on the unmodeled functionalities.
scope aware input generation.
inspired by tortoisefuzz we propose a new coverage accounting approach that selects test cases based on the coverage of modeled functionalities.
our insight is that we consider only modeled functionalities in the fuzzing coverage metric and exclude the irrelevant unmodeled functionalities.
in this work we refer to the edges between basic blocks concerning modeled functionalities as model edges and their associated code coverage as model coverage respectively.
we design sediff to exclusively instrument the model edges in the original implementations and thus measure only model coverage during testing.
our input generator prioritizes test cases by the new model coverage metric and culls the prioritized test cases by the hit count of model edges.
the input generator explores the input space of the internal functions.
it favors and saves both the inputs arguments and the results of a concrete test case during fuzzing if the test case is interesting.
specifically it regards a test case as interesting if the test case brings new model coverage such as hitting new model edges or increasing model edge hit count.
the rationale behind this is that such situations causing new model coverage are likely to reach new components in the models as well.
the saved fuzzing results on original implementations are next applied to the models for differential testing .
.
.
62sediff scope aware differential fuzzing to test internal function models in symbolic execution esec fse november singapore singapore feedback mechanisms.
the fuzzing component employs two kinds of feedback mechanisms for seed selection and mutation.
the feedback mechanism summarizes the importance of a test case and decides whether it deserves further exploration and mutation .
basically our fuzzer tracks the visited code in a testing trial and uses the feedback from model coverage.
it decides if a test case triggers new model coverage.
additionally the input generator allows feedback from the checker to favor certain test cases.
it currently uses the bug checking result whether a bug is triggered or not as the feedback.
more energy for the mutation and exploration is allocated to the test cases with positive feedback.
the feedback allows sediff to further lean its fuzzing efforts towards erroneous locations.
the rationale is that a test case triggering a bug is likely to trigger other bugs near it because erroneous locations sometimes contain more than one bug.
this has been evident in memory safety bugs .
.
.
differential fuzzing.
in each fuzzing trial of the original implementations sediff simultaneously applies the fuzzing results to the models for differential testing.
driver program generation.
sediff constructs simple driver programs to help verify whether models comply with concrete fuzzing trials of original implementations.
suppose an interesting fuzzing case provides a tuple of for a function f sediff prepares a corresponding smt lib formula in the form of assert op f where opdenotes comparison operators such as etc.sediff then passes the formula with the extracted model to the smt solver and queries a satisfiability solution.
the solution is used for the conformance check.
tailored bug checker.
we design a tailored bug checker to facilitate compliance checks.
a bug checker can naturally be designed to cross check the satisfiability solution from the solver and its expected value and report any unexpected deviations as bugs.
however there are two categories of inconsistent behaviors that a bug checker needs to distinguish inconsistent behaviors associated with modeled functionalities and unmodeled ones respectively.
a model can produce inconsistent results concerning the unmodeled functionalities as they are not fully supported by the developers.
such cases nonetheless are not our focus in this work and should be excluded.
our bug checker probes if the inconsistent behaviors are associated with modeled functionalities.
to do this we use an instrumented version of the original implementation to mark the code paths of the modeled functionalities.
during testing the bug checker invokes the instrumented version to monitor whether a test case triggers the instrumented modeled functionalities and thus distinguishes the two types of inconsistencies.
the checker also signals the bug checking result as the feedback for input generation and fuzzing.
implementation we implemented a prototype of sediff currently for models whose original implementations are written in c c .
we developed the data flow analysis for original implementations as an llvm pass above juxta with 1k lines of c code.
we used 2k lines ofpython code to parse the smt lib language and realize its dataflow analysis.
the grey box fuzzing stage was built above afl using around 1k lines of c code.
the tailored bug checker was realized above afl s llvm instrumentation tool using lines of python code.
the prototype is available with the .
zenodo.
.
the rest of the section describes some important implementation details.
instrumenting original implementations.
the instrumentation phase of fuzzing inserts additional instructions in each basic block.
the fuzzer can leverage the instructions to dynamically perceive which particular basic blocks or edges are visited in a fuzzing trial.
to realize our tailored instrumentation against modeled functionalities we first identify all basic blocks of the modeled functionalities discovered during the data flow analysis and path mapping steps.
besides the bitmap for overall coverage we allocate an additional shared memory area for the model coverage.
we also employ instrumentation to realize the bug checker.
in particular given a test case we record the execution trace of the original implementations and check whether it triggers a code path in the modeled functionalities.
feedback and seed selection.
afl maintains a favored seed queue and adds test cases triggering new coverage to the queue .
we extend afl by adding test cases that trigger bugs to the queue according to the checker feedback.
in particular we modified thesave if interesting function of afl.
the function could perceive if a test case causes positive checker feedback new model coverage and new overall coverage.
we modified the cull queue function of afl to perform seed selection.
the cull queue function is used to prune the test cases while maintaining the same amount of edge coverage.
we select efficient test cases that cover all visited model edges using the model coverage information.
evaluation this section evaluates sediff on various aspects.
we aim to answer the following questions how effective is sediff in identifying modeled functionalities?
cansediff detect bugs in internal function models?
how do our techniques contribute to sediff s bug detection capability?
in the rest of this section we first describe the experimental setup .
.
then we evaluate the effectiveness of modeled functionality identification .
and bug detection .
.
next we present the ablation study and comparison .
.
.
experimental setup we include diverse state of the art symbolic execution engines that employ internal function models in our evaluation.
our dataset selection criteria are to include engines that are implemented in different language systems used for diverse application scenarios and tested by related works.
as our prototype currently supports only c c we limit the engine selection to those of which the modeled internal functions are implemented in c c .
to this end we include representative symbolic execution engines shown in the first column of table .
the engines are implemented in different programming languages such as python java and c and have application targets of binary web applications and kernel.
63esec fse november singapore singapore penghui li wei meng and kangjie lu we currently do not include some popular symbolic execution engines in our evaluation either because they are not open sourced or they support internal functions using approaches other than function modeling .
for example klee does not employ function modeling in analyzing the llvm ir of c c programs because the relevant internal functions e.g.
library functions are also implemented in c c and can be compiled into llvm ir for analysis.
nevertheless we believe the high diversity of our dataset allows us to thoroughly evaluate the effectiveness and scalability ofsediff .
we download the source code of each engine from its official website and configure it with the default settings in our experiments.
we first manually identify the function names and signatures of the models from the engines for minimal program synthesis.
as sediff relies on the original implementations of the models for its analysis we also find the original implementations of each model.
the original implementations can be found from different sources such as gnu c library php interpreter etc.the experiments were conducted on a server running debian gnu linux .
stretch with four core intel xeon cpus and 512gb ram and a desktop computer running debian gnu linux buster with a core intel xeon cpu and 16gb ram.
.
identification of modeled functionalities we use sediff to extract the model and perform data flow analysis.
here we evaluate its efficacy in identifying modeled functionalities.
.
.
identification results.
table presents the results of our modeled functionality identification phase.
in general not all internal functions and functionalities are modeled in practice.
our dataset in total contains internal function models and 424functionalities out of which .
were identified by sediff as modeled ones.
this is consistent with our previous claim in .
and can be explained by the limited human resources and high requirement of domain knowledge.
it further indicates the importance of our functionality identification technique for testing internal function models.
we further compute the proportion of the modeled functionalities at source code level.
each modeled functionality corresponds to a code path in the original implementation.
therefore we find the relevant basic blocks in the code path count the number of basic blocks and calculate the proportion of the identified modeled functionalities.
we found that the modeled functionalities comprised only a small proportion .
of the code base in the original implementations.
the detailed proportion for each engine is presented in the 8th column of table .
.
.
precision of identification.
we study if sediff can precisely identify the modeled functionalities i.e.
if it can precisely map the data flow pairs.
we are particularly interested in understanding how many unmodeled functionalities are wrongly identified as modeled ones.
a wrong identification is an incorrect positive mapping between the data flow in the smt lib formula and the one in the source code.
we conduct a manual analysis to investigate the results sediff reported.
due to the large number of reported functionalities confirming all of them requires excessive human effort and is infeasible.instead we sample a total of models in the engines according to the number of models in them.
specifically we randomly selected and models from the engines respectively.
we believe such a random sampling approach is sufficient for obtaining some general statistics about the precision of our technique.
for each sampled model function we manually confirm true positives in the mapped functionality paths by understanding whether each pair conveys the same functionality.
we specifically compare the semantics and usage by reading the code and descriptions.
the models contain in total 984functionalities in the original implementation.
sediff identified as modeled functionalities that were mapped to their original implementations.
among those our manual investigation revealed that out of were true modeled functionalities resulting in a precision of .
.
considering the inherent challenge of understanding the modeled functionalities across diverse representations we believe that this number is reasonable for guiding path exploration.
we have investigated the causes of the incorrect mappings.
the main causes can be categorized into three classes.
first the data flow in some cases could not be precisely reconstructed by our heuristics due to the lack of semantics in the formulas.
our conservative approach considers all possible data flow directions in the assignment statements.
as a result sediff mistakenly mapped several code paths.
such situations account for around of the incorrect mappings.
second around of incorrect mappings were caused by our limited inter procedural analysis.
our data flow analysis encounters inter procedural calls.
the model and its original implementation have different supports of function calls.
we temporally treat all function calls equally and do not intercept their semantics.
as a result some data flow could not be captured.
third our current implementation does not support complex parameter logic precise point to analysis etc.such cases account for of the incorrect mappings.
.
.
performance.
sediff s static analysis is highly efficient and scalable.
it statically analyzed all the models in the complex symbolic execution engines within minutes.
the analysis time for each engine in detail is shown in the 9th column of table .
.
bug detection we further apply sediff to differentially fuzz the internal function models and detect bugs.
each engine contains multiple internal function models and we separately fuzz each model for runs each with hours.2this experiment in total took over 000cpu hours.
due to the fundamentally random nature of fuzzing sediff could report diverse results in different runs even with the same configurations.
therefore we aggregate all reported unique bugs and present the results in table .
we do not use the average because the aggregation allows us to quantitatively analyze the false positives among the reported bugs.
sediff reports as a unique bug if the case exhibits behavior deviations concerning modeled functionalities and triggers a unique execution trace.
overall sediff is highly effective and reported new bugs in the symbolic execution engines.
specifically sediff identified and bugs in angr 2though klees et al.
recommended to run the fuzzer for complex programs for hours and runs our practice shows that hours here are sufficient as we separately fuzz each model and function.
64sediff scope aware differential fuzzing to test internal function models in symbolic execution esec fse november singapore singapore table experiment results of modeled functionality identification in representative symbolic execution engines.
m. func.
and func.
mean the number of modeled functionalities and the total functionalities among all models in an engine.
m. code means the basic block level code proportion.
time stands for the static analysis time in minutes.
engine impl.
lang.
target model func.
m. func m. func.
m. code time angr python binary .
.
navex java web .
.
kubo c kernel .
.
deadline c kernel .
.
total .
.
table bug detection results of sediff .
engine fp tp tp str.
tparr.
tparith.
tpother angr navex kubo deadline total navex kubo and deadline respectively.
the bugs span .
out of internal function models.
this demonstrates that many internal function models in production symbolic execution engines are still error prone.
we observe that the bug detection result varies per engine.
in particular the state of the art php symbolic execution engine navex has more bugs than enginies targeting binary analysis and kernel analysis.
we suspect that navex statically translates certain php internal built in functions into smt formulas and does not carefully consider the dynamic typing feature of php.
the results include a few false positives.
our manual investigation showed that the false positives caused inconsistent behaviors that concerned unmodeled functionalities which were previously incorrectly identified as modeled ones .
.
.
in other words all false positives come from the false positives in the static identification phase.
differential testing approaches usually have a large number of false reports e.g.
.
of bugs that r2z2 reported were false cases.
nevertheless as shown in table the ratio of false positives to all bugs reported by sediff is not high only out of cases .
.
while these are not vulnerabilities that can be exploited for attacks we reported the bugs to the developers of the symbolic execution engines which are widely employed for security applications.
at the time of writing bugs have been acknowledged and the others are still under review.
we will continue working with the developers to understand and fix the bugs.
.
.
bug characterization.
we present the characterization of the detected bugs.
correlation with function types.
we classified the bugs by the types of functions they reside in.
in particular based on the data type the functions operate on we categorized them into string processing functions array related functions arithmetic functions and others.
the breakdown statistics can be found in table .
we find models of certain types of functions are especially buggy.
for example models of string processing functions e.g.
table bug detection results of sediffafl sediffnfand xsym.
enginesediffafl sediffnf xsym tp fp tp fp tp fp angr navex kubo deadline total strip tags and array related functions e.g.
explode are the dominant buggy types compared to the other types.
.
and .
of bugs occur in these two types respectively.
causes of bugs.
the models did wrongly behave over certain inputs in our testing.
yet it is still hard to conclude the causes due to the nature of such correctness logic bugs.
unlike memorysafety bugs and crashes that have clear clues of misuses e.g.
useafter free vulnerabilities such correctness bugs are mainly related to program logic and we cannot confidently and objectively label particular code locations as incorrect i.e.
the root causes.
with the source code and manual investigation we currently could only conclude that bugs were caused by the functionality simplification that certain checks or conditions were intentionally discarded or ignored in the models.
this could also be confirmed in related descriptions in .
we will closely work with the developers to investigate the bugs.
.
ablation experiments and comparison we design experiments to understand how each technique in sediff contributed to the final bug detection results and compare it to the related work.
we include two sediff s variants together with a related work into controlled experiments sediffafl.
to understand the benefits of sediff s awareness of scope we replace sediff s fuzzing component with a vanilla afl into sediffafl which thus equally explores all code space.
sediffafl is customized to report any inconsistencies as bugs regardless in modeled or unmodeled functionalities.
sediffnf.sediffnfis a variant of sediff that uses only the basic model coverage feedback but not the feedback from the bug checker.
xsym.
we include the only relevant work xsym into our evaluation.
xsym employs a regression testing suite to test navex s internal function models.
65esec fse november singapore singapore penghui li wei meng and kangjie lu the differential fuzzing framework of sediff includes a greybox fuzzing component.
however besides sediffafl we do not construct variants with other grey box fuzzing components.
this is reasonable because sediff is a specially designed framework for differentially fuzzing internal function models whereas other fuzzers detecting corruptions etc.
are orthogonal in terms of targets.
besides some generic techniques proposed in other fuzzers are complimentary to sediff .
for example though not open sourced collafl s path sensitive approach to eliminating bitmap hash collision can be integrated to sediff and improve sediff from another angle.
we believe the controlled experiments by comparing sediff with sediffafl sediffnfand xsym are sufficient to demonstrate the efficacy of sediff .
we present the experiment results in table .
awareness of scope.
compared to sediff sediffafl is not scope aware.
after evaluating sediffaflwith the same resource budget sediffafl naively reported 309cases as bugs which include a large number of false positives.
to filter out them we first applied the tailored bug checker of sediff on the reports which excluded 285cases concerning unmodeled functionalities from the reported results.
we then manually investigated the rest cases and further removed false positives.
this demonstrates the necessity of our tailored bug checker in detecting bugs associated with only modeled functionalities.
in total sediffafl detected true positives in the models whereas sediff outperformed it with .
more bugs.
this is because sediffaflspent much effort on exploring unmodeled functionalities.
we further characterized the bugs reported by both and found that sediff successfully identified allbugs sediffafl reported.
the results demonstrate that sediff s awareness of scope significantly improves the testing performance.
feedback from bug checker.
we compare sediff tosediffnf to investigate the benefits of the feedback from the bug checker.
the results show that sediffnfdetected only bugs fewer than sediff in the modeled functionalities.
the explanation lies in that the test cases receiving positive feedback from the checker are prioritized for more mutations and testing.
some erroneous code locations contain more than one bug.
therefore by exploring more in that direction sediff can potentially detect more bugs.
comparison with regression testing.
since xsym does not support other engines we evaluated xsym on only navex s internal function models.
xsym identified true positive bugs out of reports spanning models.
note that xsym used a shorter cpu time to finish the tests.
the bugs were also successfully detected by sediff .
the inherent limitation of xsym in using only the existing regression test suite in a black box manner made it impractical to find bugs in the models.
we further analyzed the false reports of xsym.
these cases caused true program deviations however they concerned only unmodeled functionalities.
therefore we conclude that identifying modeled functionalities and the awareness of scope allowed sediff to detect more bugs in navex s models.
code coverage.
besides bug detection code coverage is another important measure of the effectiveness of fuzzing.
intuitively the more execution paths are covered the more thoroughly a target model is tested.
we interpret model coverage concerning the modeled functionalities instead of overall code coverage in original a angr time hours b navex time hours c kubo time hours d deadline time hours sediff sediff afl sediff nf figure model coverage percentage over time.
implementations because model coverage can better describe the exploration efficacy in the models.
each engine contains multiple models.
we calculate the average model coverage among all models for an engine.
we depict per engine the model coverage of sediff sediffaflandsediffnfover time during testing in figure .
we do not include xsym because its method does not employ fuzzing and it finishes testing much early.
it is not meaningful to depict its coverage time diagram.
from figure we find that sediff achieves higher model coverage than its variants in all engines.
at the end of the hour period sediff ultimately outperforms sediffaflby and for angr navex kubo and deadline respectively.
the improvements mainly come from generating in scope workloads.
besides sediff outperformed sediffnfin all engines regarding model coverage.
additionally figure shows the increasing trend of model coverage over time.
it suggests that all variants usually could find a lot of paths at the beginning and then get stuck at some time.
it also indicates that the model coverage in sediff constantly performed better than sediffaflandsediffnf.
summary.
our comparison and characterization demonstrate the benefits of the awareness of scope and bug checking feedback insediff .
the full fledged sediff thus could outperform its variants in both bug detection and code coverage.
in particular many bugs and paths would be missed without the awareness of scope.
the comparison with xsym further shows the high efficacy of our scope aware differential fuzzing approach in exercising the models.
discussion threat to validity.
sediff relies on the smt solver for the model extraction and testing.
our approach assumes the underlying smt solvers can perform correctly during symbolic execution.
we believe this is a valid assumption because the smt solvers have been thoroughly tested before releases and bugs in smt solvers can rarely be triggered.
in our experiments we do not observe any such cases.
however we admit that it is still possible that smt solvers do not behave correctly for example having soundness bugs .
66sediff scope aware differential fuzzing to test internal function models in symbolic execution esec fse november singapore singapore because of that the results reported by sediff could be unreliable.
to mitigate this problem one approach is to leverage multiple smt solvers for testing.
the final result would be more reliable if all solvers give consistent solutions for a case.
code availability of function implementations.
sediff currently requires the source code of original implementations for its semantic mapping and grey box fuzzing.
for the common usage of internal functions most of them can be found directly from public channels e.g.
official websites.
certain language systems do not publicize the internal functions in the form of source code but binary thus sediff currently is not capable to analyze them.
we believe the techniques in sediff are generic.
in the future we plan to extend sediff to handle such binary forms by utilizing advanced binary analysis techniques .
soundness and completeness.
sediff combines both static analysis and dynamic analysis.
it is neither sound nor complete by design.
on the one hand as mentioned earlier in .
the static analysis of sediff is not sound as it could report modeled functionalities incorrectly.
this is caused by its imprecision in reconstructing the data flow and the complicated parameter logic etc.on the other hand the differential testing part does not produce false positives however the fuzz testing nature means sediff is not complete and can miss bugs.
our primary goal in this work is to design an automated and scalable framework to test internal function models.
meanwhile achieving soundness or completeness is challenging.
we will explore this direction in the future.
portability.
a key contribution of sediff is applying differential testing selectively on part of the functionalities via path mapping.
it can be considered a generic mechanism to explore two different semantically equivalent implementations without domain specific knowledge about their internals.
although this work particularly studies the internal function models sediff is capable to test other function models as well e.g.
user defined functions if the data flow in them can be constructed and mapped.
besides sediff has huge potential for other application domains that have multiple implementations of common functionalities that comply with similar requirements or specifications.
for example database systems data parsers etc.
related work testing symbolic execution engines.
the correctness of symbolic execution is essential.
to date source code auditing is still the mainstream approach to testing symbolic execution engines.
there is only a little research on testing symbolic execution engines.
kapus and cadar proposed the first study testing symbolic execution engines through differential testing.
they checked the conformance of symbolic execution against concrete execution.
xsym used the existing php regression testing suite to test navex s internal function models.
to the best of our knowledge our work is the first study especially on testing internal function models in symbolic execution engines.
instead of blindly generating test cases our work takes advantage of grey box fuzzing to explore the input space assisted with new concepts of modeled functionalities new coverage guidance and a new bug checker.
rather than internal function models some work tested smt solvers to identify memory issuesand soundness bugs other relevant works revealed bugs in static analyzers model checker debugger etc.
differential testing.
in some cases it is difficult to define a testing oracle without prior knowledge of expected behaviors.
differential testing addresses this problem by checking the behavior conformance among similar implementations.
for example chen et al.employed differential fuzzing to find bugs across java virtual machines .
slutz proposed differential testing for database management systems .
chen et al.
used the asymmetric behaviors between testing programs to guide the fuzzer towards finding semantic bugs in ssl tls implementations .
our work uses the function behaviors on original implementations as the ground truth and differentially tests internal function models.
fuzz testing.
many researchers have paid great attention to coverage guided fuzzing to identify bugs.
it has been applied to many aspects such as kernel binary network protocols etc.for example collafl tortoisefuzz and muzz proposed new coverage metrics to guide the seed selection to achieve better code coverage.
static analysis is also useful in assisting fuzzing.
for example muzz used static analysis to extract suspicious interleaving operations for concurrency bug detection in multi threaded programs.
steelix and vuzzer analyzed magic values immediate values and strings that could affect control flow to help input mutation.
sediff first applies a static analysis to identify modeled functionalities.
based on the results sediff employs a new coverage metric to guide the exploration.
besides some techniques proposed in other fuzzers that generically improve fuzzing efficiency can complement sediff .
though orthogonal we plan to explore integrating them to sediff in the future.
conclusion symbolic execution is a foundational program analysis technique that typically models internal functions.
the correctness of internal function models is critical as it would affect the broad range of applications of symbolic execution.
in this paper we proposed new concepts of modeled functionalities and showed the importance of identifying them for bug detection.
we designed sediff a scope aware differential testing framework.
sediff employs new algorithms to automatically identify the modeled functionalities with the recovery of data flows in smt lib formulas.
after that sediff takes advantage of grey box fuzzing with a scope aware input generator and tailored bug checker to efficiently detect bugs.
in a thorough evaluation on several state of the art symbolic execution engines sediff was able to identify the modeled functionalities with high precision and found new bugs.
the evaluation results demonstrate that sediff is scalable and effective in finding bugs in internal function models in symbolic execution.