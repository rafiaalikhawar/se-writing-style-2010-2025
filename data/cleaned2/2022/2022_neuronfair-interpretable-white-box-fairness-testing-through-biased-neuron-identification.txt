neuronfair interpretable white box fairness testing through biased neuron identification haibin zheng zhejiang university of technology haibinzheng320 gmail.comzhiqing chen zhejiang university zqc zju.edu.cntianyu du zhejiang university zjradty zju.edu.cn xuhong zhang zhejiang university zhangxuhong zju.edu.cnyao cheng huawei international chengyao101 huawei.comshouling ji zhejiang university sji zju.edu.cn jingyi wang zhejiang university wangjyee zju.edu.cnyue yu national university of defense technology yuyue nudt.edu.cnjinyin chen zhejiang university of technology chenjinyin zjut.edu.cn abstract deep neural networks dnns have demonstrated their outperformance in various domains.
however it raises a social concern whether dnns can produce reliable and fair decisions especially when they are applied to sensitive domains involving valuable resource allocation such as education loan and employment.
it is crucial to conduct fairness testing before dnns are reliably deployed to such sensitive domains i.e.
generating as many instances as possible to uncover fairness violations.
however the existing testing methods are still limited from three aspects interpretability performance and generalizability.
to overcome the challenges we propose neuronfair a new dnn fairness testing framework that differs from previous work in several key aspects interpretable it quantitatively interprets dnns fairness violations for the biased decision effective it uses the interpretation results to guide the generation of more diverse instances in less time generic it can handle both structured and unstructured data.
extensive evaluations across datasets and the corresponding dnns demonstrate neuronfair s superior performance.
for instance on structured datasets it generates much more instances .
and saves more time with an average speedup of .
compared with the state of the art methods.
besides the instances of neuronfair can also be leveraged to improve the fairness of the biased dnns which helps build more fair and trustworthy deep learning systems.
the code of neuronfair is open sourced at .
ccs concepts computing methodologies artificial intelligence software and its engineering software reliability .
corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn .
.
.
.
interpretability fairness testing discriminatory instance deep learning biased neuron acm reference format haibin zheng zhiqing chen tianyu du xuhong zhang yao cheng shouling ji jingyi wang yue yu and jinyin chen.
.
neuronfair interpretable white box fairness testing through biased neuron identification.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction deep neural networks dnns have been increasingly adopted in many fields including computer vision natural language processing software engineering etc.
however one of the crucial factors hindering dnns from further serving applications with social impact is the unintended individual discrimination .
individual discrimination exists when a given instance different from another only in sensitive attributes e.g.
gender race etc.
but receives a different prediction outcome from a given dnn .
taking gender discrimination in salary prediction as an example for two identical instances except for the gender attribute male s annual income predicted by the dnn is often higher than female s .
thus it is of great importance for stakeholders to uncover fairness violations and then to reduce dnns discrimination so as to responsibly deploy fair and trustworthy deep learning systems in many sensitive scenarios .
much effort has been put into uncovering fairness violations .
the most common method is fairness testing which solves this problem by generating as many instances as possible.
initially fairness testing is designed to uncover and reduce the discrimination in traditional machine learning ml with low dimensional linear models.
however such methods are suffering from several problems.
first most of them e.g.
fairaware blackft and fliptest cannot handle dnns with high dimensional nonlinear structures.
then though some of them e.g.
themis symbgen and aequitas can be applied to test dnns they are still challenged by the high time cost and numerous duplicate instances.
recently several methods have been specifically developed for dnns such as adf and eidig etc.
these methods make progress in ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zheng et al.
effectiveness and efficiency through gradient guidance but they still suffer from the following problems.
first these methods can hardly be generalized to unstructured data.
as we know dnns are originally designed to process unstructured data e.g.
image text speech etc.
but most existing fairness testing methods cannot be applied to these data.
it is mainly because these methods cannot determine which features are related to sensitive attributes and cannot implement appropriate modifications to these features e.g.
how to determine pixels related to gender attribute in face images and how to modify these pixel values to change gender .
however even a seemingly simple task such as face detection is subject to extreme amounts of fairness violations.
it is especially concerning since these facial systems are often not deployed in isolation but rather as part of the surveillance or criminal detection pipeline .
therefore these testing methods still cannot serve dnns widely until we solve the problem of data generalization.
second the generation effectiveness of these methods is challenged by gradient vanishing.
they leverage the gradient guided strategy to improve generation efficiency but the gradient may vanish and cause instance generation to fail.
additionally when the gradient is small the generated instances are highly similar.
however the purpose of fairness testing is to generate not only the numerous instances but also the diverse instances.
third almost all existing methods hardly provide interpretability.
they only focus on generating numerous instances but cannot interpret how the biased decisions occurred.
dnns decision results are determined by neuron activation then we try to study these neurons that cause biased decisions.
we find that the instances generated by existing testing methods will miss the coverage of these neurons that cause biased decisions refer to the experiment result in fig.
.
more seriously we cannot even know which neurons related to biased decisions have been missed for testing when there is a lack of interpretability.
therefore we need an interpretable testing method so as to interpret dnns biased decisions and evaluate instances utility for uncovering fairness violations.
based on these the interpretation results can guide us to design effective testing to uncover more discrimination.
in summary the current fairness testing challenges lie in the lack of data generalization generation effectiveness and discrimination interpretation.
to overcome the above challenges our design goals are as follows we intend to uncover and quantitatively interpret dnns discrimination then we plan to apply this interpretation results to guide fairness testing furthermore we want to generalize our testing method to unstructured data.
due to the decision results of dnns are determined by the nonlinear combination of each neuron s activation state thus we imagine whether the biased decisions are caused by some neurons.
then we try to observe the neuron activation state in dnns hidden layers through feeding instance pair which is two identical instances except for the sensitive attribute.
surprisingly we find that the activation state follows such a pattern i.e.
neurons with drastically varying activation values are overlapping for different instance pairs.
we observe that dnns discrimination is reduced when these overlapped neurons are zeroed out.
therefore we speculate that these neurons causethe dnns discrimination.
then we intend to quantitatively interpret dnns discrimination by computing the neuron activation difference actdiff values.
according to the interpretation results we further design a testing method neuronfair to optimize gradient guidance.
first we determine the main neurons that cause discrimination called biased neurons.
then we search for discriminatory instances with the optimization object of increasing the actdiff values of biased neurons.
because the optimization from the biased neuron shortens the derivation path it reduces the probability of the gradient vanishing and time cost.
moreover we can produce more diverse instances through the dynamic combination of biased neurons.
all in all we leverage the interpretation results to optimize gradient guidance which is beneficial to the generation effectiveness.
we leverage adversarial attacks to determine which features are related to sensitive attributes and make appropriate modifications to these features.
the adversarial attack is originally to test the dnns security e.g.
slight modifications to some image pixels will cause the predicted label to flip .
taking the gender attribute of face image as an example we consider training a classifier with male and female as labels then adding the perturbation to the face image until its predicted gender label flips.
based on this generalization framework we can modify the sensitive attributes of any data thereby generalizing neuronfair to any data type.
in summary we first implement to quantitatively interpret the discrimination using neuron based analysis then we leverage the interpretation results to optimize the instance generation finally we design a generalization framework for sensitive attribute modification.
the main contributions are as follows.
through the neuron activation analysis we quantitatively interpret dnns discrimination which provides a new perspective for measuring discrimination and guides dnns fairness testing.
based on the interpretation results we design a novel method for dnns discriminatory instance generation neuronfair which significantly outperforms previous works in terms of effectiveness.
inspired by adversarial attacks we design a generalization framework to modify sensitive attributes of unstructured data which generalizes neuronfair to unstructured data.
we publish our neuronfair as a self contained open source toolkit online.
background to better understand the problem we are tackling and the methodology we propose in later sections we first introduce dnn data form individual discrimination and our problem definition.
dnn .
a dnn can be represented as f x x y including an input layer several hidden layers and an output layer .
two popular architectures of dnns are fully connected network fcn and convolutional neural network cnn .
for a fcn we denote the activation output of each neuron in the hidden layer as fk l x where is the weights l ... nl nlis the number of neural layers k ... nk l nk lis the number of neurons in thel th layer.
for a cnn we flatten the output of the convolutional layer for the calculation of neuron activation.
the loss function of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
neuronfair interpretable white box fairness testing through biased neuron identification icse may pittsburgh pa usa figure illustration of discriminatory instance generation on adult dataset .
i the discriminatory instance generation process.
the normal instance pair is x x and the discriminatory instance pair is xd x d .x x senatt xd x bias x d x senatt bias where biasis the bias perturbation senatt is the perturbation added to the gender attribute to flip gender.
ii discrimination exists when the instance s predicted label changes as the gender attribute is flipped i.e.
the instance crosses the decision boundary.
dnns is defined as follows j x y nh n i 0 m j yi j log yi j i wherenis the number of instances mis the number of classes yi is the ground truth of xi yi f xi is the predicted probability log is a logarithmic function.
data form .
denotex xi y yi as a normal dataset and its instance pairs by x x xi x i i ... n .
for an instance we denote its attributes by a ai i ... na whereas ais a set of sensitive attributes and ans ans i ans i a andans i as is a set of non sensitive attributes.
note that sensitive attributes e.g.
gender race age etc.
are usually given in advance according to specific sensitive scenes.
individual discrimination .
as stated in previous work individual discrimination exists when two valid inputs which differ only in the sensitive attributes but receive a different prediction result from a given dnn as shown in fig.
.
such two valid inputs are called individual discriminatory instances idis .
definition idi determination.
we denote xd x d xd i x d i as a set of idi pairs which satisfies f xd i f x d i s.t.xd i x d i xd i x d i wherei ... nd xd i represents the value of xd i with respect to attribute as.
note that our instances are generative e.g.
maybe the age of a generated instance is years old on adult dataset thus we need to clip their attribute values that do not exist in the input domain i. neuronfair an overview of neuronfair is presented in fig.
.
neuronfair has two parts i.e.
discrimination interpretation and idi generation based on interpretation results.
during the discrimination interpretation we first interpret why discrimination exists through neuronbased analysis.
then we design a discrimination metric based on the interpretation result i.e.
auc value as shown in fig.
i .
auc is the area under as curve where the as curve records the percentage of neurons above the actdiff threshold.
finally we leverage the as curve to adaptively identify biased neurons which serves for figure an overview of neuronfair.
idi generation.
during the idi generation we employ the biased neurons to perform global and local generations.
the global phase guarantees the diversity of the generated instances and the local phase guarantees the quantity as shown in fig.
ii .
on the one hand the global generation uses the normal instance as a seed and stops if an idi is generated or it times out.
on the other hand the generated idis are adopted as seeds of local generation leading to generate as many idis as possible near the seeds.
besides we implement dynamic combinations of biased neurons to increase diversity and use the momentum strategy to accelerate idi generation.
in the following we first quantitatively interpret dnns discrimination then present details of idi generation based on interpretation results and finally generalize neuronfair to unstructured data.
.
quantitative discrimination interpretation first we draw as curve and compute auc value to measure dnns discrimination.
then based on the measurement results we identify the key neurons that cause unfair decisions as biased neurons.
.
.
discrimination measurement.
the actdiff is calculated as follows zk l n n i abs fk l xi fk l x i wherezk lis the actdiff of the k th neuron in the l th layer l ... nl nlis the layer number nis the number of normal instance pairs x x xi x i i ... n abs returns an absolute value fk l x returns the activation output of thek th neuron in the l th layer represents the model weights.
based on eq.
we plot as curve and compute auc value.
we first compute each neuron s actdiff and normalize it by hyperbolic tangent function tanh as shown in fig.
i .
l1 means the st hidden layer of a dnn with neurons.
then we set several actdiff thresholds at equal intervals count the neuron percentages above the actdiff thresholds and record them as sensitive neuron rate senneur .
finally we plot as curve according to the senneur under different actdiff thresholds and then compute the area under as curve as auc value as shown in fig.
ii where the x axis is the actdiff value normalized by tanh function the y axis is senneur.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zheng et al.
figure illustration of the neuron based discrimination interpretation.
dataset adult dimension fcn based dnn structure .
algorithm as curve drawing and auc calculation.
input the activation output fk l x actdiff threshold intervalstep interval .
instance pairs x x .
output as curve and auc value of each layer.
calculate the average actdiff of each neuron zk l n n i abs fk l xi fk l x i 2forl nl 3zl tanh zl 4max z max zl 5xtmp step interval max z 6ytmp forcount length xtmp 8ytmp end for 10ytmp ytmp length zl 11area count ytmp step interval plot the as curve based on xtmp ytmp .
savearea as the auc of the l th layer.
13end for repeat such an operation for each layer we can intuitively observe the discrimination in each layer and find the most biased layer with the largest auc value.
as shown in fig.
i the nd layer l2 is selected as the most biased layer with auc .
.
more specific operations on as curve drawing and auc calculation are shown in algorithm .
first we compute the average actdiff values of each neuron zk lat line .
in the loop from lines to for each neural layer we get senneur for plotting the as curve.
then we compute auc value by integration at line .
.
.
biased neuron identification.
the most biased layer is selected for adaptive biased neuron identification.
a neuron with a largezk lvalue demonstrates that it responds violently to the modification of sensitive attributes thus it carries more discrimination.
we define biased neuron as follows.
definition biased neuron.
for a given discrimination threshold tdof the most biased layer the biased neurons satisfy the condition zk td.zkis the average actdiff normalized by tanh of the k th neuron in the most biased layer k ... nk td .
based on the definition we know that once tdis determined biased neurons can be found.
here we give a strategy for adaptively determining td.
we draw a line y xthat intersects the as curve.
the x axis s value of this intersection is td.
as shown in fig.
ii the intersection is the point .
.
and td .
after determining td we record these biased neurons and save theiralgorithm global generation guided by biased neurons.
input normal instance x xi initial set g xc kmeans x nc c ... nc the number of seeds for global generation numg the maximum number of iterations for each seed max iterg the perturbation size of each iteration step sizeg the decay rate of momentum g the step size for random disturbance r stepg.
output a set of idi pairs found globally g. 1fori int numg nc forc nc select seed xfromxc g0 g .
fort max iterg if mod step sizeg r stepg then r rand pr end if create x x s.t.x x x x .
if f x f x then g g x x break end if gt g gt xjdl x g t g g t x jdl x dire sign gt g t dire x x dire step sizeg x clip x i end for end for 21end for positionp wherepis a vector with nkelements.
the strategy works well in practice as the discrimination is often concentrated on a few certain neurons rendering a normal distribution of the actdiff s frequency map.
.
interpretation based idi generation neuronfair generates idis in two phases i.e.
a global generation phase and a local generation phase.
the global phase aims to acquire diverse idis.
the idis diversity in the global phase is crucial since these instances serve as seeds for the local phase.
instead to guarantee the idis quantity the local phase aims to search for as many idis as possible near the seeds.
.
.
global generation.
to increase the idis diversity we design a dynamic loss as follows jdl x nn 1 i 0nk k pk rk fk x i log fk xi wherex icomes from xiafter flipping its sensitive attribute nkis the number of neurons in the most biased layer fkis the activation output of the k th neuron.pis the position of biased neurons ris the position of randomly selected neurons to increase the dynamics of jdl x .r rand pr whererand pr returns a random vector with only or .
rhas the same size as pand satisfies r int nk pr where int returns an integer.
here we set pr .
means or pk rk 0if and onlypk 0andrk .
the optimization object of idi generation is arg maxjdl x .
algorithm shows the details of global generation with momentum acceleration.
we first adopt k means clustering function kmeans x nc to process xintoncclusters and then get seeds from clusters in a round robin fashion at line .
we update random authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
neuronfair interpretable white box fairness testing through biased neuron identification icse may pittsburgh pa usa algorithm local generation guided by biased neurons.
input idi pairs g xd i x d i i ... ng initial set l the maximum number of iterations for each seed max iterl the perturbation size of each iterationstep sizel the decay rate of momentum l step size for random disturbance r stepl.
output a set of idi pairs found locally l. 1fori ng select seed x x from g g0 g .
fort max iterl if mod step sizel r stepl then r rand pr end if 7gt l gt xjdl x 8g t l g t x jdl x 9dire sign gt g t 10pdire softmax gt g t forans ans generate a random number ptmp .
if ptmp pdire then x x dire step sizel end if end for 17x clip x i create x x s.t.x x x x .
if f x f x then l l x x end if end for 23end for vectorrat equal intervals from lines to not only to increase the dynamics but also to avoid excessively disturbing the generation task.
according to definition we determine the idis from lines to .
we employ the momentum acceleration operation at lines and which can effectively use historical gradient and reduce invalid searches.
note that we keep the value of the sensitive attribute inxat line .
finally we clip the value of xto satisfy the input domain i. .
.
local generation.
since the local generation aims to find as many idis as possible near the seeds we increase the iteration number of each seed max iterl and reduce the bias perturbation added in each iteration as shown in algorithm .
compared to the global phase the major difference is the loop from lines to where we add perturbation to the non sensitive attributes of large gradients with a small probability.
we automatically get the probability of adding perturbation to each attribute in xat line .
.
generalization framework on unstructured data we intend to solve the challenge of asmodification to generalize neuronfair to unstructured data.
here we take image data as an example.
attributes of an image are determined by pixels with normalized values between and i.e.
the input domain of images isi .
motivated by the adversarial attack we design a generalization framework to implement the image s asmodification which modifies asthrough adding a small perturbation to most pixels as shown in fig.
.
figure an overview of generalization framework on image data type.
we consider a fairness testing scenario for face detection which determines whether the input image contains a face.
the face detector consists of a cnn module i.e.
fig.
i and a fcn module i.e.
fig.
ii .
as shown in fig.
for a given face image xand a detectorf x there are three steps build a sensitive attribute classifier produce senatt based on eq.
senatt is the perturbation added to image to flip sensitive attribute generate bias based on neuronfair where biasis the bias perturbation added to an image to flip the detection result.
first we need a sensitive attribute classifier fsa x sa that can distinguish the face image s as e.g.
gender .
we build the as classifier by adding a new fcn module i.e.
fig.
iii to the face detector s cnn module i.e.
fig.
i .
then we froze the weights of the cnn module and train the weights of the newly added fcn module.
next we modify the face image s asbased on the adversarial attack.
a classic adversarial attack fgsm is adopted to flip the predicted result of the sensitive attribute by generating senatt as follows senatt sign xj x ysa sa satisfying that fsa x sa fsa x senatt sa where is a hyper parameter to determine perturbation size sign is a signum function return or xis an input image ysais the ground truth of xabout sensitive attributes sais the weights of the asclassifier.
finally we leverage neuronfair to generate bias and then determine whether the instance pair x bias x bias senatt satisfy definition .
we determine the discrimination at each layer of the detector at first.
for the cnn module the activation output of the convolutional layer is flattened.
then in the process of image idi generation only the global generation is employed which is due to the different data forms between image and structured data.
taking the input image in fig.
as an example its attributes can be regarded as a r64 .
based on a seed image idi generated in the global phase numerous image idis will evolve in the local phase.
however these image idis are similar with only a few pixel differences which have little effect on fairness improvement of the face detector.
besides we cancel the signum function sign at line of algorithm for image data.
for other unstructured data e.g.
text we could first process it into a vector structure similar to an image through standard embedding techniques e.g.
word embedding then apply the framework authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zheng et al.
in fig.
in a similar way.
to ensure the generated inputs are realistic we follow previous works e.g.
adf and eidig to limit the range of perturbed features for structured data e.g.
maximum age limit and the maximum perturbation size for unstructured data e.g.
human imperceptible perturbation .
distance evaluation results show that the distances between the generated inputs and the seed inputs are relatively small which means the generated inputs are not overtly surprising in comparison to the training data.
experimental setting .
datasets we evaluate neuronfair on datasets of which five are structured datasets and two are image datasets.
each dataset is divided into three parts i.e.
as training validation and testing respectively.
the open source structured datasets include adult german credit gercre bank marketing banmar compas and medical expenditure panel survey meps .
the details of these datasets are shown in table .
all datasets can be downloaded from github1 and preprocessed by ai fairness toolkit aif360 .
the image datasets i.e.
clba in and lfw in are constructed by ourselves for face detection.
clba in dataset consists of face images from celeba and non face images from imagenet .
lfw in dataset consists of face images from lfw and non face images from imagenet .
the pixel value of each image is normalized to .
.
classifiers we implement fcn based classifiers for structured datasets and cnn based face detectors for image datasets since fcn and cnn are the most widely used basic structures in realworld classification tasks.
the fcn based classifiers can be divided into two types.
the one is composed of hidden layers for processing low dimensional data i.e.
adult gercre banmar denoted as lfcn.
the another is composed of hidden layers for processing high dimensional data i.e.
compas and meps denoted as hfcn.
the activation functions in hidden layers and the output layer are relu and softmax respectively.
the hidden layer structures of lfcn and hfcn are and respectively.
the cnn based face detectors serve for face detection which are variants from two pre trained models i.e.
vgg16 and resnet50 of keras.applications.
we use the cnn module of vgg16 and resnet50 as fig.
i and design the fcn module of fig.
ii and iii as .
.
baselines we implement and compare state of the art sota methods with neuronfair to evaluate their performance including aequitas symbgen adf and eidig .
note that themis has been shown to be significantly less effective for dnn and thus is omitted .
we obtained the implementation of these baselines details of the datasets.
datasets scenarios sensitive attributes records dimensions adult census income gender race age gercre credit gender age banmar credit age compas law race meps medical care gender clba in face detection gender race lfw in face detection gender race from github2 .
all baselines are configured according to the best performance setting reported in the respective papers.
.
evaluation metrics five aspects of neuronfair are evaluated including generation effectiveness efficiency interpretability the utility of auc metric andgeneralization of neuronfair.
.
.
generation effectiveness evaluation.
we evaluate the effectiveness of neuronfair on structured data from two aspects generation quantity and quality.
quantity .
to evaluate the generation quantity we first count the total number of idis then count the global idis number and local idis number respectively recorded as idis .
note that the duplicate instances are filtered.
quality .
we use generation success rate gsr generation diversity gd and idis contributions to fairness improvement i.e.
dm rs to evaluate idis quality.
gsr idis non duplicate instances where non duplicate instances represent the input space.
gdnf cons baseline crnf bl crbl nf where crnf bl idis of baselines fall in nf idis of baselinerepresents the coverage rate of the neuronfair s idis to baseline s idis nfis the area with neuronfair s idis as the center and cosine distance consas the radius similar to crbl nf idis of neuronfair fall in bl idis of neuronfair.
the neuronfair s idis are more diverse when gdnf .
the generated idis serve to improve dnn s fairness by using these idis to retrain it.
dm rs is the percentage of idis in randomly sampled instances.
high dm rs value represents that the dnn is biased i.e.
the idi s contribution to fairness improvement is low.
dm rs idis instances randomly sampled .
.
efficiency evaluation.
we evaluate the efficiency of neuronfair by generation speed i.e.
the time cost of generating idis sec idis .
.
.
interpretability evaluation based on biased neurons.
to interpret the utility of neuronfair we refer to paper to design the coverage of biased neurons which is defined as follows for a given instance compute the activation output of the most biased layer normalize the activation values select neurons with activation values greater than .
as the activated neurons compare the coverage of the activated neurons to the biased neurons.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
neuronfair interpretable white box fairness testing through biased neuron identification icse may pittsburgh pa usa table parameter setting of experiments.
no.
parameters values glo.
loc.
descriptions 1nc the number of clusters for global generation 2numg the number of seeds for global generation 3max iter the maximum number of iterations for each seed 4step size .
.
the perturbation size of each iteration 5 .
.
the decay rate of momentum .
.
6r step the step size for random disturbance r step table the accuracy of classifiers and face detectors.
datasets adult gercre banmar compas meps clba in lfw in classifiers lfc a lfc g lfc b hfc c hfc m vgg16 resnet50 accuracy .
.
.
.
.
.
.
.
.
.
.
.
.
utility evaluation of auc metric.
in our work based on the interpretation results we design auc value to measure the discrimination.
we evaluate the utility of auc metrics from three aspects consistency significance and complexity between auc and dm rs.
consistency .
to evaluate the consistency we adopt spearman s correlation coefficient as follows s 6 n i 1d2 i n n2 wheredi ai bi i ... n aiandbiare the rank of auc and dm rs values respectively.
high smeans more consistent.
significance .
to evaluate whether auc can measure discrimination more significantly than dm rs we use the standard deviation as follows r i 1n ci n whereciis auc or dm rs of different testing methods i ... n is the mean value of ci.
large means more significant.
.
.
generalization evaluation on image data.
we evaluate the generalization of neuronfair on image data from two aspects generation quantity and quality.
quantity .
to evaluate the generation quantity on image data we only count the global image idis number recorded as idis .
quality .
we adopt gsr and idis contributions to face detector s fairness improvement based on auc value to evaluate idis quality then compute its detection rate dr after retraining.
.
implementation details to fairly study the performance of the baselines and neuronfair our experiments have the following settings the hyperparameters of each method are set according to table where glo.
and loc.
represent the global and local phases respectively the experimental results are repeated times and then averaged for the fcn based classifier we set the learning rate to .
and choose adam as the optimizer for the cnn based face detector we set the learning rate to .
and choose sgd as the optimizer the training results are shown in table where .
.
.
represents the accuracy of face detector gender classifier and race classifier respectively.
we conduct all the experiments on a server with one intel i77700k cpu running at .20ghz gb ddr4 memory tb hdd and one titan xp gb gpu card.table comparison with aequitas adf and eidig based on the total number of generated idis.
datasetssen.
att.ae quitas adf eidig neuronfair idis gsr idis gsr idis gsr idis gsr adultgender .
.
.
.
race .
.
.
.
age .
.
.
.
gercr egender .
.
.
.
age .
.
.
.
banmar age .
.
.
.
comp as race .
.
.
.
meps gender .
.
.
.
experimental results we evaluate neuronfair through answering the following five research questions rq how effective is neuronfair how efficient is neuronfair how to interpret the utility of neuronfair how useful is the auc metric how generic is neuronfair?
.
research questions how effective is neuronfair in generating idis?
when reporting the results we focus on the following aspects generation quantity andquality.
generation quantity .
the evaluation results are shown in tables and including three scenarios the total number of idis the idis number in global phase and the idis number in local phase.
implementation details for quantity evaluation symbgen works differently from other baselines thus we follow the comparison strategy of zhang et al.
i.e.
evaluating the generation quantity of neuronfair and symbgen within the same time i.e.
sec limit as shown in table for a fair global phase comparison we generate non duplicate instances without constrained bynumg then count idis number and record it in table where the seeds used are consistent for different methods for a fair local phase comparison we mix idis generated globally by different methods and randomly sample as the seeds in local phase then generate non duplicate instances for each seed without constrained by max iterl count the idis number on average for each seed and record it in table .
neuronfair generates more idis than baselines especially for densely coded structured data.
for instance in table on adult dataset with different attributes the idis number of neuronfair is on average which is .
times and .
times that of aequitas and eidig respectively.
in addition in table neuronfair generates much more idis than symbgen on all datasets.
the outstanding performance of neuronfair is mainly because the optimization object of neuronfair takes into account the whole dnns discrimination information through the biased neurons while aequitas and eidig only depend on the output layer.
however the idis number on compas dataset with race attribute is which is slightly lower than that of eidig.
since the compas is encoded as one hot in aif360 we speculate the reason is that too sparse data coding reduces the derivation efficiency from biased neurons.
as shown in table neuronfair generates much more idis than all baselines in the global phase which is beneficial to increase the diversity of neuronfair s idis in the subsequent local phase.
for instance on all datasets the idis number of neuronfair is authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zheng et al.
table comparison with symbgen based on the number of idis generated in seconds.
datasets sen. att.symbgen neuronfair idis gsr idis gsr adultgender .
.
race .
.
age .
.
gercr egender .
.
age .
.
banmar age .
.
comp as race .
.
meps gender .
.
table idis measurement in the global and local phases.
datasetssen.
att.global p hase local phase ae qui tassymb genadf eidigneuron fairae qui tassymb genadf eidigneuron fair adultgender race age gercr egender age banmar age comp as race meps gender on average which is .
times and .
times that of aequitas and eidig respectively.
this is mainly because the optimization object of neuronfair takes into account the dynamics through the dynamic combination of biased neurons.
thus neuronfair searches a larger space to generate more global idis.
besides we conduct a preliminary t test about idis on the adult and gercre datasets.
the p values of all models are small enough to reject the null hypothesis i.e.
less than .
which demonstrates the significance of neuronfair.
in the local phase neuronfair is much more efficient than baselines in general.
for instance in table on average neuronfair returns .
.
.
and .
more idis than aequitas symbgen adf and eidig respectively.
recall that aequitas adf eidig and neuronfair all guide local phase through a probability distribution which is the likelihood of idis by modifying several certain attributes i.e.
the loop from lines to ofalgorithm .
the probability determination of neuronfair takes into account the momentum and softmax activation i.e.
at line of algorithm while the baselines do not.
hence neuronfair generates more local idis.
generation quality .
the evaluation results are shown in tables and fig.
including the generation success rate gsr generation diversity gd and fairness improvement dm rs .
implementation details for quality evaluation for a fair diversity comparison we seed each method with the same set of global idis and apply them to generate local idis for each seed without considering max iterl as shown in fig.
we randomly select idis of each method to retrain dnns then compute their fairness improvement results to avoid contingency we repeat times and record the average dm rs value in table .
as shown in tables and the gsr values of neuronfair are higher than that of baselines on almost all datasets i.e.
neuronfair can search for a larger valid input space where the input space is calculated by idis gsr .
for instance in table on all datasets aequitas has a gsr of .
on average whereas neuronfair achieves a gsr of .
which is .
more than that of aequitas.
the outstanding performance of neuronfair istable fairness improvement measured by dm rs where before and after represent the original and the retrained dnns respectively.
datasetssen.
att.befor eafter ae qui tassymb genadf eidigneuron fair adultgender .
.
.
.
.
.
race .
.
.
.
.
.
age .
.
.
.
.
.
gercr egender .
.
.
.
.
.
age .
.
.
.
.
.
banmar age .
.
.
.
.
.
comp as race .
.
.
.
.
.
meps gender .
.
.
.
.
.
a comparison with aequitas b comparison with adf figure generation diversity of neuronfair compared to aequitas left and adf right .
mainly because it not only considers the whole dnn s discrimination through biased neurons but also takes into account the dynamics of the optimization object through the combination of biased neurons.
thus neuronfair searches a larger valid input space than aequitas.
meanwhile the gsr value of neuronfair on different sensitive attributes is more robust than adf and eidig.
for instance in table on the gercre dataset with gender and age attributes the gsr values of neuronfair are .
and .
whereas that of eidig are .
and .
.
we speculate the reason is that the discrimination about the gender attribute in the output layer is not obvious but neuronfair can find potential fairness violations through the internal discrimination information of biased neurons.
therefore we can realize stable testing for different sensitive attributes.
in addition the valid input space of neuronfair is larger than baselines in general i.e.
a larger input space supports more diverse idi generation.
for instance in table the average input space of neuronfair is .
times that of symbgen.
it is mainly because the momentum acceleration strategy employs historical gradient as auxiliary guidance which reduces the number of invalid searches.
hence neuronfair generates more idis in a large input space.
in all cases neuronfair can generate more diverse idis which is beneficial to discover more potential discrimination and then improve fairness through retraining.
for instance in fig.
compare to aequitas and adf the gdnfvalues are all greater than under different radius values cons and as the radius increases the value of gdnfgradually converges to .
it demonstrates that the idis generated by neuronfair can always cover that of baselines.
we speculate the reason is that the dynamic loss authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
neuronfair interpretable white box fairness testing through biased neuron identification icse may pittsburgh pa usa table time sec taken to generate idis.
datasetssen.
att.ae qui tassymb genadf eidigneuron fair adultgender .
.
.
.
.
race .
.
.
.
.
age .
.
.
.
.
gercr egender .
.
.
.
.
age .
.
.
.
.
banmar age .
.
.
.
.
comp as race .
.
.
.
.
meps gender .
.
.
.
.
function expands the valid input space by combining different biased neurons as the optimization object.
besides a close investigation shows that there is a similar trend in the generation diversity for the same sensitive attribute.
for instance when cons .
in fig.
a or cons .
in fig.
b the line l2 with race is always the highest the line l4 with age is always the lowest while lines l1 and l3 with gender are in the middle.
since both datasets adult and gercre are related to money i.e.
salary and loans we speculate that there is similar discrimination for gender in classifiers lfc a and lfc g for similar tasks thus gdnfshows similar trends in gender attribute.
in all cases neuronfair can obtain smaller dm rs values i.e.
the idis generated by neuronfair contribute more to the dnns fairness improvement.
for instance in table measured by dm rs neuronfair realizes fairness improvement of .
on average versus baselines i.e.
.
for aequitas .
for symbgen .
for adf and .
for eidig.
it is because the idis of neuronfair are more diverse than those of baselines so it can discover more potential fairness violations and implement higher fairness improvement through retraining.
answer to rq1 neuronfair outperforms the sota methods i.e.
aequitas symbgen adf and eidig in two aspects quantity it generates .
idis on average compared to baselines quality it searches .
input space with more than .
gsr on average compared to baselines it generates idis that are .
and .
more diverse than aequitas and adf on average with cons .
it is beneficial to dnns fairness improvement of .
on average.
.
research questions how efficient is neuronfair in generating idis?
when answering this question we refer to the generation speed.
the evaluation results are shown in table where the time cost of symbgen includes generating the explainer and constraint solving.
here we have the following observation.
neuronfair generates idis more efficiently which meets the rapidity requirements of software engineering testing.
for instance in table on average neuronfair takes only .
.
.
and .
of the time required by aequitas symbgen adf and eidig respectively.
the outstanding performance of neuronfair is mainly because it uses a momentum acceleration strategy and shortens the derivation path to reduce computational complexity.
hence it takes less time than baselines.
a activated neurons by idis b activated neurons by non idis figure the overlap of biased neurons and neurons activated by different instances.
answer to rq2 neuronfair is more efficient in generation speed it produces idis with an average speedup of .
.
.
research questions how to interpret neuronfair s utility by biased neurons?
when interpreting the utility we refer to the biased neuron coverage.
the evaluation results are shown in fig.
.
implementation details for interpretation we conduct experiments on the adult dataset with gender attribute for the lfc a classifier we compare the interpretation results of neuronfair with adf and eidig for a fair interpretation we randomly select idis and non idis i.e.
the generated failure instances for each method and then compute the coverage of biased neurons as shown in fig.
.
biased neurons can be adopted to interpret the utility of idis and neuronfair.
first idis trigger discrimination by activating biased neurons.
for instance the neurons activated by idis can cover most of the biased neurons in fig.
a while the coverage of the biased neurons by non idis of different methods is in fig.
b .
we can further interpret the utility of testing methods is related to the coverage of biased neurons i.e.
neuronfair is more effective than adf and eidig because they miss some discrimination contained in biased neurons while neuronfair does not.
for instance in fig.
a the neuronfair s idis activate all biased neurons in the nd layer of lfc a classifier while the neurons activated by other idis cannot cover all for adf and for eidig .
answer to rq3 the main reason for neuronfair s utility is that its idis can activate more biased neurons.
neuronfair s idis activate biased neurons while .
for adf and for eidig.
.
research questions how useful is the auc metric for measuring dnns fairness?
when answering this question we refer to the following aspects the consistency significance and complexity between auc and dm rs.
the evaluation results on adult and gercre datasets with multiple sensitive attributes are shown in table .
from the results we have the following observations.
in all cases auc can correctly distinguish dnns fairness violations i.e.
auc can serve the discrimination measurement of dnn.
for instance in table all of the svalues are .
indicating that the discrimination ranking results of different dnns authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zheng et al.
table the consistency and significance between dm rs and auc s .
note that here we only use normal instance pairs to compute each layer s auc and select the maximum auc as the classifier s discrimination.
datasetssen.
att.metrics befor eafter s ae qui tassymb genadf eidigneuron fair adultgenderdm rs .
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
racedm rs .
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
agedm rs .
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
gercr egenderdm rs .
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
agedm rs .
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
table idis and gsr measurements in the global phase on image datasets.
datasets sen. att.adf eidig neuronfair idis gsr idis gsr idis gsr clba ingender .
.
.
race .
.
.
lfw ingender .
.
.
race .
.
.
based on auc are completely consistent with those based on dmrs.
since dnn s decision results are determined by the neurons activation we speculate that the biased decisions are also caused by the neurons activation i.e.
neurons contain discrimination information.
therefore we can leverage the discrimination information in neurons to determine dnns fairness.
in all cases auc can distinguish the different dnn s discrimination more significantly than dm rs which is beneficial for a more accurate evaluation of idis of different testing methods.
for instance in table all values of auc are higher than those of dm rs and the average value of auc is .
times that of dm rs.
the outstanding performance of auc is mainly because we use the neurons actdiff to measure the discrimination which extracts more bias related information from the whole dnn while dm rs only uses the bias related information from the output layer.
the computational complexity of auc is much lower than that of dm rs which is beneficial to quickly distinguish dnns discrimination or the idis effect.
the time frequency of auc is t nl count nl 1based on algorithm .
thus the time complexity of auc is o nl while that of dm rs is o nlogn wherenis the instance number nlis the layer number n nl.
it is mainly because auc only conducts matrix operations while dm rs requires iterative operations until convergence.
answer to rq4 the auc is useful for discrimination measurement.
compared to the results in table auc is consistentwith dm rs .
more significant than dm rs low computational complexity witho nl .
.
research questions how generic is neuronfair for the task of image idi generation?
when reporting the results we focus on two aspects generation quantity andquality.table fairness improvement of face detectors.
datasetssen.
att.befor eafter adf eidig neuronfair auc dr auc dr auc dr auc dr clba ingender .
.
.
.
.
.
.
.
race .
.
.
.
.
.
.
lfw ingender .
.
.
.
.
.
.
.
race .
.
.
.
.
.
.
implementation details for neuronfair generalized on image data we only perform comparisons with adf and eidig at global phase because the effect of adf and eidig on dnns is much better than that of aequitas and symbgen we remove the kmeans operation set step sizeg .
for image and all face images are used as input we retrain the face detector with all image idis of each method and measure its fairness improvement by auc we measure the bias perturbation biasand sensitive attribute perturbation senatt byl2 norm.
generation quantity .
the evaluation results are shown in table measured by the idis number in global phase.
from the results we have the following observation.
in all cases neuronfair can obtain more idis than adf and eidig especially for the discrimination against race attribute.
for instance in table on average neuronfair generates .
times and .
times idis of adf and eidig respectively.
the outstanding performance of neuronfair is because it adopts dynamic loss to expand the valid input space while adf and eidig do not consider the dynamics of search.
meanwhile the number of idis generated by neuronfair for race is .
times that for gender.
we speculate the reason is that the pixel information related to race is mainly skin color i.e.
light dark or black white while the pixel information related to gender is more diverse such as hair makeup face shape etc.
.
therefore the image idis generation for race is easier through manipulating skin color.
generation quality .
the evaluation results are shown in tables and including three scenarios the generation success rate gsr the fairness improvement auc and the detection rate dr .
among image data image idis of neuronfair are of higher quality than those of adf and eidig which can be applied to retrain face detectors and contribute to their fairness improvement in face detection scenarios.
for instance in table on average the gsr value of neuronfair is .
times and .
times that of adf and eidig respectively.
it is because neuronfair reduces the probability of gradient vanishing which in turn improves the probability of non duplicate idis generation guided by the gradient.
hence all gsr values of neuronfair are higher than those of baselines.
meanwhile the valid input space of neuronfair is .
times and .
times that of adf and eidig respectively.
since the probability of falling into a local optimum is reduced by dynamically combining biased neurons we can perform valid searches in limited instance space.
neuronfair contributes more to the fairness improvement of the face detector i.e.
its generalization on image data is better than that of adf and eidig.
for instance in table on average the discrimination of detectors retrained with idis of neuronfair dropped by .
while the auc values of adf and eidig authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
neuronfair interpretable white box fairness testing through biased neuron identification icse may pittsburgh pa usa only dropped by .
and .
respectively.
we speculate that the valid input space of neuronfair is larger so its idis can find potential discrimination that other methods idis cannot.
then improve the detector s fairness through retraining.
neuronfair hardly affects the detector s dr values while improving its fairness.
for instance in table on average the dr value of detectors retrained with neuronfair s idis only dropped by .
while that of adf and eidig dropped by .
and .
respectively.
we compare the l2norm of biasand senatt generated by different methods and find that biasof neuronfair is much lower than that of adf and eidig.
therefore neuronfair can not only improve the detector s fairness but also maintain its detection performance.
answer to rq5 the generalization performance of neuronfair on the image dataset is better than the sota methods i.e.
adf and eidig in two aspects quantity it generates .
and .
image idis on average compared to adf and eidig respectively quality it searches .
input space with more than .
gsr on average it is beneficial to detectors fairness improvement of .
on average but hardly affects their detection performance.
thus neuronfair shows better generalization performance than adf and eidig.
threats to validity correlation between attributes .
the attributes of unstructured data are not as clear as structured data so we provide a generalization framework that can modify sensitive attributes.
however there is a correlation between attributes i.e.
after the perturbation for one sensitive attribute is added another attribute may also be changed.
since the transferability of perturbation is not robust.
the slight attribute change will not affect our idi generation.
sensitive attributes .
we consider only one sensitive attribute at a time for our experiments.
however considering multiple protected attributes will not hamper the effectiveness or generalization offered by our novel testing technique but will certainly lead to an increase in execution time.
this increase is attributed towards the fact that the algorithm in such a case needs to consider all the possible combinations of their unique values.
access to dnns .
neuronfair is white box testing that generates idis based on the biased neurons which means it requires accessing to dnns.
it is widely accepted that dnn testing could have full knowledge of the target model in software engineering.
related works fairness testing .
based on the software engineering point of view several works on testing the fairness of traditional ml models are proposed .
to uncover their fairness violations galhotra et al.
firstly proposed themis a fairness testing method for software which measures the discrimination in software through counting the frequency of idis in the input space.
however its efficiency for idis generation is unsatisfactory.
to improve the generation speed of themis udeshi et al.
proposed a faster generation algorithm aequitas which uncovers fairness violations by probabilistic search over the input space.
aequitas adopts a two phase operation in which the idis generated globally are used as seeds for the local generation.
however aequitas usesa global sampling distribution for all the inputs which leads to the limitation that it can only search in narrow input space and easily falls into the local optimum.
thus aequitas s idis lack diversity.
to further improve the instance diversity agarwal et al.
designed a new testing method symbgen which combines the symbolic execution along with the local interpretation for the generation of effective instances.
symbgen constructs the local explainer of the complex model at first and then searches for idis based on the fitted decision boundary.
therefore its instance effectiveness almost depends on the performance of the explainer.
the above mentioned methods mainly deal with traditional ml models which cannot directly be applied to deal with dnns.
recently several methods have been proposed specifically for dnns.
for instance zhang et al.
first proposed a fairness testing method specifically for dnns adf which guides the search direction through gradients.
the authors proved that its effectiveness and efficiency of idis generation for dnns are greatly improved based on the guidance of gradients.
based on the adf zhang et al.
designed a framework eidig for discovering individual fairness violations which adopts prior information to accelerate the convergence of iterations.
however there is still a problem of gradient vanishing which may lead to a local optimum.
neuron based dnn interpretation .
kim et al.
first introduced concept activation vectors which provide an interpretation of a dnn s internal state i.e.
the activation output in the hidden layer .
they viewed the high dimensional internal state of a dnn as an aid and interpreted which concept is important to the classification result.
inspired by the concept activation vectors du et al.
suggested that interpretability can serve as a useful ingredient to diagnose the reasons that lead to algorithmic discrimination.
the above methods study the activation output of one hidden layer while liu et al.
studied the activation state of a single neuron.
they observed that the neuron activation is related to the dnns robustness and used the abnormal activation of a single neuron to detect backdoor attacks.
these methods leverage the internal state to interpret dnns classification performance and robustness which inspires us to use it to interpret dnns biased decision.
conclusions we propose an interpretable white box fairness testing method neuronfair to efficiently generate idis for dnns based on biased neurons.
our method provides discrimination interpretation and idi generation for different data forms.
in the discrimination interpretation as curve and auc measurement are designed to qualitatively and quantitatively interpret the severity of discrimination in each layer of dnns respectively.
in the idi generation a global phase and a local phase collaborate to systematically search the input space for idis with the guidance of momentum acceleration and dynamic loss.
further neuronfair can process not only structured data but also unstructured data e.g.
image text etc.
we compare neuronfair with four sota methods in structured datasets and face image datasets against dnns the results show that neuronfair has significantly better performance in terms of interpretability generation effectiveness and data generalization.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa zheng et al.
acknowledgment this research was supported by nsfc nos.
open research projects of zhejiang lab no.
2022rc0ab01 the zhejiang provincial natural science foundation for distinguished young scholars no.
lr19f020003 the key r d projects in zhejiang province nos.
2021c01117 2022c01018 the ten thousand talents program in zhejiang province no.
2020r52011 .