prioritizing mutants to guide mutation testing samuel j. kaufman kaufmans cs.washington.edu university of washington seattle washington usaryan featherman feathr cs.washington.edu university of washington seattle washington usajustin alvin jalvin umass.edu university of massachusetts amherst massachusetts usa bob kurtz rkurtz22 gmu.edu george mason university fairfax virginia usapaul ammann pammann gmu.edu george mason university fairfax virginia usaren just rjust cs.washington.edu university of washington seattle washington usa abstract mutationtestingoffersconcretetestgoals mutants andarigorous test efficacy criterion but it is expensive due to vast numbers of mutants many of which are neither useful nor actionable.
prior work has focused on selecting representative and sufficient mutant subsets measuringwhetheratestsetthatismutation adequateforthesubsetisequallyadequatefortheentireset.however noknown industrial application of mutation testing uses or even computes mutation adequacy instead focusing on iteratively presenting very few mutants as concrete test goals for developers to write tests.
thispaper articulatesimportantdifferencesbetweenmutation analysis where measuring mutation adequacy is of interest and mutation testing where mutants are of interest insofar asthey serve as concrete test goals to elict effective tests introducesanewmeasureofmutantusefulness calledtestcompleteness advancement probability tcap introduces an approach to prioritizingmutantsbyincrementallyselectingmutantsbasedon theirpredictedtcap and presentssimulationsshowingthat tcap basedprioritization ofmutantsadvances testcompleteness more rapidly than prioritization with the previous state of the art.
ccs concepts software and its engineering software testing and debugging empirical software validation.
keywords mutationtesting mutantselection mutantutility testcompleteness advancement probability tcap machine learning acm reference format samuel j. kaufman ryan featherman justin alvin bob kurtz paul ammann and ren just.
.
prioritizing mutants to guide mutation test ing.
in44th international conference on software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
introduction mutationtestinggeneratesasetofprogramvariantscalled mutants and challenges a developer to create tests that detectthem that is distinguishesthevariantsfromtheoriginalprogram.thereis strongempiricalevidencethatmutantsarecoupledtorealfaults and that mutant detection is positively correlated with real faultdetection .
this correlation is stronger than is the case for code coverage criteria commonly used in practice e.g.
statement and branch coverage .
mutationtestingisexpensiveduetothelargenumberofmutants thatcanbegeneratedforagivensoftwaresystem.recentresearch focusing on the practicality of presenting mutants as test goals identifiedthetotalnumberofmutantsandthefactthatmostofthem are not useful test goals as key challenges to adoption .
further equivalent and redundant mutants make it difficult fora developer to assess how close they are to achieving mutation adequacy .equivalent mutants are functionally identical to the original program and therefore cannot be detected by any test.
redundant mutantsarefunctionallyidenticaltoothermutants and arethereforealwaysdetectedbyteststhatdetecttheothermutants.
to make mutation testing feasible for practitioners it is necessaryto select justa fewof thenumerous mutantsproducedby currentmutationsystems.giventhatmanymutantsarenotuseful such a selection strategy must be biased toward useful mutants.
furthermore neither achieving nor measuring mutation adequacy is among the reported desiderata of industrial mutation testing systems whichareinsteadconcernedwithiterativelypresenting one or a small number of mutants as test goals to incrementally improve test quality over time .
thispaperproposesanewmeasureformutantusefulness which values mutants according to their likelihood of eliciting a test that advances test completeness and evaluates the measure s ability to effectively prioritize mutants.
specifically this paper contributes anarticulationofthedifferencesbetweentwomutationuse cases mutationanalysis vs.mutationtesting andimplications for empirically evaluating them section .
anewmeasure testcompletenessadvancementprobability tcap that quantifies mutant usefulness section .
a mutation testing approach that prioritizes mutants for selection based on their predicted tcap section .
an evaluation showing that for a variety of different initial testsetcoverages prioritizingmutantsaccordingtotcap improvestest completenessmorerapidly thantheprevious state of the art random selection section .
ieee acm 44th international conference on software engineering icse icse may pittsburgh pa usa samuel j. kaufman ryan featherman justin alvin bob kurtz paul ammann and ren just background amutation operator is a program transformation rule that generates amutant i.e.
program variant of a given program based ontheoccurrenceofaparticularsyntacticelement.oneexample of a mutation operator is the replacement of an instance of the arithmetic operator with .
specifically if a program contains an expression a b for arbitrary expressions a and b this mutation operator creates a mutant where a b replaces this expression.the mutation isthesyntacticchangethatamutation operator introduces.
a mutation operator is applied everywhere it ispossibletodoso.intheexampleabove ifthearithmeticoperator occurs multiple times the mutation operator will create a separatemutantforeachoccurrence.thispaperconsidersfirst order mutants where each mutant contains exactly one mutation as opposed to higher order mutants where each mutant is the product of multiple applications of mutation operators.
amutation operator group is a set of related mutation operators.
for example the aor arithmetic operator replacement mutation operator group contains all mutation operators that replace an arithmetic operator including the example above.
a mutant may behave identically to the original program on all inputs.
such a mutant is called an equivalent mutant and cannot be detected by any test.
as an example consider the ifstatement infigure1a whichdeterminesthesmallervalueoftwointegers numbers min .replacingtherelationaloperator with results intheequivalentmutant numbers min ifnumbers and min areequal assigningeithervalueto miniscorrect andhenceboth implementations are equivalent.
atrivial mutant is one that is detected due to an exception by every test case that executes the mutated code location.
as anexample considerthe forloopinfigure1a whichincludesa boundarycheckforanarrayindex for int i i numbers.length i .
if the index variable iis used to access the array numbersthen a mutation i numbers.length always results in an exception as the last value for iis guaranteed to index numbersout of bounds.
hence thismutant istrivial asany testthat reachesthe loopwill terminate with an exception.
.
dominator mutants given a set of mutants m a test set tismutation adequate with respectto miffforeverynon equivalentmutant minm thereis sometest tintsuchthat tdetectsm.however mutationoperators generate far more mutants than are necessary the cardinality of the mutant set is much larger than the cardinality of the mutationadequate test set.
this redundancy among generated mutants was formallycapturedinthenotionof minimalmutation .givenany set of mutants m adominator set of mutants dis a minimal subset ofmsuch that any test set that is mutation adequate for dis also mutation adequate for m. computing a dominator set is an undecidable problem but it is possible to approximate it with respect to a test set the morecomprehensivethetestset thebettertheapproximation.this approximation is not useful to a developer interested in writing tests theydo notyet have atest setwith which toapproximate a dominator set .
however from a research and analysis perspective a dominator set provides a precise measure for redundancy in a set1public int getmin int numbers 2int min numbers 3for int i i numbers.length i if numbers min min numbers return min a mutated relational operator in two different program contexts.
tests mutant properties t1t2t3t4mutop ctx tcap equi.
triv.
dom.
m1 !
for .0yes m2 for .
m3 for .
yes m4 for .
yes m5 for .
m6 true for .
yes m7 false for .
yes m8 !
if .
yes m9 if .
yes m10 if .0yes m11 i f .
m12 if .
m13 true if .
yes m14 false if .
yes symbols indicate test results indicates that tipasses on mj indicates that tifails on mjwith an assertion failure indicates that tifails on mj with an exception i.e.
the mutant crashes during execution .
b test results and mutant properties.
m4 m7 m9 m14m8 m13 m2 m5 m11 m12 m3 m6 m1 m10 c dynamic mutant subsumption graph for the mutants.
intuitively mutants high in the graph are dominating other mutants whereas mutants low in the graph are subsumed.
figure motivating example for program context and testcompleteness advancement probability tcap .
1744prioritizing mutants to guide mutation testing icse may pittsburgh pa usa of mutants and hence the dynamic approximation approach is an important research tool for analyzing mutation testing techniques.
givenafinitesetofmutants mandafinitesetoftests t mutant midynamically subsumes mutantmjif some test in tdetectsmi andeverytestin tthatdetects mialsodetects mj.ifmidynamically subsumes mjbuttheconverseisnottrue thesubsumptionis strict.
if two mutants miandmjinmare detected by exactly the same tests int miandmj the subsumption is not strict.
thedynamicmutantsubsumption graph dmsg capturesthe subsumption relationship among mutants .
each node in a dmsg represents a maximal set of redundant mutants and each edge represents the dynamic subsumption relationship between twosetsofmutants.morespecifically if mistrictlysubsumes mj then there is an edge from the node containing mito the node containing mj.
if a test detects any arbitrary mutant in the dmsg it is guaranteed to detect all the subsumed mutants i.e.
all mutants in the same node or below it in the graph.
figure 1b shows an example detection matrix that indicates whichtestdetectswhichmutants.inthisexample theset mconsists of14mutantsandtheset tconsistsof4tests.everytestthatdetects m12alsodetects m3 m6 andm11.hence m12dynamicallysubsumes these mutants.
in the case of the first two mutants the dynamic subsumptionisstrict.however m11andm12aredetectedbyexactly the same tests so the subsumption is not strict.
the dmsg shown in figure 1c visualizes the subsumption relationships.
mutants m1andm10are not detected by any of the testsint shownintheunconnectednodewithadashedborder.
these mutants are equivalent with respect to tbut they may be detectablebyatestthatisnotanelementof t.thedmsgisbased on a finite test set and can only make claims about equivalence with respect to t. dominator mutants appear in the graph inside dominator nodes stylizedwithdoubleborders.figure1chastwodominatornodes anycombinationofonemutantfromeachdominatornode suchas m4 m8 or m9 m13 formsadominatorset.figure1chas4 distinct dominator sets.
ultimately only two of the mutantsmatter if a test set detects the mutants in a dominator set it is guaranteed to detect all non equivalent mutants in the dmsg.
mutation analysis vs. mutation testing thispaperdistinguishesbetweentwomutationusecases mutation analysis which we define as a research based use of mutation techniquestoassessandcomparethemutationadequacyofexistingtestsets and mutationtesting whichwedefineasatestingapproach in which a developer interprets mutants as test goals and writes tests to satisfy those goals.
thisdistinctionisblurredintheliteratureand asaconsequence priorworkusuallyappliedthesamemethodsforevaluatingmutant selection techniques to both analysis and testing use cases.
specifically evaluations usually compare mutant selection strategies torandom mutant selection by sampling a fraction often less than of all mutants once and then evaluating how effective a randomly sampled test set which achieves full or x mutation adequacy on the sample of mutants is for the full setof mutants.
in other words these evaluations assess appropriatesampling thresholds and how representative the sampled set ofmutants is of the entire set with respect to measuring mutationadequacy.
examples include e selective n random andsdl approaches allofwhichareevaluatedwithrespect tomutationadequacyor morerecently withrespecttominimal mutation adequacy .
we argue that this evaluation methodology is appropriate for mutationanalysis butnotmutationtesting.mutantselectionapproaches for mutation analysis and mutation testing differ both in their overall goals selecting a representative subset of mutants to measure an existing test set s mutation adequacy vs. selecting atest goal that elicits an effective test and presumed use cases apriorivs.incremental mutant selection .
this paper accounts for these differences in the design of a selection strategy for mutation testing and the methods used to evaluate its efficacy.
goals the goal of mutation analysis is to assess and compare existingtestsetsortestingapproachesbymeasuringmutationadequacy.inthecontextofmutationtesting however achievingfull mutation adequacy is neither realistic nor desirable .
developersdonot writemutation orevencoverage adequate testsets and for good reasons .
the problems with achieving full coverage adequacy e.g.
test goals that are unsatisfiable or simply not worth satisfying apply equally to mutation adequacy with mutation adequacy having the additional burden of equivalent mutants whichposeanunrealisticworkload .instead industrial mutation testing systems present few mutants at a time and do not even compute mutation adequacy .
as a result mutation testing requires selecting the most useful of all mutants according to some measure.
section proposes such a measure tcap.
evaluation mutation analysis usually selects an entire subset of mutants just once a priori while mutation testing repeatedly andincrementally selects a few mutants.
in the mutation testing use case a developer is presented with one or a few mutants at a time then resolves them by writing a test or labeling them as equivalent .ifamutantispresentedasatestgoalandresolved at a given time then subsequent selections reflect the fact that the mutant as well as all subsumed mutants are detected.
a key difference between a priori and incremental mutant selection is the effect of redundancy among mutants on the effort requiredtoresolvethosemutants.asanexample considera priori selecting three mutants with two selection strategies s1ands2.
suppose the first mutant of s1elicits a test that detects all three mutants whereas the first mutant of s2elicits a test that detects onlythatmutant thesecondmutantisequivalent andthethirdmutant elicits an additional test.
the mutant sets of s1ands2contain theexactsamenumberofmutants buttheefforttoresolvethose mutantsdiffers s1requiredresolvingonlyonemutantwhereas s2 required resolving all three.
prior evaluations of mutant selection techniques were largely basedona priorimutantselectionandconsideredtwomeasures the number or ratio of selected mutants and the mutation adequacy achieved by a corresponding test set.
this is appropriate forthemutationanalysisusecase.forthemutationtestingusecase however anevaluationshouldbeprincipallyconcernedwiththe effortrequiredtoresolvemutantsandoverallprogresswithrespecttoadvancing testcompleteness.
inotherwords such anevaluation 1745icse may pittsburgh pa usa samuel j. kaufman ryan featherman justin alvin bob kurtz paul ammann and ren just shouldbe agnostictoredundancyand measuretestcompleteness over actual effort as opposed to the number of selected mutants .
our evaluation section6 is aligned withthe mutation testing usecaseandadoptsthemodelproposedbykurtzetal.
.specifically it operationalizes effort as a sequence of worksteps wherein adeveloperispresentedasinglemutantandtheneitherwritesa test to detect it or labels it as equivalent.
the amount of work to resolve each mutant is presumed to be equal and the total amount of work is therefore the sum of the number of tests written and the number of equivalent mutants.
this model has two advantages.
first it is agnostic to redundancy after a test is introduced all detected mutants are removed from further consideration and never subsequentlyselected.second equivalentmutantshaveacostin that they consume work but do not advance test completeness1.
test completeness advancement probability tcap we propose a new measure of mutant usefulness test completeness advancement probability tcap which enables prioritizing mutants for incremental selection.
for a given mutant tcap is the probability that a mutant if presented as a test goal will elicit a testthatadvancestestcompleteness.theprobabilitydistributionof tcapisgenerallyunknowable butitispossibletoestimateitwith respect to an existing set of developer written tests.
for simplicity tcap refers to its estimate in the remainder of this paper.
kurtzetal.
defined testcompleteness intermsofwork what fraction of the expected number of tests necessary for mutation adequacy have been written?
kurtz et al.
further showed that dominator score which is the fraction of dominator nodes detected by a test set enjoys a linear relationship with test completeness.
thisisincontrasttothetraditionalmutationadequacyscore which rises rapidly with the first few tests due to redundant mutants and henceisapoormeasureoftestcompleteness.consequently this paper uses dominator score as a proxy for test completeness.
unlikepriorworkwhichdefinesmutantusefulnessasaproperty solely of the mutant itself e.g.
tcap quantifies the usefulness of a mutant in terms of the value of its detecting tests.thiscapturesakeyidea amutantisusefulasatestgoalonlyinsofarasitelicitsusefultests andausefultestisonethatadvances test completeness.
notice four properties of tcap equivalent mutants have a tcap of .
this is desirable and capturesthefactthatequivalentmutantsdonotleadtotests.
dominator mutants have a tcap of .
this is in line with thedefinitionoftestcompleteness selectingatestforadominator mutant is guaranteed to advance test completeness.
subsumedmutantshaveatcapofstrictlygreaterthan0 but less than or equal to .
since subsumed mutants are always detected by at least one test that also detects a dominatormutant theirtcapisstrictlygreaterthan0.notethat tcap can be for subsumed mutants which is desirable andcapturestheideathatamutant susefulnessisdefined by the tests that it elicits.
1this model considers equivalent mutants as useless because they do not lead to tests.
this is a simplification equivalent mutants can be useful and for example expose code defects or lead to code refactorings .
the tcap of a subsumed mutant is smaller than or equal to that of its dominating mutant s .
this is desirable becausesubsumed mutants can impose overhead if a dominatingmutant is later presented as a test goal a developer might write a weak test to detect a subsumed mutant and later writeastrongertesttodetectadominatingmutant itwould have been more efficient to simply write the stronger test.
recallthemotivatingexampleinfigure1 onlytheequivalent mutantsm1andm10reachtheminimumtcapof0 allsixdominatormutantshaveatcapof1 thesubsumedmutants m2andm5 as well as mutants m3andm6have a tcap of .
half of the tests thatdetectthesemutantsalsodetectadominatornode.incontrast the subsumed mutants m11andm12have a tcap of despite not being dominators both tests that detect these mutants also detect a dominator mutant.
we do not value mutants according to their ability to detect known faults fault coupling for three reasons.
first any benchmark that provides a set of known real faults is inevitably a subset of thefaults thatcould havebeen introducedor thatalready exist butare yettobe detected.asa result biasingmutant selectionto a limited set of mutants may cause parts of the programs undertest to not be mutated and tested at all.
second the core idea ofmutation testing is to systematically mutate a program to guard against fault classes not just a few known faults.
finally the set of dominator mutants subsumes all fault coupled mutants.
predicting tcap toevaluatethebenefitsofusingtcaptoprioritizemutants we trainedasetofmachinelearningmodels linearmodelsandrandom forests that predict tcap from mutants static program context.
notethatthepurposeoftrainingthesemachinelearningmodels is to evaluate whether program context is predictive of tcap and whetherpredictionperformancetranslatestodownstreamimprovementsinmutationtestingwhenincrementallyselectingmutants based on said predictions.
the goal is neither to maximize anyparticular metric of model performance nor to comprehensivelyexplore the design space of machine learning models to identify themodeldesignthatwouldbebestsuitedforthistask.weconjecture that more sophisticated machine learning models and a richer featuresetwilllikelyyieldlargerimprovements butweleavean in depthexplorationof modelingchoicesandfeature importance as future work.
.
dataset toproduceadataset wegeneratedmutantsforsubjectsdrawnfrom defects4j andtransformedthemintofeaturevectorsdescribing themutationandprogramcontext.additionally weassociatedeach mutant with a label for tcap derived from detection matrices.
wechose9subjects projects fromthedefects4jbenchmark v2.
.
which provides a set of open source projects accompanied by thorough test suites.
we selected the latest version of eachprojectandgeneratedmutantsfortheentireproject.outof projects we filtered out because of technical limitations in the mutationframework e.g.
jvmlimitsonthesizeofanindividual method and3forwhichthecomputationofafulldetectionmatrix was computationally too expensive.
1746prioritizing mutants to guide mutation testing icse may pittsburgh pa usa table1 summaryofsubjectclassesandcoveredmutants.
covering givesthemeannumberoftestscoveringeachmutant and detecting gives the mean number of tests detecting each mutant.
project classes mutants tests total equivalent detectable dominator all total covering detecting chart .
.
.
.
.
cli .
.
.
.
.
codec .
.
.
.
.
collections .
.
.
.
.
csv .
.
.
.
.
gson .
.
.
.
.
jacksonxml .
.
.
.
.
jxpath .
.
.
.
.
lang .
.
.
.
.
overall .
.
.
.
.
we used the major mutation framework to generate all possible mutants for each of the subjects and to compute the detectionmatrices.ofthe2 496entriesinthedetectionmatrices .
were inconclusive due to a timeout of to seconds where tois a sample of the test runtime before mutation.
mutants that time out are considered detected.
weretainedonlymutantsthatarecoveredbyatleastonetest fortheevaluationandtrainingsets.coveredbutundetectedmu tants are deemed equivalent which is a common approximation inmutationtestingresearch.sinceuncoveredmutantscannotbe detectedbuttherearenoteststhatwouldincreaseconfidenceinthe approximation of mutant equivalence these are excluded.
table provides a detailed summary of our final dataset showing only retained covered mutants.
.
program context features adopting the modeling approach and extending the model feature setofjustetal.
wemodeledprogramcontextfeaturesusing information available in a program s ast.
given a mutated astnode we consider syntactic context i.e.
parent and child nodesin the ast as well as nesting information and semantic context i.e.
the data type of expressions and operands or the data type of method parameters of that node.
notethatpriorwork e.g.
usedinformationderivedfrom test executions e.g.
code coverage when making predictions in a mutation analysis context.
because our goal is to identify useful mutants for tests that have not yet been written mutation testing we necessarily avoid features derived from tests.
specifically we chose the following set of features mutationoperator.
thespecificprogramtransformationthat generates a mutant e.g.
!
in figure .
mutationoperatorgroup.
oneofaor cor evr lor lvr oru ror sor or std.
node data types.
the summary data type of the mutated node in the ast e.g.
int class o rboolean int int encoding the return and parameter types of methods andoperators as well as a more abstract version which mapscomplextypestotheirresulttypes e.g.
boolean int int becomes boolean .
node kind.
the kind of the mutated ast node e.g.
binary operator literal method call .
ast context.
four features each of which is a categorical variable thesequenceofastnodekindsfromthemutatednode inclusive totherootnodeoftheast extends the first feature by including edge annotations describing noderelationships e.g.
a forloophaschildnodes for init for cond for inc o rfor body and correspond to thefirsttwofeatures butprovideahigherlevelofabstraction andincludeonlythosenodesthataretop levelstatements as opposed to individual expressions .
parentcontext.
versionsof astcontext featuresthatconsider only the immediate parent of the mutated node.
childrencontext.
threefeaturesthatindicatethenodekinds oftheimmediatechildnodesofthemutatedastnode animmediatechildnodeisa literal animmediatechild nodeisa variable animmediatechildnodeisan operator.
relative position.
the relative line number of the mutated nodeinsideitsenclosingmethod dividedbythetotalnumber of lines in that method.
nesting.sevenfeatures intotal a the maximumblock nestingdepthanywhereintheenclosingmethod b thenesting depth numberof enclosingblocks consideringonly loops only conditionals and any enclosing block i.e.
the sumof the previous two and c an additional three features dividing the previous three by the maximum nesting depth.
.
machine learning models we evaluated a small number of model design choices and training settingsagainstanintrinsicmeasureofmodelperformancewiththeultimategoalofchoosingasinglemodelfordownstreamevaluation.
each training setting was a kind of hold one out train test split using each held out project or class in a given project at a time as the evaluation set.
we trained all models using scikit learn and evaluated every combination of the following choices 1747icse may pittsburgh pa usa samuel j. kaufman ryan featherman justin alvin bob kurtz paul ammann and ren just model choice.
we compared ridge regression .
to a random forest regression max depth of and trees .
feature set.
we used a comprehensive set of features all features enumeratedinsection5.
andasubsetofthesefeatures few features usedin onlythemutationoperator and detailed parent statement context .
trainingsetting.
weevaluatedthefollowingtrain testsplits a allprojects trainingonmutantsfromallprojects including those in non held out classes in the same project and testing on mutants in the held out class b between projects training on mutants strictly in other projects and testing on mutants in the held out project c project only trainingonmutantsinallbutoneheld out class in a single project and testing on mutants in the held out class.
these training test splits correspond to three realistic mutationtestingsettings inwhichadeveloperintendstotesta new class in an existing project with or without access to other projects or a completely new project.
weevaluatedeachcombinationofmodelchoice featureset and trainingsettingbytrainingonemodelforeachpossibletraining test split.
for example for a given model choice and feature set the all projectstraining testsplitsresultedinatotalof1 084models one for each held out class in the dataset whereas the between projects splits resulted in just models one for each held out project.
we compared the combinations based on the spearman rank correlation coefficient between the tcap predictions and labels.
therankcorrelationcoefficientisanappropriateintrinsicmeasure becauseweareprincipallyinterestedintheorderinwhichmutants willbeselected.figure2showsthe distributions oftheresulting coefficients across all models.
we find that modelchoice.
alinearmodelissufficientforthefeaturesets considered anobservationconsistentwithpriorwork .
featureset.
alarger featuresetmodestlyimproves theperformanceoflinearmodels butitreducesvariationincorrela tioncoefficientsbetween splits perhaps byinducing models thatare lesssensitivetonoise inindividualfeatures.many ofthese featuresarecollinear e.g.
thevariousnestingfeatures .whilethisdoesnotaffectthesuitabilityofourmodel designs to the downstream evaluation collinearity meansthat linear model coefficients and permutation feature im portances are not individually interpretable and the highcardinality of our categorical features mean the same for random forest impurities.
still an ad hoc analysis suggests that syntactic context features are the most important ones.
training setting.
the median performance of project only is consistentlythebest especiallyforthenon linearmodels though the difference is less pronounced for linear models.
whilemanyof themodelconfigurationsperformsimilarly we choosethefollowingconfigurationfortheexperimentsinsection6 model linear features all training setting project only project onlyisacommonevaluationscenarioandthechosencombination has the highest median correlation coefficient.
.
.
.
.
.4median corr.
coefficientsmodel linearfeatures used allmodel random forest allprojects between projects project only training setting0.
.
.
.
.4median corr.
coefficients allprojects between projects project only training settingfeatures used few figure2 intrinsicevaluationofmodelperformance brokendownbymodelchoice featureset andtrainingsetting.eachboxplotcontainsninedatapoints showingthedistributionof spearman s for all projects.
whiskers extend up to .
times the interquartile range.
evaluation considerdevelopingcodeforalargeprojectforwhichasignificant body of code along with associated mutants and tests alreadyexists.
a realistic mutation testing scenario employing a tcapbased mutant selection approach is train a model that predicts tcap on a project s existing mutants and tests.
generate new mutants for a developer s current source file.
predicttcapofthesenewmutants usingthetrainedmodel.
provide the developer with the highest tcap mutant asa test goal if they write a test then remove all mutants detectedbythattestfromfurtherconsideration.repeatuntilastoppingconditionismet e.g.
somefixedamountofwork or a predicted tcap threshold .
asmotivatedinsection3 thisscenariocorrespondstomutation testing usingtcaptoprioritizemutantsforincrementalmutant selection and each iteration corresponds to a single work unit.
work simulation toevaluatetcap basedmutantprioritization we simulated the aforementioned scenario.
a work simulation begins with some initial possibly empty test set and the set ofmutants not detected by those tests selects the highest scoring mutant according to some prioritization strategy adds a randomly selected test without replacement that detects that mutant to the test set and repeats with the remaining set of undetected mutants.
we evaluated tcap based mutant prioritization against two baselines optimalandrandom.
optimal prioritizes mutants based on the tcap labels in the dataset and random simply producesa randomized order.
optimalestablishes an upper bound on the performance of any mutant prioritization strategy and random perhaps surprisingly corresponds to the state of the art .
allmutantprioritizationstrategiesinourevaluationarestochastic tiesfor tcaparebrokenrandomly and thetestintroducedat each work step is chosen uniformly at random without replacement fromthosethatdetecttheselectedmutant.ourevaluation repeatseachworksimulation1 000timesperclass forallstrategies.
1748prioritizing mutants to guide mutation testing icse may pittsburgh pa usa a aworksimulationforasingleclass plottingallindividual1 runs for each strategy.
b the mean test completeness over the individual runs per unit of work.
the dashed line indicates the predicted tcap.
figure an example work simulation for the collectionutils class in apache collections.
figure shows an example work simulation for a single class illustrating how test completeness increases over the course of the simulation.theoptimalstrategyincreasessmoothlyandrapidlyto atestcompletenessof100 sinceeachunitofworkdetectsone or occasionallymorethanone dominatornode.tcap basedselectiondoesnotincreaseasrapidly despitemakingconstantprogress since the choices are imperfect.
however it increases substantially fasterthantherandomstrategy.considertheunitsofworkrequired by each strategy to reach .
test completeness.
the optimal strategy requires about units of work and tcap based selection requires no more than .
the random selection strategy in compari son requiresabout100unitsofwork.inthissimulation adeveloperinterestedinreachingatestcompletenessof0.75neededtoresolveabout20 moremutantswiththetcap basedselection compared to the optimal strategy whereas randomly selecting mutants as test goals would have required resolving more mutants.
efficiency inordertosummarizeaworksimulationandquantify the efficacy of a prioritization strategy we define efficiency to be a measurementofastrategy simprovementoverprioritizingmutants randomly normalizedbytheperformanceoftheoptimalstrategy.
specifically the efficiency of the tcap based strategy tover a sequence of work units uis summationdisplay.
u cu t cu r summationdisplay.
u cu o cu r wherecuo cur andcu tare test completeness at work unit ufor the optimal random and tcap strategies respectively.
an optimal strategyhasanefficiencyof1 astrategynobetterthanrandomhas an efficiency of and a strategy that performs worse than random has a negative efficiency.
intuitively a positive efficiency indicates how much of the gap wasted work between random and optimal thestrategycloses.incontrast anegativeefficiencyindicatesan underperformingstrategy butitisnotnormalizedbecausewedo not include the worst possible strategy.
the subsequent sections showthattcap basedprioritizationismoreefficientthanrandom and they also investigate outliers of negative efficiency results.
chart cli codec collections csv gson jacksonxml jxpath lang projectefficiency figure4 efficiencyperclass groupedbyproject 7extreme outliers with efficiency are removed from the plot forclarity see section .
.
for details.
notethat46outof1 084classeshadeitherexactlyonegenerated mutant or very few yet only equivalent mutants.
in either case all three prioritization strategies are trivially equivalent and hence we discarded these classes leaving classes for analysis.
.
simulating work .
.
measuringaverageefficiency.
ourgoalistoevaluatewhether tcap basedmutantprioritizationislikelytosaveworkforadevlopertestinganarbitraryclasswithanarbitrarytestbudget.to that end we simulated the efficiency of tcap based prioritization for all retained classes in our data set.
we derived tcap predictions from the model described in section .
figure shows the distribution of efficiency per class broken down by project.
the results show that tcap based prioritization consistently and meaningfully outperforms the random strategyacross all projects reducing median wasted work by between a third and a half.
.
.
inspecting extreme outliers.
we encountered seven extreme outliers with efficiencies ranging from .
to .
which are 1749icse may pittsburgh pa usa samuel j. kaufman ryan featherman justin alvin bob kurtz paul ammann and ren just .
.
.
.
.
worktest completenessmutant prioritization optimal tcap random figure5 worksimulationforanextremeoutlierclass constantfactory with a negative efficiency of .
.
table2 efficienciescalculatedasthesumofeveryworkunit acrossallclasses perproject.
totalreferstoallclassesacross allprojects.theseefficienciesaccountforclasssizeandcor respondingtotalnumberofworkunits.thisisincontrasttofigure which plots distributions over class level efficien cies irrespective of the number of work units required toachieve test completeness.
chartcli codec collections csv gson jacksonxml jxpath lang total .
.
.
.
.
.
.
.
.
.
removed from figure for clarity.
the asymmetry in the efficiency measure motivates us to understand whether these extreme outliersindicateapotentialformeaningfulcostsinpracticeoverthe random approach.
one possible explanation for these values lies in features that can make a mutant set well tailored to the random approach.forexample allextremeoutliershavefiveorfewerdominatornodes withfouroutliersonlyhavingone.thepercentage of covered mutants that are dominators is over for all outliers.
consequently when most mutant choices increase completion and problemsizeissmall anearlysuboptimalchoicemadebytcapbased selection can result in a substantial negative efficiency score since random exhibits steady progress.
figure demonstrates this by showing an example for an extreme outlier constantfactory from apache collections with a computed efficiency of .
.
to introduce some perspective we can quantify the potential real world cost of these outliers for a developer generating the handfuloftestsneededtoreachfulltestcompletenessonclasses ofthissize.for5outof7outliers themediantimetocompletion for tcap based selection is only steps behind random steps for the remaining outliers .
however this measure ignores the high variance present in the random approach compared to tcap based selection.
when considering the mean completion percentage tcap based selection finishes with or before random for outliers with the final outlier taking only one additionalstep.
in summary none of these results suggest the potential for significant performance concerns arising from these outlier values.
figure6 tcapthresholdasapredictoroftestcompleteness of the tests elicited by all mutants whose predicted tcap isabovethatthreshold .notetheinvertedtcapthresholdaxis.allspearman srankcorreletioncoefficients aresignificant at p .
.
.
.
accountingforclasssize.
apotentialweaknessoftheefficiencyanalysisinsection6.
.1isthatittreatsallclassesasbeing equal even though they differ in size and therefore perhaps in importanceortestingdifficulty.toaccountforthis wecomputed the overall efficiency per project and across all projects that is the efficiency over all mutants per project and over all mutantsin the entire data set.
this means that larger classes with moremutants and work steps have a higher weight.
recall figure 3b which visualized efficiency as the ratio of two areas.
intuitively overall efficiency is the ratio of the sums of these two areas across all classes as opposed to the average ratio per class.
table shows theresults.whilethe efficiencyvariesbetweenprojects itisconsistentlypositive.furthermore thevariationinoverallefficiency aligns with the variation of median efficiency across projects.
in conclusion tcap basedmutationtestingreducesthetotalamount of wasted work by a third.
.
deciding when to stop testing selectingmutantsinorderofdescendingpredictedtcapallows a developer to focus time and effort on the most important test goals.
however the ranking alone does not answer the fundamental question of when resolving additional mutants provides onlymarginal benefits.
in other words when should a developer stop testing and how well tested is a software system after writing tests for all mutants with a tcap above a given threshold.
in order to understand whether tcap thresholds are predictive of expected test completeness we correlated the two for all classes in our data set.
figure shows the results indicating a strong associationbetweentcapthresholdsandtestcompleteness.atthe same time the variance of tcap thresholds is quite high for some projects.forexample adeveloperinterestedinreachingatleast50 1750prioritizing mutants to guide mutation testing icse may pittsburgh pa usa figure test sampling ratio vs. line coverage.
test completeness for an arbitrary class in csv could confidently use a tcap of about .
as a stopping criterion.
however it sless clear what tcap threshold a developer of chart should use a substantial amount of tcap density spans the range from .6to .
.
nonetheless these results are promising and suggest that accounting for project specific characteristics may reduce varianceandimprovethesepredictivemodels.weleaveadeeperexploration as future work.
.
simulating work with initial test sets our evaluation so far has focused on the efficiency of tcap based mutantprioritizationinascenariowheremutationtestingisapplied from scratch.
however mutation testing often happens after some testshavealreadybeenwritten.toassesswhethertheefficiencyof tcap based mutant prioritization is sensitive to the efficacy of an existingtestset weperformedanadditionalsimulation.specifically we ran an additional work simulations for each class with arandomlyselected line coverage guidedinitialtestsetselected from that class existing test set.
for the purpose of this simulation we measure test set efficacy as the line coverage ratio.
our goal is to understand the relationship between an initial testset scodecoverageandtheefficiencyoftcap basedmutant selection for all remaining mutants not detected by that initial test set.consequently weaimtogenerate foreachclass acollection of initial test sets with a uniform distribution of code coverage ratios.asnotedbychenetal.
therelationshipbetweentest setsizeandcodecoverageisnotlinear.auniformrandomselection overtestsetsizewoulddrasticallyoversampletestsetswithvery highcode coverage ratios.figure 7visualizesthis problem.given thelog linearrelationship weresortedtoinversetransformation sampling we fitted a log linear model for each class predictingthe log of the test sampling ratio from a given code coverage ratio wesampled1 000code coverageratiosuniformlyatrandom we computed the corresponding test sampling ratio by sampling from the inverse of the fitted model.
the outcome of this sampling approachwasapoolof1 000testsetsforeachclass whosecodecoverage distribution was approximately uniform.
performing a work simulation for each of these initial test sets yielded efficiency values that correspond to a given code coverage ratio.
figure efficiencies per class broken down by project andcoverage quartile.
for simplicity figure shows these efficiency results binned by quartilesofthecode coveragedistribution.aregressionanalysis using thenon binneddata confirmedthe visualtrend thedegree of code coverage achieved by the initial test suite is either uncorrelatedwithefficiencyoritisweaklypositivelycorrelated.thekeytakeawayisthattheefficiencyoftcap basedmutantprioritization is agnostic to the efficacy of the existing test set.
threats to validity external validity our results are potentially limited to the projects in our empirical study all of which are java programs.
while we chose a variety of different projects our results do not necessarily apply to other languages or even to other java projects with different characteristics.
additionally our estimates of tcap rely on existing developer written tests which were likely notdeveloped in a mutation testing setting.
it is possible that thesetestsarenotrepresentativeof thosethat developerswould write whenresolvingamutant.however astudyofpetrovi etal.
inanindustrialsetting foundnoqualitativedifferencesbetween tests written specifically for mutants vs. tests written for other objectives.
constructvalidity asiscommoninmutationtestingresearch weapproximateequivalentmutantsanddominatormutantswith a set of existing tests.
since test sets generally have to be quite thoroughbeforethedynamicapproximationofthesubsumption relations convergesto the truesubsumption relation werisk identifying some non dominator mutants as dominators and viceversa.
to counter this threat we relied on projects that come with thorough test sets.
additionally as described in section we assumethatdominatorscoreisavalidproxyfortestcompleteness w.r.t.mutationtesting .whileanychoiceofproxyposesathreat to construct validity dominator score is a better proxy than the alternative the mutation score.
internal validity we rely on an idealized model of mutation testing.forexample weassumethatworkunitscorrespondtosome constant amount of actual engineering effort but there is some variancearoundthetimerequiredtoresolveasinglemutant .
whilewehavenoreasontobelievethisisthecase itispossiblethat ourevaluatedmodelisbiasedtowardmutantswhichsystematically take either more or less actual effort to resolve.
1751icse may pittsburgh pa usa samuel j. kaufman ryan featherman justin alvin bob kurtz paul ammann and ren just related work thelargenumberofgeneratedmutantshaslongbeenarecognized probleminmutationanalysisandmutationtestingresearch.this section first discusses the most closely related work by just et al.
and zhang et al.
and then provides a more general overview of related work.
closely related work just et al.
demonstrated that program context derived from the abstract syntax tree can significantly improve estimates of a mutant s expected usefulness.
in this context usefulness was formally quantified as mutant utility along three dimensions equivalence triviality and dominance.
in short justetal.showedthatmutantusefulnessiscontext dependent a mutation that leads to a useful mutant in one context does not necessarily do so in another.
while just et al.
showed that program context correlates with mutant utility they did not make use of that correlation.
they did not build a predictive model and didnot evaluate the benefits of using such a model for downstream applications such as mutation testing.
zhang et al.
used machine learning to predict mutation scoresbothwithinandacrossprojectsforafixedtestsuite using featuresderivedbothfromprogramcontextand critically runtime information such as code coverage which is only available after tests have been written.
our predictions are very different rather than predicting expected mutation scores based on existing test suites we predict which mutants are useful and likely lead to additional effective test cases.
this distinction goes to the heart of the differences between mutation analysis and mutation testing.
mutationtestinginpractice petrovi etal.reportedonalargescale deployment of mutation testing at google .
their mutation testing system was integrated into a commit oriented development workflow.
to combat the problems of generating too manymutants linesofcodenotchangedbyacommitwereignored as were lines in the commit not covered by at least one existing test.foreachremaininglineofchangedcode thesystemgenerated at most one mutant.
our work is immediately applicable to this usecase.tcap basedmutantselectionallowsforpickingthemost useful mutant for any given line.
beller et al.
report on a similar large scale deployment at facebook.theyintegratedamutationtestingsystemintoacommitoriented development workflow and evaluated the system s acceptancebyworkingengineers.theyinnovatedbysemi automatically learningasmallnumberofcontext sensitivemutationoperators from real faults reducing the total number of mutants generated.useful mutants researchers have addressed the notion that somemutantsaremoreusefulthanothers disjointmutants kintisetal.
stubbornmutants yaoetal.
difficult to detect mutants naminetal.
minimal akadominator mutants ammannetal.
andkurtzetal.
andsurfacemutants gopinath et al.
.
disjoint stubborn difficult to detect dominator and surface mutants are suitable in a research context but are not directly applicable to the engineer in practice.
namin et al.
described muranker atooltoidentifydifficult to detectmutants basedonthesyntacticdistancebetweenthemutantandtheoriginal artifact.theypostulatedtheexistenceof hardmutants thatare difficulttodetectandforwhichadetectingtestmayalsodetectanumberofothermutants.thisiscloselyrelatedtowhatkurtzet al.
have formalized as dominator mutants .
the key idea that distinguishes tcap from other proxy measures for mutant usefulnessisthatamutantisusefulasatestgoalinmutationtestingonly insofar as it elicits a test that advances test completeness.
mutantselection priorworkonmutantselectionhasfocused on using a subset of the mutation operators mathur offutt et al.
wong et al.
barbosa et al.
namin et al.
untch dengetal.
delamaroetal.
and delamaro et al.
and choosing a random subset of mutants acree budd and wong and mathur .
comparisons of the two approaches zhang et al.
gopinath et al.
and kurtz et al.
ultimately showed the counterintuitive result that existingmutantselectionapproachesdonotoutperformrandom selection.
just et al.
s results are consistent with these findings theyshowedthatcontext agnosticmutantselectionshowsno appreciable improvement over random selection.
however their results also demonstrated that program context is predictive of mutant usefulness which motivated our work.
fault coupling while the numbers of mutants generated by mutationoperatorsarealreadylarge evenmoremutationoperators areneededtogeneratemutantsthatarecoupledtorealfaults empir icalstudiesofmutationadequacy daranandth venod fosse naminandkakarla andrewsetal.
andjustetal.
showedthatfaultcouplingishigh butalsothatthereisroomforim provement.thetailoredmutantworkofallamanisetal.
andthe wild caughtmutantworkofbrownetal.
demonstratedmutation approachesthatcanclosethisgap butatthecostofsubstantially increasingthenumberofgeneratedmutants.context basedmutantselectionhasthepotentialtomakethesehigh couplingapproachespractical.papadakisetal.
investigatedtherelationshipbetween various quality indicators measures of usefulness for mutants of particularrelevancehereisthat forthefaultsintheirstudy only of dominator mutants were fault revealing a property closely related to fault coupling .
as discussed in section we did notinclude a dimension for fault coupling in our model precisely toavoid the consequent blind spots.
the results of papadakis et al.
suggested that these blind spots may be quite large.
equivalentandredundantmutants jiaetal.surveyedmutationtesting ingeneral andprovideda detailedreviewof mutation equivalence detection techniques .
reducing the number of equivalent mutants presented as test goals is a key goal in making mutationtesting practical and hence a keyfocus ofour work.
ourworkcanbeappliedinadditiontoexisting context agnostic techniques prioritizingmutantswithrespecttotcapallowsan incrementalmutantselectionapproachtoavoidmutantsthatare likelyequivalentinaparticularcontext.researchershavealsoconsideredredundancyofmutantswithrespectto weak mutation kaminskiet al.
forrelationaloperator replacement ror justetal.
forconditionaloperatorreplacement cor yaoet al.
for the arithmetic operator replacement aor and just and schweiggert over cor uoi and ror.
weak redundancy analysistechniquesaresound butonlyapplytoasmallsubsetof the mutation operators do not consider propagation and do not address the equivalent mutant problem.
1752prioritizing mutants to guide mutation testing icse may pittsburgh pa usa conclusions tomakemutationtestingfeasibleforpractitioners itisnecessaryto address the vast number of mutants produced by current mutation systems and the fact that most of these mutants are not useful.
this paper introduces a new measure for mutant usefulness called test completeness advancement probability tcap built on the insight that a mutant is useful as a test goal in mutation testingonlyinsofarasitelicitsausefultest onethatadvancestestcompleteness.furthermore thispaperdemonstratesthatamutant s staticprogramcontextispredictiveoftcap andthatprioritizing mutants with tcap can effectively guides mutation testing.
the main results of this paper are as follows programcontext modeledassyntacticandsemanticfeatures of a program s abstract syntax tree is predictive of tcap.
tcap based mutant prioritization independently of initial test set code coverage ratios improves test completeness farmorerapidlythanrandomprioritization whichperhaps surprisingly had prevailed as the state of the art despite decades of research on selective mutation.
predictedtcapandachievedtestcompletenessarestrongly correlated.whilepredictedtcapshowshighvariancefor some subjects the results suggest that an improved pre diction model could render predicted tcap as a practical stopping criterion.
data software availability toaidreuseandreplication weprovidethedataandsourcecodeunderlying this work at