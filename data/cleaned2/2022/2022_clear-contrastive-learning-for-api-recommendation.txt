clear c ontrastive le arning for a pi recommendation moshi wei york university toronto canada moshiwei yorku.canima shiri harzevili york university toronto canada nshiri yorku.cayuchao huang institute of software chinese academy of sciences yuchao2019 iscas.ac.cn junjie wang institute of software chinese academy of sciences junjie iscas.ac.cnsong wang york university toronto canada wangsong yorku.ca abstract automatic api recommendation has been studied for years.
there aretwoorthogonallinesofapproachesforthistask i.e.
informationretrieval based ir based and neural based methods.
although theseapproacheswerereportedhavingremarkableperformance our observation shows that existing approaches can fail due to the following tworeasons most ir based approachestreat task queries as bag of words and use word embedding to represent queries whichcannotcapturethesequentialsemanticinformation.
both the ir based and the neural based approaches are weak atdistinguishingthesemanticdifferenceamonglexicallysimilar queries.
in this paper we propose clear which leverages bert sentenceembeddingandcontrastivelearningtotackletheabovetwoissues.specifically clearembedsthewholesentenceofqueriesandstackoverflow so postswithabert basedmodelratherthanthebag of word basedwordembeddingmodel whichcanpreservethe semantic related sequential information.
in addition clear uses contrastive learning to train the bert based embedding model for learning precise semantic representation of programming terminologies regardless of their lexical information.
clear also builds a bert based re ranking model to optimize its recommendationresults.
given a query clear first selects a set of candidate so posts via the bert sentence embedding based similarity to reduce search space.
clear further leverages a bert based re ranking model to rank candidate soposts and recommends the apis from the ranked top so posts for the query.
our experimentresults on three differenttest datasets confirm theeffectivenessofclearforbothmethod levelandclass level api recommendation.
compared to the state of the art api recommendation approaches clear improves the map by at method level and at class level.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
concepts computingmethodologies semanticnetworks applied computing document searching information systems recommender systems.
keywords api recommendation contrastive learning semantic difference acm reference format moshi wei nima shiri harzevili yuchao huang junjie wang and song wang.
.
clear contrastive learning for apirecommendation.
in 44thinternationalconferenceonsoftwareengineering icse may21 pittsburgh pa usa.
acm new york ny usa pages.
https introduction overthepastdecades open sourcesoftwaredevelopmenthasreceived extensive attention from the software engineering community.thisattentionleadstoatremendousdemandforalready devised libraries or apis which facilitate software development and maintenance.
developers often search for existing apis or codesnippetsontheinternettoobtainthefunctionstheywishto implement .
to help with api search many automated api recommendation approacheshavebeenproposed .there aretwoorthogonallinesofapproachesforthistask i.e.
information retrieval based e.g.
biker and neural based methods e.g.
deepapi .biker usesbag of word basedwordembedding i.e.
a word2vec model built on java so posts and idf inversedocumentfrequency vocabularytocalculatethesimilarity scorebetweentwotextdescriptionsandthenleveragesaquery s similaritywithbothsopostsandapidocumentationstorecommend appropriate apis for the query.
deepapi formulates the apirecommendationasamachinetranslationproblem i.e.
givena naturallanguagequery itaimstotranslateitintoanapisequence.
specifically it adapts a recurrent neural network rnn encoderdecodermodeltoencodeaqueryintoafixed lengthcontextvector and recommends an api sequence based on the context vector for the query.
although these approaches achieved remarkable performance by replicating these studies we found two major problems that can affect their effectiveness.
ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa moshi wei nima shiri harzevili yuchao huang junjie wang and song wang the first problem is that these ir based approaches e.g.
biker treatqueriesandsopostsasbag of wordsandusewordembedding to represent queries which cannot capture the semanticrelated sequential information.
for example given a real world query convert string to calendar object in java biker cannot recommend the correct api and the top api recommended by biker is java.time.localdate.parse from the most similar post identified by biker i.e.
convert java gregorian calendar to string whose intent is opposite to the intent of the query.
biker fails to retrieve the correct answer for the above query becauseof its bag of words based representation which cannot capture the semantic related sequential information.
to properly represent the semantic related sequential information of the text descriptions the embedding of queries and so posts has to be considered comprehensively instead of using bag of words.
the second problem is that both the ir based and the neuralbasedapproachesareweakatdistinguishingthesemanticdifference amongquiresthatarelexicallysimilar.forexample givenarealworldquery filereader.read methodnotworking neitherbiker nor deepapi can recommend a correct api.
specifically the most likelyapirecommendedbybikeris java.io.randomaccessfile .read fromthepost bufferedreaderread notworking asthe text descriptions of the query and the post are almost identical except the terminology filereader and bufferedreader .
however the answer to this query is java.io.outputstreamwriter.flush .
the root cause of such a failure of biker is that the two quires are lexically close but semantically different.
biker s word2vec embedding relies on the context of the words in a text description.however theaboveexampleshowsthatonlyusingthecontextofthewordsisnotenoughtodistinguishthesemanticofthe query in api recommendation tasks.
for deepapi we experiment withtheabovetwoqueries filereader.read methodnotworking and bufferedreaderread not working whiledeepapi generates thesameapisequenceforbothqueries i.e.
string.length object.tostring whichisincorrectasthesetwoquerieshavedifferent semantics.oneofthereasonsforsuchafailureisthatdeepapiuses an rnn encoder decoder base architecture to encode every query intoafixed lengthcontextvectorandgeneratesanapisequence basedontheoverallcontextofthequery.thus duetotheabove nature of rnn deepapi often fails for similar queries that have different key words .
to alleviate the above two problems we propose clear an api recommendation approach based on bert sentence embedding and contrastive learning .
specifically to solve the first issue clear uses a bert based model to embed text descriptions of queries and so posts which produces the embedding of the whole sentence of an api query while taking sequential informationintoconsiderationratherthancombiningtheembedding of each word i.e.
bag of words .
for solving the second issue clearusescontrastivelearningtotrainthebertsentenceembedding model for learning semantically equivalent representation a query clear first selects a set of candidate so posts via the bert sentence embedding based similarity to reduce search space.
clearfurtherleverages abert basedclassification modeltorerank candidate so posts and recommend the apis from the ranked top so posts for the query.
inordertoevaluatetheeffectivenessofclear were usethe dataset from biker .
specifically we have developed three test sets derived from biker s datasetfor testing.
the first is biker s manuallycreatedtestdataset thesecondisrandomlyselected1k sample so posts to alleviate potential human bias.
since around posts in so contain multiple apis in order to test the performanceonthescenarioofmulti apianswers weaddedathird testdataset whichis1krandomlyselectedsamplesopostswith multiple apis in answers.
we use the corpus that excludes thesetesting data as our training dataset to train clear.
the resultsshow that clear outperforms the state of the art information retrievalbasedandneural basedapproaches i.e.
biker and deepapi respectively significantly at both method leveland class level on all three test sets.
we also conduct a case study to evaluateclearagainstthelatestsoposts andtheresultsconfirm the effectiveness and practical values of clear.
this paper makes the following contributions weproposeclear anovelapirecommendationapproach which usesthe bert sentence embeddingmodel to represent queries for capturing sequential semantic information and leverages contrastive training to train the bert model for learning precise semantic representation of queries regardless of their lexical information.
we evaluate clear using three different test datasets includingtestdatafrompreviousstudies 1krandomlyselectedsoposts and1krandomlyselectedsopostswithmulti api answers.
our experiment results confirm that clear can significantly outperform the state of the art baselines.
weconductacasestudyonthelatestsopoststoevaluatetheperformance of clear and our results suggest the practical value of clear.
we release the source code of clear and the dataset of our experimentstohelpotherresearchersreplicateandextend our study5.
therestofthispaperisstructuredasfollows.section2describes the background ofthis study.
section 3presents the framework of the proposed clear.
section introduces experimental design baselines andresearchquestions.section5analyzestheexperiment results.section6discussesopenquestionsandthethreatstothe validityofthiswork.section7surveystherelatedworkandsection summarizes this paper.
background .
language embedding language embedding technique is a method for converting words orsentencesintonumericalvectors .thedeeplearningbased language models have been widely examined to be useful in capturing implicit semantics for natural language sentences.
5replication package link authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
clear c ontrastive le arning for a pi recommendation icse may pittsburgh pa usa there exist studies of language embedding on both word level andsentence level .typicaldeeplearninglanguage embedding models include gpt and bert .
gpt introduces minimal task specific parameters and is trained on the downstream tasks by simply fine tuning all pretrainedparameters.bert isdeeplearninglanguageembedding based on transformer units.
it uses a layer or layer transformer layer with a multi head attention mechanism as feature extraction andthenusesaregressionfunctiontogeneratethefinal output.bertmodelcanbeusedformultipletasks e.g.
sentence embedding classification question answer tasks sentence tagging etc.
with different minor adaptions .
in this paper we use the bert model for two different tasks.
first we use bert as sentence embedding to represent the text of queries and so posts for preserving their semantic information regardlessoftheirlexicalinformation.second weusebertasa binary so post classifier to re rank the retrieved so posts for a givenquery.forboththetwotasks weuserobertamodel astate of the artbertvariant .forsentenceembedding weadoptthe contrastivelearningprocesstotrainthemodel weprovideaninputsampletothemodelandtaketheoutputvectorofthemodelasthe sentenceembeddingoftheinput.forre rankingposts following existingwork weusethejointembeddingtrainingprocessto train the classifier which takes paired posts as input and the label is whether or not they have the same apis.
thedifferenceofrobertatotheoriginalbertmodelisthat robertaapplieddifferenttrainingprocessesanddistillationsintraining which reduces the number of parameters while increasing the robustness of the bert model.
.
contrastive learning contrastivelearning isadeepneuralnetworktrainingprocess that takes paired sentences as input and uses the similarity inthe paired sentences as labels.
the training goal is to learn therelationship between sentences i.e.
whether two sentences aresemantically similar regardless of their lexical similarity.
hoffer etal.
proposedthe tripletnetworkforcontrastive training.it requires a triplet s p n as the input where scorresponds to the originalquery preferstothepositiveequivalentof s andnisthe negative one.
inthiswork weusecontrastivelearningtotrainaroberta modelforsentenceembedding.foragivenpostinthetrainingdata itspositivepostsarepostswiththesameanswerandnegativeposts are posts with different answers.
.
joint embedding training joint embedding training was widely used to train bert as a classification model.
figure shows the architecture of jointembedding training for bert.
bert provides a special token whichallowstwopoststobeconcatenatedasinput.injoint embedding training is used to identifythe end of the first post.
the process of joint embedding training is fine tuning the modelwithpairsofpoststothetargetthatifgiventwosemantic equivalent posts the model returns otherwise returns .
theloss function we use for joint embedding training is the classic figure joint embedding training cross entropy loss function i.e.
loss loss y log y y log y whereyindicates whether the given two posts are semantically equivalent and yis the prediction of the re ranking model.
in this work we leverage joint embedding training to train a roberta based classification model to re rank the retrieved so posts for a given query.
approach figure shows the pipeline of clear which consists of two parts language model building section .
and searching relevant apis section .
.
the language model building process contains four steps i.e.
post triplets construction section .
.
bert sentence embeddingwithcontrastivelearning section3.
.
candidateposts filtering section .
.
and the joint embedding training based reranking model section .
.
.
.
building bert base language models .
.
post triplets construction .the format of the training datausedinthecontrastivetrainingprocessisdifferentfromthe traditionalnaturallanguageprocessingtasks e.g.
sentimentanalysis wheretheinputsaresentencesandtheoutputsarethelabels.
contrastivetrainingrequirestripletsasinputs .everysingle triplet is a combination of three posts which are an input query s a positive sample post pthat is semantically equivalent to s and a negativesamplepost nthatisnotrelatedto sandp.therefore the trainingcorpusneedstobeconvertedtotriplets.forexample givenaninputquery javastringsplitwithmultipledelimeters thetriplet s p n can be java string split with multiple delimeters how tosplit apathusing stringtokenizer?
howto loadafile acrossthe network and handle it as a string .
algorithm shows the process of generating training triplets.
ourtripletsgenerationalgorithmhastwoparameters i.e.
pis the number of positive samples and nis the number of negative samplingforatraininginstance.whengeneratingthetriplets eachquestionneedstobepairedwithpositiveandnegativesamples.for each question itemint we use function get equivalent subset to get its positive posts i.e.
posts that have the same answer with item.
in addition we consider posts that have a different answer fromitemas the negative posts of item.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa moshi wei nima shiri harzevili yuchao huang junjie wang and song wang figure overview of our proposed clear.
algorithm triplets generator result tuple list of element s p n defgettriplets p int n int t list question answer result list new list initialize empty result list foritem in t do s item question sentence answer item t p get equivalent subset t answer t n set t set t p p list random sample t p p n list random sample t n n foritem p in p list do foritem n in n list do result list.append s p n end end endreturn result list note that the ratio between positive and negative samples is important in contrastive training different configurations may impacttheresultsignificantly .inouralgorithm tofindthe bestconfigurations i.e.
pandn weperformagridsearchwitha listofcandidatevaluesforboth pandn whichare1 and .
we use pandnthat can achieve the best performance in our experiment detailsareinsection4.
.forapisthatdonothave ppositivesamples weusealltheirpositivesamples.weperform randomsamplingontheapisthatexceed porntolimitthenumber of positive or negative samples.
.
.
bert sentence embedding model .inthis step weuse contrastivetrainingtotraintherobertabasedsentenceembeddingmodelwiththeposttripletscreatedinsection3.
.
.thegoalof this process is to learn a semantic presentation with which similar samplesstayclosetoeachother whiledissimilaronesarefarapart.
figure shows an illustration for this process.
in the figure greenpoints are positive posts that have the same api arrays.aslist with query s and the red points are negative posts of s. with contrastivelearning thecentergreenpoint splaystheroleofan anchor the positive samples are pulled towards the anchor and the negative samples are pushed away from the anchor.
figure3 architectureforcontrastivelytrainningrobertabased sentence embedding model figure shows the architecture of the contrastive learning used inourwork inwhichtheroberta modelisthebasemodel for sentence embedding and we use a pooling layer to connect the roberta model and the triple network.
triple network has two layers the first layer is three identical deep neural network models for feature extraction of input sentences.
the feature extractionlayer can also be replaced with other models or algorithms.
the secondlayerofthetripletnetworkisalossfunctionbasedonthe cosine distance operator.
the purpose of the loss function is to minimizethedistancebetweensimilarsentencesandmaximizethe distance between unrelated sentences.
the training objective is to fine tune the network so that the distance between the question sandthepositivequestion piscloserthanthedistancebetween the question sand the negative question n. formally the training objective is to minimize the following function max es ep es en wherees ep andenare the sentence embeddings of question s p andn.
is the margin of the distance between sandn.b y default is set to which means that the cosine distance between a question and its irrelevant question should be .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
clear c ontrastive le arning for a pi recommendation icse may pittsburgh pa usa s n np p how to convert foreign characters in java?
java.lang.integer.tostringhow to convert comma separated string to list?java.util.arrays.aslisthow to initialize list string object in java?java.util.arrays.aslistconverting array to list in javajava.util.arrays.aslist how to convert a number to a string collectionjava.lang.integer.tostring figure contrastive training for a single post.
.
.
candidate posts filter .in this step with the bert sentenceembedding built insection3.
.
wefurther filteroutirrelevantquestionsforagivenqueryandkeeptop kquestionsfordetectingcandidateapis.followingexistingwork clearkeeps top 50similarquestionsasthecandidates sinceretrievingtoomany questionscanintroducenoisetotherecommendationprocess.in thisstep weusetheeuclideandistancebetween twoquestionsas the metric to filter out irrelevant questions.
note that although our experimental results show that directly using the candidate questions from the filter for api recommendationcanachievebetterperformancethanbothbikerand deepapi details are in section .
we observe that there exist noisy questions in the retrieved candidate questions from the filter oneofthepossiblereasonsisthelowqualityofsoposts whichcouldhurttheperformanceofapirecommendation.thus a re ranking model for the candidate posts is needed and details are in the next section.
.
.
candidate post re ranking model .theobjectiveofour filtermodel detailsareinsection3.
.
istofilteroutthenumberof irrelevant posts from the entire search space while this re ranking model is to optimize the ranking of the left kcandidate posts from the filter model.
forsemanticembeddingre rankingtasks wechoosethesame bert model i.e.
roberta the state of the art bert based model for semantic embedding re ranking tasks as the base model.
then wefine tuneitwithjointembeddingtraining whichturns therobertaintoaclassificationmodel detailsareinsection2 thelabeliswhethertwopostshavethesameapis.fortrainingthe model wefirstusethefiltermodel detailsareinsection3.
.
to find the top similar posts i.e.
ts s1 s2 s3 ...s50 for a postp inour trainingdataset.wethencreate50 pairsfromthepost i.e.
pairs p s1 p s2 p s3 ... p s50 andthelabel of each pair is whether they have the same apis.
in total we have around .7m pairs to train the roberta based classification model.
we use the predicted possibility to rank the candidate posts.
.
search apis given a natural language described query q the first step is to retrieve the top k candidate questions from so.
clear first uses the trained roberta based sentence embedding model to transform itintoanembedding.
clearthenusesthefilter modeltofilterout irrelevantpostsandgetalistofcandidates postsbasedonthebertsentence embedding.
then in the re ranking phase the re ranking model calculates the probability that qand a given candidate post havethesamelabel weusetheprobabilitytorankthe50candidate posts.
we then extract the apis from the ranked posts and output themastherecommendationtothequery q.afterobtainingthe ranked list of candidate apis clear also summarizes supplementary information for qto describe the api usage examples and help users decide which api should be chosen for their tasks.
the supplementary information summarized by clear considers two aspects i.e.
the title of similar questions and code snippets from these questions.
note that clear recommends apis at method level by default.
it can be easily adapted to class level recommendations as well.
in thecaseofapiclasssearching weremovethemethodnameofthe candidate api to adjust the candidate api to the class level.
experiment design .
dataset to evaluate the performance of clear we reuse so data from the state of the artapproachbiker whichwerecollectedfrom theofficialdatadumpofsobyfollowingcriteria thequestion is related to java jdk programming the question should have apositivescore and3 atleast1answertothequestioncontains api entities and the answer s score should be positive.
theapiswereextractedfromthecodesnippetsinmarkdown scripts of the accepted answers in so.
in a markdown script code snippets are wrapped by code tags.
one can use regular expressions to localize the code snippets and further extract the apis.
in total biker sdataset contains 33k java relatedquestions.
biker alsoprovidedatestdatasetforevaluatingitsperformance which was manually created with a set of well designed criteria e.g.
one of their criteria is the score of the question itself should be at least five the details about the process are in their section .
the test datacontains413questionsalongwiththeirgroundtruthapis.we use the title of these questions as the query for api search.
notethat biker stestdatasetmainlycontainssopostswith highquality whichcannotreflecttheoverallqualityofsoposts.
thus wehavealsocreatedtwodifferentrandomtestdatasetswhich contain randomlyselected soposts forremoving human bias details are in section .
.
.
experiment settings weusegooglecolab professionalversionforfine tuningthe models.
the cpu we use is two intel xeon .20ghz cpu with 5gcache.thegpuresourceweuseisonenvidiav100graphic cardwith 13gmemory.wefine tunethefilteringmodel andthere ranking model for five epochs each and then select the model with the best performance on the validation set.
thetripletsgenerationalgorithminclearhastwoparameters i.e.
the number of positive samples p and the number of negative samples n which could affect the performance of clear.
to find the best values of these two parameters we tune them together.
for pandn we experiment with five discrete values i.e.
and15 whichresultsinacombinationof25model authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa moshi wei nima shiri harzevili yuchao huang junjie wang and song wang table1 performancecomparisonofdifferent p ositivesampling and n egative sampling settings.
p n1351015 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
configurations.
because the fine tuning on the full data is very time consuming we perform the grid search on the model witha quarter of the training data.
we train the filtering model until full convergence or up to epochs to sufficiently train the models.
the random seed is locked across the models to make sure the random samplingon positive and negativesamples is consistent.
werandomlyselect5kpostsasthetestdatafortuningthesetwo parameters andweusetheaccuracyofourfiltermodelasametric during our tuning.
following existing studies we use the accuracy 1asthemetricforparametertuning whichiscalculated as firstmatchiscorrect testinstances .
table shows the result of accuracy based on different parameter settings in which the row and column indices are the numbersofpositiveandnegativesamplesrespectively.overall the performance of clear increases with the increase of positive and negative samples and the performance of clear reaches the peakatthepointwherethenumberofpositiveandnegativesamplesare both equal to .
thus we set positive samples and negative samples for each training instance when training clear in ourexperiments.
in the case that there are less than positive and negative samples we include all positive and negative samples.
.
evaluation datasets tocomprehensivelyevaluatetheperformanceofclear weadopt three test datasets covering three different scenarios i.e.
highqualitysoposts i.e.
biker stestdataset real woldrandomso posts and so posts with multi api answers as our observationshows that around posts in so contain multiple apis.
the details of the three datasets are as follows biker test dataset is the evaluation dataset of biker whichcontains413manuallyselectedandverifiedsoqueries with api answers.
random test dataset contains 1k random selected so queries with api answers from biker s training dataset.
multi api test dataset contains 1k random so queries with multi api answers from biker s training dataset.
during our experiments questions from the test datasets and their duplicate questions were excluded from the training dataset.
.
baselines we compared clear with biker rack and deepapi which are three state of the art api recommendation techniques.
to show the impact of contrastive training we alsointroduce a variant of the filter model without adopting the con trastive training which is the pre trained roberta model.
notethat bikerandourclearshareacommonprocedure i.e.
afilter model to retrieve top k candidate posts and a re ranking modelto re rank the candidate posts.
thus we also introduce the filer models of biker and our clear as the baselines.
baseline1 biker first uses a mixture of tf idf and a trained word2vec model to calculate the similarity of a givenquery and the so posts and then the top posts are selectedas the candidates.
finally it re ranks the candidates by usingthe similarity between the query and the corresponding official apidocumentdescriptions.tocomprehensivelycompareitwith clear we employ two related baselines i.e.
biker filter biker without re ranking and biker complete the whole approach .
baseline2 rack isakeyword apimappingsystemthat recommends apis by matching keywords from the query.
the keyword api isconstructed bymining thestatistical relationship betweenthesoquestionsandtheacceptedanswersofquestions.
please note that rack only recommends api at the class level.
baseline3 deepapi modelsapirecommendationtaskas amachinetranslationproblem.itusesarecurrentneuralnetwork rnn encoder decodermodeltoencodeagivenqueryintoafixedlengthcontextvector andgenerateanapi methodsequencebased onthecontextvector.theauthorofdeepapiprovidedanonline toolfortestingandevaluation.however thewebsiteisnotavailablecurrentlyduetothebudgetlimit.initially wecontactedtheauthors for their trained models unfortunately the author claimed that they did not maintain the trained models anymore.
then we used its reproduction package6and rigorously follow its instruction tore trainthedeepapimodelfromscratchwithitsdataset.the training process takes days and we achieve similar performance regarding blue scores as reported in the paper of deepapi.
the reproductionmodelrepresentsthebesteffortwemadetoreproduce the deepapi model.
in this work the evaluation of the deepapi model is performed on the reproduced model.
baseline5 pre trained roberta filter is the pre trained robertamodel.wecompareclear filterwithrobertatoexplore the performance increase introduced by contrastive learning.
we use the same pre trained roberta model as used in clear.
baseline5 clear filter sinceclearhastwosteps i.e.
the filtermodel andthere rankingmodel weseparatethefiltermodelfromthere rankingmodeltoshowtheperformanceincreaseintroduced by both of them.
.
performance measures followingexistingstudies weusemeanreciprocalrank mrr mean average precision map precision k and recall k to evaluate the performance of api recommendation approaches.
mrr and map are the widely accepted measurements forinformationretrieval.mrrmeasurestheeffortneededtofind thefirstcorrectanswerintherecommendedlistandmapconsiders the ranks of all correct answers.
wealsoevaluatetheperformancewith precision kandrecall k wherekcan be and .
for the search result of a query precision and recall can be defined as follows precision k relevantitemsretrieved k retrieveditems authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
clear c ontrastive le arning for a pi recommendation icse may pittsburgh pa usa recall k relevantitemsretrieved k relevantitems where the relevantitemsretrieved refers to the number of correctlyrecommendedapi the retrieveditems referstothenumberoftotalretrievedapis andthe relevantitems referstothe number of apis in the answers of the queries.
.
research questions to evaluate theperformance of clear we design experiments to answer the following research questions rq1 how effective is clear comparing with existing api recommendation baselines at method level?rq2 how effective is clear comparing with existing api recommendation baselines at class level?rq3 how does random sampling of triplet generation affect the performance of clear?
in rq1 and rq2 we set out to investigate the performance of the clear on method and class level api recommendation tasks.
to demonstrate its advantages we compare clear with state ofthe art baselines details are in section .
.
in rq3 we explore the impact of the random sampling process in the triplet generation algorithm detailsareinsection3.
.
ontheperformanceofclear.
.
statistical testing in this paper we use a parametric test to check the statistically significant difference inthe performance of differentapi recommendationbaselines.weusetheparametricwilcoxonsignedranked test whichhasbeenwidelyusedinmanysoftwareengineering studies .
the advantage of the wilcoxon test is that it doesnotrequiretheresultstofollowanyspecificdistribution.a p value smaller than .
indicates that the difference between the two baselines performance is statistically significant.
result analysis thissection presentsourexperiment results andanswersthe three research questions asked in section .
regarding the effectiveness ofclearatmethod levelapirecommendation section5.
and class level api recommendation section .
and the impact of randomness in clear section .
.
.
rq1 effectiveness of clear at method level experimentalmethod .toanswerthisresearchquestion wecompare clear with the baselines listed in section .
on the three different test datasets listed in section .
.
note that we exclude rackinthisresearchquestionasitrecommendsapiatclass level only.
since biker s authors have published the replication package7 we directly use it to conduct experiments and compare with clear.
for deepapi as we described in section .
we use the re trained model for our experiments.
since deepapi recommends api sequence for a given query we consider a recommendation is correctifanyoneoftheapisinthesequenceisthegroundtruth of the query the same comparison manner has also been used in the comparison of biker and deepapi in biker s paper .
results.
table shows the result of clear compared with the other baselines.
as shown in the table overall clear outperformsbothbiker includingbothitsfiltermodelandre ranking model and deepapi.
notethat biker has the same performance reportedinthisworkanditsoriginalpaper .however different from the comparison reported in biker s paper where deepapi s mrr and map are .
and .
in this study deepapi reportsmuchworseperformance i.e.
allmrrsandmapsarebelow0.
.thereasonisthatinpaper deepapiwasevaluatedonthe online tool released by deepapi s authors we re trained deepapi withitsreproductionpackage detailsareinsection4.
.onbiker test data the recall of clear complete is .
indicating that there is at least one right answer in the first candidates in .
cases.
comparing the biker filter model and clear filter model theclear filtermodeloutperformsthebiker filtermodel by .
and .
on mar and map.
in terms of precision andrecall clear filtermodelimprovesthe precision by51.
.
.
.
recall 10by52.
.
.
.
respectively which shows the effectiveness of our filter model.
ontherandomtestdata clear completemodeloutperforms biker complete model in all the measurements.
comparing to biker completemodel clear completemodel improvesb y185.
on mrr .
on map .
.
.
.
onprecision and326.
.
.
.
on recall 10respectively.onmulti apitestdata clear complete mode outperforms biker complete mode by .
on mrr and .
onmap.intermsofprecisionandrecall clear complete improves the precision by .
.
.
.
and recall 10by301.
.
.
.
respectively.
compared to the roberta model clear s filtermodel achieves better performance on all the three test datasets whichindicatesthatcontrastivelearningcanhelplearnaprecise semantic representation of programming tasks.
we have also conducted the wilcoxon signed rank test p .
tocomparetheperformanceofclearandbaselines.thetest result suggests that clear achieves significantly better performance than all the baselines.
clear significantly outperforms the state of the art baselines at method level api recommendation and clear s performance remains stable across different test datasets.
.
rq2 effectiveness of clear at class level experimentalmethod .toanswerthisresearchquestion weperformthesameevaluationmethodonthebaselinesand clear.weusethesamethreetestdatasetswithapimethodsremovedtocom pareapianswersattheclasslevel.tocomparewithrack werunexperimentswithrack sreplication .forbothbikeanddeepapi we use the same manner as the experiment at method level api recommendation in section .
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa moshi wei nima shiri harzevili yuchao huang junjie wang and song wang table performance comparison at method level rq1 method level biker filter biker complete deepapi roberta clear filter clear complete biker test datamrr .
.
.
.
.
.
map .
.
.
.
.
.
precisionp .
.
.
.
.
.
p .
.
.
.
.
.
p .
.
.
.
.
.
p .
.
.
.
.
.
recallr .
.
.
.
.
.
r .
.
.
.
.
.
r .
.
.
.
.
.
r .
.
.
.
.
.
random test datamrr .
.
.
.
.
.
map .
.
.
.
.
.
precisionp .
.
.
.
.
.
p .
.
.
.
.
.
p .
.
.
.
.
.
p .
.
.
.
.
.
recallr .
.
.
.
.
.
r .
.
.
.
.
.
r .
.
.
.
.
.
r .
.
.
.
.
.
multi api test datamrr .
.
.
.
.
.
map .
.
.
.
.
.
precisionp .
.
.
.
.
.
p .
.
.
.
.
.
p .
.
.
.
.
.
p .
.
.
.
.
.
recallr .
.
.
.
.
.
r .
.
.
.
.
.
r .
.
.
.
.
.
r .
.
.
.
.
.
results.
table shows the result of clear compared with the otherbaselineapproachesattheclasslevel.overall clear outperforms other baselines on each of the three datasets.
among the three baselines similar to method level api recommendations biker reports better performance than rack and deepapi.
on biker test data the recall of clear complete is .
indicating that there is at least one right answer in the top three candidatesin80.
cases.comparingtheclear completemodel with rack the clear complete model outperforms rack by .
in mrr and .
in map.
in terms of precision and recall clear completeimprovesthe precision 10by236.
.
.
.
and recall 1by242.
.
.
.
respectively.
comparing the clear complete model with the biker complete model the clear complete model outperforms the biker complete model by .
in mrr and .
in map.
on the random test data clear outperforms rack biker and deepapi in all the measurements.
comparing the clearcomplete model with rack clear complete outperforms rack by .
in mrr .
in map .
in precision and .
in recall .
on the multiple api test data clear complete model outperforms rack by .
in mrr .
in map.
in terms of precision and recall clear complete outperformsrackthe precision 10by393.
.
.
.
and recall 10by399.
.
.
.
respectively.comparedtotherobertamodel clearfiltermodelachieves consistently better performance on each of the three datasets indicating the effectiveness of contrastive learning.
the wilcoxon signed rank test p .
also suggests that clear achieves significantly better performance than all other baseline approaches.
clear significantly outperforms the state of the art baselines atclass levelapirecommendationandclear sperformance remains stable across the three test datasets.
.
rq3 impact of random sampling experimentalmethod .inclear stripletgeneration forqueries with more than positive or negative samples clear randomly selects10foreachquery.tounderstandhowdoesrandomsamplingaffectstheperformanceofclear were runthetripletgeneration times.
please note that fine tuning the model with full training triplets is very time consuming so we perform this experiment on a subset of the training triplets containing 92k pairs i.e.
a quarter of the full training triplets .
result.
table shows the impact of random sampling on the performance of clear measured by the average error and coefficientofvariation cv .aswecanseefromthetable theaverage error on mrr is .
indicating that the difference of mrr introducedbyrandomsamplingbetweendifferentrunsis0.
on authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
clear c ontrastive le arning for a pi recommendation icse may pittsburgh pa usa table performance comparison at class level rq2 class level biker filter biker complete rackdeepapi roberta clear filter clear complete biker test datamrr .
.
.
.
.
.
.
map .
.
.
.
.
.
.
precisionp .
.
.
.
.
.
.
p .
.
.
.
.
.
.
p .
.
.
.
.
.
.
p .
.
.
.
.
.
.
recallr .
.
.
.
.
.
.
r .
.
.
.
.
.
.
r .
.
.
.
.
.
.
r .
.
.
.
.
.
.
random test datamrr .
.
.
.
.
.
.
map .
.
.
.
.
.
.
precisionp .
.
.
.
.
.
.
p .
.
.
.
.
.
.
p .
.
.
.
.
.
.
p .
.
.
.
.
.
.
recallr .
.
.
.
.
.
.
r .
.
.
.
.
.
.
r .
.
.
.
.
.
.
r .
.
.
.
.
.
.
multi api test datamrr .
.
.
.
.
.
.
map .
.
.
.
.
.
.
precisionp .
.
.
.
.
.
.
p .
.
.
.
.
.
.
p .
.
.
.
.
.
.
p .
.
.
.
.
.
.
recallr .
.
.
.
.
.
.
r .
.
.
.
.
.
.
r .
.
.
.
.
.
.
r .
.
.
.
.
.
.
table impact the random sampling in triplet generation metric mrrmap average error .
.
coefficient of variation cv .
.
average.thecoefficientofvariationiscalculatedby cv where isthestandarddeviationand isthemean.thecvofour result suggests that the difference introduced by random sampling is negligible.
theimpactofrandomsamplingintripletgenerationontheperformance of clear is negligible which shows the robustness of clear.
discussions thissectiondiscussesopenquestionsregardingtheperformance and threads to validity of clear .
.
why clear outperforms existing baselines?
to understand why clear significantly outperforms the baselinesintroducedinsection4.
wevisualizetheembeddingofthe api search space of the model before and after contrastive training.
specifically we use the uniform manifold approximation and projection umap approachtoreducethedimensionofthebert basedsentenceembeddingtotwodimensions.thenwelabel the embedding vectors with the hierarchical density based spatialclusteringofapplicationswithnoise hdbscan an unsupervised cluster classification approach for the coloring.
figure5showsthevisualization inwhichtheuppergraphshows thesentenceembeddingvisualizationofthetrainingsamplesonthe modelbeforeweapplycontrastivetraining inwhichthepointsrepresentthesentenceembeddingvectorsintwo dimensionalspaceandthecolorofthepointsindicatestheapis.fromthevisualization we can see that the majority of the apis are mixed and the boundary of each api is not clear.
this graph shows clearly that it is very hard to draw the decision boundary for different clusters in themodelbeforecontrastivetraining.sincethetrainingtargetof contrastivetrainingistominimizethedistancebetweensemantically equivalent sentences and maximize the distance between the irrelevantsentence themarginbetweenclustersshouldbelarger and clearer after training.
tosupporttheabovehypothesis wealsoapplythesamevisualization approach to the fine tuned model after we applied contrastive training.
figure lower graph shows the sentence embeddingvisualizationofthetrainingsamplesaftercontrastivetraining.
from this figure we can see clear cluster patterns of the query embeddingvectors.mostofthe apisarefromdenseclustersandthe marginspacebetweenclustersisrelativelyclear.thisvisualization supportsourhypothesisofcontrastivetraining meaningthatthe contrastive training does pull semantic equivalent queries together and separates the irrelevant vectors apart.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa moshi wei nima shiri harzevili yuchao huang junjie wang and song wang table5 recommendationresults i.e.
apisandtopsimilarquestions ofclearforexamplequeries.
indicatesthegroundtruth api and indicates the recommended api is incorrect.
question api answers input query how to convert dateformat fri jan gmt to java.sql.date java.text.simpledateformat.parse 1st how to parse thu aug ist to ?
java.text.simpledateformat.parse 2nd converting 15t20 .000z in gmt format using java java.text.simpledateformat.parse 3rd convert string date into java.util.date in the dd mm yyyy format java.text.dateformat.format 4th date format and the hour is always .
java.time.instant.parse input query how to retrive value from property file which are present outside of the app java.util.properties.load 1st how to close the fileinputstream while reading the property file java.util.properties.load 2nd using maven properties to connect to a database java.lang.system.getproperty 3rd why do we need properties class in java?
java.util.properties.load 4th issue reading a file path from a properties file java.util.properties.store figure5 visualizationofapiquestionsentenceembeddingbefore i.e.
the upper image and after i.e.
the lower image contrastive training.
.
clear in the real world practice we run clear biker rack and deepapi on recent javarelated questions from stack overflow9.
comparing the top recommended apis clear successfully recommends apis for queries biker successfully recommends apis for queries racksuccessfullyrecommendsapisfor4queries anddeepapi successfully recommends apis for queries.
weselectedtworandomexamplesthatcanbesolvedbyclearonly fordemonstration.table5showstherecommendationresultsof clear for the two example latest so posts.
the first example is about converting date formats we can see that clear can understandtheconceptoftimeinmultipleformatsandpickthekeyword convert correctly.theresultshowsthatclearisnotsuffering fromthelexicalsimilaritypitfallconcerningthetimeformatand the full list can be found in the reproduction packageis able to recommend correct apis.
the second example is aboutproperty file access the semantic of the question is how to load property files and the clear is able to get the keywords that are themostrelatedtothe question i.e.
propertyfile and retrieve .
we also see that the keyword reading the synonym of retrieve is correctly recognized as well.
throughtheabovetwocasestudies wecanseethattheclearis more effective in capturing the semantic of the api queries regardless of the lexical information thus can be used for api recommendation in a real world application.
.
threat to validity internalvalidity .ourcodehasbeencheckedtoensureourimplementationiscorrectandthequestionsinthetestingdatasetarenotincluded in the question base.
we reuse the replication packages of the baselines to ensure their correctness.
in addition although the dataset collected from so is being filtered by heuristic rules there arestillnoisesinthedatasetduetotheopennessofso whichmay affect the performance of the clear.external validity .
in this work we used the dataset published bybikertodemonstratetheeffectivenessofclear whichonlysupportsjavaapi recommendations.theperformanceofclear canbedifferentonapirecommendationforotherprogramming languages.
in addition as the dataset only contains questions from stackoverflow clearmightperformdifferentlyondatacollected fromotheronlineforums.futurestudyisneededtoexaminethe performance of clear on data from other sources.constructvalidity weusemrr map precision k andrecall k tomeasuretheperformanceofapirecommendation our approachmighthavedifferentperformanceunderothermetrics.in this work we assume that so questions with the same api answer assemanticallyequivalentwhencontrastivelytrainingourbertbased sentence embedding.
future study is needed to examine our assumption on api q a pairs from other sources or other tasks.
related work .
api recommendation therearemanyexistingstudiesonapirecommendation including api invocation sequences mining dependency graphbased api phrases mining api recommendation for feature authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
clear c ontrastive le arning for a pi recommendation icse may pittsburgh pa usa requests query api keyword mapping with crowed knowledge code snippet synthesis similarity based api recommendation with language model and api recommendation basedonsimilarityoffunctionalityverbphrasesinfunctionality descriptions and user queries .
mcmillan et al.
first presented portfolio an api recommendation tool that returns code snippets for a programming query.
thungetal.
introducedhistoricalfeaturerequestscombined with official api documents information for api recommendation for new feature requests.
nguyen et al.
proposed gralan a graph based language model for object oriented source codes.
liu et al.
improved the ranking of the top result of gralan by introducing api usage path information to the graph system.
nguyen et al.
used statistical learning on the commit changes informationforapirecommendation.guetal.
firstintroduced a deep learning model to api learning which achieves end to end api sequence generation.
clear uses roberta as the base model which is different from deepapi.
rahman et al.
presented rack an api recommendation tool leveraging the real api usage datafromstackoverflow .thedifferencebetweentherack andclearisthatclearusesalanguagemodelinsteadofkeywordmapping.
huang et al.
proposed biker which filters the candidate apis based on the similarity against so questions and then re ranks the candidates based on the similarity against officialapidocumentationdescription.themaindifferencebetween biker and clear is that clear uses contrastive training instead of unsupervised training in the model building stage.
.
api usage pattern mining xieetal.
proposedmapo anapiusagepatternminingtool withvariouscodepatternminingalgorithms.thummalapentaet al.
proposed parseweb a java code reuse example generationtoolbuilduponopen sourcejavacodedata.tsengetal.
proposed up miner a toolset that contains thirteen java utility codepatternminingalgorithmsthatimprovetheperformanceof up miner.fowkesetal.
presentedpam aparameter freeprobabilisticalgorithmforminingtheapiusagepatterns.wenetal.
proposedanapimiss usedetectiontoolthatcandetectapimisuse patternsofjavalibraries.chenetal.
firstappliedanunsupervisedtechniquetocreateanalogicalapimappingsofthird party libraries.renetal.
builtanapi constraintknowledgegraph for api misuse detection purpose.
conclusion in this paper we propose clear a novel approach for api recommendation.
clear uses the bert based model for embedding which produces the embedding of the whole sentence of an api querywhileconsideringsemantic relatedsequentialinformation.ituses contrastive training to better capture the semantics of the api queries regardless of the lexical information.
our experiment resultsconfirmtheeffectivenessoftheclearforbothmethods and class levelapirecommendation.ourcasestudywithclearon the latest so posts further demonstrates its practical value.
inthe future we plantoextendcleartoother taskssuchas third party api recommendation linux command search code snippet search and program patch search.