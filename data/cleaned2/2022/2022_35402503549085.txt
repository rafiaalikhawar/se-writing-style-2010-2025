fuzzing deep learning libraries via automated relational api inference yinlin deng university of illinois at urbana champaign usa yinlind2 illinois.educhenyuan yang university of illinois at urbana champaign usa cy54 illinois.edu anjiang wei stanford university usa anjiang stanford.edulingming zhang university of illinois at urbana champaign usa lingming illinois.edu abstract deep learning dl has gained wide attention in recent years.
meanwhile bugs in dl systems can lead to serious consequences and may even threaten human lives.
as a result a growing body of research has been dedicated to dl model testing.
however there is still limited work on testing dl libraries e.g.
pytorch and tensorflow which serve as the foundations for building training and running dl models.
prior work on fuzzing dl libraries can only generate tests for apis which have been invoked by documentation examples developer tests or dl models leaving a large number of apis untested.
in this paper we propose deeprel the first approach to automatically inferring relational apis for more effective dl library fuzzing.
our basic hypothesis is that for a dl library under test there may exist a number of apis sharing similar input parameters and outputs in this way we can easily borrow test inputs from invoked apis to test other relational apis.
furthermore we formalize the notion of value equivalence and status equivalence for relational apis to serve as the oracle for effective bug finding.
we have implemented deeprel as a fully automated end to end relational api inference and fuzzing technique for dl libraries which automatically infers potential api relations based on api syntactic semantic information synthesizes concrete test programs for invoking relational apis validates the inferred relational apis via representative test inputs and finally performs fuzzing on the verified relational apis to find potential inconsistencies.
our evaluation on two of the most popular dl libraries pytorch and tensorflow demonstrates that deeprel can cover more apis than state of the art freefuzz.
to date deeprel has detected bugs in total with already confirmed by the developers as previously unknown bugs.
surprisingly deeprel has detected .
of the high priority bugs for the entire pytorch issue tracking system both authors contributed equally to this research.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore association for computing machinery.
acm isbn .
.
.
.
a three month period.
also besides the code bugs we have also detected documentation bugs all confirmed .
ccs concepts software and its engineering software testing and debugging software reliability .
keywords fuzz testing oracle inference deep learning differential testing acm reference format yinlin deng chenyuan yang anjiang wei and lingming zhang.
.
fuzzing deep learning libraries via automated relational api inference.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
introduction recent years have witnessed the surge of deep learning dl in a variety of applications including computer vision natural language processing robotics bioinformatics and software engineering .
meanwhile similar to traditional software systems dl systems can also have bugs which can lead to serious consequences and may even threaten human lives .
to date most prior work on dl testing focused on testing verifying dl models with an emphasis on adversarial attacks metrics for model testing applicationspecific model testing and verifying certain properties of models .
meanwhile there is limited work targeting the reliability of dl libraries which serve as the central infrastructures for building dl models and are the foundation for training and deploying dl models.
cradle is one of the trailblazing work on testing dl libraries which resolves the oracle challenge with differential testing of various dl models on multiple backends of keras .
audee and lemon further augment cradle by leveraging search based mutation strategies to generate more diverse dl models inputs for testing library code.
different from the above model level dl library testing techniques more recently freefuzz has been proposed to mine example inputs from open source including code snippets from the library documentation developer tests and dl models in the wild to directly test each esec fse november singapore singapore yinlin deng chenyuan yang anjiang wei and lingming zhang dl library api in isolation.
freefuzz has been evaluated on pytorch and tensorflow currently the two most popular dl libraries with 54k 162k stars on github .
the experimental results show that freefuzz can cover more apis than state of the art lemon and detect various previously unknown bugs.
despite the promising results existing techniques for fuzzing dl libraries still suffer from the following limitations.
first the input generation is still far from optimal.
cradle and audee can only test apis that are covered in the original models and lemon can cover slightly more apis with layer mutations furthermore although freefuzz can cover up to apis for pytorch and tensorflow which is already a huge improvement over other work it is still unable to test an api if there is no code snippet directly invoking the api.
second there is still a lack of powerful test oracles.
existing techniques typically perform differential testing across different dl libraries or hardware backends e.g.
gpu cpu to address the test oracle issue.
however differential testing across dl libraries is typically applied at the model level and suffers from the limited effectiveness of model level testing e.g.
limited api coverage and accumulated floating point precision loss while different backends often share common code logic design and thus may also share similar bugs .
thus it is also crucial to investigate novel test oracles for effective dl library fuzzing.
to address the aforementioned limitations in this work we open a new dimension for testing dl libraries via automated relational api inference.
the inspiration stems from the fact that prior work has discovered a number of equivalent apis in traditional software systems e.g.
java projects .
we envision such relational api inference also to be an inspiring direction for fuzzing dl libraries.
in this way given the same inputs generated via fuzzing apis that are equivalent in functionality should produce the same numerical results i.e.
value equivalence .
moreover besides the previously studied equivalent apis we further leverage the fact that dl apis with similar functionality should behave similarly in terms of program status i.e.
status equivalence for more effective fuzzing.
for example although adaptiveavgpool3d andadaptivemaxpool3d in pytorch are not equivalent they are functionally similar apis thus we can feed any valid input of the first api to the second api and expect its invocation to also be successful.
based on this intuition we can easily borrow test inputs generated for one api to test other relational apis.
also api relations can directly serve as test oracles for differential testing.
therefore we can easily overcome the aforementioned limitations.
we have built a fully automated technique deeprel which infers such api relations without human intervention for fuzzing dl libraries.
one key challenge is how to obtain the api relations automatically and accurately.
existing work on equivalent api inference for traditional software systems can hardly be applied for dl library testing e.g.
the most recent memo work heavily relies on well documented api relations which are rare in dl libraries.
to this end deeprel first automatically infers all possible candidate api pairs that are matched based on api syntactic and semantic information.
then deeprel synthesizes concrete test programs for those potentially relational apis.
after that deeprel 1some of such existing work treated the entire software systems under test as the test objects and thus viewed this as metamorphic testing .
in this paper we treat each api as a test object and view this as differential testing .
figure background knowledge on dl models and apis leverages a set of representative valid inputs automatically traced during prior normal api executions to check whether the inferred api relations hold or not.
lastly deeprel takes the validated api pairs and leverages mutation based fuzzing to generate a much more diverse and extensive set of test inputs for detecting potential inconsistencies among relational apis.
our study has shown for the first time that there can be a surprising number of equivalent or similar apis within popular dl libraries e.g.
verified relational api pairs by deeprel for pytorch tensorflow which can substantially help with fuzzing dl libraries and beyond .
in summary our paper makes the following contributions dimension.
this paper opens a new dimension for fullyautomated dl library fuzzing via relational api inference.
technique.
we build deeprel a fully automated end toend framework for dl library testing.
deeprel automatically infers all possible candidate relational apis based on both api syntactic and semantic information and then dynamically verifies them via test program synthesis.
while this work focuses on dl libraries the basic idea of deeprel is general and can also be applied to other software systems.
evaluation and impact.
deeprel covers more apis than prior work i.e.
improvement and has detected bugs in total with already confirmed by the developers as previously unknown bugs.
surprisingly deeprel was able to detect .
of the high priority bugs for the entire pytorch issue tracking system in a three month period.
also besides the code bugs we were able to detect documentation bugs all confirmed as a by product of our experimentation.
background .
basics about dl models and apis for dl models inference is the process of using a fixed dl model to complete a specific task while training is the process of updating the weights of a neural network to better perform a certain task given the labeled data under the scenario of supervised learning .
we next shed light on how this is achieved by apis from dl libraries.
dl models.
to build and run a dl model developers first need to define the model by writing a dl program in dl libraries e.g.
pytorch and tensorflow .
take the dl program neta written in pytorch shown on the left side of figure as an example it includes a convolution layer conv2d a max pooling layer maxpool2d and a linear layer linear .
the function forward defines how the input tensor x should flow in the defined layers and other related apis .
besides input tensors there are also weight 45fuzzing deep learning libraries via automated relational api inference esec fse november singapore singapore tensors e.g.
w1and w2shown on the right side of figure .
their values will be updated during training the process of which is called back propagation a procedure natively supported by dl libraries.
training the model is achieved by first running the forward part i.e.
inference of the neural network out net data computing the loss loss crossentropyloss label out computing the gradient loss.backward and invoking the optimizer optimizer.step for back propagation.
dl apis.
when running a dl model the apis involved in building the model are also executed.
essentially writing a dl program can be viewed as defining a computation graph .
it is a directed acyclic graph dag whose nodes are dl apis while edges are the flow of the tensors.
figure also shows the computation graph composed of three parts forward part taking input tensors and weight tensors as input loss computation part requiring label tensors and backward part for updating weight tensors .
actually the backward part needs to construct a very complex graph but we omit it in figure for simplicity.
essentially running a whole dl model can be broken down into invoking a series of dl apis based on the topological sorting of the computation graph.
.
fuzzing dl libraries to our knowledge there are mainly two categories of work for fuzzing dl libraries model level testing and api level testing.
model level testing.
cradle is one of the first to apply differential testing for dl libraries.
since keras is a library featuring high level apis for building dl models apis in keras may have multiple implementations in its supported lower level libraries.
thus cradle takes pre trained dl models as input and runs differential testing to find inconsistencies between different low level libraries for keras.
more recently audee and lemon have proposed to use search based mutation strategies to generate mutated dl models for differential testing on different backends.
while audee focuses on mutating parameters of layers weight tensors and input tensors lemon applies mutation rules by adding deleting layers and changing the values of weight tensors.
in this way lemon s mutation rules are more general and can cover more apis than the original models.
however even lemon s mutation can only be applied to a limited number of apis.
for instance its intact layer mutation rule requires that the output tensor shape of the api to be added deleted should be identical to its input tensor shape making a large number of apis inapplicable for mutation.
researchers have recently shown that lemon can hardly invoke additional library code apis with its mutation rules e.g.
covering only apis in total for tensorflow .
very recently liu et al.
proposed nnsmith which leverages lightweight specifications for more diverse model generation.
meanwhile it also mainly focuses on commonly used apis operators.
api level testing.
different from prior work on dl library fuzzing the recent freefuzz work proposes to directly mine test inputs from open source for api level fuzzing a much finer grained level than model level testing.
one challenge is that python is a dynamically typed language making it hard to determine the types of api parameters for fuzzing python apis.
prior work has to manually set up the api arguments and thus can only test a small1result1 torch.broadcast shapes shapes 2result2 torch.broadcast tensors map torch.empty shapes .shape figure api pair with the same output number of apis e.g.
predoo can only test apis for tensorflow.
a very recent work docter constructs rules to extract dl specific input constraints from api documentation and uses them to generate valid invalid inputs for testing dl libraries meanwhile it requires manual annotation for of api parameters.
in contrast freefuzz resolves this challenge fully automatically via dynamically tracing api executions in code snippets from the documentation developer tests and dl models.
more specifically freefuzz records the traced argument values in a database and further performs mutation based fuzzing to mutate those traced values to generate even more inputs for fuzzing dl library apis.
lastly freefuzz applies differential testing on different hardware backends i.e.
cpu gpu for detecting potential consistency bugs.
despite its big improvement over prior work freefuzz can only test apis for pytorch and tensorflow which are the ones covered in its input mining stage leaving a total of apis uncovered.
also different hardware backends may still share code logic design causing the differential testing oracle used by freefuzz to miss various bugs.
in this work we propose to test relational apis to further overcome such limitations.
we build our technique deeprel upon freefuzz to automatically infer relational apis and leverage them to fuzz dl libraries.
note however that our deeprel idea is general and can be built on any api level fuzzer for dl libraries e.g.
docter .
we choose freefuzz since it is a recent state of the art technique that is both publicly available and fully automated.
preliminaries we first introduce the preliminaries for our fuzzing technique in this section.
given the set of all possible apis a for a dl library under test we aim to define the relational property between the invocation results of a source api s a and a target api t a. intuitively we can directly check whether sandtproduce equivalent outputs.
for example figure shows an api pair which according to the pytorch documentation should always produce the same results.
the broadcast shapes api applies broadcasting on a list of compatible shapes to align them while the broadcast tensors api applies broadcasting on a list of shapecompatible tensors to align their shapes.
in fact the first api can be rewritten as creating intermediate empty tensors from tensor shapes with mapand torch.empty calling broadcast tensors with these tensors and getting the shape of the output tensor.
since the source and target apis can achieve the same functionality with totally different implementations given the same input shapes in figure they provide a great opportunity for differential testing .
therefore we have the following formal definition definition .
.
equivalence value.given a set of inputs d source apis a and target api t a satisfy equivalence value modulo d iff their invocations always output the same results given any input ind.
formally s t modd x d.s x t x while this can be effective in detecting potential consistency bugs the checking is too strict and may not apply to a large number 46esec fse november singapore singapore yinlin deng chenyuan yang anjiang wei and lingming zhang 1layer1 torch.nn.adaptiveavgpool3d output size 2result1 layer1 input 3layer2 torch.nn.adaptivemaxpool3d output size 4result2 layer2 input figure api pair with different outputs but same status of apis.
in fact it could be possible that sandtproduce totally different results but tend to behave similarly given similar inputs.
for example the api pair shown in figure does not satisfy the equivalence value property since the output of adaptiveavgpool3d is different from adaptivemaxpool3d .
the first api applies a 3d adaptiveaverage pooling over an input but the latter applies a 3d adaptivemaximum pooling.
however these two apis do share certain functionality in common since both of them apply a pooling operation which is also valuable for testing.
therefore we further abstract the invocation result of a program into a set of coarse grained statuses success exception and crash .success denotes that program executions terminate normally while exception means that program executions throw known exceptions.
lastly crash represents the cases where the program executions crash with unexpected errors e.g.
segmentation faults or internal assert failed errors which are never acceptable as commented by pytorch developers .
we then further introduce the notation of success exception crash to return the execution status of an input program.
for example s x success indicates that s terminates normally with the input x. in this way we can define another property for checking potential consistency definition .
.
equivalence status .given a set of inputs d source apis a and target api t a satisfy equivalence status modulo d iff their invocation always output the same statuses given any input ind.
formally s t modd x d. s x t x to conclude the equivalence status relation is a relaxed notation for the equivalence value relation which is in turn a relaxed notation of semantic equivalence denoted as s t .
formally s t s t modd s t modd one crucial component of these two definitions is the domain d on which the properties are constrained.
aiming for more accurate api relations it would be beneficial to cover more representative test inputs within the intersection of the valid input space of the source and target apis as the domain.
fuzzing relational apis figure shows the overview of our deeprel technique for fuzzing relational apis of dl libraries.
deeprel takes as input the targeted dl library its api documentation and a database of valid historical api invocations e.g.
automatically collected via running documentation examples library tests and dl models .
each entry of the database contains the concrete argument values passed into an api during an invocation and is obtained through dynamic tracing.
overall deeprel performs the following four phases iteratively api matcher section .
.
in order to test a dl library which typically has hundreds or even thousands of apis the first challenge is to identify the api pairs that are likely to satisfy the desired properties equivalence value or equivalence status .
api matcher mapseach api into embeddings based on api documentation and uses embedding similarity to identify candidates of api pairs.
invocation synthesizer section .
.
given a collection of potential api pairs invocation synthesizer decides how to invoke them.
to construct valid invocations for later verification we impose a constraint on the source api it must have at least one valid invocation in the database.
in this way given an invocation of the source api invocation synthesizer aims to synthesize the invocation code for the target api.
api match verifier section .
.
given the invocation code of matched apis this phase would check whether each api pair satisfies property equivalence value or equivalence status with a set of representative inputs as the verifying test inputs.
if the result values resp.
execution statuses are consistent for all tests then api match verifier accepts the api pair as equivalence value resp.
equivalence status .
if api match verifier detects any inconsistency in this phase it then rejects the api pair.
api fuzzer section .
.
the last step is to leverage the verified api pairs to detect potential consistency bugs.
api fuzzer uses mutation based fuzzing to generate a large number of test inputs for source apis and tests the verified api pairs with oracles section .
lastly recall that in order to generate valid inputs the source api must have at least one valid invocation in the database.
deeprel further adopts an iterative process to cover more api pairs section .
.
the newly generated valid target api invocations can be added to the database to serve as the source apis for the next iterations to detect more potential api pairs.
the following sections would explain each phase in detail.
.
api matcher in this phase deeprel identifies potential matched api pairs from the documentation.
deeprel uses api matcher to infer similar api pairs as candidate pairs which will be further verified later .
api matcher would map each api into its embeddings and compute the cosine similarity of embeddings to be the similarity of each api pair.
we consider signature similarity anddocument similarity that cover both api syntactic and semantic information for similarity computation.
overall for each api pair the similarity is defined as the maximum of the two simapi s t max simsig s t simdoc s t we compute the pair wise similarity for every api pair and pair each api with its k closest neighbors as the candidate pairs.
kis a hyper parameter and is set to 10in the default setting of deeprel.
notably we also analyze the impact of different values of kin our experimental study section .
.
signature similarity.
the signature of an api contains the api name and an ordered list of argument names.
the apis that will be paired typically have signatures that follow a similar syntactic pattern.
for example the api pair tf.maximum and tf.minimum satisfies equivalence status and their signatures are very similar tf.maximum x y and tf.minimum x y .
we map an api signature into its tf idf term frequency inverse document frequency embedding and compute the embedding similarity.
tf idf has been widely adopted in the field of information retrieval and it reflects the importance of each word in a document.
some common words like tfand torch in the api signature are 47fuzzing deep learning libraries via automated relational api inference esec fse november singapore singapore api matcher api fuzzer invocation synthesizer invocation code consistent?
accept api match reject api matchcrash?
torch.tensor split input indices or sections dim torch.tensor split torch.vsplittensor torch.rand torch.size dtype torch.float32 sections 0api match verifier valid inputs for srcapi inconsistent?tensor torch.rand torch.size dtype torch.float32 sections candidates of matched api pairstorch.tensor split input indices or sections dim splits a tensor into multiple sub tensorsapi documentations differential testing res1 torch.vsplit tensor sections res2 torch.tensor split tensor sections dim torch.allclose res1 res2 true?
torch.vsplit torch.tensor split differential testing res1 torch.vsplit tensor sections crashres2 torch.tensor split tensor sections dim error raisedtorch.allclose res1 res2 true?api matching modeltorch.vsplit input indices or sectio ns splits input into multiple tensors vertically.
input indices ...input indices ...dimargument matching vsplit tensor splittemplate matching torch.tensor split input indices or secti ons dim database mutation oracle inconsistency?
this is equivalent to calling torch.tensor split input indices or sections dim vsplit tensor splitinvocation code valid inputs for tgtapi potential bugs figure deeprel overview less informative so their tf idf weights tend to be smaller.
to obtain the tf idf embedding for each api we first break the api signatures into subwords also called tokens and then standardize them.
letndenote the size of the vocabulary from all the tokenized api signatures an api scan be represented as an unnormalized term frequency embedding cs cs ... csn wherecs jis the number of occurrences of word jin the api signature of s. we further normalize it with the inverse document frequency for each word to get the tf idf embedding repsig s cs 1 s acs cs 2 s acs ... csn s acs n the cosine similarity of two vectors is the cosine of the angle between them and thus always belongs to the interval .
the cosine similarity of two arbitrary vectors x yis defined as follows cos x y x y x y we then compute the cosine similarity between the tf idf embeddings to be the signature similarity of two apis s t simsig s t cos repsig s repsig t document similarity.
to complement the signature similarity we further model the semantic similarity between api documents.
first we extract all api descriptions from the documentation each of which is a one sentence summary of an api given at the beginning of the document.
for example api torch.vsplit is described as splits input a tensor with two or more dimensions into multiple tensors vertically according to indices or sections.
the description succinctly and surgically states the expected input the transformation applied and the expected output.
next we use sentencebert to encode these informative description sentences into semantically meaningful sentence embeddings.
the sentence bert encoder takes a natural language sentence as input and outputs a vector in high dimensional space it targets specifically at generating embeddings whose cosine similarity reflects the semantic textual similarity.
we use s.description to denote the description for the api s and usesbencoder to denote the sentence bertencoder.
for each api s we obtain its document embedding as repdoc s sbencoder s.description for each api pair s t we compute the cosine similarity between their document embeddings as their document similarity simdoc s t cos repdoc s repdoc t .
invocation synthesizer in this phase we leverage argument matching and template matching to synthesize the invocation code for each matched api pair.
note that the invocation code of source api is simply the code snippet that directly invokes the source api.
therefore we will next focus on generating the target api invocation code.
argument matching.
for each candidate api pair deeprel first synthesizes the invocation code based on api definitions.
it maps the arguments of the source api to the arguments of the target api to synthesize the invocation code of the target api with the arguments from the source api .
we transform the argument matching problem into a maximum weighted bipartite matching problem .
deeprel generates the invocation code based on the best argument match.
more formally given the source api s the target api t and their argument lists s.args andt.args the corresponding bipartite graph is g l r e wherel a a s.args r b b t.args ande a b a l b r .
the weight of each edge a b eis the similarity simarg a b ofaandb which is defined as simarg a b simname a b simtype a b simpos a b the similarity simarg a b is determined by the names potential types and positions of the arguments.
first the similarity of the names is computed based on the following formula simname a b levenshtein aname bname max len aname len bname whereaname is the name of argument a. this similarity is based on the levenshtein distance between the two names.
next we compute the similarity of two type sets as simtype a b atype btype atype 48esec fse november singapore singapore yinlin deng chenyuan yang anjiang wei and lingming zhang figure example weighted bipartite graph torch .
vsplit torch .
tensor split dim figure invocation synthesis via argument matching whereatype is the set of possible types of a. if the set of types that argumentbcan take contains all possible types of a ais more likely to be mapped to bsince all types of aare legal for b. we also compute the positional similarity of two arguments as simpos a b aidx bidx max len s.args len t.args whereaidxis the index of ains s argument list.
for example if a andbare both the first argument for sandt then aidx bidx equals to 0and thus their positional similarity is .
after constructing the graph deeprel leverages kuhn munkres algorithm to find the best argument match and synthesizes the invocation code based on it.
when the source and target apis have the same number of arguments deeprel will synthesize the invocation code based on the best argument match directly.
otherwise if any non optional argument is unmatched deeprel will abort for the current api pair since the search space for determining the values of unmatched non optional arguments is huge.
that said deeprel only considers the case where the optional arguments of the source or target api are unmatched.
for the unmatched optional arguments deeprel just uses their default values python optional arguments always have default values .
take an api pair vsplit and tensor split for example whose weighted bipartite graph is shown in figure .
for each vertex its name and type information are marked next to it such as vertex a1 whose argument name is input possible type set is composed oftensor and index is .
the weight on each edge is the similarity between the two arguments.
for vertices a1andb1 since they have exactly the same name possible type and index their similarity is3.
fora1andb2 their names are different but the type set of a1is the subset of b2 s so they have a relatively high similarity .
.
however for a2andb1 only one type of a2is legal forb1 causing their similarity to be low .
.
thus the best match in the graph is a1 b1 a2 b2 leavingb3 the optional argument dim unmatched.
then deeprel sets dimas its default value 0to generate the invocation code as shown in figure where placeholders i indicate the argument mapping between source and target apis .
note that for each argument of each api we gather its possible types from open source.
to be precise we extract the argument type information from all the traced invocations of the api to form the possible type set.
the type set could be incomplete since it relies on the traces.
when no traces cover a particular argument bof a target api the type set btype will be empty thus the type similarity betweenband any other argument awill besimtype a b .
note a documentation of tf.scatter nd tf.
scatter nd tf.
tensor scatter nd add tf.
zeros .
dtype b invocation code from template figure invocation synthesis via template matching that the argument matching algorithm still works in this case with only the name and positional similarities being considered.
template matching.
for some complex api pairs deeprel cannot leverage argument matching to generate the correct invocation code of the target api.
figure 7b shows the right invocation code between scatter nd and tensor scatter nd add .
obviously argument matching fails to synthesize the complex invocation code of tensor scatter nd add in which case a matching template can be useful.
a matching template is a code snippet elaborating a matched api pair.
it presents an invocation of the target api whose inputs are obtained from the arguments of the invocation of the source api.
figure 7a shows an example matching template highlighted with underline from the documentation of tf.scatter nd .
it suggests that invoking scatter nd is equivalent to invoking tensor scatter nd add with proper argument mappings as shown in figure 7b.
to automatically detect such templates deeprel examines each code block in the documentation.
whenever a code snippet contains the invocation of another api deeprel extracts it as a potential candidate.
note that not every api pair has such templates.
if deeprel failed to extract any the matching template will simply be none.
for api pairs with a matching template regardless of whether it is in top ksimilar pairs deeprel synthesizes additional invocation code using the matching template as the target api invocation code.
.
api match verifier in this phase deeprel runs the invocation code synthesized for each matched api pair over a set of verifying inputs to validate properties equivalence value and equivalence status defined in section .
the verifying inputs are a collection of valid inputs for the source api.
these inputs can be collected from the documentation library tests and existing dl models so that they are representative of the valid input space of the source api.
for example in our implementation we leverage state of the art freefuzz which can collect all such information fully automatically.
equivalence value .
deeprel first checks whether a candidate api pair satisfies the equivalence value property given the verifying inputs.
if so deeprel accepts this matching pattern and marks it as equivalence value .
take the api pair in figure 7b for example scatter nd always has the same output as tensor scatter nd add for all verifying inputs.
hence it is labeled as equivalence value .
equivalence status .
if the api pair violates equivalence value deeprel further checks whether the source and target api have the same status given verifying inputs.
if so deeprel accepts this api relation as equivalence status .
for instance the equivalence value property does not hold for the pattern shown in figure since the output of adaptiveavgpool3d is different from adaptivemaxpool3d 49fuzzing deep learning libraries via automated relational api inference esec fse november singapore singapore over the input set.
however the equivalence status property holds as they always have the same status over the verifying inputs.
if an api pair is verified as equivalence value or equivalence status it will be accepted by the api match verifier and further tested in the next fuzzing phase otherwise deeprel rejects this pair.
please note that it is crucial to have a set of representative verifying inputs.
if the verifying inputs are not representative the api match verifier could mistakenly accept a wrong api relation when the verifying inputs do not cover certain important regions of the possible input space.
we will study such false positives in detail in our experimental study section .
.
on the other hand the api match verifier may also reject some true matched api pairs if the verifying inputs directly trigger real consistency bugs in this phase.
although it is hard to avoid such false negatives our experimental results show that deeprel detects bugs for popular dl libraries fully automatically demonstrating the effectiveness of this design.
.
api fuzzer in the last phase deeprel further leverages the verified api pairs to detect bugs for dl libraries.
specifically deeprel applies off theshelf mutation based fuzzing techniques to mutate the source api inputs for generating diverse inputs for differential testing.
for equivalence value the source and target apis are expected to have the same output.
we can detect consistency bugs by comparing the results of the source and target apis.
for equivalence status the source and target apis are expected to have the same status.
thus we compare their statuses to detect bugs.
.
the iterative process in order to cover more apis by matched api pairs deeprel performs the above four phases iteratively until the fixed point or a given number of iterations i by default .
in the api match verifier phase if the target api is not covered in the current iteration and its invocation generated by the synthesizer has success status we will add this invocation into the database even when the corresponding api relation got falsified and label the target api as newly covered api .
after this iteration if there is any newly covered api deeprel will re run the framework with these newly covered apis as the source apis otherwise the fixed point has been reached and deeprel will terminate.
it is worth mentioning that the entire iterative deeprel approach is fully automated.
for the newly covered apis the verifying inputs are also automatically borrowed from the source apis valid inputs.
figure presents one example of this iterative process.
in the first iteration the api match verifier takes api pair torch.vsplit torch.tensor split as input and queries the invocation database 1to get a record for torch.vsplit .
invoking torch.tensor split 2results in success .
assuming that torch.tensor split is not covered in the database at the beginning of the iteration this successful invocation is then inserted into the database .
in the next iteration this invocation record will be retrieved 1to verify the matched api pairs with torch.tensor split as the source api.
experimental setup in the experiments we address the following research questions rq1 how effective is deeprel in terms of api coverage?
rq2 what is the false positive rate of deeprel?
rq3 how do different configurations affect deeprel?
rq4 can deeprel detect real world bugs?
our experiments are performed on pytorch .
and tensorflow .
the latest stable release versions for the two most popular dl libraries with 54k 162k stars on github which are the most widely studied dl libraries in prior dl library testing work .
we run all experiments on a machine with an core .20ghz intel cpu 16gb ram and ubuntu .
.
.
implementation api matcher .
to find high quality matched api pairs we first use the bs4 python package to parse the documentation of all apis from tensorflow and pytorch.
we collect both api signatures and descriptions from the documentation.
before computing the tf idf embedding we use the snowball stemmer to convert tokens into word stems.
as for the document embedding we use the sentencetransformer python package and adopt the pretrained model all minilm l6 v2 as oursbencoder .
invocation synthesizer .
for argument matching we use the munkres python package implementing the kuhn munkres algorithm to solve the maximum weighted bipartite matching problem.
for template matching we automatically search and extract the code snippets for matching templates from the documentation.
api match verifier .
we verify the relation of candidate api pairs with a set of representative valid inputs.
we obtain the valid inputs traced from various input sources used by state of the art freefuzz which include the documentation developer tests and dl models and are representative to verify the function of apis.
we feed a maximum of 100valid invocations of the source api from the freefuzz database into both the source api and target api as the verifying inputs and check if they have consistent behaviors.
api fuzzer .
we leverage the fuzzing strategies of freefuzz to mutate all the valid inputs traced for each source api within the freefuzz database and run all the generated inputs for each source api following the default setting of freefuzz on both the source api and target api to detect consistency bugs.
.
metrics of covered api .
following prior work in dl library testing we report the number of covered apis.
an api is covered by deeprel if it is successfully invoked by api match verifier either as a source api or a target api i.e.
invocations with the success status .
since dl libraries contain a large number of apis api coverage is an important metric of test adequacy.
false positive rate .
if an api pair satisfies that at least one of its invocation code is accepted by the api match verifier and at least one of its accepted invocation code is against its labeled property during the fuzzing phase it is named an inconsistent api pair.
the false positive rate for inconsistent api pairs is the proportion of detected inconsistent api pairs which are false alarms.
it is commonly used in prior work on fuzzing or testing .
of detected bugs.
bug finding is the ultimate goal for fuzzing and thus we also report the number of distinct bugs deeprel finds.
50esec fse november singapore singapore yinlin deng chenyuan yang anjiang wei and lingming zhang table comparison with freefuzz on api coverage total freefuzz deeprel improvement pytorch tensorflow total table verified api pairs equivalence value equivalence status total pytorch tensorflow total result analysis .
rq1 effectiveness in api coverage in this rq we aim to study the effectiveness of deeprel in terms of covering more apis with api relations.
table shows the number of dl library apis covered by deeprel and state of the art freefuzz.
column total presents the total number of apis in dl libraries while column improvement presents the improvement of deeprel over freefuzz.
in the fuzzing stage deeprel covers apis which is a huge improvement over freefuzz that covers only apis.
for example there are totally pytorch apis and deeprel can cover apis more than freefuzz.
a large number of apis are not covered by freefuzz because they are less frequently used and not covered by any of the three sources of freefuzz.
leveraging api relations deeprel can successfully invoke these apis with their relational apis inputs.
the huge api coverage improvement demonstrates the potential of deeprel.
table source distribution of inferred api pairs srctgtseed new pytorchseed new tensorflowseed new table shows the number of verified api pairs detected by deeprel.
columns equivalence value and equivalence status present the number of value equivalent and status equivalent api pairs accepted by the api match verifier respectively.
deeprel accepts api pairs in total showing that such api relations are common in dl libraries.
on pytorch deeprel accepts more statusequivalent api pairs than value equivalent .
the reason is that the latter relation is stricter than the former and statusequivalent api pairs are more common.
for example in term of splitting a tensor pytorch provides a set of apis torch.split torch.tensor split torch.vsplit splits the tensor vertically and torch.dsplit splits the tensor depthwise .
it is worth noting that tensorflow has much more apis than pytorch and deeprel detects more value equivalent api pairs than status equivalent ones on tensorflow.
this is because tensorflow contains lots of apis for compatibility and low level access operations and thus has higher functional overlap the tf.compat module contains redundant apis to support forward and backward compatibility across versions.
for example tf.compat.v1.layers.conv2d is an alias for tf.layers.conv2d and it allows user to use the conv2d layer with tensorflow v1 behavior in tensorflow v2 the tf.raw opsmodule contains low level apis to provide direct access to all tensorflow ops.
for example tf.raw ops.pad adds padding to tensors and is a low level api compared to the high level api tf.pad with the same functionality.
table further presents a detailed distribution of the api pairs inferred by deeprel based on whether the source target apis involve newly covered apis.
column src and row tgt present the categorization of the source and target apis respectively columns rows seed and new indicate whether an api is from seed apis covered by freefuzz or is newly covered by deeprel.
out of all the api pairs verified by deeprel only involve apis covered by the original freefuzz and all the remaining pairs involve newly covered apis which shows the importance of leveraging api relations to cover more apis.
we also conduct a manual study to investigate why there are so many value equivalent api pairs.
note that we do not look into status equivalent api pairs because they are more intuitive e.g.
many apis may share similar input parameter types and or output behaviors .
since the number of verified value equivalent api pairs is huge we select the set of equivalent api pairs explicitly specified in the documentation for our study.
we mine the documentation for all pytorch and tensorflow apis to extract api pairs when one api explicitly