semantic test repair for web applications xiaofang qi school of computer science and engineering southeast university china xfqi seu.edu.cnxiang qian school of computer science and engineering southeast university china qq.comyanhui li state key laboratory for novel software technology nanjing university china yanhuili nju.edu.cn abstract automation testing is widely used in the functional testing of web applications.
however during the evolution of web applications such web test scripts tend to break.
it is essential to repair such broken test scripts to make regression testing run successfully.
as manual repairing is time consuming and expensive researchers focus on automatic repairing techniques.
empirical study shows that the web element locator is the leading cause of web test breakages.
most existing repair techniques utilize document object model attributes or visual appearances of elements to find their location but neglect their semantic information.
this paper proposes a novel semantic repair technique called sem antic testrepair semter for web test repair.
our approach captures relevant semantic information from test executions on the application s basic version and locates target elements by calculating semantic similarity between elements to repair tests.
our approach can also repair test workflow due to web page additions or deletions by a local exploration in the updated version.
we evaluated the efficacy of our technique on six real world web applications compared with three baselines.
experimental results show thatsemter achieves an average repair ratio within an acceptable time cost significantly outperforming the state of the art web test repair techniques.
ccs concepts software and its engineering software testing and debugging .
keywords web testing test repair gui testing semantic similarity acm reference format xiaofang qi xiang qian and yanhui li.
.
semantic test repair for web applications .
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
introduction web applications frequently evolve to meet the constantly changing needs of users .
regression testing is conducted on the updated versions to ensure that such evolution does not break the functionality of the applications .
in such testing scenarios software engineers commonly employ record replay test techniques to automate the testing of web applications .
typically a record replay tool for web applications like selenium test framework captures and records manual operations e.g.
mouse clicks and filling in forms that testers conducted on graphic user interface gui to generate a test script which testers redeliver to browsers for replaying and testing automatically.
even though record replay techniques improve the ability of test reuse and automation dramatically they suffer from the wellknown test fragility problem .
a test script would usually become fragile as the application evolves e.g.
a modification in gui as minor as adding or deleting a user interface ui element would make the test script break i.e.
test breakage1 .
empirical studies demonstrate at least one breakage occurs in of web application tests and nearly of these tests exhibit multiple breakages within the same test .
besides the manual repair for test breakage is time consuming expensive and highly tedious .
currently web developers tend to release new versions frequently to attract more users implying a shorter time available for test repairs and regression testing.
in this context automated test repair technique is urgently demanded to ensure the high quality of web applications.
researchers have aimed to analyze potential causes of test breakages including ui element locator value action exception and page reloading.
their empirical studies show that the ui element locator is the leading cause.
as a result researchers have paid much attention to improving the accuracy of ui element locators to repair broken test scripts .
most existing web test repair techniques essentially leverage document object model dom attributes and visual appearances of ui elements as critical factors to match appropriate ui elements.
the assumption behind these repair techniques is that ui elements dom attributes and visual appearances are relatively stable i.e.
unchanged or only slightly changed as a web application evolves.
unfortunately this assumption would be unrealistic in some real world cases.
fig.
illustrates the change of ui elements between two versions of claroline2 where two ui elements my user account on claroline .
.
1a test breakage indicates that a test case that functions well on the previous web application version is no longer applicable to its updated version not due to bugs but rather due to a change that makes the test function incorrectly.
2claroline is one of the six web applications studied in our paper whose detailed information will be presented in section .
.
esec fse december san francisco ca usa xiaofang qi xiang qian and yanhui li a a snapshot with ui element my user account on claroline .
.
b a snapshot with ui element manage my account on claroline .
.
figure an example of two claroline versions to show how ui elements change as a web app evolves.
two elements required to be matched are highlighted with dashed red boxes.
and manage my account on claroline .
.
with dashed red boxes are required to be matched when fixing test breakages.
from fig.
we have the following two observations dom attributes are insufficient to match these two elements .
the structure of dom trees on current web pages has greatly changed between the two versions which causes the dom attributes e.g.
linktext and xpath of the latter to be utterly distant from that of the former.
visual appearances are too different to match these two elements.
fig.
shows the obvious differences between the visual appearances of these two ui elements e.g.
the text content text fonts and background colors are all changed.
consequently methods based on visual appearances would underestimate the similarity between these two elements and fail to match them.
this example reveals the limitations of current techniques and drives us to rethink how testers could match these two elements.
for testers the text content of these two elements contains semantic information their text my user account and manage my account indicate that these two elements are highly related to operations e.g.
manage modify and search on the current user account.
previous studies have shown that ui elements carry rich semantic information e.g.
textual descriptions and icons which greatly facilitate human understanding of their functionalities .
the above observations indicate that semantic information would be helpful for achieving more accurate ui element locators.
in this paper we propose a novel approach called sem antic test repair semter to repairing tests for web applications.
the key insight of semter is that it simulates human repair behaviors andenables automated regression testing by semantic matching techniques.
specifically semter initially runs a test on the base version of a web application and collects relevant semantic information of ui elements and other requisite information as the reference of the test execution.
then when the test is replayed on the updated version it utilizes collected semantic information to decide which ui elements from the base version have been changed and identify possible counterpart ui elements from the updated version.
semter captures semantic meanings contained in texts and images of ui elements i.e.
computes the semantic similarity by a hybrid deep learning based semantic model which transforms both text and image information of ui elements into the semantic information in a unified framework.
furthermore the contexts of ui elements are also incorporated to augment the semantic information of ui elements.
besides semter adopts the local exploration algorithm in vista to handle the test breakage scenarios due to the broken workflow of test execution e.g.
the target ui elements are not on the same page but removed or moved to the neighboring web page.
the evaluation of our approach semter is conducted on six real world and open source web applications.
we compare semter with three representative web test repair methods namely water vista and webevo .
the results corroborate the effectiveness of semter .
this paper makes the following contributions strategy.
we propose a novel semantic test repair approach semter for web applications which leverages semantic information of ui elements to yield effective repairs.
implementation.
we implement a prototype tool also called semter to support the application of our semantic test repair approach.
study.
we empirically evaluate the efficacy of semter on six real world web applications.
results demonstrate that semter achieves an average repair ratio within an acceptable time significantly surpassing the three state of theart web test repair techniques.
background and motivation example this section introduces motivation examples and the background of our studies including web testing test breakage and semantics required for test repair.
.
web testing and test breakage a web test script i.e.
a test case that runs on a given web app is a set of statements st1 st2 ... st n wheresti ei oi i n describes an ui element event containing the ui element eiand the operationoiperformed on ei.
fig.
a and c shows the ui element event sequence of a test on the basic version .
.
of claroline and the accompanying test script tcrespectively.
as can be seen in fig.
c tchas statements st1 ... st which run successfully on the version .
.
.
to illustrate st3indicates a successful operation click on an element the enter button .
as mentioned in section test scripts are brittle and test breakages occur easily as the app evolves.
from a repair oriented perspective researchers categorized locator related test breakages into the following classes 1191semantic test repair for web applications esec fse december san francisco ca usa a version .
a ui elements on version .
.
of claroline b ui elements on version .
.
of claroline a version .
a version .
.
driver .findelement by.id login .sendkeys smith .
driver .findelement by.id password .sendkeys pass .
driver .findelement by.name submitauth .click .
driver .findelement by.linktext my user account .click .
driver .findelement by.linktext view my statistics .click .
new select driver .findelement by.id cidreq .selectbyvisibletext math .
assertequals exercise driver .findelement by.xpath .
div div table tbody tr td a .gettext .
assertequals driver .findelement by.xpath .
div div table tbody tr td .gettext .
driver .findelement by.id login .sendkeys smith .
driver .findelement by.id password .sendkeys pass .
driver .findelement by.cssselector button .click .
driver .findelement by.linktext manage my account .click .
driver .findelement by.linktext view my statistics .click .
new select driver .findelement by.id cidreq .selectbyvisibletext math .
assertequals exercise driver .findelement by.xpath .
div div table tbody tr td a .gettext .
assertequals driver .findelement by.xpath .
div div table tbody tr td .gettext c a successful test script tccontaining statements on version .
.
with four test breakages highlighted by on the updated version .
.
a version .
a version .
.
driver .findelement by.id login .sendkeys smith .
driver .findelement by.id password .sendkeys pass .
driver .findelement by.name submitauth .click .
driver .findelement by.linktext my user account .click .
driver .findelement by.linktext view my statistics .click .
new select driver .findelement by.id cidreq .selectbyvisibletext math .
assertequals exercise driver .findelement by.xpath .
div div table tbody tr td a .gettext .
assertequals driver .findelement by.xpath .
div div table tbody tr td .gettext .
driver .findelement by.id login .sendkeys smith .
driver .findelement by.id password .sendkeys pass .
driver .findelement by.cssselector button .click .
driver .findelement by.linktext manage my account .click .
driver .findelement by.linktext view my statistics .click .
new select driver .findelement by.id cidreq .selectbyvisibletext math .
assertequals exercise driver .findelement by.xpath .
div div table tbody tr td a .gettext .
assertequals driver .findelement by.xpath .
div div table tbody tr td .gettext d a revised and successful test script tc containing statements on version .
.
with changes highlighted by from tc figure an example of test breakages occurring as web apps evolve and the need for semantics during test breakage repair.
non selection same page nssp .
when a test script statement is executed no ui element is found and returned.
however the target ui element is present on the current page i.e.
where the test stops .
non selection neighbouring pages nsnp .
the target element is not found on the current page but it is on its neighboring page e.g.
due to the insertion of a web page in the updated version .
non selection removed nsr .
the target element is not found since it is removed from the page.
mis selection directed and propagated msdp .
when a test script statement is executed an incorrect ui element is selected as the target element and returned.
this case tends to cause a test execution different from the intended behavior.
as shown in fig.
b in the subsequent version .
.
of claroline changes come to pages e.g.
the text of the my user account menu item marked with is changed to manage my account and the background color of the enter marked with is also changed.
when the test case tcis executed on version .
.
it breaks at lines and .
based on the above classification the manual check shows that all test breakages in fig.
c are nssps due to significant changes in the dom attributes of the ui elements.
.
semantics required for test repair the breakage at line see fig.
c on version .
.
shows that semantic information is required to locate target ui elements accurately in test repair.
comparing the source and target elements i.e.
my user account menu item marked with 4on version .
.
in fig.
a and manage my account menu item on version .
.
in fig.
b we observe that large changes in dom attributes and visual appearances occur.
such changes cause methods based on dom attributes visual appearances to fail to repair this breakage.
in addition the semantic information about surrounding elements would help locate the ui elements.
as shown in fig.
there are two similar input boxes marked with 1and2on two versions which are hard to differentiate based on their local information.
we find that the text elements in the right hand of source and target input boxes marked with namely add category add version identical on the two versions regardless of case supplement the semantic information and strongly indicate that these two input boxes are matched on the two versions.
1192esec fse december san francisco ca usa xiaofang qi xiang qian and yanhui li a a page snapshot with the input boxes 1and2on mantisbt .
.
b a page snapshot with the input boxes 1and2on mantisbt .
.
figure an example to show the requirement for the semantic information supplemented by surrounding elements.
approach fig.
provides an overview of our semter approach with three main modules i.e.
semantic test tracer test repair and semantic similarity calculator .
given a base version vof a web app a test casetcthat runs successfully on v and an updated version v semter first runstconv records its execution trace and collects a variety of semantic information e.g.
text by the semantic test tracer module then it runs tconv and the previous trace is utilized to validate the correctness of each test script statement.
once a test breakage occurs the test repair module attempts to exploit the previously generated semantic information and the page information to find the possible target ui element by calling semantic similarity calculator and then fix the breakage.
afterward the next test statement continues its execution.
each statement in tc proceeds sequentially until all statements in tcare executed.
finally semter outputs a repaired test case tc that runs successfully on v along with report information.
the tester can analyze the report and manually check whether the repairs for breakages are correct or not.
.
semantic test tracer for a test case tc semantic test tracer runstcon the basic version v records the execution trace of tc and generates a semanticaugmented test case which contains semantic information of the ui elements that are executed by tc.
as described in section .
we formulate a test case tcas a set of ui element events with their operations e1 o1 e2 o2 ... en on whereeidenotes a ui element e.g.
a menu item and oiis the operation performed on ei.
as shown in fig.
c the operation can be a simple action like click or a method call with arguments such as sendkeys pass on line figure overview of semter .
besides an oracle is also taken as a special type of event where the operation is an assertion e.g.
assertequals on line .
for each ei oi semantic test tracer analyzes the recorded trace and retrieves semantic information of ei which consists of the following two kinds of semantic information.
theindividual semantic information of ei denoted as ei.is is extracted entirely from eiitself which consists of its text and image denoted as ei.text andei.image respectively.
considering the fact that the semantic information of a ui element that a human captures mostly depends on visible texts or images rather than those invisible dom attributes while he observes it we extract only the text contents that are displayed on the page.
specifically semter retrieves the visible text contents of ei.text by calling selenium methodwebelement.
gettext or extracting the text information fromtextcontent attribute orvalue attribute of a form etc.
images are captured from the screenshot on the page.
if no visible text content image is retrieved ei.text ei.image isnull.
thecontextual semantic information of ei denoted as ei.cs is extracted from the context of ei i.e.
ei.csis a set of ui elements surrounding ei.
as ui elements in ei.cstend to be close to eiin the dom tree semantic test tracer retrievesei.csby analyzing the dom tree.
it first visits the node eiand selects all text contained ui elements in the parent of eiand the descendants3of the siblings ofeias candidate elements.
if no candidate element is captured it recursively ascends to visit the parent of the node just visited and again selects candidate elements in its parent and descendants of its siblings the process continues until candidate elements are captured or the root i.e.
the element with xpath html body is reached.
here text contained ui elements are referred to as elements on the leaf nodes or those whose texts are not null but the texts of all their descendants not including themselves are null.
eventually those candidate elements that are far from eion the page are filtered.
specifically ei.csonly contains those ui elements that have coordinate overlap with eior are closest in terms of euclidean distance toeiin the up down left and right directions.
.
test repair algorithm illustrates how the test repair module works.
it takes a test casetcthat runs successfully on the basic version vand the updated version v as inputs and outputs the repaired test case tc that works well on v and the relevant repair actions ra.
3here we consider that the descendants of a node include the node itself.
1193semantic test repair for web applications esec fse december san francisco ca usa the algorithm starts by initializing tc andra and opening a web driver to load v lines .
for each test script statement sti intc it first retrieves the ui element eexecuted by stionv the operationoone and the dom based locator lused bysti then searches for a candidate target element e on the current web page by calling searchelement function lines .
if it is found eis substituted by e and the corresponding repair action is added to ra lines .
otherwise the algorithm attempts to find it on the neighbouring pages lines .
the event evthat is clickable on the current page sis triggered to reach the neighbouring page function localexplore in line to find the element.
once a candidate target element e is found on some neighbouring page the elementevand the click operation that triggers the page transition and the found element e and its operation are added to ra and the test continues line .
if no candidate element is found on any neighbouring page our algorithm considers the target element asremoved fromv .
then the repair action of removal is added tora lines .
considering that an exhaustive exploration often causes a state explosion our algorithm adopts the same local exploration strategy as vista namely the exploration is limited to one step from the current page.
specifically only the clickable events on the current page sare selected and triggered to reach the neighbouring page lines .
during the local exploration when not finding the target element on some neighbouring page our algorithm would backtrack to the current page s line .
before executing the next test script statement the tester checks the correctness of the repair actions in raonsti line .
if the automatic repair is inappropriate it is substituted by a manual fix.
subsequently the repaired statement stiis executed line and the repair process proceeds.
finally a repaired test case tc is generated by performing the repair actions in raontc line .
the function searchelement attempts to search for a candidate target element on the current page.
it takes a web driver driver a ui elemente and its dom based locator linvas the input and returns a ui element in v that matches esemantically.
it first utilizes the original locator lto look up the dom of v to return a ui element e line .
if e is notnull and the semantic similarity between eande sim e e is greater than or equal to a threshold t e is returned as the target element lines .
otherwise i.e.
e is null orsim e e is less thant the function tries to find the element emax as the candidate target element on the current page lines .emax has the maximum semantic similarity with eand the value is greater than or equal to t. note thatemax could benull which implies that no target element is returned.
to improve the search efficiency in the first step lines the function does not search for emax but uses a semantic similarity threshold tfor sifting out those impossible candidate elements.
in this work the thresholdtis set to .
detailed explanation will be provided in section .
.
semantic similarity calculator the two motivating examples see figures and show that comprehensive semantic information namely combining individual and contextual semantic information is required and useful to locate target elements.
thus in our approach the semantic similarity between two ui elements is calculated from the individual andalgorithm semantic test repair input tc st1 st2 ... st i ... st n a test case that runs successfully on the basic version v u the url of the updated version v .
output tc a repaired test case that works on v ra a set of repair actions.
1tc ra 2driver loadapp u 3fori 1tondo e getelement sti o getaction sti l getlocator sti e searchelement driver e l ife null then ra.add sti update e o else s driver.
getstate forev s.getclickable do s.localexplore ev click e searchelement driver e l ife null then ra.add sti insert ev click ra.add sti update e o break driver.
updatestate s ife null then ra.add sti remove null checkrepair sti ra driver executeupdate sti v 24tc performrepair tc ra 25return tc ra 26function searchelement driver e l e driver .
findelement l ife null sim e e tthen return e emax null sim max foreach e driver .
getelement do ifsim e e sim max sim e e tthen sim max sim e e emax e return emax contextual perspectives.
given two ui elements eande similarity calculator calculates the comprehensive semantic similarity betweeneande namelysim e e .
in algorithm sim e e is the crucial criterion for selecting the target element.
in our approach it is calculated as sim e e simi e e simc e e wheresimi e e andsimc e e represent the individual semantic similarity and the contextual semantic similarity between eande respectively and is a weighting parameter set to .
which will be discussed in section .
.
.
individul semantic similarity.
specifically the individual semantic similarity simi e e betweeneande is calculated based on the individual semantic information of eande denoted as e.is ande .isrespectively.
considering that e.isconsists ofe.text and e.image our semantic model provides a hybrid semantic similarity 1194esec fse december san francisco ca usa xiaofang qi xiang qian and yanhui li calculation between text text text image or image image pri x.is x.text ifx.text is not null x.image ifx.text is null.
simi e e ms pri e.is pri e .is wherepri x.is indicates the prioritized one in individual semantic information text has a higher priority over image and ms presents the running results of our semantic model.
our semantic model consists of two parts an nlp model and an image model.
they take texts and images as inputs respectively and output their semantic encodings.
a we have chosen sentence bert as our nlp model which is the modification of the pretrained bert network that uses siamese and triplet network structures to derive sentence embeddings with dimensions of .
it handles semantic information at the sentence level rather than the word level e.g.
word2vec making it have a strong capability of natural language processing.
compared with bert the model has high efficiency in calculating semantic similarity while maintaining accuracy.
b we have chosen resnet as our image model and revised it to produce encodings of the same dimension i.e.
as encodings produced by the nlp model.
resnet has demonstrated excellent performance on large scale image classification tasks and often outperforms previous state of the art architectures.
it has become a widely used and preferred choice as a backbone network in many image processing applications.
we have used of the data for training for early stopping and the remainder as the test set to determine the value of threshold t. the model has been trained in such a way that it maps images to text encoding space specified by the nlp model.
more specifically the goal is to make the semantic similarity between icons and the corresponding labels as high as possible while the semantic similarity between icons and the corresponding negatively sampled labels as low as possible on average.
c as mentioned above the nlp and image models output 384dimensional encodings.
the semantic similarity between texts and texts images and images or texts and images is measured by the cosine similarity of their semantic encodings.
due to space limitation the details of our semantic model are presented in the readme.md file at to illustrate consider the menu item with the text my user account marked with 4in fig.
a on version .
.
denoted as e and the counterpart one with the text manage my account on version .
.
in fig.
b denoted as e from the motivating example.
using the individual texts of eande i.e.
my user account and manage my account the individual similarity between eand e is computed as follows simi e e ms my user account manage my account .
.
.
contextual semantic similarity.
the contextual semantic similarity between eande is calculated based on the contextual semantic information of elements.
it is formulated as follows simc e e ck e.csmax simi ck c j t wherec jis the best matched element of ckine .cs andtis the semantic similarity threshold.
in detail the matching procedure ontwo contexts of eande is conducted as follows a pick the pair ck c j with the max similarity where ck e.csandc j e .cs and considerc jthe best matched element of ck b remove ckandc j from the two sets and goto a until e.cs ore .cs .
to illustrate we also consider the matching between my user account e and manage my account e .
the context of ehas two ui elements labelled with my desktop and my message see fig.
a denoted as c1andc2 respectively.
the context of e also has two elements labelled with bert smith and logout denoted asc 1andc respectively see fig.
b .
thus there are two matching pairs from the two contexts i.e.
c1 c and c2 c .
the context similarity between eande is calculated as follows simc e e max simi c1 c t max simi c2 c t max .
.
max .
.
finally the comprehensive similarity between eande is computed as follows sim e e simi e e simc e e .
.
.
experimental results to evaluate the efficacy of our semter in supporting web test repair we conducted an empirical study on six real world web applications compared to water vista and webevo .
our three research questions rqs are summarized as follows rq1 effectiveness.
how effective is semter in terms of repair ratio of test breakages compared to three baselines?
rq2 efficiency.
how efficient is semter in terms of running time compared to three baselines?
rq3 parameter setting.
what is the impact of parameter setting on test repair effectiveness?
.
experimental setup subject applications.
in our experiment we selected six realworld web applications.
addressbook a contact manager that manages personal information in groups.
claroline an online collaborative learning environment that allows teachers or education institutions to create and administer courses.
collabtive a project management application that provides the functionality of creating tracking and managing projects.
password manager pwma an application used to generate and manage the passwords of users.
mantisbt a bug tracker that facilitates tracking bugs.
meeting room booking system mrbs a system used for multi site booking of meeting rooms or any other resources such as computers planes etc.
table shows their properties including the number of releases the average number of lines of code loc per release and the number of test cases across all releases.
for each application we selected those representative releases between which non trivial gui differences occur instead of adjacent versions to find out the repair capability of semter in the face of challenges details on selected releases are available at 1195semantic test repair for web applications esec fse december san francisco ca usa table subject applications and their test suites applications releases locs test cases addressbook claroline collabtive pwma mantisbt mrbs we reused the test cases designed by 4and extended them to all releases except for the last release .
baselines.
three representative state of the art web test repair tools namely water vista and webevo were selected as baselines.
all three repair tools are based on differential testing that compares the executions of the test case on the basic and updated versions of a web application.
the test case runs successfully on the basic version but may break on the updated version.
the difference among the three techniques is the method of mapping ui elements.
water collects dom attributes of ui elements and uses them to find the target element.
instead vista captures the visual information of ui elements from the test execution and exploits image processing techniques to map ui elements while attempting to repair nsnp breakages using the local exploring strategy the exploration step is one .
webevo combines the string similarity computed by levenshtein distance and image similarity of ui elements to identify the target element.
.
rq1 effectiveness motivation and approach.
the goal of rq1 is to evaluate the effectiveness of semter in repairing test breakages.
for each subject application and each test case we applied water vista semter andwebevo to each test breakage that occurred on the subsequent updated version.
for each tool and each breakage the correctness of each repair was examined by manual inspection.
only those repairs passed by the manual inspection were counted as correct repairs.
specifically a we invited two graduate students majoring in computer science to judge whether each breakage was correctly repaired by studied tools the inter rater agreement between the first two students was measured using the cohen s kappa coefficient .
b the first two students discussed the disagreements with the third student to form a unified judgment.
results.
the cohen s kappa coefficients to measure the inter rater agreement in step a are .
.
.
and .
for water vista semter and webevo respectively.
the four cohen s kappa coefficients are more than indicating the very high consistency of labeling results from manual inspection.
table reports the repair effectiveness.
for each application the table presents the number of breakages and the number of correct repairs made by water vista webevo and semter .
the results are further divided into four test breakage classes nssp msdp nsnp and nsr.
on the whole semter is capable of repairing breakages whereas water vista and webevo are capable of repairing and breakages respectively.
as a result semter can correct more breakages than water vista and webevo with 4test cases are available at repaired results t .
.
applications breakages water vista webevo semter addressbooknssp msdp nsnp nsr total clarolinenssp msdp nsnp nsr total collabtivenssp msdp nsnp nsr total pwmanssp msdp nsnp nsr total mantisbtnssp msdp nsnp nsr total mrbsnssp msdp nsnp nsr total all appsnssp msdp nsnp nsr total ratio and increments respectively.
concerning specific applications semter repairs breakages more than water more than vista and more than webevo .
observe the repair effectiveness of different classes of breakages.
semter repairs of nssp breakages whereas water vista and webevo repair only and respectively.
even though semter repairs only nsnp breakages it prevails over water vista and webevo .webevo repairs msdp breakages more than semter .
the overall superiority of semter over webevo is however still great as msdp breakages occupy only .
out of all breakages.
there is no great significant difference between the four tools with respect to nsr breakages.
fig.
further compares semter water vista and webevo .
in each venn diagram the red green blue and yellow circles denote the number of breakages repaired by semter water vista and webevo respectively.
the six left venn diagrams show the number of overlaps of repaired breakages for each application.
for example for addressbook breakages are repaired by four tools breakages are repaired only by water semter andwebevo breakages are repaired only by water andsemter and breakages are repaired only by semter .
the rightmost diagram provides the total across all applications.
as shown in the rightmost diagram breakages are correctly repaired by all four tools.
however there are breakages that are repaired only by semter .
in contrast only breakages are repaired only by water whereas and by vista andwebevo respectively.
it is noted that no technique is capable of repairing .
test breakages.
1196esec fse december san francisco ca usa xiaofang qi xiang qian and yanhui li figure partition of breakages based on whether they can be repaired by each approach answer to rq1.
semter is able to repair of breakages on average significantly outperforming water vista and webevo .
.
rq2 efficiency motivation and approach.
rq2 aims to evaluate the running time of semter .
our experiment was performed on windows and firefox web browser .
running on a .
ghz intel core i7 cpu with gb memory.
we measured the execution time required to run the test suites without and with the trace module and repair breakages.
results.
table reports the average time per test case that is required to run the test case set without column and with column the trace module and repair breakages column .
vista takes the most trace time .51s then semter .00s and webevo .04s finally water .83s .
the reason is that water traces only the dom information of ui elements and webevo requires capturing additional page images.
vista requires capturing the page image and other necessary information to generate visual locators.
the process of image capturing and processing seriously slows down the efficiency of vista .
compared with water and webevo the increase in time for semter mainly comes from the process of extracting the contexts of elements which is positively correlated with the number of elements in the unfiltered contexts.
in most cases the number of elements in the unfiltered contexts is relatively small so semter will not spend much more time than water andwebevo .
concerning the repair time water still takes the least repair time due to its rather simple repair process.
webevo takes the most time as its repair requires the simultaneous computation of text similarity and image similarity of ui elements.
vista is fastertable execution time applications run s trace s repair s water vista webevosemter water vista webevosemter addressbook .
.
.
.
.
.
.
.
.
claroline .
.
.
.
.
.
.
.
.
collabtive .
.
.
.
.
.
.
.
.
pwma .
.
.
.
.
.
.
.
.
mantisbt .
.
.
.
.
.
.
.
.
mrbs .
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
figure difference of repair ratio with different than semter which is much faster than webevo .
the context processing is a key factor that greatly influenced the repair time forsemter .
on the whole vista takes the most time .25s then webevo .20s and semter .29s finally water .92s .
the total time spent by semter is less than minute which is an acceptable time.
answer to rq2.
the efficiency of semter is lower than water but higher than vista andwebevo .
the total running time is acceptable.
.
rq3 parameter settings motivation and approach.
the weighting parameter in formula is a key parameter that impacts the repair effectiveness of semter .
to evaluate the impact we selected different values for and for each we conducted a repair effectiveness experiment and counted the repair ratios.
results.
fig.
reports the impact of on the repair effectiveness.
when is selected as .
the highest repair ratio is achieved across all applications.
however when is i.e.
the contextual semantic information is not taken into account the repair ratio reduces by .
on average.
the reduction ranges from .
.
across different applications as compared with .
.
such a result demonstrates that contextual semantic information can facilitate test repairs significantly improving the repair ratio.
additionally when changes from .
to .
the repair rate varies slightly.
the difference between the maximum and the minimum repair ratios is only .
.
answer to rq3.
the contextual semantic information improves the repair ratio significantly.
variation of in some range yields no big fluctuation on the repair ratio.
1197semantic test repair for web applications esec fse december san francisco ca usa table causes of breakages not repaired by any approach breakages causes numbers nsspui elements are changed from text to icon and the changes are great.
both appearances and visible text contents of ui elements are changed significantly.
multiple similar ui elements on the page are difficult to differentiate.
ui elements change essentially e.g.
from drop down list to radio button.
msdpmis selected elements are similar to original elements in dom attributes and appearances.
nsnptoo many neighbouring pages and the limitation of exploration strategy make the repair difficult.
discussion this section further discusses the factors that may impact the effectiveness of the repair and presents tool implementation.
.
explanation of effectiveness results breakages not repaired by semter .as shown in table semter achieves the best repair ratio of nssp breakages .
the critical factor is the relatively reliable semantics of most ui elements during the evolution of web applications compared with their dom attributes or gui appearances .
however the ratios of nsnp msdp and nsr repaired by semter are comparatively low.
to find out the cause we conducted an additional experiment.
considering that when repairing msdp breakages algorithm does not guarantee that the most similar ui element is selected as the target element since the code in lines is executed if the original locator lreturns a non null element.
then we modified the algorithm and forced it to select the most similar ui element on the current page to repair the breakages.
similarly for nsnp breakages we forced it also to select the most similar ui element from all neighbouring pages.
the experimental results show that our approach is capable of repairing more msdp breakages and more nsnp breakages.
accordingly the repair ratio of msdp increases from to whereas nsnp from to achieving a significant increase.
the results further corroborate the superiority of semter .
as for nsr increasing the thresholdtwould improve the repair ratio yet at the expense of influencing repairing other classes of test breakages.
breakages not repaired by any approach.
fig.
shows that breakages are not repaired by any approach.
if we use semter and select the most similar element as the target element and then remove such repaired breakages there are still nssps nsdps and nsnp breakages.
table describes the number of breakages and the corresponding causes.
.
selection of the threshold of semantic similarity in algorithm the threshold tis utilized to filter candidate semantically dissimilar elements.
a too large threshold may lead to missing the target elements whereas a too small threshold may produce excessive candidate elements.
to select an appropriate threshold value we conducted an empirical study.
the subjects of our experiment consist of a set of text text pairs a set of text image figure precision recall of different pairs pairs and a set of image image pairs.
for each subject we used our semantic model to predict a semantic similarity score.
when the score is greater than or equal to the threshold t we say the pair is semantically similar.
otherwise it is semantically dissimilar.
we selected the following data sets text text pairs.
snli corpus is a collection of english sentence pairs with labels entailment contradiction and neutral .
we selected it as the data set of text text pairs.
those text text pairs with the label entailment in the set were taken as semantically similar pairs and others as semantically dissimilar pairs.
eventually we generated a data set with semantically similar pairs and semantically dissimilar pairs.
text image and image image pairs.
we selected the test set of the data set used for training our semantic model as described in section .
those icon images and their labels were taken as semantically similar image text pairs whereas those icon images and their negatively sampled labels were taken as semantically dissimilar pairs.
those two icons with the same labels were taken as a semantically similar image image pair.
for each icon we randomly sampled an icon image from the test set to form a semantically dissimilar image image pair.
finally we generated a data set with semantically similar image text pairs and dissimilar pairs and a data set with semantically similar image image pairs and dissimilar pairs respectively.
as shown in fig.
the solid and dotted lines represent the precision and recall of similar elements respectively.
the precision and recall is calculated as precision tp tp fp recall tp tp fn wheretpdenotes the number of true similar pairs which are also predicted as similar ones i.e.
true positive fpdenotes the number of false similar pairs which are yet predicted as similar ones i.e.
false positive fndenotes the number of true similar pairs which are yet predicted as dissimilar ones i.e.
false negative .
astincreases from 0to0.
the precision of text image and image image pairs rises quickly to a peak nearly .
.
then the precision has no change if tincreases continuously.
the precision of text text pairs rises steadily as tincreases from which might be due to the different quantity of positive and negative samples.
instead the three recall curves reduce steadily as the threshold t increases from 0to0.
then they decline rapidly.
overall .
is an ideal threshold of semantic similarity.
1198esec fse december san francisco ca usa xiaofang qi xiang qian and yanhui li figure precision of similar elements .
effectiveness of semantic model as mentioned in section .
our semantic model supports the calculation of semantic similarity which is crucial for their matching.
we conducted an experiment to observe the effectiveness of our semantic model in calculating semantic similarity.
we first collected those ui elements exercised by the test statements at which nssp and msdp test breakages a total of occurred nsr and nsnp were not chosen as the target elements were not on the current page .
then we invited graduate students majoring in computer science to construct the standard set of semantically similar ui elements for such ui elements.
specifically the first students independently found semantically similar ui elements on the current page for each ui element.
the inter rater agreement among them was measured using cohen s kappa coefficient .
in our experiment cohen s kappa coefficient was nearly .
afterwards the first students discussed the disagreements with the third student and eventually all the similar elements in the standard set were unanimously passed.
subsequently we used semter vista and webevo to automatically search for similar elements on the corresponding pages water has not been considered here as dom attributes of ui elements are often invisible for testers and they are volatile in many cases during the evolution of web apps .
to measure the effectiveness of our semantic model in essence semter only leveraged individual semantic information to compute the semantic similarity between ui elements and find similar elements.
the contextual semantic information has not been considered as it only makes up for the inadequacy of semantic information of ui elements.
we checked whether the element returned by semter vista orwebevo was in the standard set.
if the returned element was in the standard set it was considered to be accurate.
otherwise it was not.
fig.
reports the precision of the returned elements captured bysemter vista and webevo across applications.
the precision ofsemter is .
.
it ranges from .
to .
for each application whereas vista from .
to .
and webevo from .
to .
.
the results corroborate that our semantic model is very effective in computing semantic similarity between ui elements.
.
comparison of different model components to evaluate the key component of our semantic repair approach we conducted an empirical study on six real world web applications and compared the repair effects with multiple different natural language processing and image processing components.table repaired results of different model components applications breakages wv tl sb tl sb rn addressbook claroline collabtive pwma mantisbt mrbs all apps ratio we replaced sentence bert with word2vec which was often used by most semantic gui test tools mentioned in the related work.
specifically we selected word2vec google news .
the model was trained using a corpus of approximately billion words from the entire google news and covers approximately million words and phrases.
regarding image components we chose a transformer based model like labeldroid also mentioned in the related work and the data set that semter was used to train a label predicting model for image based ui elements.
the structure loss function other training details of the model and corresponding codes were similar to labeldroid.
table reports the repaired results of three different configurations where wv sb rn and tl represent word2vec sentencebert resnet and transformer based label model respectively.
the last column sb rn is the configuration of semter whereas the two left columns marked as wv tl and sb tl are taken as comparisons.
the results show that semter sb rn is capable of repairing breakages whereas wv tl and sb tl are capable of repairing and breakages respectively.
our hybrid model used in semter is confirmed to be the best configuration of natural language processing and image processing components that we have found.
sb tl is capable of repairing breakages more than wv tl indicating that sentence bert is a much stronger natural language processing component than word2vec.
instead there is no big difference between sb tl and sb rn demonstrating that the two image based processing components have similar semantic processing capabilities.
moreover we find that even though different natural language processing and image based processing components achieve different repair effects the lowest repair ratio using our semantic based approach is still which is much higher than those dom based or image based methods e.g.
water vista and webevo .
this comparison further corroborates the superiority of our semantic based approach over the state of the art repair techniques.
.
implementation we have implemented our approach into a tool called semter to automate the repair of gui test scripts for web applications.
semter written in java supports selenium test cases written in java.
as shown in fig.
semter mainly consists of semantic test tracer semantic similarity calculator and test repair modules.
semantic test tracer which is responsible for recording and collecting 1199semantic test repair for web applications esec fse december san francisco ca usa the execution trace of test cases is realized using aop aspect oriented programming technique.
semantic similarity calculatoradopts pytorch to implement our semantic model in python which interacts with java code through jep6.semter is available at note that our approach is general and easily adapted to repair test cases developed by other testing frameworks or programming languages.
threats to validity the main internal threat is the possible faults in implementing our approach.
to mitigate this threat we have carefully reviewed our code to ensure its correctness.
besides the data set of icon images may not be quite sufficient and representative which influences the precision of the semantic similarity predicted by our semantic model especially for icon related ui elements.
more icon image data are required to be collected for retraining our semantic model.
the external threat is the ability to generalize our results to other web applications.
however in our experiment we select six real world web applications that have been used in previous studies and reuse the test suite to ensure the objectivity and fairness of the results.
in the future we plan to conduct empirical studies on more web applications to mitigate this threat further.
related work gui test repair.
choudhary et al.
propose water that uses dom attributes of ui elements to search for the target elements and provides repair suggestions .
hammoudi et al.
further improve water by implementing an incremental strategy that repairs the breakages across intermediate fined grained successive versions .
stocco et al.
present vista that exploits visual appearances of ui elements to match ui elements .
shao et al.
combine the text similarity based on levenshtein distance with image similarity to match ui elements and present a framework webevo for repairing breakages .
recently dom based and vision based test repair techniques have been extended to regression testing of mobile applications .
yoon et al.
also present a machine learningbased android gui test case repair technique .
different from these web test repair techniques semter simulates human repair behaviors.
it transforms both text and image information of ui elements into semantic information in a unified framework and then uses it to match them.
instead existing test repair techniques repair web tests by comparing either dom attributes or images.
in addition grechnaik et al.
propose an approach that reports repair suggestions by comparing the differences in gui models .
huang et al.
use a genetic algorithm to repair gui test suites .
memon et al.
present event flow graphs as the gui model of desktop applications for path repairs .
gao et al.
further implement an event flow graph based repair algorithm .
harman et al.
present an automated session based test repair approach .
daniel et al.
use a white box method to integrate the functionality of recording gui code modification on ide and then repair tests .
semantic gui testing.
rau et al.
present a semantic based method to transfer tests across web applications by using word2vec technique to compute semantic similarity between web ui elements .
these techniques are then extended to mobile applications marriani et al.
conduct an empirical study on different semantic mapping of gui events for test reuses .
thummalapenta et al.
propose a guided test generation technique which implements higher coverage of specified business rules by extracting semantic information about widgets .semter differs from these semantic gui testing techniques in the computation method of semantic similarity by training a hybrid semantic model that can handle text and image information in a unified semantic framework and incorporate the contextual semantic information.
moreover semter extracts only visible texts or images as the semantic information source like humans while most of these semantic gui testing techniques often also extract many invisible texts which may actually reduce the effectiveness of key semantic information due to conflicting or dispersing impacts between texts.
finally semter selects sentencebert as the nlp model which processes semantic information in the sentence level instead of the word level e.g.
word2vec which is used by most of these above semantic gui testing techniques.
besides mariani et al.
present an automated technique to generate semantic gui test cases for independent application functionalities .
talebipour et al.
exploit cv and nlp techniques to evaluate the similarity of gui events for test migration across mobile platforms .
zhang et al.
adopt deep learning techniques and the word2vec model to generate text input for mobile applications automatically .
recently deep learning techniques have been utilized to generate labels for icons automatically .
web element locator.
leotta et al.
propose a robust xpath locator generator tool robula by converting absolute xpaths to relative xpaths .
subsequently they integrate the five most commonly used locators into one robust multi locator tool that gains all advantages of the five locators .
long et al.
also present a self replay enhanced robust record replay tool webrr for web testing which is capable of deriving multiple locators .
conclusion in this paper we propose a novel semantic test repair technique and a prototype tool semter for repairing web tests which retrieves relevant semantic information from test executions to facilitate test repair.
we evaluated semter on six real world web applications.
our experimental results show that semter is capable of correctly repairing on average of web test breakages within an acceptable time outperforming the state of the art repair techniques significantly.
in future work we will conduct additional empirical studies further to corroborate the effectiveness of our semantic test repair technique.
moreover we will extend our semantic test repair approach to mobile applications.
data availability we provide data and source code used to conduct this study at acknowledgement the authors thank the anonymous reviewers for their valuable feedback.
this work is supported by the national science foundation of china under grant no.
and .
yanhui li yanhuili nju.edu.cn is the corresponding author.
1200esec fse december san francisco ca usa xiaofang qi xiang qian and yanhui li