ereba black box energy testing of adaptive neural networks mirazul haque mirazul.haque utdallas.edu the university of texas at dallasyaswanth yadlapalli yaswanth.yadlapalli utdallas.edu the university of texas at dallas wei yang wei.yang utdallas.edu the university of texas at dallascong liu cong utdallas.edu the university of texas at dallas abstract recently variousdeepneuralnetwork dnn modelshavebeen proposed for environments like embedded systems with stringent energyconstraints.thefundamentalproblemofdeterminingtherobustness of a dnn with respect to its energy consumption energy robustness isrelativelyunexploredcomparedtoaccuracy basedrobustness.thisworkinvestigatestheenergyrobustnessofadaptiveneuralnetworks adnns atypeofenergy savingdnnsproposed for many energy sensitive domains and have recently gained traction.
we propose ereba the first black box testing method for determiningtheenergyrobustnessofanadnn.erebaexplores and infers the relationship between inputs and the energy consumptionofadnnstogenerateenergysurgingsamples.extensive implementation and evaluation using three state of the art adnns demonstrate that test inputs generated by ereba could degrade the performance of the system substantially.
the test inputs generated by ereba can increase the energy consumption of adnns by compared to the original inputs.
our results also show that testinputsgeneratedviaerebaarevaluableindetectingenergy surging inputs.
ccs concepts security and privacy software and application security.
keywords green ai ai energy testing adversarial machine learning acm reference format mirazulhaque yaswanthyadlapalli weiyang andcongliu.
.ereba black box energy testing of adaptive neural networks.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm newyork ny usa 12pages.
.
both authors contributed equally to this research.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
introduction recentlytherehasbeenaconsiderableamountofresearchindeveloping energy saving dnn models to allow state of art dnns with high computational costs to be deployed in mobile and embeddedarchitecture.
adaptiveneuralnetworks adnns are energy saving dnn models that determine when to switch off certainpartsofthenetworktoreducethenumberofcomputations.
becauseanadnnmodeldetermineswhichpartsoftheneural network to run based on inputs an adversary s ability to surge the energy consumption by carefully crafting inputs is a crucial concern in energy critical environments.
for example adnns like blockdrop andskipnet canreducethecomputationsin resnet significantly and an alteration on the input can nullify a largeportionofthereducedcomputations invalidatingthemodels purpose.
such behavior would lead the app or software using an adnn model to consume energy erratically resulting in devices power failure and disastrous consequences.
thus there is a strong needtoprovideasystematictestingmethodtofindenergyhotspots inthemodelandfilteroutpotential power surging inputsthat will negatively impact the model s performance.
creating testing inputs to increase the energy consumption of a dnnmodelischallengingbecauseinferringtherelationbetween energyconsumptionandinputis achallengingtask.unlikeinferring the relation between input and output where we can find the derivatives from a series of computation functions in the model energy consumptioncan onlybe measured byrunning themodel.
traditional dnn testing methods and traditional adversarial attacks on dnns have been designed to create carefully crafted synthetic testing inputs using the gradient of generated output with respect to the input.
however for energy testing itisunclearwhetherachangeintheinputinducesanincrease or decrease in the energy consumption of the model.
tothe best of our knowledge ilfo is the first work that seeks to formulate all types of adnn s energy robustness section .
problem by modeling the relation between input and intermediate output deepsloth only evaluates energy robustness of early terminationadnns .
however ourinvestigations section3 showthatilfogenerated energy surging samples lack traditional transferability i.e.
the adversarial samples generated by ilfo for a target adnn cannot be applied to a new adnn to increase its energy consumption.
therefore the traditional black box accuracy testing method of dnns using surrogate model can not be used for energy robustnessevaluation.therefore ilfogeneratedsamplescannot evaluate the energy robustness of adnns in a black box scenario.
ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa mirazul haque yaswanth yadlapalli wei yang and cong liu this paper presents ereba energyrobustness using estimator basedapproach toperformenergytestingonadnnsunderthe black box setting where there is no prior knowledge known about the adnn model.
to our knowledge this is the first attempt in this direction.
erebaaims to evaluate the energy robustness of adnnandidentifyinputsthatwillnegativelyimpactthemodel s performance.specifically wedeveloptwotestingmethodstoassess anygivenadnnmodel senergyrobustness namelyinput based testing and universal testing.
input based testing evaluates energy robustnesswheretestinginputsaresemanticallymeaningfultothe adnn e.g.
meaningfulimages compilableprograms .ontheother hand universal testing evaluates worst case energy robustness whereeachtestinginputmaximizestheenergyconsumptionfor each target adnn.
forgeneratingtestinginputsforadnnsinablack boxsetting it isneededtofindarelationbetweeninputandenergyconsumption of adnns.
based on the working mechanism of adnns we know thatdifferentnumbersofresidualblocks layersareactivatedduringinferencefordifferentinputs.thenumberofactivatedblocks layers during inference has a semi linear step wise relation with energy consumption whichcan alsobenoticedin figure7.throughthis step wise relation between the number of activated blocks and energyconsumption wecanconcludethatinputandenergyconsumption of adnns are related.
because of this reason erebais able to learn a decent approximation of the energy consumption of an adnn given the input.
based on such approximation ereba thengeneratesinputperturbationsthatsignificantlyincreasethe energy consumption of the adnn.
we evaluate erebaon four criteria effectiveness sensitivity quality androbustnessusingthecifar 10andcifar 100datasets .
first to evaluate the effectiveness of the testing inputs generated by ereba we calculate the energy required for adnns to classifythese inputswhile running onan nvidiatx2 server.
wethencomparethisvaluewiththeenergyrequiredbytheinputsgen eratedfromcommoncorruptionsandperturbationstechniques andasurrogatemodel basedapproach.weobservethat erebais twiceaseffective.thesensitivityof erebaismeasuredthroughthe behavior of the energy consumption of testing inputs generated while limiting the magnitude of perturbation allowed which enables a comparison between the adnn models energy robustness.
the quality of the generated testing inputs is evaluated against the original input through peak signal to noise ratio psnr and structuralsimilarity index ssim .finally therobustness oferebais demonstrated by providing corrupted input images for thegenerationoftestinginputs whichrevealsthecapabilityofthe estimatormodeltoimitatetheshortcomingsofthetargetadnn.
wefurtherdemonstratetwowaystoshowhow erebagenerated testinputscanhelptoincreaseenergyrobustness throughinput filtering and gradient based detection.
our paper makes the following contributions anapproach ereba thefirstenergy orientedblack boxtesting methodology for adnns.
a systematic empirical study on transferability of energybased testing inputs.
fourevaluationstodemonstratetheeffectiveness sensitivity quality and robustness of ereba.
two applications demonstrating the energy saving capability of ereba.
background .
energy robustness ilfo hasdefinedtheenergyrobustnessofadnnasthestability of the model s energy consumption after getting a perturbed input.however amodel senergyrobustnessshouldnotonlydepend on the inputs that belong to the training data distribution of the model.
energy robustness should also be evaluated basedon the out of distribution inputs.
because of this reason we define two types of energy robustness for dnns input based energy robustness ei and universal energy robustness eu .
eiisdefinedbythemaximumenergyconsumedbythemodel for an input which belongs to the training data distribution ofthe model.
let us assume xis an input that is within the data distributionof adnn f.wewant toadd perturbation toxsuch thatenergyconsumptionismaximum.inthatscenario eicanbe represented as ei max r engf x engf x whererissetofadmissibleperturbationssuchthat x remains within distribution and engfrepresents the energy consumption of dnn f. eucan be described as the highest possible energy consumed by a model for any input.
inputs used to measure eucan be out ofdistribution inputsalso.
fora dnn fand anyinput x eucan be represented as eu maxxengf x whereengfrepresentsenergy consumptionof dnn.
byincreasing the value of eiandeu energy robustness of a model can be increased.
.
adnns the main objective of adnns is to minimize executing layers in a neural network while maintaining reasonable accuracy.
the adnns can be divided mainly into two types conditional skipping adnns andearly termination adnns .
both types of adnnsreducecomputationsiftheirintermediateoutputvaluessatisfypredefinedconditions.forreducingcomputations conditionalskippingadnnsskipafewlayersorresidualblocks1 inthecaseof resnet whileearly terminationadnnsterminatestheoperations within a block or network early.
transferability of energy based testing inputs.
inthis section bycarrying outapreliminary study weshow that traditionaltransferabilitydoesnotexistinenergytestinginputs and existing technique like attacking surrogate model to generate accuracy based testing inputs cannot be applied in energy testing.
for traditional accuracy based testing transferability refers to the 1residual block consists of multiple layers whose output is determined by adding the output of the last layer and input to the block.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ereba black box energy testing of adaptive neural networks icse may pittsburgh pa usa propertythatadversarialexamplesgeneratedforonemodelmay also be misclassified by another model.
motivation.
in a black box setting existing techniques evaluate the accuracy robustness of dnns based on the traditional transferabilityofadversarialsamples .adversarialexamplesof dnns are perturbed inputs close to the original correctly classifiedinputsbutaremisclassifiedbydnns.becauseadversarialexamples are commonly used as testing inputs to measure the robustness oftheneuralnetworks wewillalsousetheterm testing inputstorefertotheadversarialexamplesinthispaper.goodfellow et al.and szegedy et al.
have concluded that accuracybasedtestinginputsonatraditionaldnnmodelaretransferable.
therefore adversarialexamplesgeneratedbyattackingasurrogate dnnmodelcanbeappliedtootherdnnsforevaluatingrobustness.inthissection weinvestigateiftraditionaltransferability whichis used for measuring accuracy robustness in a black box setting can be applicable for energy based testing inputs.
table1 itpamongdifferentarchitectures.rnisresnet bd isblockdrop bnisbranchynet.bmrepresentsbasemodel while tm is target model.
bmtmranbd rn bnbd rn ran .
.
.
.
bd rn .
.
.
.
bn .
.
.
.
bd rn .
.
.
.
table2 etpamongdifferentarchitectures.rnisresnet bd isblockdrop bnisbranchynet.bmrepresentsbasemodel while tm is target model.
bmtmranbd rn bnbd rn ran .
.
.
.
bd rn .
.
.
.
bn .
.
.
.
bd rn .
.
.
.
preliminarystudy.
wehaveconductedastudytoinvestigatethe traditional transferability of energy based testing input on adnns.
to our knowledge this is the first effort to explore the transferability of energy based testing input on adnns.
we define base and target models for this study.
the white box attack is performed on the base model and the target model classifies the testing input.
wefocusontwometricstomeasuretransferability thepercentage ofthetransferableadversarialinputsandtheaveragepercentageofthetransferableenergyconsumptionincrease.wedefinetwoterms effectiveness transferability percentage etp andinput transferability percentage itp .
etpis defined based on incrf which is the fractional increase in adnn reduced floating point operations flops afterfeedingenergy basedtestinginputs.wealsodefine pb andpt theaverage incrfonbaseandtargetmodels respectively with the same testing inputs.
we define etp pt pb .itp is defined as the percentage of testing inputs for which the flops count during inference increases in the target model.
for an attack ifitpis high it means that most of the generated testing inputs for the base model can also increase the energy consumption inthe target model.
if etpis high it means that the average increase inthetargetmodel senergyconsumptioniscomparablewiththe base model.
thus if both etpanditpare high then it confirms transferabilityin the attack.
forexample weattackthebasemodelandperturbteninputs.if theaverage incrfonbasemodelis0.
i.e.
pb .
.ifsevenoutof ten testing inputs increase the flops on the target model itpwill be .
for target model the average incrfis .
.ptwould be .3andetp .
.
.wehavesetmultiple thresholds ofitpandetpto determine whether an attack is transferable.
in this study we explore how many combinations of base adnn and target adnn exceeds the different itpandetpthresholds.
wehaveconductedatransferabilitystudyonfouradnnmodels ranet blockdrop resnet resnet andbranchynet .
images sampled from the cifar dataset were used in thisstudy.wegeneratetestinginputsusingtheilfoattack figure1 sub figure i onthebase model.tables1and 2showthe itpandetpamong the architectures.
from the tables we can see thatonlyfourcombinations outof12 ofbaseandtargetmodels exceedthe50 thresholdforboth itpandetp forotherthresholds we have added a table in the website .
from these results we can conclude that for the majority of adnn models the white box attack is non transferable.
althoughtraditionaltransferabilitymaynotbefeasibleforattackingadnns theobservationofthisfailuremotivatesustodevelop an effective alternative.
specifically our key observation on thenon transferabilityofenergy basedattacksisthattheenergysaving mechanisms of adnn models behave differently for the same input i.e.
an input causing high energy consumption on one modelmightconsumelowenergyforanothermodel.hence extending any white box attack method such as ilfo through surrogate models is not viable in the black box scenario.
approach as we have observed that surrogate models are not feasible to test the energy robustness of adnns we develop ereba an estimator model based black box testing system.
ereba contains two ma jor components namely an estimator model and a testing inputgenerator.
figure illustrates the estimator model s training for anadnnusingitsenergyconsumptiononannvidiatx2server.
theestimatormodeladdressesthechallengeofnon transferability discoveredintheprevioussection.additionally thetestinginput generator in ereba has two modes of testing input based where an input image is perturbed to achieve higher energy consumption and universal where a noisy testing input that can maximize energyconsumptionisgenerated.thesemodesenableerebato assess the energy robustness of each adnn effectively.
figure sub figure ii shows the generation of testing inputs using the trained estimator model.
.
estimator model design traditionally misclassificationblack boxadversarialmethodson dnns are achieved through surrogate models also dnns trained usingtheoutputlabelsproducedbyfeedingthetargetdnnwith originalimages.
testing inputsgeneratedby awhite box method againstthetrainedsurrogatemodelarethenusedagainstthetarget authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa mirazul haque yaswanth yadlapalli wei yang and cong liu testing using estimator modeltesting using surrogate model trained surrogate modeltraining generate loss functionintermediate outputstrained adnn model training estimated energy optimizeroptimize perturbation optimizer optimize perturbation input images with energy consumption tx2 dnn model architecture trained estimator modeloriginal input perturbation perturbation best perturbationtest input test input best perturbation i ilfo ii ereba original inputggmeasure energy and data cleaninginput images with output labeladnn model architecturegship ship car100j 120j 200j figure difference between testing using estimator model and surrogate model dnnasillustratedinfigure1 insidetheblue dottedbox .however this approach is not feasible for the current use case due to a lackoftraditionaltransferabilityinwhite boxattacks section3 .
because building such a surrogate model with the target function ofmappinganimagetoaclasswouldnottransfersimilarenergy characteristics to the surrogate model.
the target function should be the energy saving mechanism in an adnn but the output dimensions of these change with different adnns.
so we need a separate surrogate model for each adnn this is not viable for two reasons.first suchamodelwouldrequireanewneuralnetwork architectureforeachadnn whichmakesithardtoapplytofuture adnnmodels.second theenergy savingmechanisms outputsare intermediate values within an adnn which are not accessible in a black box scenario.
totacklethis webuildanestimatormodeltoemulatethecharacteristicsoftheenergy savingmechanisminadnns.thefeasibilityoftheestimatormodelfollowsfromthefollowingtwokeyobserva tions.
wecanperceivetheenergy savingmechanisms characteristics through system diagnostics such as the energy consumption for each inference which can be observed even in a black box setting.
eventhougheachadnnhasadifferentenergy saving mechanism the resulting energy consumption is always expected tolieinastep wisepattern2 seefigure7andsection7.3formore details.
thus we seek to leverage this patterned energy consumptioninourblack boxapproachtotrainanestimatormodelforeach targetadnnatwhichpointtheestimatormodelcanpredictthe energy consumption of each image.
however the energy consumption of an embedded system such asnvidiatx2isaffectedbynoisefromthesystemenvironment suchasbackgroundprocessesanddynamicfrequencyscaling makingitchallengingtocreateanaccurate model.
further inablackboxenvironment itishardtocategorizewhichdataisnoisy.we do not have any additional information e.g.
number of the executed blocks about the inference our approach has to tackle these challenges.
an overview of theestimator model training is given in figure insidereddottedbox .first wecollectenergyconsumptiondata 2energy consumption of processing an extra residual block or layer in an adnn will alwaysaddsimilarenergyconsumptionintothetotalenergyconsumption making the energy consumption pattern step wise.forimagesusedfortrainingand toaddressthenoiseinthedatadue tothesystemenvironment wedeactivatethedynamicfrequency scaling of nvidia tx2 and ensure that no other user processes are running.additionally werecordtheenergyconsumptionbythe target adnn during inference of an input image twenty times and discard values which are higher than the median value.
we define the mean of the remaining values is defined as f xi where xirepresents an input in the dataset.
we define the estimator s dnn loss function as estimator loss nn i whereestdenote the estimator model and nis the size of the dataset.estimator loss isusedtotraintheestimatorforeachtarget adnn which enables the model to give a reasonable prediction of energy consumption of the target adnn for a given input.
.
testing input generator the objective of the testing input generator is to create testing inputs that increase the estimator model s prediction which in turnshould increasethe actualenergy consumptionof theadnn.
we explore two use cases of ereba input based test and universal test for measuring the input based and universal energy robustness as defined in section .
.
.
.
input based testing.
in this use case we modify the input imageinsuchawaythatitisimperceptiblebyahuman andthe resultingtestinginputhashigherenergyconsumptiononthetarget adnn.wethusaddaperturbation itotheinput xi.pickingthe best i i can be formulated as i argmax iest xi i .
additionally wehavetoensurethatthemagnitudeofperturbation isalsosmallashighermagnitudeperturbationsaremoresusceptible to detection.
we can reformulate the maximization problem to a minimization problem as follows minimize i i c est xi i where xi i n wherec is a hyperparameter chosen through grid search depending on the adnn model.
also ccontrols the magnitude of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ereba black box energy testing of adaptive neural networks icse may pittsburgh pa usa generated perturbation i where a large cmakes the loss function more dependant on the energy estimate allowing for larger perturbations.whereasasmaller cmakesthelossfunctionmore dependant on i .
hence cand i are directly proportional.
this constrained optimization problem in ican be converted into a non constrained optimization problem in wi where the relationship between iandwiis i tanh wi xi thetanhfunctionwouldensurethatthegeneratedtestinputvalues staybetween0and1.theequivalentoptimizationproblemin wi is minimizewi arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowverttanh w i xi arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert arrowvert c est tanh w i .
.
universal testing.
in this use case erebagenerates a testing inputonlyusingtheestimatormodel.unlikeinput basedtesting whichaddshumanimperceptibleperturbationtooriginalimages universal testing creates noisy testing inputs which can maximize the energy consumption of the target dnn independent of the input.the intuitionbehind thistesting isthatadversaries cansend noisy testing inputs exclusively to increase the system s energy consumptionbecausehumanperceptionmaynotbeaconcernin everyscenario.hencewemodifytheoptimizationfunctionfrom equation to minimizewi est tanh w i algorithm testing input generation using ereba inputs xi inputimage outputs fi perturbedimage 1begin 2initialize wi 3t number of iterations 4iter no 5whileiter no tdo l loss xi wi c lnew wi optimizer l wi iter no 9end 10fi tanhwi 11end both minimization problems can be solved through an iterative approachgivenbyalgorithm1 whichisalsoillustratedinfigure1 sub figure ii inside green box .
the algorithm outputs the testing inputfiwhiletakingthecurrentimage xi notrequiredinuniversal test mode as input.
wiis initialized to a random tensor multidimensional array with a size equal to the input image dimension.
foreachiteration thelossfunctionofthecurrentmode givenin equations2 iscomputed atline6 .thislossisback propagated and the optimizer takes a step in the direction of the negative gradientofthelossw.r.t wiandupdates wiwithitsnextvalue.once the iteration threshold t is reached the algorithm computes and returns the testing input fi at line .
in the universal test mode this algorithm is repeated for nrdifferent random initializations of wi out of which wicorresponding to the lowest loss value is used for computing fi.
evaluation we evaluate the performance of erebaon three popular adnns ranet blockdrop andbranchynet interms of four research questions rqs rq1 effectiveness.
how much increase in energy consumption is achievable by the testing inputs generated by ereba?
rq2 sensitivity.
howdoestheenergyconsumptionofadnns react to limiting the magnitude of perturbation in ereba?
rq3 quality.
what is the difference in semantic quality between original images and testing inputs generated by ereba?
rq4 robustness.
iserebarobust against distribution shifts?
.
experimental setup datasets.
for all adnn models the cifar and cifar datasets have been used to train the estimator model andgeneratetestinginputs.boththedatasetsconsistof50000training and test images where cifar and cifar have 10and100classlabels respectively.byusingthesetwodatasets we show that erebais useful for both easier cifar and more complex prediction cifar tasks.
baseline.
as there are no existing black box energy testing frameworks we compare our technique with two different types of baseline techniques.
first we compare our techniques with realworld corruption and perturbation techniques like fog frost .
the datasets generated from these techniques are commonly used totesttherobustnessofneuralnetworks.second weuse a surrogate model technique that utilizes ilfo to generate testing inputs.
commoncorruptiontechniques containdifferentvisualcorruption whichincludespracticalcorruptionslikefog snow frost.
we use different corruption types and for each type five visual corruptions are created from severity level one to five resulting in atotalof95differentvisualcorruptions.intheimagesgenerated by common corruption techniques the noise present in the inputs is human perceptible.
commonperturbationtechniques use14practicalperturbationtypes foreachoriginalinput 30differentimagesarecreated with different amounts of perturbation.
with perturbation slightly perturbed images are generated that are difficult for humans to differentiate from the original images.
otherthanusingcommoncorruptionsandperturbations we also use the surrogate model based technique as a baseline.
for thisapproach wecreateasurrogatemodelforeachadnnanduse thesurrogatemodeltogenerateadversarialimages.asweseein tables1and2thatadversarialinputsgeneratedusingblockdrop as the surrogate model are more effective on other adnns weadd a baseline that uses blockdrop as a surrogate model and is referredtoassurrginthefollowingssections.foreachadnn we firstclassify50000cifar 10andcifar 100trainingdataonthe target adnnand basedon itsoutputs andwe trainthe surrogate model.
then we use the ilfo attack on the surrogate model togenerate test inputs.
we use surrogate model to generate bothlimited perturbation input based surrg and noisy universal surrg test samples.models.
we have selected adnn models where the range of maximum energy consumption during inference is large j 160j .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa mirazul haque yaswanth yadlapalli wei yang and cong liu table hyperparameters of ereba mode adnn clearning rate tnr input basedblockdrop .
500branchynet .
500ranet .
500universalblockdrop .
branchynet .
ranet .
weshowthat erebacanbeusedagainstadnnmodelswithboth higher and lower number of parameters.
adnn blockdrop is built modifyingresnet 110architectureandtrainedoncifar .while for training using cifar dataset blockdrop is built modifyingresnet 32architecturebecauseresnet 110blockdroparchitecturetrainedoncifar 10datasethasshownlessadaptability.resnetarchitecture starts with a 2d convolution layer which is followed by residualblocks.blockdropselectswhichblockstoexecutethrough policy network for blockdrop.
both ranet and branchynet aremulti exit networks where operation can be terminated in oneof the earlier exits based on the confidence score of the exit.
the estimatormodelisa resnet withtheoutputfullyconnected tennodelayerchangedtoafullyconnectedsinglenode.theloss functionischangedtothefunctiondefinedinsection4.
.hyperparameters chosen by the estimator model c learning rate number ofiterations t foreachadnnmodelareintable3 reasonsfor choosing these parameters are given in section .
.
.
these are parameters used for the results reported in sections .
.
and .
.
whereas section .
.
reports the behaviour of erebawhenc tare changed.hardwareplatform.
we usethenvidia jetsontx2 boardforour energyconsumptionmeasurements whichareusedtotrainthees timatormodel.bydefault tx2hasadynamicpowermodel whichscalesthecpuandgpufrequenciesbaseduponthecurrentsystemload whichaddsadditionaluncertaintytotheenergyconsumption measurements.
to combat this we set the tx2 board to max n mode which forces cpu and gpu clock to run at their maximum possible values which are .
ghz and .
ghz respectively.
jetsontx2modulehastwopowermonitorchipsonboardfor measuringpowerconsumption.oneofthepowermonitorsmeasures the power consumption of cpu gpu and soc as in fig.
of the user manual of nvidia tx2 .
during the inference processoftheadnns wemeasurethepowerconsumptionofgpu using a monitor program.
since the monitor program only usesthe cpu the program does not affect the energy measurement.
additionally tx2 internal power monitors have been validated by otherstudiessuchass.k hleretal.
seefig1b.
whereitis shown that the power measurements using the internal monitor chips collaborate with external measurement techniques.
as stated in oneconcernwithusingtheinternalchipsisthatthepower consumptionfromthecarrierboard fan andpowersupplyisnot measured whichcomesouttobearound2w.however sinceour studymeasurestheeffectofvarioustestinginputs whichcannot affect such components behavior and both measurements testing input original image ignore the consumption from these com ponents the conclusions drawn are valid.
further to ensure the collected energy consumption data is correct we run the inference twenty times and discard values outlier values that are higher a original b testing inputs figure testing inputs generated by erebafor blockdrop in input based testing mode thanthemedianvalue.themeanoftheremainingvaluesisused as the single energy consumption value reported.metrics.
we evaluate the effectiveness and robustness of ereba using the percentage increase in energy consumption for each target adnn energyconsumption fi energyconsumption xi energyconsumption xi wherexiis the input image provided to erebaandfiis the testing inputgenerated.forsensitivity rq2 measurements weusethe incrementinenergyconsumptioninjoules j tobettercompare sensitivity between target adnns and use the average squared difference in pixels values between the input image and the testing input to quantify the magnitude of the perturbation.
the testing inputs qualityismeasuredusingpeaksignaltonoiseratio psnr andstructuralsimilarityindex ssim becauseofusage of these metrics in the industry to measure image quality.
.
experimental results .
.
rq1.effectiveness.
toevaluatetestingeffectivenessby ereba wehavemeasuredtheaverage percentageincreaseineachadnn model s energy consumption between the original images in the datasetandthecorrespondingtestinginputsgeneratedby ereba.
we compare the effectiveness of universal testing against the commoncorruptiontechniques because inbothapproaches noise introduced to the inputs is human perceptible.
whereas inputbasedtestingaddsimperceptibleperturbationtotheinput hence wecompareagainstthecommonperturbationtechniques .the hyperparameters chosen for each model are in table .
parameters vary between adnns due to variations in input normalization whichisonlyappliedinbranchynetandranet.weevaluateon imagesfromthecifar 10andcifar 100datasets whichhavea considerable reduction in the energy consumption on the target adnns .
the estimator models have been trained on cifar and cifar training images.
we apply common corruption and perturbation techniques to cifar and cifar test images.
as there are numerous corruption and perturbation techniques weonly report the bestperforming techniques i.e.
highestincrf for each adnn model for the incrf valuesofothercorruptionsandperturbations pleaseseethewebsite3 table reports the exact corruption perturbation technique.
table5reportsthemeanpercentageincreaseinenergyconsumption of theadnn models under ereba universal input based testings andthebaselinesonthecifar 10dataset.figure2illustrates some input based testing inputs generated by erebafor blockdrop.
we observe that erebainput based testing inputs dominate authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ereba black box energy testing of adaptive neural networks icse may pittsburgh pa usa table corruptions and perturbations we have used for comparisonforeachmodel.
corrrepresentscorruptionsand perrepresents perturbations.
data typemodels blockdrop branchynet ranet best corr cifar contrast impulse noise contrast best per cifar gaussian blur snow gaussian blur best corr cifar contrast impulse noise fog best corr cifar zoom blur zoom blur shot noise table5 meanpercentageincreaseinenergyconsumptionof themodelsforcifar 10datasetagainst erebaandbaseline techniques.
perturbationtypemodels blockdrop branchynet ranet universal testing ereba .
.
.
best corr .
.
.
universal surrg .
.
.
input based testing ereba .
.
.
best per .
.
.
input based surrg .
.
.
the baseline methods for mean energy increase on branchynet.
whereasforblockdrop becausesurrghasblockdropasitsarchitectureandilfoisawhite boxmethod itisexpectedtooutperform ereba a black box method.
interestingly for ranet common perturbation techniques induce a much higher energy increase thanthecorruptiontechniques whichisquitedifferentfromthebehavior observed in the other adnns.
while erebaunderperforms the perturbations in terms of energy consumption increase ereba stilloutperformssurrg.also weobservethatforalladnns samples generated through universal testing outperform the baseline techniques.
furthermore for branchynet and ranet due to fewer executionmodes twoinbranchynet andeightinranet theenergy consumption is higher than blockdrop up to more than the original data with 254modes.
forthecifar 100dataset table6showstheaveragepercentage increase in energy consumption for erebaand the baseline techniques.wenoticethat erebageneratedinputsoutperformcommon corruptionandperturbationtechniquesforallthreeadnns.similar to the cifar dataset surrg generated inputs consume more energy than erebagenerated inputs only for theblockdrop model.
for ranet universal testing inputs can not significantly increaseenergyconsumptionbecauseranetalwayspredictsan inputwithhighnoiseasroadorshrewwithhighconfidence therefore the inference is stopped at initial exits resulting in lower energy consumption.
nevertheless the input based testing inputs canincreaseupto4000 energyconsumptionoftheoriginalinputs for the ranet model.
thus we conclude that on average over all threeadnnmodels erebaperformsbetterthananyotherbaseline technique in terms of increasing energy consumption.
.
.
rq2.
sensitivity.
we define the sensitivity of erebain terms of the magnitude of the perturbation i .
intuitively if an adnn model s energy consumption spikes up with a relatively loweraverage perturbation magnitude then that model is less robust.table6 meanpercentageincreaseinenergyconsumptionof themodelsforcifar 100datasetagainst erebaandbaseline techniques.
perturbation typemodels blockdrop branchynet ranet universal testing ereba .
.
.
best corr .
.
.
universal surrg .
.
.
input based testing ereba .
.
.
best per .
.
.
input based surrg .
.
.
a cifar b cifar figure average energy consumption increase of testing inputsconstrainedbymagnitudeofperturbationforblock drop branchynet and ranet.
weknowthat cand i aredirectlypropositional giventhatthe number of iterations is constant.
through empirical observations t is sufficient to achieve convergence in erebafor all adnn models.notethatsensitivitycannotbecomparedusingthemagnitude of cas only branchynet and ranet use normalization filters whereas blockdrop does not which makes the optimal cof branchynetandranetlarger seetable3 .tomeasurethemagnitude of perturbation for a set of c t we measure the average squareddifferencebetweenthetestinginputandtheinputimage which is defined as follows average squared difference nn i xi fi wherexiis the input image and fiis its corresponding testing input.
figures 3a and 3b show the average percentage increase inenergyconsumptionversustheaveragesquareddifferenceon the cifar and cifar datasets.
we observe that for both datasets compared to blockdrop branchynet and ranet are more sensitivetotheperturbationmagnitude.blockdrop slowersensitivityismainlyduetoblockdrop spolicynetwork whichprovides morerefinedcontroloverenergyconsumption henceblockdrop ismorerobustthantheothertwoadnns.additionally wecanseethepotencyoftheestimatormodelforeveryadnnmodel.adirect proportionality between the average increasein energy consumptionandtheaveragesquareddifferenceisobservedinalltheadnn models whichisevidencethattheestimatormodelissuccessful inimitatingtheenergyconsumptionofeachadnn.additionally we observe that erebaperforms very similarly for both cifar and cifar datasetsfor blockdrop andbranchynet.
whereas authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa mirazul haque yaswanth yadlapalli wei yang and cong liu a psnr between original and generated images b ssim between between original and generated images.
figure quality of the generated images for each adnn model for cifar dataset a psnr between original and generated images b ssim between between original and generated images.
figure quality of the generated images for each adnnmodel for cifar dataset for ranetfor cifar theenergy spike inducedis much higher thanthatforcifar indicatingthatthecifar 100ranetis more robust than the cifar version.
.
.
rq3 quality.
in this section we evaluate the quality of the perturbationgeneratedbyinput basedtestingof erebawiththe hyper parameters set to the values given in section .
using peak signal to noise ratio psnr and structural similarity index ssim .
bothof these metricsare used in theindustry to measure the image quality of noisy images.
snr of an image can be represented by snr image image where imageisthemeanvalueoftheimagepixelsand imageis theerrorvalueofthepixelvalues.
forpsnr thehighestvalueof theimagepixelsisusedinsteadofthemeanvalue.thestructural similarity index ssim is a perceptual metric that quantifies the image quality degradation caused by processing such as data com pression or by losses in data transmission.
higher values for ssim and psnr indicate higher quality test inputs.
figure4andfigure5showthevaluesofssimandpsnrbetween thetestinginputsandtheoriginalimagesforcifar 10andcifar100 datasets.
for both datasets we see that ssim for the generated testinginputsissimilarforallthetargetadnns.whereaspsnrforranetisworsebutstillcomparabletoblockdropandbranchynet.
weconcludethatmostoftheinputsgeneratedthroughinput based testing are of high quality even if some test inputs might have noise they are structurally similar to the original inputs.table effect of corruptions on ereba.
average percentage increase in energy consumption for all adnn models for various corrupted inputs from cifar and cifar .
adnn dataset normal frost fog snow ranetcifar .
.
.
.
cifar .
.
.
.
branchynetcifar .
.
.
.
cifar .
.
.
.
blockdropcifar .
.
.
.
cifar .
.
.
.
.
.
rq4 robustness.
erebaestimatesenergyconsumptionbased onthetrainingdata whichcanbeimpactedbydistributionshift .
therefore to evaluate the robustness of erebaagainst distribution shifts wehaveanalyzedthebehaviorof erebaagainstpracticalcorruptions.practicalcorruptions e.g.
fog snowetc.
arefrequently noticed mainly when we use mobile phones or autonomous ve hicles to take images.
for this purpose we have used real world common corruption techniques .
table shows the average percentage increase in energy consumption for the testing inputs generated using the original and corruptedimagesofcifar 10andcifar 100by erebaininputbased testing.
we picked the corruption classes of fog frost andsnow due to their natural occurrence.
in general the corruptedimages do not hinder the performance of erebaexcept for the cifar version of ranet.
in other cases the increase in energy consumption achieved by erebausing corrupted images is in fact higher than that achieved using the original cifar and cifar100datasets.thisismainlyduetothecommoncorruptions introducing better initialization spots white areas .
for cifar ranet erebamanagestoincreasetheenergyconsumptionslightly.
however similar to the universal testing case inputs with high noiseareclassifiedasroadorshrewwithhighconfidence which leads to lower performance in comparison to other settings.
additionally throughtheseresults wefurthernoticethehigh stabilityoftheestimatormodelinapproximatingtheshortcomings ofthetargetadnns.
erebacangeneratehighenergy consuming testinginputsdespitethecorruptionofimages.whilethereissome variance in how erebabehaves when provided with an image with different corruption classes the median energy consumption increment is consistent for all target adnns.
increasing energy robustness in this section we demonstrate two ways to increase the energy robustness of adnns.
in both ways we use prior erebagenerated inputs to detect new erebagenerated energy surging inputs for adnns.
for detecting universal test inputs we use input filtering method based on pixel values while for detecting input based test inputs we use gradient based input detection.input filtering.
as we can notice that noisy samples generated fromuniversaltestingcanincreaseenergyconsumptionbyasignificantamount henceitisessentialtoadapttheadnnmechanism against these noisy images.
for traditional dnns highly noisy images consumethe same energyas the standard imagesand are no threattotherobustnessofthednn theobjectisnotvisibleinthose noisy images .
to adapt adnns against high energy consuming images we propose to include a filter in adnns.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ereba black box energy testing of adaptive neural networks icse may pittsburgh pa usa as a filter we have created a resnet model binary classifier with only six residual blocks.
the classifier can classify into two categories normal input andenergy consuming noisy input .
for each adnn we have trained the resnet model with normal dataset images and high energy consuming noisy images creating three different trained resnet models.
for testing the models images have been used from each class .
our results show that the filter can identify each test image with the correct class accuracy for all three adnns for both datasets.
theresultsconfirmthatwecanfilterouthighenergy consuming noisy images with a model whose energy consumption is low.gradient based input detection.
in contrast to detecting adversarial inputs similar to the samples generated by the universal testingmode adversarialinputssimilartothesamplesgenerated by the input based testing mode are harder to differentiate frombenign inputs.
additionally the energy constraint on such a detectionsystemisasignificantchallenge.therefore thedetection techniquemust consumesignificantlylow energywithrespectto theenergyconsumedbyinput basedtestinginputsduringinfer ence.
to address these challenges we propose a gradient based adversarialinputdetectionmechanismthatusespartialinference from the adnn.
in this detection mechanism we leverage the behavior of the energy saving mechanism within various adnns.
these mecha nisms in general try to ensure that the difference between an intermediate output and a predefined condition is large which will deactivate certain parts of the adnn.
in other words if the loss function of intermediate outputs is large for any input the energy consumption will be low .
therefore if the gradients of the intermediatelossfunctionwithrespecttotheweightsarelarge the input is more likely to be a benign input.
hence we only need partialinference weightgradientsofaninitiallayer fromtheadnns and a linear svm to detect the energy surging inputs where both are low energy consuming steps.
so the energy impact of our detectioncomponentissignificantlylow.iftheinputispredicted as energy surging by the detector the inference is stopped early.
toevaluate ourdetection component we generateinput based testinginputsforcifar 10andcifar 100trainingandtestdatasetsforallthreeadnns.next wecalculatethegradientsoftheweights with respect to the intermediate loss function for the training sectionofdatasets.forallthreeadnns weconsidertheweightsof thefirstlayeroftheadnn.specificallyforblockdrop wecalculate the intermediate loss function of the policy network whereas for ranetandbranchynet weusethefirstexit slossfunction section .
.
after calculating the weight gradients for the training section ofdatasets welabelthemaseitheroriginalortestinginputsand use them for training an svm binary classification model for each adnn.finally wetestthesvmclassifiersonthegradientsgeneratedby theoriginaland input basedtesting inputforthe testing section of datasets.
table8showsthedetectionaccuracy andaucscore of ourgradient basedinputdetectiontechnique.aucscorecomputes the area under the receiver operatingcharacteristic curve roc auc and measures the efficacy of any binary classifier with higheraucscorescorrespondingtobetterclassifiers.theresults showthatin5outof6scenarios bothaucscoreishigherthan0.
and the detection accuracy is higher than percent showing ourtable detection accuracy auc score accuracy drop percentage adversarial energy decrease percentage andbenignenergyincreasepercentageofthegradient basedin put detection incorporated in to various adnn models adnn dataset detection aucacc drop adv eng dec ben eng inc ranetcifar .
.
.
.
.
cifar .
.
.
.
.
branchynetcifar .
.
.
.
.
cifar .
.
.
.
.
blockdropcifar .
.
.
.
.
cifar .
.
.
.
.
approach s efficacy.
additionally we also report the accuracy drop of the adnns due to false positives from the detection system.
we observe that the accuracy drop is minimal in all cases except for the cifar blockdrop model.
furthermore to demonstrate the benefits of our gradient based detectionsystemfromtheenergyperspective wealsoreportthe average energy decrease percentage for an adversarial input adv eng dec and average energy increase percentage for a benigninput ben eng inc .
we observe that our detection system cansignificantly reduce energy consumption induced by adversarialinputs up to while introducing minimal energy burden as evidenced by a low increase in consumption for benign inputs.
discussion wediscussthealternativedefenseforadnns theadaptabilityof adnnsondifferentdatasets andtherelationshipbetweenblock activation and energy consumption of adnns.
also we discuss correlation between measured and estimated energy consumption and the correlation between energy consumption increased by different techniques.
.
alternative defense.
wehaveinvestigatedtheapplicationofadversarialtrainingasan alternative defense mechanism against erebagenerated energysurging inputs.
to understand the effect of adversarial training on adnns we use the erebagenerated testing inputs for cifar dataset to retrain the original adnns.
we used input based testing inputsgeneratedfrom1000imagesofthecifar 10trainingdatasetasthetrainingsetandretrainedthebranchynetandranetadnns for150epochswithalearningratesameparametersastheinitial training.
we generate the test set using a batch of images from the cifar test dataset.
we found that adversarial training does notincreasetheenergyrobustnessforalladnnmodels.specifically ranet is easier to improve using adversarial training compared to branchynet.duetospaceconstraints wehavereportedtheresults for adversarial training in our website4.
.
adaptability of adnns inour observations weseethat adnnsmay notbeadaptiveun der all circumstances.
each adnn can decrease its flops count however thismaynotalwaysresultinconcreteenergyconsumptionpatterns.figures6a 6b 6c and6dshowblockdrop resnet110 and skipnet models adaptability on cifar and imagenet authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa mirazul haque yaswanth yadlapalli wei yang and cong liu a adaptability of blockdrop rn on cifar dataset b adaptability of skipnet on cifar dataset c adaptability of blockdrop rn on imagenet dataset d adaptability of skipnet on imagenet dataset figure adaptability of adnns on imagenet and cifar100 dataset.
datasets.wecanseethattheblockdrop sadaptability thedifferencebetweenthehighestandlowestnumberofactivatedblocks for both datasets is limited less than .
for skipnet the range of adaptability is better than blockdrop s range.
.
comparison to misclassification attacks we can assume that the energy saving mechanisms of conditionalskipping networks like blockdrop would classify an image into n categories.
nis the number of blocks in the dnn with each image in category iactivating i the first block is always active blocks.whereasforthecaseofearly terminationnetworkssuch asbranchynetandranet theyclassifyanimageinto ecategories whereeis the number of exits in the network.
howev er due to noisefromthesystemenvironment ourestimatormodelcannot differentiate between all the classes.
figure shows the scatter plotsbetweentheseimageclassesandtheirenergyconsumption for each adnn model.
we can see the step wise pattern in the plot foralltheadnnmodels.theestimatormodelistrainedtolearn this pattern of energy consumption of adnns.
.
correlation between actual energy consumption and estimated energy consumption toillustratethecorrelationbetweenenergyconsumptionpredicted bytheestimatormodelandoriginalenergyconsumption weuse the pearson correlation coefficient r and correlation p value.
iftwosetsofvaluesarecorrelated thervaluewouldbesignificant and the p value will be low.
for cifar dataset the r values are .
.
and .
for ranet blockdrop and branchtnet models respectively where allthep valuesarelessthan0.
.theseresultsconcludethatthe values are correlated.
forcifar 10dataset thevalueofrforranetis0.
however p value is .
therefore it is more likely that the values are correlated.forblockdropmodel thevalueofrandp valueare0.004and .
which suggests that the values are less likely to be correlated.
butifweconsideronlytheinputswhoseenergyconsumptionis higher than the 75th percentile value the p value becomes .
suggestingacorrelation.therefore iftheestimatormodelcanaccuratelypredicthighenergy consuminginputs i.e.
differentiate clearlybetweenlow midandhighenergy consuminginputs we can use the estimator model to generate energy expensive testing inputs.
.
correlation of increase of energy consumption between different techniques inthissection wetrytoexplorethecorrelationbetweenenergyconsumption modified by input based testing and baseline techniques.
weusepearsoncorrelationforthatpurpose.pearsoncorrelation isoneofthemetricsthatcanfindthestrengthoftherelationship between two variables.
for cifar data we show the table9 that represents the pearson correlation coeff r and p value betweenthepercentageofenergyconsumptionincreasedbyinput basedtestinginputsandenergyconsumptionincreasedbybaseline techniquegeneratedinputs.itcanbenoticedthatformostofthe cases the energy increase percentages are less likely to be cor related.
only for branchynet we can find a significant negative correlation between input based and perturbation induced energy consumption increase.
table correlation between the percentage of energy consumption increased by input based testing inputs and per centage energy consumption increased by baseline tech nique generated inputs for different models for cifar 100data modelsbaseliner perturb p value perturb r surrg p value surrg ranet .
.
.
.
blockdrop .
.
.
.
branchynet .
.
.
.
related works adnns.among conditional skipping models hua et al.
and gaoetal.
explorechannelgatingtodeterminecomputational blind spots for channel specific regions unessential to classifica tion.
liu et al.
propose a new type of adnn which utilizes reinforcementlearningtoachieveselectiveexecutionofneurons.
skipnet uses gating techniques to skip residual blocks.
on the other hand graves et al.
figurnov et al.
and teerapittayanon et al.
propose sact and branchynet respectively which are early termination adnns.
sact terminates the computation within a residual block early based on intermediate outputs while branchynet uses separate exits within network for early termination.cascadingmultiplednnswithvariouscomputational authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ereba black box energy testing of adaptive neural networks icse may pittsburgh pa usa a b c figure energy consumption of a ranet b blockdrop c branchynet for cifar training set coststhroughasinglecomputationunittodecidewhichdnnto executehasbeenproposed.thecascadingmodelsusevarioustechniques such as termination policy reinforcement learning and gating techniques to achieve early termination.
adversarial examples.
adversarialexamplesarethesynthesizedinputs thatis ableto modifytheprediction ofthe mlmodel.
szegedyet al.
and goodfellow et al.
propose white box adversarial attacks on convolutional neural networks.
papernot et al.
have used surrogate model to attack a dnn in black box setting.liu etal.
useensembleofmultiplewhite boxmodelsto generate adversarial examples which can attack black box models.
ilyasetal.
useevolutionarysearchstrategiestoestimatethe gradient of a model to attack black box models.
however all these attacks focus on changing the prediction and do not concentrate on increasing test time.
ilfo is the first work to attack a dnn by increasing the energy consumption of the model.
however ilfo uses white box setting and does not have transferability.
therefore ilfo can not be used for black box attack.
next deepsloth uses modified pgd to attack against earlytermination adnns using the confidence scores in each exit.
however deepslothcannotbeusedagainstconditional skippingadnns.
also deepsloth provides a study about the transferability of the attack.
the study considers the efficacy of the early termination models as the transferability metric.
however we propose a more systematic transferability study by introducing of metrics like etp and itp.dnn testing.
multiple testing methods have been proposed recently to test dnns.
deepgauge is proposed based on a test criteria set that verifies the corner neuron activation values.
deepxplore proposestocovereachneuron sbinaryactivation statusanduseneuroncoveragetotestdnns.deeptest tests autonomousdrivingcarsbyusingneuroncoverage.recently deephunter proposestousecoverage guidedfuzztestingondnns.
erebaevaluates the energy robustness of adnns in a black box settingunliketheaforementionedtechniques whicharefocusedon testingtheaccuracy robustnessoftraditionaldnnsinwhite box setting conclusion inthispaper wehaveproposedpracticalblack boxtestingmethods to evaluate energy robustness of adnns.
the core idea behind the technique is to create inputs which increase the energy consumption of adnn to a higher level.
to achieve this goal we have presented ereba5 wherewehaveproposedtwotypesoftesting universaltestingandinput basedtesting.toourknowledge we are the first to explore black box testing on adnns.
test inputs generated by erebacan improve the energy robustness of adnns.
finally thispaperalsoanalyzesthebehaviorofadnnsandsuggests model improvement strategies.
acknowledgement this work was partially supported by siemens fellowship and nsf grant ccf .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa mirazul haque yaswanth yadlapalli wei yang and cong liu