gifdroid automated replay of visual bug reports for android apps sidong feng monash university melbourne australia sidong.feng monash.educhunyang chen monash university melbourne australia chunyang.chen monash.edu abstract bug reports are vital for software maintenance that allow users to inform developers of the problems encountered while usingsoftware.
however it is difficult for non technical users to write cleardescriptionsaboutthebugoccurrence.therefore moreand more users begin to record the screen for reporting bugs as it is easy to be created and contains detailed procedures triggering the bug.
but it is still tedious and time consuming for developers to reproduce thebug due to thelength and unclearactions within therecording.toovercometheseissues wepropose gifdroid alightweightapproachtoautomaticallyreplaytheexecutiontracefrom visualbugreports.
gifdroid adoptsimageprocessingtechniques to extract the keyframes from the recording map them to states in guitransitionsgraph andgeneratetheexecutiontraceofthose statestotriggerthebug.ourautomatedexperimentsanduserstudydemonstrateitsaccuracy efficiency andusefulnessoftheapproach.
ccs concepts software and its engineering software testing and debugging.
keywords bug replay visual recording android testing acm reference format sidong feng and chunyang chen.
.
gifdroid automated replay of visualbugreportsforandroidapps.in 44thinternationalconferenceon software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction software maintenance activities are known to be generally expensive and challenging and one of the most important maintenance tasks is to handle bug reports .
a good bug report is detailed with clear information about what happened and what theuserexpectedtohappen.itgoesontocontainareproduction step or stack trace to assist developers in reproducing the bug and corresponding authors permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
information such as screenshots error logs and environments.
as long as this bug report is accurate it should be straightforward for developers to reproduce and fix.
bugs are often encountered by non technical users who will document a description of the bug with steps to reproduce it.
however clear and concise bug reporting takes time especially for non developer or non tester users who do not have that expertise and are not willing to spend that much effort .
a poorly writtenreportwouldbeevenpoorlyinterpreted which oftendevolvesintothefamiliarrepetitivebackandforthandthe need to nag that comes with every single bug.
that effort may further prohibit users contribution to bug reporting.
compared to writing it down with instructions on how to replicate video basedbugreportssignificantlylowerthebarfordocumentingthebug.first itiseasytorecordthescreenasthereare many tools available some of which are even embedded intheoperatingsystembydefaultlikeios andandroid .
second videorecordingcanincludemoredetailandcontextsuchas configurations andparameters henceitbridgestheunderstanding gap between users and developers.
that convenience may even betterengageusersinactivelyprovidingfeedbacktoimprovethe app.
despitetheprosofthevideo basedbugreport itstillrequires developerstomanuallycheckeachframeinthevideoandrepeatit intheirenvironment.accordingtoourempiricalstudyof13 bug recordings from android apps in section one video isof .
frames on average with a varied resolution for manual observation.inaddition only6.
ofvideorecordingsstartfrom the app launch and most recordings begin steps before the bug occurrence indicatingthatdevelopersneedtoguessstepstothe entryframeofthevideobythemselves.therefore itisnecessarytodevelopanautomatedbugreplaytoolfromvideo basedbugreports to save developers effort in a bug fix.
therearemanyrelatedworksonbugreplaybutrarelyrelated to visual bug reports.
some researchers leverage the natural language processing methods with program analysis togenerate the test cases from the textual descriptions in bug reports.
however thoseapproachesdonotapplytovideo basedbugreports.
there are platforms providingboth video recording and replaying functionalities whichalsostorethelow levelprogram execution information.
they require the framework installation or app instrumentation which is too heavy for end users.
users tend tousegeneralrecordingtoolstogetthevideothatonlycontains the visual information according to our observation in section .
.
automation for processing general recordings to reproduce bugs is necessary and would help developers shift their focus toward bug fixing.
ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa feng et al.
toautomatetheanalysisofbugrecordings weintroduce gifdroid a light weight image processingapproach to automatically replay thevideo gif basedbugreportsforandroidapps.first weextract keyframes i.e.
fully renderedguis ofarecordingby comparing the similarity of consecutive frames.
second a sequence of located keyframes is then mapped to the gui states in the existing utg ui transition graph of the app by calculating image similarity based on pixel and structural features.
third given the mapped sequence we propose a novel algorithm to not only address the defective mapped sequence but also auto complete the missing trace betweenapplaunchtotheentryframeofthevideo resultinginan optimal execution trace to automatically repeat the bug trigger.
toevaluatetheeffectivenessofourtool wecreatethegroudtruth by manually labelling video recordings from apps.
as our approachconsistsofthreemaincomponents weevaluatethemone byoneincludingkeyframelocation guimapping andtracegeneration.inalltasks ourapproachsignificantlyoutperformsother baselines and successfullyreproduce82 video recordings.
apart from the accuracy of our tool we also evaluate the usefulness of ourtoolbyconductingauserstudyonreplayingbugsfrom10realworld videorecordings ingithub.
throughthe study weprovide theinitialevidenceoftheusefulnessof gifdroid forbootstrapping bug replay.
the contributions of this paper are as follows the first light weight image processing based approach gifdroid toreproducebugsforandroidappsdirectlyfrom the gif recordings with code released for public1.
a motivational empirical study of large scale recordings within real world issue reports from github including their content length etc.
a comprehensive evaluation including automated experiments and a user study to demonstrate the accuracy efficiency and usefulness of our approach.
motivational mining study whilethemainfocusandcontributionofthisworkisdeveloping an approach to automatically replay the visual bug reports we still carry out an empirical study to understand the characteristics ofvisualbugreports.theoverallstatusofvisualbugreportscan clearly frame the context and motivation of this work and theircharacteristics will be taken into consideration in our approach design.butnotethatthismotivationalstudyjustaimstoprovidean initialanalysistowardsdeveloperssupportingvisualbugreports and a more comprehensive empirical study would be needed to deeply understand it.
.
data collection we choose f droid as the source of our study subjects as it containsalargesetofapps 274atthetimeofourstudy covering diversecategoriessuchasconnectivity financial multimedia.all appsareopen sourcehostedonplatformslikegithub which makesitpossibleforustoaccesstheirissuerepositoriesforanalysis.
we built a web crawler to automatically crawl the visual bug reportsfromissuerepositoriesoftheseappscontainingvisualrecord ings e.g.
animation video withsuffixnameslike.gif .mp4 etc.
or figure1 numberofrecordingsingithubfrom2012to2020 figure example of the issue reports for bug replay.
thereporters provide a visual recording i.e.
gif to help devel opers understand the bug report more clearly.
urlfromvideosharingplatforms e.g.
giphy2 youtube .
it took us two weeks to scan issues from apps and finally mined visual recordings from issues apps .
the dataset consists of gifs and videos.
as shown in figure attaching visual recording in the issue report is more and morepopular.withinthevideo thereisalwayssomeextrainformation e.g.
caption whole screen of the pc face of speaker inadditiontothe appusagescreen.sincetherearemore gifsthan videos we focus on the gif visual recording for brevity in this paper.
2giphy is the most popular animated gif sharing platform serving million users authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
gifdroid automated replay of visual bug reports for android apps icse may pittsburgh pa usa table recording resolution.
ratios occurrences resolution .
.
figure number of frames of each recording.
.
what are in visual recordings?
to understand the content within these visual recordings the first two authors manually check .
gifs and their corresponding descriptions in the issue report.
following the card sorting method we classify those gifs into three categories i bugreplay .mostscreenrecordingsareaboutthebugreplayincludingdetailedproceduresintriggeringthebugs especially forthoserequiringcomplicatedactionswithoneexampleseenin figure .
the visual recordings bridge the lexical gap between users and developers and help developers read and comprehendthe bug report reasoning about the problem from the high level description.
ii issue fixed .
once the issue is fixed developers tend to record the screen to display the update changes along witha checklist for project owners to approve the pull request also those recordings are used for app introduction or answering users feature requests.
iii feature request .
users may use recordings to ask formissing functionality e.g.
providedby otherapps or missing content e.g.
incataloguesandgames andsharingideasonhowto improve the app in future releases by adding or changing features.
.
what are characteristics of bug recordings?
sincethetargetofthisworkistoauto replaythebugrecording we further analyze the characteristics of bug recordings classified in section .
.
due to the difference of devices or users resize ofthevideo theremaybedifferentresolutionsandaspectratiosassummarized in table .
about half of bug recordings are of aspect ratio with varied resolution from high quality 1920x1080 to 960x540.therearealsosomeminoraspectratiosandresolutions users may post process the recording by resizing or cropping arbitrarily according to our observation.
figure3depictsthenumberofframesinvisualbugrecording.
on average there are .
frames per video and some of them areevenwithmorethan500frameswhichrequiredevelopersto manually check and replay in their own settings.
we also find that only recordings .
start from the launch of the app while mostrecordings startfrom 7steps beforethebug occurrence.it indicates that there is no explicit hint to guide developers to the entry frame of the recording and that barrier may negatively influence developers efficiency.
as the important information to show users actions somerecordingscontaintouchindicators e.g.
circle or arrow of the touch position which is animportant resource to replaythebug .however thereareonly155recordings .
enabling the show touches option in our dataset.
developers especially noviceones haveto guess andtry thepotential actions to trigger the target page from the current page.
summary by analyzing issue reports from existing apps crawled from f droid of them are with recordings for bug replay.
a large number of frames and varied resolution make itdifficultfordeveloperstoreplaythemintheirsetting.such phenomenonisfurtherexacerbatedas74.
ofrecordingsare without touch indicators on the screen.
these findings confirm thenecessityanddifficultyofthereplayofvisualbugreports andmotivateourapproachdevelopmentforautomaticreplaying the recordings for developers and testers.
approach given an input bug recording we propose an automated approach to localize a sequence of keyframes in the gif and subsequentlymap them to the existing utg ui transition graph to extractthe execution trace.
the overview of our approach is shown in figure which is divided into three main phases i the keyframe location phase which identifies a sequence of keyframes of an input visual recording ii the gui mapping phase that maps each located keyframe to the guis in utg yielding an index sequence and iii the executiontracegeneration phasethatutilizestheindex sequence to detect an optimal replayable execution trace.
.
keyframe location note that gui rendering takes time hence many frames in the visual recording are showing the partial rendering process.
the goal of this phase is to locate keyframes i.e.
states in which gui are fully rendered in a given visual recording.
.
.
consecutive frame comparison.
inspiredbysignalprocessing we leverage the image processing techniques to build a per ceptual similarity score for consecutive frame comparison basedon y difference or y diff .
yuv is a color space usually used in video encoding enabling transmission errors or compression artifactsto bemoreefficientlymasked bythehuman perceptionthan using a rgb representation .
y diff is the difference in y luminance valuesoftwoimagesintheyuvcolorspace.weadopt theluminancecomponentasthehumanperception a.k.ahuman vision is sensitive to brightness changes.
in the human visual system a majority of visual information is conveyed by patterns of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa feng et al.
figure the overview of gifdroid.
contrastsfromitsbrightnesschanges .furthermore luminance is a major input for the human perception of motion .
since peopleperceiveasequenceofgraphicschangesasamotion consecutive images are perceptually similar if people do not recognize any motions from the image frames.
consider a visual recording braceleftbig f0 f1 .. fn fn bracerightbig wherefnis the current frame and fn 1is the previous frame.
to calculate the y diff of the current frame fnwith the previous fn we first obtain the luminance mask yn ynby splitting the yuv color spaceconvertedbythergbcolorspace.then weapplytheperceptual comparison metric ssim structural similarity index to produceaper pixelsimilarityvaluerelatedtothelocaldifferencein the average value the variance and the correlation of luminances.
indetail thessimsimilarityfortwoluminancemasksisdefined as ssim x y 2 x y c1 2 xy c2 2x 2y c1 2x 2y c2 wherex ydenote the luminance masks yn yn and x x xyarethemean standarddeviation andcrosscorrelationbetween the images respectively.
c1andc2are used to avoid instability when the means and variances are close to zero.
a ssim score is a number between and and a higher value indicates a strong level of similarity.
.
.
keyframe identification.
tomakedecisionsonwhetherthe frame is a keyframe we look into the similarity scores of consecutiveframesinthevisualrecordingasshowninfigure5.thefirst step is to group frames belonging to the same atomic activity according to a tailored pattern analysis.
this procedure is necessary because discrete activities performed on the screen will persist figure an illustration of the y diff similarity scores of consecutive frames in the visual recording.
acrossseveralframes andthus needtobegroupedandsegmentedaccordingly.
there are types of patterns i.e.
instantaneous transitions animation transitions and steady.
instantaneous transitions as shown in figure activity clicking a button the similarity score starts to drop drastically whichrevealsaninstantaneoustransitionfromonescreentoanother.
in addition one common case is that the similarity scorebecomes steady for a small period of time tsbetween two drastically droppings as shown in figure activity .
the occurrenceof this short steady duration tsis because gui has not finished loading.whiletheguilayoutofguirenderingisfast resources loading may take time.
for example rendering images from the web depends on device bandwidth image loading efficiency etc.
animationtransitions figure5activity2showsthesimilarity sequenceofthetransitionswhereanimationeffectsareused forexample the scrolling event.
that is over a period of time the similarity score continues to increase slightly.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
gifdroid automated replay of visual bug reports for android apps icse may pittsburgh pa usa figure6 anexampleofpartialutgonmobileappguiproceeding from state gui to state gui .
steady figure5givesanexampleofaguisteadystatewhere the consecutive frames are similar for a relatively long duration.
wehaveempiricallyset0.954asthethresholdtodecidewhether two frames are similar and frames as the threshold to indicate a steady state.
.
gui mapping it is easy for developers to get the utg of their own app .
therefore instead of inferring actions from the recording we directly map keyframes extracted from the recording to states guiswithintheutg.toachievethis wecomputetheimagesimilaritybetweenthekeyframeandeachguiscreenshotbasedon both pixel and structural features.
the gui screenshot that has the highest similarity score is regarded as the index of the keyframe.
.
.
utg construction.
a gui transitions graph utg of an androidappiswidelyusedtoillustratethetransitionsacrossdifferent guis triggered by typical elements such as toasts pop ups text boxes textviewobjects spinners listitems progressbars checkboxes.
in figure we illustrate how a utg emerges as a resultof user interactions in an app.
starting with the gui the user scrolls down to the bottom of the page gui .
when the user taps abutton theguitransitstothegui .therearemanytools to construct a utg either manually or automatically .
inthispaper weadoptthefirebase awidely usedautomated guiexplorationtooldevelopedbygoogle whileothertoolscan also be used.
.
.
feature extraction.
thebasicneedforanyimagesearching techniquesistodetectandconstructadiscriminativefeaturerepresentation .aproperconstructionoffeaturescanimprove the performance of the image searching method .
according to our observation in addition to the pixel features as that in natural images guiscreenshotsarealsoofadditionalstructuralfeatures i.e.
thelayout ofdifferent components inone page.therefore we adoptahybridmethodbasedontwotypesoffeatures ssim structuralsimilarityindex andorb orientedfastandrotated brief forsearchingthemappingguiscreenshotsintheutg for the keyframe.
whilessimdetectsthefeatureswithinpixelsandstructures i.e.
adetaileddescriptionisdemonstratedinsection3.
.
itstillhas several fundamental limitations that exist in visual recordings e.g.
imagedistortion .toaddressthis wefurthersupplement a local invariant feature extraction method orb.
given an image 4we set up that value by a small scale pilot study.
figure illustration of the execution trace generation.
in dex sequence indicate two types of defective sequences i.e.
missing d and wrong mapping to b respectively.
orb first detects the interest points indicating at which the direction of the boundary of the object changes abruptly or intersection point between two or more edge segments.
then orb converts eachinterestpointintoann bitsbinaryfeaturedescriptor which acts as a fingerprint that can be used to differentiate one feature from another.
a feature descriptor of an interest point is computed by an intensity difference test p x y braceleftbigg if p x p y otherwise wherep x p y areintensityvaluesatpixel x yaroundtheinterest point.
due to the characteristic of local feature extraction orb features remain invariant of scale brightness and also maintain a certain stability of affine transformation and noise.
.
.
similarity computation.
based on the features extracted by ssim and orb we compute a similarity value sssimandsorb respectively.
to compute sorb we adopt the brute force algorithm which compares the hamming distance between feature descriptors.
we compute the sssimusing equation based on similarityonluminance contrast andstructure.wethenfurther determine the similarity scombbetween the keyframe and states in utg by combining two feature similarities score scomb w sorb w sssim wherewisaweightfor sssimandsorb takingavaluebetween0 to .
smaller wvalue weights sssimmore heavily and larger value weightssorbmoreheavily.weempiricallychoose0.5asthe wvalue for the best performance.
based on the combined similarity between the keyframe and each gui screenshot we select the highest score to be the index of the keyframe.
consequently a sequence of keyframes is converted to a sequence of the index in the utg.
.
execution trace generation after mapping keyframes to the guis in the utg we need to go one step further to connect these guis states into a trace toreplay the bug.
howev er this process is challenging due to two reasons.
first the extracted keyframe section .
and mapped guis section3.
maynotbe100 accurate resultinginamismatch of the groundtruth trace.
for example in figure d is missed in theindexsequence2andthesecondkeyframeiswronglymapping authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa feng et al.
to b intheindexsequence3.second differentfromtheuploaded gif which may start the recording anytime the recovered trace in our case must begin from the launch of the app.
therefore thetracegenerationalgorithmneedstoconsiderboth the wrong extraction mapping in our previous steps and the missingtracebetweentheapplaunchandfirstkeyframeinthevisual bug report.
to overcome these issues our approach first generates all candidate sequences in utg between the app launch to the last keyframe from gif.
by regarding the extracted keyframes as a sequence ourapproachthenfurtherextractsthelongestcommon subsequence lcs between it and all candidate sequences.
theoverflowofourapproachcanbeseeninalgorithm1.given an index sequence x x1 x2 ... x n extracted by keyframe mapping where xnis the last node a utg graph g and an app launch nodes.tofindacyclicpaths avoidingdeadloops fromapplaunch node s tolastindexnode xn weadoptdepth firstsearchtraversal thattakesapathon gandstartswalkingonitandcheckifit reaches the destination then count the path and backtrack to take anotherpath.toavoidcyclicpath werecordallvisitednodes line sothatonenodecannotbevisitedtwice.theoutputofthetraversalisasetofacyclicpath seq y1 y2 ... y m wherey1 sand ym xn.
we regard those acyclic paths as the candidate sequences forexecution.forexample infigure7 therearethreecandidate sequences from launch node a to last index node f are found a b c d e f a b c h i f a b c h i e f .
note that a b c d e d e f is omitted due to cyclic.
next foreachcandidatesequence seq weadoptthedynamic programming algorithm to find the lcs to the index sequence x lines in respect to detect how many index nodes are coveredinthiscandidatesequence.therecursivesolutiontodetect the lcs for each candidate sequence seqto index sequence xcan be defined as com 0i fi 0o rj com ifx seq max com com if x seq wherecomtobeatablefor xandseq e.g.
com istherelation between xiandseq j .
a lcs can be found by tracing the table com.
we omit the details of tracing the table as findlcs com due tospacelimitations.notethatweinitializefirstrowandcolumn ofcomas zero to prevent the occurrence of null line .
for example infigure7 thelcssbetweenindexsequenceandthree candidate sequences are c e f c f c e f respectively.
once the lcss are detected we select the candidate sequence thathasthelongestlcsastheexecutiontraceduetoitreplaysmostkeyframes orindexnodes inthevisualrecording.besides ourgoal istohelpdevelopersreproducethebugwiththeleastamountof time steps.
therefore we choose the optimal execution trace with theshortestsequence.forexample infigure7 a b c h i f is omittedduetoitdoesnotreplaythemostindexnodes i.e.
itslcs c f is not the longest .
a b c h i e f is omitted due to it is not the optimal trace i.e.
not the shortest sequence .
therefore theoptimal executiontrace a b c d e f is generated based on the index sequence even defective.algorithm execution trace generation inputs x index sequence x1 x2 x3 ... x n g utg graph s starting node in utg output execution trace find the candidate sequences seqs from app launch node to last index node 1seqs 2seq 3visited false for all nodes in utg 4dfs s xn visited seq 5visited true prevent acyclic sequence 6seq.append s 7ifs xnthen seqs.append seq 9else foreachv g.adj do ifvisited false then dfs v xn visied seq end 14end backtrack to take another path 15seq.pop 16visited false find the lcss between index sequence and each candidate sequence 17foreachseq seqsdo 18letcom be new table 19initialize com prevent null sequence 20fori 1tox.length do forj 1toseq.length do ifx seq then com com else ifcom com then com com else com com end end 30end 31lcss save findlcs com 32end find the execution trace with longest lcss and shortest sequences 33trace seqs 34returntrace automated evaluation of gifdroid in this section we describe the procedure we used to evaluate gifdroid in terms of its performance automatically.
we manually construct a dataset as the groundtruth for evaluating each step within our approach instead of using the real world bug recordingsduetotworeasons.first manyreal worldbugreportshave authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
gifdroid automated replay of visual bug reports for android apps icse may pittsburgh pa usa been fixed and the app is also patched but it is hard to find the correspondingpreviousversionoftheappforreproduction.second the replay of some bug reports e.g.
financial social apps requires much information like authentication database hardware to generatetheutgwhicharebeyondthescopeofthisstudy.therefore we collect visual recordings from open source android apps which were used in previous studies .
they are also top rated on google play covering app categories e.g.
development productivity etc.
.
to make these recordings as similar toreal worldbugreportsaspossible weadoptdifferentwaysfor generatingtherecordingincludingdifferentcreationtools 32from video conversion from mobile apps from emulator screen recording varied resolutions diverse length frames and differed playing speed framespersecond .
for each app we also collect its utg by google firebase.
since our approach consists of three main steps we evaluate each phase ofgifdroid including keyframe location section .
gui mapping section .
and execution trace generation section .
.
therefore we ask two experienced developers to manually label keyframesfromrecordings guimappingbetweenrecordingand utg and real trace in the utg as the groundtruth for each phase.
note that each human annotator finished the labelling individually and they discussed the difference until an agreement was reached.
.
accuracy of keyframe location ground truth to evaluate the ability of keyframe location to accuratelyidentifythekeyframespresentinthevisualrecordings we manually generated a ground truth for the keyframe.
we recruited two paid annotators from online posting who have experiencein bug replay.
to help ensure the validity and consistency of the groundtruth wefirstaskedthemtospendtwentyminutesreading throughthevideoannotationguidelines i.e.
trecvid and get familiar with the widely used annotation tool virtualdub .
then we assigned the set of visual recordings to them to annotate keyframes independently without any discussion.
after the annotation the annotators met and sanity corrected the subtle discrepancies i.e.
3frames .anydisagreementwouldbehanded over toone authorfor the finaldecision.
in total we obtained289 keyframesfor61recordings .73perrecordingonaverage tallying with our observations for real world recordings in section .
.
metrics we employ three evaluation metrics i.e.
precision recall f1 score toevaluate the performance ofkeyframe location.
the predicted frame which lies in the ground truth interval is regarded as correctly predicted.
since there should be only onekeyframe per interval if two or more keyframes are localized ina single interval only the first keyframe is counted as correct.
precisionistheproportionofframesthatarecorrectlypredictedas keyframes among all frames predicted as keyframes.
precision framescorrectlypredicted askeyframes all frames predicted as keyframes recall is the proportion of frames that are correctly predicted as keyframes among all keyframes.
recall framescorrectlypredicted as keyframes all keyframestable performance comparison for keyframe location.
method precision recall f1 score hecate .
.
.
comixify .
.
.
ils summ .
.
.
pyscenedetect .
.
.
gifdroid .
.
.
f1 score f score or f measure is the harmonic mean of precision and recall which combine both of the two metrics above.
f1 score precision recall precision recall for all metrics a higher value represents better performance.
baselines we set up four state of the art methods which are widely used for keyframe extraction as the baselines to compare withourmethod.
comixify isan unsupervisedreinforcement learningmethodtopredictforeachframeaprobabilitytoextract keyframesinthevideos.
ils summ formulatesthekeyframe extraction as an optimization problem using a meta heuristic optimization framework to extract a sequence of keyframes that has minimumfeaturedistance.
hecate isatooldevelopedbyyahoo thatestimatesframequalityontheimageaestheticsandclusters them to select the centroid as a keyframe.
pyscenedetect i sa practical tool implemented as a python library that is popular in github.thecoretechniqueforpyscenedetecttodetectkeyframes isacontent awaredetectionbyanalyzingthecolor intensity mo tion between frames.
results table shows the performance of all approaches.
the performance of our method is much better than that of other baselines i.e.
boost in recall precision and f1 score compared with the best baseline ils summ pyscenedetect .
the issueswiththesebaselinesarethattheyaredesignedforgeneral videoswhichcontainmorenaturalsceneslikehuman plants animals etc.
howev er different from those videos our visual bug recordings belong to artificial artifacts with different rendering processes.
therefore considering the characteristics of visual bugrecordings our approach can work well in extracting keyframes.
ourapproachalsomakesmistakesinkeyframeextractiondue to three reasons.
first within some apps the resource loading is so slow that the partial gui may stay for a relatively long time beyond our threshold setting in section .
.
so that frame is wrongly predicted as akeyframe.
second some usersmay click the button beforetheguiisfullyrenderedtothenextpage.thatshortperiodmakesourapproachmissthekeyframe.third someguismaycon tainanimatedappelementssuchasadvertisementormovieplaying whichwillchangedynamically resultinginnosteadykeyframes being localized.
.
accuracy of gui mapping ground truth to evaluate the ability of gui mapping to accuratelysearchthenearestguiscreenshotintheutg wefirstcollectedtheutgandtheirguiscreenshotsforthoseapps following the procedure outlined in section .
.
.
given the keyframes i.e.
a framefromthegroundtruthinterval weselectedthemostsimilar authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa feng et al.
figure examples of bad cases in gui mapping.
guiscreenshotintheutgasthegroundtruthforguimapping.
notethat labellingwas finishedby twoannotatorsindependently without any discussion and any disagreement would be handed over to one author for the final decision.
thus we obtained ground truth pairs of keyframes and gui screenshots.
metrics weformulatetheproblemofguimappingasanimage searching task i.e.
search the most similar gui screenshot so we adoptprecision ktoevaluatetheperformanceofguimapping.
thehighervalueofthemetricis thebetterasearchmethodperforms.precision kistheproportionofthetop kresultsforaquery gui that contains the grouptruth one.
note we only consider kin therange1 asdevelopersrarelycheckalongrecommendation list.
baselines tofurtherdemonstratetheadvantageofourmethod we compare it with image processing baselines including pixel level e.g euclidean distance color histogram fingerprint andstructurallevel e.g.
ssim sift surf orb .
results table 3shows theoverall performance ofall methods.
incontrastwithbaselines ourmethodoutperformsinallmetrics .
.
.
for precision precision precision respectively.
we observe that the methods based on structural features perform much better than pixel features due to the reason that the pixel similarity suffers from the scale invariant as the resolutions for visual recordings varies.
our method that combines ssimandorbleadstoasubstantialimprovement i.e.
.
higher overanysinglefeature indicatingthattheycomplementeachother.
in detail orb addresses the image distortion that causes false gui mapping considering only ssim.
albeitthegoodperformanceofourmethod westillmakewrong mapping for some keyframes.
we manually check those wrongmapping cases and find that one common cause is the dynamicallyloadedcontent.forexample asseeninfigure8 someguis mappings look visually very different as the pop up window or imagesloadedfromtheinternetmayvaryalotatdifferenttime.as the dynamic content takes over a large area of the whole gui our approach based on visual features cannot accurately locate them.
.
performance of trace generation ground truth to evaluate the ability of trace generation to accuratelygeneratethereplayableexecutiontrace welabeltheexecution trace that can replay the visual recording from the app launchasthegroundtruth.notethattheremaybemultipleground figure illustration of bad casefor trace generation.
blackline represents ground truth.
red line represents the gener ated execution trace.
truthtracescomplyingwiththeoptimaldefinition i.e.
theshortest trace to replay the recording in section .
.
therefore we manually check and label all the ground truths by two annotators independentlywithoutanydiscussion.toensurethequality any disagreement would be handed over to one author for the finaldecision.
totally we obtained execution traces including reproduction steps.
metrics to measure the similarity of the groundtruth trace andpredictedreplaysequence wefirstgetthelcsbetweentwo sequences.
we then calculate the similarity following2 m t wheremisthelengthoflcs and tisthelengthofthesumofboth sequences.
it gives a real value with a range and is usually expressedasapercentage.thehigherthemetricscore themore similar the generated execution trace is to the ground truth.
if the generated trace exactly matches the ground truth the similarity value is .
baselines wesetuponestate of the artscenariogeneration method v2s and an ablation study of gifdroid without lcs algorithm gifdroid lcs asourbaselines.
v2s isthefirstpurely graphicalandroidrecord and replaytechnique.v2sadoptsdeep learning models to detect user actions via classifying touch indicatorsforeachframeinavideo andconvertstheseintoascriptto replaythescenarios.notethatv2shasstrictrequirementsabout theinputvideoincludinghighresolution framespersecondand touchindicatorforinferringdetailedactions.therefore inaddition to testing v2s in all our datasets we also test its performance inthe part of our dataset i.e.
recordings which contain touch indicatorscalled v2s touch.totesttheimportanceoftheproposed algorithm that addresses defectiveindexsequence in section .
wealsoaddanotherablationstudycalled gifdroid lcs whichdoes not contain that component.
results table4showstheperformancecomparisonwiththe baselines.
our methodachieves .
sequence similarity which is much higher than that of baselines.
note that due to the strictrequirement of input recordings v2s does not work well in allour datasets but performs well in our partial dataset with touch indicators.evenforrecordingswithtouchindicators theextracted trace is still not that accurate as it could not recover the trace from the app launch to the entry in the recording.
in a word the hard requirementsstilllimititsgeneralityintherealtestingenvironment especially those open source software development.
in addition addinglcscanmitigatetheerrorsintroducedinthefirsttwostepsinourapproach resultinginaboostofperformancefrom82.
to89.
.although applyinglcstakes abitmoreruntime i.e.
.
seconds on average it does not influence its real world usage as it can be automatically run offline.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
gifdroid automated replay of visual bug reports for android apps icse may pittsburgh pa usa table performance comparison for gui mapping metricpixel stucture gifdroid euclidean histogram phash dhash ahash ssimsiftsurforbssim orb precision .
.
.
.
.
.
.
.
.
.
precision .
.
.
.
.
.
.
.
.
.
precision .
.
.
.
.
.
.
.
.
.
table performance comparison of execution generation.
metric v2sv2s touch gifdroid lcs gifdroid similarity .
.
.
.
time sec .
.
.
.
table shows detailed results of the success rate for each visual recordings where each app execution trace number of steps and successfullyreplayedstepsaredisplayed.greencellsindicateafully reproduced execution trace from the video recording orange cells indicate more than of steps reproduced and red cells indicate less than of reproduced steps.
gifdroid fully reproduces of the visual recordings signals a strong replay ability.
we manuallychecktheinstanceswhereourmethodfailedtoreproduce scenarios.
instances where slightly biased orange cells are largely due to inaccuracies in keyframe location i.e.
in figure a b is missing and gui mapping i.e.
in figure b b is incorrectly mappingto d .instancesthatfailedtoreproduce redceils are duetotheinaccuraciesonthelastindexasourmethoddependson thelastindextoendthesearch i.e.
infigure9 c wesearchthe execution trace on e .
usefulness evaluation weconductauserstudytoevaluatetheusefulnessofthegenerated execution trace for replaying visual bug recording into real world developmentenvironments.werecruit8participantsincluding6 graduate students master 2ph.d and 2software developers to participateintheexperiment.allstudentshaveatleastone year experienceindevelopingandroidappsandhaveworkedonatleast one android apps project as interns in the company.
two software developers are more professional and work in a large company alibaba about android development.
procedure wefirstgivethemanintroductiontoourstudyand alsoa realexampleto try.eachparticipant isthenasked toreproduce the same set of randomly selected visual bug recordingsfrom githubwhichareofdiversedifficultyranging from6 to11 stepsuntiltriggeringbugs.detailedexperimentdatasetcanbeseen in our online appendix5.
the study involves two groups of four participants the experimental group p1 p2 p3 p4who gets help with the generated execution trace by our tool and the control groupp5 p6 p7 p8who starts from scratch.
each pair of participants angbracketleftpx px angbracketrighthavecomparabledevelopmentexperience sothat the experimental group has similar capability to the control group intotal.notethatwedonotaskparticipantstofinishhalfofthe with our tool while the other half without assisting tool to avoidpotentialtoolbias.ourtooltakesabout138.08sonaverage to generate execution trace for the average .59s bug recording as seen in the table .
we only record the time used to reproduce the visualbugrecordingsinandroid astheexecutiontracegeneration canbefinishedoffline especiallyforlongrecordingswhichrequire much processing time.
since our approach is fully automated our model can automatically deal with thebug video recording immediately once uploaded.
participants have up to minutes for each bug replay.
results table shows the experiment result.
although most participantsfrombothexperimentalandcontrolgroupscansuccess fullyfinishthebugreplayontime theexperimentgroupreproducesthevisualbugrecordingmuchfasterthanthatofthecontrolgroup with an average of .
seconds versus .
seconds .
in fact the average time of the control group is underestimated because three bugs fail to be reproduced within minutes which means that participantsmayneedmoretime.incontrast allparticipantsinthe experimentgroupfinishallthetaskswithin2minutes.tounderstandthesignificanceofthedifferencesbetweenthetwogroups wecarryoutthemann whitneyutest specificallydesigned for small samples on the replaying time.
the testing result sug gests that our tool can significantly help the experimental group reproduce bug recordings more efficiently p value .
.
we summarise two reasons why it takes the control group more time to finish the reproduction than the experiment group.
first some visual recording is quite complicated which requires participantsinthecontrolgrouptowatchthevisualrecordingsseveral times for following procedures.
the gui transitions within therecording may also be too fast to follow so developers have to replay it.
second it is hard to determine the trigger from one gui tothenextone.asillustratedinsection2.
only25 ofvideosarerecorded with the touch indicator resulting in developers guess of theactionfortriggeringthenextgui.thattrialanderrormakes the bug replay process tedious and time consuming.
it is especiallysevereforjuniordeveloperswhoarenotfamiliarwiththeappcode.
threats to validity we had discussed the limitations of our approach at the end of eachsubsectionoftheevaluationinsection4 suchaserrorsduetoslowrenderinginkeyframelocation section4.
dynamicloadingcontentinguimapping section4.
etc.inthissection wefurther discuss the threats to validity of our approach.
internal validity.
in our automated experiments evaluating gifdroid threats to internal validity may arise from human annotatorsandartificialrecordings.tohelpmitigatethisthreat we authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa feng et al.
table detailed results for execution trace generations.
green cells indicate fully reproduced recordings orange cells reproduced and red cells .
table the execution time of gifdroid for real world bug recordings appnamegif gifdroid execution duration sec keyframe location sec gui mapping sec trace generation sec total sec ankidroid .
.
.
.
.
ankidroid .
.
.
.
.
kiss .
.
.
.
.
neurolab .
.
.
.
.
neurolab .
.
.
.
.
behe .
.
.
.
.
behe .
.
.
.
.
androbd .
.
.
.
.
pdfconverter .
.
.
.
.
pdfconverter .
.
.
.
.
average .
.
.
.
.
table7 performancecomparisonbetweentheexperimental and control group.
denotes p .
.
appnamecontrol group experimenal group success time sec success time sec ankidroid ankidroid kiss neurolab neurolab behe behe androbd pdfconverter pdfconverter average .
.
.
recruited two paid annotators from online posting who have experienceinvideoannotation.tomitigateanypotentialsubjectivity orerrors weaskedthemtoannotateindependentlywithoutany discussion andthenmetandsanitycorrectedthediscrepancies.another potential threat concerns the selection of optimal execution trace.tomitigatethisthreat wechosetheshortestcandidatesequenceastheoptimalexecutiontracetohelpdevelopersreproduce the bug with the least amount of time steps.
external validity.
the main threat to external validity arises fromthepotentialbiasintheselectionofexperimentalappsusedin our automated evaluation.
to help mitigate this threat we utilized theappsusedinpreviousstudies whichhaveundergoneseveralfilteringandqualitycontrolmechanismstoensurediversity.
one more potential external threat concerns the generalizability on the manual creation of visual recordings for validating the performanceofourapproach.forexample therearemanydifferent types of devices with different screens especially in android which mayresultindifferentguirendering.tomitigatethisthreat we took care to generate the recordings as general as possible includingdifferentcreationtools variedresolutions diverselengthand differedrecor dingspeed.
related work agrowingbodyoftoolshasbeendedicatedtoassistinginrecording and replaying bugs in mobile and web apps.
we introduce related works of bug replay based on different types of information including the app running information textual description and visual recording in this section.
.
bug record and replay from app running information nurmuradov et al.
introduced a record and replay tool for android applications that captures user interactions by displaying the device screen in a web browser.
it used event data captured during therecordingprocesstogenerateaheatmapthatfacilitatesdevelopers understanding of how users are interacting with an application.
additional tools including echo reran barista andandroidbotmaker areprogram analysisrelatedapplications for the developer to record and replay interactions.
however they required the installation of underlying frameworks such as replaykit troyd or instrumenting apps which is too heavyappname rep. trace appname rep. trace appname rep. trace appname rep. trace token timetracker trackercontrol yolosec deadhash gnucash afreerdp antennapod protonvpn fastnfitness jiofi wifianalyzer pslab droidweight openscale keepassdx trigger adbungfu etesyncnotes portauthority atime adaway stinglephoto invizible authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
gifdroid automated replay of visual bug reports for android apps icse may pittsburgh pa usa for end users.
in contrast to these approaches our gifdroid is rather light weight which just requires the input recording and utg which can be generated by existing tools.
.
bug replay from textual information tolowertheusagebarrierofrecordandreplaythatrequiresframeworks many of the studies facilitate the bug replay base on the natural language descriptions in bug report which contains immediately actionable knowledge e.g.
reliable reproduction steps stack traces test cases etc.
for example recdroid leveraged the lexical knowledge in the bug reports and proposed a natural language processing nlp method to automaticallyreproducecrashes.however ithighlydependedonthe descriptionwritinginthebugreportincludingformatting word usage granularity which limit its deployment in the real world.
many works that assist developers in writing bug reports stillcannotdirectlybenefitit.differentfrom textual bug reports visual recordings contain more bug details and can be easily created by non technical users.
therefore our work focuses on the automated bug replay from these visual bug reports.
.
bug replay from visual information insoftwareengineering therearemanyworksonvisualartifacts including recording tutorials bug reports with some of them specifically for usability and accessibility testing .
in detail bao et al.
focused on the extractionofuserinteractionstofacilitatebehavioralanalysisofdevelopers during programming tasks such as code editing text selection andwindowscrolling.krieteretal.
analyzedevery singleframeofavideotogeneratelogfilesthatdescribewhateventsarehappeningattheapplevel e.g.
the k keyispressed .different fromtheseworksinextractingdevelopers behavior ourworkis concerned with the automated bug replay from the recording in the bug report.
bernal et al proposed a tool named v2s which leverages deep learning techniques to detect and classify user actions e.g.
a touchindicatorthatgives visualfeedbackwhenauserpresseson thedevicescreen capturedinavideorecording andtranslateitintoareplayabletestscript.althoughthetargetofthisworkisthesame asours therearetwomajordifferencesbetweenthem.first v2s requireshigh resolutionrecordingwithtouchindicatorswhichis hardtogetinreal worldbugreportsaccordingtoouranalysis less than25.
insection2.
.second itrequirescompleterecording fromtheapplaunchtothebugoccurrencewhilemostrecordings .
in the real world do not start from the app launch but just steps before the bug page.
in contrast our approach designisfullydrivenbythepracticaldata henceitdoes nothavethose requirements.theuserstudyofreal worldbugreplayalsoconfirms the usefulness and generality of our approach.
conclusion the visual bug recording is trending in bug reports due to its easy creation and rich information.
to help developers automatically reproduce those bugs we propose gifdroid an image processing approach to covert the recording to executable trace to trigger thebug in the android app.
our automated evaluation shows that our gifdroid can successfully reproduce visual recordings from31androidapps.theuserstudyonreplaying10real world visualbugrecordingsconfirmstheusefulnessofour gifdroid in boosting developers productivity.
in the future we will keep improving our method for better performance in term of keyframe extraction gui mapping and trace generation.
for example the traditional image processing methods may not robust to minor gui changes such as configuration and parameterchanges.wewillfurtherimproveourapproachtolocatemorefine grainedparameterinformation.tomake gifdroid more usable wewillalsotakethehumanfactorintotheconsideration.astheautomatedapproachmaynotbeperfect wewillfurtherexplore how human can collaborate with the machine for replaying the bugsinthevisualbugreport.while gifdroid isfullyautomated can run in the background the execution overhead is not ideal.inthefuture wewillimprovetheefficiencyofourapproach for example accelerating by more advanced hardware and algorithm.