deepstl from english requirements to signal temporal logicjie hejie.he tuwien.ac.attechnische universit t wienvienna austriaezio bartocciezio.bartocci tuwien.ac.attechnische universit t wienvienna austriadejan ni kovi dejan.nickovic ait.ac.atait austrian institute of technologyvienna austriaharis isakovicharis vmars.tuwien.ac.attechnische universit t wienvienna austriaradu grosuradu.grosu tuwien.ac.attechnische universit t wienvienna austriaabstractformal methods provide very powerful tools and techniques for thedesign and analysis of complex systems.
their practical applicationremains however limited due to the widely accepted belief that for mal methods require extensive expertise and a steep learning curve.writing correct formal speci cations in form of logical formulas isstill considered to be a di cult and error prone task.in this paper we propose deepstl a tool and technique for thetranslation of informal requirements given as free english sen tences into signal temporal logic stl a formal speci cationlanguage for cyber physical systems used both by academia andadvanced research labs in industry.
a major challenge to devisesuch a translator is the lack of publicly available informal require ments and formal speci cations.
we propose a two step work owto address this challenge.
we rst design a grammar based genera tion technique of synthetic data where each output is a random stlformula and its associated set of possible english translations.
inthe second step we use a state of the art transformer based neuraltranslation technique to train an accurate attentional translatorof english to stl.
the experimental results show high transla tion quality for patterns of english requirements that have beenwell trained making this work ow promising to be extended forprocessing more complex translation tasks.ccs concepts requirements engineering formal speci f ication for mal veri f ication signal temporal logic stl .keywordsrequirements engineering formal speci cation signal temporallogic stl machine translationacm reference format jie he ezio bartocci dejan ni kovi haris isakovic and radu grosu.
.
deepstl from english requirements to signal temporal logic.
inpermission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor pro t or commercial advantage and that copies bear this notice and the full citationon the rst page.
copyrights for components of this work owned by others than theauthor s must be honored.
abstracting with credit is permitted.
to copy otherwise orrepublish to post on servers or to redistribute to lists requires prior speci c permissionand or a fee.
request permissions from permissions acm.org.icse may pittsburgh pa usa copyright held by the owner author s .
publication rights licensed to acm.acm isbn .
.
.
.
international conference on software engineering icse may pittsburgh pa usa.acm new york ny usa pages.
introduction what is reasonable is real.
that which is real is reasonable.
this famous proposition from hegel saying that everything has its logic often resonates in alice s mind.
alice is a veri cation engi neer responsible for safety critical cyber physical systems cps .she advocates the use of formal methods with requirements speci ed in logic as part of the development of complex cps.formal speci cations enable rigorous reasoning about a cpsproduct for example its model checking or systematic testing dur ing all its design phases as well as during operation for example viaruntime veri cation .
alice is frustrated by the resistance of hercolleagues to adopt formal methods in their design methodology.she is aware that one major bottleneck in a wider acceptance ofthese techniques results from the steep learning curve to translateinformal requirements expressed in natural language into formalspeci cations.
the correspondence between a requirement writ ten in english and its temporal logic formalization is not alwaysstraightforward as illustrated in the example below english requirement whenever v mot is detected to become equal to then at atime point starting after at most time units spd act shallcontinuously remain on for at least time units.
signal temporal logic stl g rise v mot f g spd act bob is alice s colleague and an expert in machine learning.
he in troduces alice to the tremendous achievements in natural languageprocessing nlp demonstrated by applications such as googletranslate and deepl.
alice is impressed by the quality of transla tions between natural languages.
she realizes that nlp is a technol ogy that can reduce the gap between engineers and formal methods and signi cantly increase the acceptance of rigorous speci cations.however alice also observes that this potential solution doesnot come without challenges.
in order to build a translator fromone spoken language to another there is a huge amount of textsavailable in both languages that can be used for training and thereis also a series of systematic translation solutions.
in contrast fortranslating cps requirements given in natural language into formalspeci cations there are two major challenges ieee acm 44th international conference on software engineering icse icse may pi t tsburgh pa usajie he ezio bartocci dejan ni kovi haris isakovic and radu grosu challenge lack of available training data.
the informal re quirement documents are sparse and often not publicly available and formal speci cations are even sparser.
challenge no mature solutions for translating english re quirements into formal speci cations where special features ofthese two languages need to be considered.in this paper as a rst attempt to adopt nlp to tackle the abovetwo challenges we propose deepstl a method and associatedtool for the translation of cps requirements given in relatively freeenglish to signal temporal logic stl a formal speci cationlanguage used by the cps academia and industry.
to develop deep stl we address the following ve research questions rq thesolutions of which are also our main contributions.rq1 what kind of empirical statistics of stl requirements foundin scienti c literature can guide data generation?rq2 how to generate synthetic examples of stl requirementsconsistently with the empirically collected statistics?the rst two research questions are related tochallenge .
forrq1 empirical stl statistics in literature and practice are analyzedin section .
forrq2 we design in section a systematic grammar based generation of synthetic data sets consisting of pairs of stlformulae and their associated set of possible english translations.rq3 how effective is deepstl in learning synthetic stl?rq4 how well does deepstl extrapolate to stl requirementsfound in scienti c literature?rq5 how do alternative deep learning mechanisms used in ma chine translation compare to deepstl s transformer archi tecture?the last three research questions are relevant tochallenge .they are addressed in section and discussed in section .
we em ploy a corresponding transformer based nlp architecture whoseattention mechanism enables the e cient training of accurate trans lators from english to stl.
we also compare deepstl with othermachine translation techniques with respect to translating per formance on synthetic stl training and test data set and theirextrapolations.the collected data and the implementation codes in this papercan be found in the provided links1.
related workfrom natural language to temporal logicsdespite manyapproaches proposed in the literature the problem of trans lating natural language requirements into temporal logics remainsstill open .
the main challenge arises from translating an am biguous and context sensitive language into a more precise andcontext free formal language.
to facilitate and guide the translationprocess most of the available methods require the use of prede nedspeci cation patterns or of a restricted and more controllednatural language .
handling the direct translation of un constrained natural languages is instead more cumbersome.
otherworks address this problem by translating the naturallanguage expression rst into an intermediate representation.
then the translation process continues by applying a set of manually1artifact repository rules macros mapping the intermediate representationinto temporal logic expressions.
these approaches are centeredon linear temporal logic ltl a temporal logic suitable toreason about events occurring over logical time boolean signals.in this paper we consider instead for the rst time to the bestof our knowledge the problem of automatic translation of uncon strained english sentences into signal temporal logic stl a temporal logic that extends ltl with operators to express tem poral properties over dense time real valued signals.
stl is a well established formal language employed in both academia and ad vanced industrial research labs to specify requirements for cpsengineering .semantic parsingour problem can be considered an exampleof semantic parsing .
this task consists in automatically translat ing sentences written in a context sensitive natural language intomachine understandable expressions such as executable code orlogical representations.
semantic parsers are automatically learnedfrom a set of utterances written in natural languages that are anno tated with the semantic interpretation in the target language.
somerelevant toolkits available for developing semantic parsers arewasp sempre krisp sippycup and cornellsemantic parsing .
applications of semantic parsing includethe translation of questions or commands expressed in natural language into structured query language sql queries python code bash commands and other domain speci clanguages .
the main di culty for this task is to learn the setof semantic rules that can cover all the potential ambiguity arisingwhen translating from a context sensitive natural language.
thus to be effective this task requires a large training data set.in order to cope with the lack of publicly available informal requirement and formal speci cation data sets we rst designa grammar based generation technique of synthetic data whereeach output is a random stl formula and its associated set ofpossible english translations.
then we address a neural translationproblem where a deep neural network is trained to predict giventhe utterance in english the optimal stl formula expressing it.
ourwork leverages general purpose deep learning frameworks such aspytorch or tensor ow and of state of the art solutionsbased on transformers and their attention mechanisms .
signal temporal logic stl signal temporal logic stl with bothpastandfutureoper ators is a formal speci cation formalism used by the academicresearchers and practitioners to formalize temporal requirementsof cps behaviors.
stl allows to express real time requirementsof continuous time real valued behaviors.
an example is a simplebounded stabilization property formulated as follows wheneverv in is above then there must exist a time point in the next timeunits at which the value of signal v out should be less than .the syntax of an stl formulavover a setrof real valuedvariables is de ned by the grammar v e h v v1 v2 v1u u1d43cv2 v1s u1d43cv2wheree r h q b is a non emptyinterval.
for intervals of the form we will use the notation l instead.
with respect to a signalo r z r the semantics ofan stl formula is described via the satis ability relation o v 611deepstl from english requirements to signal temporal logicicse may pi t tsburgh pa usaindicating that the signalosatis esvat the time index o e h o e h o v o v o v1 v2 o v1or o v2 o v1u u1d43cv2 b t o v2and o v1 o v1s u1d43cv2 b t o v2and o v1we usesanduas syntactic sugar for theuntimedvariants of thesinces anduntilu operators.
from the basic de nitionof stl we can derive the following standard operators.tautologytrue contradictionfalse truedisjunctionv1 v2 v1 v2 implicationv1 v2 v1 v2eventually nallyf u1d43cv true u u1d43cvalways globallyg u1d43cv f u1d43c vonceo u1d43cv true s u1d43cvhistoricallyh u1d43cv o u1d43c vrising edgerise v v vs truefalling edgefall v v vs truewe can now formalize the rather verbose english descriptionof the abovebounded responserequirement with a succinct stlformula as follows g v in f v out .this formula can be directly used during the veri cation of acps before it was deployed or to generate a monitor checking thesafety of the cps after its deployment.
empirical stl statisticsin order to address the relative lack of publicly available stlspeci cations we develop a synthetic training data generator asdescribed in section .
instead of exploring completely random stlsentences the generator should focus on the creation of commonlyused stl speci cations.
in addition every stl formula shall beassociated to a set of natural language formulations with commonlyused sentence structure and vocabulary.we analyzed over stl speci cations and their associatedenglish language formulation from scienti c papers and industrialdocuments.
the investigated literature covers multiple applicationdomains speci cation patterns automatic driving robotics time series analysis and electronics .although this literature contains data that is not statistically ex haustive it still provides valuable information to guide the designof the data generator and address the research questionrq1.we present our results on the statistical analysis of the stlspeci cations in section .
and of their associated natural languagerequirements in section .
.
.
analysis of stl speci f icationswe conducted two main types of analysis for the stl speci ca tions encountered in the literature identi cation of commontemporal logic templates and computation of the frequencyof individual operators.
during analysis we made several otherrelevant observations that we report at the end of this subsection.
.
.
stl templates distribution.we identi ed four common stltemplates that we call invariance reachability immediate response temporal responseandstabilization recurrence.invariance reachability template bounded and unboundedinvariance and reachability are the simplest temporal stl proper ties.
they have the formgv g v fvorf v wherevis anatomic predicate.
we provide one example of bounded invariance bi and one example of unbounded reachability ur speci cation respectively as encountered in our investigation ab g .
c u1d459 lcu1d445 f e .
immediate response template this template represents formu las of the formg v cu1d713 wherevandcu1d713are atomic propositionsor their boolean combinations.
except for the startinggoperator there are no other temporal operators in the formula.
an exampleof an immediate response ir speci cation is the one from bcu1d445 g not eclipse sun currents .temporal response template this template represents formu las of the formg v cu1d713 wherevandcu1d713can have non nestedtemporal operators.
we illustrate several tr speci cations that weencountered in the literature.
they all belong to this class cu1d447cu1d4451 g rise op cmd passive f spd act cu1d447cu1d4452 g currentadcsmode sm cu1d443u cu1d443 cu1d447cu1d4453 g rise gear id g fall gear id incu1d447cu1d4452 above cu1d443 real omega target omega .stabilization recurrence template these templates representformulas allowing one nesting of the temporal operators.
typicalnesting isgfvfor recurrence re andfgvfor stabilization st with their bounded counterparts.
herevis a non temporal formula.the following speci cations from the literature are in this category cu1d446cu1d447 f g e10 .
cu1d445cu1d438 g f regiona f regionb other formulas these are formulas that do not fall into any ofthe above categories.
the following speci cation belongs to thisclass g rise v1 f rise v2 v2u v3 it captures the following requirement whenever the preconditionv1becomes true there is a time withincu1d4611units wherev2becomes trueand continuously holds untilv3becomes true within another interval .this pattern is used in the electronics eld to describethe situation where one digital signal tracks another .statistics we encountered 39invariance reachability .
27immediate response .
33temporal response .
and 31stabilization recurrence .
templates.
the category of othertemplates is orthogonal to the rst four ones since it includes adhoc formulas.
there are overall .
temporal responseand .
stabilization recurrencetemplates belonging to this type.
.
.
stl operators distribution.we investigated the distributionof the stl operators as encountered in the speci cations found inthe above mentioned literature.
figure summarizes our results.612icse may pi t tsburgh pa usajie he ezio bartocci dejan ni kovi haris isakovic and radu grosu u1d465 u1d462 u1d465 u1d462 u1d465 u1d462 u1d465 u1d462 u1d465 u1d462rise u1d711 fall u1d711 f u1d43c u1d711g u1d43c u1d711 u1d7111u u1d43c u1d7112o u1d43c u1d711h u1d43c u1d711 u1d7111s u1d43c u1d7112 u1d711 u1d7111 u1d7112 u1d7111 u1d7112 u1d7111 u1d7112306090120150 figure frequency distribution of stl operators.we rst discuss the atomic numeric predicates.
we observe thatthe equality operator occurs more often in numerical predicatesthen the other relations.
this happens because manyspeci cations refer to discrete mode signals and equality is used tocheck if a discrete variable is in a given mode.conjunction and implication are the two most frequently usedboolean operators.
conjunction is often used to specify that a signalmust lie within a given range.
implication is used in a pretty widerange of response speci cations.theriseandfalloperators are typically used in front of anatomic predicate for examplerise e .
.
the frequency of risingedges is higher than that of falling edges which can be explainedby the fact that many speci cations refer to time instants where acondition starts holding rather than when it stops holding.thegoperator has a much higher frequency than any othertemporal operator.
this is not surprising because .
ofthe speci cations are invariance or response or recurrence proper ties that start with an always operator.
thefoperator ranks secondand is often used in speci cations of robotic applications to de nereachability objectives.
we also remark that eventually is used inbounded unbounded and stabilization properties.we nally observe that future temporal operators g f u areused more often than their past counterparts o h s and thatunary temporal operators g f h o are used more often thanthe binary ones u s .
these two observations are explained by thefact that most declarative speci cations have a natural future avor a trigger now implies an obligation that must be ful lled later andunary temporal operators are easier to understand and handle.
.
.
other observations.in this section we discuss additional ndings that we discovered during the analysis of the stl speci cations occurring in the literature we found a frequent usage of the pattern e cu1d466.alt to denote thepointwise distance between signalseandcu1d466.alt especially in themotion control applications .
some publications use abstract predicates to denote complextemporal patterns without providing their detailed formalization.one such example is the use of the predicatespike e to denotea spike occurring within the signale .
it is relatively common in the literature to decompose a complexstl speci cation into multiple simpler ones by giving a nameto a sub formula and using that name as an atomic propositionin the main formula.
time bounds in temporal operators and signal thresholds aresometimes given as parameters rather than constants.
rise falland past temporal operators are normally used aspre conditions while future operators are often used as post conditions.
negation is used conservatively e.g.
fallis usedto represent a particular stabilized condition should hold for adesignated time interval .
.
analysis of nl speci f icationsin this section we investigate the usage of natural language nl in the literature to express informal requirements which arethen formalized using stl.
in particular we identi ed the englishvocabulary used to formulate stl operators and sentences andstudied the quality accuracy and preciseness of the language.
.
.
english formulation of stl sentences.we considered severalaspects e.g.
nouns verbs adverbs etc.
when studying the use ofnatural language in the formulation of numeric atomic predicates temporal operators phrases speci c scenarios e.g.
a rising falling edge .the main outcome of this analysis is that the language featuresused in the studied requirements are unbalanced and sparse andthat it is hard to identify a general recurring pattern.
we illustratethis observation with two representative examples example we counted different english utterances to expressthe semantics ofe .. the most frequently used collocationis be above which appears overall four times.
next comes increase above somewhat ambiguous because this may alsorepresent a rising edge which is used two times.
then be higherthan be larger than and be greater than are only used oncerespectively.
however we do not nd any requirements usingother synonymous expressions like be more than or be over .
example we observed that two temporal adverbs are fre quently used to expressg andh which are for at leastcu1d461time units cu1d46l cu1d45acu1d46l etc.
eight times and for more thancu1d461timeunits six times .
however other reasonable possibilities like for the following pastcu1d461time units are not found.the sparsity and lack of balance may be a consequence of therelative small base of publicly available literature that de nes thistype of requirements.
despite the fact that the ndings of thisanalysis may not be su ciently representative we can still use theoutcomes to improve our synthetic generation of examples.
.
.
language q uality.for the english requirements found in theliterature of particular interest is the language quality how accu rately does a requirement re ect the semantics of its correspondingstl formula?
given this criterion we classify the studied englishrequirements intoclear indirectandambiguousrequirements.clear these requirements have a straightforward stl formalisa tion that results in an unambiguous speci cation without room forinterpretation.
an example of a clear requirement is the sentence 613deepstl from english requirements to signal temporal logicicse may pi t tsburgh pa usaif the value of signal control error is less than10 then the value ofsignal currentadcsmode shall be equal to nmf .
the resultingstl speci cation is given by the formula g control error currentadcsmode nmf indirect these requirements need an expert to translate theminto an stl formula that faithfully captures the intended meaning.they typically assume some implicit knowledge that must be addedto the formal speci cation from the context.
an example is thesentence the vehicle shall stay within the lane boundaries if this ispossible with the actuators it is equipped with .
this is an indirectrequirement formalized using the following stl formula g cu1d7lf cu1d7lf u1d45a u1d44e u1d465 p herepis the contextual sub formula vehicle corridor.ambiguous these requirements lack key information that cannotbe easily inferred from the context and that must be extracted fromexternal sources such as tables gures timing diagrams or experts.they use vague and ambiguous language and can have multipleinterpretations.
an example is the following sentence to preventthe destruction of the device by avalanche due to high voltages thereis a voltage clamp mechanismcu1d44d u1d446 .
u1d44d implemented that limitsnegative output voltage to a certain levelcu1d449 u1d446 cu1d449 u1d446 .
u1d44d .
please referto figure and figure for details .
this is an ambiguousrequirement that can be translated to the following stl formulas g cu1d449 u1d442 u1d448 u1d447 cu1d449 u1d43a u1d441 b u1d43f cu1d449 u1d442 u1d448 u1d447 cu1d449 u1d446 cu1d449 u1d446 .
u1d44d g cu1d449 u1d442 u1d448 u1d447 cu1d449 u1d43a u1d441 cu1d449 u1d442 u1d448 u1d447 cu1d449 u1d446 cu1d449 u1d446 .
u1d44d the english requirement only vaguely mentions the post condition.the pre condition characterizes the drop of voltagecu1d449 u1d442 u1d448 u1d447belowcu1d449 u1d43a u1d441 when the inductive load is being switched off.
this is ob tained from the previous context and figure of with somephysical knowledge that inductive current has to change smoothly.we encountered 46clear .
43indirect .
and 41ambiguous .
english requirements.
corpus constructionthis section addresses research questionrq2.
it rst introducesa new method for the automatic generation of stl sentences andtheir associated natural language requirements.
the generatorincorporates the outcomes from section for improved results.finally we use this method to do the actual generation of stl speci cation nl requirements pairs.
.
corpus generationin the following we propose an automatic procedure for ran domly generating synthetic examples.
each example consists of an stl formula and a set of associated sentences in englishthat describe this formula.
we associate multiple natural languagesentences to each formal stl requirement to re ect the fact thatformal speci cations admit multiple natural language formulations.we illustrate this observation using thebounded responsespeci ca tion from section formalized as the stl formula below g v in f v out this admits multiple synonymous english formulations including globally if the value of v in is greater than then nally thevalue of v out should be smaller than at a time point within10 time units.
it is always the case that when the signal v in is larger than then eventually at sometime during the following time unitsthe signal v out shall be smaller than .this example shows that two nl formulations of the same stlformula can be very different making the generation of syntheticexamples a challenging task.
the systematic translation of unre stricted stl is indeed extremely di cult especially for speci ca tions that include multiple nesting of temporal operators.
in prac tice deep nesting of temporal formulas is rarely used because theresulting speci cations tend to be di cult to understand.hence we rst restrict stl to a rich but well structured sub fragment that facilitates a fully automated translation while at thesame time covering commonly used speci cations.
.
.
restricted stl fragment.in this subsection we present therestricted fragment of stl that we support in our synthetic examplegenerator.
we de ne this fragment using three layers that can bemapped to the syntax hierarchy identi ed in section .
.
.the bottom layer calledsimple phrase sp layer consists of atomic propositions u1d736 including rising and falling edgesand boolean combinationsof up to two atomic propositions.cu1d6fc e h e h rise e h fall e h rise e h fall e h sp cu1d6fc cu1d6fc cu1d6fc cu1d6fc cu1d6fcwhereeis a signal name his a constant or a mode name and .the middle layer which we calltemporal phrase tp layer admits the speci cation of temporal formulas over simple phrases tp tp prime tp prime risetp prime falltp prime risetp prime falltp primetp prime uto u1d43c cu1d6fc cu1d6fc bto u1d43c cu1d6fc whereuto f g o h andbto u s are unary and binarytemporal operators respectively.bis an interval of the form with cu1d4611 cu1d4612 .
this can be omitted ifcu1d4611 andcu1d4612 .the top layer which we call singlenested temporal phrase ntp layer allows the formulation of formulas with a single nest ing of a subset of temporal operators ntp f u1d43cg u1d43c cu1d6fc g u1d43cf u1d43c cu1d6fc wherebfollows the same de nition as mentioned above.finally with an auxiliary syntactical componentp sp tp formulacu1d713de nes thesupported fragmentof stl that we map tothe four template categories discussed in section .
.
.cu1d713 g u1d43c sp f u1d43c sp bcu1d45bcu1d463lcu1d45f lcu1d45bccu1d452 cu1d445cu1d452lccuni21lelcu1d44f cu1d459 cu1d461cu1d466.alt g sp sp bcu1d45acu1d45acu1d452z lcu1d461cu1d452 cu1d45fcu1d452cu1d46l cu1d45ccu1d45bcu1d46lcu1d452 g p tp cu1d447cu1d452cu1d45a cu1d45ccu1d45flcu1d459 cu1d45fcu1d452cu1d46l cu1d45ccu1d45bcu1d46lcu1d452 g p ntp cu1d446cu1d461lcu1d44f cu1d459 cu1d467lcu1d461 cu1d45ccu1d45b cu1d445cu1d452chcu1d45fcu1d45fcu1d452cu1d45bccu1d452 this fragment balances betweengenerality needed to expresscommon practice requirements andsimplicity needed to facilitatethe automated generation of synthetic examples.
it results in thefollowing restrictions we allow the conjunction and disjunction614icse may pi t tsburgh pa usajie he ezio bartocci dejan ni kovi haris isakovic and radu grosuof only two atomic propositions only one atomic propositionis allowed inside a temporal operator intp we do not allowboolean combinations ofspandtpformulas and formulasoutside the four mentioned templates are not supported.by relating the generator fragmentcu1d713to the empirical statisticsin section .
.
figure summarizes for each syntactical category the proportion of templates that the fragment can support.
invariance reachability immediate response temporal response stabilization recurrencesupportnot support complex grammar not support other .
.
.
.
.
.
.
.
.
.
figure stl template support summary.the generator nearly supports allinvariance reachabilitytem plates appearing in our database.
forimmediate responseones thereis one template missing due to restriction .
fortemporal responsetemplates we are able to support .
of them.
for the not sup ported ones .
use a complex grammar that violates restriction and while the remaining ones .
belong to theothercategory for ad hoc purposes.
concerning nesting formulas weonly considerstabilization recurrencetemplates.
other combina tions such asffvorfv1uv2are not supported .
of them arein thecomplex grammargroup while the left .
are in theothercategory.
.
.
random sampling stl formulas.this short subsection brie ydescribes how we sample stl speci cations from the restrictedfragment.
the main idea is to decorate the grammar rules withprobabilities according to the template distribution collected insection .
and the operator distribution shown in figure .consequently we use the probabilities described in section .1to generate the four categories of fragmentcu1d713 which will naturallymake thegoperator rank rst to a large extent followed by thefoperator regarding to usage frequency.
the frequencies of theother operators within these categories are as discussed above.
.
.
translating stl into english.the main translation strategylinked to .
is as follows.
for the predicates used to express logicalrelations in the bottom layer we use with some reservations mainlywith regards to accuracy the frequencies of section .
.
.
this way the translation candidates are selected with different weights.
forthe others such as the adverbs specifying temporal information we incorporated relevant english utterances encountered in ourdatabase on the condition that the generation and recognition canbe done with both accuracy and uency.
furthermore we reservedenough space to add synonymous utterances that can be typicallyused but that are not included in the database.in order to systematically organize the translation and maximizelanguage exibility we start with the translation of atomic propo sitions de ned ascu1d6fcin .
.
in the bottom syntactical layer anduse this as a pivot to tackle temporal phrases and their nestingscenarios in the middle and top layers.bottom layer.the english counterparts of atomic propositionstypically consist of a subject a predicate and an object.
they areindispensable in each english sentence.
hence their variationsespecially in the predicate including the choice of verbs formats tenses and their active passive voice are considered rst.
thework ow for the organisation of their translations which is dividedinto ahandlerand atranslator is illustrated in figure .typepositiongenerationinformation instructionadverbialinformationpredicatecommands generation information instruction adverbial information predicate commands handlerrandomly selectedtranslationsassemblertemplaterefinerrandomizedsamplerrefined templatetranslationlist assembler template refiner randomized sampler refined template translation t t listtranslatorfigure translation procedure for atomic propositions.the handler as a preprocessor takes thetypeandpositioninfor mation as inputs.typeis a branch ofcu1d6fcused to compute and outputthegeneration information.
this includes anindex it triggers acorresponding translation strategy identi f iers numbers and thestl expressionof a randomly generated atomic proposition.positionspeci es the location of the proposition.
this determineswhether the translation states a certain scenario if it is a condition before implication symbol or if it emphasizes that a propertyhas to hold with a satis ed condition after .
in the latter case modal verbs like should or must will be used and often togetherwith adverbial modi ers like instantly or without any delay incase ofimmediate responseformulas.
this information is embeddedintopredicate commands incorporating the choice of verbs theirformat and the use of modal verbs and of adverbial modi ers.generation informationandpredicate commandsare sent to thetemplate re f iner inside translator whose architecture is shownin figure .
here the subject and object placeholders within thetemplates can be replaced by randomly generated identi ers andnumbers.
the verbs associated to predicates are changed to theirproper format and are decorated with adverbs when applicable.
generationinformation predicatecommandsraw templatesubject objectextractor s ubject object extractorpredicaterefiner predicate refinerrefined subjectrefined objectrefined predicaterefined templatetemplate refiner figure template re f iner.in the next step theassemblermodule of the translator com pletes the re ned templates into a complete sentence that also615deepstl from english requirements to signal temporal logicicse may pi t tsburgh pa usaincludes adverbial modi ers.
finally therandomized samplermod ule of the translator samples a designated number of sentencesfrom the overall translation list.middle top layer.the translation approach presented above isextended to temporal phrases in a straight forward manner becausethe sentences generated by the bottom layer can be reused exceptfor the need to add adverbial modi ers and enrich the verb tensesaccording to the temporal operators.
fi x temporal operator z tense sdvwsuhvhqwixwxuhtier tp y variant s fall tp future tp rise tp tp translation beforeimplication gi oi hi 1ui 1si 2fall tp rise tp fall tp tier tp tier rise tp tier fall tp tier rise tp tier fall tp translation afterimplication f tp future f tp present figure translation of temporal phrases.the temporal aspects nevertheless do increase the translationcomplexity.
we need to consider three orthogonal aspects dimen sions as shown in figure .
thee axis represents the six stltemporal operators from thetplayer thecu1d466.alt axis their variantspreceded by the negation rising or falling edge operators and thecu1d467 axis the choice of a verb tense in english for speci c temporal op erators.
hence a node in figure represents a speci c combinationof these three aspects.we adopt a slicing approach to tackle the complexity.
we rstprocess nodes a f with present tense where the six temporal oper ators are used individually.
then we enrich the usage of verb tensesaccording to the semantics of a particular operator and its nestingsituation.
this results in tiertp primewhile preserving language exi bility.
the same approach is used for processing unary operatorsin tier tp prime.
the semantics of direct negation of binary operators rising falling edges and their negations for layertpare compli cated.
considering their relatively low usage frequency we provideseveral xed templates to facilitate their translations.
.
corpus statisticsfollowing the approach described in section .
we have au tomatically generated a corpus consisting of stl englishpairs where each pair consists of a randomly generated stl formulaand one of its generated translation in natural language.
.
.
stl formula statistics.in figure we provide the frequen cies of the stl operators in our synthetic dataset above corpus .as one can see they are largely consistent with the ones in figure .as before the most frequent stl operator is the global temporaloperatorg u1d43cvwith occurrences.
the least frequent stloperator is thev1s u1d43cv2temporal operator with occurrences.while this frequency differs a bit from figure it is still consistentwith the empirical results.
u1d465 u1d462 u1d465 u1d462 u1d465 u1d462 u1d465 u1d462 u1d465 u1d462rise u1d711 fall u1d711 f u1d43c u1d711g u1d43c u1d711 u1d7111u u1d43c u1d7112o u1d43c u1d711h u1d43c u1d711 u1d7111s u1d43c u1d7112 u1d711 u1d7111 u1d7112 u1d7111 u1d7112 u1d7111 u1d711225k50k75k100k125k figure frequency of stl operators in the corpus.table shows the statistics of templates and subformulas in thegenerated corpus.
as mentioned in section .
an stl template isde ned as the parse tree of a formula without its leaves.
for exam ple the template for the formulav g in f out isg v1 f v2 .
each formula has a nite number of sub formulas.
for example the formulavabove has ve subformulas v5 g in f out v4 in f out v3 f out v2 out andv1 in .table stl formula statistics unique stl formulas unique stl templates subformulas for each formula.
formulas templates subformula per formulaminmaxavg.median120 .987table shows the mutual mapping relation between stl op erators and stl formulas in our corpus.
we count for each stloperator how many formulas it has appeared in.
this produces thecontainment statistics shown in the last three columns.table stl formula mapping statistics stl operators foreach formula stl formulas for each operator.
stl oper.
per formula formulas per stl oper.avg.medianmaxavg.medianmax6.
.
870since identi ers and constants frequently appear in our corpus we also analyzed their frequency as shown in table .
.
.
natural language statistics.the statistical results of the nat ural language in our corpus are shown in table .
there are only265 different effective english words considering word variants not including signal names which are strings generated randomly 616icse may pi t tsburgh pa usajie he ezio bartocci dejan ni kovi haris isakovic and radu grosutable identi f ier and constants statistics average numberof identi f iers per formula of chars used per identi f ier number of digits used per constant.
identi ersper formula chars per identi er digits per constantminavg.medianminavg.median2.
.
.312constituting a relatively small vocabulary.
this is understandablebecause most english words are used to express the logical relationin stl the number of which is thus limited.
besides table recordsthe statistics of effective word numbers in all english sentences.
italso counts for each english word the number of english sentencesusing it.table english statistics unique sentences uniquewords words per sentences and sentences per word.
sent.
word words per sent.
sent.
per wordavg.medianavg.median120 .
.
.
machine translationin order to answer questionsrq3 we take advantage of thecorpus generated as discussed in the previous sections to developdeepstl a tool and technique for the translation of informal re quirements given as free english sentences into stl.
deepstlemploys a state of the art transformer based neural translationtechnique to train an accurate attentional translator.
we comparethe performance of deepstl with other nl translator architectureson the same corpus and we also investigate how they are able toextrapolate to sentences out of the corpus.
.
neural translation algorithmsthe translation of natural language into stl formulas can beabstracted as the following probabilistic problem.
given an encod ing sequencee cu1d4521 cu1d4522 .
.
.
cu1d452 u1d45a from the source language englishrequirements a decoding sequences cu1d46l1 cu1d46l2 .
.
.
cu1d46l u1d45b from thetarget language stl formulas generates all of its tokenscu1d46l u1d458con ditioning on the decoded history of the target sequencecu1d46l u1d458andthe whole input of the source sequenceesuch that cu1d443 s e cu1d7l3 producttext.
u1d45b u1d458 1cu1d443 cu1d46l u1d458 cu1d46l u1d458 e cu1d7l3 wherecu1d7l3are the parameters of the model.
acurrent practice in the community of nlp is to learn these prob abilities through neural translation nt where the tokens areencoded into real vectors.
.
.
nt architectures considered.we considered three main nt architectures sequence to sequence seq2seq sequence to sequenceplus attention att seq2seq and the transformer architecture.seq2seq architecture.seq2seq uses two recurrent neural networks rnns one in the encoder and one in the decoder to sequentiallyprocess the sentences word by word .att seq2seq architecturea drawback of the seq2seq architecture is that it gradually encodes the dependencies among words in theinput and output sentences by sequentially passing the informationto the next cell of the rnn.
as a consequence far away dependen cies may get diluted.
in order to correct this problem an attentionmechanism is introduced in att seq2seq to explicitly capture andlearn these dependencies .transformer architecturethe previous two architectures are rel atively slow to train because the rnns hinder parallel processing.to alleviate this problem the transformer architecture introducesa self attention mechanism dropping completely the use of rnns.this dramatically speeded up thecomputation time of attention based neural networks and conferred a considerable momentumto nt .
for this reason we adopted a transformer based archi tecture for our deepstl translator.
.
.
preprocessing and tokenization.there are three main fea tures that distinguish our translation problem from general transla tion tasks between natural languages nl2nl out of vocabulary oov the signal names we call themidenti ers for short and numbers can be arbitrarily speci ed.therefore it is impossible to maintain a xed size vocabularyto cover all imaginable identi ers and numbers.
high copying frequency during translation identi ers andnumbers need to be much more frequently copied from thesource language to the target language than in nl2nl.
unbalanced language english is a kind of high resource lan guage while stl formulas belong to a low resource logicallanguage that has very limited exclusive vocabulary.in view of the above characteristics a successful translation ofenglish to stl requires more than in nl2nl a correct tokenizationof identi ers and numbers.
although one can use an explicit copy ing mechanism this method requires to modify the structureof the neural network which may increase complexity.subword tokenizationwe therefore adopt a subword techniqueto tokenize sequences during data preprocessing.
subword algo rithms such as byte pair encoding bpe wordpiece andunigram are commonly used in state of art nt systems totackle the oov problem.
without modifying the model structure these algorithms are able to split words into meaningful morphemesand even independent characters based on statistical rules.ideally we hope when identi ers and numbers are tokenized they can be respectively encoded by separate characters and digits.for example pwmand12.5are expected to get encoded as and respectively.
this way wecan use a limited number of characters and digits to represent arbi trary identi ers and numbers.
we chose bpe due to its simplicity.the tokenization procedure of bpe is executed as follows splitevery word separated by a space in the source data to a sequenceof characters.
a prepared token list will include all possiblecharacters without repetition in the source data.
the most fre quently occurring pair of characters inside a word are merged andadded to the token list then this pair will be treated as an indepen dent character afterwards.
step is repeated until the size of thetoken list reaches to an upper limit or a speci ed hyperparameter.after tokenization when a sequence is encoded the generated listis iterated from the longest token to the shortest token attemptingto match and substitute substrings for each word in the sequence.inspired by bpe algorithm before tokenization identi ers andconstants have to be split into characters and digits in advance so that for each pair of two adjacent characters and digits there617deepstl from english requirements to signal temporal logicicse may pi t tsburgh pa usawould be a whitespace between them e.g.
pwm pwm .
.
.
in this way characters and digits will not participate inthe merging procedure of bpe.
hence during the encoding phase only characters and digits in the generated token list can matchidenti ers and constants after they are recognized and split.during testing time although it is easy to use regular expres sions to match numbers and split them into digits it is challengingto accurately match identi ers.
this is because identi ers can benon meaningful permutations of characters or complete englishwords.
these two scenarios cannot be easily distinguished.
an idealmethod is to adopt name entity recognition ner to match iden ti ers and split them.
now identi ers are automatically identi ed by checking that they do not belong to our data set of commonlyused english words or the english formulation of stl operators.
.
implementation details6.
.
data split.we overall generated english stl pairs from which we rst sampled to prepare a xed testingset.
for the rest before each training experiment we sampled of them for training and for validation.
.
.
hyperparameters.the implementation of the three modelsmentioned in .
.
are mainly based on with several modi ca tions using pytorch.
the following describes how hyperparametersare chosen for each model and the optimizer.seq2seqwe used gated recurrent unit gru as rnn units.the encoder is a layer bidirectional rnn with hidden sizecuni21le 128for each direction and the decoder is a layer unidirectional rnnwithcuni21le .
the embedding dimension for mapping a one hotvector of a token into real valued space is .
drop out rate is .
.att seq2seqfor the encoder decoder we used the same hyper parameters as seq2seq architecture.
for bahdanau attention we used a feed forward neural network with hidden layer and128 neurons to calculate attention score.transformerfor the encoder and the decoder they both have4 layers with attention heads input and output dimensions foreach computing block are always kept aszmodel neuronnumber in feed forward layers equals toz u1d453 u1d453 drop out rateis .
for layer normalization cu1d716 .optimizerwe used adam optimization algorithm withcu1d6fd1 .
cu1d6fd1 .
cu1d716 while the learning ratecu1d459cu1d45fis dynamicallyscheduled as slightly changed from cu1d459cu1d45f z .5model min cu1d46lcu1d461cu1d452 cu1d45bhcu1d45a .
cu1d46lcu1d461cu1d452 cu1d45bhcu1d45a olcu1d45fcu1d45ah .
u1d460 u1d461 u1d452 u1d45d u1d460 whereolcu1d45fcu1d45ah u1d460 u1d461 u1d452 u1d45d u1d460 zmodel .cu1d46lcu1d461cu1d452 cu1d45bhcu1d45arepresents thetraining steps training on one batch corresponds to one step .
isan adjustable parameter for each architecture and we chose .1and for seq2seq att seq2seq and transformer respectively.
forseq2seq and att seq2seq models in order to ease gradient explosiondue to long sequence dependency we also used gradient clippingto limit the maximum norm of gradients to .otherwe dealt with variable length of input and output sequenceusing padding.
we rstly encoded all english and stl sequencesinto subword token lists from which we picked the maximumlength as the step limit both for the encoder and the decoder.
duringtraining for sequence whose length is smaller than the maximumvalue we padded a special token pad to its end for complement.
.
.
train validate test procedure.for training and validation we used teacher forcing strategy in the decoder.
we rstly pre pared two special tokens bos begin of sentence and eos end of sentence .
suppose the reference output of the decoderisabc eos .
to start with we input bos as a starting signal tothe decoder and hoped that it could outputa.
no matter whetherthe actual rst output of the decoder isa we then sentato the de coder and hoped that it would outputb.
this procedure continuesuntil the maximum step length of the decoder is reached.we summed up all token level only for valid length cross entropy loss between the prediction and reference sequence anddivided it by the maximum length of the decoder.
this is the lossfor one sample.
we trained a batch of samples in parallel.
thebatch loss is averaged over all sample losses inside a single batch which is used for back propagation to update network parameters.for testing teacher forcing is abandoned.
the only token man ually input to the decoder is bos for initialization.
at each timestep of decoding the decoder adopts a greedy search strategy out putting a token with maximum probability only based on its outputin the previous step and the output of the encoder.
the decodingprocedure will end until the decoder outputs an eos token or themaximum limit length is reached.
.
results6.
.
loss accuracy curves.we trained seq2seq att seq2seq andtransformer architectures for and epochs respectively usingstl formula accuracy de ned in .
.
in validation as anindicator to stop training.
the validation loss accuracy curves areobtained by independent experiments and shown as follows.
figure validation loss.
figure validation formula accuracy.618icse may pi t tsburgh pa usajie he ezio bartocci dejan ni kovi haris isakovic and radu grosufigure and figure show that with the guidance of teacherforcing all the three models are able to converge during training making the stl formula accuracy approach to when the networkbecomes stabilized.
the only difference is the rate of convergence which depends on many factors like the volume of the model e.g.
number of parameters noises learning rate etc.
.
.
testing metrics.we rstly report two different measures ofaccuracy thestl formula accuracy cu1d434 u1d439 and thetemplate accuracy cu1d434 u1d447 .
the rst measures the alignment accuracy for the referenceand prediction sequence in a string level while the second rstlytransforms the reference and predication instances into stl tem plates and then calculates their alignment accuracy.
for example formula always x template always phi formula always y template always phi the rst line is reference sequence and the second line representsmodel prediction.
for better illustration we insert a white spacebetween each token and thus there are six tokens in the formulas and four tokens in the templates.
for formulas overall ve tokensappear in the same position always while the left one token x in the reference is mistranslated to y .
therefore the formula accuracycu1d434 u1d439 .
as for the template since all tokens are aligned with each other the template accuracycu1d434 u1d447 .we also report another metric called bleu bilingual evalua tion understudy that has been pervasively used in machinetranslation research.
it evaluates the number of n grams cu1d45b appearing in the reference sequence.
the best bleu score for a pairof sequences is which means complete overlapping.table testing accuracy.formula acc.template acc.bleuseq2seq0.
.
.
.
.
.0361att seq2seq0.
.
.
.
.
.0011transformer0.
.
.
.
.
.0005in table it can be seen that once teacher forcing is removed the performance of seq2seq architecture decreases dramatically which is partly due to its lack of attention mechanism to realize self correction.
for the other two models both of them can achieve veryhigh accuracy with transformer slightly better than att seq2seq.since the testing data and training data are sampled from the samedata set in this sense these two models show high translationquality when the distribution of language patterns in testing casesare similar to the training data.
we also nd that the templateaccuracy is higher than the formula accuracy.
this phenomenon isunderstandable once one formula is transformed into the form oftemplate the potential translation errors in identi ers constantsand logical relation symbols are masked.
.
.
extrapolation.in the following we use the informal require ments that we identi ed from the literature in section to evaluatehow well the machine learning algorithm generalizes the transla tion outside of the training and validation data set.in order to have a fair evaluation we used the 14clearrequire ments of the entire set with the template structure supportedby our tool.
we pre processed the requirements to remove unitsthat are not supported by our tool.
table summarizes the accu racy results for the three learning approaches.
we see that withnon synthetic examples the formula accuracy drops considerablyfor all algorithms while the average template accuracy remainsrelatively high .
for the transformer approach.
we believethat higher availability of publicly available informal requirementsthat could be used for training would considerably help improvingthe accuracy of the approach.table extrapolation accuracy.formula acc.template acc.bleuseq2seq0.
.
.
.
.
.0120att seq2seq0.
.
.
.
.
.0348transformer0.
.
.
.
.
.0030in the following we provide three examples2that illustrate thepossibilities and the limits of our approach random seed .we also report the following metric that considers the averagelogarithmic value of the output con dence at each decoding step cu1d436 u1d45a u1d43f u1d6fc summationtext.
u1d43f u1d458 1logcu1d443 cu1d46l u1d458 cu1d46l u1d458 e cu1d7l3 wherecu1d43fis the length of the out put sequence cu1d6fcis an adjustable factor which is set to .
by de fault andcu1d45a cu1d46l l cu1d461 withcu1d46l l cu1d461denoting seq2seq att seq2seqand transformer model respectively.example if the value of signal rws angular momentum isgreater than .
then the value of signal rws torque shall beequal to .
transformer cu1d436 u1d461 .
always rws angular momentum .
rws torque att seq2seq cu1d436 u1d44e .
always rws angular mxyomemeeqm .
rws torque seq2seq cu1d436 u1d460 .
always wncai1idsddyd1yd2y171a71aa2345324621 ......too long display omittedexample whenever op cmd changes to passive then in re sponse spd act changes to after at most time units.
transformer cu1d436 u1d461 .
always rise op cmd passive eventually rise spd act att seq2seq cu1d436 u1d44e .
always rise op cmd passive not eventually spd act seq2seq cu1d436 u1d460 .
always rise piwed .
q8y5ydy6y1y1r11y1y1g1y1a......too long display omittedexample whenever v mot enters the range then inresponse starting after at most time units spd act must be inthe range .
transformer cu1d436 u1d461 .
always rise v mot and v mot eventually spd act and spd act att seq2seq cu1d436 u1d44e .
always rise v mot and v mot not eventually spd act and spd act 2these examples are the actual outputs of the translator.
they are not displayed in amathematical way.
the part that is incorrectly translated is represented in blue color.619deepstl from english requirements to signal temporal logicicse may pi t tsburgh pa usa seq2seq cu1d436 u1d460 .
always rise p qhx q3daqadamymaolq ya fall......too long display omittedthe extrapolation test shows the poor translation of seq2seqthat is consistent with its low accuracy measured in table .
thetranslation quality of transformer and att seq2seq is much higher.it is however sensitive to how similar the patterns used in theinformal requirement are to the ones used in the training data.in example transformer makes the correct translation whileatt seq2seq fails to copy the identi er and the number and greaterthan is mistranslated into .
in example transformer tendsto add ariseoperator before the subformula wrapped inside anfoperator although in some occasions this is equivalent to the actualintention of the requirement because changes to often indicatesthe signi cance of a rising edge.
on the other side att seq2seqadds a negation operator in front of the subformula startingwith anfoperator so the meaning becomes reversed.
in example transformer translates the requirement correctly while att seq2seqmakes the same mistake.
for the three examples considered theseq2seq model fails to translate all of them without even guessingcorrectly the template it tends to generate lengthy symbols withoutexplicit meaning.
discussioncorpus generatorone of the major limitations is that the natu ral language is still generated through a rule based approach withhuman intervention.
although for commonly used stl formulas the corpus generator can already produce enormous uent syn onymous translations the diversity in expression is still limited.however it is this cold start approach that makes it possible inthe future to adopt automatic data augmentation techniques in nlp to produce much more english utterances exponentially.these new variants may involve different linguistic features suchas ambiguity and vagueness.furthermore the english requirements produced from the cor pus generator are generic texts strictly following the semantics ofstl without incorporating terminology and domain knowledgeof a particular eld e.g.
electronics robotics and biology.
howto cover characterize and process this information with modulardesign patterns is a future research direction.neural translatoran important improvement would be to unifythe pipeline in data preprocessing we need to combine name en tity recognition ner technique with the look up tablemethod to recognize arbitrarily designated identi ers or those thatare already given in signal tables from industrial data sheets.besides translation accuracy and decoding con dence should befurther exploited for training because they are indicators of transla tion performance.
in fact the template accuracy mentioned in .
.2is biased by design in that it penalizes positional mismatches withcumulative effect more strongly than individual token mismatch ing errors.
hence an unbiased criterion for quantifying templateaccuracy needs to be considered.
for translation con dence a highlevel is not necessarily indicating that the decoder will always insiston the correct translation sometimes it implies that the decodermay be stubborn to the wrong output example of transformerin .
.
.
however for lower con dence values they tend to indi cate insu cient training of a particular feature due to unbalancedtraining samples.
given the rich information conveyed these twometrics can be promisingly used as feedback signals to guide the op timization of the loss function so that different problems occurringin training can be detected and corrected.furthermore due to the attention mechanism att seq2seq isstill a strong competitor to transformer despite being inferior incertain test metrics and cases.
although it is interesting to improvetranslation quality from multiple transformer based pre trainingtechniques with large models it is also important to gure outwhat role attention mechanism exactly plays in translation unlikethe english in daily communications or in literature the contextsused to specify formal languages like stl are relatively limited.thus an english stl translator that only depends from statisticalinformation learned from a data set as generally it occurs in nl2nltranslators may be not ideal.however the approach presented here still depends on learn ing the statistical features of the training data rather than reallyunderstanding the requirement language.
this is the reason forthe mistranslation of greater than into in example of att seq2seq.
given this in .
.
it is reasonable to see the drop inaccuracy when testing cases are very different from what havebeen trained.
to build deepstl with enhanced trustworthiness the integration of syntactic and semantic information into the end to end learning process using attention mechanism will be a topicof further investigation.finally from a user interaction point of view the next generationof deepstl should output multiple possible translations for the userto choose from thus remembering the user s language preferencesin order to provide customized service.
conclusionwe studied the problem of translating cps natural languagerequirements to stl commonly used to formally specify cps prop erties by the academic community and practitioners.
to addressthe lack of publicly available natural language requirements wedeveloped a procedure for automatically generating english sen tences from stl formulas.
we employed a transformer based nlparchitecture to e ciently train an accurate translator from englishto stl.
experiments demonstrated promising results.while this work focuses on stl speci cations and cps applica tions the underlying principles can be applied to other domainsand speci cation formalisms and have a signi cant positive impacton the eld of requirement engineering.
unlike natural languages formal speci cations have a very constrained structure.
we believethat this observation can be further explored in the future to de velop an even more robust translation mechanism and thus furtherstrengthen requirements engineering methodologies.acknowledgmentsthis project has received funding from the european union shorizon research and innovation programme under grantagreement no and funding from the austrian ffg ict ofthe future program under grant agreement no .620icse may pi t tsburgh pa usajie he ezio bartocci dejan ni kovi haris isakovic and radu grosureferences ezio bartocci jyotirmoy deshmukh alexandre donz georgios fainekos odedmaler dejan ni kovi and sriram sankaranarayanan.
speci cation based moni toring of cyber physical systems a survey on theory tools and applications.
inlectures on runtime veri f ication pages .
springer .
oded maler and dejan ni kovi .
monitoring properties of analog and mixed signal circuits.international journal on software tools for technology transfer .
rani nelken and nissim francez.
automatic translation of natural languagesystem speci cations.
inproc.
of cav the 8th international conference oncomputer aided veri f ication volume oflncs pages .
springer .
matthew b. dwyer george s. avrunin and james c. corbett.
patterns in propertyspeci cations for nite state veri cation.
inproc.
of icse the internationalconference on software engineering pages .
acm .
aarne ranta.
translating between language and logic what is easy and whatis di cult.
inproc.
of cade the 23rd international conference on automateddeduction volume oflncs pages .
springer .
hadas kress gazit georgios e. fainekos and george j. pappas.
translatingstructured english to robot controllers.adv.
robotics .
rongjie yan chih hong cheng and yesheng chai.
formal consistency checkingover speci cations in natural languages.
inproc.
of date the design automation test in europe pages .
acm .
marco autili lars grunske markus lumpe patrizio pelliccione and antonytang.
aligning qualitative real time and probabilistic property speci cationpatterns using a structured english grammar.ieee trans.
software eng.
.
andrea brunello angelo montanari and mark reynolds.
synthesis of ltlformulas from natural language texts state of the art and research directions.
inproc.
of time the 26th international symposium on temporal representationand reasoning volume oflipics pages .
schloss dagstuhl leibniz zentrum f r informatik .
allen p. nikora and galen balcom.
automated identi cation of ltl patternsin natural language requirements.
inproc.
of issre the 20th internationalsymposium on software reliability engineering pages .
constantine lignos vasumathi raman cameron finucane mitchell p. marcus and hadas kress gazit.
provably correct reactive control from natural language.auton.
robots .
rongjie yan chih hong cheng and yesheng chai.
formal consistency checkingover speci cations in natural languages.
inproc.
of design automation testin europe conference exhibition date pages .
ieee .
shalini ghosh daniel elenius wenchao li patrick lincoln natarajan shankar and wilfried steiner.
arsenal automatic requirements speci cation extractionfrom natural language.
inproc.
of nfm the 8th international symposium onnasa formal methods volume oflncs pages .
springer .
alessandro fantechi stefania gnesi gioia ristori michele carenini massimovanocchi and paolo moreschini.
assisting requirement formalization by meansof natural language translation.formal methods syst.
des.
.
juraj dzifcak matthias scheutz chitta baral and paul schermerhorn.
whatto do and how to do it translating natural language directives into temporaland dynamic logic representation for goal management and action execution.
inproc.
of icra the ieee international conference on robotics and automation pages .
christopher b. harris and ian g. harris.
generating formal hardware veri cationproperties from natural language documentation.
inproceedings of the 2015ieee 9th international conference on semantic computing ieee icsc pages49 .
sascha konrad and betty h. c. cheng.
real time speci cation patterns.
inproc.of icse the 27th international conference on software engineering icse page372 new york ny usa .
acm.
tain santos gustavo carvalho and augusto sampaio.
formal modelling of envi ronment restrictions from natural language requirements.
inproc.
of sbmf the 21st brazilian symposium on formal methods foundations and applications volume oflncs pages .
springer .
amir pnueli.
the temporal logic of programs.
inproc.
of the 18th annualsymposium on foundations of computer science pages .
ieee .
chaima boufaied maris jukss domenico bianculli lionel claude briand andyago isasi parache.
signal based properties of cyber physical systems taxonomyand logic based characterization.journal of systems and software .
bardh hoxha houssam abbas and georgios e. fainekos.
benchmarks for tem poral logic requirements for automotive systems.
in goran frehse and matthiasalthoff editors proc.
of arch cpsweek the 1st and 2nd internationalworkshop on applied veri f ication for continuous and hybrid systems volume 34ofepic series in computing pages .
easychair .
yuk wah wong and raymond j. mooney.
learning for semantic parsing withstatistical machine translation.
in robert c. moore jeffa.
bilmes jenniferchu carroll and mark sanderson editors proc.
of human language technologyconference of the north american chapter of the association of computationallinguistics.
the association for computational linguistics .
sempre semantic parsing with execution accessed .
rohit j. kate and raymond j. mooney.
using string kernels for learning semanticparsers.
in nicoletta calzolari claire cardie and pierre isabelle editors proc.
ofacl the 21st international conference on computational linguistics and 44thannual meeting of the association for computational linguistics.
the associationfor computer linguistics .
sippycup accessed .
yoav artzi.
cornell spf cornell semantic parsing framework .
navid yaghmazadeh yuepeng wang isil dillig and thomas dillig.
sqlizer querysynthesis from natural language.proc.
acm program.
lang.
oopsla .
fei li and h. v. jagadish.
constructing an interactive natural language interfacefor relational databases.proc.
vldb endow.
september .
lappoon r. tang and raymond j. mooney.
automated construction of databaseinterfaces intergrating statistical and relational learning for semantic parsing.
inproc.
of joint sigdat conference on empirical methods in natural languageprocessing and very large corpora pages .
association for computationallinguistics .
john m. zelle and raymond j. mooney.
learning to parse database queries usinginductive logic programming.
inproc.
of aaai iaai the thirteenth nationalconference on arti f icial intelligence and eighth innovative applications of arti f icialintelligence conference pages .
aaai press the mit press .
victor zhong caiming xiong and richard socher.
seq2sql generating struc tured queries from natural language using reinforcement learning.corr abs .
.
yusuke oda hiroyuki fudaba graham neubig hideaki hata sakriani sakti tomoki toda and satoshi nakamura.
learning to generate pseudo code fromsource code using statistical machine translation t .
in myra b. cohen larsgrunske and michael whalen editors proc.
of ase the 30th ieee acminternational conference on automated software engineering pages .
ieeecomputer society .
xi victoria lin chenglong wang luke zettlemoyer and michael d. ernst.nl2bash a corpus and semantic parser for natural language interface to thelinux operating system.
in nicoletta calzolari khalid choukri christopher cieri thierry declerck sara goggi k iti hasida hitoshi isahara bente maegaard joseph mariani h l ne mazo asunci n moreno jan odijk stelios piperidis and takenobu tokunaga editors proc.
of lrec the eleventh internationalconference on language resources and evaluation.
european language resourcesassociation elra .
chris quirk raymond mooney and michel galley.
language to code learningsemantic parsers for if this then that recipes.
inproceedings of the 53rd annualmeeting of the association for computational linguistics and the 7th internationaljoint conference on natural language processing volume long papers pages878 beijing china .
association for computational linguistics.
nikhil ketkar.introduction to pytorch pages .
apress berkeley ca .
mart n abadi paul barham jianmin chen zhifeng chen andy davis jeffreydean matthieu devin sanjay ghemawat geoffrey irving michael isard manju nath kudlur josh levenberg rajat monga sherry moore derek gordon murray benoit steiner paul a. tucker vijay vasudevan pete warden martin wicke yuan yu and xiaoqiang zheng.
tensor ow a system for large scale machinelearning.
inproc.
of osdi the 12th usenix symposium on operating systemsdesign and implementation pages .
usenix association .
ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n. gomez lukasz kaiser and illia polosukhin.
attention is all you need.in isabelle guyon ulrike von luxburg samy bengio hanna m. wallach robfergus s. v. n. vishwanathan and roman garnett editors advances in neu ral information processing systems annual conference on neural informationprocessing systems pages .
xiaoqing jin jyotirmoy v deshmukh james kapinski koichi ueda and kenbutts.
powertrain control veri cation benchmark.
inproceedings of the 17thinternational conference on hybrid systems computation and control pages .
christoph gladisch thomas heinz christian heinzemann jens oehlerking anne von vietinghoff and tim p tzer.
experience paper search based testingin automated driving control applications.
in2019 34th ieee acm internationalconference on automated software engineering ase pages .
ieee .
zhiyu liu bo wu jin dai and hai lin.
distributed communication awaremotion planning for multi agent systems from stl and spatel speci cations.
in2017 ieee 56th annual conference on decision and control cdc pages .ieee .
parv kapoor anand balakrishnan and jyotirmoy v deshmukh.
model basedreinforcement learning from signal temporal logic speci cations.arxiv preprintarxiv .
.621deepstl from english requirements to signal temporal logicicse may pi t tsburgh pa usa derya aksaray austin jones zhaodan kong mac schwager and calin belta.q learning for robust satisfaction of signal temporal logic speci cations.
in2016ieee 55th conference on decision and control cdc pages .
ieee .
hsuan cheng liao.
a survey of reinforcement learning with temporal logicrewards .
wenliang liu and calin belta.
model based safe policy search from signaltemporal logic speci cations using recurrent neural networks.arxiv preprintarxiv .
.
gang chen mei liu and zhaodan kong.
temporal logic based semantic fault di agnosis with time series data from industrial internet of things.ieee transactionson industrial electronics .
in neon datasheet.
sutskever oriol vinyals and quoc v le.
sequence to sequence learning withneural networks.
inadvances in neural information processing systems pages3104 .
dzmitry bahdanau kyunghyun cho and yoshua bengio.
neural machine trans lation by jointly learning to align and translate.arxiv preprint arxiv .
.
jiatao gu zhengdong lu hang li and victor o.k.
li.
incorporating copyingmechanism in sequence to sequence learning.
inproceedings of the 54th annualmeeting of the association for computational linguistics volume long papers pages .
association for computational linguistics .
rico sennrich barry haddow and alexandra birch.
neural machine translationof rare words with subword units.
inproc.
of acl the 54th annual meetingof the association for computational volume long papers .
yonghui wu mike schuster zhifeng chen quoc v. le mohammad norouzi wolfgang macherey maxim krikun yuan cao qin gao klaus macherey jeffklingner apurva shah melvin johnson xiaobing liu lukasz kaiser stephangouws yoshikiyo kato taku kudo hideto kazawa keith stevens george kurian nishant patil wei wang cliffyoung jason smith jason riesa alex rudnick oriol vinyals greg corrado macduffhughes and jeffrey dean.
google s neuralmachine translation system bridging the gap between human and machinetranslation.corr abs .
.
taku kudo.
subword regularization improving neural network translationmodels with multiple subword candidates.
inproceedings of the 56th annualmeeting of the association for computational linguistics volume long papers pages melbourne australia july .
association for computationallinguistics.
aston zhang zachary c lipton mu li and alexander j smola.
dive into deeplearning.arxiv preprint arxiv .
.
kyunghyun cho bart van merri nboer dzmitry bahdanau and yoshua bengio.on the properties of neural machine translation encoder decoder approaches.arxiv preprint arxiv .
.
diederik p kingma and jimmy ba.
adam a method for stochastic optimization.arxiv preprint arxiv .
.
kishore papineni salim roukos todd ward and wei jing zhu.
bleu a methodfor automatic evaluation of machine translation.
inproceedings of the 40th annualmeeting of the association for computational linguistics pages .
steven y feng varun gangal jason wei sarath chandar soroush vosoughi teruko mitamura and eduard hovy.
a survey of data augmentation approachesfor nlp.arxiv preprint arxiv .
.
jing li aixin sun jianglei han and chenliang li.
a survey on deep learning fornamed entity recognition.ieee transactions on knowledge and data engineering .
vikas yadav and steven bethard.
a survey on recent advances in named entityrecognition from deep learning models.arxiv preprint arxiv .
.
xipeng qiu tianxiang sun yige xu yunfan shao ning dai and xuanjinghuang.
pre trained models for natural language processing a survey.sciencechina technological sciences .