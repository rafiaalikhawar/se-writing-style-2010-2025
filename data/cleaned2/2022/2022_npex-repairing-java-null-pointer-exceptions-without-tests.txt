npex repairing java null pointer exceptions without tests junhee lee korea university republic of korea junhee lee korea.ac.krseongjoon hong korea university republic of korea seongjoon korea.ac.krhakjoo oh korea university republic of korea hakjoo oh korea.ac.kr abstract we present npex a new technique for repairing java null pointer exceptions npes without tests.
state of the artnpe repair techniquesrelyontestsuiteswrittenbydevelopersforpatchvalidation.
unfortunately however thosearetypicallyfuturetestcasesthatare unavailable at the time bugs are reported or insufficient to identify correct patches.
unlike existing techniques npexdoes notrequire test cases instead npex automatically infers the repair specification of the buggy program and uses the inferred specification to validatepatches.thekeyideaistolearnastatisticalmodelthatpredicts how developers would handle npes by mining null handling patterns from existingcodebases and to usea variant of symbolic execution that can infer the repair specification from the buggy program using the model.
we evaluated npex on real world npes collected from diverse open source projects.
the results show that npex significantly outperforms the current state of the art.
acm reference format junhee lee seongjoon hong and hakjoo oh.
.
npex repairing java null pointer exceptions without tests.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction null pointer exceptions npes are perhaps the most infamousbug in java.
npes represent a serious flaw of a program becausedereferencing a null pointer always causes the program to crash.furthermore npesarehighlyprevalentinreal worldjavaappli cations .
for example npes take up .
and .
of crashes in open source projects and android applications respectively and recent studies show that npes are the most prevailing uncaught exception in production environments .
yet fixing npes remains challenging because simply avoidingcrashesisoftenincorrectandfindingacorrectfixoutofa wide range of candidates is nontrivial.
the first and second authors contributed equally to this work.
corresponding author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
.overthelastdecade automated program repair apr techniques have shown promise inaddressingthechallengeofbugfixing .
most existing apr techniques follow the conventionalgenerate and validate approach which alternates the two phases patchgenerationand patchvalidation.in thepatch generation phase a candidate patch is selected from a pre defined search space and in the patch validation phase the correctness of thecandidatepatch ischeckedbyrunningthe patchedprogramon asetoftestcases.thisprocessisrepeateduntilaplausiblepatch that passes all test cases is found.
vfix isthecurrentstate of the artforrepairingnpes.its novel feature is to use value flow information of programs to accuratelylocalizesuspiciousstatementsandreducethesearchspaceof candidatepatchesappropriatelyfornpes.thereducedpatchspace improvestheefficiencyofthegenerate and validateprocessand also increases the chances of finding correct patches.
as a result vfix has been shown to outperform existing apr techniques such asgenprog acs capgen nopol simfix and npefix when evaluated for npes .
ourapproach .inthispaper wepresentanewapproach called npex forrepairingnpes.likeexistingaprtechniques npexfollowsthestandardgenerate and validateapproach.thedifference though isthatnpexreplacesthetest basedpatchvalidationphase of the existing approach by a novel technique that can validate patches without relying on test cases.
we avoid using test cases as a validation oracle for two reasons.
first because test cases are typically unavailable at the time a bug is reported they cannot be effectively used by a repair tool thataimstofixthebugassoonasitisdetected.furthermore using a test suite as a repair specification is likely to produce incorrectpatches fitted only to the given tests .
for example as wedemonstrateinthispaper eventhe state of the artvfix which reduces incorrect patches using a customized patch space often fails to fix diverse npes due to overfitting.
weusetwokeyideastovalidatenpepatcheswithouttests.first we use a statistical model that predicts how developers would handlenpes.tolearnsuchamodel wecollectvariousnull handling patterns available in existing codebases.
for example from null handling code x !
null ?
x.m we extract the knowledgethattheexpectedreturnvalueof x.m is0whenxisnull and therefore an npe occurs at x.m .
we then generalize this patternusingprogram independentfeaturesforexpressionsand surrounding contexts.
second we use the model to infer the expected behavior of a buggy program.
to this end we use a variant ofsymbolicexecutionthatinterpretsnpe triggeringexpressionsin the buggy program using the model s prediction.
the result of this symbolic execution is used as the repair specification of the buggy ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa junhee lee seongjoon hong and hakjoo oh a buggy program 1boolean compare int row column ?
temp column ?
org 2object o1 org.get row 3object o2 temp.get temp.size 4returno1.equals o2 npe b npe triggering input intmissing intcolumntype.missingvalueindicator table t1 table.create t1 intcolumn.create id intcolumn.create childid missing missing t1.dropduplicaterows compare is invoked inside c npex generated patch developer s patch returno1.equals o2 returno1 null?o null o1.equals o2 figure an npe bug line and developer patch program given a candidate patch during the generate and validate process we analyze the behavior of the patched program to check if it satisfies the inferred specification.
the evaluation results show that our approach substantially improvesuponthecurrentstate of the art.weimplementedour approach as a tool npex using existing methods for fault localizationandpatchgeneration .weused119npebugscollected from prior work as well as open source projects and comparedtheperformanceof npexwithtwostate of the arttech niques vfix andgenesis forrepairingnpes.theresults show that npex can correctly fix of those bugs even without test cases while genesis and vfix fixed and respectively with test cases.
contributions.
we summarize our contributions below wepresentanewtechniqueforvalidatingnpepatcheswith out test cases.
the key idea is to infer the expected behavior of a buggy program by combining statistical learning and symbolic execution.
wepresentnpex anend to endpatchgenerationsystemfor java npes.
npex is able to fix npes given a buggy program and crashing input only.
wedemonstratetheeffectiveness of npexincomparison withcurrentstate of the arts.ourresultsarereproducible thesourcecodeof npexandthebenchmarksarepublicly available.
overview this section motivates and illustrates npex with examples.
.
motivating example figure1describesannpebug2foundinproject tablesaw .method compareinfigure a checksif twoobjectsassociated with temp andorgareequivalent.thenpeoccurswhendereferencing o1 i.e.
m object obj string valueifnull if obj null return valueifnull developer patch 3class cls obj.getclass npe 4string name cls.getcanonname 5if name null return valueifnull 6else returnname figure a buggy program simplified from apache com mons lang and the developer patch commented out .
1if obj null 2return null 3class cls ... 4string name ... 1if obj null 2returnvalueifnull 3class cls ... 4string name ... p1 incorrect p2 correct figure candidate patches o1.equals o2 atline4 where o1isnullifelementsaremissing atposition rowoforg.inpractice npesaretypicallyreportedwith bug triggeringinputonly inthiscase thebugreportwasgiven3 with the single npe triggering input shown in figure b .
giventhebuggyprogram figure1 a andnpe triggeringinput figure b npex generates the patch in figure c which is exactly the same as the developer s patch.
note that producingthe correct patch is nontrivial because there are various ways of avoiding the npe.
for example all the following candidate patches eliminatethenpewheninsertedrightbeforeline4 buttheirsemantics differs from that of the developer patch if o1 null return false if o1 null return true if o1 null o1 new object toexcludetheseincorrectpatches npexautomaticallyinfers the expected specification of the buggy program and validates candidatepatchesagainst it.inthiscase npexinfersthat when o1isnull compare should return true if o2isnulland false otherwise .
none of the incorrect patches satisfy this specification and are therefore rejected by npex.
existing test based techniques e.g.
vfix and genesis do not work well when the test suite only includes the crashinginput.
vfix would generate the first incorrect patch if o1 null return false sinceitsrankingheuristicprioritizespatches that skip statements containing npes and return default values.genesisgeneratedapatchthatimplementsalogictoremoveall columns with a missing value which is obviously incorrect.
.
how npex works the distinctive feature of npex is in the patch validation phase.
we explain how npex validates patches with the buggy program in figure where method invocation obj.getclass at line authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
npex repairing java null pointer exceptions without tests icse may pittsburgh pa usa raisesannpewhenvariable objisnotinitialized.themethod m is supposed to return the canonical name of the obj s class.
when objoritscanonicalname name isnull however misexpectedto return the default value valueifnull .
assume that we are given the variable objat line as the fault expression.assumefurther thattwocandidate patches p1andp2 in figure are generated during the repair process.
while both patchessucceedtoeliminatethegivennpe p1isincorrectbecause it returns null instead of valueifnull whenobjisnull which violates the intended behavior of the method.
the goal of npex is to invalidate p1while validating the correctness of p2.
learninganull handlingmodel .npexusesastatisticalnullhandling model to validate patches which is learned from existing codebases and used to repair new unseen buggy programs.
the null handling model denoted m predicts how developers would handle an npe by inferring an alternative expression to replace the npe triggering expression.
for example it infers that when objisnull theentirenpe triggeringexpression obj.getclass at line should be interpreted as if it were the expression null.
also when clsisnull themodelinfersthatthenpe triggering expression cls.getcanonname atline4shouldbeinterpretedas null.insummary wheninstantiatedfortheexampleprogramin figure the model mcan be treated as the following function m braceleftbiggnull.getclass null null.getcanonname null bracerightbigg .
npex learns such a model by mining various null handling patterns available incodebases.
the intuition is that existingnullhandlingpatternswrittenbydevelopersaregoodreferencesforhan dlingnpes andinferringalternativeexpressions .forinstance con siderthenull handlingcodesnippetavailableinproject rapi args !
null ?
args .getclass null from which we find that expression nullcan be alternatively used for the npe triggering expression args .getclass when args isnull.
generalizing this we learn the first replacement null.getclass null ofthemodel min .thecodebasemayhavedifferentpatterns forthesamemethod getclass .forexample thefollowingpattern is also available in rapi obj !
null ?
obj.getclass object.class from which we infer the following null.getclass object.class .
when applying the model we resolve the conflict by choosing themostappropriateonebasedonthesurroundingcodecontext section3.
forourexample weassumedthepatternin was chosen.theknowledgeforhandling getcanonname canbeinferred from the following code snippet in project dozer5 destcls !
null ?
destcls.getcanonname null from which we obtain the second replacement in .
inference .once a model is learned we can use it to infer the expected behavior of a buggy program.
to do so we run a variant of symbolic execution on the buggy program that interprets npe triggering expressions using the null handling model.
the result of this symbolic execution will be used as the repair specification against which we validate candidate patches.
consider the buggy method min figure .
our symbolic execution beginswith the initial state init init where initis the initial path condition i.e.
init and initis the initial symbolic store i.e.
init that maps formal parameters to fresh symbols and .
atline3 weencounterthemethodinvocation obj.getclass whosebasevariable objisthefaultexpressionthatcausesthenpe.
the key difference between normal symbolic execution and our variant is that we interpret such an npe triggering expression obj.getclass using the alternative expression inferred by the null handlingmodel.forexample themodelin infers nullas thealternativeexpressionfor obj.getclass whenobjisnull.
thus our symbolic execution produces the following two states as output of line s1 1 1 null init s2 2 2 null init states1represents the output of the npe triggering execution whereobjisnull denoted by path condition null .
in this case store 1is obtained using the null handling model as follows 1 init init where we inferred the expected meaning of the method invocation usingm.
states2represents the normal execution where no npe occurs.
we use an uninterpreted function symbol to represent the return value of the external method f denotes the symbolic value that obj.getclass evaluates to.
withs1ands2asinputstates symbolicexecutionofline4results in the following output states s3 3 3 null 1 s4 4 4 null 2 notethattheexecutionwith s1encountersanewnpebecause cls holdsnullins1andmethod getcanonname iscalledonit.thus we usethenull handlingmodelagaintoinfertheexpectedbehavior ofnull.getcanonname and obatin store 3as follows 3 1 1 .
states4istheresultofexecutingline4withinputstate s2 where g f is the symbolic value representing cls.getcanonname .
wecompletesymbolicexecutionbyanalyzingtheifstatementat line with states s3ands4as input which produces the following three states as output s5 null 3 s6 null g f null 4 s7 null g f null 4 theinputstate s3resultsin s5takingonlythetruebranchasthe valueofnameisnullins3.withs4 weconsiderbothtrueandfalse branches producing s6ands7 respectively.finally weobtainthe authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa junhee lee seongjoon hong and hakjoo oh symbolic summary smof method mby removing information about local variables in those states sm null init null g f null init null g f null init weconsiderthesymbolicsummary smastherepairspecificationof thebuggymethod m.thatis ourrepairspecificationisthesummary of theinstrumented semanticsof the buggymethod mwhere each npe triggering expression is replaced by an alternative expression using the null handling model.
patch validation .now we validate candidate patches against theinferredspecification sm.weconcludethatacandidatepatch iscorrectiffrunninganormalsymbolicexecutiononitproduces asummaryequivalentto sm.forexample thesummary s1ofthe incorrect patch p1in figure is computed as follows s1 null init null g f null init null g f null init note that s1andsmdo not agree with the return value ret when isnull i.e.
init init concluding that patchp1does not satisfy the repair specification.
by contrast symbolicexecutionofthecorrectpatch p2producesasummaryexactly equivalentto sm.wecanchecktheequivalenceofsummariesusing an off the shelf smt solver.
our patch validation technique inthissection wedescribehownpexvalidatespatchesindetail.
ourapproachconsistsoftwophases learninganullhandling model section3.
fromacodebase and validatingcandidate patches using the model section .
.
programs .a java program p pgmis a sequence of class declarations whereaclassdeclarationisapairofaclassnameanda sequence of method declarations.
a method declaration consistsofareturntype amethodname aformalparameter andabody statement.wewrite pmandbody m fortheparameterandbody statement of method m respectively.
a type tis either a primitive type we only consider intfor simplicity or a reference type for custom classes c .
we consider the usual statements s and expressions e in java s x e returne ifes1s2 whilees s1 s2 e n null x x.m y newc e1?e2 e3 e1 e2 we do not consider field access x.y because it is very rare to directly access public fields in real world java programs fields are typicallyaccessedviagettermethodsthatourlanguagesupports.
weassumetheprogramisstaticallytypedandwrite type e forthe typeofexpression e.weassumethatmethodnamesareunique.the bodyofa whilestatementmayincludecontrolstatements breakor continue .
a variable is either a local or this.
we write enpefor thesetofexpressionswherenpesmayoccur inourlanguage enpe represents the set of method invocations i.e.
x.m y where npes occur when xis a null pointer.
.
learning a null handling model the goal of the learning phase is to learn a null handling model m pgm enpe e fromadatasetofprograms.givenaprogram p pgmanditsnpetriggeringexpression enpe enpe mp enpe predictsanalternative expression that can be used as a substitute for enpeto correctly handle the npe.
we construct the model in the following steps.
collectingnull handlingpatterns .thefirststepistocollect a dataset dof null handling patterns from a codebase.
let p p1 p2 ... pm beacollectionofprograms.thedataset disofthe type d pgm enpe e. that is dis a set of tuples p enpe e wherep pisaprograminthecodebase enpeisannpeexpression inp andeis an expression that is alternatively used in pwhen enpecauses an npe.
to collect thedataset d we traversethe abstract syntax tree of each program p pand observe how npes are handled.
for example fromternaryexpressionoftheform x null?e x.m y we collect tuple p x.m y e meaning that when xis a null pointer and hence an npe occurs at expression x.m y w ec a n alternativelyuseexpression einsteadof x.m y .whencollecting null handling patterns we mainly consider such ternary expressionsasthenpe triggeringexpression x.m y andthecorresponding alternative expression e are clearly identifiable.
note that other several null handling patterns can be translated to ternary expressions.
for example boolean expression x null x.m y istranslatedinto x null?true x.m y andrepresentedby tuple p x.m y true .
generalization .once we collect null handling patterns we generalizethembyabstractingalternativeexpressions.themain purposeofthisstepistodiscardprogram dependentinformation such as local variable and user defined class names.
we also make thedatasetmoreamenabletolearningbyconsideringafinitesubset of alternative expressions.
the output of this step is the following hatwided pgm enpe hatwidee where hatwideedenotes abstract expressions defined as follows hatwidee nd null arg new arg hatwidee hatwidee nd null latticetop here nddenotes a finite set of integers that frequently appear in the dataset d. npex uses nd because they were the top most popular integers in d. we do not distinguish names ofmethodargumentsandrepresentthembyanabstractelement denotedarg.anewexpression newc isabstractedto newwhere its type information c is discarded.
an equality test e1 e2 i s abstractedinto arg hatwideewhene1isanargumentvariableand e2 isgeneralizedtoaliteralin nd null .wediscardothercases andsimplyrepresentthemby latticetop.specifically wedefinefunction enpe e hatwideefor generalization as follows enpe e e e n d null new e newc arg enpe x.m y e y arg n enpe x.m y e y n n nd null latticetop otherwise authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
npex repairing java null pointer exceptions without tests icse may pittsburgh pa usa with the generalized dataset hatwidedis obtained as follows hatwided p enpe enpe e p enpe e d .
feature representation .next werepresentnpeexpressions as feature vectors to generate the training data d d n hatwidee.
to do so we assume nboolean features 1 2 ... n where each feature i pgm enpe is a predicate on program and npe expression pairs and describes characteristics of an npe expression and its surrounding code context.
for instance a feature may describe whether an npe expression belongs to atry catch block.
we write p enpe for the feature vector of p enpe p enpe angbracketleft 1 p enpe 2 p enpe ... n p enpe angbracketright.
with we can generate the training data das follows d p enpe hatwidee p enpe hatwidee hatwided .
weuse31featuresintable1.here eachfeatureisapredicate onmethodcalls x.m y sinceenpedenotesthesetofmethodinvocations in our language.
the features are divided into three classes method name features method body features and context features.
the method name features describe which keywords appear in the name f ofthe called method.weused keywords asthe name features.
to select these keywords we collected all the method namesfromourcodebase splitthemintokeywordsbythecamel case andrankedthetop20bytheirfrequency.themethodbodyfeaturescheckwhetherabodystatementcontainsaspecificast component.wedesignedthosetwoclassesoffeaturestoidentify what kind of methods is invoked.
for example features and are strong indicators for getter methods.
thecontext features capture the syntactic code contexts around an npe expression.
trainingamodel .from the training data d we train a probabilistic multi label classifier to learn a probability distribution over hatwideefor a given feature vector.let prbe the learned probabilitydistribution given a program p an npe expression enpe and abstract expression hatwidee hatwidee pr hatwidee p enpe denotestheprobabilityofthe alternative expression of enpebeing hatwidee.
we computed prusing an off the shelf learning algorithm for random forest classifier.
wecanconstructthenull handlingmodel mfrompr withan additional process that concretizes an abstract expression into a type compatible concrete expression.
we define enpe hatwidee e for concretization which converts an abstract expression into a concrete expression as follows x.m y hatwidee n hatwidee n t int null hatwidee null t int newc hatwidee new t c y hatwidee arg type y t y e hatwidee arg e t int otherwise wheretdenotes the type of expression x.m y .
with our nullhandling model m pgm enpe eis defined as follows mp enpe enpe argmax hatwidee cpr hatwidee p enpe wherec hatwidee hatwidee enpe hatwidee is the set of concretizable expressions and we pick one with the highest probability.table features for method invocations class description name features1 .
code .
hash .
append .
equals .
on .
error .
success .
get .
set .
is .
add .
.
close .
empty .
value .
put .
string .
to .
remove .
write .
contains body features21return type is void 22method returns a literal 23thrown exceptions are annotated 24null check expression exists 25method returns a constructor call 26method is the base of another invocation 27method returns a field context features28caller method is private 29null pointer is assigned to an array 30null pointer is assigned to a field 31null pointer is assigned to a public field .
validating patches using the model next we use the model to validate the correctness of a candidatepatch.
to this end we first infer the correctness specification ofa buggy program using the learnt null handling model and then check if the patch candidate satisfies the inferred specification.
specification inference .we use the null handling model to infer the correct behavior of a buggy program.
suppose a buggyprogram pnpe pgmisgivenandthebuggy npe triggering expressionin pnpeisxnpe.m y wherexnpeisthefaultvariablewhose valueisnullalongthebuggytrace.forsimplicity weassumethere isonlyasinglenpeinthebuggyprogram.supposealsothatanull handlingmodel mlearnedfromanexistingcodebaseisgiven.the goal of specification inference is then to infer the desired behavior of the buggy program when the npe is correctly fixed.
we infer the correctness specification by running a variant of symbolicexecutiononthebuggyprogramandinterpretingthenpetriggering expression xnpe.m y using the null handling model.
to this end we first define a normal symbolic execution procedure and explain how to extend it to use the null handling model.
weconsidertheoutputofsymbolicexecutionasthespecification of the input program.
the output of our symbolic execution is a table from methods to summaries sumtable method summary where a summary is defined as follows s summary p state s state pc store pc p symval symval store var symval v symval z class null symbol asummary summary isasetofprogramstates state andastate consistsofapathcondition pc andastore store .apathcondition isacollectionofbranchconditions whereabranchconditionisan equalityofsymbolicvaluesoritsnegation.astoreisamapfrom authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa junhee lee seongjoon hong and hakjoo oh variablestosymbolicvalues.symbolicvaluesincludeintegers class types null and symbols representing method parameters.
for scalability we have designed our symbolic execution denotedsymexec pgm sumtable to be compositional and bounded .
it analyzes each method of a program only once by calculating its summary in isolation using summaries of callee methods.loopsandrecursivecallcyclesareunrolledfinitetimes priortotheanalysis.forpresentationsimplicity weassumethat methodnamesareunique i.e.
nomethodoverridingandoverloading and ternary expressions are converted to ifstatements.
with these assumptions it is enough to define symbolic execution for the following subset of statements and expressions s x e returnx if x y s1s2 s1 s2 e n null x x.f y newc theprocedure symexec isdefinedasfollows whichcomputes method summaries in a bottom up manner symexec p mi f body mi i si init n i wherem1 ... mnare a sequence of methods sorted according to the reverse topological order of the call graph iis the partial summary table for methods m1 ... mi and the initial state si init is defined by which indicates that the formal parameter pmiof method miis bound to a fresh symbolic value mi.thesemanticfunction f stmt sumtable state p state is defined in a standard manner as follows f x n f x null f x y f x newc f x y.m z im i f s1 s2 s uniontext.
f s2 s prime s prime f s1 s f if x y s1s2 f s1 s1 f s2 s2 wheres1 s2 x y x y and im im m .
now we describe how we infer the repair specification of a buggy program pnpe.
we do so by analyzing pnpewith a variant of symbolic execution denoted symexecxnpe m wherexnperefers to the localizedfaultvariablethatcausesthenpeweaimetofixand mis the null handling model.
the overall procedure remains the same symexecxnpe m p mi fxnpe m body mi i si init ni .
the extended semantic function fxnpe m s is defined in the same way as fexcept for the following two cases.
the first case is whensisannpe triggeringstatement i.e.
x y.m z wherey is the fault variable xnpe.
in this case fxnpe m s produces f s nonnull f x mp y.m z npe where nonnull xnpe null and npe xnpe null .theformerdescribesstateswherethefaultvariableisnot null hence they normally execute the invocation.
the latter describes states where the fault variable is null.
in this case we interpret the npe triggering expression using the output of the modelm.
the second case is when sisx y.m z and the basevariable yisnotthefaultvariablebutevaluatesto null i.e.
y null .
this happens when the prediction of themodel in the former case returns null i.e.
mpnpe y.m z null.
ifanewnpeisintroducedbythemodel weapplythemodelagain fxnpe m s f x mpnpe y.m z .
example .
.
note that we infer procedural summaries not only for the faulty method but also for its callers.
let us consider the followingcodethatusesnullpointersacrossprocedureboundaries.
1a foo p returnp.hoo npe 2intgoo z 3ax this.foo z 4returnx.goo supposethatnpeoccursatline1because pisnullandthealternativeexpressioninferredbythemodelis nullforthenpe triggering expression p.hoo .
then the inferred procedural summary of foois foo null where fooandretfoo denote the symbolic parameter and return variable respectively.
then the return value nullpropagates to caller s variable x.s o the model mis applied again at line and we get the summary ofgooas goo null where we assume vis the alternative value for x.goo obtained by the model m. specification validation .the next step is to validate candidate patches against the inferred specification.
let pnpebe a buggy programand pcandbeapatchcandidate.wewouldliketodetermine whetherpcandis a correct patch of pnpe.
we do this by checking the equivalence symexecxnpe m pnpe symexec pcand wherethe left handsidedenotestheinferredrepairspecificationofthebuggyprogram.wesaythattwosummarytables 1and 2areequivalent denoted 1 2 if the following holds for all methods m logicalanddisplay.
1 1 1 m logicalanddisplay.
2 2 2 m 1 2 1 2 whereweassumethesymbolicvaluefortheformalparameterof methodmis consistently named e.g.
m .
intuitively the formula checksifalloutputstatesareequalintheinferredspecificationand the summary of the candidate patch.
note that we check the equivalence not only for the patched method but also for its callers.
a patch could implement correct semanticsforthepatchedmethod butincorrectsemanticsforits callers.
for example consider the program in example .
.
a patch that modifies p.hoo top null ?
null p.hoo is correct for method foo but it introduces a new npe in goo.
in this case wecansuccessfullyrejectthispatchbycheckingthesemantic equivalence for gooas well.
npex npexisanend to endrepairtoolbasedonourideainsection3.
in this section we describe other details of npex.
implementation .we implemented npex in lines of java and7 400linesofocamlcodes.ourfaultlocalizationalgorithmandsymbolicexecutionareimplementedontopoftheinfer framework.wealsoused thespoon librarytoparsejava programs and transform source codes.
overall algorithm .algorithm describes the overall algorithmof npex.givenabuggyprogram pnpe annpestacktrace authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
npex repairing java null pointer exceptions without tests icse may pittsburgh pa usa xnpe and a null handling model mas input the algorithm producesasetofvalidatedpatchestofixthebug.atline1 itfirstruns thebuggyprogramwiththecrashinginputtogetthefaultvariable xnpeandstacktrace .atline2 thebuggyprogram pnpeisanalyzed by our variant of symbolic execution symexecxnpe m which returns therepairspecification inferred ofthebuggyprogram.atline3 we compute a set xof candidate faults.
we iterate each candidate faultx prime npeinx and accumulate validated patches in patches.a t line we enumerate patches with given fault x prime npe and for each patchppatched wecomputeitssummarytable patchedbynormal symbolicexecution.ifthesummarytableof ppatchedisequivalent to the inferred specification inferred we add it to patches.
faultlocalization .ourfaultlocalizationissimilartothatof vfix inthatittracksthedataflowofagivennullpointer.given thefaultexpression xnpeandstacktrace only faultlocalization computesasetofnullpointerexpressionsthatmaybealiasto xnpe foreachmethodinthestacktrace .wedonotrankeachfaultand returns the set of all the computed faults as we validate patchesbyinferredspecificationsrather thanrelyingona patchranking heuristic.weimplementedalight weightpointeranalysisontop of infer to compute alias information.
patchenumeration .giventhelocalizedfaultexpression xnpe patchenumeration enumerates patches based on pre defined templates.
we used the following templates from prior work skip i if xnpe!
null s or ii if xnpe null fb replace xnpe null?
e enpe init if xnpe null xnpe e skipskips a statement or a block s containing an npe skip i orinsertsacontrolflowbreak fb break continue return e o rthrowexn skip ii .
replace substitutes an expression involving the fault expression enpe with a ternary with an alternative expression e .initinitializes a null pointer to a fresh object obtained by calling a constructor e .
for expressions e weusedfrequentexpressionsinnull handlingpatternscollected from our training database.
we collected the top frequent expressions for each of primitive types and common class types e.g.
java.util.arraylist .
we synthesize exceptions exn f r o me x ceptions thrown around the fault expression within its class.
we implemented patchenumeration using the spoon library s source code transformation.
scalable symbolic execution .we implemented symbolic executionontopoftheinfer sbottom upanalysisframework.we tookadvantageofthebottom upanalysistoanalyzeonlythepartsofprogramsrelatedtoeachpatchinthevalidationphase.althoughtheanalysisisbottom up itwasnontrivialtoimplementascalable symbolic executor that works for real world applications while supportingthefulljavalanguageincludingdynamicdispatch exception handling field accesses etc.
thus we designed a pathmerging heuristic to further accelerate the analysis we only distinguished error states where an npe occurs while merging other npe irrelevant states.
we treated results of an invocation for an externalfunctionasanuninterpretedsymbolassumingithasno side effect.forthejavalibraryclassmethods e.g thestringmeth ods we modeled the effect of each method.
we unrolled each loop of programs twice.algorithm the npex algorithm input buggy program pnpe npe stack trace xnpe modelm output a setpatchesof validated patches xnpe runprogram pnpe i fault variable and stack trace patches inferred symexecxnpe m pnpe spec inference x faultlocalization pnpe forx prime npe xdo forppatched patchenumeration pnpe x prime npe do patched symexec ppatched if patched inferred then spec validation patches patches ppatched end if end for end for returnpatches null handling model .we implemented null handling code mining and feature extraction using spoon.
we collected null handling patterns of more various syntactic forms than ternarydescribed in section .
.
for example we additionally collected null handles of the following form y e ...if xnpe!
null y xnpe.foo where we interpreted eas an alternative value for foo.
use cases of npex .npex can be used in many application scenarios.
first of all note that npex does not require a failing test instead npexonlyrequiresastacktrace oracrashinginput to obtain the stack trace .
in the context of npes a failing test is apairofacrashing npe triggeringinputandthecorresponding expected output.
what npex requires is the crashing input which isavailablewhennpesaredetectedandconfirmed.ontheother hand we do not require the expected output which is typically un availableatthetimenpesarereported itisprovidedbyadeveloper later when the reported npe is fixed.
because npex only requires a stack trace crashing input it can be used in many practical scenarios to automatically fix npes as soon as they are detected.
for example we can use npex to fix npesdetectedbyautomatictestingtoolsorstaticbug finders.also npex can be used to fix npes reported in issue tracking systems.
stacktracesareusuallyavailablewhennpesaredetectedand reported.forexample whennpesarefoundbytestingtools stack traces are immediately available from the crashes.
also static bugfinders usually provide error traces stack traces for reported bugs.
whennpebugsarereportedinissuetrackingsystems itistypical that users include a crashing input or stack trace in the bug report.
evaluation in this section we evaluate npex in comparison with state of theart techniques for repairing npes.
.
setup benchmark selection .we used four different benchmark sets vfixbm npe bugs from .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa junhee lee seongjoon hong and hakjoo oh genbm npe bugs from .
bearsbm npe bugs from bears .
ourbm npe bugs from open source repositories.
vfixbm genbm andbearsbmcamefrompriorwork.vfixbmconsistsof30npebugs ofwhich15isfromdefects4j andanother from open source repositories collected by the authors of vfix.
we note that the structures of the projects in vfixbm are modified by the authors of vfix to easily run vfix.
they removed the build system in the original projects and wrote a compilable main.javathatactsasatestsuite.weusedvfixbmastheyareprovided without any modification.we alsocollected npe bugs used forevaluatinggenesis andcontainedinbears .bothof these benchmarks consist of npe bugs collected from open source projects in github and use the apache maven project management system6.f r o m we only collected benchmarks that can be built in our environment and parsed by spoon and infer .
finally we excluded benchmarks that already exist in differentbenchmark sets leading to and npe bugs in genbm and bearsbm respectively.
in addition we tried to collect more diverse npe bugs from open source projects and constructed ourbm as the result.
we usedtwosources thetop 200javarepositoriesingithubsortedbythenumberofstarsand repositoriesundertheapacheproject page7.
among them we only considered projects that can be built bythemavensystem.fromthoserepositories wecollected4472 commitswhosemessagescontainkeywords npe or nullpointerexception whereweonlyconsideredrecentcommitsupto5years ago.
we then searched for reproducible npe bugs in a similar way as bears was collected we only ran npe triggering test cases to check whether an npe is reproducible in the buggy version i.e.
the parent revision of the collected commit and the error is removedinthefixedversion.also weexcludedbenchmarksthat spoonorinferfailtohandle.finally weexcludedbenchmarksthatarealreadycontainedinthethreebenchmarksetsabove whichled to a total of npe bugs in ourbm.
intotal weused119uniquenpebugsandallofthemcomewith test suites written by developers to check patch correctness.
all experimentsweredoneonamachinerunningubuntu18.04with cpus and 128gb memory powered by intel xeon gold processor.
tool selection andsetup .weevaluatednpexincomparison withvfix andgenesis twostate of the arttechniquesfor repairingnpes.vfixisthemostrecenttechnique whichisnpespecific and known to be significantly more effective than existing apr techniques such as npefix nopol capgen and acs .
genesis is a data driven technique that can effectively fix npes using an npe specific patch space learned fromhuman patches.
we included genesis as it was not evaluated in priorwork .wealsoconsider npexbase whichisthebaselineof npexthatusestheconventionaltest basedpatchvalidationinstead ofournewapproach npexbaseusesexactlythesametechniques for fault localization and patch generation as npex section .
we included npexbaseto see the net effect of our key contribution specification inference and validation .
in the evaluation we excluded npefix another recent technique to fix npes because it was reported that vfix significantly outperforms npefixonvfixbm .also theresultsof npexbasehintat the performance of npefix for otherbenchmarks as theyuse similar patch templates and the same patch validation method i.e.
test cases .
in summary we used the following tools in evaluation npex our technique without test cases npexbase the baseline of npex with test cases vfix a state of the art for fixing npes with test cases genesis a data driven technique for npes with test cases for npex we only used the single npe triggering test contained ineachbenchmark and didnotuse othertest cases.instead npexusedanull handlingmodellearnedfrom571javaprojects.
wecollectedtheseprojectsstartingfromthetop 1000javaprojects based on the number of stars and excluding ones that are not built withmavenorspoon.wealsoexcludedprojectscontainedinthe fourbenchmarksetsinordertoensurethatthetrainingandtestsets do not overlap.
for npexbase we used the same setting as npex except that npex baseuses test cases.
weobtainedgenesisfromthereplicationpackagereleasedby the authors8.
when running genesis we used the search space learned for npe which is also provided in the replication package.
specifically weusedthespacenamed npe space vo becauseithas beenreportedasthebestamongothers .genesistakesasinput a list of passing and failing test cases which is used for fault localization andpatch validation.
because severalbenchmarks contain multiplefailingtestsotherthanthenpe triggeringtest weonly used tests in the npe triggering test case s class as input so that the genesis can precisely localize the target npe.
although genesisusedbugswithmorethan50testcasesin weobservedthat noperformancedegradationoccurredduetothissetting compared to the original numbers reported in .
weobtainedtheexecutablebinary jar of vfixviapersonal communication with the authors.
running vfix was nontrivial as it requires notonly a stack trace and nullpointer fault expression but also a runnable main class with an entry point which actsas a test suite.
therefore running vfix on genbm bearsbm and ourbm was particularly challenging.
we had to manually writethemainclassforeachbug hadtoresolvetheclasspathfor dependencies and set up testing environments by hand without aidsofbuildsystemsandtestingframeworks.wealsoencountered severalinternalerrorsof vfixrunningonthosebenchmarksbut we could not debug them as source code is unavailable.
as a result thoughwedidourbest weendedupwith27outof89benchmarks ingenbm bearsbm andourbm.forthose27benchmarks we preparedstacktracesandnullpointerexpressionsbyrunningnpetriggering test cases.
correctness criteria .we say a patch is correct if it is semanticallyequivalenttothedeveloper spatch.wemanuallyinvestigated each of the generated patches to check the correctness.
follow ing genesis we ignored log messages and error messages of exceptions in the judgement.
vfix often failed to convert anir intermediate representation to source code.
in this case we authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
npex repairing java null pointer exceptions without tests icse may pittsburgh pa usa table evaluation results.
r the number of bugs for which each tool was successfully ran.
g the number of patchess successfully generated and validated by each tool.
c the number of correct patches.
prec precision c g .
fixr fix rate c r .
benchmarks npex npexbase genesis vfix name bug r g cprecfixr r g cprecfixr r g cprecfixr r g cprecfixr vfixbm 0n an an an a30262077 genbm bearsbm ourbm total manuallytranslatedthegeneratedirtothesourcecodewiththe samesemantics andthencheckedthecorrectness.were evaluated the patches labeled by existing works with the same criteria above.
we found that of vfix generated patches labeled as correct by the authors are actually incorrect under the criteria i.e.
patches werenot semanticallyequivalent tothe developer sfix .
thus we labeled them as incorrect in our evaluation.
.
results table shows the evaluation results.
out of bugs npex generated and validated patches for bugs g and among them were correct leading to a fix rate of and a precision i.e.
howpreciselygeneratedpatchesturnedouttobecorrect of62 .ontheotherhand npexbase whichdoesnotuseourpatch validation but relies on a test suite resulted in a fix rate of and a precision of which shows that our patch validation is much more effective than conventional test based validation.
meanwhile genesis generated patches out of bugs and 20werecorrectamongthose leadingtoafixrateof22 anda precisionof38 .wecouldnotrungenesisonvfixbmbecause ithasnobuildsystemandtestingframeworkwhicharerequired to run genesis.
wecouldsuccessfullyrunvfixfor57benchmarksandvfixgenerated patches in total.
the number of correct patches out of were leading to a fix rate of and a precision of .
most of the correct patches produced by vfix were from vfixbm outof24 .
forother benchmarks genbm bearsbm ourbm vfixgenerated18patchesand4amongthemwerecorrect leadingtoafixrateof15 andaprecisionof22 whichare substantially lower than the fix rate of and the precision of for vfixbm.
this is because most of the correct patches in vfixbmaresimilarinthattheysimplyskipstatementsorblocks that contain npes for which the vfix s ranking heuristic works well.however otherbenchmarksetscontainnpebugsthatrequire more diverse fix strategies e.g.
returning a non default value or replacinganexisting expression .bycontrast npexconsistently shows good performance over the four benchmark sets.
scalability .the sizes of programs in our benchmarks range from 2k to 340kloc 75kloc on average .
excluding the build time by infer npex took .
seconds to fix a bug on average.
specifically ittook65secondsforfaultlocalization .8seconds for specification inference and .
seconds for validating patchcandidates on average.
note that the time cost for running tests 9we made these cases publicly available for verification.
a buggy program 1publiclist getjpaannotated class c ... 2finallist jpaannotated newarraylist 3while c !
object.class for field f c.getdeclaredfields npe jpaannotated.add ... c c.getsuperclass ... 9returnjpaannoated b developer s test case 1list members ...getjpaannotated testinterface.class ... 2assert.assertequals members.size figure a simplified code snippet containing an npe line from the project apache aries jpa s revision a frequent performance bottleneck in generate and validate ap proaches is zero for npex because it does not use test cases at all.runningtestcaseswasveryexpensiveforsomebenchmarks.
for example project commons pool 41f4e41 took minutes for asinglerunofthetestsuite whichmustberepeatedmanytimes during the repair process and hence caused timeout hour for genesis.
case study .we observed that test cases written by developersareoftenincompleteinpractice andvfixandgenesiseasily produce incorrect patches in such cases.
for example consider figure4 whichdescribesannpefoundinproject aries jpa10and thetestcasewrittenbythedeveloper.method getjpaannotated figure a collects all the declared fields of the input class objectcretrieving its super classes.
an npe occurs at line because c.getsuperclass at line may return nullin case the super class is an interface.in this case the developer wrote a singletest case theassertioninfigure4 b forthepurposeofpatchvalidation whichfirstexposesthenpeandthenchecksifthelengthof the returned list equals to .
this test case is incomplete as it only checkstheexecutionwheretheloopiteratesonlyonce whilethe fully expected behavior of the method is that it retrieves all the superclassesuntil c.getsuperclass returnsobject.class or null.
with this incomplete specification genesis and vfix generatedthefollowingpatchesthatpassthetestcasebutareincorrect authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa junhee lee seongjoon hong and hakjoo oh if c.getsuper... !
null while c !
... ... while c !
... if c null return new arraylist fix by genesis fix by vfix bycontrast npexgeneratedthefollowingpatchthatissemantically equivalent to the developer s fix which was possible because npexcanautomaticallyinfertheexpectedspecificationfromthe buggy code rather than relying on test cases.
while c !
... if c null break while c !
object.class c!
null fix by npex fix by developer limitationsofnpex .nextwediscusslimitationsof npexidentified from the evaluation.
first npex failed because of unsupported fix patterns.
in figure for example the developer fixed an npebychangingthetypeofalocalvariablefrom inttodouble.
thisisbecausethefaultofthisnpeisduetounsafetypeconversion from doubletoint.
because of this unsafe conversion the methoddistance returnsnanvalue whichcausestheconditionat line to produce false and therefore clusterisnullat line .
wealsoidentifiedalimitationofourspecificationinference.this happened when another fault exists in the buggy program other than the npe to be fixed.
for example the program in figure has an npe at line since iterable can benullnpex inferred the incorrectspecificationforthisprogram if iterable isnull then thrownullpointerexception whichwascomputedbyinterpretingthenpeexpression iterable.iterator asnullusingthe learned model and symbolically executing the constructor at line which is through this ... at line .
however there was another bug in the constructor at line .
on the other hand npex could infer a correct specification if illegalargumentexception were thrown at line .
validated patches .we observed that npex can successfully validatevariouspatchesbeyondsimpleternaryforms.interestingly all patches fixed and validated correctly by npex were in theformsofskiporinit.inotherwords npexrejectedallternary patcheseventhoughweusedternarynullhandlingcodeforspecifi cationmining.thesebugsrequire skiporinitpatchestofixnpes since simply replacingan npeexpression toa ternaryexpression introducedanewnpe.npexinferredcorrectspecificationwhichis semantically equivalent to skiporinitpatches e.g.
section .
.
falsely validated patches .we manually investigated table false positive cases i.e.
incorrect patches accepted by the patch validator during manual assesment of validated patches.
those cases were classified into the following cases cases inference of correct specification failed due to the existence of faults other than the target npe as decribed in limitations of npex .
cases correct specification is inferred but an incorrect patchisvalidatedduetotheimprecisionofstaticsymbolic execution.
cases the learnt null handling model returns wrong alternative expressions.1doubledistance int p1 int p2 ints u m doubles u m for inti i p1.length i sum ... returnmath.sqrt sum return nan 7voidassignpointstoclusters t point cluster cluster null if point.distance ... double.max value false cluster ... cluster.addpoint p npe figure5 annpebug line11 andthedeveloperpatch sim plified code snippet math in defects4j 1publiciteratorreader iterable string iterable if iterable null throw new illegalargumentexception ... this iterable.iterator npe 6publiciteratorreader iterator string iterator if iterator null throw new nullpointerexception throw new illegalargumentexception ... this.iterator iterator figure an npe bug line and the developer patch sim plified from opengrok 6a95adb whilethefirstcaseisthelimitationof npex weexpectthatthe other cases can be resolved.
the second case could be resolved by standard techniques to improve symbolic executionsuch as more advancedstatemergingheuristics.thethirdcasecouldberesolvedbyrefiningthenull handlingmodelwithmorefeaturesandtraining dataset.
related work we discuss prior work closely related to ours.
we focus on automated program repair apr approaches rather than techniques for detecting and mitigating npes e.g.
.
apr techniques are broadly classified into general purpose and special purposetechniques.special purposetechniquesareapplica bletoparticularkindsofbugs.forexample footpatch canfix heap relatedbugssuchasresourceleaks memoryleaks andnull dereferences.
saver memfix and leakfix are techniquesforfixingmemoryleaks use after frees anddouble freesincprograms.otherspecial purposetechniqueshavebeenproposed to fix common and important classes of bugs e.g.
concurrencybugs buffer integer overflows errorhandling bugs and performance bugs .
vfix and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
npex repairing java null pointer exceptions without tests icse may pittsburgh pa usa npefix are npe specific techniques.
npex is also specialized for fixing npes with its novel patch validation approach.
general purpose approaches areapplicabletoanykindsofbugs wheremost techniquesrelyontest cases tovalidatepatches.general purpose approaches are further classified into generate and validate andsemantics basedapproaches .
generate and validatetechniquesusesearchalgorithms e.g.
genetic programming to iteratively generate candidate patches fromapatchspaceuntilplausiblepatchesthatpassthegiventest suite are found.
semantics based approaches explore the search spaceimplicitlybygeneratingconstraintsoncorrectpatchesand usingsmtsolverstosynthesizesatisfyingpatches.althoughthese techniques are general they are less effective for fixing specific types of bugs such as npes as demonstrated by xu et al.
.
to mitigate overfitting existing apr techniques are often combined with patch prioritization .
for example capgen uses context information of code astnodes torankcorrectpatchesbeforemerelyplausibleones.
prophet learns a probabilistic model of correct code from a dataset of human written patches collected from open source software repositories and uses the model to rank candidate patches based on the probability of being correct.
vfix uses a heuristic that ranks npe patches by solving a graph congestion problem.
we believe these ranking techniques can be combined with our approach to better identify correct npe patches.
recently various data driven techniques have emerged to enhanceprogramrepair .npexliesinthislineof research whereweusedatatolearnanull handlingmodel.notable existing data driven techniques related to fixing npes are genesis and getafix.
genesis uses data a set of human patches for searchspaceinference.inparticular genesiscanfixnpesusing aspecializedsearchspacelearnedfromexistingdata.getafix aims to quickly generate human like fixes for bugs detected bystatic analyzers.
to do so getafix uses repair templates learned from past human patches and suggests the most appropriate fix for a given bug.
compared to npex getafix is more focused on the patchgenerationphasewhilerelyingonasimplerankingheuristictoselectcorrectpatches.asaresult onelimitationofgetafixisthat itcannotpreciselyinfertheexpectedbehaviorofbuggycode which is particularly important for repairing npes.
our patch validation technique could be used with getafix to better suggest npe fixes.
ourworkalsoliesinthelineofworkonidentifyingtest overfitted patches .t anetal .
proposedasetofcommon syntactic patterns for incorrect patches which can be used to prevent specific classes of patches that are likely to be incorrect.ods trains a statistical model to predict overfitted patches based on featuresthat describe syntacticcharacteristics of correct patches.fix2fit focusedonavoidingpatchesthatcausecrashes beyondthegiveninput bygeneratingnewtestinputsusingagreybox fuzzing technique.
xiong et al .
proposed a technique to validatepatchesbymeasuringsimilarityordissimilaritybetweena buggy program and a patched program for newly generated testinputs.comparedtothesework thegoalof npexisfocusedon npesandpresentsanewapproachbasedonlearningandsymbolic execution.
conclusion while npes are recurring and critical bugs in java applications automaticallyrepairingnpesstillremains asignificantchallenge.
themaindifficultyisinidentifyingcorrectfixesoutofawiderange of plausible patches that pass but overfitted to test cases a central open problem in automated program repair.
in this paper we presented a new approach to address this challenge.
instead of relying on test cases our approach infers the expected behavior of a buggy program by combining learning and symbolic execution and validates candidate patches against theinferred repair specification.
we implemented our approach in a tool npex andshowedthatnpexcanfixdiversereal worldnpes more effectively than state of the art test based techniques.
future work .although we focused on npes in this paper our approach couldbegeneralizedto otherfaults.note thatthe core ideaofnpexconsistsoftwogeneralcomponents learningof error handling model from codebases and validating patches using symbolic execution.
the second component symbolic execution is alreadyreusable forother typesoffaults onceappropriate error handling model is given.
instantiating the first component learning of error handling model for each different fault is less obvious and will be interesting future work.
a good starting point for generalization would be the class of faults whose alternative semantics can be easily captured fromerror handling code.
for example class cast exceptions cces yet another common runtime error in java are such a case.
in java projects developers handle cces in a way similar to npes i.e.
usingternaryexpressionswithtypecheckingguardandalternative expression.
in this case the idea of npex can be reused without significant changes.