does mutation testing improve testing practices?
goran petrovi c google switzerland gmbh z rich switzerland goranpetrovic google.commarko ivankovi c google switzerland gmbh z rich switzerland markoi google.comgordon fraser university of passau passau germany gordon.fraser uni passau.deren just university of washington seattle usa rjust cs.washington.edu abstract various proxy metrics for test quality have been defined in order to guide developers when writing tests.
code coverage is particularly well established in practice even though the question of how coverage relates to test quality is a matter of ongoing debate.
mutation testing offers a promising alternative artificial defects can identify holes in a test suite and thus provide concrete suggestions for additional tests.
despite the obvious advantages of mutation testing it is not yet well established in practice.
until recently mutation testing tools and techniques simply did not scale to complex systems.
although they now do scale a remaining obstacle is lack of evidence that writing tests for mutants actually improves test quality.
in this paper we aim to fill this gap by analyzing a large dataset of almost million mutants we investigate how these mutants influenced developers over time and how these mutants relate to real faults.
our analyses suggest that developers using mutation testing write more tests and actively improve their test suites with high quality tests such that fewer mutants remain.
by analyzing a dataset of past fixes of real high priority faults our analyses further provide evidence that mutants are indeed coupled with real faults.
in other words had mutation testing been used for the changes introducing the faults it would have reported a live mutant that could have prevented the bug.
index terms mutation testing code coverage fault coupling i. i ntroduction testing is an essential part of software development and software developers need guidance in how much testing they need to do and where to add more tests.
various proxy metrics for test suite quality have been defined over time with the aim to provide this guidance.
out of these code coverage is probably best established in practice executing code is a prerequisite for revealing faults code coverage can be easily visualized for example by highlighting covered lines in a different color than uncovered lines coverage is cheap to compute and it is well supported by commercial grade tools .
there are however downsides to coverage quantifying code quality based on code coverage alone leads to questionable estimates whose general utility and actionability are a matter of controversy in the research community .
coverageadequate test suites which satisfy all test goals are not the norm nor should they be.
in practice developers only satisfy a fraction of the test goals but adequate thresholds for code coverage ratios are inherently arbitrary and a matter of much debate .
code coverage is also easily fooled as it only determines whether code has been executed regardless of how well its behavior has been checked.
these downsides are overcome by mutation testing a test suite is evaluated on a set of systematicallygenerated artificial faults mutants .
any surviving mutant that is not detected by the test suite constitutes a concrete test goal pointing out possible ways to improve the test suite.
while the idea of mutation testing is appealing adoption in practice has long been hampered by scalability issues even simple programs may result in large numbers of mutants.
performing traditional mutation testing which evaluates all possible mutants for a large code base is impracticable.
for example at google tests are executed per day gate keeping code changes.
however as a result of decades of research on mutation testing it is now possible to apply mutation testing even at such scale .
while the computational challenges should no longer prevent adoption in practice there remains uncertainty about whether the expected benefits of showing mutants to developers manifest for a large system many mutants can be produced yet only few of these can be shown to developers.
do developers actually improve their test suites when shown these mutants and do tests written for these mutants have the potential to help prevent real faults?
in this paper we aim to shed light on these questions of central importance.
using a dataset of almost million mutants created in industrial software projects at google over a duration of six years we investigate the effects of showing these mutants as test goals to developers.
in particular we aim to answer the following research question rq1 effects on testing quantity .
how does continuous mutation testing affect how much test code developers produce?
our data shows that developers working on projects exposed to mutation testing over a longer period of time tend to write more tests for their code section iii c .
this raises an immediate follow up question are they writing good tests?
rq2 effects on testing quality .
how does continuous mutation testing affect the survivability of the mutants on a project?
our data shows that the tests that developers add when exposed to mutants are effective the more mutants they act on the fewer mutants survive for new changes over time as the effectiveness of their test suites improves section iii d the additional tests written improve the test suite s ability to detect mutants beyond the ones for which they were written.
naturally this leads to the next question are tests that are effective at detecting mutants also effective at detecting ieee acm 43rd international conference on software engineering icse .
ieee real faults?
mutants are worth writing test cases for only if they are coupled with real software faults i.e.
test suites that detect mutants would also detect real faults.
the third research question is centered around this issue rq3 fault coupling .
are reported mutants coupled with real software faults?
can tests written based on mutants improve test effectiveness for real software faults?
using a dataset of historical faults and fixes our data shows that had mutation testing been used for the fault introducing changes it would have reported a live mutant that is killed by tests in the fault fixing change section iv c .
it is thus likely that mutants had they been reported could have prevented the fault by guiding the developers to investigate the mutants and write tests for them.
finally one of the reasons that modern mutation testing systems scale is that they do not generate and analyze all possible mutants only a small sample.
in particular in our dataset developers were never shown more than one mutant per line of code.
this leads to the fourth research question rq4 mutant redundancy .
are the mutants generated for a given line redundant?
is it sufficient in practice to select a single mutant per line?
our data shows that most mutants share a majority fate section iv d .
if a single mutant is killed in a line most likely all mutants in that line will be killed.
conversely if a single mutant survives in a line most likely all mutants in that line will survive.
this backs the intuition and design choices behind google s mutation testing system in particular the practice of generating only a single mutant per line.
overall our results for the first time provide strong evidence that mutants are coupled with real faults that matter in practice and that showing mutants as test goals to developers leads to them writing more and better tests.
ii.
m utation testing at google traditionally mutation testing is performed by generating all viable mutants for a software under test and then running its test suite in an attempt to kill those mutants i.e.
to have at least one test that fails on the mutant code.
the output of this process is the mutation score i.e.
the ratio of killed mutants a higheris better measure.
considering the scale of software systems at google this traditional approach is computationally infeasible.
even if it were feasible the mutation score itself is difficult to act on by developers.
as a consequence mutation testing at google has evolved compared to the traditional approach .
google s mutation testing system currently supports programming languages c java go python typescript javascript dart sql common lisp and kotlin.
this section describes the main distinguishing features of the mutation testing system and we refer an interested reader to a full description of the system for further details .
the key difference at google is that mutation testing is integrated into the code review process developers send their code changes for code review in form of changelists .
a changelist is subject to various static and dynamic analyses thatproduce code findings which are reported to the developer and the reviewers assigned to that changelist.
an example analysis is line coverage which is reported at the level of the changed files as well as the actual code changes.
mutation testing is integrated as another such finding a selection of mutants within the changed code of a changelist which are not killed by the existing tests are shown as findings.
these live mutants thereby serve as concrete test goals which a developer can satisfy by adding tests.
to avoid cognitive overload no more than seven mutants are reported per file in a changelist.
reviewers can mark findings as particularly important by clicking on the corresponding please fix link and developers can provide feedback about findings that are not actionable using a not useful link.
developers can update the changelist based on findings and reviewer comments.
once the reviewers approve a changelist is submitted merged into the main source tree.
mutating only changed code is key to reducing the computational costs but further optimizations are necessary to make mutation testing feasible and actionable.
first mutants are only generated in lines that are covered by tests since lack of coverage is already reported by the coverage analysis.
second only one mutant is generated per line.
third in order to increase the chances of generating productive mutants suppression rules filter out code that cannot result in productive mutants e.g.
logging statements .
the developer feedback informs these heuristics for mutant productivity.
finally after applying the suppression rules an important and technically challenging aspect is the choice of mutation operator to generate a mutant for a given line.
our mutation system implements five mutation operators aor arithmetic operator replacement lcr logical connector replacement ror relational operator replacement uoi unary operator insertion and sbr statement block removal .
the mutation system selects a mutation operator for a given line based on historical information on whether mutants in similar context survived and whether developers thought they were productive.
if a mutation operator is not applicable to a line another one is chosen until one mutant in the line is generated.
many individual software projects are developed at google and each project can opt in to use the mutation testing system.
when mutation testing is enabled for a project each changelist in review for that project will be analyzed for mutants and live mutants will be reported to the changelist author and reviewers.
over time the same files may be mutated repeatedly whenever they are part of a changelist under review.
the mutation system does not offer manual invocations or project level analyses only the change based approach.
hence developers only observe live mutants that are reported during code review.
mutation testing has been deployed at google for more than six years and some projects have been rolled in since the beginning while many joined over time.
there have now been more than million mutants generated and hundreds of thousands of analyzed changelists providing a suitable dataset for analyzing the long term effects of mutation testing on the developers working on a project employing it.
911iii.
l ong term effects of mutation testing a core assumption of mutation testing is that mutants are actionable test goals and that reporting them has the desired effect on developers they augment their test suites and generally improve their testing practices over time.
we therefore wished to study whether developers exposed to mutants write more tests and whether these tests improve the test suite quality beyond simply covering additional code.
thus in this section we focus on the effects that mutants have on the tests developers write and aim to answer the first two research questions rq1 effects on testing quantity .
how does continuous mutation testing affect how much test code developers produce?
rq2 effects on testing quality .
how does continuous mutation testing affect the survivability of the mutants on a project?
to answer these research questions we performed a longitudinal study that fully integrates mutation based testing into the software development process.
our study employs a direct intervention to form a treatment group developers who act on mutants and uses a control group developers who use only code coverage .
a. datasets although we are interested in how mutation testing affects developers focusing on individual developers for analysis is difficult developers tend to multi task either working on a side project maintaining an older code base or still partially working on their previous engagement.
different codebases tend to differ greatly in their testing quality especially when comparing side projects older projects and new engagements.
thus instead of considering the behavior of individual developers we consider individual files of source code.
we created two datasets of files one dataset based on files subjected to mutation testing and as baseline one dataset based on files subjected to only code coverage analysis.
mutant dataset google has used mutation testing since .
at the time of this writing a total of mutants have been generated for code changes in files.
our mutant dataset contains all of them.
for each mutant the dataset contains information about the mutation operator the programming language of the mutated file the code location and the results of mutation testing i.e.
whether the mutant was killed and whether a reviewer requested a test for it .
coverage dataset as a baseline for comparison we randomly sampled code changes from projects that did not use mutation testing but had line coverage calculation enabled within the same period of time.
in total the sample resulted in code changes with files.
b. methodology rq1 we are interested in understanding the effects of mutants on tests written for the mutated code.
therefore for each file we need to quantify the amount of testing related to that file.
for each code change we identified the edited testfiles that correspond to that change using the build system.
however the raw number of edited lines of test code is not a reliable measure because of differing programming languages testing styles categories of tests and the specifics of testing and mocking frameworks.
for example in a table based testing approach a test case may only consist of a single line of code whereas an equivalent test case possibly including harness code can easily span tens or hundreds of lines.
therefore we quantify the amount of testing using the number of test hunks the changed code hunks in the edited test files.
hunks are groups of differing lines edited or added that intersperse sequences of lines in common.
in addition we measure the exposure for each file in a code change computing the number of times the file has been changed and had a code finding reported before the change under analysis.
code findings are reported mutants for the mutant dataset and code coverage results for the coverage dataset.
for example if a change edits a file for the 10th time but in the previous times mutants were reported only in instances the exposure would be for that change.
this measure captures the exposure of developers to mutants the more often mutants had been reported in a file the more exposure the authors and reviewers developing that file collectively had to mutation testing.
in order to answer rq1 we evaluate the number of test hunks for each file over the file s exposure.
if developers get accustomed to mutation testing and act on mutants to improve the test suite we expect the number of test hunks to be larger for mutation than for the baseline.
further we expect a positive relationship between exposure and number of test hunks.
since we do not expect that relationship to be linear and to show some saturation we rely on rank statistics.
specifically we quantify the effect size using spearman s rank correlation coefficient rs.
in addition we compute the number of test hunks for individual changelists considering two timestamps when code findings are initially reported to the developer during code review and when the changelist is approved and submitted.
if code findings are actionable we expect an increase in the number of test hunks after reporting the findings.
rq2 rq1 is concerned with testing quantity but not quality.
writing more tests does not necessarily improve the quality of a test suite.
for example tests written simply for the sake of increasing code coverage tend to be ineffective at detecting faults .
in particular if mutation testing generally improves test suite quality then we expect to observe several effects first reported mutants should be killed by additional tests while a changelist is in code review second over time the ratio of mutants generated for a new changelist that are already killed by the existing tests should increase third fewer mutants should see please fix requests by the reviewers.
as a proxy measurement of test quality we use mutant survivability i.e.
the probability of a generated mutant being killed.
the mutant survivability for a file in a code change is calculated as the ratio of surviving mutants to the total number of generated mutants for that file.
a lower mutant survivability indicates a higher test suite quality.
we compute the mutant 912fig.
test hunks changed per file as exposure to reported mutants vs. line coverage increases.
test hunksmutation coverage fig.
test hunks changed per changelist after initially reporting mutants vs. line coverage.
the median is for mutation and for coverage.
outliers outside of times the interquartile range are not shown for clarity.
survivability for each file in the mutant dataset over the exposure of the mutated file.
if the tests added due to mutation testing lead to an improvement of the test suite quality then we expect a negative correlation between exposure and survivability i.e.
the tests should become more effective at killing mutants over time even for mutants that are generated later for newly added or changed code.
if tests are strictly added to kill reported mutants we expect no correlation because survivability should remain fairly constant.
we further compare the number of live mutants first reported to the developer with the final number of live mutants when the changelist is submitted.
if mutants are actionable test goals we expect that the number of live mutants at submission time is lower than the number of originally reported mutants as a result of the additional tests added by the developer.
in the code review system reviewers can request developers to write tests for mutants they consider important.
if developers improve their test suites over time we would expect the ratio of such requests for all reported mutants to gradually decrease.
therefore we also compute the ratio of requested fixes for mutants over exposure.
c. rq1 effects on testing quantity figure shows the number of changed hunks of test code normalized by the number of files in the change over exposureto code findings.
this figure shows the estimated central tendency mean and corresponding confidence interval.
note that the confidence intervals get wider for higher levels of exposure for mutation because the number of files with such high levels in the mutant dataset decreases.
this means that accurately fitting a trend for higher levels of exposure and identifying saturation is challenging.
however there is a clear signal for the mutant dataset the number of test hunks is larger than that for coverage.
the larger the exposure the more test hunks are changed on average.
spearman s rank correlation between exposure and the average number of changed test hunks is rs p .
in contrast figure shows no signal for the coverage dataset.
in fact there is a weak negative correlation between exposure and the average number of changed test hunks rs p .
these results suggest that mutation testing has a positive long term effect on testing quantity.
figure shows the number of test hunks changed in the changelist between the initial state when a developer sends it for review and the final state when it passes the code review and is submitted .
the median number of changed test hunks for mutation is while for coverage it is .
the difference between mutation and coverage is statistically significant wilcoxon rank sum test p and remains significant when normalized for changelist size.
this suggests that mutants are actionable and guide developers in writing additional tests.
rq1 as exposure to mutation testing increases developers tend to write more tests.
alternative hypotheses while our study uses an interventional design and a substantial dataset it is not a fully randomized controlled experiment.
hence we account for possible confounding factors which might also explain the increase in testing quantity.
specifically we explored and rejected three alternative hypotheses.
dispersed coverage dataset the mutant dataset contains all changes that were subject to mutation testing whereas thecoverage dataset contains only a sample of changes that were subject to code coverage analysis.
as a result the coverage dataset may miss individual changes to individual files.
we downsampled the mutant dataset to make it as dispersed as the coverage one and repeated our analysis.
the results led to the same conclusions for rq1 there is a strong positive relationship rs p between exposure and testing quantity increasing our confidence that the trend for the mutant dataset is indeed linked to mutation testing and that the absence of that trend in the coverage dataset is not an artifact of random sampling.
changelist size coverage analysis can be done on virtually any code change while mutation testing has some preconditions.
in order for a mutant to be reported for a code change that change must contain covered source code and the covered source code must contain code elements for which mutants are not suppressed by the mutation system s suppression rules.
it is thus expected that on average the mutant dataset contains larger 913fig.
files changed as exposure to mutants increases.
fig.
files changed as exposure to line coverage increases.
changelists than the coverage dataset largely due to differences in the lower tails.
if additional test hunks were just the by product of larger changelists then we would expect normalizing for the changelist size to uncover this fact which it did not neither on a per file nor on a per changelist basis .
changes to individual files are part of code changes of varying sizes.
to ensure that any effects observed are not a result of differences in the number of changed files figure and figure show the number of files changed by a changelist that contains an exposed files as a function of exposure.
the plots suggest that the numbers of affected files is not positively correlated with exposure for the mutant dataset indeed the number of affected files tends to slightly decrease over time for both datasets rs 26for the mutant dataset and rs 34for thecoverage dataset .
overall the results show that it is very unlikely that the changelist size as a function of exposure confounds the observed effects.
tests for code coverage developers who received mutant information also received coverage information which could confound our results.
in order to determine whether developers wrote tests for the reported mutants or simply to increase code coverage for their changelists we live surfaced mutantsreview submitfig.
number of surfaced mutants that are live at the beginning of the code review review and at the end of the code review submit .
the median is for review and for submit.
outliers outside of 5times the interquartile range are not shown for clarity.
fig.
mutant survival rate as exposure to mutants increases.
analyzed the differences in code coverage for the changed code between the initial review state and the final submit state and correlated it with exposure.
the results show that code coverage is largely stable over time for the coverage dataset there is a negligible correlation with exposure rs p for the mutant dataset there is a weak negative correlation rs p .
this makes it unlikely that developers exposed to mutants wrote tests to increase code coverage.
rather they wrote tests to kill the reported mutants.
d. rq2 effects on testing quality figure shows the difference between the number of reported live mutants at the beginning of the code review review when code findings are initially surfaced and at end of the code review submit .
submitted changelists have significantly fewer live mutants which confirms that tests added by developers in response to mutants indeed succeed at killing these mutants.
if additional tests for a changed file improve overall test suite quality then future changes to the same file should see fewer surviving mutants.
figure shows the probability of a mutant to survive over time as files are mutated over and over again the more mutants a file sees the more likely it is that the already existing tests incl.
those written for the submitted 914fig.
fix requested rate as exposure to mutants increases.
change kill those mutants.
there is a negative relationship rs p between exposure and survivability of mutants.
these results suggest that developers not only write more tests when exposed to mutation testing the tests they write indeed improve test suite quality.
as a further indication that developers write good tests figure shows the ratio of reported mutants for which the reviewers request developers to write tests.
the results show that in the beginning reviewers ask for a larger ratio of the reported mutants to be killed than later rs p .
this corroborates that developers write better tests such that the surviving mutants represent less critical issues or futile test goals and reviewers have to request fewer changes related to reported mutants.
rq2 as exposure to mutation testing increases developers tend to write stronger tests in response to mutants.
alternative hypotheses while we observe that developers write tests that kill reported mutants it is theoretically possible that they write minimal tests that are simple and purely focused on killing mutants as opposed to tests they would write otherwise.
however two general observations and two analyses suggest that this is not the case.
first this is unlikely in principle code reviews are a safety net and minimal changedetector tests would not pass code review.
second anecdotally from manually inspecting numerous tests written for mutants over the past six years we did not observe any unique features of such tests.
third our analysis of mutant redundancy sectioniv d shows that most mutants generated for the same line are killed by the tests developers write.
since multiple mutants related to conditional or relational operators would require distinct tests to be killed e.g.
testing boundary conditions in a conditional statement this suggests that developers do not write minimal tests focused on a single mutant.
finally the increasing number of test hunks and the decreasing survivability section iii c support the conclusion that developers write more tests than would be necessary to detect individual reported mutants.
in summary we did not find evidence that developers write minimal tests for reported mutants.iv.
f ault coupling the coupling effect is a foundational assumption underlying mutation testing simple faults are coupled to more complex faults in such a way that a test suite that detects simple faults is sensitive enough to likely detect complex faults as well.
since mutants represent simpler faults compared to more complex real world faults it is important to assess whether and to what extent the coupling effect can be observed for mutation testing of real world software systems.
in particular mutants are only suitable test goals that are worth satisfying if they are coupled to real software faults.
recall that our mutation testing system only surfaces a single mutant per line because evaluating all mutants is prohibitively expensive and reporting all live mutants to a developer in an actionable way is impracticable.
however we also observed that developers get accustomed to mutation testing in two ways.
first they use and interpret mutants as concrete guides to improve their code and corresponding test suites as opposed to merely writing a minimal test per test goal mutant .
second they write stronger tests in response to or anticipation of mutants that are generated and surfaced.
we hypothesize that most mutants per line share the same fate and that it is thus sufficient to surface only one of them.
specifically we hypothesize that if a developer writes a test suite based on one surfaced mutant in a given line then that test suite will detect most of the mutants that could be generated for that line.
conversely if a surfaced mutant in a given line survives then most mutants that could be generated for that line will survive.
testing this hypothesis is important to determine whether the assumed coupling effect holds for mutation testing systems that rely on sampling representative mutants.
this section answers the remaining two research questions rq3 fault coupling .
are reported mutants coupled with real software faults?
can tests written based on mutants improve test effectiveness for real software faults?
rq4 mutant redundancy .
are the mutants generated for a given line redundant?
is it sufficient in practice to select a single mutant per line?
a. dataset in order to evaluate whether mutants are coupled to bugs that matter in practice we mined our source code repository and obtained a set of bugs that had a high priority for being fixed.
for each bug the subsequent coupling analysis evaluated mutation testing on the buggy and fixed source code version of that bug.
specifically we automated the following analysis find explicit bug fixing changes in the version control history section iv a1 .
analyze changes and retain suitable bugs section iv a .
generate mutants and perform mutation testing on both the buggy and the fixed version of the code section iv b .
analyze the mutation testing results and identify faultcoupled mutants section iv c .
change selection we mined our source code repository for changes that explicitly fix high priority bugs.
bugs are assigned a priority class by developers and high priority bugs are expected to be fixed quickly.
our selection approach did not filter for change size or other code related attributes.
this was a conscious design decision to obtain an unbiased sample spanning multiple programming languages projects code styles etc.
our selection step resulted in candidate bugs suitable for our coupling analysis.
we limited the selection to changes that fixed a bug in the last six months.
this temporal restriction increases the chances of being able to build the source code and reproduce a bug the underlying build infrastructure guarantees that recent source code can be built.
furthermore we limited the selection to changes authored by a developer and hence changes that are subject to code review.
the selection was not limited to changes for which mutation testing was not enabled.
precisely determining when a bug was introduced and whether mutation testing was enable for that project at that time is extremely difficult.
to approximate the ratio of bugs that were introduced while mutation testing could have been enabled we determined the ratio of bug fixing changes for which mutation testing was enabled.
overall mutation testing was enabled for .
of bug fixing changes in our final dataset.
we rely on developers change descriptions and labeling to identify bug fixes.
while bug hygiene is imperfect and not all of these bugs are necessarily bugs encountered in the field all of the change descriptions explicitly claimed to fix a highpriority bug making it very unlikely that the change in fact does not.
change filtering to establish the coupling between mutants and bug fixes we need to parse and build the code mutate it and evaluate affected tests against each mutant.
this means that the source code in question needs to be correctly configured buildable and the number of tests to be executed needs to be reasonable.
mutant generation is non trivial and carries a hidden cost.
for example our mutation system uses the clang compiler front end for the ast analysis and manipulation of c code.
this requires indexing the compilation unit with the build system to prepare the transitive closure of included headers and the set of clang arguments that are mandated by the project under mutation s configuration.
a common example is code that runs on specialized architecture or requires additional virtualization libraries which is unknowable given just the file and the file is not analyzable without it.
the additional cost of indexing all c compilation units is relatively small but still accounts for a large resource expenditure overall.
while the total number of generated mutants is comparatively low due to our mutant suppression and reduction strategies the sheer number of required test target executions renders this coupling analysis as very expensive.
a test target defines a set of tests at the build system level.
a test target can be a single test file or a test suite i.e.
collection of test files each potentially containing hundreds or thousands of individual tests.
this variance comes from how the build system is used test targets log fig.
number of test targets for all candidate bugs.
test targets100101102103104mutants log fig.
number of test targets and number of mutants for all retained bugs.
and differs from project to project.
in a large project with complex dependencies any change to a widely used core library will easily require millions of tests to be executed each of which has the said library in the transitive closure of its dependencies and all of which have to be evaluated.
failure to evaluate all test targets as is the norm inevitably leads to inaccuracies of reported live mutants and would decrease developers confidence in mutation testing.
given the challenges above and our candidate bugs we automatically filtered bugs for which a project configuration failure prevented us from building the buggy or fixed source code version rendering them unsuitable for our analysis.
bug fixes for which the project configuration exhibited a substantial dependency chain with a very large number of associated test targets.
including these bugs would have made our analysis computationally infeasible.
we empirically determined a threshold of test targets each usually containing many tests as our filter criterion.
figure shows the distribution of the number of test targets for all candidate bugs indicating that bugs with more than test targets are outliers.
our final dataset contains retained bugs .
table i shows further characteristics of these bugs and figure shows their distribution of number of test targets and number of mutants.
in total our coupling analysis involves bugs almost thousand mutants and over million test target executions.
we performed the coupling analysis over a prolonged period of time because of the huge amount of processing power required for the dependency analysis mutagenesis and test target executions.
916table i characteristics of the retained bugs.
bugs test targets affected files affected lines count ratio median mean median mean median mean c .
.
.
.
java .
.
.
.
python .
.
.
.
go .
.
.
.
total .
.
.
.
.
b. methodology incremental mutation testing is substantially different from the traditional approach.
lines are selectively mutated based on the structure of the code mutator operators are probabilistically picked and tried out and most potential mutants are discarded because reporting too many mutants during code review would be too visually daunting and likely have a negative effect on developers perception of mutation testing.
in order to evaluate whether the mutants our mutation system generates are coupled with the high priority bugs that we retained we had to modify the system to generate multiple mutants per line and to evaluate all of them.
this turned out to be very expensive even for a manageable number of bugs validating our intuition that the traditional approach would not scale to an environment with thousands of changes per day.
note that we kept the notion of suppressing unproductive mutants which represent futile test goals in the modified system and hence did neither generate nor evaluate them.
for each bug in our dataset we automatically executed the following steps run dependency analysis and determine all test targets affected by the bug fixing change.
using the buggy source code version generate all possible mutants for all lines that are affected by the bug fixing change.
using the fixed source code version generate all possible mutants for all lines that are affected by the bug fixing change.
determine the set of fault coupled mutants.
in line with prior work we measure fault coupling as follows given a test suite with at least one fault triggering test a buggy source code version and a fixed source code version a mutant is coupled to a fault through the triggering tests if that mutant exists in the buggy and the fixed source code version and that mutant is only detected by the triggering tests.
in other words a fault coupled mutant is live in the buggy but killed in the fixed source code version had mutation testing been run on the buggy source code version a mutant would have been reported in the lines affected by the fixing change and the test accompanying the fix kills it.
c. rq3 fault coupling this research question is concerned with whether mutation testing would have reported a live mutant on the change introducing the bug a live mutant that is subsequently killed by a bug triggering test.
reporting that mutant would have had c java python go all .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
number of coupled mutantsratio of bugsc java python go allfig.
number of mutants coupled to each of the bugs grouped by programming language of the bug fix.
of all bugs to coupled mutants are ommitted for clarity.
a good chance of preventing the bug being introduced in the first place.
coupled faults we found that for of the bugs mutation testing would have reported a fault coupled mutant in the bug introducing change.
recall that each bugintroducing change was covered by the existing tests suggesting that code coverage had exhausted its usefulness.
rq3 mutants are coupled with of high priority bugs for which mutation testing would have reported a live fault coupled mutant on the bug introducing change.
it is interesting to note that when a bug is coupled to a mutant it is usually coupled to more than one as seen in figure .
this observation is consistent with the finding that the majority of mutants generated for a given line share the same fate section iv d .
the statement block removal sbr mutation operator being the most prolific one generated most of the coupled mutants figure .
the distributions of number of coupled mutants are consistent across all languages figure .
in contrast the distribution of coupled mutants across mutation operators is different for go figure .
given the relatively small sample size of go bugs it is possible that this observation is an artifact of the sample size or that go bugs have indeed different coupling characteristics.
917c java python go sbr uoi lcr ror aor sbr uoi lcr ror aor sbr uoi lcr ror aor sbr uoi lcr ror aor0.
.
.
.
.
mutation operatorratio of coupled mutantssbr uoi lcr ror aorfig.
ratio of coupled mutants per mutation operator grouped by programming language of the bug fix.
non coupled faults recall that out of bugs were not coupled to any of the generated mutants.
we randomly sampled of the non coupled bugs for manual inspection.
for each bug we determined the reason for the absence of fault coupling following the classification of just et al.
weak mutation operator missing mutation operator no such mutation operator.
weak mutation operator while focusing our analysis on the weaknesses of the five mutation operators employed by our mutation system two patterns emerged.
first the sbr mutation operator currently does not mutate statements that affect control flow including return continue and break statements.
the reason is that mutating these statements is more likely to cause compilation issues or infinite loops.
given the occurrences of these statements in our bug data set however it seems worthwhile to strengthen the sbr mutation operator to mutate them employing additional heuristics or program analyses to avoid invalid mutants.
second the sbr mutation operator does not delete variable declarations because these mutants would not compile.
however a variable declaration with a complex initializer should be mutated e.g.
by replacing the initializer with a constant value.
missing mutation operator recall that our set of mutation operators and the corresponding suppression rules are intentionally chosen to make mutation testing scalable and the number of surfaced mutants manageable.
nonetheless we considered a broad set of mutation operators regardless of their costs to determine whether additional mutation operators would generate mutants that are coupled to the bugs in our data set.
we noticed that identifier based bugs are a nontrivial portion in our randomly selected set of non coupled bugs.
while prior work demonstrated that mutation operators that target identifiers have the potential to increase fault coupling the same work also showed that these mutation operators can easily quadruple the number of mutants.
we leave a deeper investigation into heuristics and program analyses to tame these mutation operators for future work.
no such mutation operator similar to the findings of just et al.
we observed a number of non coupled bugs for which no obvious mutation operator exists.
examples include very subtle yet valid changes to configurations orenvironments for which general purpose mutation operators are not applicable.
similarly bugs in higher level specifications or protocols are outside of the scope of mutation testing.
in other words mutation testing is effective in guiding testing to assess whether an algorithm is correctly implemented but not whether the correct algorithm is implemented.
discussion while we desire higher fault coupling to prevent more bugs we also have a competing incentive to show only productive mutants and not overwhelm the developers.
generating more mutants would almost certainly increase fault coupling but at what cost?
if more coupling means more mutants or worse more unproductive mutants then this is undesirable developers would likely abandon mutation testing because of too many false positives .
it is possible that fault coupling can be increased without increasing the ratio of unproductive mutants by adding additional suppression rules tailored to additional mutation operators.
fault coupling is a valid measure if tests written for mutants are similarly effective as those that are written for other objectives.
section iii provided evidence that this is indeed the case.
further we count on code authors to push back on introducing tests to kill unproductive mutants and we count on reviewers to push back on low quality tests specifically written to kill mutants.
anecdotally we often see both code authors and reviewers pushing back on a mutant because the kind of test that would kill it is considered low quality or even harmful.
over the past six years we have observed that code authors do not blindly use mutants as test goals.
rather they reason about their usefulness and report unproductive mutants so that we can improve suppression rules.
overall we have no reason to believe that tests written for the mutants are substantially different from other tests.
d. rq4 mutant redundancy our mutation testing system rests on the assumption that generating and evaluating multiple mutants in the same line is not necessary.
the primary reason for this is that we do not compute the mutation score but rather report mutants as test goals and direct developers attention to the mutated piece of code any one productive mutant is sufficient for the latter.
a secondary reason is the expectation that mutants for a given line are highly redundant.
we tested our hypothesis about mutant redundancy by analyzing the mutant data from our data set of retained bugs.
since we generated all possible mutants for that data set we can reason about redundancy.
specifically we looked at the testing outcomes of mutants in lines for which multiple mutants were generated.
we calculated the ratio of the majority event for each line that is the ratio of mutants in the majority group sharing the same fate live or killed .
this allows us to capture both cases when most mutants are killed and when most mutants are not the closer the majority fate is to the higher the redundancy.
the rationale for validating our hypothesis is twofold.
first the results can inform mutant sampling strategies.
second the results from our coupling analysis translate to our own mutation system only if the .
.
.
.
.
.
mutant majority fatenumber of linesfig.
mutant majority fate for all lines with multiple mutants.
majority fate is high on average that is if picking a single mutant per line is indeed sufficient.
figure shows the distribution of the mutant majority fate for all lines that have at least two mutants.
given that more than of all lines have a mutant majority fate of we conclude that the generated mutants are highly redundant and that generating and reporting at most a single mutant per line is a valid optimization.
rq4 mutants are heavily redundant.
in more than of cases either all mutants in a line are killed or none are.
v. t hreats tovalidity construct validity is concerned with the chosen proxy measures and whether these accurately measure the concepts of interest.
to address this concern we relied on proxy measures accepted in the literature where applicable.
given that there are no comparable studies on the long term effects of mutation testing we had to make two notable choices.
first we measure exposure to mutants as the number of times mutants are surfaced during code review on a per file basis.
we argue that this is a valid proxy for exposure because both authors and reviewers have exposure to mutants during the code review process and code review usually involves peer review of project members and hence this measure captures the exposure of a development team to mutation testing.
second we measure testing effort as the number of changed test hunks as opposed to the raw lines of code .
this was a concious choice because lines of code do not generalize across programming languages or testing paradigms.
finally we consistently employed baselines for comparisons and the results not only show a signal for mutation testing but also the absence of a signal for the coverage testing baseline.
internal validity is concerned with how well our study design isolates variables of interest and whether it accounts for possible confounding.
to address this concern we relied on an interventional study design and tested alternative hypotheses for all reported observations which our study suggests are linked to mutation testing thereby increasing confidence in our results.
for example when quantifying how exposure to mutants affects testing effort we considered possible confounding effects suchas number of affected files and an increase in code coverage.
our explorations of alternative hypotheses all led to the same conclusions.
it is however possible that we missed other confounding effects.
external validity is largely concerned with generalizability and how well the reported results translate to other development environments.
our study reports on data and observations from a single company.
however our study involves tens of thousands of developers and many different projects which we believe are representative of a larger population.
furthermore contemporary code review is ubiquitous and used by software engineers at other companies and in open source projects.
vi.
r elated work while mutation testing has seen growing interest in research and practice reports of actual deployments and studies of its efficacy and long term effects are very rare in the literature.
indeed we are not aware of any studies that investigate the long term effects of mutation testing on test quality test quantity and developer behavior.
this section describes the prior work most closely related to ours focusing on industrial case studies studies that compare the characteristics of mutants and real faults and existing empirical evidence that suggests that mutation testing is likely effective in practice.
industrial case studies ahmed et al.
reported on a case study performing mutation analysis with mutants for a linux kernel module with subsequent analysis of surviving mutants .
the study aimed at reducing the computational costs of performing mutation analysis on complex software systems and it concluded that mutation testing can and should be more extensively used in practice .
delgado p rez et al.
reported on a case study performing mutation analysis with mutants for functions ranging from to lines of code of different firmware modules with subsequent manual analysis of surviving mutants.
this study focused on the computational costs and human effort for identifying equivalent mutants and developing a mutationadequate test suite by extending a coverage adequate one.
the study concluded that mutation testing can potentially improve fault detection compared to structural coverage guided testing .
in prior work we reported on the scalable mutation testing system deployed at google as well as on challenges associated with applying mutation testing in practice .
in this prior work we addressed the computational costs of applying mutation testing at scale with a key focus on the identification and elimination of unproductive mutants mutants that developers consider non actionable test goals similar to false positive warnings in static analysis .
in other words we identified mutants that can but should not and in practice will not be detected to avoid ineffective tests that negatively affect testing time and maintainability.
in contrast to the three industrial case studies above our work differs in two ways.
first it reports on a longitudinal interventional study that spans six years of development and involves more than million mutants reporting on the effects of mutation testing on test quantity and quality.
second it reports 919on whether critical real faults are coupled to mutants whether mutation testing has the potential to prevent those faults.
very recently an industrial application of mutation testing at facebook applied complex mutation operators learned from past bug inducing changes.
these operators achieve higher survival rates at the cost of being applicable to smaller parts of the codebase.
these learned mutation operators could offer an alternative approach to taming the number of mutants.
similar to our mutation testing system facebook s system provides information to developers during code review.
fault coupling and fault characteristics a number of empirical studies showed that mutants are coupled to real faults and that mutant detection is positively correlated with real fault detection .
the same studies also showed limitations and that about of real faults were not coupled with commonly generated mutants.
brown et al.
and allamanis et al.
aimed at narrowing this gap with their work on wild caught mutants and tailored mutants respectively.
both approaches employ semantics related mutations e.g.
replacing identifiers with similar type compatible alternatives and have the potential to further improve fault coupling.
however the improved fault coupling comes at a cost of significantly more mutants.
for example replacing function calls with all type compatible alternatives more than quadrupled the number of mutants.
gopinath et al.
analyzed the relationship between mutants and real faults from a different viewpoint.
specifically they compared the complexity and distributions of mutants and real faults .
their analyses showed that a typical real fault is more complex in terms of syntactical tokens and that real faults are rarely equivalent to mutants generated by traditional mutation operators.
the observed positive correlations between mutant detection and real fault detection on the one hand and the different characteristics of mutants and real faults on the other hand motivated in part our work on studying the long term effects of mutation testing and its efficacy in practice.
mutant characteristics other researchers have addressed the notion that some mutants are more valuable than others including stubborn mutants yao et al.
difficult to kill mutants namin et al.
dominator mutants kurtz et al.
and ammann et al.
and surface mutants gopinath et al.
.
while these definitions are useful in a research context e.g.
to study redundancy among mutants they are not directly relevant to a developer in practice.
for example a difficult to kill mutant may still be unproductive and hence writing a test for it would be undesirable.
mutant sampling prior work examined whether guided mutant sampling is more effective than random mutant sampling for similar numbers of mutants.
acree and budd independently concluded that a test suite developed to detect a randomly selected of mutants is almost as effective as a test suite that detects all of the mutants.
wong and mathur reached similar conclusions finding that randomly sampling mutants beyond yields marginal improvements.
zhang et al.
compared guided mutant sampling and random mutantsampling and also found no appreciable difference in their performance.
gopinath et al.
expanded this investigation using a large body of open source software again finding that random mutant sampling performs as well as any of the considered guided mutant sampling strategies.
in line with prior results our mutation approach samples very few mutants to make mutation testing applicable at scale.
our results confirm that the set of mutants generated with traditional mutation operators is indeed highly redundant and that small sampling ratios are sufficient.
moreover our results show that multiple mutants generated for the same line of code virtually always share the same fate in practice implying that surfacing one mutant per line is sufficient.
this observation is consistent with zhu et al.
s work that also supports the selection of representative mutants.
vii.
c onclusions the idea of mutation testing was introduced more than four decades ago and in all this time research revolved mainly around problems of scalability.
all along research was based on the fundamental assumption that mutants are meaningful and actionable test goals which lead to positive effects.
this assumption however has not been evaluated until now.
we have implemented and deployed a mutation testing system capable of scaling to very large software.
developers are shown only a fraction of the possible mutants by limiting the number of mutants and suppressing mutants assumed to be unproductive test goals.
this paper uses long running production data of this system in order to validate the central assumption underlying mutation testing for the very first time.
our results show that developers working on projects with mutation testing write more tests on average over longer periods of time compared to projects that only consider code coverage.
mutants are effective test goals developers exposed to mutants write more effective tests in response to them.
since the ultimate goal is not just to write tests for mutants but to prevent real bugs we investigated a dataset of highpriority bugs and analyzed mutants before and after the fix with an experimental rig of our mutation testing system.
in of cases a bug is coupled with a mutant that had it been reported during code review could have prevented the introduction of that bug.
finally we also validated our approach of generating a single mutant per line for the vast majority of lines either all mutants in a line are killed or all survive.
therefore generating a single mutant per line is a valid optimization.
this paper finally provides evidence that mutants are indeed meaningful and actionable test goals.
considering that this insight emerges at a time where robust industrystrength mutation tools appear for more and more programming languages we hope that mutation testing will see a substantial boost in industrial adoption leading to better software quality.