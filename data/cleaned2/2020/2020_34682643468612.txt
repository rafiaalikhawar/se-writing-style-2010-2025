exposing numerical bugs in deep learning via gradient back propagation ming yan college of intelligence and computing tianjin university china yanming tju.edu.cnjunjie chen college of intelligence and computing tianjin university china junjiechen tju.edu.cnxiangyu zhang purdue university usa xyzhang cs.purdue.edu lin tan purdue university usa lintan purdue.edugan wang college of intelligence and computing tianjin university china acmer.wg gmail.comzan wang college of intelligence and computing tianjin university china wangzan tju.edu.cn abstract numerical computation is dominant in deep learning dl programs.
consequently numerical bugs are one of the most prominent kinds of defects in dl programs.
numerical bugs can lead to exceptional values such as nan not a number and inf in nite which can be propagated and eventually cause crashes or invalid outputs.
they occur when special inputs cause invalid parameter values at internal mathematical operations such as log .
in this paper we propose the rst dynamic technique called grist which automatically generates a small input that can expose numerical bugs in dl programs.
grist piggy backs on the built in gradient computation functionalities of dl infrastructures.
our evaluation on realworld dl programs shows that grist detects bugs including unknown bugs.
by submitting them to the corresponding issue repositories eight bugs have been con rmed and three bugs have been xed.
moreover grist can save .79x execution time to expose numerical bugs compared to running original programs with its provided inputs.
compared to the state of the art technique debar which is a static technique debar produces false positives and misses true bugs of which bugs can be found by grist while grist only misses one known bug in those programs and no false positive.
the results demonstrate the e ectiveness of grist.
ccs concepts software and its engineering !software testing and debugging computing methodologies !machine learning .
junjie chen is the corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior speci c permission and or a fee.
request permissions from permissions acm.org.
esec fse august athens greece association for computing machinery.
acm isbn ... .
deep learning testing numerical bug gradient back propagation search based software testing acm reference format ming yan junjie chen xiangyu zhang lin tan gan wang and zan wang.
.
exposing numerical bugs in deep learning via gradient backpropagation.
in proceedings of the 29th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa 12pages.
introduction in recent years dl systems have become one of the most popular kinds of software systems and are widely used in various domains e.g.
face recognition autonomous driving and software engineering .
a dl system consists of three levels as shown in figure including the production level i.e.
dl models program level i.e.
dl programs that are used for building dl models and infrastructure level e.g.
dl libraries .
bugs in any level could a ect the overall quality of the dl system.
therefore it is necessary to guarantee the quality of dl systems at all the three levels.
currently a great deal of research has been conducted on the production level by proposing various adversarial input generation methods or designing various testing metrics but there is relatively little attention on the other two levels.
actually both the program level and the infrastructure level are the basis of the production level since dl models are built based on dl programs by invoking dl libraries and thus bugs in the former two levels could directly a ect the performance of dl models .
therefore it is critical to guarantee the quality at these two levels.
in this paper we target the program level.
di erent from traditional programs the life cycle of a dl program consists of not only the traditional coding phase but also the expensive training phase in which a large corpus of data is used to train the dl model parameters and the validation phase which is analogous to the testing and debugging phase in traditional software development and aims to provide feedback to change training inputs or hyper parameters to achieve better accuracy.
their erroneous behaviors may have consequences in both the cyber space esec fse august athens greece ming yan junjie chen xiangyu zhang lin tan gan wang and zan wang tlxgyzx iz xk 2k kr 6xumxgs 2k kr 6xuj izout 2k kr ujotm xgototm grojgzout vxumxgsy sujkry figure the architecture of dl systems and the physical space some even life threatening depending on the application scenarios.
therefore detecting bugs in dl programs is indeed critical.
following the existing work our work also focuses on numerical bugs in dl programs since they are one of the most prominent categories of dl program bugs due to the very heavy presence of numerical computation in dl programs.
moreover numerical bugs could occur at various stages of dl programs including the data preprocessing stage training stage and validation stage.
numerical bugs in dl programs manifest themselves in the form of nan meaning that the value is not a number inf meaning that the value is an in nite number or crash during the process of training or validation .
they are typically caused by mathematical property violations or oating point representation errors.
once a numerical bug is triggered in computation it will continue to propagate and eventually lead to invalid outputs.
figure 2ashows an example bug in a tensorflow program in which nan appears in the return value of a function normalize frames at line when the divisor np.std v is zero.
this bug was not discovered until the program was released.
figure 2balso shows another numerical bug that is not easy to expose in a pytorch program .
speci cally a pytorch user reported that she he encountered nan when training the dl model even though she he had specially added a small value self.eps to the denominator at line to avoid division by zero.
however nan was still thrown out after running for a period of time.
later it was found that the program tried to access the derivative of sigma.sqrt when sigma was zero.
since sqrt x has no derivative when x an nan is produced.
although numerical bugs are prevalent in dl programs many are very di cult to nd reproduce and x. unlike traditional programs dl programs require lengthy training maybe on the scale of days or even months with a large scale of data in order to achieve good accuracy.
the process is dominated by numerical computation.
that is numerical bugs may not be triggered until several hours days or even weeks into the training process.
these bugs hence may cost developers a high price since the expensive training may have to be redone.
furthermore these bugs may be non deterministic which means that they may or may not manifest themselves during a particular training step.
this is because random values are heavily used in dl programs e.g.
in initialization ghi qrupdol hbiudphv p uhwxuq y qs phdq y qs vwg y iru y lq p ghi iruzdug vhoi h wudqvsrvh frqwljxrxv ylhz px phdq nhhsglp 7uxh vljpd ydu nhhsglp 7uxh px vljpd vtuw vhoi hsv vhoi zhljkw vhoi eldv ylhz wudqvsrvh uhwxuq 7hqvru orz dpsoh 7rufk dpsoh a tensorflow program bug example from github ghi qrupdol hbiudphv p uhwxuq y qs phdq y qs vwg y iru y lq p ghi iruzdug vhoi h wudqvsrvh frqwljxrxv ylhz px phdq nhhsglp 7uxh vljpd ydu nhhsglp 7uxh px vljpd vtuw vhoi hsv vhoi zhljkw vhoi eldv ylhz wudqvsrvh uhwxuq 7hqvru orz dpsoh 7rufk dpsoh b pytorch program bug example from pytorch forums figure examples of numerical bugs in dl programs regularization and optimization.
as such these bugs may be di cult to reproduce even though reproduction is the necessary rst step for understanding the root cause and xing it.
therefore it is very meaningful to expose numerical bugs con rm them through deterministic reproduction with failure inducing inputs and reduce such inputs to minimize debugging e orts.
recently zhang et al.
proposed the rst static technique called debar to detect numerical bugs in tensorflow programs.
speci cally debar incorporates abstract interpretation to statically analyze whether the value of a variable can violate its valid range in mathematical calculation.
although it has been demonstrated to be e ective to some degree debar su ers from false positives like many static techniques in other domains .
also like all other static techniques debar requires manually creating models for third party libraries that are in other languages or do not have source code.
besides debar relies on the static computation graph of a dl program and thus cannot be applicable to dl programs with dynamic computation graphs such as pytorch programs which account for a large portion of dl programs in practice.
to further guarantee the quality of dl programs we propose the rst dynamic technique called grist gradientsearch based numerical bug triggering to expose numerical bugs.
grist gets rid of false positives does not require modeling third party libraries and can be applied to both dl programs with static computation graphs and those with dynamic computation graphs.
in particular grist not only points out where a numerical bug is but also provides a small concrete input that can deterministically trigger the bug within short execution time.
speci cally we observe that if a numerical bug is not deterministic meaning that it may or may not be triggered depending on the input and the particular run it must be directly or transitively related to some external values which could be training input samples or values generated by random functions e.g.
random initial weights .
these external values induce invalid operands at numerical operations such as division or invalid parameters to mathematical functions such as log causing nan inf.
while the data ow from external inputs to the failure points may be highly complex e.g.
through many layers of matrix multiplications relus and max pooling the underlying infrastructures such as tensorflow and pytorch have a powerful mechanism to compute the gradients of arbitrary operands and function parameters regarding external 628exposing numerical bugs in deep learning via gradient back propagation esec fse august athens greece inputs.
as such we do not need to derive the explicit symbolic form of data ow like in .
instead we leverage the gradients through back propagation to understand how we should change the external values to induce an exception.
to realize the idea we overcome a number of practical challenges.
for example a dl program by default only computes gradients between a loss function and the model weight values during training or between a loss function and the input during adversarial sample generation .
in contrast we need to compute gradients between an arbitrary external value and a parameter of some internal mathematical operation in grist.
furthermore dl program training is di erent from normal software execution.
it takes in a large corpus of inputs through multiple iterations in a random fashion.
we need to have a way to supply the mutated inputs generated by back propagation to the training process so that grist can induce the failure.
we conducted an experimental study to evaluate the e ectiveness of grist in exposing numerical bugs and accelerating failure triggering based on real world dl programs that are collected from github according to the descending order of github search relevance with operations vulnerable to numerical bugs e.g.
log and existing studies .
our results show that grist detects bugs within the given time limit i.e.
minutes among which are unknown bugs i.e.
the latest commit for the corresponding dl program still contains the bug .
it only misses one known bug in those programs.
through submitting them to the corresponding github issue repositories eight bugs have been con rmed and three bugs have been xed by developers.
also grist can save .79x execution time to expose numerical bugs compared to running the original programs with their provided inputs and expose bugs in a much more stable fashion bugs can always be triggered by grist in all repeated runs while only bugs can always be triggered by running the original programs with their provided inputs in all repeated runs .
compared to the state of the art technique debar which is a static technique on the same set of dl programs debar produces false positives and misses true bugs of which bugs can be found by grist while grist only misses one bug and has no false positive.
the results demonstrate the superiority of grist.
in summary the contributions of this work are as follows we propose grist the rst dynamic technique to expose numerical bugs in dl programs based on gradient backpropagation.
we conduct an experimental study based on real world dl programs.
grist nds bugs from these programs and misses only one known bug.
it outperforms a simple strategy of running these programs with their provided inputs and hoping to trigger numerical exceptions and a state of theart static technique debar.
we release our tool and dataset containing real world numerical bugs in dl programs which can be found at .
usv zgzout xgvn kxo gzo k usv zgzout usv zgzout xgvn kxo gzo k usv zgzoutfigure computation graph and derivatives computation for5 g1 g2 g1g2 b8 g1 using automatic di erentiation background and challenges .
gradient computation in deep learning via automatic di erentiation automatic di erentiation ad is a technique that can compute the derivative of a runtime value during program execution over a given input variable denoting the level of sensitivity of the value to the variable.
assume the runtime value is a function g of the input variable g. mathematically the derivative is de ned as follows.
g lim n!
g n g n directly computing derivatives based on the above formula is di cult for a program which is discrete by nature.
ad decomposes the function into a sequence of elementary arithmetic operations such as b and b8 which can be automatically done by tracking the runtime data ow of individual statements in the program.
by repeatedly applying the chain rule of derivative computation to these operations the derivative of the whole function can be automatically calculated.
figure 3shows a simple computation graph for a function g1 g2 g1g2 b8 g1 and the corresponding derivative computationm5 g1 g2 mg1.
observe that ad decomposes the function into simple operations and computes the derivative in a forward fashion following the data ow direction of the computation graph .
dl frameworks such as tensorflow and pytorch have built in ad support which is used to compute gradients.
please note that in ad we need to inform about the variable s over which the derivatives are computed.
in dl if we need to compute gradients derivatives regarding a variable we need to set the property require grad true for that variable to make it to be trainable .
as such the framework automatically computes the gradients for each value encountered at runtime over the trainable variables.
while in dl training model weight values are by default set to trainable and the runtime value for which gradients are queried is the cross entropy loss value the mechanism is general meaning that we can declare any variable to trainable and query the gradient of any runtime value regarding a trainable variable.
.
challenges due to the characteristics of dl programs exposing numerical bugs in dl programs faces the following main challenges 629esec fse august athens greece ming yan junjie chen xiangyu zhang lin tan gan wang and zan wangl1 tf.nn.softplus tf.add tf.matmul z w1 b1 l2 tf.nn.softplus tf.add tf.matmul l1 w2 b2 x reconstr mean tf.nn.sigmoid tf.add tf.matmul l2 w3 b3 reconstr loss tf.reduce sum x tf.log x reconstr mean 1e x tf.log 1e x reconstr mean 671112figure example of failing to avoid the numerical bug by adding a perturbation id 35a in table non determinism the computation in dl programs has substantial non determinism due to the natural randomness in training inputs the heavy use of random numbers and computation environment uncertainty.
the natural variations in training data are inevitable.
depending on the training inputs a numerical bug may or may not manifest itself.
random values are heavily used in the numerical computation of dl programs such as initialization regularization and optimization leading to substantial non determinism.
while dl program developers may reduce randomness by xing random seeds this may lead to degradation of model accuracy and robustness.
in fact a popular way to improve robustness is to introduce more randomness during training .
in addition the exposure of numerical bugs may also be a ected by runtime environment such as gpu .
due to the inherent non determinism numerical bugs may not be exposed before release which could amplify the damage.
on one hand other users may adopt the buggy dl program to build dl models based on their own training data and then the numerical bugs may manifest themselves.
on the other hand the numerical bugs that manifest in real system usage tend to be more devastating since it could cause unexpected system behaviors even crash the system.
moreover due to non determinism it is challenging to reproduce numerical bugs which could largely aggravate debugging di culty.
in fact we have found in many tensorflow github issues and pytorch forum posts developers complained that they cannot reproduce the numerical bugs reported by users.
lengthy training dl programs typically require lengthy training which is dominated by numerical computation with a large amount of data in order to achieve high model accuracy.
the typical training time of dl programs ranges from a few minutes to several days.
as such a numerical bug may only manifest itself after hours or even days into the training process.
since it is often necessary to repeat the training process of a dl program several times during the process of identifying the root cause of a numerical bug and validating x es debugging may be prohibitively expensive and quick failure induction is critical.
complexity due to the heavy and complex numerical computation in dl programs numerical exceptions may have lengthy and subtle failure inducing chains making diagnosis di cult.
speci cally numerical bugs are di cult to nd during code review since they are often caused by complex component interactions .
even though simple checks perturbations can be added to operations with the goal of avoiding numerical bugs e.g.
adding a small value nto a non negative variable gin g operations to avoid exceptions they may change program semantics and degrade readability.
in many cases such checks are redundant in a xgjoktz giq vxuvgmgzout vjgzk tv z h giq vxuvumgzout9zgzoi tgr yoy 4uxsgr xgototm gzin gor xk nkiqkx xo kx 6xumxgs m 8kvuxz 3gxq gxoghrk xgotghrk jktzol rtkxghrk 5vkxgzout figure overview of grist broader view because the preconditions may already preclude the invalid values.
even worse these safety checks and perturbations may be implemented incorrectly.
for example as shown in figure 1e is added to the parameters in the 6operations in order to avoid the occurrences of which is a common trick by dl developers.
however in this case due to the speci c oating point precision of the host machine 1derived from oating point computation is represented as a number that is larger than 1e but smaller than 1e .
thus when x reconstr mean holds the representation of value 1e x reconstr mean yields a value smaller than zero in the second operation leading to an nan.
another pytorch example is shown in figure 2bpresented in section .
although a small value self.eps has been added to the denominator at line a numerical bug still occurs since the derivative of sigma.sqrt is accessed when sigma is zero and sqrt has no derivative at zero.
approach .
overview to e ciently and e ectively expose numerical bugs in dl programs we develop an automated technique called grist.
it aims to help dlprogram developers or users to generate failure inducing inputs which include training samples and external values e.g.
those produced by random number generators .
bugs triggered by random values are as important as those triggered by training samples since if there exist certain random values that could trigger numerical bugs e.g.
nan or inf even though such bugs may not manifest themselves most of the time they are latent and could be triggered some time in the future.
in particular a numerical bug manifested after system release is even more devastating since it could cause unexpected behaviors during real system usage .
as shown in figure our technique grist consists of three main components static analysis component gradient backpropagation component and driver .
given a dl program the static analysis component analyzes the program to identify the operations that are susceptible to numerical exceptions such as log x 630exposing numerical bugs in deep learning via gradient back propagation esec fse august athens greece operation that is not guarded by a range check note that an operation without such check may not be a real bug indicating that identifying this condition alone is not accurate enough for bug nding and the external values.
as such we mark the variables denoting external values as trainable such that tensorflow and pytorch will track gradients of these variables at runtime.
a loss function called suspect loss is then constructed for each vulnerable operation.
intuitively the loss function describes the distance from the current variable value to an invalid value that can expose a speci c numerical bug.
minimizing the loss function by changing the external values through gradient back propagation is essential to push the value at the suspect operation to become invalid.
the gradient back propagation component updates external values based on two strategies.
please note that in the remainder of the paper we use the terms external values andinputs interchangeably.
the rst one is for iterative inputs which are inputs that impact program states through multiple iterations.
training samples and random weight perturbations are iterative inputs as they a ect the model execution states cumulatively through many steps.
in particular for each suspect operation grist identi es all the external values whose gradients with respect to the suspect loss of the operation are non zero suggesting that these values have data ow reaching the suspect.
grist updates their values along the opposite direction of the gradient sign with a constant delta.
intuitively this is similar to how inputs are mutated in adversarial sample generation .
the di erence lies in that adversarial sample generation updates a single sample input based on a cross entropy loss or a logits loss of the output while grist updates any external values that are related to some internal operation susceptible to numerical bugs.
the second kind of inputs is non iterative meaning that they contribute to the program state once when they are loaded .
random initializations that do not happen iteratively belong to this category.
for these inputs grist does not update them iteratively.
instead grist approximates the relation between the suspect operation and an external value with a linear function that can be derived from the gradient and then directly infers a new value that can induce an invalid value at the suspect operation.
intuitively since the complexity of the correlation between the external value and the suspect operation is not growing with the iteration number there is a good chance we can approximate it with a relatively simple function and directly derive the failure inducing value achieving cost e ectiveness.
the two kinds of inputs are distinguished by their loading places.
the driver component is responsible to update the training batch and or restart the execution if needed so that the external value changes made by the gradient back propagation component can take e ect.
intuitively at the end of each training iteration it updates the training batch by replacing only a small number of samples that are not important for inducing bugs at the suspect operation with new samples.
in other words it retains those that are important and hence must have gone through non trivial changes by gradient back propagation .
fresh samples are needed to prevent the failure inducing input generation process from being trapped in some local optima that cannot trigger the numerical bug .
if a numerical bug can be triggered within a time limit the buggy operation and the corresponding failure inducing external value s table vulnerable operations operation valid range error type division g g invalid valueexp g g expm1 g g log1p g g log g g sqrt g g lgamma g g .
.
.
sqrt g g 0invalid derivativeacos g g are reported.
in the following we will explain the details of each individual component.
.
static analysis to identify vulnerable operations and external values intuitively the essence of grist is no di erent from that of the large body of existing software testing techniques which is to identify and model causality between some inputs and a possible failure program point and then derive the input values that can trigger the failure.
while existing techniques leverage static dynamic and or symbolic analysis to derive such causality grist piggy backs on the underlying gradient computation mechanism of dl development infrastructures.
as mentioned in section .
when a variable is declared trainable the underlying infrastructure will compute its gradient for any runtime value denoting how sensitive the runtime value is to the variable s value change.
if there are multiple trainable variables a matrix of gradients is computed for any runtime value regarding all these variables.
if there is no data ow between a runtime value and a trainable variable the corresponding gradient must be .
as such the static analysis essentially identi es all the possible starting points i.e.
external values and all the possible end points of causality i.e.
operations vulnerable to numerical bugs .
grist then marks the starting points as trainable and observes at an end point if any of the trainable variables have non zero gradient at this point.
if so grist will use gradient back propagation to change the variable s trying to induce failure.
examples can be found later in the section.
vulnerable operations.
following the existing work we consider a list of vulnerable operations shown in table 1in our work.
this is because as investigated by the existing work these operations are the most frequent and have a high possibility to cause numerical bugs.
for example exp may cause nan or inf when its input is greater than because of over ow.
please note that some operations may implicitly trigger numerical bugs and their invalid ranges are not very obvious.
that is there are several operations that trigger numerical bugs due to unde ned derivatives as shown in table .
for example although and are valid for acos numerical bugs still happen when the dl program tries to obtain the derivative of acos at or .
grist identi es all 631esec fse august athens greece ming yan junjie chen xiangyu zhang lin tan gan wang and zan wang the occurrences of these operations in the dl program that do not have explicit range checks as those shown in table .
de ning suspect loss.
for a vulnerable operation g grist constructs its suspect loss automatically according to its valid ranges.
in the simplest scenario let g have a valid input range g grist constructs its suspect loss g8 .
here 8denotes the external input and hence the loss is a function of the input and g8 denotes that the operand parameter gat operation is a function of8.
as such any update to the external value 8that reduces is heading towards inducing a failure at the operation.
for g with multiple valid ranges denoted as d1 d2 ... d without losing generality grist constructs a loss function for each of the boundary values as follows.
c g8 c 5dc dc g8 with c2 at runtime let g82 c dc grist uses c ifg8 c dc g8 5dc otherwise.
take lgamma as an example the logarithm of the absolute value of gamma function .
in the implementation of tensorflow and pytorch its valid range is that g with .
.
.
.
assume g8belongs to and g8 g8 we use g8 .
currently grist considers one vulnerable operation at a time.
in other words it uses the suspect loss function for one operation in input mutation.
since the average number of vulnerable operations in a program is usually not large our design is reasonable.
considering multiple vulnerable operations at the same time entails using multiple suspect loss functions whose optimization directions may be contradictory rendering ine ectiveness.
external values.
we currently consider the following two kinds of external values training inputs andvalues generated by random number generators .
grist marks them as trainable in order to compute gradients.
for training inputs similar to adversarial sample generation grist marks the input vectors after being loaded from the input le and preprocessed as trainable.
for random values grist marks the variables that hold the return values of random number generators as trainable.
example.
figure 6apresents a simpli ed buggy code snippet from a github dl program for mnist .
the training loop is in lines in which a cross entropy loss is computed.
lines specify the input and output vectors.
line denotes the computation of a hidden layer followed by max pooling at line .
softmax is applied at line and cross entropy is computed at line .
our static analysis identi es that the log operation at line is a vulnerable operation as it does not have any range check and lines denote iterative inputs as they are repeatedly loaded in the training loop.
please note that the ground truth label vector y is also input in our context as it is loaded from some external le.
as such vectors x andy at lines and are possible starting point of a failure causal path and marked trainable and y conv at line is a possible end point from which grist constructs the suspect loss.
please note that some statements between line and line were omitted due to the space limit and the complete code including complete data control dependency between xandy conv can be found at .
in this case since the parameter of a log operation ought to be greater than the suspect loss is g 2 e 0regarding the12345678910111213141516172024252627282930313233x tf.placeholder tf.float32 shape y tf.placeholder tf.float32 shape x image tf.reshape x w conv1 weight variable b conv1 bias variable h conv1 tf.nn.relu conv2d x image w conv1 b conv1 h pool1 max pool 2x2 h conv1 omit some internal statementsw fc2 weight variable b fc2 bias variable y conv tf.nn.softmax tf.matmul h fc1 drop w fc2 b fc2 cross entropy tf.reduce sum y tf.log y conv omit some internal statementsmnist input data.read data sets data one hot true for i in range batch mnist.train.next batch feed dict x batch y batch keep prob .
loss sess.run feed dict irkgt osgmk a simpli ed buggy code snippet456789101112131415161718192021222324252627282930313233x tf.placeholder tf.float32 shape y tf.placeholder tf.float32 shape x image tf.reshape x w conv1 weight variable b conv1 bias variable h conv1 tf.nn.relu conv2d x image w conv1 b conv1 h pool1 max pool 2x2 h conv1 ......w fc2 weight variable b fc2 bias variable y conv tf.nn.softmax tf.matmul h fc1 drop w fc2 b fc2 cross entropy tf.reduce sum y tf.log y conv optimizer definition ...... load datasetmnist input data.read data sets mnist data one hot true for i in range batch mnist.train.next batch loss sess.run feed dict x batch y batch keep prob .
irkgt osgmk b mutated images figure example of gradient back propagation for iterative inputs from starting point of x. our goal is hence to change xsuch that y conv becomes smaller than or equal to .
.
gradient back propagation back propagation for iterative inputs.
assume the suspect loss at a vulnerable operation is with 8a vector of external inputs.
grist updates 8at the end of the cc iteration as follows with 8c denoting the 8value at c. n b86 r5 8c 8c ?
8c 0g in the formula b86 returns the sign of a real number and nis a hyperparameter that determines how fast grist updates the input.
the formula means that grist acquires the gradient sign of the suspect loss and updates the input by nalong the opposite direction of gradient sign.
the updated input value needs to be clipped to its legal range.
example.
consider the example in figure 6aagain.
although our static analysis marks both xandy in lines and to trainable respectively at runtime grist observes that the gradient of y is aty conv at line indicating y does not a ect the parameter of 632exposing numerical bugs in deep learning via gradient back propagation esec fse august athens greece define inputs and weights abovegain tf.get variable name g matmul 1 initializer tf.random uniform minval maxval skip intermediate calculation ....curr scale tf.multiply max scale s new scale tf.div curr scale gain 89101112figure example of gradient back propagation for noniterative inputs from thelog operation.
as such it focuses on changing the value of x. since it is a vector and the individual elements of the vector denote image pixels and may have di erent gradients these pixels undergo di erent scales of mutation.
the images in figure 6bdemonstrate these mutations.
observe that unlike adversarial sample generation we do not need to bound the mutation to some norm.
back propagation for non iterative inputs.
assume the suspect loss is at some operation with 8a vector of non iterative inputs.
we approximate with a linear function particularly with r5 the gradient of the suspect loss over input 8computed by the infrastructure.
assume gis an invalid value we want to reach at the suspect operation.
grist can directly update the input 8as follows.
g r5 ?
0g intuitively it solves the aforementioned linear function to make it achieve the invalid value g. please note that gcan be easily derived from the valid range of the operation parameter .
this strategy is very e ective in practice as non iterative inputs tend to be used in low complexity computation that can be su ciently approximated by a linear function.
note that a simple non linear functions can be easily approximated by multiple linear functions.
for cases where linear updates cannot trigger a bug within a small number of rounds grist resorts to gradient sign based mutations like for iterative inputs.
example.
consider another example in figure .
it is from a stochastic computing deep neural network scdnn program for mnist in github .
in this case the static analysis identi es the div operation at line is vulnerable to an invalid divisor value of and variable gain at line is a non iterative input as it is used in the initialization phase.
the variable is marked trainable.
at runtime grist identi es that the input variable gain has a non zero gradient i.e.
gradient is equal to at the divisor at line as the variable is directly used as the divisor.
grist approximates the relation between gain and the divisor with a linear function .
according to formula gain gain and the variable is updated to in the next execution according to formula triggering an nan value.
.
driver the driver is responsible to include the mutated inputs in model execution so that the mutation can take e ect and lead to failures.
if the inputs being updated are non iterative the driver simply restarts the execution with the updated inputs.
in the following we focus on discussing how the driver handles iterative input updates.
we cannot directly use the default training batching algorithm which tends to use di erent inputs for each iteration.
as such the mutated inputs have no impact.
a simple strategy would be to restart every time after update.
however the boot up process is very expensive.
as such our driver tends to retain all the important inputs i.e.
the inputs that have strong causality with the numerical bug to trigger and replaces the non important ones with fresh samples in order to avoid being stuck in local optima.
in particular we compute an importance score for each input 8at the end of cc iteration as follows.
score c updatec clipc in this formula refers to the number of iterations that input has been updated among citerations.
please note that should be less than cas input 8may be added during training.
and updatec 1d where d refers to the ratio of the number of elements e.g.
pixels of an image of input 8updated in the c iteration to the total number of elements in the input clipc where refers to the ratio of the number of elements beyond its legal range after input 8is updated in the c iteration to the number of elements.
a high score indicates that the input contributes more to expose the numerical bug.
at the end of each iteration the driver replaces called the switch rate a hyper parameter in grist inputs that have the lowest scores with fresh ones.
please note that updatec clipc and are for newly added inputs which hence have the highest scores among all the inputs.
termination condition.
termination condition determines when grist should give up on a suspect.
we currently have a simple termination condition.
we use both a xed time limit timeout and the trend of loss function .
evaluation in this section we aim to address the following research questions rq1 is grist e ective for exposing numerical bugs in dl programs?
rq2 how does grist perform compared with the state ofthe art technique debar?
rq3 does our data replacement strategy in the driver improve the e ectiveness of grist?
experimental datasets in our study we consider both tensorflow programs and pytorch programs since they are two most widely used dl frameworks and involve both static computation graphs and dynamic computation graphs.
in total we collected dl programs with numerical bugs each dl program contains at least one numerical bugs as subjects from the following two sources known bugs from existing studies and github we used subjects containing known bugs from existing studies and github.
speci cally we used eight subjects from the existing empirical study on tensorflow program bugs and one subject from 633esec fse august athens greece ming yan junjie chen xiangyu zhang lin tan gan wang and zan wang tensorfuzz following the existing work .
regarding known bugs from github we adopted bug relevant keywords including nan inf and the operations listed in table to search a set of candidate programs from github according to the descending order of github searching relevance and then conducted manual ltering.
since di erent dl programs tend to require di erent runtime experiments dependencies and datasets it is non trivial to run a dl program and reproduce its bugs successfully.
therefore we used eight subjects whose bugs can be reproduced conveniently and successfully in our runtime experiment.
unknown bugs from github we applied grist and the state of the art technique debar to fuzz github dl programs and nally identi ed subjects with unknown numerical bugs to developers.
speci cally we rst collected a set of github dl programs each of which contains at least one operation listed in table 1and can run successfully in our runtime experiment according to the descending order of github searching relevance with the considered vulnerable operations.
then we applied grist and the state of the art technique debar to the latest commit of each program respectively.
if at least one technique can detect a numerical bug within minutes in a dl program we regarded this dl program as a subject.
in particular we consider the diversity of our subjects.
besides di erent dl frameworks and di erent types of computation graphs our subjects also include di erent neural network architectures e.g.
cnn rnn and gan and di erent datasets e.g.
mnist fashion mnist and user de ned data .
experimental settings to answer rq1 we ran each subject with and without grist using its default dataset and hyperparameters.
grist has hyperparameters timeout the time limit for running grist nthat de nes the input update rate and switch rate that speci es the fraction of samples that are replaced at each batch for iterative inputs.
speci cally timeout is set to minutes nis set to .
and switch rate is set to .
we have investigated the in uence of main parameters in section .
.
note that with grist the inputs are mutated during execution.
to mitigate non determinism e.g.
numerical exceptions being randomly triggered we repeated each run times and reported the aggregated results.
to answer rq2 we applied debar with its default hyperparameters to each subject and also set its time limit to minutes for fair comparison.
to answer rq3 we ran each subject through grist without its data replacement strategy while the other two hyperparameters in grist remain the same.
hardware and runtime environments our experiment was conducted on the intel xeon silver machine with 128gb ram ubuntu .
.
lts and two gtx ti gpus.
we used the anaconda environments to switch di erent versions of pytorch and tensorflow.
.
rq1 overall e ectiveness of grist setup.
we ran subjects containing bugs times with and without grist respectively.
table 2shows the comparison results between with and without grist in which cis the total number of times that a bug is exposed in repeated runs trefers to the average execution time for exposing a bug.
please noted that if a numerical bug is exposed in out of the runs only the time in these times are used to calculate the average result.
wecalculated the average improvement achieved by grist in terms of the execution time for each bug denoted as .
we also calculated the average results for the overall bugs as shown in the last row in table .
for those bugs that were not triggered within the given time limit we used the time limit i.e.
minutes to calculate the overall average time.
due to the space limit we use id to replace the subject name and the complete information about our subjects can be found at our project homepage1.
results.
table 2shows the e ectiveness of grist in exposing numerical bugs and accelerating failure triggering.
overall grist is able to successfully detect out of bugs within minutes among which are unknown bugs i.e.
the latest commit for the corresponding subject still contains the bug .
in particular of unknown bugs cannot be detected by the state of the art technique debar demonstrating the unique superiority of grist more detailed comparison with debar can be found in section .
.
through submitting them to the corresponding issue repositories and communicating with developers eight bugs have been con rmed and three bugs have been xed.
we further analyzed the bug that was not exposed by grist i.e.
id which cannot be triggered by running the original program with the default inputs either and found that grist indeed pushes the parameter value of the vulnerable operation i.e.
exp very close to the boundary but cannot go beyond to trigger the failure .
by relaxing the time limit to one hour grist is able to trigger the bug with average time of minutes .
from table there are bugs which were never be exposed in the runs of using the default inputs.
in contrast grist can always trigger numerical bugs in all the runs and the remaining two bugs in some of the runs due to inherent non determinism .
regarding the bugs that can be exposed by both grist and default inputs grist can trigger them in a much more stable fashion.
speci cally grist can trigger them in all the runs whereas using the default inputs triggers eight of them in some of the runs even less than times for the subject with id .
also observe from table 2that grist can substantially reduce the time spent on triggering bugs.
overall grist can save .79x time cost on average.
in particular for the bug id using the default input took .
seconds to trigger it while grist took only .
seconds saving .32x time cost.
there is only one bug i.e.
id 2a that grist spends longer average time on triggering it than the original program with the default input.
we analyzed that for this bug using the default input alone took only .
seconds to trigger it.
for such a bug grist cannot accelerate the process that is already extremely fast.
.
rq2 comparison with the state of the art technique debar setup.
for comparison with the state of the art technique debar we applied it to each subject and used 7to mark whether debar can detect the bug or not in table .
as debar does not need to run programs we do not need to run it times.
results.
as expected the execution time of the static technique debar is only seconds on average across all the subjects but .
634exposing numerical bugs in deep learning via gradient back propagation esec fse august athens greece table results for using the default inputs grist grist and debar iddefault input grist grist debar iddefault input grist grist debarct ct ct ct ct ct .
.
.
x .
.
x .
.
.
x .
.
x 2a .
.
.
x .
.
x .
.
.
x .
.
x 2b .
.
.
x .
.
x .
.
.
x .
.
x .
.
.
x .
.
x 35a .
.
.
.
35b .
.
.
.
36a .
.
.
x .
.
x .
.
.
x .
.
x 36b .
.
.
.
.
x .
.
x .
.
.
x .
.
x .
.
.
x .
.
x .
.
9a .
.
.
x .
.
x 39a .
.
.
x .
.
x 9b .
.
.
x .
.
x 39b .
.
.
.
.
x .
.
x .
.
.
x .
.
x 11a .
.
.
x .
.
x .
.
.
x .
.
x 11b .
.
.
x .
.
x .
.
.
x .
.
x 11c .
.
43a .
.
.
.
.
x .
.
x 43b .
.
.
.
.
.
.
.
.
x .
.
x 45a .
.
.
x .
.
.
x .
.
x 45b .
.
.
x .
.
x 16a .
.
.
.
16b .
.
.
x .
.
x .
.
16c .
.
48a .
.
.
x .
.
x 48b .
.
.
x .
.
x .
.
.
x .
.
x 49a .
.
.
.
.
x 49b .
.
.
.
.
.
.
.
.
.
x .
.
.
.
.
.
.
x .
.
x .
.
.
x .
.
x .
.
.
x .
.
.
x .
.
x .
.
.
x .
.
x .
.
.
x .
.
x .
.
.
.
28a .
.
.
.
.
x .
.
x 28b .
.
.
.
.
x .
.
x 28c .
.
.
.
.
x 28d .
.
.
.
.
x .
.
x .
.
.
x .
.
x .
.
.
x .
.
x .
.
.
x .
.
.
.
total .
.
.
.
.
1means that the grist or grist based run s can expose numerical bugs in the runs while the default inputs cannot 1means grist cannot nd numerical bugs in the runs while the default inputs can indicates that the corresponding technique cannot expose the numerical bugs 7means that debar can detect the bug or not.
indeed debar reports fps false positives which have been extensively explained in the work proposing debar .
also there are out of bugs that were not detected by debar of which bugs were detected by grist.
in fact grist can detect a superset of the bugs that debar can detect.
we manually analyzed the fns false negatives of debar and found that there are three reasons as mentioned earlier debar cannot be applicable to dynamic computation graphs and thus it missed to detect bugs based on dynamic computation graphs.
it is remarkable that the latest version of tensorflow has also supported dynamic computation graphs and takes it as the default usage indicating that supporting to detect bugs based on dynamic computation graphs like grist will be an inevitable trend in the future to some degree.
of fns fall into this category.
debar does not support the error type of invalid derivative listed in table 1since the derivation operation can be found only at runtime .
of fns fall into this category.
debar requires users to manually con gure the range of each primitive parameter in the program but there are three bugs which debar cannot detect when con guring the correct range e.g.
the range of the variable after normalization is but can detect when setting a more coarse range e.g.
.
theresults demonstrate that grist outperforms debar in terms of both fps and fns.
.
rq3 contribution of the data replacement strategy in grist setup.
to investigate the impact of replacing unimportant samples with fresh ones in grist we prohibited grist from dropping inputs with low scores or adding new inputs.
in other words it continued to update the same set of samples iteratively.
the settings ofnandc8 dc remain the same.
we call this variant grist .
results.
observe that replacing unimportant samples has a positive e ect on the performance of grist.
first of all in terms of the number of exposed bugs grist exposes bugs in runs in total while grist grist without data replacement only exposes bugs in runs.
also there are six bugs that were not detected by grist but were detected by the original programs using default inputs.
second in terms of time cost reduction in exposing bugs grist can save .99x time cost compared to the original programs using default inputs while that of grist is .79x.
635esec fse august athens greece ming yan junjie chen xiangyu zhang lin tan gan wang and zan wang the results demonstrate the data replacement strategy is indeed able to improve the performance of grist.
discussion .
in uence of main parameters in grist we investigated the in uence of two main parameters in grist i.e.
n the input update rate and switch rate the fraction of samples being replaced at the end of each training iteration by conducting an experiment based on three randomly selected subjects id id id .
regarding n we studied .
.
.
.
and .
while regarding switch rate we studied .
.
.
.
and .
whose average results are shown in figure .
in the experiment only one parameter is changed each time while others use our default settings.
we found that in general grist is insensitive to norswitch rate except .
within the studied range.
regarding switch rate of .
one subject has a small batch size such that the number of replaced data is very small making it nearly equivalent to grist .
.
generalizability of grist on one hand grist can work on both static computation graphs and dynamic computation graphs while debar can only support the former indicating that grist is more general than the stateof the art technique debar for detecting numerical bugs in dl programs.
on the other hand even though grist is designed to expose numerical bugs in dl programs it can be also generalized to dl libraries to some degree.
this is because dl libraries can also utilize their gradient computation mechanisms that grist piggy backs on through invocations from dl programs.
we use an example of the pytorch library shown in figure to illustrate how grist is generalized to detect numerical bugs in dl libraries.
figure 8ashows the function entropy in pytorch which could produce an nan when self.rate is in log.
grist can detect this numerical bug by nding or creating a dl program that invokes this function shown in figure 8b constructing suspect loss by instrumenting pytorch to return the parameter value ofloginentropy along with its original returned value lines in figure 8b and updating the argument value of entropy in the dl program via gradient computation utilizing the gradient computation mechanism in pytorch between suspect loss and the argument rate ofentropy lines in figure 8b .
in this way rate becomes zero eventually and the numerical bug in pytorch is exposed.
compared with dl programs the main di erence of detecting numerical bugs in dl libraries is that the logical relationship between suspect loss andinput of the library function under test lies in dl libraries rather than dl programs and thus the parameters of the buggy operations have to be returned to dl programs from dl libraries for gradient computation.
.
threats to validity theinternal threat to validity mainly lies in the implementation of grist.
to reduce this threat two authors have carefully examined the implementation of grist including reviewing and testing the code.
speci cally they cross reviewed each function and wrote unit tests.
also regarding the integrated tool they used the debug mode q wrufk glvwulexwlrqv h srqhqwldo srqhqwldoghi hqwurs vhoi uhwxuq wrufk orj vhoi udwh q qvwuxphqwhg srqhqwldoghi hqwurs vhoi uhwxuq wrufk orj vhoi udwh vhoi udwh q ulyhu ri 67udwh lqlwldol hbudwh udwh fodps udwh h srqhqwldo srqhqwldo udwh zkloh 1rw7huplqdwh h srqhqwldo srqhqwldo udwh dfwxdobuhvxowv prqlwruhgbydu h srqhqwldo hqwurs vxvshfwborvv ghilqhbvxvshfwborvv prqlwruhgbydu judgv fdofxodwhbjudglhqwv vxvshfwborvv udwh 1d1b khfn dfwxdobuhvxowv udwh xsgdwhbudwhbe bjudgv judgv udwh fodps udwh a function in the pytorch library q wrufk glvwulexwlrqv h srqhqwldo srqhqwldoghi hqwurs vhoi uhwxuq wrufk orj vhoi udwh q qvwuxphqwhg srqhqwldoghi hqwurs vhoi uhwxuq wrufk orj vhoi udwh vhoi udwh q ulyhu ri 67udwh lqlwldol hbudwh udwh fodps udwh h srqhqwldo srqhqwldo udwh zkloh 1rw7huplqdwh h srqhqwldo srqhqwldo udwh dfwxdobuhvxowv prqlwruhgbydu h srqhqwldo hqwurs vxvshfwborvv ghilqhbvxvshfwborvv prqlwruhgbydu judgv fdofxodwhbjudglhqwv vxvshfwborvv udwh 1d1b khfn dfwxdobuhvxowv udwh xsgdwhbudwhbe bjudgv judgv udwh fodps udwh b pytorch program invoking the function driver of grist figure example of applying grist to detect a numerical bug in the pytorch library in the pycharm ide to ensure the correctness of the intermediate states and the nal output for a program.
theexternal threat to validity mainly lies in the subjects used in our study.
to reduce this threat we collected real world dl programs containing bugs from two sources as subjects in our study including known bugs from existing studies and github and unknown bugs from github that can be detected by either grist or debar.
section 4presents the subject collection process in detail.
in the future we will evaluate grist on more dl programs based on more dl libraries.
related work dl program bugs.
the most related work to ours is debar which has been discussed and compared in sections .2and4.
.
besides there are a number of empirical studies on dl program bugs .
for example zhang et al.
analyzed the root causes and symptoms of tensorflow program bugs from github issues and stack over ow posts.
humbatova et al.
provided a taxonomy of dl program bugs through manual analysis and interviews based on github issues and stack over ow posts.
islam et al.
analyzed the types root causes impact and x patterns of dl program bugs based on ve popular dl libraries.
zhang et al.
inspected questions on stack over ow about dl and summarized many common challenges in developing dl programs.
di erent from them we focus on proposing the rst dynamic technique to expose numerical bugs in dl programs.
numerical bugs in traditional software.
there is some work on numerical bugs in traditional software.
for example franco et al.
conducted a comprehensive study on numerical bugs in traditional software.
dietz et al.
developed ioc a dynamic checking tool for integer over ow and conducted the rst empirical study on integer over ow in c and c code.
tang et al.
proposed a toolchain that can detect potential numerical instability and diagnose the reasons for such instability.
guo et al.
proposed 636exposing numerical bugs in deep learning via gradient back propagation esec fse august athens greece a n b bf8c2 a0c4 figure results for di erent settings of nandbf8c2 a0c4 an approach based on symbolic execution to e ciently generating oating point inputs to trigger program errors.
di erent from them our work targets at numerical bugs in dl programs which are very di erent from traditional software as presented in section .
furthermore fu et al.
adopted gradient optimization to analyze oat point code in traditional software aiming at generating tests for high coverage.
even though they also utilized gradients di erent from them our contribution lies in handling bugs in dl programs.
speci cally dl training is extremely expensive and demands many processes whereas the execution model of traditional numerical programs is simple.
grist piggy backs on existing gradient back propagation mechanism which makes it easily deployable.
it requires solving new challenges as well such as interacting with dl primitives e.g.
automatically marking selected variables as trainable and handling data loading.
dl testing.
over the years a large amount of work focus on dl testing .
however they aim to either test dl models by proposing various input generation techniques or designing various test criteria or test dl libraries and dl compilers di erent from them our work aims to detect dl program bugs i.e.
numerical bugs in dl programs.
conclusion in this paper we propose the rst dynamic technique to generate inputs to expose numerical bugs in dl programs and implement it in a tool named grist.
the technique piggy backs on the built in gradient computation of the underlying deep learning framework.
our results on real world dl programs with numerical bugs show that grist can expose unknown numerical bugs and substantially reduce the execution time needed to trigger bugs.
acknowledgement we thank all the anonymous reviewers for their valuable comments.
this work has been supported by the national natural science foundation of china intelligent manufacturing special fund of tianjin iarpa trojai w911nf 19s nsf and onr n000141712045 n000141410468 n000141712947.
any opinions ndings and conclusions in this paper are those of the authors only and do not necessarily re ect the views of our sponsors.