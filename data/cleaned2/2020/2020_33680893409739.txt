search basedadversarial testing and improvementof constrained credit scoring systems salah ghamizi universityof luxembourg luxembourg salah.ghamizi uni.lumaximecordy universityof luxembourg luxembourg maxime.cordy uni.lumartingubri universityof luxembourg luxembourg martin.gubri uni.lu mike papadakis universityof luxembourg luxembourg michail.papadakis uni.luandreyboystov universityof luxembourg luxembourg andrey.boystov uni.luyves le traon universityof luxembourg luxembourg yves.letraon uni.lu anne goujon bglbnp parisbas luxembourg anne.goujon bgl.lu abstract creditscoringsystemsarecriticalfintechapplicationsthatconcerntheanalysisofthecreditworthinessofapersonororganization.
whiledecisionswerepreviouslybasedonhumanexpertise they arenowincreasinglyrelyingondataanalysisandmachinelearning.
in this paper we assess the ability of state of the art adversarial machine learning to craft attacks on a real world credit scoring system.
interestingly we find that while these techniques can generatelargenumbersofadversarialdata thesearepracticallyuseless as they all violate domain specific constraints.in other words the generated examples are all false positives as they cannot occur inpractice.tocircumventthislimitation weproposecoeva2 a search basedmethodthatgeneratesvalidadversarialexamples satisfying the domain constraints .
coeva2 utilizes multi objective searchinorder to simultaneouslyhandle constraints perform the attack and maximize the overdraft amount requested.
we evaluatecoeva2onamajorbank sreal worldsystembycheckingits abilityto craft valid attacks.
coeva2 generates thousandsofvalid adversarial examples revealing a high risk for the banking system.
fortunately by improving the system through adversarial training basedontheproduced examples we increaseitsrobustnessand make our attackfail.
ccs concepts appliedcomputing onlinebanking computingmethodologies machine learning .
permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage.copyrights forcomponentsofthisworkownedbyothersthanthe author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
esec fse november 8 13 virtual event usa copyright heldby the owner author s .
publicationrightslicensed to acm.
acm isbn .
search based adversarial attacks fintech random forest credit scoring acmreference format salah ghamizi maxime cordy martin gubri mike papadakis andrey boystov yvesletraon andannegoujon.
.search basedadversarial testing and improvement of constrained credit scoring systems.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november 8 13 virtual event usa.
acm new york ny usa 12pages.
introduction the banking industry increasingly relies on machine learning to support decision making based on customers historical data.
one prominentapplicationcaseis creditscoring i.e.
asetofdecision modelsandtheirunderlyingtechniquesthataidcreditlendersin the grantingof credit .
bylearning fromhistory credit cases and their outcomes whether the credit was returned in time supervised models can automate the approval and rejection of new creditrequests withlimitedhuman intervention.
ourindustrialpartner thedatasciencelabofbglbnpparibas luxembourg henceforth referred to as bgl bnp paribas has recently engineered such a credit scoring system.
their system deals with the approval of overdraft requests which occur when a transactioncausesthebalanceoftheaccounttodropbelowzero.
then it is up to the bank employees to allow or reject this transaction.
bgl bnp paribas implemented an automated system relying on random forests.
that is the approval of overdraft requests is seen as a binary classification problem approved or rejected .
the system approves or rejects overdrafts automatically based on data abouttherequestedtransactionandthecustomers history.ifthe overdraft is rejected by the system an expert re analyzes the requestandmayoverrulethedecision.ifitisaccepted thesystem latercheckswhether the overdrafthas been reimbursedintime.
esec fse november8 virtualevent usa s.ghamizi m. cordy m. gubri m. papadakis a.boystov y. le traon anda.goujon the first challenges faced by our partner were feature engineeringandmodelselection.asthesehavebeenwidelyresearched see e.g.
theybenefitedfromtheavailablebodyofknowledge and techniques tobuild a quality system that achieved a test accuracyof80 .asofnow thissystemhasprocessedmorethan overdraftrequests over aspan of30 months.
yet thestringentsecurityrequirementsforceduponthebanking sector oblige them to protect their credit scoring system against maliciousthirdparties.inourpartner scontext thethreatliesin the capability of the third party to modify the requested credits and the profile of customers to make the system accept overdrafts that itshould have rejected.
inmachinelearning suchmaliciousinputsarecalled adversarial examples andarecraftedbyalteringbenigninputsinsuchaway thattheyfooltheclassificationsystem.adversarialexamplesare mainlystudiedinthecontextofcomputervisionanddeepneural networks whereelusivealterationstothepixelsofimages cause misclassifications.
such research has shown that adversarial examples can be crafted by a systematicprocedure the adversarialattack whichtypicallyutilizesinformationabouttheneural network sgradientstofindtheslightestperturbationthatwould changethe outputclass.
interestingly theapplicationofadversarialattackstofintech andrandomforestsremainslargelyunexplored .thisissurprisinggiventhewidespreaduseofthesetechniquesinindustrialapplications.toourknowledge thestate of the artattackforrandom forest classification algorithms is the one designed by papernot et al.
.itconsistsofastochasticprocedurethatvisitsandattempts tofliptheindividualdecisionnodesoftheforest streesuntilthe classificationoutcomeischanged.analternativeapproachcould betobuilta surrogate deepneuralnetwork usingthetraining data based on which we could apply a prominent gradient based attack with the hope that this attack will be transferable to the random forestmodel .
nevertheless all adversarial attack techniques lean on the internal computationsof theclassification models anddisregardthe factthatalteringtheoriginalinputmayproducefalsepositives i.e.
infeasible intherealworld or invalidforthesoftwaresysteminputs that are acceptable by the classification model.
while this phenomenon is less likely to occur in image recognition where slightly altering an image can easily produce a valid image application domains such as fintech are subject to hard domain constraints delimiting the set of valid inputs.
for instance a credit scoring systemrelies onfinancialinformation suchascustomers account balance contractedcredits monthlyincome andindebtmentrate.
such data are naturally constrained e.g.
income is positive interdependent indebtment rate depends oncontracted creditsand monthlyincome orbounded e.g.
themaximumoverdraftamount authorizedbythebank .thus anysuccessfulattackshouldrespect thesedomainconstraintsandproduce examples that satisfy them.
moreover weconductexperimentswiththecurrentstate of theart i.e.
thepapernotattack onourpartner ssystem.1interestingly we show that while the attack successfully generated adversarial examples that flipped the classification results for of the cases its grosssuccess rate none of them satisfied the domain 1wereport onthese experimentsin section .constraints.thismeansthattheattackhasan actualsuccessrateof .theseresultsindicatethatstate of the artadversarialattacks cannotgeneratedomain constrainedtest inputs.
dealing with domain constraints is a recurrent problem in softwareengineering .inthecaseofgeneratingadversarialexamples one cannot handle satisfy the domain constraints independently oftheattack technique.the issueis that ontopoftheconstraints manyofwhichareimposedbyothersystems components one needsto craftthe attacks and fulfil some additional objectives e.g.
causemisclassification maximizetheoverdraftamount .therefore reducing the problem to constraintsatisfactionisnot enough.
to dealwith this issue we propose a search based method that generates constrained adversarial examples for banking applications.weformulatethegenerationofadversarialexamplessatisfyingthedomainconstraintsasamulti objectivesearchproblem and show that search based techniques offer suitable solutions.
ourmethod calledconstrainedevolutionaryadversarialattack coeva2 operatesinagrey boxway itreliesonthefeaturerepresentationoftheinputsbutisindependentoftheinternalparameters ofthe classification model.
weapplycoeva2tobglbnpparibas screditscoringsystem and show that it can generate thirteen thousand of valid adversarialexamplesfrom8 .
oftherealoverdrafts.thisdrastically improvesoverstate of the artadversarialattacks whichfailedcompletely.then weshowthatwecanmakeourpartner ssystemmore robust by performing adversarial training i.e.
retrain the model using the produced adversarial examples .
after such training the systemresiststo our attack appliedundersimilar conditions .
in summary the contributionsof this paper are wedemonstratetheneedfordomain constrainedadversarial attacktechniquesforindustrialfinancialsystems.wealso show that existing attacks are inapplicable to real world creditscoringsystems such as the one of our partner.
wedevelopcoeva2 anewadversarialattackmethod for random forest applications based on multi objective search.
givenaclassificationmodelanddomainconstraints coeva2 effectivelygeneratesvalid adversarialexamples.
weevaluatecoeva2onourpartner ssystemandempirically show that it can craft adversarial examples with an actual successrateof8.
leading to thousandsof examples.
wedemonstratethatourmethodhelpstoimprovethesystem s robustness to adversarial attacks .
indeed retraining the system on adversarial examples results in improving its robustnesssignificantly.
related work .
credit scoring thestudyoflouzadaetal.
presentsacomprehensivesurveyof classification methods in the context of credit scoring automation.
whilefocusingonclassificationmodels louzadaetal.alsoreported thedifferentproblemstackledbythesurveyedpapers withnone ofthembeen relatedto modelrobustnessoradversarialattacks.
much research has been conducted on feature engineering and modelselectionforcreditscoring.forexample demeloandbanzhaf combinedkaizenprogrammingandlogisticregressiontofind thebestnon linearcombinationoffeatures.saiaetal.
proposed 1090search basedadversarialtestingandimprovement of constrainedcreditscoringsystems esec fse november8 virtualevent usa a wavelet based feature engineering method and evaluated its performanceusingmultipletypesofmodels.fengetal.
proposeda featureselectionapproachbasedonfiltersandanovelindexnamed new separation degree .
these techniques are orthogonal to ours as they donot target adversarialattacksorrobustness.
.
adversarialexamples adversarialexamples were firstmentionedby the studies of biggio et al.
and szegedy et al.
in the context of deep neural networksforimageclassification.theirintriguingpropertyresides inthe small perturbations neededto changethe predictedlabel.
accordingtobiggioetal.
white boxattacksassumeperfect knowledge on the model its parameters training set and features.
grey boxattacksusesomeknowledgeaboutthetargetedsystem but assume another part to be unknown.
black box attacks rely on the raw input space and the system s outputs to generate adversarialexamples.
in the recent years the ever increasing literature has studied adversarial examples mainly for computer vision e.g.
with applications to autonomous cars and facial recognition and to a lesserextent naturallanguageprocessing andsoftwaresecurity .
papernot et al.
mention the potential threats of adversarial examples for financial fraud detection.
yet to the best of our knowledge there exists no prior work applying adversarial attacks to industrialsystemsfrom the financialdomain.
inanotherpaper papernotetal.presentanattacktodecisiontrees.whilethisattackisstraightforwardtoextendtorandom forests itdoesnotsupportdomainconstraints.asweshowlater thismakesitincapableofgenerating adversarialexamplessatisfyingthe constraints.
kantchelianetal.
havealsoproposedanotherrandomforest attack.ittransformsthedecisionnodestoformula formingthem as misclassification objective and uses a sat solver to generate solutions.thus anysolutioncorrespondstoanadversarialexample.
while this attack can theoretically solve the problem of generating constrainedadversarialexamples byaddingconstraintsintothe formula in practice it faces scalability issuesdue to the inherent problems andlimitationsofthe satsolvers.
indeed weconductedanexploratoryexperimentbasedonthe helocdataset2whichhashalfthenumberoffeaturescomparedto our partner s dataset and simple constraints involving at most two features.
after hours the kantchelian attack could not generate any adversarialexample satisfyingthe constraints.
ourmethodovercomesthelimitationsofstate of the artattacks and designs a search based evolutionary algorithm to generate adversarial examples that cause misclassification and satisfy the domainconstraintswhileminimizingtheperturbationandmaximizing the business impact i.e.
the acceptedoverdraftamount .
theideaofusingsearch basedalgorithmstoperformadversarial attackisnotnew.alzantotetal.
haveproposedablack boxattack on image recognition models viz.
deep neural networks .
being focused on images the problem they tackle is different and does not involve domainconstraints.
constrained testgeneration the problem of generating test inputs under domain constraints is not new and was tackled by several works in the context oftraditional code based software aswitnessed by the survey of mcminn .
more recently ali et al.
evaluate different searchbasedmethodsingeneratingtestinputssatisfyingoclconstraints.
inthecontextofcombinatorialinteractiontesting cit garvin et al propose to reorganize the search space of metaheuristics to reflect the structure of the cit problems and their inherent constraints.comparedtosuchworks thenoveltyofourresearchis that it targets machine learning systems under adversarial settings.
analternativetomulti objectivegasearchwouldrequirethe useofasatsolvertofindallvalidconfigurationsthenchoosing the optimal ones with regards to the other objectives.
however thecombinationofbothsearchspacesandthecomplexityofthe constraintsmake itcomputationallyexpensive.
industrialcreditscoringsystem .
process anddatasets when a customer initiates through any channel a transaction whose amount exceeds the customer s account balance the paymentengineasksthecreditscoringsystem css forpermission.
thecssexaminesthecustomer sprofileandeitherapprovesthe credit overdraft or it suggests the operator reject the request.
in thelattercase theoperatorcanfollowthesuggestionofthecss oroverrule itandacceptthe request.
to make informed decisions the css pulls information from adozensources.inadditiontobasicfeatureslikethetransaction amount and the customer s current balance much information aboutthecustomer shistoryisconsolidated.intheend anoverdraft request isrepresentedas avector of features.
afterapproving an overdraft request the bank expects the customertoreturnthecreditinduetime.incasethecustomerdoes notdoso thebankconsidersthatitwaswrongtoallowtheoverdraft otherwise it considers that it was correct.
through this postanalysis we can associate each approved overdraft credit with a binarylabel trueorfalse .suchlabelsformthe groundtruth and are used to assess the accuracy of the css.
a similar process is usedforrejectedoverdraftandanalyzes basedonthecustomer s future transactions whetherthe overdraft credit would have been returnedintime should ithave been approved.
overall thecssdatasetcomprises400 000overdraftcreditrequestswiththeirassociatedlabel outofwhich275 000areusedfor training and125 for testing.
.
model requirementsandcharacteristics therationalebehindourpartner sprojectistoreducehumaninterventioninoverdraftapprovalbyautomaticallyapprovingsafe overdraft requests sending only rejected overdraft to human experts while minimizing the acceptance of risky overdrafts e.g.
transactions of large amount .
our partner also expects the system torunonline inreal time andefficientlysothatitdoesnotcompromise the efficiency of the other services.
finally the selected modelshouldbe interpretable asexplaininghardly interpretable 1091esec fse november8 virtualevent usa s.ghamizi m. cordy m. gubri m. papadakis a.boystov y. le traon anda.goujon modelscanbeinefficientandevendangerousinhigh stakedecisionmakingprocesses such as overdraftapproval.
to satisfy those requirements our partner performed feature engineering in close collaboration with business experts.
they performed model selection considering decision trees random forest and gradient boosted trees and used grid search to find optimal model parameters.
auc for roc curve was used as an optimizationcriterionforthegridsearch whilef1scorewasthe criteriontochoosetheoptimalclassificationthreshold.thefinal modelisarandom forestwith500estimators upto level deep.
thismodelisbuiltandintegratedwithinadataikudsspipeline3.
itachievesacceptableperformance .99aucand0.99accuracyon thetrainingset .88auc .80accuracyand .70f1 scoreonthe test set.
problem formulation .
unconstrainedadversarialattack letf .
be a binary classification model defined over a input space i.forsimplicity assume itobenormalizedsuchthat i m andf i for anyi i. letx0 irepresents an original example correctlyclassifiedby f .
.
adversarial attacks generate altered inputs that are close to theiroriginalcounterparts yetaremisclassifiedbythemodel.in traditional unconstrained adversarial attacks the ideal adversarial examplex craftedfrom x0to foolf .
isdefinedas x argmin x x x0 p such that f x f x0 x x0 i andwhere .
pisthelpnorm e.g.
l2 .
thep normdistancebetweenaperturbedinputandaninitial one is agood first indicationof the effort required to generatethe adversarialexample.however tobeacceptable theperturbedinput hastosatisfyinherentdomainconstraints.thisisafundamental differencewithimagerecognition whereitisgenerallyadmitted that a small distance between xandx0ensures that xhas a strong perceptualsimilarityto x0and thus constitutes avalid image.
therefore the problem of generating adversarial attacks for mlbasedfintechsystemstakesadifferentform boththeoriginaland the adversarial examples must be part of the subspace of inputs thatareconsideredvalid.tocharacterizethissubspace weproceed byfirstelicitingthe differentdomainconstraints.
.
formalizationoftheconstraints a first validity criterion demands that the adversarial example still represents an overdraft that is the transaction amount remains above the current balance of the customer s account.
additionally weconsiderthisamountrelevantifitishigherthan1 .00currencyunits.features4canalsobeinterdependent.forinstance the indebtmentratemustbepositiveandisobtainedbydividingthe 4duetondawecannotrevealtheexactfeaturesused.theexamplesoffeaturewe provide are different from the ones used by our partner.
however their interrelations areof the same level of complexity.monthly credit reimbursement by the monthly income.
there also exist categorical features that can only take values froma finite set.
forexample eachcustomercanbeassociatedwithapersonallevel ofrisk e.g.ona1 10scale basedonitsprofileandpastinterviews with the bank.
the corresponding feature can only take as value any integerbetween 1and10.
thishighlights the types ofconstraints thatourmethodmust support features can be bounded each by a different bound some may only take certain values and there may exist numerical dependencies between them.
accordingly we define that a formula encoding such constraints i.e.
a constraint formula over a set fof features isformedaccording to the following grammar 1 2 f f c1...ck c f 1 2 wheref f c c1 ... ckare constant values 1 2are constraintformulae 1 2arenumericalformulae and .
inadditiontosatisfyingsuchformula anadversarialattackmay not be able tomodify some features.
for instance the level of risk associatedtoacustomerisundercontrolofthebankandcannot bechangedbythecustomerhimself.thesameholdsforfeatures resulting from the aggregation of data over time.
thus we enforce the requirement that the attack can only alter the subset f fof mutablefeatures.theotherfeatures whichtheattackcannotalter areimmutable .
in bgl bnp paribas s css features are mutable and the other are immutable.
this means that the attacker s capability to succeed strongly depends on the features it cannot change.
we thus consider the features of different customers as differentstarting pointsfor our search algorithm.
wecannotdisclosethefeaturesofourpartner smodel oritsspecificconstraints butweprovideinthegitrepositoryareplication example onthe lending club load datase5 .
constrained adversarialattack leti mbe the feature vector space over the feature set f f1...fm f fbethesetofmutablefeaturesand bethe formulaover fencodingthedomainconstraints.furthermore let i denote the subspace of valid feature vector i.e.
i i i i .
given a binary classification model f .
and an original input x0 x0 ... x0 m i theidealadversarialexample x generatedfrom x0to foolf .
isdefinedas x argmin x x x0 p such that f x f x0 x x0 i fi f x0 i x i i m. here thedifficultyofperformingsuchattackliesinthatitcanonly alterfeatures infandinawaythat remainssatisfied.
1092search basedadversarialtestingandimprovement of constrainedcreditscoringsystems esec fse november8 virtualevent usa table1 successratesandaverageperturbationproducedby existingadversarialattacksappliedonourpartner ssystem.
whileeverymethodmanagestogenerateadversarialexamples none ofthese satisfy thedomainconstrains.
attack grosssuccessrate actual successrate avgl2 papernot .
.
.
pgd .
.
.
cw2 .
.
.
motivation howhelpful are existing attack techniques?
westartourstudybyassessingthecapabilityofexisting unconstrained attacks to generate valid adversarial examples in our realworld use case.
we assess the gross success rate of these attacks percentage of times they manage to create an example misclassifiedbythemodel theiractualsuccessrate afterremovingthe examples that do not satisfy the domain constraints and the averageamountofperturbationapplied measuredasthe l2distanceto theoriginalinput .theamountofperturbationismeanttoserve as ametric comparison between the attacks.
.
random forestattack first we consider the attack proposed by papernot et al.
henceforthnamedthe papernotattack whichwasoriginallydesignedtocausemisclassificationsindecisiontreesbyvisitingall nodesinthetreeandmakingthemflipuntilthemisclassification isachieved.
this is the only attack relevant to our case.
so we adapt it to randomforests byiterativelyapplyingthepapernotattacktoevery tree of the forest until the classification outcome of the random forestchanges.we callthis method iterativepapernot .
we evaluated iterative papernot on all original test inputs of our use case where the model makes correct classifications.
the results are recorded in table 1and reveal that the attack seems successful asitmanagestogenerateadversarialexamples causing misclassification in74 .
ofourstartingpoints inputs withan averagel2distance to the corresponding original inputs of .
.
however it turned outthat noneof thegenerated inputs satisfied the domainconstraints leadingto an actual successrateof0 .
.
gradient basedattacks another popular family of adversarial attacks are the gradientbased attacks.
these attacks were designed to generate adversarial examples ondeep neuralnetworks dnns .
wenote that during learning adnniterativelyadjustsitsneurons weightaccording to the gradient of its cost function which depends on the weights .
gradient based attacks exploit the same information to produce a perturbation that changes the output of the last neuron layer thereby changing the classification outcome.
being gradient based those methods can apply only on models relyingondifferentiablecostfunctions.thus theydonotwork out ofthebox onrandom forests.a common way to circumvent this limitation is to build a surrogatemodel adnn thatmimicstherandomforest.thatis wetrain this dnn on the same input set and use the outputs classification results oftherandomforestasthegroundtruthforthednn.then weperformthegradient basedattackonthesurrogatednnand obtain an adversarialexample.the underlying assumption of this method is that any adversarial example that fools the dnn also foolsthe mimickedmodel.
for our experiments we consider two gradient based attacks projected gradient descent pgd and cw2 which are considered among the most effective attacks.
we apply each attack onalloriginaltestinputsthatthemodelcorrectlyclassifies.weimplementadnnmodelusingthetensorflow kerasframeworksand we use the implementation of the gradient based attacks provided bythe ibmrobustnesslibrary .
results are shown in table .
pgd succeeds in generating adversarial examples causing misclassification in only .
of the attempts yetitdoessowiththesmallestaverageamountofperturbationamongstalltechniques l2distanceof0.
.nevertheless noneofthegeneratedadversarialsatisfythedomainconstraints.
cw2 has a much higher gross success rate at the cost of a higher perturbation than pgd .
yet much lower than the papernotattack.liketheothertwomethods cw2failstogenerate asingleexample satisfyingthe constraints.
overall our analysis shows that by focusing on classification method and outcome while being unaware of the domain constraints state of the art attacks fail to generate valid adversarialexamples .thisfactdemonstratestheneedfornewconstraintaware attacks i.e.
attacksthat satisfy the constraints bydesign.
research questions having shown that state of the art adversarial attacks are not usefulinourcase welookforwaystocircumventtheirlimitationsand successfully generate valid adversarial examples.
we focus more particularly on theuse casewhere amalicious thirdpartyaimsat foolingthesystem i.e.
makingitapproveoverdraftsthatshould berejected.thisusecaseisdeemedrelevantbyourpartnerasit inducesariskoffinanciallossfor the bank.
tothisend weinvestigatewhethersimplemethodssatisfying the domain constraints can solve our problem.
thus in our first question wecheckwhetheralteringtheinitialpointswhilekeeping constraintssatisfiedissufficient.
hence we ask rq1canwegeneratesuccessfuladversarialexamplesbyjust satisfying thedomainconstraints?
toanswerthisquestion weinvestigatetwosolutions.thefirstis to extend the iterative papernot attack in order to make it consider theconstraintsasitsearchesthroughthenodes.thesecondisto search for solutions using single objective search that satisfy the constraints.then wecancheckwhethertheproducedexamples are adversarial.
as our results shall show these single objective methods can craft examples that either change the classification outcome or satisfythedomainconstraints butnotbothatthesametime.we conjecturethat ontheonehand theiterativenatureofthepapernot attack blocks it into a narrow part of the landscape and on the 1093esec fse november8 virtualevent usa s.ghamizi m. cordy m. gubri m. papadakis a.boystov y. le traon anda.goujon otherhand therandomsearchdoesnotbenefitfromtheknowledge oftheoriginalinput causingarbitraryperturbation .thismeans that an effective searchshould not only be guided withadditional criteria e.g.
minimize the perturbation but also explore a diverse space.
to achieve this we experimented with evolutionary genetic algorithms.
such techniques are directed by some feedback aka fitness function that quantifies how close the current solutions are tothesoughtones.
atthesametime therandomalterationsthey applytothecandidatesolutionscreatedisruptioninthesearchand so avoids fallingintolocal optima.
our definition of constrained adversarial attack see section .
hints that such a search algorithm needs to handle multiple objectives minimizeperturbation fliptheclassification satisfythe domain constraints changing only mutable features .
additionally a malicious third party looks for optimizing a domain specific objective maximizethe overdraftamount.
thus wedesignageneticalgorithmthathandlesalltheseconstraintsand objectives.
we assess itsperformance and investigate in particular which fitness function combination of objectives performs the best.thus we ask rq2how effective is our fitness function at generating constrained adversarialexamples?
weanswerthisquestionbypresentingouralgorithm named coeva2 andempiricallyevaluatingitusingdifferentvariantsofthe fitness function.
havingshownthatourmethodconstitutesaneffectiveattack we aim to improve the defence mechanism of our partner s system inorder to eliminate any risk that real worldattacks succeed.
therefore we turn our attention toward improving the robustness of the css.
to achieve this we used adversarial training which consists of re training the model with generated successful adversarial examples together with their correctclassificationlabel.
suchapracticeiswidelypopularandhasbeenshowntoimprove therobustnessofmachinelearningmodels.we therefore useadversarialtrainingtoimproveourpartner ssystemandcheckthe scaleofthis improvement.hence we ask rq3how much adversarial training based on coeva2 can increase therobustness ofthesystem?
weanswerthisquestionbycheckingthesuccessrateofcoeva2 when appliedonvariousstarting points.
search based generation of constrained adversarial examples figure1displaysanoverviewofthecoeva2process.startingfrom a set of samples randomly selected from the test set we iterate over the elements of this set.
at each iteration coeva2 starts from the sampled element named the initial state and creates an initial population of new examples.
then it evolves this population with the aim offindingvalid adversarialexamples.
.
population since only a subset of the features are mutable out of in our industrial case an adversarial example can differ from the initialstateonlybythevalueofitsmutablefeatures.thus givenaninitialstate sandafeaturevectorspace i thepopulation isa subsetp ioffeaturevectorssuchthatany individual p phas thesamevalueas sforallimmutablefeatures.wecan therefore reduce the genotype of an individual as a single chromosome whichisthevectorofitsmutablefeatures.any geneisanelement ofthischromosomeandcontainsthevalueofthecorresponding mutable features.
notethatwedonotrequireanyindividualtosatisfythedomain constraints orto causea misclassification.
indeed we allow the algorithm to produce invalid and benign examples throughout the evolutionprocess.thisprovidesasmoothlandscapeforthesearch allowing it to explore efficiently this large search space.
constraint satisfaction and misclassification are actually encoded into the fitness objective functions see section .
in a way that valid adversarial examples are considered better than invalid and benign ones.
since misclassification is one of the objective the evaluation of the individuals makes use of the attacked model in a black box way using only the outputclass probabilities .
.
fitnessfunction weformulatethegenerationofconstrainedadversarialexamples as an optimization problem with four objectives.
each objective can be independently assessedthroughan objective function.
the first objective function f1models the requirementsof causing misclassification thatis maximizingtheprobabilitythatthe example is classified in the targeted class.
it is defined as the distance between the example and the incorrect class targeted by the adversarialattack.
withoutlossofgeneralityweassumethetargetclassis0 the correctclassis1 .whenprovidedwithaninput x abinaryclassification model outputs p x the prediction probability that xlies in class .
if p x is above the classification threshold a hyperparameter of the model the model classifies it in class otherwise in class0.thus wesee p x asthedistanceof xtoclass0.byseeking aninputx thatminimizesthisdistance weincreasethelikelihood of misclassification regardless of the actual classification threshold.
thus we have f1 x p x .
the second objective is to minimize the amount of perturbation measuredbetweentheinitialstateandtheadversarialexample a commonrequirementofadversarialattacks .we useaconventionalmeasureofthisamount thenormalized l2distancebetween the two inputs.
thus given aninitial state x0 the distance from an examplexandx0isgiven by f2 x l2 x x0 .
the third objective is the actual domain objective that is maximizing the approved overdraft credit amount.
by convenience we transform this objective into a normalized minimization problem.
letxbe an example and x tbe the value of the feature encoding the requested overdraft amount.
then the objective function f3 can be definedas f3 x x t thus this objective considers that the most successful solution is the one that reaches the highest overdraft amount.
in practice 1094search basedadversarialtestingandimprovement of constrainedcreditscoringsystems esec fse november8 virtualevent usa figure overview ofcoeva2.
adversarial examples are generated frombenign inputs sampled fromthe testset .
though ourpartner likemostbanks specifiesamaximaloverdraft amount above whichthe transactionisalwaysrejected.
the fourth and last objective concerns the satisfaction of the domain constraints.
as mentioned we allow individuals to violate the constraints as the evolution progresses.
yet to converge towards validadversarial examples we transformthe satisfaction of each numerical constraint into a normalized penaltyfunction to minimize representinghowfaranexample xisfromsatisfyingthe constraint.
more precisely we transform each constraint into an inequalityoftheformof c x e.g.3f gyields3f g .
if the constraint is not satisfied c x and we use the absolute value of c x as distance.
the overall distance to constraint satisfactionisthe mean ofthe normalizedindividualdistances.
thus assuming logicalandtext.
i ..k i thefourthobjectivefunctionis definedas f4 x k summationdisplay.
ipenalty x i .
in our implementation thetransformation ofthe constraints into these penalty functions is automatically handled by the framework weuse seemoreinsection .otherheuristicstocomputesuch distance to satisfaction exist and could be considered in future work.
overall we consider thatthe success of an adversarialexample canbemeasuredbythetrade offbetweenthelikelihoodofflipping theclassificationoutcome theappliedperturbation theoverdraft amountandthesatisfactionoftheconstraints.toobjectivelyquantifythistrade off wedefineourfitnessfunctionasalinearequation over the fourobjective functions that is fitness x f1 x f2 x f3 x f4 x where are meta parameters that specify the relative importance of the four objective.
overall the search process will attempttogenerateexamplesthatminimizethisfitnessfunction andsimultaneouslyfulfil the fourobjectives.
in practice we set these meta parameters according to our partner s requirements and experience.
the rationale was to reflect the domainrequirements constraints these shape the valid input space meaning that any non conforming input is invalid infeasible.
it isinput x0 an initialstate fitness afitness function ngen anumber ofgenerations l apopulation size output a population pof adversarialexamples minimizing the fitnessfunction 1p init x0 l 2forj 1tongendo 3psurvive binary tournament select p fitness 4pof fspring sbx crossover psurvive 5p psurvive polymutate pof fspring 6end 7returnp algorithm1 generation processof coeva2 imperative to satisfy the constraints and hence we make themour mostimportantobjective .
maximise overdraft for a bank minimising the potential lossofmoneyisofutmostimportance.indeed theoverdraft amount represents the potential gain for the attacker which forms the objective to maximize .
cause misclassification wealsodeemedit moreimportant tocausemisclassificationthantominimizingperturbation such that theperturbation shouldonlyserve to rank adversarialexamples that are successfulandvalid.
as revealed by our experiments our fitness function provides a feasible and practical solution to our problem.
alternatively we could have relied on search methods to automatically set the weights.
another option is to define four fitness functions one per objective thereby reducing our problem to multi objective optimization and search for pareto fronts.
while studying these alternativesisofinterest itisunlikelythattheywillmakemajordifferences under such interdependent constraints.
the github repositoryproposesbothagrid searchoptimisationoftheweightsand a non dominated multi objective approach nsga and shows limitedperformanceimprovementsincomparisonwiththeweights proposedbyour domain expert.
1095esec fse november8 virtualevent usa s.ghamizi m. cordy m. gubri m. papadakis a.boystov y. le traon anda.goujon .
generation process algorithm 1formalizes the generation process of our genetic algorithm.fromagiveninitialstate x0 wegenerateaninitialpopulation pincluding lindividuals byrandomlysettingthemutablefeatures ofx0 line .
the only constraints we enforce are the categorical constraints of the form f c ... ck and the boundary constraintsoftheform f cwherefisafeature andc c1 ... ckare constant values.
this allows reducing the numberofinvalidexampleswithoutbiasingthegeneration sincethe boundary constraintsinvolve only one feature each .
then wemakethepopulationevolveforapredefinednumber ngenof generations lines 2 6 .
at each iteration generation weevaluatethefitnessfunctionofeachindividualofthecurrent population p. this is achieved by first combining the genotype of each individual its mutable features with the immutable features ofx0.then wecaninputanyresultingexample xintothefitness function as definedpreviously andobtain the fitness valueof x. what follows is the application of selectors and alterers to form the next generation.
wefirst usetournamentselection thatkeeps thebestindividuals accordingtothefitnessfunction outofsamples oftwo line .thus halfofthe population disappear.
asforalterers werandomlyapplycrossoverandmutationoperators.
forthe crossover line4 we randomly pick pairs of individuals thatsurvivedthetournamentselection anduseasimulated binary crossover to create two new offsprings from the numericalandcategoricalfeaturesoftheparents.weassignthesame probabilisticimportancetoeachparent.attheendofthecrossover weobtainanewapopulationofsize l halfparents halfoffsprings .
next weapplymixedpolynomialmutationtoalterrandomlythe mutablefeaturesoftheoffspring line5 .eachfeaturehasaprobabilitypmtobealtered setto pm f 1inourexperiments .like theinitialisationprocessofthepopulation theappliedmutation operators take into account the nature categorical integeror real andboundariesofeachfeature.attheend ofthemutationprocess we obtain anewpopulation pjto proceedinthe nextgeneration.
after the specified number of generations passed the algorithm returns the examples of the last generation that satisfy the constraints.
in addition to these individuals the algorithm also returns the associatedvaluesoffitness andobjective functions.
empiricalevaluation .
experimentalsetup toaddressourresearchquestions weimplementedcoeva2.the tool was developed in python on top of pymoo an established frameworkformodellingandexecutinggeneticalgorithmsinpython.
ourimplementationispubliclyavailable.6allexperiments were run onour partner s internal server with about6 cores allocated for our experiments.
we set the meta parameters of the genetic algorithm as follows.
populationsizewassetto40tomaintainanacceptablecomputationtime coeva2runon4 000initialstatestakesabout24days .
exploratoryexperimentsshowedthatahigherpopulationsizedoes notaffectourresults.also westopthealgorithmafter10 000generations.thesenumberswerefoundexperimentallytobesufficientin our technique to craft successful adversarial examples.
for selection mutationandcrossover wekepttheirdefaultparameters which worked well in our case.
during our experimentation we performedexploratorytrialswithalternativesettingsandobserved minor differences.
this is in line with the study of zamani and hemmati onthesensitivityofsearch basedtestingmethods to theirhyper parameters.
allourexperimentsfocusonourpartner scasestudy i.e.generatingfeasible adversarialoverdraftrequestsapprovedbythecss.
to that end we consider our partner s real world data comprising 000requests.
the 000were usedby ourpartner to train the css s random forest.
out of the remaining the test set we keep only those which are rejected overdraft requests correctly classifiedbythecss.therationaleisthatinrealisticsettings an attackercanonlymanipulatefuturetransactionsandaccountstatus whichareinherentlyoutsidethetrainingset withtheaimtomake previously rejected requests accepted by the system and so retrievingmoney illicitly.
this leaves us with data points.
we use two random samplesofthisset eachofwhichcontains4 000initialstates customer account and transaction history the first sample is used in rq1 and rq2 while the second is used to assess the adversarial training in rq3.
thus for each rq we execute coeva2 times once oneachinitialstate.this issufficient to ruleoutrandom effects.
here it must be noted that the above settings are common to all rqs we investigate.
still the related settings required to answer eachspecificrqaregivenatthebeginningoftheresultsections i.e.
thosethat answer rq1 andrq2 sections .
.
.
.
.
rq1 constrainedpapernotandrandom search our first series of experiments consider the papernot attack extendedtoconsiderthedomainconstraintand arandomsearch thatonlyconsidersthesatisfactionoftheconstraintsasobjective aka coeva2 with the same meta parameters but using only f4 as the fitness function .
we regard these two attacks as baseline methodsthat we seekto improve.
our extension of the papernot attack differs from the original in three ways.
first it avoids visiting thenodesrelated to immutable features thus itneverchangesthesefeatures .second itchecks the satisfaction of boundary constraints on the fly each time a feature is altered.
third it attempts to satisfy the other constraints byupdatingthe dependent features.
toallowforfine grainedanalysisoftheirresults wedefinefour objectiveindicators.eachindicatorreportsthepercentageofinitial states from which a given methodcan produce avalid adversarial example.the objective corresponding to theseindicators are o1 satisfy the domainconstraints o2 cause misclassification o3 satisfy o1 ando2 o4 satisfyo3andcreatearelevantoverdraft morethan1 currency units weevaluatethetwobaselinemethodsonasampleof4 000initial states randomlypickedfrom19 274rejectedoverdrafts .thatis we run eachmethod4 times onceper sampledinitialstate .
1096search basedadversarialtestingandimprovement of constrainedcreditscoringsystems esec fse november8 virtualevent usa table objective indicators of random search and constrained papernotattacks success rate objective random search papernot constraints o1 .
.
misclassification o2 .
.
o1 ando2 o3 .
.
o3 andoverdraftamount o4 .
.
resultsareshownintable .interestingly noneofthegenerated adversarial examples by any of the two attacks are valid none of them satisfy o4 .
in the case of papernot a small number of the generated examples satisfy the domain constraints and about onefourth overall cause misclassification.
however there is none that fulfilbothobjectives.thisshowsthatstraightforwardextensions tounconstrainedattacks tomakethemconsidertheconstraints remainineffective.
inthecaseoftherandomsearch weobservethatmorethanhalf ofthereturnedexamplescausemisclassification.interestingly none ofthemsatisfytheconstraintsalthoughthisistheonlyobjective forceduponthesearch.adetailedinvestigationofthegenerated examples reveals that the perturbation amount ranges from .
to more than .
this is significantly more than the papernot attack and the aforementioned gradient based methods see our preliminary study section .
from these observations we hypothesizethatminimizingtheperturbationwouldallowrestricting the exploration within a reasonable area around the initial state.
so the search would increase the likelihood to find valid adversarialexamplesaroundthisinitialstate inparticular when initializingthe population andperformingmutation .
.
rq2 coeva2anditsfitnessfunction given thatthe baselinemethodsdonot generatevalidadversarial examples we implement and evaluate coeva2.
we execute the algorithmonthesamerandomly pickedsetofthe4 000initialstates that was used in rq1.
we also consider the same four objective indicators as inrq1 to allowfor fine grainedanalysis.
to identify and form a good fitness function we consider multiplevariantsofcoeva2 eachofwhichusesadifferentsubsetofthe objectivefunctions.inadditiontotherandomsearchguidedonly bytheconstraintsatisfaction previouslystudiedinrq1 weconsiderthreevariants thefullcoeva2 anothervariantwhereonly thef2 perturbationminimization partisremovedandanotherone whereonlythe f3 overdraftmaximization partisremoved.misclassificationandconstraintsatisfactionareminimummandatory criteria in order to generate valid examples and thus all the three coeva2variants we examine include them.
table3summarizes our results.
it shows that the variant of coeva2 with all parts of the objective function activated is the only one capable of generating adversarial examples that cause misclassification satisfy the constraints and engender relevant overdrafts.
coeva2 is successful for .
of the initial states.
thus on average only initial states are needed to perform a successful attack.
an interesting observation here is that from one initial a f1 predictionprobability lower is better b f2 perturbation l2distance lower is better c f3 overdraftamount higheris better d f4 constraintsviolation error lower is better figure2 meanvalue red andboundaries bluebetweenthe maximumandtheminimumvalues ofeachobjectivefunction over4 initial statesand for10 generations.
state we can generate more than one valid adversarial example.
this results in more than thirteen thousand of valid adversarial examples bypassing the banking system.
these results seem to suggestthatthefitnessfunctionweformiseffectiveandthatallits parts are important.
thislastpointcanbeconfirmedbytherestoftherecordedresults.theseshowthatalltheobjectivefunctionpartsarenecessary to generate successful adversarial examples.
without the perturbationminimizationobjective one before lastcolumn coeva2 generatesslightlymoremisclassifiedexamples for31.
ofthe 1097esec fse november8 virtualevent usa s.ghamizi m. cordy m. gubri m. papadakis a.boystov y. le traon anda.goujon table objective indicatorsachieved by coeva2 usingdifferentfitnessfunctions.
objective indicators random search f4 coeva2 all coeva2 f1 f3 f4 coeva2 f1 f2 f4 constraints o1 .
.
.
.
misclassification o2 .
.
.
.
o1 ando2 o3 .
.
.
.
o3 andoverdraftamount o4 .
.
.
.
figure adversarial training process.
initialstatesinsteadof27.
butnoneofthemsatisfiestheconstraints.
this confirms our previous hypothesis that not restricting the perturbation makes the algorithm create examples much different from the original valid example.
in highly constrained search space this increases thelikelihood of generating invalid examples.
finally withouttheobjectiveofmaximizingtheoverdraftamount lastcolumn coeva2generatesexamplessatisfyingtheconstraints in every case.
however only .
of them cause misclassification.
none of these achieve a sufficient overdraft amount currencyunits .thisisbecausethealgorithmappliesonlysmall variationsandonlytotheothermutablefeatures whichreduces the likelihoodofviolating the constraintsandofmisclassification.
tobetterunderstandhowcoeva2handlesthetrade offbetween the four objective functions we show in figure 2how the value ofeachofthem evolvesoverthegenerationswhenappliedtothe initial states for which it managed to generate valid adversarial examplesover 000generations.
at each generation we average the objective function scores obtainedbythecurrentpopulation.thusweobtain foreachinitial stateandeachobjectivefunction 000values onepergeneration .
then we show the minimum mean and maximum values of each averaged score over all the initial states.
the red line is the mean whereas the blue area denotesthe minimal andmaximal scores.
the four plots confirm that constraint satisfaction is the first objective fulfilled by the algorithm and it does so always in the early generations after about .
the figure also shows that theoverdraftamountisthesecond mostdominantobjectiveand is always achieved within the first generations reaching currencyunits themaximumamountauthorizedbythecss.all the individuals of the population in all the next generations inheritthismaximumvalueandkeepsatisfyingtheconstrains.meanwhile thel2distance fluctuates around .
which is times less than thepapernotattack.theaveragepredictionprobabilitystabilizes around .
whichisslightly belowthe prediction threshold.
interestingly taken together these results suggest that a careful choiceoftheinitialstateallowscoeva2tofindvalidadversarial examples after a limited number of generations .
moreover theseexamplesmakethesystemoverdraftofhighamount close to the strict maximum authorized by thebank .
while frightening theseresultsalsomeanthatwecanfocusonspecificinitialstatesto buildcountermeasures andincreasethe robustnessof the system.
overall ourresultscorroboratetheconclusionthatallfourparts ofourfitnessfunctionplayacrucialroleincraftingvalidadversarial examples.atthesametime ourapproachdemonstratesthatitis indeed feasible to craft valid adversarial examples in real world criticalsystems.thismotivatestheneedforappropriatedefence mechanisms to reinforce the robustness of the system against such attacks.we investigate this inthe nextresearch question.
.
rq3 adversarialtraining figure3shows the adversarial training process we designed to improve the robustness of our partner s system against our previouslysuccessful adversarialattack.first wegenerate4 000valid adversarialexamples overdraftsacceptedbythemodelthatshould be rejected and re train the model to classify them correctly.
to do so we use the initial states used in rq2.
after re training themodel weexecuteagaincoeva24 000timesusingeachtime a new initial state that was not used to produce the adversarial 1098search basedadversarialtestingandimprovement of constrainedcreditscoringsystems esec fse november8 virtualevent usa trainingset.wecheckwhethertheattackmanagedtogenerateany adversarialexamples.
itresultsthat the adversarial training makes coeva2 incapable of generating valid adversarial examples.
thus our adversarial training method grants protection against the very same attack thatwaspreviouslyeffective.thisisapositiveoutcomethatcanbe used by our partner in order to improve the robustness of the css.
as our system is still in testing phase it is used in parallel to the original model.
thus an overdraft approved by the existing model and rejected by ours is likely to be an adversarial example.
in all the othercases one should followthe decision ofthe firstmodel.
.
threatsto validity validitythreatstoourresultsmayarisebytheimplementationswe used.
thus potential bugs either in our or the underlying frameworks may influence our results.
we do not consider this threat as important since we thoroughly checked our code and many of the adversarial examples we generated were verified by our partner.moreover werelyonwidelyusedandrelativelyreliable frameworks scikit learn and tensorflow for the machine learning algorithms and reputable libraries like the adversarial toolbox fromibm foradversarialattacksandpymoofromthemichigan stateuniversity7for multi objective genetic algorithms.
anotherpotential threatconcernsthespecificityofthedataset and classification model we used.
both are from our partner s real production system and since our partner is a major player its data andpracticesshouldberepresentativeofothercompanies.moreover averificationofhistoricaldatarevealedremarkableresultsfor thelastyear.duetothespecificityofourindustrialcase theresults we obtained may not fully transfer to other industries namely outside of credit scoring domain .
nevertheless our endeavour shows that the problem exists in the real world and formalises it to facilitate the design of similar solutions to other cases.
moreover our algorithm and approach have been designed to be generic enough tobeadjustedtootherusecases andweprovidethealgorithmand allthe hyper parametersofour approach for reproducibility.
toreducetheimpactofrandomeffects allourexperimentsconsider4 000differentinitialstates customeraccountandtransaction history andrunthestudiedmethodsonceperstate.sincewemake 000independentexecutions multiplerunsperexecutioncanonly make a difference in isolated cases and not in the overall performance expected case .
this is because initial states can be seen as independent repetitions.
inourexperiment weperformasinglerunperstatesincewe focus on trends.
thus we run our approach on cases and found adversarial cases in .
these are sufficiently large numbers to ruleout randomeffects.
yet multiple repetitionsand more generallyadditionalsearchtime budgetmayimprovetheresultsof the search.
we run the randommethod times initial states generations with individuals and found adversarial cases whichdemonstrates theineffectiveness of the random method.
conclusion inthispaper westudiedtheproblemoftestingamachine learningbasedindustrialcredit scoringsystemagainstmalicious inputs.in particular weconsideredthecasewhereanattackermanipulates therelatedfeatures withtheaimtocauseamisclassificationbya binaryclassificationmodel.tothisend weevaluatedthecurrent state of the artadversarialattacks bothinafull knowledgecontext andalimited knowledgeusingourpartner s datasetandsystem.
basedonthisstudy weshewthatapproachesproposedintheliteraturecanindeedgenerateadversarialexamplesbutthesearenot usefulsincetheydoaccountfordomainconstraints.thislimitation of the methods results in generating implausible examples.
to deal withthissituation weproposedasearch basedmethodovercoming theselimitations.weshowedthatournewattackconstitutesareal security threat to fintech systems relying on machine learning.
at the same time we exploit this threat to improve the defence mechanisms of our industrial system.
in the end the system becomes immuneto our attack.
artifact our library is available on github and can be extended to any constrainedadversarialattacktask.the twomain branches are fse thisbranchtacklestheimplementationpresentedinthis paper and the experiments to reproduce our results.
our datasetbeingproprietaryandprivate weprovide asimilar open sourcedataset lendingclubloaddataset8toevaluate our approach.
the tool is built around configuration files locatedin configurations folder whereyoucandefinethe constraintsofyour problem your objective functions etc... the folder srccontains the actual implementation of our algorithm whilethe folder experiments provides scripts to easily run eachofthe research questions experiments.
master this branch is the ongoing iteration of the library.
it provides an extension of the approach using grid and random search to optimize the weights of each objective andmoeva2annsga extensionofourapproachthat usesnon dominated multi objective evolution.thisbranch will contain the stable evolutions of the library in particular allelements mentionedas future orongoing work.