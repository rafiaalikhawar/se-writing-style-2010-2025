flexeme untangling commits using lexical flows profir petru p rt achi profir petru.partachi.
ucl.ac.uk university college london london united kingdomsantanu kumar dash s.dash surrey.ac.uk university of surrey guildford surrey united kingdom miltiadis allamanis miallama microsoft.com microsoft research cambridge cambridgeshire united kingdomearl t. barr e.barr ucl.ac.uk university college london london united kingdom abstract today most developers bundle changes into commits that they submit to a shared code repository.
tangled commits intermix distinct concerns such as a bug fix and a new feature.
they cause issues for developers reviewers and researchers alike they restrict the usability of tools such as git bisect make patch comprehension more difficult and force researchers who mine software repositories to contend with noise.
we present a novel data structure the nfg a multiversion program dependency graph augmented with name flows.
a nfg directly and simultaneously encodes different program versions thereby capturing commits and annotates data flow edges with the names lexemes that flow across them.
our technique flexeme builds a nfg from commits then applies agglomerative clustering using graph similarity to that nfg to untangle its commits.
at the untangling task on a c corpus our implementation heddle improves the state of the art on accuracy by0.
achieving .
in a fraction of the time heddle is32times faster than the previous state of the art.
ccs concepts software and its engineering software version control mathematics of computing graph algorithms computing methodologies kernel methods general and reference general conference proceedings .
keywords graph kernels clustering commint untangling acm reference format profir petru p r t achi santanu kumar dash miltiadis allamanis and earl t. barr.
.
flexeme untangling commits using lexical flows.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november virtual event usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
introduction separation of concerns is fundamental to managing complexity.
ideally a commit to code repositories obeys this principle and focuses on a single concern.
however in practice many commits tangle concerns .
time pressure is one reason.
another is that the boundaries between concerns are often unclear.
murphyhill et al.
found that refactoring tasks are often committed together with code for other tasks and that even multiple bug fixes are committed together.
tangled commits introduce multiple problems.
they make searching for fault inducing commits imprecise.
tao et al.
found that tangled changesets commits hamper comprehension and that developers need untangling changeset decomposition tools.
barnett et al.
confirmed this need.
herzig et al.
studied the bias tangled commits introduce to classification and regression tasks that use version histories.
they found that up to of bug fixes in java systems consisted of multiple fixes in a single commit.
they also found that using a tangled version history significantly impacts regression model accuracy.
in short tangled commits harm developer productivity two ways directly when a developer must search a version history and indirectly by slowing the creation of tools that exploit version histories.
version histories permit a multiversion view of code one in which multiple versions of the code co exist simultaneously.
le et al.
built on principles described by kim and notkin for multiversion analysis they constructed a multiversion intraprocedural control flow graph and used it to determine whether a commit fixes all nversions .
this task is important when multiple versions are active as in software product lines and the patch fixes a vulnerability.
inspired by le et al.
we define a pdg a multiversion program dependence graph pdg a graph that combines a program s data and control graphs .
we hypothesise that identifiers differentiate concerns.
we harvest names that are used together in a program s execution as in this statement takehome tax salary to augment our pdg and produce a nfg.
a desirable property of our nfg is its modularity.
it allows projecting any combination of data control or lexeme.
consequently we could effortlessly reproduce barnett et al.
s and herzig et al.
s methods to explore the design space in tooling for concern separation in commits.
we introduce flexeme a novel approach to concern separation that uses the nfg.
we group edits into concerns using the graph similarity of their neighbourhoods.
we base this on the intuitionesec fse november virtual event usa profir petru p rt achi santanu kumar dash miltiadis allamanis and earl t. barr that nodes are defined by the company they keep their neighbourhoods and cluster them accordingly.
thus we reduce the concern separation problem to a graph clustering task.
for clustering we start by considering each edit in a commit as an separate concern then use graph similarity to agglomeratively cluster them.
we compute this similarity using the weisfeiler lehman graph kernel .
we realised flexeme in a tool we call heddle1.
developers can runheddle to detect tangled commits prior to pushing them or reviewers can use it to ask developers to untangle commits before branch promotion.
we show that heddle improves the state of theart accuracy by .
and run time by 32times or .
we also demonstrate the utility and expressivity of our pdg construct by adapting herzig et al.
s confidence voters cv to use the pdg rather than diff regions the resulting novel combination which we call pdg cv improves the performance and lowers the run time of herzig et al.
s unmodified approach.
in summary we present two novel data structures the pdg a multiversion program dependence graph and nfg which augments a pdg with lexemes theflexeme approach for untangling commits that builds a nfg from a version history then uses graph similarity and agglomerative clustering to segment it and heddle a tool that realises flexeme and advances the state of art in commit untangling in both accuracy and run time.
all of the tooling and artefacts needed to reproduce this work are available at example localising a bug with git bisect to determine a bug inducing commit or reviewing a changeset during code review in presence of tangled commits can make the task unnecessarily difficult or even impossible .
further as herzig et al .
found tangled commits have a statistically significant impact on the performance of regressions methods used for defect prediction.
barnett et al .
determined that developer productivity benefits from tools that can propose changeset decompositions.
in light of this it is natural to ask how do different code entities co occur within a concern?
the code entities of a concern tend to be in close proximity with each other in both the control and data flow graphs.
barnett et al.
exploited this by using def use chains which offer a shortrange view of these connections.
however as shown in figure connectivity through the data flow graphs on its own is insufficient to demarcate concerns.
indeed this observation is reflected in the relatively lower accuracy rates on concern separation reported in barnett et al .
compared to herzig et al .
the concerns and consisting of the hunks 1a 1d and 2a 2b respectively could be conflated as they are method invocations of the same driver class.
the conflation might occur even though hunks 1b 1cand1d are connected via the use of the colors.menu and colorscheme which provides counterweight to conflating concerns and .
control flow can help delineate regions or constructs that handle specific types of concerns.
for example a loop could be performing 1a heddle is wire or cords with eyelets that hold warp yarns in a place in a loom.
while it does not untangle a heddle prevents tangles so we have named our tanglepreventing tool after it.
namespace terminal this.baritems baritems this.host host colorscheme colors.menu 1a canfocus true public override void redraw rect region driver.setattribute colors.menu.normal 1b drawframe region true driver.setattribute colorscheme.normal drawframe region padding fill true for int i i baritems.children.length i var item baritems.children move i driver.setattribute item null ?
colors.base.focus 1c i current ?
colors.menu.focus colors.menu.normal driver.setattribute item null ?
colors.base.focus i current ?
colorscheme.focus colorscheme.normal for int p p frame.width p if item null driver.addspecial specialchar.hline 2a driver.addrune driver.hline else driver.addch 2b driver.addrune if item null continue move i drawhotstring item.title i current?
colors.menu.hotfocus 1d colors.menu.hotnormal i current ?
colors.menu.focus colors.menu.normal i current?
colorscheme.hotfocus colorscheme.hotnormal i current ?
colorscheme.focus colorscheme.normal figure a diff with two tangled concerns a the change of the drawing api all other changes and b the migration from using chars and special chars to runes the two changes related to addrune .
attempting to disentangle this diff with state of the art tools relying on du chains fails because the tangled changes are connected in the def use chain pertaining to driver and are in close proximity in the file.
using a pdg allows us to additionally exploit control flow information to aid untangling.flexeme untangling commits using lexical flows esec fse november virtual event usa a specialised computation that forms a single concern on its own.
we see an example of such a loop in figure .
the for loop captures the process by which a screen line is generated and is strongly related to how on screen characters are handled 1aand1b .
this suggests that using a program dependency graph pdg which encapsulates both control and data flow as a basis for performing commit untangling overcomes some of the shortcomings of using the data flow alone.
the pdg provides evidence that 1aand1b could be a part of the same concern because of control flow.
additionally the pdg also tells us that 1cand1dcould be a part of the same concern by virtue of data flow through colors.menu and colorscheme .
however it may be observed that the link with 2a 2b is still strong due to flows through driver .
lexemes in the two concerns in figure provide strong evidence for their separation.
while concern uses set methods in driver concern uses add methods.
this evidence is missed by pdgs which discard lexical information.
developers tend to use dissimilar names for different tasks.
dash et al .
leveraged this observation to augment data flow with lexical information to successfully identify type refinements.
in our work we take a similar approach and use lexical information to separate concerns.
our approach to introducing lexemes in our pdg representation is similar to the name flows construct of dash et al .
.
while they augmented data flow with lexemes we augment pdgs and a description of how we achieve this follows.
concerns as lexical communities given consecutive versions of some code flexeme constructs their pdgs and overlays them adding name flows to build a nfg.
we feed the nfg to a graph clustering procedure to reconstruct atomic commits.
a nfg naturally captures flows that bind concerns together such as data and control flows.
additionally it also captures natural correlation in names that developers choose when addressing a given concern.
figure overviews how flexeme constructs and uses a nfg.
for a sequence of contiguous versions we generate a pdg first with the help of a compiler.
we then combine these pdgs to form a multi version pdg which we call a pdg.
we then decorate the pdg with version specific name flow information to obtain a nfg.
we feed the nfg to agglomerative clustering.
we use graph similarity to separate concerns across the original set of contiguous versions.
we discuss the details of the nfg construction in section .
section .
and section .
.
we discuss the graph clustering approach in section .
.
.
multi version name flow graphs we now formally define the pdg pdg and nfg in order to bootstrap discussion on the nfg construction.
definition .
.
program dependency graph pdg .flexeme s pdg is a directed graph with node set nand edge set es.t.each node n nis annotated with either a program statement or a conditional expression each edge e ehas an optional annotation representing the name or the data that flows along it and a kind that describes the relationship type data or control.definition .
.
multi version program dependency graph pdg .
a pdgp qis the disjoint union of all nodes and edges across all versions in .
pdgp pis the pdg at version p. definition .
.
name flow graph nfg .flexeme s nfg is a standard dataflow graph g n e augmented with name flows the raw lexemes of the literals and identifiers in a program text that originate at some node flow across edges and collect in downstream nodes.
a name flow labels an edge with those lexemes that flow across it and a node with those that either originate at it or flow into it.
we re use nfg from dash et al.
s refinym .
to a first approximation lexemes flow along def use chains and collect in the variables on the lhs of assignments.
definition .
.
multi version name flow graphs nfg .
a nfgp qis the pdgp q augmented with name flows if an edge exists in both the pdg and the nfg of a version we augment the pdg edge with the corresponding name flow.
inspired by le and pattison s multiversion intraprocedural graphs we are the first to propose and construct pdgs.
to construct a pdg we start from the initial version considered.
for each subsequent version we make use of line span information in the pdg and unix diff on the source files to determine changed and unchanged nodes making flexeme language agnostic.
changed nodes are introduced to the pdg as they appear in the new version.
pdgs retain nodes deleted across the versions a pdg spans.
deletion becomes a label.
we match unchanged nodes between the nodes of the pdg and the new version.
to match we use string similarity to filter candidates and we use line span proximity to rank them section .
.
for nodes the new version deletes we backpropagate the delete label to edges flowing into them.
to add edges we consider all unmatched edges in the new version then match their source and target either to existing pdg nodes or when a either the source or target does not exist in input pdg match it to a fresh node section .
.
finally to obtain a nfg we endow the pdg with name flow information for each of the versions considered by matching nodes using their line spans.
.
anchoring nodes across versions to integrate a fresh pdg gj we start with the patch pij.
we view each hunkh pijas a pair of snippets s i s j where version i deletess iand version jaddss j. snippetss iands jdo not exist for hunks that only add or only delete represents these patches.
accounting for s iis straightforward we do not update the nodes in theg1 ithat fall into s i. accounting for s jis non trivial much like patching utilities we need a notion of context.
for alls j we introduce fresh nodes in the pdg.
however we cannot anchor these nodes until we identify counterparts for nodes ingjthat were untouched by pij.
identifying untouched nodes ingiis straightforward we can simple check locations in pijagainst the location of each node in gj.
all touched nodes from gjare treated as new added nodes and need to be introduced in the pdg.
identifying the counterpart in giof an untouched node ingjrequires a notion of node equivalence.esec fse november virtual event usa profir petru p rt achi santanu kumar dash miltiadis allamanis and earl t. barr figure overview of flexeme s nfg construction and concern separation.
definition .
.
node equivalence .
given a node vjin agjand a candidate node viing1 i vj vi p q r a a .f p q t here a returns all nodes adjacent to the node kin a graph.
ris a variant of the stable roommates problem where nodes drawn from a are matched with nodes drawn from a .
each node ina has an affinity for nodes in a proportional to the similarity of lexemes at the nodes.
the operator rconsiders these affinities and tries to match each node with the one it has the highest affinity for.
by construction ralways returns a oneto one match even though two different nodes aandbmay have a strong affinity to a third node c. in such a case either aorbwill be matched with cbut not both the one that is not matched to its highest preference defined in terms of affinity is matched to the next node from its preference list.
we further require that lexical similarity computed by the function f is above the threshold t. this lets us control the level of fuzziness while matching nodes.
in this work we have chosen fto be string edit distance and set t .0thus requiring exact matches.
.
integrating nodes across versions once counterpart nodes are identified using a notion of node equivalence the next task is to store the location information for the untouched nodes in gjat theirs counterpart and mark the location with version j. finally we add all the nodes pijadds to the pdg and create edges between them and the counterparts of their parents and children.
we demonstrate the pdg construction in figure .
we show the pdg for two versions of an application and .
since version is our initial version in this example it is also our pdg g1.
we have omitted the data flows in the pdg for brevity.
each node in the pdg contains a list of location version tuple the location information has been supressed for simplicity.
the patch above the two pdgs is the diffof the two versions.
we have two snippets in the patch s 1for the snippet that is to be deleted in ands 2the snippet that is to be added in .
accounting for the deleted line comes for free as we store locations for snippets across versions.
all we need to do is to check the location information fors 2against the span of the nodes in the g1.
fors we need to search for equivalent nodes across the two versions.
we perform fuzzy matching on lexemes in nodes shortlisted using location information as detailed above.
in the case of s we identify the call expressions moveand driver.addch ... as parents and children respectively for s .
mergings 2into the pdg shown on the right is then a straightforward task of drawing edges between nodes and their parents children.
once we obtain this pdg representation we perform the untangling task in a reconstructive manner.
.
identifying concerns we start by assuming each change is atomic and iteratively merge changes that are similar enough.
at a high level we expect similar nodes to have similar neighbourhoods .
to measure this we build thek hop neighbourhood2 for each node.
we then cluster by similarity of these neighbourhoods.
to compute graph similarity we use the weisfeiler lehman graph kernel which builds on top of the weisfeiler lehman graph isomorphism test .
for a pair of graphs the test iteratively generates multi set labels.
when two graphs are isomorphic then all the sets are identical.
formally let the initial vertex labelling function of the graph bel0 v g l wherelis the space of all node labels.
at stepi letli v li v v n v wheren v is the set of neighbours of vertex v. at each iteration i this process labels the nodevwith a set comprising the labels of all of v s neighbours.
this set becomes the new label of that node.
since isomorphism testing can diverge we bound it to niterations and obtain the sequence g0 g1 ... gn .
a positive semi definite kernel on the non empty set xis a symmetric function k x x r s.t.n i 1n j 1cicjk xi xj n n x1 ... xn x c ... cn r. this function can take the arguments in either order and for any parametrization by real constants has non negative weighted sum over all inputs.
a graph kernel is a positive semi definite kernel on a set of graphs.
when a kernel takes a set of graphs g as input we define thek g ij k gi gj gi gj g to compute the matrix of pairwise kernel values.
letgbe the set of graphs over which we wish to compute graph based similarity and let k g r g r g be a graph kernel.
then the wl graph kernel becomes kwl g k g0 k g1 ... k gn where g0 g1 ... gn is obtained by applying nsteps of the isomorphism test to each graph in g 2in our experiments we consider the k hop neighbourhoods.flexeme untangling commits using lexical flows esec fse november virtual event usa driver.setattribute hasfocus?
colors.base.hotfocus colors.base.hotnormal driver.setattribute hasfocus?
colorscheme.hotfocus colorscheme.hotnormal hot pos !
move hot pos drivers.setattribute hasfocus?
colorscheme.hotfocus colorscheme.hotnormal driver.addch hot key exit redraw terminal.rect 1hot pos !
move hot pos drivers.setattribute hasfocus?
colors.base.hotfocus colors.base.hotnormal driver.addch hot key exit redraw terminal.rect 2hot pos !
move hot pos drivers.setattribute hasfocus?
colorscheme.hotfocus colorscheme.hotnormal drivers.setattribute hasfocus?
colors.base.hotfocus colors.base.hotnormal driver.addch hot key exit redraw terminal.rect figure construction of a pdg from two versions and of a program.
version is obtained from version by application of the patch shown in the program.
each node is annotated with the version number it is present in.
the wl graph kernel kis a meta kernel that extends an underlying kernel.
we want a subtree wl graph kernel that counts the number of identical rooted subtrees for each node in the graph of the same depth as the iteration.
in our case this maps to identical downstream behaviour from each node in terms of each of the flows considered.
to achieve this behaviour we set kto be the vertex label histogram kernel and encode outgoing flow types in the label function.
this kernel is defined as follows let be a function that embeds the graph into a vector space often called a feature map in literature and let be the inner product then g f fi v v v g li l lv v li k g ij gi gj for clustering we opt for agglomerative clustering like herzig et al.
herzig and zeller .
with node neighbourhood pairwise similarity information we can build an affinity i.e.a pair wise distance matrix for clustering trivially by simply inverting the value i.e.
similarity.
section .
details the implementation.
4heddle heddle realises flexeme .heddle first constructs a pdg for each input file and combines them into a nfg.
heddle then decomposes the nfg into a forest and uses graph kernels to compute distance matrices which we input into agglomerative clustering.
we close by describing how a project could adopt heddle .
.1 pdg construction we implement both name flow extraction and pdg extraction in roslyn the open source compiler for c and visual basic from microsoft.
we store the pdg in graphviz dot format.
we then implement the pdg merging procedure as described above over the dot files.
this allows us to reuse the merging procedure it is language agnostic.
one need only provide pdgs and optionallyname flows as dot files.
to enable the merging process we store the origin line span3and method membership information in the nodes along with the usual data associated with such graphs i.e.
expression information and edge kind.
to obtain textual diffs needed for nfg construction we make use of the unix diff tool.
by default heddle constructs one nfgs per file.
to mitigate the problems cross file dependencies cause and reduce the cost of untangling heddle merges all graphs associated with a commit into a single structure.
this merge uses node equivalence definition .
when operating on files that share a namespace.
a key difference in the same version cross file setting is that we need to copy over both types of changed nodes and add the edges similar to the added nodes scenario described in section .
to simplify our code our implementation of pdg extraction does not consider goto statements in the control flow graph this does not matter much in practice as goto statements are very rare in our corpus.
.
graph node clustering we use grakel for the weisfeiler lehman wl graph kernel implementation and leave the number of iterations of the isomorphism tests at the library s default of .
we set the underlying kernel to vertex histogram graph kernel to obtain the same behaviour as the subtree wl graph kernel.
for agglomerative clustering we use scipy .
we precompute the affinity matrix by using the wl kernel similarity.
we call the clustering method with the linkage parameter set to complete which mimics the behaviour described in herzig et al.
i.e.when two groups are merged the maximal distance from any member of the group to any other group is kept as the new distance.
we stop merging groups when they are less than .5similar to any other group instead of providing oracle information to the method.
this 3we consider code snippets at line granularity.esec fse november virtual event usa profir petru p rt achi santanu kumar dash miltiadis allamanis and earl t. barr models the fact that in practice developers do not know how many concerns a commit contains.
code for both pdg construction and node clustering is available online4.
.
deployability heddle takes ten seconds on average to untangle a commit section .
and 45s on average to construct and merge the pdg for a commit into a pdg.
this is beyond the one second limit suggested by nielsen for processes that allow a user to feel like operating directly on data which suggests that our tools should be onboarded into a process that is out of band with regards to developer attention.
an example of such a process is the build automation within continuous deployment.
heddle could be added as an additional pass at the end of the build process providing an untangle report for the code reviewers ready to be inspected when the review process starts.
further on boarding heddle in such a manner makes it independent of the workflow and tooling choices made by the developers the system would only need to be deployed on the build servers.
the report provided would allow reviewers to better focus on the different parts of the patch and aid patch comprehension.
there is an initial onboarding cost requiring generating nfgs for all source files in the code base.
however our construction is incremental and for any fresh patch that needs integration into the nfg we only need to consider the files touched by the patch.
experimental design in this section we discuss how we constructed a dataset measure untangling performance and our reproduction of two baseline methods.
.
corpus construction to construct our corpus we reuse herzig et al .
methodology who artificially tangle atomic commits.
therefore we consider commits that have been committed by the same developer within days of each other with no other commit by the same developer in between them.
change namespaces whose names have a large prefix match.
contain files that are frequently changed together.
do not contain certain keywords such as fix bug feature implement multiple times.
the first criterion mimics the process by which a developer forgets to commit their working directory before picking up a new task.
the next criterion is an adaptation of herzig et al.
s change close packages criterion to the c environment.
the third considers files that are coupled in the version history thus creating a tangled commit not too dissimilar from commits that naturally occurred.
the intuition being that if commit atouches file faand commitbtouches file fb s.t.faandfbare frequently changed before coupling thenaandbshould be tangled.
the final criterion is a heuristic to ensure that we do not consider tangling commits that we are certain are not atomic.
we add this condition to mitigate the problem of tangling actually tangled commits which project statistics.
the last revision indicates the commit at which we performed the git clone .
project loc of commits last revision commandline 67f77e1 commonmark f3d5453 hangfire 175207c humanizer 604ebcc lean 71bc0fa nancy dbdbe94 newtonsoft.json 4f8832a ninject 6a7ed2b restsharp b52b9be would cause an issue when computing ground truth.
overall this artificially created corpus mimics some of the tangled commits we expect developers to make specifically it captures the intuition of a developer committing multiple consecutive work units as a single patch.
section discusses the threat this poses to heddle s validity.
following the above procedure we obtain a shortlist of chains of shas of varying length for nine c systems we show project statistics in table .
these shas refer to atomic commits.
we sanity check that they are atomic by uniformly sampling commits from our corpus and examining each commit for up to five minutes.
we found to be atomic of the tangled commits refactor comments which are invisible and therefore atomic to heddle and tangled commit due to merging content from a different versioning system svn in a single commit.
from this study we extracted two heuristics that we used to filter out non atomic commits.
specifically we excluded all merge commits and those that generate pdgs that have no changed nodes.
we attempt to create tangled commits by selecting the shas in the tail of these chains and git cherry picking them onto the head.
we then mark the originating commit in the tangled diff using the individual atomic diffs as not all selections are successful.
some of the successful selections may not have changes from all tangled commits as later commits may shadow them.
therefore we perform a final pass to learn the actual number of surviving concerns.
in the end we built two sets of tangled commits those that tangle and those that tangle .
this models the most common numbers of tangled concerns in the wild .
table shows the final statistics for our corpus where the number of concerns is the count of surviving concerns at the end of the selection process.
we report all successfully generated data points and detail in section the subsets on which we compared any two methods when at least one of them did not run on the full corpus due to time outs.
we do not treat time outs as a zero accuracy result but drop them from consideration.
we remark that the primary source of time outs is the computational cost of running our reproduction of herzig et al.
.
.
experimental setup our experiments assess how well our method recovers the original commits compared to the baseline methods proposed by barnett et al.
and herzig et al.
.
additionally we measure the runtime cost of the different methods.
for this all methods are runflexeme untangling commits using lexical flows esec fse november virtual event usa table successfully tangled commits.
project concerns overall commandline commonmark hangfire humanizer lean nancy newtonsoft.json ninject restsharp overall in isolation on the same high end laptop i7 8750h .
ghz gb ram mhz and we compute accuracy for all methods as follows a correctly labeled nodes nodes in graph.
both baselines as well as heddle may recover an arbitrary permutation of the ground truth labels.
to avoid artificially penalising them we first use the hungarian algorithm to find the permutation that maximises accuracy.
consider the ground truth should a tool output a na ve approach would award it .0accuracy while a trivial permutation of the labelling function reveals that this is indeed .0accuracy.
we report this maximal accuracy for each method.
for the purpose of timing we perform one burn in run of commit segmentation followed by repeats that are used to compute the runtime cost.
we then obtain the speed up factor as a nonparametric pairwise comparison between the methods.
notably we do not include the cost of the static analysis required for each method rather only the cost of segmentation.
this is due to deriving the required program representations for each method as a projection from the nfg.
.
reproducing barnett et al.
and herzig et al.
in order to use barnett et al.
s method as a baseline we had to reimplement it because its source is not public.
their method rests on def use chains.
they retain all def use chains that intersect a diff hunk in a commit.
to obtain this we first recover the dataflow graph and then we separate the flows by kill statements such as assignments.
in a pdg this becomes a def use chain projected onto a diff hunk.
two chains are equivalent if a they are both changed and are both uses of the same definition or b they are a changed use of a changed definition.
under this partition they divide the parts into trivial and nontrivial.
all diff regions in a trivial part fall within a single method.
to avoid overwhelming developers with chains that are highly likely to be atomic they do not show trivial parts implicitly they are assuming that developers can see and avoid method granular tangling.
in contrast we like herzig et al.
consider method granular tangling so our re implementation does not distinguish trivial and non trivial parts.to reproduce herzig et al.
s method we reconstruct the call graph by collapsing into hypernodes by method membership we recover the dataflow from the pdg and we additionally generate an occurrence matrix specifying the files changed by a commit as well as file sizes in terms of number of lines.
finally we compute a diff region granular corpus for all the successful tangles as the herzig et al.
algorithm works at a diff region granularity.
using this information we construct a distance matrix for each tangled commit.
this distance matrix is populated by the sum of the distances from each individual voter.
all confidence voters are identical to the original paper with one exception.
we replaced package distance by namespace distance we do however compute it in the same manner.
at evaluation time we also provide the number of concerns to be untangled.
this is known by construction as in the original paper.
we perform agglomerative clustering on the resultant matrix using complete linkage i.e.taking the maximum distance over all diff regions within a cluster.
we also create a version of herzig et al.
s confidence voters method that operates directly on pdgs which we call pdg cv.
the last stage here is not dissimilar to flexeme with the remark that we still provide herzig et al.
s approach with oracle access to the number of concerns while flexeme requires only a similarity threshold.
we implemented the voters so that only file distance and change coupling require auxiliary information.
this is precomputed from the git history of the project under analysis.
every other voter call graph distance data dependency and namespace distance are computed on demand only for the nodes that we consider for merging.
for both baselines as well as heddle we measure only the time taken to untangle and not the construction of auxiliary structures.
we exclude the construction time as we derive the du chains callgraphs and dataflow graphs from our pdg.
results in this section we compare heddle against our two baselines in terms of accuracy and runtime.
to implement our baselines we reproduced the methodology and tooling from herzig et al.
and barnett et al.
.
we show that heddle outperforms in both accuracy and run time our reproduction of herzig et al.
s method.
we report comparisons between tools only on the subset of datapoints on which both tools run to completion.
.
untangling accuracy when recovering the original partition of the nfg from our artificial tangle of code concerns heddle achieves a median accuracy of0.81and a high of .84on the project nancy it outperforms herzig et al.
by0.14and trails pdg cv only by .02while scaling better to big patches.
unlike herzig et al.
heddle achieves this result without resorting to heuristics or manual feature construction.
heddle outperforms both baselines in accuracy the difference being statistically significant at p .
wilcoxon pair wise test and matches the performance of pdg cv the new technique we have built from grafting herzig et al.
s confidence voters on top of our nfg p .
wilcoxon pair wise test .
unlike heddle the other approaches consider file granular features.
specifically esec fse november virtual event usa profir petru p rt achi santanu kumar dash miltiadis allamanis and earl t. barr table median performance of untangling commits for each method by project and number of tangled concerns.
the performance differences are significant to p .001for all overall results according to a two tailed wilcoxon pair wise test on the common set of data points except pdg cv vs heddle which is significant to p .
.
entries indicated by a signify that there was no relevant data point to report the performance on and those indicated by x indicate time outs.
project name barnett et al.
herzig et al.
pdg cv heddle nfg wl overall overall overall overall commandline .
.
.
.
.
.
.
.
.
.
.
.
commonmark .
.
.
.
.
.
.
.
hangfire .
.
.
.
.
.
.
.
.
.
.
.
humanizer .
.
.
.
.
.
.
x .
.
.
.
lean .
.
.
.
.
.
.
.
.
.
.
.
nancy .
.
.
.
.
.
.
.
.
.
.
.
newtonsoft.json .
.
.
.
.
.
.
.
.
.
.
.
ninject .
.
.
.
.
.
.
.
restsharp .
.
.
.
.
.
.
.
.
.
.
.
overall .
.
.
.
.
.
.
.
.
.
.
.
table median time taken s to untangling commits for each method by project and number of tangled concerns up to sig figs.
the runtime cost differences are significant to p .001for all overall results according to a two tailed wilcoxon pair wise test except pdg cv vs heddle where the difference is not statistically significant p .
.
entries indicated by a signify that there was no relevant data point to report the performance on and those indicated by x indicate time outs.
project name barnett et al.
herzig et al.
pdg cv heddle nfg wl overall overall overall overall commandline .
.
.
.
.
.
.
.
.
.
.
.
commonmark .
.
.
.
.
.
.
.
hangfire .
.
.
.
.
.
.
.
.
.
.
.
humanizer .
.
.
.
.
.
.
x .
.
.
.
lean .
.
.
.
.
.
.
.
.
.
.
.
nancy .
.
.
.
.
.
.
.
.
.
.
.
newtonsoft.json .
.
.
.
.
.
.
.
.
.
.
.
ninject .
.
.
.
.
.
.
.
restsharp .
.
.
.
.
.
.
.
.
.
.
.
overall .
.
.
.
.
.
.
.
.
.
.
.
they compute a probability that two files are changed together and by proxy tackle the same concern from the version history.
this allows them to better cluster related changes that span multiple files.
heddle in such cases relies only on the existence of call edges between the different files when projected onto a nfg.
further herzig et al.
has oracle access to the number of concerns while heddle has not.
despite the lack of explicit file level relationships or oracle access heddle s accuracy matches confidence voters when applied to nfgs and outperforms them when they are applied to diff regions.
of the four methods we consider our re implementation of barnett et al.
s method section .
produces the lowest median accuracy .
.
we believe that two reasons account for this accuracy.
first we evaluate our re implementation on trivial parts.
second barnett et al.
speculate that their high fn rate is due to relations like method calls that def use chains miss .
we emphasise that barnett et al.
performed much better in its native setting.
they built their approach for microsoft developers and the commits they handle on a daily basis.
section details the threats to heddle svalidity this difference in methodology incurs.
section .
further details their approach and evaluation and its differences to heddle .
when considering accuracy for an increasing number of concerns see figure only barnett et al.
and herzig et al.
report statistically significant performance drops p .01andp .
according to a mann whitney u test .
barnett et al.
s drop is however not observable at two decimal points while herzig et al.
s drop is by .
.
both nfgs based tools report statistically indistinguishable results as the number of concerns increases.
asheddle is not privy to the number of concerns its behaviour on atomic commits is interesting.
when we apply heddle to atomic commits they are correctly identified as atomic with .63accuracy.
this results is when we ask the the yes no question is this commit atomic?
.
we also want to determine how wrong heddle is when creating spurious partitions.
for this we consider the node level accuracy of heddle .
the result is .
suggesting that heddle often mislabels a small number of changed nodes.
table shows detailed per project results broken down by project and number of concerns for each of the four untangling techniques.flexeme untangling commits using lexical flows esec fse november virtual event usa barnett et al.
herzig et al.
pdg cv heddle nfg wl method0.
.
.
.
.
.0accuracy concepts a accuracy barnett et al.
herzig et al.
pdg cv heddle nfg wl method10 1101103105107time s concepts b runtime figure boxplot comparing the accuracy of the baseline and heddle figure 4a as well as time taken s to segment a commit figure 4b for all projects.
the drop in accuracy for herzig et al.
s approach as the number of concerns increases is significant to p .001and barnett et al.
s top .01according to a mann whitney u test.
the results of the same test for pdg cv and heddle indicate that there is no statistically significant difference p .28andp .76respectively .
all increases in time taken to segment are statistically significant p .
mann whitney u test .
.
untangling running time figure 4b shows that barnett et al.
s def use chain technique is by far the fastest.
this result is expected because the algorithm is at its core strongly connected components detection over a sparse graph and is therefore linear in the number of nodes in def use chains that contain at least one addition.
however as we have previously seen in table its accuracy is considerably worse.
heddle is32times faster than herzig et al.
in a pair wise ratio test.
where nis the number of diff regions the herzig et al.
technique requires n2shortest path computations each requiring the solution of n2reachability queries over the dataflow graph.
consider the sparse occurrence matrix that encodes which commit touched which file its dimensions are the number of commits by number of files that ever existed in the repository.
herzig et al.
s technique also sums each row of this matrix.
although their technique needs these steps only to populate the distance matrix before agglomerative clustering these operations are expensive and must be computed for all diff regions within a patch.
the fact that their technique is heavy weight is unsurprising.
when compared to pdg cv the performance on graphs tangling only two concerns is comparable however heddle scales better as the number of concerns and the number of changed nodes increases.
we estimate the runtime of both heddle and pdg cv using a robust linear model regression and fitting a second order polynomial in the number of changed nodes n .
we find heddle to scale with t .
.0041n .0015n2 r2 .00and pdg cv with t .
.0528n .0019n2 r2 .
.
at nodes changed which is common in our dataset this would account for a difference of 68seconds.finally we compute the pair wise ratio of runtimes and find that heddle is over the median of these ratios 9times slower than barnett et al.
and 32times faster than herzig et al.
at untangling commits taking on average ten seconds per commit.
threats to validity heddle faces the usual threat to its external validity the degree to which its corpus of commits across a set of projects is representative.
the fact that we construct tangled commits exacerbates this threat and introduces the construct validity threat that commits that we assume are atomic are not in fact atomic.
to address the latter threat we validated the atomicity of the commits from which we built tangled commits on a small uniform sample of commits across our corpus.
as is conventional we choose because this is typically when the central limit theorem starts to apply .
we did not validate the representativeness of our corpus against a real world sample of tangled commits.
ground truth in real world samples can be hard to identify so we opted to use the methodology from herzig et al.
to create an artificial corpus that mimics some tangled commits we expect developers to make it captures the intuition of a developer committing multiple consecutive work units as a single patch.
this decision restricts our results only to the type of tangled commits we mimic which generalise only in so far as our algorithmically tangled commits generalise.
further like barnett et al.
we evaluated heddle only on c files so despite flexeme s language agnosticism heddle s result may not generalise to other languages.
our re implementations of herzig et al.
s and of barnett et al.
may contain errors.
section .
details these re implementationsesec fse november virtual event usa profir petru p rt achi santanu kumar dash miltiadis allamanis and earl t. barr and where they differ from their authors descriptions of the original implementations.
finally we published these re implementations at so other researchers can vet our work.
we borrowed herzig et al.
s commit untangling evaluation strategy wholesale as section .
and section .
detail.
thus we were able to directly compare our work with theirs.
barnett et al.
opted for a different evaluation strategy section .
because obtaining a ground truth for their evaluation is too time consuming in their setting.
thus we can neither directly compare heddle against their approach nor assess our re implementation relative to their tool.
they also conducted a user study showing both a developer need for such tooling and that their suggestions are useful.
because we did not conduct a user study our results lack the sanction of developer approval.
related work we first discuss the impact of tangled commits both on developers and researchers.
we then discuss approaches to untangling such commits followed by a discussion of multiversion representations.
we conclude with a discussion of graph kernels.
.
impact of tangled commits taoet al.
were amongst the first to highlight the problem of change decomposition in their study on code comprehension they highlight the need for decomposition when many files are touched multiple features implemented or multiple bug fixes committed.
the latter is diagnosed by murphy hill et al.
as a deliberate practice to improve programmer productivity.
tao et al.
conclude that decomposition is required to aid developer understanding of code changes.
independently herzig et al.
investigate the impact of tangled commits on classification and regression tasks within software engineering research.
the authors manually classify a corpora of real world changesets as atomic tangled or unknown and find that the fraction of tangled commits in a series of version histories ranges from to they also find that most projects contain a maximum of four tangled concerns per commit which is consistent with previous findings by kawrykow and robillard .
they find non atomic commits significantly impact the accuracy of classification and regression tasks such as fault localisation.
.
untangling commits into atomic patches it is natural to think of identification of communities in the nfg as a slicing problem .
however boundaries across concerns do not naturally map to a slicing criterion it is unclear how to seed a slicing algorithm and when to terminate it.
this is because concerns are linked with multiple edges which makes their separation difficult to specify with a slicing criterion.
in the rest of this section we discuss the literature around the problem of tangled commits and the theoretical foundations of flexeme .
research on the impact of both tangled commits and non essential code changes prompted an investigation into changeset decomposition.
herzig et al.
apply confidence voters in concert with agglomerative clustering to decompose changesets with promisingresults achieving an accuracy of .
.80on an artificially constructed dataset that mimics common causes of tangled commits.
in contrast kirinuki et al.
compile a database of atomic patterns to aid the identification of tangled commits they manually classify the resulting decompositions as true false or unclear and find more than half of the commits are correctly identified as tangled.
the authors recognise that employing a database introduces bias into the system and may necessitate moderation via heuristics such as ignoring changes that are too fine grained or add dependencies.
other approaches rely on dependency graphs and use define chains roover et al.
use a slicing approach to segment commits across a program dependency graph and correctly classify commits as un tangled in over of the cases for the systems studied excluding some projects where they are hampered by toolchain limitations.
they propose but do not implement the use of system dependency graphs to reduce some of the limitations of their approach such as being solely intraprocedural.
flexeme tackles interprocedural and cross file dependencies by merging the pdgs of the files touched by a commit.
barnett et al.
implement and evaluate a commit untangling prototype.
this prototype projects commits onto def use chains clusters the results then classifies the clusters as trivial or nontrivial.
a cluster is trivial if its def use chains all fall into the same method.
barnett et al.
employ a mixed approach to evaluate their prototype.
they manually investigated results with few non trivial clusters finding that their approach correctly separated of non atomic commits or many non trivial clusters finding that in all cases their prototype s sole reliance on def use chains lead to excessive clustering.
for results containing clusters they conducted a user study.
they found that out of the developers surveyed agreed that the presented clusters were correct and complete.
this result is strong evidence that their lightweight and elegant approach is useful especially to the tangled commits that microsoft developers encounter day to day.
during the interviews multiple developers agreed that the changeset analysed did indeed tangle two different tasks sometimes even confirming that developers had themselves separated the commit in question after review.
in addition to validating their prototype their interviews also found evidence for the need for commit decomposition tools.
because they use def use chains and ignore trivial clusters barnett et al.
s approach can miss tangled concerns that flexeme can discern.
barnett et al.
s user study itself shows that this can matter it reports that some developers disagreed with the classification of some changesets as trivial.
dias et al.
take a more developer centric approach and propose the epiceauntangler tool.
they instrument the eclipse ide and use confidence voters over fine grained ide events that are later converted into a similarity score via a random forest regressor.
this score is used similarly to herzig et al.
s metrics i.e.to perform agglomerative clustering.
they take an instrumentation based approach to harvest information that would otherwise be lost such as changes that override earlier ones.
this approach also avoids relying on static analysis.
they report a high median success rate of when used by developers during a two week study.
while dias et al.
sidestep static analysis they require developers to use an instrumented ide.
heddle is complementary to epiceauntangler itflexeme untangling commits using lexical flows esec fse november virtual event usa allows reviewers to propose untanglings of code that may originate from development contexts where instrumentation might not be possible.
.
multiversion representations of code related work has considered multiversion representations of programs for static analysis.
kim and notkin investigate the applicability of different techniques for matching elements between different versions of a program.
they examine different program representations such as string ast cfg binary or a combination of these as well as the tools that work on them on two hypothetical scenarios.
they only consider the ability of the tools to match elements across versions and leave the compact representation of a multiversion structure as future work.
some of the conclusions from the matching challenges presented by kim and notkin are echoed in flexeme as well we make use of the unix diff as it is stored within version histories however we also make use of linespan hints from the compilers for each version of the application to better facilitate matching nodes within a nfg.
leet al.
propose a multiversion interprocedural control graph mvicfg for efficient and scalable multiversion patch verification over systems such as the putty ssh client.
our pdg is a generalisation of this approach to a more expressive data structure with applications beyond traditional static analysis.
alexandru et al.
generalise the le et al.
mvicfg construction to arbitrary software artefacts by constructing a framework that creates a multiversion representation of concrete syntax trees for a git project.
they adopt a generic antlr parser allowing them to be language agnostic and achieve scalability by state sharing and storing the multi revision graph structure in a sparse data structure.
they show the usefulness of such a framework by means of mccabe s complexity which they implement in this framework such that it is language agnostic does not repeat computations unnecessarily and reuses the data stores in the sparse graph by propagating from child to parent node.
sebastian and harald propose a compact multiversion ast that cleverly shares state across versions.
flexeme in contrast rests on pdgs and is wellsuited for the untangling tasks as our evaluation demonstrates.
.
semantic slicing of version histories features in a system often co evolve which tangles the changes made for a one high level feature with others in a version history.
to resurface feature specific changes they dynamically slice a target version then walk backwards in history while they can reverse the intra version patch without conflict at each version they reach they add any commit that contains a hunk that touches the current slice to it.
the goal of this semantic slicing of version histories is to find a minimal slice of a version history that captures the evolution of a feature.
li et al.
first formulated and introduced this problem.
semantic slicing is a form of commit untangling backwards through history.
this retrospective framing is why they treat the history as immutable.
in this initial solution li et al.
treat commits as atomic so their slices may contain noise introduced by tangled commits.
to reduce this noise li et al.
in more recent work unpack commits into single file commits into a private local history.
flexeme in contrast is static and online built fromthe ground up to rewrite commits as developer make history.
as such flexeme and semantic slicing are complementary flexeme would improve the signal to noise ratio of semantic slicing.
an interesting direction for future work would be to use flexeme to preprocess version histories prior to semantically slicing them as with definer .
.
graph kernels real world data is often structured from social networks to protein interactions and even source code.
knowing if a graph instance is similar to another is useful if we wish to make predictions on such data by means that employ either similarity or distance.
vishwanathan et al.
provide a unified framework to study graph kernels bringing previously defined kernels under a common umbrella and offering a new method to compute graph kernels on unlabelled graphs in a fast manner reducing the asymptotic cost fromo n6 too n3 .
they mainly study the construction of the different graphs and demonstrate the run time improvement without applying it to a downstream prediction task.
shervashidze et al.
introduce the weisfeiler lehman graph kernel which they evaluate with three underlying kernels subtree edge histogram and shortest path on several chemical and protein graph datasets.
although code is often represented as a graph structure and the methods presented here are also used by us to compute graph similarity this literature primarily concerns itself with chemical and social network datasets that have become standardised benchmarks.
conclusion we have presented flexeme a new approach to commit untangling.
flexeme s realisation in heddle advances the state of the art it is .14more accurate achieving .
and 32times faster than the previous state of the art.
this result rests on a novel data structure nfg which augments a multiversion program dependence graph also introduced in this paper with name flows.
nfg facilitate dual channel reasoning across versions.
thus we believe that nfg will be useful on tasks other than commit untangling such as code refactoring notably renaming or code summarisation as when suggesting docstrings.