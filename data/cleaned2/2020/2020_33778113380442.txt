impact analysis of cross project bugs on software ecosystems wanwangying ma state key lab.
for novel software technology nanjing university nanjing china wwyma smail.nju.edu.cnlin chen state key lab.
for novel software technology nanjing university nanjing china lchen nju.edu.cnxiangyu zhang purdue university west lafayette usa xyzhang cs.purdue.edu yang feng nanjing university nanjing chinazhaogui xu nanjing university nanjing chinazhifei chen nanjing university nanjing china yuming zhou state key lab.
for novel software technology nanjing university nanjing china zhouyuming nju.edu.cnbaowen xu state key lab.
for novel software technology nanjing university nanjing china bwxu nju.edu.cn abstract software projects are increasingly forming social technical ecosystems within which individual projects rely on the infrastructures or functional components provided by other projects leading to complex inter dependencies.
through inter project dependencies a bug in an upstream project may have profound impact on a large number of downstream projects resulting in cross project bugs.
this emerging type of bugs has brought new challenges in bug fixing due to their unclear influence on downstream projects.
in this paper we present an approach to estimating the impact of a cross project bug within its ecosystem by identifying the affected downstream modules classes methods .
note that a downstream project that uses a buggy upstream function may not be affected as the usage does not satisfy the failure inducing preconditions.
for a reported bug with the known root cause function and failure inducing preconditions we first collect the candidate downstream modules that call the upstream function through an ecosystem wide dependence analysis.
then the paths to the call sites of the buggy upstream function are encoded as symbolic constraints.
solving the constraints together with the failure inducing preconditions identifies the affected downstream modules.
our evaluation of existing upstream bugs on the scientific python ecosystem containing versions of popular projects with a total of millions loc shows that the approach is highly effective from the candidate downstream modules that invoke the buggy upstream functions it identifies modules where the upstream bugs can be triggered pruning .
of the candidates.
the technique has corresponding author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
false negatives and an average false positive rate of .
.
only downstream modules out of the we found were reported before to be affected.
ccs concepts software and its engineering software maintenance tools maintaining software open source model .
keywords software ecosystems cross project bugs bug impact dependence analysis symbolic constraints acm reference format wanwangying ma lin chen xiangyu zhang yang feng zhaogui xu zhifei chen yuming zhou and baowen xu.
.
impact analysis of cross project bugs on software ecosystems.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
introduction recent years have seen a trend that software projects are forming large scale social technical ecosystems in which projects depend on the infrastructures or functional components provided by other projects .
projects within an ecosystem often have complex inter dependencies that impose new challenges in software maintenance .
as an important indicator of software quality bugs have long been a focus of study in the field of software engineering and are undoubtedly a more significant concern in ecosystems as bugs found in a project are very likely to affect many other projects in the ecosystem through inter dependencies .
for example scipy is an upstream library in the scientific python ecosystem and has a significant number of downstream projects depending on it such as scikit image that is a collection of algorithms for image processing and nilearn which is a python module for fast and easy statistical learning on neuroimaging data.
a bug was found inscipy s function scipy.ndimage.interpolation.affine transform reported in the project scipy with issue id scipy scipy and confirmed to affect nilearn.
this kind of bug which has impact ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea ma and chen et al.
on not only the reported project but also its downstream project s is called cross project bug.
cross project bugs are not uncommon in practice.
ma et al.
identified hundreds of instances from the scientific python ecosystem .
after inspecting the fixing process of cross project bugs and conducting an online survey they reported that compared with intra project bugs such bugs have much more severe impact and are extremely more difficult to deal with.
unlike single project development different projects within a software ecosystem are developed and maintained separately and asynchronously thus fixing of a cross project bug locally is usually not the end of its impact on other projects.
not until a patched version of the upstream project is released will the downstream projects get rid of the bug .
then if the published fix is not satisfactory the affected projects have to wait for another release cycle to get a new fix which enlarges the bug impact and requires extra efforts.
therefore the upstream developers are very cautious when facing a cross project bug and they are willing to seek advice from their dependent projects.
but even so the proposed bug fixes are sometimes unsatisfactory.
take the aforementioned bug scipy scipy as an example.
the function scipy.ndimage.interpolation.affine transform applies an affine transformation on a given array.
it will produce wrong results when the parameter matrix is a diagonal matrix and the parameter offset is not .
fixing the buggy method requires changing the output interface and hence might break some downstream projects.
scipy s developers were very cautious about how to repair the bug.
they asked scikit image s developers for feedback because they thought that scikit image would have called the method frequently.
after a lengthy inspection of their code scikit image s developers reported that there is no use of affine transform that satisfies the failure triggering conditions and hence the bug may not concern their project.
still scikit image s developers provided several suggestions and the bug was eventually fixed after lengthy debate.
unfortunately six months later a developer of nilearn reported that they were unhappy about the fix since it broke their code without any warning and they spent much effort in debugging the problem tracing back to the problematic fix.
from the discussion scipy s developers were completely unaware of the fact that nilearn was using the functionality until then.
the real world example discloses that it is difficult to provide an appropriate fix if the upstream and downstream sides are unclear about the possibly affected downstream code before starting to design a fix.
in other words in order to repair a cross project bug effectively and efficiently it is important to determine its impact.
however it is challenging in software ecosystems with numerous projects and project versions.
for the upstream side where a bug occurs the developers may have no idea which downstream projects are using the buggy function making it very difficult to solicit bug fix suggestions from the downstream developers.
for the downstream side as a scikit image s developer pointed out they themselves are not sure whether and how much an upstream bug affects their projects unless they comb through the code and figure out how they call the upstream function everywhere they use it.
it is time consuming and error prone.
thus some truly affected projects like nilearn may not realize the impact until the projects fail by the bug or its fix which however is too late for the downstream developers to give advice or take part in the fixing.it is not hard to see that analyzing cross project bug impact requires lots of painful manual efforts.
therefore to alleviate the problem we present an ecosystem wide bug impact analysis to identify the affected downstream modules classes methods of a given upstream bug.
note that an upstream function containing the bug is invoked in a downstream module does not mean the bug in the function must be triggered as the failure inducing preconditions may not be present in the downstream project.
hence our goal is to find out all the truly impacted downstream uses from the huge number of modules within an ecosystem so that the proposed upstream fix is more likely to satisfy all its affected downstream developers.
specifically a downstream module is truly impacted if the failure inducing preconditions of the upstream bug can be satisfied in the downstream module such that the buggy logic can be triggered leading to corrupted states.
for a reported bug with the known root cause function and failure inducing preconditions we first collect the candidate downstream modules based on an ecosystem wide dependence analysis.
then a conservative pathsensitive intra module impact analysis is performed by encoding the paths to the call sites of the buggy upstream function together with the preconditions as symbolic constraints.
solving the constraints discloses if the downstream module can be affected.
we evaluate the approach on the scientific python ecosystem.
we have collected cross project bugs from projects numpy and scipy in this ecosystem that have at least one confirmed affected downstream project.
we then analyze popular projects in different versions in the ecosystem with a total of millions loc to identify the impact of these bugs.
from modules that are using the buggy methods our technique identifies totally modules that are affected by these bugs saving .
inspection efforts for the developers to check the bug impact .
our analysis is conservative in the sense that if it concludes a module is not affected the module must not be affected.
although it may have false positives due to the conservative symbolic encoding our experiments show that the average false positive rate is only .
.
among the modules reported by our tool only were reported before.
our technique is also efficient.
the mean time for estimating every module is only .
seconds.
the ecosystem wide bug impact analysis is useful for both the upstream and downstream developers in helping them fix crossproject bugs effectively and efficiently as well as minimizing the bug impact on the entire ecosystem.
for the buggy upstream project once a bug occurs our approach can tell the developers which downstream projects and how much they are likely to be influenced by a given bug so that they can communicate with the affected projects especially the most important ones to understand the downstream requirements determine the priority of the bug and decide the ultimate solution.
for a downstream project our approach can tell the developers whether it might be influenced by a given bug and point out all the possibly affected modules methods or classes preventing to report duplicated bugs .
the approach saves the developers effort by directing their inspection towards these modules.
after inspecting the affected code the developers can even choose to work around the bug without waiting for the upstream fix.
they can also learn the possible workarounds from the sibling projects affected by the same bug .
101impact analysis of cross project bugs on software ecosystems icse may seoul republic of korea scipyamico pandas matplotlibsklearn daskskimage nilearn msmtools librosa mne aplpyastropynengonumpy .unique scipy scipy 3330ipython sympysunpy poliastrosynphot figure the impact of a bug in numpy.unique .
the central point denotes numpy.unique the surrounding dots of different colors mean the modules of different projects and the lines indicate the calls from these modules to numpy.unique .
the five projects ipython synphot sunpy sympy and poliastro have no use of numpy.unique .
the red dots are the modules potentially affected by numpy numpy .
motivating example in this section we use a real case in the scientific python ecosystem to illustrate the problem and motivate the design of our approach.
numpy is a fundamental library in the scientific python ecosystem with more than projects relying on it.
fig.
shows a small part of the dependencies including projects such as sunpy andsynphot.
the function numpy.unique was reported to produce wrong results when the first parameter aris an array with more than items and the parameter return index is set to be true reported in numpy numpy .
to analyze the impact of this bug on the projects we first have to identify which of them are using numpy.unique .
a direct way is to analyze the call relationships between the downstream projects and the buggy numpy function.
by inspecting the code of the projects in fig.
with totally modules functions or classes are found to call numpy.unique in various ways.
the central point in fig.
denotes numpy.unique the surrounding dots of different colors mean the modules of different projects and the lines indicate the calls from these modules tonumpy.unique .
however not all these modules are affected by the upstream bug depending on the bug inducing preconditions.
for example in librosa though the function librosa.core.fmt calls numpy.unique it uses the default value of parameter return index .
as such the bug has no effect on this module.
thus picking out the affected ones requires an analysis on how the downstream modules use the erroneous upstream function or more specifically which downstream uses satisfy the bug inducing preconditions.
after reviewing the code modules from the projects mne skimage nilearn pandas scipy matplotlib astropy and amico call numpy.unique in the bug triggering way i.e.
with len ar and return index true and thus are affected by numpy numpy shown asred dots in fig.
.
it is also worth noting that scipy s developers have reported the impact in scipy scipy .
the motivating example illustrates two key problems which we have to tackle when analyzing the ecosystem wide impact of a cross project bug with known erroneous method and bug inducing preconditions.
first which dependent modules are using the buggy upstream method?
second which downstream uses may satisfy the bug inducing preconditions?
for the first problem it is natural to leverage a cross project call graph to solve it.
however the dynamics and complexity of software ecosystems give rise to many new challenges.
as an open environment new projects may join in an ecosystem at any time by simply importing and using a library within the ecosystem.
therefore the cross project call graph should be extended flexibly to include new projects in order to gain a full scale impact analysis.
at the same time the extension should only induce local changes without interfering with most of the existing graph structure so that there is no need to reconstruct the ecosystem wide call graph which incurs high overhead especially for large ecosystems.
moreover the graph shall be version aware modeling multiple versions of a project as long as they are still used by some downstream projects.
specifically a buggy upstream function may only be used by some specific versions of a downstream project.
for example the motivating example numpy numpy which came up in numpy .
.
does not affect scipy .
.
which requires numpy .
.
.
taking into account the requirements of scalability flexibility and version sensitivity we leverage a dependency analysis to extract cross project call relationships between the upstream functions and the downstream modules functions or classes .
it can precisely identify the particular versions of a downstream project that is affected by an upstream function and the versions of the upstream project that a downstream project uses.
after the analysis the candidate modules which are using concerned upstream buggy functions can be identified.
note that although our technique can traverse dependences within the whole ecosystem the identification of dependences is performed in a modular fashion.
that is our algorithm constructs cross project dependences for each project separately.
such a design is critical to handling the dynamic evolution of an ecosystem.
more details can be found in section .
.
for the second problem processing of individual candidate modules in downstream projects is needed to determine whether a module invokes the buggy function in the failure inducing fashion.
considering the number and diversity of candidate modules several requirements arise when proposing a method for selecting the bug triggering downstream uses.
efficiency .
within a software ecosystem the number of candidate downstream modules identified from the cross project call graph may be large especially for a popular upstream function e.g.
modules in the aforementioned case .
since cross project bug impact analysis is supposed to be used before designing the bug fixes the analysis on individual modules should be completed in a short time in order not to hold up the fixing process.
complete coverage .
the analysis is supposed not to miss any affected downstream module so that the upstream fix is more likely to satisfy all their downstream users.
therefore for each module 102icse may seoul republic of korea ma and chen et al.
the designed method should examine every possibility of input for invoking the buggy function in order to decide whether it is affected or not.
therefore simply running the downstream tests is insufficient since downstream projects may not have test cases to expose upstream bugs even though they may have consequences.
considering the above requirements we develop a conservative path sensitive intra module symbolic analysis to determine whether the values of input parameters of an upstream function invocation meet the failure inducing preconditions.
specifically we analyze the candidate downstream modules and encode paths to the call sites of the upstream function in symbolic constraints.
by asserting the conjunction of these constraints and the failure inducing preconditions we can tell whether the downstream modules are affected.
our technique is not a symbolic execution engine which explores individual paths and encodes one single path at a time.
instead our technique encodes all the paths reaching the upstream function call sites at once without any path exploration.
furthermore symbolic execution usually can achieve precise encoding as it encodes concrete paths in which all the dynamic features are unfolded e.g.
dynamic types of variables are known whereas our encoding is conservative due to the lack of concrete information.
in the next section we show the design of our ecosystem wide bug impact analysis in details.
method design .
overview fig.
presents the overview of our approach which consists of two main phases the ecosystem wide dependence analysis to select downstream module candidates that call the upstream buggy methods and the intra module impact analysis to identify the affected modules that may meet the bug inducing preconditions.
the goal of the ecosystem dependence analysis is to construct a version sensitive dependence network over the target ecosystem which is accomplished by the dependence analyzer and the version handler.
within the target ecosystem each project is processed independently to better handle the dynamic evolution of the ecosystem and to achieve scalability.
first for each project with a base version of the project as the input the dependence analyzer leverages fine grained function invocation relations to construct a base dependence network.
then the version handler processes successive versions of the project incrementally by comparing function call changes to add version specific information to the network.
note that while the network is stored as a central database its construction and update are modular and distributed to individual projects.
hence when a project is updated only the dependences related to the project may be updated.
such a design substantially reduces the maintenance overhead.
as shown in section .
.
the size of the network for part of the scientific python ecosystem is only .4mb and hence very manageable.
given an upstream buggy function the module selector can easily identify the candidate downstream modules using the dependence network.
the intra module impact analysis takes three resources as inputs i.e.
individual candidate modules a buggy upstream function and the failure inducing preconditions extracted from bug reports.
it analyzes each candidate and identifies whether the candidateis truly affected.
we say a module is truly affected if with some legitimate inputs to the module the bug in the upstream function can be triggered.
specifically the intra module analysis consists of three subcomponents the code preprocessor the constraint encoder and the smt solver.
the code preprocessor reduces code with rich syntax to a simple canonical form.
the constraint encoder symbolically encodes paths to call sites of the upstream function as well as the failure inducing conditions.
the constraints are then passed to the smt solver.
if it is satisfiable the analyzed module is considered affected.
.
ecosystem wide dependence analysis the dependence analysis processes each project in the ecosystem seperately.
consider a software eocsystem sewhich consists of nprojects.
being a member of the ecosystem a project pi i n inseplays two roles.
as a downstream project piuses the functionalities provided by another project pj j n j i and the cross project call relations form a directed inter project dependence graph g pi vf rom vto e wherevf rom is a set of source nodes representing modules classes or functions in pi vtois a set of target nodes representing functions defined in projectpjand called by pi ande vf rom vtois a set of directed edges representing the call relations.
in the remainder of the section we usem vf rom to denote a downstream module and f vtoto denote an upstream function.
on the other hand as an upstream project the functions defined in pican be used by pjand thus serve as the target nodes in g pj .
therefore for any project in se the dependence analysis cares about its function definitions and inter project call relations.
in order to identify which versions of a downstream project are affected by a cross project bug in a specific upstream version we analyze multiple releases of each project.
assume pihaskversions i.e.
vi0 vi1 ... andvik.
we first choose a version such as the oldest versionvi0 as the base to extract the inter project call dependencies and construct a base graph.
to represent version information an attribute tfis maintained for each function f which is defined as a tuple to indicate the first and last versions where pihasf.
meanwhile a hash table cis constructed for each cross project call edgee m f e. the table maps a specific version of mto a range of versions of f indicating the version range of fon which min that version depends.
for example in fig.
the hash table on the edge denotes that min thevi0version ofpicallsfin versions vj1tovj5ofpj min thevi1version ofpicallsfin versionsvj2to vj5ofpj and so on.
note that f.tf isvj5.
after all the nprojects in the ecosystem seare analyzed the generated individual graphs g p1 g p2 ... g pn are combined to form the ecosystem wide dependence network g se by merging the same nodes i.e g se g p1 g p2 ... g pn where p1 p2 ... andpn se.
next we introduce the base graph construction and the version analysis.
.
.
base graph construction.
the base graph of a project is built by the dependence analyzer which consists of three subcomponents the ast parser the filter and the dependence graph storage.
it processes the base version of every project independently.
103impact analysis of cross project bugs on software ecosystems icse may seoul republic of korea ecosystem dependence analysis failure inducing preconditionsintra module impact analysisdependence analyzer constraint solveraf fected downstream modulescode preprocessor software ecosystem... ... ... module selector v ersion handler v ersion sensitive ecosystem wide dependence network... constraint encodercandidate downstream modulesindividual projects base graphs v ersioned graphs fn... ...buggy upstream function figure the workflow of our approach upstream project pj function f f.tf v j0 vj5 e downstream project pi module me.c vi0 vj1 f.tf vi1 vj2 f.tf vi2 vj2 f.tf vi3 vj2 f.tf figure versioning the upstream and downsteam projects import numpy as np def ttest rel ... ... dm np.mean d axis denom np.sqrt v n with np.errstate ... t np.divide dm denom t prob ttest finish df t a code snippet numpy.sqrt numpy.mean numpy.errstate scipy.stats.ttest relnumpy.divide b corresponding call dependencies figure inter project call graph for scipy.stats.ttest rel given the base version vi0of projectpi the ast parser first parses the source code into abstract syntax trees asts .
the function call entities are further analyzed to extract the callers and callees.
since we focus on the cross project impact of erroneous upstream functions we only concern the inter project call relations that is only the callees defined in other projects need to be retained.
to do this we employ a filter to preclude the callees defined within the project based on the import commands the class definitions and the function definitions.
fig.
illustrates a simple example of extracting the dependency relation.
as shown in fig.
4a the function ttest rel in the project scipy calls np.mean np.sqrt np.errstate np.divide and ttest finish at line to line .
since ttest finish is defined within scipy it is not of interest in this study and thus is precluded from the following analysis.
fig.
4b shows the corresponding inter project call dependencies.
meanwhile the function definition entities are also recorded since they are likely to be the target nodes of the graphs for other projects.
.
.
version analysis.
when constructing the base graph for project piof thevi0version the value of tf i.e.
the version range in which a function is availableinpi and the entries of c i.e.
hash table on edge e m f are initialized as vi0 vi0 and vi0 respectively.
to obtain the corresponding value of c we first try to acquire the information from the configuration files such as the setup.py in python projects inpi which may indicate the lower and upper bounds of depending versions of the upstream projects.
however such information may be incomplete due to the lack of configuration files or not specifying versions in these files.
in such cases the lower upper bound is the first latest version of the upstream project pjwhich contains fwith the exact same interface.
for the example in fig.
e.cis initialzied as vi0 vj1 f.tf wherevj1is obtained from the configuration file and f.tf is the lastest version of pjcontaining f. after the base graph is built the version handler updates the values of tfandcby comparing two subsequent versions of project ofpiincrementally.
the version handler consists of two subcomponents the code comparator to identify the differences between two versions and the version updater to add version information to base graphs.
from version vi1to the latest version vik the code comparator compares the asts between vipandvi p p k .
it records four kinds of changes function call deletion function call insertion function definition deletion and function definition insertion.
these changes are sent to the version updater to update the values of tf andc.
updating tf.when a new function is defined in the vipversion itstfis initialized as vip vip .
if an existing function is deleted fromvip itstfremains unchanged.
for other functions in vip the second item of their tfis updated from vi p tovip.
updating c.in the version vipof projectpi if its module mis modified so that it no longer calls the upstream function f the hash table on edge efrommtofdoes not need to be updated.
otherwise an entry is added to cto denote the invocation in version vip.
in fig.
since version v4the call from mtofis deleted cihas four entries denoting versions vi0 vi1 vi2 andvi3.
the values for new entries are obtained from the configuration files or f.tf as described above.
after all the versions are processed the values of tfandcare obtained and the version sensitive dependence network is constructed once every interested project is analyzed.
with the network we can tell in which versions a downstream module is invoking an upstream buggy function of a specific version.
the dependence network serves as a database for the whole analysis.
the incremental processing of code indicates that the 104icse may seoul republic of korea ma and chen et al.
dependence network can be easily updated with code changes of a project.
anytime a developer commits some change the network can be easily modified accordingly without interfering with other projects that do not have direct dependences.
moreover with the version information the network can show the profile of interproject dependency relationship of a software ecosystem at any interesting point of time.
last the network features the capabilities of dealing with ecosystem dynamics i.e.
projects join and leave .
after the ecosystem wide dependence network is constructed for a given cross project bug with known root cause buggy function the candidate selector identifies all the downstream modules which are using the buggy upstream function.
then the candidates are sent to the intra module impact analyzer one by one to check whether they are truly affected.
.
intra module impact analysis the intra module impact analysis symbolically encodes each module to assess whether the given upstream buggy function can be invoked with the failure inducing preconditions.
specifically for each concerned downstream module the analyzer first utilizes the code preprocessor to normalize the module code and then it replaces the body of the buggy function with a simple check of the failure inducing conditions.
then the constraint encoder encodes the possible paths from the module entry to the call sites of the buggy upstream function.
last all the constraints including the encoded failure inducing conditions are sent to the constraint solver.
a module is affected by the bug if the result obtained from the solver is satisfiable.
.
.
code preprocessing.
a code normalization.
in a source code file one source code line may contain multiple statements and a long statement may cross multiple lines.
for the simplicity of the subsequent analysis we first normalize the downstream module so that each line only contains a simple operation.
while such normalization is well supported in languages such as c c and java e.g.
through compiler ir it is lacking for our target language python.
as such we develop our own normalization methods.
the following two kinds of normalization are currently performed.
linearizing nested expressions.
nested expressions combine multiple operations together e.g.
foo a b .
we linearize these nested expressions as a set of simple assignments each containing a simple expression.
simplifying complex constructs.
python provides expressive syntax to represent complex semantics concisely.
despite of its convenience for developers it brings difficulties for analysis.
the code preprocessor transforms several kinds of advanced constructs to a small set of basic operations.
fig.
illustrates how we process list comprehension in python as an example.
the statement x shows a concise method to construct a list which is transformed into several basic statements such as a for statement that contains an if statement.
b code integration.
after normalizing the downstream code the code preprocessor abstracts the buggy upstream function to a simple check of the x i for i in range if i x for i in range if i tmp i x.append tmp figure simplifying list comprehension failure inducing conditions which is sufficient for our purpose.
the procedure is shown in fig.
and explained as follows.
first the code preprocessor only retains the interface of the upstream function upfunc and replaces its body with an if else statement.
the failure inducing preconditions obtained from the bug report act as the conditions of the if else statement.
then the code preprocessor retains the body of the downstream module downfunc from the first line to the call sites of the buggy upstream function.
it modifies the statement at the downstream call site by replacing the original return target variable as tmpresult or adding the target variable if there is not one .
an example of the resulting code is shown in fig.
6c.
it is then sent to the symbolic encoding component.
.
.
symbolic analysis.
a input variables initializing.
for dynamic programming languages like python the static type information of variables is not explicitly indicated.
a specific input variable of a module can be of different data types.
for example the project numpy specifies that the input parameter axis of its function numpy.nanpercentile can be an integer a list of integers ornone.
this poses challenges to symbolic analysis in which symbolic variables need to be explicitly typed.
to handle such situation we use multiple symbolic variables of different types to denote the value of an input variable x. for a statement sinvolving x all the symbolic variables representing xare updated to encode the possible behavior of salong with the different types of x. b constraint encoding.
the constraint encoder symbolically encodes possible paths from the module entry to the call sites.
during encoding it transforms each path into its single static assignment ssa form so that every variable is defined exactly once.
next we describe how we encode several typical constructs.
assignments.
for a constant assignment x v vrepresents a typical object literal including the number string list etc.
the encoder transforms it into the ssa form and encodes it to constraints.
for a simple assignment x y the encoder looks for the most recent definition of y. if it is found the encoder first resolves the definition and then encodes it after transformation to the ssa form.
otherwise we initialize ywith multiple symbolic variables of different types.
for binary operation such as x y z the encoder processes it similarly.
... def upfunc arg1 arg2 ... function body k def upfunc arg1 arg2 ... if conditions return else return statement statement ... tmpresult upfunc p1 p2 ... c resulting code to be encoded ... k def downfunc arg1 arg2 ... statement statement ... a upfunc p1 p2 ... a upstream buggy function b downstream module to be analyzed extracted from bug reports figure the procedure of code integration 105impact analysis of cross project bugs on software ecosystems icse may seoul republic of korea calls.
to ensure the efficiency of impact analysis the encoding is performed within the target module.
as the module may call other functions in addition to the buggy upstream function we manually provide symbolic models for a set of commonly used library functions.
note that this is normal in symbolic analysis.
we resolve other calls to un modeled external functions in a conservative way.
we assume these functions can change the values of their input parameters and return any value of any type.
therefore for a statement x f p1 ... pn the return target variable x and input variables pi i n are reinitialized with multiple symbolic variables of different types.
in this way our analysis is conservative meaning that if a buggy upstream function can affect a downstream module our tool must report it.
we consider this to be more desirable than a typical aggressive no false positive strategy in symbolic bug finding as identifying the potentially affected downstream modules is critical for upstream bug fixing.
in section .
our results show that even though our analysis is conservative it allows pruning .
of the downstream modules that invoke the buggy functions.
conditionals.
for a branch if conditions s1elses2 we first resolve the predicate and then aggressively process each statement of s1 ands2.
during encoding paths are classified into two categories dead end and active.
a dead end path goes into a direction that can not reach the call sites of the buggy upstream function and thus is discarded during encoding.
an active path can lead to the concerned point.
we only encode the active paths.
loops.
we unroll all the constant loops to their bounds.
for a loop with variable bound e.g.
while loops we unroll it times.
to be conservative in the else branch of the last round of unrolling we re initialize all the variables.
example.
consider the example in fig.
where uf is the buggy upstream function.
the constraint encoder aims to encode the path to the call sites of uf at line within the module.
it first transforms each statement into its ssa form before encoding.
at line since the encoder does not find a definition of k kis the input parameter of the module it initializes kwith multiple symbolic variables of different types such as integer and string.
due to the unsupported addition operation between an integer and a string the symbolic variable of the string type is discarded from the following analysis.
at line an external function ef is called.
the encoder encodes mand bwith variables of multiple types like k. for the if statement at line the predicate is resolved and two paths are generated with the constraints m k and m k separately with the former path not containing line .
therefore lines and form the only active path to uf within the module and only the constraints along this path together with the failure inducing preconditions are then sent to the smt solver.
c condition types.
during symbolic execution the failure inducing preconditions are m a k b ef m if m k p b else p uf a m initialize k newint and newstr discard k of newstr reinitialize m b newint and newstr discard the deadended path figure an example for encodingalso encoded.
through inspecting a number of cross project bugs in the scientific python ecosystem we summarize three kinds of the most common conditions under which upstream buggy functions will exhibit unexpected behaviors.
type condition.
a bug will occur when the type of a certain input parameter for the upstream function falls out of an acceptable set.
for example the function numpy.fix can not correctly process a scalar which means that when the input parameter xis an integer or a float the bug will be triggered numpy numpy .
value condition.
a bug will occur when the value of a certain input parameter for the upstream function falls out of an acceptable range.
for example the numpy s function numpy.percentile breaks when the input parameter interpolation is set to midpoint numpy numpy .
property condition.
a bug will occur when some property of a certain input parameter for the upstream function falls out of an acceptable range.
for example the function numpy.unique in numpy returns wrong results when it processes an array with more than items numpy numpy .
we currently support the three kinds of failure inducing preconditions and their combinations.
for such bugs our proposed method reports no false negatives due to its conservative nature.
we manually extract the conditions from bug reports and send them in canonical forms to the code preprocessor before encoding.
then all the constraints collected along the active paths including the encoded conditions are passed to the solver.
if the solver reports sat and the value of the variable tmpresult is one we decide that the subject downstream module is possibly impacted by the given upstream bug.
the impact triggering input can also be obtained.
evaluation we implemented our approach in a prototype tool in python.
since python programs are likely to use a number of external functions and classes implemented in other languages we manually modeled some commonly used external functions by rewriting them in python.
we used z3 as the smt solver.
we conduct an experiment on the github scientific python ecosystem to evaluate our approach.
.
research questions we attempt to address the following research questions rq1 how effective is our approach in finding the affected downstream modules?
for this question we examine what percentage of the downstream modules using an upstream buggy method is identified to be affected by a confirmed cross project bug.
we also check the false positives of the identified modules.
rq2 how efficient is our approach?
to answer this research question we monitor the time used to extract the inter project call dependencies and the time to analyze the intra module impact.
.
dataset in order to answer the above research questions we evaluate our approach on a set of cross project bugs which were confirmed to affect some downstream modules.
these bugs were collected manually by three steps.
first we focused on two fundamental libraries 106icse may seoul republic of korea ma and chen et al.
figure an automatic hint indicating that the issue pandasdev pandas reported to the project pandas is related with the numpy bug numpy numpy .
in the scientific python ecosystem i.e.
numpy and scipy .
they are the core projects used by nearly all the other projects within the ecosystem so the bugs occurring these projects are very likely to affect other projects.
among the closed bugs reported for the two libraries we selected all those which had at least one explicit link with issues reported for other projects.
the link may be shown in the comments of the bug report such as bug found by testing astropy see astropy astropy in numpy numpy s comments or an automatic hint in the bug page shown in fig.
.
second for each selected bug we examined whether its linked downstream issues were caused by the bug through reading the bug reports and the comments.
if so the bug was confirmed as a crossproject bug and the linked downstream projects were considered affected.
third for each cross project bug we recorded its buggy function failure inducing preconditions and the affected downstream modules.
excluding the bugs which we could not identify all of the three kinds of information we collected cross project bugs in total involving downstream projects belonging to the scientific python ecosystem.
we extract the call dependencies from a total of version of the projects to construct an inter project dependence network.
the dependence network is stored in mysql and the candidate downstream modules are selected through query statements.
we select the projects because the cross project bugs that we manually studied were confirmed to affect them.
therefore they can be used as a baseline to validate whether our approach can identify the truly affected downstream modules.
note that our evaluation only involves projects because we have to manually check the results produced by our tool which costs much effort and limits the number of evaluated projects.
.
results .
.
effectiveness rq1 .
table shows our experimental results within the sub ecosystem.
the column bugindicates the bug id in the github issue tracker.
the prefixes nand smean the bug is from numpy and scipy respectively.
the second and third columns show the number of candidates which are using the buggy upstream functions and the number of affected downstream modules identified by our tool from other projects.
the column affs shows the percentage of the affected downstream modules over all candidates.
for the cross project bugs our approach first filters downstream modules that do not call buggy upstream functions through an ecosystem wide call graph leaving candidates for intramodule symbolic analysis.
then the number of affected modules identified by our technique ranges from to with a total number of and an average number of .
.
the percentage of impacted modules ranges from .
to with an average of .
.
for bugs the affected modules are less than .
of all the modules using the buggy upstream methods highlighted intable statistics of experimental results bug cans affs affs fps p constraints time s max.
avg.
avg.
total n .
.
.
.
n .
.
.
.
n .
.
.
.
n .
.
.
.
.
n .
.
.
.
n .
.
.
.
.
n .
.
.
n .
.
.
.
n .
.
.
.
n .
.
.
.
n .
.
.
n .
.
.
.
n .
.
.
n .
.
.
.
n .
.
.
.
n .
.
.
.
n .
.
.
.
.
n .
.
.
.
.
n .
.
.
.
n .
.
.
.
.
n .
.
.
.
.
n .
.
.
.
.
n .
.
.
.
n .
.
.
.
n .
.
.
.
s .
.
.
s .
.
.
s .
.
.
.
.
s .
.
.
.
s .
.
.
s .
.
.
.
.
avg.
.
.
.
.
.
.
total .
.
the column bugindicates the bug id in the github issue tracker.
the prefixes nand smean the bug is from numpy andscipy respectively.
the second and third columns show the number of candidates which are using the buggy upstream functions and the number of affected downstream modules.
the column affs shows the percentage of the affected downstream modules over all candidates.
the column fps lists the false positives for each bug and the column pshows the precision fps min affs .
the two columns of constraints indicate the maximum and average numbers of constraints collected from the module entries to the call sites of the buggy upstream function across all the candidates.
the column avg.
oftime s shows the mean time that the intra module impact analyzer needs to process a candidate module for the bug.
table .
for the affected modules the analyzer identifies the impact by providing the inputs that can trigger the cross project bugs.
due to the conservativeness of the intra module analysis our approach has recall and the modules filtered out from the candidates are ensured to be unaffected.
among the identified downstream modules only modules have ever been reported in the past.
the number of newly found modules for the bugs ranges from to with a total number of .
to examine the false positives of them we take three steps to decide whether they are indeed affected.
for each reported module a test case is first generated with the inputs provided by our tool.
then we configure the upstream project to the version where the cross project bug happens and the downstream project to the version that our tool specifies.
in addition other depending projects are also configured to the appropriate versions for normal operation of the module.
last we run the test case and observe whether the values of the input parameters of the buggy upstream function conform to the bug inducing preconditions when the function is invoked.
if so the module is considered truly affected otherwise the module is a false positive.
due to the high cost of the examination we can not validate all modules.
for the bugs with affs we examine all the affected modules identified by our tool.
for other bugs we 107impact analysis of cross project bugs on software ecosystems icse may seoul republic of korea table number of encoded constructs in various types funcdef if call while assign augassign return others randomly select modules from the identified ones and ensure each involved downstream project is under inspection.
we totally validate modules.
table shows the results.
the column fps lists the false positives for each bug and the column pshows the precision fps min affs .
it can be seen that the precision of our approach is high with an average of .
.
apart from the bug n with a precision of .
the precisions for other bugs are not lower than .
.
moreover no false positives are found for bugs highlighted in table .
bug n reports that numpy s function numpy.log1p returns a wrong result with the input as an infinite number.
for this case the five false positives are all found in the project nilearn.
the reported nilearn modules call the function numpy.empty like to randomly produce an array before using numpy.log1p .
we cannot obtain an infinite number after numpy.empty like is invoked when running the test cases and thus the failure inducing precondition cannot be met.
however we did not model the behavior of numpy.empty like such that our tool reports that an infinite number is possible.
seen from table our method filters out a large number of unaffected candidate modules that use the buggy methods.
with our tool developers can save at most .
.
for n of the effort for a single bug by not inspecting the unaffected ones.
for bugs the developers save .
.
of the effort in code review on average.
the result means that our technique can effectively help the downstream developers to focus their efforts on a limited number of truly affected modules instead of wasting time on inspecting a mass of modules immune to the bugs.
to gain a broader view of our symbolic anlysis table lists the number of various types of constructs that we encode including function definition if statement assignment augmented assignment while statement function call return and others such as try statement and raise statement .
totally we symbolically encode candidate downstream modules with kloc.
among those types of constructs function calls are most frequently encountered followed by if statements and assignments.
among these callees .
are commonly used libray functions that we have manually modeled while others are resolved in the conservative way as described in .
.
.
considering the high precision of our approach the considerable number of un modeled function calls do not result in too many false positives indicating that the conservative processing of calls is suitable in bug impact analyis.
it ensures that the symbolic analysis is performed in a limited code range for individual modules e.g.
loc per candidate module on average without much precision loss.
in addition to the number of encoded constructs of various types we also provide fig.
to show the number of symbolic constraints collected from each candidate module during impact analysis.
each bar in fig.
represents the number of modules in which the number of collected constraints falls into the specific range.
it can be seen that paths to the buggy upstream functions in .
of candidate modules are encoded into to constraints.
.
.
.
.
.
.
.
.
constraintsfigure the distribution of numbers of constraints collected from candidate modules.
.
.
efficiency rq2 .
dependence analysis.
table shows the time used to analyze inter project call dependencies.
due to limitations on space we only present the information for six projects i.e.
numpy scipy astropy scikit learn pandas and matplotlib .
they are the core libraries in the scientific python ecosystem and involve the most number of analyzed cross project bugs in our study.
the first column shows the name of the project.
the columns sloc functions and calls mean the numbers of the source lines of code functions and method calls to other projects in base version of the project respectively.
the column versions shows the number of analyzed versions.
the last two columns present the time used to extract the inter project call relations from the base version of each project and the time to incrementally analyze all the versions.
it can be seen that the time for processing base versions ranges from .
hours to .
hours with an average of .
hours.
the total time for each project ranges from .
to .
hours.
combining the graphs from individual projects we construct an ecosystem wide call dependence network for projects of versions with a time cost of .
hours.
the network consists of directed edges and takes .4mb in mysql.
the time cost is acceptable because the dependence network is constructed in advance.
it is only updated by updating the graphs of individual projects when new versions are committed.
intra module impact analysis.
the two columns of constraints in table indicate the maximum and average numbers of constraints collected from the module entries to the call sites of the buggy upstream function across all the candidates.
the column avg.
oftime s shows the mean time that the intra module impact analyzer needs to process a candidate module for the bug.
the last column presents the total time used to analyze the impact of the bug including the time for selecting the candidates from the ecosystem wide dependence network and the time for processing all the candidates.
the time cost of our approach is reasonable.
it takes .
seconds on average to analyze the local impact for every module.
for bugs it takes no more than seconds to estimate table time used in dependence analysis project sloc k functions calls versions b h t h numpy .
.
scipy .
.
astropy .
.
scikit learn .
.
pandas .
.
matplotlib .
.
108icse may seoul republic of korea ma and chen et al.
a scikit image skimage feature register translation.py def register translation src image target image upsample factor space real upsampled region size n umpy.ceil upsample factor .
dftshift n umpy.fix upsampled region size .
sample region offset dftshift shifts upsample factor b mne io egi events.py def read mff events filename sfreq nsamples marker start sample int np.fix start sfreq float numpy.ndarray float figure examples of how the impact of a cross project bug is worked around unrelated code is omitted.
the ecosystem wide impact for each of them.
the analysis time for n and n is raletively long since the two bugs each involves more than candidate modules.
the result suggests that our technique is sufficiently fast to be used during fixing crossproject bugs.
by integrating the approach into bug trackers it can tell the impact of a cross project bug in a short time.
.
threats to validity we discuss the threats to validity during the evaluation.
first to validate the affected modules reported by our tool we manually configured individual modules and their dependencies to the suitable versions to run the generated test cases.
it is very time consuming and costs substantial human efforts.
therefore we only validated all the reported modules for bugs.
for each of the remaining eight bugs we randomly sampled modules.
in total we checked modules.
while we believe the results indicate the effectiveness of our technique it is possible that results may be different for the unsampled modules and untested bugs.
another threat concerns the generalization of our experimental results.
we evaluated our tool using cross project bugs.
these bugs were collected after lengthy manual inspection of bug reports to confirm whether they are cross project ones.
the failure inducing preconditions were also manually extracted from bug reports which may be error prone as we are dealing with others projects.
to mitigate the threat we were very cautious during data collection and only retained the bugs with preconditions clearly indicated in bug reports.
in addition due to the scale of the project the evaluation was conducted only on the scientific python ecosystem.
it is possible that our results may not generalize to other ecosystems.
however the individual components of our technique are designed in an ecosystem agnostic fashion.
discussion in this section we discuss our findings from the evaluation and their inspiration for our future work.
.
cross project impact could be got around as mentioned above a large percentage of the affected downstream modules identified by our approach have not been reported before which to some extent indicates that the cross project impact of upstream bugs is often hard to be noticed by developers.
after inspecting these modules we find that the wrong results produced by buggy upstream functions are sometimes worked around by downstream modules.fig.
shows such a real case.
the function fix innumpy was reported to falsely return a numpy array numpy.ndarray with zero dimension when it was applied to a scalar numpy numpy .
asnumpy s documentation indicated numpy.fix should produce a scalar.
the function register translation in the project scikitimage used the buggy upstream function numpy.fix with a float input shown at line in fig.
10a .
at line the variable dftshift was the returned value of numpy.fix with the data type ofnumpy.ndarray .
the variable dftshift was then only used at line as an operand.
since a dimension numpy.ndarray was seen as a scalar in this operation the wrong data type did not lead to a wrong output of register translation inscikit image.
therefore though scikit image used the buggy upstream function numpy.fix with the impact triggering input its users or developers were not likely to be aware of the wrong result produced by numpy.fix .
another downstream function read mff events in the project mne also called numpy.fix .
fig.
10b shows how read mff events used numpy.fix used as np.fix in the code and processed its output.
the result of start sfreq was a scalar.
when it was passed to numpy.fix the buggy function falsely returns a wrong output of a dimension array rather than a scalar.
however an explicit type cast int was applied to the output and converted it to a correct type.
therefore the wrong output is suppressed.
the two downstream modules worked around the upstream bug by using the wrong results in insensitive operation or processing the wrong results to suppress the bug for the time being.
however it is unclear if the downstream developers are aware of the possible wrong outputs and put the work arounds intentionally.
nonetheless the wrong output of the buggy upstream function may put the downstream module in risk.
without the awareness of the cross project bug if developers of scikit image modify the code to use dftshift in a type sensitive operation in future it may lead to some unpredictable consequences.
this case shows the possibility of designing the future bug impact analyzer to further tell whether the bug impact is worked around in affected downstream modules.
this can be done by analyzing how the modules process and use the returned values of the buggy upstream functions.
for example considering the aforementioned case that the returned value is of a wrong data type if the value is then used in a type insensitive operation or data type convention is applied we have the reason to conjecture that the wrong returned output will not interfere with later code of the module.
to design the approach we need to get hints from code or developers experience.
more specifically we first have to classify the differences between the expected and the wrong outputs of the buggy upstream functions into several categories such as data type difference or value difference.
then we need to summarize which operations are likely to be insensitive to each type of difference or to eliminate the difference.
last the analysis system needs to learn these hints and apply them to the downstream modules to decide whether they will get around the unexpected results of buggy upstream functions.
109impact analysis of cross project bugs on software ecosystems icse may seoul republic of korea .
keep the ecosystem in focus when considering bug impact as we have discussed in section the cross project impact of bugs indicates the necessity of changing the developers points of view during bug fixing.
with the popularity of the collaboration in software development and the increasing trend of software ecosystem understanding and repairing a bug can not be limited within its rooted project.
both the upstream and downstream sides should consider the bugs and their fixes from the perspective from the whole ecosystem.
however in most cases only when the cross project bugs are submitted by the downstream projects the upstream developers would check whether the fixes satisfied the demands of the reported downstream projects.
for other bugs they rarely ask for the suggestions or feedbacks for the fixing from other projects mostly due to the lack of the awareness of cross project impact of bugs and thus the proposed patches may not be satisfactory.
for the downstream projects the developers should also take into account the potential threat for their located ecosystems when dealing with upstream bugs.
as we have discussed a part of downstream modules seldom use the upstream erroneous functions in the way that triggers the bugs within the projects.
therefore the downstream developers may not be aware of the impact or even deal with the bugs.
however as members in the ecosystem the affected modules are likely to be used by other projects.
once the input parameters that they pass to the buggy upstream functions via the directly affected downstream modules trigger the impact it may cause unpredicted consequences.
such uncertain use of the downstream modules put the ecosystem in potential threat.
related work .
cross project bugs the increasing number of cross project bugs have attracted growing attention from researchers.
canfora et al.
proposed an approach to identifying cross system bug fixings csbfs in freebsd and openbsd kernels.
they also employed social network analysis to associate the occurrences of csbfs with the social characteristics of contributors.
ma et al.
concentrated on the common practices of developers in fixing cross project bugs.
they especially focused on downstream developers and addressed the questions about how they found the root causes and coordinated to deal with upstream bugs.
ding et al.
studied the characteristics of workarounds which were usually proposed by downstream developers when facing cross project bugs.
liu studied third party library upgrade bugs and developed an automated tool to repair them.
decan et al.
reported that failures in upstream packages brought more and more troubles to downstream projects.
in contrast our study focuses on the ecosystem wide impact of cross project bugs and proposes a technique to identify the affected downstream modules.
.
change impact within software ecosystems projects within a software ecosystem co evolve with each other through their inter dependencies.
changes to one project including fixing a bug may cause ripple effects to many other downstream ones.
bavota et al.
found that upstream upgrades have strongeffects on downstream projects when a downstream project depends on upstream frameworks or general services.
a large number of studies focus on the api changes in libraries .
hora et al.
characterized the impact of api evolution in the pharo ecosystem by observing to what extent api changes propagate to other projects.
robbes et al.
investigated the ripple effects of api deprecations across a smalltalk ecosystem considering five aspects including the frequency magnitude duration adaptation and consistency.
bogart et al.
studied how developers reasoned about and applied changes in three software ecosystems eclipse r cran and node.js npm by observing their differences in practice polices and tools applied when performing avoiding a breaking change.
xavier et al.
analyzed the impact of api breaking changes on client projects in java ecosystem.
they concluded that most breaking changes did not have a massive impact on clients.
tools have also been developed to make breaking changes less harmful by easily applying patches to downstream projects .
additionally api changes in android ecosystem have also been investigated.
mcdonnell et al.
concluded that android apis evolved faster than client migration.
linares vasquez analyzed how the number of questions in stackoverflow increased when apis were changed.
they showed android developers were more active when they faced api modifications.
to the best of our knowledge although these studies have empirically confirmed that upstream changes have ripple effects on downstream projects no existing work has proposed methods to automatically analyze cross project bug impact with such finegranularity and precision.
recently hejderup et al.
proposed to construct an ecosystem call graph for dependency management.
they made an initial evaluation on npm based projects by executing test cases of npm packages in jalangi.
compared with their work our ecosystemwide dependence analysis especially considered the scalability and dynamics of software ecosystems by processing each project independently and handling versions on an incremental basis.
conclusion we present an approach to analyzing the impact of cross project bugs on software ecosystems by identifying the affected downstream modules classes methods .
for a confirmed bug with known root cause function and failure inducing preconditions we first leverage an ecosystem wide dependence analysis to collect the candidate downstream modules.
then we perform an intra module analysis to encode the paths to the call sites of the buggy upstream function as symbolic constraints.
by solving the constraints together with the failure inducing preconditions the affected downstream modules are identified.
our evaluation on the scientific python ecosystem shows that the approach is highly effective.