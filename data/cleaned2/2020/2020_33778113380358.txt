simulee detecting cuda synchronization bugs via memory access modeling mingyuan wu southern university of science and technology shenzhen china mail.sustech.edu.cnyicheng ouyang southern university of science and technology shenzhen china mail.sustech.edu.cnhusheng zhou university of texas at dallas dallas usa husheng.zhou utdallas.edu lingming zhang university of texas at dallas dallas usa lingming.zhang utdallas.educong liu university of texas at dallas dallas usa cong utdallas.eduyuqun zhang southern university of science and technology shenzhen china zhangyq sustech.edu.cn abstract while cuda has become a mainstream parallel computing platform and programming model for general purpose gpu computing how to effectively and efficiently detect cuda synchronization bugs remains a challenging open problem.
in this paper we propose the first lightweight cuda synchronization bug detection framework namely simulee to model cuda program execution by interpreting the corresponding llvm bytecode and collecting the memory access information for automatically detecting general cuda synchronization bugs.
to evaluate the effectiveness and efficiency of simulee we construct a benchmark with popular cuda related projects from github upon which we conduct an extensive set of experiments.
the experimental results suggest that simulee can detect out of the manually identified bugs in our preliminary study and also previously unknown bugs among all projects of which have already been confirmed by the developers.
furthermore simulee significantly outperforms state of the art approaches for cuda synchronization bug detection.
acm reference format mingyuan wu yicheng ouyang husheng zhou lingming zhang cong liu and yuqun zhang .
.
simulee detecting cuda synchronization bugs via memory access modeling.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
yuqun zhang is the corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
introduction cuda is a mainstream parallel computing platform and programming model that allows software developers to leverage generalpurpose gpu gpgpu computing .
cuda is advanced in simplifying i o streams to memories and dividing computations into sub computations since it parallelizes programs in terms of grids and blocks.
in addition cuda enables more flexible cache management that speeds up the floating point computation of cpus.
cuda is thus considered rather powerful for accelerating deep neuralnetwork related applications where relevant matrix computations can be efficiently loaded.
unlike traditional cpu multi thread programs where the synchronization mechanism is built upon managing the shared resource that can be accessed by multiple threads the typical synchronization mechanism of gpu programs is built upon synchronizing the instruction flows .
in particular since gpu programs use barriers rather than locks for synchronization and enable simplified barrier based happens before relations traditional locksetbased and happens before based bug detection approaches for cpus become obsolete and expensive in detecting parallel computing related bugs for gpus.
recently several approaches e.g.
have been proposed to detect synchronization bugs for cuda kernel functions.
in general they can be categorized into two classes the compiler based approaches that leverage compiler instrumentation with without static analysis to identify race free locations for detecting data race bugs and the smt solverbased approaches that integrate static analysis and symbolic execution with smt solver to detect data race and barrier divergence bugs .
although such approaches can detect cuda synchronization bugs under their respectively defined environments they have limited applicability and may rely on certain assumptions.
in particular the compiler based approaches are limited due to relying on developer provided test inputs and detecting data races only while the smt solver based approaches can be heavyweight due to triggering expensive static analysis overhead and may also involve manually provided test inputs.
in this paper to address the aforementioned issues we develop a systematic lightweight bug detection framework namely simulee ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea mingyuan wu yicheng ouyang husheng zhou lingming zhang cong liu and yuqun zhang which automatically detects general synchronization bugs for cuda kernel functions.
in particular simulee generates a memory access model that maintains thread wise memory access information including thread id visit order and action.
accordingly simulee utilizes the llvm bytecode of cuda kernel functions to initialize the running environmental setups including arguments dimensions and global memory if necessary based on the memory access model .
moreover simulee applies evolutionary programming to approach error inducing inputs for exposing the dangerous program execution paths which may possibly induce synchronization bugs.
subsequently simulee collects the corresponding memory access information from such paths.
at last by combining cuda specifics such collected memory access information are analyzed to find whether they can potentially lead to synchronization bugs.
compared with other cuda synchronization bug detection approaches simulee can detect multiple bug types including data race redundant barrier function and barrier divergence fully automatically.
moreover simulee benefits from exploring the dangerous execution paths guided by the lightweight evolutionary search without incurring large overhead e.g.
for constraint solving such that it is more efficient than existing state of the art approaches that usually rely on heavyweight techniques or manual inputs.
to evaluate the effectiveness and efficiency of simulee we first collect popular cuda related projects from github with a total of commits and .
million loc by aug as our benchmark suite.
then as a preliminary study we manually identified real world synchronization bugs from a subset of the studied real world cuda projects and the gklee benchmark suite.
we conduct a set of experiments to explore how many of those manually identified bugs can be detected by simulee for the preliminary analysis whether simulee can detect previously unknown bugs on those real world cuda projects and how simulee compares with state of the art approaches in cuda bug detection.
the experimental results suggest that simulee can successfully detect of the manually identified synchronization bugs in our preliminary study.
furthermore it even detects previously unknown bugs from all the real world cuda projects of which have already been confirmed by the corresponding developers.
the experimental results also demonstrate that simulee can be much more effective than state of the art approaches i.e.
gklee gklee sesa gpuverify and racechecker in detecting synchronization bugs e.g.
simulee can detect 2x more previously unknown bugs than any of the other studied state of the art approaches.
in addition simulee can significantly outperform the other studied approaches in terms of the runtime overhead.
in summary our paper makes the following contributions idea.
to the best of our knowledge we propose the first idea of cuda synchronization bug detection via evolutionary search guided by memory access modeling.
implementation.
we have implemented the proposed idea as a lightweight fully automated and general purpose detection framework for cuda synchronization bugs namely simulee that can automatically detect a wide range of synchronization bugs in cuda programs which are hard to be captured manually.
block block grid block block block block thread thread thread thread thread thread thread thread thread block figure cuda hierarchy study.
we evaluate simulee under multiple experimental setups.
the results suggest that simulee is able to detect most of the manually identified synchronization bugs in the benchmark.
in addition it even detects previouslyunknown bugs of the entire benchmark fully automatically and significantly outperforms state of the art approaches.
background in this section we give an overview on cuda the cuda parallel computing mechanism and typical cuda synchronization bugs.
cuda overview.
cuda is a parallel computing platform and programming model which allows developers to use gpu hardware for general purpose computing e.g.
autonoumos driving .
cuda is composed of a runtime library and an extended version of c c .
in particular cuda programs are executed on gpu cores namely device while they also need to be allocated with resources on cpus namely host prior to execution.
as a result developers need to retrieve allocated resources such as global memory after cuda program execution.
to conclude a complete cuda program contains runtime stages host resource preparation kernel function execution and host resource retrieve.
cuda parallel computing mechanism.
a cuda kernel function refers to the part of cuda programs that runs on the device side.
specifically thread is the kernel function s basic execution unit.
at the physical level threads are bundled as a thread warp wherein all the threads execute the same statement at any time except undergoing a branch divergence while at the logic level one or more threads are contained in a block and one or more blocks are contained in a grid.
the execution of kernel functions is initialized by setting runtime environments e.g.
dimensions of grids and blocks passing relevant arguments such that the computation can be divided into sub computations and each sub computation can be dispatched to different threads.
eventually the results of sub computations can be merged as the final result of the overall computation through applying algorithms such as reduction .
the hierarchy of the parallel computing mechanism of cuda kernel functions is presented in figure .
to synchronize threads cuda applies barriers at which all the threads in one block must wait before any can proceed.
in cuda kernel functions the barrier function is syncthreads which synchronizes threads from the same block.
when a thread reaches a barrier it is expected to proceed to next statement if and only if all the threads from the same block have reached the same barrier.
otherwise the program would be exposed to undefined behaviors.
938simulee detecting cuda synchronization bugs via memory access modeling icse may seoul republic of korea tid threadidx.x .... if y a c f val2reduce f else f val2reduce infinity syncthreads fix by adding syncthreads get block min will write data to f val2reduce int ip get block min f val2reduce f idx2reduce float up value p f val2reduce .... figure an example of data race const unsigned tid threadidx.x s median flt max s idx syncthreads if i iterations ... s idx i s median m .... figure an example of redundant barrier cuda synchronization bugs.
there are three major synchronization bugs in cuda kernel functions data race barrier divergence and redundant barrier function .
specifically data race indicates that for accessing global or shared memory cuda cannot guarantee the visit order of read write actions or write write actions from two or more threads.
for example figure demonstrates the bug fixing revision no.
febf515a82 in the file smo kernel.cu of the project thundersvm one of the highly rated github projects.
it can be observed from figure that the if statement writes to the memory of f val2reduce while inside the device the function get block min writes to the same memory.
this write write bug is fixed by adding syncthreads which synchronizes actions among threads.
a barrier function is considered redundant when there is no data race after deleting it from source code.
a redundant barrier function compromises the program performance in terms of time and memory usage.
for instance figure demonstrates bug fixing revision no.
31761d27f01 in file kernel homography.hpp from project arrayfire .
it can be observed that the block is onedimensional from line the value of tid is assigned only by threadidx.x .
that indicates that the tid s are identical among different threads from the same block.
as a result s median and s idx can only be accessed by one thread leading to a redundant barrier function in line because there is no race in s median or s idx after deleting it.
a barrier divergence takes place when some threads in a block complete their tasks and leave the barrier while the others have not reached the barrier yet.
figure demonstrates the bug fixing revision no.
0ed6cccc5ff in the file nearest neighbour.hpp from the project arrayfire caused by barrier divergence.
it can be indicated from figure that developers make sure all the threads in the same block reach the same barrier in every execution of the kernel function by moving the statement of syncthreads .... s dist dist s idx s idx syncthreads fix by moving the barrier out.
syncthreads .... figure an example of barrier divergence outside the given branch.
otherwise they will have to handle undefined behaviors.
framework of simulee in this section we introduce simulee a lightweight automatic and device independent framework to detect real world cuda synchronization bugs.
typically simulee takes llvm bytecode translated from cuda kernel function programs as input.
then it automatically generates the associated error inducing test inputs and yields memory access model to detect synchronization bugs.
specifically simulee is composed of two components automatic input generation and bug detection via memory access model .
automatic input generation is initialized by inputting the llvm bytecode of cuda kernel function programs.
next it slices the memoryaccess statements e.g.
read and write statements and inputs them for evolutionary programming .
subsequently evolutionary programming helps generate error inducing environmental setups by iteratively mutating and sorting dimensions arguments and passes the acceptable ones to bug detection via memory access model .
at last bug detection via memory access model traces real execution paths by using the error inducing inputs and collects the memory access information from the paths to detect whether there are synchronization bugs as it were simulating runtime environment.
the details can be found in figure .
llvm bytecode of kernel functions slicing original statements mutating argumentsmutating dimensionsinitializing solutions sorting solutionstop rank solution acceptable?iterating memory model constructionmemorymodelbased detection resultsautomatic input generation evolutionary programming memory based synchronization bug detection figure framework of simulee .
automatic input generation generating potentially error inducing inputs is essentially equivalent to generating the inputs that can lead to the memory access 939icse may seoul republic of korea mingyuan wu yicheng ouyang husheng zhou lingming zhang cong liu and yuqun zhang conflicts among threads to improve the possibility of cuda synchronization bug occurrences.
however how to automatically generate such error inducing inputs remains challenging.
intuitive solutions e.g.
random generation coverage oriented generation can be limited in effectiveness and efficiency because they are not specially designed for triggering memory access conflicts.
in this section we introduce how simulee automatically generates potentially error inducing inputs for exposing the dangerous program execution paths which could lead to synchronization bugs in an effective and efficient manner.
.
.
intuition.
an effective and efficient automatic approach to generate potentially error inducing inputs for triggering cuda synchronization bugs implies generating as many memory access conflicts as possible within a short time limit.
given the ith memory address and the kernel function inputs i.e.
grid and block dimensions and arguments f i is defined as the number of threads that access the ith memory address while g i is a function that returns when the ith memory address is accessed by any thread and returns otherwise.
denotes the memory access range.
an intuitive target function f dimensions ar uments can be presented in equation which denotes the ratio of the total number of the accessed memory addresses to the total number of the memory access threads f dimensions ar uments end i star t i end i star tf i it can be derived that the max value of f dimensions ar uments is which denotes that there is no memory access conflict between any thread pair.
on the other hand the smaller f dimensions ar uments is the higher chance the memory access conflict takes place.
therefore f dimensions ar uments can be used for optimization to obtain error inducing inputs that trigger cuda synchronization bugs.
note that since f dimensions ar uments is discrete we choose evolutionary programming as our optimization approach.
.
.
algorithm.
the framework of automatic input generation is presented in algorithm .
first simulee randomly initializes arguments anddimensions to create and sort individual solutions for evolving lines to .
in each generation each solution is mutated to generate two children which are added to the whole population set lines to .
next the population winners survive for the subsequent iterations lines to .
the iterations can be terminated once it finds an acceptable solution.
otherwise after completing the iterations it returns the optimal solution.
initial solutions.
the initial dimensions and arguments are randomly generated and passed to fitness functions as initial solutions for future evolution.
note that the dimensions can be extracted from kernel functions.
for instance if a kernel function has threadidx.x and threadidx.y it means the block is two dimensional.
fitness function.
equation is chosen as the primary fitness function for evolutionary programming.
specifically the output off dimensions ar uments is the fitness score for a solution of dimensions and arguments in evolutionary programming.
however it is difficult to derive an optimal solution of dimensions andalgorithm framework for automatic input generation input population generation output acceptable arguments and dimensions function evolution algorithm populationlst list fori in population do singlesolution initialsolution singlescore fitness singlesolution populationlst.append sortbyscore populationlst fori in generation do childlst list forsolution in populationlst do childrensolutions mutation solution newscores fitness childrensolutions childlst.append populationlst.merge childlst sortbyscore populationlst populationlst populationlst ifpopulationlst acceptable then return populationlst return populationlst arguments by only optimizing f dimensions ar uments .
in particular since f dimensions ar uments is non differentiable when the gradient does not exist it is hard to find an optimal solution given the set of inferior solutions e.g.
all the solutions of f dimensions ar uments are s. to address such issues we design a secondary fitness function such that they are sorted according to their possibility to be optimal r start end end start .
in particular it indicates that a smaller memory access range leads to a higher possibility of memory access conflict.
as a result we define fitness score of the primary fitness function as primary score and the fitness score of the secondary fitness function as secondary score .
during the population evaluation the primary score is sorted first if and only if the top ranked primary score is the secondary score is sorted to decide which solution is more likely to converge to the minimum of f dimensions ar uments .
mutation.
insimulee solutions are generated by mutation where each solution generates two children in one generation.
specifically arguments anddimensions are independent from each other during mutation with respective mutation strategies.
the mutate strategy for dimensions is trivial first simulee randomly generates an integer vector ranging from to according to the dimension size next the child s dimension is mutated by summing the parent s dimension and the generated integer vector.
the details of the mutation strategy for arguments is presented in algorithm .
since the memory access relevant arguments are numbers simulee views them as floating numbers and converts them back to their actual types when executing f i .
accordingly each generation generates two children one adds a random number generated by standard normal distribution n x 2 e x2.
to the arguments inherited from the parent solution and the other adds a random number generated by standard cauchy distribution c x x2 to the arguments inherited from the parent solution.
we define the search step length of the arguments as 940simulee detecting cuda synchronization bugs via memory access modeling icse may seoul republic of korea algorithm mutating arguments input parent output mutation children solutions function argument mutation normalsolution copy parent cauchysolution copy parent forargument in parent do normalsolution parent normal cauchysolution parent cauchy return normalsolution cauchysolution the absolute value of the number generated from the two aforementioned distributions with the expected values shown in equations and .
enormal x 0x1 2 e x2.
2dx .
ecauch y x 0x1 x2 dx we next explain why we apply the above two distributions.
it can be observed from equations and that the step length generated from standard normal distribution is expected to be small.
that indicates that if there is an optimal solution nearby the generated child is likely to approach it.
on the contrary the step length generated from standard cauchy distribution is expected to be large.
that indicates that if there is an inferior solution nearby the generated child is likely to escape from it.
acceptable function.
the acceptable function is used to terminate the whole process given an acceptable solution.
in this paper the acceptable solution is defined as that primary score is smaller than .
.
in summary by applying evolutionary programming simulee is expected to deliver error inducing grid and block dimensions and arguments that lead to memory access conflicts and trigger cuda synchronization bugs.
.
memory based synchronization bug detection with the auto generated error inducing inputs the synchronization bug detection of simulee is established on building a memory access model that depicts thread wise memory access instances.
based on the memory access model simulee develops a set of criteria to detect synchronization bugs including data race redundant barrier functions and barrier divergence.
.
.
memory access model.
the memory access model accessed by the kernel functions is defined to be composed of a set of memory units where each memory unit corresponds to a memory address and is composed of a set of unit tuple s. a unit tuple is defined as a three dimensional vector space visit order thread id action where visit order represents the visit order to the associated memory address from different threads thread id represents the indices of such threads and action refers to the read or write action from those threads.
an example of memory unit is demonstrated in figure with four unit tuple s read read read and read where threads and read read read read memory unitbarrier functionfigure memory unit example read the same memory address in the same visit order since none of them have reached any barrier function before they read.
assume all the threads reach a barrier function later and thread reads thevisit order is then incremented from to for thread and the other threads afterwards.
.
.
memory accessing model construction.
since memory access model is only associated with barrier functions and memory access statements it is applicable to detect synchronization bugs by obtaining such statements and then extracting analyzing the memoryaccess information instead of executing the complete cuda programs on gpus i.e.
modeling the execution of cuda kernel function programs.
this modeling process is initiated by inputting the auto generated block and grid dimensions and arguments passed to the kernel functions.
next it constructs the memory unit for each memory address by tracing back the execution path for each thread.
the overall memory access model construction is demonstrated in algorithm .
in particular the algorithm is launched to initialize the block and grid dimensions as well as the global and shared memory for each thread lines to .
next for each block the shared memory line and the thread wise visit order for each global and shared memory address lines to are initialized.
if there are still some unterminated threads for all of them their corresponding memory unit s are derived based on the collected parameters e.g.
globalmem andvisitorderglobal lines to .
the construction of the thread wise memory unit s for shared memory and global memory are completed if there is no running thread left lines to .
algorithm illustrates the details of memory access model construction for a single thread.
specifically given a running thread and the parameters passed by algorithm lines to algorithm is initialized by detecting whether the current statement is the end of file.
if so the thread would be terminated.
if there is any thread halting afterwards we can confirm there is a barrier divergence bug because that indicates at least a thread has not reached the barrier function where the other threads of the same block all have completed their tasks and left lines to .
if the current statement calls barrier function and all the other threads have reached the same barrier function the visit order for both global and shared memory would be incremented if they have been visited before lines to since it indicates that all the threads in one block have visited the current memory address and the subsequent visits in the same block would be made rigorously later than the previous visits.
on the other hand if the 941icse may seoul republic of korea mingyuan wu yicheng ouyang husheng zhou lingming zhang cong liu and yuqun zhang algorithm memory access model construction input griddim blockdim arguments output memory access model function construct memory model blocks generatefromdimension griddim threads generatefromdimension blockdim globalmem sharedmemlst list forblk in blocks do sharedmem visitorderglobal visitordershared while hasunterminatedthread do fort in threads do env environment arguments process thread t globalmem sharedmem visitorderglobal visitordershared env sharedmemlst.append sharedmem return globalmem sharedmemlst current statement does not call barrier function the corresponding visit order and the action of the associated thread is recorded to construct the memory access model lines to .
.
.
bug detection via memory access model mechanism.
the design of memory access model can be used in simulee to detect cuda synchronization bugs i.e.
data race redundant barrier function and barrier divergence.
data race.
in general parallel computing programs a possible data race takes place when multiple threads access the identical memory address in the same visit order and at least one of them writes.
specifically in cuda kernel functions besides the generic circumstances a data race also takes place when the threads are from different thread warps or the threads from the same thread warp underwent branch divergence or the threads from the same thread warp without undergoing branch divergence write to the same memory address by the same statement.
by combining the data race detection criteria above and the design of memory access model simulee can detect data race in cuda kernel functions as described in theorem .
.
theorem .
.
given two unit tuples iand jfrom the identical memory unit a data race between them takes place if the conditions below are met i j i !
j i write or j write when the threads of iand jare from different thread warps or executing the write action on the same statements in the same thread warp or underwent branch divergence before the current write action.
redundant barrier function.
a redundant barrier function indicates that no data race can be detected by removing that barrier function.
in cuda kernel functions the visit order is incremented for one unit tuple when at least one thread reaches a barrier function.
in other words two unit tuple s with adjacent visit order in onememory unit indicates the presence of a barrier function shownin figure .
therefore to detect whether a barrier function is redundant or not it is essential to collect all the associated unit tuple s and analyze whether they together would lead to data race.
the barrier function is defined to be redundant if no data race can be detected among such unit tuple s. the details of how to detect data race and redundant barrier function based on memory access model are presented in algorithm .
for each memory unit to detect data race simulee first groups theunit tuple s with the same visit order.
for all the unit tuple s in one group simulee checks whether any unit tuple has data race with others according to theorem .
lines to .
to detect redundant barrier function of one memory unit simulee extracts its visit order and groups all the unit tuple s with adjacent visit order to find out whether any data race can take place lines to .
if there is no data race simulee identifies the associated barrier function and increments its recorder by lines to .
at last it checks whether the total recorder number matches the total number of the changing visit order caused by that barrier function which can be obtained after constructing the memory access model .
this barrier function is redundant if the two numbers are equivalent lines to .
barrier divergence.
as mentioned in section .
.
barrier divergence can be detected during constructing memory access model when there is any halting thread after the current execution is terminated because it indicates that there is at least one thread which has not reached the barrier function while the others have already left.
to conclude simulee first applies evolutionary programming to generate error inducing grid and block dimensions and arguments.
next simulee inputs such dimensions and arguments to construct memory access model that delivers thread wise memoryaccess information.
eventually such information along with the cuda synchronization bug detection mechanism are used to detect whether there exists any cuda synchronization bug.
evaluation in this section we conduct an extensive experimental study to evaluate the effectiveness and efficiency of simulee in detecting synchronization bugs of cuda kernel functions.
in particular we first perform a preliminary study on manually identified cuda synchronization bugs to explore the efficacy of simulee.
next we explore the capability of simulee in detecting previously unknown bugs from all the real world cuda projects in our benchmark suite.
furthermore we also compare simulee with multiple existing stateof the art approaches to explore whether simulee can outperform them.
.
benchmark construction to conduct a preliminary study for evaluating simulee it is essential to establish a set of cuda synchronization bugs as the ground truth.
to this end we first consider an existing benchmark i.e.
the gklee dataset and select synchronization bugs that can represent all the basic synchronization bug patterns in the dataset.
furthermore we augment the bug dataset with more real world cuda bugs.
in this paper we aim to collect important and influential real world cuda benchmark projects for our evaluation by defining a set of policies for selecting open source cuda 942simulee detecting cuda synchronization bugs via memory access modeling icse may seoul republic of korea algorithm thread processor input thread globalmem sharedmem visitorderglobal visitordershared env output none or barrier divergence function process thread ifshouldhalt or isfinished then return curstmt env.getnextinstruction ifcurstmt.iseof then thread.finish ifhashaltthreads then return barrier divergence return ifcurstmt.issyncthreads then ifall threads reach same barrier then updatecurrentvisitorder visitordershared updatecurrentvisitorder visitorderglobal else isglobal memindex simulateexecute curstmt env ifisglobal then index visitorderglobal updatememorymodel globalmem memindex index else index visitordershared updatememorymodel sharedmem memindex index return table subject statistics pr ojects star number commit number loc kaldi 364k arrayfire 381k thundersvm 343k cuda cnn 12k cudasift 24k cudpp 58k gunrock 178k projects in github.
specifically we initialize our cuda project collection by searching the keyword cuda and collect more than projects from github in the first place.
next we sort these projects in terms of the star number and commit number.
we randomly select projects with large star commit numbers.
as a result we collect kaldi arrayfire thundersvm cuda cnn cudasift cudpp and gunrock for augmenting our benchmark suite as listed in table .
more specifically we randomly select projects arrayfire kaldi and thundersvm from our real world cuda benchmark suite to retrieve their historical synchronization bugs.
note that we do not consider all the projects from our benchmark suite since the manual bug retrieval process can be quite time consuming.
the synchronization bugs for those selected projects are identified based on their commit messages and git diff results.
the specific operations are listed as follows.
following prior study on other types of bugs we first filter the commits and only keep the commits with the messages that contain at least one keyword in the set fix error sync to retain the commits that have higher chances to contain synchronization bugs.
however thealgorithm bug detection via memory access model input memorymodel changingvisitordernumber output data race redundant barriers function examine memory model data race false redundant barriers dict formemoryunit in memorymodel do forvisitorder in memoryunit do tuples gettuplesbyorder visitorder forthread performing write in tuples do otherts getdifferentthreads thread tuples fort in otherts do ifinsamewarp t thread then ifusingsamestmt t thread then data race true ifhasbranchdivergence t thread then data race true else data race true barrierdict dict forvisitorder in memoryunit do nextorder visitorder current gettuplesbyorder visitorder target gettuplesbyorder nextorder ifcanmergewithoutrace target current then barrier getsplitbarrier nextorder memoryunit barrierdict forbarrier in barrierdict do redundant barriers isredundant barrierdict changingvisitordernumber return data race redundant barriers commit messages only with these keywords might not be relevant with cuda bugs.
therefore next among the filtered commit messages we further filter them according to whether they have at least a keyword in the set global device or match at least one regular expression in the set cuda w s with its parent node s git diff results.
to illustrate global is the modifier of kernel functions and device is the modifier of the device functions that can be called by kernel functions.
cuda w s is designed in accordance with the information that the resource is prepared released in host side before after executing kernel functions.
for instance cudamalloc void host sizeof int allocates a global byte memory for kernel functions before execution cudafree host releases the allocated memory for kernel functions after execution.
is designed in accordance with the scenario that sets up the environment for kernel functions e.g.
function grid size block size arguments .
all these regular expressions together deliver the complete life cycle of executing kernel functions such that all the bugs of the whole life cycle can be covered.
we further manually review all the remaining commits after the above two rounds of filtering to remove any potential false positive.
due to the tedious and time consuming manual inspection all the selected cuda projects are analyzed within the most recent commits or all of them if there are less than commits.
as a result we collected a total of real world 943icse may seoul republic of korea mingyuan wu yicheng ouyang husheng zhou lingming zhang cong liu and yuqun zhang cuda bugs.
by combining with the synchronization bugs from thegklee benchmark suite we obtain a total of cuda bugs as the ground truth for our preliminary study.
.
environment setups we performed our evaluation on a desktop machine with intel r xeon r cpu e5 and gb memory.
the operating system is ubuntu .
.
for the evolutionary programming settings of automatic input generation in simulee the population and generation are both set to be by default.
note that the simulee webpage includes more experimental results under different settings for the evolutionary programming component.
we select state of the art cuda synchronization bug detection approaches i.e.
gpuverify gklee gklee sesa and racechecker for the performance comparison with simulee.
more specifically racechecker is the nvidia s official tool and represents state of the art compiler based approach while the rest approaches represent state of the art smt solver based approaches.
note that the timeout for all studied techniques are uniformly set to be hours.
.
result analysis .
.
preliminary study on known bugs.
we first present the experimental results for detecting the manually identified synchronization bugs in our preliminary study in table .
in the table dr bd and rb respectively denote data race barrier divergence and redundant barrier function.
and f respectively denote the successful failed and false positive bug detection attempts.
to denotes that the associated bug detection attempt incurs timeout while n a denotes that the buggy kernel function is out of the scope of the bug detection capability of the corresponding techniques.
note that each row represents one kernel function which could include multiple bugs indicated by column bug num .
for such cases we present all the reported bugs for each kernel function e.g.
fff denotes that the corresponding technique reports four bugs in total for the kernel function of which are false positives.
from the table we can observe that in terms of the overall effectiveness simulee can detect .
of the the manually identified synchronization bugs within seconds e.g.
simulee at most costs .
seconds when applied on kernel function jacobisvd .
we further analyze the cases for which simulee fails to detect bugs.
simulee fails to detect the data race in kernel functionhamming matcher because this bug can only be exposed under occasional branch coverage which is out of the scope of the input generation component of simulee that focuses on the memoryaccess conflict potentials.
simulee fails to detect bugs for kernel function softmax reduce and div rows vec because they are largely reimplemented to reduce the usage of unnecessary barrier functions while the current version of simulee is not designed for such challenging bugs requiring large code refactoring.
we next analyze the comparison results between simulee and state of the art gpuverify gklee gklee sesa andracechecker from the table in details.
note that gpuverify requires user provided dimension settings and the other techniques require the overall user provided environmental settings.
we provide them all withthe ideal settings that can trigger the most possible bugs for fair comparison with simulee.
gpuverify.
gpuverify is designed to detect data race and barrierdivergence bugs via integrating static analysis with smt solvers.
from the table we can observe that gpuverify can successfully detect out of the synchronization bugs.
meanwhile gpuverify also reports false positives.
we next manually check all such false positives and observe that gpuverifytends to report false positives due to two reasons.
first the false positives are triggered by the bottleneck of the static analysis optimization.
for instance in kernel functions deadlock 0 andcomputedescriptor gpuverify reports false positives due to nonexistent execution paths.
second its adopted smt solvers are used to detect data race bugs caused by thread wise access conflicts however the thread warp mechanism adopted in cuda kernel functions can resolve some of such bugs e.g.
the inter instruction read write race.
shown in figure warpsize is equal to in revision 5cc9731af4f of function trace mat mat trans from projectkaldi .
suppose there are two threads and and the tidof thread is while the tidof thread is .
moreover when the loop terminates shift is set to .
meanwhile for thread statement ssum ssum is executed for thread statement ssum ssum is executed.
in traditional cpu programs since thread is reading data from thread ssum while thread is attempting to write data to ssum it can incur a read write data race.
however in cuda kernel functions since thread and thread are located in the same thread warp without branch divergence they essentially are executing the same instruction at the same time.
since the statement ssum ssum tid shift can be compiled to the following two instructions load ssum store ssum the read action is executed strictly prior to the write action.
as a result it turns to be a false positive data race in cuda kernel functions.
we issued this case to its corresponding developers who further verified our finding as follows you are correct that ssum ssum and ssum ssum are executed at the same time.
but since we are now in a warp all the threads tid .. are synchronized.
so reading data from ssum and ssum always happens before writing data to ssum and ssum for thread tid and tid .
kaldi gklee andgklee sesa.
gklee andgklee sesa are designed to detect synchronization bugs via integrating concolic execution with smt solvers.
by launching the environmental setups they collect read and write statements into different sets and use smt solvers to detect synchronization bugs accordingly.
from our preliminary study gklee and gklee sesa can detect and manually identified bugs respectively without any false positive.
interestingly gklee sesa incurs more timeouts and detects less bugs than gklee.
the reason is that gklee sesa leverages more static analysis techniques to reduce its dependency on the initial userprovided environmental setups while such techniques are rather time consuming.
moreover similar to gpuverify because they are both smt solver based approaches they are also likely to report false positives on data race further confirmed by our later study 944simulee detecting cuda synchronization bugs via memory access modeling icse may seoul republic of korea table detection results of the identified bugs pr oject re vision k ernel function bug type bug numsimule e gp uverify gklee gklee seas raceche cker effe ct time s effe ct time s effe ct time s effe ct time s effe ct time s arrayfir ea7a297ba814 scan nonfinal kernel dr .
.
.
t o .
a7a297ba814 scan dim nonfinal kernel dr .
.
.
t o .
0c5a38182b7 hamming matcher dr .
.
.
t o .
0c5a38182b7 hamming matcher unr oll dr .
.
.
t o .
d7ab cf2358e jacobisvd dr .
f f f .
t o t o .
c59116e3e c3 warp r educe dr .
.
.
t o n a a515b112076 scan dim kernel dr .
.
.
t o .
1050816e422 hamming matcher dr .
.
.
t o .
df bfca5fb77 sele ct matches bd .
.
.
t o n a 0e0c726d7d0 hamming matcher unr oll bd .
t o .
t o n a e e4d0bd77d7 computedescriptor bd .
f f .
.
t o n a 0d0d7d1285a warp r educe bd .
.
.
t o n a 31761d27f01 computeme dian rb .
n a n a n a n a faefa30c3a0 harris r esponse rb .
n a n a n a n a gkleetests10eb6373d53 de vice global dr .
.
.
.
n a 10eb6373d53 colonel dr .
.
.
.
n a 10eb6373d53 dl deadlo ck 0 bd .
f .
.
.
n a 10eb6373d53 dl deadlo ck 2 bd .
.
.
.
n a kaldib c13196e7fe add diag mat mat bd .
.
.
t o n a 42352b63e62 softmax r educe rb n a n a n a t o n a bb589475b10 div r ows vec rb n a n a n a t o n a thundersvm febf515a826 nu smo solv e kernel dr .
t o .
t o .
t otal detection result 0f 6f 0f 0f 0f table detection results of the previously unknown bugs pr oject re vision k ernel function bug type bug numsimule e gp uverify gklee gklee seas raceche cker effe ct time s effe ct time s effe ct time s effe ct time s effe ct time s cuda cnn c843bb2861e g getcost 3 rb .
n a n a n a n a cudasifta2e57327ddc findmaxcorr rb f f f .
n a n a n a n a a2e57327ddc findmaxcorr1 rb .
n a n a n a n a a2e57327ddc findmaxcorr2 rb .
n a n a n a n a a2e57327ddc findmaxcorr3 rb .
n a n a n a n a cudpp9dc7357e e81 sparsematrix vectorfetchandmultiply rb .
n a n a n a n a 9dc7357e e81 sparsematrix vectorsetflags rb .
n a n a n a n a 9dc7357e e81 y gather rb .
n a n a n a n a gunr ock 248a12107ef join bd .
t o .
t o n a kaldi5cc9731af4f add diag v ec mat dr .
.
.
t o n a 5cc9731af4f cop y low upp dr .
f .
f .
f .
n a 5cc9731af4f cop y upp low dr .
f .
f .
f .
n a 5cc9731af4f splice dr .
.
.
n a n a 5cc9731af4f cop y from tp dr .
.
.
t o n a 5cc9731af4f cop y from mat dr .
.
.
t o n a 5cc9731af4f sum r educe dr rb .
.
n a .
n a t o n a .
n a thundersvm 05de37f83b6 c smo solv e kernel dr .
t o .
t o .
t otal detection result 3f 2f 2f 2f 0f on detecting new bugs and fail to detect any redundant barrierfunction bugs because their detecting mechanism is not designed for such bugs.
we next discuss the failure cases for the better gklee because gklee sesa timed out on most cases gklee fails to detect barrier divergence bugs in kernel functions select matches and add diag mat mat because gklee models the kernel functions over two parametric threads and tends to ignore important execution paths for detecting barrier divergence bugs.
racechecker.
racechecker is a device dependent tool designed only for detecting cuda data race bugs.
specifically it can only detect the data race bugs incurred in shared memory.
in particular racechecker can detect all the data race bugs that are relevant to shared memory but fails to detect other synchronization bugs including the data race bugs incurred in global memory from the manually identified bugs for our preliminary study.
note that since racechecker does not involve smt solver it does not report any false positive data race bug as the other smt solver based approaches.
.
.
further study on previously unknown bugs.
after our preliminary study we further apply simulee and all the compared techniques to detect previously unknown synchronization bugs forall the projects with the results demonstrated in table which follows the same format as table .
from the table we can observe that simulee detects bugs and reports false positives in total where all the false positives are redundant barrier function bugs in kernel function findmaxcorr .
note that simulee reports such false positives because it is possible that automatic input generation may miss some potential error inducing inputs that can trigger synchronization bugs such that a barrier function can be reported as a redundant barrier function.
meanwhile even the most effective existing technique i.e.
gpuverify can only detect previously unknown bugs with false positives.
we have also reported all the detected bugs to the corresponding developers and show their feedback statistics in table .
to date they have confirmed bugs in total tt including data race bugs dr barrier divergence bug bd and redundant barrierfunction bugs rb .
to be specific the developers of cudpp and cudasift responded as follows i think you re right... there are considerably faster ways to do matrix multiply calls... cudpp 945icse may seoul republic of korea mingyuan wu yicheng ouyang husheng zhou lingming zhang cong liu and yuqun zhang table developer feedback statistics pr ojectsdete cted confirme d under discussion nonr esponse t t dr rb bd t t dr rb bd t t dr rb bd t t dr rb bd kaldi thundersvm cudasift cuda cnn cudpp gunrock t otal const int32 cuda tid threadidx.y blockdim.x threadidx.x ... if tid warpsize pragma unroll for intshift warpsize shift shift ssum ssum ... figure an example of false race yes there is a bit of cleaning up to do there.
sometimes when i detect oddities in the output i add an unnecessary synchronization just in case.
in fact those things should be all run on the same thread since it cannot be parallelized anyway.
thank you for pointing it out.
cudasift since barrier divergence is an undefined behavior it may not hang on every situation.
the developers of gunrock responded as follows and further fixed the bug in a later commit i do see what stefanlyy eagleshanf mean for the divergence issue and surprise the code didn t hang.
in addition data race bugs are still being actively discussed by developers.
we label such bugs under discussion as stated in table .
in summary it can be observed from section .
.
and section .
.
that simulee can correctly detect most of the synchronization bugs while the other approaches are all limited in their detection scopes failing to detect certain bugs that they are designed for or triggering additional false positives.
we now summarize the reasons why simulee can outperform the other approaches simulee applies lightweight evolutionary test generation guided by effective memory access modeling and dynamic runtime monitoring in tandem for powerful cuda synchronization bug detection.
on the other hand the other approaches are usually bounded by heavyweight techniques such as constraint solvers which prevent the techniques from exploring all the possible cases.
threats to validity the threats to external validity mainly lie in the subjects and faults used in our benchmark.
though the projects of our benchmark suite may not represent the overall project distributions they shall be selected in order to possibly maximize the overall features of the cuda projects.
in this way our benchmark is derived based on real world programs from github i.e.
we select seven popular cuda related projects with a total of commits and .
million loc.
the threats to internal validity mainly lie in the potential bugs in our implementation due to the complicated mechanism of simulee.to reduce the threats three graduate students closely mentored by three se systems supervisors have been carefully working for over one year.
we manually reviewed all our implementation code and also included corresponding tests for verifying our implementation.
in addition the effectiveness of automatic input generation can impact on the performance synchronization bug detection.
it is possible that the automatic input generation component may miss certain inputs that can trigger synchronization bugs such that simulee would miss detecting the bug or report a false positive.
to reduce this threat we set a large number of suitable parameters for the evolutionary algorithm adopted in automatic input generation to reduce the probability of missing error inducing inputs.
to threats to construct validity mainly lie in the metrics used in this work.
to reduce the threats we measure the number of both previously known and the identified bugs detected by the studied techniques as well as their false positive rate and corresponding time cost.
related work as our work investigates the automatic bug detection techniques for cuda programs the related work includes the following two parts empirical studies on cuda programs and techniques of cuda bug detection.
moreover since simulee essentially is a search based bug detection technique we also discuss such relevant work.
empirical studies for cuda programs there are several existing work that study bugs and other features on cuda programs.
for instance yang et al.
delivered the empirical study on the features of the performance bugs on cuda programs burtscher et al.
studied the control flow irregularity and memory access irregularity and found that both irregularities are mutually dependent and exist in most of kernels.
che et al.
examined the effectiveness of cuda to express with different sets of performance characteristics.
some researchers are keen on the comparisons between cuda and opencl.
for instance demidov et al.
compared some c programs running on top of cuda and opencl and found that they work equally well for problems of large size.
du et al.
on the other side studied the discrepancies in the opencl and cuda compilers optimization that affect the associated gpu computing performance.
in our previous work we also conducted empirical studies to explore cuda program features.
for instance we investigated the features and the distribution of multiple cuda program bug types based on a collected github dataset .
moreover we developed an approach that can automatically repair cuda synchronization bugs via program transformation and validated its performance via an experimental study based on real world benchmarks .
cuda bug detection unlike traditional program bugs which can be deterministically tested and debugged cuda synchronization bugs especially data race and barrier divergence can often result in undefined behaviors.
to detect such bugs there are typically two types of approaches compiler based approaches and static analysis smt solver based approaches.
in particular compiler based approaches e.g.
usually link the detectors to the applications in the compiling stage and detect the bugs in the runtime process of gpu programs.
they are limited by not being fully automatic because developers have to manually 946simulee detecting cuda synchronization bugs via memory access modeling icse may seoul republic of korea provide test cases.
moreover given inferior inputs the synchronization bugs might not be triggered and detected because such bugs could only occur under limited conditions.
they can also be expensive since such runtime detection demands compiling process and gpu computing environment.
to the best of our knowledge these approaches fail to detect barrier divergence and redundant barrier function because of their detection mechanisms.
on the other hand various automatic synchronization bug detection approaches e.g.
depend on static analysis and smt solver which could lead to poor runtime performance when handling complicated gpu programs.
besides such approaches tend to report false positives or false negatives because it lacks runtime information.
although developers do not have to provide whole test inputs for them they still need to provide heuristic settings in order to avoid path explosions e.g.
dimension settings for gpuverify main functions and initial environments of kernel functions for gklee.
compared with these approaches simulee can automate the detection process to achieve superior detection performance by enabling the automatic input generation component and the memory based synchronization bug detection component.
search based software engineering.
the optimization approaches such as evolutionary programming are widely used to solve software engineering problem by modeling them into optimization problems .
yu et al.
proposed a metric pset constraint to detect cpu based synchronization bugs.
harman et al.
applied evolving pareto front approximation to refactor software systems.
hierons et al.
used many objective evolutionary optimisation to optimize the process of software product selection.
mcminn et al.
evolved coverage criteria to improve the performance of bug detection.
ouni et al.
modeled the process of refactoring into a multiple objective search based problem for generating refactor patches.
conclusions in this paper we develop a fully automated approach namely simulee that can successfully detect cuda synchronization bugs efficiently based on accurate memory access modeling.
more specifically simulee consists of two different components the automatic input generation component that applies evolutionary computation for automatically generating bug inducing test inputs and the bug detection via memory access model component that builds an accurate memory model for deriving the underlying cuda synchronization bugs.
to evaluate the efficacy of simulee we construct a benchmark from real world cuda related projects.
our evaluation results suggest that simulee can detect most of the manually identified synchronization bugs out of the studied projects and successfully detect previously unknown bugs which have never been reported detected before.
in addition simulee can achieve better effectiveness and efficiency than multiple state of the art approaches.
acknowledgement this work is partially supported by the national natural science foundation of china grant no.
shenzhen peacock plan grant no.
kqtd2016112514355531 and science and technology innovation committee foundation of shenzhen grant no.jcyj20170817110848086 .
this work is also partially supported by national science foundation under grant nos.
ccf and ccf as well as ant financial services group.