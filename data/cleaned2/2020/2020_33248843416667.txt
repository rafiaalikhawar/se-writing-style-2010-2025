revisiting the relationship between fault detection test adequacy criteria and test set size yiqun t. chen university of washington seattle wa usarahul gopinath cispa helmholtz zentrum saarbr cken germanyanita tadakamalla george mason university fairfax va usamichael d. ernst university of washington seattle wa usa reid holmes university of british columbia vancouver bc canadagordon fraser university of passau passau germanypaul ammann george mason university fairfax va usaren just university of washington seattle wa usa abstract the research community has long recognized a complex interrelationship between fault detection test adequacy criteria and test set size.
however there is substantial confusion about whether and how to experimentally control for test set size when assessing how well an adequacy criterion is correlated with fault detection and when comparing test adequacy criteria.
resolving the confusion this paper makes the following contributions a review of contradictory analyses of the relationships between fault detection test adequacy criteria and test set size.
specifically this paper addresses the supposed contradiction of prior work and explains why test set size is neither a confounding variable as previously suggested nor an independent variable that should be experimentally manipulated.
an explication and discussion of the experimental designs of prior work together with a discussion of conceptual and statistical problems as well as specific guidelines for future work.
a methodology for comparing test adequacy criteria on an equal basis which accounts for test set size without directly manipulating it through unrealistic stratification.
an empirical evaluation that compares the effectiveness of coverage based testing mutation based testing and random testing.
additionally this paper proposes probabilistic coupling a methodology for assessing the representativeness of a set of test goals for a given fault and for approximating the fault detection probability of adequate test sets.
ccs concepts software and its engineering software testing and debugging empirical software validation.
keywords fault detection test set size mutation testing code coverage acm reference format yiqun t. chen rahul gopinath anita tadakamalla michael d. ernst reid holmes gordon fraser paul ammann and ren just.
.
revisiting the permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn ... .
between fault detection test adequacy criteria and test set size.
in 35th ieee acm international conference on automated software engineering ase september virtual event australia.
acm new york ny usa pages.
introduction the software engineering research community has long recognized a complex interrelationship between three variables fault detection the degree to which a test set detects real faults test set adequacy the degree to which a test set satisfies a set of test goals such as statements branches or mutants and test set size the cardinality of a test set .
fault detection is the best estimate for a test set s efficacy but fault detection is not directly measurable since the number of unfound faults in a program is unknowable.
as a result developers and researchers use test set adequacy criteria such as code coverage or mutant detection as a proxy measure.
there is a positive association between test set size and the other two variables.
for example adding a test to a given test set cannot decrease fault detection or test set adequacy.
similarly reducing a given test set cannot increase fault detection or test set adequacy.
moreover best practices e.g.
modularity and separation of concerns result in a strong association between test set adequacy and test set size.
for example a developer may write one test per use case or function.
namin and andrews empirically showed a strong association between fault detection test set adequacy and test set size and noted that large test sets with low adequacy and small test sets with high adequacy were unattainable in practice.
however beyond the observation that the three variables are positively associated the strength of the associations and their precise relationships are a matter of open debate and controversy in the research community.
consider fig.
which shows the relationship between the three variables fault detection test set adequacy specifically code coverage ratio and mutant detection ratio and test set size.
for each of 2311real faults from the defects4j benchmark we created coverage adequate test sets and mutation adequate test sets greedily selecting tests from the pool of existing developer written tests that accompany the fault.
at each selection step tests are selected at random and the first test that increases test set adequacy is added to the test set.
during test selection we measured all three variables at each test selection step.
figure plots the aggregated 1this paper uses a subset of defects4j for consistency with prior work .
35th ieee acm international conference on automated software engineering ase ase september virtual event australia y. chen r. gopinath a. tadakamalla m. ernst r. holmes g. fraser p. ammann r. just .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
code coverage ratiofault detection probability .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
code coverage rationumber of selected tests .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mutant detection ratiofault detection probability .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mutant detection rationumber of selected tests figure test sets generated to achieve a mutant detection rate rexhibit higher fault detection but are also substantially larger than those generated to achieve coverage rate r. these plots show the results of adequacy based test selection for faults details in section .
each adequacy bucket i.e.
all test sets that have a coverage ratio or mutation detection ratio in the indicated range includes data points.
results fault detection probability and average test set size for each of the faults and given adequacy threshold shown in buckets for simplification .
each data point in an adequacy bucket corresponds to one of the real faults.
figure illustrates the positive association between test set adequacy fault detection and test set size test sets with higher adequacy code coverage ratio or mutant detection ratio have a higher fault detection probability and are larger in size.
what fig.
cannot answer however is which of the two adequacy criteria provides better selection goals at any point in the process including the end point.
more precisely consider two test sets tm generated to achieve mutant detection and tc generated to achieve code coverage.
according to fig.
tmhas a greater fault detection probability than tcon average however tmis also substantially larger than tcon average.
does tmhave greater fault detection because mutation provides better test goals than coverage or does it have greater fault detection just because satisfying mutation adequacy requires more tests?
likewise does selecting tests based on an adequacy criterion achieve greater fault detection than randomly selecting the same number of tests?
consequently should a developer select tests based on coverage mutation or just randomly?
one approach previously used to answer this question measures the correlation between test set adequacy and fault detection for fixed test set sizes.
this stratification approach repeatedly draws test sets of the same size independently and uniformly at random from a test pool and analyzes the results for each stratum .
prior work has also proposed two alternatives.
alternative creates test sets based on a given test budget and objective and then measures and correlates fault detection and test set adequacy .
alternative considers existing test sets created based on sometest objective and assesses the importance of test set adequacy and test set size when modeling fault detection .
these three approaches to teasing out the role of test set size are all valid approaches in principle.
however the experiments in the literature adopting these approaches have resulted in contradictory conclusions.
there are multiple reasons for this including the interpretation of correlation values noise in the data and the applied models of random test selection.
this paper investigates and resolves the supposed contradiction of prior work its contributions and organization are as follows a review of four contradictory analyses of the relationship between fault detection test set adequacy and set size section and an explication of their experimental designs section .
a discussion of conceptual problems explaining why test set size is neither a confounding variable as previously suggested nor an independent variable that should be experimentally manipulated section and statistical pitfalls section .
a methodology for comparing test adequacy criteria that accounts for test set size without directly manipulating it through stratification section .
an empirical evaluation that compares the effectiveness of coverage based testing mutation based testing and random testing sections .
to .
.
additionally this paper proposes probabilistic coupling a methodology for assessing the representativeness of a set of test goals for a given fault and for approximating the fault detection probability of adequate test sets section .
.
consistent with prior work this paper uses test set size as a proxy for the cost of creating or executing a set of tests section discusses the validity of using test set size as a proxy for these variables.
test set size in prior work previous refereed papers that study the relationship between fault detection test set adequacy and test set size report on experiments with contradictory conclusions.
this is a serious scientific problem which ones are trustworthy?
as examples this section provides two pairs of papers with similar research questions but contradictory results gopinath et al.
and inozemtseva and holmes just et al.
and papadakis et al.
.
these papers report contradictory conclusions about whether and how test set size should be experimentally controlled when assessing the correlation between test set adequacy and fault detection and whether the correlation between test set adequacy and fault detection is significant and strong.
while some previous work notes these conflicts without providing resolutions of greater concern is the fact that many other papers simply cite the aforementioned papers without noting the contradictions.
as of august google scholar reports over citations to these four papers.
this section briefly reviews each of these four papers.
each review focuses on the aspects relevant to the apparent contradictions and does not necessarily provide a complete summary of contributions and findings.
sections to resolve the conflicts by showing which papers have flawed experimental or statistical methodology.
238revisiting the relationship between fault detection test adequacy criteria and test set size ase september virtual event australia .
gopinath et al.
icse gopinath et al.
investigated whether code coverage is strongly correlated with fault detection for seeded faults mutants .
the study used java projects of different sizes and characteristics.
test source both developer written tests existing test sets and automatically generated tests randoop were separately analyzed.
automatically generated tests were created based on a fixed time budget.
test set sampling none.
each test set developer written and automatically generated was used for analysis without sampling.
test adequacy measures statement coverage block coverage branch coverage and path coverage.
statistical methodology considering all java projects the study used regression analysis with mutant detection as the dependent variable and test set adequacy along with project size and cyclomatic complexity as independent variables.
test set size was not included in the model to avoid multicollinearity the study identified a strong correlation between test set size and project size testset sizewasrepresented inthemodel viaproject sizeasaproxy.
results and conclusions statement coverage on its own was strongly correlated with mutant detection and this correlation was stronger compared to those of all other studied code coverage criteria.
the correlation between statement coverage and mutant detection was stronger for developer written test sets than for automatically generated test sets.
test set size did not increase model accuracy when test set adequacy was already included in that model.
.
inozemtseva and holmes icse inozemtseva and holmes investigated whether code coverage is strongly correlated with fault detection for seeded faults mutants when test set size is ignored and controlled for.
the study used five java projects of different sizes and characteristics.
test source developer written tests existing test sets .
test set sampling random sampling and stratification.
for each of the five java projects and different test set sizes and tests up to the maximum size possible for that project thestudy sampled testsetsoffixed size.
in total the study sampled test sets across the five projects and different test set sizes.
thestudy analyzed these testsets both with andwithoutcontrollingfortestsetsize.
each test set was sampled uniformly at random without replacement.
test adequacy measures statement coverage decision coverage and modified condition coverage.
statistical methodology for each of the five java projects the study measured and correlated code coverage and mutant detection of the randomly sampled test sets both with and without controlling for test set size.
results and conclusions the correlations between statement coverage and mutant detection were moderate to strong when test set size was ignored with almost identical results for stronger code coverage criteria.
the correlations became negligible to moderate when test set size was controlled.
.
just et al.
fse just et al.
investigated whether mutant detection is strongly correlated with fault detection.
the study used five java programs with real faults defects4j .
test source both developer written tests existing test sets and automatically generated tests evosuite jcrasher and randoop were separately analyzed .
automatically generated tests were created based on a fixed time budget.
test set sampling none.
each test set developer written and automatically generated was used for analysis without sampling.
test adequacy measures statement coverage and mutant detection.
statistical methodology for each real fault the study analyzed pairs of existing pre fix and post fix developer written test sets and measured and correlated mutant detection and fault detection of automatically generated test sets both with and without controlling for code coverage.
test setsizewas ignored because itwas notsignificantly associated with anincrease infault detection for pairs of pre fix and post fix developer written test sets anditwas irrelevant forautomatically generated testsets which were created based on a fixed time budget without further sampling.
results and conclusions the correlation between mutant detection and fault detection was moderate to strong and remained significant when code coverage was controlled for.
the correlation between mutant detection and fault detection was stronger than the correlation between statement coverage and fault detection.
.
papadakis et al.
icse papadakis et al.
investigated whether mutant detection is strongly correlated with fault detection when test size is ignored and controlled for.
the study used five java programs with real faults a subset of defects4j .
test source both developer written tests existing test sets and automatically generated tests evosuite and randoop .
for each of the real faults all developer written tests and automatically generated tests were combined intoalarge testpool.
test set sampling random sampling and stratification.
for each real fault the study sampled testsetsoffixed size in the range of ofthetestpool size with .
increments and testsetsofrandom size in the range of ofthetestpool size .
each test set was sampled uniformly at random without replacement.
test adequacy measures mutant detection.
statistical methodology for each real fault the study measured and correlated mutant detection and fault detection of the randomly sampled test sets both with and without controlling for test set size.
results and conclusions the correlations between mutant detection and fault detection were moderate to strong when test set size was ignored.
the correlations became negligible to weak when test set size was controlled.
2the study separately analyzed four c programs reaching the same conclusions.
239ase september virtual event australia y. chen r. gopinath a. tadakamalla m. ernst r. holmes g. fraser p. ammann r. just .
apparent contradictions code coverage vs. artificial fault detection gopinath et al.
built a regression model that used code coverage to predict fault detection.
the study concluded that code coverage is strongly correlated with fault detection and adding test set size to the regression model did not improve its accuracy.
in apparent contradiction inozemtseva and holmes used stratification to control for test set size and computed correlations between code coverage and fault detection at each strata.
based on the small absolute values of the correlations the study concluded that code coverage is not strongly correlated with fault detection when test set size is taken into account.
in other words gopinath et al.
found test set size to play essentially no role whereas inozemtseva and holmes found test set size to play a dominant role.
note that gopinath et al.
performed a regression analysis across projects whereas inozemtseva and holmes performed a correlation analysis for each project.
mutant detection vs. real fault detection just et al.
correlated mutant detection and fault detection for pairs of pre fix and post fix developer written test sets and separately automaticallygenerated test sets.
the study concluded that mutant detection is strongly correlated with fault detection for most real faults and the correlation between mutant detection and fault detection was stronger than the correlation between statement coverage and fault detection.
furthermore test set size was an insignificant factor when comparing pre fix and post fix developer written test sets.
in apparent contradiction papadakis et al.
expanded the approach used by inozemtseva and holmes used stratification to control for test set size and computed correlations between mutant detection and fault detection.
based on the small absolute values of the correlations the study concluded that mutant detection is only weakly correlated with fault detection when test set size is taken into account.
given the observed weak correlations when test set size was controlled the study concluded that test set size is a confounding variable that explains fault detection.
abstract experiment design the four papers described in section yielded seemingly contradictory results about the relationships between fault detection test set adequacy and test set size.
this section describes the experimental artifacts and design of these papers at an abstract level and the constraints these artifacts imposed on the experimental results.
all experiments in section have the same overall structure.
first there is a universe of tests from which it is possible to sample a test set according to some distribution.
second there is an oracle that determines for each test whether a test detects a fault success or failure event.
note that a failing test that detects a fault corresponds to the success event and a passing test that does not detect a fault corresponds to the failure event.
third there is an adequacy criterion that imposes test goals on the system under test.
for each test it is possible to compute the set of test goals satisfied by that test as well as a summary statistic that captures the overall criteria satisfaction.
for example for mutation based testing the former amounts to computing the set of mutants detected by a given test and the latter amounts to computing the overall mutant detection ratio.
the crucial step is choosing the methodology for subsequent analysis which we outlined in section and expand upon here randomselection create by various means a large fixed universe of tests i.e.
the test pool sample test sets from this test pool uniformly at random without replacement and measure and correlate fault detection and test set adequacy.
this methodology has two variants sizefixed fix the test set size via stratification and analyze the results independently for each stratum.
sizerandom draw the test set size itself from a distribution prior to sampling a test set.
alternative create test sets based on a given time budget and test objective and measure and correlate fault detection and test set adequacy.
alternative consider existing test sets created according to some test objective measure fault detection test set adequacy and test set size and statistically assess the importance of test set adequacy and test set size.
we will expand on the randomselection methodology because it is popular yet unrealistic and prone to wrong conclusions and its underlying problems are easily neglected.
the subsequent sections explicate and address its conceptual and statistical problems.
section first describes why the randomselection methodology is problematic at a conceptual level test set size is an unrealistic test objective section .
and test generation in practice does not yield an independent random sample section .
.
section further provides a technical explanation of the statistical pitfalls of the randomselection methodology using highly correlated explanatory variables section .
ignoring the bounds of the point biserial correlation section .
and ignoring the class imbalance effect due to extremely low or high fault detection probabilities section .
produces misleading results.
conceptual problems prior work using the randomselection methodology performed a correlation analysis of test set adequacy and fault detection over randomly sampled test sets in particular it modeled test set creation as a uniform random selection process of tests from a finite test pool.
there are two often neglected conceptual issues with this methodology the first is concerned with the use of test set size as test objective and the second is concerned with how representative the random selection process is for test set creation in practice.
.
test set size is an unrealistic test objective a test adequacy criterion can be used for either test set creation where an adequacy criterion provides test goals that facilitate test selection under a given budget or test set evaluation where an adequacy criterion provides an adequacy score for an existing test set e.g.
generated by developer preference .
however using the randomselection methodology to create a test set of a given size measured as the number of tests does not model developer behavior.
developers do not use the number of tests as a test objective nor should they.
an appropriate stopping criterion in terms of number of tests is unknowable should a developer write tests or tests for a given program and how?
in practice developers write tests using a mix of many different objectives such as exercising a new feature exposing a defect i.e.
regression test or optimizing for an adequacy criterion .
240revisiting the relationship between fault detection test adequacy criteria and test set size ase september virtual event australia furthermore what exactly constitutes a single test is not well defined since real world tests are decidedly non uniform unit vs. integration vs. system tests one vs. many assertions per test etc.
.
for example just et al .
found that developers were equally likely to strengthen an existing test or adding a new test when exposing a defect.
in other words the number of tests was irrelevant in this case and did not accurately measure test set size.
test adequacy criteria such as code coverage and mutant detection may be imperfect test objectives but in contrast to test set size they are well defined and provide concrete test goals.
in conclusion analyzing the correlation between test set adequacy and fault detection using the randomselection methodology does not provide actionable insights for real world test creation.
.
test generation vs. independent random sample for an implementation of a simple function e.g.
y f x a test generation approach might sample inputs xuniformly at random without replacement from the universe of all inputs e.g.
all integers and repeat this process independently for many iterations.
however automated test generators for e.g.
object oriented programs do not sample tests via independent random sampling.
in fact most automated test generators create subsequent tests based on the tests generated thus far.
hence the randomselection methodology while simple to execute is not a realistic model of either developers or automated test generators.
note that the key conceptual issue is the non guided random selection of ntests selection based on a realistic test objective is reasonable.
the eclat tool introduced feedback directed random test generation which was popularized by randoop .
when randoop generates a valid test a sequence of instructions it uses that test to build subsequent larger tests in other words it guides the search toward that valid test.
when randoop generates an invalid test it prohibits creation of tests that build on it in other words it guides the search away from the invalid test.
additionally randoop eliminates redundant and subsumed tests from the final test set.
feedback directed generation was motivated in part by the poor performance of independent random sampling.
another example of a test generation tool is evosuite which uses meta heuristic search to generate test sets that maximize code coverage while minimizing size.
meta heuristic search is essentially a sampling process of an implicit probability distribution in that search space using a combination of stochastic search operators.
the main operators are mutation of tests which may insert remove or replace arbitrary statements in a candidate sequence and crossover of two tests where subsequences of two parents are recombined to two new offspring sequences.
the sampling process is guided by fitness functions that estimate how close tests are to satisfying test goals.
the number of calls in a sequence is treated as a secondary objective such that given two tests that are equal in terms of their fitness the shorter one is preferred.
the search uses a many objective optimization algorithm where a single population of individuals is evolved with respect to all test goals thus sampled tests are not independent and in fact very much dependent.
in conclusion the randomselection methodology is not a good approximation of test creation processes in practice neither for developers nor for automated test generators.
statistical pitfalls measuring the efficacy of an adequacy criterion by correlating test set adequacy and fault detection while controlling for test set size has become increasingly popular in empirical studies first a large number of test sets is created based on random sampling from an existing test pool.
consistent with prior sections we refer to the two variants of this randomselection methodology assizefixed if each test set has the same size e.g.
tests or of the test pool and sizerandom if the size of each test set follows a non trivial probability distribution e.g.
of the test pool uniformly at random .
second the adequacy criterion of interest e.g.
code coverage or mutant detection and fault detection are computed for each test set.
finally a higher empirical correlation between fault detection and test set adequacy corresponds to a more effective adequacy criterion.
despite its popularity the correlation analysis based on the randomselection methodology has three statistical pitfalls that are often neglected in practice.
first correlation analysis does not allow causal conclusions without further assumptions on the underlying process.
for instance one cannot statistically distinguish a confounding variable e.g.
test set size impacts both fault detection and test set adequacy with no direct relationship between the two from a mediating variable e.g.
test set size impacts fault detection by itself andthrough test set adequacy .
in particular the notion of confounding effects implies a causal relationship which cannot be concluded from simply a change in correlations .
second correlation between a dichotomous variable e.g.
fault detection which takes on either success or failure and a continuous variable e.g.
mutant detection is bounded and the bound depends on the success probability of the dichotomous variable.
third correlating two variables based on stratification on a third is a crude approximation to what is known as the partial correlation .
the stratification leads to a limited range of the resulting correlation and in particular often makes it incomparable to the non stratified version .
the rest of this section explains why the randomselection methodology in general and its sizefixed variant in particular is prone to misleading results and wrong conclusions.
section .
argues that attempts to attribute the fault detection contribution to one of two highly correlated variables are ill posed the section proceeds to discuss some alternative data analysis methods.
section .
explains that the absolute value of the point biserial correlation a special case of the pearson correlation is bounded with a maximum much smaller than in many cases.
section .
expands on the bounded correlation observation and analyzes the randomselection methodology used in previous studies this section reveals the neglected flaws of this methodology especially the correlations obtained with the sizefixed variant.
.
highly correlated explanatory variables in practice test set adequacy and test set size are highly correlated and both are correlated with fault detection.
however the question of which of the two explains fault detection is ill posed and cannot be answered by measuring the correlation e.g.
between test set adequacy and fault detection while controlling for test set size.
241ase september virtual event australia y. chen r. gopinath a. tadakamalla m. ernst r. holmes g. fraser p. ammann r. just more precisely when controlling for one of the two variables the observed correlation of fault detection and the other variable will necessarily be weaker.3in particular partial correlations may yield spurious results and do not necessarily give rise to an interpretable coefficient because their sign and range are quite sensitive to the pairwise correlations among the variables being studied .
therefore a more principled data analysis method to investigate therelative importance of test set adequacy and test set size is to employ multiple regression and use effect size measures such as regression coefficients.
another possible approach is to use a standard variable selection method to see how much additional predictive power test set adequacy provides in addition to test set size when used to predict fault detection.
we refer interested readers to more detailed expositions in h rdle and simar and james et al.
.
.
point biserial correlation is bounded pearson correlation with point biserial correlation as its special case is widely used to characterize the relationship between two variables and standard guidelines exist for interpreting the resulting coefficient e.g.
weak vs. strong correlation .
however these guidelines are only appropriate when the pearson correlation ranges from to .
consider a pearson correlation between a continuous variable e.g.
test set adequacy and a dichotomous variable e.g.
fault detection .
this special case of the pearson correlation is also known as the point biserial correlation4.
the coefficient of this correlation is at most .
and its range can be even smaller.
following gradstein and cheng and liu eq.
expresses the maximal correlation between a normally distributed continuous variable and a dichotomous variable as a function of the latter s success probability p where z1 pis the pquantile of a standard normal distribution rmax 1p 2 p p exp z1 p we observe that the maximal correlation for p .
is close to .
instead of the maximal correlation decreases monotonically as pmoves away from .
and the maximal correlation is symmetric around p .
.
for example the maximal correlation forp .
and p .
is .
and the standard guidelines for interpreting the pearson correlation would incorrectly conclude that two perfectly correlated variables are notstrongly correlated.
this is not a hypothetical problem.
consider the defects4j dataset and a large test pool of automatically generated test sets say from randoop and evosuite .
some defects4j faults are almost always detected with many fault detecting tests per test set whereas others are almost never detected with many non fault detecting tests per 3consider the extreme case in which two explanatory variables x1andx2are perfectly correlated e.g.
x1 x2 and both are correlated with an outcome variable y. fixing the value of x1also fixes the value of x2 hence the conditional variance of x2 x1 is and a partial correlation cannot even be computed.
the general version of this problem is known as multicollinearity and results in unreliable estimates in regression analysis .
4prior work missed the fact that the point biserial correlation is mathematically equivalent to the pearson correlation when arguing in favor of one over the other.test set .
for these faults the randomselection methodology results in very low or very high probabilities of success and hence small maximal correlation coefficients.
very low or very high probabilities of success can result in a significant underestimation of the true correlation .
this problem is particularly pronounced for the sizefixed variant.
for example out of test set sizes used in prior work result in success probabilities of p .
orp .
for most faults.
in fact even the most balanced out of test set sizes results in success probabilities of p .
orp .
for more than of the faults.
a possible fix is to normalize the correlation by an upper bound such as the one computed from eq.
.
however not only does the maximal correlation depend on the exact distribution of the continuous variable which makes the exact upper bound hard to compute such procedures also lack statistical guarantees .
.
therandomselection methodology is flawed this section shows that the correlation between test set adequacy and fault detection computed with the randomselection methodology is extremely sensitive to the distribution of fault detecting tests in a test pool which resulted in misleading interpretations of thesizefixed results in previous work.
to provide concrete examples this section uses the defects4j faults and the corresponding combined test pools used by papadakis et al .
see section .
.
we first make precise the mathematical relationships between test set size fault detection and test set adequacy under the sizefixed variant.
let ndenote the test pool size k nthe number of fault detecting tests in the test pool and n nthe test set size then the number of fault detecting tests x out of the nsampled tests follows a hypergeometric distribution hg n k n taking on integer values between and min k n p x x n k n x k x n n .
given a test set size n the probability of success p i.e.
the probability of sampling a fault detecting test set therefore is equal to the probability of sampling at least one fault detecting test p p x p x n k n n n n n k n n k this analysis can be extended to the sizerandom variant where nitself is now drawn from a distribution and the resulting probability of success pis a convolution of different distributions.
this analysis can also be extended to computing the probability of satisfying any single test goal for a given adequacy criterion e.g.
detecting a mutant .
combining these individual test goal distributions into a cumulative distribution for the corresponding test set adequacy measure e.g.
the mutant detection ratio requires knowing the interdependencies between test goals but is nonetheless computable.
however given the complexity of such an analysis a common approach is to resort to simulations with sampled test sets to get a close approximation .
the key point is that test set size completely determines the distribution of test set adequacy and fault detection.
242revisiting the relationship between fault detection test adequacy criteria and test set size ase september virtual event australia .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
test set size relative to test pool size plot fault detection probability maximal correlation observed correlation mutant detection ratio fault not detected fault detected figure relationship between mutant detection and fault detection when controlling for test set size closure .
the test pool contains tests out of which are fault detecting.
the red line gives the probability of sampling a fault detecting test set as a function of test set size eq.
.
the solid blue line gives the theoretical maximal correlation eq.
and the dashed blue line the observed correlation between mutant detection and fault detection.
the observed correlation is set to if all sampled test sets are fault detecting.
for all but the smallest test set sizes the vast majority of sampled test sets are fault detecting.
this class imbalance leads to very small correlation coefficients even if the underlying correlation is actually strong.
for a fixed test size n the probability of success largely depends on the ratio k n which leads to the class imbalance effect motivated in section .
.
figure precisely demonstrates this class imbalance effect and its implication on the maximal and observed correlations.
for a particular fault closure we used the sizefixed variant to sample test sets for each of distinct test sizes following the methodology described in section .
.
for each test set size fig.
shows the results in particular the mutant detection ratios of the sampled test sets grouped by fault detection the probability of sampling a fault detecting test set eq.
and the maximal correlation eq.
and the observed correlation.
the results show that the probability of sampling a fault detecting test set is close to for all but very small test set sizes.
for example at test set size that probability is .
in expectation over of the sampled test sets are fault detecting which leads to a maximal correlation of .
.
a naive interpretation of the observed correlation coefficients would conclude that mutant detection and fault detection are weakly correlated at best for most test set sizes.
we extended the analysis of the class imbalance effect to all faults.
for each fault fig.
plots the distribution of the faultdetection probabilities and the corresponding distribution of the maximal correlations as a function of test set size.
figure 3a demonstrates that the probability of detecting a fault monotonically increases as a function of test set size and different faults exhibit distinct fault detection probability curves.
more precisely at test set size faults take on distinct probabilities.
note that the more upper left a curve is the more fault detecting tests exist in that fault s test pool.
similarly the diagonal corresponds to faults with only a single fault detecting test.
connecting these distributions to the maximal correlation discussion in section .
fig.
3b plots the maximal correlation5between mutant detection and fault detection for each fault again as a function of test set size.
5assuming that mutant detection is normally distributed.
.
.
.
.
.
.
test set size relative to test pool size fault detection probability a fault detection probability.
.
.
.
.
.
.
test set size relative to test pool size maximal correlation b theoretical maximal correlation.
figure fault detection probability and theoretical maximal correlation as a function of test set size for all faults.
each line is a distinct fault in total .
a for faults with many fault detecting tests in their test pool the fault detection probability i.e.
selecting at least one fault detecting test is nearly a step function for faults with only one faultdetecting test in their test pool the fault detection probability is a straight line.
b for faults with five or more fault detecting tests in their test pool of all faults the maximal correlation peaks before test set size for faults with only one fault detecting test in their test pool of all faults the maximal correlation peaks at test set size.
the key takeaway from fig.
is that the maximal correlation is a function of the test set size and varies drastically across faults and different test set sizes.
for example even at test set size of all faults have a maximal correlation of less than .
.
a naive interpretation of the observed correlation coefficients would always conclude that mutant detection and fault detection are weakly correlated or uncorrelated even if they were perfectly correlated.
243ase september virtual event australia y. chen r. gopinath a. tadakamalla m. ernst r. holmes g. fraser p. ammann r. just at a fixed test set size the correlations between mutant detection and fault detection have drastically different maximums for different faults.
therefore summary statistics e.g.
median and boxplots can be misleading since each individual fault has a very different range of variation across different test set sizes.
to illustrate this point consider the four selected faults in fig.
whose ratios of fault detecting tests differ substantially.
figure 4a plots the fault detection probability and maximal correlation for these faults as a function of test set size.
the maximal correlations for chart math and closure peak very early compared to lang .
figure 4b reports the observed correlations between mutant detection and fault detection for sizefixed sampling at and together with a sizerandom sampling where test set size is drawn uniformly at random from .
for sizefixed the median correlation across the four faults and all test set sizes is .
and a naive interpretation of this correlation coefficient is that mutant detection and fault detection are uncorrelated.
note that extending the range of the sizefixed sampling to makes matters worse the observed correlations become for most test set sizes and faults except for lang .
further note that the class imbalance also affects the sizerandom variant though to a lesser extent.
for example and of the sizerandom sampled test sets for chart and math respectively are fault detecting whereas only of the sampled test sets for lang are fault detecting.
closure is most balanced with fault detecting test sets.
while the correlation computed under the sizerandom variant is larger than the sizefixed one for chart math and closure the opposite is true for lang .
this contradicts the confounding effects theory mutant detection is weakly correlated with fault detection after controlling for test set size but is consistent with our analysis above a relatively large ratio of faultdetecting tests for chart and math means that larger observed correlation coefficients occur below .
test set size which only thesizerandom variant samples.
in contrast lang has only one fault detecting test and the maximal correlation peaks at test set size.
this means the sizerandom variant samples more of the low correlation region.
if the confounding effects theory holds one would expect the correlation to be attenuated for all faults.
this however is not the case.
in conclusion the randomselection methodology can be misleading and should be interpreted with care if not avoided all together.
in particular the class imbalance problem has contributed to unsubstantiated claims and incorrect conclusions in previous work.
controlling for test set size section motivated controlling for test set size when answering research questions about the effectiveness of test adequacy criteria.
however sections and demonstrated the adverse effects of directly manipulating test set size as an independent variable in a random selection process.
this section resolves this dilemma and describes a methodology that accounts for test set size without directly manipulating it and without changing the test objective.
recall figure which compared mutation based with coveragebased testing.
it is not surprising that mutation adequate test sets achieve a higher fault detection probability than coverage adequate closure lang 51chart math .
.
.
.
.
.
.
.
.
.
.
.
test set size relative to test pool size plot fault detection probability maximal correlation a fault detection probability and theoretical maximal correlation between fault detection and mutant detection.
fault fault detecting tests in test pooltest set size relative to test pool size sizefixed sizerandom chart .
.
.
.
.
math .
.
.
.
.
.
closure .
.
.
.
.
.
lang .
.
.
.
.
.
b observed correlations between fault detection and mutant detection for both variants of the randomselection methodology.
figure case study for four selected faults.
chart and lang correspond to the two extremes in fig.
and closure corresponds to the detailed example in fig.
.
for chart and math the faultdetection probability is indistinguishable from for all but the smallest test set sizes it is highly unlikely to sample a non fault detecting test set even when sampling test sets.
the observed correlation is set to if all sampled test sets are fault detecting.
the median correlation across the four faults and allsizefixed test set sizes is .
.
the class imbalance problem also affects sizerandom out of the sampled test sets for each fault are faultdetecting for chart for math for closure and for lang .
test sets mutation adequacy requires satisfying more test goals.
however figure does not directly answer questions such as q1 is mutation based test generation more effective than coveragebased test generation for test sets of the same size?
q2 does mutation provide better test goals than code coverage or does it simply elicit more tests?
the primary goal of this section is to describe a general methodology for evaluating testing approaches taking test set size into account.
additionally this section reports on comparisons between mutation based testing coverage based testing and random testing using the described methodology.
this section consistently uses the defects4j faults used in prior work together with all developer written tests for each fault and mutation and coverage information obtained from the major mutation framework for each fault and test.
244revisiting the relationship between fault detection test adequacy criteria and test set size ase september virtual event australia .
.
.
.
.
.
.
.
.
.
.
.
test set size relative to coverage adequate test sets fault detection probabilitytesting approach coverage mutation random figure fault detection probability for coverage based test selection compared to equally sized baselines.
the trend lines are fitted over all bugs and the test set size is normalized over the final number of tests in each coverage adequate test set.
.
adequacy based test selection sometimes developers need a subset of an existing test set that runs faster.
developers often do test selection manually based on their intuition but they may also use an adequacy based test selection approach.
there might also be a run time budget e.g.
to enable a continuous integration server to run tests hourly a selected test set must run in less than an hour .
in particular we note that developers rarely use random selection with test set size as the test objective.
we use an adequacy based test selection approach and measure fault detection test set adequacy and test set size.
specifically adequacy based test selection performs the following steps greedily select one test at a time to incrementally achieve adequacy for a given adequacy criterion.
tests are selected at random the first one that satisfies at least one additional test goal is added to the test set.
as each test is added to the test set record fault detection fd or for every test set fault pair test set adequacy a and the number of tests n. test selection stops as soon as all test goals are satisfied.
our experimental methodology repeats the above adequacy based test selection procedure times for each fault and we report averages over the trials which yield small error estimates.
additionally we compute a random baseline for each fault each trial and each test set size n. the fault detection probability in this case can be computed from eq.
in section .
.
.
comparing inadequate test sets comparing two adequacy criteria accounting for test set size is straightforward until the weaker criterion is satisfied.
figure shows such a comparison for coverage based and mutation based testing.
this plot shows the fault detection probability of equally sized test sets created by increasing coverage red line and increasing mutant detection blue line respectively.
the trend lines are fitted over all faults using local regression and test set size is normalized over the final number of tests in each coverageadequate test set.
this plot sheds light on the first question q1 and shows that on average selecting tests based on coverage yields test sets that are as strong or stronger than those selected based on mutation at least until coverage is satisfied .
moreover both coverage and mutation are superior to random selection gray line .
the latter is consistent with the findings of andrews et al.
.
.
.
.
.
.
.
.
.
.
.
.
.
test set size relative to mutation adequate test sets fault detection probabilitytesting approach coverage stacked coverage mutation mutation randomfigure fault detection probability for mutation based test selection compared to equally sized baselines.
the trend lines are fitted over all bugs and the test set size is normalized over the final number of tests in each mutation adequate test set.
.
comparing adequate test sets since coverage exhausts its usefulness much earlier than mutation we need a different approach to further compare the two.
together figures and show that mutation adequate test sets will eventually be more effective than coverage adequate ones but it is not clear whether mutants provide additional value beyond simply expanding the test set e.g.
with randomly selected tests .
to assess the independent contribution of mutants as test goals we again need a baseline test set of equal size.
one possibility to achieve this is to use a stacking approach .
this means that whenever a weaker test adequacy criterion is satisfied the resulting test set is preserved and the test selection process restarted again optimizing for the same adequacy criterion.
the final test set is then the union of all created test sets.
another possibility is a hybrid approach switching to the stronger adequacy criterion as soon as the weaker one is satisfied.
figure shows the outcome of a testing simulation using both the stacking coverage stacked and the hybrid coverage mutation approach.
random is again included as a baseline.
overall the coverage mutation approach achieves the highest fault detection probability at each step in the test selection process.
the coverage mutation approach is similar to the mutation testing set up at google .
while google s decision to implement such an approach was driven by practicality and efficiency concerns our results provide empirical evidence for the effectiveness of such an approach.
.
adequacy based test set reduction in addition to adequacy based test selection focusing on adequacybased test set reduction can provide useful insights into the sensitivity of an adequacy criterion and the expected loss of faultdetection capability.
figure shows the outcome of coverage based and mutation based test set reduction in comparison to an equally sized random baseline.
figure shows the loss in fault detection probability when reducing a fault detecting test set based on coverage or mutation that is when creating a smaller yet adequate test set.
since these criteria result in test sets of different size the random baseline differs for each criterion.
the black dots indicate medians showing that most test sets reduced based on mutants maintain their fault detection capability whereas test sets reduced based on coverage see a substantial loss of fault detection capability.
245ase september virtual event australia y. chen r. gopinath a. tadakamalla m. ernst r. holmes g. fraser p. ammann r. just .
.
.
.
.
.
coverage coverage min mutation mutation min selection approachfault detection probability coverage coverage min mutation mutation min random figure fault detection probability of coverage adequate and mutation adequate test sets for all faults.
the left pair of violin plots labeled coverage correspond to two of the .
points in figure .
this figure shows all values indicates the median and indicates the mean whereas figure shows only one value the fitted average across all faults.
likewise the third pair labeled mutation correspond to two of the .
points in figure .
the text details the minapproaches.
coverage min and mutation min refer to approximated minimum test sets derived from greedily picking tests that maximize the corresponding criterion.
specifically coverage min is a test set generated in the same way as coverage described in section .
but always choosing the globally best test the one in the test pool that maximizes coverage rather than greedily choosing the first one that increases coverage at all.
next to it in figure is a randomlygenerated test set of the same size.
mutation min is analogous.
.
probabilistic coupling the key takeaway from section is that even a well established and understood statistical measure such as a correlation coefficient may require a nuanced interpretation in software engineering research due to problems that arise from a limited set of known faults class imbalance in fault detection and noise irrelevant test goals .
without expertise in statistics and even with this is difficult and prone to incorrect conclusions and seemingly contradictory results.
section .
described a general methodology for assessing and comparing adequacy criteria accounting for test set size without experimentally manipulating it.
however estimating fault detection probabilities and comparing adequacy criteria still requires costly simulations.
further the limited set of known real faults and test goals unrelated to those faults introduce noise.
this section proposes a new measure probabilistic coupling for assessing the sensitivity of a set of test goals for a known real fault.
specifically given a real fault fand a test goal i probabilistic coupling provides an estimate for the conditional probability p p detect f iis detected that is the probability of detecting the real fault when selecting a test that satisfies the test goal.
if p we say that iis perfectly coupled to f. ifp we say that iis perfectly decoupled from f. otherwise we say that iis probabilistically coupled to f. given a set of test goals we compute the maximum probabilistic coupling between any of the test goals and the real fault.
this is because we have incomplete knowledge about the set of all possible real faults.
computing the maximum allows reasoning about the sensitivity of the employed test goals for a known real fault and is agnostic to noise caused by unrelated test goals.t1t2t3t4pc f 1 2 .
3 4 a test goal matrix.
.
.
.
.
.
.
coverage mutation selection approachprobabilistic coupling coverage mutation b maximal pcfor faults.
figure example test goal matrix left and distribution of the maximal probabilistic coupling pc values for all faults for coverage and mutation right .
the two violin plots correspond to the coverage and mutation plots in fig.
showing that probabilistic coupling closely approximates the fault detection probability of adequate test sets.
indicates that tidetects for satisfies j indicates the median and indicates the mean.
figure 8a gives an example for a test goal matrix with four test goals i four tests tj and one real fault f. the symbol indicates that tidetects for satisfies j. in this example 1is perfectly coupled to fsince every test that satisfies 1also detects f. test goals 3and 4are perfectly decoupled 4even unsatisfiable.
the probabilistic coupling for 2is .
it is satisfied by two tests one of which detects f. the maximal probabilistic coupling is which means that the set of test goals is highly sensitive to f. figure 8b shows the maximal probabilistic coupling for each of the faults and their corresponding test goals coverage and mutation in the buggy code.
since probabilistic coupling does not capture the complex interdependencies between test goals it is an approximation of the fault detection probabilities in figure .
for mutation based testing probabilistic coupling is related to the coupling effect and the notion of fault coupling used in prior work .
for example just et al.
focused on perfect fault coupling when studying the relationship between faults and mutants using existing test sets .
if a fault detecting test did not detect any additional mutants compared to an existing non faultdetecting test set then the corresponding fault was considered not coupled to any of the mutants.
this is a conservative approach for estimating how many real faults a mutation based selection approach may have missed.
we argue that in the context of adequacy based testing a probabilistic view on coupling is more appropriate.
for example a mutant may be detected by multiple tests.
if only one of them is not a fault detecting test probabilistic coupling is still high and better approximates the probability of detecting the fault.
the notion of fault coupling is also closely related to mutant subsumption .
indeed when considering a real fault as just another mutant in the mutant test matrix then a mutant is perfectly coupled to a real fault if that mutant subsumes the real fault.
we expect that incorporating subsumption information into the probabilistic coupling measure will further improve the estimates of fault detection probabilities.
we leave a deeper investigation as future work.
in summary measuring probabilistic coupling has two key advantages.
first it does not require costly simulations to estimate fault detection probabilities.
second it is robust to noise introduced by irrelevant test goals and tests.
246revisiting the relationship between fault detection test adequacy criteria and test set size ase september virtual event australia discussion measuring test set size this paper measures test set size as the number of test methods for consistency with previous work and to enable direct comparisons e.g.
.
for junit this is the number of test annotations6.
this measure assumes that all test methods are similar in terms of run time and number of exercised program behaviors.
this assumption however rarely holds in practice .
for example developer written test methods range from unit tests to system tests executing just a few instructions or millions of instructions.
a single test method may exercise a single or multiple program behaviors the latter could in fact be considered a set of distinct tests.
furthermore some test methods validate the behavior of a program by simply ensuring that it does not crash while others use a set of complex assertions.
the number of test methods is only one possible measure of test set size.
alternative measures include number of lines of test code and number of assertions .
test set size as a proxy when constructing a test set a developer s goal is not to write ntests but rather to exercise program behavior with number of tests being a consequence of secondary concerns such as adhering to coding guidelines and best practices.
researchers also do not care about test set size per se but rather use it as a proxy for a quantity of interest such as test execution or construction cost.
test set size however is an imperfect and unreliable proxy for such quantities.
for example an entire set of tests can be combined into a single test method e.g.
table driven testing or split into an arbitrary number of test methods without changing the overall test execution or construction costs.
test execution cost can and should be directly measured as run time of a test.
this assumes that the test can be run automatically without human intervention or judgment.
test construction cost can and should be directly measured for automatically generated tests.
for example when comparing two test adequacy criteria this comparison can be based on the same effort i.e.
the same test generation budget for each of the criteria rather than counting the number of generated tests.
correlation does not imply causation the driving question for research about the interrelationship between fault detection test adequacy criteria and test set size is causal in nature.
for example that research aims to understand whether creating test sets based on an adequacy criterion yields a high degree of fault detection in practice and if so which adequacy criterion is most cost effective.
however causal reasoning is a separate issue from statistical estimation and different causal relationships can give rise to the same statistical observations.
for example the observation of a reduced correlation between test set adequacy and fault detection when controlling for test set size is compatible with multiple causal models one of which is that test set size is a confounder .
an alternative causal model is that a developer writes tests to increase adequacy which in turn results in a larger test set and higher fault detection i.e.
test set adequacy is a confounder .
yet another causal model is that neither variable is a confounder and the root cause of the observed correlations among all three variables is developers desire to write effective tests based on a variety of test objectives 6for junit it is the number of test methods that follow junit s naming conventions.while adhering to coding guidelines and best practices thereby increasing test set size test set adequacy and fault detection.
we recommend that future studies should explicitly state their causal models and assumed underlying processes which forces a clear statement of scientific questions and enables reasoning about whether the proposed experiments and analyses can answer that question .
moreover future studies should explicitly state their statistical quantities and justify why these answer the causal question of interest.
for example prior work operated under the assumption that test set adequacy has an impact on fault detection if and only if the conditional and unconditional correlation between the two has the same distribution.
however the formal statistical quantity of interest the conditional correlation cor fault detection test set adequacy test set size rarely makes an appearance let alone an explanation as to why an equality in distributions translates into a causal impact or lack thereof.
when does correlation imply causation?
as the research community continues to explore whether and how an adequacydriven approach to test generation yields effective tests experiments with clear causal frameworks can shed light on the practical impacts of such approaches while preventing the aforementioned conflation between causal inference and statistical inference.
while scale content and even realization of the actual experiments may vary e.g.
randomization may not be possible we encourage these developer centric experimentations because they best approximate the practical benefits of different testing approaches by avoiding unrealistic assumptions and test objectives such as test uniformity and test set size driven development.
conclusions this paper addresses and resolves the contradictions in prior work that studied the interrelationship between fault detection test adequacy criteria and test set size.
it explains why test set size is an unrealistic test objective and neither a confounding variable nor an independent variable that should be experimentally manipulated.
furthermore it explains the conceptual and statistical issues that arise when controlling for test set size via random selection and stratification concluding that the random selection methodology is flawed.
additionally this paper proposes a methodology for comparing test adequacy criteria on a fair basis accounting for test set size without direct unrealistic manipulation and probabilistic coupling a methodology for approximating the fault detection probability of adequate test sets.
using the proposed methodology this paper concludes that adequacy based test selection is superior to random selection and that mutation based test selection is most effective when employed after coverage has exhausted its usefulness.
finally this paper argues that the number of test methods is not a reliable measure for test set size.
highlighting the non uniformity of real world test methods it further discusses the validity of using this measure as a proxy for test creation and test execution cost.