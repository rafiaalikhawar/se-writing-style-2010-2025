do you r eally code?
designing and evaluating screening questions for online surveys with programmers anastasia danilova university of bonn bonn germany danilova cs.uni bonn.dealena naiakshina university of bonn bonn germany naiakshi cs.uni bonn.destefan horstmann university of bonn bonn germany stefan.horstmann gmx.netmatthew smith university of bonn fraunhofer fkie bonn germany smith cs.uni bonn.de abstract recruiting professional programmers in sufficient numbers for research studies can be challenging because they often cannot spare the time or due to their geographical distribution and potentially the cost involved.
online platforms such as clickworker or qualtrics do provide options to recruit participants with programming skill however misunderstandings and fraud can be an issue.
this can result in participants without programming skill taking part in studies and surveys.
if these participants are not detected they can cause detrimental noise in the survey data.
in this paper we develop screener questions that are easy and quick to answer for people with programming skill but difficult to answer correctly for those without.
in order to evaluate our questionnaire for efficacy and efficiency we recruited several batches of participants with and without programming skill and tested the questions.
in our batch of clickworkers stating that they have programming skill did not meet our criteria and we would recommend filtering these from studies.
we also evaluated the questions in an adversarial setting.
we conclude with a set of recommended questions which researchers can use to recruit participants with programming skill from online platforms.
i. i ntroduction conducting user studies is an essential part of empirical software engineering however recruiting enough participants with programming skill can be challenging.
researchers use different methods to recruit programmers for studies related to software engineering.
one common method is to recruit computer science cs students or developers from local companies for a local and in person study.
on the other end of the spectrum researchers also commonly recruit developers on an international level for remote studies using a variety of platforms.
one advantage of recruiting locally is that researchers can be fairly certain that most of their sample actually has a computer science programming background e.g.
.
unfortunately finding enough willing participants locally can be difficult naiakshina et al.
reported that they could only get out of cs students to take part in a study where the compensation was euros.
to widen the recruitment pool and include nonstudent participants it is common for researchers to resort to online studies and recruit participants online e.g.
.
diverse recruitmentstrategies have been used such as cold calling programmers on platforms such as stack overflow github meet up groups etc.
or posting open invitations on social media in forums newsletters and events with the expectation being that participants without programming knowledge will not sign up for the studies .
however since researchers often offer significantly higher compensation than for end user studies there can be an incentive for participants to take part in a study despite having no programming skill.
the acquisition of skill is divided in three overlapping phases knowledge acquisition knowledge association and autonomous task performance .
for programming skill we use the definition of bergersen et al.
which is in accordance to the definition used in psychology the ability to use one s knowledge effectively and readily in execution or performance of programming tasks.
in previous work with programmers participants were often expected to have programming skill in various programming languages such as python java c perl haskell javascript php etc.
e.g.
.
however people who use programs such as excel manage a content management system cms or write html might consider themselves as having programming skill.
while this does not match our understanding and the requirements of previous research with programmers we want to make it clear that participants stating that they have programming skill might be an honest misunderstanding from our perspective and not necessarily malicious intent.
none the less having these kinds of participants in programming related studies and surveys is detrimental.
in studies which contain actual programming tasks these participants can be detected fairly easily.
however since it is common practice to pay participants independently of how well they perform they still cost time and cause financial damage to the researchers.
more critically studies which aim to examine attitudes towards software engineering related topics such as new features of programming languages api design error handling or security and privacy might corrupt their data by including answers from participants who do not understand the subject matter because they do not have any ieee acm 43rd international conference on software engineering icse .
ieee programming skill.
examples for such studies are .
researchers can also use online recruitment platforms such as clickworker or qualtrics for developer studies e.g.
.
these platforms provide panels to recruit participants with specific skills such as programming.
however as mentioned above there might be misunderstandings concerning the term and the compensation for participants with self stated programming skills is higher than for other types of study participants and consequently there is the risk of participants falsely stating that they have these skills.
danilova et al.
came across such a case.
they ran a survey to study developers attitudes to security warning design for which they used qualtrics to recruit participants with programming skill.
to test the participants basic developer knowledge the authors presented participants with some pseudocode that printed hello world backwards and asked what the output would be.
the authors reported that out of the participants recruited on qualtrics who stated that they had programming skill only gave the correct answer.
since most of the rest of the study consisted of closed questions without the programming skill question the authors would have included many participants in their data who were not able to understand a very simple program.
to enable researchers to be more confident about conducting online surveys with programmers we investigated the research question which questions can be used to screen out participants without any programming skill while meeting our requirements of effectiveness efficiency and robustness against cheating ?
we created a survey instrument consisting of questions which can be used to assess whether a participant actually has programming skill.
the questions are designed to take as little time as possible so they can be used in free or cheap pre screening surveys.
they needed to be so easy as to not annoy or challenge people with programming skill so we do not falsely reject participants but also hard enough so that people without programming skill cannot make an educated guess or google the answer quickly.
we designed questions of different types and tested them with different groups of participants cs students professional programmers students enrolled in a behavioral economics study platform as well as participants from clickworker with and without self stated programming skill.
we evaluated the results from these groups to provide a shortlist of questions which seemed promising as screening questions for developer studies.
to evaluate these questions we tested them in an adversarial environment where we offered non programmers an extra monetary incentive to answer them correctly by any means including using the internet.
as a final result we offer a list of questions we believe can be used to screen nonprogrammers out of surveys with only minimal overhead for the participants with actual programming skill.ii.
r elated work in order to provide context for this field of work we separate our related work into two sections.
we first outline developer studies where recruitment strategies are discussed or chosen in a way that developers are targeted with a high probability.
second we provide insight into other work that either uses identification and verification mechanisms in the research or investigates how participants could be tested for programming skill.
a. recruitment strategies researchers mostly designed the recruitment process in such a way that only software developers were targeted such as through recruitment of participants on github or on freelance platforms for developers .
for example when investigating the effect of happiness on productivity graziotin et al.
recruited their participants by contacting software developers on github .
github developers were also recruited for a security developer study conducted by acar et al.
to investigate how they perform with regard to security related tasks.
furthermore meyer et al.
when conducting a study on job satisfaction and productivity of software developers directly recruited employees from microsoft to ensure that all participants indeed work as software developers.
a number of recruitment strategies were compared by baltes and diehl in .
they recruited survey participants using different approaches via a personal network online networks and communities directly contacting companies public media survey advertisement by software engineers and by using information from ghtorrent which collects data on public github projects.
they concluded that the most efficient way to recruit is to use public media and asking software engineers to advertise the survey.
nevertheless baltes and diehl did raise the question as to whether recruitment strategies like commercial recruiting services or crowdsourcing platforms e.g.
amazon mechanical turk are suitable for developer recruitment but did not follow up on it which we do.
another concern is also raised by yamashita and moonen who discussed the recruitment of freelance developers for surveys on the platform freelancer.com.
the authors acknowledged that employers rely on self reported skills by members of such platforms.
they suggested running skill assessment tests to ensure the internal validity of research findings.
our work addresses this issue.
b. identifying programming skill bergersen et al.
constructed and validated an instrument for measuring java programming skill.
this was done by evaluating participants performance on programming tasks.
in a study lasting two days professional developers solved java programming tasks.
each task had a time limit of between and minutes.
the research goal of bergersen et al.
was to construct an instrument to find the best programmers when recruiting for a job or allocating to projects.
the task 538time of minutes is too long for our purpose of screening participants before a survey.
feigenspan et al.
conducted an experiment with students and compared the self reported programming experience with the participants performance in solving program comprehension tasks.
they found a correlation between selfreported experience and performance using a minute survey instrument.
in addition to that the authors highlighted that the software engineering community is lacking a clear definition of programming experience .
however by using this term researchers often referred to years a participant was programming by using a specific programming language or in general.
interestingly bergersen et al.
found a correlation between programming experience and skill which was largest during the first year of experience and disappeared after about four years.
while we also used program comprehension tasks in our study we did not aim to understand how experience correlates with performance our objective was to find a simple way to exclude participants without programming skill from online developer studies.
in balebako et al.
conducted a study concerning the behavior of smartphone app developers in regard to security and privacy.
potential participants had to fill out a screening survey to qualify for the interviews.
this survey included two technical questions to test for knowledge of app development.
in addition the authors verified their findings in a followup online survey with participants recruited on various online forums.
again knowledge and attention check questions were required to be correctly answered by participants.
of the responses had to be discarded because they did not fulfill the requirements.
we contacted balebako et al.
and asked for their used screening questions.
unfortunately the authors were not able to provide us the exact questions.
however they remembered to have asked for ides participants have experience with and apps they developed.
after that the authors manually inspected whether the mentioned ides or apps exist.
the authors acknowledged that especially the ide question was hard to verify because of the high amount of ides existing in the wild.
instead of asking for ides we therefore decided to provide participants a list of programming languages including non existing ones.
in acar et al.
studied the effect of information resources for software development on security by conducting an online survey and a lab study.
for the online survey the researchers sent about emails to developers they were able to identify on google play.
of the participants who completed the survey acar et al.
excluded for invalid answers.
additional filters to find non developer participants were not applied.
in the lab study participants were recruited based on their experience with app development having either completed a course on android development or with work experience of at least one year.
the participants first had to complete a short programming task to demonstrate their skills.
however following complaints that the task took too much time they were instead tested with multiple choice questions covering basic android development knowledge at least 3of which needed to be answered correctly.
this is a good example showing that programming tasks are not well suited as screening question and that multiple choice questions are more acceptable.
we contacted acar et al.
and learned that their screening questions specifically covered android development knowledge.
since we aimed to identify questions for general programming skill we did not include them to our instrument.
however we included questions affecting developers beyond android development such as error handling.
danilova et al.
investigated the developers preferences about security warnings in ides and tested participants programming skill with a simple pseudocode multiple choice question.
a detailed description of the study can be found in the introduction.
to further evaluate the used question we included it to our question set as q16.
assal and chiasson conducted online surveys to investigate developers software security processes.
a section of their participants were recruited through a paid service provided by qualtrics.
during survey completion participants were provided different descriptions of software security and were prevented from progressing till they chose the authors preferred definition of security.
participants initially providing incorrect answers were not excluded from evaluation.
the authors wanted to ensure a baseline of security understanding rather than to test for software security skill.
however participants who provided invalid data or completed the survey too quickly where excluded from evaluation.
as can be seen there is currently no common approach to detecting whether participants have programming skill.
each set of authors come up with their own ideas and no instrument has been tested in any rigorous manner.
iii.
m ethodology in this section we present the questions we designed to identify participants with programming skill and the studies we ran to evaluate it.
a. instrument requirements unlike bergersen et al.
s instrument to determine programming skill which takes two days to complete our goal is to assess whether participants have programming skill or not with as little effort as possible.
for the questions to be used in pre screening surveys or as quality control questions we must ensure that they take people with programming skill only a few minutes at most to answer.
therefore our requirements regarding the instrument were as follows effectiveness the instrument should be able to differentiate between programmers and non programmers.
hence the questions need to rely on domain knowledge and be complex enough so that only programmers can answer in a reasonable amount of time.
it should not leave any scope for mere guesses.
efficiency the instrument should consume as little time as possible.
so the goal is to frame questions that programmers can answer quickly.
it is also desirable if it would help the participants without programming skill 539table i overview of all questions no question abbreviation category q1 which of these lesser known programming languages have you worked with before?
unkno wn.languages programming language recognition q2 which of these websites do you most frequently use as aid when programming?
source.usage information sources q3 choose the answer that best fits the description of a compiler s function.
compiler basic knowledge q4 choose the answer that best fits the definition of a recursive function.
recursive basic knowledge q5 choose the answer that best fits the description of an algorithm.
algorithm basic knowledge q6 which of these values would be the most fitting for a boolean?
boolean basic knowledge q7 please pick all powers of .
power.of.
basic knowledge q8 please translate the following binary number into a decimal number .
bin.conv number formats q9 please select all even binary numbers.
bin.even number formats q10 please select all valid hexadecimal numbers.
hexa.num number formats q11 when multiplying two large numbers your program unexpectedly returns a negative number.
what might have caused this?
error.overflow finding errors q12 what is the run time of the following code?
runtime algorithmic runtime q13 when running the code you get an error message for line array index out of range.
what would you change to fix the problem?
error.outofbound finding errors q14 what is the purpose of the algorithm?
sorting.array code comprehension q15 what is the parameter of the function?
function.param basic knowledge q16 please select the returned value of the pseudo code.
backward.loop code comprehension to decide quickly that they cannot answer the question since we do not want to waste their time either.
robustness against cheating the instrument should be designed in a way that it becomes difficult for participants without programming skill to come by the answers for instance by using online search engines or forums on which clickworkers exchange information about studies.
language independence the instrument should work regardless of the programming language the participants are skilled in.
while it might also be useful to filter based on specific languages that is beyond the scope of this paper.
b. survey we used dillman s pre testing process to develop an online survey with different questions .
the dillman s pre testing process is a three step approach to design survey questions in general.
it includes literature review using a think aloud approach and conducting a pilot study.
first we reviewed related work and decided on different question types.
we started with a larger pool of questions from related work.
since these questions rarely met all our requirements e.g.
time and effort three researchers from computer science in different positions graduate student phd student professor developed further questions by considering related work but also examining the main concepts of programming.
second another researcher went through the questions using a thinkaloud approach.
third we conducted a pilot study with two participants.
a summary of our questions can be found in table i. the full questions can be found in the supplementary material.
a total of questions were created and put under a number of categories programming language recognition q1 q1 is a two part question.
the first part asks the participants to self report their programming language skill for well known programming languages such as c c or java.
this part does not need to be evaluated for the instrument.
the second part asks the participants to self report their programming language skill for lesser known programming languages such as torg or yod.
however all but one of the lesser known programming languages are fake.
both the parts offer a none of the above option.
theidea behind this question is to see how quickly people with programming skill select their languages from the first list and then realize that they do not know any from the second.
our hypothesis is that they will probably also realize that most of the names on the second list are fake and select none of the above while non programmers who want to falsely claim skill would select a couple.
information sources q2 previous studies have analyzed what kind of websites developers use while programming with the most popular being stack overflow .
hence q2 contains stack overflow and some decoy options.
participants with programming skill can quickly pick stack overflow while non programmers might not be aware at all.
basic knowledge q3 q7 q15 these questions cover general programming knowledge for instance regarding what a compiler does what an algorithm is and what a recursive function is.
number formats q8 q10 we asked simple questions related to hexadecimal and binary conversion.
most computer science programs or programming language tutorials deal with binary and hexadecimal numbers hence most non programmers will not have much experience with this.
finding errors q11 q13 a good test of programming skill would have been asking the participants to actually write some code however that would cost more time than can be permitted and is hard to automatically verify.
therefore as an alternative we asked the participants to find errors in code snippets or explain why the errors occurred.
algorithmic runtime q12 we also added a basic question about the run time of some simple pseudocode.
program comprehension q14 q16 we showed the participants two pseudo algorithms and asked them about their functionality and output.
it is important to note that q16 was taken from the study by danilova et al.
.
the questions q13 q14 as well as q15 q16 are based on the same pseudocode.
hereafter we will refer to each pair of these questions as a question block.
while we tried to keep the time spent on each question short especially for participants with programming skill we also had to enable 540automatic evaluation and make the questions robust against random guesses.
thus we opted for closed multiple choice questions with to possible answers for each question.
most questions had one unambiguous correct answer.
exceptions were of the number format questions where participants were asked to select all correct solutions.
the incorrect answers were chosen in a way as to look plausible to participants without programming skill.
furthermore an attention check question appeared randomly during the survey to filter out careless respondents.
for the attention check question this is an attention check question.
please select the answer octal the correct item needed to be picked.
the questions and answer options were shown in a randomized order to mitigate response fatigue and response order effects .
we used versions of this survey.
the initial version included i don t know or i don t program answer options.
we included these options because we wanted to minimize guessing at this stage so we could get an accurate view of what non programmers state did not know.
the second version of the survey was conducted in an adversarial setting see section vii b .
here the participants were given a monetary reward for each correct answer and the i don t know or i don t program options were removed.
this setting simulated a screening setting in which non programmers might try to guess the correct answers to take part in a well compensated survey.
after completing the programming questions the participants were asked to answer demographic questions including ones related to their age job and programming experience.
the full questionnaire can be found in the supplementary material.
for evaluation and for testing our time requirement we set a timer for each question to measure how much time was spent to solve it.
c. statistical testing we categorized the answers as correct orincorrect .
in order to test whether the different groups had different success rates for different questions we used the fisher s exact test fet on each question.
we reported confidence intervals ci and odds ratio or to interpret the details of the tests.
we corrected all fisher s exact tests for multiple testing using the bonferroni holm correction.
to analyze the entire set of questions we used latent class analysis as it is suited the categorical data .
the latent class analysis reveals whether the data shows a number of distinct classes.
our assumption was that we will get two participants with and without programming skill.
we tested the models with more classes as well but selected the one with the lowest bayesian information criterion bic .
d. participants recruitment we sampled through different channels to obtain data from different groups.
we sampled cs students using the mailing list of an advanced programming lecturefrom the undergraduate program of our university.
as compensation the students received bonus points for their exam admission.
all the cs students passed our attention check.
additionally we invited professional developers from personal contacts and from a database of professional developers who took part in our past programming studies and agreed to take part in future studies.
thirty five participants completed the survey.
we excluded one from our data set because we were not able to identify the participant on our invitation list and it seemed like that the study link was forwarded.
all the professionals passed our attention check and received euros for their participation.
we combined these two groups to form our ground truth since we knew for sure that they all have programming skill.
next we recruited students in cooperation with the behavioral economics group from our university.
they have a recruitment system which sends email invitations for studies to enrolled users.
the majority of them were economics students however others potentially including computer science students could have enrolled as well.
we refer to these participants as econ students .
of these participants passed the attention check.
based on the question of selfreported programming experience participants had at least some .
years experience.
the participants received euros as compensation.
we also recruited participants from clickworker who did not have any programming skill.
of these participants passed the attention check and completed the survey.
they received .
euros for their participation.1however in contrast to all other samples we used the default clickworker invitation description which cautions clickworker participants that attention check questions needed to be solved correctly to receive the payment.
we accepted this difference since this is the norm on clickworker it is the norm to pay participants even if they fail the attention check questions on the other recruiting platforms.
we combined the last two groups as our ground for participants without programming skill.
however the situation is not as clear cut as with the programmers above since cs students can also be enrolled in the econ platform and both econ students and regular clickworker participants might have programming skill even though they do not state it.
in this combined group we have out of participants who stated that they have programming experience.
however since we have no way of verifying this properly we did not remove them from our evaluation to be on the conservative side.
further we recruited clickworker participants who listed programming as a skill in their profile.
the hiring conditions were the same as above.
of these participants passed the attention check.
while the above mentioned groups were used to design our screening instrument we used this last group as a real life test to see how many of these would pass our screening questions.
1this fulfills the minimum wage requirement.
our compensation was higher than the recommendation of the platform which was .
euros for minutes.
541table ii demographics of the participants n group sample n gender age country of residence general programming experience programmercsstudents female male min max mean .
md sd .
germany min max mean .
md .
sd .
na professional developers female male min max mean .
md sd .
germany austria min max mean .
md sd .
non programmerecon students female male pnta min max mean .
md sd .
germany na min max mean .
md sd .
clickworkers without programming skill female male pnta min max mean .
md .
sd .
germany uk usa other min max mean .
md .
sd .
test group clickworkers with programming skill female male pnta min max mean .
md .
sd .
germany uk other min max mean .
md sd .
na attack scenario clickworkers without programming skill female male pnta min max mean .
md sd .
germany italy spain usa other min max mean .
md sd .
md median.
pnt a prefer not to answer.
see supplementary material for further details on occupation and country of residence.
finally we tested the best questions using an attack scenario with participants from clickworker of whom passed the attention check.
we paid a base compensation of euros to clickworkers who did not state that they had programming skill and provided a bonus payment of euros for each of the correct answers.
this should simulate a nonprogrammer adversary who wants to pass a screener question to be able to take part in a well compensated developer study.
demographics the demographics of our tested groups can be found in table ii.
of all the participants were male were female and preferred not to answer the question.
from the programmer group and the test group almost all participants were male developer male test group male .
by contrast from the non programmer group more participants were female out of female male and preferred not to tell .
the majority of the participants were from germany.
while professional developers reported to have on average .
years of programming experience min max median md standard deviation sd .
cs students indicated on average .
years of experience min max md .
sd .
.
all the participants from the programmer group indicated to have worked with java before.
a total of of the programmer participants indicated to have worked with javascript with c with python with c with php with c with shell with typescript with ruby another with groovy and with go.
clickworker participants who claimed to have programming skill in their profile indicated in our survey to have on average .
years of experience min max md sd .
.
by contrast clickworker participants who did not indicate to have programming skill in their profile reported in the survey to have on average .
years of experience min max md .
sd .
.
finally most of the econ students reported not to have programming experience at all mean .
min max sd .
.
iv.
e thics the institutional review board of our university approved our project.
the participants of our study were provided with a consent form outlining the scope of the study and the data use and retention policies and we also complied with the general data protection regulation gdpr .
the participants were informed of the practices used to process and store their data and that they could withdraw their data during or after the study without any consequences.
the participants wereasked to download the consent form for their own use and information.
v. l imitations we compensated each sample differently as the different groups had different payment expectations.
however it could be that the different compensation levels affected the results.
we found a couple of participants in the non programmer group who looked like they had programming skill.
there might also have been some with programming skill whom we did not recognize.
however we think that the number of programmers that accidentally fell in the non programmer group was not significant enough to interfere with our study.
if anything our instrument s performance will be underreported since we count any unknown programmer in the non programmer group who is identified as a programmer as a failure for our instrument.
while we have recruited a mix of cs students econ students professional developers and clickworkers with and without programming skill we do not claim that this is representative for all programmers.
hence further studies will be needed to extend and validate our results.
vi.
r esults in this section we describe the effectiveness and efficiency of our defined screener questions.
however the questions should also be effective in a way that that the number of programmers who fail and the number of non programmers who either know or guess correctly should be low.
therefore we additionally tested our questions with a test group to reduce our question set to the most promising questions and evaluated them in an adversarial scenario.
a. effectiveness except for q1 all fisher s exact tests were highly significant even after the bonferroni holm correction.
this in turn indicates that the remaining questions were different in the distributions of correct and incorrect answers between the non programmer and programmer groups.
we conducted a latent class analysis on the questions.
we chose a model with two groups g2 .
likelihood ratio deviance statistic 2 .
chi square goodness of fit maximum log likelihood .
entropy .
since the bic was lower for models with more classes and it fit well to our assumption.
figure visualizes the proportion of probabilities for choosing the correct or incorrect items according to the groups.
the predicted class shares were .
for class non programmer and .
for class programmer .
thus according to the class analysis two classes can 542non programmer programmerq1 unknown.languages q2 source.usage q3 compiler q4 recursive q5 algorithm q6 boolean q7 power.of.
q8 bin.conv q9 bin.even q10 hexa.num q11 error.overflow q12 runtime q13 error.outofbound q14 sortingarray q15 function.param q16 backward.loop questionsproportioncorrect or incorrect pr incorrect pr correct fig.
plot of latent class analysis with the programmer and non programmer groups.
be distinguished within this sample.
this fits into our selfchosen samples since we had programmers and nonprogrammers sampled.
indeed our questions are applicable to split a population according to the answers the participants provided.
in the following we describe the effectiveness of each question in detail.
programming language recognition q1 we found that almost all the non programmers or of and programmers or of answered the question for lesser known languages correctly.
that means in this case they chose the answer none of the above.
nine participants from the non programmer group and one participant from the programmer group selected non existent programming languages.
this shows that without incentive most non programming participants had no reason to pick fake languages although it is interesting that roughly of non programmers selected some of the fake languages.
information sources q2 all the programmers selected stack overflow as one of the most used aids for programming.
no other source was reported.
most participants from the non programming group reported that they do not program or while said that they do not use any of the listed websites in the questionnaire for programming.
interestingly participants chose memoryalpha selected wikipedia other participants marked linkedin and only participants from the non programmer group picked stack overflow as their answers.
basic knowledge q3 to q7 and q15 first we analyzed the answers given on the description of a compiler q3 .
all the participants from the programmer group and participants from the non programmer group chose the correct answer.
as stated earlier our non programmer group is not as controlled as our programmer group because participants from the group stated that they had some programming skill.
however of the correct answers only came from this group i.e.
participants who stated to have programming skill did not give the right answer for q3 whereas whostated that they had no skill got it right.
this similar pattern that emerged was found in all the knowledge questions with no clear distinction visible between the two subgroups.
thus for simplicity we will not report further on this but a full overview can be found in the supplementary material.
second we analyzed the answers given on the definition of a recursive function q4 .
the answers were very similar to the compiler question.
all programmers could answer the question correctly whereas of the non programmers got the correct answer.
the performance for q5 that was about the definition of an algorithm q5 was even worse as out of were able to answer it correctly.
one programmer failed the question.
the effect on the boolean question q6 was significant as well since all the programmers successfully chose the correct answer while only of the non programmers answered correctly.
we also included a question q7 about the power of two since we thought most programmers work with powers of two.
the answers were only marked as correct if all the powers of two were selected.
two programmers answered incorrectly while the rest chose the correct answer.
from the non programmer group managed to pick the right powers of two as well.
furthermore we asked our participants to pick what a function s parameter is q15 .
this question was answered correctly by all the programmers while only participants from the non programmer group selected the correct answer.
it seems that programmers were familiar with the definition while the non programmers struggled to answer this question correctly.
number formats q8 to q10 first we asked our participants to convert a number from the binary system into the decimal system q8 .
forty eight of the programmers and of non programmers solved the question correctly.
with regard to picking all the even binary numbers question q9 with multiple answers programmers failed to select all the correct answers.
however out of participants from the non programmer group got the correct answer.
to test the participants knowledge with hexadecimal numbers we asked them to select all the valid hexadecimal numbers in q10.
to get the correct answer multiple choices needed to be selected.
while the effect of groups on the answers was again significant this question seemed to be very challenging for all the participants.
of of the programmers were unable to solve this question.
from the non programmer group only participants succeeded in selecting the correct answers.
finding errors q11 and q13 fixing bugs takes a large percentage of a programmer s working time.
with regard to the question of what could happen if two large numbers are multiplied and a negative number is returned q11 the difference of the two groups was significant.
forty seven of the programmers were able to answer this question correctly as well as of non programmers.
we also investigated the common errors that programmers face during programming and requested them to solve an erroroutofbound q13 .
only a few non programmers answered the question correctly of .
however the programmers also seemed to have trouble with this question because only out of selected the correct answer.
algorithmic runtime q12 the question for the runtime seemed to be very difficult for both the groups.
we concluded that even the participants with programming skill were not very familiar with algorithmic run times.
the effect of the group variable was significant because the proportion of correct answers differed between both the groups.
program comprehension q14 and q16 comprehension of the sorting array pseudocode seemed to be an easier task for the programmers because almost all of them answered q14 correctly of .
from the non programmer group selected the correct answer.
furthermore programmers were unable to solve the hello world pseudocode task q16 correctly.
additionally only of non programmers choose the correct answer.
consequently the difference in correct answers between both the groups was significant.
b. efficiency the participants in the non programmer group recorded .
minutes as the median time to complete the whole questionnaire while the participants in the programmer group finished the survey with a median time of .
minutes.
all questions showed a mean under seconds thus all questions fulfilled our efficiency requirement.
we found that answering knowledge questions took the least time while answering questions about number conversion took longer.
as expected each of the two question blocks including pseudocode q13 q14 and q15 q16 took more time as compared to other multiple choice questions.
we found that participants with programming skill needed more time to answer them.
the reasons for this could be that non programmers selected i don t know or gave a random answer quickly since they knew they could not understand the code.
the adversarial measurements in section vii b are more relevant for these questions.
a visualization of the mean times for both programmer and non programmer groups according to each task block an overview for the number of correct and incorrect answers of the programmer and non programmer groups for each question as well as the statistical analysis summary are available in the supplementary material.
vii.
t esting the instrument we tested the instrument in two scenarios nonadversarial test group and adversarial attack group.
first we tested our survey instrument with a set of participants from clickworker who indicated in their profiles to have programming skill.
this scenario is close to how real studies would be conducted i.e.
researchers use a platform like clickworker to recruit participants who state that they have programming skill.
we did not offer significantly higher compensation to minimize the incentive to claim skill to participate in our survey.
we also included in the i don t know options since we wanted to see how many of the self reported programmers from clickworker would choose that they did notknow answers in a non adversarial setting.
the results also served for comparison of self reported programming skill of the participants from clickworker with professional developers from our controlled sample.
later we selected the most promising questions and tested them in an adversarial scenario where we recruited participants from clickworker who did not state to have programming skill.
in the introduction we explained the goal of our study and asked the participants to try and pass themselves off as programmers.
to incentivize them we paid a base fee of euro and an additional euro for every correct answer for the questions.
in this scenario we removed the i don t know options because we needed to evaluate the questions in an adversarial setting and measure their guessability.
this scenario simulates people without any programming skill trying to break our screener questions to take part in a well compensated developer study.
a. non adversarial test group programming language skill q1 forty eight of the participants did not select any imaginary languages when asked for skill with lesser known programming languages.
the majority selected none of the above and selected shroud.
information sources q2 for answering the question for the most used information sources of the participants selected stack overflow while the rest chose that they did not program or have not used any of the websites suggested of .
five chose wikipedia.
basic knowledge q3 to q7 and q15 forty one of the participants correctly selected the description of a compiler q3 whereas failed.
for the description of a recursive function q4 and the value of a boolean q6 selected the correct answer.
for the description of an algorithm q5 only failed to select the correct answer.
forty participants were able to select all the powers of two q7 while did not.
thirty three participants selected the function s parameter q15 correctly.
number formats q8 to q10 forty participants were able to select the correct answer for a simple binary conversion q8 while selected a wrong answer and another reported to not know the answer.
the multiple response questions seemed to be more difficult.
thirty two participants could correctly select all the even binary numbers q9 .
further only participants selected all the valid hexadecimal numbers q10 while failed or selected i don t know .
error q11 and q13 thirty five participants correctly selected an overflow as source of error in q11 and participants reported that they did not know the answer and the rest selected an underflow.
for the array out of bound error q13 only of participants were able to select the correct solution.
algorithmic runtime q12 the runtime question seemed to be the hardest one for the participants from the test set.
only answered correctly did not know the answer and the rest selected a wrong response.
544non programmer programmer test group count of correct answers participants per group fig.
number of correct solutions of all questions per group.
program comprehension q14 and q16 thirty one participants selected the correct purpose of our sorting array pseudocode q14 .
interestingly only participants selected the correct output of the hello world pseudocode q16 whereas participants selected the wrong answer hello world.
comparison of the groups table iii shows the correct answer rates of the programmer non programmer and the non adversarial test group for the questions.
the test group clickworker who stated that they had programming skill always had more correct answers than the non programmer group econ students and non programmer clickworkers but less than the programmer group cs students and company developers .
this suggests that some clickworker participants do not interpret programming skill the way we do or falsely indicated in their profile to have programming skill.
in either case it is important to be able to identify these participants during screening.
interestingly participants from this test group selected i don t program when we asked for their level of programming expertise at the end of the survey despite listing programming as a skill in their profile.
the number of correct solutions for all the questions per group is visualized in figure .
b. attack scenario based on the above findings we selected the most promising questions q2 to q4 q6 q14 and q15 by excluding all the questions that did not achieve a correct answer rate of at least from the programmer group.
we also excluded all the questions where more than of the non programmer group gave the correct answer table iii .
we chose these cut offs for several reasons.
first we did not require correctness from the programmers because even programmers make mistakes.
additionally we allowed some false positives from the non programmers because we need to keep the questions quick and simple to not lose programmers to the screening process.
since in most scenarios we would recommend the use of multiple questions the false positive rate will be lower due to the combination.
in addition to the questions mentionedtable iii percentages of correct answers in each group.
no question programmersnon test programmers group q2 source.usage .
q15 function.param .
q6 boolean .
q4 recursive .
q3 compiler .
q14 sorting.array .
q5 algorithm .
q1 unknown.languages .
q8 bin.conv .
q7 power.of.
.
q16 backward.loop .
q11 error.overflow .
q9 bin.even .
q12 runtime .
q13 error.outofbound .
q10 hexa.num .
the table is sorted descended by the column programmers and ascended by the column non programmers because the most promising questions require to be correctly answered by programmers and incorrectly by non programmers.
above we included q1 and q16 to our set of most promising questions because we expected them to perform better in the attack scenario.
after each question we asked the participants whether they looked up the answer on the internet or solved it on their own see supplementary material for more details .
programming language skill q1 in the adversarial setting we tested q1 in two versions both parts of the questions real and fake programming languages and on its own only fake programming languages .
both versions were ineffective with only of in version and of in version where the participants chose non existent programming languages.
our assumption that non programmers would pick these turned out to be false.
sources q2 twenty nine of the clickworkers reported stack overflow to be their most used information source for programming.
six chose none of the above while chose wikipedia and memoryalpha.
compiler s function q3 thirty six of the participants chose the correct answer for the functionality of a compiler.
recursive function q4 and boolean q6 of participants correctly defined a recursive function and answered the value that a boolean can take.
sorting array q14 twenty nine of the participants answered the sorting algorithm question correctly.
this might be the first indication of algorithms being more difficult for the participants without programming skill to look up.
parameter of a function q15 thirteen of the participants selected the correct answer.
hello world q16 of clickworkers of picked the correct answer for the hello world question.
our analysis showed that q15 and q16 performed best according to the correct answer rates in the attack scenario.
figure shows the time taken to solve the questions correctly for the programmer and the attack groups.
we excluded q1 545table iv overview of screening question recommendations for programming skill question recommended suggested time limit excluded programmers with time limit n attackers n included excluded q1 q2 q3 q4 q6 q14 q15 not necessary q16 not necessary the table shows an overview of our recommendations for the eight questions tested in the attack scenario.
colors red notrecommended green recommended without restrictions yellow recommended but with time limit q6 booleanq4 recursiv eq3 compilerq2 source.usage time questiongroup attack progr ammer fig.
comparison knowledge questions time to solve each question correctly .
since we tested versions of this question as described above and the question performed so poorly that it was not considered.
we also did not directly compare q14 q15 and q16 to the original questions since in the prior analysis they were part of a question block.
in the attack scenario we split them in order to get the information for each question whether participants googled the answers or not.
all knowledge questions except q2 p .
showed a significant time difference wilcoxon rank sum test between the developer and attacker groups with the attackers taking significantly longer.
viii.
d iscussion and recommendations when conducting our non adversarial evaluation with the clickworker test group we only selected participants whose profiles included programming skill.
the results of this test group demonstrated that for the kind of developer studies that are common in our community it is not recommendable to rely on the self reported programming skill or a platform s recruitment features.
in our test set of the clickworker programmers got fewer correct answers than the poorest performers in our ground truth programmers group.
theymostly got all the answers right while many clickworker developers got less than half right answers.
considering the small sample sizes which are common in developer studies even a small amount of noise can mask true effects or worse create false effects.
having potentially one third participants without programming skill in a developer survey can cause significant disruption and we highly recommend using screening questions to avoid this.
the fact that we removed of our questions since they proved to be less effective than we had hoped suggests that the current practice of some researchers creating and using untested screener questions is sub optimal.
we hope that our tested questions can be a first step toward creating a common screener instrument for our community.
we recommend the use of screener questions for studies targeting people with programming skill especially if these studies do not contain a programming task.
table iv summarizes our screener question recommendations.
the most effective but also the slowest questions were the code comprehension questions i.e.
q15 and q16.
if time penalty is acceptable we recommend using these or similar questions as screeners.
if this is not feasible we recommend to randomly use one of the four knowledge questions q2 to q4 and q6 with a time limit since our attack group demonstrated that these question can be looked up.
the time limit can be used to configure the false rejection participants with programming skill and the false acceptance of those without.
we recommend a seconds time limit for q2 q4 and q6 and a seconds time limit for q3.
in supplementary material we provide details of how we chose these time limits.
figure shows the distribution over the recommended questions of correct solutions in the groups with the time limits applied.
ix.
c onclusion in previous online studies with programmers researchers often relied on participants claims to have programming skill or they used programming tasks or programming knowledge questions to verify these.
our work showed however that designing programming screener questions is not trivial and we would not recommend using questions without testing them before.
while we raised a methodological problem in softwareengineering work on a meta level we also contributed concrete and validated screener questions on a primary level.
546attack non programmer programmer test group count of correct answers of participants per group fig.
distribution of correct solutions of all recommended questions per group with time limits applied as in table iv.
we surveyed a total of people to find questions that can be used to filter participants with programming skill.
to get a ground truth sample of programmers we selected participants for whom we were able to verify that they actually have any programming skill.
we then recruited non programmers and clickworkers with and without self reported programming skill to test our screening instrument.
finally we tested our instrument under adversarial conditions to test its robustness.
based on our evaluation we recommend of our screener questions for use in online studies.
in future work we will continue to expand and test our question set.
while the small set is sufficient to protect against non adversarial participants who simply have a different interpretation what programming is than we do a larger set will be more robust in an adversarial setting.