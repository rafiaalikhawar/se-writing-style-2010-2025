legion best first concolic testing dongge liu the university of melbourne school of computing and information systems melbourne victoria australia donggel student.unimelb.edu.augidon ernst lmu munich software and computational systems lab munich bavaria germany gidon.ernst lmu.de toby murray the university of melbourne school of computing and information systems melbourne victoria australia toby.murray unimelb.edu.aubenjamin i.p.
rubinstein the university of melbourne school of computing and information systems melbourne victoria australia benjamin.rubinstein unimelb.edu.au abstract concolic execution and fuzzing are two complementary coveragebased testing techniques.
how to achieve the best of both remains an open challenge.
to address this research problem we propose and evaluate legion.
legion re engineers the monte carlo tree search mcts framework from the ai literature to treat automated test generation as a problem of sequential decision making under uncertainty.
its best first search strategy provides a principled way to learn the most promising program states to investigate at each search iteration based on observed rewards from previous iterations.
legion incorporates a form of directed fuzzing that we callapproximate path preserving fuzzing appfuzzing to investigate program states selected by mcts.
appfuzzing serves as the monte carlo simulation technique and is implemented by extending prior work on constrained sampling.
we evaluate legion against competitors on benchmarks from the coverage category of test comp as well as measuring its sensitivity to hyperparameters demonstrating its effectiveness on a wide variety of input programs.
keywords concolic execution constrained fuzzing monte carlo tree search acm reference format dongge liu gidon ernst toby murray and benjamin i.p.
rubinstein.
.
legion best first concolic testing.
in 35th ieee acm international conference on automated software engineering ase september virtual event australia.
acm new york ny usa pages.
this research was supported by data61 under the defence science and technology group s next generation technologies program.
ase september virtual event australia copyright held by the owner author s .
acm isbn .
introduction theseus killed minotauros in the furthest section of the labyrinth and then made his way out again by pulling himself along the thread.
pseudo apollodorus bibliotheca e1.
.
trans.
aldrich the complexity of modern software programs are like labyrinths for software testers to wander their program states and execution paths form a confusing set of connecting rooms and paths.
like the minotaur faults often hide deep inside.
one might guess at a fault s possible location via static analysis but in order to slay it theseus needs to know the path to it for sure and the software tester needs to know which input will trigger it.
in the myth of theseus the hero king finds minotauros by accurately tracing past paths with a ball of thread allowing him to learn and estimate the maze structure.
we argue that the very same tricks namely recording exact concrete execution traces and applying machine learning to estimate software structure and guide its exploration can also benefit coverage based testing.
the focus of this paper is the quest of coverage based testing which is to cover as many paths in as little time as possible delegating minotaur detection to separate tools e.g.
addresssanitiser ubsan valgrind purify .
traditional methods for coverage based testing have been dominated by the two complimentary approaches of concolic execution as exemplified by dart and sage and coverage guided greybox fuzzing as exemplified by libfuzzer afl its various extensions such as aflfast aflgo collafl angora .
continuing the mythological metaphor with concolic execution one spends a long time rigorously planning each path through the maze via constraint solving to make the correct turn at each branching point and ensure that no path will ever be repeated.
however such computation is expensive and for most modern software the maze is so large that repeating it for every path is infeasible.
in contrast a coverage guided fuzzer like afl blindly scurries around the maze neither spending much time on planning nor accurately memorising the paths and structure traversed.
thus much time is inevitably spent unnecessarily repeating obvious execution paths.
observing the complementary nature of these two methods our research aims to generalise them with theseus s strategy.
our 35th ieee acm international conference on automated software engineering ase this work is licensed under a creative commons attribution international .
license.
ase september virtual event australia dongge liu gidon ernst toby murray and benjamin i.p.
rubinstein toollegion1traces observed execution paths to estimate the maze structure.
then it identifies the most promising location to explore next plans its path to reach that location and applies a form of directed fuzzing to explore extensions of the path to that location.
legion precisely traces each concrete execution i.e.
fuzzing run and gathers statistics to refine its knowledge of the maze to inform its decisions about where to explore next.
statistics gathering is central to legion s approach unlike traditional fuzzers like afl that eschew gathering detailed statistics to save time.
instead legion aims to harness the power of modern machine learning algorithms informed by detailed execution traces as in other contemporary tools .
real life coverage testing is more complicated than the theseus myth as it requires a universal strategy that can adjust itself according to different program structures i.e.
to fuzz the program parts that are more suitable to fuzz and favour concolic execution elsewhere.
however how to determine the best balance between these two strategies remains an open question.
to address this challenge legion adopts the monte carlo tree search mcts algorithm from machine learning .
mcts has proven to work well in complex games like go multiplayer board games and poker as it can adapt to the game it is playing via iterations of simulations and reward analysis.
specifically mcts learns a policy by successively simulating different plays and tracking the rewards obtained during each.
in legion plays correspond to concrete execution directed fuzzing while rewards correspond to increased coverage discovering new execution paths .
more importantly mcts s guiding principle of optimism in the face of uncertainty is appropriate for exploring a maze with an unknown structure randomness and large branching factors where rigorously analysing every detail is infeasible.
instead mcts balances exploitation of the branches that appear to be most rewarding based on past experience against exploration of less well understood parts of the maze where rewards path discovery are less certain.
with the two tricks of theseus legion provides a principled framework to generalise and harness the complementary strengths of concolic execution and fuzzing.
in so it sheds new light on the key factors for efficient and effective input search strategies for coverage based testing on diverse software structures.
we term legion s directed fuzzing approach approximate pathpreserving fuzzing appfuzzing and are inspired by quicksampler .appfuzzing aims to fuzz a specific location of the search space by launching several binary executions that with high probability follow the same path to that location but might take different paths afterwards .
it is described in section .
.
legion treats coverage based testing as progressively exploring a large space with uncertainty by iteratively sampling inputs using cheap but less accurate appfuzzing that targets specific program states selected by mcts.
symbolic state information i.e.
a path constraint is required to seed appfuzzing for each program state.
however legion avoids unnecessary symbolic execution and constraint solving by performing symbolic execution lazily specifically legion computes symbolic successor states only for 1the name is a homage to the marvel fictional character who changes personalities for different needs.
our strategy can adjust its exploration preference under different metrics.program states deemed promising i.e.
those for which existing statistics indicate are worthy of investigation .
legion s adoption of mcts is designed to ensure that computational power is used to explore the most beneficial program locations as determined by the score function.
in legion scores are evaluated according to a modularised reward heuristic with interchangeable coverage metrics as discussed in section .
.
our contributions are we propose a variation of monte carlo tree search mcts that maintains a balance between concolic execution and fuzzing to mitigate the path explosion problem of the former and the redundancy of the latter section .
we propose approximate path preserving fuzzing which extends a constrained sampling technique quicksampler to generate inputs efficiently that preserve a given path with high probability section .
.
we conduct experiments to demonstrate that legion is competitive against other state of the art approaches section .
.
and evaluate the effect of different mcts hyperparameter settings.
overview legion generalises the two traditional approaches to coveragebased testing concolic execution and coverage guided fuzzing.
concolic execution relies on a constraint solver to generate concrete inputs that can traverse a particular path of interest.
new paths are selected by flipping path constraints of previously observed execution traces thereby attempting to cover all feasible execution paths.
however it suffers from the high computation cost of constraint solving and exponential path growth in large applications.
coverage guided fuzzing has become increasingly popular during the past decade due to its simplicity and efficiency .
it generates randomised concrete inputs at low cost e.g.
via bit flipping by mutating inputs previously observed to lead to new execution paths.
however the resulting inputs more often than not fail to uncover new execution paths nor to satisfy complex constraints to reach deep program states.
the complementary nature of these two techniques which legion s design harnesses is highlighted by considering the exploration of the program ackermann02 in fig.
.
this program is drawn from the test comp benchmarks2 .
the program takes two inputs mand n lines and then reaches a choke point in line which likely takes the common branch when mandnare chosen at random and thus immediately returns in line .
concolic execution can compute inputs to penetrate the choke point to reach the rare branch lines but generating sufficient inputs to cover all paths of the recursive function ackermann via constraint solving is unnecessarily expensive.
in comparison a hypothetical random fuzzer restricted to generating values of m and n .
.
.
will quickly uncover all paths ofackermann without the need to consider exponentially growing sets of constraints from the unfolding of its recursive calls.
note that in general finding such closed form solutions is expensive 55legion best first concolic testing ase september virtual event australia int ackermann int m int n if m return n if n return ackermann m return ackermann m ackermann m n void main int m input n input choke point if m m n n log n m common branch return else int r ackermann m n rare branch assert m r figure ackermann02.c pr ogram entry state rar e branch ... log n m ...... unkno wn paths obser ved paths ... ... scor e estimate the likelihood of finding new pathsa concrete execution traceof the common branch figure a tree representation of ackermann02 and or undecidable for programs constraints that involve nonlinear arithmetic or bitwise operations.
however we note that it is instead sufficient if the inputs preserve a chosen path prefix with high probability.
since they have complementary benefits much prior work has sought to combine concolic execution and fuzzing .
but how should they be combined and when should each be used?
for instance in the example would it be more efficient to quickly flood both branches with unconstrained random inputs or to focus on uncovering the rare branch even though each input generation takes longer?
legion provides a general purpose answer to this question by collecting and leveraging statistics about the execution of the two branches.
legion collects statistics about program executions while simultaneously iteratively exploring the program s execution paths and branching structure unifying this information together into a common tree structured search space on the fly.
fig.
illustrates such a tree representation of ackermann02.c .
the tree root corresponds to the program entry point and every child node represents a conditional jump target of its parent.
each node of the tree thus represents a partial program path.
each stores statistics about the concrete executions observed so far that follow that path i.e.
pass through that node .
at each iteration of the search these statistics allow legion to decide which node is most worthy of further investigation.
having selected a node legion unifies concolic execution input generation via solving path constraints and fuzzing in the form of approximate path preserving fuzzing appfuzzing to target that part of the search space.
appfuzzing is designed to sample inputs that pass through the node i.e.
to generate inputs that with high probability cause the program to follow the execution path from the root to the node selected but also distribute relatively randomly and uniformly among all child paths of the selected node.
appfuzzing uses a combination of constraint solving applied to the node s path condition and controlled mutation applied to solver generated inputs.
statistics are gathered from the concrete executions produced byappfuzzing to further refine legion s understanding of the search space of the program under test for subsequent iterations of the search.
in essence these statistics capture the value of sampling from a particular node.
since legion s goal is to maximise coverage itscurrent implementation measures value in terms of new execution paths uncovered during concrete execution of the program on those inputs .
thus statistics such as the ratio of observed paths over total paths serve to estimate the potential of finding new paths by sampling from a particular subtree.
this enables legion to address the following two trade offs the trade off in depth between a parent program state and its child.
sampling under the path constraints of a parent node e.g.
the choke point in the example has three benefits a symbolic execution to the child states common and rare branches can be avoided b inputs generated from the parent may traverse execution paths of all children and c parents tend to have simpler constraints to solve.
however this may waste time on children with constraints that are easy to satisfy.
for instance in the example sampling the entry state of the program may cover both branches but many executions will repeatedly traverse the common branch leaving the more interesting recursive function ackermann insufficiently tested.
sampling from the rare branch state can guarantee executions to pass through the recursive function but it is more computationally expensive and will miss the function log n m .
the trade off in breath between siblings program states.
given two siblings sampling from either can potentially gain the benefit of covering more paths and collecting more statistical information of the program structure underneath the selected node at the opportunity cost of losing the same benefit on its sibling.
for example choosing to sample inputs for the rare branch will cover more paths of the function ackermann but it comes with a higher cost for input generation via constraint solving and can neither cover the sibling nor learn about the subtree beneath it.
legion s statistical approach allows it to address these trade offs by adopting neither a breath nor depth first approach but instead abest first strategy.
legion s best first strategy is a variation of the monte carlo tree search algorithm a popular ai search strategy for large search problems in the absence of full domain knowledge.
a sequential decision making framework mcts carefully balances the choice between selecting the strategy that appears to be most rewarding based on current information exploitation vs one that appears 56ase september virtual event australia dongge liu gidon ernst toby murray and benjamin i.p.
rubinstein to be suboptimal after few observations but may turn out to be superior in the long run exploration .
we argue that mcts is particularly well suited for automated coverage testing not only due to its utility on large search spaces without full domain knowledge or even domain heuristics but also because it is known to perform well on asymmetric search spaces as exhibited in the running example and ubiquitous in software generally .
to utilise the full potential of mcts on coverage testing legion addresses the following challenges the selection policy of mcts controlled by its score function explained later in section .
plays a key role in its performance.
however there is no well established strategy or heuristic in coverage testing to determine the most efficient program compartment to focus in different scenarios.
thus legion implements a modular score function flexible to a range of heuristics section .
that we show can be efficiently instantiated for coverage based testing section .
.
how should mcts hyperparameters section .
be chosen for a program under test and what is their influence on legion s performance?
we answer this question by empirical evaluation showing that legion can perform effectively with naive hyperparameter choices across a wide variety of programs as well measuring the sensitivity of its performance to the choice of parameters section .
to achieve maximal efficiency mcts requires being able to randomly and uniformly simulate plays from the node selected at each iteration.
for legion this means being able to generate many random and uniform inputs that can traverse the selected program state by mutating solutions from constraint solving.
neither fuzzing nor constraint solving alone are sufficient for this purpose for which legion introduces approximate path preserving fuzzing explained in section .
.
3legion mcts the key insight of legion is to generalise concolic execution and fuzzing in a principled way with the monte carlo tree search algorithm.
to do so legion makes two modifications to traditional mcts to make it more suitable for coverage based testing which we describe in this section.
these concern respectively the mcts tree nodes and the tree construction.
.
tree nodes as mentioned in section legion treats testing as searching a tree structured space that represents the reachable states of the program an exemplar of which is depicted in fig.
.
each tree node is identified by the address of a code block in the program under test.
the tree root corresponds to the program entry and every child node represents a conditional jump target of its parent.
as mentioned each node represents the partial execution path from the program s entry point to it and stores statistics about the concrete program executions observed so far to follow that path which are used by the mcts selection policy to decide which part of the tree to investigate at each iteration of the search algorithm.
when the mcts algorithm selects a node for investigation legionthen generates new program inputs that with high probability cause the program to traverse the path represented by that node.
to do so recall that legion uses a form of directed fuzzing called approximate path preserving fuzzing appfuzzing which is a hybrid of mutation fuzzing and input generation by constraint solving.
legion s appfuzzing implementation thus benefits from symbolic information about the program state that corresponds to the tree node i.e.
the state reached after traversing the partial path that the node represents specifically the symbolic path condition.
therefore certain nodes in the tree also carry a symbolic state which encodes the corresponding path condition.
however not all tree nodes carry a symbolic state.
recall from section that legion performs symbolic execution lazily.
this means that after observing a new concrete execution path that path will be integrated into the tree but without symbolically executing it.
indeed legion defers symbolically executing a path until it has evidence that investigating that path could be beneficial for uncovering additional new execution paths as determined by the mcts selection algorithm .
until a path is symbolically executed the tree nodes that represent it do not contain symbolic state information.
thus legion s tree nodes come in a variety of types depending on their purpose and the information they contain.
for instance hollow nodes are ones that represent observed concrete execution paths but do not yet carry symbolic state information while solid nodes additionally do carry satisfiable symbolic state information phantom nodes represent feasible program paths observed and validated during symbolic execution but not yet observed during concrete execution.
two further types also exist redundant and simulation as described below.
we discuss each type of node with occasional reference to fig.
.
hollow nodes are basic blocks found by concrete binary execution but have not been selected for symbolic execution yet and hence do not have their symbolic states attached.
they are used to mark the existence and reachability of paths and to collect statistics of observed rewards.
when a hollow node is selected for investigation by the mcts selection step explained shortly legion invokes symbolic execution from its closest solid ancestor to obtain a path condition to seed appfuzzing.
by so the node will be re categorised as one of the following two types.
each hollow node appears as a hollow round node in fig.
.
solid nodes are hollow nodes with symbolic states attached and whose path condition has one more constraint over that of its closest solid ancestor i.e.
they are not redundant.
each solid node has a special child node called a simulation child of square shape described below.
each solid node appears as a solid round node in fig.
.
redundant nodes represent states for which appfuzzing is a impossible or b redundant either a they were observed during concrete execution but not during symbolic execution e.g.
due to under approximation and concretisation during symbolic execution and so cannot be selected for appfuzzing because they lack symbolic state information or b have exactly the same symbolic constraint as their closest solid parent e.g.
jump targets of tautology conditions for which appfuzzing is redundant because 57legion best first concolic testing ase september virtual event australia sele ction simulation expansion back pr opagation figur e the four stages of each iteration of legion s mcts algorithm.
identical information is already captured by their closest solid ancestor.
hence legion never simulates from them i.e.
never selects them for appfuzzing .
no redundant nodes are depicted in fig.
.
phantom nodes denote symbolic states whose addresses have not yet been seen during concrete execution but have been proved to exist by the symbolic execution engine.
they are found during the selection stage when the symbolic execution engine shows that the symbolic state of a hollow lone child has a sibling state.
they act as place holders for as yet unseen paths waiting to be revealed by concrete binary execution i.e.
by appfuzzing .
when that happens a phantom node will be replaced by a solid node when legion integrates the observed concrete execution path into the tree.
no phantom nodes are depicted in fig.
.
simulation nodes.
different from vanilla mcts legion allows sampling from intermediate nodes which represents appfuzzing applied to some point along a partial execution path.
to incorporate this into mcts we add special leaf nodes to the tree whose shape is a square and whose parent is always solid.
when the mcts selection stage chooses a simulation node for appfuzzing this choice implies that legion believes that directing fuzzing towards the program state represented by the solid parent is more beneficial than fuzzing any of its child program states where beneficial means the estimated likelihood of discovering a new path .
each simulation node appears as a square node in fig.
.
.
tree construction fig.
illustrates how legion uncovers the tree structured search space in its variation of mcts each iteration of the search algorithm proceeds in four stages.
in fig.
bold lines highlight the actions in each stage.
solid thin lines and nodes represent paths and code blocks that have been covered and integrated into the tree.
dotted thin lines and nodes represent paths and nodes not yet found.
the four stages are as follows selection.
shown by bold arrows legion descends from the root by recursively applying a selection policy section .
until it reaches a simulation node square shape in fig.
.
upon visiting a hollow node i.e.
that carries no symbolic state depicted as hollow circles it performs symbolic execution from the nearest solid ancestor depicted as filled nodes to compute the symbolic state of the hollow node adds the symbolic state to that node turning it solid and attaches to it a simulation child the square .simulation.
having selected which program state to target for investigation legion applies appfuzzing section .
on the program state represented by the solid parent of the selected simulation node to generate a collection of inputs that with high probability will cause the program to follow the path from the root to the solid parent.
it then executes the program on those inputs and observes the resulting execution traces which are represented by dashed circles and lines in fig.
.
expansion.
this step involves mapping each observed execution trace to a path of corresponding tree nodes new traces cause new hollow round nodes to be added to the tree.
back propagation.
this step updates the statistical information recorded in the tree to take account of the executions observed during the simulation step.
legion computes the reward section .
from each simulation i.e.
from each concrete execution performed during the simulation step and propagates the reward to all nodes along the execution trace.
note that the path s observed during concrete execution might differ from that chosen during the simulation step because appfuzzing is necessarily approximate.
therefore in this step legion also propagates the reward to each node on the path from the root to the node chosen during the selection step.
design considerations having described legion s adaptation of mcts at a high level we now discuss two of the most critical parts of its design namely the design of the selection policy used during the selection phase of each mcts iteration and the design of legion s directed fuzzing implementation appfuzzing.
we discuss further implementation details and considerations in section .
.
selection policy one of the central design goals of legion is to generalise a range of prior coverage based testing methods.
so requires a general policy for selecting which tree node to investigate at each mcts iteration to make legion adaptable to different search strategies and coverage reward heuristics with a modularised design.
at its simplest the selection policy s job it to assign a score to each node.
this score is used as follows during the selection step 58ase september virtual event australia dongge liu gidon ernst toby murray and benjamin i.p.
rubinstein of each mcts iteration.
recall that selection proceeds via recursive descent through the tree towards that part of the tree deemed most worthwhile to investigate.
the score guides this descent.
selection starts at the root.
then the immediate child with the highest score is traversed with ties being broken via uniform random selection .
traversal proceeds to that child s highest scoring child and so on.
inlegion the score of each node represents the optimistic estimation that appfuzzing will discover new paths when applied to the program state represented by the node.
scores are computed by applying the upper confidence tree uct algorithm on the rewards obtained during the prior simulation i.e.
during the prior appfuzzing .
we leave a discussion of rewards to section .
but for now it suffices to understand that rewards correspond to the discovery of new execution paths.
for a node nwe define its score uct n as follows.
for a newly created node its score is initialised to to ensure that uninvestigated subtrees are always prioritised over their siblings.
otherwise uct n is uct n xn s lnpsel nsel where xnis the average past reward from n is a hyperparameter described below that defines the mcts exploration ratio nseland pselare respectively the number of times that node nand its parent have been traversed so far during prior selection stages.
this score is designed to balance two competing concerns when searching the tree namely exploitation vs.exploration.
exploitation corresponds to investigating a part of the tree that has proved rewarding in the past high xn in the belief that because it has yielded new execution paths before it is likely to do so again in the future.
exploration on the other hand correspond to investigating a part of the tree that so far appears under explored low psel nsel and where rewards are less certain.
the second term derives from an upper bound of a confidence interval for the true mean based on the multi armed bandit algorithm ucb1 .
the precise balance between these two concerns is controlled by the choice of non negative hyperparameter .
were zero or very large legion would base its selection decisions only on past rewards resp.
visitation counts corresponding to pure exploitation resp.
exploration .
instead should be chosen to be some small positive value to permit exploration.
we investigate in more detail how affects legion s performance.
for any fixed choice as a node s parent is traversed without the node visited the fractionq lnpsel nselgrows causing legion to favour the child.
.
approximate path preserving fuzzing having selected a node i.e.
program state to target legion then applies its approximate path preserving fuzzing algorithm appfuzzing to generate inputs that when supplied to the program under test will with high probability cause the program to execute from the entry point to reach that state following the path from the tree root to the selected node.
appfuzzing can be seen as a hybrid of input generation via constraint solving and mutation fuzzing and is seeded by the symbolic path condition stored in the selected simulation node.
legion s appfuzzing is inspired by quicksampler a recent algorithm for sampling likely solutions to boolean constraints that mixes satsolving and bit mutation.
legion s appfuzzing on the other hand operates on smt constraints specifically the bit vectors theory of the constraints produced by legion s symbolic execution engine angr .
defappfuzzgen constraint solve constraint yield foreach bit biof do solve constraint bi for in do end yield end algorithm input generation for appfuzzing defappfuzz nsamples node results while len results nsamples do results.append appfuzzgen node.path constraint end algorithm approximate path preserving fuzzing theappfuzzing algorithm appfuzz is depicted in algorithm .
its inputs comprise the selected node to which appfuzzing is being applied as well as constant nsamples theminimum number of new inputs that appfuzzing should attempt to generate.
like nsamples is a hyperparameter discussed further in section .
.
input generation is delegated to a helper generator function depicted in algorithm which is repeatedly called until at least nsamples have been generated.
by design the helper generator appfuzzgen can yield a variable number of inputs each time it is called.
hence appfuzz can often end up generating more than the minimal number of required inputs for each simulation.
input generation handled by appfuzzgen in algorithm is performed using a mixture of constraint solving and mutation of prior solver generated solutions.
thus appfuzzgen takes as a parameter the path constraint constraint of the node in question.
on its first invocation it simply solves the node s constraint and returns that solution .
however when subsequently invoked for the same node e.g.
if multiple inputs are required for simulation when nsamples its execution restarts from the point directly after the first yield statement i.e.
at the entry to the outer loop.
each iteration of this outer loop generates an ever larger set of new inputs and the generator returns the newly generated inputs after each iteration.
subsequent invocations of the generator resume execution from the point just after the second yield statement i.e.
at the point where the next iteration of the outer loop proceeds.
59legion best first concolic testing ase september virtual event australia the outer loop iterates over each bit biof the initial solvergenerated solution .
in each outer loop iteration the generator invokes the constraint solver once to generate a solution to the path constraint that if one exists is guaranteed to be distinct from by differing in bit bi.
then for each input generated in previous iterations of the outer loop ismutated with and to produce a new input.
the and all of the new mutation generated inputs are then returned.
thus each invocation of the generator causes a single invocation of the constraint solver however repeated invocations yield exponentially more inputs.
this process continues until the outerloop terminates.
the generator will begin afresh on subsequent invocations.
not depicted in algorithm is the fact that previously generated inputs are remembered to avoid returning duplicate inputs.
once the solver can return no new solutions a node is marked as exhausted and no further simulation appfuzzing will be performed on it see section .
.
.
the mutation operator combining and via bitwise exclusive or simulates the mutation operator used in a similar fashion by quicksampler on boolean constraints lifting it to bit vectors.
that operator was shown with high probability to produce results that each satisfy the boolean constraint and in aggregate are uniformly distributed.
for this reason we conjecture that our appfuzzing implementation is likely to produce inputs that preserve the path to the selected node and that satisfy i.i.d.
requirements of mcts simulations.
in scenarios where one wishes to produce more inputs per constraint solution our implementation can be adjusted to do so by having it perform more mutations per outer loop iteration.
however so is likely to reduce the accuracy of the results i.e.
the probability that they will satisfy the given path condition.
practical considerations with the major design considerations out of the way we now turn to the salient details of legion s current implementation.
these concern respectively the reward heuristic used in the uct score function of its mcts implementation as well as the choices of the various hyperparameters like andnsamples .
.
a reward evaluation heuristic in mcts rewards quantify the benefits observed during each simulation.
in legion s mcts simulation corresponds to concrete execution of the program under test via appfuzzing.
an important implementation consideration is what should be the reward function?
put another way what should rewards correspond to?
when should a simulation concrete execution be considered rewarding?
recall that the average past rewards associated with a node n was denoted xn in the uct score function defined in eq.
in section .
.
by choosing different instantiations for this term one can naturally adapt legion to various exploitation strategies.
however since the goal of legion s present implementation is to discover the maximum number of execution paths in the shortest possible time in this paper we implement and evaluate a simplereward heuristic the reward of a simulation is the number of new paths found by appfuzzing.
recall that for a node n nseldenotes the number of times nhas been traversed during selection and that pseldoes likewise for n s parent.
then we denote by nwinthe number of distinct execution paths discovered so far that pass through node n. the average past reward associated with node nis thennwin nsel the ratio of the number of paths found so far that pass through this node compared to the number of times it or a child has been selected for appfuzzing.
this ratio is chosen under the assumption that the more new paths were found by running appfuzzing on a node in the past the more potential the node has in increasing coverage in the future.
plugging this into eq.
and remembering that the initial score of a node is set to we arrive at the following instantiation of the uct score in legion s current implementation uct n nsel nwin nsel q lnpsel nselnsel to better understand this heuristic let us return to the example of fig.
.
note that only a specific pair of mandncan violate the assertion on line but uncovering that assertion requires being able to get past the recursion of the ackermann function.
the recursion ofackermann is therefore an attractive nuisance for uncovering theassert statement since recursion necessarily produces new execution paths.
this is why the exploration component of the uct score is critical.
at the same time the use of such a fine grained coverage metric which tracks individual execution paths instead of more coarse grained metrics like statement and branch coverage or afl s coverage maps ensures that legion does not overlook paths that can arise only after deep recursion.
as we show later in section .
even with this simple heuristic legion performs surprisingly well and the heuristic appears relatively robust.
yet there of course exists much scope to consider heuristics that take into account other relevant information such as time consumption subtree size or other static properties of the program.
we leave the investigation of such for future work.
.
.
optimisations.
this heuristic permits a number of optimisations on node selection which we have implemented in legion.
essentially these allow legion to decide when a node will no longer produce any future rewards i.e.
that no new paths can be found via appfuzzing applied to the node .
when so legion overrides the node s score to .
in this case we say that the node is pruned from the tree.
however note that the node is never physically removed from the tree its score is just overridden to ensure it will never be selected.
fully explored nodes.
a node is fully explored if there is no undiscovered path beneath it.
for example final nodes of complete concrete execution paths are fully explored.
a parent node will be pruned if all non simulation children are fully explored.
given a fully explored node may have hidden siblings legion will prune it only after identifying all of its siblings via symbolic execution.
useless simulation nodes.
a simulation node is useless if it has less than two not fully explored siblings.
recall that simulation nodes are children of solid nodes and that solid nodes represent 60ase september virtual event australia dongge liu gidon ernst toby murray and benjamin i.p.
rubinstein a point in a concrete execution path and contain a symbolic path condition.
when a simulation node is selected during the mcts selection stage section this represents the decision to target its solid parent node with appfuzzing.
so essentially will yield some paths from the full set of paths sin the subtree under the solid parent.
on the other hand sampling from one of the simulation node s siblings i.e.
from another child of the solid parent will yield paths that are drawn from a strict subset tofs.
sampling from s can be beneficial if it can yield paths from multiple such t. however if there is only one such tremaining it is better to sample from it than from s. hence in this case the simulation node is pruned.
exhausted simulation nodes.
a simulation node is exhausted if no input can be found when applying appfuzzing on it.
this happens when all inputs that the solver is capable of producing under the constraint of the node have been generated.
under approximate symbolic execution.
due to underapproximation the symbolic execution engine might incorrectly classify a feasible state as infeasible e.g.
due to early concretisation.
this creates a mismatch between the symbolic execution results and concrete execution traces.
in this case legion cannot apply appfuzzing to such a node or any of its decedents but must instead target its parents.
under approximation can cause legion to erroneously conclude that a subtree has been fully explored.
to mitigate this issue legion can be run in persistent mode which continues input generation even for apparently fully explored subtrees see section .
.
.
recall from section that to construct the search tree legion uses binary instrumentation to collect the addresses of conditional jump targets traversed during concrete execution.
so produces a trace i.e.
a list of conditional jump target addresses.
legion can be configured to limit the length of such traces to a fixed bound mitigating the overheads of instrumented binary execution and hence the depth of the search tree.
the number is controlled by a hyperparameter named tree depth see section .
.
.
hyperparameters another important practical consideration is the choice of the various hyperparameters that control legion s behaviour.
some of these like andnsamples we have already encountered.
however we summarise them all below for completeness.
naturally different choices of the hyperparameters will bias legion s performance in favour of certain kinds of programs under test.
we investigate this effect in section .
.
.
exploration ratio .the exploration ratio of the mcts algorithm controls the amount of exploration performed in comparison to exploitation see section .
by the selection phase of mcts.
number of cores.
legion supports the leaf parallelisation of mcts wherein simulations are run in parallel.
for legion this corresponds to running multiple concrete executions in parallel when appfuzzing returns multiple inputs.
the maximum number of such simultaneous parallel executions is controlled by this hyperparameter.
tree depth.
legion can limit the depth of its search tree to this parameter by forcibly terminating concrete executions once the length of the trace of conditional jump targets produced by the binary instrumentation reaches this value.concrete execution timeout.
this hyperparameter controls when legion will forcibly terminate concrete executions produced byappfuzzing that take too long.
symbolic execution timeout.
recall that when legion decides to target a node for appfuzzing that does not yet contain its symbolic path condition it then symbolically executes to that node from its nearest symbolic ancestor.
the symbolic execution timeout is used to forcibly terminate such symbolic executions if they take too long.
if such a timeout occurs legion will proceed to select the nearest symbolic ancestor produced by the terminated symbolic execution.
minimum number of samples per simulation nsamples .recall that this parameter controls the minimum number of inputs to generate for each appfuzzing invocation and that each such invocation might return more than this minimum see section .
.
persistent.
when set this boolean flag causes legion to continue input generation even for apparently fully explored subtrees to mitigate under approximate symbolic execution section .
.
and expensive constraint solving.
evaluation we designed two kinds of experiments to evaluate legion s current design and implementation.
we sought to answer two fundamental questions respectively is legion effective at generating high coverage test suites in fixed time as compared to other state ofthe art tools?
and what is the effect of the choices of legion s various hyperparameters on its performance and do there exist suitable default choices for these that are robust across a variety of input programs?
peer competition.
to answer the first question legion competed in the cover branches category of test comp test generation competition.
legion has evolved since the competition this paper reports the result of running the latest version of legion on the same bechmark suite3on the same host machine with the same resources controlled by the same benchmarking framework as was used in test comp thereby allowing our results to be compared against results obtained during the competition.
sensitivity evaluation.
to answer the second question we selected a carefully chosen subset of the benchmark programs from the test comp benchmarks and then we evaluated the effect of varying legion s various hyperparameters on its ability to perform on these programs.
again we report the results based on the most recent version of legion.
.
experiment setup to maximise reproducibility we carried out both evaluations using thebenchexec framework4 .
it allows the usage of cores and 15gb memory.
our evaluations used test comp benchmarks in which for each coverage percentages computed by testcov5 were reported after minutes.
there are programs in total in 61legion best first concolic testing ase september virtual event australia settings scor e function cor et ree depth conex timeout symex timeout nsamples scor e p value baseline uct .
scor e function random random .
.
uct .
.
.
uct .
.
.
uct .
.
cor e uct .
.
cor e uct .
.
t ree depth 102uct .
.
t ree depth 103uct .
.
t ree depth 107uct .
.
conex timeout .
uct .
.
.
conex timeout uct .
.
symex timeout uct .
.
symex timeout uct .
.
nsamples uct .
.
nsamples uct .
.
table the sensitivity experiment compared hyperparameter settings.
only one setting is changed in each alternative indicated by the first column including the score function exploration ratio the number of cores core concrete execution timeout conex timeout symbolic execution timeout symex timeout and the minimum number of samples per simulation nsamples .
the significant p values .
are in bold font the test comp set sorted into 13suites.
legion6requires two dependencies angr7andclaripy8.
.
.
peer competition.
all tools to which we compared legion in the peer competition were seeded with the same initial dummy input .
we purposefully did not fine tune the hyperparameters for the competition.
for instance we used the value of 2for which is commonly used for uct scores .
we limited the tree depth to be within and the number of cores to be as they are sufficient for legion in most cases.
we did not time out symbolic or concrete execution and run at least one input in each simulation stage nsamples like the original mcts.
the results of our sensitivity experiments would later suggest that the performance oflegion is not sensitive to most of these parameters when they were chosen reasonably.
section .
.
.
each experiment was conducted on the same host machine as the test comp competition with a .
ghz intel xeon e3 v5 cpu running at mhz with turbo boost disabled.
to support a fair and meaningful comparison we excluded two benchmark suites busybox memsafety andsqlite memsafety .
all programs in the former cause source code compilation errors due to name conflicts.
all tools scored close to 0on the latter suite because of an unknown issue.
since legion s goal is maximising coverage our evaluation was restricted to the coverage as opposed to the error finding category i.e.
cover branches of test comp .
the peer competition we ran legion in persistent mode discussed in section .
.
to ensure that it would make full use of the time given to it for each benchmark program.
.
.
sensitivity experiments.
we evaluated legion s sensitivity to the various hyperparameters by measuring its performance on thesequentialized benchmark suite from the test comp benchmarks.
this benchmark suite was selected following the competition results which showed that legion had some room to improve its coverage score for this suite yet the competition result for it was not abysmal either.
hence effects on legion s performance here would be clearly visible in the final coverage score obtained for this benchmark suite.
this suite is also of sufficient size containing programs that together comprise branches branches on average per program .
the various hyperparameter settings that we compared are listed in table .
for these experiments legion was run on a machine with a .
ghz intel xeon platinum 8180m cpu at mhz.
the persistent mode flag was not enabled during these sensitivity experiments to more accurately demonstrate how other hyperparameters affect the results.
.
results .
.
peer competition.
the normalised9results from the peer competition appear in table .
each benchmark suite is listed in the first column with the number of programs it contains in brackets.
that number is also a theoretical upper bound on the total coverage score that can be achieved for each category.
the following columns list the score of each competitor on each suite where the score is 62ase september virtual event australia dongge liu gidon ernst toby murray and benjamin i.p.
rubinstein the average of the coverage score between and achieved on each program in the suite.
the peer experiment demonstrates that legion is effective across a wide variety of programs despite the simplicity of its current heuristics and limitations of its implementation.
legion is competitive in many suites of test comp achieving within of the best score in of the suites in the cover branches category.
legion outperformed all other tools on some benchmarks discussed below which highlights the general effectiveness of the approach.
.
.
sensitivity experiments.
for each of the hyperparameter settings investigated table reports the sequentialized suite coverage result.
it also reports the p value obtained by applying student s t test paired two tailed to determine whether the difference from the baseline was statistically significant.
conventionally we claim the difference is significant when that value is less than .
.
as to be expected these results indicate uct scoring superior to the baseline random selection.
legion s performance is also sensitive to the choice of its exploration ratio .
small values of near .
appear to work best based on these results and outperform pure exploitation .
for currently unknown reasons using core appears to have a slightly better performance.
the choices of other hyperparameters including the tree depth concrete execution timeout symbolic execution timeout and the minimum number of inputs to generate for each appfuzzing nsamples appear to be not influential when chosen within a reasonable range.
however the value of still exhibited very limited effect across all suites when we were measuring legion s overall performance to rule out overfitting.
the most preferable setting above .
improved the overall competition score by merely .
.
.
discussion legion inherits limitations from angr and mcts.
angr as symbolic execution backend of legion eagerly concretises size values used for dynamic memory allocations which then causes it to conclude erroneously that certain observed concrete execution paths are infeasible.
the design of legion s mcts allows it to work around this limitation legion first detects this case from the mismatch between symbolic and concrete execution then omits the erroneous programs states from the selection stage.
when mcts predicts new paths under them legion invokes appfuzzing on their parents instead.
with this mitigation legion achieved full coverage on loops sum array .c in contrast to all other tools despite the dynamic allocations.
angr uses vex ir which prior work has noted leads to increased overheads in symbolic execution.
legion mitigates this by performing symbolic execution lazily only computing the symbolic states of nodes selected by mcts.
angr cannot model arrays that have more than 0x1000 elements.
in particular it failed on 16benchmarks in suite arrays that involves multidimensional arrays.
angr only supports out of the system calls in the linux kernel .
and is known to scale poorly to large programs .
the nature of mcts makes legion less suitable for exploring spaces where the reward is rare.
for example benchmarks in suite controlflow are full of long sequences of equality constraints that are satisfied by few inputs making new path discovery via sampling i.e.appfuzzing very rare.
this benchmark suite happens to be an extreme negative example of the trade off in depth discussed in section that legion intends to balance where fuzzing the parent gives no reward.
expensive constraint solving also adds extra cost to sampling.
in particular claripy spent .82seconds on average to solve each constraint in this suite.
generally invoking appfuzzing at intermediate nodes with less complicated constraints to generate mutations can amortise this cost.
however although on average legion generated .37mutations per program at negligible costs 5seconds per mutation and .
of them preserved their paths none of them found any new path due to the equality constraints.
to a certain extent this could possibly be mitigated by decreasing legion s exploration ratio constant in the uct score but such fine tuning would overfit legion to the competition benchmark suites.
to analyse the impact of this extreme example we re normalised the scores of the peer competition with this suite excluded.
it shows that the overall normalised score of legion .
is higher than klee .
and close to hybridtiger .
.
mcts works much better on less extreme examples.
benchmarks seq mthreaded pals lcr var start time .cinterleave equality constraints with range constraints making new path discovery less rare .
of the new paths are found via sampling at a pathpreserving rate of .
and less expensive each constraint solving took .81seconds on average .
as a result legion performed roughly the same as coveritest on these 12benchmark programs and largely outperformed all other competitors.
similarly legion fully covered the sample program ackermann02.c shown in fig.
with .
of the new paths uncovered by mutations from appfuzzing .
of them preserving their path prefix at an average cost of .
5seconds approximately times faster than constraint solving via claripy.
related work we consider recent work that adopts similar ideas to legion at the intersection of fuzzing and concolic execution.
like legion driller s design is also inspired by wanting to harness the complementary strengths of concolic execution and fuzzing.
it augments afl by detecting when fuzzing gets stuck and then applying concolic execution constraint solving to generate inputs to feed back to the fuzzer to allow it to traverse choke points.
unlike our appfuzzing however little attempt is made to ensure that subsequent mutations made by the fuzzer to each solver generated input preserves the input s paths condition.
thus afl might undo some of the hard work done by the solver.
legion uses rewards from past appfuzzing to predict where to perform concolic execution modelling automated test generation as monte carlo tree search.
the authors in formally model programs as markov decision processes with costs.
their model is used to decide when to perform input generation via constraint solving vs. when to generate inputs via pure random fuzzing.
like legion their approach tracks the past rewards from concrete execution to decide when to perform fuzzing.
however unlike legion their fuzzing approach is purely random.
legion applies the uct algorithm to make choices about which parts of the program to target at each iteration while the approach of instead applies 63legion best first concolic testing ase september virtual event australia participants legion klee coveritest hybridtiger libkluzzer prtest symbiotic tracer x verifuzz arrays .
.
f loats .
.
.
.
.
heap .
.
.
.
.
lo ops .
.
.
.
.
.
.
re cursive .
.
.
.
.
.
.
.
.
de vicedriverslinux64 .
.
.
.
.
.
.
mainheap .
bitv ectors .
.
.
.
.
.
.
.
contr olflow .
.
.
.
.
.
.
.
.
eca se quentialized .
.
.
.
.
.
.
.
.
normailise d average .
.
.
.
.
.
.
.
.
table normalised accumulated coverage scores for each benchmark suite the higher the better .
legion outperformed klee in7out of 11benchmark suites in bold font .
the results are reproduced with the latest version of legion excluded two benchmark suites to avoid noise busybox memsafety sqlite memsafety a greedy algorithm to estimate the rewards of random input generation.
the authors approach unlike legion applies a static heuristic to estimate the cost of constraint solving in order to make an informed decision between the precision and expense of constraint solving vs. the imprecision and efficiency of pure random fuzzing.
legion eschews this all or nothing choice altogether by blending fuzzing and concolic execution via appfuzzing to avoid the drawbacks of both while retaining their strengths.
digfuzz extends driller and similar to legion collects statistics to decide which program states would benefit most from concolic execution via monte carlo simulations.
while legion collects coverage statistics digfuzz instead focuses on learning which parts of the program are most difficult for the fuzzer to traverse and only then does it decide to invoke the solver on the assumption that solving is expensive and should only be used when necessary.
whereas legion estimates the likelihood of reward uncovering new execution paths via directed appfuzzing for each node based on past rewards from appfuzzing digfuzz instead estimates the probability that the undirected fuzzer will be able to traverse each path based on the fuzzer s past performance.
it collects statistics about how often each branch is traversed by the fuzzer.
then the probability of traversing a particular path is computed by multiplying together estimates of the probabilities on each of the branches along that path.
so while both methods use a form of monte carlo simulation to track statistics to decide how to generate inputs for the program they do so for quite different purposes and using methods that appear relatively complementary.
this comes from their different design philosophies digfuzz wants to minimise solver use as much as possible and is happy to spend more time on repeated traversal of the paths by the cheap fuzzer.
legion instead is willing to use the solver more often although not as often as in traditional concolic testing to avoid concrete executions that often repeat the same execution paths.
mcts has also been used recently to guide traditional concolic execution .
the authors use mcts to pick which branch to concolically execute.
unlike legion this requires symbolic execution along the entire path which legion can avoid since it only ever performs symbolic execution lazily section .
.
it also requires one solver call for each concrete execution.
legion avoids this by using appfuzzing instead which generates increasingly more inputsfor each solver invocation at the price of not guaranteeing that all generated inputs will satisfy the path constraint.
finally while legion s score function applies uct to estimate rewards in terms of discovering new execution paths it is not clear what is the score function used in .
finally we note that other work has also attempted to improve fuzzing by adopting methods from machine learning.
for instance learn fuzz trains a neural network to represent the program under test to aid fuzzing.
the angora fuzzer applies gradient descent as an input mutation strategy to help it traverse conditional branches while aflgo uses simulated annealing to guide directed fuzzing.
in contrast legion adopts mcts with appfuzzing as a principled unification of fuzzing and concolic execution.
conclusion how can we maximise code coverage by generalising concolic execuiton and fuzzing?
legion shows a possible solution with its variation of the monte carlo tree search algorithm.
by tracking past rewards from appfuzzing legion learns where concolic execution effort should be spent namely on those parts of the program in which new execution paths have been observed in the past.
symbolic execution then returns the favour by computing new promising symbolic states to support accurate appfuzzing.
which states to prefer is estimated using the uct algorithm which navigates the exploration versus exploitation trade off.
we demonstrated a simple reward heuristic to maximise discovery of new execution paths and showed how this could be encoded in mcts s traditional uct score function.
we evaluated legion both to measure its performance against its peers and to understand its sensitivity to hyperparameters.
we found that legion was effective on a wide variety of benchmark programs without being overly sensitive to reasonable choices for its hyperparameters.
legion provides a new framework for investigating trade offs between traditional testing approaches and the incorporation of further statistical learning methods to assist automated test generation.
our results demonstrate the practicality and the promise of the ideas it embodies.
64ase september virtual event australia dongge liu gidon ernst toby murray and benjamin i.p.
rubinstein