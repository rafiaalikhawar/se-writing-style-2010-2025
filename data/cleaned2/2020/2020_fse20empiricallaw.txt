fuzzing on the exponentialcost ofvulnerability discovery marcel b hme monash university australia marcel.boehme acm.orgbrandon falk gamozolabs llc usa bfalk gamozolabs.com abstract we present counterintuitive results for the scalability of fuzzing.
given the same non deterministic fuzzer finding the same bugs linearly fasterrequireslinearly more machines.for instance with twicethemachines wecanfind allknownbugs inhalfthetime.yet finding linearly more bugs in the same time requires exponentially more machines.
for instance for every new bugwe want to find in hours we might need twice more machines.
similarly for coverage.
with exponentially more machines we can cover the same code exponentially faster but uncovered code only linearly faster.
in other words re discovering the same vulnerabilities is cheap but finding new vulnerabilities is expensive.
this holds even underthe simplifying assumption of noparallelizationoverhead.
wederivetheseobservationsfromoverfourcpuyearsworth of fuzzing campaigns involving almost three hundred open source programs twostate of the artgreyboxfuzzers fourmeasuresof code coverage and two measures of vulnerability discovery.
we provideaprobabilisticanalysisandconductsimulationexperiments to explainthis phenomenon.
ccs concepts software andits engineering software testing .
keywords softwaretesting scalability probabilisticanalysis coveragefrontier acmreference format marcelb hmeandbrandonfalk.
.fuzzing ontheexponentialcostof vulnerabilitydiscovery.in proceedingsofthe28thacmjointeuropeansoftware engineering conference and symposium on the foundations of software engineering esec fse november 8 13 virtual event usa.
acm newyork ny usa 12pages.
introduction fuzzinghasbecomeoneofthemostsuccessfulvulnerabilitydiscoverytechniques.forinstance googlehasbeencontinuouslyfuzzing itsownsoftwareandopensourceprojectsonmorethan25 000machines since december and found about 16k bugs in chrome and11kbugsinover 160oss projects onlybyfuzzing .
thosebugsthatarefoundandreportedarefixed.hence lessnew bugsarefoundwiththeavailableresources.itwouldbereasonable to increase the available resources to maintain a good bug finding permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage.copyrights forcomponentsofthisworkownedbyothersthanthe author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
esec fse november 8 13 virtual event usa copyright heldby the owner author s .
publicationrightslicensed to acm.
acm isbn ... .
r .
exponential cost machines additional vulns discovered linear cost min5 min15 min1 hour6 hours machinestime to expose same vulns figure each vuln.
discovery requires exponentially more machines left .
yet exponentially more machines allow to find thesamevulnerabilities exponentially faster right .
rate.sothen howisanincreaseintheamountofavailableresources relatedto an increaseinvulnerabilitydiscovery?
suppose google has stopped finding new bugs when fuzzing their software systems on thousand machines for one month.
so googledecidestoruntheirfuzzerson100xmore .
million machines for one month finding five new criticalbugs.
once thesearefixed howmany unknown criticalbugswouldanattacker findinamonththatwasrunningthesamefuzzersetupon5 million machines?
what if the attacker had millionmachines?
we proposeanempiricallawthatwouldsuggestthattheattackerwith 2xmore 5million machinesfindsanunknowncriticalbugwith likelihood or less while the attacker with 100x more million!
machines only finds five unknown critical bugs or less.
weconductedfuzzingexperimentsinvolvingoverthreehundred opensourceprojects incl.oss fuzz fts twopopular greyboxfuzzers libfuzzer andafl fourmeasuresof code coverage libfuzzer s feature and branch coverage as well as afl s path and map branch coverage and two measures of vulnerability discovery known vulns.
found and crashing campaigns .
fromtheobservations wederiveempiricallaws whichareadditionally supported and explained by our probabilistic analysis and simulation experiments.
an empirical law is a stated fact that is derivedbasedonempirical observations e.g.
moore slaw .
wemeasurethecostofvulnerabilitydiscoveryasthenumber of machines required to discoverthe next vulnerabilitywithin a giventimebudget.the numberofmachines ismerelyanabstraction of the number of inputs generated per minute.
twice the machines cangeneratetwicetheinputsperminute.conceptually onefuzzing campaignremains onecampaignwhereinputsarestillgenerated sequentially only machinestimesasfast.weassumeabsolutely nosynchronizationoverhead.formutation basedfuzzers anyseed that is added to the corpus is immediately available to all other machines.
notethat this gives usa lower bound on thecost ofvulnerability discovery our analysis is optimistic.
if we took synchronization overhead into account the cost of vulnerability discovery wouldfurther increasewiththe number of physical machines.
749esec fse november8 virtualevent usa marcelb hme andbrandon falk our first empirical law suggests thata non deterministic fuzzer that generates exponentially more inputs per minute discovers only linearly more vulnerabilities within a given time budget.
this meansthat a giventhesametimebudget thecostforeachnew vulnerability is exponentially more machines cf.
fig.
.left and b giventhesame machines thecostofeachnewvulnerability isexponentiallymoretime.infact wecanshowthisalsoforthe coverage of a new program statement or branch the violation of a newassertion orany otherdiscrete program property ofinterest.
our second empirical law suggests that a non deterministic fuzzerwhichgeneratesexponentiallymoreinputsperminutediscovers the same number of vulnerabilities also exponentially faster cf.
fig.
.right .
this means if we want to find the same set of vulnerabilitiesinhalfthetime ourfuzzerinstanceonlyneedsto generatetwice as manyinputsper minute e.g.
on2x machines .
given the same time budget and non deterministic fuzzer an attacker with exponentially more machines discovers a given known vulnerability exponentially faster but some unknown vulnerability onlylinearlyfaster.similarly withexponentiallymoremachines thesame code is covered exponentially faster but uncovered code onlylinearlyfaster.inotherwords re discoveringthesamevulnerabilities or achieving the same coverage is cheap but finding new vulnerabilities orachievingmorecoverage isexpensive.thisis under the simplifying assumption of nosynchronization overhead.
wemakeanattemptatexplainingourempiricalobservationsby probabilisticallymodellingthefuzzingprocess.startingfromthis model we conduct simulation experiments that generate graphs thatturnoutquitesimilartothoseweobserveempirically.wehope thatourprobabilisticanalysisshedssomelightonthescalabilityof fuzzingandthecostofvulnerabilitydiscovery whyisitexpensive to cover newcode but cheap to cover the same code faster?
empiricalsetup .
research questions rq.1giventhesamenon deterministicfuzzerandtime budget what is the relationship between the number of available machines andthe number ofadditional speciesdiscovered ?
rq.2giventhesamenon deterministicfuzzerandtime budget what is the relationship between the number of available machinesandthe timetodiscoverthesamenumberofspecies ?
rq.3giventhesamenon deterministicfuzzerandtime budget whatistherelationshipbetweenthenumberofavailablemachines and the probability to discover a given set of species ?
we call our dependent variables as species explained in sec.
.
.
.
non deterministicfuzzers forourexperiments weusethetwomostpopularnon deterministic coverage based greybox fuzzers libfuzzer and afl.
both fuzzers recieve different kinds of coverage feedback and implement different coverage guided heuristics.
libfuzzer isa unit levelfuzzer whileafl isasystem level fuzzer.
libfuzzer isastate of the artgreyboxfuzzerdeveloped at google and is fully integrated into the fts and oss fuzz benchmarks.libfuzzer is a coverage based greybox fuzzer which seeks to cover program features .
generated inputs that cover a new feature are added to the seed corpus.
a featureis a combination ofthebranchthatiscoveredandhowoftenitiscovered.forinstance two inputs exercising the same branches have a different feature set if one exercises a branch more often.
hence feature coverage subsumes branch coverage .libfuzzer aborts the fuzzingcampaign as soon as the first crash is found or upon expiry of a set timeout.inourexperiments weleveragethedefaultconfigurationof libfuzzer if not otherwiserequiredbythe benchmark.
afl isoneofthemostpopulargreyboxfuzzers.incontrast tolibfuzzer afldoesnotrequireaspecificfuzzdriverandcanbe directlyrunonthecommandlineinterface cli ofaprogram.afl isacoverage basedgreyboxfuzzerwhichseekstomaximizebranch coverage.generatedinputsthatexerciseanewbranch orthesame branch sufficiently more often are added to the seed corpus.
in afl terminology the number of explored paths is actually the number ofseedsinthe seedcorpus.
.
benchmarksandsubjects we chose a wide range of open source projects and real world benchmarks.
together we generated more than four cpu years worthofdatabyfuzzingalmostthreehundreddifferentopensource programs from variousdomains.
oss fuzz 263programs .3mloc 6hours 4repetitions is an open source fuzzing platform developed by google for the large scale continuous fuzzing of security critical software.
at the time of writing oss fuzz featured executable programs in 176open sourceprojects.weselected263programstotaling58.
millionlinesofcodebychoosingsubjectsthatdidnotcrashorreach the saturation point in the first few minutes and that generated morethan1 000executionspersecond.evenforthechosensubjects we noticed that the initial seed corpora provided by the project areoftenforsaturation featurediscoveryhaseffectivelystopped shortly after the beginning of the campaign.
it does not give much room for further discovery.
hence we removed all initial seed corporas.weran libfuzzer forallprogramsfor6hoursand given the large number ofsubjects repeatedeachexperiment 4times.
fts 25programs .0mloc 6hours 20repetitions isastandard set of real world programs used by google to evaluate fuzzer performance.
the subjects are widely used implementations of file parsers protocols and data bases e.g.
libpng openssl and sqlite amongst others.
each subject contains at least one known vulnerability cve some of which require weeks to be found.
the fuzzer testsuite fts allowstocomparethecoverageachievedaswellas thetimetofindthefirstcrashontheprovidedsubjects.whenreporting coverage results we removed those programs where more than of runs crash leaving programs with .2m loc .
as libfuzzer aborts when the first crash is found the coverage results for those subjects would be unreliable.
we set a 8gb memory limitandran libfuzzer for6hours.togainstatisticalpower we repeatedeachexperiment times.
open source programs .1m loc hours repetitions is a set of open source programs from a wide range of domains includinganetworksniffer wireshark andavideoandaudiocodec library ffmpeg .
we ran the default configuration of afl on all programsfor96hours exceptforlibxml2 whereweranaflfor days i.e.
hours.
we repeatedeachexperiment times.
750fuzzing on the exponentialcost of vulnerabilitydiscovery esec fse november8 virtualevent usa .
variablesandmeasures weexploreseveraldefinitionsofspeciesaslistedbelow.wecollect this information from the standard output of libfuzzer and the plot data file of afl.
we vary one indepent variable machines andmeasure six dependent variables.
machines cores hyperthreads isanabstractionofthenumber of inputs the fuzzer can generate per minute.
twice the machinescangeneratetwicetheinputsperminute.conceptually this isstillasinglefuzzingcampaignwhereinputsarestillgenerated sequentially .weassumeabsolutelynosynchronizationoverhead andthatanydiscoveredseed addedtothecorpus is immediately availabletoallothermachines.notethatthisgivesusa lowerbound on the cost of vulnerability discovery our analysis is optimistic.
ifwetook synchronization overheadintoaccount thecostofvulnerability discovery would further increase with the number of physical machines.
datascaling .inordertovarythenumberofavailablemachines we scale our existing data.
for oss fuzz and fts we measured ourdependentvariablesinover3 000fuzzingcampaignsof6 hours.
for open source we measured our dependent variables in campaigns of daysand campaigns of3 months.
again we assume that for each fuzzing campaign twice the machines can generate twicetheinputsperminutewithzerosynchronizationoverhead.
hence we employ a simple scaling strategy we first make sure thattimestartsfromzeroatthebeginningofthefuzzingcampaign.
then givenascalingfactor 2x wedivideeach timestamp by2x.
wemakenoothermodifications.
wemakedataandscriptsavailable here .
vulnerabilities fts .
fts consists of programs each containing a known vulnerability.
for each run of libfuzzer on each program we measure the time needed and number of test cases generated to discover the corresponding vulnerability i.e.
when thefirst crashisreported.from this information we can compute the averagenumber ofvulnerabilitiesfoundat any given time.
crashingcampaigns libfuzzer .whentheprogramcrashes duringfuzzing i.e.
abugisfound thentheentirefuzzingcampaign crashes.thisisthedefaultbehaviorof libfuzzer .fromthetime stampofthecrash wecancomputethetotalnumberofcampaigns that have crashedat any give time.
features libfuzzer .theclassiccoverage feedbackfor libfuzzeris the feature reported as ft .
the llvm documentation explains libfuzzer uses different signals to evaluate the code coverage edge coverage edge counters value profiles indirect caller callee pairs etc.
these signals combined are called features .
edges libfuzzer .
in addition to the number of features libfuzzeralsoreportsthenumberofedgescovered reportedas cov .
the proportionofcovered edges versus thetotal number of edges gives the classic branchcoverage.
seeds afl .
the classic measure of progress for afl is the numberofseedsaddedtothecorpus reportedas paths total .it isoftenreportedasthemeasureoffuzzereffectiveness .however ithasbeenarguedthatthenumberofseedsaddedisstrictly dependentontheorderinwhichtheseedsareadded .hence we also provide the number of branches covered branches as anothermeasure offuzzereffectiveness.
r .
r f .
r e .
crashing campaigns features and edges 80e 002e 054e 056e machines crashing campaigns features covered edges covered figure2 crashes features edges oss fuzz .average number of additional species discovered when fuzzing all programs in oss fuzz simultaneously with libfuzzer for45minutes as afunction ofavailablemachines 4reps .
map coverage afl .
another measure of progress for the aflgreyboxfuzzerismapcoverage reportedas map size .afl receives coverage feedback via a shared memory map.
for each branch that is exercised the coverage instrumentation writes to an indexinthismap.thepercentageindicesthataresetinthismap gives the mapcoverage.
.
setup andinfrastructure allexperimentsfor ftswereconductedonamachinewithintel r xeon r platinum81702.10ghzcpuswith104coresand126gb of main memory.
all experiments for oss fuzz were conducted on amachinewithintel r xeon r cpue5 2699v42.20ghzwitha totalof88coresand504gbofmainmemory.allexperimentsfor open source were conducted on intel r xeon r cpue5 .
ghzwithatotalof40coresand64gbofmainmemory.toensurea fair comparison we always ran all schedules simultaneously same workload eachschedulewasboundtoone hyperthread core and ofcores were left unusedto avoid interference.
empirical results rq1.
numberofadditionalspecies discovered giventhesamenon deterministicfuzzerandtime budget weinvestigate therelationship between thenumber ofavailable machines i.e.
thenumberofinputsgeneratedperminute andthenumber ofadditionalspecies discovered.
presentation .foreachbenchmarkandspecies weshowline plots geom line oftheadditionalnumberofspeciesdiscovered lineary axis asthenumberofavailablemachinesincreases exponential x axis .
with each line plot we show the r2standard measure of goodness of fit for a linear regression lm .
anr2of would mean that the linear regression explains all of the variation andthatallobservationsfallexactlyontheregressionline.
we also show the standard error of a linear regression grey band .
oss fuzz .
the results for running libfuzzer on the almost threehundredprogramsinoss fuzzareshownin figure2.wecan clearly observe linear increase in the number of additional species discoveredasexponentiallymoremachinesbecomeavailable.in fact fittingalinearregressionmodeltothelogarithmofthenumber 751esec fse november8 virtualevent usa marcelb hme andbrandon falk r .
r .
1min campaign 8min campaign machines additional vulns discovered a vulnerabilities fts.average number of additionalvulnerabilities found when fuzzing all25programsin fts simultaneouslywith libfuzzer for or8 mins respectively as the number of available machinesincreases repetitions .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
r f .
r e .
re2 vorbis wpantund libxml2 v2.
.
openssl .
.0c x509 openthread radio harfbuzz .
.
lcms libjpeg turbo boringssl freetype2 guetzli machinesnumber of more features covered coverage features edges b featuresand edges fts.averagenumber of additionalnumber of features edges covered when fuzzing these programs in fts with libfuzzer for minutes as the number of available machinesincreases repetitions .
figure vulns features edges ftsbenchmark.
of machines and the difference in species discovered we observe a very high goodness of fit ofr squared r2 greater than98 .
ontheleftof figure2 wecanseethatthecostofmakingone morefuzzingcampaigncrashbecauseanerrorhasbeenfoundis exponential.
on the right of figure we can see that the cost of covering one more feature or one more edge is also exponential.
it isinterestingtoobservethattheslopesoftheincreasediffer.thisis because the number of features is larger than the number of edges.
fts.theresultsforrunning libfuzzer onthe25programsin oss fuzz are shown in figure .
again we can clearly observe linearincreaseinthenumberofadditionalspeciesdiscoveredasexponentiallymoremachinesareavailable.fittingalinearregression libxml2 machines additional seeds added libxml2 .
.
.
.
.
machines additional map coverage a seedsand map coverage libxml2.averagenumber of additionalseeds added and averagepercentage map covered when fuzzing libxml2 in open source with aflfor 45minsas the number of available machinesincreases reps .
r .
r .
r .
r .
r .
r .
libxml2 openssl wireshark ffmpeg json libjpeg turbo machines additional seeds added r .
r .
r .
r .
r .
r .
libxml2 openssl wireshark ffmpeg json libjpeg turbo .
.
.
.
.
.
.
.000200e 002e 054e .
.
.
.0030e 001e 042e .
.
.
.
machines additional map coverage b seedsand map coverage open source.
averagenumber of additionalseeds added toptworows and averagepercentage map covered bottom tworows when fuzzing allsix programsin the open source benchmarkwith afl for 45minutes as the number of available machinesincreases repetitions .
figure seeds map coverage open source.
modeltothelogarithmofthenumberofmachinesandthedifference in species discovered we observe a very high goodness of fit ofr squared r2 greater than97 exceptfor vorbis .
in terms of the additional number of features covered for the averageprogramintheftsbenchmarkthe r2measureis98.
.in termsoftheadditionalnumberofedgescovered fortheaverage programintheftsbenchmarkthe r2measureis96.
.onlyfor vorbis the r2 measure isbelow95 .
ftsistheonlybenchmarkwherewecancountthenumberof vulnerabilities exposed in a fuzzing campaign of the entire benchmark figure .a .
it is interesting to observe how the number of machinesmustincreaseinordertofindthenextvulnerability.each newvulnerabilityfoundcomes at an exponential cost.
752fuzzing on the exponentialcost of vulnerabilitydiscovery esec fse november8 virtualevent usa opensource .
the results for running afl on the six programs intheopensourcebenchmarkareshownin figure4.intermsof additional seedsadded figure4.b toprows weobservealinear increase as exponentially more machines are available for three out of six programs r2 .
for the remaining three programs an exponential increase in the number of machines cannot even achieve alinearincrease inthe numberofadditionalseedsadded makingitevenmoreexpensive.intermsofadditional mapcoverage figure .b bottom rows we mostly observe a sub linear behavior where adding exponentially more machines cannot even achieve a linearincreaseinthenumberofadditionalseedsadded.forwireshark thereisnodifferencebetweenthemapcoverageachieved byeightmachinesin45minutesandthemapcoverageachievedby machines inthesametime.
however for libxml2we observe an unexpectedincrease.
we investigatedthesuddenincreaseintheadditional mapcoverageachievedinlibxml2bycontinuingthefuzzingcampaigns forthreemonths whichcorrespondstorunningthefuzzeron2880 machinesfor45minutes figure4.a .intermsofboth additional seeds added and additional map coverage we identified two linear phases.
in each phase the goodness of fit of a linear regression modelisr2 .
first empirical law .
our results from over four cpu years worth of fuzzing involving almost three hundred open source programs two state of the art greybox fuzzers four measures of code coverage andtwomeasuresofvulnerabilitydiscoverysuggestthat anon deterministic fuzzerthat generates exponentiallymore inputs per minutediscoversonly linearlymorenew speciesorless.
rq2.
time to discoverthesame species giventhesamenon deterministicfuzzerandtime budget weinvestigate therelationship between thenumber ofavailable machines i.e.
thenumberofinputsgeneratedperminute andthetimeto discover the same number ofspecies.
presentation .suppose whenrunningthefuzzerforsixhours onasinglemachine thefuzzerdiscovers s1manyspecies.weshow line plots geom line of the reduction in time for that fuzzer to discoverthe same numberof species s1 exponential y axis as the number of available machines increases i.e.
the number of inputs that can be generated per minute increases exponential x axis .
figure5onlyshowstheplotsforsomebenchmarks.theotherplots look very similar andprovidenoextrainformation.
results.
the results for running libfuzzer on the almost three hundred programs in oss fuzz and the six programs in fts are shown in figure .
we can see that running libfuzzer on machines instead of one machine reduces the time to make fuzzing campaigns crash from five hours and fifty five minutes 5h55m to under one minute 00h01m fig.
.a left .
similarly runninglibfuzzer on512machinesinsteadofonemachinereduces theaveragetimetoexposethesamevulnerabilitiesinftsfromfive hours and fourty minutes 5h40m to under one minute 00h01m fig.
.a right .
together machines are also sufficient to achieve thesamecoverageinunderoneminuteasonemachineachievesin sixhours fig.
.b .thisisreasonable if libfuzzer cangenerate 512timesmoreinputsperminute then libfuzzer canmakethe same progressin1 thofthe time.oss fuzz benchmark vulnerabilities sec1 min1 hour6 hours machinestime to expose same vulnsfts benchmark vulnerabilities sec1 min1 hour6 hours machinestime to expose same vulns a time to expose the same number of vulnerabilities in oss fuzz left and the same number of crashing campaigns in fts right as a singlemachinein six hours if exponentially moremachineswereavailable.
re2 vorbis wpantund 27libxml2 v2.
.
openssl .
.0c x509 openthread radioharfbuzz .
.
lcms libjpeg turbo 2017boringssl freetype2 guetzli sec1 min1 hr6 hours sec1 min1 hr6 hours sec1 min1 hr6 hours sec1 min1 hr6 hours1 sec1 min1 hr6 hours sec1 min1 hr6 hours sec1 min1 hr6 hours sec1 min1 hr6 hours1 sec1 min1 hr6 hours sec1 min1 hr6 hours sec1 min1 hr6 hours sec1 min1 hr6 hours machinestime to achieve same coverage b time to achievethe same coverageas running the fuzzerona singlemachinefor six hours if the fuzzerwould run onexponentially moremachines.
figure5 vulns features ftsand crashes oss fuzz.
second empirical law .
ourresultssuggest that anon deterministic fuzzer thatgeneratesexponentially moreinputs perminute discoversthesamenumber ofspeciesalsoexponentially faster.
rq3.
probabilityto discovergivenspecies giventhesamenon deterministicfuzzerandtime budget weinvestigate therelationship between thenumber ofavailable machines i.e.
thenumberofinputsgeneratedperminute andtheprobability to discover agiven setof species.
presentation .
we estimate the probability of an event to occur inagiven time budget and for agiven number of machines as the proportion of runs where the event occurs in the given time budget forthegivennumberofmachines.forinstance if75 ofrunshave discovered a given vulnerability in the given time budget using sixteen machines then the probability to discoverthe vulnerability within the time budget using sixteen machines is .
we show lineplots geom line oftheprobabilitythatthefuzzerdiscovers a given set of species lineary axis as the number of available machinesincreases i.e.
thenumberofinputsthatcanbegenerated per minuteincreases exponential x axis .
results.
the results for the probability to discover a vulnerability in the fts benchmark by running libfuzzer for up to six hours are shown in figure .
our first observation is that the plots haveaverysimilarshapetothatin figure8.leftwhichshowsthe result of our probabilistic analysis of the third empirical law for non deterministic blackbox fuzzers.
for the bottom three rows the probability remains close to zero at the beginning increases at an 753esec fse november8 virtualevent usa marcelb hme andbrandon falk pcre2 .
proj4 woff2 06llvm libcxxabi openssl .
.2d openssl .
.0c bignumlibpng .
.
libssh libxml2 v2.
.2c ares cve harfbuzz .
.
lcms machinesprobability to discover the vulnerability figure probability that the vulnerability has been discovered in twenty seconds given the available number of machines solidline .averagenumberofmachinesrequiredto find thevulnerabilityintwentyseconds dashed line .
ever faster rate until it reaches the dashed line i.e.
the average machineswherethevulnerabilityisdiscovered slowsdownagain untilitreachesalmostone andthenremainsclosetooneforthe remainder.
in fact the discovery probability curve appears to be very similar to asigmoid curve.
our second observation is that for different vulnerabilities often a different average number of machines are required to expect vulnerabilitydiscovery dashedline .theharfbuzzandlcmsvulnerabilities are never discovered while the c ares vulnerability has beendiscoveredinalltwentyrunsinundertwentysecondsalready on a single machine top row .
we confirmed that adding up the individual discovery probabilities yields a linear increase in the number of vulnerabilities discoveredwith an exponential increase inthe number ofavailable machines cf.
figure .a figure .
the resultsfor theprobability tocoveratleasta givennumber offeatures s inthe ftsbenchmark byrunning libfuzzer for up tosixhoursareshownin figure7.wefixed s arbitrarilyashalf thenumberoffeaturesthat libfuzzer coversononemachinein six hours.
this value of s allows us to actually observe a transition from probability zero to one for most of the subjects.
again wemakethesameobservations.mostimportantly theplotslook similartothesigmoidshapethatwehaveseenforoursimulation results in figure .left.
third empirical law .
our results suggest that for a nondeterministic fuzzer that generates exponentially more inputs per minute the probability of discovering a given set of species seems to increase exponentially until discovery is expected whence the rate of increase slows down and thecurveapproachesprobability one.s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s 1639s s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s 3051s s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s 5889s s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 5760s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s 7588s s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s 960s s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s 1539s s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 700s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s 1009s s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s 680s s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s 1828s s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430s 7430re2 vorbis wpantund 27libxml2 v2.
.
openssl .
.0c x509 openthread radioharfbuzz .
.
lcms libjpeg turbo 2017boringssl freetype2 guetzli machinesprobability to cover at least s features figure probability that at least s features are covered in twenty seconds given the available number of machines solidline where s ishalfthenumberoffeaturesthat libfuzzercan cover in six hours on one machine on average.
we also show the average number of machines needed to discoveratleast s featuresintwentyseconds dashedline .
probabilistic analysis .
probabilisticmodel offuzzing wemakeanattemptatexplainingourempiricalobservationsby probabilisticallymodellingthefuzzingprocess.startingfromthis model we conduct simulation experiments that generate graphs thatturnoutquitesimilartothoseweobserveempirically.since the underlying probabilistic model is straightforward for blackbox fuzzers we focus only on the blackbox fuzzing process .
nevertheless we hope that our probabilistic analysis sheds some light on our empiricalobservationsforgreyboxfuzzingandonthescalabilityof non deterministic fuzzingin general why is it expensive to cover newcode but cheap to cover the same code faster?
weborrowthestadsprobabilisticmodeloffuzzingfromb hme .anon deterministicfuzzer generatesprograminputsbysamplingwithreplacementfromtheprogram sinputspace.let pbe theprogramthatwewishtofuzz.wecallas p sinputspace dddthe setofallinputsthat pcan take.fuzzing pisastochasticprocess f xn xn ddd n n ofsampling ninputswithreplacement fromtheprogram sinput space.wecall fasfuzzingcampaign andatoolthatperforms f asnon deterministicblackboxfuzzer .suppose wecansubdividethe input space dddintosindividual subdomains di s i 1calledspecies.
754fuzzing on the exponentialcost of vulnerabilitydiscovery esec fse november8 virtualevent usa .
.
.
.
.
.
machinesdiscovery probability machinesdiscovery probability log scale figure probability qexp x s 2xn to discover a given species within a given time budget as the number of machinesincreasesexponentially solidline .wealsoshowthe inflectionpoint x0ofqexp x greylines andanexponential curve dashedline thatintersects qexp x atx 0andx x0 andthatstartsoutwiththesameslopeas qexp x atx 0but grows slower than qexp x in the interval x .
we let theprobability qthatthespecieshas notbeendiscoveredon one machine x within the time budget be q and the exponential be abx cwherea .
b .
andc .
.
aninputxn fis said to discoverspeciesdiifxn diand theredoesnotexistapreviouslysampledinput xm fsuchthat m nandxm di i.e.
diis sampled for the first time .
an input s species is defined based on the dynamic program properties thatareusedastheevaluationcriteriaofthefuzzer.forinstance each branch that is exercised by input xn dddcan be identified as a species.
the discovery of the new species i.e.
branch then correspondsto an increaseinbranchcoverage.
we letpi p be the probability that xnbelongs to difori i sandt n n. the expected number of speciess n discoveredbyanon deterministic blackbox fuzzeris s n s summationdisplay.
i bracketleftbig pi n bracketrightbig s s summationdisplay.
i pi n. intuitively we can understand a non deterministic blackbox fuzzer as sampling with replacement from an urn with colored balls whereeachballcanhaveoneormoreof scolors.thespecies discoverycurve s n representsthenumberofcolorsthatweexpect todiscoverwhen sampling nballs.here a ballis aninputwhile a ball scolorsare the input s species.
fuzzing approaches .
we can distinguish a generation based and a mutation based approach .
ageneration based fuzzer generates random inputs from scratch.
a mutation based fuzzer generatesrandominputsbymodifyingexistinginputsinagiven seed corpus.
a mutation based fuzzer is non deterministic as it chooses the seed to fuzz the location in the chosen seed to mutate andthemutationoperatorstoapplyatthechosenlocationsallat random.a greyboxfuzzer isamutation basedfuzzerthataddstothe corpus generatedinputsthat increasecoverage.
a grammar guided generation based fuzzer can generate program inputs that are valid w.r.t.
a given grammar by random sampling from that grammar .
agrammar guided mutation based fuzzer can generate valid inputsbyparsingaseedasparsetree randomlymutatingtheparse tree andre constituting the modifiedtree .machinesandtimebudget .
we explore two related problems andshowthat undersimplifyingassumptions theyrepresentthe same case.
firstly we explore how the number of species discovered within a fixed time budget increases as the number of machines increases.fromequation weknowthatthenumberofspecies s n weexpectanon deterministicblackboxfuzzertodiscoverafter generating ninputsisthetotalnumberofspeciesminusthesum for each species iof the expected probability that ihasnotbeen discoveredaftergenerating ninputs.with2xtimesmoremachines we can generate 2xtimes more inputsper minute i.e.
s s summationdisplay.
i parenleftbig pi 2x parenrightbign s s summationdisplay.
i pi 2xn s 2xn so givenatimebudget suchthatthefuzzerrunningononemachinecangenerateexactly ntestinputs if2xtimesmoremachines were available s 2xn s n more species wouldbe discovered.
secondly weexplore howthenumberofspeciesdiscoveredona single machine increases as the available time budget increases .
if the non deterministic fuzzer generated 2xmore test inputs on the same machine s 2xn s n more species wouldbe discovered.
.
probabilityto discoveragivenspecies ourfirstempiricalobservationisthatanon deterministicfuzzer that generates exponentially more inputs per minute discovers only linearly more new species or less .
let us begin with an investigationofthespecialcasewhere weassumethatonlyasingle interesting species exists s .
how does the probability to discoverthisspeciesincreasewithinagiventimebudgetasthenumber ofmachines i.e.
inputsperminute increases?weinvestigated thisquestionempiricallyin section3.rq3andourobservationsfor this specialcaseare counterintuitive.
wesuggestthatanon deterministicfuzzerthatgeneratesexponentiallymoreinputsperminutealsodiscoversaspecificspecies withaprobability that is exponentially higher up to somelimit.
inotherwords theprobabilitytofindaspecificspecieswithin agiventimeincreasesapproximatelylinearlywiththenumberof machines uptosomelimit .weconductaprobabilisticanalysisfor the special case where the fuzzer is blackbox i.e.
for each species throughout the campaign the fuzzer has the same probability to generate an input that belongs to that species.
we also identify exactly where this limit is.
infigure8 weseeanexampleoftherelationshipbetweenthe probabilitytodiscoverthespeciesandanexponentialincreasein the number of available machines solid line .
we also show the inflectionpoint x0wherethegrowthstartstodecelerate greylines andanexponentialfunctionthatintersectsthediscoverprobability curveatx x0 startswiththesamerateofgrowth slope at x and lower bounds the species discovery curve within the intervalx dashedline .
given aspecific species letpbe the probability that the fuzzer generates an input that discovers the species.
we compute the expectedprobability q n thatthefuzzerhasdiscoveredthespecies as the complement of the probability that the species has not been discoveredusing ngeneratedtest inputs q n p n. 755esec fse november8 virtualevent usa marcelb hme andbrandon falk slowergrowing exponential t x abx c q a b c .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
figure examples of exponential functions t x abx c that grow slowerin the interval x than the probabilityqexp x ofdiscoveringaspecificspecieswithinagiven time budget if 2xmore machines were available where t x intersects qexp x atx x0 and starts with the same slope at thebeginningoftheinterval.
beforeweshowthatthediscoveryprobabilityincreasesexponentially up to a certain limit as the number of machines increases exponentially wewillfirstidentifymoreformallywherethis limit is.
clearly the discovery probability cannot be larger than one.
so theremustbeaninflectionpoint.an inflectionpoint isapointof the curve where the curvature changes its sign.
for brevity we definetwoquantities qexp x andqas follows q p nsincepandnare constants qexp x q2x whereqis the probability that runningthe fuzzer on one machine withinatimebudgetthatallowstogenerate ntestinputs hasnot discoveredthespecies andwhere qexp x givestheprobabilitythat running the fuzzer on 2xmachines within the same time budget hasdiscoveredthe species.
inflectionpoint .tofindtheinflectionpoint wesetthesecond derivative of qexp x to 0andsolve for xto findx0.
x0 log2 parenleftbigg log q parenrightbigg wherex0 0ife q .
notethattheexpectedprobabilitythatthespecieshasbeendiscoveredat this inflection pointis qexp x0 e .
we can demonstrate that qexp x grows exponentially in the intervalx by showing that for all q e q 1and x x x0 there exists a b andc such that the exponential functiont x abx cintersectswith qexp x atx x0 that the slopes of t x andqexp x are equal at x i.e.
x t x qexp x 0atx and that qexp x t x 0for0 x x0 i.e.
there isnothirdintersection inthe interval .
figure9showsthevaluesfor a b andcthatsatisfytheseconstraintsforsomeinterestingprobabilities qthatthespecieshasnot been discoveredwithin the given time budget onone machine.
giventheprobability qthatanon deterministicblackboxfuzzer hasnotdiscovered a given species within a given time budget an attackerthatrunsthesamefuzzerinthesametimebudgeton 2xtimes more machines such that x has a probability qexp x of discovering the species where qexp x growsfasterthan an exponential whichintersects qexp x atthebeginningandend oftheintervaland starts withthesameslope.for non deterministic blackbox fuzzers an example is shown in figure .
recall that q p n wherepis the probability thatthenon deterministicfuzzergeneratesaninputthatbelongs tothatspeciesand nisthenumberoftestinputsthatcanbegenerated within the given time budget on one machine.
while the probabalisticresultsarederivedfromamodelforblackboxfuzzing they explain the empirical evidence for the two greybox fuzzers in section3.rq3.thegraphsgeneratedfromourprobabilisticanalysis infigure .left and as a result of our empirical analysis in figure and7are almostidentical.
intuition consequences .intuitively ifyoubuytwo four or eight lottery tickets instead of one also increases your chance of drawing a winning ticket by a factor of two four or eight.
rolling sixdicesimultaneouslyinstead ofone increasesthechance to roll at least one six by a factor of four.
so what does that mean for our empirical observation that the cost of discovering the next unknownvulnerabilityincreasesexponentially?
foranon deterministicblackboxfuzzer theprobabilityof exposingaspecific knownvulnerability reachinga specific program statement violating a specificprogram assertion or observing a specificevent of interest i.e .
species within a given time budget increases approximately linearly with the number ofavailable machines upto acertainlimit.
the same observation holds even if our objective is to discoverallspecies in a given set of species.
on the average the most difficult species to discover is that which has the highestprobability qmaxnottobediscoveredaftergeneratingntest inputs.
by setting q qmax we can reduce the problem of discovering allspecies in a given set to exposing a specific species.
from the second law we also know that the time spent finding the same number of species is inversely proportional to the number of available machines.
the same observation holds even for the discovery of the nextunknownvulnerability ifweassume thatthereexists onlyasingleunknownvulnerability or ifweassumethatall unknown vulnerabilitieshave exactlythesame probability qi snottobediscoveredwithinthegiventimebudget onone machine i.e.
qi qi sfori i s. .
explaining thefirst empirical law giventheinsightsfromtheprevioussection whydoourempirical observationssuggestanexponentialcostforthediscoveryofthe nextunknown vulnerability ourfirstlaw ?fromtheexponential behaviorofofthediscoveryprobabilitycurve qiexp x foraspecies i we canderive thatdiscoveryprobability iseither approximately zero or approximately one with an almost linear transition at around x log2 qi when discovery is expected.
figure .left illustrates this behaviornicely.
thenumberofspecies s 2xn discoveredif 2xmoremachines were available isthe sum of the individual discoveryprobabilities s 2xn summationtext.1s i 1qiexp x .
without making any additional assumptionsaboutthetotalnumber sofspeciesortheprobabilities qi s i we mostly observe the effects of the almost linear transitions of the individual discovery probabilities qiexp x as they contribute to the total number of discovered species s 2xn .
this additive 756fuzzing on the exponentialcost of vulnerabilitydiscovery esec fse november8 virtualevent usa total species total species total species total species .
.
.
.
.
machines more species discovered figure10 numberofadditionalspeciesdiscovered s 2xn s n asthenumberofavailablemachinesincreasesexponentially s random samples of qi s i 1each .
we recognize the exponential increase for a single species on the left andthelinear increase for1000 species on theright.
acummulation of the individual curves for each species explains ourempiricalobservationofalinearincreaseinthenumberofnew species discovered within the same time budget and as 2xmore machines are available.
simulation .weexplorethis explanationinseveralsimulation experiments.wevarythethetotalnumberofspecies sandassume apower lawdistribution2overtheprobabilities qi s i .specifically for each species iwe sample a random floating point value xi uniformlyfromtheinterval andsettheprobability qithat ihasnotbeendiscoveredaftergenerating ninputs i.e.
x as qi xi.in otherwords themostabundantspeciesis about twice as likely to be discovered as the next most abundant species and so on.
we let the total number of species s and for each value of srepeat the sampling of qi s i 1five times.
thesimulationshouldbynomeansbeconsideredaproofofour firstempiricallaw butratherasanexplorationorasanexplanation.
forthereadertotryoutotherdistributions wemakeourscripts available here .
results.
the simulation results for a non deterministic blackboxfuzzer are shown in figure .
itdepicts the additional number of species found as 2xtimes more machines are available to an exponentially more powerful attacker i.e.
the attacker can generate 2xmore inputs per minute .
on the left we can recognize the exponential species discovery curve qexp x from the third empirical law cf.
fig.
.
if we assume that only a single species exists exponentially more machines will discover this species also exponentiallyfaster.ontheright wecanseethelineardiscovery curve which is the subject of our first law.
if we assume that a thousand species exist exponentially more machines will increase the number of additional species discovered only linearly.
the two charts in betweenfor s illustrate how theexponential curvesfromtheindividualspeciesadditivelyaccumulatetoform anapproximatelylinearcurvefortheadditionalspeciesdiscovered.
fortwonon deterministicgreyboxfuzzers weprovideempirical evidenceinfavorofthe firstempirical law in section .rq1.
ifweassume thatthereisjustoneundiscoveredspecies anondeterministicfuzzerthatgeneratesexponentiallymoreinputsper 1wepresented ourempirical observationsin section3.
2wealsoexploredthe unrealistic assumption of a uniform distribution over qi s i i.e.
to sample qiuniformly from the interval .
it is unrealistic because we wouldotherwise expectdiscovery of most specieswithonly 10x moremachines.we conductedsimulationexperimentsandobserveda sub linear increaseinthenumberof more species discovered as the number of available machines increases exponentially.minutealsodiscoversaspecificspecieswithaprobabilitythatis exponentiallyhigher up to some limit section4.
.
however we cannot assume to know the total number of species in advance.
we cannotassumethere isonly one species left undiscovered.
withoutmakingassumptionsonthenumberofspecies ifspecies probabilitiesaredistributedaccordingtothepowerlaw wesuggest that a non deterministic fuzzer that generates exponentially more inputsper minutediscoversonly linearlymore new species orless .
wecallthisobservationanempiricallawbecauseitiscontingent on the fact that species are distributed roughly according to the power law.
in the special cases where a all species are equally likely pi sfor alli i s or b there exists just one species s this law does not hold.
however from our empirical observations in section .rq1 we can derive that the speciesmeasured inour dependentvariables e.g.
vulnerabilities are indeed distributed according to the power law.
the plots for ourempiricalobservations figure2 4 lookverysimulartoour plots for our simulation results figure .right .
apower law distribution gives a very high probability to a small numberofeventsandaverylowprobabilitytoaverylargenumber ofevents.the80 20paretoprincipleisanexample.forus there are very few extremely abundant species but a large number of extremelyrarespecies.inoursimulation thesecondmostabundant species isonly halfas likely as the mostabundant andsoon.
intuition .
when collecting baseball cards the first couple of cards are always easy to find but adding a new card to your collection will get progressively more difficult even if all baseball cards were equally likely.
this is related to the coupon collector s problem.similarly ourfirstlawsuggeststhatcoveringonemore branch or discovering one more bug will get progressively more difficult so difficult in fact that each new branch covered and eachnewvulnerabilityexposedcomes at an exponential cost.
.
explaining thesecondempirical law while our first empirical law implies that it is expensive to cover newcode thesecondlawimpliesthatitis cheaptocoverthesame code.
similarly it is expensive to find an unknown vulnerability but cheap to find the same known vulnerabilities.
suppose for a non deterministicblackboxfuzzer intheoriginalsetuponeinputis generated per minute while in the exponential setup 2xinputs are generatedperminute.giventheoriginaltime n weneedtofindthe 757esec fse november8 virtualevent usa marcelb hme andbrandon falk sec1 min1 hr1 day1 week1 mth1 year machinestime to achieve same coverage figure second law .
we observe an exponential decrease in the time spent to discover the same number of species with an exponential increase in available machines i.e.
in thenumberoftestcasesthat can be generated perminute .
timem suchthatthenumberofspeciesfoundintheexponential setup inmunits of time is equivalent to the number of species foundinthe originalsetupin nunitsoftime s s summationdisplay.
i parenleftbig pi parenrightbign s s summationdisplay.
i parenleftbig pi 2x parenrightbigm whichistrue when we have that m n 2x foranon deterministic blackboxfuzzer figure illustrates the thirdempiricallawwheretheoriginalsetupspendsoneyear.for two non deterministic greybox fuzzers we provided empirical evidenceinfavorofthe secondempirical law in section .rq2.
wesuggestthatanon deterministicfuzzerthatgeneratesexponentially more inputs per minute discovers the same number of species also exponentially faster.
more specifically we suggest that thetimetofind thesame numberofspeciesisinverselyproportional to thenumber ofmachines.
related work fuzzingisafast growingresearchtopicwithmostrecentadvances incoverage guidedfuzzing whichseekstomaximizecoverageof the code.
the insight is that a seed corpus that does not exercise a program element ewill also not be able to discover a vulnerability observablein e.coverage guidedgreyboxfuzzers uselightweightinstrumentationtocollectcoverage information duringruntime.foracomprehensiveoverview werefertoarecent survey .
coverage guided whitebox fuzzers use symbolicexecutionto increase coverage.
for instance klee has a search strategytopriotizepathswhichareclosertouncoveredbasicblocks.
the combination and integration of both approaches have been explored as well .
in this paper we focus only on nondeterministic fuzzers.
non deterministic fuzzers generate program inputs in random fashionwithouteverexhaustingthesetofinputsthatcanbegenerated.
in contrast to deterministic fuzzers there is no enumeration of finite determined set of inputs or of program properties like paths .
a non deterministic generation based fuzzergeneratesnew inputs by sampling from a random distribution over the program sexponential cost machines covered branches blackbox greybox global queue greybox local queue linear cost 2561e 021e 031e 041e machinestime to achieve same coverage blackbox greybox global queue greybox local queue figure each new branch covered requires exponentially more machines left .
yet exponentially more machines allowtocoverthesamebranchesexponentiallyfaster right .
input space.3for instance a random input file can be generated by sampling a random number nof utf characters c1 ... cn whereci .
anon deterministic mutation based fuzzer generatesinputs by randommodificationsofa seedinput.
the fuzzer chooses a random set of mutation operators to apply at random locations in theseed input.in this paper we conduct anempirical analysis for two non deterministic greybox fuzzers and provide aprobabilisticanalysisfornon deterministicblackboxfuzzingin order to shedsomelight onour observations.
deterministicfuzzers enumerateafinitenumberofobjectsand then terminate.
for instance a symbolic execution based whitebox fuzzer enumerates interesting paths.itmightnotenumerate allpaths butideally itwouldnevergenerateasecondinputexercisingthesamepath.
adeterministicmutation basedfuzzer enumerates a determined set of mutation operators and applies them to a determined set of locations in the seed input.
greybox fuzzerssuchasaflmayfirstfuzzeachseeddeterminsticallybefore switchingtoanon deterministicphase.
inthelimit such hybrid greybox fuzzersare stillprimarilynon deterministic.
probabilistic analysis .
arcuri et al.
analyzed the scalability of search based software testing and show that random testing scales better in the number of targets than a directed testing technique thatfocusesononetargetuntilitis covered beforeproceeding to the next.
b hme and paul argue that even the most effective techniqueislessefficientthanblackboxfuzzingifthetimespent generatingatestcasetakesrelativelytoolongandprovideprobabilistic bounds.
majumdar and niksic discuss the efficiency of random testing for distributed and concurrent systems.
to the best ofourknowledge oursisthefirstworktoinvestigatethescalability offuzzingacrossmachinesandthecostofvulnerabilitydiscovery.
discussion our first empirical law suggests that using a non deterministic fuzzer a giventhesametimebudget eachnewvulnerabilityrequiresexponentiallymoremachinesand b giventhesamenumber ofmachines eachnewvulnerabilityrequiresexponentiallymore time.intuitively when collecting baseball cards the first couple of cards are easy to find but collecting the next new card gets progressivelymore difficult.
3itispossible of course that thereis zeroprobabilityweightover some inputs.
758fuzzing on the exponentialcost of vulnerabilitydiscovery esec fse november8 virtualevent usa our second empirical law suggests that a non deterministic fuzzer which generates exponentially more machines discovers the same vulnerabilities also exponentially faster.
this means that findingthesamevulnerabilitiesinhalfthetimerequiresonlytwice as many machines.
intuitively if each day you would bought twice asmanypacksofbaseballcards youcouldhavecollectedthesame cardsthat you have nowinhalfthe time.
inourempiricalanalysis wemakethesimplifyingassumption that there is no synchronization overhead .twice themachines can generatetwicetheinputsperminute.conceptually thisisstilla single fuzzing campaign where inputs are still generated sequentially.
any discovered seed added to the corpus is immediately available to allothermachines.
our analysisisoptimistic.
open science and reproducibility .
we derive our empirical laws from the data that has been available to us and call upon the communitytotestthemforotherfuzzingtools otherdefinitions of species e.g.
mutants killed other programming languages and so on.
to facilitate this extended investigation we provide all data andscriptstoreproduceourempiricalevaluation oursimulation andallfigures inthis paper at .
impactofsynchronization overhead weconductedpreliminaryexperimentstoinvestigatetheimpactof this simplifying assumption.
we ran xfuzzing campaigns simultaneouslyon xmachinesinthefollowingthreesettings a blackbox fuzzers b greybox fuzzers each with a local seed corpus and c greyboxfuzzersallsharingaglobalseedcorpus.thelastsetting corresponds to our simplifying assumption.
for each setting we measuredtheincreaseincoverageover allsimultaneouscampaigns.
figure12 showsthetremendousimpactofsharingaglobalqueue amonggreyboxfuzzersandmakingseedsfoundimmediatelyavailable to all other fuzzing campaigns.
running greybox fuzzers in parallelwithoutsharing a global queue does not scale much betterthanrunning blackbox fuzzersinparallel.without efficient sharingofinformation acrossmachines thecostofcoveringeach newbranchis still linear but the slope ofthe lineismuchsmaller.
.
implications in practice wereachedouttosecurityresearchersandpractitioners ontwitter to understand the practical implications of our findings.
in the following we summarize the discussion.
coolpaper!asomewhatrelatedthoughtthatcomestomind to find new bugs faster one would need to make a better fuzzer insteadoftrying to scaleupexistingones.
andrey konovalov andreyknvl i think there is something else though the difficulty of individual bugs coverage are not fixed.
better mutators and feedback can reduce the cost by orders of magnitude think a grammar fuzzer finds morecoverage withafractionofthecompute .
cornelius aschermann is eqv the results show that only throwing more cpu power at fuzzing is not the way to go.
in a similar vein to what is eqv said we ll bebetteroffoptimizingtheprocess seedselectionpolicy structureaware mutations new feedback signals and combining it with othertechniques.
khaledyakdan khaledyakdan fuzzing smarter .wecannotsimplythrowmoremachinesat vulnerability discovery when we stop finding vulnerabilities.
instead weneedtodevelopsmarterandmoreefficientfuzzers.similar tocompoundinterest i.e.
exponentialgrowth eventhesmallest increaseindiscoveryprobabilityprovidestremendousperformance gainsinthelongrun.evensmallperformancegainsononemachine has tremendousbenefitswhen scalingto multiple machines.
this probably also means that just fuzzing everything a little is pretty lucrativeto findthe low hanging fruit.
henk poley henkpoley fuzzing in ci cd .
fuzzing everything for just a little bit we canalreadycoveralotofground.inanunfuzzedtarget themajority ofvulnerabilitiesisfoundwithrelativelyfewresources.
love the last paragraph!
our results suggest to compare fuzzers intermsoftimetodiscoverthesamebug s orthetimetoachieve thesamecoverage.
chengyusong laosong fuzzingevaluation .
our results suggest to compare fuzzers in termsofthetimetodiscoverthesamebug s orthetimetoachieve thesamecoverage.reportingtheincreaseincoveragewithinthe sametimebudgetmaybemisleadingsinceevenasmallincrease comes at an exponential costinterms of time ormachines.