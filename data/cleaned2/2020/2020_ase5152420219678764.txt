deepmetis augmenting a deep learning test set to increase its mutation score vincenzo riccio nargiz humbatova gunel jahangirova and paolo tonella universit a della svizzera italiana lugano switzerland email name.surname usi.ch abstract deep learning dl components are routinely integrated into software systems that need to perform complex tasks such as image or natural language processing.
the adequacyof the test data used to test such systems can be assessed bytheir ability to expose artificially injected faults mutations thatsimulate real dl faults.
in this paper we describe an approach to automatically generate new test inputs that can be used to augment theexisting test set so that its capability to detect dl mutationsincreases.
our tool d eep metis implements a search based input generation strategy.
to account for the non determinism of thetraining and the mutation processes our fitness function involvesmultiple instances of the dl model under test.
experimentalresults show that d eep metis is effective at augmenting the given test set increasing its capability to detect mutants by onaverage.
a leave one out experiment shows that the augmentedtest set is capable of exposing unseen mutants which simulatethe occurrence of yet undetected faults.
index t erms deep learning mutation testing search based software engineering i. i ntroduction deep learning dl based software is widespread and has been successfully applied to complex tasks such as image processing and speech recognition.
systems including dlcomponents are also employed in safety and business criticaldomains e.g.
autonomous driving and financial trading.
dlsystems possess the human like ability to learn how to performa task from experience i.e.
the inputs seen during training but such ability comes with the possibility to make errorswhen presented with new inputs.
therefore it is crucial for dlsoftware developers and manufacturers to assess to what extentthese systems can be trusted in response to real world inputs as they could face scenarios that might be not sufficientlyrepresented in the data from which they have learned.
traditional test adequacy criteria like code coverage fail to determine whether dl systems are adequately exercised by atest set since most of the dl systems behaviour depends ontheir training data not the code.
recent research defined ad hoc white box adequacy metrics based on dl software s inter nal architecture e.g.
neuron or surprise coverage .a limitation of these approaches is that their output cannot bedirectly associated with a root cause of a dl system s failure i.e.
a dl fault .
on the other hand mutation testing approaches evaluate a test set against faults that are artificially injected into thesystem under test.
so the inability of a test set to exposeinjected faults kill mutants in the mutation testing jargon can be interpreted as its inability to properly exercise themutated code .
the tool deepcrime generates mutants of dl systems by injecting artificial faults that resemble thosedescribed in the taxonomy of real dl faults by humbatova etal.
.
in this way it addresses the challenge of simulatingreal world dl faults .
hence a dl test set that cannot killa mutant generated by deepcrime is also unlikely to expose any real fault similar to the one injected by deepcrime i n case such a fault affected the dl system under test.
in sucha situation the test set should be augmented with additionaltests that target the undetected fault.
in this paper we introduce a novel and automated way to augment existing test sets with inputs that kill mutantsgenerated by deepcrime.
our goal is to increase the mutation score of a test set by generating new inputs that kill themutants not killed by the original test set.
to this aim wepropose d eepmetis a search based test generator for dl systems that uses mutation adequacy as guidance.
intuitively a mutant is killed if the correct behaviour is observed for adl model under test while a misbehaviour is observed on itsmutated version.
however mutation testing approaches shouldtake into account the stochastic nature of dl in particular of its training process and of mutation generation somedl mutations are non deterministic to properly measure thetest set s ability to discriminate the original system from theartificially generated faulty versions .
in fact observing adrop in accuracy between the original and the mutated modelis not enough to conclude that the mutant is killed sincesuch a drop might be due to random fluctuations of accuracyassociated with the non determinism of the training and themutation process.
the mutation killing criterion proposed byjahangirova and tonella addresses this dl specific chal lenge by evaluating a test set on multiple re trained instancesof the same model and applying statistical tests.
d eepmetis adopts the same non deterministic view on dl systems andcorrespondingly its generation process is guided by multipleinstances of the model being mutated.
recently dl specific mutation operators have been used for different tasks such as program repair adversarialinputs detection generation of adversarial code snip pets and calculation of optimal oracles for autonomousvehicles but no approach leveraged them to generate newinputs which augment an inadequate test set.
36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee we evaluated d eepmetis on both a classification problem and a regression problem using mutation operators provided bydeepcrime.
results show that d eepmetis is effective at generating inputs that improve a test set in terms of itsmutation killing ability.
we also conducted a leave one outexperiment to simulate a practical usage scenario where anundetected fault affecting the dl system is unknown.
in thisexperiment setting one mutant produced by deepcrime is taken apart while test augmentation is performed by d eepmetis based only on the remaining mutants.
in this way the left out mutants simulate a yet unknown fault.
results showthat left out mutants can be killed by the augmented test seton average of the time.
ii.
b ackground a. mutation testing of dl systems mutation testing is a technique that injects artificial faults into a system under test guided by the assumption that theability to expose such artificial faults translates into the abilityto expose also real faults.
in traditional software systems themain decision logic of a program is implemented in its sourcecode and synthetic faults are introduced by applying smallsyntactic changes to the source code.
in contrast the behaviourof a dl system is determined not only by the source code butalso by its training data the structure of its neural networksor the tuning of various hyperparameters.
as syntactic codechanges are not sufficient to achieve realistic fault injection dl mutation operators have a different nature .
deepmutation and munn were the first works to recognise the need for mutation operators tailored specificallyto dl systems.
in deepmutation later extended into a toolcalled deepmutation the authors propose a set of operators of two distinct categories source level and model level operators.
source level operators apply changes to training data or model structure before training is performed whilemodel level operators alter weights biases or the structureof an already trained model.
model level mutation operatorstend to be less costly as unlike source level operators they donot require re training.
mutation operators proposed in munn solely belong to the latter category.
jahangirova tonella performed an extensive empirical evaluation of the mutation operators proposed in deepmu tation and munn and investigated the configuration spaceof their parameters.
for example for a mutation operator thatimitates training with corrupted data by changing the labelsof training inputs to incorrect ones the parameter would bethe percentage of mutated labels.
according to their results the choice of the parameter values affects the impact of themutation to a major extent.
moreover the authors propose a novel mutation killing criterion which takes into account the stochastic nature of dlsystems.
their definition requires multiple re trainings of boththe original program and the mutant to obtain ndistinct model instances of each n in their experiments .
then they measure whether the difference between accuracies or anyother quality metrics obtained on original vs mutated modeltable i mutation operators provided by deepcrime and not killed by the initial test sets of our case studies group mutation operator mutation parameters training datachange labels of training data tcl label to perform the mutation on percentage of data to mutate remove portion of training data trd percentage of data to delete unbalance training data tud percentage of data to remove add noise to training data tan percentage of data to mutate make output classes overlap tco percentage of data to mutate hyperparamsdecrease learning rate hlr new learning rate value change number of epochs hne new number of training epochs activationchange activation function ach layer w non linear activ.
function new activation function remove activation function arm layer w non linear activ.
function add activation function to layer aal layer w linear activation function new activation function regularisation add weights regularisation raw layer w o weights regularisation new weights regulariser weights change weights initialisation wci layer to perform the mutation on new weights initialiser optimisation change optimisation function och new optimisation function instances is statistically significant p value .
and whether the effect size is not negligible .
if these conditionshold the mutation is considered killed.
b. deepcrime deepcrime is a mutation testing tool designed for automated seeding of artificial faults mutations into dl systems.its main difference from deepmutation is that deepcrime is based on a set of mutation operators derived from real faults.i ndeepcrime the authors propose and implement 24source level mutation operators that target different aspects of the development and training of dl systems.
this set ofoperators was extracted from an existing taxonomy of realfaults in deep learning systems and was complementedwith the issues found in the replication packages for the studiesby islam et al.
and zhang et al.
.
to establish whethera mutation is killed or not deepcrime incorporates the notion of statistical killing proposed by jahangirova tonella using by default re trainings for the original model and foreach of the applied mutations.
the mutation operators in deepcrime have two types of parameters continuous and non continuous.
for example theoperator that removes part of the training data has the con tinuous parameter percentage which decides what portion of inputs should be deleted.
its value varies in the range to as we cannot delete all training data .
in contrast mutation operators that operate on a per layer basis have anon continuous parameter layer which determines the specific layer of a neural network to mutate.
in case the parameter values are not specified by a user deepcrime automatically computes the best configuration for the mutation operator.
for non continuous parameters deepcrime performs an exhaustive search by iterating through all of the possible values for a parameter.
in the case of continuousparameters the computation is based on identifying the lowestand the highest possible values and performing a binary searchin this range.
the aim of the search is to discover the mostchallenging and yet killable configuration of the mutationoperator for a given test suite.
for example for the operator 356remove portion of training data trd in table i the binary search first checks if the most aggressive configuration is killed by the test data.
if so deepcrime finds the middle point in the range of possible values .
and checks it forkillability.
if the middle point gets killed the search continueson the lower part of the range .
otherwise onthe upper half of the range .
.
this process isapplied in a recursive manner till the point when the size ofa new range becomes smaller than or equal to the desiredprecision epsilon1.
the observed value of the percentage parameter that is not killed which is epsilon1 close to the least aggressive killable configuration is the output of the binary search thisnon killed mutant is the target of test generation.
the authors of deepcrime also propose a definition of mutation score per operator.
the definition is based on theassumption that training data is a set of inputs to which atrained model is the most sensitive.
given a test set ts its mutation score ms is the proportion of configurations killed by both test and train set over those killed by the train set.
itis calculated as ms mo ts k mo ts k mo trs k mo trs for example if for the mutation operator trd the least aggressive killed configuration found by binary search is for the training data and for the test data the mutationscore will be computed as ms .
.
.
.
.
.
the overall mutation score of the test suite is computed as the average of mutation scoresacross all operators.
the fact that deepcrime offers a wide selection of mutation operators that are based on real dlfaults and that it produces a statistically reliable outcome wasthe key motivation for us to choose this tool.
the list ofdeepcrime s mutation operators with their parameters thatproduced mutants that were not killed by the test sets used inour case studies can be found in table i killed mutants arenot the target of d eepmetis s input generation .
iii.
t hedeepmetis technique deepmetis aims to augment an existing test set by extending it with mutant killing inputs that increase its mutationscore.
the algorithm describes the main steps implementedin d eepmetis to generate new inputs that kill mutants.
starting from the original code of a dl model and an existing test set d eepmetis leverages deepcrime to obtain the configurations for which the considered mutation operatoris not killed by the original test set for continuous operators this is the most aggressive non killed configuration found bybinary search .
deepcrime injects the corresponding mutation into the model s code and produces multiple original modeland mutant instances by executing ntimes the training process on the original and the mutated model s code respectively line .
d eepmetis uses evolutionary search to generate new test inputs that can discriminate the original model instancesalgorithm overall algorithm of d eepmetis input tso original test set c original dl program code gmax max number of generations popsize population size mutop mutation operatorn number of re training runs o number of original model instancesm number of mutant instances output ts a augmented test set 1generate original and mutant instances using deepcrime 2original model instances m o 3mutant model instances m m 4mo m m deepcrime c mutop n m o 5start evolutionary search 6generation g 7archive a 8initial population p0 initpopulation mo popsize 9population p p0 10eva l uat e p mo mm 11a update archive p 12assign crowding distance to individuals 13p select p popsize 14while g g max do g g selection based on dominance crowding distance offspring q seltourdcd p popsize substitute most dominated misbehaving on m o p repopulation p p0 a foreach q qdo q mutate q end eva l uat e p q mo mm a update archive p q p select p q popsize 26end 27augment the test set with the archived inputs 28ts tso a 29return ts from the mutated ones.
the algorithm is based on nsgaii a multi objective evolutionary search algorithm largelyused in search based software testing research .
after initialising variables g a p p lines the evolutionary steps are repeated for a given number of iterations g max.
in each iteration a population of individuals i.e.
test inputs is evolved and their behaviour is evaluated againstthe original and mutant models.
the result of such evalu ation lines and is the assignment of fitness valuesto individuals.
based on fitness values the best individualsare identified and sorted by means of crowding distance sorting a technique that accounts for both dominance between individuals according to the fitness values as wellas the distance between individuals that belong to the samedominance front lines and .
then we use tournamentselection to select the surviving individuals q line which are mutated by genetic operators line .
the worstindividuals are replaced by means of the repopulation operator which re introduces some of the initial seeds p into the current population p line .
when mutation killing inputs 357fig.
.
digit input representation and mutation.
a original input b original svg model after vectorization c svg model mutated by moving a controlpoint d mutated input are generated they are stored in an archive lines and .
finally the archived solutions are used to augment the initialtest suite line .
the test set improvement can be assessedby re running deepcrime to check if the previously non killed configuration is now killed.
d eepmetis s evolutionary algorithm rewards individuals that behave correctly on original models and misbehave onmutants.
d eepmetis is hybridised with novelty search as it also rewards individuals that exhibit the diversity of be haviours .
it uses an archive to store the best solutionsfound during the search in order to avoid cycling.
it also usesrepopulation to escape the stagnation in local optima with thehigh basin of attraction.
preliminary experiments supported theadoption of our newly proposed non standard twists in nsga ii such as the repopulation operator or the hybridisation withnovelty search as they provide more diverse solutions thanthe standard algorithm.
a. model based input representation d eepmetis belongs to the family of model based test input generators i.e.
tools that manipulate a model of the input instead of directly modifying the input data e.g.
pixels .
inthe following we will refer to the model used for manipulatinginputs as input generation model in order to distinguish it from the models used in the dl training and prediction process.
input data derived from an input generation model are more likely to be realistic and belong to the input validity domainthan data subjected to low level manipulation .
thisimplies that d eepmetis is applicable to problems for which an input generation model is available.
the development ofinput generation models is the standard practice in severaldomains such as cyber physical systems including safety critical ones e.g.
automotive .
below we present inputgeneration models for domains we considered in our experi mental evaluation a vector image format for handwritten digitclassifiers and a 3d human eye region model for eye gazepredictors.
digit classification.
we consider handwritten digit samples in the format adopted by the mnist database .
its inputsare originally encoded as 28images with greyscale levels that range from to .
as shown in figure wemodel them by adopting scalable vector graphics svg as their representation.
svg is an xml based vector imageformat for two dimensional graphics which defines shapesas combinations of cubic and quadratic b ezier curves.
the parameters determining the shape of a modelled digitare the start point the end point and the control points ofeach b ezier curve.
this representation helps in preserving the smoothness and curvature of handwritten shapes afterminor manipulations of the curve parameters .
weuse the potrace algorithm to transform an mnist inputinto its svg model representation.
this algorithm performsa sequence of operations to obtain a smooth vector imagestarting from a bitmap.
to transform an svg model back intoa28 28grayscale image we perform rasterisation by using two popular open source libraries librsvg 2and cairo3 .
gaze prediction.
we focus on the input format for the gaze estimator model proposed by zhang et al.
whichtakes as an input an eye image and a 2dhead rotation angle pitch and yaw and predicts the eye gaze angle.
the eye images are generated by exploiting unityeyes a freely available rendering framework .
our eye model consists ofall the independent parameters used by unityeyes to generatean eye image.
they can be divided into two groups thosethat cover various aspects related to an eye appearance headangle eye angle pupil size iris size iris texture skin texture and others that describe the lighting texture rotation ambientintensity exposure for image based lighting and rotationand intensity for directional lighting .
only some of theseparameters are directly controllable when asking unityeyesto generate new images namely head rotation angles and eyerotation angles the latter providing us with the ground truthfor the gaze prediction while the others are decided internallyby unityeyes.
all parameters are recorded by unityeyes ina json file that accompanies a generated image.
for eachpair of head and eye angles controllable parameters it ispossible to request unityeyes to generate an arbitrary numberof eye images differing among each other by the remain ing not directly controllable parameters.
when manipulatingunityeyes parameters for the purpose of test generation weneed to know the range in which each parameter falls inorder to ensure the validity of the manipulated values.
thus for head and eye angles we use the ranges suggested in theunityeyes interface.
to learn the valid ranges for the remaining parameters we generated a dataset of more than millionimages and analysed the generated json files.
the identified ranges and the script used for such analysis are available inour replication package .
b. fitness functions d eepmetis optimises two fitness functions which measure the ability of an individual to kill mutants and its diversity from the solutions already encountered during the search.
mutation killing.
the fitness function f1measures how close an individual is to misbehave on mutants.
in particular for a given mutant instance mut its value is negative in the presence of a misbehaviour while its value is positiveand indicates the distance from a misbehaviour when the 358system behaves correctly.
we estimate the distance from a misbehaviour as the model s confidence in the predicted classfor classifiers or the difference between the tolerable error andthe actual prediction error for regressors.
hence the lower thevalue assumed by such distance to misbehaviour the higherthe mutant s likelihood of misbehaving.
to take into accountthe non determinism of mutation and training we generate andtrainmmutant instances.
correspondingly the fitness value of an individual is computed as the sum of our misbehaviourcloseness metric over mmutant instances.
the fitness function f 1has to be minimised minf1 x m i n summationdisplay mut mmeval mut x to compute f1for an individual x d eepmetis executes the minstances of the considered mutant with xas an input.
the definition of function eval is clearly problem specific.
digit classification.
the eval function exploits the classifier s output softmax layer which can be interpreted as theconfidence level assigned to each possible class.
the predictedclass corresponds to the highest confidence level and there isa misbehaviour when the expected class has a confidence levellower than another class.
in particular eval is calculated as the difference between the confidence associated with the expectedclass and the maximum confidence associated with any otherclass when the prediction is correct it is otherwise.
gaze prediction.
a misbehaviour is detected when the prediction error exceeds the maximum tolerated error.
theprediction error is the difference between the model predictionand the expected prediction provided as ground truth byunityeyes .
since predictions consist of a pair of eye rotationangles in radians pitch and yaw the error is calculated asthe angle between the expected vector and the predicted one.the maximum tolerated error can be set according to problem specific requirements.
in our study we set it to 5degrees as this is an acceptable error in other gaze prediction applications .
the value of f 1is the difference between such an acceptable threshold and the actual gaze prediction error.
diversity.
the fitness function f2represents an individual s sparseness with respect to individuals in the archive and wewant to maximise it maxf x m a x spars x a whereais the archive of solutions and xis the individual being evaluated.
function spars measures the minimum distance of an individual xfrom the solutions in the archivea min y a y negationslash xdist x y .
the distance function dist is computed on pairs of inputs and is domain specific.
fordigit classification it is computed as the euclidean distancebetween pixel vectors.
in the gaze prediction problem we use the genotypic distance i.e.
the distance between thechromosomes of two individuals whose genes are the eyeparameters used by unityeyes.
because in the chromosomethere are float vectorial and categorical gene values to obtainan overall distance between chromosomes we compute thedistances between genes of the same type normalise themseparately and return the weighted sum of gene distances.
inparticular for float genes we compute the difference dand normalise it as d d for the pitch and yaw angles pairs we calculate the angle between two vectors in radians giventhe natural limits for eye rotation the difference never exceeds1 radian for categorical genes we assign to the distance ifthe genes contain the same category otherwise.
c. initial population to obtain the initial population we first gather a set of seeds i.e.
inputs on which the original models behave correctly.
then we select the most diverse seeds by computing pairwisedistances and greedily constructing the set of most diverseseeds starting from a randomly selected first seed up to thedesired population size.
then initial individuals are obtainedby applying a mutation genetic operator to each selected seed.we considered as seeds the samples in the training set onwhich the models behave correctly.
d. archive of solutions the best individuals encountered during the search are kept in the archive of solutions .
this prevents the search for novelty from cycling a phenomenon where the population moves from one area of the solution space to another andback again without memory of the areas it has alreadyexplored .
at the end of the last iteration the archive willcontain the final solutions.
an individual of the population is a solution candidate to be included in the archive if it behaves correctly on at least one oftheooriginal model instances and it triggers a misbehaviour on at least one mutant model instance.
when a new candidatesolution is found it competes locally with similar solutionsalready in the archive so that only the best ones are kept i.e.
those with the lowest value of fitness function f .
in the archive used for digit classification a solution competes with the archived inputs that are generated from thesame mnist seed.
in the archive used for gaze prediction w e do not rely on the starting seeds as unityeyes generates valideye images from any random vector of controllable parameterswithin the validity range without requiring to evolve them froman initially valid seed solution.
hence we had to define asimilarity criterion for the archive used for gaze prediction i f the distance from the nearest neighbour in the archive is higherthan a threshold t a the new individual is kept in the archive.
otherwise the new candidate competes locally with its nearestneighbour in the archive.
the threshold t ais a parameter that can be adjusted by a tester to obtain a proper trade off betweenthe number of solutions that enter the archive and the diversityof the archive.
to empirically choose the value of t a w e recommend to compute the minimum distance among arandomly selected set of diverse inputs choose a valuegreater than this number iteratively adjust this value basedon the corresponding archive size and similarity.
e. genetic operators in multi objective evolutionary algorithms there are multiple dimensions in our case f 1andf2 on which to compare 359fig.
.
eye input mutation the individuals.
we use the s election operator from nsgaii which applies pareto front analysis and promotes individuals that are not dominated by any other individual.
this operator favours individuals with smaller non dominationrank and when the rank is equal i.e.
they belong to the samepareto front it encourages diversity by favouring the one ina less dense region.
the offspring of the current populationis obtained through tournament selection with the tournamentsize equal to by choosing the best between each pair of individuals being compared.
each offspring individual is mutated by the m utation genetic operator which is domain specific.
for digit classification the mutation genetic operator randomly chooses ansvg model s point and applies a displacement to it in oneof the four directions in the 2d space.
then the rasterisationoperation is applied to obtain the new digit image.
for gaze prediction the mutation genetic operator randomly chooses agene from the individual s chromosome and applies a displace ment to its value.
then an input image that corresponds to thenew values of the eye model s parameters is supposed to begenerated.
however since only a small subset of parameterscan be controlled in unityeyes d eepmetis generates a high number of images and json file pairs under the desired controllable parameters.
from these pairs it selects theone that is closest to the desired mutant chromosome checkingthat it has never been used before during the search.
figure 2shows an original eye image left and the correspondingmutated image right obtained by maintaining the controllableparameters unchanged.
during the search exploration could get stuck in the local optima despite the use of fitness function f 2to promote diversity.
to mitigate this situation and further vary the population deepmetis uses the r epopulation genetic operator which replaces at each iteration the individuals in the populationthat are behaving incorrectly on all the considered originaldl model s instances.
the repopulation operator also replacesa fraction of the most dominated individuals in the currentpopulation i.e.
the individuals at the bottom of the paretofront ranking.
the aggressiveness of this operator can be tunedby setting the range from which such fraction is uniformlysampled i.e.
the repopulation upper bound.
as an example if the repopulation upper bound is set to at each iteration a number ris uniformly sampled between and and then the rmost dominated individuals are replaced.
the new individuals are generated starting from a randomly chosenseed.
repopulation is applied when the archive is not empty.iv .
e xperimental ev aluation a. subject systems we ran our experiments on two subject systems for which a model of the input is available and can be manipulated viaour genetic operators mnist and unityeyes.
mnist is a publicly available dataset consisting of images of hand written digits.
typically images areused for training and the remaining for testing.
thedl system consists of a dnn model that predicts whichdigit is represented by an input image.
we considered thedeep convolutional neural network cnn provided by keras because of its popularity simplicity and effectiveness .
test accuracy .
for the gaze prediction case study based on unityeyes we use a multimodal cnn which provides an im plementation based on the lenet network architecture following the approach described in the work by zhang etal.
.
the cnn learns the mapping from an eye imageand a 2dhead angle pitch and yaw t oa 2deye gaze angle.
the dataset that we used for training and testing issupplied along with the model and consists of eyeregion images with images used for training and25 for testing synthesised with unityeyes .
each image generated by unityeyes is accompanied by a json file describing 2dhead angle eye gaze vector as well as other parameters used to generate the image such as skin textureand various lighting features.
when presented to a model fortraining and prediction the images are converted to grayscaleand cropped to 36pixels.
the head angle and eye angle which represent the second input to the model and the groundtruth respectively are converted into radians.
b. research questions we have performed a set of experiments to answer the following research questions rq1 effectiveness can d eepmetis generate inputs that improve a given test set in terms of mutation killing capability?
to answer this research question for each of our subject systems we need an initial test set that we will then improve withthe help of d eepmetis.
the original test sets available for these subjects are very large in size and successful in terms ofmutation score for mnist and .
for unityeyes .we therefore had to artificially construct a weaker test set forour case studies.
for mnist we did so by removing the testinputs that are predicted with low confidence i.e.
confidenceless than from the original test set.
the elimination of suchinputs leads to a test set with smaller discriminative power aslow confidence inputs typically represent difficult corner casesthat are effective at discriminating a mutant from the originalmodel.
for unityeyes which solves a regression not a classi fication problem we instead removed inputs with the smalleststandard deviation of loss measured across instances of theoriginal model.
such inputs are very discriminative as mutants convnet 360typically amplify the standard deviation of the error observed for the original model so the effect is more visible when westart from a small standard deviation.
a similar approach toconstruct weak test sets for both classification and regressionsystems was adopted in humbatova et al.
.
the approachwe used for classification systems has also been previouslyused in the work by jahangirova and tonella for weaktest set construction and by byun et al.
for test inputprioritisation.
the size of the weak test set for mnist is 813elements and for unityeyes it is elements.
we then performed mutation testing of our subject systems considering the constructed weak test sets and usingdeepcrime.
out of the mutation operators implementedindeepcrime were applicable to mnist and to unityeyes.
for operators with non continuous parameters weapplied every value from the list exhaustively.
for operatorswith continuous parameters we performed the binary searchon the full range of the parameter value space.
we adopted thestatistical notion of mutation killing using the wilcoxontest to calculate the p value and cohen s dto measure the effect size.
according to our procedure statistical significanceis reached when p value .05and the effect size is greater than small i.e.
cohen s d .
.
overall we got not killed mutants i.e.
mutated versions producedbydeepcrime s mutation operators for mnist and for unityeyes.
as mutation testing suffers from the problem of equivalent mutants it is possible that some of the mutants not killedby our weak test set are not killable by any set of inputs and therefore our attempts for generating inputs that kill thesemutants are vain.
to avoid this situation we use the definitionof likely equivalent mutants proposed by humbatova etal.
.
according to this definition if a mutant is notkilled by the training data i.e.
the data the mutant shouldbe most sensitive to as the mutant was trained on suchdata then this mutant is deemed likely equivalent.
after filtering out the likely equivalent mutants we were left with19 mutants for mnist and for unityeyes.
the mnistmutants belong to different mutation operators while forunityeyes mutants are produced by mutation operators.to make our experiments feasible we further reduced theset of mnist mutants by picking only one mutant for eachmutation operator.
we applied d eepmetis to each of the mutants.
we first ran the initial population generation process timesto obtain different populations for each subject study.we then invoked the input generation process for each pairof the mutant and initial population getting as a result 10runs of d eepmetis on each mutant to account for the non deterministic search based nature of our tool.
in theseexperiments d eepmetis is run in the 1vs5 original vs mutant instances configuration.
this means that the number of mutant instances used by the fitness function f1 see equation is .
the next research question investigates other alternative configurations of our tool.table ii deepmetis configurations parameter mnist unityeyes population size generations archive threshold ta .
repopulation upper bound rq2 fitness guidance how does the fitness function based on a single mutant instance compare to the fitnessfunction based on multiple mutant instances in guiding d eepmetis towards the generation of mutation killing inputs?
the aim of this research question is to identify whether providing more instances of the same mutant to d eepmetis increases its success in generating mutation killing inputs.
forthis purpose we ran d eepmetis in different modes by providing it with either or instances of the samemutation i.e.
we configure it as 1vs1 1vs5 1vs10 and 1vs20 .
similarly to rq1 we perform runs using different initial populations.
we do not evaluate extensively the effectof increasing the number of instances of the original model e.g.
5vs5 or 10vs10 as preliminary experiments showedthat the effect of such alternative choices is negligible on theeffectiveness of the fitness function while at the same time issubstantially increasing the overall computation time.
rq3 comparison with other tools can we use existing dl input generators to achieve comparable improvement inthe mutation killing capability of a test set?
to answer this research question we compare d eepmetis to two state of the art test input generators for dl systems deepjanus and dlfuzz .
deepjanus is a modelbased tool that uses a multi objective evolutionary algorithmto generate frontier inputs for dl systems.
the frontier inputs are defined as pairs of inputs that are similar to each otherbut trigger different behaviours of a dl system.
the idea isthat for a low quality dl system such a frontier will includepairs that intersect the validity domain while for a high qualityone it will have a small or no intersection at all.
in ourexperiments we passed deepjanus one instance of the original model and from the generated set of pairs of inputs we useonly those inputs that do not trigger any misbehaviour in theoriginal model as our goal is to obtain inputs that behavecorrectly on the original models but misbehave on the mutatedones.
another option could be passing deepjanus the mutated model and then using the misbehaving set of inputs.
however some preliminary runs showed that the misbehaving inputsfor the mutant almost never behave correctly on the originalmodel.
therefore we excluded this setup from our comparisonstudy.
deepjanus can be applied to both unityeyes and mnist.
moreover it shares with d eepmetis the same input representation and mutation genetic operator which guaranteesa fair comparison of the approaches.
dlfuzz is representative of search based fuzzing testing tools that generate test inputs by applying perturbations to 361the raw input i.e.
pixels .
it aims to generate adversarial inputs that maximise neuron coverage for a dl system undertest.
for this purpose dlfuzz iteratively selects neurons the activation of which would lead to increased neuron coverage and applies perturbations to test inputs in order to activatethose neurons so guiding dl systems towards exposing mis behaviours.
the publicly available version of dlfuzz 5does not support regression systems.
therefore we could not applyit to unityeyes.
moreover this implementation does not workwith python versions higher than .
.
so we had to updatethe code to make it compatible with python .
.
similarly to d eepmetis both deepjanus and dlfuzz are affected by randomness so we performed runs of eachtool each run using a different initial population.
however we fixed the same population across runs of different tools toensure that the differences in their performance are not dueto the different starting points of the algorithms.
as explainedbefore deepjanus uses the original model in its generation process not requiring a re run for each mutant.
in contrast asdlfuzz generates only inputs that get misclassified by the given dl model we used the mutants.
as a result dlfuzz had to be re run for each considered mutant.
overall we performed runs of deepjanus populations for the original model of both mnist and unityeyes runs of dlfuzz populations for mnist mutants and runs of d eepmetis populations for mnist and unityeyes mutants .
for both tools we used the configuration reported as the one achieving the best performance by their authors.
rq4 fault detection can the test set augmented by deepmetis expose more faults than the original test set?
this research question analyses whether d eepmetis delivers its promise of improving the test set so that it detectsmore faults.
since to the best of our knowledge there is nopublicly available dataset of reproducible real faults for dlsystems we use deepcrime mutants as a replacement for real faults in a cross validation setup.
specifically we perform cross validation by leaving one of the mutants out and augmenting the test set with all theinputs generated by d eepmetis for the remaining mutants.
we ensure that none of the remaining mutants is generatedby the same mutation operator as the cross validation mutant assuming that mutants produced by the same operator mayhave similar properties.
we then check if the augmented testset is able to kill the cross validation mutant.
this processis repeated separately for the inputs generated in each of the10 runs of d eepmetis.
we added the previously excluded mnist mutants to this analysis as although there are noinputs generated specifically for them they can still serve ascross validation mutants.
before proceeding with the exper iment we performed a redundancy analysis among themutants of each subject to ensure that inputs generated forone mutant do not kill another mutant just because the latteris redundant with respect to the former.
redundancy analysis that all unityeyes mutants are non redundant while for mnist out of mutants are redundant.
weexcluded redundant mutants from further analysis i.e.
we didnot use them as cross validation mutants.
c. results columns subject and mo in table iii indicate the dl system and the mutation operator that provided the mutants used by d eepmetis for test input generation.
for each operator we report in brackets the parameter values whichwere found by the binary exhaustive search and were usedto generate the non killed mutant.
for mutation operatorsthat manipulate the training data this value indicates theratio of the affected data.
for example mnist trd removes .
of the training data.
for the other operators parametervalues with the prefix l followed by a number indicate thelayer to which a mutation operator was applied.
all the otherparameters specify the exact value used to inject the fault.
forexample mnist ach l6 sigmoid means that the activation function of layer number was changed from the original tothe sigmoid one.
in table iii the sub columns kindicate the killing probability computed as the mutation score see equation for continuous operators or as the binary killed non killedoutcome for discrete operator since we did not apply d eepmetis to all the possible mutants produced by discrete operators equation cannot be used for them .
column weak tsshows the killing probability kof the initial weak test set.
in the following columns the sub column inputs shows the average number of inputs generated across runs byeach tool tool configuration while the sub column kshows the average killing probability of the test set augmented withthe generated inputs computed across runs.
rq1 effectiveness the results for d eepmetis in its best configuration 1vs5 show that for both subjects theaugmentation of the initial test set with the d eepmetisgenerated inputs leads to a substantial increase of the mutationscore.
for mnist the improvement across the operators variesbetween and with the average kjumping from to .
for unityeyes the improvement ranges from to on a per operator basis and the average krises from to .
the number of generated inputs whichwould require manual labelling is on average for mnistand for unityeyes.
as these numbers constitute only0.
of the training data set size for mnist and .
for unityeyes we consider the labelling effort associated with d eepmetis to be low.
rq1 d eepmetis is able to achieve a substantial improvement in killing probability on each of theprovided mutants.
the magnitude of this improvementis for mnist and for unityeyes.
themanual labelling effort for the newly generated inputscan be deemed acceptable.
362table iii results column k killing probability reports mutation score for continuous operators and binary killed non killed outcome for discrete operators both a veraged across 10runs subjectweak ts deep metis deep metis deep metis deep metis deepjanus dlfuzz mo 1vs1 1vs5 1vs10 1vs20 k inputs k inputs k inputs k inputs k inputs k inputs k mnisttcl .
trd .
tud .
tan tco .
hlr .
hne ach l6 sigmoid arm l5 raw l0 l1 l2 wci l0 ones och rmsprop average unityeyestcl .
trd .
tud tan .
hlr .
hne aal l9 signsoft raw l1 l2 raw l3 l2 wci l1 ones average rq2 fitness guidance columns d eepmetis 1vs1 deepmetis 1vs5 d eepmetis 1vs10 d eepmetis 1vs20 report the results obtained when the fitness function uses and all instances of a mutant during the inputgeneration process respectively.
in the case of mnist for 3mutants out of 1vs1 and 1vs5 provide the same results.for operators 1vs5 performs better however for out ofthose the improvement is marginal .
for the remaining3 operators 1vs1 outperforms 1vs5 with the difference forone of the operators being only .
when we further compare1vs5 to 1vs10 the latter exhibits an improvement for equalperformance for and deterioration for operators while beingsubstantially more expensive computationally.
overall as alsoreflected in the average kacross operators for mnist the optimal performance is obtained with 1vs5 and 1vs10 settings which provide slightly better results than 1vs1 and 1vs20.
the results for unityeyes show that 1vs5 and 1vs10 produce the same average k which is slightly better than 1vs20 but is definitely superior when compared to 1vs1 .
on a closer inspection 1vs5 outperforms 1vs10 and1vs20 on mutants out of with the majority of them beingcontinuous operators while 1vs10 is the best in cases and1vs20 in .
as was noted 1vs20 on average performs similarlyto 1vs5 and 1vs10 however in one case wci l1 ones it fails to produce any improvement at all.
the reason behind the comparative weakness of 1vs1 w.r.t.
the other settings is that its fitness function has a verylimited range because it aggregates the eval value of a single mutant instance which provides restricted guidance to the testgeneration process.
the input generation for our experiments was performed on various machines.
it complicates the comparison of theexecution time between different configurations of d eepmetis.
however for each subject we ensured to run all configurations on the tud operator selected randomly using the same machine.
for mnist we used a macbook prolaptop .
ghz intel core i7 cores 16gb ram whilefor unityeyes we used alienware aurora r8 .
ghz intelcore i9 9900k cores 32gb ram nvidia geforce rtx2080 ti gb .
for mnist this operator took 47and minutes on average across runs for 1vs1 1vs5 1vs10 and 1vs20 respectively.
for unityeyes the generationof inputs for one run on average lasted 1vs1 1vs5 1vs10 and 1vs20 minutes.
these results show that1vs5 is the optimal setting for balancing the improvement inmutation score and the time required to generate the inputs.
rq2 the 1vs5 configuration of d eepmetis proved to be the optimal one.
it outperforms 1vs1 by asubstantial margin as a single mutant instance 1vs1 cannot provide enough guidance to generate effectiveinputs.
the settings with a higher number of mu tant instances are sometimes comparable in terms ofmutation score improvement but they might requiresignificantly more computation time.
rq3 comparison with other tools columns dlfuzz and deepjanus in table iii report the results for each of the tools being compared to d eepmetis.
in the case of mnist for out of mutants d eepmetis 1vs5 performs better than deepjanus while for the remaining mutants they have similar performance.
the average kacross all mutants for deepmetis 1vs5 is higher by than for deepjanus.
when it comes to the comparison between d eepmetis and 363dlfuzz d eepmetis provides better results for mutants dlfuzz for mutants and the outcome is equal for the remaining .
the average kacross all mutants is for deepmetis 1vs5 and for dlfuzz.
however dlfuzz generates .
more inputs than d eepmetis 1vs5 and therefore requires much more manual labelling effort.
asdlfuzz is not applicable to regression problems the comparison for the unityeyes subject was only possible between d eepmetis and deepjanus.
results show that deepjanus is not able to produce any improvement in the majority of the cases.
the only exceptions are tud and hlr operators where for the former the average improvement is40 compared to of d eepmetis 1vs5 and for the latter the improvement of deepjanus is limited to vs of d eepmetis.
we performed statistical analysis on the comparison of the results by each tool.
for mutants with continuous parameters we used the wilcoxon statistical test to obtain the p value and the vargha delaney a 12to quantify the effect size.
for mutants with non continuous parameters we calculateconfidence intervals using wilson s method.
when comparing d eepmetis and deepjanus for mnist the difference is statistically significant p value .
or confidence intervals do not intersect for mutants out of .
for out of 7mutants with continuous parameters the effect size is large for mutant it is medium and for the remaining one itis small.
in case of d eepmetis and dlfuzz there is a statistically significant difference for mutants.
the effect sizeis negligible for small for medium for and large for 1mutant.
the results of the comparison of d eepmetis 1vs5 and deepjanus on the unityeyes subject are statistically significant for out of applied mutants.
for the mutantswith continuous parameters the effects size ranges betweenlarge small and negligible .
when it comes to execution time comparison conducted in the same conditions as described for rq2 for mnist d eepmetis took on average minutes deepjanus minutes and dlfuzz minutes.
for unityeyes d eepmetis took about minutes on average and deepjanus about minutes.
rq3 d eepmetis outperforms dlfuzz and deepjanus in the task of augmenting a test set to improve its mutation score.
rq4 fault detection results are presented in table iv where column mo specifies the cross validation mutant used to check the hypothesis that d eepmetis generated inputs are also able to kill other previously unseen mutants.column inputs indicates the average number of inputs that were generated by d eepmetis and added to the originally weak test set across runs.
finally column killed reports the proportion of runs out of in which the augmented testset was able to kill the validation mutant.
for mnist almost all validation mutants were killed in all runs with the exception of arm l5 and raw l0 l2 that were killed in runs and wci l0 random uniform thattable iv fault detection subject mo inputs killed mnisttcl .
tud .
tco .
hlr .
ach l6 hard sigmoid ach l6 softplus ach l6 softmax arm l5 raw l0 l1 l2 raw l0 l2 wci l0 ones wci l0 random uniform och rmsprop unityeyestcl .
trd .
tud tan .
hlr .
hne aal l9 signsoft raw l1 l2 raw l3 l2 wci l1 ones was killed in run.
the latter is an almost equivalent mutant with a very low triviality score which is very difficult tokill for d eepmetis.
the results for unityeyes also indicate that d eepmetis is always able to kill the unseen mutant at least once.
for mutants out of the test set augmented with deepmetis inputs killed the mutant in of the runs.
in all other cases except for trd .
and hne the augmented test set succeeds in to out of runs.
rq4 the mutation killing capability of the d eepmetis generated inputs holds also for previously unseen mutants with average success rate acrossour two subjects.
d. threats to v alidity construct validity the choice of the distance metrics may threaten our findings.
we chose sound metrics for theconsidered domains.
we used euclidean distance when com paring matrices of grayscale values also used in previousstudies .
when comparing unityeyes inputs we used acombination of appropriate distances for each gene type in thechromosome.
internal validity the main threat affecting the internal validity of our results is the choice of mutation operatorsand mutation tool.
we use deepcrime a dl mutation tool that accounts for the stochastic nature of dl systems and dlspecific mutation operators by adopting the statistical notion ofmutation killing.
moreover its operators are derived from realdl faults that ensure a higher degree of realism as comparedto alternatives.
364external validity the choice of the subject dl systems is a possible threat to the external validity.
to mitigate it we chose two diverse dl systems.
one solves a classification problem while another solves a regression problem.
theexecution of multiple original and mutant models may hinderthe generalisation to more complex dl problems e.g.
self driving cars that require simulations to be evaluated.
however our results show that d eepmetis generates effective inputs with a limited number of models i.e.
original and mutated.a wider set of systems including industrial ones should beconsidered in future studies to further generalise our findings.
to ensure reproducibility of our results we share online the source code of d eepmetis the considered subjects and the experimental data .
v. r elated work a. test generation for dl systems several works in the literature propose techniques that generate test inputs for dl systems by manip ulating raw input data i.e.
they apply small perturbations toavailable real inputs.
a limitation of these approaches is thelack of realism of the generated inputs.
while these corruptedimages are useful for security testing as adversarial attacks they are not necessarily representative of data captured bysensors of a real dl system.
another family of testing techniques adopts a model based approach that exploits model manipula tion and model based generation.
differently from raw inputmanipulation approaches these techniques tend to generatemore realistic inputs if a faithful model of the input domainis adopted since the generated images are compliant with theconstraints of such a model.
in this work we adopt a model based approach to improve the realism of the generated inputs.
pei et al.
propose a raw input manipulation technique aimed at generating inputs that trigger inconsistencies betweenmultiple dl systems .
other techniques manipulate rawimages and consider as failures the inconsistent behaviourstriggered by the original and transformed test inputs .
model based approaches proposed by abdessalem et al.
and gambi et al.
aim to test advanceddriver assistance systems by generating extreme and challeng ing scenarios that maximise the number of detected systemfailures.
riccio and tonella proposed a model based approachthat produces test suites made of pairs of inputs that identifythe frontier of behaviours of a dl system i.e.
the inputs atwhich the dl system starts to misbehave .
udeshi et al.generate inputs that highlight fairness violations by perturbingdiscriminatory parameters e.g.
gender .
vahdat pour etal.
use dl mutation to guide the generation of adversarialcode snippets for dl models tailored to the computation ofcode embeddings.
d eepmetis differs from the existing approaches because its goal is to increase the mutation killing ability of a testset.
with the advent of dl mutation frameworks such asdeepmutation munn and deepcrime theproblem of achieving a high mutation score is increasinglyimportant especially when mutants mimic real faults as isthe case of deepcrime .
d eepmetis is the first approach that can assist developers in the challenging task of making a dl test set better atmutation killing.
b. test adequacy for dl systems several test adequacy criteria have been proposed for dl systems.
pei et al.
use the number of neuron activations of the model to measure test adequacy.
in particular a neuronis considered activated if its output value is higher than apredefined threshold.
ma et al.
propose a set of addi tional adequacy criteria based on neuron activations.
they useactivation values obtained from the training data and divide therange of values for each neuron into kbuckets.
kim et al.
designed a test adequacy criterion named surprise adequacy based on the degree of surprise of an input for the neuralnetwork.
similarly to ma et al.
s criteria bucketing isused to make the surprise measure an adequacy criterion allkbuckets of surprise ranges must be covered by the test set.
x. zhang et al.
observe how inputs are distributed acrossdifferent uncertainty patterns i.e.
combinations of alternativeuncertainty metrics e.g.
high prediction confidence and lowvariation ratio .
although they do not define a proper adequacycriterion they recommend generating additional test inputs tocover the least covered uncertainty patterns and they showthat such inputs evade defences against adversarial attacks.
we adopt a test set s mutation score as an adequacy criterion.
like other criteria our criterion uses thetraining set as a reference since it contains the inputs to whichthe model is mostly sensitive the mutation score of a test setshould be as close as possible to the training set s one.
jahangirova tonella compared mutation score to other adequacy metrics such as neuron coverage andsurprise coverage showing that mutation score is moreeffective in differentiating between weak and strong test setsthan the existing alternatives.
d eepmetis is the first tool that uses mutation adequacy as guidance for the generation of inputs that increase the mutationscore of an existing weak test set.
vi.
c onclusions and future work we proposed d eepmetis the first automated test generator for dl systems that can increase the mutation score of aweak test set guided by mutation adequacy.
our empiricalevaluation shows that our tool outperforms state of the art dltest generators in this task.
the test sets generated by d eepmetis can expose unknown faults simulated in our leaveone out experiment by means of previously unseen mutants.in our future work we plan to generalise our results to a widersample of dl systems including industrial ones.
a cknowledgment this work was partially supported by the h2020 project precrime funded under the erc advanced grant 2017program erc grant agreement n. .
365references c. d. manning p. raghavan and h. sch utze introduction to information retrieval.
new york ny usa cambridge university press .
k. pei y .
cao j. yang and s. jana deepxplore automated whitebox testing of deep learning systems in proceedings of the 26th symposium on operating systems principles.
acm pp.
.
j. guo y .
jiang y .
zhao q. chen and j. sun dlfuzz differential fuzzing testing of deep learning systems in proceedings of the acm joint meeting on european software engineering con ference and symposium on the foundations of software engineering esec sigsoft fse pp.
.
y .
tian k. pei s. jana and b. ray deeptest automated testing of deep neural network driven autonomous cars in proceedings of the 40th international conference on software engineering ser.
icse .
new york ny usa acm pp.
.
.
available x. xie l. ma f. juefei xu m. xue h. chen y .
liu j. zhao b. li j. yin and s. see deephunter a coverage guided fuzztesting framework for deep neural networks in proceedings of the 28th acm sigsoft international symposium on software testingand analysis ser.
issta .
new york ny usa associationfor computing machinery p. .
.
available j. kim r. feldt and s. yoo guiding deep learning system testing using surprise adequacy in proceedings of the 41st international conference on software engineering icse pp.
.
f. harel canada l. wang m. a. gulzar q. gu and m. kim is neuron coverage a meaningful measure for testing deep neural networks?
inesec fse 28th acm joint european software engineering conference and symposium on the foundations of software engineering virtual event usa november pp.
.
y .
jia and m. harman an analysis and survey of the development of mutation testing ieee transactions on software engineering vol.
no.
pp.
.
n. humbatova g. jahangirova g. bavota v .
riccio a. stocco and p. tonella taxonomy of real faults in deep learning systems inproceedings of 42nd international conference on software engineering ser.
icse .
acm p. pages.
j. m. zhang m. harman l. ma and y .
liu machine learning testing survey landscapes and horizons ieee transactions on software engineering vol.
early access no.
pp.
.
v .
riccio g. jahangirova a. stocco n. humbatova m. weiss and p. tonella testing machine learning based systems a systematicmapping empir .
softw.
eng.
vol.
no.
pp.
.
.
available g. jahangirova and p. tonella an empirical evaluation of mutation operators for deep learning systems in ieee international conference on software testing v erification and v alidation ser.
icst .
ieee p. pages.
j. sohn s. kang and s. yoo search based repair of deep neural networks arxiv preprint arxiv .
.
j. wang g. dong j. sun x. wang and p. zhang adversarial sample detection for deep neural network through model mutation testing in2019 ieee acm 41st international conference on software engineering icse .
ieee pp.
.
m. v .
pour z. li l. ma and h. hemmati a search based testing framework for deep neural networks of source code embedding inieee international conference on software testing v erification andv alidation ser.
icst .
ieee p. pages.
j. gunel s. andrea and t. paolo quality metrics and oracles for autonomous vehicles testing in ieee 14th international conference on software testing v alidation and v erification icst .
ieee .
l. ma f. zhang j. sun m. xue b. li f. juefei xu c. xie l. li y .
liu j. zhao and y .
wang deepmutation mutation testingof deep learning systems in 29th ieee international symposium on software reliability engineering issre memphis tn usa october pp.
.
.
available w. shen j. wan and z. chen munn mutation analysis of neural networks in ieee international conference on software quality reliability and security companion qrs c july pp.
.
q. hu l. ma x. xie b. yu y .
liu and j. zhao deepmutation a mutation testing framework for deep learning systems in 34th ieee acm international conference on automated software engineer ing ase .
ieee pp.
.
n. humbatova g. jahangirova and p. tonella deepcrime mutation testing of deep learning systems based on real faults in proceedings of the 30th acm sigsoft international symposium on software testingand analysis .
m. j. islam g. nguyen r. pan and h. rajan a comprehensive study on deep learning bug characteristics in proceedings of the 27th acm joint meeting on european software engineering conferenceand symposium on the foundations of software engineering ser.esec fse .
new york ny usa acm pp.
.
.
available y .
zhang y .
chen s. c. cheung y .
xiong and l. zhang an empirical study on tensorflow program bugs in proceedings of the 27th acm sigsoft international symposium on software testing and analysis ser.
issta .
new york ny usa acm pp.
.
.
available k. deb a. pratap s. agarwal and t. meyarivan a fast and elitist multiobjective genetic algorithm nsga ii ieee transactions on evolutionary computation vol.
no.
pp.
april .
a. panichella f. m. kifetew and p. tonella automated test case generation as a many objective optimisation problem with dynamicselection of the targets ieee transactions on software engineering vol.
no.
pp.
.
s. yoo and m. harman pareto efficient multi objective test case selection in proceedings of the international symposium on software testing and analysis ser.
issta .
new york ny usa acm pp.
.
.
available using hybrid algorithm for pareto efficient multi objective test suite minimisation journal of systems and software vol.
no.
pp.
.
.
available k. mao m. harman and y .
jia sapienz multi objective automated testing for android applications in proceedings of the 25th international symposium on software testing and analysis ser.
issta2016.
new york ny usa acm pp.
.
.available k. lakhotia m. harman and p. mcminn a multi objective approach to search based test data generation in proceedings of the 9th annual conference on genetic and evolutionary computation ser.
gecco .
new york ny usa acm pp.
.
.available v .
riccio and p. tonella model based exploration of the frontier of behaviours for deep learning system testing in proceedings of the 28th acm joint meeting on european software engineering conferenceand symposium on the foundations of software engineering ser.
esec fse .
new york ny usa association forcomputing machinery p. .
.
available j. lehman and k. o. stanley abandoning objectives evolution through the search for novelty alone evolutionary computation vol.
no.
pp.
.
.
available a00025 b. marculescu r. feldt and r. torkar using exploration focused techniques to augment search based software testing an experimentalevaluation in ieee international conference on software testing v erification and v alidation icst april pp.
.
m. utting a. pretschner and b. legeard a taxonomy of model based testing approaches software testing verification and reliability vol.
no.
pp.
.
t. zohdinasab v .
riccio a. gambi and p. tonella deephyperion exploring the feature space of deep learning based systems throughillumination search in proceedings of the 30th acm sigsoft international symposium on software testing and analysis pp.
.
c. larman applying uml and patterns an introduction to objectoriented analysis and design.
prentice hall .
y .
lecun l. bottou y .
bengio p. haffner et al.
gradient based learning applied to document recognition proceedings of the ieee vol.
no.
pp.
.
p. selinger potrace a polygon based tracing algorithm sourceforge.net potrace.pdf .
x. zhang y .
sugano m. fritz and a. bulling appearance based gaze estimation in the wild in proceedings of the ieee conference on computer vision and pattern recognition pp.
.
e. wood t. baltru saitis l. p. morency p. robinson and a. bulling learning an appearance based gaze estimator from one million synthesised images in proceedings of the ninth biennial acm symposium on eye tracking research applications pp.
.
v .
riccio n. humbatova g. jahangirova and p. tonella replication package for deepmetis .
e. d. de jong the incremental pareto coevolution archive in genetic and evolutionary computation gecco k. deb ed.
berlin heidelberg springer berlin heidelberg pp.
.
j. b. mouret and j. clune illuminating search spaces by mapping elites .
an implementation of a multimodal cnn for appearance based gaze estimation.
.
t. byun v .
sharma a. vijayakumar s. rayadurgam and d. cofer input prioritization for testing neural networks in ieee international conference on artificial intelligence testing aitest .ieee pp.
.
.
available s. dola m. b. dwyer and m. l. soffa distribution aware testing of neural networks using generative models arxiv preprint arxiv .
.
m. zhang y .
zhang l. zhang c. liu and s. khurshid deeproad gan based metamorphic testing and input validation framework forautonomous driving systems in proceedings of the 33rd acm ieee international conference on automated software engineering ase pp.
.
s. lee s. cha d. lee and h. oh effective white box testing of deep neural networks with adaptive neuron selection strategy inproceedings of the 29th acm sigsoft international symposium onsoftware testing and analysis ser.
issta .
new york ny usa association for computing machinery p. .
.available r. b. abdessalem s. nejati l. c. briand and t. stifter testing advanced driver assistance systems using multi objective search andneural networks in proceedings of the 31st ieee acm international conference on automated software engineering ase pp.
.
r. b. abdessalem a. panichella s. nejati l. c. briand and t. stifter testing autonomous cars for feature interaction failuresusing many objective search in proceedings of the 33rd acm ieee international conference on automated software engineering ser.
ase2018.
new york ny usa acm pp.
.
.available r. b. abdessalem s. nejati l. c. briand and t. stifter testing vision based control systems using learnable evolutionary algorithms inproceedings of the 40th international conference on software engineering ser.
icse .
new york ny usa acm pp.
.
.
available a. gambi m. m uller and g. fraser automatically testing self driving cars with search based procedural content generation in proceedings of the 28th acm sigsoft international symposium on software testingand analysis issta pp.
.
s. udeshi p. arora and s. chattopadhyay automated directed fairness testing in proceedings of the 33rd acm ieee international conference on automated software engineering ser.
ase .new york ny usa acm pp.
.
.
available l. ma f. juefei xu f. zhang j. sun m. xue b. li c. chen t. su l. li y .
liu j. zhao and y .
wang deepgauge multi granularity testing criteria for deep learning systems inproceedings of the 33rd acm ieee international conference onautomated software engineering ser.
ase .
new york ny usa acm pp.
.
.
available x. zhang x. xie l. ma x. du q. hu y .
liu j. zhao and s. meng towards characterizing adversarial defects of deep learning softwarefrom the lens of uncertainty in proceedings of 42nd international conference on software engineering ser.
icse .
acm p. pages.