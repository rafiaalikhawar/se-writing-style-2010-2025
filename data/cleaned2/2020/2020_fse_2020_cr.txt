mining assumptions for software components using machine learning khouloud gaaloul university of luxembourg luxembourg khouloud.gaaloul uni.luclaudio menghi university of luxembourg luxembourg claudio.menghi uni.lushiva nejati university of ottawa canada university of luxembourg luxembourg snejati uottawa.ca lionel c. briand university of ottawa canada university of luxembourg luxembourg lionel.briand uni.ludavid wolfe qra corp canada david.wolfe qracorp.com abstract software verification approaches aim to check a software component under analysis for all possible environments.
in reality however components are expected to operate within a larger system and are required to satisfy their requirements only when their inputs are constrained by environment assumptions .
in this paper we propose epicurus an approach to automatically synthesize environment assumptions for a component under analysis i.e.
conditions on the component inputs under which the component is guaranteed to satisfy its requirements .
epicurus combines search based testing machine learning and model checking.
the core of epicurus is a decision tree algorithm that infers environment assumptions from a set of test results including test cases and their verdicts.
the test cases are generated using search based testing and the assumptions inferred by decision trees are validated through model checking.
in order to improve the efficiency and effectiveness of the assumption generation process we propose a novel test case generation technique namely important features boundary test ifbt that guides the test generation based on the feedback produced by machine learning.
we evaluated epicurus by assessing its effectiveness in computing assumptions on a set of study subjects that include requirements of four industrial models.
we show that for each of the requirements epicurus was able to compute an assumption to ensure the satisfaction of that requirement and further of these assumptions were computed in one hour.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november virtual event usa association for computing machinery.
acm isbn .
.
.
.
concepts software and its engineering software verification and validation search based software engineering .
keywords environment assumptions model checking machine learning decision trees search based software testing acm reference format khouloud gaaloul claudio menghi shiva nejati lionel c. briand and david wolfe.
.
mining assumptions for software components using machine learning.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
introduction the ultimate goal of software verification techniques is to provably demonstrate the correctness of the system under analysis for a given system requirement.
however this problem is generally undecidable for cyber physical or hybrid systems and too difficult to achieve for many industrial systems that are far too complex to be verified exhaustively and in their entirety .
as a result in practice exhaustive verification techniques e.g.
can only be applied to some selected individual components or algorithms that are amenable to exhaustive verification and are used within a larger system.
in general we cannot conclude if an entire system satisfies or refutes some requirements by verifying the constituent components of that system.
in other words the verification results of individual components cannot be generally lifted to the system level.
unless we rely on some compositional verification framework component verification alone does not contribute to evaluating a system as a whole.
however exhaustively verifying individual components can still be beneficial especially for components performing some critical algorithmic computation or components that are reused in several systems.
in checking components individually however it is essential to identify the environment information in whichesec fse november virtual event usa gaaloul menghi nejati briand wolfe each component is expected to operate correctly .
attempting to verify components for a more general environment than their expected operational environment may lead to overly pessimistic results or to detecting spurious failures.
the problem of identifying the environmental context for individual software components has been extensively studied by classical compositional and assume guarantee reasoning approaches e.g.
.
these approaches capture the context for an individual software component by describing the expectations that a component makes about its environment using environment assumptions i.e.
conditions or constraints on component inputs .
traditional compositional verification frameworks expect environment assumptions to be developed manually.
this is however difficult and time consuming.
for most practical cases engineers simply may not have sufficient information about the details of the components under analysis to develop a sufficiently detailed useful and accurate environment assumption.
there have been approaches to automate environment assumption computation in the context of assume guarantee reasoning using an exact learning algorithm for regular languages and finite state automata .
these approaches however assume that the components under analysis and their environment can be specified as abstract finite state machines.
state machines are not however expressive enough to capture quantitative and numerical components as well as continuous behavior of systems interacting with physical environments.
besides software components may not be readily specified in abstract state machine notations and converting them into this notation may cause significant extra modeling effort or may lead to loss of important information required for assumption learning.
in this paper we propose epicurus assumption generation approach for cps .
epicurus is tailored for the analysis of simulink models which are commonly used in early stages of development for cyber physical systems.
epicurus receives as input a software component mand a requirement such that mviolates for some but not all of its inputs.
it automatically infers a set of conditions i.e.
an environment assumption on the inputs of msuch that msatisfies when its inputs are restricted by those conditions.
epicurus combines machine learning and search based testing to generate an environment assumption.
search based testing is used to automatically generate a set of test cases for mexercising requirement such that some test cases are passing and some are failing.
the generated test cases and their results are then fed into a machine learning decision tree algorithm to automatically infer an assumption aon the inputs of msuch that mis likely to satisfy when its inputs are restricted by a. model checking is used to validate an environment assumption aby checking if mguarantees when it is fed with inputs satisfying a. if not validated epicurus continues iteratively until it finds assumptions that can be validated by model checking or runs out of it search time budget.
to increase the efficiency and effectiveness of epicurus we design a novel test generation technique namely important features boundary test ifbt .
ifbt guides the test generation by focusing on input features with highest impact on the requirement satisfaction and the areas of the search space where test cases change from passing to failing.
at each iteration epicurus uses the decision tree from the previous iteration to obtain this information.we evaluated epicurus using four industrial models with requirements.
our evaluation aims to answer two questions i if ifbt our proposed test generation policy can outperform existing test generation policies proposed in the literature uniform random ur and adaptive random testing art in learning assumptions more effectively and efficiently rq1 and ii if epicurus when used with its optimal test generation policy is effective and efficient for practical usages rq2 .
our results show that for all the requirements epicurus is able to compute an assumption ensuring the satisfaction of that requirement and further epicurus generates of these assumptions in less than one hour and ifbt outperforms ur and art by generating more valid assumptions while requiring less time.
the contributions of this work are summarized in the following we present the epicurus assumption generation approach and provide a concrete and detailed implementation of epicurus sections and .
we formulate the assumption generation problem for simulink models section .
we describe how we infer constraints from decision trees and how the constraints can be translated into logic based assumptions over signal variables such that they can be analyzed by an industrial model checker namely qvtrace section .
.
we introduce ifbt a novel test case generation technique that aims at increasing the efficiency and effectiveness of epicurus section .
.
we evaluate epicurus on four real industrial models and requirements.
structure.
section introduces the autopilot running example.
section outlines epicurus and its pre requisites.
section formalizes the assumption generation problem.
section presents how epicurus is developed.
section evaluates epicurus and section discusses the threats to validity.
section compares with the related work and section concludes the paper.
context and running example in this section we motivate our approach using a running example and describe the pre requisites for epicurus our automated assumption generation framework.
our running example which we refer to it as autopilot is a software component in the autopilot system of a de havilland beaver aircraft.
autopilot issues commands to the plane actuators to control the aircraft s orientation pitch roll and yaw angles .
the autopilot component receives its inputs from two other components a route planner component that computes the aircraft route and a flight director component a.k.a.
auto throttle which provides autopilot among other inputs with the throttle force required to adjust the aircraft speed.
for the de havilland beaver aircrafts the throttle input of autopilot which is required to help the aircraft reach its desired altitude is typically provided by the pilot as such aircrafts may not contain a flight director component.
theautopilot model is specified in the simulink language .
the simulink model of autopilot is expected to satisfy a number of requirements one of which is given below 1 when the autopilot is enabled the aircraft altitude should reach the desired altitude within seconds in calm air.mining assumptions for software components esec fse november virtual event usa the above requirement ensures that autopilot controls the aircraft such that it reaches the input desired attitude within a given time limit i.e.
500sec in this requirement .
to determine whether or not autopilot satisfies the requirement 1 we convert the requirement into a formal property and use qvtrace a commercial smt based model checker for simulink models.
qvtrace however fails to demonstrate that the autopilot simulink model satisfies the requirement .
neither can qvtrace show that autopilot satisfies indicating that for some inputs autopilot violates and for some it satisfies .
note that if the model satisfies either or there is no need for generating an input assumption.
one of the reasons that autopilot does not satisfy 1is that autopilot is expected to operate under the following environmental assumption 1 to provide the aircraft with enough boost so that it can reach the desired altitude the pilot should manually adjust the power given to the engines of the aircraft to ensure that the aircraft does not enter a stall condition.
in other words autopilot can ensure requirement 1only if its throttle boost input satisfies the 1assumption.
for example if the pilot does not provide autopilot with sufficient throttle force when the aircraft is in climbing mode the aircraft will not reach its desired altitude and autopilot will fail to satisfy 1. objective.
without including assumption 1 in the above example we may falsely conclude that autopilot is faulty as it does not satisfy 1. however after restricting the inputs of autopilot with an appropriate assumption we can show that autopilot satisfies 1. hence there is no fault in the internal algorithm of autopilot .
in this paper we provide epicurus an automated approach to infer environment assumptions for system components such that they after being constrained by the assumptions can satisfy their requirements .
epicurus is applicable under the following pre requisites or contextual factors prerequisite .
the component mto be analyzed is specified in the simulink language.
simulink is a well known and widelyused language for specifying the behavior of cyber physical systems such as those used in the automotive and aerospace domains.
prerequisite .
the requirement the component has to satisfy is specified in a logical language.
this is to ensure that the requirements under analysis can be evaluated by model checkers or converted into fitness functions required by search based testing.
both model checking and search based testing are parts of epicurus.
prerequisite .
the satisfaction of the requirements of interest over the considered component can be verified using a model checker.
prerequisite .
the model satisfies neither the requirement nor its negation since otherwise an input assumption is not needed.
epicurus overview fig.
shows an overview of epicurus which is described by algorithm .
epicurus iteratively performs the following three main steps test generation where a set tsof test cases that exercise mwith respect to requirement is generated.
the test suite tsis generated such that it includes both passing test cases i.e.
satisfying and failing test cases i.e.
violating assumption generation where using the test suite ts an assumption ais generated such that mrestricted by ais likely to satisfy model testgeneration gensuite trueepicurus1 modelchecking modelcheck assumptiongeneration genassum 23falseatsafigure an overview on the epicurus framework.
algorithm the epicurus approach.
inputs .m the simulink model test requirement of interest opt options max it max number of iterations outputs .a the assumption function a epicurus m opt max it counter ts variables initialization do ts gensuite m ts opt test suite generation a genassum ts assumption generation counter increases the counter while not modelcheck a m and counter max it return a end function checking where mrestricted by ais model checked against .
we use the notation a m borrowed from the compositional reasoning literature to indicate that mrestricted by asatisfies .
if our model checker can assert a m an assumption is found.
otherwise we iterate the epicurus loop.
the approach stops when an assumption is found or a set time budget elapses.
simulink models.
simulink is a data flow based visual language for model based design.
each simulink model has a number of inputs and a number of outputs.
we denote a test input for m asu u1 u2.
.
.um where each uiis a signal for an input of m and a test output for masy y1 y2.
.
.yn where each yiis a signal for some output of m. simulink models can be executed using a simulation engine that receives a model mand a test input uconsisting of signals over a time domain t and computes the test output yconsisting of signals over the same time domain t. atime domain t is a non singular bounded interval of r. asignal is a function f t r. asimulation denoted by h u m y receives a test input uand produces a test output y. for example fig.
2a shows a test input for the autopilot example where signals are defined over the time domain and fig.
2b shows the corresponding test output.
specifically fig.
2a shows input signals for autopilot.
each of these inputs is related to a command received from the pilot through the instruments in the cockpit i.e.
apen hdgmode alt mode represent the status of the autopilot engaging mode enabler hdgre f represents the desired value of the heading angle throttle represents the power applied to the engine pitchw heel represents the degree of adjustments applied to the aircraft pitch and turnknob represents the desired value of the roll angle .
fig.
2b represents the output signalsesec fse november virtual event usa gaaloul menghi nejati briand wolfe a inputs b outputs figure an example of input output signals of the autopilotsimulink model.
of autopilot namely psiandphithat respectively represent the heading and the roll angles .
the simulink simulation engine takes around 30s to simulate the behavior of the system over the time domain .
test generation .
the goal of the test generation step is to generate a test suite tsof test cases for msuch that some test inputs lead to the violation of and some lead to the satisfaction of .
without a diverse test suite tscontaining a significant proportion of passing and failing test cases the learning algorithm used in the assumption generation step is not able to accurately infer an assumption.
we use search based testing techniques for test generation and rely on simulations to run the test cases.
search based testing allows us to guide the generation of test cases in very large search spaces.
it further provides the flexibility to tune and guide the generation of test inputs based on the needs of our learning algorithm.
for example we can use an explorative search strategy if we want to sample test inputs uniformly or we can use an exploitative strategy if our goal is to generate more test inputs in certain areas of the search space.
for each generated test input the underlying simulink model is executed to compute the output.
the verdict of the property of interest is then evaluated based on the simulation.
note that while inputs that satisfy and violate the property of interest can also be extracted using model checkers due to the large amount of data needed by ml to derive accurate assumptions we rely on simulation based testing.
further it is usually faster to simulate models rather than to model check them.
hence simulation based testing leads to the generation of larger amounts of data within a given time budget compared to using model checkers for data generation.
assumption generation .
given a requirement and a test suite tsgenerated by the test generation step the goal of the assumption generation step is to infer an assumption asuch that m restricted based on ais likely to satisfy .
the test inputs generated by the test generation step are labelled by the verdict value pass or fail .
we use decision tree dt learners to derive an assumption 1machine core i7.
.
ghz.
gb of ram node 1total data 1000node 2total data 494node 3total data 532pitchwheel 5pitchwheel 5altmode node 4total data 379label passnode 5total data 115label failaltmode throttle .
node 6total data 200label failnode 7total data 332throttle .
node 8total data 120label passnode 9total data 212label failthrottle .
throttle .
test casesverdictconditionfigure an example of classification tree constraining some of the inputs of the autopilot running example.
based on test inputs labelled by binary verdict values.
dt are supervised learning techniques that are trained based on labeled data and can address regression or classification problems.
in this paper we rely on classification trees to represent assumptions since our test cases are labelled by binary pass fail values.
fig.
shows an example of a classification dt used to learn an assumption based on labelled test cases for autopilot .
the internal nodes of the tree a.k.a.
split nodes are associated with conditions in the form a vwhere ais an attribute vis a value and .
each leaf node is labelled with pass or fail depending on the label of the majority of instances that fall in that leaf node.
the dt algorithm recursively identifies attributes elements in the training set to be associated with each internal node defines conditions for these attributes and branches the training instances according to the values of the selected attribute.
each branching point corresponds to a binary decision criterion expressed as a predicate.
ideally the algorithm terminates when all the leaf nodes are pure that is when they contain instances that all have the same classification.
specifically the path which traverses the nodes 8corresponds to the following conditions on the throttle and the pitch wheel .
throttle throttle .
pitchwheel indicating that when the inputs throttle andpitchwheel of autopilot are constrained according to these conditions the requirement 1likely holds see section .
recall that the assumption 1explained in section requires the throttle value to be higher than a certain threshold to ensure requirement 1. this matches the condition .
throttle produced by the decision tree.
the conditions pitchwheel 5andthrottle .57may or may not be needed to ensure requirement 1. in our approach the path conditions that are typically produced by decision trees may involve additional constraints that may render assumptions too strong restrictive and hence less informative.
as a result in this paper we are interested to produce the weakest the most informative assumptions that can guarantee our requirements.
model checking .
this step checks whether the assumption agenerated by the assumption generation step is accurate.
note that the dt learning technique used in the assumption generation step being a non exhaustive learning algorithm cannot ensure that aguarantees the satisfaction of form.
hence in this step we use a model checker for simulink models to check whether mrestricted byasatisfies i.e.
whether a m holds.
we use qvtrace tomining assumptions for software components esec fse november virtual event usa exhaustively check the assumption agenerated in the assumption generation step.
qvtrace takes as input a simulink model and a requirement specified in qct which is a logic language based on a fragment of first order logic .
the description of the qct language and examples of how to express properties in qct are provided in our online appendix .
in addition qvtrace allows users to specify assumptions using qct and to verify whether a given requirement is satisfied for all the possible inputs that satisfy those assumptions.
qvtrace uses smt based model checking specifically z3 bmc to verify simulink models.
the qvtrace output can be one of the following no violation exists indicating that the assumption is valid i.e.
a m holds no violation exists for k kmax.the model satisfies the given requirement and assumption in the time interval .
however there is no guarantee that a violation does not occur after kmax violations found indicating that the assumption adoes not hold on the model m and inconclusive indicating that qvtrace is not able to check the validity of adue to scalability and incompatibility issues.
assumption generation problem in this section we formulate the assumption generation problem for simulink models.
let mbe a simulink model.
an assumption afor mconstrains the inputs of m. each assumption ais the disjunction c1 c2 .
.
.
cnof one or more constraint c c1 c2 .
.
.
cn .
each constraint incis a first order formula in the following form t 1 p1 t t 2 p2 t .
.
.
t n n pn t where each pi t is a predicate over the model input variables and each i i tis a time domain.
recall from section that t is the time domain used to simulate m. an example constraint for the autopilot model discussed in section is the constraint c1defined as follows t alt mode t .
t hrottle t .
the constraint c1contains two predicates that respectively constrain the values of the input signals alt mode andthrottle of the autopilot model over the time domain .
letube a test input for a simulink model m and let cbe a constraint over the inputs of m. we write u cto indicate that the input usatisfies the constraint c. for example the input ufor theautopilot model and described using the diagrams in fig.
satisfies the constraint c1.
note that for simulink models test inputs are described as functions over a time domain t and similarly we define constraints cas a conjunction of predicates over the same time domain or its subsets.
leta c1 c2 .
.
.
cnbe an assumption for model m and letube a test input for m. the input usatisfies the assumption aif u a. for example consider the assumption a c1 c2where c1 t alt mode t h dg ref t c2 t alt mode t h dg ref t the input uin fig.
satisfies the assumption asince it satisfies the constraint c1.
letabe an assumption and let ube the set of all possible test inputs of m. we say u u is the valid input set ofmrestricted by the assumption aif it contains every input u u such that u a. let be a requirement for mthat we intend to verify.
recall from section that our search based testing framework works based on a fitness function fnthat is defined to derive test inputs violating agiven requirements .
for every test input uand its corresponding test output y our fitness function fn u y returns a value that determines the degree of violation or satisfaction of when mis executed for test input u. specifically following existing research on search based testing of simulink models we define the fitness function fnas a function that takes a value between such that a negative value indicates that the test inputs u reveals a violation of and a positive or zero value implies that the test input uis passing i.e.
does not show any violation of .
the fitness function fnallows us to distinguish between different degrees of satisfaction and failure and hence guide the generation of test inputs for simulink models within our search based testing framework.
when fnis positive a closer value to indicates that we are close to violating although not yet violating requirement while a value close to shows that the model is far from violating .
dually when fnis negative a fitness value close to shows a less severe failure than a value close to .
definition .
letabe an assumption let be a requirement for m and let fnbe the fitness function defined to assess requirement .
we say the degree of satisfaction of the requirement over model m restricted by the assumption aisv i.e.
a m v if v min u u fn u y where yis the test output for any test input u uanduis the valid input set of mrestricted by the assumption a. we say an assumption aisv safefor a model mand its requirement if a m v. as discussed earlier we define the fitness function such that a fitness value vlarger than or equal to 0indicates that the requirement under analysis is satisfied.
hence when an assumption ais0 safe the model mrestricted by asatisfies .
for a given model m a requirement and a given fitness value v we may have several assumptions that are v safe.
we are typically interested in identifying the weakest v safe assumption since the weakest assumption leads to the largest valid input set u and hence is less constraining.
let a1anda2be two different v safe assumptions for a model mand its requirement .
we say a1is more informative than a2ifa2 a1.
in this paper provided with a model m a requirement and a desired fitness value v our goal is to generate the weakest most informative v safe assumption.
we note that our approach while guaranteeing the generation of v safe assumptions does not guarantee that the generated assumptions are the most informative.
instead we propose heuristics to maximize the possibility of the generation of the most informative assumptions and evaluate our heuristics empirically in section .
implementation in the following we describe the implementation of each step of algorithm i.e.
the main loop of epicurus .
since our implementation relies on qvtrace which can not handle quantitative fitness values we are considering safe assumptions.
section .
describes alternative test case generation procedures for line of algorithm .
section .
presents our assumption generation procedure for line of algorithm .
section .
describes the model checking procedure for line of algorithm .
section .
presents our test case generation procedure ifbt for line of algorithm .esec fse november virtual event usa gaaloul menghi nejati briand wolfe .
test generation algorithm shows our approach to generate a test suite i.e.
a set of test inputs together with their fitness values.
note that epicurus iteratively builds a test suite and at each iteration it extends the test suite generated in the previous iteration.
to do so line copies the old test suite into the new test suite.
then within a for loop the algorithm generates one test input line in each iteration and executes the test input to compute its fitness value line .
the new test suite is finally returned line .
below we describe our test generation strategies as well as our fitness functions.
definition of the fitness function fn.
we use existing techniques on translating requirements into quantitative fitness functions to develop fncorresponding to each requirement .
fitness functions generated by these techniques serve as distance functions estimating how far a test is from violating and hence they can be used to guide the generation of test cases.
in addition we can infer from such fitness functions whether or not a given requirement is satisfied or violated by a given test case.
specifically if fn u y the output ygenerated by the test input u u1 u2.
.
.um satisfies and otherwise yanduviolate .
specifying test cases.
algorithm iteratively generates a new test input uifor the modelm.
sincemis a simulink model the algorithm should address the following test generation challenges it should generate inputs that are signals functions over time instead of single values since simulink model inputs are signals.
input signals should be meaningful for the model under analysis and should be such that they can be realistically generated in practice.
for example a signal representing an airplane throttle command is typically represented as a sequence of step functions and not as a high frequency sinusoidal signal.
to generate signals we use the approach of matlab that encodes signals using some parameters.
specifically each signal uu inuis captured by intu ru nu where intuis the interpolation function ru ris the input domain and nuis the number of control points.
provided with the values for these three parameters we generate a signal over time domain tas follows i we generatenucontrol points equally distributed over the time domain t i.e.
positioned at a fixed time distance i ii we assign randomly generated values cu cu .
.
.
cu nuwithin the domain ruto each control point and iii we use the interpolation function intuto generate a signal that connects the control points.
the interpolation functions provided by matlab includes among others linear piecewise constant and piecewise cubic interpolations but the user can also define custom interpolation functions.
to generate realistic inputs the engineer should select an appropriate value for the number of control points nu and choose an interpolation function that describes with a reasonable accuracy the overall shape of the input signals for the model under analysis.
based on these inputs the test generation procedure has to select which values cu cu .
.
.
cu nuto assign to the control points for each input uu.
for example the signals in fig.
2a have three control points respectively representing the values of the signals at time instants and .
the signals apen hdgmode altmode and throttle hdg ref turnknob pitchwheel are respectively generated using boolean and piecewise constant interpolations.algorithm test suite generation.
inputs .m the simulink model the property of interest tsold old test suite opt options outputs .
tsnew new test suite function tsnew gensuite m tsold opt tsnew tsold test suite initialization fori i opt.testsuitesize i ui gentest m tsold opt test case generation vi fn ui m ui execute of the test case tsnew tsnew uu vi add the test to the test suite end for return tsnew end function generating test cases.
the test suite generation technique uses a test case generation policy pto select values for control points related to each test input.
some test case generation policies such as adaptive random testing art and uniform random testing ur can be used to generate a diverse set of test inputs that are evenly distributed across the search space.
ur samples each control point value following a random uniform distribution and art randomly samples values from the search space by maximizing the distance between newly selected values and the previously generated ones hence increasing the distance between the sampled values and ensuring that they are evenly spread over the search space.
execution of the test cases.
our procedure uses the simulink simulator see section to generate output signals y m u associated with the generated test input u. using the fitness function fn we obtain the verdict pass fail value for each test input uand output yof the model under analysis.
for example the simulink simulator generates the output in fig.
2b from the input in fig.
2a.
the fitness value for this input and output computed based on the requirement 1 described in section is .
.
.
assumption generation we use machine learning to automatically compute assumptions.
specifically the function genassum see algorithm infers an assumption by learning patterns from the test suite data ts .
this is done by i learning a classification tree that predicts requirement satisfaction ii extracting from the tree a set of predicates defined over the control points of the input signals of the model under analysis and iii transforming the predicates into constraints over input signals as defined in section such that they can be fed as an assumption into qvtrace.
the steps i ii and iii which are fully integrated in the matlab framework are described as follows.
learning classification trees.
we use classification trees to mine an assumption from sets of test inputs labelled with pass fail verdict.
classification trees are a widely adopted technique to identify interpretable patterns from data .
recall from section .
that test inputs are captured in terms of value assignments to signal control points.
hence classification trees learn conditions on the values of signal control points.
more specifically we use themining assumptions for software components esec fse november virtual event usa function fitctree of matlab to build the trees.
this function implements the standard cart algorithm .
epicurus enables the users to select parameter values to configure the cart algorithm implemented by the fitctree function .
the user can select the values of these parameters by considering the characteristics of the model under analysis and some trial and error experiments.
fig.
reports an example of decision tree computed by the assumption generation procedure for the autopilot example when each model input is encoded using a single control point.
setting the parameters of the dt learning is about avoiding both underfitting and overfitting standard ml problems.
in this paper we use default parameters provided by the matlab library since they yield reasonable results.
we follow a standard procedure to extract conditions on control points from a classification tree .
each pure leaf labeled pass i.e.
each leaf containing test inputs satisfying yields a conjunctive predicate which is obtained by conjoining all the conditions on the path from the tree root to the leaf see below cu v1 .
.
.
cu q vk .
.
.
cz j vh where cx ydenotes the yth control point associated with input x and each condition cx y vsuch that andv ris a constraint over the control point cx y. for example in the above conjunction the control points cu 1andcu qare related to input u and the control point cz jis related to input z. from conjunctions of predicates to a qvtrace assumption.
the conjunctive predicates constrain control points.
before we can use them with our model checker qvtrace they have to be converted into constraints over signal variables as defined in section .
to do so we use the rules provided in table to convert each predicate over control points into constraints over signal variables.
specifically the rules in table are as follows when the conjunction includes cu j v cu j v the predicate cu j vis replaced by a constraint over input signal u using the cases and rules in table depending on the type of the relation .note that in this case the conjunction includes predicates over two adjacent control points related to the same input signal i.e.
cu jandcu j 1are two consecutive control points related to the input signal u .
for brevity in table we present only the cases for and and when the input uis a real signal.
the cases in which uis a boolean signal and 1and 2are are similar to the one reported in table and are presented in our online appendix .
intuitively the conversion rules in table assume that the consecutive control points are connected by a linear interpolation function.
while other functions can also be considered and custom functions can be defined by users we believe that linear interpolation functions provide a good compromise between simplicity and realism.
in our evaluation see section we assess the impact of our assumption on the effectiveness of our approach.
note that we only assume that consecutive control points are connected by a linear function to be able to generate an assumption over input signals.
otherwise input signals can be encoded using various nonlinear interpolation functions and our test generation step is able to generate input signals using any given interpolation function.
when the conjunction includes cu j v but no control point adjacent to cu jappears in the conjunction then the predicate cu j vis replaced by a constraint over input signal uusing the cases and rules in table depending on the type of the relation .in this case we assume that the resulting constraint holds from the time instant t1associated with the control point cu jto the time instant t1 i where iis the time step between two consecutive control points.
following the above rules we convert any conjunction of predicates over control points into a constraint cdefined over input signals.
note that provided with a classification tree we obtain a conjunction of predicates for every pure leaf labelled with a pass verdict.
the set of all conjunctions is then converted into an assumption a c1 c2 .
.
.
cnwhere each ciis obtained by translating one conjunction of predicates using the rules in table .
.
checking accuracy checking accuracy aims at verifying whether a given assumption isv safe.
to do so we rely on qvtrace which exhaustively verifies a given model constrained with some assumption against a formal requirement expressed in the qct language.
as discussed in section qvtrace generates four kinds of outputs.
when it returns no violation exists or no violation exists for k kmax we conclude that the given assumption aisv safe i.e.
the model under analysis when constrained by asatisfies the given formal requirement.
otherwise we conclude that the assumption is not v safe and has to be refined or modified.
.
ifbt important features boundary test learningv safe assumptions in our context requires a sufficiently large test suite which is necessarily generated by simulating the model under analysis a high number of times.
to reduce the number of test cases that have to be generated for assumption learning we propose a new test case generation strategy namely important features boundary test ifbt .
the idea is to generate test cases in areas of the input domain that are more informative for the ml procedure used to learn v safe assumptions.
we make the following conjectures conj the values assigned to some control points have a higher impact on the fitness value than the values assigned to others.
identifying such control points and focusing the search on them enables more effective learning of v safe assumptions.
conj generating test cases in boundary areas of the input domain where the fitness value changes from being lower than v to being greater than venables more effective learning of v safe assumptions.
based on the above intuitive conjectures ifbt generates a test suite by following the steps of algorithm detailed below.
step line we build a regression tree from the previously generated test suite tsold that describes the relationship between the values assigned to the control points i.e.
the features of the regression tree and the fitness value.
we choose to use regression trees since we want to learn the impact of control point values on the continuous fitness value and this is therefore a regression problem.
the leaves of the tree contain test cases that are characterized by similar fitness values for control points.
step line this step follows from conjecture conj and attempts to generate boundary test cases.
to do so among all leaves in the tree we pick the two leaves with average fitness values thatesec fse november virtual event usa gaaloul menghi nejati briand wolfe table generating the predicates of the constraint.
condition qct clause condition qct clause case case two consecutive control pointscu j v1 cu j v2 t1it2uky k v1v2t12 t t1 t1 i u t y t t t1 i t2 u t y t cu j v1 cu j v2 u1d716 u1d716t1it2kt12 uv1v2y k t t1 t1 i u t y t t t1 i t2 u t y t case case cu j v1 cu j v2 uv1v2t1it2kt12 y k t t1 t1 i u t y t t t1 i t2 u t y t cu j v1 cu j v2 u1d716 u1d716t1it2kt12 uv1v2y k t t1 t1 i u t y t t t1 i t2 u t y t case case one control point cu j v1 uv1v2t1it2kt12 y k t t1 t1 i u t v1 cu j v1 uv1v2t1it2kt12 y k t t1 t1 i u t v1 t1 i j and t2 i j andy t v2 v1 i t t1 v1 and i t2 t1 time distance.
algorithm ifbt important features boundary test.
inputs .m the simulink model the property of interest tsold old test suite opt options outputs .
tsnew new test suite function tsnew gensuite m tsold opt tsnew tsold rt genregressiontree tsold learn a regression tree tc gettests rt v get tests on leaves feat rng getimpf rt opt.num get features fori i opt.testsuitesize i ui gentest tc.next feat rng opt test case generation vi fn ui m ui execute of the test case tsnew tsnew uu vi add the test to the test suite endfor return tsnew end function are the closest to the selected vthreshold that is in our case as described above one being below the threshold and the other one above.
we extract the test cases tc associated with these nodes.
these test cases are the ones closest to boundary where the fitness value changes from being greater than vto being lower than vand are therefore used to generate the new test cases in the following steps of the algorithm.
step line we save in the variable feat the subset of the opt.num most important features of the regression tree.
this step follows from conjecture conj as feature importance captures how much the value assigned to the feature control point influences the fitness value.
furthermore for every control point cu jthat belongs to the set of features feat it computes a range saved inrng associated with the control point based on the conditions that constrain the control point cu jin the regression tree rt.
for every condition cu j v1that constrains control point cu jin rt the interval is added to the range rng associated with the control point cu j. for example if a constraint cu 2associated with control point cu 1is present in the regression tree rt and opt.perc the interval is added to the range rng associated with cu .
this ranges will be used to generate test cases in the area of the input domain where the fitness changes from being lower than vto being greater than v following from conjecture conj .
step lines we create a set of opt.testsuitesize new test cases from the test cases in tc as follows.
we iteratively select in sequence a test case tc.next in tc.
a new test case is obtained from tc.next by changing the values of the control points in feat according to their ranges in rng using either ur or art sampling.
we use the acronyms ifbt ur and ifbt art to respectively indicate the sampling strategy each alternative relies on.
evaluation in this section we empirically evaluate epicurus by answering the following research questions effectiveness and efficiency rq1 which test case generation policy among ur art ifbt ur and ifbt art helps learn assumptions most effectively and efficiently?
with this question we investigate our four test generation policies i.e.
ur and art discussed in section .
and ifbt ur and ifbt art discussed in section .
and determine which policy can help compute the most v safe assumptions that are the most informative while requiring the least amount of time.
usefulness rq2 can epicurus generate assumptions for real world simulink models within a practical time limit?
in this question we investigate if epicurus when used with the best test generationmining assumptions for software components esec fse november virtual event usa table identifier name description number of blocks of the simulink model blocks number of inputs inputs and number of requirements reqs of our study subjects.
id name description blocks inputs reqs tu tustin a numeric model that computes integral over time.
reg regulator a typical pid controller.
tt two tanks a two tanks system where a controller regulates the incoming and outgoing flows of the tanks.
fsm finite state machine a finite state machine that turns on the autopilot mode in case of some environment hazard.
policy identified in rq1 can generate v safe assumptions for our real world study subject models within a practical time limit.
implementation and data availability.
we implemented epicurus as a matlab standalone application and used qvtrace for checking the accuracy of the assumptions.
the implementation models and results are available at .
study subjects.
we consider eleven models and requirements provided by qra corp a verification tool vendor active in the aerospace automotive and defense sectors .
qra is a canada based company specialized in the development of enterprise tools for early stage validation and verification of critical systems.
the models and the requirements have been used in a recent study to compare model testing and model checking .
among the requirements only requirements on four models could be handled by qvtrace prerequisite and neither the requirements nor their negation could be proven by qvtrace prerequisite .
out of the requirements could not be handled by qvtrace violating prerequisite and violated prerequisite .
for requirements their simulink models were not supported by qvtrace.
for requirements qvtrace returned an inconclusive verdict due to scalability issues.
also qvtrace could prove requirements and refute one requirement for every input.
we can conclude that for requirements epicurus cannot be applied due to the technical issues with mc.
however epicurus is applicable to requirements though in of the cases mc is sufficient.
we note that epicurus is complementary to mc but since it relies on mc as one of its components it also inherits its limitations i.e.
only model components handled by mc can be targeted by epicurus.
thus we retain only four models and 18requirements.
table describes the four models the number of blocks and the inputs of each model and the number of requirements for each model.
epicurus is only needed when prerequisite andprerequisite hold since otherwise there is no need to generate assumptions.
prerequisite however is related to the scalability issues of applying qvtrace or mc in general to large complex simulink models.
experiment design.
to answer rq1 andrq2 we perform the experiments below.
we execute epicurus using the ur art ifbt ur and ifbtart test case generation policies.
for each requirement and study subject we execute different experiments considering input signals with one ip two ip and three ip control points.
we set the number of new test cases considered at every iteration to opt.testsuitesize see algorithms and .
we considered a maximum number of iterations max it see algorithm as this is a common practice to compare test case generation algorithms .for ifbt ur and ifbt art we set the value opt.num of the most important features to consider for test case generation as follows.
for iterations 1to10 opt.num is set to one meaning that only the most important feature is considered.
for iterations 10to20 opt.num is set to two and iterations 20to30 opt.num is equal to the number of features of the decision tree.
we do not know a priori the number of features that will be constrained by the final assumption.
the above strategy to set opt.num starts by focusing on the most important features and gradually enlarges the set of considered features if no valid assumptions are found.
we set the value opt.perc used by ifbt ur and ifbt art to compute the next range to be considered to1 counter.
this value ensures that the size of the next interval to be considered is decreasing with the number of iterations counter .
the intuition is that the more iterations are performed the closer ifbt is to computing the v safe assumption and thus a more restricted interval can be considered.
we repeated every experiment 50times to account for the randomness of test case generation.
we recorded whether epicurus was able to compute a v safe assumption the computed v safe assumption itself and its execution time.
to compare efficiency we consider the average execution time avg time of each test case generation policy across different experiments.
to compare effectiveness we consider i the percentage of experiment runs among the executed v safe in which each test case generation policy is able to compute a v safe assumption and ii how informative the assumptions learned by different test case generation policies are in relative terms.
to measure the latter we considered each assumption learned by a test case generation policy.
we computed the number of times this assumption was more informative than another assumption learned with a different test case generation policy for the same model requirement experiment and number of control points.
we define the information index inf index of a test case generation policy as the sum across the different assumptions learned with that policy of the number of times the assumption is more informative than another assumption learned with a different test case generation policy.
to check whether an assumption a1is more informative than a2 we check if a2 a1is valid i.e if a2 a1is a tautology .
this is done by checking whether a2 a1 is satisfiable.
if a2 a1 is unsatisfiable then a2 a1is a tautology.
the satisfiability of a2 a1 is verified by an mitl satisfiability solver recently provided as a part of the tack model checker .
we set a timeout of two minutes for our satisfiability solver.
if an unsat result is returned within this time limit a2 a1holds otherwise either a2 a1 is satisfiable or a longer execution time is needed by the satisfiability checker.esec fse november virtual event usa gaaloul menghi nejati briand wolfe as a complementary analysis we repeat the experiment above but instead of fixing the number of iterations across different epicurus runs we set a one hour time bound for each run of epicurus on each requirement.
we consider this to be a reasonable time for learning assumptions in practical settings.
note that we still execute ifbt ur for a maximum of 30iterations.
however if the maximum number of iterations was reached without finding a valid assumption and the execution time was still less than one hour epicurus was re executed.
the motivation is to re start epicurus every iterations so that it does not focus its search on a portion of the search space that has no chance of gathering useful information to learnv safe assumptions due to a poor choice of initial inputs.
running all the experiments required approximately days.
.
rq1 effectiveness and efficiency the scatter plot in fig.
depicts the results for rq1 obtained when comparing test generation strategies in terms of effectiveness and execution time when running epicurus a maximum of iterations.
the x axis indicates the average execution time avg time our efficiency metric.
the lower this time the more efficient a test case generation policy.
the y axis indicates the percentage of cases v safe across runs for each requirement for which each test case generation policy could compute a v safe assumption.
the higher the value the higher the effectiveness of a test case generation policy.
each point of the scatter plot is labeled with the information index inf index associated to that policy.
the higher this index the more informative the v safe assumptions computed with a test case generation policy.
as shown in fig.
ifbt ur is the best test case generation policy.
ifbt ur has indeed both the lowest average execution time avg time and the highest v safe percentage.
ifbt ur generates more valid assumptions than ur and art and requires less time.
it is only slightly better than ifbt art thus showing that the main driving factor here is ifbt.
furthermore ifbt ur s information index inf index is higher than those of the other policies.
regarding the impact of using ifbt fig.
also shows that the difference between ur and ifbt ur is small in terms of v safe though large in terms of the execution time.
however when fixing the execution time to a maximum of one hour instead of iterations ifbt ur and ur identify a v safe assumption respectively in and of the requirements.
that is when provided with an equal execution time budget ifbt ur outperforms ur by learning a v safe assumption for more requirements.
the answer to rq1 is that among the four test case generation policies we compared ifbt ur learns the most v safe assumptions in less time.
further the assumptions learned by ifbt ur are more informative than those learned by other test generation policies.
.
rq2 usefulness to answer rq2 we use ifbt ur the best test case generation policy identified by rq1.
on average one epicurus run can compute a v safe assumption within one hour for of the requirements.
2we executed our experiments on the hpc facilities of the university of luxembourg .
the parallelization reduced the experiments time to approximately five days.
avg time s 545658606264v safe ur art ifbt ur ifbt artfigure comparison of the test case generation policies.
further epicurus learns assumptions that are not vacuous and all the generated assumptions had a non empty valid input set i.e.
none of the requirements was vacuously satisfied by the computed assumption.
across all runs which take for ifbt ur around four hours per requirement epicurus is able to compute a v safe assumption for all the requirements of our four simulink models.
the average number of constraints in an assumption is .
with .4predicates on average.
from that we can conclude that the computed assumptions are relatively simple thus suggesting they are easy to understand and that epicurus does not generate much accidental complexity.
the answer to rq2 is that epicurus can learn non vacuous and short assumptions for all the requirements of our subject models within reasonable time.
discussion and threats to validity our empirical evaluation confirms that our conjectures conj andconj hold and that the effectiveness of epicurus is adequate for practical usages.
in the following we discuss the practical implications of epicurus.
epicurus learns classification trees and converts them into classification rules.
directly learning classification rules could be a better solution as it may yield more concise assumptions.
however as classification rules are not supported by matlab we would have to rely on external tools e.g.
weka to generate them and further our solution based on classification trees already works reasonably well.
decision trees and decision rules can only learn predicates defined over single features i.e.
single control points .
that is all the learned predicates are in the following form c v. hence they are not suited to infer predicates capturing relationships among two or more features i.e.
control points .
while this was not a limitation in our work our approach can be extended to infer more complex assumptions using other machine learning techniques e.g.
more expressive rules or clustering .
alternatively we can use genetic programming to learn more expressive assumptions.
epicurus generates assumptions using the rules in table that assume that consecutive control points are connected using a linear interpolation function.
our evaluation shows that this assumption provides a good compromise between simplicity and realism.
the rules in table can be expanded to consider more complex interpolation functions in particular when we have specific domain knowledge about the shapes of different input signals.mining assumptions for software components esec fse november virtual event usa our solution combines different techniques.
let nbe the number of instances and mbe the number of input features the time complexity of the decision tree induction is o m n lo n o n lo n .
the time complexity of running qvtrace is exponential in the size of the smt instance to be solved.
the time complexity of ur and art test case generation is linear in the number of tests to be generated.
for ifbt the time complexity of the decision tree induction comes in addition to the time complexity of ur and art.
as shown in our evaluation our solution was sufficiently efficient to effectively analyze our study subjects.
our results are subject to the following threats to validity.
external validity.
the selection of the models used in the evaluation and the features contained in those models are a threat to external validity as it influences the extent to which our results can be generalized.
however i the models we considered have been previously used in the literature on testing of cps models ii they represent realistic and representative models of cps systems from different domains and iii our results can be further generalized by additional experiments with diverse types of systems and by assessing epicurus over those systems.
internal validity.
using the same models to select the optimal test generation policy rq1 and to evaluate epicurus rq2 is a potential threat to the internal validity.
however since the test generation policy is not optimized for any particular model it is a good general compromise among many different models.
related work this section compares epicurus with the following threads of research i verification testing and monitoring cps ii compositional and assume guarantee reasoning for cps iii learning assumptions for software components and iv learning the values for unspecified parameters.
verification testing and monitoring of cps.
approaches to verifying testing and monitoring cps have been presented in the literature e.g.
.
these approaches however often assume that assumptions characterising the valid ranges of test inputs are already specified.
our work in contrast automatically identifies implicit assumptions on test inputs.
such assumptions are an important pre requisite to ensure testing and verification results are not overly pessimistic or spurious .
compositional reasoning.
assume guarantee reasoning and design by contract frameworks have been extensively discussed in the literature e.g.
.
some recent work extends such type of reasoning to signal based modeling formalisms such as simulink and analog circuits e.g.
.
our work is complementary as the assumptions learned by epicurus can be used within these existing frameworks.
our work also differs from assume guarantee testing where assumptions defined during software design are verified during test case execution .
learning assumptions.
several approaches to automatically learn assumptions a.k.a supervisory control problem have been proposed e.g.
.
those approaches however are not applicable to signal based formalisms e.g.
simulink models and are solely focused on components specified in finitestate machines.
our work bears some similarities with templatebased specification mining .
however the ltl gr specifications used in that work are substantially different and less expressive than signal based assumptions generated in our work.
further we rely on testing to generate the data used to learn assumptions as compared to model checking testing can generate a larger amount of data in less time.
one interesting idea is to combine model checking and model testing to improve the quality and performance of assumption learning.
our approach is related to a recent study focused on the complementarity between model testing and model checking for fault detection purposes.
learning parameters.
approaches that learn requirement parameters from simulations have been presented in the literature .
in contrast to those approaches our work is explicitly tailored to learning assumptions.
our technique can be considered as an extension of counterexample guided inductive synthesis where learned assumptions are exhaustively verified using an smt based model checker.
furthermore our approach considers signal based formalisms that are widely used in the cps industry and extracts assumptions from test data.
test case generation allows us to efficiently produce a large amount of data to feed our machine learning algorithm and derive informative v safe assumptions.
conclusion in this paper we proposed epicurus an approach to automatically infer environment assumptions for software components such that they are guaranteed to satisfy their requirements under those assumptions.
our approach combines search based software testing with machine learning decision trees to learn assumptions.
in contrast to existing work where assumptions are often synthesized based on logical inference frameworks epicurus relies on empirical data generated based on testing to infer assumptions and is hence applicable to complex signal based modeling notations e.g.
simulink commonly used in cyber physical systems.
in addition we proposed ifbt a novel test generation technique that relies on feedback from machine learning decision trees to guide the generation of test cases by focusing on the most important features and the most informative areas in the search space.
our evaluation shows that epicurus is able to infer assumptions for all the requirements in our subject studies and in of the cases the assumptions are learned within just one hour.
further ifbt outperforms simpler test generation techniques aimed at creating test input diversity as it increases the number and the quality of the generated assumptions while requiring less time for test generation.
for future we plan to extend our work and eliminate some of the limitations of epicurus based on the ideas summarized in section .