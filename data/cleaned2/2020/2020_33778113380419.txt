symbolic verification of message passing interface programs hengbiao yu1 zhenbang chen1 xianjin fu1 j iw a n g1 zhendong su3 jun sun4 chun huang1 wei dong1 1college of computer national university of defense technology changsha china 2statekeylaboratoryofhighperformancecomputing nationaluniversityofdefensetechnology changsha china 3department of computer science eth zurich switzerland 4school of information systems singapore management university singapore hengbiaoyu zbchen wj nudt.edu.cn zhendong.su inf.ethz.ch junsun smu.edu.sg wdong nudt.edu.cn abstract messagepassingisthestandardparadigmofprogramminginhighperformancecomputing.however verifyingmessagepassinginterface mpi programsischallenging duetothecomplexprogram features suchasnon determinismandnon blockingoperations .
inthiswork wepresentmpisymbolicverifier mpi sv thefirst symbolic execution based tool for automatically verifying mpi programswith non blockingoperations.mpi sv combinessymbolic execution and model checking in a synergistic way to tackle the challenges in mpi program verification.
the synergy improves the scalability and enlarges the scope of verifiable properties.
we have implemented mpi sv1and evaluated it with real world mpi verification tasks.
the pure symbolic execution based technique successfully verifies out of the tasks within one hour while in comparison mpi sv verifies tasks .
on average compared with pure symbolic execution mpi sv achieves 19x speedupsonverifyingthesatisfactionofthecriticalpropertyand 5x speedups on finding violations.
ccs concepts software and its engineering software verification and validation keywords symbolic verification symbolic execution model checking message passing interface synergy acm reference format hengbiao yu zhenbang chen xianjin fu ji wang zhendong su jun sun chunhuang andweidong.
.symbolicverificationofmessagepassing interfaceprograms.in 42ndinternationalconferenceonsoftwareengineering icse may23 seoul republicofkorea.
acm newyork ny usa pages.
the first two authors contributed equally to this work and are co first authors.
zhenbang chen and ji wang are the corresponding authors.
1mpi sv is available at permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn ... .
introduction nowadays an increasing number of high performance computing hpc applications have been developed to solve large scale problems .
the message passing interface mpi is the current defactostandardprogrammingparadigmfordevelopinghpcapplications.manympiprogramsaredevelopedwithsignificanthuman effort.
one of the reasons is that mpi programs are error prone because of complex program features such as non determinism andasynchrony andtheirscale.improvingthereliabilityofmpi programs is challenging .
program analysis is an effective technique for improving program reliability.
existing methods for analyzing mpi programs can be categorized into dynamic andstaticapproaches.
most existingmethodsaredynamic suchasdebugging correctness checking and dynamic verification .
these methodsneed concreteinputstorunmpiprogramsandperformanalysisbased on runtime information.
hence dynamic approaches may miss input relatedprogramerrors.staticapproaches analyze abstract models of mpi programs and suffer from false alarms manualeffort andpoorscalability.tothebestofourknowledge existingautomatedverification approachesformpiprogramseither do not support input related analysis or fail to support the analysis of the mpi programs with non blocking operations the invocations of which do not block the program execution.
non blocking operations are ubiquitous in real world mpi programs for improving the performance but introduce more complexity to programming.
symbolicexecution supportsinput relatedanalysisby systematically exploring a program s path space.
in principle symbolicexecutionprovidesabalancebetweenconcreteexecutionand static abstraction with improved input coverage or more precise program abstraction.
however symbolic execution based analyses suffer frompath explosiondue to theexponential increaseof programpaths w.r.t.thenumberofconditionalstatements.theproblem isparticularlyseverewhenanalyzingmpiprogramsbecauseofparallelexecutionandnon deterministicoperations.existingsymbolic execution based verification approaches do not support non blocking mpi operations.
in this work we present mpi sv a novel verifier for mpi programs bysmartlyintegrating symbolic executionand modelchecking.
as far as we know mpi sv is the first automated verifier thatsupportsnon blockingmpiprogramsandtheverificationof ltl properties.
mpi sv uses symbolic execution to extract path level models from mpi programs and verifies the models w.r.t.
the expected properties by model checking .
the two techniques complement each other symbolic execution abstracts ieee acm 42nd international conference on software engineering icse thecontrolanddatadependenciestogenerateverifiablemodelsfor modelchecking and modelcheckingimprovesthescalabilityof symbolic execution by leveragingthe verification results to prune redundant paths and enlarges the scope of verifiable properties ofsymbolic execution.
in particular mpi sv combines two algorithms symbolic execution of non blocking mpi programs with non deterministic operations and modeling and checking the behaviors of anmpi program path precisely.
to safely handle non deterministic operations thefirstalgorithmdelaysthemessagematchingsofnon deterministicoperationsasmuchaspossible.thesecondalgorithm extracts a model from an mpi program path.
the model represents all the path s equivalent behaviors i.e.
the paths generated by changingtheinterleavingsandmatchingsofthecommunication operationsinthepath.wehaveprovedthatourmodelingalgorithm ispreciseandconsistentwiththempistandard .wefeedthe generated models from the second algorithm into a model checker to perform verification w.r.t.the expected properties i.e.
safety andlivenessproperties in linear temporal logic ltl .
if the extractedmodelfromapath psatisfiestheproperty p sequivalent pathscanbesafelypruned otherwise ifthemodelcheckerreportsacounterexample aviolationof isfound.thisway wesignificantly boost the performance of symbolic execution by pruning a large setofpathswhichareequivalenttocertainpathsthathavebeen already model checked.
we have implemented mpi sv for mpi c programs based on cloud9 andpat .wehaveusedmpi svtoanalyze12realworld mpi programs totaling 47k lines of code loc three are beyondthescalethatthestate of the artmpiverificationtoolscan handle w.r.t.the deadlockfreedom propertyand non reachability properties.
for the 111deadlock freedom verification tasks when we set the time threshold to be an hour mpi sv can complete tasks i.e.
deadlock reported or deadlock freedom verified while puresymbolicexecutioncancomplete61tasks.forthe100completed tasks mpi sv achieves on average 19x speedups on verifyingdeadlockfreedomand5x speedupsonfindingadeadlock.
the main contributions of this work are a synergistic framework combining symbolic execution and model checking for verifying mpi programs.
a method for symbolic execution of non blocking mpi programswithnon deterministicoperations.themethodisformallyproventopreservethecorrectnessofverifyingreachabilityproperties.
aprecisemethodformodelingtheequivalentbehaviorsofan mpipath whichenlargesthescopeoftheverifiableproperties and improves the scalability.
a tool for symbolic verification of mpi c programs and an extensive evaluation on real world mpi programs.
illustration inthissection wefirstintroducempiprogramsanduseanexample to illustrate the problem that this work targets.
then we overview mpi sv informally by the example.proc varr t r e comm proc proc ifeproc elseproc while edoproc comm ssend e send e recv e recv barrier isend e r irecv e r irecv r wait r figure syntax of a core mpi language.
.
mpi syntax and motivating example mpi implementations such as mpich and openmpi provide the programming interfaces of message passing to support thedevelopmentofparallelapplications.anmpiprogramcanbe implementedindifferentlanguages suchascandc .without loss of generality we focus on mpi programs written in c. let t beasetoftypes nasetofnames and easetofexpressions.for simplifying the discussion we define a core language for mpi processesinfigure1 where t t r n and e e.anmpiprogram mpisdefinedby a finitesetof processes proc i i n .for brevity we omit complex language features such as the messagesin the communication operations and pointer operations although mpi sv does support real world mpi c programs.
the statement varr tdeclares avariable rwith type t. the statement r eassigns the value of expression eto variable r. aprocesscanbeconstructedfrombasicstatementsbyusingthe composition operations including sequence condition and loop.
for brevity we incorporate the key message passing operations in the syntax where eindicates the destination process s identifier.
these message passing operations can be blockingornon blocking.
first we introduce blocking operations ssend e sendsamessagetothe ethprocess andthesending processblocksuntilthemessageisreceivedbythedestination process.
send e sends a message to the eth process and the sending processblocksuntilthemessageiscopiedintothesystembuffer.
recv e receives a message from the eth process and the receiving process blocks until the message from the eth process is received.
recv receivesamessagefrom anyprocess andthereceiving process blocks until a message is received regardless which process sends the message.
barrier blocks the process until all the processes have called barrier.
wait r theprocessblocksuntiltheoperationindicatedby ris completed.
arecv operation called wildcardreceive mayreceiveamessage from different processes under different runs resulting innon determinism.
the blocking of a send e operation depends on the size of the system buffer which may differ under differentmpiimplementations.forsimplicity weassumethatthesize of the system buffer is infinite.
hence each send e operation returnsimmediately after being issued.
note that our implementation allows users to configure the buffer size.
to improve the performance the mpi standard provides non blockingoperations to overlap computations and communications.
1249p0 p1 p2 p3 send if x!
a send send recv else irecv req recv figure an illustrative example of mpi programs.
isend e r sendsa message to the eth process and the operation returnsimmediately afterbeing issued.the parameter ris the handle of the operation.
irecv e r receives a message from the eth process and the operation returns immediately after being issued.
irecv r is the non blocking wildcard receive.
the operations above are key mpi operations.
complex operations such as mpi bcast andmpi gather can beimplemented by composing these key operations.
the formal semantics of the core languageisdefinedbasedoncommunicatingstatemachines csm .wedefineeachprocessasacsmwithanunboundedreceiving fifoqueue.forthesakeofspacelimit theformalsemanticscan be referred to .
an mpi program runs in many processes spanned across multiplemachines.theseprocessescommunicatebymessagepassingtoaccomplishaparalleltask.besidesparallelexecution thenondeterminism in mpi programs mainly comes from two sources inputs whichmayinfluencethecommunicationthroughcontrol flow and wildcard receives which lead to highly nondeterministic executions.
consider the mpi program in figure .
processes p0 p2and p3only send a message to p1and then terminate.
for process p1 if inputxisnotequal to a p1receives a message from p0in a blocking manner otherwise p1uses a non blocking wildcard receive to receive a message.
then p1receives a message from p3.
whenxis a and irecv req receives the message from p3 adeadlock occurs i.e.
p1blocks at recv and all the other processes terminate.
hence to detect the deadlock we need to handlethenon determinismcausedbytheinput xandthewildcard receive irecv req .
to handle non determinism due to the input a standard remedy is symbolic execution .
however there are two challenges.
the first one is to systematically explore the paths of an mpi program withnon blockingandwildcardoperations whichsignificantlyincrease the complexity of mpi programs.
a non blocking operation does not block but returns immediately causing out of order completion.
the difficulty in handling wildcard operations is to get all thepossiblymatchedmessages.thesecondoneisto improvethe scalabilityofthesymbolicexecution.
symbolicexecutionstruggles withpathexplosion.mpiprocessesrunconcurrently resultingin an exponential number of program paths w.r.t.the number of processes.furthermore thepathspaceincreasesexponentiallywith the number of wildcard operations.
.
our approach mpi svleveragesdynamicverification andmodelchecking to tackle the challenges.
figure shows mpi sv s basic framework.an mpi program csp model checkerviolation pathsymbolic executor state pruner violation mpi svyesnoyes propertytest case csp modelno figure the framework of mpi sv.
theinputsofmpi svareanmpiprogramandanexpectedproperty e.g.
deadlockfreedom expressedinltl.mpi svusesthebuilt in symbolic executor to explore the path space automatically andchecks the property along with path exploration.
for a path that violates the property called a violation path mpi sv generatesa test case for replaying which includes the program inputs the interleavingsequenceofmpioperationsandthematchingsofwildcard receives.
in contrast for a violation free pathp mpi sv builds acommunicatingsequentialprocess csp model whichrepresents the paths which can be obtained based on pby changing the interleavingsandmatchingsofthecommunicationoperationsin p. then mpi sv utilizes a csp model checker to verify w.r.t.the property.ifthemodelcheckerreportsacounterexample aviolation is found otherwise if satisfies the property mpi sv prunes all behaviors captured by the model so that they are avoided by symbolic execution.
sincempiprocessesarememoryindependent mpi svwillselectaprocesstoexecuteina round robin mannertoavoidexploring all interleavings of the processes.
a process keeps running until it blocksorterminates.whenencounteringanmpioperation mpi sv records the operation instead of executing it and the mes sage matching.
when every process blocks or terminates and at leastoneblockedprocessexists mpi svmatchestherecordedmpi operationsoftheprocesses w.r.t.thempistandard .theintuition behind this strategy is to collect the message exchanges as thoroughlyaspossible whichhelpsfindpossiblematchingsforthe wildcard receive operations.
consider the mpi program in figure and thedeadlock freedom property.
figure shows the symbolic execution tree where the node labels indicate process communications e.g.
means that p1receives a message from p3.
mpi sv first symbolically executes p0 which only sends a message to p1.
thesend operationreturnsimmediatelywiththeassumption of infinite system buffers.
hence p0terminates and the operation send is recorded.
then mpi sv executes p1and explores both branches of the conditional statement as follows.
true branch x nequal a .in this case p1blocks at recv .
mpi svrecordsthereceiveoperationfor p1 andstartsexecuting p2.
likep0 p2executesoperation send andterminates afterwhich p3is selected and behaves the same as p2.
afterp3terminates the globalexecutionblocks i.e.
p1blocksandalltheotherprocesses terminate.
when this happens mpi sv matches the recorded operations performs the message exchanges and continues to execute thematchedprocesses.the recv inp1shouldbematchedwith thesend inp0.
after executing the send and receive operations mpi svselects p1toexecute because p0terminates.then p1blocksat recv .same asearlier theglobalexecutionblocks 1250x a x a p1 p2 p3p4 deadlock figure the example program s symbolic execution tree.
andoperationmatchingneedstobedone.
recv ismatchedwith thesend inp3.
after executing the recv andsend operations all the processes terminate successfully.
path p1in figure is explored.
false branch x a .the execution of p1proceeds until reachingtheblockingreceive recv .additionally thetwoissued receiveoperations i.e.
irecv req andrecv arerecorded.
similartothetruebranch wheneveryprocessblocksorterminates wehandleoperationmatching.here p0 p2andp3terminate and p1 blocks at recv .irecv req should be matched first because ofthenon overtaken policyinthempistandard .therearethree sendoperationcandidatesfrom p0 p2andp3 respectively.mpi sv forks a state for each candidate.
suppose mpi sv first explores the state where irecv req is matched with p0 ssend .
after matchingandexecuting p1 srecv andp3 ssend thepath terminates successfully which generates path p2in figure .
violation detection.
mpi svcontinuestoexploretheremaining two cases.
without csp based boosting the deadlock would be found in the last case i.e.
p4in figure where irecv req is matched with p3 ssend andp1blocks because recv has no matchedoperation.
mpi svgenerates a cspmodel based on the deadlock free path p2wherep1 sirecv req is matched withp0 ssend .
each mpi process is modeled as a csp process and all the csp processes are composed in parallel to form .
notably in we collect the possible matchings of a wildcard receive through statically matching the arguments of operations in thepath.additionally therequirementsinthempistandard i.e.
completes before relations are also modeled.
a csp model checkerthenverifiesdeadlockfreedomfor .themodelchecker reports a counterexample where irecv req is matched with thesend inp3.
mpi sv only explores twopaths for detecting the deadlock and avoids the exploration of p3andp4 indicated by dashed lines .
pruning.
because the csp modeling is precise cf.
section inadditiontofindingviolationsearlier mpi svcanalsoperform pathpruningwhenthemodelsatisfiestheproperty.supposewe change theprogram in figure 2to bethe onewhere the laststatementofp1isarecv operation.then theprogramis deadlock free.thetruebranch x nequal a has2paths becausethelastwildcard receivein p1hastwomatchings i.e.
p2 ssendand p3 ssend and p0 s send has been matched by p1 srecv .
the false branch x a has paths because the first wildcard receive has matchings send operations from p0 p2andp3 and the last wildcard receive has matchings because the first wildcard receive has matched one send operation .
hence in total there are paths i.e.
if we usepure symbolicexecution.
incontrast with model checking mpi sv only needs paths to verify that the program is deadlock free.
for each branch the generated model is verified to be deadlock free so mpi sv prunes the candidate states forked for the matchings of the wildcard receives.
properties.
because our csp modeling encodes the interleavingsofthempioperationsinthempiprocesses thescopeofthe verifiableproperties isenlarged i.e.
mpi sv canverifysafetyand liveness properties in ltl.
suppose we change the property tobe the one that requires the send operation in p0should be completedbeforethe send operationin p2.actually thesend operationin p2canbecompletedbeforethesendoperationin p0 due to the nature of parallel execution.
however puresymbolic execution fails to detect the property violation.
in contrast withthe help of csp modeling when we verify the model generatedfrom the first path w.r.t.the property the model checker gives a counterexample indicating that a violation of the property exists.
symbolic verification method in this section we present our symbolic verification framework and then describe mpi sv s symbolic execution method.
.
framework given an mpi program mp proc i i n a statesc inmp s symbolic execution is composed by the states of processes i.e.
s0 ... sn and each mpi process s state is a tuple m stat pc f b r wheremmaps each variable to a concrete value or a symbolic value statis the next program statement to execute pcis the process s path constraint fis the flag of process status belonging to active blocked terminated band rare infinite buffers for storing the issued mpi operations not yet matched and the matched mpi operations respectively.
weuse si scto denote that siis a process state in the global state sc.
an element elemofsican be accessed by si.elem e.g.
si.fis theithprocess sstatusflag.inprinciple astatementexecutionin any process advances the global state making mp s state space exponentialtothenumberofprocesses.weusevariable seqidefined inmto record the sequence of the issued mpi operations in proc i and seq sc to denote the set seqi i n of global statesc.
global state sc s path condition denoted by sc.pc i st h e conjunctionofthepathconditionsof sc sprocesses i.e.
logicalandtext.
si scsi.pc.
algorithm shows the details of mpi sv.
we use worklistto store the global states to be explored.
initially worklistonly containssinit composedoftheinitialstatesofalltheprocesses and eachprocess sstatusis active.atline4 selectpicksastatefrom worklistas the one to advance.
hence selectcan be customized with different search heuristics e.g.
depth first search dfs .
then scheduler selects an active process proc ito execute.
next execute cf.algorithm2 symbolicallyexecutesthestatement stat iinproc i and may add new states into worklist.
this procedure continues untilworklistis empty i.e.
all the paths have been explored detectingaviolationortimeout omittedforbrevity .afterexecuting stat i ifalltheprocessesinthecurrentglobalstate scterminate i.e.
a violation free path terminates we use algorithm to generate a csp model from the current state line .
then we use a csp modelcheckertoverify w.r.t.
.if satisfies denotedby 1251algorithm symbolic verification framework mpi sv mp sym data mpis proc i i n is a property and sym is a set of symbolic variables 1begin 2worklist sinit 3whileworklist nequal do sc select worklist mi stat i pci fi bi ri scheduler sc execute sc proc i stat i sym worklist if si sc si.f terminated then generatecsp sc modelcheck if then worklist worklist sp worklist sp.pc sc.pc end else if negationslash then reportviolation andexit end end 17end 18end we prune the global states forked by the wildcard operations along thecurrentpath line11 i.e.
thestatesin worklistwhosepathconditions imply sc s path condition otherwise if the model checker gives a counterexample we report the violation and exit line .
sincempiprocessesarememoryindependent weemploypartial orderreduction por toreducethesearchspace.
scheduler selectsaprocessina round robin fashionfromthecurrentglobal state.
in principle scheduler starts from the active mpi process withthesmallestidentifier e.g.
proc0atthebeginning andanmpi processkeepsrunninguntilit isblockedorterminated.then the next active process will be selected to execute.
such a strategy significantlyreducesthepathspaceofsymbolicexecution.then with the help of csp modeling and model checking mpi sv can verify more properties i.e.
safety and liveness properties in ltl.
the details of such technical improvements will be given in section .
.
blocking driven symbolic execution algorithm shows the symbolic execution of a statement.
common statements such as conditional statements are handled in the standard way omitted for brevity and here we focus on mpi operations.
the main idea is to delaythe executions of mpi operationsasmuchaspossible i.e.
tryingtogetallthemessagematchings.
insteadofexecution algorithm recordseachmpioperationfor each mpi process lines .
we also need to update buffer b after issuing an mpi operation lines .
then if stat iis a nonblockingoperation theexecutionreturnsimmediately otherwise weblock proc i line10 exceptingthe waitofan isendoperation .
when reaching globalblocking lines i.e.
every process is terminatedorblocked weuse matching cf.algorithm3 tomatch the recorded but not yet matched mpi operations and execute the matchedoperations.sincetheopportunityofmatchingmessages isglobalblocking we call it blocking driven symbolic execution.
matching matches the recorded mpi operations in different processes.toobtainallthepossiblematchings wedelaythematchingalgorithm blocking driven symbolic execution execute sc proc i stat i sym worklist data global state sc mpi process proc i statement stat i symbolic variable set sym worklistof global states 1begin 2switch stat i do case sendorisendorirecvdo seqi seqi angbracketleftstat i angbracketright si.b si.b angbracketleftstat i angbracketright end case barrierorwaitorssendorrecvdo seqi seqi angbracketleftstat i angbracketright si.b si.b angbracketleftstat i angbracketright si.f blocked ifglobalblocking then si sc si.f blocked si.f terminated matching sc worklist end end default execute sc proc i stat i sym worklist as normal 16end 17end of a wildcard operation as much as possible.w eu s e match nto matchthenon wildcardoperationsfirst line3 w.r.t.therulesin the mpi standard especially the non overtaken ones if two sendsofaprocesssendmessagestothesamedestination andboth can match the same receive the receive should match the first one and ifaprocesshastworeceives andbothcanmatchasend the first receive should match the send.
the matched send and receive operationswillbeexecuted andthestatusesoftheinvolvedprocesses will be updated to active denoted by fire sc pairn line .
if there is no matching for non wildcard operations we use algorithm blocking driven matching matching sc worklist data global state sc worklistof global states 1begin 2msw matching set of wildcard operations 3pairn match n sc match non wildcard operations 4ifpairn nequalempty pair then fire sc pair n 6end 7else msw match w sc match wildcard operations forpairw mswdo s primec fork sc pairw worklist worklist s primec end ifmsw nequal then worklist worklist sc end 16end 17ifpairn empty pair msw then reportdeadlock andexit 19end 20end 1252p0 p1 p2 isend req irecv req barrier barrier barrier isend req wait req wait req wait req figure an example of operation matching.
match wto match the wildcard operations line .
for each possible matchingof awildcardreceive we fork anew state denoted byfork sc pairw at line to analyze each matching case.
if no operations can be matched but there exist blocked processes a deadlockhappens line17 .besides fortheltlpropertiesother thandeadlockfreedom suchastemporalproperties wealsocheck them during symbolic execution omitted for brevity .
take the program in figure 5for example.
when all the processesblockat barrier mpi svmatchestherecordedoperation in the buffers of the processes i.e.
s0.b angbracketleftisend req barrier angbracketright s1.b angbracketleftirecv req barrier angbracketright and s2.b angbracketleftbarrier angbracketright.
accordingto the mpi standard each operation in the buffers is ready to be matched.hence matching firstmatchesthenon wildcardoperations i.e.
the barrieroperations thenthestatusofeachprocessbecomes active.afterthat mpi svcontinuestoexecutetheactiveprocesses and record issued mpi operations.
the next globalblocking point is p0andp2terminate and p1blocks at wait req .
the buffersare angbracketleftisend req wait req angbracketright angbracketleftirecv req wait req angbracketright and angbracketleftisend req wait req angbracketright respectively.alltheissued wait operations are not ready to match because the corresponding non blocking operations are not matched.
so matching needs to match the wildcard operation i.e.
irecv req which can be matched with isend req orisend req .
then a new state is forked for each case and added to the worklist.
correctness .blocking drivensymbolicexecutionisaninstance of model checking with por.
we have proved the symbolic execution method is correct for reachability properties .
due to the space limit the proof can be referred to .
csp based path modeling in this section we first introduce the csp language.
then we present the modeling algorithm of an mpi program terminatedpath using a subset of csp.
finally we prove the soundness and completeness of our modeling.
.
csp subset let be afiniteset ofevents ca set of channels and xa set of variables.
figure shows the syntax of the csp subset where pdenotes a csp process a c c x andx x. the single event process aperforms the event aand terminates.
there are three operators sequential composition fatsemi external choice square and parallel composition with synchronization bardbl x .p squareqperforms as p p a p fatsemip p squarep p bardbl xp c?x p c!x p skip figure the syntax of a csp subset.orq and the choice is made by the environment.
let psbe a finite setofprocesses squarepsdenotestheexternalchoiceofalltheprocesses inps.p bardbl xqperforms pandqinaninterleavingmanner but pand qsynchronize on the events in x. the process c?x pperforms aspafterreadingavaluefromchannel candwritingthevalueto variablex.
the process c!x pwrites the value of xto channel c and then behaves as p. process skipterminates immediately.
.
csp modeling for each violation free program path algorithm builds a precise cspmodelofthepossiblecommunicationbehaviorsbychanging the matchings and interleavings of the communication operations along the path.
the basic idea is to model the communication operationsin eachprocess asacsp process then composeallthe csp processes in parallel to form the model.
to model proc i w e scanits operationsequence seqiinreverse.foreach operation we generate its csp model and compose the model with that of the remainingoperationsin seqiw.r.t.thesemanticsoftheoperation and the mpi standard .
the modeling algorithm is efficient and has a polynomial time complexity w.r.t.the total length of the recorded mpi operation sequences.
we use channel operations in csp to model send and receive operations.eachsendoperation ophasitsownchannel denoted bychan op .
we use a zero sized channel to model ssendoperation line10 because ssendblocksuntilthemessageisreceived.
in contrast considering a sendorisendoperation is completed immediately weuse one sized channelsforthem line14 sothe channel writing returns immediately.
the modeling of barrier line is to generate a synchronization event that requires all the parallel csp processes to synchronize it lines .
themodeling of receive operations consists of three steps.
the first step calculates the possibly matched channels written by the send operations lines20 .thesecondusestheexternalchoiceof reading actions of the matched channels lines so as to model different cases ofthe receive operation.
finally the refined externalchoiceprocessiscomposedwiththeremainingmodel.if theoperationisblocking thecompositionissequential line22 otherwise it is a parallel composition line .
staticmatchedchannel opj s lines20 returnsthesetof thechannelswrittenbythepossiblymatchedsendoperationsof the receive operation opj.
we scan seq s to obtain the possibly matched send operations of opj.
given a receive operation recvin process proc i smo recv s calculatedasfollowsdenotestheset of the matched send operations of recv.
ifrecvisrecv j orirecv j r smo recv s contains proc j s send operations with proc ias the destination process.
ifrecvisrecv orirecv r smo recv s containsanyprocess s send operations with proc ias the destination process.
smo op s over approximates op s precisely matched operations and can be optimized by removing the send operations that aredefinitelyexecutedafter op scompletion andtheoneswhose messages are definitely received before op s issue.
for example letproc0besend barrier send and proc1berecv barrier.
smowill add the two send operations in proc0to the matching setofthe recv inproc1.since recv mustcompletebefore barrier we can remove the second send operation in proc0.
such 1253algorithm csp modeling for a terminated state generatecsp s data a terminated global state s and seq s seqi i n 1begin 2ps 3fori ...ndo pi skip req r irecv r seqi irecv i r seqi forj len th seqi ...0do switchopjdo case ssend i do c1 chan opj c1 s size is pi c1!x pi end case send i orisend i r do c2 chan opj c2 s size is pi c2!x pi end case barrierdo pi b fatsemipi end case recv i orrecv do c staticmatchedchannel opj s q refine square c?x skip c c s pi q fatsemipi end case irecv r orirecv i r do c staticmatchedchannel opj s q refine square c?x skip c c s ew waitevent opj opj s wait event pi q fatsemiew bardbl ew pi end case wait r andr reqdo ew generateevent opj pi ew fatsemipi end end end ps ps pi 37end 38p bardbl b ps 39returnp 40end optimization reduces the complexity of the csp model.
for brevity we use smo op s to denote the optimized matching set.
then staticmatchedchannel opj s is chan op op smo opj s .
tosatisfythempirequirements refine p s lines21 refines the models of receive operations by imposing the completesbefore requirements as follows ifareceiveoperationhasmultiplematchedsendoperationsfrom the same process it should match the earlier issued one.
this is ensured by checking the emptiness of the dependent channels.
thereceiveoperationsinthesameprocessshouldbematched w.r.t.their issue order if they receive messages from the sameprocess except the conditional completes before pattern .
we use one sized channel actions to model these requirements.
wemodela waitoperationifitcorrespondstoan irecvoperation line because isendoperations complete immediately undertheassumptionofinfinitesystembuffer.
waitoperationsare modeledbythesynchronizationinparallelprocesses.
generateevent generates a new synchronization event ewfor each waitoperation line31 .then ewisproducedafterthecorrespondingnonblocking operation is completed line .
the synchronization on ewensures that a waitoperation blocks until the corresponding non blocking operation is completed.
we use the example in figure for a demonstration.
after exploringa violation free path therecordedoperationsequencesare seq0 angbracketleftisend req barrier wait req angbracketright seq1 angbracketleftirecv req barrier wait req angbracketright seq2 angbracketleftbarrier isend req wait req angbracketright.w e first scan seq0in reverse.
note that we don t model wait req becauseitcorrespondsto isend.wecreateasynchronizationevent bformodeling barrier lines16 .forthe isend req we modelitbywritinganelement atoaone sizedchannel chan1 and use prefix operationto compose its modelwith b lines .
in this way we generate csp process chan1!a b fatsemiskip denoted by cp0 for proc0.
similarly we model proc2byb fatsemichan2!b skip denoted by cp2 wherechan2is also a one sized channel and bis achannelelement.for proc1 wegenerateasingleeventprocess ew to model wait req because it corresponds to irecv lines .
for irecv req we first compute the matched channels using smo line25 and staticmatchedchannel opj s contains bothchan1andchan2.then wegeneratethefollowingcspprocess chan1?a skip squarechan2?b skip fatsemiew bardbl ew b fatsemiew fatsemiskip denoted by cp1 for proc1.
finally we compose the csp processes using the parallel operator to form the csp model line i.e.
cp0 bardbl b cp1 bardbl b cp2.
csp modeling supports the case where communications depend onmessagecontents.mpi svtrackstheinfluenceofamessageduring symbolic execution.
whendetecting that the message content influences the communications mpi sv symbolizes the content on the fly.wespeciallyhandlethewidelyused master slave pattern fordynamicloadbalancing .thebasicideaistousearecursive csp process to model each slave process and a conditional statement for master process to model the communication behaviorsof different matchings.
we verified five dynamic load balancing mpiprogramsinourexperiments cf.section5.
.thedetailsfor supportingmaster slavepatternisinthesupplementarydocument.
.
soundness and completeness in the following we show that the csp modeling is soundand complete.suppose generatecsp s generatesthecspprocess csp s. here soundness meansthat csp smodelsallthepossiblebehaviors by changing the matchings or interleavings of the communication operationsalongthepathto s andcompleteness meansthateach tracein csp srepresentsarealbehaviorthatcanbederivedfrom s bychangingthematchingsorinterleavingsofthecommunications.
sincewecompute smo op s bystaticallymatchingthearguments of the recorded operations smo op s may contain some 1254falsematchings.calculatingthepreciselymatchedoperationsof op isnp complete andwesupposesuchanidealmethodexists.
we use csp staticandcsp idealto denote the generated models using smo op s and theideal method respectively.the following theorems ensure the equivalence of the two models under the stable failuresemantics ofcspand csp static sconsistencyto thempisemantics whichimplythesoundnessandcompleteness of our csp modeling method.
let t p denote the trace set o f csp process p andf p denote the failure set of csp process p. each element in f p is s x wheres t p is a trace and xis the set of events prefuses to perform after s. theorem .
.
f csp static f csp ideal .
proof.
we only give the skeleton of the proof.
we first prove t csp static t csp ideal based on which we can prove f csp static f csp ideal .
the main idea of proving these two equivalence relations is to use contradiction for proving the subset relations.
we only give the proofoft csp static t csp ideal theothersubsetrelations can be proved in a similar way.
supposethereisatrace t angbracketlefte1 ... en angbracketrightsuchthatt t csp static butt nelementt csp ideal .
the only difference between csp staticand csp idealis that csp staticintroduces more channel read operations during the modeling of receive operations.
hence theremustexistareadoperationofanextrachannelin t.supposethe first extra read is ek ce?x where k n. therefore cecannotbereadin csp idealwhenthematchingofthecorresponding receive operation starts but ceis not empty at ekincsp static.
despite of the size of ce there must exist a write operation ce!yin angbracketlefte1 ... ek angbracketright.because angbracketlefte1 ... ek angbracketrightisalsoavalidtracein csp ideal it means ceis not empty in csp idealatek which contradicts with the assumption that cecannot be read in csp ideal.
hence t csp static t csp ideal holds.
square theorem .
.
csp staticis consistent with the mpi semantics.
theproof smainideaistoprovethat csp idealisequaltothe model defined by the formal mpi semantics w.r.t.the failure divergencesemantics.then basedontheorem4.
wecanprove that csp staticis consistent with the mpi semantics.
please refer to for the detailed proofs for these two theorems.
experimental evaluation inthissection wefirstintroducetheimplementationofmpi sv thendescribestheresearchquestionsandtheexperimentalsetup.
finally we give experimental results.
.
implementation wehaveimplementedmpi svbasedoncloud9 whichisbuilt uponklee andenhanceskleewithbettersupportforposix environmentandparallelsymbolicexecution.weleveragecloud9 s supportformulti threadedprograms.weuseamulti threadedlibrary for mpi called azequiampi as the mpi environment modelforsymbolicexecution.mpi svcontainsthreemainmodules programpreprocessing symbolicexecution andmodelchecking.
the program preprocessing module generates the input for symbolicexecution.weuseclangtocompileanmpiprogramtollvmtable the programs in the experiments.
program locbrief description dtg 90dependence transition group matmat 105matrix multiplication integrate 181integral computing diffusion2d 197simulation of diffusion equation gauss elim 341gaussian elimination heat 613heat equation solver mandelbrot 268mandelbrot set drawing sorting 218array sorting image manip 360image manipulation depsolver 8988multimaterial electrostatic solver kfray 12728kf ray parallel raytracer clustalw 23265multiple sequence alignment total open source programs bytecode which isthen linkedwith thepre compiled mpilibrary azequiampi.thesymbolicexecutionmoduleisinchargeofpath explorationandpropertychecking.thethirdmoduleutilizesthe state of the art csp model checker pat to verify csp models and uses the output of pat to boost the symbolic executor.
.
research questions we conducted experiments to answer the following questions effectiveness canmpi svverifyreal worldmpiprogramseffectively?
how effective is mpi sv when compared to the existing state of the art tools?
efficiency howefficientismpi svwhenverifyingreal world mpi programs?
how efficient is mpi sv when compared to the pure symbolic execution?
verifiableproperties canmpi svverifypropertiesotherthan deadlock freedom?
.
setup table1liststheprogramsanalyzedinourexperiments.alltheprogramsarereal worldopensourcempiprograms.
dtgisatesting program from .matmat integrate anddiffusion2d come from the fevs benchmark suite .matmatis used for matrix multiplication integrate calculatesthe integralsoftrigonometric functions and diffusion2d isaparallelsolverfortwo dimensional diffusionequation.
gauss elim isanmpiimplementationforgaussian elimination used in .heatis a parallel solver for heat equation used in .mandelbrot sorting andimage manip come from github.
mandelbrot parallel draws the mandelbrot set for a bitmap sorting usesbubblesorttosortamulti dimensionalarray andimage manip isanmpiprogramfor imagemanipulations e.g.
shifting rotating and scaling.
the remaining three programs are largeparallelapplications.
depsolver isaparallelmulti material 3d electrostatic solver kfrayis a ray tracing program creating realistic images and clustalw is a tool for aligning gene sequences.
to evaluate mpi sv further we mutate the programs by rewritingarandomlyselectedreceiveusingtworules replace recv i withif x a recv i else recv replace recv withif x a recv else recv j .herexisaninputvariable a 1255isarandomvalue and jisgeneratedrandomlyfromthescopeofthe process identifier.
the mutations for irecv i r andirecv r aresimilar.rule1istoimproveprogramperformanceandsimplify programming while rule is to make the communication more deterministic.sincecommunicationstendtodependoninputsin complexapplications suchasthelastthreeprogramsintable1 we also introduce input related conditions.
for each program we generatefivemutantsifpossible orgenerateasmanyasthenumberof receives.
we don t mutate the programs using master slave pattern i.e.
matmatandsorting and only mutate the static scheduling versions of programs integrate mandelbrot and kfray.
baselines.
weusepuresymbolicexecutionasthefirstbaseline because none of the state of the art symbolic execution basedverificationtoolscananalyzenon blockingmpiprograms e.g.
c iv l mpi spin can support input coverage and non blocking operations but it requires building models of theprogramsmanually and other automatedtools thatsupport non blockingoperations suchasmopper andisp can only verify programs under given inputs.
mpi sv aims at covering both the input space and non determinism automatically.
to compare with pure symbolic execution we run mpi sv under two configurations symbolic execution i.e.
applying only symbolic execution for path exploration and our approach i.e.
using model checking based boosting.
most of the programs run with6 and processes respectively.
dtgandmatmatcan only be run with and processes respectively.
for diffusion and the programsusingthe master slave pattern weonlyrunthemwith and processes due to the huge path space.
we use mpi sv to verify deadlock freedom of mpi programs and also evaluate 2non reachability properties for integrate andmandelbrot .
the timeout is one hour.
there are three possible verification results finding a violation no violation or timeout.
we carry out all the tasksonanintelxeon basedserverwith64gmemoryand82.5ghz cores running a ubuntu .
os.
we ran each verification task threetimesandusetheaverageresultstoalleviatetheexperimental errors.
to evaluate mpi sv s effectiveness further we also directly compare mpi sv with civl and mpi spin .
note that since mpi spin needs manual modeling we only use mpi sv to verify mpi spin s c benchmarks w.r.t.deadlock freedom.
.
experimental results table2liststheresultsforevaluatingmpi svagainstpuresymbolic execution.
the first column shows program names and procsis thenumberofrunningprocesses.
tspecifieswhethertheanalyzed program is mutated where odenotes the original program and mi represents amutant.
a taskcomprises aprogram and thenumber of running processes.
we label the programs using master slave patternwithsuperscript .column deadlock indicateswhethera taskisdeadlockfree where0 and 1denote nodeadlock deadlock andunknown respectively.
we use unknown for the case that both configurations fail to complete the task.
columns time s and iterations showtheverificationtimeandthenumberofexplored paths respectively wheretostandsfortimeout.theresultswhere our approach performs better is in gray background.
for the verification tasks mpi sv completes tasks within one hour whereas tasks for symbolic execution.
verification time thresholds completed verification taskssymbolic execution our approach figure completed tasks under a time threshold.
our approach detectsdeadlocksin48tasks whilethenumberof symbolic execution is44.wemanuallyconfirmedthatthedetected deadlocksarereal.forthe48taskshavingdeadlocks mpi svon average offers a 5x speedups for detecting deadlocks.
on the other hand our approach canverifydeadlockfreedomfor52tasks while only tasks for symbolic execution.
mpi sv achieves an average 19x speedups.
besides compared with symbolic execution our approach requires fewer paths to detect the deadlocks on average and complete the path exploration on average .
these results demonstrate mpi sv s effectiveness and efficiency.
figure shows the efficiency of verification for the two configurations.thex axisvariesthetimethresholdfrom5minutestoonehour whilethey axisisthenumberofcompletedverificationtasks.
our approach cancompletemoretasksthan symbolic execution under the same time threshold demonstrating mpi sv s efficiency.
inaddition our approach cancomplete96 tasksin5minutes which also demonstrates mpi sv s effectiveness.
forsometasks e.g.
kfray mpi svdoesnotoutperform symbolic execution.thereasonsinclude a thepathscontainhundredsofnon wildcardoperations andthecorrespondingcspmodelsare huge and thus time consuming to model check b the number of wildcard receives or their possible matchings is very small and as a result only few paths are pruned.
comparison with civl.
civlusessymbolicexecutiontobuild amodelforthewholeprogramandperformsmodelcheckingonthe model.
in contrast mpi sv adopts symbolic execution to generate path levelverifiable models.civldoesnotsupportnon blocking operations.
we applied civl on our evaluation subjects.
it onlysuccessfully analyzed dtg.diffusion2d could be analyzed after removingunsupportedexternalcalls.mpi svandcivlhadsimilarperformance on these two programs.
civl failed on all the remaining programs due to compilation failures or lack of support for non blockingoperations.incontrast mpi svsuccessfullyanalyzed of the programs in civl s latest benchmarks.
the failedones are small api test programs for the apis that mpi sv does notsupport.forthereal worldprogram floydthatbothmpi sv andcivlcananalyze mpi svverifieditsdeadlock freedomunder processes in minutes while civl timed out after minutes.
the results indicate the benefits of mpi sv s path level modeling.
comparison with mpi spin.
mpi spin relies on manual modeling of mpi programs.
inconsistencies may happen between an 1256table experimental results.
program procs tdeadlocktime s iterations symbolic execution our approach symbolic execution our approach dtg o .
.
m10 .
.
m21 .
.
m31 .
.
m41 .
.
m51 .
.
matmat o .
.
integrate o0 .
to to .
.
.
m10 to to to .
to to m21 .
.
.
.
.
.
integrate o0 .
.
.
.
diffusion2d o0 .
to .
.
m10 .
.
.
.
m20 .
.
.
.
m30 to to .
.
m41 .
.
.
.
m51 .
to .
.
gauss elim o0 to to to .
.
.
m11 .
to to .
.
.
heat o1 .
.
.
.
.
.
m11 .
.
.
.
.
.
m21 .
.
.
.
.
.
m31 .
.
.
.
.
.
m41 .
.
.
.
.
.
m51 .
.
.
.
.
.
mandelbrot o0 to to to .
.
to m1 to to to to to to m2 to to to to to to m31 .
.
.
.
.
.
mandelbort o0 .
.
.
.
sorting o0 to to .
.
image mani o0 .
.
.
.
.
.
m11 .
.
.
.
.
.
depsolver o0 .
.
.
.
.
.
kfray o0 to to to .
.
.
m11 .
.
.
.
.
.
m2 to to to to to to m31 .
.
.
.
.
.
kfray o0 to to .
.
clustalw o0 to to to .
.
.
m10 to to to .
.
.
m20 to to to .
.
.
m31 .
to to .
.
.
m40 to to to .
.
.
m50 to to to .
.
.
mpiprogramanditsmodel.althoughprototypesexistfortranslatingctopromela theyareimpracticalforreal worldmpi programs.
mpi spin s state space reduction treats communication channelsasrendezvousones thus thereductioncannothandletheprogramswithwildcardreceives.mpi svleveragesmodelchecking to prune redundant paths caused by wildcard receives.
we applied mpi svonmpi spin s17cbenchmarkstoverifydeadlockfreedom andmpi svsuccessfullyanalyzed15automatically indicatingtheeffectiveness.fortheremainingtwoprograms i.e.
blobflow andmonte mpi svcannotanalyzethemduetothelackofsupport for apis.
for the real world program gausselim mpi spin needs 171s to verify that the model is deadlock free under processes whilempi svonlyneeds27stoverifytheprogramautomatically.if thenumberoftheprocessesis8 mpi spintimedoutin30minutes but mpi sv used 66s to complete verification.
1257temporal properties.
wespecifytwotemporalsafetyproperties 1and 2forintegrate andmandelbrot respectively where 1 requires process one cannot receive a message before process two and 2requires process one cannot send a message before process two.
both 1and 2can be represented by an ltl formula !
aub which requires event acannot happen before event b. we verify integrate andmandelbrot under processes.
the verification resultsshowthatmpi svdetectstheviolationsof 1and 2 while pure symbolic execution fails to detect violations.
runtime bugs.
mpi svcanalsodetectlocalruntimebugs.during the experiments mpi sv finds unknown memory access outof bound bugs in depsolver a n d1i nclustalw.
related work dynamic analyses are widely used for analyzing mpi programs.
debugging or testing tools have better feasibility and scalability but depend on specific inputs and running schedules.
dynamic verification techniques e.g.
isp and dampi run mpi programs multiple times to cover the schedulesunderthesameinputs.b hmetal .
proposeastate space reductionframeworkforthempiprogramwith non deterministic synchronization.theseapproachescandetectthebugsdepending on specific matchings of wildcard operations but may still miss inputs related bugs.
mpi sv supports both input and schedule coverages and a larger scope of verifiable properties.
mopper encodesthedeadlockdetectionproblemunderconcreteinputsin a sat equation.
similarly huang and mercer use an smt formula to reason about a trace of an mpi program for deadlock detection.however thesmtencodingisspecificforthezero buffer mode.
khanna et al .
combines dynamic and symbolic analyses to verify multi path mpi programs.
compared with these path reasoning work in dynamic verification mpi sv ensures input space coverage and can verify more properties i.e.
safety and livenesspropertiesinltl.besides mpi svemployscsptoenablea moreexpressivemodeling e.g.
supportingconditionalcompletesbefore and master slave pattern .
forstaticmethodsofanalyzingmpiprogram mpi spin manuallymodelsmpiprogramsinpromela andverifiesthe modelw.r.t.ltl properties by spin cf.section .
for empiricalcomparison .mpi spincanalsoverifytheconsistency betweenanmpiprogramandasequentialprogram whichisnot supported by mpi sv.
bronevetsky proposes parallel control flowgraph pcfg formpiprogramstocapturetheinteractionsbe tweenarbitraryprocesses.butthestaticanalysisusingpcfgishard tobeautomated.partypes usestypecheckinganddeductive verification to verify mpi programs against a protocol.
partypes s verification results are sound but incomplete and independent with the number of processes.
partypes does not support nondeterministicornon blockingmpioperations.mpi checker is astaticanalysis toolbuiltonclang staticanalyzer andonly supportsintraproceduralanalysisoflocalpropertiessuchasdouble non blocking and missing wait.
botbol et al .
abstract an mpi programtosymbolictransducers andobtainthereachabilityset basedonabstractinterpretation whichonlysupportsblocking mpi programs and may generate false positives.
compi usesconcolictesting todetectassertionorruntimeerrorsinmpi applications.
ye et al .
employs partial symbolic execution to detect mpi usage anomalies.
however these two symbolic execution based bug detection methods do not support the non determinism caused by wildcard operations.
luo and siegel propose a preliminary deductive method for verifying the numericproperties of mpi programs in an unbounded number of processes.
however this method still needs manually provided verification conditions to prove mpi programs.
mpi svisrelatedtotheexistingworkonsymbolicexecution whichhasbeenadvancedsignificantlyduringthelastdecade .
many methods have been proposed to prune paths during symbolic execution .
the basic idea is to use the techniques such as slicing and interpolation tosafelyprunethepaths.comparedwiththem mpi sv only prunes the paths of the same path constraint but different messagematchingsoroperationinterleavings.mpi svisalsorelated to the work of automatically extracting session types o r behavioral types for go programs and verifying the extracted type models.
these methods extract over approximation models fromgoprograms andhencearesoundbutincomplete.compared with them mpi sv extracts path level models for verification.
furthermore there existswork ofcombining symbolicexecution and modelchecking .yogi andabstraction drivenconcolic testing combine dynamic symbolic execution with counterexample guided abstraction refinement cegar .
mpi svfocusesonparallelprograms andtheverifiedmodelsare path level.
mpi sv is also related to the work of unbounded ver ification for parallel programs .
compared with them mpi sv is a bounded verification tool and supports the verifica tion of ltl properties.
besides mpi sv is related to the existingworkoftestingandverificationofshared memoryprograms .
compared with them mpisv concentrates on message passing programs.
utilizing the ideas in these work for analyzing mpi programs is interesting and left to the future work.
conclusion we havepresented mpi sv forverifying mpi programswith both non blocking and non deterministic operations.
by synergistically combiningsymbolicexecutionandmodelchecking mpi svprovides a general framework for verifying mpi programs.
we have implemented mpi sv and extensively evaluated it on real world mpiprograms.theexperimentalresultsarepromisingdemonstrate mpi sv seffectivenessandefficiency.thefutureworkliesinseveraldirections enhancempi svtosupportmorempioperations investigatetheautomatedperformancetuningofmpiprograms based on mpi sv apply our synergistic framework to other message passing programs.
acknowledgement this research was supported by national key r d program of china no.
2017yfb1001802 and nsfc program no.
and .