taxonomy ofreal faultsindeep learningsystems nargiz humbato va universit dellasvizzera italiana lugano switzerland nargiz.humbatova usi.chguneljahangirova universit dellasvizzera italiana lugano switzerland gunel.jahangirova usi.chgabriele bavota universit dellasvizzeraitaliana lugano switzerland gabriele.bavota usi.ch vincenzo riccio universit dellasvizzera italiana lugano switzerland vincenzo.riccio usi.chandreastocco universit dellasvizzera italiana lugano switzerland andrea.stocco usi.chpaolo tonella universit dellasvizzeraitaliana lugano switzerland paolo.tonella usi.ch abstract the growing application of deep neural networks in safety critical domains makes the analysis of faults that occur in such systems of enormousimportance.inthispaperweintroducealargetaxonomy offaultsindeeplearning dl systems.wehavemanuallyanalysed 1059artefactsgatheredfromgithubcommitsandissuesofprojects thatusethe most populardl frameworks tensorflow keras and pytorch andfromrelatedstackoverflowposts.structuredinterviewswith20researchersandpractitionersdescribingtheproblems theyhaveencounteredintheirexperiencehaveenrichedourtaxonomy with a variety of additional faults that did not emerge from the other two sources.
our final taxonomy was validated with a surveyinvolvinganadditionalsetof21developers confirmingthat almost all fault categories were experienced by at least of the survey participants.
ccs concepts software and its engineering software verification and validation.
keywords deep learning real faults software testing taxonomy acmreference format nargizhumbatova guneljahangirova gabrielebavota vincenzoriccio andreastocco andpaolotonella.
.taxonomyof realfaultsindeep learning systems.
in 42nd international conference on software engineering icse may23 seoul republicofkorea.
acm newyork ny usa 12pages.
introduction deep learning dl is finding its way into a growing number of areasinscienceandindustry.itsapplicationrangesfromsupporting daily activities such as converting voice to text translating texts from one language to another to much more critical tasks such as permission to make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissionsfrom permissions acm.org.
icse may seoul south korea associationfor computing machinery.
acm isbn ... .
detection in creditcard companies diagnosis and treatment of diseases in medical field autonomous driving of vehicles.
the increasingdependenceofsafety criticalsystemsondlnetworks makesthetypesoffaultsthatcanoccurinsuch systemsacrucial topic.
however the notion of fault in dl systems is more complex than in traditional software.
in fact the code that builds the dl networkmightbebugfree butthenetworkmightstilldeviatefrom the expected behaviour due to faults introduced in the training phase suchasthemisconfigurationofsomelearningparameters orthe use ofan unbalanced non representative training set.
the goal of this paper is to build a taxonomy of real faults in dl systems.
an example of a subject dl system could be an object detectionsubsysteminanautonomouscar.suchataxonomycan be usefultoaid developersavoiding common pitfallsor canserve asachecklistfortesters motivatingthemtodefinetestscenarios that address specific fault types.
we consider that a dl fault has takenplacewhenthebehaviourofthedlcomponentisinadequate forthetaskathand i.e.
itis functionallyinsufficient inlinewith iso pas21448 andtherootcauseforsuchinadequacyisa human mistake that occurred during dl development and training.
the taxonomy could also be used for fault seeding as resemblance withrealfaultsisanimportantfeatureforartificiallyinjectedfaults.
a taxonomy is mainly a classification mechanism .
accordingtorowleyandfarrow therearetwomainapproachesto classification enumerativeandfaceted.in enumerativeclassification theclassesarepredefined.however itisdifficulttoenumerate allclassesinimmatureorevolvingdomains whichisthecaseofdl systems.therefore usingavettedtaxonomyoffaults would notbeappropriateforourpurpose.incontrast in facetedclassificationtheemergingtraitsofclassescanbeextendedandcombined.
forthisreasonweusedfacetedclassification i.e.
wecreatedthe categories subcategories ofour taxonomyinabottomup way by analysingvarioussourcesof information aboutdl faults.
our methodology is based on the manual analysis of unstructuredsourcesandinterviews.westartedbymanuallyanalysing477 stackoverflow so discussions 271issuesandpullrequests prs and commits from github repositories in which developers discuss fixissues encounteredwhile usingthree popular dlframeworks.
the goal of the manual analysis was to identify the root causebehindtheproblem.theoutputofthisstepwasthefirsthierarchical taxonomy of faults related to the usage of dl frameworks.
then two of the authors interviewed researchers and practitioners to collect their experience on the usage of dl frameworks.
all the interviews were taped and transcribed allowing an open ieee acm 42nd international conference on software engineering icse icse may seoul south korea humbato va andjahangirova et al.
coding procedure among all authors by which we identified the categoriesoffaultsmentionedbytheinterviewees.thisallowed to complement our preliminary taxonomy andto produce its final version.
tovalidateourfinaltaxonomywehaveconductedasurveyto which an additional set of researchers practitioners have responded.inthesurvey weincludedthecategoriesofthetaxonomy alongwithadescriptionofthetypesoffaultstheyrepresent and askedtheparticipantstoindicatewhetherthesefaultshavebeen encounteredintheirpriorexperiencewhendevelopingdlsystems.
most faults were experienced by or more of the participantsandnofaultcategoryremainednon validated theleast frequent category wasconfirmed by24 participants .
themaincontributionofthispaperisthevalidatedtaxonomy ofrealfaultsindlsystems.toourknowledge thisisthefirstwork that includes interviews with developers on the faults related to thedevelopmentofdlsystems.withoutsuchinterviews 2inner nodes and leaf nodes of the taxonomy would be completely missed.severalothernodesarehighlyrepresentedininterviews but they appear quiterarely inthe otheranalysedartefacts.
structureofthepaper .
section2gives an overview of related work.
section 3describes the methodology used to collect faults to build the taxonomy and to validate it.
the final version of the taxonomy along with the description of its categories and the resultsofthevalidationsurveyarepresentedinsection .section containsadiscussionofourfindings whilesection 6reviewsour threatsto validity.finally section 7concludes the paper.
related work .
repositorymining oneofthefirstpapersconsideringfaultsspecificallyinmachine learning ml systemsisthe empiricalstudybythung etal.
.
theauthorsmanuallylabeled500bugreportsandfixesfromthebug repositoriesofthreeopensourceprojects apachemahout lucene and opennlp to enable their classification into the categories proposed by seaman et al.
.
descriptive statistics were used to addressresearchquestionssuchashowoftenthebugsappear how severethebugsareandhowmucheffortisputintotheirresolution.
a similar study was published in by sun et al.
.
the authors examined bug patterns and their evolution over time.
as a subject of the study the authors considered three ml projects from github repositories scikit learn caffeandpaddle .the collected issues have been organised into categories.
manual analysis of 329successfullyclosedbugreportsallowedtheauthorstoassess the fault category fix pattern and effort invested while dealing withabug.
themaindifferencebetweenthesetwoworksandourstudyis that they analysed bugs inthe frameworks themselves while we focus on the faults experienced when building dl systems that use aspecific framework.
zhangetal.
studiedanumberof dlapplicationsdeveloped using tensorflow.
they collected information about tensorflow related bugs from so and github.
manual examination of thesebugsallowedtheauthorstodeterminethechallengesdevelopersfaceandthestrategiestheyusetodetectandlocalisefaults.the authors also provide some insight into the root causes of bugs andinto the consequences that bugs have on the application behaviour.
theauthorswereabletoclassifytheirdatasetintosevengeneral kindsof root causes andfourtypes of symptoms.
in our study we analyse dl applications that use the most populardlframeworks tensorflow pytorchandkeras notjust theformer.thepopularityofthesethreeframeworks inparticular keras andtheirstrongprevalenceoverothersimilarproductsallows us to consider them as representative of the current situation inthefield.anothermethodologicaldifferenceliesinthemining of the so database.
zhang et al.considered so questions under the constraint that they had at least one answer while we analysed only questions with an acceptedanswer to be sure that the fault was investigated indepthandsolved.
asforgithub zhang etal.usedonly11projectstocollectthe faults.afteracomplexfilteringandcleaningprocess wewereable touse564projects.forfurthercomparison zhang etal.foundin total175bugs whichincludethosethatwediscardedasgeneric i.e.
nondlspecific whileourtaxonomybears 375dlspecificfaults in total.
it is difficult to compare the overall number of analysed artefacts as such statistics are not reported inzhang et al.
s paper.
lastbutnotleast wedecidednottolimitouranalysistojustsoand github we includedinterviewswithresearchers and practitioners whichrevealedtobeakeycontributiontothetaxonomy.adetailed comparisonbetweenourandzhang etal.
staxonomyisreported in section .
another work worth mentioning is a dl bug characterisation by islam et al.
.
the aim of the authors is to find what types of bugs are observed more often and what are their causes and impacts.they alsoinvestigatedwhether thecollectedissuesfollow a common pattern and how this pattern evolved over time.
the authors studied a number of so and github bugs related to five dlframeworks theano caffe keras tensorflowandpytorch.to perform their analysis the authors labeled the dataset according to aclassification systemadapted from the 1984work bybeizer .
forthecategorisationofthebugcauses theauthorsadoptedthelist ofrootcausesfromzhang etal.
.differentlyfromus islam etal.
didnothavetheaimofbuildingacomprehensivefaulttaxonomy.
instead theyperformedananalysisofvariousfaultpatternsand studiedthecorrelation distributionofbugsindifferentframeworks reusingexisting taxonomies available in the literature.
.
interviewswith practitioners oneofthestudiesthatprovidessomeinsightintochallengesindustrialpractitionersfacewhiledevelopinganddeployingml based applicationsisby lwakatare et al.
.
similarlyto our approach theauthorsconductedsemi structuredinterviewstocollectdataof interest.basedon12interviews andaworkshopheldwithpractitioners from six projects a taxonomy that represents the evolution stagesoftheuseofmlcomponentsinindustrialpracticewasobtained.
the resulting taxonomy consists of five stages that include experimentation and prototyping non critical deployment critical deployment cascadingdeployment and autonomousmlcomponents.
the challenges associated with these stages fall into four broadcategories assembledataset createmodel trainandevaluate model and deploy model.
for each of the categories the authors provide from to descriptionsof possible challenges developers 1111taxonomyof real faults in deep learning systems icse may seoul south korea may experience on a particular evolution stage.
although some of the challenges cover the leaf nodes in our taxonomy namely imbalancedtrainingset andnotenoughdata therestofthedata have completely differentnature andstructure.
in a work conducted in a similar way arpteg et al.
study softwareengineeringchallengesassociatedwithbuildingdlapplications.
they took advantage of direct communications with employeesfromsevenreal worldprojects.theauthorspresenta list consisting of three main categories development production andorganisational challenges.
each of the categories consists of severalsubcategories 12intotal thatoutlinetheproblematicareas andaremappedtothecasestudies basedonwhethertheassociated challenges were experiencedornot.
fromtheprovidedinformation culturaldifferences andeffort estimation appeartobethemostprevalentchallengesamongthe organisation related problems while testinganddependency management are the most frequent for development and production stages respectively.thepresentedclassificationprovidesahighlevel overview of theproblematic aspects of the development and production process while our study focuses ondl faults.
methodology .
manual analysis ofsoftwareartefacts toderiveourinitialtaxonomyweconsideredthethreemostpopular dl frameworks tensorflow keras and pytorch.
we manually analysedfoursourcesofinformation commits issues pullrequests prs fromgithubrepositoriesusingtensorflow keras orpytorch andso discussionsrelatedto the three frameworks.
.
.
mining github.
we used the github search api to identifyrepositoriesusingthethreedlframeworkssubjectofourstudy.
theapi takesas aninput asearchstringandfetches sourcecode files from github repositories that match the search query.
for example inpython tensorflowcanbeimportedbyusingthestatementimport tensorflow as tf .thus weusedthesearchstring tensorflow toidentifyallpythonfilesusing tensorflow.clearly this may result in a number of false positives since the string tensorflow may be presentinside a source fileforotherreasons e.g.
as part of a string literal .
however the goal of this search is only toidentify candidate projectsusingthethreeframeworks andfalse positivesareexcludedinsubsequentsteps.thesearchstringswe definedare tensorflow keras and torch .welimitedthesearch to pythonsourcefiles using the language python argument.
while using the githubsearchapi a single requestcan return results at most.
to overcome this limitation we generated several requests each having a specific size range.
we used the size min..max argument to retrieve only files within a specific sizerange.inthisway weincreasedthenumberofreturnedresults toup1 n wherenisthenumberofconsideredsizeranges.for eachsearchstring wesearchedforfileshavingasizerangingfrom 0to500 000bytes withastepof250bytes.overall we generated search requests for eachframework.
foreachretrievedpythonfileweidentifiedthecorresponding github repository and we extracted relevant attributes such as number of commits number of contributors number of issues prs numberofstars andnumberofforks .then weexcluded i personal repositories classified as those having less than five contributors ii inactiverepositories i.e.
havingnoopenissues iii repositories with trivial history i.e.
having less than commits and iv unpopular repositories that we identified as those withless than10 stars and10 forks.
suchaprocessresultedintheselectionof151tensorflowprojects 237kerasprojects and326pytorchprojects.then oneoftheauthors checked the selected repositories with the goal of excluding tutorials books orcollectionsofcodeexamples notrepresenting real software systems used by developers in practice and false positives i.e.
projects containing the search strings in one of their pythonfiles but not actually using the relatedframework .
this process left us with tensorflow keras and pytorchprojects.foreachoftheretained564projects wecollected issues prs andcommitslikelyrelatedtofixingproblems discussing issues.forissuesandprs weusedthegithubapitoretrieveall those labelled as either bug defect orerror.
for commits we minedthechangelogoftherepositoriestoidentifyallthosehaving a message that contained the patterns fix or solve and bug or issue or problem or defect or error .
then for each framework we selected a sample of projects for manual analysis.
instead of applying a random selection we selected the ones having the highest number of issues and prs.
forframeworksforwhichlessthan100projectshadatleastone relevant issue pr we selected the remaining projects sorting them by the number of relevant commits i.e.
commits matching the patterndescribedabove .the100selectedprojectsaccountfora total of issues andprs and28 423commits.
before including these artefacts in our study we manually inspected a random sample of elements and found many false positives i.e.
issues prs commits that while dealing with fault fixingactivities wereunrelatedtoissuesrelevanttotheusage of the underlying dl framework i.e.
were about generic programming bugs .
thus we decided to perform a further cleaning step to increasethe chanceofincluding relevant documents inthemanual analysis.we defineda vocabulary ofrelevantwordsrelated to dl e.g.
epoch layer and excluded all artefacts that did not contain any of these words.
specifically we extracted the complete listof 986stemmed words i.e.
train trained and training were counted only once as train composing the vocabulary of the mined issues prsand commits.
for commits we searched for the relevant words in their commit note whereas for issues and prs we considered title description and all comments posted in the discussion.
we sorted the resulting words by frequency i.e.
number of artefacts in which they appear and we removed the longtailofwordsappearinginlessthan10artefacts.thiswasdone to reduce the manual effort needed to select the words relevant for dl from the resulting list of words.
indeed even assuming that oneoftheautomaticallydiscardedrarewordswererelevantfordl this would have resulted in missing at most nine documents in our dataset.
the remaining words have been manually analysed we split this list into five batches of equal size and each batch was assigned to one author for inspection with the goal of flagging the dl relevant words.
all flagged words were then discussed in a meeting among all authors in which the final list of relevant words was defined.
the list is available in our replication package 1112icse may seoul south korea humbato va andjahangirova et al.
and includes words such as layer train tensor.
after excluding allartefactsnotcontainingatleastoneofthe105relevantwords we obtainedthe final listof commits and of issues prs .
.
.
mining stack overflow.
we used stackexchange data explorer to get the list of so posts relatedto tensorflow keras and pytorch.stackexchange dataexplorer is a web interface that allows the execution of sql queries on data from q a sites including so.
for each framework we created a query to get the list of relevant posts.
we first checked if the name of a framework is indicated in the post s tags.
then we filtered out posts which contained the word how install or build in their title to avoid general how to questions and requests for installation instructions.
we also excluded posts that did not have an accepted answer to ensure that we consider only questions with a confirmed solution.
as a result we obtained posts for tensorflow for keras and653forpytorch.weorderedtheresultsofeachquerybythe numberoftimestheposthasbeenviewed.then toselecttheposts that may be addressing the most relevant faults we selected the top mostviewedposts overall posts .
.
.
manuallabelling.
thedatacollectedfromgithubandso was manually analysed by all authors following an open coding procedure .
the labelling process was supported by a web application that we developed to classify the documents i.e.
to describethereasonbehindtheissue andtosolveconflictsbetween the authors.
each author independently labelled the documents assignedto her by defining a descriptive label of the fault.
during the tagging the web application shows the list of labels already created whichcanbeusedbyanevaluatorshouldanexistinglabel apply to the fault under analysis.
although in principle this is against the notion of open coding little is still known on dl faults andthenumberofpossiblelabelsmaygrowexcessively.thus such achoice wasmeant tohelp codersuseconsistent namingwithout introducing substantial bias.
the authors followed a rigorous procedure for handling special and corner cases.
specifically i we marked as a false positive any analysed artefact that either was not related to any issue fixing activityorhappenedtobeanissueintheframeworkitselfrather than in a dl system.
ii if the analysed artefact concerned a fix but the fault itself was not specific to dl systems being rather a commonprogrammingerror e.g.
wrongstoppingconditionina forloop wemarkeditas generic.
iii iftheartefactwasrelated to issue fixing activitiesand itwasspecific ofdl systems but the evaluatorwas not able to traceback the root cause of the issue the unclearlabel wasassigned.
wheninspectingthedocuments wedidnotlimitouranalysis by reading only specific parts of the document.
instead we looked attheentiresodiscussions aswellastheentirediscussionsand related code changes in issues and prs.
for commits we looked at the commit noteas well as at the code diff.
in cases where there was no agreement between the two evaluators thedocumentwasautomaticallyassignedbythewebplatform toanadditionalevaluator.incaseoffurtherdisagreementbetween the three evaluators conflicts were discussed and solved within dedicatedmeetingsamong allauthors.
the labelling process involved six rounds each followed by a meetingamongallauthorstodiscusstheprocessandsolveconflicts.table manual labelling process roundanalyse d conflictsrelevant new inner new leaf artefacts todl categories categories 1st lvl.
2ndlvl.
3dlvl.
subtotal interviews total table1reports statisticsfor eachof thesix rounds of labelling including i thenumberofartefactsanalysedbyatleasttwoauthors ii thenumberofartefactsforwhichconflictsweresolvedinthe followingmeeting iii thenumberofartefactsthatreceivedalabel identifyingfaultsrelevantfordlsystems and iv thenumberof new top inner leafcategoriesinthe taxonomy of faults.
in the first three rounds we defined a total of leaf categoriesgroupingthe35dl relevantartefacts.withthegrowing number of categories in round four we started creating a hierarchical taxonomy see figure with inner nodes grouping similar leafcategories .
table1shows the number of inner categories created in the fourth fifth andsixthroundorganisedbylevel 1stlevelcategories arethemostgeneral .wekepttrackofthenumberofinnercategoriesproducedduringourlabellingprocessanddecidedtostop theprocess whenwe reached saturation for such inner categories i.e.
when a new labelling round did not result in the creation of any newinnercategoriesin the taxonomy.
in the last two rounds we increased the number of labels assigned to each author.
we opted for a longer labelling period becausetheprocesswaswell tunedandtherewasnoneedforregular meetings.overall welabelled1 059documents and111 .
of them required conflict resolution inthe open discussion meetings.
.
developerinterviews unliketraditionalsystems dlsystemshaveuniquecharacteristics astheirdecisionlogicisnotsolelyimplementedinthesourcecode but also determined by the training phase and the structure of the dlmodel e.g.
numberoflayers .whilesopostsand githubartefacts are valuablesourcesof information for our study the nature oftheseplatformslimitstheissuesreportedtomostlycode level problems hence possibly excluding issues encountered e.g.
during model definition or training.
to get a more complete picture we haveinterviewed20researchers practitionerswithvariousbackgrounds and levels of expertise focusing on the types of faults encountered duringthe developmentof dl basedsystems.
.
.
participantrecruitment.
toacquireabalancedandwideview on the problems occurring in the developmentof realdlsystems we involved two groups of developers researchers and practitioners.intheformergroup weconsideredphdstudents post docs andprofessorsengagedinfrequentusageofdlasapartoftheir research.
the second group of interviewees included developers working inindustryor freelancers for whomthedevelopmentof dl applicationswas the main domainof expertise.
weexploitedthreedifferentsourcestoattractparticipants.first weselectedcandidatesfrompersonalcontacts.thisresultedinalist 1113taxonomyof real faults in deep learning systems icse may seoul south korea of39developers 20ofwhomwerecontactedviae mail.wereceived positive responses from researchers and practitioners.
to balancetheratiobetweenresearchersandpractitioners wereferred toothertwosourcesofcandidates.oneofthemwasso whosetop answerersareexperienceddldeveloperswithprovencapability to help other developers solve recurring dl problems.
to access thetopanswererswereferredtostatisticsassociatedwiththetag that represents each of the three frameworks we study.
we used the last30days and alltime categoriesoftopanswerersand extractedthetop10answerersfrombothcategoriesforeachtag dlframework resultingin candidates in total.
as there is no built in contact form on so it was not possible to get in touch with all of the shortlisted users.
we managed to locateemailaddressesfor17ofthemfrom links to personalpages that users left on their so profiles.
from 17of the contacted users wereceived6responses ofwhich4werepositive dividedinto3 practitioners and1 researcher .
the other source was upwork a large freelancing platform.
we created a job posting with the description of the interview process on the upwork website.
the post was restricted to invited public.theinvitedcandidateswereselectedaccordingtothefollowingcriteria i acandidateprofileshouldrepresentanindividual andnotacompany ii thecandidate sjobtitleshouldbedl related iii thecandidate srecentlycompletedprojectsshouldmostlybe dl related iv upwork success rate of the candidate should be higher than and v the candidate should have earned more than10 000usdontheupworkplatform.from23invitationssent 5candidatesacceptedtheoffer butoneofthemwaslaterexcluded being a manager of a team of developers and not a developer herself.
overall theparticipantrecruitmentprocedureleftuswith20successfully conducted interviews equally divided among researchers andpractitioners 10pergroup .detailedinformationontheparticipants dl experience is available in our replication package .
forwhatconcernsthe overallcodingexperience amongtheinterviewedcandidatesthelowestvalueis2.5yearsandthehighestis years median .
.
as for the dl specific relevant experience the range is from 3months to years median .
theintervieweesreportedtousepythonasamainprogramming languagetodevelopdlapplications withafewmentionstomatlab r java scala c andc .concerningtheusageofdlframeworks tensorflowwasmentioned12times keras11 andpytorch8times.
thedomainsofexpertiseoftheintervieweescoverawidespectrum from finance androbotics to forensics andmedical imaging.
.
.
interview process.
since we are creating a taxonomy from scratch rather than classifying issues and problems into some known structure the interview questions had to be as generic and open endedaspossible.
we optedfora semi structuredinterview whichcombinesopen endedquestions toelicitunexpected typesofinformation withspecificquestions tokeeptheinterview within its scope andto aid interviewees withspecific questions .
insemi structuredinterviewstheinterviewerneedstoimprovise newquestionsbasedontheinterviewee sanswer whichmightbea challengingtask.therefore itmightbeusefultohaveanadditional interviewerwhocanaskfollow upquestions andsupport theprimary interviewer in case of need.
for this reason our interviewswere conducted by two authors simultaneously but with different roles one led the interview while the other asked additional questionsonlywhenappropriate.
eachrolewasperformedbythesame authorinalltheinterviews.
theworkbyhove etal.
shows that half of the participants in their study talked much more when the interviews were conducted by two interviewers instead of one.
this was the case also in our experience as in all the interviews the secondinterviewer askedat leasttwoadditional questions.
after collecting information about the interviewees general and dl specificprogramming experience we proceeded with the questionsfrom our interviewguide .
ourfirstquestionwasverygeneralandwasphrasedas what typesofproblemsandbugshaveyou facedwhendevelopingml dl systems?
.ouraimwiththisquestionwastoinitiatethetopicas open ended as possible allowing the interviewees to talk about their experience without directing them to any specific kind of faults.
then we proceeded with more specific questions spanning amongverybroaddltopics suchastrainingdata modelstructure hyperparameters lossfunctionandhardwareused.weaskedthe interviewees if theyeverexperienced issues and problems related to these topics and then if the answer was positive we proceeded withmore detailed questionsto understandthe relatedfault.
all of our interviews were conducted remotely using skype videocalls exceptonewhichwasconductedinperson.thelength oftheinterviewsvariedbetween26and52minutes withanaverage of minutes.
for each interview one of the two interviewers was also the transcriber.
for the transcription we used descript an automated speech recognition tool that converts audio video files into text.
after the automated transcription was produced the transcriber checked itanddidmanual corrections incaseof need.
.
.
open coding.
to proceed with open coding of the transcribed interviews one moderator and two evaluators were assigned to each interview.
the moderator was always one of the interviewers.thefirstevaluatorwastheotherinterviewer while thesecondevaluatorwasoneoftheauthorswhodidnotparticipate in the interview.
the role of each evaluator was to perform the open coding task.
in contrast the moderator s role was to identify andresolveinconsistently labelledfragmentsoftextbetweenthe evaluators e.g.
different tags attached to the same fragment of text .
we decided to involve the interviewers in this task in two roles evaluator and moderator because they were more informed ofthecontentandcontextoftheinterview havingbeenexposed to the informaland meta aspects ofthe communication with the interviewees.thesecondevaluatorwhowasnotinvolvedinthe interview ensuredthe presenceof adifferentpointof view.
twentyinterviewswereequallydividedamongtheauthorswho did not participate in the interviewprocess.
each interviewer was theevaluatorof10interviewsandthemoderatorfortheremaining .
the open coding was performed manually in the google docs online tool.
overall pieces of text were tagged by the evaluators.amongthem therewereonly6casesofconflict where the evaluators attached different tags to the same fragment of text.
moreover there were cases when one evaluator puta tag on a fragmentoftext whiletheotherdidnot.amongthesecases werekeptbythemoderators whiletherestwerediscarded.asa result of this process final tags were extracted.
the number of 1114icse may seoul south korea humbato va andjahangirova et al.
tags per interview ranged between and with an average of tags.
once the open coding of all interviews was completed a final meetingwithalltheauthorstookplace.atthismeeting authors wentthroughthefinallistoftags focusinginparticularonthetags thatweredeemednotrelatedtoissuesandproblemsindlsystems but rather had a more general nature.
after this discussion tags wereremoved leavingthefinal226tagsavailableforthetaxonomy.
.
taxonomy construction andvalidation to build the taxonomy we used a bottom up approach where wefirstgroupedtagsthatcorrespondtosimilarnotionsintocategories.then wecreatedparentcategories ensuringthatcategories andtheir subcategoriesfollow an is a relationship.eachversion ofthetaxonomywasdiscussedandupdatedbyallauthorsinthe physicalmeetingsassociatedwiththetaggingrounds.attheend oftheconstructionprocess inaphysicalmeetingtheauthorswent together through all the categories subcategories and leaves of the final taxonomy for the final minor adjustments.
toensurethatthefinaltaxonomyiscomprehensiveandrepresentative of real dl faults we validated it through a survey involving a new set of practitioners researchers different from those who participatedin the interviews.
to recruit candidates for the survey we adopted the same strategy and selection criteria as the one we used for the interview process section .
.
.
the first group of candidates we contacted was derived from authors personal contacts.
we contacted individualsremainingfromourinitiallistand13ofthemactuallyfilled thesurvey.thesecondandthethirdgroupofcandidatescamefrom soandupwork respectively.fromthesoplatformweselectedthe top20answerers fromthe last30days and alltime categories for each of the three considered frameworks.
by the time we were performing the survey these two categories had partly changed in terms of the featured users sothere were new users alsoin the top lists.
from the set of users we discarded those who had beenalreadycontactedfortheinterviews.amongtheremaining candidates we were able to accesscontactdetails ofonly 20users.
we contacted all of them and have completed the survey.
for the upwork group we created a new job posting with a fixed payment of usd per job completion and sent an offer to users.
four of them completed the survey.
overall participants took part in oursurvey 10researchersand11practitioners withaminimum overall coding experience of year and a maximum of years median .
concerning the relevant dl experience the minimum was1 year andthe maximum 7years median .
to create our survey form we used qualtrics a web based tool to conduct survey research evaluations and other data collection activities.
we started the survey with the same background questions as inour interviews.
then we proceededwith the questionsrelatedtoourfinaltaxonomy.puttingthewholetaxonomy structureinasinglefigureofthesurveywouldmakeitoverlycomplicated to read and understand.
therefore we partitioned it by innercategories choosingeitherthetopmostinnercategory when itwas not toolarge orits descendants when itwasalarge one.
foreachinnercategorythatpartitionedthetaxonomy wecreated a textual description including examples of its leaf tags.
inthe survey form we presented the name of the category its textual description andthenthreequestionsassociatedwithit.thefirst questionwasa yes or no questiononwhethertheparticipant hadeverencountered thisproblem.incaseof positiveanswer we had twomorelikert scalequestions ontheseverityoftheissue and the amount of effort required to identify and fix it.
in this way we evaluated not only the mere occurrence of a taxonomy fault but alsoits severityas perceivedby developers.
in the final partof our survey in the form of a free text answer weaskedtheparticipantstolistproblemsrelatedtodlthatthey haveencounteredbutwhichhadnotbeenmentionedinthesurvey.
by the faults in the developer s experience and if it did not we could find outwhat ismissing.
results thematerialusedtoconductour studyandthe anonymised collecteddata are publiclyavailable for replication purposes .
.
the final taxonomy thetaxonomyisorganisedinto5toplevelcategories 3ofwhich arefurtherdividedintoinnersubcategories.thefulltaxonomyis shown in figure .
the two numbers separated by a plus sign after eachcategorynamerepresentthenumberofpostsassignedtosuch a category during manual labelling and the number of occurrences of such atag in the interviews after open coding respectively.
model.thiscategoryofthetaxonomycoversfaultsrelatedto the structure andpropertiesof adl model.
model type properties.
this category considers faults affecting themodelasawhole ratherthanitsindividualaspects components.
one such fault is a wrong selection of the model type for example when a recurrent network was used instead of a convolutional network for a task that required the latter.
in addition there are several cases ofincorrect initialisation of a model which resultin theinstabilityofthegradients.anothercommonpitfallfromthis categoryisusingtoofewortoomanylayers causingsuboptimal network structure which in turn leads to poor performance of the model.anexamplewasprovidedbyoneofourinterviewees when we started we were thinking that we needed at least four layers in the encoder and the decoder and then we ended up having half of them like actually very shallow model and it was even better than the bigger deeper model .
layers.faultsinthiscategoryaffectaparticularlayerofaneural network.thisisalargetaxonomycategorythatwasfurtherdivided intothe three innersubcategoriesdescribedbelow missing redundant wrong layer.
these faults represent cases where adding removing or changing the type of a specific layer was needed to remedy the low accuracy of a network.
this is differentfrom the suboptimalnetwork structure ofmodeltype properties category asherethesolutionislocaltoaspecificlayer rather than affecting the whole model.
an interviewee described suchafault whichwasrelated nottothewrongarchitectureas whole butmoreusuallytothewrongtypeoflayer becauseusually inourfieldpeoplehaveappliedtypeoflayerswhichwerenotsuited for the type ofinputwhichtheyare processing .
1115taxonomyof real faults in deep learning systems icse may seoul south korea p q r s t q r s q t sr 6q r s q r s r9 q s t q r st q r s q r s q s q t s q sr q r s q r s r q s q s q r s q r s q r s q t s q r s q r s q r s q r s q s r q r s q r s q r s q r s q r s q r s q s q r s q r s q r s q s q t s q r s q r s q s t q s q r s t q s q s q r s q s q r s 6q t s q r s q r s q t s q t s q t s r p p p q r s q sr q r s9 q t s q r s q s q sr q r srr q r s q s 1q r sr q r s t r s r q r s q t s q s r r q sr q s r q s r q s t q s rr q r s q r sr t q s t q s q sr q s q s r q s q r s r q r s q s r q r s q r s q r s t q sr q r s q r s q r s figure final taxonomy 1116icse may seoul south korea humbato va andjahangirova et al.
layer properties.
this category represents faults due to some layer s incorrect inner properties such as its input output shape input sample size number of neurons in it.
as per interviewee s description wesettoolargenumberofneuronsandwehadlike veryslow training and validation .
activation function.
another important aspect of a neural networkistheactivationfunctionofneurons.ifnotselectedproperly itcandramaticallyruinthemodel sperformance.oneinterviewee noted that when i changed sigmoid activations into linear activations in the speech recognition it gaveme a gain .
tensors inputs.
this category deals with problems related to the wrong shape type or format of the data.
we encountered twodifferentclassesof faults inthis category wrong tensor shape.
a faultybehaviour manifests during some operationontensorswithincompatibleshapesoronasingletensor with incorrectly defined shape.
as shown in figure there is a numberofpossiblecausesforawrongtensorshape e.g.
missing outputpadding missingindexing or asitwasprovidedinoneof the interviews a case when a developer was using a transposed versionofthe tensor insteadofthe normal one .
wronginput.
afaultybehaviourisduetodatawithincompatible format typeorshapebeingusedasaninputtoalayeroramethod.
a wrong input to a method is a problem frequently observed in traditional software as well as in dl programming.
however in dl these faults happen to be of a specific nature ranging from the inputhavingunexpecteddatatype e.g.
string insteadof float or shape a tensor of size 5x5instead of 5x10 to cases when the input hasacompletely wrong format e.g.
awrongdata structure .one interestingexample ofa wronginput formatwasprovided byour interviewee my data was beingloaded in withchannel access first insteadoflast.sothatactuallywasasilentbuganditwasrunning and i actually don tunderstandhow it evenran butit did .
training.
this is the largest category in the taxonomy and it includesawiderangeofissuesrelatedtoallfacetsofthetraining process such as the quality and preprocessing of training data tuning of hyperparameters the choice of appropriate loss optimisation function.
it also accounts for the faultsoccurring when testing validating apreviously trainedmodel.
hyperparameters.
developersfacealargenumberofproblems whentuningthehyperparametersofadlmodel.themostreported incorrect hyperparameters are learning rate databatch size and numberofepochs.whilesuboptimalvaluesfortheseparameters do not necessarily lead to a crash or an error they can affect the trainingtime andthe overallperformance achievedbythe model.
an example from the interviews is when changing learning rate from or orders of magnitude we have found that it impacts the performance ofabout up to to in termsofaccuracy .
loss function.
this category contains faults associated with the lossfunction specificallyitsselectionandcalculation.wrongselectionofthelossfunctionorusageofapredefinedlossfunction maynotadequatelyrepresentthe optimisationgoalsthatamodel is expected to achieve.
in its turn a wrong calculation of a loss functionoccurswhenacustomlossfunctionisimplementedand some error in the implementation leads to the suboptimal or faulty behaviour.
as one interviewee noted they needed to get a morebalanced loss function than just something that can predict one class verywell and then screws up the other ones .
validation testing.
it includes problems related to testing and validating a trained model such as the bad choice of performance metrics orfaultysplit ofdata intotraining andtestingdatasets.
preprocessingoftrainingdata.
preprocessingofatrainingdataset is a labour intensive process that significantly affects the performance of a dl system.
this is reflected in the large number of elements in this category and in the high variety and number of its leaves.
at the high level we have separated the faults in this categoryintotwogroups missingpreprocessingandwrongpreprocessing.
the former refers to cases when a preprocessing step that wouldleadtoabetterperformancehasnotbeenappliedatall.in thelattercase thepreprocessingstephasactuallybeenapplied but eitheritwasofanunsuitabletypeorwasappliedinanincorrect way.examplesofthemostfrequentissuesaremissingnormalisationstep missinginputscalingorsubsampling andwrongpixel encoding.
it is important to remark that preprocessing steps for training data are heavily dependent on an area of application.
this explains the large variety of leaf tags in this category.
we had to omit some of them from the taxonomy figure due to the lack of space.
optimiser.
thiscategory isrelatedtotheselection ofan unsuitableoptimisationfunctionformodeltraining.wrongselectionof theoptimiser e.g.
adamoptimiserinsteadofstochasticgradient descent or suboptimal tuning of its parameters too low epsilon for adam optimiser can ruin the performance of amodel.
training data quality.
in this group fallall the aspects relevant tothequalityoftrainingdata.ingeneral issuesoccurduetothe complexity of the data and the need for manual effort to ensure ahighqualityoftrainingdata e.g.
tolabelandcleanthedata to remove the outliers .
more specific cases of data collection challenges include privacy issues in the medical field and constantly changinguserinterfacesofwebpages fromwhichthedataisgatheredautomatically.allofthisleadstothemostfrequentissuein thiscategory whichis notenoughtrainingdata.avariantofthis problem is unbalanced training data where one or more classes inadatasetareunderrepresented.moreover togetagoodclassification model it is important to ensure the provision of correct labelsfortrainingdata.however intheinterviewees experience gettingwronglabelsfortrainingdata isacommonandanannoying issue.
the set of other issues related to the quality of training data such as the lack of a standard format missing pieces of data or the presence of unrelated data e.g.
images from other domains are gatheredtogetherunderarathergeneraltag lowqualityoftraining data because specific issuesdepend onthe area of application.
training process.
this category representsthe faults developers faceduringtheprocessofmodeltraining suchas wrongmanagement of memory resources ormissing data augmentation.
it also containsleavesrepresentingtheexploitationofmodelsthataretoo big to be fitted into available memory or reference to non existing checkpoints during model restoration.
regarding the data augmentation one of the interviewees noted that it helped to make the datamorerealistictoworkbetterinlowlightenvironments while the other said that sometimes you add more pictures to data set and as a result you can face the overfitting of the network problem so sometimes data augmentation can help sometimes it can damage .
1117taxonomyof real faults in deep learning systems icse may seoul south korea gpuusage.
thistop levelcategorygathersallkindsoffaults related to the usage of gpu devices while working with dl.
there is no further division in this case as all the examples we found represent very specific issues.
some highlights from this category are wrong reference to gpu device failedparallelism incorrectstatesharingbetweensubprocesses faultytransfer ofdatato agpudevice.
api.thispartofthetaxonomyrepresentsabroadcategoryof problems arising from framework s api usage.
the most frequent iswrongapiusage whichmeansthatadeveloperisusinganapi inawaythatdoesnotconformtothelogicsetoutbydevelopers of the framework.
another illustrating example could be a missing orwrongly positionedapi call.
for each of the inner nodes of the resulting taxonomy we have calculatedthepercentageofcontributingso gitfaultsthataredetectableatruntime i.e.
ledtoacrashorerror .wedidnotconsider interviewsinthiscalculationasinmanycasestherewasnoknowledge on whether the fault led to a crash error or not.
as expected thetensors inputs branch of the taxonomy contained nodes with thehighestpercentageofsuchfaults specifically wronginput with and for its inner nodes and wrong tensor shape with .
another category with a high number of crashes errors causedbytheassociatedfaultsisthe layerproperties nodeofthe modelbranch as well as the apibranch .
.
contributions to thetaxonomy thefinaltaxonomywasbuiltusingtagsextractedfromtwodifferent sourcesofinformation so githubartefactsandresearcher practitionerinterviews.thetop5tagsobtainedfromso githubwith theirrespectivenumberofoccurrences shownas nn mm where nnrefers to so github mmto interviews are wrong tensor shape wrongshape ofinput dataforalayer missing preprocessing wrongapiusage and wrongshapeof inputdatafor amethod .
fortheinterviews thetop5tagsare missingpreprocessing suboptimalnetworkstructure wrongpreprocessing not enoughtrainingdata and wronglabelsfortrainingdata .
these lists have an intersection of only one tag missing preprocessing .
the top so github list contains two tags that did not occur in the other source wrong api usage wrong shape of input dataforamethod .thetop5interviewlistcontainsonesuchtag not enough training data .
moreover the number of occurrences is unbalanced between the two sources for the top so github tags there are occurrences while for the top interview tagsthe number becomes .
this shows thatthe two selected sourcesare quitecomplementary.
indeed the complementarity between these sources of informationisreflectedintheoveralltaxonomystructure.ifweconsider the five top level categories in the taxonomy i.e.
the five direct childrenoftherootnodeinthetaxonomy wecanfindonecategorytowhichinterviewtagshavenotcontributedatall namely theapicategory.
this might be due to the fact that api related problemsarespecificandtherefore theydidnotcomeupduring interviews where interviewees tended to talk about more general problems.similarly inthe gpuusage categorythereisonlyoneinterview tag.
tensors inputs is another category dominated by so githubtags thenumberofwhichis twicethenumberofinterview tags.
in contrast the main contributors to the modelcategory are interviews.
the largest difference is for the training category where interviews contributed times more tags which led to addition of two more subcategories.
the presence of training related faults onlyintheinterviewsisexpected asthesetypesofproblemscan not usually be solved by asking a question on so or opening an issue on github.
out of pre leaf categories one consists of tags providedonlybyso github api andanotheroneonlybyinterviews trainingprocess .
another pre leaf category trainingdata quality was abstracted from the few existing leaves only after collectingmoredatafromtheinterviews.theremaining16consist ofdifferentproportionsofthetwosources with6havinghigher number ofso github tags higher number of interview tags and2 the same amount of tags from the twosources.
overall the distribution of the tags shows that so github artefactsandresearcher practitionerinterviewsaretwoverydifferent and complementary sources of information.
ignoring one of them would provide an incomplete taxonomy which would not be representative ofthe full spectrumof real dl faults.
.
validationresults the results of the validation survey are summarised in table .
for each category we report the percentage of yes and no answers to thequestion asking whetherparticipants ever encounteredthe related issues.
we also show the perceived severity of each fault category and the perceived effort required to identify and fix faults in such a category.
there is nocategory of faults that the survey participantshaveneverencounteredintheirexperience whichconfirmsthatallthecategoriesinthetaxonomyarerelevant.themost approved category is training data with of yes answers.
accordingtotherespondents thiscategoryhas critical severityand requires high effort for and of participants respectively.
the least approved category is missing redundant wrong layer whichhasbeenexperiencedby24 ofthesurveyparticipants a nonnegligiblefractionofalltheparticipants .acrossallthecategories theaveragerateof yes answersis66 showingthatthe final taxonomy contains categories that match the experience of a large majority of the participants only two categories are below .
participants confirmed on average .
categories out of acrossallthe surveys.
table validationsurvey results categoryresponse severity effortrequired yes no minor major critical low medium high hyperparameters loss function v alidation testing pr eprocessing of training data optimiser t raining data t raining process mo del type properties missing re dundant wrong layer lay er properties a ctivation function w rong input w rong tensor shape gp u usage api 1118icse may seoul south korea humbato va andjahangirova et al.
someparticipantsprovidedexamplesoffaultstheythoughtwere not part of the presented taxonomy.
three of them were generic codingproblems whileoneparticipantdescribed theeffectof the fault ratherthanits cause.
theremainingthreecouldactuallybeplacedinourtaxonomy under missing api call wrong management of memory resources and wrongselectionoffeatures .wethinktheparticipantswerenot able to locate the appropriate category in the taxonomy because the descriptions in the survey did not include enough exemplar cases matching their specific experience.
discussion finaltaxonomyvs.relatedwork.
toelaborateonthecomparison with existing literature we analysed the differences between ourtaxonomyandthetaxonomyfromtheonlyworkwhereauthors compiledtheirownclassification offaults ratherthanreusingan existing one which is by zhang et al.
.
to ease the comprehension welist the categorieswiththe exactnamingand excerpts of descriptionsfrom the corresponding publication .
incorrect model parameter or structure ips bugs related to modelling mistakes arose from either an inappropriate model parameter like learning rate or an incorrect model structure like missingnodesorlayers .inourtaxonomywedistinguishtheselection of an appropriate model structure from the tuning of the hyperparameters.
so in our taxonomy class ips corresponds to two leaves suboptimalnetwork structure andsuboptimalhyperparameterstuning eachbelongingtoadifferenttop levelcategory modelandtraining respectively.
.
unaligned tensor ut a bug spotted in computation graph construction phase when the shape of the input tensor does not match what it isexpected .
class ut can be mapped to the wrong tensor shape and partly to the wrong shape of input data as far as itconcernstensors categoriesof our taxonomy.
.confusion with tensorflow computationmodel ccm bugs arisewhentfusersarenotfamiliarwiththeunderlayingcomputationmodelassumedbytensorflow .ccmdealswiththedataflow semanticsoftensors whichmightbeunintuitivetonovices.thisis adifficultythatdevelopersfacewhenstartingtoworkwithtensors in general.
we did not gather evidence for this fault because we excludedexamples toy programs andtutorials from our analysis.
zhangetal.didnotobservethisfaultingithub onlyinso .as theyremark theycanbecommonmistakesmadebytfusersand discussedat stackoverflowseeking advice .
.tensorflowapichange apic anomaliescanbeexhibitedby atfprogramuponanewreleaseoftensorflowlibraries .asthese bugsarerelatedtotheevolutionoftheframework theyaresimilar to those that affect any code using third party libraries.
hence we regardedthemasgenericprogrammingbugs notdl specificfaults.
.
tensorflow api misuse apim bugs were introduced by tf userswhodidnotfullyunderstandtheassumptionsmadebythe apis .
this class can be directly linked to the wrong api usage leaf intheapicategory withtheonlydifferencethatinourcasethe leafincludes apis from three not just one dl frameworks.
.
structure inefficiency si a major difference between si andipsisthatthesileadstoperformanceinefficiencywhilethe ipsleadstofunctionalincorrectness .thisclassofbugsissimilarto classips differing only in the observable effects functional vs efficiency problems which are not taken into account in our taxonomy we looked at the root cause of a fault not at its effects .
so the mapping is the same as for ips.
.
others o other bugs that cannot be classified are included inthistype.thesebugsareusuallyprogrammingmistakesunrelatedtotensorflow suchaspythonprogrammingerrorsordata preprocessing .
generic programming errors are excluded from our taxonomy which is focused on dl specific faults.
data preprocessingerrorsinsteadcorrespondtothecategory preprocessingof training data.
in summary zhang et al.
s classes ips si and apim map to leaf nodes of our taxonomy classes ut and o map to inner nodes although for out of the mapping ispartial .
in total see table1 our taxonomy has inner nodes and leaf nodes.
so our taxonomy contains inner nodes out of that represent newfaultcategorieswithrespecttozhang etal.
s 19outof24if wedonotcountdescendantsofmappednodes .forwhatconcerns the leaves the computation is more difficult when the mapping is partial because it is not always easy to decide which subset of leaves is covered by classes ut and o. if we conservatively overestimatethatallleavesthatdescendfromapartiallymapped node are transitively covered zhang et al.
s classes would cover 13leafnodes outof92 inourtaxonomy.thismeansthat79leaf categories have been discovered uniquely and only in our study.
ontheotherhand thetwounmappedclassesbyzhang etal.
ccm and apic correspond to generic programming bugs or bugs faced bynoviceswhoseekadviceabouttensorcomputationinso.we deliberately excludedsuch classesfrom our analysis.
overall alargeproportionofinnerfaultcategoriesandofleaf fault categories in our taxonomy are new and unique to our study whichhencerepresentsasubstantial advancement oftheknowledge of real dl faults over the previous work by zhang et al.
finaltaxonomyvs.mutationoperators.
mutantsareartificial faults that are seeded into a program to test under the assumption that fault revelation will translate from mutants to real faults.
theworksbyma etal.
andshen etal.
havemadeinitialattemptstodefinemutationoperatorsfordlsystems.thecombined listofmutationoperatorsfromtheseworkscanbeclassifiedinto twocategories pre trainingmutations appliedtothetraining dataortothemodelstructurebeforetrainingisperformed posttrainingmutations thatchangetheweights biasesorstructureofa model that has already been trained.
for each pre training mutant aftermutationthemodelmustberetrained whileforpost training mutants noretrainingis needed.
whethermutantsareavalidsubstituteforrealfaultshasbeen anongoingdebatefortraditionalsoftware .toobtainan insight on the correspondence between the proposeddl mutants and real faults indl systems we matched the mutation operators from the literature to the faults in our taxonomy.
table 3lists each pre training mutation operator and provides the corresponding taxonomycategorywhensuchamatchexists.thisisthecasefor allpre training mutation operators except datashuffle .
for whatconcerns the post trainingmutants there isnosingle faultinthetaxonomyrelatedtothechangeofmodelparameters afterthemodelhasalreadybeentrained.indeed thesemutation 1119taxonomyof real faults in deep learning systems icse may seoul south korea table taxonomy tags formutation operators from mutation operator taxonomy category data repetition unbalancedtraining data lab el error wrong labelsfortraining data data missing not enoughtraining data data shuffle noise perturbation lowquality oftraining data lay erremoval missing redundant wrong layer lay eraddition missing redundant wrong layer a ctivationfunctionremoval missingactivationfunction operators are very artificial and we assume they have been proposedastheydonotrequireretraining i.e.
arecheapertogenerate.
however their effectiveness is stillto be demonstrated.
overall wecannoticethattheexistingmutationoperatorsdo notcapturethewholevarietyofrealfaultspresentinourtaxonomy asoutof92uniquerealfaults leafnodes fromthetaxonomy only 6haveacorrespondingmutationoperator.whilesometaxonomy categoriesmaynotbesuitabletobeturnedintomutationoperators we think that there is ample room for the design of novel mutation operators for dl systemsbasedonthe outcome of our study.
stackoverflow vs.real world.
thestudybymeldrum etal.
which analyses papers that use so demonstrates the growing impact of so on software engineering research.
however the authors note that this raises quality related concerns as the utility and reliability of so is not validated in any way.
indeed wecollectedfeedbackonthis issuewheninterviewingthetopso answerers.
all so interviewees agreed that the questions asked onsoarenotentirelyrepresentativeoftheproblemsdevelopers encounterwhenworkingonadlproject.oneintervieweenoted thatthesequestionsare somehowdifferentfromthequestionsmy colleagues will ask me while the other called them two worlds completely different worlds .
interviewees further elaborated on whytheythinkthisdifferenceexists.onereasoningwasthat most engineersintheindustryhavemoreexperienceinimplementing in tracing the code so their problems are not like how should i stack these layers to make a valid model but most questions on so are like model building or why does it diverge kind of questions .
another argumentwasthatthequestionsonsoaremostly sortofbeginner questionsofpeoplethatdon treallyunderstandthedocumentation and that they are asked by people who are extremely new to linear algebra and to neuralnetworks .
weaddressedthisissuebyexcludingexamples toyprogramsand tutorials from the set of analysed artefacts and by complementing our taxonomy withdeveloper interviews.
commonproblems.
ourinterviewswithdeveloperswereconducted to get information on dl faults.
however due to thesemistructured nature of these interviews we ended up collecting information on more topics than that.
the version incompatibility between different libraries and frameworks was one of interviewees mainconcerns.theyalsoexpressedtheirdissatisfactionwith thequalityof documentation available with onedevelopernoting that this problem is even bigger for non computer vision problems.
anotherfamilyofproblems mentioned very oftenwasthe limited support of dl frameworks for a number of tasks such as implementationofcustomlossfunctionsandofcustomlayers serialisationof models and optimisation of model structure for complex networks.thelack of tools to support activities such as performance evaluation combining outputs of multiple models converting models fromoneframeworktoanotherwasyetanotherchallengingfactor according to our interviewees.
threats to validity internal.
a threat to the internal validity of the study could be the biasedtagging oftheartefactsfrom so github and ofthe interviews.tomitigatethis threat eachartefactandinterviewwas labelledbyatleasttwoevaluators.also itispossiblethatquestions asked during the developer interviews might have been affected by the initial taxonomy based on so github tags or that they have directed theinterviewees towards specific typesof faults.to prevent this from happening we kept the questions as generic and disjointfromtheinitialtaxonomyaspossible.anotherthreatmight berelatedtotheprocedureofbuildingthetaxonomystructurefrom a set of tags.
as there is no unique and correct way to perform this task thefinalstructuremighthavebeenaffectedbytheauthors pointof view.for this reason itwas validatedviasurvey.
external .
the main threat to the external validity is generalisation beyond the three considered frameworks the dataset of artefactsusedandtheinterviewsconducted.weselectedtheframeworks based on their popularity.
our selection was further confirmed by the list of frameworks that developers from both the interviewsandsurveyhadusedintheirexperience.tomakethe final taxonomy as comprehensive as possible we labeled a large number of artefactsfromso githubuntil we reached saturation oftheinnercategories.togetdiverseperspectivesfromtheinterviews we recruited developers with different levels of expertise andbackground acrossawide range of domains.
conclusion wehaveconstructedataxonomyofrealdlfaults basedonmanual analysis of github so artefacts and interviews with developers.
the taxonomy is composed of main categories containing375instancesof92uniquetypesoffaults.tovalidate the taxonomy we conducted a survey with a different set of developerswhoconfirmedtherelevanceandcompletenessofthe identified categories.
in our future work we plan to use the presented taxonomy as a guidance to improve dl systems testing and as asourcefor the definitionof novel mutation operators.