representation of developer expertise in open source software tapajit dey the university of tennessee knoxville tn usa email tdey2 vols.utk.eduandrey karnauch the university of tennessee knoxville tn usa email akarnauc vols.utk.eduaudris mockus the university of tennessee knoxville tn usa email audris utk.edu abstract background accurate representation of developer expertise has always been an important research problem.
while a number of studies proposed novel methods of representing expertise within individual projects these methods are difficult to apply at an ecosystem level.
however with the focus of software development shifting from monolithic to modular a method of representing developers expertise in the context of the entire oss development becomes necessary when for example a project tries to find new maintainers and look for developers with relevant skills.
aim we aim to address this knowledge gap by proposing and constructing the skill space where each api developer and project is represented and postulate how the topology of this space should reflect what developers know and projects need .
method we use the world of code infrastructure to extract the complete set of apis in the files changed by open source developers and based on that data employ doc2vec embeddings for vector representations of apis developers and projects.
we then evaluate if these embeddings reflect the postulated topology of the skill space by predicting what new apis projects developers use join and whether or not their pull requests get accepted.
we also check how the developers representations in the skill space align with their self reported api expertise.
result our results suggest that the proposed embeddings in the skill space appear to satisfy the postulated topology and we hope that such representations may aid in the construction of signals that increase trust and efficiency of open source ecosystems at large and may aid investigations of other phenomena related to developer proficiency and learning.
index terms expertise developer expertise vector embedding doc2vec api api embedding project embedding developer embedding skill space machine learning open source world of code i. i ntroduction the number of projects and developers involved with open source software has reached staggering heights e.g.
github reported that over million new developers joined and over million new projects were created in alone1.
while many of these developers or projects are based on individual effort further statistics such as over million pull requests being merged and million issues being closed in the past year on github alone demonstrate that open source development is a highly collaborative effort.
the key premise of open source software is not only to share the code but more importantly to enable contributions from the community .
however despite improved tools and enabled by social coding platforms such as github it is not always easy to get contributions accepted and as many studies have shown repeated interactions between the maintainers and contributors are necessary to establish trust and increase the chances of pull request acceptance or issue resolution .
however this method of building reputation and trust by repeated interactions does not scale very well and with a growing number of developers and an increasing number of projects their code may depend on other means of establishing trust are becoming necessary.
previous work has shown that both technical and social aspects of a developer s reputation can play an important role in building the trust between themselves and other developers.
while social aspects such as previous collaboration can greatly increase the trust between two developers these aspects are not broadly applicable as they enhance trust within an already established developer circle.
for a developer looking to contribute for the first time to a project outside of their social circle the technical aspect of their reputation often referred to as expertise may serve as an important source of trust for other developers when evaluating a developer as a potential team member or collaborator .
we therefore concentrate on gauging the relevant expertise of a developer based on their previous development activities.
such measure if it could be obtained might partially substitute for the traditionally laborious reputation building process as a developer transitions from a peripheral participation in a project to a contributor role and could potentially increase the efficiency of the open source development as a whole.
however previous attempts at measuring developer expertise either focus on very detailed views e.g.
counting experience atoms associated with changes made by a developer on a specific source code file or at the least granular level counting the volume frequency and breadth of a developer s overall activities.
unfortunately the former approach can not be applied for developers who have never participated in a specific project while the latter does not account for the specific experience of a developer beyond the aggregated activity traces and projects they ve worked on.
aggregates of developer s contributions by programming language was previously proposed by amreen et al.
however experience in a particular language does not immediately confer experience in the variety of libraries or frameworks in that ieee acm 43rd international conference on software engineering icse .
ieee language which specific applications might rely on.
however this measure of domain expertise or expertise measured by the fluency of using specific apis is something that may be of greater concern to projects than a potential contributor s overall skill in a language.
in this work we try to measure and evaluate such specific domain expertise by defining what we refer to as skill space that can be applied to developers projects and individual programming languages or apis as well.
in other words skill space provides avectorrepresentation forindividual developers projects program ming languages orapis with thetopol ogy oftheresultingrepresentations skill vectors reflectingtheconceptual andpractical api related relationships among these four entities.
to operationalize this skill space we use the world of code woc data that contains apis extracted from changes to source code files discussed further in section iv b in programming languages.
we employ doc2vec text embedding that uses as input the dependencies apis of a file modified in each change made by a developer to produce the skill space representation for individual apis developers projects and languages.
the topology in this space is defined by the alignment cosine similarity between vectors representing any pair of developers projects apis developers and apis developers and projects and projects and apis.
compared to similar other methods see section iii using skill space offers the following practical advantages a ability to compare the developers projects and the apis in the same space b a more faithful representation of expertise due the completeness of the training data entire oss c crosslanguage comparison d up to date representation of expertise based on the latest version of world of code woc dataset.
our key contributions consist of a conceptualization of developer skill expertise that transcends individual project boundaries making it specific enough to determine its relevance in a novel context b postulating the desirable topology of the resulting skill space c proposing doc2vec embedding method for operationalizing the skill space and d an empirical evaluation of the proposed topology for this operationalization.
a replication package for this paper is made available at .
in the rest of the paper we start by describing the specific research problems in section ii.
the related works are described in section iii.
we describe our methodology in section iv and the evaluation results for our proposed embedding for the proposed skill space is described in section v. details of the replication package we shared is described in section vi.
we describe the limitations to our study in section vii the planned extension of the proposed technique in section viii and conclude the paper in section ix.
ii.
r esearch problem our aim in this paper is to define a feasible representation of a developer s expertise in specific focus areas of software development by gauging their fluency with different apis.
such medium granularity representation of developerexpertise might serve as a way to get a better understanding of developer skill help recommender systems that suggest apis projects or contributors or to increase the trust between external contributors and maintainers of a project.
to achieve these goals we define the concept of skill space and we propose the desirable properties and an operationalization of this concept.
we quantify skill space based on the world of code woc data that contains information on the apis extracted from changes to source code files discussed further in section iv b in programming languages.
a. postulated properties of skill space the critical feature of our concept of skill space is the ability to make direct comparisons among three entities developers projects and apis.
the simplest way to accomplish that is to represent each entity as a vector in a linear space.
once such representation is accomplished for it to be meaningful it needs to satisfy several simple properties first we expect that the skill vectors of apis representing similar skills will be close to each other second a developer s skill vector should be similar to the representation of the apis they use most frequently third a project s skill vector should be similar to the representations of the apis used in these projects finally we expect the developer representations to be aligned with their subjective perceptions of their api mastery.
apart from these four fundamental properties for skill space to be useful in practice we expect a few additional properties to be satisfied first in order to predict api usage we expect that the new apis a developer will use in the future should have representations more similar to the representations of apis they have used in the past compared to randomly selected apis second we expect that new apis added in projects should also follow a similar pattern third we expect that developers will be more likely to join new projects that have representations similar to themselves in the skill space .
we also expect other manifestations of good skill spaces in terms of outcomes of developer work e.g.
the closeness between the skill vector of a developer who submitted a pull request pr to a project and that of the target project should have a significant impact on the pr acceptance probability.
skill spaces satisfying these properties can obviously be of practical and theoretical use hence our objective in this paper is to construct such a skill space and to evaluate if it satisfies these desirable properties.
b. operationalization of skill space to produce the representations in the skill space we follow previous successful approaches such as degree of knowledge model and experience atom that take the uncontroversial position that developer s skill increases as they complete and repeat tasks requiring a specific skill.
in the context of software engineering that involves making changes to the source code.
since we are trying to capture the experience of using programming apis we capture the apis that a modified source code file depends upon.
we further discuss the pros and cons of this choice and potential alternatives in 996section vii.
since many of the software source code files are an approximation of software modules the collection of the apis a file depends upon should represent a specific use case of the functionality instantiated by the file and should thus provide implicit dependencies between the apis utilized in that file.
the entirety of all source code thus should embody all realized relationships among apis.
once these implicit relationships among apis based on changes to the source code are captured the representation of a developer in theskill space could simply be derived from the changes they have made the representation of a project through changes made in that project and the representation of a programming language through all changes involving that language.
a naive representation of each change would simply be a high dimensional vector2that represents each of the distinct apis extracted from over billion changes to the source code files of the languages under consideration.
however such representation of apis in the skill space is not very effective or practical and techniques from text analysis may be used to reduce the dimensionality of this vector.
the key underlying assumption of text analysis techniques is that words in a natural language are used in certain combinations to express certain ideas or thoughts.
the unsupervised approaches where the relationships are learned directly from the corpus of text assume that the words within a document have to be related and represent some underlying idea expressed by that document.
for larger documents sliding window techniques are often used to restrict the length of text where these assumed relationships among words pertain to the same idea.
similarly we assume that a combination of apis used in a software module would also reflect some aspects of the functionality implemented in that module.
the number of apis in a single file tends to be quite low as we find in table i so there is no need for sliding windows when representing the api.
however text analysis methods need a large corpus of natural language text to extract the semantics from word combinations.
we similarly expect that the skill space representation would require a very large corpus of software modules to represent these distinct functionalities and the associated skill of developers who implemented it .
in this paper we use doc2vec text embedding approach to produce the skill space representation not just for individual developers but also for individual apis projects and even languages.
as a result the proposed skill space representation can be used to calculate a direct measure of alignment between any pair of developers projects apis developers and apis developers and projects and projects and apis.
c. evaluation criteria a conceptual definition also needs practical utility therefore to evaluate the suitability of our proposed skill space representation we investigate several practical scenarios where developer expertise and trust might come into play and we 2we counted over million distinct import use package etc.
statements in the programming languages from woc version rexpect that a closer alignment between developers and apis or projects in the skill space will increase the likelihood of a positive outcome in these events.
specifically we pose the desirable properties of the skill space outlined in section ii a as hypotheses which we evaluate to determine if the proposed representation of a developer s specific expertise in the skill space might be useful in practice by evaluating the following topological properties of the skill space h1 a developer is more likely to choose new apis that are more closely aligned3with themselves.
h2 a developer is more likely to join new projects that are more closely aligned to themselves.
h3 a project is more likely to accept contributions from developers who are more aligned with the project.
h4 developers better aligned with the project s will have better odds to have their pull requests accepted.
h5 a developer s self reported api skills are closely aligned to their own representation in skill space .
iii.
r elated work in this section we present an overview of the historic efforts to measure developer expertise and outline the role of word embeddings in the software engineering literature to clarify the existing gaps we try to address with our work.
a. developer expertise the fascination with developer expertise and its variation began in the early days of software development .
early work was primarily motivated by the need for software project cost estimation and focused on various ways to measure the size of software by adjusting lines of code for different languages or attempting to design ways to have a language independent measure of software size .
the later works embraced the idea that beyond language each software project requires long and arduous work by a developer to comprehend its internal complexities .
this suggested that developer expertise is project and file specific with approaches such as expertise browser assuming that each change to a source code file represents an experience atom whereby a developer changing code is forced to understand the files internal design and perhaps impart of their own design through implementing that change.
however these early measures of lines of code written and file specific experience atoms pertain to expertise within a specific project.
they do not provide a general enough profile of developer expertise that can be transferred among software projects.
contemporary social coding platforms e.g.
github provide a variety of indicators of developer activity the timeline of commits and their social status followers .
this has sparked a variety of research into how developer traces and developer profiles can provide insight into a developer s expertise.
these studies include qualitative approaches such as the one by marlow et.
al.
who showed that your developer profile on github can help other developers gauge your general 3since we use cosine similarity to measure the closeness between entities the word alignment is a better choice than a more conventional distance.
997coding ability and project relevant skills but only at a more general level.
similarly singer et.
al.
interviewed developers and employers to observe how they utilize developer profiles to gauge the quality of a potential new hire.
the results showed that profile sites with a skills word cloud representing the technologies languages frameworks etc.
a developer claimed to be familiar with proved to be the most helpful assessment of a developer s expertise.
these works indicate that more specific measures such as language specific technologies and frameworks help others gauge the relevant expertise of developers in open source.
there have also been several attempts to automate the process of identifying developer expertise through social coding platforms e.g.
cvexplorer is a tool created to expose developer expertise using a word cloud of all relevant technologies frameworks and general skills by parsing their commit messages and readme files.
scsminer is another tool created to help identify experts on github based on an arbitrary input query.
the authors also obtain expertise attributes by parsing readme files of projects a developer has contributed to but they extend this by creating a generative probabilistic expert ranking model to rank developers based on certain skills or expertise one might be looking for.
lastly hauff et.
al.
attempt to match developers with job advertisements based on a developer s expertise by extracting relevant terms from readme files and mapping them to the same vector space as job advertisements and ranking all developer profiles based on the cosine similarity they share with the job advertisements.
cosine similarity has been used in similar contexts in a number of earlier studies e.g.
and was also used for evaluating the performances of the doc2vec and word2vec techniques .
while all of these approaches are a similar step in the same direction as us they provide a weaker link between developers and their technologies than desired by utilizing readme files as the main source of developer expertise while we extract language specific apis from files a developer has modified.
furthermore along with measuring a developer s similarity to the technologies they use as attempted in previous work we also aim to use the apis to measure the similarity between developers projects developers and projects and projects and apis.
we also motivate our work through some more recent studies.
montandon et.
al.
present an approach to determine experts for three javascript libraries.
the authors identify developers who have made changes to projects that depend on these libraries and conduct a survey with developers to obtain their self reported expertise.
using these survey results as validation the authors argue that their clustering approach is feasible and can be used to identify relevant experts.
however they also present the shortcomings of using basic github profile features for machine learning classifiers to predict expertise in software libraries.
we utilize the survey dataset provided by the authors for our own evaluation and also attempt to better predict developer expertise in software libraries an area in which the authors achieved poor performance.
the more recent import2vec paper produces em beddings for each imported package.
the authors do such embeddings for javascript python and java and provide some qualitative evidence suggesting that these embeddings of apis accurately reflect different functionality profiles by providing a number of examples where the similar apis also appear to implement similar functionalities.
unfortunately none of the proposed approaches are suitable for directly comparing developers and projects as neither developers nor projects are accurately represented in the same vector space as the api embeddings.
it is therefore not clear how import2vec embeddings can be used to represent developers domain expertise nor if such profiles would accurately reflect developer proficiency.
furthermore the import2vec approach can not be applied in a cross language context.
our proposed approach tries to address this gap by constructing a skill space representation that on one hand may transcend the specific programming languages and on the other hand may identify a meaningful representation that can be matched with skill sets of other developers or projects.
b. vector embedding in software engineering vector embeddings have been used in software engineering for various tasks e.g.
using natural language associated with coding to determine sentiment using writing style in commit messages to determine developer identity or improve requirements traceability .
in these cases the natural language techniques do not need to be modified substantially as the underlying data represents natural language.
even more techniques have been applied to model programming language source using text analysis techniques.
for example these approaches can improve interactive development environments ides by performing next token prediction suggesting better class names or even automatic patching .
in a recent paper alon et al.
proposed a method for representing snippets of code as continuous distributed vectors code embeddings .
the attempt to provide a common embedding space for natural language and code was proposed by ye et al.
by training the natural language models on the api documentation and the applications that use these apis.
unlike these approaches we focus on training the models on the apis used in files that undergo a code change.
while we do not go to the level of a specific function used in the api we treat each import use statement as an indication of the specific functionality provided by the corresponding package.
as noted above the best natural language analysis techniques typically exploit the order of the words in a text document such as commit messages requirements or documentation .
the programming language modeling techniques also rely heavily on the specific sequence that is necessary to do an accurate prediction of the next token for example.
in contrast our work looks at embedding package imports within source code files where the order of import statements may not be important.
thus the existing techniques that attempt to model the order of the tokens need to be modified to fit our purpose.
998iv.
m ethodology to represent our entities in the skill space we need a very large corpus of software and we turn to world of code woc due to its size coverage data quality and the ability to obtain desirable subsamples as described below.
a. data source world of code woc is a prototype of an updatable and expandable infrastructure aimed at supporting research and tools that rely on version control data from open source projects that use git.
it stores large and rapidly growing amounts of data that approximates the entire floss ecosystem and provides capabilities to efficiently extract and analyze the data at that scale.
in addition to storing objects from all git repositories woc also provides relationships among them.
the primary focus of woc is on the types of analyses that require global reach across floss projects so it is the most appropriate choice for answering the research questions we presented here.
woc data is versioned with the latest version labeled as r containing .
billion blobs billion commits .
billion trees .
million tags million projects distinct repositories and million distinct author ids.
this version of woc data was collected during march .
as is often the case with datasets of this size certain data cleaning steps are critical for obtaining meaningful results.
conveniently in addition to providing access to the raw data woc offers advanced data augmentation capabilities.
two such techniques were used in this study for data preprocessing fork resolution deforking and developer identity resolution since our skill space representation considers the relationship among projects developers and their api usage.
accurately representing all three of these entities is therefore necessary.
project clones fork resolution git is a distributed version control system that inherently makes it easy to clone or fork git projects.
this however creates a unique data cleaning problem for woc which has over million projects many of which are clones or forks of another project.
this poses several problems for our expertise analysis.
one such problem is that a developer who contributes to a highly cloned project will have their commits appear in the remaining cloned projects as well e.g.
if a developer contributes to one project using the flask module in python and other people clone this project and make little to no changes the developer would be attributed with having worked with flask on different projects rather than just one.
to address this we use the dataset published in which applies the louvain community detection algorithm to a massive graph consisting of links between commits and projects in woc because two projects are highly unlikely to share the same exact commit unless they are clones .
we leverage that work to combine commits from the forked projects and ensure that we do not count the same projectrelated information multiple times due to these forks clones.
identifying a developer identity resolution the woc dataset contains the author id for each git commit which would ideally correspond to a single developer and could beused to aggregate all commits associated with the author id and perform our expertise analysis.
however this is seldom the case as the author id is obtained from the git configuration file residing on the developer s laptop desktop server where they use git.
the author id tags therefore often differ between commits made on different computers used by a developer.
as a result many developers have multiple author ids with some that they might not even be aware of in woc collection that collectively need to represent the same developer.
to address this we have used a dataset shared by fry et al.
that resolves the million author identities in woc version q by creating blocks of potentially related author ids e.g.
ids that share the same email unique first last name and then predicting which ids actually belong to the same developer using a machine learning model.
the approach identified over million author ids belonging to at least one other author id.
from this set around .
million developers were identified with a median of two author ids per developer.
when performing the expertise analysis described in this paper we identify each developer using the new associations created by the identity resolution approach.
this allows us to create a much more accurate representation of each developer s api usage and expertise and helps us avoid comparing two author ids that are in fact the same developer.
b. api extraction to obtain developer api usage we utilize the language mappings inside woc.
these mappings contain apis extracted from changes to source code files in c c java fortran go javascript python r rust scala perl ruby dart kotlin typescript and julia languages as well as source code present in jupyter ipython notebooks4.
the mappings are created by first obtaining all files in woc with extensions used by each of the languages listed previously.
for each language the woc file to blob5map is used to obtain all blobs associated with language specific files.
the content of the resulting blobs is then parsed for import statements depending on the syntax of each language e.g.
include in c import in java python use in perl the dependencies in the package.json file for npm and so forth .
each of these blobs versions of the source code is further mapped to the commit s that produced it and projects that have that commit.
timestamps authors and projects of these commits are then associated with the blob as well as with the apis parsed from that blob resulting in the following tuple programming language repository timestamp author id timestamp api1 ... .
we use deforking and author aliasing described above to transform repository into deforked project id and author id into aliased developer id.
the timestamp allows us to perform time based prediction in some of our models as discussed in section iv e. thus the final mapping and data used by some of the models is a compressed file of entries containing 999project timestamp developer api1 api2 ... where each entry represents all modules apis included in the file that the developer added to the project at the instance in time.
there is a unique set of entries for each language listed earlier and they are stored in separate compressed files.
while this mapping serves as the base data for most of our analysis there are several intermediate steps that require a transformation of the provided mapping as well.
c. summaries of api usage the previous subsection describes the procedures used to obtain the data from woc version r that captures for each modification to the source code the programming language the timestamp the developer the project and the list of import statements.
table i shows the number of deltas changed blobs associated with each language as well as the number of distinct authors and projects involved.
the largest number of delta by far involve c and c we do not distinguish between the two followed by java and python.
the relatively low number of javascript delta relates to the way dependencies are specified in javascript projects where a single file package.json is used to specify the dependencies while in c java or python every source code file needs to include its dependencies explicitly.
notably java language dominates in terms of the number of unique apis presumably because the apis in java can be specified using global namespace while for other languages they are defined by the package managers or within the source code files like .h files in c c that may share the same name but be otherwise unrelated see section vii .
as noted above the total number of distinct apis we observe is far higher than the number of words in a natural language putting computational strains on the text analysis methods designed to deal with many orders of magnitude smaller dictionaries.
moreover the order of the apis in source code files is not important hence we need to apply methods that do not attempt to model the sequences.
while some early text analysis methods such as lsi work strictly on the bag of words bow and are immune from this problem.
others such as continuous bag of words cbow try to predict words within a certain window size.
the wider the window the more complicated and time consuming it is to fit these models.
to investigate what window sizes might be appropriate we investigate the distribution of the number of distinct apis within a single delta a modification by a single commit to one source code file .
table i shows the fraction of delta for each language where the number of distinct apis is less than and also shows the maximum number of apis.
again javascript is an outlier here since a single file package.json defines apis for the entire project.
we chose to consider the window size of or less for the cbow models since it captures most of the deltas for all languages.
the deltas with huge numbers of apis used may indicate unusual cases or outliers that may not bringmuch information to which apis are used together and it is not unreasonable to exclude those from consideration.
the total number of delta and the number of distinct apis pose serious computational challenges if we want to fit the complete dataset obtained from woc with .3b delta and over 100m distinct apis not counting the number of distinct projects and authors.
we therefore fit several smaller datasets by filtering the data to a more manageable size.
first for the multi language model we focus on developers that made between and 25k commits partially to exclude the bot activities and partly to consider ordinary but productive developers since by the premises of our proposed hypotheses we re trying to focus on developers who have a good amount of contributions in social coding platforms since our assumption is that they will use new apis contribute to multiple projects and will submit a number of pull requests.
this filter reduces the total number of delta down to .2b.
for language specific models we are dealing with much smaller datasets but we can decrease that size even further by randomly sampling projects or developers.
we used these smaller samples to debug the techniques and to find the parameters for the skill space embeddings that produce feasible results before running the computation on the entire model.
d. vector embedding since the total number of possible apis that can be used by a developer or a project across different languages is extremely large and the naive embedding representing api usage as a component of over a 100m dimensional vector is not practical we reduce the dimensionality of the skill space .
we chose to employ doc2vec embedding method since it is capable of embedding not only the apis themselves but developers and projects at the same time.
it is also one of the most efficient embeddings to compute an important consideration given the large data corpus we handle.
word2vec is a highly computationally efficient algorithm used to create a numerical representation for a word using a continuous bag of words or skipgram two distinct algorithms .
the primary assumption of word2vec is that only words that are close together in a document are semantically related.
in our context that assumption doesn t hold because there is no semantic order for the apis used by a developer or a project.
we address this potential problem by using the continuous bag of words algorithm with a wide window of words.
since the number of apis associated with a single blob rarely exceeds as shown in table i the algorithm in practice predicts one api of a blob using all remaining apis.
doc2vec is an extension of word2vec where in addition to word api embeddings the model also produces the embeddings for an arbitrary set of tags associated with a group of apis as is the case when an author a project and a language is associated with the set of apis extracted from each change of every file.
the continuous bag of words analog in doc2vec corresponds to obtaining doc vectors by training a neural network on the synthetic task of predicting a word based on an average of both context word vectors and the full 1000table i summary of data retrieved from woc version .rperlanguage language delta changed blobs authors projects distinct apisfraction of deltas changed blobs with or fewer apismax no.
of apis in one delta changed blob for tran .
julia .
r .
ipython .
perl .
rust .
dart .
kotlin .
typescript .
c .
go .
scala .
ruby .
javascript .
python .
c c .
java .
document s doc vector.
we used the gensim framework for evaluation due to its high performance.
e. evaluation strategies the evaluation strategy involves fitting a doc2vec model on past data where each document represents the apis encountered in a single delta and the document tags represent the language the project and the developer.
the resulting model thus creates vectors for each api for each developer each project and each language.
we then obtain new apis a developer uses during the testing period the new projects the developer joins and the new developers who join a project during the testing period.
the alignment to these factual apis projects developers are then compared with randomly chosen sets of apis projects developers of the same size.
we chose the dates so that we have a fairly short testing period starting from february .
all changes prior to that date were used to fit the model and the activities past that date to check the predictions.
we used these dates for predicting new apis developers joining new projects and projects accepting new contributors.
for pr acceptance and self reported expertise we fitted models based on data prior to feb and tested on activities after that time in order to have a sufficient number of accepted or rejected prs during the testing period for most developers.
to conduct the study of pull request acceptance we sourced the pull request dataset used by dey and mockus for verifying our hypothesis and studying the effects of technical and social factors on pr acceptance.
the dataset contained information on prs from popular npm packages and github users who created those.
we filtered this dataset to only include developers who made between and commits similar to what we did for testing earlier hypotheses.
in addition we removed small projects that didn t have any api calls.
after filtering we were left with prs made by developers for github projects.then as in the other cases we proceeded to obtain embeddings for the developers and projects using past data and then model the acceptance rate during the future pr activity using the binomial regression with the independent variable representing the alignment of the developer and project vectors where the prs have been submitted to together with the predictors used by .
we once again use february to separate training and test data.
finally we use a previously reported survey of javascript developers to compare how aligned each surveyed developer is to the the api in which developers were reported to be proficient.
since the survey did not include apis where developers reported being not proficient we randomly chose ten other apis under the assumption that they might not be equally proficient in these randomly chosen apis.
as in other comparisons we report the difference in alignment between the self reported expert apis and the randomly chosen apis.
to make the skill space representations commensurate with developer self reported expertise we only use the data close to the time when the survey was conducted also february .
given the very large vocabularies for the apis we chose a relatively high dimensional vector of for skill space to make sure there is enough flexibility to represent the extremely large number of potential skills.
we excluded apis that occur in fewer than five deltas to increase computational efficiency and also avoid highly uncertain embeddings.
as discussed above we chose a window size of to ensure that the order of apis in the delta does not matter.
finally we chose the negative sampling parameter to be .
it tends to speed up the convergence by creating synthetic samples api combinations that do not exist in the data and penalizes the model if it produces a good fit for such negative samples.
all of these parameters were chosen after extensive experimentation fitting the models on manageable size datasets.
1001table ii summary of per language results of t test showing the difference of alignments between a developer s representation in the skill space and the api s they used in future vs .random api s they didn t use in the same language .
p values 1e are shown as .
language estimated difference in means95 confidence intervalp value dart .
.
.
.12e julia .
.
.
.57e r .
.
.
.46e ipython .
.
.
.68e perl .
.
.
.85e rust .
.
.
.01e kotlin .
.
.
.09e typescript .
.
.
c .
.
.
.16e go .
.
.
scala .
.
.
.45e ruby .
.
.
.80e java .
.
.
c c .
.
.
python .
.
.
javascript .
.
.
for tran .
.
.
.
v. r esults a. qualitative evaluation of skill space embeddings for a qualitative evaluation of our proposed embedding we decided to observe which apis are reported as similar to others in the same language and also which apis provide similar functionality across different languages.
for the python package pandas we observed that the apis reported to be most similar are indeed the ones that are most frequently used with it primarily for data manipulation data visualization machine learning applications.
mod.most similar pandas matplotlib.pyplot .
numpy .
seaborn .
we can also do some arithmetic with the resulting vectors by asking what are packages the most similar to python pandas package in r language mod.wv.similar by vector mod.docvecs mod.docvecs mod.wv.get vector pandas as we see the most popular data frame after which pandas was modeled packages are most similar.
also only r packages appear in the most similar list even though we start from the python package and move in the direction of r. b. examining h1 new apis used by developers are closely aligned to themselves in the skill space we follow the process outlined in section iv e to get the alignment between embeddings of each developer created by the apis they used during the training period and the new apis used in the testing period and a set of random apis in the same language that they did not use.
we did the calculation separately for each language to get a clearer understanding of the performance of our proposed skill space embeddings at that level.we were unable to fit model for the entire corpus it would have taken several months on a fast multi processor server .
instead we sampled 36k projects that contain .2b delta by 690k authors in all languages.
the amount of data for each language is similar to that in the entire corpus.
the paired t test results in table ii show that the apis used in the future were indeed more closely aligned as compared to random apis they didn t use.
the amount of data for the fortran language in the sample was too small to get a statistically significant difference.
c. examining h2 a developer is more likely to join a new project that is more closely aligned to them in the skill space here we try to validate the expectation that the new projects a developer will join make an accepted contribution to would be more closely aligned with the developer s skill vector than a randomly selected project.
as described in section iv e we calculated the alignment between embeddings of each developer and the projects they contributed to and a set of random other projects in the same language that they did not contribute to and measured if there is any significant difference between them using t test.
we found there is indeed a significant difference p value .2e with a difference between the estimated means of the cosine similarity of and confidence interval of .
this supports our hypothesis that there is a similarity between the developers vectors and vectors of the projects they contribute to in future.
d. examining h3 a project is more likely to accept contributions from developers who are aligned to the project in the skill space one of the potential skill space applications is increasing trust.
new contributors who have skill vectors aligned to a project s skill vectors should be more likely to have their contributions accepted all other factors being equal.
their skill if it exists should manifest itself in the technical aspects of the pr and therefore might be recognized by the maintainers of that project.
once again we constructed skill vectors for the developers who contributed to a project measured the alignment between them and the skill vectors of the corresponding projects and compared them with the alignment between skill vectors of a project and the skill vectors of randomly chosen developers who did not contribute to that project.
the differences between the alignments were found to be significant using t test with p value .2e an estimated difference of means between the alignments being .
and a confidence interval of .
e. examining h4 a developer whose skill space is aligned more closely to the project s skill space will be more likely to have their pull requests accepted to more directly evaluate the previous hypothesis here we restrict our attention to pull requests formal external contributions where we can see not only the cases when the contribution was accepted as above but also cases where the 1002table iii result of logistic regression model predicting pr acceptance .cosine similarity between developer and project is the variable we introduced in this study highlighted in gray .
other variables are adopted from .
t he non significant variable is highlighted in red binary variables are in blue predictor coefficient std.
error p value intercept .
.
.24e cosine similarity between developer and project0.
.
.10e creator submitted .
.
2e creator accepted .
.
2e repo submitted .
.
.62e repo accepted .
.
2e dependency .
.
2e age .
.
2e comments .
.
2e review comments .
.
2e commits .
.
2e additions .
.
.
deletions .
.
2e changed files .
.
2e contain issue fix .
.
.89e user accepted repo .
.
2e creator total commits .
.
2e creator total projects .
.
.
contain test code .
.
.
contribution was made but not accepted.
as previously we hypothesize the developers alignment with projects in skill space should have a significant impact on pr acceptance probability with a better alignment being associated with a higher chance of acceptance.
we used a regression model for this analysis as mentioned in section iv e. the result of the logistic regression model is presented in table iii which shows that the alignment between developers and projects remains a significant variable even after accounting for the other social and technical factors described in i.e.
this variable describes a factor which is not captured by other technical and social factors.
we also notice that the coefficient for this variable is positive i.e.
the closer a developer s alignment is to a project the higher the chance of their pr being accepted which validates our proposed hypothesis.
we checked the variance inflation factors for these variables and found the values to be less than .
in all cases signifying that there is no multicollinearity effect.
the variable contain test code was found to be insignificant similar to .
however the variable deletions was found to be insignificant in but it s significant here which could be because we re only focusing on a subset of the data used in that study.
f .
h5 a developer s self reported api skills are closely aligned to themselves the final question we pose is whether the representations in skill space align with developer s self reported opinions about their own expertise related to a specific technology.
we obtained data from the replication package of that surveys a sample of github users to create a ground truth for self reported developer expertise in the studied libraries.
in this survey the participants declared their expertise on atable iv result of linear regression models a explaining developer api a lignment r2value .
b explaining self reported skill score r2value .
a predictors estimate std.
err.
p value api mongodb .
.
2e api react .
.
2e api sock etio .
.
2e log no.
of commits .
.
.
self reported score .
.
.8e b predictors estimate std.
err.
p value api mongodb .
.
2e api react .
.
2e api sock etio .
.
2e log no.
of commits .
.
2e developer api alignment .
.
.81e scale from to for three javascript libraries mongodb react and socketio .
similarly to previous experiments we obtain skill space representations for survey participants and the three apis.
we investigate if the skill space similarity can be explained by the self reported score by fitting a linear regression model and find that the self reported score explains increases in alignment to each api as self reported expertise score increases.
the result of the linear regression model is shown in table iv a .
finally we try to model the self reported score using the amount of activity commits as reported in and adding theskill space similarity.
again we find that the increase in skill alignment has a statistically significant positive relationship with the self reported score even after adjusting for the direct measure of experience based on the number of commits.
the result of the model is shown in table iv b .
in summary we find that the proposed skill space embedding based on doc2vec models of the apis in files changed by a developer has a strong and statistically significant relationship with the self reported developer expertise.
furthermore even after adjusting for the less granular measure of experience number of commits we still see that skill space representation has a strong explanatory power.
vi.
r eplication package the replication package for this paper is made available through zenodo under cc .
license at .
the data we share include the input data processed with the details of the apis in each blob modified by oss developers who made between and commits all the scripts used by us for the evaluation and the steps for replicating the results presented in the paper in the readme file .
although we do not share it as a tool package which would be difficult to run without access to the world of code dataset we are working on extending the publicly available capability of the world 1003of code dataset which would make such a tool practical in near future we share the input data so that researchers can fit their own models and experiment with the dataset.
we provide a detailed account of the steps we took and share the scripts we used so that researchers can replicate our findings.
we also share the pre trained doc2vec models so that researchers can use them for their applications without having to re train the model.
vii.
l imitations it is important to note the primary objective behind introducing the concept of skill space the ability to compare developers projects languages and apis with the ultimate goal of better measuring developer skills and at facilitating ways to make open source software development more effective by creating signals about the developers expertise that is more general than the modification of individual files but more specific than their volume of overall activity.
the objective of this work is to conceptualize skill space to list some of its properties and to demonstrate that it is possible to construct it on a very large corpus of programming languages and apis.
as such we focus on demonstrating the feasibility and novel applications enabled by the proposed measure rather than trying to compare our method with existing ones since existing developer expertise measures are not suitable for directly comparing developers projects and the apis used by in them.
our results consequently have to be interpreted with care.
first our definition of developer skill is constructive and practical.
we are only concerned that it reflects postulated measures of performance and has some agreement with developers subjective perceptions.
further work is needed to ascertain if it satisfies any additional properties or is suitable for non constructive definitions of skill.
specifically the definition of skill space we chose is based on api usage but the skill embeddings can be conducted for other types of skills as well.
we validate the proposed skill space by checking if it would satisfy the intuitive properties the skill space should exhibit but there may be additional properties we do not consider and the proposed skill space does not satisfy .
for example our primary concern in this work is to capture the aspects of developer expertise related to the apis they use and we are not concerned with other types of expertise such as their proficiency to do good design architecture testing and so forth or with their ability to communicate with other developers.
the particular mechanism of what it means to use an api may be refined.
we only consider if the version of the file modified by a developer has certain import statements but do not verify that the api is actually exercised in the file and we also do not check if the developer made a change to the part of the code that exercises a specific subset of the api used in the file.
moreover it can be argued that just because a developer uses some api in a file doesn t mean that they are expert in using that api since code snippets are often copiedand pasted from different sources.
however our assumption is that a developer should have a basic familiarity with the apis used in the files they modify at least more than a random other api they have never been associated with and as noted by lucassen and schraagen domain familiarity can be seen as a weaker form of domain expertise.
since our aim is to capture the profile of expertise as a trust building support and we attempt to create such measures that equally apply to individual apis projects and developers there are no golden datasets that could be created to evaluate the objectivity of all such measures.
specifically there is no convincing test everyone would agree upon that a developer is a good fit for a project.
as such we can evaluate the goodness of the measures we propose through several indirect means e.g.
can a specific developer be trusted when they make a contribution if there has been no prior interaction between the developer and maintainer?
as we noted above different languages have different conventions in which apis are declared and these differences may play a role or need to be taken into account in order to improve upon the proposed implementation of the skill space.
it may be surprising how a relationship between apis in different languages can be established using our methodology apis are language specific and every blob contains only apis from a single language .
however a large fraction of developers have modified files in multiple languages and many projects contain files in several languages.
since developers and projects serve as tags in doc2vec model such instances appear to provide information needed to establish association of the apis across languages.
there are a few other shortcomings associated with our approach e.g.
our method of measuring expertise can t be applied to complete newcomers since they likely have worked with very few apis and their representation in the skill space is likely to be unstable.
however these developers are not our target audience we are trying to focus on developers with a moderate amount of contribution record who are trying to join a new project trying to use a new api or aiming to get their contributions accepted in a project.
similarly rare apis may not be accurately represented as the corpus may not have sufficient number of instances of using such api.
many potential improvements to the embedding approaches could be considered.
since our concern was to demonstrate the feasibility of the approach we chose an established and computationally efficient doc2vec method.
with the field of text analysis rapidly evolving we expect that future work will develop more accurate methods that are likely to vary with the task api developer project pr prediction vary with the programming language or use alternative embedding techniques.
we also expect further work to refine the parameters of embedding methods as well.
our largest model took more than three weeks to fit limiting the ability to run performanceoptimization experiments.
while demonstrating the use of skill space based embedding we only compared our results with a random selection of apis developers projects.
a more practical application would 1004be to use our method to predict for example which apis a developer will use in future and test the prediction accuracy.
another potential shortcoming of our approach is that it is not completely resistant to hacking similar to most other existing methods of reporting developer expertise since it is possible to generate a number of toy projects that use a specific set of apis to give an impression that the developer who set up those projects is skilled with such apis.
however this is not completely straightforward either since it involves the creation of several toy projects.
further refinements of our method are in progress to make it more robust.
while we model a very large corpus of software it all represents open source development.
the activity of developers in non public repositories and non public software are not captured in this analysis.
future work is needed to apply our techniques on proprietary code bases to ascertain if skill spaces can be operationalized in the same way or some adaptations are needed to take into account the differences in the development process.
in terms of external validity our method can only account for the developers expertise while it is possible that other factors e.g.
change in job responsibilities might influence developers when choosing apis to use h1 or which projects to contribute to h2 which won t be captured by our approach.
viii.
f uture work previous sections discussed a variety of promising approaches for future work to improve the quality of skill space representations and to evaluate alternative ways to capture to what extent a particular change may require increase apirelated skills.
we can use the skill space embeddings of the developers projects and apis together with more efficient machine learning models to further test the applicability of our approach.
more far reaching extensions of skill space would be to include non technical skills such as communication and collaboration skills that are also very important in establishing trust.
we could potentially use traces of development activity related to developers ability to communicate write highquality code respond to issues get pull request accepted and other important skills.
this however would require a way to evaluate the quality of the artifacts a developer produces and the quality of the practices they employ.
a recent paper utilized woc as a way to estimate the reputation of a developer using a tool dre that serves up developer profiles and provides a broad overview of many facets of a developer s activity focusing on both technical and social aspects.
the skill space embedding presented in this paper can be used to enhance such developer profile tools and can also provide recommendations for both the developers e.g.
similar projects that they might consider joining similar developers they might want to work with in the future and similar technologies apis they might consider working with etc.
and the project maintainers e.g.
potential contributors who might possess relevant skills .
further application of our approach might include a detecting if a developer is actually a bot by analyzing theconcentration of their skill vector similar to b checking the alignment between skill vectors of different developers for identity resolution similar to c analyzing theskill vectors of the developers in a project to infer the transparency of the corresponding software supply chain .
ix.
c onclusion we have established a proof of concept for skill space an approach to represent packages apis developers languages and projects in the same vector space with a topology that satisfies several practically relevant criteria such that the representations of developers projects in skill space are similar to the representations of the apis they use contain .
furthermore skill space representations are predictive of the future api usage by developers developers joining new projects and it also affects the probability of a developer s pull requests being accepted.
finally these representations are aligned with developers self reported expertise.
as with all data intensive techniques only entities that have sufficient data can be accurately represented but a large volume of public data from oss projects can help.
the simplicity of the proposed estimation techniques make it easy to apply them within enterprises producing company specific skill spaces that could be integrated with the oss data.
two observations were primary motivator for us to conceptualize the medium granularity expertise created from the implicitly defined relationships among apis in the vast corpus of open source software projects contemporary software development increasingly involves complex dependency chains with much of the software product depending on software developed by unknown and unfamiliar teams the ability of developers to use specific libraries and frameworks in the dependency chains noted above is an important factor that determines their ability to complete programming tasks.
we hope that the progress on measuring and understanding technical aspects of expertise may prove helpful in developing approaches that establish trust between maintainers and contributors who had no prior interactions.
we also hope that it may shed some light on the causes of the vast differences in programmer productivity and help research on developer learning trajectories.
we shared source code and the datasets used in this work and are also working on making them accessible via a web interface through the world of code website which can be used to calculate individual vectors and similarities between different entities with the intention of facilitating replications further improvements in the approaches to construct skill space and more generally supporting further studies in this area.