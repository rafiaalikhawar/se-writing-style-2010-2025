specusym speculative symbolic execution for cache timing leak detection shengjian guo baidu security sjguo baidu.comyueqi chen penn state university yxc431 ist.psu.edupeng li yueqiang cheng baidu security lipeng28 chengyueqiang baidu.com huibo wang baidu security wanghuibo01 baidu.commeng wu ant financial services group bode.wm antfin.comzhiqiang zuo state key lab.
for novel software technology nanjing university zqzuo nju.edu.cn abstract cpu cache is a limited but crucial storage component in modern processors whereas the cache timing side channel may inadvertently leak information through the physically measurable timing variance.
speculative execution an essential processor optimization and a source of such variances can cause severe detriment on deliberate branch mispredictions.
despite static analysis could qualitatively verify the timing leakage free property under speculative execution it is incapable of producing endorsements including inputs and speculated flows to diagnose leaks in depth.
this work proposes a new symbolic execution based method specusym for precisely detecting cache timing leaks introduced by speculative execution.
given a program leakage free in non speculative execution specusym systematically explores the program state space models speculative behavior at conditional branches and accumulates the cache side effects along with subsequent path explorations.
during the dynamic execution specusym constructs leak predicates for memory visits according to the specified cache model and conducts a constraint solving based cache behavior analysis to inspect the new cache behaviors.
we have implemented specusym atop klee and evaluated it against open source benchmarks.
experimental results show that specusym successfully detected from to leaks in programs under different cache settings and identified false positives in programs reported by recent work.
ccs concepts security and privacy cryptanalysis and other attacks software and its engineering software verification and validation.
keywords speculative execution cache timing side channel leak symbolic execution both authors contributed equally to this research.
yueqi chen worked on this project while he interned at baidu usa.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
reference format shengjian guo yueqi chen peng li yueqiang cheng huibo wang meng wu and zhiqiang zuo.
.
specusym speculative symbolic execution for cache timing leak detection.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa 13pages.
introduction cpu cache is a limited but crucial storage area on modern processor chips.
it primarily relieves the speed disparity between the rapid processors and the slow main memory by buffering recently used data for faster reuse.
cache timing side channel attacks leverage the distinct cache physical symptoms i.e.
the cache visiting latencies of various program executions to penetrate the confidentiality of the victims.
on exploiting the vulnerable software implementations adversaries can extract the application secrets infer the neural network structure or even dump the kernel data .
a timing side channel generally serves as the intermediate carrier through which private data could inadvertently disclose to observers who can elaborately measure the timing information of certain operations.
one particular instance is the cache timing side channel which leaks data by the variance of the cache visiting latency.
state of the art program repair method mitigates cache timing leaks by enforcing constant execution time for all secret relevant operations.
however this strong mitigation may still get compromised by the thread level concurrency or the instruction level parallelism like speculative execution .
speculative execution is a microarchitectural optimization in modern processors.
it primarily increases the cpu instruction pipeline throughput by beforehand scheduling instructions under predicted branches which prevents control hazards from stalling the pipeline.
despite its essential importance the cache side effects caused by prediction errors could engender severe detriment through the cache timing side channel .
program analysis for speculative execution is by no means a new research domain.
previous efforts mainly researched safe and efficient execution worst case execution time estimation concurrency bug prediction and spectre vulnerability detection .
wu et al.
recently proposed a dedicated static analysis of timing leakage free property under speculative execution.
however this abstract interpretation based method qualitatively answers the yesornoquestion it is incapable of generating input and speculative flows to diagnose leaks in depth.
moreover the over approximation nature inevitably results in false positives which desires a more precise method.
ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea guo et al.
symbolic sensitive input leakage free programp insensitive plain inputsymbolic execution cache state modelingcache behavior analysisspeculative execution modeling new timing leak witnesses1 figure overall flow of specusym.
to this end we propose a new symbolic execution based method specusym for detecting cache timing leaks caused by speculative execution.
figure 1displays the overall flow of specusym.
given a programp which is timing leakage free in non speculative execution the sensitive input presented in symbol and the insensitive input specusym leverages symbolic execution to explore p s state space systematically.
meanwhile it models speculative execution at conditional branches cf.
and accumulates cache side effects along with subsequent executions cf.
.
based on a cache model specusym constructs leak predicates for memory visits and conducts a constraint solving based cache behavior analysis cf.
to generate the leak witnesses cf.
.
our new method has three significant challenges.
the first challenge comes from the modeling of speculative behaviors.
classic symbolic executors neither support speculative execution nor are cache aware since they primarily concentrate on the functional correctness rather than reasoning the implicit program properties.
the second challenge derives from the cache state maintenance.
due to the symbolic nature a symbolic memory address may correspond to multiple concrete addresses.
updating the cache status after each memory operation unquestionably leads to an explosive number of different cache states.
the last challenge stems from the analysis cost.
processors may trigger multiple branch mispredictions during program execution.
indiscriminately covering all possibilities introduces not only tremendous constraint solving overhead but also many unnecessary cases.
to overcome the first challenge we design a new modeling algorithm in symbolic execution which satisfies both feasibility and high fidelity.
in essence it utilizes the stateful exploration to mimic the speculative behaviors and isolates memory changes in auxiliary states from the normal symbolic states.
to tackle the second challenge we develop a lazy modeling strategy that tracks memory accesses and lazily reasons about cache effects rather than maintaining a complete set of cache states on the fly.
to address the last challenge we filter the branches that are unlikely to cause harmful speculative execution.
also we develop several optimizations to shrink the constraint size for solving cost reduction.
we have implemented specusym atop klee and llvm and evaluated it on benchmarks which have lines of c code in total.
results demonstrate that specusym successfully detects from to leaks in programs under set associative caches and identifies false positives in programs reported by recent work.
to summarize we have made the following contributions a novel technique for modeling microarchitectural speculative execution and analyzing the affected cache behaviors in symbolic execution.
the implementation of specusym which addresses three major challenges and supports cache timing leak detection under speculative execution.
the evaluation of specusym on open source benchmarks to demonstrate its effectiveness through revealing from to leaks under different cache settings.
the remainder of this paper is organized as follows.
section 2motivates our work and section 3reviews the background knowledge.
section 4states the core contributions and optimizations.
then we conduct experiments in section 5and discuss the related work in section .
finally we conclude our work in section .
motivation this section motivates our work with an example.
by studying its leakage free cache behavior under non speculative execution and the new leaks caused by speculative execution we position how specusym should facilitate leak detection.
.
programpand the cache mapping figure a shows a program snippet pwhose execution time remains stationary in non speculative execution but varies in terms of the sensitive input when running under speculative execution.
listed at line phas local variables as s x v1 and v2.
operating these variables e.g.
the implicit memory read of x line and the explicit store tov1 line may lead to memory access.
the remaining variable i line is a register variable that incurs no memory access.
also variable xis the sensitive input and any form of revealing its value turns to be a leak.
we use a fully associative cache cfor the analysis purpose of p as shown in figure b .
it is an extreme case of the n way associative cache where the memory address of a variable in p may map to any cache line of c subjecting to the line availability and the replacement policy.
here we assume cadopts the least recently used lru policy which always evicts the least used line oncechas been entirely occupied.
cachecconsists of cache lines and each line has exactly 1byte size.
local variables are mapped to caccording to the program execution order and their sizes e.g.
in figure b array smaps from cache lines to because of the array traverse in the while loop lines and each byte array item successively occupies a full cache line.
then variable xassociates with line .
next v1 fills the last available line line if x 128satisfies thus the execution proceeds into the ifflow.
otherwise the execution takes theelsebranch and writes v2 mapping v2to line .
.
leakage free in non speculative execution runningpwithout speculative execution won t leak any information about x. this section analyzes the cache behavior in detail.
there are two program paths in pbecause of the if else branch.
let s name the one containing the ifbranch as p1and the other one asp2.
the only difference between p1andp2is the store operation which writes v1onp1butv2onp2.
as analyzed in section .
v1 would map to the last line of cache c. similarly without speculative execution v2also maps to the same line as annotated by the solid arrow in figure b .
this overlapping situation is because usually either p1orp2could be taken hence either the store tov1or the store tov2may happen.
in both cases line is empty before the store operations.
thereby v1orv2uses this available line.
1236specusym speculative symbolic execution for cache timing leak detection icse may seoul republic of korea x sensitive input uint8 t s x v1 v2 register uint8 t i while i load s if x store v1 else store v2 load s x a the program snippet p256 lines v1xs s ......s s s byte v2speculative non speculative b the byte cache c figure program pand its cache mapping.
in view of this fact we can observe similar cache behaviors on both p1andp2under non speculative execution.
the first load operations on array s the next implicit memory read of x and the following store tov1onp1or to v2onp2 all cause cold misses since cachecis initially empty.
likewise the last memory load on s line must be a cache hit on both paths because sandx have already been in cache c. in other words p s cache behavior is independent of the sensitive input x. as a result phas no cache timing leaks under non speculative execution.
.
new leak under speculative execution in section .
only one store operation can happen in non speculative execution.
however the situation changes and a new timing leak appears when taking speculative execution into account.
under speculative execution the instructions guarded by a branch brcan be scheduled before the execution proceeds into brin case cpu predicts that bris likely to be taken.
for example suppose we first runpwith x several times and flush the cache after each run.
afterward we rerun pbut setting xto .
still the store instruction under the ifbranch line would be executed before psteers into the elsebranch due to the branch misprediction.
more importantly though the cpu performs a rollback to discard the value update to v1 v1remains inceven after the remedy.
going until line array sand variable xmap from lines to and v1still occupies line .
at this point there is no empty line available for v2.
following the lru policy declared in section .
executing the store instruction at line would evict the oldest item s from cachecand map v2to the vacated line as shown by the dotted arrow in figure b .
after that the program execution continues to line reaching the last memory load ofs .
sensitive input xnow determines which array cell would be visited.
and we examine the cache behavior of this load in terms of two cases x 0andx .
x preads array cell s .
recall that xis still in cachec buts is no longer incdue to the replacement by v2.
so this memory load causes a conflicting cache miss.
x since the whole array sexcept s is inc the load ofs must get a cache hit no matter what value xis.
only if x 0there appears one more cache miss on path p2.
it is a unique situation that enables attackers to learn the value of xdue to a measurable longer execution time.
note that the cold miss from speculatively writing v1also causes an internal latency.
however it is un observable to the external users and we ignore it safely for analysis purposes.
.
what specusym should provide the motivating example shows that though a program may have been carefully crafted to avoid cache timing leaks running it under speculative execution could still exhibit new leaks.
since speculative execution is one of the fundamental optimizations in modern processors a systematic analysis that detects the subtle leaks would be of vital importance.
specifically we emphasize two requisite abilities in our proposed new method.
first specusym should be able to systematically explore the program state space to identify execution paths and speculative flows that may cause leaks e.g.
p2and the speculative execution of the ifbranch.
by contrast speculation of the elsebranch won t cause any leak along with p1.
second specusym should be able to pinpoint the leak sites by a precise cache analysis and generate concrete inputs that witness new cache behavior at the identified memory visit sites e.g.
the memory store instructions to v2and the value zero of input x. preliminaries this section reviews the preliminary knowledge of symbolic execution cache timing leak and speculative execution.
.
symbolic execution symbolic execution as a systematic program testing and analysis technique was first introduced in the 1970s .
in this work we assume that a program pconsists of a finite set of instructions andpdefines execution semantics in program paths.
let instbe an instruction then interpreting an event e lb inst la in symbolic execution stands for the execution of instwhere lbandla denote the locations before and after inst respectively.
a program execution explores a sequence of events along the program path.
close to we abstract a symbolic event einto three categories in terms of the type of instthatecontains.
event which presents a branch instruction.
it models the then branch by assume c and the elsebranch by assume c respectively.
term cis the representative of a conditional predicate expressed in symbolic expression.
event which corresponds to a memory read instruction of the form var load addr or a memory write instruction likestore addr expr where addr is the memory address and expr is a symbolic expression.
event which represents other types of instructions in the form var expr.
here varis a variable and expr is a symbolic expression computed from preceding events like arithmetic calculation bit manipulation etc.
although symbolic executors always support a rich set of instructions we use the above event types to abstract away the internal implementation details like memory allocation function return and et al.
to center on the high level flow of symbolic execution.
algorithm 1presents the baseline symbolic execution of a program with sensitive input.
unlike prior works both global and local memory accesses are uniformly handled in this algorithm.
the data input in t determines a program execution path consisting of ordered events e1 .
.
.
en where is the sensitive input e.g.
privacy data or cipher keys and tis the insensitive input.
the global container stack is used for storing symbolic states during the dynamic exploration.
a symbolic state exhibits the frontier of a path execution.
we use a tuple pc e brs to define a 1237icse may seoul republic of korea guo et al.
algorithm baseline symbolic execution.
initially the global state container stack is empty stack .
start basesymexec sini on an initial state siniwith in t .
1basesymexec symbolicstate s 2begin stack.push s ifs.eis branch event then forc s.brsand s.pc cis satisfiable do s.pc s.pc c basesymexec subsequentstate s the event end else if s.eis memory access event then basesymexec subsequentstate s the event else if s.eis other interpretable event then basesymexec subsequentstate s the event else terminate state sand report error end stack.pop 17end 18subsequentstate symbolicstate s 19begin s symbolically execute e.instins s .e next available event return s 23end state s. symbol pcdenotes the path condition that leads to s where e is the event to execute at s.brscontains the set of branch predicates ifeis a event.
and is the symbolic memory which maintains the symbolic memory values of the program variables at state s. initially the state container stack is empty and we start the main procedure basesymexec with the initial state sinion input in.
during the recursive execution basesymexec may split a branch lines perform a memory operation lines conduct an internal computation lines or terminate a state line depending on the type of the event to execute.
note that at the entry of each recursion basesymexec takes a new symbolic state as the input which is obtained from invoking a secondary procedure subsequentstate.
this procedure inputs the current state sand outputs a new state s by symbolically executing theinstins.e.
for brevity we omit the details of the instruction interpretation which can be found in .
.
cache timing leak memory operations are prone to timing leaks because of the outstanding accessing latency between the cache and the main memory.
for example reading data from the cache may cost processor cycles whereas loading data from memory could spend hundreds of cycles.
in this section we first establish the threat model and then formalize the leak definition based on the threat model.
.
.
the threat model.
as exhibited in section .
sensitive data involved in memory access may get leaked from the timing traffic of a memory write.
to capture such kind of subtle leak in our analysis we assume the attackers can perform strong external threats.
first we assume the attackers share the same processor with the victim process.
hence they can learn the shared cache states by probe methods.
second they are allowed to request the execution of the victim process.
third they can observe the latency of the interested memory visits in the victim process.
our threat model is close to those used in practical attacks like where the attackers can deduce the cache block states by measuring the timing traffic of either the victim or the attacker process.
moreover thismodel also appears in leak detection techniques like .
therefore we believe it is a reasonable model for analysis purposes.
.
.
the leak definition.
formally we abstract a sensitive data related programpto be a function fp in out.fpprocesses the data input in t cf.
section .
and returns the output out.
for example assuming pis an encryption process is the private key and tis the content to encrypt then outis the ciphertext.
let t fp in denotes the execution time of pwith input inunder non speculative execution.
different inputs may explore various program paths.
however since we focus on timing leaks introduced by speculative execution here we assume the time of those nonspeculative program executions remain similar or the same no matter what the sensitive inputs are which is t .t fp t t fp t symbols and denote any two sensitive inputs and tis still the public input.
nevertheless since in practice attackers may gain information by observing several memory visits or cache lines we restrict the leak granularity at the memory operation level regarding our threat model.
specifically let ebe a memory event on executingpand the time of interpreting ewith and without speculative execution be ts pe in andt pe in we assume t .t pe t t pe t then the existence of a new cache timing leak under speculative execution can be checked by the following formula t .
ts pe t ts pe t t pe t ts pe t where a leak appears if two different sensitive inputs can cause significant timing differences in executing eunder speculative execution or two sensitive inputs can cause significant timing difference in executing ewith and without speculative execution.
in other words pleaks due to speculative execution if any pair of and exists.
furthermore we transform formula into a dedicated leak constraint and simplify the constraint to a more concise form in section .
also as public input plays a minor role in modeling cache timing leaks we set insensitive input tto a fixed value to reduce the reasoning cost of formula .
.
speculative execution the cpu instruction pipeline allows overlapped executions of proper instructions where each instruction execution consists of a series of micro stages.
this instruction level parallelism benefits hardware utilization since instruction can start execution before the time its prior instructions have completed all their stages.
however a pipelined processor may get stalled once the program control flow needs to divert but the destination remains unknown e.g.
at a conditional branch .
accordingly the pipeline has to wait until the flow decision gets computed.
to alleviate the cost of such control hazard processors leverage speculative execution and branch prediction to reduce the delay that could incur on conditional branch instructions.
generally they predict the execution flow based on the history of recently executed branches and schedule instructions under predicted branches ahead of jumping into these branches.
specifically on approaching a control hazard the processors first predict a branch to take.
then they execute the instructions under the selected branch and 1238specusym speculative symbolic execution for cache timing leak detection icse may seoul republic of korea maintain the temporary path state in a dedicated buffer.
finally they commit the buffered state to continue the program flow if they achieved a correct prediction.
otherwise upon an incorrect prediction they have to discard the temporary state to revert the effects of the executed instructions hence avoiding functional errors.
this rollback mechanism unfortunately withdraws no affected cache state which raises security risks.
as shown in section .
variable v1maps to cache line due to the misprediction of the ifbranch and this cache effect remains unchanged even control flow directs to the elsebranch.
as a result sensitive data xleaks due to the interfered cache state.
abstracting away the hardware details we can model the speculative behavior in symbolic execution as a three phase analysis and evaluate its cache side effects with a constraint solving based approach.
.
.
misprediction modeling.
as aforementioned on reaching a control hazard the processors make a prediction to select a branch for execution.
despite the experience based hardware realization in cpus we can model this behavior by an auxiliary symbolic state.
to be specific before diverging the control flow into the elsebranch our symbolic executor would decide to duplicate a new state from the current symbolic state and schedule it immediately into the if flow which models the branch prediction of the ifbranch.
similarly we can model the misprediction of the elsebranch on demand.
.
.
speculative state execution.
each duplicated state in misprediction modeling has the same snapshot of its parent state.
for clarity we use the speculative state to alias this newly forked state.
aspeculative state would be prioritized to the front of the state container in the symbolic executor and uninterruptedly executes until it meets a predefined threshold like the size of the reorder buffer rob the pipeline stage number the branch depth etc.
also aspeculative state runs independently from its parent state thus any memory updates in the speculative state won t taint its parent state who is waiting for the speculative state returns.
for the sake of cache analysis we also maintain the cache data in each symbolic state.
a speculative state inherits such data from the parent state and keeps updating the cache during its execution.
.
.
rollback and cache merging.
once the speculative state reaches the threshold it has to stop and exit the state stack.
right before the termination it notifies the awaiting parent state the finish of the speculation and transfers the latest cache data back to its parent.
upon accepting the notification the parent symbolic state merges the received cache information into its cache data to form the latest cache state.
after that the parent state aborts waiting and resumes the regular execution.
this step models the processor rollback in high fidelity and retains the cache status changes from speculation.
since the cache changes have already merged into the parent state terminating the speculative state causes no further effects.
it is worth noting that in this work we constrain the scope of speculative execution to customary branch prediction and subsequent out of order instruction execution.
in practice modern processors may perform other forms of speculation e.g.
memory dependence speculation and disambiguation .
however they are not the main focus of this work.
algorithm in this section we explain the core technical contributions portrayed in figure .
algorithm 2shows the procedure of specusymalgorithm symbolic execution in specusym .
initially the global state container stack is empty stack .
start specusym sini on an initial symbolic state siniwith in t .
1specusym symbolicstate s 2begin ifsis a speculative state and sreaches the threshold then return end stack.push s ifs.eis branch event then forc s.brsand s.pc cis satisfiable do speculativeexplore s c enter speculative modeling ...... resume normal execution end else if s.eis memory access event then analyzecache s s. update cache state by interpreting s.e specusym subsequentstate s ...... 17end 18speculativeexplore symbolicstate s predicate c 19begin ifcrelies on a memory access then s duplicate state s fork speculative state s redirect s to the c control flow negate branch direction specusym subsequentstate s s. s .
terminate s end 27end 28analyzecache symbolicstate s 29begin ifsis a regular symbolic state and s.e relates to sensitive input then build the leak constraint for s.e ifs.pc is satisfiable then generate witness end end 36end built upon the baseline algorithm where the main changes are highlighted at the state checkpoint lines the branch point line and the memory access point lines .
.
speculative modeling this section explains how specusym models branch misprediction and speculative execution by introducing an auxiliary speculative state and orchestrating it with the normal symbolic state properly.
.
.
modeling overview.
on entering the specusym procedure in algorithm we first check if current state sis aspeculative state and whether shas reached the predefined threshold line .
if both conditions meet the recursive symbolic execution on sstops and returns immediately line .
note that a state becomes a speculative state if it is duplicated from a normal symbolic state line by invoking speculativeexplore at a branch event line .
lines in algorithm 2present the modeling procedure speculativeexplore.
generally at a conditional branch line we call speculativeexplore line to start the speculative probe.
that is if the branch predicate closely relates to memory visit line e.g.
using a variable for the first time we duplicate a new state s from current state s line with a negated branch direction line .
this assumption bases on the observation that the memory visiting latency at a branch may form a time window for speculative execution to load data into the cache.
otherwise despite a branch misprediction cpu may spend only several cycles on speculative execution before its rollback which is too transient to let speculation affect the cache.
1239icse may seoul republic of korea guo et al.
s ...... s x v2 v1 s symbolic state s symb olic state sspe culative state s a interaction between sands lines v1xs ......s s v2 b the cache state in s figure the speculative execution modeling of p. after state duplication new state s becomes a speculative state since it is about to mimic the speculation of the mispredicted branch.
we let specusym explore s line and assess the effects of the memory accesses in s on the cache line .
details of the assessment present in section .
.
once the execution of s finishes we use the accumulated cache data in s to update that of s line and terminate s line to end its lifecycle.
such design ensures that the speculation of s only contributes to the cache state changes but never affects the memory of its parent symbolic state.
next after speculativeexplore returns we resume the normal symbolic execution of s line who now has an updated cache.
in this way we have constructed a speculative scenario and retained the latest cache changes.
our modeling method leverages the stateful mechanism of symbolic execution.
it not only models the speculative behavior but also precisely transfers the cache information between symbolic states with controllable flexibility.
.
.
the motivating example revisit.
figure 3shows the speculative modeling of motivating program p. figure a displays the simplified control flow graph on which we annotate the memory access related variables.
that is s indicates the first array read in the while loop and v1means the memory write in the ifbranch.
the solid arrow line denotes the execution flow of state s which takes the elsebranch in regular symbolic execution.
in figure a on reaching the branch point specusym duplicates aspeculative state s from s. then it enforces a bounded symbolic execution of s e.g.
one memory access inside the ifbranch as shown by the dashed arrow curve.
once meeting the speculation threshold specusym stops the exploration and turns back to find state swho is awaiting the finish of s .
also before resuming s specusym incorporates the cache state of s cf.
figure b into s and terminates s .
right now the entire cache has been filled since the memory write in s mapped v1into line .
subsequently executing the memory store tov2in state shas to evict s from cache line following the lru policy as shown in figure b .
then the last memory load ofs might result in a cache miss or a hit counting on the value of x which is consistent with the situation explained in section .
.
hence specusym succeeds in modeling speculative execution and conforms to the three phase analysis designed in section .
.
note that figure a only shows the modeling of the ifbranch while specusym considers both branches and misses no potential cases.
in this example updating the cache state is straightforward.
by checking the in cache addresses to find a proper cache line upon a cache miss or update the most recently used line in case of a hit.
for the non deterministic address i.e.
s we can at worst try possibilities to test the differences.
however eagerly enumerating all potentials is impractical for real world programs due to the unbearable overhead.
furthermore a great many cache mappingsare redundant in terms of leak exposure.
for instance only one specific cache layout can reveal the leak in the motivating example.
instead specusym models branch mispredictions along with a path exploration and maintains a trace of memory events as the alternative of the cache state.
then it analyzes the event trace to build the leak constraint and lazily searches for feasible solutions.
we detail this approach in section .2and section .
.
as discussed before the processor stops speculative execution once it has computed the branch destination.
since speculation may end at an arbitrary point we model the speculative window with a configurable three dimensional threshold.
that is if the number of interpreted events in a speculative state or the speculatively executed branch events meet the predefined bound we stop speculation and if a sensitive input related memory event in speculative execution must cause a cache miss we also stop the speculation after its execution.
otherwise we continue the execution.
.
cache state modeling this section addresses how specusym models the cache state during dynamic symbolic execution.
we extend the definition of a symbolic state s cf.
section .
to form a new tuple pc e brs .
the newly introduced symbol denotes the memory event trace in state s. then we establish the following notions a program state in specusym is either a normal symbolic state or a speculative state that from the former can the latter be duplicated but not vice versa.
a memory event trace denoted as m0 ... mn consists of happened memory events in the execution order.
each memory event miin where index i comes from either a symbolic state or a speculative state.
and the correlated computations alternatively represent the cache state in a program state s. to be specific before interpreting a memory event miin asymbolic state s specusym analyzes if mican cause timing leak under two scenarios namely the new divergent behavior and the new opposite behavior.
note that specusym won t perform the analyses in any speculative state.
to explain these scenarios we define four necessary notions as follows.
aidenotes the used memory address in event mi.
cs ai denotes the cache set that address aimaps to.
tag ai denotes the unique tagof address ai.
n denotes the cache associativity where n e.g.
n way set associative cache .
.
.
new opposite behavior.
it means that executing miunder non speculative execution causes an always miss while the result under speculative execution is an always hit and vice versa.
recall that we only target new leaks introduced by speculative execution and this scene depicts the exact opposite situation.
to build the formal definition we define three new notions in mi denotes the condition that mitriggers an always hit under speculative execution with input in.
in mi denotes the condition that mitriggers an always hit under non speculative execution with input in.
boolean variable org mi denotes the origin of mi where means miis from a normal symbolic state and means mi comes from a speculative state.
1240specusym speculative symbolic execution for cache timing leak detection icse may seoul republic of korea then we can formalize in mi and in mi as follows.
in mi j i aj ai x j i ax ai z 1find the nearest identical address a j i 1 y j 1cs aj cs ay z j y tag az tag ay z 2count the unique a ywho and a imap to the same set n in mi in mi org aj org ax org ay z 3filter events from speculative execution given a mi we first search for an identical address aj which was visited in event mjhappened before mi.
also ajhas to be the nearest candidate that no other addresses between ajandai are qualified cf.
.
second we count the unique addresses who andmimap to the same cache set and assure the number of such addresses is less than the set associativity n cf.
.
based on in mi we define in mi who has an extra constraint cf.
upon in mi .
the new constraint ensures that all involved memory events must be from normal symbolic states hence filtering the influences of memory events from speculative states.
.
.
new divergent behavior.
it means executing miunder speculative execution with two different inputs inandin can cause a miss and a hit respectively.
for instance reading s exposes this symptom cf.
section .
.
to analyze the behavior we build in mi which returns the cache hit condition of miin trace in mi j i tag aj tag ai cs aj cs ai z 4identify the potential a j x j i tag ax tag ai cs ax cs ai z 5find the nearest a j i 1 y j 1cs aj cs ay z j y tag az tag ay z 6count the unique a ywho and a imap to the same set n still given a mi we first seek a prior mjfrom who might let micause a cache hit.
that is the addresses ajandaihave the same tagandsetvalues cf.
.
moreover we need to find the nearest mjsince mi s cache behavior directly relies on it this demand is achieved by ensuring the non existence of a mxbetween mjand mi.
and mxandmiown the same tagandsetvalues cf.
.
next we consider the cache replacement policy.
specusym models the n way set associative cache with the lru policy whereas other policies can be modeled and embedded in equation as well.
intuitively on finding a candidate mjformi the executed events between mjandmishould not evict mjfrom the cache to promise a cache hit for mi.
under the lru policy we observe that if satisfying property can this non evicting requirement be met.
property .
to avoid evicting the most recently used cache line from a cache set the total number of subsequent new cache mappings to must be less than the set associativity.
sub formula 6checks whether an event mybetween mjandmi can form a new mapping to the cache set that address ajmaps to.we perform the check by first comparing the setvalues of ayand aj.
if the comparison satisfies we further analyze if address ayhas never been accessed by an event mzbefore by confirming that thetagvalues of azandayalways differ.
if this check also satisfies then aymust form a new cache mapping.
we count the amount of new mappings and model property in equation .
take a event trace m1 m2 m1 m3 m3 m4 m5 m4 m1 as the example.
for brevity we assume all the memory addresses associate with the same cache set and each address corresponds to one cache line.
and the cache set associativity is four.
the question is whether the last event m1 can lead to a cache hit.
here we use nto index these events where n .
backtracking from the last event m1 we first locate two prior m1events and as the candidates that satisfy .
then according to we select the nearest event to form a sub trace as underlined in .
note that after s head event m1 the cache line used by this m1becomes the most recently used line.
let s name the line as l. then following along with we can identify 3new cache mappings incurred by events m3 m4 and m5 respectively.
other events i.e.
m3 and m4 cannot form new mappings since they do not satisfy .
therefore we conclude that the target event m1 must lead to a cache hit because the identified three new cache mappings at most evict the other three lines rather than the line l. in other words the number of new mappings is less than the set associativity of the given cache which conforms to property .
.
cache behavior analysis this section leverages the formal terms in mi in mi and in mi cf.
section .
to analyze the cache behavior of mi.
in general if mi has no cache behavior variance in both speculative execution and non speculative execution for any inputs it has no leaks.
otherwise at the program location of mi there is a leak.
in algorithm specusym invokes analyzecache right before interpreting a memory event line .
in this procedure specusym first examines whether the current state sis asymbolic state and the event s.erelates to sensitive input line .
it is because the timing effect inside speculative execution is externally invisible and we are interested in the sensitive data related memory accesses.
next specusym builds the leak constraint for event s.eand solves for a solution lines .
if the solution does not exist specusym claims leakage free at s.ein current state s. to form we need to build the constraint exposing new cache behaviors at a given memory event mias follows.
oppi in in .
in mi in mi divi in in .
in in in mi in mi constraint oppichecks the existence of new opposite behavior anddivireasons new divergent behavior respectively.
we define oppi divias the leak constraint at mi.specusym first computes in mi because of the fewer cost of a must be solving.
then it uses the concretized value to substitute in mi inoppifor the further solving of in.
if this targeted inexists under the path condition then oppimust be satisfiable and specusym can safely skip the rest analysis of divi.
otherwise it has to continue reasoning divi.
finally if the solver successfully returns a concrete solution of specusym generates a test case including two inputs the trace and event mias the leak witness.
1241icse may seoul republic of korea guo et al.
for instance in figure a before interpreting the load event of s specusym analyzes the cache since the sensitive data related address s is from a symbolic state s. at this point trace insis s ... s x v2 v1 s .
also in non speculative execution reading s must get a cache hit cf.
section .
.
substituting in mi with value in oppi specusym tries to solve in.
in mi .
unfortunately this simplified oppiis still unsatisfiable since in mi evaluates to if in .
therefore specusym moves forward to divi.
this time it successfully returns two values and which expose a cache miss and a hit respectively.
finally specusym outputs the solved values the trace s. and the read event of s .
it is worthwhile to note that processors may mispredict branches several times along a program path.
as a result we need to count the cache side effects from multiple mispredictions.
however attackers always expect the minimum effort to trigger mispredictions for leak purposes.
meanwhile manipulating multiple speculation windows is very difficult for external attackers.
in specusym we follow the attacker s perspective to study whether one misprediction could be enough to cause timing leaks and leave the multiple speculation cases as our future work.
.
optimizations .
.
constraint transformation.
in section .
constraints oppi anddivicapture the complete set of leak related cache behaviors.
however based on the timing leakage free assumption of a target program under non speculative execution we observe a property which helps specusym accelerate the cache analysis property .
if under the same input in t the cache behaviors of a related memory event miin speculative execution and non speculative execution are opposite there is a cache timing leak.
property 2reflects the intersection of oppianddivi.
as assumed the cache behavior of miin non speculative execution is deterministic.
in case an opposite behavior under speculative execution miwould cause either new opposite behavior or new divergent behavior.
in any case it is a leak.
then the solving of turns to be reasoning the existence of such in which has cheaper computation cost.
we model the property into a new constraint in.
in mi in mi due to the assumption mentioned above in mi is always hit or miss .
accordingly if in mi may hit condition under speculation evaluates to or on the same in either oppiordivimay evaluate to which already deduces a leak without solving oppior divi.
therefore if is satisfiable also satisfies.
.
.
formula reduction.
however the size of still intensely increases along with the increment of i which pressures the constraint solver.
by inspecting the constraint structure we separate lengthy formulas into smaller pieces by following strategies.
first if a subformula of a conjunctive normal form cnf formula evaluates as false we directly return false.
for example in equation if 4isfalse we skip querying solver for 5and .
second if a subformula in a disjunction normal form dnf formula is determined as true we discard all other subformulas.
as in equation once we find the nearest ajby we discard subformulas for indices before j. third if two subformulas are in negated forms we avoid an extra solver query.
for example in equation constraint 5ofmjis the negation of constraint 4ofmj which implies we can save one constraint solving time.
fourth since we repeatedlytraverse memory event trace in constraint construction caching the intermediate results avoids repeated computation.
we bank the computed formulas into a hash map so that specusym can quickly retrieve them with tolerable storage overhead.
.
.
speculative assumption checking.
recall that in algorithm specusym duplicates a new state s from symbolic state s line if the branch predicate closely relates to a memory value rather than a cache value.
as mentioned earlier in section .
this strategy filters transient speculations that are unlikely to affect the cache.
wu et al.
over approximately treated all memory events as actual memory visits though predicate related values may have been loaded to the cache.
specusym proposes an alternative for symbolic execution to deal with this issue.
ideally to address the problem we have to perform a burdensome backward cache analysis from the current branch to the first memory access examining whether the value involved in the branch predicate is in cache or not.
however we observe that the memory accesses from the current branch to the last branch typically have a critical influence on the cache state before the current branch.
therefore to balance the precision and efficiency specusym backwardly examines the memory accesses in this range.
if the predicate related values have been fetched to cache beforehand and still exist in the cache we regard the speculative modeling at this branch as unnecessary.
otherwise we still conduct all analyses as usual as usual to avoid missing leaks.
although this optimization introduces extra computation overhead it still benefits overall performance since the targeted cases commonly exist in programs because of the time and spatial locality purposes.
evaluations we have implemented specusym based on the klee symbolic executor and the llvm compiler .
we refit klee in three main aspects.
first we made klee support the bounded execution of auxiliary speculative state and schedule the parent symbolic state afterward to mimic the branch misprediction.
second we made klee stitch a sequence of memory events from both normal symbolic state and speculative states to represent the incorporation of cache data from speculation.
third we made klee analyze the cache behaviors on memory events to generate concrete test cases for timing leaks.
based on these new components we built specusym for the cache timing leak analysis under speculative execution.
specifically after loading the llvm bit code of the target program specusym executes it symbolically explores speculative states records the memory event trace and conducts cache analysis following algorithm .
the leak constraint is encoded in z3compatible form.
on solving the constructed constraints specusym outputs leak witness including the event trace the leaky memory operation location and the solved inputs.
we design the following research questions for the experiments canspecusym successfully identify cache timing leaks introduced by speculative execution?
canspecusym complement the abstract interpretation based method by providing more accurate results?
can the proposed optimizations boost the overall performance of specusym?
.
benchmark programs table 1shows the statistics of the benchmarks for evaluation.
the first three columns name loc and source indicate the names 1242specusym speculative symbolic execution for cache timing leak detection icse may seoul republic of korea table benchmark statistics name lines of c code loc source sensitive input size in bytes s in and number of branches brs .
name loc sour ce s in brs hash the hpn ssh hash implementation aes the libtomcrypt aes cipher blowfish the libtomcrypt blowfish cipher chacha20 the libtomcrypt chacha20 cipher encoder the libtomcrypt hex encoder ocb the libtomcrypt ocb implementation des the openssl des cipher str2key the openssl key prepare for des des the glibc des implementation camellia the nvidia tegra camellia cipher salsa the nvidia tegra salsa20 stream cipher seed the nvidia tegra seed cipher des the libgcrypt des cipher salsa the libgcrypt salsa20 stream cipher spectre the spectre v1 application the lines of code and the sources of these benchmarks.
column s in denotes the sensitive input size in bytes.
the last column brs shows the number of conditional branches in each program.
our benchmark suite consists of a diverse set of open source c programs.
the first program comes from hpn ssh .
the second group has five programs from libtomcrypt .
.
.
the third group uses two programs from glibc .
.
the fourth group includes three programs from the tegra library .
the rest benchmarks are from the libgcrypt .
.
and the spectre vulnerability application .
most benchmarks are computation intensive despite the compact program volumes.
the sensitive input of each benchmark is initialized to a symbol whose size shows in column s in.
also each program has to conditional branches.
we evaluate the benchmarks on the n way set associative cache and lru policy with different cache settings.
to be specific we design four caches as 32kb cache size with n 32kb cache size with n 64kb cache size with n and 32kb cache size with n .
each cache line has bytes for all caches.
the first three settings are close to the l1 data cache classes in modern processors.
the last setting creates a fully associative cache on which we compare specusym with .
besides we evaluate the effectiveness of optimizations using setting .
all the evaluations are conducted on a machine running ubuntu .
bit server linux with intel r xeon r .20ghz cpus cores and 256gb ram.
each benchmark is allowed to run at most hours.
.
experimental results .
.
timing leak detection.
in this section we conduct experiments for the first research question.
table 2shows the leak detection results under the set associative cache settings.
let s name these caches as c1 c2 and c3.c1has a 32kb size and each cache set consists of lines.
as each line has bytes c1has sets in total.
c2also owns 32kb size but its associativity increases to .
hence it has sets.
c3has 64kb size while its associativity remains thereby it has sets and cache lines.
for each benchmark we collect execution statistics under all cache settings including the total execution time in minute time m and the amount of divergent opposite leaks named .d o. overall specusym identified that out of benchmarks suffer from timing leaks.
specifically blowfish is leaky only under cache c2while the other programs have leaks under all caches.
amongtable detection results on set associative caches namec1 32kb way c2 32kb way c3 64kb way time m .d o time m .d o time m .d o hash .
.
.
aes .
.
.
blowfish .
.
.
chacha20 .
.
.
encoder .
.
.
ocb .
.
.
des .
.
.
str2key .
.
.
des .
.
.
camellia .
.
.
salsa .
.
.
seed .
.
.
des .
.
.
salsa .
.
.
spectre .
.
.
these programs des has both d o leaks in all caches aeshas both d o leaks in c1 but only opposite leaks in c2andc3 and the rest programs chacha20 encoder and des have only opposite leaks under all the caches.
next we compare the results under c1andc2to research how the cache associativity variation affects leak occurrence.
intuitively the more lines per cache set the less potential cache conflicts hence fewer leaks.
however experiments affirm that the increased associativity indeed triggers more leaks.
first specusym detected and leaks under c1andc2 respectively second out of the leaky programs have more leaks under c2.
the only exception encoder has leaks in both c1andc2.
third the non leaky program under c1 blowfish now turns to expose new leaks under c2.
this phenomenon is mostly because the speculative memory visits raise more cache hits the misses under non speculative execution now have higher possibilities to be cache hits since speculative execution has fetched memory data earlier into the cache.
further we compare between c2andc3 to study how the cache size could affect leak detection.
we find that despite the sizeable 32kb capacity difference the detection results show no drastic variances.
first specusym detected the same types and amounts of leaks in programs chacha20 encoder and des in both c2 andc3.
the analysis time is also close.
second another two leaky programs aesanddes also exhibit similar statistics.
third the main difference comes from blowfish which has two leaks on c2 but no leaks on c3.
though this unique case indicates that smaller cache might incur more leaks it is not the majority situation.
besides we observe drastically varying results from different versions of the same algorithm.
for example in three des implementations from openssl glibc and libgcrpt specusym detected only opposite leaks in openssl des both d o leaks in glibc des and no leaks in libgcrypt des.
meanwhile openssl des needs about minutes of analysis time upon all caches.
the glibc desuses minutes for c1but around .
hours in both c2andc3.
by contrast libgcrypt desuses merely minute upon all caches.
therefore we can answer the first research question specusym is capable of detecting timing leaks introduced by speculative execution.
it also supports various caches for comparative analysis.
.
.
existing method comparison.
we compare specusym with in table to answer the second research question.
column 1243icse may seoul republic of korea guo et al.
table comparison betwee wu et al.
and specusym namewu et al.
specusym leak dete cted time s leak detected .leaks time s hash .
.
aes .
.
chacha20 .
.
encoder .
.
ocb .
.
des .
.
str2key .
.
camellia .
.
salsa .
.
seed .
.
of table 3lists all the used benchmarks in for timing leak evaluation.
columns show the detection result and the computation time of this abstract interpretation based method .
columns depict the result of specusym while column lists the total amount of detected leaks.
to ensure a fair comparison we configure a line fully associative cache with lru policy which equals the cache setting used in .
let s name it as c4.
overall reported that of the benchmarks are leaky as marked with in column .
consequently the rest programs are free of timing leaks.
for these robust programs specusym also detects no leaks as shown in column .
the result means specusym introduces no false positives on analyzing these programs.
in contrast for those results from specusym provides different results on two benchmarks hash andocb as underlined in table .
they are deemed to be leaky in while specusym found no leaks in them.
we manually inspect the two programs and confirm thatspecusym gives the right answer no leaks exist in these programs.
the inaccurate results of should root from its overapproximation solution and they are indeed false positives.
for the remaining programs chacha20 encoder and des both specusym and have detected leaks.
however only reports property violations whereas specusym generates rich information.
for example specusym pinpoints and leaky sites in these benchmarks respectively.
moreover specusym can provide inputs and memory event trace for leak diagnosis.
note that specusym generally performs faster on c4than on other three set associative cachess since the extreme cache setting of c4advances both cache utilization and cache hit rate for these benchmarks.
compared to specusym may have false negatives because of two reasons.
first the bounded speculative modeling might miss certain speculation cases.
second specusym stops speculation once it finds that an event on the speculative path must cause a cache miss thus it skips executing following events on that path.
nevertheless specusym provides more precise results because of the high fidelity modeling and fine grained per event reasoning.
another drawback of specusym is the computation overhead.
table 3shows that finishes all benchmarks in seconds whereas specusym needs .
seconds to analyze an openssl des.
worse the analysis time under c3for the glibc des even rises to about .
hours cf.
table .
the cost mainly comes from constraint solver since specusym reasons individual memory accesses on each program path.
however sacrificing the performance for the precision achieves reasonable paybacks.
first the increased overhead of most benchmarks is still tolerable.
next specusym finds false positives from and generates precise inputs.
moreover if hashaes blowfish chacha20encoderocbdes str2key des camelliasalsasee d dessalsaspe ctre0200400600800time min base opt a the benchmark analysis timehashaes blowfish chacha20encoderocbdes str2key des camelliasalsasee d dessalsaspe ctre01000200030004000size of constructs base opt b the smt constraint size figure performance comparison for the individual program.
benchmarks are listed by their orders in table .
table the performance boost due to optimizations.
version time constraints size .div .opp base opt .
.
provides assisting information e.g.
the suspicious locations on the control flow graph specusym can purposely guide its analysis to the problematic area at an earlier stage.
now we answer the second research question specusym can complement the latest abstract interpretation based analysis .
it introduces no false negatives and identifies two false positives reported in .
further it can provide inputs the speculation flows and the leak locations for detailed diagnosis.
.
.
optimization performance.
this section studies the performance of the optimizing strategies proposed in section .
.
table compares the overall performance between the baseline specusym without any optimizations base and the optimized specusym with all optimizations enabled opt as listed in column .
column and column compare the analysis time and the size of involved constraints between base andopt.
column and column disclose the number of identified new divergent leaks .
div and new opposite leaks .
opp respectively.
the cache setting for this experiment is c3 under which base andopthave the minimum performance gap forming a conservative comparison result.
as shown in column after optimizations the analysis time of theoptspecusym significantly decreases falling to only .
of the analysis time in base which confirms the effectiveness of the optimizations in accelerating the analyses.
apart from the time drop the optspecusym reduces the size of the involved constraint by more than compared to the base version as shown in column .
though the reduction to constraint sizes looks not as impressive as the time reduction the proposed strategies greatly ease the solver burden by constraint transformation and formula reduction.
undoubtedly constraint size reduction is the primary reason for the time decrease.
moreover column and column disclose that the optspecusym detects .
more leaks in total than the base version within a 12hour threshold.
in particular optidentifies times more divergent leaks than the base version which highlights the importance of our proposed optimization strategies.
we also examine how the optimizations impact each benchmark in terms of the analysis time in figure a and the constraint size in 1244specusym speculative symbolic execution for cache timing leak detection icse may seoul republic of korea figure b .
programs in these two figures are arranged using their orders in table .
tags base andoptalso stand for the specusym versions without and with optimizations respectively.
clearly figure a shows that optimizations drastically reduce time cost for 6out of 15cases from hundreds of minutes to less than an hour.
on the one hand the base has more repeated computations while optreuses cached intermediate results.
on the other hand formula reduction lowers the cost of solving.
figure b shows how optimizations reduce the constraint size where aes glibc des and seed have significant improvements.
for the other cases the memory trace length is commonly short.
thus our optimizations have no apparent improvements upon them.
finally we answer the last research question our optimizations significantly boost the overall performance by saving .
execution time and detecting .
more timing leaks.
.
threat to validity specusym works on the llvm ir.
the actual program behavior may differ due to the compiler optimizations and hardware features which could introduce false positives to specusym.
more low level details can further facilitate specusym to improve the analysis.
specusym considers nested speculative execution since branches may also exist on speculated paths.
as the speculative window is usually transient we treat the nested depth as configurable and set it to twoin evaluation.
also specusym executes at most the reorder buffer size of instructions on a speculative path.
however experiments show the effectiveness of this approximation.
so far specusym cannot support the analysis of multithreaded programs.
though symsc leveraged multithreading for timing leak detection considering concurrency and speculative execution together greatly amplifies the state space and interleaving space which pose exceptional challenges for a precise analysis.
another threat is from the out of order execution which schedules a set of data independent instructions in an out of order manner rather than sticking to the program order.
this processor optimization may affect the accuracy of our analysis.
however incorporating both speculative execution and out of order execution requires more dedicated analysis.
we leave it as future work.
related work regarding the security impact of processor speculative execution kocher et al.
demonstrated that speculative execution could silently influence the processor cache state thus giving rise to cache timing attacks which motivates our specusym work.
symbolic execution has been applying to side channel analysis because of the original designs of precise reasoning and input generation .
to quantify the information leakage through a cache timing side channel chattopadhyay et al.
and basu et al.
developed symbolic execution methods to study dependencies between sensitive data and cache behaviors.
wang et al.
developed cached which targets timing leaks through a trace based symbolic execution.
furthermore brotzman et al.
proposed casym a symbolic reasoning method that supports cache analysis upon multiple program paths.
considering the cache effects from thread interleavings guo et al.
proposed symsc to analyze cache timing leaks due to multithreading.
these methods however all ignore cache changes due to speculative execution.
abstract interpretation has also been adopting to cache timing side channel analysis because of its scalable analysis and soundapproximation.
cacheaudit approximates cache states by concrete state abstraction.
based on cacheaudit barthe et al.
track the program cache state affected by the attacker from a separate process.
caches provides a secret augmented abstract domain to track program secrets and dependencies.
however cacheaudit and caches are unaware of the impact of speculative execution.
though wu et al.
developed a dedicated abstract interpretation method for cache timing leak analysis under speculative execution the proposed technique is incapable of generating precise speculative flow and inputs to diagnose leaks.
likewise grey box fuzz testing has been used in detecting program undefined behaviors spectre type vulnerabilities exposing side channels and revealing timing leaks .
however they are either unaware of speculative execution or relying on sophisticated instrumentations on the control flow.
also due to the fuzzing nature these methods primarily count on various heuristics while specusym systematically solves for precise inputs.
among the existing works kleespectre spectector and are closely related to specusym.
kleespectre has an analogous understanding of modeling speculation in symbolic execution.
however kleespectre aims at spectre style vulnerability thus it has a crucial difference in constraint semantics.
spectector also targets spectre type vulnerability.
it employs symbolic execution to prove speculative non interference property or detect violations.
speculative symbolic execution proposed a method to lazily reason branch feasibility until reaching a threshold which improves the efficiency of the symbolic execution technique.
besides the above analysis methods there also exists compiler assisted techniques formal verifications and program synthesis approaches that model or mitigate side channel leaks.
still none of them is applicable to cache timing side channels due to speculative execution.
to conclude existing works may fail to produce inputs ignore cache affects from speculative execution or leverages speculation for other analyses.
in contrast specusym models speculative execution through stateful symbolic execution to generate inputs and pinpoint leak sites which can help reason the cache timing side channel leaks caused by speculative execution in depth.
conclusions in this paper we have presented a symbolic execution based method specusym for detecting cache timing leaks on running a sensitive data related program under speculative execution.
specusym systematically explores the program state space and models speculative execution at conditional branches.
by cache state modeling as well as cache behavior analysis specusym leverages constraint solving to search for divergent and opposite cache behaviors at memory access events.
experimental results show that specusym successfully detects timing leaks under different cache settings.
the proposed optimizations help specusym save .
execution time to detect .
more leaks.
comparison between specusym and state of theart abstract interpretation based method shows that specusym not only successfully detects leaks in the reported programs but also eliminates false positives for a more precise result.
acknowledgement this work was partially supported by the national science foundation of china under grants and and the natural science foundation of jiangsu province under grant bk20191247.
1245icse may seoul republic of korea guo et al.