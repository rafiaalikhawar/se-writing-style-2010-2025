input algebras rahul gopinath hamed nemati andreas zeller cispa helmholtz center for information security saarbr ucken germany email frahul.gopinath hamed.nemati andreas.zellerg cispa.saarland abstract grammar based test generators are highly efficient in producing syntactically valid test inputs and give their users precise control over which test inputs should be generated.
adapting a grammar or a test generator towards a particular testing goal can be tedious though.
we introduce the concept of a grammar transformer specializing a grammar towards inclusion or exclusion of specific patterns the phone number must not start with or .
to the best of our knowledge ours is the first approach to allow for arbitrary boolean combinations of patterns giving testers unprecedented flexibility in creating targeted software tests.
the resulting specialized grammars can be used with any grammar based fuzzer for targeted test generation but also as validators to check whether the given specialization is met or not opening up additional usage scenarios.
in our evaluation on real world bugs we show that specialized grammars are accurate both in producing and validating targeted inputs.
index terms testing debugging faults i. i ntroduction software test generators at the system level commonly known as fuzzers face the challenge of producing valid inputs that pass through syntactic checks to reach actual functionality.
the problem is commonly addressed by having a seed a set of known valid inputs which are then mutated to cover more behavior.
for complex input languages though mutations still mostly exercise syntax error handling.
we can obtain better performance by using a language specification such as a grammar to produce inputs.
as such inputs are syntactically valid by construction they reliably reach actual functionality beyond parsing.
the json grammar in fig.
for instance produces only syntactically valid json inputs and thus quickly covers json parser functionality.
writing accurate input grammars can be a significant effort which is why recent research has started extracting such grammars automatically from existing programs.
one less discussed advantage of language specifications however is how much control they grant their users over which inputs should be generated actually much more control than for seed based fuzzers.
for our json grammar for instance a user could go and assign probabilities to individual productions.
if the input should contain say several null values users can assign a high probability to null productions.
likewise users cancustomize the grammar.
adding an alternative expansion drop table students to thehstringirule will quickly populate the generated json input with sql injections for instance.
but there s a catch.
adding individual specific alternatives or adjusting probabilities is easy.
but how about contextualhjsoni helti helti hobjectijharrayijhstringijhnumberi j true j false j null hobjecti hitemsi j hitemsi hitemijhitemi hitemsi hitemi hstringi helti harrayi j heltsi heltijhelti heltsi hstringi hcharsi hcharsi hcharihcharsij hchari hnumberi hdigitsi hdigitsi hdigitihdigitsijhdigiti hdigiti fig.
json grammar simplified properties say a sql injection only in a particular context?
how about negation say any kind of input except for specific elements?
and how about their combination?
in principle such features canbe expressed in a context free language and hence in a grammar but these grammars would be nowhere as compact and maintainable as the example in fig.
.
in the past the need for such control also known as taming has been addressed by tweaking grammar based test generators that is adding special options often ad hoc and domain specific that address these concerns within the test generator .
with the test generator being turingcomplete there is no limitation to what such options can do.
however they also mean that one is tied to the particular tool and its specific features.
in this paper we address the problem of controlling grammarbased test generators from the ground up.
we introduce the concept of a grammar transformer a tool that takes a simple context free grammar and specializes it towards a specific goal.
as a result we obtain a specialized context free grammar which can then be used to produce specialized inputs with any context free grammar based test generator .
also the grammar can be used with any context free parser for checking existing inputs whether they meet the specialization properties.
to specify specializations we introduce a language that ieee acm 43rd international conference on software engineering icse .
ieee def jsoncheck json ifno key is empty string json fail one key must be empty ifany key has null value json fail key value must not be null process json fig.
jsoncheck fails if any key value is null or if no key is empty.
allows us to specify which features should be part of the specialized grammar and which ones should not.
at the base of our language we have evocative patterns orpatterns for short that form constraints over the values of specific nonterminals.
such patterns take the form hnonterminaliisvalue and are interpreted that there should be at least one instance ofhnonterminaliwith value value .
for our json grammar for instance we can create specialized grammars where at least one hitemihas a value of that is hitemiishstringi .
the resulting grammar produces json strings such as f foo bar g. where at least one key should be named zip followed by ahnumberi that is hitemiis zip hnumberi.
the resulting grammar would produce json strings such as f foo bar zip g. where at least one array should contain a null value that is heltsiisnull .
the resulting grammar would produce json strings such as f foo bar zip true qux g. for more complex specializations these patterns can be combined into boolean formulas.
these evocative expressions allows us to precisely specialize the produced inputs to match specific conditions.
as an example consider the function jsoncheck in fig.
.
the process function is only reached if no key has a null value and at least one key is the empty string.
to avoid the first branch to failure one key must be empty we can use the evocative pattern hitemiis helti this ensures that at least one item will have an empty key.
avoiding the second branch to failure key value must not be null we have to specify the absence of a pattern.
we do so bynegation expressing that noelement matching the pattern should be generated hitemiishstringi null to finally reach the process function both conditions must be met.
we obtain this by creating a conjunction of equation and equation hitemiis helti hitemiishstringi null the resulting grammar will produce null values but never as the value of anhitemi and ensure that at least one key nameis the empty string.
hence its outputs will always reach the process function in fig.
.
to the best of our knowledge this is the first work where users of a test generator can specifically express the absence andconjunction of patterns in given contexts.
going beyond simple data languages like json evocative patterns thus allow us to produce very targeted inputs for testing compilers and interpreters say a series of while loops that contain no assignments or sql queries containing inner joins left joins and right joins all in one.
this ability to express conjunctions and negations all within the grammar may be come as a surprise as context free grammars are not closed under conjunction or complement there is no way to transform a grammar into its negation.
however we show that our specialized grammars areclosed under conjunction disjunction and complement.
hence boolean combinations of patterns result in algebras of specialized grammars.
besides controlling test generation our evocative expressions which we call ewoks can be used in various ways.
for example when used in debugging the evocative patterns can quickly generate test inputs that contain a given failureinducing input validating fixes.
this works particularly well for abstract failure inducing inputs strings in which specific parts are generalized to nonterminals abstracting over concrete values which translate immediately into evocative patterns.
when used in conjunction with abstract failure inducing inputs which represent specific program behaviors our evocative expressions can be used to generate inputs that represent complex program behavior that can be checked for conformance.
for example one may mine abstract inputs that represent the coverage of specific portions of the program.
the evocative patterns corresponding to such abstract inputs may be used to produce complex evocative expressions that correspond to inputs that cover various parts of the program does not cover specific parts of the program or any combination where some parts are guaranteed not to be covered while other parts are guaranteed to be covered.
that is with evocative expressions one can build complex oracles out of simpler oracles.
when used with a parser they can check whether a given input meets a specified evocative expression for instance to identify inputs that trigger a failure or vulnerability.
evocative expressions can serve as query languages for searching and capturing specific patterns in structured data.
any of the above patterns could be used in a query.
going further evocative expressions might serve as alternatives for regular expressions especially as they allow to express negation.
given their verbosity structure and named subexpressions evocative expressions may be easier to read write and maintain than regular expressions.
evocative expressions can serve as configuration language to adapt generic configurations towards specific goals.
700features in software product lines customizations of user interfaces and permissions in access control lists could be combined in arbitrary ways.
this work opens the door towards giving developers simple yet powerful controls over what fuzzers produce without requiring them to modify fuzzer sources or rewrite grammars and other specs from scratch.
beyond fuzzing usages of specialized grammars also include generating targeted failure inducing inputs for validating fixes parsing inputs checking whether they contains a particular pattern or combination thereof querying patterns in data possibly even replacing regular expressions configuring and customizing systems towards specific goals.
after introducing basic definitions section ii the remainder of this paper is organized along its contributions abstract patterns.
section iiiintroduces abstract patterns which form the base for grammar specializations.
specializing grammars.
in section iv we introduce the algorithm for specializing grammars to contain at least one instance of the pattern on any of the generated inputs.
specialization algebras.
section vshows how to combine specializations into algebras using boolean operators.
we provide partially mechanized proofs that grammar specializations are closed under disjunction conjunction and negation.
implementation and usage.
section viintroduces evogram a grammar transformer prototype that implements these techniques as well as usage scenarios for testing debugging and adaptation.
evaluation.
in section vii we show that the specialized grammars accurately produce andrecognize inputs that satisfy the given patterns.
related work.
comparing to related work section viii ours is the first approach that allows test generators to express absence and conjunction of patterns in a given context.
in contrast to the closest related work evogram can produce andrecognize inputs that contain failure inducing patterns in arbitrary contexts.
as detailed in section ix evogram and all experiments are available for reuse and replication.
we close with conclusion and future work.
ii.
d efinitions the following definitions are based on .
alphabet.
the alphabet of the input language of a program is the set of all symbols accepted by the program.
input.
a contiguous sequence of symbols from the alphabet that is passed to a given program.
terminal.
a sequence of symbols from the alphabet.
these form the leaves of the derivation tree.
nonterminal.
a symbol outside the alphabet whose expansion is defined in the grammar.
rule.
a finite sequence of terms two types of terms terminals and nonterminals that describe an expansion of a given nonterminal.definition.
a set of rules that describe the expansion of a nonterminal or how the nonterminal is matched .
context free grammar.
the context free grammar is composed of a set of nonterminals and corresponding definitions that define the structure of the nonterminal.
derivation.
a terminal derives a string if the string contains only the symbols in the terminal.
a nonterminal derives a string if the corresponding definition derives the string.
a definition derives the string if one of the rules in the definition derives the string.
a rule derives a string if the sequence of terms that make up the rule can derive the string deriving one substring after another contiguously also called parsing .generation is defined complementarily .
derivation tree.
an ordered tree that describes how an input string is derived by the given start symbol.
an abstract derivation tree has some nodes marked as abstract and abstract nodes may not have child nodes.
compatible node.
a node is compatible to another if both have the same nonterminal.
a tree is compatible to another if both have compatible root nodes.
reachable nonterminal.
a nonterminal aisreachable from another nonterminal bifais reachable from any of the rules in the definition of b. a nonterminal is reachable from a rule if that nonterminal is present in the rule or that nonterminal is reachable from any of the nonterminals in the rule.
for example harrayiis reachable from hjsoni helti hobjecti hitemsi hitemi heltsiand also itself.
subtree.
for any node a subtree is a tree rooted in any nonterminal reachable from that node.
the characteristic node of that subtree is its top most node and its nonterminal is thecharacteristic nonterminal .
we also introduce the following new definitions generalizing beyond failure inducing inputs to evocative inputs that is inputs that trigger a specific program behavior.
evocative input.
an input string is evocative or failureinducing if on execution of the program with the string as input the program fails in a particular fashion or displays an expected behavior.
evocative fragment.
a fragment of an evocative input string isevocative or failure inducing if some property of the fragment is the cause of the behavior or failure observed.
that is we can transplant the subtree corresponding to that fragment to a compatible node in another derivation tree and the corresponding string reproduces the same behavior.
iii.
a bstract patterns our end goal is to generate specialized grammars that obey given constraints.
our ongoing example will be the code constraints from fig.
requiring that at least one json object has an empty string as key and no json object has null as a key value.
in our pattern language we can produce 701hjsoni helti hobjecti fhitemi hstringi hcharsi helti hstringi hcharsi g fig.
derivation tree for f g the following evocative expression from which a grammar that obeys the given constraints can be produced.
hjsone ni wher ehitemeiis helti hitemniishstringi null this expression is equivalent to the compound expression in equation .
here hitemei represents the constraint of empty key andhitemni represents the constraint of null value.
the expression hjsone nirepresents the specialized grammar with the combined constraint of at least one empty key and nonull values in any generated input.1in the rest of the paper this forms the running example and we see how each component of this expression is derived.
how do we relate these expressions to grammars?
the constraints are predicates on the derivation tree.
that is hitemeiis heltirepresents the constraint that a derivation tree produced should contain an hiteminode with two children.
the first should be an empty string and the second could be anyhelti.
a. finding abstract patterns in derivation trees to derive the constraint ethat represents a particular failure condition we start with an evocative input that induces the expected failure f g. this will have a derivation tree as given in fig.
.
are all parts of the input equally needed to satisfy the constraint?
indeed we can easily see that the key valueheltiof value can be replaced with any other helti and still induce the failure.
that is the following is an abstract representation of inputs that induces the same failure f heltig.
we note that this is exactly the abstract pattern generated by ddset .
that is for any given derivation tree the corresponding abstract pattern is the abstract string representation where the string representation of nodes marked as abstract are thecorresponding nonterminals called an abstraction .
for example fhstringi nullgis an abstract pattern and contains 1while both evocative patterns have hitemias the characteristic nonterminal in this example there is no such requirement.
that is hjsone iiwhere hnumber iiis011hdigitsiis allowed.hitemi hstringi hcharsi helti a abstract treehiteme0i hstringe1i hcharse2i helti b specialized nodes fig.
abstract trees for hitemeiis helti hstringias an abstraction of the corresponding input fragment.
when deriving an abstract pattern a nonterminal also matches the corresponding abstraction.
such abstract patterns concisely and precisely specify what parts of the input are important and the abstract pattern is a recipe for minimal andcomplete evocative inputs.
however we are only interested in a smaller part of the corresponding abstract derivation tree.
we are interested in the smallest subtree that when included in a larger input induces the failure reliably.
b. abstract patterns to evocative patterns so what part of the derivation tree actually caused the failure?
on inspection one can see that a much smaller part of the derivation tree under the node for hitemiis sufficient to induce the failure.
that is one can replace an hitemi node in any derivation tree with this node and the resulting string will induce the failure.
that is the subtree given in fig.4aaccurately captures the constraint.
such subtrees can be represented by their characteristic nonterminal and the string representation of the rest of the tree using nonterminal symbols where abstract nodes are present.
we call these evocative patterns .
for example hitemeiis heltiis the evocative pattern that represents the subtree given in fig.
4a.
given an abstract pattern one can also automatically obtain the characteristic node by simply looking for the smallest subtree that contains all terminal symbols in the abstract pattern.
we use such evocative patterns in our evaluation.
however the characteristic node obtained could likely be trimmed further to produce a smaller subtree that can still induce failures reliably in a larger variety of contexts.
iv.
t ransforming grammars we now show how one can transform the underlying grammar such that any input generated from it would contain at least one instance of the evocative pattern.
the underlying non specialized grammar is called the base grammar and the definitions rules and nonterminals in that grammar are called base definitions base rules and base nonterminals respectively.
note that we require base grammars to be nonambiguous .
that is any given string should have only a single derivation.
transforming the grammar means to specialize it and this is accomplished by specializing each nonterminal the corresponding definition and each applicable rule in the definition.
we describe specializations of nonterminals and their corresponding definitions next.
702specialized nonterminal.
a specialized nonterminal is a base nonterminal name followed by a specialization suffix.
for example given a nonterminal hitemni thehitemiis the corresponding base nonterminal also called the base representation of the specialized nonterminal and the subscript nis the specialization representing the evocative expression.
note that a terminal cannot be a specialized.
hence the base representation of a terminal is always itself.
a term is same kind as another term if both have the same base representation.
the subscript nis constructed as follows an evocative pattern is defined as hnonterminal subscriptiisvalue where subscript refers to the particular constraint represented by value .
we use a related notation for specialization.
we usehnonterminal subscriptito denote a specialized nonterminal where subscript is a boolean expression of the constraints acting on the given nonterminal.
note that in terms of the context free grammar this is just another identifier.
a context free grammar containing such specialized nonterminals can be used exactly like any other context free grammar.
for us however it is a unique and expressive identifier that states the precise purpose.
specialized definition.
a specialized definition can have rules with specialized nonterminals or some of the expansion rules may be removed from the corresponding base grammar definition.
the following is a specialized definition ofhobject ei removing the empty object expansion and includes specialized nonterminals hitemseiandhitemse1i.
hobject ei hitemsei j hitemse1i some of the specialized rules such as above may have the same base representation rule hobjecti f hitemsi g in the above example.
such a set of rules in a definition is called a ruleset for that base rule and such rules have same kind.
a. translating evocative patterns to pattern grammars we translate the abstract derivation tree rooted at characteristic node to a grammar capable of producing instances of the evocative fragment using our json grammar as running example.
to do this we specialize the non abstract nodes from the abstract tree with the evocative pattern name andunique suffixes such that no two nonterminal symbols will reuse the same name and suffix.
for example given the abstract tree fig.
4a nodes are specialized in fig.
4b.
next with the characteristic nonterminal hiteme0ihere as the start symbol this tree is collapsed into a grammar children of each node forming a single rule definition for their nonterminal.
hiteme0i hstring e1i helti hstring e1i hcharse2i hcharse2i next we will see how the characteristic symbol of pattern grammar hiteme0i is connected to the rest of the grammar.b.
constructing a reaching grammar finding insertable positions to be able to instantiate instances of the evocative fragment one needs to be able to reach the characteristic nonterminal of the evocative pattern.
for example to reach hitemiin the json grammar one has to start from one of the following nonterminal symbols hjsoni helti hobjecti hitemsi hitemi harrayi heltsi.
for each rule in the grammar we identify the nonterminal terms that can reach the nonterminal of the characteristic node.
for json the following are the insertable positions.
hjson i h elt i helti h object ijh array i hobject i h items i hitems i h item ijh item i h items i hitem i hstring i h elt i harray i helts i h elt ijh elt i h elts i in the json grammar hstringicannot reachhitemi.
hence it is unmarked.
none of the other nonterminals have any rules that can reachhitemi.
for the reaching grammar we take each rule of a given definition and identify the insertable positions in the rule.
next for each insertable position we produce a copy of the rule with the nonterminal at the identified position specialized with the evocative fragment name.
the reaching definition corresponding to the new specialized nonterminal is the collection of such new rules.
if the rule has no insertable positions it cannot derive evocative fragments.
hence such rules are discarded.
if a nonterminal has no reaching rules its definition is empty and it is discarded from the reaching grammar .
the reaching grammar is a grammar composed of reaching nonterminals and their corresponding reaching definitions .
the definition for nonterminals in reachable grammar for eis as follows hjsonei heltei heltei hobject eijharrayei hobject ei hitemsei hitemsei hitemei hitems ijhitem i hitemsei jhitemei hitemei hstring i heltei harrayei heltsei heltei helts ijhelti heltseijheltei c. connecting pattern grammar and reaching grammar for the final grammar we merge the pattern grammar and the reaching grammar and use the start symbol from the reaching grammar.
the connection is made at the reaching characteristic nonterminal here hitemei .
we merge the definition from the characteristic nonterminal of the pattern grammar here hiteme0i to the reaching nonterminal of characteristic node.
note thathstring e1iwas previously defined and represents the empty string.
hitemei hstring i helteijhstring e1i helti 703hitemi hstringi helti null a abstract treehitemn0i hstringi heltn1i null b specialized nodes fig.
abstract trees for hitemniishstringi null v. a lgebra of grammar specializations next we discuss how arbitrary boolean expressions can be composed from other grammar specializations.
we call these evocative expressions .
again consider the expression introduced in equation that represents a specialized grammar producing inputs that contain at least one empty key and does not contain a key value null .
this will be our ongoing example for specializations.
we first look at negation of grammar specializations.
in the grammar we indicate negation by an over line.
to illustrate the algebra we use the second pattern at least one instance of anull key value in the input.
the abstract pattern from which the expression is derived is fhstringi nullg and the evocative pattern is hitemiishstringi null .
the abstract tree is given in fig.
5a and its pattern tree in fig.
5b.
from this the specialized grammar contains all the above nonterminal definitions as well as hjsonni heltni heltni hobject nijharrayni harrayni hobject ni hitemsni heltsni heltni helts ijhelti heltsnijheltni hitemsni hitemni hitems ijhitem i hitemsni jhitemni hitemni hstring i heltnijhstring i heltn1i heltn1i null now we come to the actual definition of boolean expressions.
we start with the axioms for terms where we have two basic requirements none of the operations can change the term type orkind.
in the case of two or more operands operations are only defined with respect to the same kind of terms.
we usehnonterminal i short hnonterminalior where unambiguous to represent base nonterminal and hnonterminal ?ior?for nonterminals with empty definition.
rules with ?
terms are removed recursively at the end of evaluation of the complete expression.
a. negation of a single term negation of a term means that if a term derived a given substring the negated term will not derive the same substring and vice versa.
negation of a terminal is empty.
a nonterminal with specialization is negated with respect to the specialization.
that is harrayeirepresents elements in harrayinot derived byharray ei.
negation of a base nonterminal is ?.
negation of an empty nonterminal is .
that is hitem?i hitemi.b.
conjunction of two terms the term from conjunction of two terms will only derive any and all substrings derived by both the operands and is defined only for terms of the same kind.
the conjunction between two equal nonterminals is the same nonterminal between and a specialized nonterminal is the specialized nonterminal between a nonterminal and its negation is ?
and between?
and anything else is ?.
for example conjunction of harrayei andharray niisharray e nirepresenting elements in harrayi derived by bothharray eiandharray ni.
c. disjunction of two terms the term from disjunction of two terms will only derive any and all substrings derived by either operands and is only defined for terms of the same kind.
the disjunction between two equal nonterminals is the same nonterminal between and a specialized nonterminal is between a nonterminal and its negation is and between any nonterminal and ?
is the first nonterminal.
for example disjunction of harray ei andharray niisharray e nirepresenting elements in harrayi derived by eitherharray eiorharray ni.
d. negation of a single rule negation of a rule produces as many rules as there are specialized nonterminals each with one specialized nonterminal negated and the rules from negation of a specialized rule will not be able to derive a string derived by the operand and vice versa.
say you have a rule heltei heltsei.
to negate the rule we take each specialized nonterminal and negate it one at a time.
in this example the result is two rules heltei heltseiandheltei heltsei.
proof c2a string derived by the operand could not have been derived by any of the new rules because each rule contains at least one nonterminal that will reject the corresponding derivation.
bif any new rule derived a string at least one nonterminal in operand will reject it3.
e. conjunction of two rules conjunction is defined only between rules of the same kind and the result will derive any and all strings that could be derived by both the operands.
to produce a conjunction of two rules we line up both and produce a conjunction of terms from each at corresponding positions.
that is given two rules heltei heltseiandheltni heltsni the conjunction ishelte ni heltse ni.
proof csay the new rule derives a string.
pick an operand.
each nonterminal in the deriving rule could be replaced by one nonterminal in operand rule without affecting the derivation.
bsay a string is derived by both operands.
that string could be split into contiguous substrings such that each substring is derived by either a terminal or corresponding nonterminals from both operands.
if two nonterminals derive the same string then their conjunction also derives it.
2we use candbto indicate the direction of the proof.
3the appendix for this paper contains a partial mechanization for proofs in hol4 .
704f .
disjunction of two rules disjunction is defined only between rules of the same kind and the result will derive any and all strings that could be derived by one of the operands.
to produce a disjunction of two rules merge them or use each as alternatives in any resultant definition.
one may merge two rules into one if the two rules differ only by a single specialized nonterminal which is replaced by a disjunction of operand specializations.
given two rulesheltei heltsiandheltni heltsi the disjunction ishelte ni heltsi.
on the other hand given heltei heltseiandheltni heltsni the disjunction is exactly the same as original two rules.
proof cpick any operand.
the merged rule differs from the operand rule in exactly one place which is a superset of operand specialization any string derived by the operand could also be derived by the new rule.
bany string that is derived by the new rule can be split into contiguous substrings such that each term in the new rule derives one substring.
the new rule differs from operand rules in exactly one nonterminal which is a disjunction of operand nonterminals.
g. negation of a ruleset the result of negation of a ruleset derives any and all strings that will not be derived by the negated ruleset.
given a ruleset with multiple rules one has to only remember that they are alternatives.
e.g.
s r1jr2jr3.
hence negation is based on boolean algebra.
that is r1jr2jr3is same as r1 r2 r3.
given that each rule negation results in multiple alternates we apply distributive law.
that is the new ruleset is as follows fr1 r2 r3 r12r1 r22r2 r32r3g proof cany string derived by any of the new rules will be derived by each of the negations because it is a conjunction of one rule from negation of each rule.
since there cannot be a string that is derived from both a rule and its negation there does not exist a derivation using the original ruleset.
bany string that is derived by the original ruleset will not be derived by the new because the new is composed of negations from each rule in the original.
h. conjunction of two rulesets result of conjunction of two rulesets derives any and all strings derived by both of the operands.
for conjunction between two rulesets we take one rule from each and compute the conjunction of both.
the new rules will be all such conjunctions fr1 r2 r12s1 r22s2g proof cany string that is derived by one of the rules in the new ruleset will have been derived by at least one rule from both operand rulesets.
bif both operand rulesets derived the same string then there exist a rule in both that derived it and the new ruleset contains conjunction of all such rules.
i. disjunction of two rulesets the result of disjunction of two rulesets derives any and all strings derived by any of the operands.
disjunction of two rulesets is a new ruleset with rules from both merging rules that can be merged.proof cany string derived by the new ruleset will be derived by a rule in at least one of the operands.
bany string derived by a rule in a parent operand will be derived by new ruleset because the same rule is there in the result.
j. negation of a definition the result of a negation derives any and all strings that will not be derived by the operand.
for negation of a definition any base rule that is not represented by a ruleset in the nonnegated definition is added directly to the negated definition.
these correspond to the rules with empty terms that we discarded when the operand was produced.
then negations from each rulesets are combined together and added to the negated definition.
the negation of a definition is represented by the negation of its corresponding nonterminal.
proof csay a string was derived by the operand.
a rule that was not present in the original rulesets could not have derived the string as part of the original non negated definition.
hence non represented rules could not derive a string that could be derived by the operand.
next all other rulesets are negations of rulesets in the operand none of which can derive a string derived by the operand.
bif a string was derived by the new definition this string was either derived by one of the directly added rules in which case there is no corresponding rule in the operand or by one of the negated rules in which case the operand could not have derived it anyway.
k. conjunction of two definitions result of conjunction of two definitions derives any and all strings derived by both the operands.
to produce a conjunction of two definitions the rulesets of the same kind from each operand are paired up and conjoined together dropping those that do not have a pair in either operand.
the conjunction of two definitions is represented by the conjunction of the specialization of their corresponding nonterminals.
proof cany string derived by the result would be derived by one of the conjoined rulesets which is a conjunction of rulesets from operands.
bif a string was derived by both operands a ruleset exists in both that derives the string.
a conjunction of all such ruleset pairs exists in the new definition.
l. disjunction of two definitions the result of disjunction derives any and all strings derived by any of the operands.
disjunction of two definitions is again simply a combination of rulesets of the same kind from each operand and is represented by the disjunction of the specialization of their corresponding nonterminals.
proof cany string derived by the new definition was derived by one of the rulesets which came from one of the operands.
bpick an operand and say it derived a string.
the ruleset from that operand is part of the new definition.
m. negation of a specialized grammar negation of an arbitrary grammar specialization is produced by first negating its start symbol and constructing the negations and other expressions for any specialized 705nonterminals that is needed from the definition of the start symbol recursively.
given below is the grammar for evocative expressionhjsonniwherehitemniishstringi null .
hjsonni heltni heltni false j null j true jhnumber ijhstring ijharraynijhobjectni harrayni j hobjectni j hitemsni heltsni heltnijheltni heltsni hitemsni hitemnijhitemni hitemsni hitemni hstring i heltn n1i heltn n1i false j true jhnumber ijhstring ijharraynijhobjectni n. conjunction of two grammar specializations the conjunction between two grammar specializations is produced by first conjoining their start symbol and hence their corresponding definitions recursively.
the following is the rest of the specialized nonterminals for the grammar specialization representing equation .
hjsone ni helte ni helte ni harraye nijhobjecte ni harraye ni hobjecte ni hitemse ni heltse ni helte nijhelte ni heltsni jheltni heltse ni heltn n1i false j true jhnumber ijhstring ijhobjectnijharrayni hitemse ni hiteme nijhiteme ni hitemsni jhitemni hitemse ni hiteme ni hstring e1i heltn n1i jhstring i helte n n1i helte n n1i harraye nijhobjecte ni o. disjunction of grammars disjunction of two grammars is built by disjunction of their start symbol and corresponding definitions recursively.
p .
constructing definitions corresponding to nonterminals to convert an evocative expression to grammar we try to construct the start symbol of the new grammar.
to do that we need to apply the given operation to the corresponding definitions of the start symbols of the subject grammars.
these in turn require further specialized nonterminals to be computed which is done recursively until no more specialized nonterminals need to be constructed.
at each step the nonterminal to be constructed is simplified into its canonical dnf form.
we then reconstruct this term from our smallest specializations i.e the specializations that correspond to a single pattern that can be directly reconstructed from the evocative patterns.
we note that one can also collect all the boolean expressions for the same nonterminal from operand grammars and solve them to reconstruct the new term in terms of available terms.
that is the algebraic operations can be done on conforming grammars even if the smallest terms are not known and the nonterminals are not labelled with pattern expressions.vi.
i mplementation and usage scenarios we have implemented evogram as a standalone jupyter4 notebook with detailed steps and examples5.
the grammars are accepted and produced in the fuzzingbook canonical format and the evocative patterns in the ddset format.
grammars can be converted from and to other popular formats such as antlr.
we see the following usage scenarios for evogram precise control during fuzzing.
given a particular pattern or a set of patterns that is associated with some behavior of the program one can use grammar specializations to specify that inputs generated satisfy arbitrary boolean constraints inducing certain failures while preventing others.
the utility of such a grammar is that one can precisely ask the fuzzer to concentrate on portions of code or portions of input space one wants to explore further avoiding the behaviors that one does not want to trigger.
testing and validating fixes.
the above control over test inputs works particularly well if a concrete failure inducing input can be generalized towards an abstract failureinducing input as produced by ddset .
when fed with such patterns the evogram produces a grammar whose produced strings all contain instantiated patterns and thus variants of the original failure inducing input in all sorts of contexts which makes them helpful for validating fix correctness.
validating inputs.
assuming that a certain vulnerability is known to be induced by a failure inducing pattern under specific contexts one can encode the specific context under which the failure is induced and allow only the negation of this pattern to proceed to the program rejecting any string that may induce the failure.
this provides the developers with a quick fix tool for identifying and quickly rejecting potentially malicious inputs such as sql injections without the knowledge of the internals of the program.
algebra of oracles.
the abstract behavior inducing inputs are mined from a given program and a given predicate using ddset .
such abstract inputs correspond to specific program behaviors and are directly representable as evocative patterns.
given such evocative patterns we can build evocative expressions that represent complex program behaviors and can be used to validate the program behavior for corresponding inputs.
supercharged recognizers.
regular expressions regexes are typically used to match and extract parts of input by programmers.
these inputs may often be encoded in a structured format such as json xml html and sexpr.
however the siren song of regular expressions is hard to ignore6.
while the situation has started to change with projects such as combi semgrep and coccinelle that rely on the underlying grammar 706the constructs they use are limited disjunction and at best conjunction and the expressions need to be written by hand which limits their usability.
the evocative expressions can be automatically mined from sample expressions and combined to form arbitrarily complex matching specifications.
further evocative expressions can be extended to support constraints on each term such as length 10or variable aisdefined .
the relational algebra of such constraints can be easily added to the underlying boolean algebra.
generating data structures.
algebraic data types except gadts have a mapping to context free grammars and property checkers such as quickcheck rely on generation of data structures to verify properties.
the specialized grammars from evocative expressions could precisely specify how and what properties these structures should contain.
configuring and customizing systems.
most hierarchical structures can be represented as derivation trees from context free grammars.
such structures include urls file systems gui navigation object hierarchies and more.
all these structures have some concept of access control defining under what conditions certain elements can be reached or certain actions can be performed.
such access control rules could be expressed via evocative patterns specializing general access rules towards specific environments.
vii.
e valuation we have evaluated evogram and grammar specializations both in a testing context producing inputs that contain specific evocative patterns and in a prevention context checking whether inputs contain a specific pattern .
specifically we pose the following research questions rq1 how effective are the specialized grammars produced by evogram in producing expressions that contain and do not contain any evocative fragments?
rq2 how effective are the generated specialized grammars in recognizing expressions that contain or do not contain evocative fragments?
a. evaluation setup for evaluation we use the subjects from ddset .
the first are programming language interpreters clojure closure rhino and lua.
input languages for these subjects are more constrained than simple context free languages with the ability to declare and use variables and functions.
when using a grammar based fuzzer the probability of randomly generating asemantically valid string is extremely low.
hence for such language interpreters we rely on evaluating the specialized grammars only as recognizers.
for the unix utilities findand grep only syntactic validity is required.
hence we evaluate these utilities as both producers and recognizers.
for the evaluation as producers we generate inputs using two strategies the first strategy is to insert evocativetable i percentage of inputs generated with evocative strategy that induces failure f and non evocative strategy that did not induce failure f .
bug f f find 07b941b1 of of find of of find c8491c11 of of find dbcb10e9 of of grep 3c3bdace of of grep 54d55bba of of grep 9c45c193 of of total of of fragments into the grammar.
the resulting grammar we call this the evocative grammar and the strategy the evocative strategy is then used for input generation.
the second strategy negates the previous grammar and the resulting grammar we call this the non evocative grammar and the strategy the non evocative strategy is used to produce inputs.
the inputs thus generated are fed to the program and the program is monitored for the expected behavior and its absence.
for the evaluation as recognizers we require a source of inputs that induces the failure as well as a source of inputs that is guaranteed not induce the failure.
since we are using the subjects from ddset we use inputs generated during the pattern mining for this purpose.
that is we collect the semantically valid strings generated during minimization and abstraction which were found to have induced a failure or otherwise.
we then evaluate whether the specialized grammars produced by evogram using the evocative strategy are capable of recognizing evocative inputs and rejecting the non evocative inputs.
similarly we evaluate whether the specialized grammars produced by evogram using non evocative strategy are capable of rejecting any failure inducing input.
b. evaluation results and discussion our evaluation results are as follows the result of generating evocative inputs using the evocative andnon evocative strategies tested against the program for reproducing the failure is given in table i. thefcolumn contains the percentage of inputs using evocative strategy that induced the failure when tested against the program.
the fcolumn contains the percentage of inputs using non evocative strategy thatdid not induce the failure when tested against the program.
from table i we find that specialized grammars generated by evogram can produce inputs that contain the given evocative fragment and reproduce the expected failure with high accuracy when used as a test generator for unix utilities.
further when used to produce inputs that do not contain the evocative fragment evogram succeeds in avoiding such failure inducing fragments in its inputs with an accuracy of .
.
the bug grep 9c445c193 could not be abstracted.
hence only a single input was produced during fuzzing and only three substrings recognized.
707table ii recognizing failure inducing inputs with fand non failure inducing inputs with f. bug f f find 07b941b1 .
of of find .
of of find c8491c11 .
of of find dbcb10e9 of of grep 3c3bdace .
of of grep 54d55bba .
of of grep 9c45c193 .
of of clojure .
of .
of clojure .
of .
of clojure .
of .
of clojure .
of .
of clojure .
of .
of clojure .
of .
of closure .
of .
of closure of .
of closure .
of .
of closure .
of .
of closure .
of .
of closure .
of .
of lua .
.
.
of .
of rhino .
of .
of rhino .
of .
of total .
of .
of evogram grammars induce expected failures with accuracy and prevent such failures with .
accuracy.
the result of recognizing evocative inputs using the evocative strategy is given in fcolumn of table ii.
the result of recognizing non evocative inputs using the non evocative strategy is given the fcolumn.
looking at evogram s performance as a recognizer from table iiwe find that grammars from evogram are able to recognize the failure inducing inputs for most bugs.
for a number of bugs however lua .
.
clojure closure clojure grep 9c45c193 less than half of the failure inducing inputs were predicted as such.
this is due to the ddset pattern specializing to the first failure inducing bug which then leads to an overspecialization in the resulting grammar.
however even with this caveat the grammars produced by evogram are able to recognize failure inducing inputs with .
accuracy and non failure inducing inputs with .
accuracy.
evogram grammars recognize failure inducing inputs with .
and non failure inducing inputs with .
accuracy.
evocative expressions represent specialized context free grammars that guarantee production of the requisite pattern somewhere in the input string produced.
however having the particular pattern somewhere in the string is no guarantee that a given failure is induced.
for example the null check may be ignored under specific circumstances.
hence it is important to validate how effective the grammars are in converting the input patterns to actual failures.
our results from table iusing real world bugs show that the evocative expressions work well in generating inputs that contain the failure pattern as wellas in inducing the requisite failure.
similarly the same table shows that we can generate inputs that will not contain the problematic patterns thus freeing the fuzzer to explore rarer bugs.
as our results from table iishow evocative expressions shine in the role of recognizers of specific patterns in input and can work in the role of a validator for inputs.
c. threats to validity our empirical evaluation is subject to the following threats to validity external validity.
the external validity generalizability of our results depends on the representativeness of our data set.
our subjects were a small set of language interpreters and two unix utilities.
further only a few bugs were evaluated and their patterns chosen for experiments.
hence it is possible that our subjects are not representative of the real world.
the main mitigation here is that these were actual bugs found in the wild logged by real people.
further the grammars are from popular and complex real world input and programming languages.
internal validity.
the threat to internal validity correctness of evaluation of our results is mitigated by careful verification including formal proofs of our algorithms.
construct validity.
to mitigate the threat to construct validity the degree to which a test measures what it claims to be measure of we measure how accurate our specialized grammars are as recognizers and generators which are the main ways we expect practitioners to use our tool.
viii.
r elated work a. grammar based testing already in hanford suggested the use of grammars to systematically produce valid inputs .
today s approaches combine specification based producers with symbolic constraint solving reusing fragments from bug reports search based strategies grammar coverage annotations search heuristics power schedules and local input generators search based grammar testing is now also applied for security testing .
all these tools and approaches can immediately benefit from specialized grammars as produced by evogram targeting specific input subsets or the locations that process them.
b. patterns and pattern languages in software engineering patterns have been frequently used to obtain specific search and configuration results.
besides the ubiquitous regular expressions and wildcards a number of approaches allow to express structural properties.
combi shows how patterns based on a base context free grammar can be used for identifying and transforming structures in code.
semgrep by r2cis another tool that allows programmers to specify patterns similar to evocative patterns.
note though that both are for recognition which is a simpler problem than generation as one can run the matching rules as as sequence of filters.
we note that while the patterns used by combi are similar to the evocative patterns they 708are meant to be specified by hand only.
combi and semgrep allow conjunction and disjunction of patterns but algebras and negations are not supported.
micro grammars is another general approach for partial parsing and semantic analysis.
another related work is coccinelle that defines a pattern language for transformations of c programs such as the linux kernel.
while coccinelle supports disjunction of patterns conjunction and negation are not supported.
conjunctive and boolean grammars are a generalization over context free grammars and specify grammars based on conjunction implicit disjunction and negation of arbitrary context free grammars.
while one can reuse context free grammar parsers by applying one grammar after another it is not clear whether efficient producers exist for such languages.
c. generalizers generalizers are tools that turn a concrete input into a more general pattern with similar effect.
ddset generates failure patterns from any given failure inducing input and the corresponding predicate.
smartcheck from lee pike generalizes algebraic data structures.
extrapolate by braquehais et al.
generalizes counter examples of functional test properties.
groce et al.
show one can identify canonical minimal tests with annotations for generalizations.
in our context the generalized patterns all serve as starting point forevocative patterns .
none of these tools would produce boolean combinations of patterns.
ix.
c onclusion and future work with evogram we have introduced the concept of a grammar transformer specializing a grammar towards boolean combinations of pattern occurrences.
such transformations give testers unprecedented control over the test inputs to be produced.
the transformations are proven to be correct an evaluation shows the usefulness of transformed grammars for producing and checking patterns.
our future work will focus on the following applications.
the lion s share of our future work will focus on further usage scenarios hinted at in section vi from parsing over pattern matching to configuration and adaptation.
richer specifications.
we have described how to insert at least one failure inducing fragment into the input or not .
what if one wants a particular number of fragments say exactly one ?
what if one wants sequences of fragments one pattern should always follow another one ?
such constraints can still be represented in a context free grammar and we will be investigating specific transformations for them.
constrained grammars.
some input properties cannot be easily expressed in a context free grammar numerical properties is a typical example.
we want to attach turingcomplete constraints to individual patterns and then use transformation rules together with constraint solving toproduce inputs that satisfy structural as well as other constraints.
ambiguous grammars.
our algebra is restricted to nonambiguous context free base grammars.
however it may be extended to allcontext free grammars by taking into account the fact that there could be multiple parse trees for an evocative pattern.
we provide a well explained jupyter notbook7that details our technique as well as a partial mechanization of proofs using hol4 for verification8.
the complete replication package is available as a virtual machine at