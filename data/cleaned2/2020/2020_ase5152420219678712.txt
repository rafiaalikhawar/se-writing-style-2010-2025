thinking like a developer?
comparing the attention of humans with neural models of code matteo paltenghi department of computer science university of stuttgart stuttgart germany mattepalte live.itmichael pradel department of computer science university of stuttgart stuttgart germany michael binaervarianz.de abstract neural models of code are successfully tackling various prediction tasks complementing and sometimes even outperforming traditional program analyses.
while most workfocuses on end to end evaluations of such models it often remainsunclear what the models actually learn and to what extent theirreasoning about code matches that of skilled humans.
a poorunderstanding of the model reasoning risks deploying modelsthat are right for the wrong reason and taking decisions basedon spurious correlations in the training dataset.
this paperinvestigates to what extent the attention weights of effectiveneural models match the reasoning of skilled humans.
to thisend we present a methodology for recording human attentionand use it to gather human attention maps from 91participants which is the largest such dataset we are awareof.
computing human model correlations shows that the copyattention of neural models often matches the way humans reasonabout code spearman rank coefficients of .
and .
whichgives an empirical justification for the intuition behind copyattention.
in contrast the regular attention of models is mostlyuncorrelated with human attention.
we find that models andhumans sometimes focus on different kinds of tokens e.g.
strings are important to humans but mostly ignored by models.the results also show that human model agreement positivelycorrelates with accurate predictions by a model which calls forneural models that even more closely mimic human reasoning.beyond the insights from our study we envision the release ofour dataset of human attention maps to help understand futureneural models of code and to foster work on human inspiredmodels.
i. i ntroduction neural models that analyze source code have become extremely effective on various tasks such as code summarization bug detection bug injection bug repair and type inference .in essence these models learn implicit rules patterns andheuristics from a large number of code examples and thenapply them to previously unseen code.
an implicit assumptionis that the models reason about code in a way similar to humansoftware developers.
however it currently remains unclearto what extent the computations performed by trained neuralmodels actually resemble how humans reason about code.
understanding the relation between neural and human reasoning is an important step toward better understanding whyneural models of code work or sometimes do not work.current models are mostly black boxes and it remains difficultto understand why a model succeeds or fails.
gaining abetter understanding of these models is crucial to validatethat a model is right for the right reasons instead of e.g.
picking up coincidental but meaningless correlations in adataset.
moreover it will ultimately help build more effectivemodels by identifying current weaknesses and confirming whyparticular techniques are effective.
a popular way to increase the transparency of neural networks is an attention mechanism .
it assignsa weight to each part of the input showing which partsof an input a model is most interested in.
recent workin natural language processing studies the effectiveness ofattention weights as an explanation technique by comparingthem with alternative explanation approaches .
asa first attempt to understand attention weights in models ofcode bui et al.
artificially remove individual statements observe how it affects a model s predictions and then comparethe importance of an input segment to attention weights.
aquestion that remains open is how attention weights in modelsof code relate to how humans reason about source code.
this paper presents the first systematic study to compare neural models of code with human reasoning.
we comparethe attention weights of neural models with the attention thathumans pay when reasoning about source code examples.our work focuses on the method summarization task whichis interesting as it requires a thorough understanding of apotentially complex piece of source code and a populartask for neural models of code.
for this task we study twoneural models which offer two kinds of attentionweights regular attention showing what tokens the model focuses on and copy attention showing what tokens the model considers to copy verbatim into the output.
we compare theseattention weights to humans working on the same methodsummarization task while participating in our study.
a key challenge for our work is capturing the attention of humans while they reason about source code.
we address thischallenge through a novel methodology for recording humanattention paid while solving a code related task.
intuitively the idea is to approximate the human attention with the time ahuman looks at a particular code element.
to measure whichparts of the code the participants of our study pay attentionto we show blurred source code to the participants who must temporarily unblur individual tokens of the source code to 36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee understand it.
we gather a total of human attention maps from participants including five examples for each of 250java methods sampled from ten real world projects.
based on the dataset of human attention maps we thoroughly study to what extent human attention matches theattention weights of learned models.
we envision that abetter understanding of the human machine relationships couldinspire either future explainability methods or human inspiredmodels of code.
our study addresses the following researchquestions.
rq1 are the intrinsic attention weights of neural models correlated with human attention?
answering this question quantifies how closely neural models resemble the human rea soning.
we find that neural models and humans agree on copyattention but not on regular attention which experimentallyconfirms the benefit of copy attention in models of code.
rq2 how does the distribution of attention across tokens differ between models and humans?
answering this question could highlight differences between models and humans thathelp understand their strengths and weaknesses.
we find thatnone of the studied models closely mimics how humansdistribute their attention.
similar to copy attention humanssometimes do not explore all tokens but ignore tokens notrelevant for the prediction task.
rq3 do neural models and humans attend to the same kinds of tokens e.g.
identifiers separators operators andkeywords?
if humans and models attend to different kinds of tokens then future neural models may want to take inspirationfrom the humans to better mimic their way of understandingsource code.
we find that neural models pay more attentionto basic syntactic tokens whereas humans pay more attentionto strings operators and keywords.
rq4 do learned models and humans struggle with the same kinds of examples?
answering this question could reveal complementary strengths and it may motivate work toward ad dressing the current weaknesses of neural models.
we find thatmodels and humans largely agree on what methods are hardto summarize showing the need for more effective models especially on longer methods.
we also find that models aremost effective on getter and setter methods whereas humansunderstand a wider range of methods.
rq5 how does the agreement between models and humans relate to model effectiveness?
this question is relevant to check if creating models that more closely resemble humanreasoning is likely to yield more effective models.
we findthat if a model pays attention to the same tokens as humans then the chance of making a correct prediction increases.
thisresult motivates research on human inspired neural models.
in summary this paper makes the following contributions a novel methodology for recording human attentionduring code related tasks.
an in depth study of similarities differences and corre lations between the attention paid by models and humans and its impact on model effectiveness.
a dataset of human attention maps which we makeavailable for future work.our replication package tooling and all data are permanently available at ii.
b ackground a attention based models neural network models have recently been proposed to help developers on varioustasks .
many of them use attention layers .an attention mechanism lets the network learn a weightedsum of the input units to compose a weighted context vectorfor downstream modules .
besides improving a model spredictions attention weights also give some transparency tomodels by showing which parts of the inputs are most relevantto a model.
attention is used to attend to different parts ofsource code e.g.
source code tokens paths in the abstractsyntax tree or nodes of a graph representation of sourcecode .
the attention weights of these models tellus which tokens paths or graph nodes explain a specificprediction.
the meaning of attention weights is still underactive discussion but to the best ofour knowledge no one has ever studied attention weightsby comparing them to the attention of programmers whileperforming a task on source code.
b copy attention many models of code use copy attention to learn to copy relevant tokens from the input codeverbatim to the predicted output.
this idea was introduced withthe pointer network architecture for solving combinatorialproblems characterized by an output vocabulary of arbitrarysize.
a pointer network uses attention as a pointer to selecta part of the input sequence as the output.
the output ofthe attention mechanism is a probability distribution over theinput.
copy attention has become popular to address the out of vocabulary problem in code summarization tasks such asmethod naming.
allamanis et al.
notice that about of the output tokens appear in the method body.
indeed copy attention improves the effectiveness of models especially when using a dedicated attention layer .
a central assumption for these models is that the outputtokens are either in the fixed size vocabulary which is learnedduring training or in the input sequence.
iii.
m ethodology when studying the similarities and differences between attention based neural models and humans we face two chal lenges.
creating an environment to capture the humanattention on code related tasks.
comparing the capturedhuman attention to the learned attention weights in neuralmodels.
we present our methodology for addressing these twochallenges in sections iii b and iii c respectively and westart by describing the prediction task our work focuses on.
a. code summarization task among the many tasks that neural models of code are applied to we select code summarization.
one reason for this choice are the various neural models targeting thistask which could be impacted by our 868findings.
another reason is that the task requires a model to capture and summarize relatively large pieces of code i.e.
there are several code elements to attend to.
two variants of the code summarization task exist predicting the method name and predicting a method level comment .
since both variants are popularin previous work we select the method name predictiontask as it simplifies creating a corresponding human task.nonetheless our methodology could also be used to study thecomment prediction task in future work.
thus the task for themodel is to predict the original method name given the methodbody as an input.
specifically the models we study predictthe name as a sequence of tokens e.g.
get client data for a method called getclientdata .
we ask the human participants of our study to perform a variant of this tasks inspect a method body and then select the correct methodname among a set of seven alternatives.
in addition to thecorrect solution the alternatives consist of three names similarto the correct name and three randomly selected other names.the similar names are intended to stimulate the participant sreasoning process and we select them from the nearestneighbors of the correct name in a tf idf based bag of wordsencoding of method names.
the set of alternatives in figure 1includes testinitializing doesnttakereadaction which is the real name of the method three close byalternatives testtostringdoesntexhaustiterator testcorrectprogressandreadaction testaction and three random options disablesyncscrollsupport testdeepconflictingreturntypes calculatetimestamp .
the tasks given to the models and the humans are closely related since both the model and the humans mustinspect the method body and condense it into a summary ofthe functionality of the code.
as a dataset of methods we sample methods from an existing java corpus .
the corpus contains code fromseveral application domains and is a popular benchmark forneural models .
b. capturing human attention the first major challenge is how to capture the attention of a human working on the code summarization task.
we address this challenge through a novel gamification inspired atten tion annotation interface called human reasoning recorder hrr .
the participants working with the hrr are not awarethat the ultimate goal is to capture how much attention theypay to specific code elements but instead are simply asked toselect a suitable name for a method.
the interface is dividedinto two main areas figure an answer selection area which shows the names to choose from and a code inspection area which shows the code of the method body.
the key idea to capture which parts of the code a participant attends to is a deblurring mechanism.
initially all code in themethod body is blurred and the participant must deblur tokens 1the term token in this paper means subtokens that result from tokenizing code as specified by the programming language and then further splitting identifiers based on camel case and other conventions.
fig.
.
interface of the human reasoning recorder.
to understand the code.
participants can deblur a token in two ways.
on the one hand moving the mouse over a token revealsthe token and its neighbors for the time the mouse pointer ison them.
based on our initial pilot study and the fact that theaverage number of pieces of information that a human can holdin short term memory is seven we set the neighborhoodto three tokens before and three tokens after the pointed totoken ignoring neighbors in other lines.
on the other hand participants can also click on tokens to make them permanently visible even when the mousemoves away and they can blur tokens again with anotherclick.
this mechanism allows participants to pinpoint themost important parts of the already explored code.
to forceparticipants to move the mouse away from the code whilereading the candidate method names the answer selection areais also blurred by default and becomes visible only when themouse is in this section.
the hrr tracks which tokens a participant deblurs and for how long each token is visible.
to this end the interfacecontinuously logs all mouse movements and clicks.
overall the hrr captures the following information each time aparticipant summarizes a method definition human attention record .
the human attention record is a tuple hr id uid evts s r where idis a unique identifier for a method in the dataset uid is the unique user identifier evts is a sequence of mouse token interaction events sis the selected method name and ris a rating given by the user about the difficulty of naming the method.
the sequence evts contains events for a specific token becoming visible and invisible either through hovering or clicking.
the rating ris obtained by asking the participant after each method to rate how difficult choosing the namewas on a scale from easy to hard .
each participant in our study gets assigned a set of methods that are randomly sampled from the test set of thedataset .
following a common practice in human stud ies we consider the first three questions as a warm up i.e.
every participant produces human attention records.the sampling is done such that each method is seen by m different participants where we set m following related studies .
we recruit participants among undergraduate level and graduate level university students in computer science and fig.
.
visualization of token level attention weights derived from cnn model left and humans right .
red boxes indicate which token was clicked by the participant.
via amazon mechanical turk amt .
the amt participants must have at least approval rate and approvedtasks to participate in the study and are rewarded withone us dollar upon successful completion .
to filter outparticipants who misunderstand the task or fail to successfullycomplete it for other reasons we measure the correctness ofthe selected method name on two levels exactly correct when the participant selects the original method name and pseudocorrect when the participant selects either the original name or one of the three similar names.
for each combination of a number of correct and a number of pseudo correct answers we compute the probability that aparticipant performing random guessing obtains the same or abetter result.
based on this probability we accept only partic ipants that provide results with a probability of less than to come from a random guesser.
specifically we consider themultinomial distribution as we are dealing with an extensionof the binomial experiment with three possible outcomes a for the participant selecting the exactly correct answer bfor the participant selecting a pseudo correct answer and cfor the participant selecting a wrong name.
for a random guesser these outcomes have probabilities p a p b p c .
given the number of exactly correct pseudocorrect and wrong answers of a single participant as x y andzrespectively we compute the probability for a randomly acting participant to obtain the same or a better result prndguesser c x n y w z p c x n y w z y summationdisplay i 1p c x i n y i w z z summationdisplay i 1p c x n y i w z i z summationdisplay i 1p c x i n y w z i where the vector of random variables x c n w is multinomially distributed with index n and parameters p a p b p c i.e.
x mult n .
after filtering the final dataset contains human attentionrecords which contain at least five human annotations for250 methods.
the records are gathered from those outof participants that pass our filtering.
of the acceptedparticipants are computer science students and are recruitedvia amt.
on average a human attention record contains about1 mouse token interaction events.
c. comparing attention neural models vs. humans the second major challenge is comparing the captured human attention to learned attention weights in neural models.
figure illustrates the problem with an example method where the model attention is shown on the left and the humanattention is shown on the right.
the following describes theneural models we study and how we compare them againstthe human attention records.
neural models we study two attention based neural models representative of two widely used architectures aconvolutional attention model called cnn model and a transformer based model called transformer model.
despite the recent popularity of transformers we choose to studyalso a cnn model because it is one of the first attention basedmodels for this task and because it allows us to draw moregeneral conclusions.
the cnn model also has the advantage oftaking arbitrarily sized inputs whereas the transformer modelimposes a fixed input length.
both models have a sequence to sequence architecture that reasons about the method body as a sequence of tokens andthen predicts the tokens of the method name.
870we distinguish between two kinds of attention regular attention which is implemented as convolutional attention for the cnn model and as multi head self attention for the transformer model.
the regular attentionshows which parts of the code the models pay mostattention to when reasoning about the meaning of themethod.
copy attention a mechanism to tackle the out of vocabulary problem by optionally copying some tokensfrom the method body to the output.
the copy attentionshows which parts of the method body the model con siders as candidates for verbatim copying.
for both the cnn and the transformer we train projectspecific models as they outperform a single cross projectmodel .
we leave the model architecture and all hyper parameters in their default configurations except for oneadaptation of the transformer model.
the original model isdesigned to summarize a method into a javadoc sentence.
weadapt the model to the method naming task by first pre trainingthe model on its original dataset and by then fine tuningthe project specific models on the method naming dataset .moreover since the transformer model attends only to the first150 tokens of a method all results for this model considerthose tokens only.
to measure the effectiveness of the models we compute the f1 score of the top most predicted name .
itconsists of comparing the set of predicted tokens and thetokens in the original name and then computing the har monic mean between precision correctly predicted tokens predicted tokensand recall correctly predicted tokens tokens in the original name.
the average f1 score of the cnn model and the transformer model are .
and .
respectively which is in line with the originally reportedresults.
measuring human model dis agreement we summarize the attention spent by humans and models into vectorsand then compute correlations between the two.
as a proxyof the human attention given to a token we consider the totaltime that the token was visible similarly to fixation time ineye tracking studies definition human attention .lethr id uid evts s r be a human attention record for a method body with ntokens.
the human attention vector is vectorh h h2 ... hn wherehi is the total time that the token at position ihas been visible to the participant according to evts .
for each of the two kinds of attention we summarize the model s attention as follows definition model attention .
suppose a method body withntokens and a sequence of ktokens predicted by the model as the method name.
the machine attention vector is vector m m m2 ... mn wheremi mean a1 i ... aki withaj i indicating the attention weight assigned by the model to the token at position iof the method body during the prediction of thejth output token.computing the mean handles the fact that the models produce one vector of attention weights for every predictedtoken in the method name.
for example for a predictedmethod name getclientdata for each token in the method body we average the attention weights assigned to that tokenduring the prediction of the three tokens get client and data .
given two attention vectors vectorhand vector m we compute to what extent they agree on the importance of tokens by computingspearman s rank coefficient .
to this end we convertthe attention vectors to a ranking of tokens rg handrgm and then compute spearman s rank correlation coefficient asthe pearson correlation coefficient between the rank variables spearman cov rg h rgm rgh rgmwherecov and are the standard deviation and the covariance respectively.
the coefficientranges between and where means that both attentionvectors perfectly agree means that the attention weightsyield exactly the inverse ranking and zero means that both areunrelated.
for all reported correlation coefficients we includeonly pairs of attention vectors with high confidence results p value .
.
a valid alternative measure to spearman s coefficient is the kendall tau it yields similar results asthose reported here and is omitted for space reasons.
iv .
r esults our dataset contains human attention records from which we extract the same number of token level attentionvectors as explained in definition .
it comprises methodsfrom ten different repositories where each method is annotatedby at least five of the human annotators.
on averageour participants took seconds to name a single method producing mouse token events each time.
a. rq1 correlation between model and human attention to quantify the overall degree of agreement between the attention paid by neural models of code and humans we compute the correlation between both.
figure shows thedistribution of spearman rank correlation coefficients for thetwo kinds of model attention for each of the two models westudy.
each plot shows how many of the studied java methodsfall into a specific correlation range.
a correlation of .
wouldmean that a model and the humans are completely unrelated and a correlation of .
would mean that both agree perfectlyon the relatively order of all attention weights.
the first andsecond plot show the results for regular and copy attentionof the cnn model respectively and likewise with the thirdand fourth plot for the transformer model.
for example thesecond plot shows that for the majority of methods the copyattention weights of the cnn model have a rank correlationbetween .
and .
with the humans who inspect the samemethod.
for both models the regular attention weights show a weak correlation with humans with means of .
and .
.
in contrast the copy attention weights of both modelsshow a moderate to strong human machine correlation withmeans of .
and .
.
as an example in figure both 871fig.
.
correlation between machine attention and human attention.
the copy attention of the cnn model bottom left and the human bottom right are paying most of the attention tothe last few tokens of the method body.
another interestingobservation is that the human shows interest for the string testsynchronousdestination which the model seems to overlook.
we provide a separate discussion on strings insection iv c. as a point of reference the last plot in figure shows the correlation between different humans who inspect the samemethod.
the human human agreement can be considered anupper bound of the expected model human agreement as itwould be unrealistic to expect a neural model to be closer tothe average human than another human.
the mean human human correlation is .
which shows two points.
first it confirms that different participants in our study tend toattend to similar tokens which is a prerequisite for comparingmodels against humans as a group.
second it shows thatthe mean correlations on copy attention are relatively high asthey are only .
.
points lower than the human humancorrelation.
insight neural models and humans often agree about what tokens to copy verbatim from the input to the output but less on what other tokens to attend to.
the relatively highcorrelation for copy attention gives an empirical justification tothe copy attention mechanisms used by many neural models.fig.
.
median value of normalized attention profiles across all studied methods.
b. rq2 distribution of attention across tokens the following aims at understanding how models and humans distribute their attention across the tokens in a method.
intuitively we are interested in how much the attention isfocused in a few highly relevant tokens as opposed to beingroughly uniformly distributed.
to quantify and visualize thedifferent attention distributions we compute a normalizedattention profile from each vector of attention weights definition normalized attention profile .
given a vector of attention weights vector a its normalized attention profile is vector p percentiles sort normalize vector a where normalize divides all elements by the maximum value in vector a sort sorts the vector in increasing order and percentiles projects a vector of arbitrary length into a sequence of percentiles with linear interpolation .
for example suppose a very small method with five tokens and an attention vector vector a .
normalizing and sorting the attention vector yields which is then mapped into percentiles to give the a normalized attentionprofile where e.g.
the percentile is zero and the percentile is .
.
figure shows the normalized attention profiles for the five kinds of attention vectors we study four from the neuralmodels and one from the humans.
each curve is the medianvalue across the attention vectors of all methods in our dataset.intuitively the more a curve is dented toward the lower rightcorner the more focused the attention vectors are on a smallnumber of tokens.
the results show that copy attention tends tobe clearly more focused then regular attention i.e.
the modelstake a clear decision about which tokens may be worth copying 872to the output.
in contrast the regular attention especially of the cnn model are more uniformly distributed with respectto their own copy counterparts.
both the regular and copyattention of the transformer disregards a large number oftokens.
the human profile is in between the two transformer attention mechanisms for the top most attended token top right in figure and then decreases almost constantly untilit perhaps surprisingly reaches zero.
reaching zero meansthat the humans often completely ignore some tokens i.e.
our participants could summarize a method based on only asubset of all its tokens.
during manual inspection of attentionrecords we notice that especially on longer methods humansoften focus on variables declared at the beginning and thenskim read to the end of the method paying most attention toreturn statements and assertions.
insight no attention mechanism among those studied closely mimics the way humans distributes their attention onthe tokens of the method body.
insight the transformer model seems to be overspecialized in attending only a small subset of tokens as comparedto the convolutional model.
insight sometimes the humans do not fully explore the entire method but base their answers on a subset of thetokens in the methods typically the beginning esp.
variabledeclarations and end esp.
returns and assertions .
suggestion future human inspired transformer models should be trained with an objective to attend to a largerportion of the source code rather than overspecializing to afew tokens.
c. rq3 categories of tokens source code is composed of different categories of tokens e.g.
identifiers separators keywords and strings.
for the code in our dataset the most common token categories areidentifiers and separators .
.
to quantify howmuch attention a specific token category receives we definethe following notion.
intuitively it indicates how much moreor less attention a specific token category receives comparedto uniformly distributed attention.
definition distance from uniformity .
given a vector of attention weights vector afor a sequence tof tokens the distance from uniformity of a subset softis dfu s summationtext t sat summationtext t tat s t s t whereatis the attention weight assigned to token t. adfu value of zero indicates that the token category is getting exactly the attention of uniformly distributed attention.
a positive or negative value indicates that the token category isreceiving more or less attention respectively.
the lower boundis where the token category is receiving no attention at all.
figure presents the dfu for different token categories.
the results show significant differences between the mod els and the humans.
for example the humans give morefig.
.
distance from uniformity dfu for different token categories.
fig.
.
attention maps from the transformer model and humans.
importance to keywords operators and strings whereas themodels pay less attention to these token categories.
thisdifference suggests that these tokens play an important role incomprehending code and they should not be left unattended byneural models.
one can also observe differences between thedifferent kinds of model attention.
for example the regularattention by the transformer model is surprisingly high forseparators and relatively small for identifiers.
some tokencategories especially booleans are mostly ignored both bythe models and the humans.
a manual inspection of various attention maps confirms 873our quantitative results.
for example consider the code in figure which shows the attention maps of the cnnmodel s regular attention top and of the humans who studiedthis method bottom .
the humans pay a lot more attentionto string literals which indeed contain information relevantfor the method summarization task whereas the model isoverlooking their importance in favor of other tokens.
theobservation illustrated by this example motivates work onneural models that understand string literals which currentlyare often abstracted away or split with empty spaces when other splits might be more effective e.g.
with slash .
another finding is that humans tend to overlook curly braces which is visible in figure and also confirmed bythedfu of curly braces being close to its lower limit dfu .
.
in the upper part of figure we see how the transformer model prefers syntactic tokens such asdot comma and open parenthesis.
after a thorough manualinspection we confirmed this to be a general characteristic ofthe regular attention of the transformer model which focuseson tokens that proceed and follow method calls in an attemptto isolate method calls.
this is explaining also the attentionprofile of the regular transformer in figure where the plateauon the top right is made of those tokens i.e.
dots commas and open parentheses used to isolate method calls.
insight high attention paid by the copy attention to identifiers confirms their effectiveness in focusing primarily ontokens that might be copied verbatim into the method name.
suggestion the focus of copy attention on identifiers could be stressed even more by masking the other kinds oftokens.
insight strings keywords and operators are often overlooked by the models whereas the humans give moreattention to them.
suggestion future neural models could pay more attention to strings keywords and operators which humansconsider important during the method summarization task.
insight block level separators such as curly braces are attended mostly by the models whereas the humans get thisinformation implicitly from the indentation of the formattedcode.
suggestion future models of code could encode basic syntactic information into token embeddings preventing themodel to focus its attention on purely syntactic tokens suchas curly braces.
insight regular attention of transformers specializes in the recognition of separators that proceed and followmethod invocations.
this confirms and extends an analogousspecialization of multi head attention observed also in naturallanguage processing .
we here confirm that transformersare attentive to separators also when applied to code relatedtasks.
we hypothesize that recognizing separators is importantfor the model to understand the role of individual tokens e.g.
that a specific token represents the name of a called method.an interesting future work could be to further explore the rootcauses of this phenomenon.fig.
.
distance form uniformity dfu for different groups of identifiers.
given the high attention given by models to identifiers we further analyze different groups of identifiers based on theirlength and popularity.
figure shows how copy attention forboth models prefers long and popular identifiers over shortand rare ones respectively.
insight long and frequent identifiers are good candidates to be copied verbatim into the method name by theanalyzed models.
d. rq4 perceived difficulty vs model effectiveness understanding which examples are more difficult for humans and models could reveal in which measure they are similar and if they can complement each other.
we use therating given by the participant on how easy it was to name eachmethod to create a per method average rating.
we aggregatethe ratings of five different annotators on the same method toget a more stable human ground truth.
comparing these ratingsto the f1 score of the models shows a positive correlation pearson correlation .
and .
for cnn and transformer respectively .
insight the neural models and the humans agree on which methods are more difficult to name.
to investigate further which are those difficult methods we also compare the performance of humans and modelson different method lengths and different groups of methods.figure shows how both humans and models are good onshorter methods whereas predicting the name of longer onesis more challenging.
to better understand what kinds of methods models and humans are successful on we analyze five groups of methods getter setter checker test starting respectively with get set is or has and test and other for all the remaining methods.
figure reports the models effectiveness measuredwith f1 score and the percentage of correctly and pseudo correctly named methods by humans.
it shows how gettersand setters are the easiest to predict for both humans andmodels.
an interesting finding is that humans are almost asgood on checkers as they are on getters whereas this is notthe case for the models which struggle with identifying thename of a method that is checking some property on the 874fig.
.
method length for different performance levels for human correct or wrong and model f1 score .
the error bars measure the uncertainty aroundthe estimate.
object.
for test methods and other methods we see a lower percentage of correctly named methods for both humans andmodels.
we note that humans have a high portion of pseudo correct answers for the test methods which could be due tothe presence of multiple reasonable method names for them.
insight beside getters and setters neural models often struggle to predict more challenging kinds of methods such ascheckers and test methods whereas the humans are successfulacross a wider range of methods.
suggestion models could learn from the human to name more challenging types of methods on which humans performbetter e.g.
by using human attention traces during training.
in table i we consider both characteristics presenting the length of the different groups in terms of lines of code locs .we see that test and others methods which are hard formodels are generally longer than other groups showing onceagain the impact of method length on model effectiveness.
insight longer methods are harder to summarize both for models and humans.
suggestion to obtain models that better complement human reasoning future training datasets should include a largerportion of difficult examples for a more effective training orat least provide different sub datasets of increasing difficulty.to establish the difficulty of a method we envision the useof heuristics or human labeling.
in particular to select moredifficult methods we propose the following strategies includemethods with high cyclomatic complexity reduce thepercentage of getter and setter methods reduce the percentageof methods for which the method body contains many or allsubtokens present in the method name i.e.
methods where themodel can exploit the copying mechanism and increase thepercentage of longer methods.
in addition to these automatedstrategies for increasing the difficulty humans could rate asmall pool of methods based on their notion of difficulty which could then serve as a curated benchmark.fig.
.
model effectiveness and human performance on predefined groups.
the error bars measure the uncertainty around the estimate.
table i method length of method bodies for five predefined groups .
lines of code locs group min median mean max getter .
.
setter .
.
checker .
.
test .
.
other .
.
entire dataset .
.
e. rq5 human model agreement vs. model effectiveness given the moderate to strong correlation between neural models and humans a reader may wonder whether a stronger correlation coincides with more accurate predictions by themodel.
we address this question in two ways.
one of them isin figure which shows for each method in our datasettwo pieces of information i on the horizontal axis theaccuracy of the model s prediction measured as the f1 score section iii c1 and ii on the vertical axis the human model agreement measured as in rq1.
the four plots showthe cnn model on top and the transformer model at thebottom with regular attention and copy attention on theleft and right respectively.
each plot also shows the linearregression trend between two the axes.
overall we observea moderate correlation between human model agreement andmodel effectiveness.
in particular for the regular attention ofboth models the pearson correlation coefficients are .
and0.
p values 4and2 .
as a second way of addressing the question we repeat the measurements from rq1 i.e.
how much models and humansagree about what tokens to attend to for those methods wherethe models make accurate predictions.
accurate here meansthat the f1 score of a prediction is at least .
.
table iicompares the human model correlation across all methodswith those methods where the respective model predicts the 875fig.
.
human model correlation vs. model effectiveness.
table ii human model correla tion for all vs .accura te predictions .
spearman rank correlation mean all methods methods with f1 .
cnn regular attention .
.
cnn copy attention .
.
transformer regular attention .
.
transformer copy attention .
.
name accurately.
the results show that the human model correlation is clearly higher for accurate predictions e.g.
increasing from .
to .
for the regular attention paidby the cnn model.
insight a higher human model correlation coincides with more effective predictions by the neural models.
suggestion creating models that more closely mimic the human attention seems a promising way toward more effectivemodels.
future work could use human attention datasets duringmodel training or use loss functions that nudge themodel s attention to mimic humans.
v. t hrea ts to validity internal v alidity several factors may influence our results.
first the human task of choosing the correct nameamong seven alternatives differs from the model s task ofpredicting the entire name.
because both tasks are stronglyrelated and require to understand the meaning of a method we consider the resulting attention vectors to allow for ameaningful comparison.
moreover we ensure the human taskto be challenging by providing alternatives similar to thecorrect name section iii a .
second using a crowd platformto hire participants risks getting submissions of mixed quality.we carefully filter all human attention records based onthe overall performance of a participant section iii b .
amanual inspection of the dataset confirms that realistic codeexplorations are retained by the filtering.
third computinghuman attention based on the time a token is visible canonly approximate actual attention.
in computer vision mousetracking has been established as a scalable way of capturingvisual attention and an in depth study could assessthe accuracy of it on source code related tasks in the future.fourth our hrr interface introduces some trade offs com pared to the eye tracking based studies on the one hand welose the pixel level precision of an eye tracker and are not ableto capture if a participant indeed looks at the unblurred code.on the other hand hrr enables easier remote participation supports code snippets of arbitrary length and automaticallycaptures token level attention.
a further study of strengths andweaknesses of the two approaches for software engineeringstudies will be interesting future work.
fifth the choice ofthe neighborhood size of unblurred tokens which is threetokens before and three tokens after the clicked token in ourexperiments could lead to different results.
sixth truncatingthe input to transformers to the first tokens may influenceour results since the model cannot look beyond that limit.finally method length and code style may confound ourfindings.
we partially study the influence of method lengthin figure but do not consider code style as it is difficult toquantify.
to mitigate the impact of both possible confounders we randomly sample from multiple repositories methods withdifferent lengths and code styles.
threats to external v alidity several factors may influence the generalizability of our results.
first the participants ofour study may not fully represent other humans.
we mitigatethis threat by recruiting participants through different waysand by retaining only participants that show high performance.second findings on the code summarization task might notgeneralize to other code related prediction tasks.
as the taskhas been proved to be a good benchmark for the abstractionabilities of models of code we envision our findingsto at least partially generalize to other tasks.
by makingour human reasoning recorder available we facilitate futurework to study different tasks.
third we select a cnn basedand a transformer based model with token level attention assubjects for the study.
other models e.g.
those based on astpaths may expose other attention patterns.
our datasetof human attention records is available for comparisons withother models.
vi.
r ela ted work a. capturing human attention capturing the human reasoning has always been a challenging and demanding task as witnessed by previous studieson computer vision and natural language process ing .
indirect experiments suchas ours have been also used in these fields .
insoftware engineering eye tracking has been the basis of 876code comprehension studies .
with human eye tracking records the dataset by bednarik et al.
was thelargest dataset on human attention on code available so far.two tools have been proposed to ease the collection of eyedata .
however due to the equipment and calibra tion requirements eye tracking is not easily compatible withremote participation.
neuroimaging is another interesting yetalso very involved way to measure the activity of programmersduring program comprehension tasks .
our workcontributes a deblurring based interface for capturing humanattention on code which complements existing techniquesby providing a lightweight and scalable technique that iscompatible with remote participation.
b. comparing models with developers previous work studies which parts of a method are of interest for a group of ten java developers performing a code summarization task and compares their eye tracking dataagainst a tf idf method .
they also show that eye trackingdata from programmers can improve the tf idf model.
a firstattempt to compare neural models of code against humanattention captured via eye tracking compares the gazeof single human participant against the code2vec model .our work contributes the first in depth multi participant studyto compare neural models of code with human attention.
c. studies of attention mechanisms the role of attention layers as an explanation technique is still under active study e.g.
by measuring the effectiveness of attention layers against other explanation techniques .
instead of comparing multiple explanation techniqueswith each other our work compares a model against humanattention records.
bui et al.
study attention in neural modelsof code by comparing attention weights with a metric basedon the perturbation of the input program .
their papermentions that evaluations with real programmers can bemore convincing in validating whether results matchthe actual importance viewed by human which matches themotivation for our work.
trying to understand the attentionof transformer models some work highlights how the vari ous attention heads of a transformer are redundant and thatsome attention heads specialize in attending syntactic tokens such as punctuation .
a similar observation is that muchof the attention of transformer based models is assigned topunctuation tokens .
arous et al.
show that integratinghuman rationales into an attention based model for nlp canimprove its effectiveness .
the attention records gatheredin our work could serve as a basis of similar future work onmodels of code.
d. neural models of code there are various neural models of code and we refer to a recent review article and a survey for a detailed discussion.
many models consider source code as a sequenceof tokens which also is the representationunderlying our study.
some tree based models and graph based models also adopt an attention mechanism whichwould be interesting to compare against our human attentionrecords.
vii.
c onclusion motivated by the success of neural models of code combined with the difficulties to understand what exactly themodels are learning this paper presents the first compre hensive study to compare human and model attention.
theresults show how the copy mechanism is empirically verysimilar to the human attention.
moreover we have pointedout important differences between models and humans e.g.
the different attention weights given to basic syntactic tokens such as curly braces but also a tendency of neural modelsto underestimate the value of strings.
we reveal that neuralmodels generally struggle on longer methods and on methodsbeyond getters and setters whereas the humans successfullyunderstand a wider range of methods.
our work also high lights that human model agreement positively correlates withaccurate predictions which calls for neural models that evenmore closely mimic human reasoning.
together with the study we release a novel dataset of human attention maps onthe code summarization task collected via the newly proposedhuman reasoning recorder which could serve as an enablerof further research and human studies.
ultimately we envisionthe usage of our dataset and our tool to produce ground truthhuman annotations to fuel human inspired neural models.
a cknowledgment this work was supported by the european research council erc grant agreement and by the german researchfoundation within the concsys and perf4js projects.
we alsothank the anonymous reviewers for their insightful commentsand suggestions which have contributed to improve the qualityof this work.
r eferences wasi uddin ahmad saikat chakraborty baishakhi ray and kai wei chang.
a transformer based approach for source code summarization.
arxiv .
may .
miltiadis allamanis earl t barr premkumar devanbu and charles sutton.
a survey of machine learning for big code and naturalness.acm computing surveys csur .
miltiadis allamanis earl t. barr soline ducousso and zheng gao.
typilus neural type hints.
in proceedings of the 41st acm sigplan conference on programming language design and implementation pldi pages new y ork ny usa june .
associationfor computing machinery.
miltiadis allamanis marc brockschmidt and mahmoud khademi.
learning to represent programs with graphs.
arxiv .
may .
miltiadis allamanis hao peng and charles sutton.
a convolutional attention network for extreme summarization of source code.
ininternational conference on machine learning icml may .
uri alon shaked brody omer levy and eran yahav.
code2seq generating sequences from structured representations of code.
international conference on learning representations february .
uri alon meital zilberstein omer levy and eran yahav.
code2vec learning distributed representations of code.
proceedings of the acm on programming languages popl january .
ines arous l. dolamic jie yang akansha bhardwaj giuseppe cuccu and p .
cudr e mauroux.
marta leveraging human rationales for explainable text classification.
in proceedings of the thirty f ourth aaai conference on artificial intelligence .
pepa atanasova jakob grue simonsen christina lioma and isabelle augenstein.
a diagnostic study of explainability techniques for text classification.
in proceedings of the conference on empirical methods in natural language processing emnlp pages online november .
association for computational linguistics.
joris baan maartje ter hoeve marlies van der wees anne schuth and maarten de rijke.
understanding multi head attention in abstractivesummarization.
arxiv .
november .
dzmitry bahdanau kyunghyun cho and y oshua bengio.
neural machine translation by jointly learning to align and translate.arxiv .
may .
roman bednarik teresa busjahn agostino gibaldi alireza ahadi maria bielikova martha crosby kai essig fabian fagerholm ahmadjbara raymond lister pavel orlov james paterson bonita sharif teemu sirki a jan stelovsky jozef tvarozek hana vrzakova and ian van der linde.
emip the eye movements in programming dataset.science of computer programming october .
n. d. q. bui y .
y u and l. jiang.
autofocus interpreting attentionbased neural networks by code perturbation.
in 34th ieee acm international conference on automated software engineering ase pages november .
abhishek das harsh agrawal larry zitnick devi parikh and dhruv batra.
human attention in visual question answering do humansand deep networks look at the same regions?
computer vision and image understanding october .
jay dey oung sarthak jain nazneen fatema rajani eric lehman caiming xiong richard socher and byron c. wallace.
eraser abenchmark to evaluate rationalized nlp models.
in proceedings of the 58th annual meeting of the association for computational linguistics pages online july .
association for computationallinguistics.
elizabeth dinella hanjun dai ziyang li mayur naik le song and ke wang.
hoppity learning graph transformations to detectand fix bugs in programs.
in international conference on learning representations september .
elizabeth dinella hanjun dai ziyang li mayur naik le song and ke wang.
hoppity learning graph transformations to detect andfix bugs in programs.
in 8th international conference on learning representations iclr addis ababa ethiopia april .openreview.net .
janet feigenspan christian k astner sven apel j org liebig michael schulze raimund dachselt maria papendieck thomas leich andgunter saake.
do background colors improve program comprehensionin the ifdef hell?
empirical software engineering august .
zhangyin feng daya guo duyu tang nan duan xiaocheng feng ming gong linjun shou bing qin ting liu daxin jiang andming zhou.
codebert a pre trained model for programming andnatural languages.
in findings of the association for computational linguistics emnlp pages online november .association for computational linguistics.
thomas fritz andrew begel sebastian c. m uller serap yigit elliott and manuela z uger.
using psycho physiological measures to assess task difficulty in software development.
in proceedings of the 36th international conference on software engineering icse pages402 new y ork ny usa may .
association for computingmachinery.
sebastian gehrmann y untian deng and alexander rush.
bottom up abstractive summarization.
in proceedings of the conference on empirical methods in natural language processing pages brussels belgium october .
association for computationallinguistics.
d. t. guarnera.
enhancing eye tracking of source code a specialized fixation filter for source code.
in ieee international conference on software maintenance and evolution icsme pages september .
drew t. guarnera corey a. bryant ashwin mishra jonathan i. maletic and bonita sharif.
itrace eye tracking infrastructure fordevelopment environments.
in proceedings of the acm symposiumon eye tracking research applications etra pages newy ork ny usa june .
association for computing machinery.
rahul gupta soham pal aditya kanade and shirish k. shevade.
deepfix fixing common c language errors by deep learning.
insatinder p .
singh and shaul markovitch editors proceedings of the thirty first aaai conference on artificial intelligence february san francisco california usa pages .
aaai press .
s. haiduc j. aponte l. moreno and a. marcus.
on the use of automated text summarization techniques for summarizing sourcecode.
in 17th working conference on reverse engineering pages october .
vincent j. hellendoorn christian bird earl t. barr and miltiadis allamanis.
deep learning type inference.
in gary t. leavens alessandrogarcia and corina s. pasareanu editors proceedings of the acm joint meeting on european software engineering conference and sym posium on the f oundations of software engineering esec sigsoftfse lake buena vista fl usa november pages152 .
acm .
vincent j. hellendoorn and premkumar devanbu.
are deep neural networks the best choice for modeling source code?
in proceedings of the 11th joint meeting on f oundations of software engineering esec fse pages new y ork ny usa august .association for computing machinery.
vincent j. hellendoorn charles sutton rishabh singh petros maniatis and david bieber.
global relational models of source code.
in8th international conference on learning representations iclr addis ababa ethiopia april .
openreview.net .
hamel husain ho hsiang wu tiferet gazit miltiadis allamanis and marc brockschmidt.
codesearchnet challenge evaluating the state ofsemantic code search.
arxiv .
june .
t. d. itoh t. kubo k. ikeda y .
maruno y .
ikutani h. hata k. matsumoto and k. ikeda.
towards generation of visual attentionmap for source code.
in asia pacific signal and information processing association annual summit and conference apsipa asc pages november .
srinivasan iyer ioannis konstas alvin cheung and luke zettlemoyer.
summarizing source code using a neural attention model.
in proceedings of the 54th annual meeting of the association for computationallinguistics v olume long papers pages berlin ger many august .
association for computational linguistics.
sarthak jain and byron c. wallace.
attention is not explanation.
arxiv .
may .
m. jiang s. huang j. duan and q. zhao.
salicon saliency in context.
in ieee conference on computer vision and pattern recognition cvpr pages june .
j. jiarpakdee c. tantithamthavorn h. k. dam and j. grundy.
an empirical study of model agnostic techniques for defect predictionmodels.
ieee transactions on software engineering pages .
rafael michael karampatsis hlib babii romain robbes charles sutton and andrea janes.
big code !
big v ocabulary open v ocabularymodels for source code.
in ieee acm 42nd international conference on software engineering icse pages october2020.
m. g. kendall.
a new measure of rank correlation.
biometrika .
chris lankford.
gazetracker software designed to facilitate eye movement analysis.
in proceedings of the symposium on eye tracking research applications etra pages new y ork ny usa november .
association for computing machinery.
piyawat lertvittayakumjorn and francesca toni.
human grounded evaluations of explanation methods for text classification.
in proceedings of the conference on empirical methods in naturallanguage processing and the 9th international joint conference onnatural language processing emnlp ijcnlp pages hong kong china november .
association for computationallinguistics.
shuai lu daya guo shuo ren junjie huang alexey svyatk ovskiy ambrosio blanco colin clement dawn drain daxin jiang duyutang ge li lidong zhou linjun shou long zhou michele tufano ming gong ming zhou nan duan neel sundaresan shao kundeng shengyu fu and shujie liu.
codexglue a machinelearning benchmark dataset for code understanding and generation.arxiv .
march .
rabee sohail malik jibesh patra and michael pradel.
nl2type inferring javascript function types from natural language information.
inproceedings of the 41st international conference on software engineering icse montreal qc canada may pages304 .
thomas j. mccabe.
a complexity measure.
ieee transactions on software engineering december .
george a. miller.
the magical number seven plus or minus two some limits on our capacity for processing information.
psychological review .
kyosuke nishida itsumi saito kosuke nishida kazutoshi shinoda atsushi otsuka hisako asano and junji tomita.
multi style generativereading comprehension.
in proceedings of the 57th annual meeting of the association for computational linguistics pages florence italy july .
association for computational linguistics.
jibesh patra and michael pradel.
semantic bug seeding a learningbased approach for creating realistic bugs.
in diomidis spinellis georgios gousios marsha chechik and massimiliano di penta edi tors esec fse 29th acm joint european software engineering conference and symposium on the f oundations of software engineering athens greece august pages .
acm .
norman peitek janet siegmund sven apel christian k astner chris parnin anja bethmann thomas leich gunter saake and andr e brechmann.
a look into programmers heads.
ieee transactions on software engineering .
michael pradel and satish chandra.
neural software analysis.
communications of the acm .
to appear.
michael pradel georgios gousios jason liu and satish chandra.
typewriter neural type prediction with search based validation.
inproceedings of the 28th acm joint meeting on european softwareengineering conference and symposium on the f oundations of softwareengineering esec fse pages new y ork ny usa november .
association for computing machinery.
michael pradel and koushik sen. deepbugs a learning approach to name based bug detection.
proceedings of the acm on programming languages oopsla october .
grusha prasad yixin nie mohit bansal robin jia douwe kiela and adina williams.
to what extent do human explanations of modelbehavior align with actual model behavior?
arxiv .
december .
arijit ray yi yao rakesh kumar ajay divakaran and giedrius burachas.
can y ou explain that?
lucid explanations help human aicollaborative image retrieval.
proceedings of the aaai conference on human computation and crowdsourcing october .
laura rieger chandan singh william murdoch and bin y u. interpretations are useful penalizing explanations to align neural networks withprior knowledge.
in international conference on machine learning pages .
pmlr november .
p .
rodeghero c. liu p .
w. mcburney and c. mcmillan.
an eye tracking study of java programmers and application to sourcecode summarization.
ieee transactions on software engineering november .
anna rogers olga kovaleva and anna rumshisky.
a primer in bertology what we know about how bert works.
transactions of the association for computational linguistics .
andrew slavin ross michael c. hughes and finale doshi v elez.
right for the right reasons training differentiable models by constrainingtheir explanations.
in proceedings of the twenty sixth international joint conference on artificial intelligence pages mel bourne australia august .
international joint conferences onartificial intelligence organization.
zohreh sharafi bonita sharif yann ga el gu eh eneuc andrew begel roman bednarik and martha crosby.
a practical guide on conductingeye tracking studies in software engineering.
empirical software engineering september .
janet siegmund norman peitek andr e brechmann chris parnin and sven apel.
studying programming in the neuroage just a crazy idea?communications of the acm .
ekta sood simon tannert diego frassinelli andreas bulling and ngoc thang vu.
interpreting attention models with human visualattention in machine reading comprehension.
in acl signll conference on computational natural language learning conll october2020.
c. spearman.
the proof and measurement of association between two things.
the american journal of psychology .
michele tufano jevgenija pantiuchina cody watson gabriele bavota and denys poshyvanyk.
on learning meaningful code changes via neuralmachine translation.
in proceedings of the 41st international conference on software engineering icse pages montreal quebec canada may .
ieee press.
ashish v aswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n. gomez ukasz kaiser and illia polosukhin.
attentionis all you need.
advances in neural information processing systems .
oriol vinyals meire fortunato and navdeep jaitly.
pointer networks.
advances in neural information processing systems .
yaza wainakh moiz rauf and michael pradel.
idbench evaluating semantic representations of identifier names in source code.
in 43rd ieee acm international conference on software engineering icse2021 madrid spain may pages .
ieee .
yao wan zhou zhao min yang guandong xu haochao ying jian wu and philip s. y u. improving automatic source code summarization viadeep reinforcement learning.
in proceedings of the 33rd acm ieee international conference on automated software engineering ase pages new y ork ny usa september .
association forcomputing machinery.
y u wang ke wang fengjuan gao and linzhang wang.
learning semantic program embeddings with graph interval neural network.
proceedings of the acm on programming languages oopsla november .
jiayi wei maruth goyal greg durrett and isil dillig.
lambdanet probabilistic type inference using graph neural networks.
in international conference on learning representations september .
sarah wiegreffe and y uval pinter.
attention is not not explanation.
arxiv .
september .
jian zhang xu wang hongyu zhang hailong sun yanjun pu and xudong liu.
learning to handle exceptions.
in ieee acm international conference on automated software engineering ase .