automated construction of energy test oracles for android reyhaneh jabbarvand university of illinois urbana champaign usa reyhaneh illinois.eduforough mehralian university of california irvine irvine usa fmehrali uci.edusam malek university of california irvine irvine usa malek uci.edu abstract energy efficiency is an increasingly important quality attribute for software particularly for mobile apps.
just like any other software attribute energy behavior of mobile apps should be properly tested prior to their release.
however mobile apps are riddled with energy defects as currently there is a lack of proper energy testing tools.
indeed energy testing is a fledgling area of research and recent advances have mainly focused on test input generation.
this paper presents aceton the first approach aimed at solving the oracle problem for testing the energy behavior of mobile apps.
aceton employs deep learning to automatically construct an oracle that not only determines whether a test execution reveals an energy defect but also the type of energy defect.
by carefully selecting features that can be monitored on any app and mobile device we are assured the oracle constructed using aceton is highly reusable.
our experiments show that the oracle produced by aceton is both highly accurate achieving an overall precision and recall of and efficient detecting the existence of energy defects in only 37milliseconds on average.
ccs concepts software and its engineering software testing and debugging.
keywords software testing test oracle deep learning green software engineering android acm reference format reyhaneh jabbarvand forough mehralian and sam malek.
.
automated construction of energy test oracles for android.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
https introduction improper usage of energy greedy hardware components on a mobile device such as gps wifi radio bluetooth and display can drastically discharge its battery.
recent studies have shown energy to be a major concern for both users and developers .
in spite of that many mobile apps abound with energy defects.
this esec fse november virtual event usa copyright held by the owner author s .
acm isbn .
mainly due to the lack of tools and techniques for effectively testing the energy behavior of apps prior to their release.
in fact advancements on mobile app testing have in large part focused on functional correctness rather than non functional properties such as energy efficiency .
to alleviate this shortcoming recent studies have tried to generate effective energy tests .
while the proposed techniques have shown to be effective for generating energy aware test inputs they either use manually constructed oracles or rely on observation of power traces i.e.
series of energy consumption measurements throughout the test execution to determine the outcome of energy testing .
test oracle automation is one of the most challenging facets of test automation and in fact has received significantly less attention in the literature .
a test oracle compares the output of a program under test for a given test to the output that it determines to be correct.
while power trace is an important output from an energy perspective relying on that for creating energy test oracles faces several non trivial complications.
first collecting power traces is unwieldy as it requires additional hardware e.g.
monsoon or specialized software e.g.
trepn to measure the power consumption of a device during test execution.
second noise and fluctuation in power measurement may cause many tests to become flaky.
third power trace based oracles are device dependent making them useless for tests intended for execution on different devices.
finally power traces are sensitive to small changes in the code thus are impractical for regression testing.
the key insight in our work is that whether a test fails detects an energy defect or passes can be determined by comparing the state of app lifecycle and hardware elements before during and after the execution of a test.
if such a state changes in specific ways we can determine that the test is failing i.e.
reveals an energy issue irrespective of the power trace or hardware specific differences.
the challenge here lies in the fact that determining such patterns is exceptionally cumbersome and requires deep knowledge of energy faults and their impact on the app lifecycle and hardware elements.
furthermore energy defects change and new types of defects emerge as mobile platforms evolve making it impractical to manually derive such patterns.
to overcome this challenge we present aceton an approach forautomated construction of energy testoracles for a ndroid.
aceton employs deep learning to determine the mis behaviors corresponding to the different types of energy defects.
it represents the state of app lifecycle and hardware elements in the form of a feature vector called state vector sv .
each instance of our training dataset is a sequence of svs sampled before during and after the execution of a test.
aceton leverages attention mechanism to ensure generation of explainable dl models.
this paper makes the following contributions 927this work is licensed under a creative commons attribution international .
license.
esec fse november virtual event usa reyhaneh jabbarvand forough mehralian and sam malek a deep learning technique for automated construction of an energy test oracle in android apps that relies on a novel representation of app lifecycle and hardware elements as a feature vector.
aceton is app and device independent.
a novel utilization of attention mechanism from the deep learning literature to go beyond the usage of deep learning as a black box technique and understand how aceton determines the correctness of test execution outcome.
an extensive empirical evaluation on real world android apps demonstrating that aceton is highly accurate achieves an overall precision and recall of efficient detects the existence of energy defects in only 37milliseconds on average and reusable across a variety of apps and devices.
an implementation of aceton which is publicly available .
the remainder of this paper is organized as follows.
section provides a background on energy defects and illustrates a motivating example.
section provides an overview of aceton while sections describe details of the proposed approach.
section presents the evaluation results.
the paper concludes with a discussion of the related research.
motivating example an energy defect occurs when the execution of code leads to unnecessary energy consumption.
the root cause of such issues is typically misuse of hardware elements on the mobile device by apps or android framework under peculiar conditions.
to determine whether test execution reveals an energy defect developers can monitor the state of hardware elements and environmental factors e.g.
speed of user or strength of network signal before during and after the test execution.
if those states change in a specific way or do not change as expected between consecutive observations it can be an indicator of energy defect.
for example when developing location aware apps developers should use a location update strategy that achieves the proper trade off between accuracy and energy consumption .
user location can be obtained by registering a locationlistener .
while the accuracy of the location updates obtained from a gps location listener is higher than that of a network location listener gps consumes more power than network to collect location information.
to achieve the best strategy developers should adjust the accuracy and frequency of listening to location updates based on the user movement.
example of violating the best practice is when the app uses gps to listen to location updates while the user is stationary.
this energy defect can be detected if the following pattern in the state of user and gps hardware is observed during test execution gpsi gpsi on location listeneri location listeneri gps user movement i user movement i stationary here gps location listener anduser movement are the factors corresponding to manifestation of energy defect and the indices indicate to which state stateiorstatei they belong.
as shown in the above example existence of a defect can be determined by monitoring for certain patterns in the state of hardware and environmental settings during test execution.
identifying such patterns manually requires significant expertise and can be attention analysis dl engine test case training dataset labeled database p p f p f dl algorithm oracle label sv sequence attention weights attended features sequence collector training testing aceton figure overview of the aceton framework extremely complicated and time consuming.
for example a pattern corresponding to violation of location best practice by listening to location updates at a high frequency when the user moves slowly i.e.
walking should include additional invariants related to network andlistener frequency .
thereby our objective in this paper is to construct an oracle that automatically learns such patterns to determine the correctness of test execution.
such oracle can be reusable across different apps and mobile devices as long as the changes in the state of software and hardware can be monitored.
automatic construction of test oracles this way is specifically important for android as the platform rapidly evolves i.e.
substantial amounts of apis become deprecated and new apis and features are introduced in newer versions.
approach overview prior research has shown that energy defects manifest themselves under specific contextual settings .
specifically some energy defects e.g.
wakelocks and resource leaks happen under specific sequences of lifecycle callbacks while others manifest themselves under peculiar hardware states e.g.
poor network signal no network connection or low battery.
this observation forms the basis of our work.
we hypothesize an automated energy test oracle can be constructed by monitoring and comparing the state of app lifecycle and hardware elements before during and after the execution of a test.
if such a state changes in specific ways the oracle determines that the test is failing i.e.
reveals an energy issue.
determining such patterns requires a deep knowledge of both energy defects and their corresponding impact on the app lifecycle and hardware elements.
to overcome this challenge aceton leverages deep learning dl techniques to automatically learn the mis behaviors corresponding to the different types of energy defects.
specifically aceton monitors the state of app lifecycle and hardware elements during the execution of a test.
each sampled state is represented as a bit vector called state vector sv .
the result of executing a test is thus a sequence of svs which serves as the feature vector for the dl algorithm.
each instance of training and test dataset is a sequence of svs sampled during the execution of a test.aceton feeds the svs and their corresponding labels indicating the presence of an energy defect or not to a long short term memory lstm network which is a variant of recurrent neural networks rnns to train a classifier.
this classifier is subsequently used as our test oracle to determine the label of new tests.
the dl engine of aceton uses attention mechanism a method for making the rnns work better by letting the network know 928automated construction of energy test oracles for android esec fse november virtual event usa lifecycle battery bluetooth cpu display location network sensor activity running activity paused activity stopped activity destroyed service idleservice running service stopped broadcast registered broadcast called broadcast destroyed charging ac powered usb powered wireless powered battery fullbattery okbattery lowbattery very low overheat temperature increasing low power mode enabled connected connecting scanning discovering discoverable bonded paired a2dp service connected lifecycle battery bluetooth awake dozing enabled process exists utilized partial wakelock wakelock cpu display location network sensor onbrightness dark brightness dimbrightness medium brightness light brightness bright auto brightness long tieout gps registered network registered high frequency last known location gps enabled user stilluser walking user running user biking user driving airplane mode scanning wifi available wifi connected radio available radio connected signal poor signal good signal great high perf locked full locked scanning locked infinite waitbackground network active sensor wake up fast delivery fast delivery accelerometer fast delivery gravity fast delivery ...fast delivery temperature figure state vector representation where to look as it predicts a label to generate an explainable model.
specifically aceton is able to identify a subset of svs that the oracle attends to for determining the final passing or failing outcome.
by analyzing in what features the attended svs are different from their predecessor svs we can verify whether the dl model has attended to the relevant features corresponding to the energy defects in order to determine the correctness of a test.
figure provides an overview of our proposed approach consisting of three major components sequence collector dl engine and attention analysis .
to construct the oracle aceton takes a labeled database of apps with energy defects accompanied with test suites as input.
the sequence collector component executes each test case and captures svs at a fixed rate during test execution to build the training dataset for aceton .
the training dataset is then fed to the dl engine which constructs the classifier that serves as our test oracle.
to use the oracle aceton takes a test case as input and collects a sequence of svs during its execution.
the oracle takes the sequence as input and produces a fine grained label for it indicating whether the test has failed and if so the type of energy defect that was revealed by the test.
to help us understand the nature of patterns learned by the model the oracle also produces an attention weights vector.
attention analysis component then takes the attention weights vector to determine the list of features that involved in the oracle s decision.
these features essentially constitute the defect signature learned by the oracle.
in the following sections we describe the details of aceton s components.
sequence collector the sequence collector component takes a test case tias input executes it and captures the state of app lifecycle and hardware components at a fixed rate to generate a sequence of svs seqi sv0 sv1 ... svm .
inaceton seqiserves as the feature vector for the dl algorithm.
in this section we first explain details of sv and then describe the process of sequence collection.
.
state vector sv proper feature selection i.e.
feature engineering is fundamental to the application of dl techniques as the quality and quantity of features greatly impact the utility of a model.
we chose ourfeatures to reflect the changes in the state of app lifecycle and hardware elements during the execution of a test as these factors have shown to play an important role in manifestation of energy defects .
to capture the state during the execution of a test aceton relies on a model called state vector sv .
at the highest level sv consists of entries representing the lifecycle state of app under test and the state of major energy greedy hardware elements namely battery bluetooth cpu display location network e.g.
wifi or radio and sensors e.g.
accelerometer gravity gyroscope temperature etc.
sv c0 c1 ... c wherecrepresents the element category.
at a finer granularity each category is broken down to sub entries that capture the corresponding state in terms of multiple features cj f0 f1 ... fnj wherefis a binary value representing the state of feature.
figure demonstrates the representation of sv at the highest level in the first row and at a finer granularity for all the entries.
as shown in figure location element consists of ten sub entries namely gps registered indicates whether a gps listener is registered by an app network registered indicates whether a network listener is registered by an app high frequency indicates if the registered location listener listens to location updates frequently last known location indicates whether the last known location is available for an app gps enabled indicates whether the gps hardware is on or off and entries indicating the type of user movement as the test executes.
to determine sub entries i.e.
features we needed two sets of information a set of lifecycle states for android components i.e.
activity lifecycle and broadcastreceiver and states of key hardware elements that can be changed at the software level.
we referred to android documentation to determine the former.
for the latter we followed a systematic approach similar to that presented in the prior work to obtain all the android apis and constant values in the libraries that allow developers to monitor or utilize hardware components.
specifically we performed a keyword based search on the android api documentation to collect hardware relevant apis and fields identified all the hardware states that can be changed or monitored at the software level and constructed state vector as demonstrated in figure .
by identifying 929esec fse november virtual event usa reyhaneh jabbarvand forough mehralian and sam malek the hardware features using the mentioned approach i.e.
determining the hardware states that can be manipulated or monitored using application software or android framework we are assured the oracles constructed following our approach are device independent.
additionally the constructed oracle is app independent as it monitors the features that are related to app s lifecycle state which are managed by android framework in contrast to features that are related to the code of apps e.g.
usage of specific apis.
thereby once trained on a set of apps the oracle can be reused for testing of other apps.
an sv consists of a total of 84binary features.
we leveraged one hot encoding to transform all the categorical data into binary values.
for example while user movement can be a single feature with categorical text values of still walking running biking and driving1 we model it as five binary features.
this is mainly because binary features are easier to learn by dl techniques thereby leading to a higher level of accuracy in a shorter amount of time.
.
collecting sequences the sequence collector component executes a given test ti and collects the values for different sub entries of sv at a fixed sampling rate to generate seqi.aceton sdl engine requires the size of all the seqis be the same.
since tests may take different amounts of time to execute sequence collector adjusts the frequency of sampling based on the length of tests.
current implementation of aceton requires 128sv samples details in section .
sequence collector leverages dumpsys andsystrace capabilities of the android debug bridge adb along with instrumentation of apps to collect the necessary information at different time stamps.
dumpsys is a command line tool that provides information about system services such as batterystats connectivity wifi power etc.
for example adb shell dumpsys wifi command collects and dumps the statistics related to the wifi hardware element.
to determine if there is a wifi network available we look at the value of wifi is line in the dumpsys report.
similarly to see if the phone is connected to a wifi network we look at the value of curstate .
if curstate notconnectedstate the phone is not connected to a wifi network.
if curstate connectedstate the phone has connection to a wifi network in which case we collect additional information about the connection e.g.
the strength of the signal.
while dumpsys provides detailed information about all the running services on a phone its reporting time for cpu is very long.
that is it batches all the cpu usage information and updates the cpu report every several minutes.
thereby we used systrace to collect the information about cpu usage of an app during test execution.
finally we could not find information in either dumpsys orsystrace report for a subset of features.
to that end aceton automatically instruments the app under test to collect such information.
for example location category contains features related to the type of user movement.
to identify how and when user movement changes aceton instruments the app to register an activity recognition listener and listens to the changes in user movement.
that is when the device recognizes a change in the user movement by collecting the data from various sensors android will notify the 1these categories are specified in the android documentation.
rnn a b xihi x0ht rnnh0 x0rnnht xt ... ... xilstm lstm x0xt... ...hih0 ht lstm x0htfigure architecture of an rnn and lstm networks listener about the type of detected activity e.g.
walking running.
as another example all the lifecycle callbacks will be instrumented to print a message android log i.e.
logcat as they are invoked.
by processing the log files collected for an sv during test execution we determine the values for lifecycle features.
learning engine in this section we describe the dl based construction of our energy test oracle.
.
model selection to determine what machine learning model is suitable for solving the energy oracle problem we considered the following criteria the construction of energy oracle is a form of classification problem i.e.
we train our model based on a set of labeled passing or failing tests.
hence the model should be suitable for such supervised learning problem we have a relatively high dimensional data i.e.
each single input to the model is a sequence of svs sampled during execution of a test.
for a sequence size of 128and sv size of 84with binary features each instance of our feature vector can take values.
thereby the model should be able to deal with both sequential andhigh dimensional data energy defects can occur anywhere during the execution of a test.
as a result the index of svs where an energy defect occurs can be different among tests.
thereby our proposed oracle should be able to detect emergence of the anomalous energy behavior in svkfrom the svs that appear before it svl l k .
that is our model should be able to holistically consider the observed svs in order to accurately detect energy defects.
given these criteria the learning component of aceton uses long short term memory lstm which is a type of recurrent neural network rnn .
specifically aceton uses an lstm neural network augmented by attention mechanism to construct oracles for energy defects in android.
in the remainder of this section we describe the intuition behind why lstm is the best dl model for construction of an energy test oracle.
.
long short term memory lstm neural networks nns have been widely used to recognize underlying relationships in a set of data through a statistical process.
930automated construction of energy test oracles for android esec fse november virtual event usa such systems learn to perform a task or predict an output by considering examples supervised learning rather than pre defined rules.
for example nn algorithms have been shown to effectively identify presence of a certain object in a given image only by analyzing previously seen images that contain that object and without knowing its particular properties.
neural networks are basically a collection of nodes i.e.
artificial neurons which are typically aggregated into layers.
the network forms by connecting the output of certain neurons in one layer to the input of other neurons in the predecessor layer forming a directed weighted graph.
neurons and their corresponding edges typically have a weight that adjusts as the learning proceeds.
classic nns transmit information between neurons in a single direction thereby are not effective in dealing with sequential data.
recurrent neural networks rnns are specific type of nns that have shown to be effective in solving large and complex problems with sequential data e.g.
speech recognition translation and timeseries forecasting.
they are networks with loops in them which allows them to read the input data one sequence after the other.
that is if the input data consists of a sequence of length k rnn reads the data in a loop with kiterations.
figure a shows the architecture of an rnn on the left which is unfolded over time on the right.
while the chain like nature of rnns enables them to reason about previous sequences basic rnns are unable to learn long term dependencies due to the vanishing gradient problem .
learning long term dependencies is essential in the energy oracle problem defect patterns should persist for some time in order to be considered a defect.
for example registering a gps listener that listens to location updates as frequently as possible by setting the time and distance parameters of requestlocationupdates to is an example of an energy defect .
the pattern of this defect may involve gps registered andhigh frequency sub entries in the sv figure i.e.
turn their corresponding value to as an app registers the listener.
however simply observing that pattern in a sampled sv does not necessarily entail an energy defect.
that is if developer registers a high frequency location listener in a short lived broadcast receiver or service or set a short timeout to unregister it the pattern does not impact the battery life hence should not be considered a defect.
in other words the pattern should persist among several consecutive svs during the execution of a test or persist after the test terminates to be an energy defect.
lstm networks are special kind of rnns that are capable of learning long term dependencies thereby can remember the patterns that will persist.
similar to classic rnns lstms have the form of a chain of repeating modules of neural network as shown in figure b. however the repeating module in lstm right hand side of figure b has a different structure compared to that of rnn right hand side of figure a .
while rnns have a single nn layer demonstrated by black rectangle lstms have four of them which are interacting in a special way to create an internal memory state.
the combination of layers enable lstm to decide what information to throw away and what to keep i.e.
empowering lstm to remember what it has learned till present.
the lstm layer consists of several lstm modules that take a sequence of svs as input and generate an output vector hm.
a regular classification algorithm projects this output to the classificationspace with dimensions equal to the number of classes and then applies a probabilistic function a.k.a.
softmax to normalize the values between and generate a label.
however to produce more accurate labels aceton takes hmas an input to an additional layer i.e.
attention layer as discussed next.
.
dataset curation a dl approach requires the availability of large amounts of high quality training data i.e.
a large dataset with diverse types of energy defects in mobile apps accompanied by test suites that reveal their existence.
we present a novel usage of mutation testing to curate such dataset.
specifically we used droid an energy aware mutation testing framework designed for android .
the rationale behind this choice includes droid can provide us with a large diverse and high quality dataset.
the mutation operators of droid are designed based on the most comprehensive energy defect model for android to date which is constructed from real energy defects obtained from several dozens of android apps.
these defects have been shown to strongly associate with previously unknown real energy defects in apps that were different from those where the defect model was derived from.
droid also comes with a set of high quality developer written passing and failing tests which are essential for generating a labeled dataset for our classification problem.
each pair of mutant test from droid contributes one data point for our dataset.
droid categorizes mutants based on the hardware components that they misuse providing us with fine grained labels for failing tests namely pass failbluetooth failcpu faildisplay faillocation failnetwork andfailsensor to perform additional analysis and verify the validity of the dl model see section .
.
attention mechanism while lstms have memory their performance drastically degrades as the length of sequences gets longer known as the long sequence problem in the literature .
attention mechanism is a method for making lstms overcome this challenge by reminding the network where it has previously looked as it performs its task .
thereby no matter how long the sequences lstm knows where it has focused and decides what to do next based on that information.
in addition to solving the long sequence problem attention mechanism is extensively used in the deep learning community to resolve the explainability of neural networks.
the responsibility of attention layer is to generate an attention weight vector aw w0 w1 ... xm and adjust the weights as svs are sequentially being fed to the lstms.
once the oracle receives all the svs aw contains weight values corresponding to each sv.
aceton uses soft attention wherewivalues in aware between and and m i 0wi .
thereby it provides a convenient probabilistic interpretation of which svs in the test case the oracle has relied on to determine the outcome of a given test.
for example ifaceton decides a test fails due to a location related energy defect i.e.
predicts faillocation label for it we expect that the highest weights in awbelong to svs in which location sub entries were actively changed as the test executed.
if so the model proves to focus on relevant sequences to predict the outcome.
otherwise it has learned an incorrect pattern and might be invalid.
931esec fse november virtual event usa reyhaneh jabbarvand forough mehralian and sam malek sv index sv index sv index sv index a b c d attention weight figure visualization of attention weight vector for energy defects related to a cpu b display c location and d network attention analysis interpretability of dl models is essential as they are highly vulnerable to the data leakage problem .
data leakage causes a model to create unrealistically good predictions based on learning from irrelevant features.
a famous example of data leakage is a cancer predictive model that makes its decision based on the lab s label on the x ray rather than focusing on the content of x ray itself.
while this model may make good predictions it is invalid.
to ensure validity of a model it is hence crucial to determine the features that impact its decision and verify they are relevant.
utilization of attention by itself improves the performance and accuracy of the energy oracle.
aceton takes advantage of attentionlayer s product i.e.
attention weight vector to identify a set of features that aceton s model has focused on to predict a label.
this set can be used for two purposes verify validity of the learned model and enhance energy fault localization.
algorithm presents aceton s approach for attention analysis.
for a given failing test ti it takes the sequence of svs seqi sv0 sv1 ... svm attention weight vector awi and predicted label li as input and produces a list of features that were involved in the decision i.e.
attended features as output.
the algorithm starts by identifying a subset of svs in seqithat the oracle has attended to decide the label seq i svn svk n k m line and determines the features that are common between svs in seq ito construct commonsi line .
next the algorithm takes the predecessor to the first element in seq i predi svn line and compares the values of features in commonsiwith that of in predi s features to identify attended features featuresi lines .
finally algorithm extracts the sv category corresponding to the attended features ci line .
iflimatches the attended category ci algorithm verifies that the model attended to the features relevant to the type of defect and returns featuresi lines .
otherwise it returns an empty set as the model has attended to the incorrect svs and might be invalid lines .
to explain the intuition behind algorithm consider figure which visualizes aw for four samples of our dataset related to energy defects that engage cpu display location and network.
figure a is for an energy defect related to the cpu which utilizes cpu when the app is paused i.e.
goes in the background.
in this example the spike in the attention weights that remains for some time corresponds to when the test puts an app in the background.
figure b is for an energy defect related to the display that increases the display brightness to the max during app execution.
the spike in this figure is where the app increases the screen brightness by setting the screen flag.
as the app terminates algorithm attention analysis algorithm input sv sequence of a failing test seqi predicted label li attention weight vector awi output attended features features i 1features i seq i getattendedsvs seqi aw i 3commons i getcommonattendedfeatures seq i 4pred i getpredecessor seq i 5foreach fx vx commons ido 6v x getfeaturevalue fx pred i ifv x vxthen 8features i features i fx 9ci getattendedcategory features i 10ifcimatcheslithen returnfeatures i 12else return android clears the flag and the brightness goes back to normal thereby the attention of the model also fades.
figure c is for an energy defect related to the location where the developer registers a listener for receiving location updates with high frequency and forgets to unregister the listener when the app terminates.
in this case attention of the model goes up at the sv index in which the app registers the listener and does not drop even when the test terminates.
finally figure d is for a network energy defect where the app fails to check for connectivity before performing a network task.
when there is no network connection available the app still performs a signal search which consumes an unnecessary battery consumption.
in figure d the attention of model lasts shorter compared to other examples as searching for the signal is effective for a short period of time compared to the length of test.
thereby it appears in few sampled svs.
as shown in figure depending on where the energy defects in these energy greedy apps occur how much they last and whether their impact remains when a test terminates or not attention of the model to the sampled svs varies.
however there is one pattern common among them.
there is always a sharp jump in the attention weights which indicates where the model starts to notice the pattern.
the spike of attention either remains until end or sharply drops after some time.
to that end algorithm sets svnas the start of the biggest jump in the weights in awi andsvkas the end of biggest drop following the sharpest jump.
if there is no sharp drop until the end of awi algorithm sets svkto the last sv in seqi i.e.
svm.
the svs between svnandsvkconstructseq i.
932automated construction of energy test oracles for android esec fse november virtual event usa the next step after identifying the attended svs is to determine the attended features.
to that end algorithm first collects the features that are common i.e.
have the same value among all svs in seq ito construct commonsi.
formally speaking commonsib fx vx svj seq i fx.vx fx.vx .
that is commonsiis a set of pairs fx vx where the value vxof each feature fxamong all the svs in seq iis always or always .
while these features are common among the attended svs not all of them are relevant to the final decision of the oracle.
for example commonsiis very likely to contain display on feature in most cases as test execution happens when the display is on.
however this feature should not appear in the attended features if a test that fails due to a network misuse.
to exclude the irrelevant features algorithm refers to svn which is the predecessor to the first sv in seq i. the intuition here is thatsvn seq iis where the model starts to attend indicating a change in the state of lifecycle and hardware elements that cause the energy defect.
hence svn 1indicates a safe state with no energy defect.
for each fxincommonsi algorithm finds the value of its corresponding feature in svn .
if that value is different from vx algorithm adds it to the attended features featuresi.
once the list of attended features is extracted algorithm identifies the category corresponding to those features by referring to the high level structure of sv recall figure .
for example if featuresicontains enabled connected connecting and bonded paired features category ciis set to bluetooth .
if the predicted category for the given test li matchesci we determine that the model has attended to the right features to decide the label.
attended features can be viewed as the footprint of energy defects on the app s lifecycle and hardware states i.e.
defect signature .
thereby in addition to verifying the validity of the oracle they can be used by developers to enhance the fault localization process.
in fact knowing the fine grained properties of the app lifecycle and hardware elements that are involved in the manifestation of an energy defect can focus the developers effort on parts of the code that utilizes android apis related to them making the identification of the root cause easier.
for example if the defect signature contains gps registered andhigh frequency features from the location category developers are provided with strong hints that parts of the program that register location listeners for gps and adjust the frequency of receiving location updates are culpable for the energy defect.
evaluation we investigate the following five research questions in the evaluation of aceton rq1.
effectiveness how effective is the generated test oracle for detection of energy defects in android apps?
rq2.
usage of attention mechanism to what extent usage of attention mechanism improves the performance of the model?
what features impact the oracle s decision?
rq3.
detection of unseen energy defects to what extent can aceton detect unseen energy defect types i.e.
those that are not in the training dataset?
rq4.
reusability of the oracle can the generated oracle be used to detect energy issues on different apps and mobile devices?
average recall average samples per test figure sensitivity of the oracle s accuracy to sampling rate rq5.
performance how long does it take for aceton to train and test a model?
.
experimental setup dataset droid dataset contains 413mutants from various categories of energy defects and comes with 329high quality tests generated by android developers making it suitable to generate our dataset.
each pair of mutant test from droid serves as a data point in our labeled database figure .
droid provides only passed orkilled labels for its tests.
we transformed the killed label into a more fine grained label in our approach ref.
section .
based on the high level categories related to the hardware components that the mutants misuse.
that is if the killed mutant belongs to bluetooth category in droid we change its label to failbluetooth .
in addition we removed the mutants that were reported as equivalent by droid as well as mutants which could not be killed by test suites leaving us with 295mutants containing 22types of energy defect.
the first six columns of table show details about the properties of the labeled database .
overall the labeled dataset contains 347instances of mutant test where 266of them are passing and 081are failing.2we executed each instance using sequence collector component and collected corresponding svs for each instance to generate our final dataset.
table shows the details of droid s dataset.
dl engine configuration we implemented our learning model using pytorch an open source ml library for python.
there are multiple parameters in the implementation that impact the performance of a dl model.
one of them is the loss function which determines how well the algorithm approaches to learn a model.
while cross entropy is the most commonly used loss function for classification problems it was not the best option in this problem due to the imbalanced nature of our dataset i.e.
the number of passing instances in our database is higher than failing ones.
thereby we used weighted cross entropy loss function to enforce model focus on minority classes.
to enhance the performance we utilize adam optimizer to update the network weights and minimize this loss function iteratively.
overfitting can also have a negative impact on the performance of a model.
to overcome overfitting and ensure the generalization of the model on new data we useearly stopping technique .
that is we track the performance of the trained model on the validation dataset at each epoch and 2the actual size of labeled dataset in the context of dl is as each mutant test consists of 120svs where the model should consider each of them to generate a correct label.
for the sake of simplicity we only report the size of mutant test pairs.
933esec fse november virtual event usa reyhaneh jabbarvand forough mehralian and sam malek table properties of labeled database learned defect signatures and aceton s performance on unseen defects.
hardware categorysubcategory iddefect description mutants instances defect signatureunseen recall failing passing bluetoothb1 unnecessary active bluetooth connections 110be bc ap ad ss .
b2 frequently scan for discoverable devicebs bti .
b3 keep discovering for devices when not interactingbe bs ap .
cpuc1 high cpu utilization 2022cpua pe cpuu charging bti bo ap ad sr .
c2 high cpu utilization when battery is lowcpua pe cpuu charging bvl bti bo ap ad sr .
c3 high cpu utilization when not interactingcpua pe cpuu charging bti bo ap ad sr .
c4 active cpu wakelock while not interacting ad cpuw .
displayd1 failing to restore long screen timeout90 2458dlt ap ad d2 maximum screen brightness set by app dsbb ar locationl1 high frequency location update gl nl hflu go lkla us uw .
l2 unnecessary accurate location listenergl nl lkla go us uw ud .
l3 active gps when not interacting gl nl lkla go ap ad ud .
l4 neglecting last known locationgl lkla hflu go ud networkn1 fail to check for connectivity 1321ws wa wc .
n2 frequently scan for wifi ws wc bti ap n3 scanning for wifi while not interacting ws wa ap ad .
n4 using cellular over wifi is availablewa wc ra rc sgo sgr .
n5 long timeout for corrupted connectionwa wc icw ap ad .
n6 active wifi wakelock while not interactingwa wc nab wls wlhp ap ad .
n7 improper high performance wifilockwa wc sp wlhp ap ad sensors1 unnecessary active sensors12 160sa ap ad .
s2 fast delivery wakeup sensorssa wfds asacc aspre asmag .
total table legend ad activity destroyed ap activity paused ar activity running be bluetooth enabled bc bluetooth connected bs bluetooth scanning bti battery temperature increasing bo battery overheat bvl battery very low cpua cpu awake cpuu cpu utilized cpuw cpu wakelock dlt display long timeout dsbb display screen brightness bright gl gps listener hflu high frequency location update go gps on lkla last known location available lct long connection timeout nl network listener nab network active background pe process exists ra radio available rc radio connected sgo signal good sgr signal great sp signal poor sa sensor active ss service stopped wa wifi available wc wifi connected wls wakelock scanning wlhp wakelock high performance ws wifi scanning ud user driving us user still uw user walking wfds wakeup fast delivery sensor asacc active accelerometer sensor spre active pressure sensor asmag active magnetic sensor stop the training if there is an increasing trend in the validation loss in consecutive epochs.
thereby we get a model with the least validation loss.
we have also followed the fold cross validation methodology in evaluating the performance of oracle.
forhyperparameter tuning we conducted a guided grid search strategy to find a configuration for the model that results in the best performance on the validation data.
one of the important hyperparameters in energy oracle model is the size of sequences.
to illustrate how this hyperparameter impacts performance of the oracle consider figure which depicts the sensitivity of the energy oracle s accuracy to the average number of samples per test.
as shown in this figure accuracy of the oracle is quite low whenwe sample svs only before and after execution of a test sample per test .
that is because a subset of energy defects e.g.
using light background fast delivery sensor listener and etc.
happen during the execution of a test and their impact disappears when the test terminates.
therefore our approach is unable to learn and later predict such types of energy issues with extremely low sample rates.
while increasing the number of samples per test alleviates this problem exceeding certain threshold past samples per test in figure appears to unnecessarily increase the complexity of dl problem thereby reducing the accuracy of classifier.
other detailed configuration of dl engine are available on aceton s website .
934automated construction of energy test oracles for android esec fse november virtual event usa table comparing ability of aceton in detecting the category of different energy defects indicates the wrong predictions aceton with attention aceton without attention pass bluetooth cpu display location network sensor pass bluetooth cpu display location network sensor pass bluetooth cpu display location network sensor precision .
.
.
.
.
recall .
.
.
.
.
.
.
table aceton s performance on detection of real defects.
apps a2dp.vol gtalk openbmap open camera sensorium ushahidi version 8624c4f 8231d4d 4767d64 dce8b85 c0f8fa2 5ce2d94 56c3a67 14d166f f72421f .
e153fdf 94c9a8d 94c9a8d 4f20612 defect type location location bluetooth cpu location cpu cpu cpu network display cpu cpu cpu location label location location bluetooth cpu location cpu cpu cpu network display cpu cpu cpu location .
rq1 effectiveness while aceton builds on top of a high quality dataset we performed two experiments to ensure generalizability of our results in evaluating the ability of aceton to detect energy defects.
in the first experiment we used the labeled dataset for both training and testing purposes.
in the second experiment we trained the oracle based on the labeled dataset and used real energy defects nonmutant apps with energy defects confirmed by their developers to test the oracle.
.
.
effectiveness on detecting mutant defects.
for the purpose of this evaluation we divided the dataset obtained from labeled database into two categories of training set to train the oracle with it and test set to test the performance of oracle.
that is we downsampled each category of mutants e.g.
location by for training and used the remaining for testing.
while our feature vector is designed to reflect information that is app independent not dependent to usage of specific apis or code constructs we ensured that during downsampling the mutants in the test set belong to different apps compared to that used in the training set.
this strategy accounts for overfitting and potential bias in favor of specific apps.
we select precision andrecall and not accuracy as metrics to measure effectiveness of aceton in predicting correct labels since our data is imbalanced.
with imbalanced classes it is easy to get a high accuracy without actually making useful predictions as the majority class impacts true negative values.
table shows the result for this experiment under aceton with attention column.
these results are obtained through a fold cross validation i.e.
downsampling repeated 10times.
each row in this table shows the number of test instances in a predicted class where each column indicates the instances in actual class.
from this result we observe that aceton predicts correct labels for each category with a very high precision and recall .
in fact aceton was able to detect all the defects related to the sensor network display cpu and bluetooth and only missed 3location defects marked by in table i.e.
identifiedthem as passed.
the average precision and recall values over all categories are .
and99.
respectively.
categorical precision and recall values are listed in the last two rows.
.
.
effectiveness on detecting real defects.
while aceton is able to effectively detect the outcome of tests in mutants we also wanted to see how it performs on android apps that have real but similar energy defects.
to that end we referred to a prior work which provides a dataset of 14android apps with real energy defects.
each app is accompanied by a test generated using their test generation tool which is manually confirmed to reproduce the energy defect.
the supplementary information in the artifact of that dataset also indicates the type of hardware element that is misused by the defect which we used to identify if aceton correctly identifies the outcome of tests.
table represents the results for this experiment.
as shown in table aceton was able to correctly identify the outcome of tests on all subjects.
this observation indicates that aceton can effectively detect real energy defects in mobile apps.
.
rq2 usage of attention mechanism recall that we use the attention mechanism for two purposes to enhance performance of the model and to verify validity of the model.
in this research question we evaluate to what extent attention mechanism affects these objectives.
to evaluate the extent of performance enhancement we removed theattention layer section .
of learning engine and repeated the experiment in section .
.
.
the result of this experiment is shown in table under the aceton without attention column.
as corroborated by these results removing the attention negatively impacts the precision and recall values .
for example in network category the recall drops to .
compared to in aceton with attention i.e.
the model misses 9out of 71network defects.
removing attention fromaceton also negatively impacts training time.
that is it takes longer for the model to learn the patterns and converge.
we discuss this more in rq5.
935esec fse november virtual event usa reyhaneh jabbarvand forough mehralian and sam malek attention analysis produces a set of features as output on which the oracle has attended more.
to visually confirm that aceton has attended to relevant features for each category of energy defects i.e.
to determine its validity we created the heatmap shown in figure .
the horizontal axis of heatmap indicates sv while the vertical axis indicates subcategories listed in table .
to construct the heatmap we counted the appearance of each attended feature for all its instances in a subcategory and divided it by the occurrence of all the attended features under that subcategory to define a weight for it.
the weights take a value between and the higher is the weight for a feature the model attended to it more under the given subcategory thus its corresponding color in heatmap is closer to yellow.
as the heatmap clearly shows the hot areas of heatmap for each subcategory in the vertical axis maps to its corresponding category in the sv meaning that the model has attended to relevant features to decide the output of tests.
an interesting observation from this heatmap is that lifecycle features specifically activity paused activity destroyed and service stopped frequently appear in the attended features.
this shows that energy defects are not solely related to the changes in app or hardware states but a combination of both.
finally we aggregated the list of attended features for each category and formally specified them as shown in table under defect signature column.
while our intention for deriving defect signatures was to verify the validity of the dl model we believe that the ability of aceton to extract and formalize the signatures can further help developers to localize the energy defects specifically for new types of energy defects that will emerge as android framework evolves.
for example the signature of unnecessary active bluetooth connections shows the root cause of this issue is failing to close a bluetooth connection bc when the bluetooth is off or turning off be which causes battery consumption even when the app is paused ap or destroyed ad ss .
.
rq3 detecting unseen defect types while prior research question evaluated effectiveness of aceton in detection of defect types it was trained on this research question investigates its ability to detect previously unseen defect types.
generally speaking dl models can only predict patterns that they have been trained on.
however we hypothesize that if our oracle is trained on a subset of defect types for a specific hardware element it may be able to detect unseen defect types related to that hardware as well.
to that end we excluded one subcategory listed in table at a time trained the model on the energy defects related to all other subcategories among all hardware categories and used instances of the excluded subcategory as test data.
here we use recall as an evaluation metric to evaluate effectiveness of aceton .
precision is not a proper metric here since our test data only belongs to one subcategory class in this experiment and no false positive is generated.
column unseen recall in table shows the result for this experiment.
we can see that in the majority of the cases aceton is able to effectively detect previously unseen energy defect types .
in fact the recall value for majority of the excluded sub categories is above .
however there are a few subcategories with lower recall values which are marked by figure a heatmap representing the attended features of sv for different subcategories of energy defects in table .
these are the cases in which the attended features i.e.
defect signature is drastically different from that of in the training dataset.
we believe as additional energy defects are included in the training dataset of aceton its ability to detect previously unseen energy defects can improve too.
.
rq4 reusability of the oracle in answering prior research questions we showed that the oracle generated by aceton is reusable among different apps.
here we investigate if the oracle is also reusable across different mobile devices.
experiments in prior research questions were performed on a google nexus 5x phone running android version .
api level .
for this experiment we used an additional phone nexus 6p running android version .
.
api level .
these two devices are not only different in terms of android version but they also have different hardware configurations e.g.
different pixel density and resolution for display cpu frequency ram size battery capacity etc.
we first repeated the experiments in section .
.
on the new device to ensure that the oracle model is still effective in detecting energy defects.
the result of this experiment showed the same level of precision and recall for the new oracle average precision .
average recall .
.
afterwards we wanted to see if the oracle trained on one device can correctly predict the label of tests executed on the other device.
to that end we split the instances of labeled database into two subsets of them to be used for training and the remaining for testing.
next we trained two oracles on the mentioned devices oracle 1on nexus 5x device and oracle 2on the nexus 6p device by executing the instances in the training set and collecting their sampled svs on the corresponding device.
similarly we executed instances of test dataset on both devices test1on nexus 5x and test2on the nexus 6p.
we then evaluated test1usingoracle 2and test2usingoracle .
the average precision and recall values for test1 onoracle 2are99.
and99.
respectively.
similarly oracle was able to detect the labels for test2with an average precision of .
and recall of .
.
these results confirm that our energy oracles are device independent hence reusable.
936automated construction of energy test oracles for android esec fse november virtual event usa figure f1 score of aceton with and without attention captured during the training phase .
rq5 performance to answer this research question we evaluated the time required to train and test the oracle.
we ran the experiments on a laptop with .
ghz intel core i7 cpu and gb ram.
it took .5minutes on average for aceton to train an energy oracle on the whole dataset while it took only .6milliseconds on average for the trained oracle to predict the label of tests in our experiments.
in addition we examined to what extent attention mechanism speeds upaceton s learning.
to that end we disabled the early stopping criterion recall section .
and tracked the f1 score of the following two models during their training aceton with attention andaceton without attention .
as shown in figure aceton without attention requires more time to train a model that achieves a comparable f1 score as aceton with attention .
in fact even after minutes of training aceton without attention was not able to match the f1 score of aceton with attention .
these results confirm that aceton is sufficiently efficient for practical use.
related work automated test oracle approaches in the literature can be categorized into specified derived and implicit test oracles .
majority of these technique focus on the functional properties of the program to generate test oracles e.g.
generating test oracles for gui.
even among those that consider non functional properties of software none has aimed to develop an oracle for energy testing.
aceton is the first attempt to construct automated reusable energy test oracles for mobile apps.
to the best of our knowledge it is also the first effort of using deep learning to tackle the oracle problem.
the biggest challenge to construction of an energy oracle is determining the observable patterns during test execution that are indicators of energy defects.
while prior research attempted to categorize energy defects in mobile apps the proposed fault models are either broadly describing a category of energy defects or identifying specific energy anti patterns in code that lead to excessive battery consumption .
also as energy defects change and new types of defects emerge due to the evolution of mobile platform i.e.
android framework the defect model proposed by prior work becomes obsolete.
aceton s contribution is the ability to automatically learn the changes in the state of hardwareand environmental settings with high precision and recall even for unseen patterns.
the closest approaches to aceton in terms of detecting energy defects through testing are jabbarvand et al.
and banerjee et al.
.
droid is an energy aware mutation testing framework for android.
it implements 50energy mutants and relies on comparing power traces of original and mutant versions of an app to construct an oracle i.e.
to determine whether a test kills a mutant or not.
the proposed technique for construction of mutation testing oracle in cannot be generalized to energy test oracles as it requires a baseline power trace that of original app to identify anomalous patterns in a given power trace mutant app.
cobweb is a search based energy testing framework for android.
the proposed approach employs a set of models to take execution context into account i.e.
lifecycle and hardware state context in the generation of tests that can effectively find energy defects.
while cobweb is effective for generating energy aware test inputs it does not address the automatic construction of oracles for energy tests.
banerjee et al.
presents a search based profiling strategy with the goal of identifying energy defects in an app.
they construct a graph representing an app s gui events extract the event traces using the generated graph and explore event traces that may possibly reach energy hotspots while profiling energy consumption of the device.
in fact analyzes the power traces using statistical and anomaly detection techniques to uncover energy inefficient behavior.
unlike the automated oracles generated by aceton usage of a power measurement hardware makes their approach device dependent expensive and thereby impractical.
in their subsequent work banerjee et al.
fixed the scalability issue of the prior work by using abstract interpretation based program analysis to detect resource leaks.
similar to the prior work they rely on a dynamically constructed model for gui events to guide the search for finding paths leading to a resource leak.
unlike aceton s test oracles that are reusable and can detect a wide range of energy defects test oracles generated by energypatch are specifically targeted to detection of resource leaks.
concluding remarks energy efficiency is an increasingly important quality attribute for mobile apps that should be properly tested.
recent advancements in energy testing have in large part focused on test input generation and not on the automated construction of test oracles.
the key challenge for the construction of energy test oracles is derivation of reusable patterns that are indicative of energy defects.
we presented aceton the first approach for automated construction of energy test oracles that leverages deep learning techniques to learn such patterns.
our experimental results show that the energy oracle constructed using aceton is highly reusable across mobile apps and devices achieves an overall accuracy of and efficiently detects the existence of energy defects in only 37milliseconds on average.