soar a synthesis approach for data science api refactoring ansong ni yale university new haven usa ansong.ni yale.edudaniel ramos inesc id ist u. lisboa portugal carnegie mellon university usa danielrr cmu.eduaidan z.h.
yang queen s university kingston canada a.yang queensu.cain es lynce inesc id ist u. lisboa lisboa portugal ines.lynce tecnico.ulisboa.pt vasco manquinho inesc id ist u. lisboa lisboa portugal vasco.manquinho tecnico.ulisboa.ptruben martins school of computer science carnegie mellon university pittsburgh usa rubenm cs.cmu.educlaire le goues school of computer science carnegie mellon university pittsburgh usa clegoues cs.cmu.edu abstract with the growth of the open source data science community both the number of data science libraries and the number of versions for the same library are increasing rapidly.to match the evolving apis from those libraries open sourceorganizations often have to exert manual effort to refactor theapis used in the code base.
moreover due to the abundance ofsimilar open source libraries data scientists working on a certainapplication may have an abundance of libraries to choose main tain and migrate between.
the manual refactoring between apisis a tedious and error prone task.
although recent research effortswere made on performing automatic api refactoring betweendifferent languages previous work relies on statistical learningwith collected pairwise training data for the api matching andmigration.
using large statistical data for refactoring is not idealbecause such training data will not be available for a new libraryor a new version of the same library.
we introduce synthesis foropen source api refactoring soar a novel technique thatrequires no training data to achieve api migration and refac toring.
soar relies only on the documentation that is readilyavailable at the release of the library to learn api representationsand mapping between libraries.
using program synthesis soarautomatically computes the correct configuration of argumentsto the apis and any glue code required to invoke those apis.soar also uses the interpreter s error messages when runningrefactored code to generate logical constraints that can be usedto prune the search space.
our empirical evaluation showsthat soar can successfully refactor of our benchmarkscorresponding to deep learning models with up to layers withan average run time of .
seconds and of the datawrangling benchmarks with an average run time of .
seconds.
index t erms software maintenance program translation program synthesis i. i ntroduction modern software development makes heavy use of libraries frameworks and associated application programming interfaces apis .
libraries provide modular functionality intended for reuse with prescribing a particular architecture and their widespread use has important productivity advan tages .
the api for a library defines the interface or both authors contributed equally to this work.contract between the hidden library implementation of apiece of library functionality and its client component .good api selection and maintenance is a key component ofmodern software engineering .
although ideally api selection and usage could be stable over the course of a software project s lifetime there are manypractical reasons that client code must update the way it usesa given api or even which api library it uses for a givenset of functionality.
broadly software may evolve becauseof a change in the code the documentation its properties or the customer experienced functionality .
the apis usedby the software can become invalid or inapplicable as thesoftware evolves.
apis themselves may become deprecatedor obsolete .
as a result to maintain and optimize softwarethat depends on apis developers often have to refactorapis between different versions or to another api i.e.
apimigration altogether.
api migration is a form of software refactoring a critical software engineering activity that is largely performed man ually and is tedious and often error prone .
migrationcan be difficult even when migrating between two closely related apis that nominally provide the same functionality.for example consider increasingly popular data science anddeep learning libraries such as tensorflow pytorch and numpy .
moving between two such libraries oftenrequires significant manual labor as well as domain andlibrary specific knowledge we illustrate with an example insection ii worse apis can change and outdated historicalknowledge can exacerbate these challenges.
fortunately many popular apis possess key properties that can inform an automated approach to support migration orevolution.
first open source apis are often reasonably well documented .
the quality quantity and structure of thatdocumentation can vary widely but as code intendedto be called and reused by unrelated client applications documentation is often key to successful api uptake .second unsuccessful api methods often raise exceptions ieee acm 43rd international conference on software engineering icse .
ieee with informative error messages that developers can use to access stack traces and information that can help them modify a program .
we observe that data science api errormessages are particularly useful as these error messages oftenidentify how the input data relates to the raised exception.
takefor example error in fit subscript out of bounds which is an error message describing an index overflow.
fromthe example error message we know that either or isout of bounds for the input matrix.
third although multipleapis may vary in concrete implementation details it is oftenpossible to discretely map between pieces of functionalitybetween source and target apis by virtue of solving the samegeneral sets of problems .
we propose soar synthesis for open source api refactoring a novel approach that combines natural languageprocessing nlp with program synthesis to automaticallymigrate refactor between apis.
we focus our approach and evaluation on deep learning and data science apis.
since there are many apis targeting these domains changes and new releases are introduced rapidly as one example tensorflow had releases in alone and switching between them iscommon and often tricky .
moreover data scientists andother users of such libraries have broad backgrounds and arenot always classically trained programmers and thus could particularly benefit from tool support to assist them in thesetasks .
however we believe the approach will generalize to other apis with similar properties see detailed discussion in section iv .
given a program that uses a given source api soar s central proposition is to use nlp models learned over availableapi documentation and error messages to inform programsynthesis to replace all source api calls with correspondingcalls taken from the target api.
soar starts by using existingdocumentation for the source and target libraries to build anapi matching model which finds likely replacement calls for each api call in the source program.
however simply finding the right function in the corresponding target api is not enough.
the new function must becalled with the correct arguments and function specificationsmay vary between libraries.
soar uses program synthesis to construct the full target method call in a way that replicatesthe original source behavior.
this synthesis step may be further informed by specifications inferred again from the api documentation.
during the program synthesis enumeration procedure a potential migrated call may throw an error when tested.
in thesesituations soar uses an error message understanding model that again uses nlp techniques to analyze error messages andgenerate logical constraints to prune the search space of the synthesis task.
to the best of our knowledge soar is the first refactoring tool that incorporates program synthesis and machine learningtools for refactoring and is a significant improvement over the prior state of the art.
soar maps programs between different apis using only readily available documentation.it does not require manual migration mappings or ahistory of previous migrations or refactorings in other software projects .
indeed soar does not require trainingdata at all and is thus applicable for migrations to a newlibrary or newer version of the same library shortly afterrelease.
we demonstrate that soar is versatile in section iv using it to migrate between two deep learning libraries i.e.
tensorflow to pytorch in the same programming language i.e.
python and between two data manipulation libraries i.e.
dplyr to pandas in two different programming languages i.e.
r and python .
prior techniques either specialize exclusivelyin supporting cross language migration e.g.
staminer or do not support it at all.
because soar uses synthesis when it succeeds the produced code is guaranteed to compile andpass existing test cases for the original source code.
in summary our main contributions are we propose soar a novel approach based on nlp and synthesis for automatic api refactoring focusing on butnot limited to deep learning and data science tasks.
soar requires no training data and its output is guaranteed to compile and pass existing test cases.
instead of using training data from prior programs soar leveragesapi documentation and program error messages to gener ate logical constraints to prune the program enumerationsearch space.
we evaluate soar on two library migration tasks i.e.
tensorflow to pytorch and dplyr to pandas to demon strate its effectiveness.
our results show that soar cansuccessfully migrate of neural network programs composed by to layers in with an average time of97.
seconds.
and for dplyr to pandas migration of benchmarks are solved on average in .
seconds.
with ablation studies we also evaluate how each part of soar impacts its performance.
we show that the use of specifications from api documents and learning fromerror messages are largely helpful for the synthesis process.
we also show how different api matching methodsperform on the two migration tasks.
we release the soar implementation for the two migration tasks mentioned above.
we also release the docu mentation and benchmark tests we use in this work tofacilitate future research on this direction.
the remainder of this paper is organized as follows section ii presents a motivating example that illustrates the chal lenges of manual api refactoring.
in section iii we describeour approach to automatic api migration.
section iv presentsour empirical evaluation and analysis of results.
next wediscuss our current approach and limitations in section v.finally we conclude with an overview of related work in section vi and conclusions in section vii.
ii.
m otiv ating example we illustrate some of the difficulties of manual api refactoring via example.
consider the tensorflow code snippet onthe left hand side of figure .
the program being refactoredshows an autoencoder program written using the tensor flow api the goal is to migrate this code to use the pytorch !
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
.
!
!
!
!
!
!
!
!
fig.
an example of how soar refactors a program written with tensorflow left to using pytorch right .
note that the whole program consists of apis calls to tensorflow though we only show four blocks of them i.e.
a b c and d for brevity.
soar can migrate the full program in seconds.
api.
an autoencoder is a type of neural network that is trained to copy its input to its output.
specifically in this example theautoencoder tries to compress an image with an encoder andthen the decoder will try to restore the original image.
the example in figure shows only a portion of the program for didactic purposes.
to build the first layer of the encoder function conv2d is called which constructs a convolution layer that can be applied to 2d images.
afterfurther elided activation and convolution layers it calls dense to output a latent representation of the input image.
decoding this output follows roughly the same procedure asthe encoding but using conv2dtranspose instead of conv2d .
the function relu appears in both the encoder not shown and decoder initializes a type of activation layer to ensurenon linearity of the neural network.
the example of deep learning library code and translation in figure illustrates several of the core challengesin refactoring open source apis as well as opportunities toinform an automated approach.
first the names of functioncalls implementing similar functionality may be very similaror even identical such as those in blocks a c and d or completely different e.g.
dense versus linear in block b .
if a developer were performing this migration manually they might reference the api documentation.
for example the tensorflow documentation describes the conv2d class as a 2d convolution layer e.g.
spatial convolution over images the corresponding pytorch documentation forthe conv2d call describes it similarly as a 2d convolution over an input signal composed of several input planes .
here the function names map well but when this does nothappen it is more challenging to connect the documentation.
even when we know which function to use however callsalgorithm synthesizer i s t c input i existing program s source library t target library c test cases output o refactored program vectorr api mapping mapapi t s o for each l i do o o end for that implement the same functionality can require different types parameters parameter names and even the parametervalues may be different between them.
this is true for themajority of the calls in our example see those in blocksa b and c .
note for example that the conv2d functions take different parameters in each of the two libraries.
thereis overlap between them both include kernel size and stride and strides clearly correspond but even the incommon parameters are not in the same argument positionbetween the two calls strides is the third parameter in tensorflow but stride is the fourth in pytorch .
sometimes some or all of the arguments to a call in the source api can be copied directly to the call in the target api see the calls inblocks a c other times correct arguments must be inferred such as the first parameter to linear in block b .
finally in other situations no single function in the target api canmatch the semantics of a call from the source api requiring instead a one to many mapping as we see in converting the conv2dtranspose call in block c .
in the next section we show how soar addresses these challenges with each of its components.
iii.
r efactoring algorithm this section describes soar our approach for automatic api migration.
we begin with a high level overview of themethod section iii a before providing more detail on indi vidual components section iii b iii c iii d .
a. overview figure shows an overview of the soar architecture while algorithm provides an algorithmic view.
soar takes asinput a program iconsisting of a sequence of api calls from a source library s the source s and target t libraries and their corresponding documentation and a set of existing testcases c .
since the user wants to refactor code from stot we assume that the user already has test cases for ithat can be reused to check if the refactored code o has the same functional behavior has the original code i .
refactoring proceeds one line at a time in i finding constructing an equivalent snippet of code composed by one or more lines that uses apis of the target library t the composition of all these translated lines comprises the output o. for each api call in the input program the first problem either a developer or a tool must face is to identify methods in the target api that implement the same functionality i.e.
!
fig.
overview of soar s architecture.
fig.
description of the program parameters in torch.nn.conv2d documentation .
for a given set of input parameters the target api call must generate the same output .
soar uses an api matching model to identify target api calls.
this model is built using nlp techniques that analyze the provided api documentation for each call and provides a mapping vectorrin algorithm that computes the similarity between each target api function andeach potential source api function.
soar uses this to find themost likely replacement methods in the target api for each source api call in the input program.
we provide additional detail in section iii b. given a potential match call in the target api the next step is to determine how to call it in terms of providing the correct parameters in the correct order of the correcttype.
soar uses program synthesis to automatically writethe refactored api call using the provided test cases to define the expected behavior of the synthesized code and its constituent parts.
the synthesis process can be assisted with additional automated analysis of api documentation whichoften provides key information about each parameter namely whether it is required or optional its type its defaultvalue if applicable and constraints between arguments input and output e.g.
input and output tensor shapes .
figure shows a snippet of the descriptions of all parametersfor torch.nn.conv2d .
for example the parameter stride is optional it takes type intortuple and its default value is .
analysis of this documentation can produce a specification constraint for the stride parameter assisting the program synthesis task.
section iii c describes the synthesis step.
given a potential rewrite in the target api a natural step for a developer would be to run the refactored code on testinputs.
unsuccessful runs can be quite informative because many apis especially in the deep learning and data sciencedomains provide error messages that can be very helpful fordebugging.
soar simulates the manual debugging processby first adapting the input whole program test cases to testpartially refactored code and then extracting both syntacticand semantic information from any error messages observedwhen running them.
soar uses this information to add newconstraints to the iterative synthesis process section iii d .
after migrating all calls in the source api to the target api such that all input tests pass soar outputs a fully refactored program.
subsequent sections provide additional detail on thepreviously described steps.
b. api representation learning and matching the first step in migrating a call in a source api is to identify candidate replacement calls in the target api withsimilar semantics.
the api matching model supports this task by analyzing the prose documentation associated with eachcall in each api and computing similarity scores between allapi pairs.
at a high level this model embeds each api method call in a source and target library into the same continuous high dimensional space and then computes similarity betweentwo calls in terms of the distance between them in that space.we explored two ways on obtaining api representation tf idf term frequency inverse document frequency and pretrained word embeddings .
tf idf .
the intuition behind tf idf is to find the most representative words rather than the most frequent words in a sentence.
normalizing by the inverse document frequency lowers the weights of common keywords that are less informa tive such as torch tensorflow and those stop words in natural language such as theorthis.
specifically we first derive a bag of words representation x i from a description of an api call after some stemming of the words with the snowball stemmer .
xi xi xi2 ... xi n wherexi jdenotes the frequency with which word xjappeared in the sentence xi andnis the size of the vocabulary from the descriptions of all apis we are trying to embed.
a tf idfrepresentation of the call is computed as equation tf idf x i bracketleftbiggxi summationtextm t 0xt xi summationtextm t 0xt ... xi n summationtextm t 0xtn bracketrightbigg 115however the major downside of tf idf is that it does not encode the similarities between words themselves.
for exam ple consider two hypothetical call descriptions remove the last item of the collection and delete one element from the end of the list .
they are semantically similar but since they have minimal overlapping words a tf idf representationmethod would not recognize these two api calls as similar.
tfidf glove.
we can extend the tf idf representation to recognize similar words by adding pretrained word embeddings.specifically we propose to use the glove embedding which is trained on a very large natural language corpus andlearns to embed similar words closer in the embedding space.
to obtain sentence embeddings from individual words we perform a weighted average of the word embeddings and usethe tf idf scores of individual words as weight factors.
it is a simple yet effective method to obtain sentence embedding for downstream tasks as noted by previous work .this is shown in detail as equation where w jis the vector encoding the glove embedding of word xj embedding xi n summationdisplay i jxi j wj summationtextm t 0xt j by including the glove embedding word similarity is preserved by including the tf idf terms the influence ofembeddings of common words is greatly reduced.
however glove is trained with common crawl which contains rawwebpages which is a mismatch from our domain of textual data i.e.
data science and programming .
api matching.
given the representation of two apis rep x i rep xj in the same space rep we compute their similarity with cosine distance sim rep xi rep xj rep xi rep xj rep xi rep xj for computational efficiency we pre compute the similarity matrix between the apis across the source and target library.
so we will be able to query the most similar api for thesynthesizer to synthesize its parameters on the fly.
c. program synthesis given the input test cases and the api matching model providing a ranked list vectorrof apis in the target library the synthesis model automatically constructs new equivalent code of one or more lines that uses apis of the target library t. the refactored program ohas the same functionality as input programi and passes the same set of tests c. to refactor each line of the existing program i we use techniques of programming by example pbe synthesis .
pbe is a common approach for program synthesis wherethe synthesizer takes as specification a set of input output examples and automatically finds a program that satisfies thoseexamples.
in the context of program refactoring our examples correspond to the test cases for the existing code.
in this paper we restrict ourselves to straight line code where each line returns an object that can be tested.
with these assumptions algorithm refactor line l t c vectorr input l line of code from i t target library c test cases vectorr ranked list of api matchings output r refactored snippet for each a vectorr do ais a target api vectors generate sketches a t for each s vectorsdo r fillsketch s ifpass tests r c then returnr end if end for end for we can automatically generate new test cases for each line k of program i. this can be done by using the input of the existing tests running them and using the output of line kas a new test case for the program composed by lines 1tok.
our program synthesizer for refactoring of apis is presented in algorithm and it is based on two main ideas i programsketching and ii program enumeration.
for each line l in program i we start by enumerating a program sketch i.e.
program with holes using apis from the target library t line .
for each program sketch we perform program enumeration on the possible completion of the api parameters line .
for each complete program we run the test cases forthe program up to line l. if all test cases succeed then we found a correct mapping for line lbetween libraries sand t line .
otherwise we continue until we find a complete program that passes all test cases.
program sketching.
program sketching is a well known technique for program synthesis where the programmerprovides a sketch of a program and the program synthesizerautomatically fills the holes in this sketch such that it satisfies agiven specification.
we refactor one line of program iat each time.
our first step is to use the ranked list of apis to create a program sketch where the parameters are unknown.
for instance consider the first layer from the motivating examplethat shows the network for an autoencoder using tensorflow tf.keras.layers.conv2d filters kernel size strides a possible sketch for this call using pytorch is torch.nn.conv2d stride padding where holes ihave to be filled with a specific value for the apis to be equivalent.
this approach works for one to one mappings but would not support common one to many mappings where the parameters often need to be transformed be fore being used in the new api.
this is the case of the previous api where a reshaping operation must be performed before calling the pytorch api.
to support this common behavior we include in our program sketch one api from the target librarytand common reshaping apis e.g.
permute long .
the sketch that corresponds to the refactoring solution of 116theconv2d api from tensorflow uses a reshaping api before calling the conv2d api from pytorch lambda x x.permute torch.nn.conv2d stride padding using occam s razor principle our program synthesizer enumerates program sketches of size 1and iteratively increases the size of the synthesized program up to a specified limit.
program enumeration.
for each program sketch p our program synthesizer enumerates all possible completions foreach hole.
since each hole has a given type we only want toenumerate well typed programs.
we encode the enumerationof well typed programs into a satisfiability modulo theories smt problem using a combination of boolean logic and linear integer arithmetic lia .
this encoding is similar to other approaches that use smt based enumeration for programsynthesis and encodes the following properties each hole contains exactly one parameter each hole only contains parameters of the correct type.
a satisfying assignment to the smt formula can be translated into a complete program.
the types for each hole can bedetermined by extracting this information from documentation by performing static analysis or by having this informationmanually annotated in the apis.
the available parameters andtheir respective types can be extracted automatically from theparameters used in the k th line of program iand by any default parameters that can be used in the api from tthat appears in the program sketch p. for instance for the conv2d example presented in this section we consider as possible values for the holes the values that appear in the existing code and default values for integer parameters that are automatically extracted from documentation.
encoding the enumeration of well typed programs in smt has the advantage of making it easier to add additional logicalconstraints that can prune the search space.
specification constraints.
as we described in section iii a api documentation often provides additional useful informa tion about parameters to function calls including type anddefault values.
for each considered api call we scrape pro cess the associated documentation to extract these propertiesand encode them as smt constraints to further limit thesynthesizer search space.
additionally some apis have complex relationships between parameters which if encoded into smt may reduce thesearch space considerably.
for instance figure shows the relationship between the different parameters for the conv2d api described in pytorch documentation.
for apis with these kinds of shape constraints we can encode these relationshipsinto smt to further prune the number of feasible completions.when we use these relationships in our experiments weencode them manually a one time cost for an actual soaruser or api maintainer but we observe that in many casesthey could be automatically extracted from documentation.
besides these specification constraints we can also further prune the search space by using the error messages provided fig.
relationship between the parameters of conv2d api described in pytorch documentation .
trying to create tensor with negative dimension hyponym 1torch.nn.conv2d stride padding pos jj target param pos nn in channels in channels out channels kernel size stride padding if pass generate smt constraint step .
match candidate faulty pa rameter with program parameter scompile program and generate error message trying to create tensor with negative dimension step .
collect candidate faulty parameters and fault causes step .
mutate program self.var5 torch.nn.conv2d stride padding if fail fig.
example error message to smt constraint pipeline using hyponym .
by the python interpreter as we discuss in the next section.
d. error message understanding we use a combination of extracting hyponymy relations and word2vec to understand run time error messages.
asoutlined in figure our smt constraint generation methodconsists of three steps.
step extract hyponymy relation candidates from error messages.
we perform an automatic extraction of customized hyponyms on each error message.
hyponyms are specificlexical relations that are expressed in well known ways .in encoding a set of lexico syntactic patterns that are easilyrecognizable i.e.
hyponyms we avoid the necessity for semantic extraction of a wide range of error message text.
wethen use the collected hyponyms to map the error message toa single faulty parameter and output a smt constraint basedon the faulty parameter.
prior work on text parsing uses tregex which is a utility developed by levy and andrew for matching patterns in constituent trees .
for example evans et al.
evaluated the performance of tregex on privacy policies .
however deep learning dl api compilation error messages aredomain specific.
sumida et al.
used the hierarchical layout of wikipedia articles to identify hyponymy relations .
similarly to wikipedia documents dl api compilation error 117table i the four hyponyms in the error message understanding model type np example error messages identified hyponym angbracketleftnoun angbracketright angbracketleftp reposition angbracketright angbracketleftadjective angbracketright?
angbracketleftnoun angbracketright trying to create tensor with negative dimension tensor with negative dimension angbracketleftnoun angbracketright angbracketleftcardinal number angbracketright embedding argument weight position must be tensor not int position angbracketleftcoordinating conjunction angbracketright angbracketleftve r b angbracketright angbracketleftadjective angbracketright angbracketleftnoun angbracketright expected dimensional input for 3dimensional weight but got dimensional input of size instead but got dimensional input angbracketleftve r b angbracketright angbracketleftadverb angbracketright angbracketleftve r b past participle angbracketright non positive stride is not supported is not supported messages are more consistent and organized than normal natural language documents.
therefore we follow the approachof extracting hyponymy relations based on the hierarchicallayout of a string.
we propose a set of four lexico syntatic patterns to identify hyponyms using noun phrases np and regular expressions frequently appearing in machine learning api error messages.table i shows the four hyponyms.
if we identify any of thefour lexico syntatic patterns within an error message we tagthe error message with a hyponym type.
as shown in figure we identify hyponym in error message trying to create tensor with negative dimension... .
step identify candidate faulty parameters and constraints.
step uses different keywords based on the result of step to identify the faulty parameter.
as shown in figure5 an error message with hyponym is likely to have thepos jj word as a parameter constraint i.e.
word negative .
based on the fault cause candidate we then store all negativenumbers as candidate faulty parameters e.g.
has as the only faulty parameter .
we then vectorize thecandidate faulty parameter name i.e.
and find the program parameter name with the closest vectorized distance.
as shownin figure the parameter in channels has the nearest vectorized distance to the candidate faulty parameter .
based on the fault cause we generate a candidate constraint.
the example error message in figure has only one candidateconstraint in channels .
step mutate program.
to validate the candidate faulty parameters and constraints we mutate each faulty parameteraccording to each faulty parameter and constraints pair.
we then re compile the program for each mutation.
if the errormessage remains the same we discard the faulty parameterand constraint pair as a candidate.
if the program passes or if the error message changes we store the faulty parameter and constraint pair as an smt constraint.
as shown in figure the api call mutator mutates the second parameter in channels to a non negative number.
the mutator first attempts inchannels and it encounters a different error message.
from the new error message wemutate this parameter to in channels and observe no further errors.
therefore we refine our previous constraint tobe in channels and store it as the final smt constraint for the program in figure .iv .
e v aluation we selected two migrations tasks tensorflow to pytorch and dplyr to pandas.
we believe that these two migration tasksare representative of the needs of the data science community.indeed tensorflow and pytorch are the two most populardeep learning frameworks and recent trends indicate that alarge portion of tensorflow user base is shifting to pytorch .
we thus chose it as an indicative relevant task.
similarly dplyr is one of the top most downloaded r libraries pandas is its python counterpart.
to evaluate our approach we answer the following research questions q1.
how effective is soar at migrating neural network programs between different libraries?
q2.
how does each component of soar impact its perfomance?
q3.
is soar generalizable to domains besides deep learning library migration?
a. benchmarks and experimental setup we collected 20benchmarks for each of the two migration tasks.
in particular for the tensorflow to pytorch task we gathered neural network programs from tensorflow tutorials off the shelf models implemented with tensor flow or its model zoo .
this set of benchmarksincludes autoencoders for image and textual data classicfeed forward image classification networks i.e.
the vgg family alexnet lenet etc convolutional network for text among others.
the average number of layers in our benchmark set is .
.
whereas the median is .
our largest benchmark is the vgg19 network which contains 44layers.
for the domain of table transformations we collected benchmarks from kaggle a popular website for data science.
the programs in the benchmark set have an averageof3.
.07lines of code and a median of 3lines.
although the programs considered for this task are relativelysmall compared to the deep learning benchmarks they are still relevant for data wrangling tasks as shown by previous program synthesis approaches .
each benchmark is also associated with a set of input output examples i.e.
test cases used to decide migration success.for the deep learning task the test cases are automaticallygenerated by running the original neural network on randominputs.
whereas the test cases for the dplyr to pandas task areuser provided.
118table ii execution time for the deep learning library migration task in each of the 20benchmarks.
soar soar w o specs.
soar w o err.
msg.
conv pool softmax 4l .
.
.
img classifier 8l .
.
.
three linear 3l .
.
.
embed conv1d linear 5l .
.
.
word autoencoder 3l .
.
.
gan discriminator 8l .
timeout .
two conv 4l .
timeout .
img autoencoder 11l .
.
.
alexnet 20l .
timeout .
gan generator 9l .
timeout timeout lenet 13l .
timeout timeout tutorial 10l .
timeout .
conv fortext 11l .
timeout .
vgg11 28l .
timeout .
vgg16 38l .
timeout .
vgg19 44l .
timeout .
densenet main1 5l timeout timeout timeout densenet main2 3l timeout timeout timeout densenet conv block 6l timeout timeout timeout densenet trans block 3l timeout timeout timeout all results presented in this section were obtained using an intel r xeon r cpu e5 v2 .60ghz with 64gbof ram running debian gnu linux and a time limit of seconds.
to evaluate the impact of each component in soar we run four versions of the tool.
soar with tf idf soar w tf idf and soar with tfidf glove soarw tfidf glove to evaluate the impact of api representationlearning methods.
soar without specification constraints soar w o specs.
and soar without error message under standing soar w o err.
msg.
to evaluate the impact of thesecomponents on the performance of soar.
b. implementation the soar implementation integrates several technologies.
scrapy a python web scraping framework is used tocollect documentation for the four libraries in our experiments.to enumerate programs in the synthesis step we use the z3smt solver .
for each target program call parameter weextract an answer for the four parameter questions in section iii a and generate corresponding smt constraints.
in both api matching model and the error message understanding model the glove word embeddings are used as an off the shelf representation of words.
for the four librariesappearing in our two evaluation migration tasks we usetensorflow .
.
pytorch .
.
dplyr .
.
with r .
.
and pandas .
.
though our proposed method and associated implementation do not rely on specific versions.
we providea replication package including benchmarks source code andvirtual environment to run soar.
c. q1 soar effectiveness table ii shows how long it takes to migrate each of the deep learning models from tensorflow to pytorch using the various approaches.
our best approach shown as soar successfully migrates 16of the 20dl models with a mean of .
.58seconds and a median of .76seconds.
the average number of lines in the 16benchmarks that we successfully migrate is .
.
whereas the average number of lines in the output programs is .
.
.
the reason the number of synthesized lines is higher than those inthe original benchmarks is that we frequently do one to manymappings.
in fact 15out of the 16require at least one mapping that is one to many.
in the 16benchmarks soar tests on average .
refactor candidates i.e.
program fragments tested for each mapping and it needs to test amedian candidates before migrating each benchmark.
the reason 4benchmarks timeout is that in each of these benchmarks there is at least one api in the benchmark thathas a poor ranking i.e.
not in the top .
d. q2 performance of each soar component we perform an ablation study to understand the effectiveness of several features in the soar design.
embeddings.
in table iii we show the execution time and average ranking for the correct api matchings for each bench mark using different api representation learning methods namely tf idf and tfidf glove as described in section iii.
we can see that for these tasks of tensorflow to pytorchmigration using tf idf based api matching model worksbetter than adding pretrained glove embeddings.
we believethis is because similar apis are often named with samewords e.g.
conv2dtranspose vs.convtranspose2d o re v e n identical name e.g.
the apis of creating a rectified linear unit are both named as relu ... for tensorflow and pytorch.
thus simple word matching method like tf idf is suffice for api matching purposes.
however things are different for the second task we consider see section iv e for more details .
another interesting result worth noticing is that although the synthesis time differs for the two approaches the averagerankings are quite similar for most of the benchmarks.
thereason is that despite the average rankings of correct targetapis being similar the incorrect apis ranked by the model before the correct one is different and the time it takes to rule out those incorrect apis varies greatly determined largely bythe number of parameters required for that api.
error message understanding.
as shown in table ii soar performs significantly better when using the error messageunderstanding model.
we can observe that without this com ponent two of the benchmarks that soar could solve wouldtimeout at the hour mark.
for the 14benchmarks it still manages to solve the synthesis time increases on average4.
.
the number of performed evaluations also increase substantially for each benchmark.
for the 16benchmarks that soar successfully migrates we evaluate an average of .
.62refactor candidates without the error message understanding model.
this corresponds to a .
increase in the number of necessary evaluations when compared to the full 119table iii execution time and average api ranking for each of the 20benchmarks using tf idf and glove models.
soar w tf idf soar w tfidf glove time s avg.
ranking time s avg.
ranking conv pool softmax 4l .
.
.
.
img classifier 8l .
.
.
.
three linear 3l .
.
.
.
embed conv1d linear 5l .
.
.
.
word autoencoder 3l .
.
.
.
gan discriminator 8l .
.
.
.
two conv 4l .
.
.
.
img autoencoder 11l .
.
.
.
alexnet 20l .
.
.
.
gan generator 9l .
.
.
.
lenet 13l .
.
timeout .
tutorial 10l .
.
.
.
conv fortext 11l .
.
.
.
vgg11 28l .
.
.
.
vgg16 38l .
.
.
.
vgg19 44l .
.
.
.
densenet main1 5l timeout .
timeout .
densenet main2 3l timeout .
timeout .
densenet conv block 6l timeout .
timeout .
densenet trans block 3l timeout .
timeout .
soar method.
in summary we can significantly reduce the search space by interpreting error messages.
specifications constraints.
in table ii we also show the impact of specification constraints that describe the rela tionship between different parameters of a given api seesection iii c for details .
even though we only have thesecomplex specifications for the 7most common apis the impact on performance is significant.
without these specificationwe can only solve 6out of 20benchmarks.
relating the arguments of the apis helps soar to significantly reduce thenumber of argument combinations that it needs to enumerate.
e. q3 soar generalizability.
our experiments so far concern deep learning library migration in python.
to study the generality of our proposedmethod we applied soar to another task of migrating from dplyr a data manipulation package for r to pandas a python library with similar functionality.
fig.
shows how the twoapi matching methods perform in this domain.
while withtfidf glove of the correct apis are ranked among thetop saving lots of evaluations for the synthesizer none of the correct apis are ranked by the tf idf based matcher asits first choices.
worse nearly half of those are ranked above making the synthesis time almost prohibitivelylong.
we believe this is because the lexical overlap between the names of similar apis in those two libraries is much smallercompared to the deep learning migration task.
for example dplyr s arrange and panda s sort values provide the same functionality they both sort the rows by a given column but the function names are different.
in this way tfidf glove cantake advantage of the pretrained embeddings to explore thesimilarities between apis beyond simple tf idf matching.
in figure we show the time it takes to migrate each of the 20benchmarks with a timeout of seconds when using word embeddings.
we solve 18out of 20collected benchmarks in under .5seconds.
the average run time1 seconds timeout instances solvedtime s fig.
execution time for each benchmark of the dplyr topandas task with a timeout of seconds.
average ranking benchmarkstf idf tfidf glove fig.
average ranking of the apis for each of the dplyrto pandas benchmarks.
for18benchmarks is .
.59seconds and a median of12.19seconds.
note that for this task we did not consider error messages nor specifications since we wanted to test howa basic version of soar would behave in a new domain.moreover for this domain all the refactored benchmarksonly used one to one mappings since no additional reshaping was needed before invoking pandas apis.
even with theseconditions we show that we are able to successfully refactorcode for a new domain across different languages.
v. l imitations and discussion here we discuss the main limitations of our method and possible challenges for extending soar s ability to refactornew apis even potentially beyond the domain of data science.
benchmarks.
our evaluation of soar uses benchmarks from well known deep learning tutorials and architectures.
however they are all feed forward networks effectively sequences ofapi calls where the output of the current layer is the input ofthe next layer.
there may be more applications that share thisfeature but support for more complex structure is likely nec essary to adapt to other domains.
additionally and naturally the apis in the benchmarks we collected may be biased andnot reflect the set of apis developers actually use.
to assess this risk we checked the degree to which the apis used in our benchmarks appear to be widely used on other open source repositories on github.
to do this we collected the top starred repositories that have tensorflow as atopic tag which contains over million lines of code andover 500k tensorflow api calls.
we found that of the1000 repositories use api calls included in our benchmarks at least once which validates some representativeness of ourcollected benchmarks.
120automatic testability.
one benefit of the data science scientific computing domain is that much of the input output and underlying methods are typically well defined.
as a result itis particularly easy to test and verify the correctness of indi vidually migrated calls which can be processed in sequence.there may be other types of libraries that share these types ofcharacteristics like string manipulation or image processinglibraries whose intermediate outputs are strings images.
wealso assume user provided tests.
given the migration task itis reasonable to assume the user has tests the code must besufficiently mature to justify migrating after all but a moregeneral solution might benefit from automatically generatingtests which would both alleviate the input burden on the user and potentially reduce the risks of overfitting.
in our current implementation we moreover use the provided teststo construct smaller test cases for each mapping.
this isparticularly easy in this domain because data science anddeep learning api calls are often functional in their paradigm.
adapting the technique to other paradigms would require more complex test slicing or generation to support synthesis.
api matching.
using the glove model for the api matching often results in out of vocabulary problems because of api names and descriptions often use of data science specificterminologies especially acronyms and abbreviations e.g.
conv2d for dimensional convolution lstm for long short term memory .
the glove model is not trained for thisdomain and the out of vocabulary problems explain the limited success of the tfidf glove model when compared to a plain tf idf.
to address this problem it would be necessaryto train a new set of embeddings with focus on data sciencejargon which is out of scope.
error message understanding.
the error message understanding model is built on four domain specific lexico syntaticpatterns which we identify as hyponyms when they appear inan error message.
we propose the hyponyms based on thespecific syntax of dl api error messages thus take nontrivial human effort to make it generalize to error messages that appear when calling apis from libraries of other domains.however we believe the idea of program mutation step offig.
is still widely applicable for the purpose of generatingsmt constraints when dealing with error messages.
synthesis.
our approach supports one to many mappings but it restricts the mapping to oneapi of the target library and one or more reshaping apis.
however this could be extended to include many apis of the target library at the cost of slower synthesis times.
an additional challenge is to support many to one or many to many mappings since this would requireextending our synthesis algorithm.
however even with thecurrent limitations our experimental results show that the current approach can solve a diverse number of benchmarks.
generalizability.
soar applies best to well documented apis with easily decomposable tests i.e.
calls have welldefined semantics and limited side effects .
deep learningand data science apis have these properties and are popular rapidly evolving and used by programmers with a variety of backgrounds.
we focus on them in the interest of im pact.
soar likely generalizes easily to domains that sharethese properties like string or image manipulation libraries.nonetheless soar always requires a one time effort to beinstantiated in any domain.
specifically soar needs acrawler and a parser to collect documentation used to build the api matching model and specification constraints this step can be facilitated with tools like python s built in function help if api s are well documented an error message messageunderstanding model which can be simply based on phrase structure rules .
we do not study the effort needed to provide these two requirements however we believe it is significantlylower than building a static migration tool from scratch.
correctness.
since we evaluate our migration tasks using test cases it is always possible for our approach to overfit to these tests.
however this threat can be mitigated if the user provides a sufficiently robust test set that provides enough coverage.
additionally code written to different apis may befunctionally equivalent but demonstrate different performancecharacteristics which we do not evaluate.
however this factis one reason users might find soar useful in the first place a desire to migrate code from one library to another that is more performant for the given use case.
overall we focus our design and evaluation on deep learning and data science libraries.
these libraries have propertiesthat render them well suited to our task in terms of commonprogramming paradigms and norms such as in the apidocumentation.
however we believe this is also a particularly useful domain to support given the field s popularity and how quickly it moves how often new libraries are released or updated as well as the wide variety of skill sets and back grounds present in the developers who write data science ordeep learning code.
automation of migration and refactoringin this domain is very minimal and we design soar as a steptowards better tool support for this diverse and highly active developer population.
vi.
r elated work a. automatic migration existing work on automatic api migration uses examplebased migration techniques.
lamothe et al.
proposed an approach that automatically learns api migration patternsusing code examples and identified api migration patternsout of distinct android apis.
fazzini et al.
proposed apimigrator which learns from how developers from existingapps migrate apis and uses differential testing to checkvalidity of the migration.
they were able to achieve of theapi usages in apps and validated of those migrations.meditor mines open source repositories and extracts migration related code changes to automatically migrate apis.
meditor was able to correctly migrate out of testcases.
unlike prior api migration tools soar can migratecode without existing code examples.
121soar also relates to automatic migration on apis between different programming languages.
zhong et al.
proposed mam and mined unique api mapping relationsof apis between java and c with accuracy.
nguyen et al.proposed staminer which is a data driven approach that statistically learns the mappings of apis between javaand c .
bui et al.
used a large sets of programs as input and generated numeric vector representations of theprograms to adapt generative adversarial networks gan .
buiet al.
then identified the cross language api mappings via nearest neighbors queries in the aligned vector spaces.
againthese methods largely rely on existing training data such asmam and staminer mine mappings from parallelequivalent code from two languages java and c wheresoar only leverages the documentation for migration.
b. program synthesis program synthesis has been used to automate tasks in many different domains such as string manipulations tabletransformations sql queries and synthesis of javafunctions .
however its usage for program refactoring is scarce.
resynth uses program synthesis for refactoring of java code by providing an interactive environment toprogrammers where they indicate the desired transformationwith examples of changes.
our approach differs from resynthsince we do not require the user to provide a partiallyrefactored code.
since our problem domain is api migration it is unlikely that the user knows all the required apis fromthe target library and can perform these edits.
nlp can be used to synthesize programs directly from natural language or to guide the search of the program synthesizer .
for instance nlp has been used to synthesize tasks related to repetitive text editing sql queries and synthesis of regular expressions .
onecan also combine input output examples with a user providednatural description to have a stronger specification and achieve better performance .
our approach follows thistrend of work where we combine nlp to guide the program synthesizer with input output examples that provide strongerguarantees in the synthesized code.
however instead of usinga natural description provided by the user our approach uses documentation from libraries to guide the search.
using error messages from the compiler or interpreter is not common in program synthesis.
the most relevant approach to ours is the one from guo et al.
where they use type error information to refine polymorphic types when synthesizing haskel code.
in contrast soar uses error messages from theinterpreter not to refine the type information but to restrict thedomain of the parameters and to prune the search space.
finally our synthesis strategy is based on program sketching and program enumeration.
this approach has close parallels e.g.
and is extremely common in modern synthe sizers because it provides a simple way of splitting the searchspace.
our approach can also be seen a generate and validatestrategy using test cases as an oracle to evaluate migrationsuccess which is also widely used repair engines .vii.
c onclusions api selection and maintenance is an important and difficult task for software development.
to match evolving software developers often have to manually refactor apis which is a tedious and error prone job.
we proposed soar to takeadvantage of api documentation and error messages as a richsources of information intended for developers.
it uses naturallanguage processing and program synthesis to automaticallywrite refactored api calls.
it is particularly well suited for data science or deep learning library refactoring a prevalent use case in modern development where tool support is positionedto have particular impact.
soar collects information fromboth api documentation and error messages to generate logi cal constraints that can be used to limit the synthesizer searchspace.
unlike prior approaches to automatic api migration soar requires no training data and its output is guaranteed to compile and pass existing tests.
our empirical evaluationshows that soar can successfully refactor of ourbenchmarks for the deep learning domain with an averagetime of .
seconds and of the benchmark set fordata wrangling tasks with an average time of .
seconds.
a cknowledgments this work was partially supported under national science foundation grant nos.
ccf ccf 1750116and ccf and by portuguese national funds throughfct fundac ao para a ci encia e a tecnologia under phd grant sfrh bd and projects uidb dsaipa ai and project ani funded byfeder and fct.
all statements are those of the authors anddo not necessarily reflect the views of any funding agency.
r eferences c. jaspan and j. aldrich checking framework interactions with relationships in ecoop vol.
of lecture notes in computer science pp.
springer .
c. r. de souza d. redmiles l. t. cheng d. millen and j. patterson how a good software practice thwarts collaboration the multiple roles of apis in software development acm sigsoft software engineering notes vol.
no.
pp.
.
w. maalej and m. p. robillard patterns of knowledge in api reference documentation ieee transactions on software engineering vol.
no.
pp.
.
c. r. de souza and d. f. redmiles on the roles of apis in the coordination of collaborative software development computer supported cooperative work cscw vol.
no.
p. .
n. chapin j. e. hale k. m. khan j. f. ramil and w. g. tan types of software evolution and software maintenance journal of software maintenance and evolution research and practice vol.
no.
pp.
.
j. h. perkins automatically generating refactorings to support api evolution in proc.
workshop on program analysis for software tools and engineering pp.
acm .
m. kim t. zimmermann and n. nagappan a field study of refactoring challenges and benefits in proc.
acm sigsoft f oundations of software engineering p. acm .
m. kim t. zimmermann r. deline and a. begel data scientists in software teams state of the art and challenges ieee transactions on software engineering vol.
no.
pp.
.
m. abadi a. agarwal p. barham e. brevdo z. chen c. citro g. s. corrado a. davis j. dean m. devin et al.
tensorflow large scale machine learning on heterogeneous distributed systems arxiv preprint arxiv .
.
a. paszke s. gross s. chintala g. chanan e. yang z. devito z. lin a. desmaison l. antiga and a. lerer automatic differentiation in pytorch in proc.
annual conference on neural information processing systems .
s. v. d. walt s. c. colbert and g. varoquaux the numpy array a structure for efficient numerical computation computing in science engineering vol.
no.
pp.
.
h. zhong l. zhang t. xie and h. mei inferring resource specifications from natural language api documentation in proc.
international conference on automated software engineering pp.
ieee .
g. uddin and m. p. robillard how api documentation fails ieee software vol.
no.
pp.
.
b. hartmann d. macdougall j. brandt and s. r. klemmer what would other programmers do suggesting solutions to error messages inproc.
conference on human factors in computing pp.
acm .
s. gulwani o. polozov r. singh et al.
program synthesis f oundations and trends in programming languages vol.
no.
pp.
.
q. guo s. chen x. xie l. ma q. hu h. liu y .
liu j. zhao and x. li an empirical study towards characterizing deep learning development and deployment across different frameworks and platforms inproc.
international conference on automated software engineering pp.
ieee .
o. meqdadi and s. aljawarneh bug types fixed by api migration a case study in proc.
international conference on data science technology and applications pp.
acm .
i. savga m. rudolf and s. goetz comeback!
a refactoring based tool for binary compatible framework upgrade in proc.
international conference on software engineering pp.
acm .
a. t. nguyen h. a. nguyen t. t. nguyen and t. n. nguyen statistical learning approach for mining api usage mappings for code migration in proc.
international conference on automated software engineering pp.
acm .
n. d. q. bui y .
yu and l. jiang sar learning cross language api mappings with little knowledge in proc.
acm sigsoft f oundations of software engineering pp.
acm .
x. gu h. zhang d. zhang and s. kim deepam migrate apis with multi modal sequence to sequence learning in proc.
international joint conference on artificial intelligence c. sierra ed.
pp.
ijcai.org .
intro to autoencoders tensorflow core.
tutorials generative autoencoder august .
api documentation tensorflow core v2.
.
.
org api docs index.html august .
pytorch conv2d api documentation.
generated torch.nn.conv2d.html august .
g. salton and c. buckley term weighting approaches in automatic text retrieval information processing management vol.
no.
pp.
.
j. pennington r. socher and c. d. manning glove global vectors for word representation in proc.
conference on empirical methods in natural language processing pp.
acl .
m. f. porter snowball a language for stemming algorithms .
c. s. perone r. silveira and t. s. paula evaluation of sentence embeddings in downstream and linguistic probing tasks arxiv preprint arxiv .
.
s. arora y .
liang and t. ma a simple but tough to beat baseline for sentence embeddings in proc.
international conference on learning representations openreview.net .
common crawl.
august .
s. gulwani o. polozov and r. singh program synthesis f ound.
trends program.
lang.
vol.
no.
pp.
.
a. solar lezama the sketching approach to program synthesis in aplas vol.
of lecture notes in computer science pp.
springer .
p. orvalho m. terra neves m. ventura r. martins and v .
m. manquinho encodings for enumeration based program synthesis in proc.
international conference principles and practice of constraint programming vol.
of lecture notes in computer science pp.
springer .
r. martins j. chen y .
chen y .
feng and i. dillig trinity an extensible synthesis framework for data science proc.
vldb endow.
vol.
no.
pp.
.
t. mikolov i. sutskever k. chen g. s. corrado and j. dean distributed representations of words and phrases and their compositionality in proc.
annual conference on neural information processing systems pp.
.
m. a. hearst automatic acquisition of hyponyms from large text corpora in proc.
international conference on computational linguistics pp.
.
r. levy and g. andrew tregex and tsurgeon tools for querying and manipulating tree data structures.
in proc.
international conference on language resources and evaluation pp.
citeseer .
m. c. evans j. bhatia s. wadkar and t. d. breaux an evaluation of constituency based hyponymy extraction from privacy policies in proc.
international requirements engineering conference pp.
ieee .
a. sumida and k. torisawa hacking wikipedia for hyponymy relation acquisition in proc.
international joint conference on natural language processing pp.
the association for computer linguistics .
h. he the state of machine learning frameworks in the gradient .
tensorflow tutorial.
august .
tensorflow applications.
keras applications august .
tensorflow models.
august .
kaggle.
august .
y .
feng r. martins j. v .
geffen i. dillig and s. chaudhuri component based synthesis of table consolidation and transformation tasks from examples in proc.
acm sigplan conference on programming language design and implementation pp.
acm .
scrapy a fast and powerful scraping and web crawling framework.
august .
l. m. de moura and n. bj rner z3 an efficient smt solver in proc.
international conference on tools and algorithms for the construction and analysis of systems vol.
of lecture notes in computer science pp.
springer .
m. lamothe w. shang and t. h. chen a4 automatically assisting android api migrations using code examples arxiv preprint arxiv .
.
m. fazzini q. xin and a. orso apimigrator an api usage migration tool for android apps in proc.
international conference on software engineering ieee acm .
s. xu z. dong and n. meng meditor inference and application of api migration edits in proc.
international conference on program comprehension pp.
ieee acm .
h. zhong s. thummalapenta t. xie l. zhang and q. wang mining api mapping for language migration in proc.
international conference on software engineering pp.
acm .
a. desai s. gulwani v .
hingorani n. jain a. karkare m. marron s. r and s. roy program synthesis using natural language in proc.
international conference on software engineering pp.
acm .
n. yaghmazadeh y .
wang i. dillig and t. dillig sqlizer query synthesis from natural language proc.
acm programming languages vol.
pp.
.
k. shi j. steinhardt and p. liang frangel component based synthesis with control structures proc.
acm programming languages vol.
pp.
.
v .
raychev m. sch afer m. sridharan and m. t. vechev refactoring with synthesis in proc.
acm sigplan object oriented programming systems languages applications pp.
acm .
q. chen x. wang x. ye g. durrett and i. dillig multi modal synthesis of regular expressions in proc.
acm sigplan conference on programming language design and implementation pp.
acm .
y .
chen r. martins and y .
feng maximal multi layer specification synthesis in proc.
acm sigsoft f oundations of software engineering pp.
acm .
z. guo m. james d. justo j. zhou z. wang r. jhala and n. polikarpova program synthesis by type guided abstraction refinement proc.
acm programming languages vol.
pp.
.
y .
feng r. martins y .
wang i. dillig and t. w. reps componentbased synthesis for complex apis in proc.
acm sigplan sigact symposium on principles of programming languages pp.
acm .
c. wang a. cheung and r. bod k synthesizing highly expressive sql queries from input output examples in proc.
acm sigplan conference on programming language design and implementation a. cohen and m. t. vechev eds.
pp.
acm .
c. le goues m. pradel and a. roychoudhury automated program repair commun.
acm vol.
no.
pp.
.