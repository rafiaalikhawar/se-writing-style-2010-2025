subdomain based generality aware debloating qi xin georgia institute of technology qxin6 gatech.edumyeongsoo kim georgia institute of technology wardballoon gatech.edu qirun zhang georgia institute of technology qrzhang gatech.edualessandro orso georgia institute of technology orso cc.gatech.edu abstract programs are becoming increasingly complex and typically contain an abundance of unneeded features which can degrade the performance and security of the software.
recently we have witnessed a surge of debloating techniques that aim to create a reduced version of a program by eliminating the unneeded features therein.
to debloat a program most existing techniques require a usage profile of the program typically provided as a set of inputs i. unfortunately these techniques tend to generate a reduced program that is overfitted toiand thus fails to behave correctly for other inputs.
to address this limitation we propose domgad which has two main advantages over existing debloating approaches.
first it produces a reduced program that is guaranteed to work for subdomains rather than for specific inputs.
second it uses stochastic optimization to generate reduced programs that achieve a close to optimal tradeoff between reduction and generality i.e.
the extent to which the reduced program is able to correctly handle inputs in its whole domain .
to assess the effectiveness of domgad we applied our approach to a benchmark of ten unix utility programs.
our results are promising as they show that domgad could produce debloated programs that achieve on average code reduction and generality.
our results also show that domgad performs well when compared with two state of the art debloating approaches.
ccs concepts software and its engineering software maintenance tools .
keywords debloating generality aware stochastic optimization acm reference format qi xin myeongsoo kim qirun zhang and alessandro orso.
.
subdomainbased generality aware debloating.
in 35th ieee acm international conference on automated software engineering ase september virtual event australia.
acm new york ny usa pages.
https permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn .
.
.
.
introduction today s programs are complex and provide an abundance of features .
typically however only a small fraction of these features are commonly accessed by users and the presence of unnecessary features can harm program performance waste power and introduce security issues .
for this reason debloating techniques which aim to remove unneeded features from a program and create a reduced version of it are becoming increasingly popular.
given a program pto be reduced existing debloating techniques e.g.
usually require a usage profile ofp typically provided as a set of inputs i. these techniques tend to remove as much code in pas possible and generate a minimal program pdeb that behaves correctly for inputs in i. because the resulting program is only guaranteed to work for i it is likely to be overfitted to iand to fail for other inputs.
we argue that a program that is guaranteed to only work for specific inputs is not generally usable as it is rarely the case that one can provide a completely accurate usage profile.
to address this limitation of existing approaches we propose domgad a novel debloating approach that has two main advantages over the state of the art.
first it produces reduced programs that are guaranteed to handle subdomains of inputs rather than specific inputs that is domgad produces programs that behave correctly for every possible input that belongs to these subdomains.
moreover for any input that does not belong to a handled subdomain the reduced programs would block the execution to avoid unexpected behaviors e.g.
crashes so as to achieve enhanced robustness.
in contrast because reduced programs produced by an input based approach are only guaranteed to behave correctly for specific inputs the only way they have to avoid unexpected behaviors is to block the execution for anyunknown input.
second unlike existing approaches that take reduction as the only goal for debloating domgad also accounts for generality the extent to which a reduced program could correctly handle inputs in its whole domain.
because there is a tension between reducing the size of a program and preserving its generality domgad aims to strike a balance between these two competing needs.
in our approach we use a path to characterize a subdomain of programp and use the notation d to indicate all the inputs ofpthat belong to that subdomain i.e.
all the inputs that follow the same path .
in order to produce a reduced program p that handles a subdomain d and behaves correctly for all the inputs in it domgad conservatively includes in p all the code executed along path .
the overall goal of domgad is to generate a reduced programp that handles the set of subdomains of pthat achieves 35th ieee acm international conference on automated software engineering ase ase september virtual event australia qi xin myeongsoo kim qirun zhang and alessandro orso the best tradeoff between reduction and generality.
intuitively assuming the inputs are uniformly distributed across the program domain this would correspond to producing a program that is as small as possible while being able to handle as many inputs as possible in the domain.
to achieve this goal we formulate debloating as an optimization problem.
specifically given a reduced program p forp we i quantify its reduction rand generality g and ii define an objective function that computes an objective score based on randg so as to make the tradeoffs between those two values explicit.
we then try to identify among all possible reduced programs p in the search space the one with the highest objective score pdeb .
while quantifying the reduction achieved by p by measuring how much code has been removed from pis relatively straightforward quantifying its generality is extremely challenging.
conceptually one could identify every possible path inp and exactly count the number of inputs that follow that path using model counting .
unfortunately however this is typically infeasible as the number of paths within p is generally unbounded and model counting is complex and has conceptual limitations .
we therefore propose a practical technique that is based on the key insight that it is possible to model the underlying input distribution of p s domain and leverage a sampling based approach.
specifically domgad i draws samples from the input distribution trying to identify a finite set of paths that can cover a significant fraction of inputs in the entire domain i.e.
it makes sense to focus on when debloating p and ii estimates the size of the subdomain corresponding to each path based on the number of sampled inputs that result in that path.
although our sampling based approach can only compute an approximation of the generality of a givenp it is possible to bound the error of the computed solution.
therefore given enough samples our approach can yield results with an estimation error being arbitrarily small.
our overall debloating process works as follows.
domgad takes as inputs a program pand an input sampler isthat models the inputs distribution in p s domain and generates input samples.
given these inputs domgad performs three main steps path identification path quantification and stochastic optimization.
in the first step domgad invokesisto generate input samples and identify a finite set of paths that cover with high confidence a fraction of inputs in the domain whose combined probability is no less than a given lower bound.
in the second step domgad invokesisagain to generate additional input samples which it uses to estimate for each the size of the subdomain characterized by .
based on these estimates domgad computes for any reduced programp it generates that preserves a subset of paths of the generality of p .
in this step domgad also computes the reduction forp by comparing its size and attack surface measured in terms of rop gadgets with those of the original program p. finally in the third step domgad applies an mcmc based approach to perform stochastic optimization with the goal of producing a debloated program pdebthat achieves an optimal tradeoff between reduction and generality.
to assess the usefulness of domgad we implemented the technique in a prototype tool and applied it to a benchmark of ten unix utility programs used in previous work .
we compared domgad with debop a generality aware debloating techniquetable paths identified for program chown.
path input pathprob uid sudo sf .
h uid uid f .
h uid uid sf .
uid uid d d d f .
uid uid f .
r uid sudo f .
uid user id sf symbolic file f file d directory.
that we developed in previous work and chisel a state ofthe art debloating technique that focuses exclusively on reduction.
our results are promising.
domgad was able to produce a reduced program that achieves on average code reduction and generality.
moreover domgad outperformed debop in terms of generating programs with better tradeoffs between reduction and generality.
finally domgad was able to achieve reduction results comparable to those of chisel which does not consider generality.
the main contributions of this paper are a new subdomain based generality aware debloating technique domgad that uses stochastic optimization to generate debloated programs that achieve good tradeoffs between reduction and generality.
an empirical evaluation that shows the effectiveness of our technique and confirms that it is possible to perform generality aware debloating.
a prototype implementation of domgad that is publicly available together with our experiment infrastructure see illustrative example in this section we show as an example how domgad debloats chown v. .
a unix utility that changes the user and group ownership of a file.
chown is one of the benchmark programs we used to evaluate domgad see section .
.
to apply domgad on chown we developed an input sampler based on the usage profile i.e.
set of inputs associated with the program and provided at see section .
.
for more details .
to debloat chown p domgad first uses the input sampler isto identify a set of paths that cover with high confidence a fraction of inputs in the domain whose combined probability is no less than a given lower bound c .
as explained in section .
.
this implies that the execution of pbased on a random input would yield a path in with a probability.
for chown a significant fraction of inputs follow a small number of paths so the result of this step is the selection of only six paths shown in table together with the inputs used to identify them.
in the second step section .
domgad uses again sampling to compute the path probability p for each which it uses to estimates the size of the subdomain characterized by .
for chown domgad generates a total of n input samples a number of samples that allows domgad to have an estimation error bound within a small range .
and with a high statistical confidence .
.
then for each domgad counts the number nof sampled inputs that exercise and computes p asn n. the last column of table shows the resulting path probability for each path in our example.
225subdomain based generality aware debloating ase september virtual event australia a reduced program p produced by domgad preserves a subset of paths .domgad computes the value of reduction rfor p in terms of size measured as number of statements and attack surface measured as number of rop gadgets .
conversely domgad computes the value of generality gforp as the sum of the path probabilities for all paths in .
as an example the generality of a reduced program that preserves paths nos.
and is0.
.
.
.
givenrandg domgad uses an objective function defined as kg r kg g wherekg is a weight.
in the third step defined in section .
domgad uses an mcmcbased approach to sample a number of reduced programs and identifypdebwith the highest objective score.
for chown using kg .
domgad produces apdebthat preserves five of the six paths all but path no.
and has r .63andg .
that is pdebcontains of the code in the original program and covers of its domain according to the distribution modeled by is.
changing the value of kgallows domgad to explore different tradeoffs between reduction and generality.
using kg .
for instance which gives more weight to generality domgad produces pdebthat preserves all the six paths achieving lower reduction r .
but higher generality g .
preliminary definitions .
subdomain and subdomain quantification given a program p its entire input domain d and a path ofp we defined as the subdomain of inputs that exercise .
we assume that the inputs of pindfollow a probability distribution with probability density function d. for an input i d i measures the likelihood of the occurrence of i. by definition i dd i .
we use path probability p to quantify the size of d and definep as the sum of the density values for all inputs in d .
more formally we have p i d d i .
assuming inputs in dare uniformly distributed p can be simplified asp d d where d is the number of inputs that belong tod and dis the total number of inputs.
.
reduction we measure the reduction for a program in terms of its size and attack surface.
given a program pand its reduced version p we define the size reduction sred as sred p p size p size p size p wheresize measures the size of a program.
similar to we definesize p as the number of statements contained in p. we define the attack surface reduction ared as ared p p attksurf p attksurf p attksurf p whereattksurf measures the attack surface of a program.
similar to we define attksurf p as the number of rop returnoriented programming gadgets inp s executable.
an rop gadget is a sequence of machine instructions that ends with a return instruction and is relevant because an attacker could take advantage of a vulnerability in the program e.g.
a buffer overflow to overwrite a gadget s return address hijack the control flow and execute malicious code .
finally we define the overall reduction redfor a program as the weighted sum of sred andared red p p kr sred p p kr ared p p wherekr is the weight.
.
generality given a reduced program p we define generality as the measure of its ability to correctly handle inputs in d. we say that p can handle an inputiifp can produce the same output as pfori.
we compute the generality genforp as the sum of path probabilities for the paths preserved in p formally defined as gen p s s p p where is a set of paths s is the set of statements executed along path ands p is the set of statements contained in p .
in theory should include all paths of p. to make the approach practical however in the first step of our technique we select a finite subset of paths that cover a fraction of inputs in the domain whose combined probability is no less than a given lower bound.
.
objective function to quantify the tradeoff between reduction redand generality gen we define an objective function othat computes an objective score as the weighted sum of redandgen formally defined as o p p kg red p p kg gen p wherekg is the weight applied to redandgen.
.
subdomain based debloating given a program p a set of paths and the two weights krandkg the goal of subdomain based debloating is to produce a reduced programpdebthat preserves a subset of paths and maximizes o. formally we have pdeb arg max o p compose p wherecompose p is the reduced program that preserves all the paths in .
note that one can use krandkgto obtain reduced programs with different tradeoffs between sred andared and between redandgen.
our technique domgad figure provides an overview of domgad s debloating process.
we first discuss the input sampler used by domgad and then present the three steps of the technique.
.
input sampler domgad relies on an input sampler to generate sampled inputs for path identification and quantification.
an input sampler isis a probabilistic program that uses a set of pre defined sampling functions to generate random values.
to be used within domgad anismust provide the following four functions getuniformint intm intn returns a random integer betweenmandn selected from a uniform distribution.
226ase september virtual event australia qi xin myeongsoo kim qirun zhang and alessandro orso figure high level overview of domgad.
getuniformreal doublem doublen returns a random real number between mandn selected from a uniform distribution.
getnorm doublemean doublesdev returns a random real number selected from a normal distribution defined by the given mean mean and standard deviation sdev .
getbinomial intn doublep returns a random integer that represents the number of trials for which heads occur when flipping a biased coin.
the total number of trials is n and the bias of the coin is determined by p. although these functions do not directly produce boolean character or string values it is possible to generate such values using these functions.
for example to get a random character between a and z we can call getuniformint to generate an integer between and and convert it to a character.
domgad relies onisto obtain a sufficient set of sampled inputs for effective subdomain identification and quantification.
in this first instance of our approach we assume that the user is familiar with the usage of the program and can provide a reasonable sampler.
as discussed in section in future work we plan to investigate automated approaches for synthesizing an input sampler possibly based on a provided usage profile.
.
path identification domgad performs this step to identify a finite set of paths that cover with high confidence a fraction of inputs in p s domain whose combined probability is no less than a given domain coverage lower bound c .
in other words the sum of path probabilities for the paths in should be no smaller than c p c. to identify domgad performs a statistical simulation based approach that is analogous to the one used in and is described in algorithm .
the algorithm starts by computing parameter k which it uses to decide when to terminate the computation and by initializing the set of paths pito the empty set lines .
it then enters its main loop lines and in each iteration of the loop it generates sample input iand computes the path piexercised by i lines .
if the path is already in pi the algorithm increments counter count line .
otherwise it resets count to0and addspitopi lines .
the loop terminates if no new paths are identified for ksubsequent iterations.
as explained in a suitable kcan be computed based on parameterscandbthrough a bayesian factor test .
specifically kcan be computed as k l logb logcm .
by tuning candb domgadalgorithm path identification.
input p original program input is input sampler input c domain coverage lower bound input b confidence parameter output pi a list of paths k computek c b pi count whilecount kdo i is.getonesample pi getpath p i ifpi pithen count count else count pi pi pi returnpi could generate that achieves a higher coverage with higher confidence .
for example given b 100andc .
k .
this means that if domgad does not identify new paths for subsequent iterations the resulting set of paths would cover with high confidence a set of inputs in the domain with a combined probability that is at least .
.
.
path quantification in this step domgad performs sampling to estimate the path probability for each path in .
for a given an input sample i drawn from the underlying distribution either i exercises or ii does not exercise .
therefore a sample can be considered the instance of a random variable xifollowing the bernoulli distributionxi bernoulli p wherep is the path probability to be estimated.
let x x1 x2 xnbe the random variable representing the sum of nindependent samples xis known to follow the binomial distribution .
we define p ase x x n the expectation of x. to compute p the estimation of p domgad performs a sequence of nbernoulli trials to get nsampled inputs.
among these inputs domgad counts how many exercise n and computes p n n. domgad performs acceptance sampling to bound errors.
to do this we define the following error bounding constraint pr p .
this constraint contains two error bounding parameters an accuracy parameter and a confidence parameter and specifies that the estimated p will deviate from the real p by at most with probability .
by tuning and to small values p gets closer top with high confidence.
given specific and we use the two sided chernoff bound to compute a lower bound nlb for the sampling number nasnlb 2ln2 .
this means that if 227subdomain based generality aware debloating ase september virtual event australia algorithm path probability estimation.
input p original program input is input sampler input pi set of previously identified paths input accuracy parameter for error bounding input confidence parameter for error bounding output pimap a map that maps a path to its estimated path probability nlb getsamplenum pimap forpi pido pimap.set pi i whilei nlbdo in is.getonesample pi getpath p in ifpi pithen count pimap.get pi pimap.set pi count i i forpi pido count pimap.get pi pimap.set pi count nlb returnpimap we usenlbsamples to estimate p the estimated p will satisfy the error bounding constraint specified by and .
given program p the input sampler is the set of paths pipreviously identified and the error bounding parameters and domgad uses algorithm to compute path probability p pi for eachpi pi.
the algorithm generates pimap which maps each pathpito its estimated path probability.
the algorithm starts by computing the number of input samples nlbbased on and line and initializing pimap by setting a key for each pi piand mapping it to a value lines .
it then iteratively generates a total ofnlbsamples and updates pimap by counting the number of samples each path covers lines .
a path picovers a sample in if runningpwithinexercisespi.
finally the algorithm computes the path probability for each based on its count and updates pimap lines .
note that domgad does not need to generate an independent set of nlbsamples to estimate path probability for eachpi pi.
this is because paths are disjoint that is a sampled input exercises at most one path.
therefore the random variables representing each path are independent.
.
stochastic optimization because there is a tension between reducing the size of a program and preserving its generality we formulate debloating as an optimization problem.
our goal is to generate an optimally reduced program that achieves the best tradeoff between reduction and generality.
since it is generally infeasible to enumerate every reduced program in the search space given its exponential size domgad performs stochastic search using an mcmc based approach to find a close to optimal solution.
we first summarize the mcmc approach we use to make the paper self contained and then present our stochastic optimization algorithm.
.
.
mcmc and metropolis hastings algorithm.
an mcmc based approach is a sampling based approach that is commonly used for estimating properties such as mean and variance of a given probability distribution whose probability density function is known .
the approach performs a sequential process to draw samples from the distribution where the generation of a new sample only depends on the previous sample.algorithm simplified metropolis hastings algorithm.
input f probability density function input n number of samples to be generated output s a set of samples curr s initialize a sample n whilen ndo new s mutatecurr sby adding random noise ratio f new s f curr s rn get a uniform random number rn ifrn ratio then accept the new sample s s new s curr s new s n n returns an algorithm commonly used for performing mcmc based sampling is the metropolis hastings mh algorithm which generates new samples through mutation by adding random noise to the current sample.
a simplified version of the mh algorithm is shown as algorithm .
it is simplified because we assume that the mutation used for generating a new sample is symmetric i.e.
the probability of generating a sample sjbased onsiis the same as that of generatingsibased onsj .
as we will show in section .
.
domgad uses symmetric mutations to generate samples of reduced programs.
the algorithm takes as input a probability distribution defined by a probability density function fand a maximum number of samples to be generated n. it starts by initializing the current sample curr s line and setting the current number of samples nto0 line .
next it iteratively generates new samples lines .
in each iteration it generates a new sample new sby adding random noise tocurr s. to decide whether to accept new sor not it computes a density ratio ratio and generates a random number rn lines .
if rnis smaller than ratio the algorithm accepts new s. this implies that whennew sis of higher density value the algorithm always acceptsnew s. otherwise when new shas a lower density it can still acceptnew sbased on its relative density drop determined byratio .
intuitively by accepting samples this way the algorithm is able to collect more samples from higher density regions of the distribution while still occasionally visiting and collecting samples from lower density regions.
this explains why the mh algorithm can generate samples that effectively approximate the given distribution.
when a new sample new sis accepted the algorithm adds it to the sample set s updatescurr s and increases n lines .
.
.
domgad s stochastic approach.
domgad uses the mh algorithm to perform stochastic optimization and produce a reduced program with the highest objective score.
following existing approaches we define a program distribution whose probability density function fis defined based on the objective function o. specifically for a program pand its reduced version p we define the probability density function f p p as f p p zexp k o p p wherekis a constant and zis the normalizing factor that ensures that the sum of density values for all programs is .
bit vector representation.
a reduced program p in the search space preserves a subset of paths previously identified by domgad.
we represent this using a bit vector.
specifically a bitvectorbitvec forp indicates which paths are preserved in p wherep preserves if it contains all the statements executed along .
a bitb inbitvec represents a path .
ifb is1 this 228ase september virtual event australia qi xin myeongsoo kim qirun zhang and alessandro orso if x s0 else s1 if y s2 else s3 pi a x s1 y s3 pi b x s0 y s2 pi c x s1 y s2 figure an example of program composition.
means that p preserves and thus is selected to compose p .
conversely a value 0forb indicates that is not part of p .
it is worth noting that p may preserve even if is not explicitly used to compose p if the code added to preserve other paths happens to include the code for .
figure illustrates this situation with an example if the programs on the left preserved the two paths pi aandpi b it would also accidentally preserve pathpi c.domgad accounts for these accidentally preserved paths when computing the generality of a reduced program.
sample mutation.
domgad mutatesp to generate a new samplep by randomly selecting a bit b inp s bit vector and flipping it.
by so domgad adds and removes entries from the set of preserved paths used to compose p .
this mutation is symmetric as each path has the same chance of being selected or not selected .
domgad s algorithm.
algorithm describes domgad s stochastic optimization approach.
the algorithm takes as input a programp a set of previously identified paths pi a map pimap that maps each path pi pito its path probability a timeout value timeout krandkg used to compute the objective score and k used to compute the density score.
given p and a reduced program p we define the density score d p p as f p p z which is equal to exp k o p p .domgad does not have to compute the density value and can instead use the density score to decide the acceptance of a new sample.
this is because when computing density ratio the normalizing factor zis a common factor and can be simplified.
the algorithm starts by generating a program with no paths line that is a program that has an empty body for each defined function.
it then computes scores for this program lines and initializescurrdscore bestdscore andbestsample which represent the current and highest density scores and the sample holding the highest score lines .
the algorithm also converts piinto a listpi list obtains its size and creates a bit vector bitvec with all bits set to lines .
the algorithm then generates samples iteratively lines .
in each iteration it randomly flips a bit in bitvec lines computes the set sof statements executed along the preserved paths lines and generates a reduced program p i.e.
a sample accordingly line .
next the algorithm computes for the generated program the reduction red line generality gen lines and density score dscore line values.
note that for computinggen it would be insufficient to only consider paths explicitly selected for composing p .
as we mentioned above the algorithm also checks for paths not selected yet accidentally preserved in p .
after generating a new sample the algorithm computes the density ratio to decide whether to accept the new sample line .
if the sample is accepted the algorithm updates currdscore and if needed bestdscore andbestsample lines .
otherwise it reverts the bit flipped line .
finally it returns bestsample the sample with the highest density and objective scores line .algorithm domgad s stochastic algorithm.
input p original program input pi set of identified paths input pimap path probability map input timeout timeout value in hours input kr weight for computing reduction input kg weight for computing objective score input k constant for computing density value output bestsample resulting debloated program p a program with no path preserved red getreductionscore p p kr gen dscore getdensityscore red gen k kg currdscore dscore bestdscore dscore bestsample p pi list tolist pi pi list size pi list.size bitvec new int forinti i pi list size i do bitvec do idx getrandomint pi list size idx pi list size bitvec bitvec flip a bit s a set of statements forinti i pi list size i do ifbitvec 1then s s getstmts pi list.get i p getreducedprog p s red getreductionscore p p kr gen forinti i pi list size i do preserved false ifbitvec 1then preserved true else s getstmts pi list.get i ifissubsetequal s s then preserved true ifpreserved then gen pimap.get pi list.get i dscore getdensityscore red gen k kg accept false ifrandom dscore currdscore then random accept true ifaccept then currdscore dscore ifdscore bestdscore then bestsample p bestdscore dscore else bitvec bitvec revert the bit whiletimeout is reached returnbestsample evaluation to assess the usefulness of domgad we implemented it in a prototype tool and applied it to a benchmark of ten programs.
we compared domgad to two baselines debop our previous approach that also performs optimization based debloating and chisel a state of the art reduction oriented technique.
specifically we investigated four research questions rq1 how does domgad perform in terms of path identification and quantification?
rq2 how does domgad perform in terms of stochastic optimization?
rq3 how does domgad compare with debop in terms of the reduction generality tradeoffs achieved by the debloated programs they generate?
rq4 how does domgad compare with chisel in terms of size and attack surface reduction?
229subdomain based generality aware debloating ase september virtual event australia table benchmark programs used in our evaluation.
program loc func stmt bzip2 .
.
chown .
date .
grep .
gzip .
.
mkdir .
.
rm .
sort .
tar .
uniq .
.
implementation details we developer our prototype tool using a combination of c java and bash scripts.
the tool takes as inputs a program an input sampler and a set of parameters c b timeout kr kg and k and generates a debloated program.
to record paths and the statements covered in that path our prototype uses the llvm cov tool .
we relied on clang v. .
.
for building the abstract syntax tree ast of a program and used the ast to record the starting and ending positions of the functions and statements in the program.
the tool produces a reduced program based on these recorded positions and on the coverage report generated by llvmcov.
to measure the number of statements in a program our tool leverages a utility provided by chisel .
finally to compute attack surface reduction the tool compiles the program using clang and measures the number of rop gadgets in the resulting executable using the ropgadget tool .
.
experiment setup .
.
benchmark programs.
as benchmark we used the ten unix utility programs the all in one file versions provided in the benchmark repository .
we selected these programs because they have been extensively used for evaluating debloating techniques in related work .
table shows the statistics of these programs in terms of size number of functions and number of statements.
.
.
sampler programs.
for each benchmark program we created an input sampler based on its usage profile that is based on the set of inputs associated with the program and provided in .
the sampler reflects how the benchmark program is used according to its usage profile.
specifically to generate an input the sampler randomly selects an option used in the usage profile where an option could be an empty option a single option e.g.
c or a combination of individual options e.g.
r f .
we computed the probability of selecting an option based on its usage frequency.
for example if an option c was used in seven out of the ten inputs within a usage profile the selection probability of the option would have been .
.
these options or the program in general may require values or inputs of a specific type to operate and the sampler must be able to provide these values and inputs.
when a numeric or enumeration value is required the sampler generates a random value from a pre defined range of values.
for example since a permission value is needed for the m option for mkdir .
.
the sampler choosesa random value between 000and .
similarly in the case of program date .
the sampler generates a random date or time value.
when a text file is needed the sampler produces a random file that contains nlines where nis a random number between 1and100 and each line contains mascii characters where m is also a random number between 1and100.
when a compressed file is needed for bzip2 .
.
gzip .
.
and tar .
the sampler generates a random text file and then invokes the corresponding utility to generate its compressed version.
finally if a directory is needed the sampler generates a directory that mirrors the structure of directories in the usage profile but contains random files.
in addition some programs require inputs with specific characteristics and relations among them.
grep for instance is a unix utility for identifying patterns within files.
the sampler we developed for grep .
does not generate a random query pattern and uses instead patterns that appear in the provided usage profile.
as the target file for grep .
the sampler first generates a random text file.
then depending on whether the query can be found in the original input or not the sampler will either insert the query in the target file or remove it if present.
in summary we carefully designed the sampler programs so as to make sure they simulated how the benchmark programs are used in their usage profiles.
we provide a detailed description of the sampler programs at .
.
.
parameters.
domgad uses a set of parameters for debloating.
for path identification we set the domain coverage lower bound toc .
and the confidence parameter bto100 as suggested in .
with these settings domgad would only terminate if it does not identify any new paths for k 90subsequent iterations.
we set as the maximum number of iterations for path identification.
for path quantification we set accuracy parameter to0.
and confidence parameter to0.
.
with these settings domgad must sample nlb inputs to satisfy the error bounding constraint.
it is worth noting that there is a tradeoff between accuracy and efficiency for both path identification and quantification.
one could decrease the value of cto sample a smaller number of inputs needed for path identification and vice versa.
similarly one could increase the values of and to sample less inputs to satisfy the error bounding constraint for path quantification and vice versa.
with the current settings it took domgad .
hours to finish path identification and quantification for all programs.
we did not investigate how sensitive are the debloating results to the values of c and but we plan to do it in future work.
when performing stochastic optimization we used different values of the two weights used for computing the objective score krandkg .
specifically to study how kgaffects the debloating result we set krto0.5and experimented with five values for kg .
.
.
.
and .
.
similarly to study how kraffects the results we setkgto0.5and experimented with three values for kr .
.
and .
.
for each benchmark program we therefore ran domgad for a total of seven trials.
in each trial domgad produced a debloated program using a timeout of six hours.
this resulted in a total of hours of machine time to finish all trials for all programs.
to compute a density score we followed the approach used in and setkto50.
230ase september virtual event australia qi xin myeongsoo kim qirun zhang and alessandro orso .
.
setup for debop.
we compared domgad with debop using its implementation available at .
unlike domgad debop is an input based technique and requires a program and a set of inputs.
to perform a fair comparison we provided debop with a programp that preserves all the paths identified by domgad asdomgad would only generate reduced versions of p .domgad leverages a set of sampled inputs ito quantify each path in and performs stochastic optimization based on the quantification result.
for comparison we provided debop with a set of inputs i ithat only contains inputs that exercise paths in .
we did not provide debop withi as there might be inputs in ithat execute paths that are not in and are not actually used by domgad for quantification.
for each input debop needs an oracle to decide whether a programp executes correctly for that input.
therefore for each sampleriswe developed we also wrote a program that automatically generates an oracle for every possible input that isgenerates.
the oracle works by comparing the output of p against that of its original program p. specifically the oracle checks a program s exit value and each output produced by the program including files and directories.
specifically for bzip2 .
.
gzip .
.
and tar .
if the program generates a text file the oracle directly checks its content.
otherwise if the generated file is compressed the oracle invokes the corresponding utility to decompress it and then checks the decompressed files.
finally if a directory is generated the oracle checks the files it contains.
for chown .
the oracle checks the ownership of files directories.
for rm .
the oracle checks the existence of files directories.
for mkdir .
.
in addition to checking the existence of the generated directories the oracle also checks their permissions.
debop assigns to a program that executes correctly for all the provided inputs generality .
this is problematic for comparison as such a program would not be considered able to handle all inputs in the whole domain by domgad.
to address this problem we slightly modified the implementation of debop so that it takes as input a generality factor gf .
then we provided debop with a generality factor that is computed as the generality of p the sum of the path probabilities for all the paths in .
in this way for a programp the generality score computed by debop becomes the product of i gfand ii the number of inputs for which p executes correctly over all provided inputs.
we also configured debop so that it quantifies reduction in the same way domgad does.
we applied debop to the benchmark programs using the same parameter values for kr kg andkthatdomgad uses the same number of trials and the same timeout per trial.
.
.
setup for chisel.
chisel is also input based and thus requires a set of inputs for debloating.
similar to debop for each benchmark program we provided chisel with program p .
because chisel is not an optimization based technique we did not provide the set of inputs i thatdebop uses.
instead we logged the exact set of paths preserved in the debloated program generated bydomgad and obtained the set of inputs i iused for quantifying paths in .
becausei corresponds to the set of inputs that can be correctly handled by the programs debloated by domgad we provided chisel withi .
for each input in i we generated an oracle using the same approach described in section .
.
.
for eachtable results of path identification and quantification.
programpath identification path quantification paths maxk time hour inputs pathprob time hour bzip2 .
.
.
.
.
chown .
.
.
date .
.
.
.
grep .
.
.
.
gzip .
.
.
.
.
mkdir .
.
.
.
.
rm .
.
.
.
sort .
.
.
.
tar .
.
.
.
uniq .
.
.
.
table reduction red generality gen objective score oscore size reduction sizered and attack surface reduction attksurfred of the debloated programs generated by domgad anddebop averaged over all programs .
kr kgred gen oscore domgad debop domgad debop domgad debop .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
kr kgsizered attksurfred red domgad debop domgad debop domgad debop .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table size reduction sizered attack surface reduction attksurfred and reduction red of the debloated programs generated by domgad andchisel averaged over all programs .
kr kgsizered attksurfred red domgad chisel domgad chisel domgad chisel .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
trial performed by domgad we obtained the corresponding program and inputs and ran chisel on those using the same timeout we used for domgad.
.
.
experiment environment.
we ran all of the experiments on a machine with a 260gb ram amd opteron .4ghz processors and running ubuntu .
.
.
results .
.
rq1 domgad s performance in terms of path identification and quantification.
table presents a summary of domgad s path identification and quantification results.
from left to right the table shows the benchmark program program the number of paths identified paths the largest kachieved during path identification maxk this is the largest number of subsequent iterations for which no new paths were identified the time taken for path identification time hour th column the number of sampled inputs used for path quantification inputs the sum of path probabilities for the paths identified pathprob and the time taken for path quantification time hour last column .
the results show that for all programs but grep .
domgad was able to identify a set of paths that achieved maxk thus satisfying the domain coverage constraint specified by the 231subdomain based generality aware debloating ase september virtual event australia .
.
.
.
.
.
.
.
.
702bzip2 .
.
.
.
.
.
.
.
.
5chown .
.
.
.
.
.
.
.
.
390date .
.
.
.
.
.
.
.
.
1269grep .
.
.
.
.
.
364gzip .
.
.
.
.
.
.
.
.
.
.
351mkdir .
.
.
.
.
.
.
.
.
.
243rm .
.
.
.
.
.
270sort .
.
.
.
.
.
.
.
.
012345678910111213141516171819tar .
.
.
.
.
.
.
.
.
.
0123456789101112131415161718192021222324252627282930uniq .
figur e path probability.
lower bound c .95and the confidence parameter b .
this provides initial evidence that our approach is feasible and that it is often possible to identify a finite number of paths to achieve a high coverage of the domain as modeled by the input sampler .
column pathprob shows the sum of the probabilities for the paths in .
for all programs this sum is higher than .
.
for grep .
in particular although set does not satisfy the domain coverage constraint the estimated path probability reaches .
which is only slightly lower than .
.
for certain programs e.g.
bzip2 .
.
although satisfies the domain coverage constraint the estimated probability is still lower than .
.
this can happen as the path probability for is estimated and the sum could therefore be either slightly lower or slightly higher than .
.
nevertheless the average path probability over all benchmark programs is .
which is fairly close to .95and which indicates that domgad s quantification is effective.
figure presents the distribution of path probabilities for the paths identified by domgad.
for many of the programs considered we can observe a small number of hot paths whose probabilities are much higher than those of other paths.
this implies that it should be possible to produce by preserving a small number of suitable paths debloated programs that achieve good tradeoffs between reduction and generality.
.
.
rq2 domgad s performance in terms of stochastic optimization.
table shows a summary of domgad s stochastic optimization results.
full results are available at on our companion website at the table shows the scores of the debloated programs generated by domgad for differentkrandkgvalues averaged over all programs.
specifically forkr .
andkgranging from .1to0.
the table shows from left to right reduction red generality gen and objective score oscore for the programs generated by domgad and debop .
similarly forkg .5andkrranging from .25to0.
the table shows from left to right size reduction sizered attack surface reduction attksurfred and reduction red for the programs.
232ase september virtual event australia qi xin myeongsoo kim qirun zhang and alessandro orso whenkrandkgare both .
i.e.
equal weights for size reduction and attack surface reduction and equal weights for reduction and generality domgad produced a debloated program that achieves on average reduction size reduction and attack surface reduction and generality.
this result indicates that domgad is able to generate by preserving paths that achieve a high domain coverage a reduced program that is significantly smaller in size and attack surface yet is highly general.
withkr .5andkggoing from .1to0.
i.e.
with increasingly higher weight given to generality and increasingly lower weight given to reduction domgad produced debloated programs with increasing generality from .06to0.
and decreasing reduction from .82to0.
.
this confirms that domgad is indeed able to explore the space of solutions and produce debloated programs with different tradeoffs.
whenkg .
domgad achieves a high generality .
but whenkgchanges from .5to0.
the generality only increases slightly .
.
whenkg .
we observe that for seven benchmark programs all but date .
grep .
and gzip .
.
the debloated programs preserve all the paths identified.
the reason for this result is that domgad in its first step successfully identified a small set of paths that achieve high domain coverage.
even a reduced program that preserves all these paths is still much smaller than the original program achieving a .49reduction on average.
therefore when reduction is not heavily weighed domgad tends to produce a reduced program that preserves most of the paths in .
whenkgis small i.e.
reduction is heavily weighed domgad tends to produce a debloated program that preserves only a few hot paths so as to reduce code as much as possible.
as an example whenkg .
domgad produced a debloated program for mkdir that preserves only three paths that have high probability i.e.
nos.
and in figure achieving a reduction of .67and a generality of .
.
considering table we can observe that when kgis0.5and krranges from .25to0.
domgad does not indeed produce debloated programs with different tradeoffs between size reduction and attack surface reduction.
as we previously discussed when kgis not extremely small domgad tends to produce a program that preserves all the paths and therefore does not explore different reduction generality tradeoffs.
in future work we will investigate how these tradeoffs vary using different values of kg possibly smaller than .
.
.
.
rq3 comparison between domgad anddebop.
table also presents debop s results.
as the table shows debop produced debloated programs with almost identical scores for reduction about .
and generality about .
whenkgvaried from .1to0.
.
in these cases therefore debop failed to produce debloated programs with different tradeoffs between reduction and generality.
the reason why debop only produced programs with high generality even when kgis as low as .
is that its debloating process starts with a program that handles all the provided inputs and thus preserves all the paths identified by domgad.
we observed that debop s stochastic search is not effective at exploring the search space.
the number of iterations that debop performs on average for its stochastic search is which is insufficient for an effective exploration.in contrast in the same amount of time i.e.
six hours domgad performed over iterations.
note that when kgwas not extremely low e.g.
kg .
debop produced debloated programs with scores similar to those generated by domgad.
this result is due to the fact that debop happens to start with the programs thatdomgad eventually identifies as optimally reduced i.e.
the programs with all paths preserved .
when kgis low i.e.
less than .
however debop could only generate debloated programs with lower objective scores.
we believe that there are two main reasons why debop has limited effectiveness.
first its search space is extremely large.
debop reduces a program at the statement level and the average number of statements in its search space is which is larger than the number of paths in domgad s search space .
second debop as an input based technique has to run the entire set of inputs to evaluate generality for every reduced program it generates which is expensive.
it is also worth noting that we provided debop with a reduced program that preserves all the paths identified by domgad.
although this allows for a fair comparison between domgad and debop it also makes debop s debloating job easier as debop starts from the partially debloated program that domgad generates.
.
.
rq4 comparison between domgad andchisel.
table presents chisel s result.
as we stated above because chisel is a reduction oriented technique we provided chisel with the exact inputs that domgad s programs could correctly handle and only compared the two techniques in terms of reduction.
our results show that domgad andchisel produce debloated programs with similar size reduction scores but domgad achieves slightly higher size reduction on average.
this implies that even using an aggressive approach that focuses only on reduction chisel is not able to outperform domgad and produce debloated programs with a smaller size.
in terms of attack surface reduction however domgad does not perform as well as chisel.
the reason for this is that domgad uses a path based approach and only eliminates statements within function bodies.
conversely in addition to removing statements chisel also reduces global variables and function declarations.
this helps chisel produce a reduced program with a smaller binary size and hence a smaller attack surface.
based on these findings in future work we plan to investigate code removal techniques for non executable statements which should improve domgad s size reduction performance.
it is worth noting that since chisel is a reduction oriented technique we provided it with the inputs that domgad could correctly handle similar to what we did for debop .
on the one hand this allowed for a fairer comparison between chisel and domgad.
on the other hand however it basically gave chisel the advantage of operating on an already partially debloated program.
.
threats to validity like all evaluations our empirical assessment of domgad could suffer from issues of internal and external validity.
to account for possible threats to internal validity we thoroughly tested and spotchecked our code.
domgad relies on an input sampler for path identification and quantification which we developed and which 233subdomain based generality aware debloating ase september virtual event australia took about a day of work .
to reduce bias we designed the sampler so that they simulate how the benchmark program is used according to its usage profile.
for the two techniques we used as baseline we leveraged the implementation provided by their authors .
as for threats to external validity we evaluated the approaches on ten unix utility programs and our results may not generalize to more complex programs e.g.
programs involving user interactions database connections and network communications for which developing effective samplers would be more challenging and path identification and quantification and stochastic optimization would be more expensive and difficult.
as we will discuss in section we envision a number of ways in which we could improve domgad to address possible issues that may arise when applying it to larger and more complex benchmarks.
related work program debloating .domgad is related to a set of reductionoriented techniques that rely on a usage profile for debloating .
trimmer performs aggressive compiler optimization for code reduction.
occam achieves reduction through partial evaluation .
c reduce perses and chisel are reduction techniques based on delta debugging .
j reduce improves delta debugging by leveraging dependency information for effective reduction.
the reduction approach adopted byrazor is based on code coverage inference and binary rewriting.
unlike all these techniques domgad performs subdomainbased debloating and produces reduced programs by focusing on subdomains rather than specific inputs.
moreover unlike most of these techniques domgad is not purely reduction oriented it also accounts for generality while debloating and performs stochastic optimization to strike a balance between reduction and generality.debop is a technique that we developed in previous work and that also performs optimization for debloating.
unlike domgad however debop is input based and operates at the statement rather than path level.
as our empirical results show this negatively affects debop s performance in terms of both reduction and efficiency.
domgad is also related to techniques that perform static analysis to remove dead or unused code and techniques that perform reduction either for specific applications e.g.
containers and web applications or for special purposes e.g.
safety checking .
more broadly domgad is related to approaches for detecting bloat identifying unnecessary code and identifying code of interest through program slicing .
it would be interesting to investigate whether and how domgad could be combined with some of these techniques and in particular slicing.
model counting and probabilistic analysis .
because domgad performs statistical sampling for path identification and quantification it is related to model counting techniques which aim at quantifying the number of models that satisfy a given formula.
for similar reasons it is also related to approaches for probabilistic software analysis which aim to quantify likelihood of the occurrence of certain probabilistic events.
finally domgad is related to statistical model checking techniques which aim at verifying probabilistic properties through statistical methods.
for path quantification domgad performs a hit or misssampling method.
like the previous set of techniques these approaches are mainly orthogonal to domgad and may be interesting to investigate for identifying possible synergies.
mcmc and optimization .domgad uses an mcmc based approach for stochastic optimization so it is tangentially related to techniques that leverage mcmc to tackle other problems such as optimization bug finding model based gui testing and program obfuscation .
finally domgad is loosely related to optimization techniques for resource adaptation energy reduction program repair and more broadly for software improvement .
conclusion and future work existing debloating techniques are prone to producing programs that are overfitted to the specific user profile i.e.
set of inputs used to drive the debloating process and are therefore likely to fail for most other inputs.
to address this problem we propose domgad a subdomain based generality aware debloating technique.
unlike most existing debloating approaches which only consider program size reduction domgad also accounts for generality a program s ability to correctly handle inputs in its whole domain.
to do so domgad focuses on preserving specific paths rather than individual statements within the original program thus producing reduced programs that are guaranteed to behave correctly for the input subdomains characterized by these paths.
in order to strike a balance between reduction and generality domgad performs stochastic optimization using an objective function that combines these two conflicting measures and can achieve close to optimal tradeoffs.
our evaluation of domgad performed on a benchmark of ten unix utility programs shows that our technique can produce debloated programs that achieve significant code reductions on average while preserving high generality on average .
our results also show that domgad performs well when compared against two state of the art debloating techniques.
in future work we will first extend our evaluation by applying domgad to a broader set of programs to assess whether our current results generalize and performing a user study to measure the value of generality in a more realistic context.
second we will investigate ways to improve the efficiency of path identification and quantification.
in particular we will consider approaches such as stratified sampling and sequential sampling as well as study the possibility of performing path identification and quantification simultaneously based on shared input samples.
third we will consider other stochastic approaches such as those based on gibbs sampling to improve our optimization results.
finally we will research ways to infer the input distribution of a program possibly based on a usage profile and build input samplers automatically.
to do this we will consider approaches based on probabilistic program synthesis probability density estimation distribution estimation and deep generative models .