hazardanalysis forhuman on the loop interactionsin suas systems michael vierhauser michael.vierhauser jku.at johannes kepleruniversitylinz austriamdnafee al islam ankitagrawal jane cleland huang janehuang nd.edu universityof notredame usajames mason james.mason ngc.com northrop grumman usa abstract withtheriseofnewaitechnologies autonomoussystemsaremovingtowardsaparadigminwhichincreasinglevelsofresponsibility are shifted from the human to the system creating a transition from human in the loop systems to human on the loop hotl systems.
this has a signi ficant impact on the safety analysis of suchsystems asnewtypesoferrorsoccurringattheboundaries of human machine interactions need to be taken into consideration.traditionalsafetyanalysistypicallyfocusesonsystem level hazardswithlittlefocusonuser relatedoruser inducedhazards that can cause critical system failures.
to address this issue we constructdomain levelsafetyanalysisassetsforsuas smallunmannedaerialsystems applicationsanddescribetheprocesswe followedtoexplicitly andsystematicallyidentifyhumaninteraction points hips hazard factors and mitigations from system hazards.
we evaluate ourapproach by first investigating the extent to which recent suas incidents are covered by our hazard trees andsecondbyperformingastudywithsixdomainexpertsusing our hazard trees to identify and document hazards for suas usage scenarios.ourstudyshowedthatourhazardtreesprovidede ffective coverage for a wide variety of suas application scenarios and were useful for stimulating safety thinking and helping users to identifyandpotentiallymitigate human interaction hazards.
ccs concepts software andits engineering software safety .
keywords human suasinteraction safetyanalysis hazardanalysis suas acmreference format michaelvierhauser mdnafeealislam ankitagrawal janecleland huang and james mason.
.
hazard analysis for human on the loop interactions in suas systems.
in proceedings of the 29th acm joint european software engineering conference and symposium on the foundations of softwareengineering esec fse august athens greece.
acm newyork ny usa 12pages.
permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on thefirst page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspeci ficpermissionand ora fee.
request permissions from permissions acm.org.
esec fse august athens greece associationfor computing machinery.
acm isbn ... .
introduction autonomous systems are increasingly moving towards a paradigm in which humans and machines work in tandem to achieve relativelycomplextasks typicallyinsystemsthatarenowreferred toas human on the loop hotl .incontrasttoamoretraditional human in the loop hitl system in which a human makes decisions at key points of the system s execution a hotl system exhibits far greater machine autonomy while providing situationalawarenesstohumans.hotlenvironmentsareableto takefulladvantageofmachineautonomytoperformtargetedtasks efficiently and quickly however in addition to traditional hazards theyintroducethepotentialfornewtypesoferrorsthatoccurat theboundariesofhuman machineinteractions.currentparadigms thatexploretheseinteractionsinsafety criticalsystemsfailtofully evaluate the way in which humans contribute to impact or fail to impact systemsafetyinsmall unmannedaerialsystems suas .
historically many hazards have occurred at the human cps interface.forexample in1988 theus navy s ussvincennes shot down a civilian plane with people on board.
the vincennes hadentered iranianwater and operators mistakenly identi fied the airbus as an attacking f tomcat despite the fact that the airbus was climbing and emitting appropriate civilian iff signals.
the mistaken identi ficationwas partiallyattributed toauser interface flaw which caused the operator to confuse the data of a military planeintheareawiththatofthecivilianone .humanoperators are frequently blamed for these types of errors which have been widelyreportedascontributingfactorsin60 to85 ofaccidentsin domainssuchasaviationandmedicaldevices .however many of these human failures can be directly attributed to flaws in the underlying system design and could therefore be classi fied as design induced faults .
similarexamplesareemerginginthedomainofsmallunmanned aerialsystems suchasthecaseofanearcollisionbetweenansuas and a highway patrol helicopter in california in .
the suas wasflying at over feet even though based on faa regulations themaximumaltitudeallowedwas400feet.
inthis case therpic remotepilotincommand haddeliberatelysetahigherrtl return tolaunch altitudetoavoidelectricalpylons.during flightthesignal to the suas was lost and the rtl failsafe mechanism activated causing the suas to return home at an illegal altitude resulting in a near collision with the helicopter.
while the rpic was clearly at fault thesoftwarewasdevelopedinawaythatallowedthemistake to happen without raising alerts either whenthe rtl altitude was incorrectly con figured or during flight when the altitude violation actually occurred.
esec fse august athens greece vierhauser al islam agrawal cleland huang mason teams building safety critical software products are required toperform arigoroushazardanalysis using techniquessuch as software fault tree analysis fta or software failure mode e ffects and criticality analysis fmeca to identify hazardous states and a set of mitigating actions which are linked to safety related requirements.
while the safety analysis must be performed on individual products several studies have shown that preliminary hazard analysis can be initially performed at the domain level and then contextualized during the application developmentprocesstoindividualproducts .various frameworks checklists andtemplatesexisttoguidesystemsand software engineers through the process of identifying and mitigating hazards associated with the development and deployment of suas .however thesetendtofocusonsystem levelhazards whilepayingscantattentiontotheuniquehumaninterfaceaspects ofmulti user multi agentsystemsthatareemerginginthesuas domain .
furthermore while human related hazards in the suas domain sharecommonalitieswiththosefromseveralotherdomainssuch asmulti agentrobotics autonomousvehicles anddronesusedin the defense domain they also exhibit unique safety concerns introducedbythedeploymentofremotelycontrolledsuasinpotentially populatedareas limitedtrainingoftheremotepilotswhomaybe ill prepared to handle o ff nominal cases and a rapidly emergent marketofsuasapplications whichinmanycasesaredeveloped byhobbyists withouttraining insafetyassurance.
this paper describes domain level safety analysis assets that explicitly focus upon human interaction hazards.
our aim is to create a shared and reusable resource and astructured process for use by software and systems engineers working in the space of suasapplication development.wefolloweda systematicprocess that started by reviewing a broad range of academic literature and whitepapersdescribingimplementedsuasframeworks templates andhazard analysisassociatedwithsuassystemsandfoundthat the majority of hazards identi fied from the literature are systemorientedandfailtocapturehazardsassociatedwithhuman suas interactions.wethenapplieda systematicprocess thatbuiltupon thesystemhazardstoidentifyadditionalhazardsassociatedwith humaninteractionpoints hips .thisanalysisresultedinasetof domain levelhazardtreesdesignedforsafetyanalysisofdiverse suassystemswhichweevaluatedintwoways first againstdetailed accounts of publicly reported suas incidents and second throughastudyinvolvingsixdeveloperswithdomainexperience working with suas.
examples throughout the paper are primarily drawn from our owndroneresponse system .
theremainderofthepaperislaidoutasfollows.section 2reports on our systematic process for identifying human suas interaction hazards from existing literature.
section 3describes the process we followed to construct our hazard trees while section 4discusses theiruse.
section 5evaluatescoverageof the hazardtrees against reported incidents while section 6reports our study with domain experts.
we analyze results in section .
finally sections 8to10 discuss threatsto validity relatedwork andconclusions.
suashazardanalysis weperformedasystematicliteraturesurveytoidentifyaninitial setofsuashazardsbasedonpublicationsreportingsafetyanalysis techniquesappliedtosuasdomains.paperscoveredtopicssuch ashazardanalysis faulttreeanalysis andsafetyanalysisusing thegoalstructuringnotation .ouraimwasnottoanalyzethe effectiveness of di fferent techniques or frameworks but to identify specifictypesofhazards faults andsafetyrequirementsreported byauthors.theresultingcollectionofsuashazardtreesformsthe foundation for our subsequent more focused and human centered safetyanalysis cf.section .
.
data aggregationandanalysis process oursystematicliteraturesearchusedtheacm ieee andscopus digital libraries to identify research papers containing descriptions of suas safety failures and incidents.
we performed a number of pilot searches based on keywords collected from an initial set of papers and re fined the search terms multiple times to ensure that relevant papers were part of the search including for example suas and various synonyms such as uav and also safety hazard or fault analysis.
two researchers then collected and analyzed the search results using the parsifal tool .
we removed duplicatesandexcludedpapersaccordingtothefollowinginclusion ic andexclusion ec criteria ec1 papersnotrelatedtosuas e.g.
airplanes orlarge militarygrade uavs were excluded.
ec2 papersnotwritteninenglishornotavailableaspdfvia the digital library were excluded.
ic1 onlypaperscontaininginformationonsuassafety related information including safety requirements hazards or faults orpaperscontaining informationon multi agentsafety related informationwithregardstointeraction collaboration between agents inthe titleand orabstract were included.
our initial search returned papers.
applying the exclusion criteria resulted in a set of papers which were reduced to papers after the inclusioncriteriawere applied.
.
hazard treeconstruction wethenskimmedeachpapertoidentifyconcretehazards faults and or safety related statements mentioned inthepaper.we refer to these as safety statements .
we extracted a total of safety statementsfrom27papers whiletheremaining93papersdidnot contain speci fic examples of safety relatedstatements for suas.
eachofthe statementswasthentransformed intooneormore explicitly stated hazards each one based on a safety requirement fault or actual hazard reported in the paper.
we then used open coding to identify hazard categories and as a result established an initial grouping of eleven di fferent categories e.g.
sensors route planning .
this encoding process was performed by two researcherswithfrequentdiscussionsandre finementofthegroups andcategoriesuntilagreementwasreached.we finallyidenti fied eight categories of hazards.
in cases where a hazard was related to multiple categories we selected the most appropriate one.
this resultedina finalsetof114distinct hazardstatements .
9hazardanalysis forhuman on the loop interactions in suassystems esec fse august athens greece system hazard c1 communication failure e.g.
gcs failure loss of wireless signal or jammed communication c5 ground control system for multi suas communication fails c4 hand held controller for manual flight loses connectivity to suas c2 communication failure between ground and suas c3 communication failure between suas figure one of the smaller hazard trees derived from the literaturesurveyforcommunicationfailures.thenumbers indicatethenumberofassociated hazard statements.
asthegranularityofthereportedhazardsvariedsigni ficantly includingspeci fichazardssuchas thesuasdeviatesfromitspredefined route due to wind shear and loss of satellite signal we establisheda hierarchy of hazards cf.
fig.
organizedunder eight hazardcategories.wherehazardscouldbegroupedundermultiple parenthazardsweselectedthemostappropriateonetoavoidduplicates but added a cross reference to the other hazard tree when appropriate.
we organized all associated hazards into a hierarchy where necessary adding intermediate hazards merging duplicates or very similar ones and removing hazards that were deemed out of scope for an suas application or too abstract.
following this process 108hazardnodesremained.wethendouble checkedthe originallisttoensurethatthetreesprovidedfullcoverageofthe hazardsidenti fiedfromtheliteratureandthatnonehadbeenmissed.
this task was performed independently by three researchers on ourteam.incaseswheretheassignmentwasnotunanimous we discussedthe mappinguntilconsensuswas reached.thisresulted infive hazardsbeing slightly modi fiedornewlyaddedto the tree.
theresultinghazardtrees basedonourliteraturesearch representeduseofprohibitedairspace 7hazardstatements separation distance hazard statements communication hazard statements hardwareandsensorfailures 37hazardstatements weather 9hazardstatements piloterror 15hazardstatements preflightchecks 6hazardstatements andsituationalawareness hazardstatements .
human suasinteractions one of the main findings of our literature survey was that the majority of hazards and safety related statements target systemlevelhazards payinglittletonoattentiontouser related oruserinducedhuman suasinteractionhazardsthatcanleadtocritical system failures.
given this lack of documented human interaction hazards weappliedasystematicprocessforderivingthemfromthe system hazards when performing hazard analysis for a certain use casescenario.ourprocessissummarizedinfig.
.westarted step byselectingasystem levelhazardfromanexistinghazardtree.
next step we systematically explored each mission mode and identified relevant scenarios that represented human interaction points step for each mode.
given aspeci fic hip within a given mode wesystematicallyexploredtheroleahumancouldplayin instigating or mitigating the hazard step with respect to system design user design and hardware and con figuration flaws.
we mission mode maintenance configuration mission planning prelaunch configuration advisories and weather takeoff inflight rtl and landing system hazard defined e.g.
uav loses satellite signal hazard factorsfor each relevant modemore hazards human initiated error situational awareness lack of empowerment human interaction point e.g.
the operator checks why a uav is unable to arm.
more modes domain assetshuman suas hazard tree figure hazards and mitigations with associated human factors and impacts were identi fied systematically for each systemhazardaccordingtomode errortype and finallythe impact upon humanoperators.
used this informationto augmentthebasic systemhazard treesto createahip orientedhazardtree capturinghiphazardsfordi fferent hazard factors.
we finally consolidated hazard trees for all relevant modesassociatedwiththespeci fichazard step5 .wenowdescribe thesesteps inmore detail.
.
mission modes step2 all suas systems transition through di fferent phases of operation i.e.
modes .theseincludepre flightconfiguration includingmaintenance and mission planning prelaunch con figuration checks on suas readiness and retrieval of flight advisories mission launch post launch flight and rtl returnto launch .
hazard scenarios including those associated with human interactions may occur across multiple phases of operation with mode speci fic characteristics and mitigations .
therefore hazard analysis must be performedforeachmode andmustaddressthesystem sability todetectandreacttobothnormalandabnormalevents .we briefly summarize each of the modes that we include in our examples throughout the paper as their unique characteristics shape theirassociatedhazardsandmitigations.
missionplanning multi suasmissionsaredrivenandconstrainedbymissionplansthatestablishrules missionboundaries and goals enable speci fic tasks and transitions between tasks and set autonomy levels for the suas .actions takenin thismode can impact safety for example if an rpic plans a mission without considering changes interrain elevation.
suasmaintenanceand con figuration flight controller systems such as ardupilot and px4 have large numbers of configurable parameters.
for example px4 lists con figuration points each with a range of allowed values.
users can con figure 10esec fse august athens greece vierhauser al islam agrawal cleland huang mason suasusingthird partysoftwarepackages manyofwhichfailto providemeaningfulconstraints.
prelaunchcon figurationchecks thesystemmustcheckcritical configuration values prior to launch and either correct them automaticallyorclearlydisplaywarnings.commonerrors asobservedinourstudy includesettingincorrectfail safevalues e.g.
rtl altitudeabove the legally allowedlevels .
advisory and weather checks rpics are required to obtain flight authorization prior to entering controlled airspaces and to check weather conditions.
incidents often involve adverse weather conditions and orunauthorized flights intocontrolledairspace.
takeoff problems not identi fied during pre launch activities canemergeattakeo ff forexample acablethatobstructsapropeller causinglossofcontrol communicationfailuresbetweensuas or suasplacement onan obstructedlaunchpad.
inflight duringflight users issue directives to the suas.
in addition thesystemmustprovidesituationalawarenesstousersso thattheycanperceivethecurrentsituation comprehendwhatis happening and make sound decisions .
accidents occur when users lose situational awareness often due to well documented design demons such as information overload attentional tunneling andout of the loopsyndrome .
rtl andlanding rtl and landing modes present unique hazards for example the need to provide safe passage home if all suas simultaneously transition to rtl due to global loss of signal.
.
human interactionpoints step3 humansdirectlyinteractwithsuasinmanydi fferentways including through physical manipulations e.g.
attaching a camera use of manual flight controls e.g.
if a human takes physical control of thesuasfromthesoftwaresystem aswellasthroughissuingcommands feedback andsettinggoalsviatheuserinterface .
we discuss five common human suas interaction patterns p1 p5 based on accounts of human interactions reported in the literature e.g.
.eachofthefollowingpatternsinvolvesactions and interactions performed by both suas and humans.
square brackets depictoptionalactions.
p1 monitor human p2 request feedback suas provide feedback human act suas monitor human p3 adapt explain suas monitor human p4 observe andcon figure human check con figuration suasorsystem p5 set mission goals human plan mission system suas act suas thefirstpattern p1 isthemostcommononeinahotlsystem where ahuman operator s responsibility isprimarilysupervisory.
the operator monitors the system and when needed requests an explanationfromthesuassystem.thehumanmaydecidetointerveneinthesuass behavior andthesuasrespondsaccordingly.
inpatternp2 ansuasexplicitlyrequestspermissiontoperforman actionorrequestscon firmationthatatakendecisionwascorrect.
an example of this is when an suas uses onboard vision to detectavictimduringasearch and rescuemission andrequestscon firmation from the operator that it made a correct decision to switch from search to track mode .
the operator provides feedback whichthe suasactsupon andthe human monitors the response.
in p3 the suas adapts independently and then provides an explanationoftheadaptation.anexamplewouldbewhenansuas makes an rtl decision due to low battery.
the human monitors theactionandifnecessaryintervenesbyfollowingpatternp1.in p4 the human con figures and checks the system either during flight or prior to flight.
finally in p5 the human sets mission goals whichguideandconstraintheactionsthesuasareallowedtotake includingtaskstheywillperform permissionstoactautonomously and ways in which they will collaborate with other suas and with human supervisors.
we explored instances of these patterns across commonandexceptionscenariosfordiverse flightmodes andused themto aid inthe identi fication of human interaction points.
.
human hazardfactors step4 wefurtherexplorethreetypesofhuman interactionerrors.
human initiated errors are quite common in the suas domain as many pilots have limited training.
examples include ignoring regulations and restrictions or failing to follow established processes.
loss of situational awareness occurs when the user is unable to fully perceivethecurrentsituation comprehendwhatishappening and make sound decisions .
for example if the system provides inaccurate information about the health or location of an suas or fails to explain why an suas behaves in a certain way e.g.
the suas stopped at a certain point and does not move further the usermaymakesuboptimaldecisionsforhowtoproceedwiththe mission.
finally lack of empowerment occurs when the operator is awareofthestateofthemission knowswhattheywouldliketo do but the system does not provide the means for them to do it.
a simpleexampleiswhenthesystemfailstoprovidetheuserwith the optionofcanceling a flight route currently inprogress.
.
constructing thehazardtrees steps5 finally basedonthissystematicapproachforidentifyinghumansuashazards weconstructedhazardtreescapturingthesystem hazard sub hazards and human suas hazards to be addressed.
partial examples for two hazard trees suas collisions and preflightconfigurations arereportedinfig.
.theseinitialtreeswere continually re fined into domain level assets step throughout the remainder of our study as additional hazards emerged.
this refinement processis further described in section .2based onadditionalhazardsdiscoveredthroughanalyzingreportedincidents.
ourfinal set of eight hazard trees is listed in table .
we also identify candidate mitigations.
for example in fig.
3b hazard px7 could be mitigated bythe requirement that the system shall store a list of default arming checks to be applied to all uavs by type e.g.
px4 ardupilot .
an alert shall be displayed if any uav s internal configuration di ffersfrom the expected armingchecks.
.
whilethispaperdoesnotfocusontheprocessofestablishing mitigations ourgithub hostedhazardtrees listofmitigationoptionsfor eachhuman interaction error1.
1suas repository 11hazardanalysis forhuman on the loop interactions in suassystems esec fse august athens greece hazard system hazard hazard f1 a ua v flies dangerously close to another object or collides with it hazard f2 a ua v flies too close to ground based objects e.g.
ground trees buildings people hazard f5 the ua v does not have an accurate terrain map and or accurate geolocation and is therefore not able to determine the correct altitude to fly athazard f11 the ua v crashes into the terrain or another object right after an operator manually assumes control of the system from the computerized system hazard fx6 when the operator assumes manual control during the mission and switches e.g.
throttle are set incorrectly the ua v responds dramatically e.g.
plunging to the ground hazard fx8 when the operator assumes manual control of the ua v they do not know how the ua v is oriented i.e.
which direction the ua v is facing and find it difficult to immediately control the ua vhazard f3 minimum separation distance and or time to impact threshold is violated between airborne ua vs hazard fx2 the operator has no means of overriding the onboard autonomy and or cannot do so quickly enough in order to avoid a collision with the terrainhazard fx1 the operator is unaware that the ua v is flying too close to the terrainhazard f8 gps accuracy is unexpectedly degraded hazard fx3 the operator is unaware that gps accuracy is degraded and that ua vs are in danger of mid air collisionshazard fx7 the operator is unaware that the switches are set incorrectly a hazardsrelatedto suas collisionshazard system hazard hazard p1 physical preflight ua v setup misses important checks hazard p2 ua vs are not placed correctly for launch hazard px1 operator places ua vs too close to each other or with insufficient clearance prior to launchhazard p3 ua v is not flight readyhazard px11 it is difficult for the user to check and configure multiple ua vs simultaneously hazard p5 no geofence has been established hazard px4 the system does not provide appropriate information regarding the geofence so the operator is unable to determine whether it has been set correctly or nothazard p6 ua v is not configured correctly for flight hazard px5 user is unaware that the system is not configured correctlyhazard px8 user has configured autopilot in an unsafe way e.g.
setting minimum number of satelite fixes required to or setting the rtl altitude illegally high or dangerously low hazard p7 the payload is too heavy or unbalancedhazard p12 the user sets switches on hand held controller incorrectly e.g.
throttle rtl land hazard px9 operator attaches overly heavy or insecured payload to ua valso see sensor and hardware hazard tree hazard px6 user is unaware that failsafe and other flight actions are configured incorrectly e.g.
rtl actions hazard px7 user is unaware that critical arming checks are disabled e.g.
satellite connections accelerometer health b hazardsassociatedwithpre flightchecksand con figurations.
figure two partial hazard trees.
system nodes were derived from the literature survey while colored nodes were derived from our analysis of human interaction errors.
legend gray system hazards blue human initiated errors green loss of situational awareness yellow lack ofempowerment.
description multiple uavs dispatched to search for victim.
primary actor drone commander dc trigger the dc activates the search.
main success scenario .
the uav performs synchronized takeoff a uavs are not placed correctly for launch system haz.
i.operator places uavs too close to each other for launch ii.operator places uavs in area with insufficient clearance .... .
dronerescue tracks and displays the location and state of each uav a communication failure between ground and uavs system haz.
i. the operator is unable to receive status data from the uavs and loses situational awareness ... more steps.... figure use case vignette includes system level hazards missionmodes and respectivehips wherehe humanerror sa loss ofsituational awareness.
leveraging the hazard trees in this section we assume the role of an end user e.g.
an suas system developer and show how a user could leverage our hazard trees and the process we developed to identify relevant humaninteractionfactorsforaspeci ficsuasapplication.ourexampleisbased on the use case vignette shown in fig.
4for a search andrescue scenario.
we systematically examine each step of the use case and identify its hips and their associated flight modes and hazardgroups.inthisexamplewefocusontheusecasesteprelated tosynchronized takeo ffwhich occurs in takeoffmode.
we identify a hip in which the operator prepares the suas for launch and then select relevanthazardtreesof preflight configuration weather and mission planning .
the user retrieves those hazard trees and utilizes them to aid in the hazard analysis process.
in this case we identify ourfirstsystem levelhazardfromthepre flightconfigurationtree stating that uavs are not placed correctly for launch .
the tree offerstwoassociatedhipsde finedashumanerrors for operator places uavs too close to each other prior to launch and operator places uavs in location with insu fficient clearance prior to launch .
we followasimilar processfor allsubsequent steps.
once human interaction hazards are identi fied we can propose mitigatingrequirements.forexample theinappropriateplacement of suas could be mitigated through including a clearance check in a prelaunch checklist or byadding a newfeature tothe system that raises a placement alert if the minimum separation distance is violatedbetween suasprior to launch.
incidentreportcoverage thefirstpartofourevaluationassessesthe coverageofhuman suas incidentsacrossthehazardtrees .wecollectedreportsofincidents accidents and failures relatedto suas usage from news services 12esec fse august athens greece vierhauser al islam agrawal cleland huang mason table1 final re finedhazardgroupswithsystem sys and user hazardshuman suasinteractionhazards hi hazards idcause of hazard sys hi clcollisions between suas otherobjects andterrain cmcommunication lossofcommwithsuas hshardware sensors e.g.
cameras gps parachutes mamission awareness mission status decision making mpmission planning flight routes andtask allocation pcpreflightcon figuration geofence launch params rcregulatory compliance airspace flightconstraints wtweather extremetemperature wind table suas incidents involving as reported publicly and orthroughregulatory bodies source url aviation safetyreporting system asrs rpsts uav.pdf acn wikipedia collection of incidentsen.wikipedia.org wiki list of uav related incidents109 dedrone collection of worldwidedrone incidents incidents all100 the centerfor the studyof the drone bardcollege drone incidents30 uk air accidents investigation branch reports and regulatory bodies.
in total we inspected reports of suas incidentsfrom fivedifferentsourcesasdepictedintable .three members of our team analyzed the incidents and mapped reported human interactionfailurestotheeighthazardgroupsandtothe threehazardfactors.foreachincident oneteammemberperformed theinitialmappingandasecondmembercheckedthemappings.
in case of disagreement all three people discussed the results to reachconsensus.
aggregatedresults are reportedinfig.
.
.
results the majority of reports simply stated that an suas was sighted inprohibitedairspacewithoutanydiscussionofthecontributing cause whileonly54provideddetailedaccounts.43oftheseincluded human relatedfactors providinginsightsintotheprevalenceand rootcausesofdi fferentincidentsandindicatingthatthemajority ofincidentsinvolvedhumanfactors.forexample someincidents related to entering a prohibited airspace were caused by lack of preflightconfigurationorappropriatecon figurationchecks coveredbythehazardtrees regulatorycompliance and pre flight configuration .
these accidents could be avoided by using a flight authorization system.
similarly in the case of pilot errors e.g.
losingline of sighttothesuas orhardwareerrors e.g.
lossof gps appropriateprelaunchcon figurationcheckssuch ascorrect fail safesettings couldhavemitigatedtheseincidents cf.
pre flight configuration .hazard groups cl cm hs ma mp pc rc wt human initiated error loss of situational awareness lack of empowerment figure a heatmap showing human interaction factors mappedagainsthazardgroupsaccordingtotheiroccurrence intheanalyzed incidentreports.
three of these incidents are summarized in table .
two cases i1 i3 were related to near collisions with other aircraft and all of them involved human initiated error eitherinflight i1 i3 orasaresultof preflightconfigurationerrors i2 .humaninitiated errors included ignoring airspace warnings i1 flying bvlos beyondvisuallineofsight i1 andfailingtoobtainpermission toflyincontrolled airspace i3 both ofwhich could wellbe mitigated through imposing constraints on flight planning see hazard treeregulatorycompliance and increasing situationalawareness levels through providing more warnings recommendations and evenprohibitions seetree missionawareness .in thesecondincident i2 therpicillegallysetthertlaltitudetoapproximately 750feetinordertoavoidpylonsandotherobstaclesifafail safe caused the suas to switch to rtl mode.
as suas can be con figured using open source applications e.g.
qgroundcontrol or missionplanner theircon figurationsmust bechecked for undesirable settings immediately prior to flight.
responsible software packages should also warn anytime a user con figured the autopilot in a potentially illegal or dangerous way.
finally in incident i3 the operator reported that he su ffered from stress due to multitasking andfailedtonoticethatthesystemhadstartedreporting altitude in meters and not feet.
this type of stress is quite common when humans supervise autonomous systems and is referred to as workload anxiety fatigue and other stressors wafos by endsley .
however the incident could have been avoided with a legally established geofence or by raising alerts if unexpected configurationswereintroduced.thesethreeincidentshighlightthe importance of software engineers designing implementing and testing suas systems systematically to address safety concerns relatedto human suasinteractions.
.
analysis hazardtreere finement asdepictedinfig.
manyofthereported incidentsincludedcollisions and were attributed to loss of situational awareness instances or directly related to human error instances .
the secondmostcommoncategorywaspre flightconfigurationissues where either the pilot was partially at fault instances or the systemdidnotprovideadequateorsu fficientinformationtoconfigurethesystemcorrectly 5instances .altogether weconclude that incidents were reported for each hazard group and that all reportedhuman interactionfactorsweresuccessfullymappedto one ormore ofthe hazardgroups.
basedonourobservationsweperformedafewupdatestoimprove the structure and clarity of the trees.
we observed that pilot operator related hazards occurred primarily due to loss of missionawarenessandprelaunchcon figurationproblems andtherefore redistributed pilot hazards to these two categories.
we further 13hazardanalysis forhuman on the loop interactions in suassystems esec fse august athens greece table example suas incidents with humancontributingfactors id incidenttype incidentdescription human related hazardref i1 uavcollisionwithhot air balloonflyinginunauth.
airspace over boise idaho in2018theamateurpilotoverrodewarningsabout flyinginunauthorized airspaceclosetoairportwithoutpermissionfromatc.theuav wentbeyondvisuallineofsightandrpicwasunawarethatthe uavwasrepeatedlyshearingagainsttheballoonuntilpropellers felloff.pilotwasunskilledwithhand heldcontrols.ignoringcritical warnings flyingbvlos.
i2 near collisionwith highway patrolhelicopter over martinez california between 700and800feetin 2015max.
altitude allowed for uav flights in the usa is 400ft or 100ft abovebuildings .therpichadoverriddenthealtitudeatwhich uavs return to launch to avoid electrical pylons.
when signal was lost with the uav during flight it switched to rtl mode and operated on autopilot at prohibited altitudes placing it into the flight pathofthe helicopter.criticaldefaultvalues overriddenbyuserina 3rdpartytool failure to check configurations prior to launch.
i3 uavwas flownto an altitudethat wasinexcess ofthe 400ft agl limitationspeci fiedwithin far part 107the rpic believed that altitude was being reported in feet and was not aware that it had been reset to meters.
as a result he accidentally flew to approx feet claiming that the mistake was caused by his focus on avoiding flying near obstacles or over people coupled with the delayed awareness that the software had reset to metric units.delayedawareness of uavstatus wafos workload anxiety fatigue andother stressors situational awareness demon extracted several hazards from across multiple categories into a new category named in flight mission awareness which grouped hazards related to situational awareness.
this new category includes hazards such as the operator is overwhelmed by status information for multiple uavs and the operator is unable to handle multiple alerts simultaneously .
this produced the current setofeighthazardgroupswhicharelistedintable 1andwereused for the subsequent study withdomainexperts.
evaluation by domain experts thesecondpartofourstudywasdesignedtoevaluatewhetherthe hazardtreeswereusefulforanalyzingandidentifyingrequirements associatedwithhuman suasinteractions.weinvitedsixexperts fromthesuasdomaintoreviewusecasesdescribingsuasmissions andtoutilizeourhazardtreestoaugmentasetofusecaseswith human interactionhazardsusingtheprocessdescribedinsection .
noneoftheseparticipantswereinvolvedinthedevelopmentofthe hazardtrees orinthe developmentofthe systematic process.
.
studydesign the study was divided into three parts that included an initial semi structured interview an analysis task and closing interview.
all phases of the study focused on two primary use cases in which suas were used to support river search and rescue and environmentalwatersampling.bothtop levelusecasesinvoked supportingusecasesto activateandarm suas generateflightroutes and to plan non intersecting routes through leasing airspace .
in addition the river rescue use case invoked active victim tracking and the environmental sampling use case invoked flight authorization .
we piloted the studyinternally with one user made improvements andthen conductedthe study as follows.initial brie fing at the start of the interview we described the hazardfactorsthatwehadaddressed namely humaninitiatederror lackofsituationalawareness andlackofempowerment however we alsostatedthatdiscussionwasnotlimitedtothesefactors.wethen presentedparticipantswithoneoftheprimaryusecasesandasked themtobrainstormpotentialsafetyhazardsforeachstepoftheuse casewiththefocusonhumaninteractionand orhumanfailures usingathink out loudprotocol .wetime boxedthisdiscussion to15minutes asthatwassu fficienttounderstandthe typesofissue each participant would identify while seeking a complete analysis would require much longer.
our aim was to establish a baseline for howdeveloperscurrentlythinkabout andidentifyhuman suas hazards.theinterviewwasrecordedusingzoomandautomatically transcribedfor lateranalysis.
afterthebrainstormingtaskwascompleted wespentapproximately10minutesexplainingthetasktobeperformed.weintroducedtheeighthazardgroupsandtheirassociatedhierarchiesof systemandhuman interactionhazardsandthenpointedtheparticipantstoan8minute take home onlinevideothattheycould use to further familiarize them with the hazard trees and the study process.
study task the study task was performed individually.
we assignedparticipantsintooneoftwogroups riverrescue environmentalsampling .eachparticipantwasgiventheirownmulti sheet googlespreadsheetwhichincluded asummaryofthe8hazard groups individual sheets for the primary use case and four supporting ones.
each use case included metadata a list of successsteps andamatrixforevaluatingeachstepandmarking a whethereachofthe8hazardswasrelevant and b inthecaseof supporting use cases exactly which hazards from the hazard trees were relevant.
fig.
6shows the main part of the spreadsheet for one particular supporting use case.
hyperlinks allowed the user 14esec fse august athens greece vierhauser al islam agrawal cleland huang mason figure anexample ofthehazardsidenti fied by oneoftheparticipantsforthesupporting use caseofactive tracking.
toeasilymovebetweenusecasesandtoviewthehazardtreeson github we instructed participants to spend up to minutes to systematicallyevaluateeachusecasestepandtomarktherelevant hazards.
follow upinterview inafollow upinterviewweaskedparticipants a series of open ended questions about their experience in working with the hazard trees.
questions included to what extent didthe trees helpyou toidentify potentialhuman interaction errors?
was it di fficult tofind a matching hazard group and or specific hazard for a use case step?
was there anything missing orunclearwiththegroupsorhazardtrees?
when flyingadrone have you ever experienced an incident that was at least partially caused by a human suas interaction problem?
if so do you thinkthatincidentcould havebeenpreventedormitigatedifyou hadaddressedhazardsdescribedinthehazardtrees pleaseexplain your answer ?
in addition we used a rubric to elicit feedback on usabilityande fficiencyoftheapproach.thefollow upinterview wasalsorecordedandtranscribed.
.
studyparticipants werecruitedsixparticipantsforourstudy eachofthemwithextensivedomainexpertiseinpilotingsuasordevelopingnon trivial suas applications.
as shown in table their experience ranged from2to 8years working onsuas development projects with an averageof3.67years.wealsoindicatewhethertheyhadexperience withsoftware hardware and orinamulti suasenvironment.in cases where a participant had prior experience with river rescue p3 orenvironmentalsampling p2 p6 weassignedthemtothose respective use cases.
we opted to include only highly quali fied domainexpertswhorepresentourtargetusers eventhoughthis reduced the size of our participant pool.
however nielsen has shown that five or six participants are su fficientfor providing meaningful and in depth feedback on a research design solution such as the hazardtrees.
.
initialinterviewanalysis we performed an inductive coding analysis on the transcripts from the initial meetings.
the researcher that conducted the interviewperformedtheinitialanalysisandthiswasthencross checked by a second researcher.
we identi fied four themes that were observedacrossseveralofthediscussions.first severalofourparticipantsfocused upon system level hazards rather than human related ones andweresometimesunabletoidentifyanyhuman interaction hazards.
for example participant p4 stated that i don t see anytable study participants application domain exp uc mult hw sw p1 suasdispatch callcenterui 4yrs es p2 environmental applications 8yrs es p3 multi suassearchandrescue 2yrs rr p4 safety security emerg.
resp.
2yrs rr p5 defibrillatordelivery 4yrs rr p6 environmental applications 2yrs es legend es environmental sampling rr river rescue mult multi suasdevelopment hw hardware sw software.
opportunities for human error associated with de fining a coverage area and allocating routes to suas.
in fact five out of six of our participants with the exception of p2 focused more on systemlevelhazardsthanhuman relatedones.inacloselyrelatedtheme threeoftheparticipantsrequestedadditionalexplanationsabout human interactionerrors indicatingthatthiswasanewconcept for them.
finally we observed several examples of blaming the operator withoutconsiderationforhowadesign flawinthesystemmighthaveincreasedthelikelihoodofanoperatorerror.for example p5 observed that the user could set an incorrect mode for takeoff humanerror butdidnotmentionthatthesystemfailedto raiseanalertwhichcouldhavenoti fiedtheoperatoroftheproblem.
.
taskanalysis andfollow up interviews once participants had completed the task we analyzed the mappings from use case steps to hazards.
we report aggregated results in table5.
for the two primary use cases river rescue and environmental sampling most participants found mappings to all eight hazard groups.
for the supporting use cases agreement was significantly lower.
out of potential mappings i.e.
supporting use cases hazard groups there were only seven cases in which allparticipantsagreedtothemapping but15casesinwhichatleast agreed.
similarly there were eight cases of full agreement that the hazard group was not relevant and cases with at least agreement.
there were only five potential mappings which lacked consensus.
asreportedintable theparticipantsfoundeachhazardgroup to be useful across at least some of the use cases.
in total communication orthelossthereof wasmentioned58timesintotal hardware sensors were mentioned times and mission awareness mentioned51times.collisionwasmentionedtheleastwithonly 24mentionsoverallusecases.allsixparticipantsmentionedthe 15hazardanalysis forhuman on the loop interactions in suassystems esec fse august athens greece table participant majority consensus for whether a specific hazard group was relevant for two top level use cases river rescue and environmental sampling and five supporting use cases.
hazard group use case cl cm hs ma mp pc rg wt river rescue environmental sampling activate arm area coverage h flight authorization leaseairspace h h active tracking h h legend majorityagreement that the hazardgroup is related h lackofagreement 3majorityagreementthatthe hazard group is not related.
the highest ranked hazard groups per use caseare underlinedin red.
usefulnessofthehazardtrees.forexample p2statedthat thetrees wereveryusefulwaytoconnectthehazards whilep3statedthat theyweresuperuseful...therewerethingsiwouldn thavethoughtof .
we also observed several cases in which a participant had stated duringtheinitialinterviewthattherewerenohuman interaction hazards associated with a speci fic use case step but found relevant ones when using the hazard trees.
for example when equipped withthehazardtree p3identi fiedpreviouslyundetectedhazards associated with loss of communication mission planning and regulatory compliance for the area coverage use case.
this indicatesthatthehazardgroupsprovidevaluableinformationregarding human suasinteractions.
based on a point likert scale very e fficient efficient ine fficient very ine fficient out of participants stated that use of the hazard groups was efficient and that the grouping improved the assignment task however two participants rated the task of identifying and assigning hazards as ine fficient.
subsequently the feedback was somewhat mixed.
p2 stated that he was hunting aroundabit butthathe likedthecategorization and thecolor coding while p5 stated that the organization of hazards within eachoftherespectivetreesmakesitprettyeasytosearchatree .p3 shared that after or minutes everything seemed to kind of make sense but that there is a lot of information because it is a complex problem .we discuss this issuefurther insection .
several participants mentioned that they leveraged systems hazardstohelpthemidentifyhuman interactionhazards.p4explained thathefirst identifiedsystem flawsandthenfollowedthemdownthe treetouncoverpotentialhuman suasinteractionproblems while p5statedthathe startedatmid level system hazardsandfound relevanthuman interactionhazards below that .
finally all participants were able to elucidate on at least one human interaction problem they had personally experienced and all agreed that knowledge of the hazard trees during the developmentprocesscouldhavehelpedthemforeseeandmitigatethe reported problem.
for example p1 described a real life incident he had experienced which led to unnecessary human intervention resultinginacrash andstatedthat weprobablywouldhavethoughtmore about how to address the hazards had we looked over those hazard trees and said that preflight check s could have alerted to the throttle position thereby preventing the accident.
in general our participants indicated that the real value of the trees is in providingexamples that encourage safety thinking .
discussion based on the analysis of reported incidents and suas accidents by regulators and the media we found that human initiated errors and loss of situationalawarenessdominatedthe reportedincidents.
basedonouranalysisandthefeedbackfromourdomainexperts weconcludethatseveralofthereportedincidentscouldhavepotentially been prevented or mitigated by addressing the hazards collectedinour domain level trees.
our study with domain experts indicated that developers in our study focused on system level hazards most likely because they were more familiar with addressing system problems and lessknowledgeableabouttheroleofhuman relatedhazards.this was the case even though they understood the full scope of the study including its focus on human interaction errors.
based on themappingstheycreatedwhenusingourhazardtreesandtheir feedbackinthe finalinterview weconcludethatthehazardtrees facilitatedsafety thinkingfrom ahuman interactionpointof view and provided agood starting pointfor diggingdeeper into these types ofhazards.
a second important consideration is the need for better tool support.
while our study participants reported that identifying typesofhazards akahazardgroups wasquiteeasy findingspeci fic hazards added an additional level of complexity and as a result sifting through all hazardsin all relevant trees was rather tedious.
thisledtotheconclusionthatadditionaltoolsupportcouldease the burden of looking for potential matching hazards.
while we do notproposea checklist liketool asthiscouldprovideafalsesense ofcompleteness featuresforsearching filtering andannotating the trees could easethe taskof identifying relevanthazards.
table two human interaction hazards with examples of potentialmitigations.
hazard px1 operatorplaces uavstoo closeto each other prior to launch px1 s1 rpicreceives proper training to conduct mandatory preflight checks processrequirement .
px1 s2 the systemchecksthe coordinates of alluavs onthe ground andraisesan alertif any of themare locatedless than minimumseparation distance apart safetyrequirement .
hazard cx3 the human operator is unable to receive status data from theuav using thesoftware based system.
cx3 s1 the approximate position andthe uncertainty of the uav scurrentposition onthe mapmustbe visually depicted e.g.
bycreating an increasingly large circle around the last known orprojectedposition of the uav safetyrequirement .
16esec fse august athens greece vierhauser al islam agrawal cleland huang mason in addition our aim is to provide a resource for addressing hazard analysis and safety assurance throughout the software engineeringlifecycle inorder toaid suas developersinbuildingsafer systemsthatempowerandsupportdiverseoperators.ourhazard trees include a set of candidate mitigations associated with each human interaction hazard as illustrated in table .
the current list ofmitigations isincludedouronline repository.ourapproachis designedtoaddressanemergentprobleminthedomainofsuas developmentbyprovidingareusablesetofhazarddescriptionsand mitigations aimed at inspiring and supporting a safety mindset for suasdevelopers.
threats to validity our work is subject to several validity threats.
while we have shown that it is applicable to real world incidents and use case scenarios the limited number of incident reports makes it likely that other types of incidents are not yet covered.
furthermore additional external evaluation of theprocessis required toensure its applicability in a more broader scenario.
the analyzed incident reportssparselycovermulti suasapplicationsandcustomsoftware solutions.
the majority ofreports are related totheuse ofo ff theshelfapplications suchasmissionplanneranddji spropriatery softwaresystem anddonotrepresentmulti suasmissions.given the increasingly common reports of suas incidents and the dearth of information discussing root causes we have created a shareable resource thatcan be usedas a starting pointfor analyzing humansuashazardsinaspeci fic application.
we consideredseveral alternate studydesigns includingacontrolled experimentthat would involve specifying requirements for asystemwith andwithout ourhazardtrees.however toaccomplishthisinanon trivialwaywouldrequiresigni ficanttimeand effort beyond available resources.
our approach falls under the broad umbrella of design science in which it has been shown that evenalimitednumberofparticipantsprovidesusefulusabilityfeedback to iteratively re fine a design .
another threat is related to the experience of the participants.
while all participants have experienceinhandlingandoperatingsuas onlyoneparticipant had previous experience with multi suas missions.
therefore we expect additional human suas interaction hazards to emerge from these types of systems and application use cases.
we release our set of hazard trees as a publicly available community resource that ismeanttoevolveoverasnewincidentsarereportedfromwhich hazardscan be identi fied.
we attempted to minimize internal validity threats associated with the incident analysis and study by dividing the transcription of audio recordings among two researchers and cross checking the resulting transcripts codes and emergent themes.
for the incident coverage threeresearchersperformedtheanalysisandeachincident was checked by two researchers.
in case of a disagreement the incident wasreevaluateduntil agreement wasreached.
related work themostcloselyrelatedworkisinsafetyassurance hazardslicing andsituational awareness.
safetyassurance workbydenneyandpai inthis area addresses di fferent aspects of suas and uav safety providingautomationsupportandtoolsforcreatingandmaintainingsafety assurancecases.theyemphasisereuseofsafetyassurancecasesby proposingdomain independentanddomain speci ficpatterns .
other work has created reusable safety case patterns as building blocks for future product development .
in the area of safety cases maintenance kelly and weaver presentedasetofpatternsandrecommendedtheuseofmodularity tosupportsafetycasesevolution.kellyandmcdermid investigatedchangesinevidence context assumptionandrequirements nodes to determine how changes impact the safety assurance case.
hazardslicing similartoourapproachofdividingalargehazard tree into several sub trees to better address the di fferent aspects severalresearchershaveshownthebene fitsofhazard basedslicing .agrawaletal.
proposedsafa softwareartifact forestanalysis that uses underlying tracelinksto create and visualizehazardstreesandtheirrespectivemitigationsinthecontextof an evolving safety critical software system.
safeslice extracts design slices based on functional safety requirements.
other work inthisareafocusesongeneratingartifactslicesusingformalverification techniques to support safety analysis .
however these approaches are all system focused with little to no emphasis onuserinducedhazardsandfaults.whilethesetypesofhazardsare important speci ficprocesses methods orguidelinesforidentifying andmitigating human interaction relatedhazardsare missing.
hci situational awareness the seminal work on situational awareness sa byendsley focusedonuser centereddesign identifying eight common design errors that occur frequently in user interface designs and which inhibit sa.
several studies in this areaexplicitly explore sa andshortcomingsof userinterfaces for varioustypesofsystemssuchastsunamiearlywarningsystems electricminingshovels oroperatorinteractionswithasingle robot or machine .
while the hci community has examined this problem from various angles they focus primarily on the user interface design and not on broader sets of hazards which our approach isdesignedto address.
conclusion in this paper we have presented an approach for systematically deriving human interaction hazards for suas systems.
based on a literature survey we identi fied eight di fferent categories of hazards thatserveasastartingpointforahuman centeredhazardanalysis.
aspartoftheprocess weidenti fieddifferentmissionmodesand contributinghazardfactors derivedpatternsforhumaninteraction points hips andconstructedaninitialsetofreusablehazardtrees.
aspartofourfutureworkweplanonfurtherextendingourhazard tree library exploring ways to make it more scalable including providing tool support to facilitate navigation and identi fication ofrelevantpartsofahazardtreefordomain speci ficmulti suas applications.
we also plan to extend our work into the design implementation and test lifecycleto provide supportfor realizing hazardmitigations.