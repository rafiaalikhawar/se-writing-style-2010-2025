mining cross domain apps for software evolution a feature based approach md kafil uddin qiang he jun han caslon chua department of computing technologies swinburne university of technology melbourne australia e mail mdkafiluddin qhe jhan cchua swin.edu.au abstract the skyrocketing growth of mobile apps and mobile devices has significantly fueled the competition among app developers.
they have leveraged the app store capabilities toanalyse app data and identify app improvement opportunities.existing research has shown that app developers mostly relyon in domain i.e.
same domain or same app data to improvetheir apps.
however relying on in domain data results in lowdiversity and lacks novelty in recommended features.
in thiswork we present an approach that automatically identifies classifies and ranks relevant popular features from cross domainapps for recommendation to any given target app.
it includesthe following three steps identify cross domain apps thatare relevant to the target app in terms of their features filter and group semantically the features of the relevant cross domain apps that are complementary to the target app rank and prioritize the complementary cross domain features in terms of their domain app feature and popularity char acteristics for adoption by the target app s developers.
wehave run extensive experiments on target apps from 10categories over cross domain apps from categories.
theexperimental results have shown that our approach to identifying grouping and ranking complementary cross domain features forrecommendation has achieved an accuracy level of over .our semantic feature grouping technique has also significantlyoutperformed two existing baseline techniques.
the empiricalevaluation validates the efficacy of our approach in providingpersonalised feature recommendation and enhancing app s userserendipity.
index t erms mobile apps software evolution app competition app improvement feature extraction app store mining i. i ntroduction with the prevalence of mobile devices the number of mobile apps and their popularity in the market has hit new heights.
in apps became a life saving tool in fightingand restricting the spread of the global covid pandemic .
by march smartphone users reached .
billion nearly half of the world population.
expectedly the mobiledeveloper population has boomed and the competition amongthe developers intensified.
in a recent report google inc.announced that its app store has paid out billion to itsdevelopers since whereas apple inc. has paid out 155billion to its ios developers indicating a large sharedeconomy by the developers in the app market.
however onlya relatively small number of developers with top rankingapps can survive in such fierce competition.
the economic0 facebook gmail vibers p p a r a l i m i s y l l a i t r a p f o produ vity business tools educa on books travel music social lifestyle entertainment personalisa on photography fig.
.
percentage of relevant cross domain apps distribution of the market is found to be skewed rather than hypothetically perfectly flat .
survival of the fittest the darwinian theory of evolution applies to the app market place.
a large number of appsdropout soon after their birth in the app market.
more than40 of app users stop using an app on the very first day ofapp downloads .
one of the key drivers for app downloadsis the popularity of app features and users liking or dislikingan app largely depends on the app features .
hence tosurvive market competition apps must continuously improvetheir features and provide new features to retain and attractusers.
a major aspect of app improvement is to differentiate the software value of a given app hereafter referred to as the target app from its competitors .
researchers have proposed several techniques to improve apps by analysingin domain data without considering any relevance with thetarget app or solely depending on the data relatedto the target app .
however a major drawbackof these studies is the filter bubble phenomenon in whichfeature recommendations made for the target app is trappedin a subspace of options that are too similar to the profile ofthe target app .
for example if the target app belongsto the education domain a.k.a category in the app store they will only recommend features identified from the samedomain that are similar to the target app s features.
moreover popular features often migrate from one domain to another offering novelty and feature diversity to cross domainapps.
36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee a report from the australia competition consumer commission accc and app annie found that due to the competitive pressure many apps are picking up cross domain features to gain popularity in the store.
drachen etal.
have shown that incorporating simple social features inmobile games increases its software value and extendssocial activity in the cohort .
others reported that blend ing elements from various domains such as social videoand entertainment is the key reason why tiktok 1became the world s most downloaded app in july .nonetheless existing studies have yet to exploit the analysis ofsuch cross domain data available in the app store.
to identifyimprovement opportunities for a target app we propose togo beyond the in domain apps and identify complementaryfeatures from relevant cross domain apps for adoption by thetarget app.
mining cross domain features is however a highly challenging task that requires automatic analysis of a high volumeof apps from various categories.
it becomes even more difficultto identify app features that are relevant and complementary to the target app due to the overlapping nature of apps and storecategories.
tackling this challenge requires the extraction offunctional features from the target app as well as the cross domain apps.
then the apps that are relevant to the target appin terms of feature similarity can be found and their coexistingbut dissimilar features can be further identified and grouped ascomplimentary features for potential recommendation.
finally the complementary features can be ranked for recommenda tions to the target app.
for example figure shows ourinvestigation on three target apps i.e.
facebook gmail andviber from the communication domain over crossdomain apps in the dataset.
we found that more than of the apps from the productivity and tools domains partially match all three target apps.
this indicates a greater chanceof finding popular cross domain features for recommendationand improving the diversity and novelty in the recommendedfeatures.
in a nutshell we answer the following three research questions in this paper identify relevant cross domain apps how to extractapp features and effectively identify cross domain appsthat are relevant to the target app in terms of their featuresimilarity?
identify complementary cross domain features h o wto automatically identify and classify semantically thosefeatures of the relevant cross domain apps that are com plementary to the target app in an effective way?
rank complementary cross domain features for per sonalised recommendation how to rank the identi fied complementary cross domain features and prioritiseadoption recommendations specific to the target app?
the rest of the paper is organised as follows.
section ii discusses the related work and research gaps that motivatethis research.
section iii presents the approach to identifying cross domain apps classifying and ranking com plementary features from the relevant cross domain apps tomake adoption recommendations to the target app.
sectioniv describes the experiment settings.
section v presentsthe experimental results and discusses the limitations of ourapproach.
section vi concludes the paper and outlines somefuture work.
ii.
r elated work existing studies use various data sources to elicit requirements for an app but mostly from app reviews and tweets.these requirements are for identifying improvements for thenext app release or for supporting app developers and stake holders .
many approaches have been proposedon review summarization classification and requirementselicitation.
in general these studies focus on the followingthree key aspects.
a. feature extraction existing studies extract software aspects such as frequent features user opinions sentiments new features bug reports etc.
from app reviews .
other studiesextract app factors such as install size code complexity sdkversion ui complexity library etc.
from app resources andassets used by the app .
in authors extractfrequent features and sentiments from tweets on twitter forsoftware evaluation and maintenance as well as elicit appimprovement requirements for the stakeholders.
however these existing studies use only the app s own user reviewswhen eliciting requirements for software evolution.
theseapproaches neglect all the information relevant to apps fromother domains that might be a rich source of information forsoftware improvement and requirement elicitation.
moreover the following comment from an app developer has also ex pressed such concern and showed the importance of reviewsfor competitors i do not want to listen only to my users butalso the users of competitive apps!
.
b. feature grouping current approaches classify and categorise extracted topics or aspects of apps into several predefined categories such as feature requests praise de praise etc.
ar miner classi fies reviews into informative or non informative reviews.
thestudy presented in classifies tweets into three categories including technical non technical and general.
in general current studies classify user reviews and tweets into two three four or five broad categories.however these studies limit themselves to high level cate gorisations only without considering specific app features forimproving the target app.
this situation becomes even worsewhen an app has a limited amount of reviews or similar typesof reviews.
we believe that there is a correlation between fea tures of the target app and features of other cross domain apps.this correlation of features would further enhance feature im provement recommendations for the target app by identifyingrelevant popular features from other domains.
the existing 744studies did not consider the feature correlation between the target app and apps from other domains.
as such to definesuch a correlation of features a new research question needsto be addressed i.e.
how to automatically identify and classifyrelevant popular app features across domains in the store?
tothe best of our knowledge there has been no attempt to explorethe relationships between cross domain apps and target apps to date.
c. feature ranking existing studies group and rank apps based on sentiment scores users opinions ratings topic frequencies social ranks etc.
derived from app reviews.
in topics are grouped andranked with frequent item set mining using lda or asum.the authors of group the review topics in terms ofsentiment scores extracted from users reviews.
in their recentwork authors use btm topic modeling for groupingand social weight function for ranking.
in authors groupreview aspects using frequent item set mining along with itssentiments and opinions.
in authors introduce clap crowd listener for release planning to group reviews intoclusters and prioritize them using a rating function.
however these existing studies group and rank the extracted app reviewaspects sentiment scores user opinions and rating scoresfor the target app only.
this grouping and ranking do notnecessarily provide a comparative view of app features oraspects in high demand across other domains.
iii.
a pproach our approach to mining and recommending features from cross domain apps for a given target app has the followingthree major components corresponding to the three steps infigure feature extraction identify relevant crossdomain appsidentify complementary cross domain featuresfiltering grouping ranking of featuresapp description app descriptionscross domain featurestarget app features step step step target app cross domain apps pre processing step fig.
.
overview of our approach a technique that allows us to accurately identify crossdomain apps that are relevant to the target app in terms of semantically similar features between the target app andcross domain apps.
this is done by extracting the appfeatures from their descriptions and analysing the featuresimilarity between the target app and each of the cross domain apps section iii a .
a technique that identifies features from the relevant cross domain apps that are different from but complementary to the target app s features for potential adoption by the target app.
this is achieved by collecting thosefeatures of the relevant cross domain apps that are dis similar i.e.
novel and or diverse to the features of thetarget app and partitioning these coexisting dissimilarfeatures into groups with each containing semanticallysimilar features and representing a complementary featureto the target app section iii b .
a technique that ranks the complementary features to provide adoption recommendations to the target app sdevelopers.
each complementary feature is scored ac cording to the distribution of features apps domains and app popularity associated with the features in thecoexisting dissimilar feature group represented by thecomplementary feature.
finally complementary featureswith high scores are recommended for adoption by thetarget app section iii c .
we discuss these three components in the following sections.
a. identification of relevant cross domain apps since the number of cross domain apps is large it is important to identify those that are specifically relevant to the target app.
to do this we first run a pre processingstep to clean up all unnecessary and irrelevant symbols andword tokens from the app descriptions.
then we extract theapp features of the target app and each of the cross domainapps from their descriptions.
finally we use a feature basedsimilarity assessment technique to identify the relevant cross domain apps that have a set of features similar to the targetapp.
pre processing app descriptions in the pre processing step we clean the apps text descriptions by removing allthe unnecessary symbols numbers hyphen characters tags and spaces.
then we discard the urls emails and all theenglish stopwords like to for the etc.
from theapp descriptions.
stopwords usually have little lexicalcontent but are not easily distinguishable from other texts.we remove them by using the python libraries nltk .finally we manually built our own dictionary with respect tothe app domain for the removal of unnecessary words suchas1 letter letters app names connecting words auxiliary verbs adverbs praising words etc.
a portion of the dictionary has been shown below inc etc able typical yet otherwise welcome none done ago recently still wait today soon always app also even ever available please much almost many 2g x facebook viber ... this pre processing step makes sure that the apps features as presented in the app descriptions are preserved without majorloss of information.
extracting functional app features in this step we extract features from both the target app and the cross domainapps.
cross domain apps are those that do not belong to thesame category as the target app.
take app canvas for example.it belongs to the education category.
cross domain appsare the apps that belong to categories other than education.note that we focus on apps functional features because they 745determine the apps core functionalities and the popularity of an app depends mainly on its functional features .unlike app reviews which usually focus on non functionalfeatures app developers often describe their apps functionalities in app descriptions .
therefore we extract the apps functional features from their descriptionscrawled from publicly available app store pages see sectioniv a for details .
we follow the approach proposed in that uses partsof speech patterns and sentence patterns to extract featuresfrom app descriptions.
we found this approach efficient in thatit does not require training and configuration datasets to extractfeatures.
moreover this method excels at extracting featuresfrom formal texts like app descriptions.
to be more precisein feature extraction however we made some improvementsin our implementation concerning the following aspects feature mentioned in double quotation feature starting withthe word feature and feature mentioned in capitalizedwords.
the pre processed app descriptions are first tokenisedusing a word tokeniser and then tagged with the parts of speech pos analysis done by using the stanford pos taggers library the world s richest pos taggers libraryfor natural language processing nlp .
finally the tokenisedand tagged app descriptions are fed into the feature extractionengine.
an example of the features extracted from facebook messenger s app description is shown below video chat share stories group video chat voice message share photos share your location send money use speech text feature find deals ... in this step we extract all the features from each of the target and cross domain apps and store them separately in a featuredatabase.
feature based relevance of cross domain apps our purpose is to identify the cross domain apps that are relevant tothe target app.
we do so by locating those cross domain appsthat have a set of features similar to those of the target app.the remaining cross domain apps are considered as irrelevantand are removed from further consideration.
to do this we calculate the semantic relevance between the features of the target app and the features of each cross domainapp.
to compute the feature by feature semantic similaritybetween apps we adopt wordnet one of the mostpopular and standard tools used by researchers for measuringsemantic relevance between words and phrases.
given twowords or phrases a similarity score can be calculated basedon the shortest path between them in wordnet .
since ourextracted features are already tokenised wordnet provides fastsimilarity score without the need for a large training corpuslike word2vec .
first we represent all the extracted features from a crossdomain app with an app feature matrix.
let us denote thefeatures extracted from an app in a given domain as f f ...fn .
then for mapps in a domain there will be a mxn appfeature matrix.
given kdomains the final feature matrix will bemxnxk for each single target app tas shown in figure .for each app in the cross domains the feature matrix containsitsfeature set app id domain id.
app app app app mcross domain apps feature feature feature feature feature nfeature 5cross domain features cross domain cross domain cross domain cross domain k ... ... fig.
.
cross domain app feature matrix after the formation of the cross domain app feature matrix we compute the relevance of each cross domain app to thetarget app in terms of their feature similarity.
we adopt the wu palmer wup path similarity between the two feature sets ofthe cross domain app and target app for the wordnet model as it provides a good semantic relatedness measure .
thesimilarity score ranges between and where means nomatch found and means a perfect match with the target app.we consider those cross domain apps with a similarity scoreabove a threshold as relevant to the target app and filter out all the apps below this threshold.
in this study we choosethe similarity score of .
as the threshold i.e.
.
indicating that a cross domain app with a similarity score of0.33or higher is relevant to the target app.
b. identification of complementary cross domain features in this step our goal is to automatically identify those unique features of the relevant cross domain apps that donot exist in the target app in terms of semantic similarity as complementary features for the target app.
to do so weneed to identify those features of all the relevant cross domain apps that are semantically different from the targetapp s features called coexisting dissimilar features or simply coexisting features and put these coexisting featuresinto groups with each group being a maximum subset ofthese features that are similar to each other.
each of thecoexisting feature group represents a complementary crossdomain feature for the target app.
identifying coexisting features in this phase we make sure to eliminate all the features of a relevant cross domainapp that are similar to those of the target app and keep theother coexisting features.
that is the coexisting features arethe set or subset of features from the feature matrix that aredissimilar to those of the target app.
for example if a targetapp t which has features t f ft1 ft2 ft3 ...ftl has similar features f f12 f13 from a cross domain app c1 which has features c1f f11 f12 f13 f14 ...f1n then features f ...f1n are considered as coexisting features.
we are interested in the coexisting features mainly becausethey are dissimilar diverse and novel relative to the target app 746f11 f12 f13 f14 f15 ... f1n f21 f22 f23 f24 f25 ... f2n f31 f32 f33 f34 f35 ... f3n ... ... ... ... ... ... ... fm1 fm2 fm3 fm4 fm5 ... fmnapp app app app m...target app features ft1 ft2 ft3 ft4 ft5 ... ftlcross domain apps relevance matching app similarity fig.
.
coexisting features in relevant cross domain apps and are potentially useful to the target app.
figure illustrates feature coexistence in relevant cross domain apps for a giventarget app with the features similar to the target app s featuresbeing shown in dashed blocks .
grouping coexisting features after removing all those features of the cross domain apps that are similar to the targetapp s features all the remaining features are dissimilar to thetarget app s features while also being part of the cross domainapps and therefore are referred to as dissimilar coexisting features.
we put all these coexisting features together ina single set and partition them into semantically differentgroups with each representing a complementary cross domainfeature for the target app.
algorithm presents this semanticsf11 f12 f13 f14 f15 ... f1n f21 f22 f23 f24 f25 ... f2n f31 f32 f33 f34 f35 ... f3n ... ... ... ... ... ... ... fm1 fm2 fm3 fm4 fm5 ... fmnapp app app app mfeature grouping by semantic relevance ...cross domain appsf1ff1ff1n f2ff2ff2n f3ff3ff3ff3n f3ff3ff3ff34 ...f1ff1ff14 f1ff1ff15 f2ff2ff25 f3ff3ff3ff35similarity fig.
.
grouping coexisting features based feature grouping process.
for a feature fiin the initial coexisting feature set f line we compare it against all the other features in the same set line .
all the features thatare similar to f iaccording to wordnet with a threshold i.e.
with a similarity score s ij equal to or higher than the threshold lines form a coexisting feature group lines in the final feature group set flist line .
we do this because developers may describe the same functionalfeature in different ways.
for example share photos and share images are considered as similar features.
in our study we set the value of .
line following an existing work .
when a match is found we form a coexisting feature groupand remove this feature from the initial master set lines .
thus each time a group is formed the size of the masterset is reduced line .
this process iterates until the masterlist is empty.
when the algorithm terminates line thefinal feature group set f listcontains all the coexisting featurealgorithm semantics based feature grouping input f ... set of coexisting features result flist ... ... ... coexisting feature groups 1import package nltk 2import package wordnet 3flist initialise output 4 .
initialise threshold 5k 6foreachfi fdo 7fn f fi 8k k foreachfj fndo sij wordnet.semanticsimilarity f i fj ifsij then flistk savefeatureclass f i fj sij fn fn fj end end 16f fn 17end 18returnflist groups with each containing semantically similar coexistingfeatures.
figure illustrates some coexisting feature groups in dashed blocks with green background with f f15 f25 f35 being such a group containing semantically similar features.
below are some example features in a coexisting featuregroup for target app facebook messenger cross domain features feature app id transfer files com.lenovo.anyshare.gps transfer large files com.dewmobile.kuaiya.play transfer pictures transfer music cn.xender c. feature ranking the final step in recommending the complementary features for adoption by the target app is to rank and prioritize them.our feature grouping technique from the previous step pro duces a set of complementary features or coexisting featuresets where each feature set contains several coexisting butsemantically similar features.
note that stored together witheach feature in the feature set are by its app id as shown in the above example and other relevant information such as appdownloads app name etc.
although we consider coexisting features relevant to the target app as complementary features these features may ormay not be suitable for the target app.
to identify personalised or most suitable features for the target app to adopt weconsider key aspects when ranking those features and derivean aggregated ranking score for each coexisting feature set.only the top ranked complementary features or feature sets are recommended to for adoption by the target app.
the4 key ranking attributes are i domain distribution ii app distribution iii popularity i.e.
download distribution and iv feature distribution.
domain distribution d s the distribution of the features in a coexisting feature group over the app domains.
this is a ratio between the number of domains that thecoexisting features in the group belong to over the totalnumber of domains that all the relevant cross domainapps belong to.
it is essential to consider the rangeof domains involved because the use of a feature inmultiple domains indicates its popularity or reach acrossthose domains.
this is confirmed in where theauthors mentioned that a strongly migratory feature hasno categories i.e.
domains and can move across the appstore.
on the other hand a feature being only used in alimited number of domains indicates its limited ability incross domain migration.
thus we prioritise a coexistingfeature group with its features reaching a larger numberof domains.
for any target app if dis the total number of relevant cross domains and dis the number of domains that a coexisting feature group has features in this group sdomain distribution d s is calculated as d d .
app distribution a s the distribution of the features in a coexisting feature group over the apps.
this is a ratiobetween the number of apps that the coexisting featuresin the group belong to over the total number of all therelevant cross domain apps.
this is an important criterionbecause if a feature is shared by multiple apps the featureis likely to be useful to the target app.
multiple featuresfrom the same app appearing in a coexisting featuregroup see example in section iii b limits the range ofapps it reaches.
considering app distribution reduces thisconcentration effect and prioritises a coexisting featuregroup that covers a wider range of apps.
for any targetapp ifnis the total number of relevant cross domain apps and nis the number of apps a coexisting feature group has feature in the group s app distribution a s i s calculated as n n .
popularity distribution p s the distribution or weighting of the popularity i.e.
app downloads of appsinvolved in a coexisting feature group.
this is a ratiobetween the accumulative popularity downloads of appshaving features in the coexisting feature group over theaccumulative popularity downloads of all the relevantcross domain apps.
popularity distribution of an app isimportant because a popular app tends to have popularfeatures which contribute to its downloads .therefore if a feature is offered by apps with highdownloads it is also likely to be more useful to thetarget app.
for any target app if nis the total number of relevant cross domain apps and nis the number of apps a coexisting feature group has feature in the group spopularity distribution p s is calculated as ps summationtextn j 1pgj summationtextnk 1prk wherepgis the downloads of each app involved in the coexisting feature group and pris the downloads of each relevant cross domain app.
feature distribution f s the distribution or weighting of coexisting features of the apps involved in a coexisting feature group.
this is a ratio between the accumulativenumber of coexisting features of the apps having featuresin the coexisting feature group over the accumulativenumber of coexisting features of all the relevant cross domain apps.
feature distribution in a group affects thepopularity of the group since the same feature fromdifferent apps may contribute to one group and viceversa.
for any target app if nis the total number of relevant cross domain apps and a feature group thatcontains features from nnumber of apps then the feature distribution f s is calculated as fs summationtextn j 1cfgj summationtextnk 1cfrk wherecfg is the number of coexisting features of each app involved in the coexisting feature group and cfr is the number of coexisting features of each relevant crossdomain app.
finally we compute a single ranking score for each of thecoexisting feature group i.e.
a complementary feature bytaking the mean of the aggregated distribution scores of allthe attributes discussed above.
we sort and rank the comple mentary features for recommendation to the target app.
iv .
e xperiment setup we have run extensive experiments on a large number of cross domain apps.
section iv a introduces the datasetused throughout the experiments section iv b describes thevalidation methods and section iv c presents the evaluationmetrics used.
a. dataset to facilitate the experiments we have crawled the google play store for the period of nov to jan and produced a required dataset.
it contains apps in 41categories.
we have removed those categories with apps orfewer.
finally our curated dataset contains apps in 31categories which also excludes the games category becauseof the different structure in its app descriptions .
then we have randomly chosen categories and target appsfrom each category forming a set of target apps fromthe communication education book and ref.
health and fitness shopping finance lifestyle productivity maps andnavigation categories or domains .
for each target app we run our approach on all the corresponding cross domain apps in the dataset.
note that thefeature extraction step is run on all the apps in all categoriesonce only and the results are stored in the feature database foruse in all further steps of our approach see section iii a .
the dataset and experiment results can be found in a github repository at 748b.
v alidation methods we validate our techniques for identification of relevant cross domain apps for any given target app semanticsbased feature grouping of coexisting features from crossdomain apps and ranking and prioritisation of complementary cross domain features to make recommendations to the target app s developers.
we have used a manually built truth set to validate the relevance of cross domain apps to thetarget app while we validate the feature grouping and rankingtechniques by conducting a user study.
we also compare oursemantics based feature grouping technique against two otherpopular techniques used for feature grouping.
further detailsof the validation methods can be found below in sections v a v b and v c. c. evaluation metrics to evaluate the technique for identifying relevant crossdomain apps we have used popular metrics precision recall and f score as defined in precision tp tp fp recall tp tp fn f score precision recall precision recall wheretp true positive is the number of features correctly found fp false positive is the number of features not correctly found and fn false negative is the number of features incorrectly excluded with respect to the truth set offeatures.
the f score is the harmonic mean of the precisionand recall.
to validate the ranking technique for the identified complementary features or coexisting feature groups we adoptthe well known normalized discounted cumulative gain ndcg as a measure for evaluating the quality of top kranking results ndcg k dcg k idcg k wherekis the number of top features to be considered dcg is the calculated ranking of the features and idcg is the ideal ranking of the same features in a truth set obtainedfrom the user study.
ndcg k is within the range of and a higher value implies greater agreement between thecalculated rank order and the ideal rank order.
v. r esults analysis and discussion in this section we discuss the experimental results of our techniques for identifying relevant cross domain apps group ing and ranking complementary cross domain app features.
wealso make some observations from these results and discussthe limitations of our approach and evaluation process.table i precision p r ecall r and f m easure f for identifying relev ant cross domain apps no target domain precision p recall r f score f communication .
.
.
education .
.
.
book reference .
.
.
health fitness .
.
.
shopping .
.
.
finance .
.
.
lifestyle .
.
.
productivity .
.
.
business .
.
.
maps navigation .
.
.
average .
.
.
a. identification of relevant cross domain apps we have run our relevant app identification technique see section iii a3 for each of the target apps from 10target domains over the apps in categories of thecurated dataset see section iv a .
for example for facebook messenger as a target app from the communication category we have identified more than relevant cross domain appsacross different domains in our experimental dataset i.e.
tools social music audio photography productivity en tertainment video players editors and lifestyle with eachhaving feature similarity with facebook messenger higher thanthe set threshold .
.
to validate the relevant cross domain apps identified by our technique we have manually created a truth set of cross domain apps corresponding to target apps one from eachcategory .
then we run our relevant app identification tech nique on the apps in the truth set.
the results are summarizedin table i. after running our experiment we have found that our technique produces mostly high precision recall and f scores with a large majority over .
.
however significantly lowerp r and f scores are observed for some target apps fromfinance p .
and maps navigation f .
domains.after further investigation we have found that the target appsfrom the finance and maps navigation domains had a verypoor app description.
for example the didi app from the maps navigation domain had a very generic app descriptionwhich caused poor feature extraction and resulted in a poorrelevance score.
however for all the target apps we haveachieved an average of .
.
and .
as p r and fscores respectively.
as such our proposed technique has beenshown to be effective in finding relevant cross domain apps fora given target app.
b. semantics based feature grouping in these experiments we compare our semantics based feature grouping technique with two other representative techniques k means clustering is one of the most commonly used grouping techniques in feature mining.
the k meansapproach starts off with a set of kseeds and assign documents set of features in our case to these seeds on 749table ii comparison between feature grouping techniques facebook messenger video editor file transfer file upload game chat save files share translation text to speech translation video editor transfer files app upload images face game save your effort share translati ons translate speech hd pro video editor transfer speed enables fil e upload strategy games save your effort space share button speech recognition video editor maker transfer large files improves file upload chat sessions save videos share word definition speech text editor transition effects transfer files friends file upload gamer chat status saver status share text supported speech video editor emoji file transfer file uploads multiplayer games insta saver videos share texts include text speech editor blur background transfer needs file upload easy fps games save high quality photos share translations speech recognition video editor text transfer videos enable file upload watch gamers saved your gallery share your findings text speech video editing features transfer files friends file upload photos mmo rpg games save favorite videos share word definition speech bubbles video editor transfer pictures upload videos online gamer chat save videos share photos text speech video editor transfer files upload video files online chat save images share texts speech translator video feature editor transfer music easy file upload game chat stream save favorite photos function share speech text feature feature editor transfer anything file upload s e t i r o v a f r u o y e v a s d e e p share translations translate speech text o v a f e v a s s p p a r e f s n a r t d n u o r g k c a b r o t i d e o e d i v rite file share translation use speech text feature a s a t a d l a n o s r e p r e f s n a r t t i d e d n u o r g k c a b o e d i v ve fast image share option pro video editor transfer files allow share video editor effects transfer files quick share translations transfer files server share words .
.
.
.
.
.
y c a r u c c a .
video editor file transfer file upload game chat save files share translation text to speech translation editor transfer upload chat save share speech video files file gamer favorite translations text background games easy online videos texts recognition feature friends uploads sessions effort definition translate effects status videos stream photos word feature s e g a m i e m a g e l b a n e s d e e n o r p words bubbles emoji music enables function space button supported maker apps improves features insta findings include edit pictures speed file image function translator editing speed photos files fast option language features videos app findings saver translation use h g i h s e l i f r e y a l p i t l u m r u l b photos friends y t i l a u q s e g a m i s p f t x e t text image e l i f o e d i v y g e t a r t s n o i t i s n a r t allow e l i f d h function data transfer .
.
.
.
.
.
y c a r u c c a .
video editor file transfer file upload game chat save files share translation text to speech translation video speed translate file save share speech editor background gallery upload video translation text e t i r o v a f e m a g d e v a s r u l b r e f s n a r t recognition feature a t s n i t a h c n o i t p o g n i t i d e e l i f word use friend feature personal photo fast definition translator y t i l a u q h g i h r e f s n a r t a t a d o e d i v o r p effect language emoji editor anything image background allow bubble t i d e r e m a g d h r e f s n a r t s p p a button include maker upload transfer saver picture finding supported r e v a s s u t a t s o r p e l i f d h function recognition effect gallery speech easy photo transition translate e g a m i e n i l n o t x e t y t i l a u q h g i h d e e n need editing transition insta share effort effort maker share picture status editor enable space option editor music saver video improves file photo video .
.
.
.
.
.
y c a r u c c a .
k means feature clustering overall accuracy .
topic modelling lda based feature grouping overall accuracy .
overall accuracy .
6hpdqwlfv based hdwxuh grouping the basis of closest similarity.
a new seed is defined in each next iteration so that it is a better central point for thegroup and this approach is continued until convergence.
anumber of recent studies employ k means clustering forfeature categorisation with good performance .
latent dirichlet allocation lda is a generative probabilistic topic modelling technique used for topic identifi cation from documents containing a mixture of topics intextual corpora.
lda is a popular unsupervised machinelearning technique used by researchers to identify topicsfrom a group of terms .
in this work we run our semantics based feature grouping k means clustering and topic modeling lda techniques onthe identified coexisting cross domain features for each of the100 target apps.
to be consistent with our feature groupingtechnique we set the value of k number of clusters in kmeans or number of topics in lda to be the same as thenumber of groups generated by our approach.
each resultingcoexisting group is given a name or label.
for example table ii summarizes the grouping outcomes for facebook messenger.
we validate the grouping outcomes of all three techniques by software practitioners phd students researcher and software developers and asked them to score if theyfind the feature grouping is appropriate in terms of semanticsimilarity.
for example the user scores if they find thatfeature video transition effects is relevant to the feature group video editor.
we find that lda performs the lowest whilek means clustering performs slightly better than lda.
ourtechnique outperforms the other two techniques in termsof individual groups and overall group averages with ourtechnique s overall accuracy being above .
this validatesthe effectiveness of our technique.
750c.
feature ranking we run the feature ranking experiments on all the complementary features i.e.
coexisting feature groups for a target app.
for example in our dataset we have found severalcomplementary features for facebook messenger as the target app including video editor file transfer save files etc.
then we run our ranking technique see section iii c on thesegroups rank them for prioritised recommendation to the targetapp.
for example the rankings for the coexisting featuregroups for facebook messenger see table ii is shown intable iii.
table iii ranking of complementary cross domain features no feature group coexisting features ranking file transfer transfer large files ..... ... .
save file save videos save images ... .
video editor video editor feature editor ... .
file upload improve file upload .... ..... .
game chat online chat face game .... .
we run feature ranking for all the target apps in our dataset and evaluated our ranking results using ndcg k. ndcgis normally used to rank documents retrieved from searchengines.
dcg is the actual ranking of documents whereasidcg is the ideal ranking of the same documents usuallyfound from a truth set.
in our case we calculate idcg from thetruth set with a user study involving software practitioners as mentioned in section v a .
since it is infeasible for ourusers to rank all complementary features for target apps we randomly selected target apps one per domain andidentified a total of complementary features.
then weasked the users to rank the features recommended for eachof the target app based on the ranking attributes explained insection iii c. in this way an idcg score can be calculatedfor each of the identified complementary feature.
table iv summarises the overall ndcg ranking evaluation that considers the top ranked complementary featuresextracted from the cross domain apps.
for clear understand ing we also include additional attributes such as number of coexisting features number of cross domain apps and number of cross domains relating to each complementary feature for a target app.
as can be seen in table iv the number ofrelevant cross domain apps varies depending on the targetapp.
for example relevant apps were found for facebookmessenger from different domains and found for zoomfrom domains.
however gumtree has only one relevantcross domain app carsales from the lifestyle domain andhas only one complementary feature live ad stats.
since there is only one complementary feature found for gumtree itsndcg score is .
no score is determined for the canvasapp because no relevant app was found from other domains.
in summary based on our empirical evaluation the ndcg scores are higher than .
for each of the targetapps.
though there is a slight difference in ranking per targetapp per domain the overall average ndcg score is higherthan .
across all categories for all the target apps.
thisvalidates the effectiveness of our approach.
d. discussion from our experiments we have drawn the following observations and actionable insights that might be helpful for the target app developers.
observation a very popular app such as facebook messenger standing at the top rank for a long period of timeusually offers multiple popular features as well as a well written description of those features.
due to this it matcheswith a large number of cross domain apps apps from8 domains for facebook messenger meaning that this app has more similarity with cross domain apps.
as such moresimilar features are found from other domains than dissimilarcoexisting i.e.
complementary features.
observation apps with more specific but less diverse features match very specific cross domain apps with simi lar features.
for example fitbit from the health domain matches with apps from domains lifestyle tools and personalisation .
the same happens in the case of gmail from the communication domain which contains specific featuresrelevant to email communications only.
observation there is high correlation shown between the target domain and the cross domains related to that targetdomain.
for example apps from the communication domainhave high relevance with the features from the productivityand tools domain.
more than of the complementaryfeatures for the communications domain are found from theproductivity and the tools domains and more than complementary features for the books and reference domainare found from the education domain.
observation unpopular or specific apps match only apps from the same domain and not those from cross domains.for example the didi app from the maps navigationdomain and the canvas app from the education domain didnot match any of the cross domain apps.
although both appsare popular in their own domains they offer features specificto only their own domains.
hence no relevant apps or featuresare found from other domains.
actionable insight based on observation the popular apps usually have a number of cross domain features.therefore developers might consider that the only reason forapp popularity is borrowing features from cross domains.however after further investigation we have found that thisis not necessarily true.
first some popular apps do not havecross domain features at all.
for example the didi app from the maps navigation domain and the canvas app from the education domain did not match any of the cross domainapps although they are ranked top in their own domains.second some unpopular apps may have a number of cross domain features.
for example ticktick is an unpopular app from the productivity domain which matches different appsfrom cross domains including lifestyle health fitness education business and tools .
751table iv ndcg v alidation results for complementary cross domain feature ranking target app category complementary feature coexisting features cross domain apps cross domains rank score facebook messenger communication file transfer .86save file video editor file upload game chat wikipedia books and reference share your knowledge .
search results v oice translation canvas education gum tree shopping live ad stats .
zoom business use filters .72message people share location watch news use custom sticker ticktick productivity increase positive energy .80receive daily quotes reduce your anxiety refresh morning routine instarem finance payout location .
exchange rate notification video support my eleven maps navigation show price .0save money earn point notebooks lifestyle record audio note .64attach files format your notes fitbit health fitness achieve your goal .78analyze report show distance score evaluate user data routine note each complementary feature corresponds to a set of similar coexisting features from cross domain apps that are relevant to the target app actionable insight when the app description is very short usually sentences vague or does not provide clear information about the app features the feature extractiontechnique is unable to identify the features as expected.
itmostly happens for low rank apps or new apps or beta releasesof apps where developers did not explain their app featuresformally and properly.
this may result in the extraction ofinaccurate features or no features at all which ultimately leadsto finding no relevant features from cross domains.
therefore developers should pay attention to providing clear and specificfunctional feature descriptions on the app description page.
actionable insight the fact that some apps have feature relevance with only one or two cross domain apps mayindicate that there might be miscategorisation of them.
thiscan happen because developers are free to upload their appsin any category regardless of the capabilities of their apps.further investigation shows that some miscategorised appsare not popular.
it is possible that some developers uploadthe beta version of their apps in different but closely relatedcategories to test the users interests.
actionable insight app developers should find the recommended features meaningful enough to understand asthe extracted features can have up to n gram word long n in our case .
for example the use speech text feature is a feature extracted from an app description which is grams words.
further examples can be found in section iii a2and table ii.
in case that further details are needed forrecommended features to gain a fuller understanding we alsokeep track of all the apps and app descriptions correspondingto the extracted and recommended features via their uniqueapp ids.
for example transfer files is a popular feature from app shareit and the linking of cross domain featuresand apps in section iii b shows that transfer files is from com.lenovo.anyshare.gps for app shareit.
as such we can easily trace a recommended feature back to its source i.e.
thecorresponding app description for more details when needed.
e. threats to v alidity we have extracted features from both the target app and the cross domain apps using an existing work .
we also consider that all the features extracted from app descriptionsare functional features.
but not all the features extractedby this method are actual features.
this technique may notextract proper features if the app description is not written inproper and formal english .
however to the best of ourknowledge this work produces the highest precision in featureextraction from text description written in formal english.
when creating the truth set for matching cross domain app features and ranking coexistent feature groups we have solelyrelied on human judgment.
since feature relevance mapping is 752subjective we have carried out a careful analysis to minimise biases.
we have also made sure that all disagreements wereresolved by debate and majority agreements among the au thors.
moreover software practitioners with varying appdevelopment experiences are included in the user study toachieve better diversity.
a threat to external validity is the representativeness of the domains categories and the target apps selected in theexperiments.
the experimental results are specific to thechosen target apps and may not be generalisable to otherapps.
to minimize this threat we have randomly selectedthe target apps from apps that belong to 10different app categories.
for each target app we have alsomade sure to run experiments across all the apps in allthe other categories in the dataset.
furthermore a usersurvey with excessive questions may discourage participantsfrom participating or completing the survey while a surveywith inadequate questions will make it difficult to collectcomprehensive feedback.
to ensure a proper user survey wehave conducted a preliminary user study and found that a totalof questions one for each target app are suitable for ouruser survey.
for recommendation purposes we have intended to validate our feature grouping and ranking techniques for all target apps.however it is infeasible to do it all manually.
to minimize thisthreat we took features randomly from the feature groupsand validated by annotators who are not authors.
this isan standard approach followed by other researchers .
vi.
c onclusion and future work in this work we have revealed the importance of crossdomain features for the evolution of software apps.
we haveproposed a new approach that mines cross domain featuresto make personalised feature recommendations for any targetapp.
to the best of our knowledge this is the first work thatmines popular complementary cross domain features from appstore repositories.
firstly we identify all the apps across other domains that are relevant to the target app where we usefeature based similarity between the target app and each ofthe cross domain apps to calculate the functional relevance ofthe cross domain app.
secondly we perform semantic based feature grouping on the features of all the relevant cross domain apps that are dissimilar to the target app s featuresto partition them into feature groups with each having similarfeatures.
finally we rank those feature groups to prioritise them for recommendation to the target app s developer.
wehave carried out comprehensive experiments on targetapps from categories over a app population from31 categories.
these experiments have generated encouragingresults in identifying grouping and ranking cross domain fea tures for recommendation with an accuracy rate of over .in addition our semantics based feature grouping techniquehas also been show to significantly outperform two existingbaseline techniques.
in general the empirical evaluation vali dates the usefulness of our approach.in the future we plan to extract and incorporate the requested features from the reviews of target apps when buildingfeature profiles for these apps putting an emphasis on rankingcross domain features requested in reviews.
we also plan toincorporate sentiment analysis into the feature recommenda tion process to improve recommendation accuracy.
753references covid apps apps accessed .
smart phone users around the world h ttps log how many phones are in the world accessed .
google inc. and apple inc. paid to developers om google billion android developers apple accessed .
b. carbunar and r. potharaju a longitudinal study of the google app market in proceedings of the ieee acm international conference on advances in social networks analysis and mining pp.
.
n. zhong and f. michahelles google play is not a long tail market an empirical analysis of app adoption on the google play app market inproceedings of the 28th annual acm symposium on applied computing pp.
.
g. j. balady survival of the fittest more evidence .
d. lim h. lee j. yoo and h. zo free to paid purchase and dropout behavior of mobile application users.
in pacis p. .
f. sarro m. harman y .
jia and y .
zhang customer rating reactions can be predicted purely using app features in ieee 26th international requirements engineering conference re .
ieee pp.
.
m. khurum t. gorschek and m. wilson the software value map an exhaustive collection of value aspects for the development of softwareintensive products journal of software evolution and process vol.
no.
pp.
.
b. fu j. lin l. li c. faloutsos j. hong and n. sadeh why people hate your app making sense of user feedback in a mobile app store inproceedings of the 19th acm sigkdd international conference on knowledge discovery and data mining pp.
.
n. chen j. lin s. c. hoi x. xiao and b. zhang ar miner mining informative reviews for developers from mobile app marketplace inproceedings of the 36th international conference on software engi neering.
acm pp.
.
j. lin k. sugiyama m. y .
kan and t. s. chua new and improved modeling versions to improve app recommendation in proceedings of the 37th international acm sigir conference on research develop ment in information retrieval pp.
.
c. gao j. zeng m. r. lyu and i. king online app review analysis for identifying emerging issues in proceedings of the 40th international conference on software engineering pp.
.
e. guzman m. ibrahim and m. glinz a little bird told me mining tweets for requirements and software evolution in ieee 25th international requirements engineering conference re .
ieee pp.
.
s. panichella a. di sorbo e. guzman c. a. visaggio g. canfora and h. c. gall how can i improve my app?
classifying user reviewsfor software maintenance and evolution in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
e. guzman and w. maalej how do users like this feature?
a fine grained sentiment analysis of app reviews in requirements engineering conference re .
ieee pp.
.
l. chen y .
yang n. wang k. yang and q. yuan how serendipity improves user satisfaction with recommendations?
a large scale userevaluation in the world wide web conference pp.
.
f. sarro a. a. al subaihin m. harman y .
jia w. martin and y .
zhang feature lifecycles as they spread migrate remain and die in appstores in requirements engineering conference re ieee 23rd international.
ieee pp.
.
report australia competition consumer commission accc.gov.au publications serial publications digital platform services inquiry digital platform services inquiry september interim report accessed .
report app annie rts app annie mobile app evolution report 2020 .pdf accessed .
a. blogs top mobile games that have social features incorporated jan. accessed .
a. drachen m. pastor a. liu d. j. fontaine y .
chang j. runge r. sifa and d. klabjan to be or not to be... social incorporatingsimple social features in mobile game customer lifetime value pre dictions in proceedings of the australasian computer science week multiconference pp.
.
theconversation.com tiktok is a unique blend of app versation.com tiktok is a unique blend of social media platforms her es why kids love it jan. accessed .
techcrunch.com tiktok consumer engagement om top mobile apps see declines in consumer engagement amid increased competition jan. accessed .
influencermarketinghub.com tiktok growth nghub.com tiktok growth jan. accessed .
l. villarroel g. bavota b. russo r. oliveto and m. di penta release planning of mobile apps based on user reviews in proceedings of the 38th international conference on software engineering .
acm pp.
.
y .
tian m. nagappan d. lo and a. e. hassan what are the characteristics of high rated apps?
a case study on free android applications in2015 ieee intl.
conf.
on sw maintenance and evolution icsme .
ieee pp.
.
e. guzman r. alkadhi and n. seyff a needle in a haystack what do twitter users say about software?
in ieee 24th international requirements engineering conference re .
ieee pp.
.
x. gu and s. kim what parts of your apps are loved by users?
t inautomated software engineering ase 30th ieee acm international conference on.
ieee pp.
.
nltk natural language toolkit accessed .
a. a. al subaihin f. sarro s. black l. capra m. harman y .
jia and y .
zhang clustering mobile apps based on mined textual features inproc.
of the 10th acm intl.
symposium on empirical sw engg.
andmeasurement.
acm p. .
w. martin f. sarro y .
jia y .
zhang and m. harman a survey of app store analysis for software engineering ieee transactions on software engineering vol.
no.
pp.
.
m. harman y .
jia and y .
zhang app store mining and analysis msr for app stores in proceedings of the 9th ieee working conference on mining software repositories.
ieee press pp.
.
a. ahmad c. feng k. li s. m. asim and t. sun toward empirically investigating non functional requirements of ios developers on stackoverflow ieee access vol.
pp.
.
n. jha and a. mahmoud mining non functional requirements from app store reviews empirical software engineering vol.
no.
pp.
.
m. lu and p. liang automatic classification of non functional requirements from augmented app user reviews in proceedings of the 21st international conference on evaluation and assessment in softwareengineering pp.
.
l. hoon r. vasa j. g. schneider j. grundy et al.
an analysis of the mobile app review landscape trends and implications faculty of information and communication technologies swinburne university oftechnology tech.
rep .
y .
liu l. liu h. liu x. wang and h. yang mining domain knowledge from app descriptions journal of systems and software vol.
pp.
.
d. lavid ben lulu and t. kuflik functionality based clustering using short textual description helping users to find apps installed on theirmobile device in proceedings of the international conference on intelligent user interfaces.
acm pp.
.
t. johann c. stanik w. maalej et al.
safe a simple approach for feature extraction from app descriptions and app reviews in ieee 25th international requirements engineering conference re .
ieee pp.
.
stanford stanford pos tagger library the richest pos tagger library online htt ps nlp.stanford.edu software tagger.shtml feb. accessed .
p. university w ordnet lexical dictionary u jan. accessed .
g. a. miller wordnet a lexical database for english communications of the acm vol.
no.
pp.
.
y .
goldberg and o. levy word2vec explained deriving mikolov et al.
snegative sampling word embedding method arxiv .
.
z. wu and m. palmer verbs semantics and lexical selection in proceedings of the 32nd annual meeting on association for computational linguistics.
association for computational linguistics pp.
.
y .
ouyang b. guo x. lu q. han t. guo and z. yu competitivebike competitive analysis and popularity prediction of bike sharing appsusing multi source data ieee transactions on mobile computing vol.
no.
pp.
.
y .
wang n. j. yuan y .
sun c. qin and x. xie app download forecasting an evolutionary hierarchical competition approach.
inijcai pp.
.
e. malmi quality matters usage based app popularity prediction inproceedings of the acm international joint conference on pervasive and ubiquitous computing adjunct publication pp.
.
a. finkelstein m. harman y .
jia f. sarro and y .
zhang mining app stores extracting technical business and customer rating informationfor analysis and prediction rn vol.
p. .
j. han j. pei and m. kamber data mining concepts and techniques.elsevier .
y .
wang l. wang y .
li d. he w. chen and t. y .
liu a theoretical analysis of ndcg ranking measures in proceedings of the 26th annual conference on learning theory colt vol.
p. .
a. al subaihin f. sarro s. black and l. capra empirical comparison of text based mobile apps similarity measurement techniques empirical software engineering vol.
no.
pp.
.
p. m. vu t. t. nguyen h. v .
pham and t. t. nguyen mining user opinions in mobile app reviews a keyword based approach t in2015 30th ieee acm international conference on automated softwareengineering ase .
ieee pp.
.
e. noei d. a. da costa and y .
zou winning the app production rally in proceedings of the 26th acm joint meeting on european software engineering conference and symposium on the f oundationsof software engineering pp.
.
m. nayebi h. cho and g. ruhe app store mining is not enough for app improvement empirical software engineering vol.
no.
pp.
.