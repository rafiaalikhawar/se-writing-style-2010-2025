flaky test detection in android via event order exploration zhen dong nationaluniversity of singapore singapore zhen.dong comp.nus.edu.sgabhishek tiwari nationaluniversity of singapore singapore dcsabhi nus.edu.sg xiao liang yu nationaluniversity of singapore singapore xiaoly comp.nus.edu.sgabhik roychoudhury nationaluniversityof singapore singapore abhik comp.nus.edu.sg abstract validation of android apps via testing is difficult owing to the presenceofflakytests.duetonon deterministicexecutionenvironments asequenceofevents atest mayleadtosuccessorfailurein unpredictable ways.
in this work we present an approach and tool flakescanner for detecting flaky tests through exploration of event orders.
our key observation is that for a test in a mobile app there is a testing framework thread which creates the test events a main user interface ui thread processingthese events and there may be severalother backgroundthreads runningasynchronously.
for anyevent ewhoseexecutioninvolvespotentialnon determinism we localize the earliest latest event after before which emust happen.
we then efficiently explore the schedules between the upper lowerboundeventswhilegroupingeventswithinasingle statement tofindwhetherthetestoutcomeisflaky.wealsocreate a suite of subject programs called flakyapprepo containing widely used android projects to study flaky tests in androidapps.
our experiments on the subject suite flakyapprepo show flakescanner detected out of known flaky tests as well as previously unknown flaky tests among tests.
ccsconcepts software and its engineering software testing and debugging keywords flaky tests non determinism concurrency event order acm reference format zhen dong abhishek tiwari xiao liang yu and abhik roychoudhury.
.
flaky test detection in android via event order exploration.
in proceedings of the 29th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa pages.
introduction regression testing aims to discover the adverse effects of the recently added code changes.
ideally a test failure during regression esec fse august athens greece copyright held by the owner author s .
acm isbn .
however sometestfailuresarenotduetotherecentupdatesbut due toflaky tests.
recent research establishes flaky tests as tests that non deterministically pass or fail when running on thesamecodeversion.unfortunately thepresenceofflakytests significantlyharmsdevelopers productivity .
androidisareactivesystem anditsnon deterministicexecution environmentoftencausesconcurrency relatedflakytests.inandroid a gui test usually simulates user interactions to exercise the app s functionality.
however due to non determinism a test could generate such interactions at incorrect timings.
for example a testtodownloadanimageandthenopenitwithoutconsideringtheinternet sspeedcouldsho wnon deterministicbehavior.apotential reasonforsuchconcurrencyissuesisthelackofsynchronization among threads e.g.
in the failing run a background thread would still be downloading the image while the testing thread tries to open it without synchronization with the background thread.
recent studies confirm that such synchronization issues lead to a significant number of flaky tests in android apps.
thorveet al.
studied flakiness related commits in android projects and discovered that failures are due to synchronization issues between testing thread and app under test e.g.
a test accessesdata in the app before the data is available.
similarly romanoet al.
s study shows that flaky test failures are caused by threads synchronization issues tests interacting with the ui elementsbefore the elements are fully loaded .
challenges.
exposingaconcurrency relatedflakytestinatest suite is challenging as such flakiness is only observed when events get executed in a particular order.
in android a test s event executionordermayshownon determinismduetothenon deterministic execution environment.
some of such irregular event orders may cause a test to fail pass occasionally.
consequently detecting such a situation would require exploring such event orders deterministically unfortunately thisposesasetofchallengesfortheexisting flakytest detectionapproaches whichwe discuss below.
rerun.atypicalwaytodetectaflakytestistorerun expressed asrerun it multiple times.
if it passes in some runs and fails in others thetestismarkedasflaky.however thisapproachcan struggle to detect concurrency related flaky tests because the target s execution environment may not introduce the needed non determinism.
besides it may require too many runs to witnessthe flakiness.
noise based.
several approaches run tests with environmental perturbations e.g.
changing cpu load or test executionorders inthehopeofobservingunexpectedbehaviors.
367this work is licensed under a creative commons attribution international .
license.
esec fse august athens greece zhen dong abhishek tiwari xiao liang yu and abhik roychoudhury despite being simple and easy to be adopted in practice adding noisedoesnotguaranteetoexploredifferentexecutionorders.
consequently theyfailtodetectmanyconcurrencyrelatedflaky tests as observed during our experiments.
event race.
the concurrency related flakiness may be caused due to a synchronization problem on the testing thread.
besides a concurrency bug on the app under test could also cause a non deterministic test failure.
thus in principle approaches identifying concurrency bugs should also detect a subset of such flaky tests.
recent works leverage program analysis techniques to analyze possible races in android apps.for instance eventracer records the execution trace of a test and statically analyzes it to find potential races.
however suchapproachesarepronetomultiplefalsepositives whichmay create more problems for the developers during the continuous integration ci process.
ourapproach.
weintroducea lightweighttechniquethatautomatically detectsa concurrencyflaky test inandroid appswithin few test runs.
our technique explores the possible event execution orders in a test by scheduling a non deterministic async event suchthateachtestrunexploresadifferenteventexecutionorder.
besides we identify and explore event orders in which the test flakinessmanifestssuchthataflakytestcanbedetectedinafew test runs.
insight.possibleeventexecutionordersareintroducedbynondeterministic execution of async events .
android apps use a concurrent event driven model in which only the main ui thread can access gui and processes user events.
to keep gui responsive the ui thread offloads a long running task e.g.
internet accessing to a background thread.
once the task is finished the background threadsendsanevent called asyncevent totheuithreadtoperformaguiupdate.inatestrun thetestingthreadandbackground threadssendeventstotheuithreadsimultaneously resultingin racesamongtheevents thetestmaypassforsomeeventordersand fail inothers.
for the examplementioned earlier thetesting thread simulatesthe opentheimage event andthebackgroundthread downloadstheimageandsendsanupdateeventaftercompleting thedownload.aracemayoccurbetweenthesetwoevents.ifthe internetisfast theupdateeventreachestheuithreadbeforethe opentheimage event andthetestpasses.otherwise the open the image event is processed first and the test fails.
eventorderexploration.
leveragingtheseinsights ourapproach explores possible event execution orders by scheduling an async event in a test run.
our approach first identifies the schedule space foreachasynceventwithdynamicanalysisandschedulestheasync eventinitsschedulespacetoavoidinfeasibleorders.tomanifest aflakytestfailurequickly ourapproachscheduleseventsatpositions where the test is more likely to fail.
specifically it schedules an async event at a statement boundary position .
the statement boundarypositionisbetweenthelasteventthatateststatement triggers and the first event that the next statement triggers.
we note that the tests are often flaky due to missing an appropriatesynchronizationoperationbetweentwoteststatements e.g.
the synchronizingoperationafterclickingadownloadbutton.thuswearemorelikelytotriggeratestfailureifanasynceventisexecuted afterexecuting certain test statements.instrumentation freetool.
weimplementourapproachintoatool calledflakescanner which leverages the debug mode supported in theandroidframeworktoperformdynamicanalysisbasedevent scheduling.thus flakescanner requiresnoinstrumentationineitherandroidappsortheandroidframeworkandworksonboth androidemulatorsanddevices.accordingtothestudy codeinstrumentation often disrupts test executions and prevents the manifestation of flaky test failures.
moreover flakescanner supports multiplewidely usedtestingframeworkswithwhichdevelopers writetestssuchas espresso or robotium .
experiment.
weevaluated flakescanner on33widely usedandroidprojects.ourexperimentsshowthat flakescanner successfullydetected45outof52knownflakytests.onaverage itdetected a flaky test within three test runs.
flakescanner outperformed the recentlypublishedflakytestdetectiontechnique shaker and thebaselinetoolrerunintermsofboththenumberofdetected flaky tests and average execution time.
flakescanner also detected flaky tests that were previously unknown.
out of these unknown flaky tests we reported to developers out of these have been confirmed and addressed by developers.
contributions.
our contributions can be summarized as follows we present an event scheduling approach that explores different event execution orders for each test run to detect concurrency related flaky tests in android apps.
to avoidexploring all possible event orders our approach adopts heuristics to identify and explore event orders in which the testflakiness is likely to occur.
we implement our approach into an instrumentation free tool that works on android emulators and physical devices whilesupporting widely used android testing frameworks.
we curate a suite of subject programs containing widelyused android projects with developer tests called flakyapprepoforevaluatingflakytestdetectiontechniques.tofacilitatefutureresearchonflakytests wemakeourprototype flakescanner and subject suite flakyapprepo available at background android concurrency model.
figure1depicts android s eventdriven concurrency model.
each android app has a main thread also called ui thread this thread processes events generated by usersortheandroidsystem.asshowninfigure theuithread maintainsaneventqueueandaneventlooper.thequeueisusedto store received events and the looper sequentially dequeues events from the queue and dispatches them to corresponding handlers for processing.
android adopts a single ui thread model in which onlythemainthreadcanaccessguiobjects.toachieverapidui responsiveness the ui thread offloads long running tasks such as network access to background threads called async threads since they communicate with the ui thread asynchronously.
once tasks are completed async threads post an event called async eventmarked in blue in figure to the ui thread and the ui thread updates the results to gui.
event races may occur in this model.
the ui thread and async threads run concurrently.
the duration that an async thread will take to complete a task and post 368flaky test detection in android via event order exploration esec fse august athens greece .
figure1 androidconcurrencymodel testingframework.
an async event is non deterministic depending on the current execution environment.
thus a race might occur among posted async eventsandothers leadingtonon deterministicexecutionorders.
intheexampleinfigure therearemultipleeventorderswhich might occur in the execution for instance angbracketlefte1 e2 e6 e3 e4 e5 e7 angbracketright and angbracketlefte1 e2 e3 e4 e5 e6 e7 angbracketright.
instrumented tests testing frameworks.
instrumented tests are tests that run on physical devices and emulators and they can invoke the android framework apis to control app under test at runtime.
these tests are often executed in a separate thread called testingthread tosimulateuserinteractions asshowninfigure .
the android system supports multiple testing frameworks to help developerswritetests e.g.
espresso .toachievereliabletests theseframeworksprovidemechanismstosynchronizeuserinteractions with app under test.
for instance when method onview isinvokedinatest espressowaitstoperformthecorresponding uiactionorassertionuntiltheeventqueueisempty background threads are terminated and user defined resources are idle.
a motivating example to set the stage for our event order exploration technique for flaky testdetection wefirstillustratethecharacteristicsofaflakytest andthen exemplifycurrent approaches inadequacy throughlistings1 .
these listings show parts of capturelocationactivitytest a flaky test taken from rapidpro surveyor app.
this test intends to validate whether the app can successfully obtain the locationdata using google apis.
as shown in listing the test launches capturelocationactivity line2 theactivitytocapturethelocation data listing .
later thetestemulates abuttonclicktofetch the location at line 5in listing and validates whether the location is successfullyfetched at line 7in listing .
despiteappearingstraightforward thetestdisplaysnon deterministic behavior i.e.
it is flaky.
as explained earlier the test runs in a testing thread and the activity under test runs in the app s uithread.the activity capturelocationactivity offloadsfetching locationdataviagoogleapiclienttoanasyncthread listing .
after obtaining the location data the async thread updates the resulttotheuithread andthentheuithreadupdatesthisresulttocapturelocationactivity .
due to the lack of synchronization between the testing thread and async thread the async thread might send the location data before or after the testing thread validates it.
ifthevalidationoccursbeforethelocationdataisreceived thetest fails else it passes.
detecting concurrency related flaky tests is non trivial as such failuresmanifestwhentheeventsareexecutedinaspecificorder.
the traditional approach rerunblindly executes the test many timesinthehopeofwitnessingtheflakytestfailures.however this approach becomes ineffective when the environment under which thetestrunsdoesnotproducetherequirednon determinism.for example rerunfailed to witness the flaky test failure in capturelocationactivitytest during our experiments.
another approach istoaddnoiseintheexecutionenvironmenttoincreasethelikelihood of observing such errors.
however such approaches do not proactively explore different event execution orders and are pronetomisscrucialeventorderings.inourevaluations therecent noise based relatedwork shaker failedtodetectmanyconfirmedflakytests including capturelocationactivitytest .wealso evaluated eventracer adynamicanalysisbasedtechniquefordetectingeventracesinandroidapps.however suchapproachesare pronetoreportmanyraces.forexample inourevaluation eventracerreported over data races for capturelocationactivitytest .
unfortunately noneofthesereporteddataracesfrom eventracer involveeventsoriginatedfromthetestingthread andhencedonot demonstratethespecificflakinessweareillustratinginthissection.
besides eventracer doesnotvalidatewhetherreportedracescan cause the testfailure.
overview of our approach this section describes the main components of our framework and lists the principles that make event exploration suitable fordetecting concurrency related flaky tests.
first the category of flaky tests should be well defined.
it is acceptable to give up on all classesofflakytestsandfocusonone concurrency relatedflaky tests.
second using only one test run we explore all possible schedulingspaceofanasyncevent.third weexecutethesenewschedulingstoobservetheflakybehavior i.e.
thereexistatleast twoexecutionsforwhichatestdepictsdifferentoutcome pass fail .
.
basicconcepts beforedivingintodetailsofourapproach wedefineaminiature domain specific syntax extended from for an android test.
test t s statement s post e assertions sync other event e muithread mbackgroundthread mos synchronize sync sync s message m a testtis composed of a series of program statements s. for concurrency related flaky tests we are interested in exploring the scheduling space of events and thus for ease of representation we categorizeateststatementintofourparts statementspostingan event assertion statements testing framework specific synchronizing statements and all other android specific statements.
an event denoted as e is a message object created in the ui thread 369esec fse august athens greece zhen dong abhishek tiwari xiao liang yu and abhik roychoudhury listing capturelocationactivitytest testing thread rule 2publicactivitytestrule capturelocationactivity rule new activitytestrule capturelocationactivity.
class test 4public void capture 5onview withid r.id.button capture .check matches isdisplayed .perform click 6instrumentation.
activityresult result rule.
getactivityresult 7assertthat result .getresultdata is not nullvalue ... listing capturelocationactivity ui thread override 2protected void oncreate bundle bundle 3connectgoogleapi ... 6protected void connectgoogleapi 7googleapiclient newgoogleapiclient.builder this ... 8googleapiclient.connect listing zaau worker thread worker thread asynchronous to the ui thread workerthread 3public void run 4zaak.zac this.zagj .lock ... muithread background threads mbackgroundthread or android framework mos .
each event specifies a specific action to perform e.g.
a button click registers an on clickevent.
synchronizing statements sync are testing framework specific methods and are used to achieve synchronization among ui thread and testing thread e.g.
espresso uses onview method to achieve synchronization among testing thread and ui thread1.
based on above constructs we define an async event easyncas the event generated from a background thread i.e easync mbackgroundthread .
definition4.
schedulingspaceofevents .
lettbeatestcontainingasetofstatements s ebethesequenceofeventsgenerated by s. let econtains nasync events and e primebe a new sequence of events created by reordering an async event in e. then the scheduling spaceof events eis a set of all possible e prime.
givenatest definition .1formallydefinesschedulingspacesof events.intuitively inatest theorderofanasynceventisnotfixed and thus creating new event orders by reordering async events willprovideallpotentialeventorders.however theseeventorders may also contain infeasible orders that will not be realized in practice.oneof thecriticalchallengesistoavoid suchorders.an infeasibleeventorderingcanbeexploredbyignoringtheevents dependencies during the execution.
for instance an async event e1 may depend on another event e2 where event e1will not complete event orders as definition .
infeasible scheduling space .
let ebe a sequence ofeventsand e primebeanewsequencecreatedbyreorderinganasync eventeasyncin efrom the position ito a new position j. then e primewill be infeasible if ek e primeafter the position jandeasync depends on ek.
intuitively dependsspecifiesthe happens before relation.inpractice avoiding infeasible event orders would require computing the dependencies among events in the test execution.
however computing event dependencies is challenging for multiple reasons.
first atestcantriggermanyevents morethan500eventsforsome cases .computingdependenciesamongthemcanbecomplexas oneevent sexecutionmaydependonmultipleotherevents.second event dependencies are not specified in the events but handed over to the componentsthat respondto theevents.
thesecomponents maybelongtoandroidframeworksorthird partylibraries makingeventdependencyanalysisdifficult.weproposeadynamicanalysis to explore various event execution orders to address this challenge.
given an async event ein a test run the analysis identifies the scheduling space angbracketleftelo eup angbracketright whereeloislower bound event andeup isupperboundevent i.e.
ecannotbeexecutedearlierthan eloor later than eupfor all execution environments.
consequently we can exploreevent execution ordersby scheduling the async event eat various positions between eloandeup.
.
identifyingthe scheduling space thesuccessfulrealizationoftheschedulingspacerequiresnoticing twocrucialpoints.first theschedulingspaceneedstoreflectsome level of determinism i.e.
there need to be some non async events.
second eachasyncevent sschedulingspaceshouldbewelldefined.
observation .
for a statement sin a testt the first event it generates will not be an async event i.e.
its order will not change for allruns.
android is a reactive system and tests in an android app invokes the functionality of android scomponents e.g.
an activity by simulating user events.
for example a test would emulate a buttonclicktoinvokesomefunctionalityprovidedbyanactivity.
theconceptofbackgroundthreadsinandroidistrivial andandroid scomponentsutilizethemtooffloadlong runningtasksin thebackground.notably abackgroundthreadisalwayscreatedby an android component via ui thread .
thus the interaction from a test via a statement to an android component would always followasequencewherethetestwouldinvokethecomponent and thenthecomponentmayinvokeabackgroundthread.considering such event chaining the first event of a test statement will always belongto muithreador mos.basedonthisobservation wedefine anchorevents as definition4.
anchorevents .
lets sbeaprogramstatement in a test t and it generates nevents in the following order e1 ... en .
then we define e1as the anchor event for s. to localize anchor events we execute a test statement by statement werecord allevents triggered byeach statement and build 370flaky test detection in android via event order exploration esec fse august athens greece a map between them.
according to this map we identify anchor eventsforthetest.definingthelowerboundofanasynceventis nowstraightforward.intuitively foragivenstatement thelower bound of an async event would always be the anchor event of this statement as the anchor event will always happen before async event observation .
localizing the upper bound event of an async event easyncis more involved and requires identifying events that depend on easync i.e.
eventsthatoccuronlyafter easync.sucheventdependence is maintained by thread synchronization operations.
for instance the testing framework espresso uses onview operation tosynchronizethetestingthreadandappundertest.thetesting threadwaitsuntilspecificthreadsorresourcesareidletoensure thatawidgetspecifiedby onview showsuponthescreen.formally we define the upper bound of an async event as definition4.
upper bound event .
lettbe a test containing a set of statements s. we define ejas the upper bound event for an asyncevent easync whereejis the first event that cannot happenbeforeeasync.
weproposea what ifanalysistolocalizetheupperboundevent ofei.
specifically after the test is launched we hook the async threadthatposts eiatruntimeandsuspendit keepingotherthreads free.
meanwhile we monitorthe testing threadto checkat which statement the testing thread stops and waits for the suspended threadtobecompleted.supposethatthetestingthreadstopsata statement son executing the event ej.
we then deem operations insto depend on ei and these operations will not be executed untileiis processed.
thus the anchor event ejtriggered by sis upper bound event of ei.
the idea behind the analysis is what ifit takesforevertocompletethelong runningtaskthatcorresponds ei operationsinatestthatdependon eiwillnotbeexecuteddue to thread synchronization and those that do not depend on eiwill be executed.
.
scheduling events next weexploretheschedulingstrategiesforanasyncevent easync.
given the lower and upper bound events of easync the anchor events that liebetween this interval areidentified.
then easyncis scheduled before each of these anchor events.
to manifest flaky testfailuresassoonaspossible weprioritizepositionsclosertothe upper bound event maximizing the runtime of the async event i.e.
wefirstschedule easyncjustbeforeitsupperboundandthen move towards its lower bound.
fortworeasons weonlyexplorepositionsbeforeanchorevents in the scheduling space of an async event instead of all possible positions.
first for non anchor events in the scheduling space their execution orders may change from run to run.
using them as hooksforeventschedulingmayintroduceinfeasibleorders.second anchor events are boundary events of test statements.
scheduling an async event before them is likely to trigger a flaky test failure.
methodology figure2shows the workflow of our approach.
for a given test our frameworkperformsaconcreteexecutiontotraceallthegenerated events.
next a map between the statements in the test and theirtracing mapping eventsidentifying schedule spacescheduling eventsan event map event orders figure workflow of exposing flaky tests through systematicschedule exploration.
correspondingeventsiscreated.thetestisexecutedmultipletimes to compute possible schedules for async events.
consequently a set of event orders that might occur in execution environments arecreated.finally weexplorethesepossibleeventexecutionorders ifatestfailureisdetectedduringtheexploration thetestisidentified as a flaky test since we have already seen passing runs of the test .
.
event tracing and mapping eventtracingisoftenusedinthedynamicanalysisofandroidapps.
itcanbeachievedbysimplyloggingeventsthataregeneratedat runtime.however suchtechniquescannotfulfillourtask.event information e.g.
eventid producedinlogsisdynamicallygeneratedbyandroidruntimeandchangesineachrun.ourapproach requires an event identifier to identify an event uniquely across different test runs.
async events that are identified during event tracingneedtobehookedandscheduledinrunsthatareperformed for event order exploration.
eventidentification.
weidentify anevent basedon interactions between the event and app under test at runtime.
two events triggeredindifferenttest runsareconsideredidenticalif they are triggered by the same test statement they are processed by the samesequenceofmethodsatruntime.forinstance a pressdown event is associated with an identifier constructed using the line numberofthestatementthattriggerstheeventandsignaturesofa sequence of methods that process it.
this practice of event identificationcomesfrom our investigation of the android framework.
tracing and mapping.
algorithm 1outlines the procedure of event tracing and mapping.
first it launches the app under testand takes control of the android runtime with a module calledarthandler .
given a test tconsisting of a series of statements arthandlerrunsthetest tinthetestingthreadandexecutesstatementsonebyone viatheandroiddebugger .whenonestatementisexecuted arthandlersmonitorstheeventqueueoftheuithreadandhooksinjectedevents.foreachevent arthandlerrecordsthe tuple angbracketleftisasync sq m angbracketrightwhereisasyncdenotes whether it is an async eventand sqmdenotesthesignaturesofasequenceofmethodsthat have processed the event.
this tuple and the line number of the statementbeingexecutedformtheevent sidentifierandgetstored in a list line .
as stated before a statement in the test might performlong running tasks whichare executedinasync threads.
whenthesetasksarecompletedisnon deterministic andtheasync eventmight bepostedafter alongtime.
tonot missasyncevents thataretriggeredbyasinglestatement wekeephookingevents untiltwocriteriaaresatisfied a therearenoneweventsand b the event queue of the ui thread is empty which often indicates the system is not running tasks.
this practice is also used in the 371esec fse august athens greece zhen dong abhishek tiwari xiao liang yu and abhik roychoudhury algorithm1 event tracing and mapping.
1procedure runtest app a test t android art launchapp a art 3arthandler attachhandler a art 4list storing pairs of a statement and events launchtest a t art ui thread s event queue 6eventq geteventq arthandler 7forsintdo runstatement arthandler s n getlinenum arthandler s whiletruedo e angbracketleftisasync sq m angbracketright getevent arthandler ife !
null then list list angbracketleftisasync sq m n angbracketright else ifisempty eventq then break end end end 20end 21returnlist espresso testing framework.
finally a map between a statement and its events is returned via the list and the first event of each statementis identified as an anchor event.
.
identifyingevent schedule space to compute possible event execution orders we perform a what if dynamicanalysistoresolveeventdependenciescausedbythread synchronizationbetweenappsandtestingframeworks.algorithm shows the procedure of resolving event dependencies.
it takes the eventtrace listgeneratedinthepreviousstepasinput.foreach async event easyncinlist the algorithm launches the test and starts to hook event easync line .
once hooked the algorithm suspends the thread that posts easyncsuch that easynccannot be posted line .
meanwhile it keeps checking the status of the testingthread line10 .ifthetestingthread sstatusis waiting itconsidersthetestingthreadisperformingthreadsynchronization withthreadsintheappandwaitingfor easynctobeexecuted.thus we consider the statement sthat is being executed in the testing thread attempts to trigger an event e.g.
ej which depends on easync.therefore theschedulespaceof easyncisboundedby ej i.e.
the first eventthat istriggered by s.so statement sisidentified as theupperboundofschedulespaceofasyncevent easync.statement sisrecordedandsetastheupperboundofevent easyncandeasync isrestoredto list.finally schedulespacesforallasynceventsin listare recorded.
.
scheduling events schedulespaceof eachasynceventinthe eventtrace listisidentifiedintheprevioussteps.next weexploreeventordersduring test execution.
an async event easynccan be simply represented by a triplet angbracketleftid n m angbracketright wherenandmare bounds of the scheduling spaceofeasync.specifically nistheindexofthestatementinthealgorithm2 event scheduling exploration.
1procedure explore app a test t android art eventmap list 2foreinlistdo ifisasync e then launchapp a art arthandler attachhandler a art launchtest a t arthandler thtest gettestingthread arthandler thasync hookasyncthread arthandler suspend arthandler th async whiletruedo ifiswaiting thtest then break end end m getlinenum arthandler th test end mis set as upper bound for e setupperbound e m update event e with upper bound m in list updateevent list e break 20end 21returnlist test that triggers easync andmis the index of the statement that triggersthe upper bound event of easync.
similartoschedulingspaceidentification wecanschedule easync by operating threads.
we first hook event easyncafter the test is launchedandsuspendthethreadthatposts easync.then wefree thetestingthreadandmonitorwhetherthestatementbeingexecuted is statement m. once statement mis reached we suspend the testing thread and free the suspended thread to post easync.
aftertheasyncthreadisterminatedoridle i.e.
event easynchas beenposted wefreethetestingthread.insuchaway event easync can be executed beforestatement m. in next testrun we schedule easyncto be executed prior to statement m until all statements betweennandmare explored.
this procedure is repeated for each asyncevent in list.
implementation oursystemisimplementedinscalaandrunsonacomputerthat connects a physical android device or an emulator.
unlike existing techniques it requires no instrumentation on apps or the android framework and can be adapted to different versions of android.
taking control of android runtime.
the android framework supports running an app in the debug mode under which the androidruntimecanbefullycontrolled.specifically weconnect the android runtime via android debug bridge adb and use the android debugger to execute the app under test.
with the debugger shelp wecanperformexecutionstepbystepandmonitor the appstate duringthreadmanipulation.
hooking events.
android adopts the event driven model and manages events using an event queue.
each event implements aninterfacemethodcalled enqueuemessage andandroidputs 372flaky test detection in android via event order exploration esec fse august athens greece table subject apps app name version loc stars category amaze file manager .
.
.2k .8k tools youtube extractor .
.
.7k video players antennapod .
.
.6k .7k music audio backpack design .
.
.2k productivity barista .
.
.9k .2k productivity cameraview .
.
.5k .9k photography catroid .
.
.5k education city localizer .
4k travel local connectbot .
.
.7k .4k communication duckduckgo .
.
.3k .2k tools espresso .
.3k .1k maps navigation firefox focus .
.
.5k .6k communication firefox lite .
.4k communication flexbox .
.
.2k .2k libraries demo gnucash .
.
.1k 1k finance ibs foodanalyzer .
.1k health fitness google i o .
.
.5k .6k books reference just weather .
.
.9k weather kaspresso .
.
.3k productivity keepassdroid .
.
.7k .2k tools kickmaterial .
.1k .6k crowdfunding kiss launcher .
.
.2k .4k personalisation medlog .
65k medical minimal to do .
.5k .8k productivity moneymanagerex .
.
170k finance my expenses .
.
.
.6k finance nybus .
.9k transport omni notes .
.
.9k 2k productivity opentasks .
.
448k productivity owncloud .
.
.7k .9k productivity sunflower .
.
.3k .1k gardening surveyor .
.
.4k communication wordpress .
rc .7k .3k productivity events to the queue by calling this method.
we set a breakpoint at method enqueuemessage inthedebugmode.wheneveranevent is generated and injected into the queue we perform predefined operations such as suspending the event posting thread.
operating threads.
we leverage the android debugger to retrieve threads running in the app under test including the testing threadanduithread.theandroiddebuggerprovidescommandsto remotelyoperatethreads e.g.
inspectingthreadstatusandsuspendingaselectedthread.italsoallowsustoobtainthecurrentstack frames of a running thread that are used for event identification.
withtheandroiddebugger wecanexecuteatestingthreadstep by step and observe execution at the statement level by inserting a breakpoint at each statement in the test.
evaluation weempiricallyevaluate flakescanner seffectivenessindetecting flakytests in the test suites of large scale android projects.
.
subject apps ourtechniqueisdesignedforatestthatrunsontheandroidframework platform and checks whether it is flaky.
to evaluate our technique we need android projects that contain such tests.
basically there are two types of tests in android projects instrumented teststable root causes of reproduced flaky test failures and theircategories.
categories description of root causes async do not wait or wait not enough when accessing background resources or services in an async manner for tasks such as imagerendering downloadingfrominternet andinvoking third party libraries.
event orders expecting an implicit event execution order that may not always occur in the test execution.
the unexpected event execution order leads to app misbehavior such as the soft keyboard disappearing late.
data race checkingunsynchronizeddatabecausecheckingoccursbeforethedatabeingupdatedduetothelackofthreadsynchronization.
lifecycle performing app state sensitive operations on the incorrect state e.g.
the testingthreadattempts tooperate guiwidgets when the app is resumed state which is prohibited.
that run on a physical device or android emulator and local unit teststhat run on local java virtual machines.
thus we need android projects that contain instrumented tests.
unfortunately most androidprojectsinexistingbenchmarkssuchasandrotest industrialappbenchmark anddatasetthatisusedforflaky testempiricalstudy have no instrumented tests.
therefore webuiltthefirstsubject suite flakyapprepo inwhich eachandroidprojectcontainsinstrumentedteststhatarewrittenbydevelopers.asshownintable flakyapprepo contains33android projects majorityofthemarewell known suchaswordpress andover5000instrumentedtestsfromdevelopers.wecollectedandroid projects containing instrumented tests as follows searching popularopen sourceandroidprojectssuchasfirefoxandmanually checking their repositories to select projects with instrumented tests intuitively popular projects are well maintained and more likely have developer tests searching keywords such as flak flakiness orintermitonthegithubandmanuallycheckingsearched repositories to select android projects containing instrumented tests.
furthermore we explored these keywords in the commit history as well to include already fixed flaky tests.
a few searched projects have star on the github.
to achieve diversity we did not exclude these projects and kept them in the subject suite.
.
research questions our evaluation aims to address the following research questions.
rq1canflakescanner detect known flaky tests that are reported by developers?
rq2how does flakescanner compare with existing techniques in terms of number of detected flaky tests?
rq3canflakescanner be used to discover flaky tests in android projects that were previously unknown?
.
experimentsetup to answer the research questions we conduct three empirical studiesontestcasesthatarewrittenbydevelopersinrealworldandroid appprojects.
.
.
study .
we first evaluate flakescanner s effectiveness in flaky test detection by running it on known flaky tests in android projects and checking how many of them are marked as flaky tests byflakescanner .
373esec fse august athens greece zhen dong abhishek tiwari xiao liang yu and abhik roychoudhury table dynamic analysis based tools for detecting flaky tests or concurrency issues in android apps.
approach categories instrumentation yearreason for not selected rerun flaky tests no shaker flaky tests no apechecker async bugs no 2018publicly unavailable erva event race yes 2016publicly unavailable eventracer event race yes asyncdroid async bugs yes 2015incompatible instrument api dataset.
weselected52knownflakytestsfrom flakyapprepo thatarecausedbyconcurrencyorsynchronizationissuesforstudy .inandroidprojects flakytestsreportedbydevelopersaremarked withadedicatedannotation flakytest suchthatflakytestscanbe automaticallyfilteredoutduringtestexecution.weidentified269 known flakytests in flakyapprepo using flakytest annotation.
we selected known tests from them in the following manner.
concurrency we select concurrency related flaky tests by manuallyanalyzing detailsaboutreportedflakytestssuchas thereasonofwhyatestisflaky whichcanbecollectedfrom detailelement2of flakytest annotation commit messageswhenflakytestswereintroducedorfixedinasubsequent version whether there existstatements in tests that are commonly involved in concurrency or synchronization execution e.g.
operations of runnable orasynctask objects.
passing weraneachselectedtestinourexecutionenvironment andensureditpassesintheinitialrun avoidingfailuresdue to environment setup.
reproducing wereproducetheflakytestfailureforeachselected test by analyzing its commits messages and detailed descriptionintherepositoryincludingrootcausesandfailingscenarios.
for cases lacking the description we contacted developerstoseekmoreinsightsonthefailurereproduction.
a test is selected if its failures is reproduced.
intheend 52knownflakytestswereselectedfortheevaluation.
meanwhile wealsoanalyzedrootcausesoftheseflakytestfailures andclassifiedthemintofourcategorieswhichareshownintable .
.
.
study .
toanswerrq2 weevaluate flakescanner andexisting tools on the data set used in study .
we reviewed most recent workson flakytestsor eventracedetection forandroidapps and summarize them in table .
we selected the following approaches for comparison.
rerun.in practice developers often run a test many times to check whether the test is flaky.
similarly we run a test times and check whether the flaky test failure manifests during execution.
we call the approach 100runand takeit as our baseline.
shaker is the most recently reported state of the art technique for detecting concurrency related flaky tests in androidapps.
shakerattemptstomanifestaflakytestfailure byaddingnoisesintheexecutionenvironmenttoaffectevent execution order e.g.
changing cpu workload.
eventracer is a the state of art dynamic technique of detecting event races in android apps which infers races android framework.
.
.
study .
to answer rq3 we run flakescanner on tests in flakyapprepo without flakytest annotation i.e.
teststhatare notreportedasflakytests.wefirstrunthesetestsinourexecution environment and exclude tests that fail then feed passing tests toflakescanner and report tests that are labeled as flaky tests by flakescanner .
effectofdebugmode.
flakescanner runsappsinthedebugmode.
the debug mode environment may affect flaky test detection by impacting the android event dispatching mechanism or increasing execution workload.
according to the official android document3 the difference between normal execution mode and debug mode is thattheandroidvirtualmachine vm loadsanadditionalandroid runtime tooling interface artti plugin that exposes runtime internals e.g.
variable values .
the artti plugin runs as a vm level component and it is transparent to event dispatching that occursintheapp smainthread i.e.
runningappsindebugmode does not impact the mechanism of event dispatching.
however runningthearttipluginandaccessingruntimeinternalsintheexecutioncouldincreasetheworkloadofthevm.duetotheworkloadchange atestcanmanifesttheflakytestfailure.to rule out such cases for each test in our study we pre execute it to ensure the test passes in the debug mode environment.
to perform end to endcomparisoninstudy2 werun 100runandshakerin the debugmode environment as well.
executionenvironment.
weconductedexperimentsonaphysical machine with gb ram and a cores intel r xeon r e5 v4 cpu running a bit ubuntu .
operating system.
each execution instance runs in a docker container to minimize the potentialinferencebetweenrunninginstances.appundertestruns on an android x86 emulator.
one execution instance is for one test case for which the android emulator is initialized to a fresh state at the beginning to provide a clean testing environment.
.
rq1 efficacy table4shows results on each known flaky test for study .
the first column indicates known test ids the second column showsapp names and testing frameworks used in apps and the third columnindicatestestmethodnames.column event indicatesthenumberofeventsobservedby flakescanner duringdetection.
run indicates the number of test runs in the event order exploration.
column time reportsthetimethatisusedtodetectaflakytest.
column succ indicateswhetherthetestisidentifiedasaflakytest byflakescanner .
indicatesthatatestisunabletobeexecuted due to library compatibility issues.
firefox lite marked with rows is a previousversion commit 465739510e .
notethat some testnames in the table are shortened for readability.
results.
flakescanner successfullydetected45outof52known flaky teststhat are from android projects including a different versionoffirefoxlite .onaverage flakescanner detectedaflaky testin101seconds.themaximumdetectiontimeisfortest20from app antennapod seconds .
the minimum detection time is for 374flaky test detection in android via event order exploration esec fse august athens greece table results on known flaky tests by flakescanner shakerand 100run .
idapp frameworkmethod nameflakescanner shaker 100run events runtime s succ time s succtime s succ surveyor espressocapture .
twoquestions .
multimedia .
contactdetails .
5youtube extractor junit4testencipheredvideo .
testunembeddable .
testagerestrictvideo .
testusualvideo .
myexpenses espressotestscenarioforbug5b.. .
editcommandkeeps.. .
clonecommandincreases.. .
changeoffractiondigits.. .
changeoffractiondigitswith.. .
firefox lite espressosaveimagethendelete.. .
dismissmenu turnonturbomode.. .
changedisplaylang .
antennapod robotiumtestgotopreferences .
testclicknavdrawer .
playbacksonictest ..on.. .
playbacksonictest ..off.. .
playbacktest ..off..episodes .
playbacktest ..on..episodes .
flexbox espressotestscrolltoposition..row .
testaddviewholders.. .
testchangeattributes.. .
testminheight..minheight .
testjustifycontent..views .
testjustifycontent center .
testflexwrap..column .
testfirstviewgone..column .
testchangeorder..params .
testalignitems..column .
testaligncontent..column .
testaligncontent..column .
testaligncontent..padding .
testflexlines..row .
testflexlines..column .
39firefox lite espressobrowsingwebsite.. .
saveimagethendelete.. .
backpack junit4test with description .
test with title .
test bottom sheet style .
test alert style .
screenshottestdialog.. .
screenshottestdialog .
test with buttons .
48barista junit4overflowmenuclick bytitle .
openoverflowmenu ..option .
overflowmenuclick byid .
51kaspresso junit4commonflakytest test .
uicommonflakytest test .
avg sum 375esec fse august athens greece zhen dong abhishek tiwari xiao liang yu and abhik roychoudhury test41 and47fromappbackpack 11seconds .
flakescanner detectedaflakytestwithin3testrunsonaverage.themaximum number of test runs is for test from antennapod runs .
to understand why flakescanner successfully detected failures within a few test runs we inspected source code of projects.
the major reason is that tests heavily use synchronization operations.
forinstance test from surveyor contains test statements of which use the synchronization operation provided by espresso onview .
when onview is called in the test statement the testingthreadwaitsuntilbackgroundthreadscompletetasks.asdesigned flakescanner does not perform event scheduling for those cases since async events are bounded in the execution of a test statement by the synchronization operation.
then flakescanner canfocusonschedulingeventsforstatementsthatlacksynchronizationoperations.moreover flakescanner prioritizesexploring positions that are closer to the upper bound event which likely triggersflakytestfailures section .
.thus flakescanner could detect failures within a few test runs.
the results also show flakescanneris a practical tool.
it successfully detected flaky test failures for test and from myexpenses for which events were generatedintheexecution.meanwhile flakescanner workedon androidprojectsthatadoptdifferenttestingframeworkssuchas espresso and robotium .
flakescanner successfully detected out of known flaky tests in android projects.
on average it detected a flaky test within3 test runs.
.
rq2 comparisonwithexistingtechniques asshownintable flakescanner outperforms shakerand100run intermsofboththenumberofdetectedflakytestsandtheaverage executiontime.outofthe52knownflakytests flakescanner detectedthemostflakytests andisfollowedby shaker and 100run .
for execution time flakescanner detected a flaky test in101secondsonaverage whichislessthan861secondsof shaker and497secondsof 100run.formostoftests 100runcouldnot detectaflakytestfailureinthefirstfewrunsandkeptexecuting themuntil reaching times which took a longer time.
regarding the overlap between flaky tests detected by each tool flakescanner detected all the flaky tests detected by shakerand 100run.
butshakerand100runfailed to detect the other flaky teststhatweredetectedby flakescanner .thebetterresultsfrom flakescanner canbeexplainedasfollows flakescanner canidentify synchronizationoperations inthe testexecution andfocus on schedulingeventsforstatementsthatlacksynchronizationoperations.
unexpected event execution orders that cause flaky test failures are more likely to explored by flakescanner .
wealsoevaluated eventracer sinceitusesdynamicanalysisto infer event race for android apps.
eventracer reported many possible races for each test run.
on average it reported races for a test.thisisbecause eventracer focusesondetectingracesinandroidappsanddoesnotanalyzeracesinwhichtestingframeworks are involved.
furthermore eventracer infers races by analyzing recordedtracesandcannotvalidatewhetherthereportedracescan cause flakytest failures.flakescanner outperforms shakerand100runin terms of both the number of detected flaky tests and average execution time.
.
rq3 real world flaky test detection we ran passing tests from the android projects in flakyapprepowhich are not annotated as flaky tests these tests may or maynotbeflaky .outofthese33projects flakescanner detected atleastoneflakytestfor19projects andreported245flakytestsin total.
to validate previously unknown flaky tests that flakescanner detected we randomly selected out of the detected flaky tests and reported them to developers.
for each selected test we manually reproducedthe failure that flakescanner witnessed duringdetectionandgeneratedadetailedroot cause analysisreport and submitted the report on the github.
at the time of writing the paper we got responses on test cases.
out of the tests were confirmed as flaky tests and addressed by developers.
for the othertwotests developersrepliedthatthereportedfailureswere not encountered yet or not reproduced at their end without giving us further explanation.
our experience with flaky test reporting shows so far that developers are more interested in identifying whichtestsareflaky.onceaflakytestisdetected theyappearto be more prone to removing them rather than investigating why it is flaky.
flakescanner detected previously unknown flaky tests in widely used android projects.
out of the reported unknown flakytests were confirmed and addressed by developers.
.
threatsto validity externalvalidity threatstoexternalvalidityrelatetothegeneralizability of the experimental results.
flakescanner is evaluated so far on android projects.
our results may not generalise beyond the33androidprojectstowhichwehaveapplied flakescanner .t o mitigate thisthreat we not only choose android projects that are popular and well maintained but also include less popular android projects i.e.
less stars on the github which were searched on the githubvia keywords.
internal validity threats to internal validity concern factors in our experimental methodology that may affect our results.
instudy we note that concurrency or synchronization related knownflakytestsarechosenbymanuallyanalyzingtheirrelated descriptions and commit messages which might result in selection bias.
similarly we manually analyze failures detected by each tool underevaluationandvalidatetheresults whichmightintroduce bias as well.
to mitigate these risks two authors of this paper independentlyperformedthemanualtasks andcross checkedeach other sresults.
.
data availability to facilitate future research on flaky tests we make our prototype flakescanner andsubject suite flakyapprepo availableatlink https github.com androidflakytest 376flaky test detection in android via event order exploration esec fse august athens greece related work flakytestdetection.
belletal.
usecodecoveragebaseddifferential analysis to identify flaky tests.
a test is deemed flaky if it fails during regression testing and its execution does not reach any code that was recently changed by developers.
lam et al.
propose idflakies a framework for detecting order dependent flaky tests teststhatfailwhenrunindifferentorders.duttaetal.
developanapproachtodetectrandomnumberrelatedflakytests tests that fail due to difference in the sequence of random numbers generatedindifferentruns.shietal.
proposeanapproachto fixorder dependentflakytestsbyleveragingpassingtests.shiet al.
propose toreruna testmultipletimes oneachmutant and obtainreliablecoverageresultssuchthattheeffectsofflakytests on mutation testing can be mitigated.
in contrast flakescanner detectsconcurrencyorsynchronizationrelatedflakytestsinandroid projects by exploring feasible event execution orders.
event race detection.
another branch of works that are close to ours is event race detection .
instead of detecting flaky tests these works leverage dynamic and static analysis to detect event races.
for instance er catcher droidracer eventracer cafa andnadroid capturehappens before relation among events and infer possible eventraces.inaddition ozkanetal.
proposetodetectasynchronous bugs by exploring different execution orders of eventhandlers in android apps.
sard leverages happens before analysistodetectuse after freeissuesinandroidapps.thesetechniqueshavethepotentialtobeapplicableforflakytestdetection butfacechallengestocapturecompleteandprecisehappens beforerelationswhenatestisexecutedbyatestingframework.manyfalse positivescanbereportedbyevent racedetectorsduetoincomplete happen beforerelationsbeingcompute.incontrast flakescanner performs a system level dynamic analysis to capture precise event dependenciesto avoid such false positives.
empirical studies on flaky tests.
multiple studies confirmconcurrencyasthemajorcauseofflakytests.luoetal.
performed an empirical analysis of flaky tests in open source projects.theyidentified concurrency andasyncwait asthemost common cause of flaky tests.
they pointed out that the majority of thesecasesarosebecausetheydonotwaitforexternalresources.
finally theydescribedthecommonfixingstrategiesthedevelopers use to fix flaky tests.
in a separate study eck et al.
surveyed professional developers to classify flaky tests they fixed.
theyidentifiedfourunreportedcausesofflakytests whicharealso considereddifficulttofix.thorveetal.
conductedanempirical studyofflakytestsinandroidapps.theysearched1000projects for the commits related to flakiness and found only relevantcommits from projects.
they found of commits occurred duetoconcurrencyrelatedissues.fanetal.
proposedahybrid approachtowardsmanifestingasynchronousbugsinandroidapps withfault patterns.
concurrency bug detection.
there have been several testing based approaches to identify concurrency relatedbugs.maple proposedacoverage drivenapproachtoexposeuntestedthreadinterleavings.letko proposedacombinationoftestinganddynamicanalysiswith metaheuuristic techniques.choudhary et al.
presented a coverage guided approach for generatingconcurrencyteststo detectbugs in thread safeclasses.
multiple related works manipulated event orderstocontrolnon determinisminmulti threadedprograms.liu etal.
proposedadeterministicmultithreadingsystemthatreplacespthreadslibrary in c c apps.
emmi et al.
proposed a searchprioritizationstrategytodiscoverconcurrencybugs.they add non determinism to deterministic schedulers by delaying their next scheduled task.
adamsen et al.
presented an automated programrepairtechniqueforeventraceerrorsinjavascript.given a repair policy they controlled the event handler scheduling in the browser to avoid bad orderings.
discussion flaky tests pose a significant problem in validating mobile apps.
in thispaper wepresentedanapproachfordetectingflakytestsvia systematic event order exploration.
we introduced flakescanner a tooltodetectflakytestsforandroidapps.
flakescanner explores the space of possible execution environments which may cause relevantthreadstointerleavedifferently.duetothelackofatesting benchmark for flaky tests we created the first subject suite flakyapprepo that is used to study test flakiness.
flakyapprepo contains33widely usedandroidappswitharound2.5kstarson average in github.
we applied flakescanner to tests from flakyapprepo.
results show that flakescanner not only detected known flaky tests but also reported new flaky tests.
we believe that ourtoolandresultsholdoutpromisefortacklingflakytests which is a significant pain point in the practice of testing.