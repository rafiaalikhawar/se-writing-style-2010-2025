on the real world effectiveness of static bug detectors at finding null pointer exceptions david a. tomassi university of california davis united states of america datomassi ucdavis.educindy rubio gonz alez university of california davis united states of america crubio ucdavis.edu abstract static bug detectors aim at helping developers to automatically find and prevent bugs.
in this experience paper we study the effectiveness of static bug detectors at identifyingnull pointer dereferences or null pointer exceptions npes .npes pervade all programming domains from systems to webdevelopment.
specifically our study measures the effectiveness offive java static bug detectors checkerframework e radicate infer n ull away and s pot bugs .
we conduct our study on real world and reproducible npes from open source projects found in the b ugsw arm and d efects 4j datasets.
we apply two known methods to determine whether a bug is found bya given tool and introduce two new methods that leverage stacktrace and code coverage information.
additionally we provide acategorization of the tool s capabilities and the bug characteristicsto better understand the strengths and weaknesses of the tools.overall the tools under study only find out of bugs .
with the majority found by e radicate .
based on our observations we identify and discuss opportunities to make thetools more effective and useful.
index t erms static bug detectors null pointer exceptions null pointer dereferences bug finding bugswarm defects4j java i. i ntroduction defects in software are a common and troublesome fact of programming.
software defects can cause programs to crash lose or corrupt data suffer from security vulnerabilities among other problems.
depending on the application domain undesirable behavior can range from poor user experience tomore severe consequences in mission critical applications .testing to uncover such software defects remains one of themost expensive tasks in the software development cycle .
there is a need for both precision and scalability when finding defects in real world code.
furthermore in an effortto increase their applicability static bug detectors are oftendesigned to target a large variety of software bugs.
manystatic bug detectors are currently beingdeveloped in industry and academia.
even with many tools tochoose from developers have some hesitation in using staticbug detectors for a variety of reasons such as large number ofbug warnings high false positive rates and inadequate warningmessages .
previous studies have evaluated static bug detectors through various metrics number of warnings number of falsenegatives tool performance and recall .these studies have focused on popular tools that identifya large number of bug patterns and their conclusions aredrawn with respect to the overall bug finding capabilities ofthe tools.
in contrast this paper evaluates static bug detectorswith respect to their effectiveness at finding a common andserious kind of bug null pointer dereferences or null pointerexceptions npes .
npes pervade all programming domains from systems software to web development.
for instance as of august2021 there are over cves common vulnerabilities andexposures that involve npes .
one such cve describesa denial of service attack in early versions of java .
and1.
caused by crashing the java virtual machine when callinga function with a null parameter .
in general npes are problematic in memory unsafe and object oriented languages.npes occur when either a pointer to a memory location or anobject is dereferenced while being uninitialized or explicitlyset to null.
depending on the programming language npes will result in either undefined behavior or a runtime exception.
this experience paper evaluates recall of static bug detectors with respect to a known set of real npe bugs.
the focus on npes allows to present an in depth study of differentapproaches to find a same kind of bug the characteristics ofreal world npes and the reasons that affect tool effectiveness.to the best of our knowledge this is the first study on the realworld effectiveness of static bugs detectors at finding npes.
there are two orthogonal approaches to finding or preventing npes which make use of either a static bug detector ora type based null safety checker.
the former uses dataflowanalysis to find null dereferences.
such approaches mainly differ on the complexity of theiranalyses.
some favor analysis scalability at the expense ofmissing real bugs and or producing numerous false positives e.g.
intra interprocedural and field sensitivity.
the latter prevents npes via a type system with null related information using dataflow analysis for type refinement.
the type checkerapproach has been adopted in recent years .
we study two popular java static bug detectors i nfer and s pot bugs and three popular typebased null safety checkers for java checker framework snullness checker cfn ullness e radica te and n ull away .
i nfer uses separation logic and bi abduction analysis to infer pre post conditions fromprocedures affecting memory.
s pot bugs detects bugs based on a predefined set of bug patterns.
cfn ullness verifies 36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee fig.
workflow for running tools collecting reports parsing results and analyzing data.
the absence of npes via type checking nullable expression dereferences and assignments.
e radica te is a type checker that performs flow sensitive analysis to find possible nulldereferences.
finally n ull away uses dataflow analysis to type check nullability in procedures and class fields.
in this study we consider real world and reproducible npes found across popular open source java projects.
76of these npes belong to the b ugswa r m dataset while the remaining are from d efects 4j .
for each npe both datasets provide buggy and fixed versions of the programsalong with scripts for compilation and testing.
furthermore each program has a failing test due to an npe.
this makes boththe b ugsw arm and d efects 4j datasets good candidates for this study we want to run existing static bug detectors and typecheckers on these programs to determine their effectiveness atdetecting and preventing real npes.
the first challenge is to determine whether a tool finds or prevents a specific npe bug.
tools may report the programlocation at which the null dereference occurs or simply thelocation where the null value originates which can be far from the dereference.
the latter is particularly difficult toassociate with the bug fix which is often applied closer to thedereference site.
another difficulty lies in the large number ofwarnings to inspect.
on average a tool produces from to bug w arnings per program in our dataset .
previous work has partially automated the process of mapping bugs to warnings based on static information such as the code difference diff between buggy and fixed versions and by comparing the warnings produced for each versionof the program .
in this paper we observe that dynamic information can also be leveraged when an input exposing thenpe bug is available which is the case for all the bugs in ourdataset.
we present two new mapping methods for npes thatuse stack trace information and code coverage of teststhat fail due to npes.
our experimental evaluation shows thatthese methods complement previous approaches.
we run cfn ullness e radica te infer n ull away and s pot bugs on our dataset of real npes.
we find that the tools produce a large number of warnings includingover npe warnings across all programs.
we applyexisting approaches and our new methods to identify thewarnings that describe the bugs under study.
ultimately wefind that the tools detect only out of bugs .
with e radica te finding the majority of these.
the second challenge is to understand the reasons why tools fail to find npes to identify opportunities to improvetheir real world effectiveness.
this requires understanding thecapabilities of the tools under study as well as the charac teristics of the npe bugs in our dataset.
first we conducta detailed analysis of the tools capabilities with respect towell known program analysis properties e.g.
flow sensitivity context sensitivity etc.
and we identify common sources ofunsoundness.
this process required us to manually inspect thesource code of the tools and write tests.
all of our findingswere later confirmed by tool developers.
second we manuallyinspect and categorize each npe bug in the dataset withrespect to the nature of the dereference and its context.
basedon the tool results and the tool and bug characterizations we identify several open opportunities to improve static bugdetectors that find npes.
the contributions of this paper are we present two new methods that leverage dynamic infor mation to map tool warnings to npe bugs section ii .
we provide a categorization of the tool s capabilities andthe bug characteristics to better understand the strengthsand weaknesses of the tools under study section iii .
we evaluate cfn ullness e radica te infer n ull away and s pot bugs on a collection of npes from which only .
of npe bugs are detected section iv .
we discuss the capabilities and limitations of each tool and provide future directions for improving their real world effectiveness section v .
ii.
m ethodology here we describe the benchmark and tool selection and the methodology to determine the effectiveness of the tools atfinding npes.
figure shows the main steps of our approach.
a. benchmark selection our study focuses on null pointer exceptions npes .
we consider bugs from the b ugswa r m and d efects 4j datasets both of which provide a bug classification based on runtime exceptions.
our selection criteria is the bug is due to annpe there is a failing test due to the npe and codecoverage can be measured.
additionally we control for uniquebuilds when selecting b ugsw arm bugs.
our final dataset 293consists of npe bugs from the b ugswa r m dataset and from d efects 4j.
the b ugsw arm npe bugs belong to java projects hosted on github that use the maven build system while the d efects 4j bugs belong to java projects that use the ant build system.
note that all npes arereproducible i.e.
one can run the programs and observe a nullpointer exception being thrown.
furthermore we manually verified that each npe bug in our study is an actual npe i.e.
a null object is eventually dereferenced.
each npe instanceconsists of the source code that contains the bug the sourcecode that fixes the bug and scripts to compile and test.
b. tool selection and configuration we conducted an extensive search for tools that find or prevent npe bugs in java projects.
we focused on publicly available tools that are standalone and under active devel opment.
out of nine tools four did notsatisfy at least one of these requirements.
in this paper westudy the remaining five tools cfn ullness e radica te infer n ull away and s pot bugs .
note that i nfer and spot bugs find a large variety of bugs in addition to npe bugs.
cfn ullness e radica te and n ull away exclusively specialize in npes.
below we describe each tool.
a cfn ullness a type checker written using the checker framework which is available as a compiler plu gin.
cfn ullness works with nullness type annotations nullable and notnull and looks for violations in their use.
namely looking for dereferences on nullable expressions and for nullable value assignments to notnull variables.
cfn ullness produces compile time warnings.
we run cfn ullness using its default configuration.
b eradica te a type checker part of the i nfer staticanalysis suite.
e radica te type checks for nullable annotations in java programs by performing a flow sensitiveanalysis to propagate null related information through assign ments and calls.
e radica te produces warnings for accesses that could lead to an npe.
e radica te produces a report in json format that provides the stack trace severity andsource location associated with each bug detected.
we run e radica te using its default configuration.
c infer a static analysis tool developed by facebook that finds a variety of bugs in java c c and objective c programs.
i nfer uses bi abduction analysis to find bugs including deadlocks memory leaks and null pointer deref erences.
similar to e radica te infer produces a report in json format that provides the stack trace severity and buglocation.
we use i nfer s default setting which runs the biabduction analysis.
d null away a type checker for java developed by uber that applies various ast based checkers to find npebugs.
n ull away is available as a plugin for maven and gradle.
we use n ull away s default configuration which assumes that unannotated method parameters return values and class fields are not null.
in such cases the tool produces a warning when it is found that any of those locations couldhold a null value.
the user can add explicit nullable annotations to obtain more precise results.
e s pot bugs spot bugs applies pattern matching and limited dataflow analysis to find a large variety of bugssuch as infinite recursion integer overflows and null pointerdereferences.
the tool produces an xml report listing bugwarnings that include class name method name severity andline numbers associated with the identified bug.
s pot bugs is available as a plugin for a variety of build systems suchas ant gradle and maven.
we run s pot bugs with effort level max which indicates that s pot bugs performs its interprocedural analysis.
also we use two different error con fidence threshold settings low and high low confidencethreshold may report a higher number of false positives .
c. analysis of npe warnings a challenge in this study is to determine whether a tool finds or prevents a specific npe bug.
in the case of npes tools may report the program location at which the null dereferenceoccurs or simply report the location where the null valueoriginates which can be far from the dereference.
the latteris particularly difficult to associate with the bug fix which isoften applied closer to the dereference site.
we consider four approaches for mapping bug warnings to actual bugs in the source code i.e.
determine whether a toolfinds a given bug under study.
two of these approaches havebeen used in previous work the c ode diffmethod and the r eport diff method .
we explore two new approaches which we refer to as the s tack trace method and the c overage method .
figure shows an example of an npe found in the openpnp1github project as part of the bugswarm dataset.
method savedebugimage is called on line of file opencvvisionprovider.java see figure 2b where argument debugmat isnull.
method savedebugimage in file opencvutils.java callstobufferedimage on line see figure 2a passing in null which is then dereferenced on line .
the code highlighted in green represents the patch to fix the npe.
figure 2e shows the stacktrace and figures 2c and 2d show the warnings produced by s pot bugs and i nfer respectively.
code diff method this method takes as input the set of warnings reported for the buggy program and the set ofpatches from the github code diff.
3the analysis focuses on npe bug warnings and checks whether the source location ofthese warnings overlaps with the lines changed in the patches.however this is based on an over approximation the lowestand highest line numbers associated with the patch in eachchanged file are considered.
4if an overlapping line is found then the warning is considered a bug candidate.
we manually examine bug candidates to verify their validity.
2bugswarm image tag openpnp openpnp .
3a github code diff may consist of several patch fragments.
4previous work has also added a configurable number of lines before the starting point and after the ending point of the line range .
public synchronized static mat ... 4455public static void savedebugimage ... mat mat if mat null return savedebugimage ... opencvutils.tobufferedimage mat ... public static bufferedimage tobufferedimage mat m if m.type cvtype.cv 8uci ... npe!
a github diff in file opencvutils.java.
1public gettemplatematches bufferedimage template ... mat debugmat null if logutils.isdebugenabled debugmat imagemat.clone ... opencvutils.savedebugimage ... debugmat b null origin in file opencvvisionprovider.java.
buginstance rank abbrev np category correctness priority type np null param deref method classname org.openpnp.util.
opencvutils name savedebugimage sourceline classname org.openpnp.util.
opencvutils start end sourcefile opencvutils.java c spotbugs xml report.
bug class prover kind error bug type null dereference qualifier object debugmat last assigned on line could be null and is dereferenced by call to savedebugimage ... at line .
file opencvvisionprovider.java severity high ... d infer json report.
java.lang.nullpointerexception at org.openpnp.util.opencvutils.tobufferedimage opencvutils.java at org.openpnp.util.opencvutils.savedebugimage opencvutils.java at org.openpnp.machine.reference.vision.opencvvisionprovider.gettemplatematches opencvvisionprovider.java ... e stack trace for buggy program.
fig.
github diff stack trace spotbugs xml report and infer json report for an npe found by s pot bugs lt and i nfer .
consider the patch in figure 2a.
the line at the top starting with indicates that the patch includes original lines through and new lines through from fileopencvutils.java.
therefore the approximated line range is through for the buggy program i.e.
theprogram before the fix.
the s pot bugs report see figure 2c includes the xml tag sourceline line of file opencvutils.java.
this location lies within the linerange thus the method correctly collects this warningas a bug candidate.
on the other hand even though i nfer see figure 2d successfully finds the bug the c ode diff method approach fails to map the warning because the report does not include lines close to the fix.
in this case using codediff information is not effective.
r eport diff method this method uses the set of bug warnings of the buggy program and the set of warningsof its fixed version.
the algorithm searches for npe bug warn ings that are only reported for the buggy program.
the intuition is that the warning that describes the bug of interest shouldnot be present in the bug report of the fixed program.
usingthis method both s pot bugs and i nfer are determined to have found the bug from figure .
this method is convenientbecause it only requires two bug reports.
however the absenceof a bug warning in the fixed program does not necessarilymean that the bug of interest was found.
the code changecould have introduced noise that leads the tool to concludethat an unrelated bug warning is no longer a problem.
we observe that this occurs often in practice see section iv b .
s tack trace method this approach requires the set of bug warnings of the buggy program and the stack trace s produced when running the buggy program.
as with previousmethods this approach only considers warnings related to npebugs.
for each npe warning the algorithm retrieves the fileand line number s associated with the warning and checkswhether those are included in the stack trace.
if so the warningis classified as a bug candidate.
consider again the example from figure .
the s pot bugs report figure 2c mentions line in file opencvutils.java.
the report pinpoints that there is anull parameter in a recursive call to savedebugimage which could result in an npe.
on the other hand the i nfer report figure 2d lists a warning associated with file opencvvisionprovider.java on line .
the call to savedebugimage in method gettemplatematches is passed debugmat as argument which could be null and result in an npe.
note that i nfer refers to a lower stack frame than s pot bugs but the s tack trace method successfully maps both reports to the same bug because both 295locations can be found in the stack trace figure 2e .
the s tack trace method takes advantage of the nature of npe bugs and their presence in the stack trace.
because npe bugs correspond to null pointer exceptions the call stackis given at the time the exception occurs.
this information isa valuable resource that leads to a more natural bug mappingthan previous methods.
however this method requires anexecutable buggy program and a reproducible npe.
also thismethod provides a line in the stack trace that can be mappedto a bug warning however this does not necessarily meanthat the tool found the correct dereference there are longdereference chains that may be associated with the same line.thus as with previous methods it is necessary to manuallyverify that the trace indeed matches the context of the npewarning.
we consider all available sources of information suchas source code and code diff during manual inspection.
c overage method this method is a general version of the s tack trace method but it includes all lines executed by the test that triggers the npe.
the input is theset of npe warnings of the buggy program and the linescovered executed by a test case that fails due to an npe.the approach determines if the source location given in awarning is covered in which case the warning is added tothe set of bug candidates.
this captures the scenario wherethe location of an npe warning is far away from the actualdereference which is particularly useful when analyzing thewarnings produced by type checkers such as n ull away and eradica te .
the assumption is that even if the npe warning and the actual dereference are located far away from eachother both source locations will be part of the execution trace.for example consider a case in which a field is set to null in a constructor and the field is dereferenced in some method.type checkers may produce a warning related to setting thefield to null but not a warning describing the dereference itself.
however in this case both source locations will bepart of the execution trace.
note that this approach requiresthe existence of a failing test that triggers the npe and theability to execute the test.
both requirements are met for ourdataset.
as with other methods we manually inspect all bugcandidates to determine their validity.
iii.
b ug and tool characteriza tion a fundamental step in evaluating the effectiveness of static bug detectors is to understand their capabilities and whetherreal world bugs possess the desired characteristics to be de tected.
in this section we characterize the dataset of realnpes as well as the tools under study with respect to theirapproaches to find npes.
we describe our methodology andresults which will be critical in section iv to determinewhether a given npe can be found by the tools.
first we performed a manual categorization of all npes to determine the root cause of the null pointer deref erences.
the categorization was performed separately by anauthor of this paper and two people external to the project.when in disagreement the inspectors met to reach consensus.
35fieldmethod parameter method returnreflectionconcurrency third party library map like objectcollection like objectgenerics number of bugsbug classification fig.
bug classification results using the source code the github code diff and the build log we identified the origin of the null value and its dereference location.
based on this inspection we identifiednine general categories of npes with respect to what is deref erenced and the context of the dereference.
these categoriesalong with their counts can be found in figure .
note thatan npe can belong to multiple categories.
the most commoncategories are when a method return value is dereferenced 32bugs and when a field is dereferenced bugs .
as for the tool capabilities we consider seven well known program analysis properties intraprocedural interpro cedural flow sensitive context sensitive fieldsensitive object sensitive and path sensitive .
we identified seven common sources of unsoundness handling of third party libraries whose source code may notbe available impure methods that have side effects andare non deterministic concurrency reasoning aboutdynamic dispatch dealing with code that uses reflection field initialization after a constructor is called and generic parameters.
unsoundness can lead to false positives incorrect bug warnings and false negatives missed bugs .
we studied cfn ullness e radica te infer n ull away and s pot bugs with respect to the above analysis characteristics and sources of unsoundness.
in this process we manually inspected the source code and documentation ofthe tools and we wrote kernel test programs that exhibiteddifferent categories of behaviors to confirm tools capabilitiesand limitations.
table i shows the tool capabilities and table iishows the sources of unsoundness for each tool.
below wedescribe our findings for each tool which were confirmed bythe corresponding developers.
a cfn ullness an ensemble of three checkers an intraprocedural flow sensitive qualifier inference for thenullness of a particular object initialization checking and map key checking.
it assumes nonnull for unannotated code except for locals and provides an analysis for iteratingover null collections and arrays.
additionally cfn ullness supports annotations to denote if a method has no side effects or is deterministic the target of a reflection invo cation and upper bounds of types for generic objects.
296table i tool capabilities confirmed by developers.
has capabilities no capabilities partial limited capabilities.
tool intraproc.
interproc.
field sensitive context sensitive object sensitive flow sensitive path sensitive cfn ullness eradica te partial infer null away partial partial n a partial partial spot bugs partial partial partial partial table ii sources of unsoundness for the tools.
is sound is unsound partial unsound in some aspects.
tool third party libs.
impure methods concurrency dynamic dispatch reflection field init.
generic types cfn ullness eradica te partial partial infer partial partial partial null away partial spot bugs b eradica te an intraprocedural flow sensitive analysis for the propagation of nullability through variable assignments and function calls.
e radica te also raises an alarm for accesses to fields that have annotated nullability howeverits field initialization checker is subject to ongoing work.
e radica te s nullability annotations allow for the annotation of methods fields and method parameters with nullable annotations.
as detailed in table ii e radica te provides built in models of the jdk and android sdk and supportsuser specified nullability signatures for other third party li braries which helps mitigate false negatives.
c i nfer an interprocedural analysis that supports tracking object aliasing side effects in methods and dynamictypes of objects.
all our tests were successful when running i nfer showing that the tool is interprocedural and field sensitive.
a caveat is that i nfer does not find uninitialized fields but it can find null dereferences to fields that have beeninitialized.
as shown in table ii i nfer partially supports third party libraries via an internal model of the jdk.
forimpure methods i nfer tracks some effects in methods e.g.
if a method sets this.field null the effect will be tracked at the call site.
tracking dynamic types of objectsis useful to refine the control flow graph.
however this onlyoccurs in the context of the entry point of the analysis.
d n ull away a flow sensitive type refinement analysis to infer nullness of local variables that includes a fieldinitialization checker.
n ull away assumes that unannotated code cannot be null.
for methods fields and method parameters annotated with the nullable annotation n ull away ensures no dereferences and that their value will not beassigned to a non null field or argument.
our tests showedthat n ull away finds local and object field dereferences without annotations.
with annotations n ull away can find null dereferences of method parameters and return values.
null away is able to avoid dynamic dispatch as a source of unsoundness by ensuring that methods that are overridden havethe same nullability as its parent s class.
n ull away s field initialization is unsound.
for example the analysis does notcheck fields that are read by methods called from constructors.
e spot bugs a null pointer analysis inherited from find bugs that combines forward and backward dataflow analyses for tracking null values.
the analysis provides limited tracking of object fields it does not support aliasingand volatile fields and it assumes that any method can modifya field of an object passed as argument.
additionally s pot bugs provides a null related annotation checkfornull to denote values that must be null checked prior to a dereference.our tests confirmed the intraprocedural nature of s pot bugs however we were unable to expose s pot bugs field sensitivity.
lastly s pot bugs infers parameter and return value information intraprocedurally if these are null checked and itsuffers from all sources of unsoundness as shown in table ii.
iv .
e xperimental ev alua tion this experimental evaluation is designed to answer the following research questions rq1 how prevalent are npes among all warnings?
rq2 how effective are bug mapping methods for npes?
rq3 how effective are static bug detectors for npes?
rq4 what are the reasons bug detectors miss npes?
we ran cfn ullness e radica te infer n ull away and s pot bugs on our dataset of programs with real npe bugs to generate bug reports for the buggy and fixed versionsof the programs.
we ran the tools on the full programs and verified that the files relevant to the bug and fix wereindeed analyzed by the tools.
we considered two settings for s pot bugs low and high thresholds.
the results are presented as s pot bugs lt and s pot bugs ht respectively.
we automatically parsed the bug reports to extract and normalizerelevant information which we stored in a mysql database.
our study is fully reproducible.
the dataset of real reproducible npe bugs from b ugswa r m and d efects 4j is publicly available as well as the tools we study.
the scriptsfor performing the experiments and all data described in thissection is publicly accessible.
000null dereferencedangerous methodreturn v alueunused fieldstatic inner class number of warningsspotbugsl t 000dangerous methodnull dereferencedead local storereturn v aluewrong map iterator number of warningsspotbugsht 000resource leaknull dereferencethread safety violationimmutable castunsafe thread interface number of warningsinfer fig.
s pot bugs lt s pot bugs ht and i nfer distribution of top warnings.
table iii number of all warnings and npe warnings produced by each tool.
avg all and avg npes refer to the average number of warnings produced per program.
tool all npes avg all avg npes cfn ullness eradica te infer .
null away spot bugs ht .
spot bugs lt .
a. rq1 prevalence of npe warnings table iii shows the total and average number of warnings produced by each tool when analyzing the programs.
there area total of w arnings across the 2programs in our dataset.
e radica te yields the largest number of warnings with all of which are npe warnings.
similarly cfn ullness has the second highest number of npe warnings with a total of .
s pot bugs lt produces the third highest number of warnings with w arnings and s pot bugs ht follows with w arnings.
unlike eradica te cfn ullness and n ull away spot bugs can generate over a hundred different types of non npe warningswhile i nfer generates seven.
figure shows the top five types of warnings for s pot bugs lt s pot bugs ht and i nfer .
it is observed that npes are one of the most prevalent warnings for these tools the mostcommon for s pot bugs lt and the second most common for both s pot bugs ht and i nfer .
indeed npes constitute from .
to .
of the total warnings produced by these tools.
for s pot bugs ht we observe a reduction in total number of warnings and npe warnings with respect to spot bugs lt of .
and61.
respectively.
finally n ull away produces the fewest warnings all of them are npe warnings with a total of .
rq1 npe warnings are prevalent in all the tools studied.
a total of npe w arnings .
of all warnings are produced for our dataset.
the percentageof npe warnings for s pot bugs lt is .
s pot bugs ht .
and i nfer .
.table iv bugs mapped by each method.
we show thenumber of correct mappings the total number of mappings.column bugs found gives the total number of bugs foundper tool.
inside parenthesis are the number of bugs that a toolfound but not others.
unique bugs are found across tools.
method tool code report stack covered bugs found cfn ullness eradica te infer null away spot bugs ht spot bugs lt total unique b. rq2 effectiveness of bug mapping methods we applied the four methods discussed in section ii c to find whether the tool warnings describe the bugs of interest.in total all methods together correctly find distinct bugsout of bugs .
.
all bug candidates were manually inspected.
table iv summarizes the results.
an effective mapping method is defined as having high recall and precision.
the s tack trace method is the most effective among the four mapping bugs with a precisionof .
.
all the npes mapped to a warning were contained within the s tack trace method except for four.
on the other hand while the c ode diffmethod and c overage method produce the largest number of bug candidates across all tools they also suffer from the lowest precision .
and .
respectively.
the r eport diffmethod mapped the lowest number of true bugs in comparison to other methods bugs but its precision of .
was still higher than that of the c ode diff method and c overage method .
the results show that the four methods are primarily complemen tary of each other as they map different types of information.
rq2 the s tack trace method is the most effective with bug candidates of which were true bugs .
.
the c ode diff method and c overage method had similar recall than the s tack trace method but a lower precision of .
and .
respectively.
the r eport diffmethod had the lowest recall but a higher precision than c ode diffmethod and c overage method .
2981protected object decode channel channel ... if channel null if channe l null if channel !
null if channel !
null channel.write response remoteaddress a npe bug found by both s pot bugs and e radica te .1public class grblcntrllr extends abstractcntrllr capabilities null capabilities null capabilities new grblutils.capabilities capabilities new grblutils.capabilities 4protected void pausestreamingevent if this.capabilities.real time ... b npe bug dereferencing field of an object not found by any tool.
1protected void ldcmdversheet string sheetname 2sheet sheet switchtosheet sheetname false if sheet null return if sheet null return 4while i sheet.getrows ... c npe bug due to null dereference of a return value.1private void verifydecodedposition if p.gntk !
null if p.gntk !
null if p.gntk !
null p.gntk .gtwrs !
null if p.gntk !
null p.gntk .gtwrs !
null for twr twr p.gntk .gtwrs d npe bug with dereferencing object returned from a method.
fig.
examples of npe diffs from the dataset.
c. rq3 effectiveness of tools at finding npes overall the tools find distinct bugs out of bugs .
.
the breakdown per tool is shown in table iv.
eradica te finds the most bugs with out of .
cfn ull ness finds bugs i nfer bugs and s pot bugs lt bugs.
n ull away and s pot bugs ht find the fewest bugs with and respectively.
we examined the overlap among bugs found by each tool.
the two tools with the most overlapare cfn ullness and e radica te with bugs.
interestingly each tool finds bugs not found by other tools also shown intable iv .
this shows that the tools are complementary andthat practitioners could benefit from running multiple tools.
achallenge to this is the large number of warnings to inspect.
an example of a bug found by cfn ullness infer and spot bugs lt was given in figure 2a.
we show the diff between a buggy version with an npe bug and the fixedversion of the github project openpnp openpnp a robotic pick and place machine .
the call to the buggy method thatcauses the npe is located on line of the buggy program.the fix for this npe bug consists of adding a null check forparameter mat insavedebugimage.
figure 5a shows an example of a bug found by cfn ull ness e radica te spot bugs ht and s pot bugs lt. here we show the diff between a buggy version and the fixed versionof project traccar traccar a gps tracking system .
the bug was that the null check was flipped incorrectly deref erencing channel when null.
the fix simply consists of changing the comparison operator from to!
.
a possible reason why i nfer did not find this bug is that i nfer does not gather information from checks.
since figure 5a includesa null check s pot bugs is able to reason that channel is dereferenced when null leading to an npe.
we conducted an additional experiment on a random sample of40programs6from our initial set for which annotations were inferred using intellij idea s infer nullity .
intellijidea infers both nullable and notnull annotations.
note that out of the programs originally include 6the process could not be automated due to the ide thus the sample.some nullness annotations.
we ran all tools on the anno tated programs except for i nfer which does not use annotations.
intellij added nullable and notnull annotations.
we applied the c overage method to map warnings.
this resulted in and 2additional bugs found by cfn ullness e radica te n ull away and spot bugs lt respectively.
these accounted for three unique bugs across all tools.
despite the small increase in bugs found the results are promising as annotating less than half of theprograms resulted in finding more bugs in total.
rq3 overall the tools have low effectiveness at findingnpe bugs.
out of the bugs in our dataset e rad ica te found bugs .
cfn ullness found .
i nfer found .
s pot bugs lt found bugs .
n ull away found .
and spot bugs ht found .
.
additional annotations resulted in finding 3more bugs.
d. rq4 reasons bug detectors miss npes we are interested in understanding the reasons why bug detectors fail to find real npes.
we start by discussing thecharacteristics of the bugs that the tools find based on thecharacterization of bugs from our dataset and the toolsthemselves see section iii .
we then discuss the characteris tics of those bugs that the tools fail to find.
a cfn ullness cfn ullness found bugs including every category shown in figure .
these included 3dereferences to a method return value and dereferences of amap object.
the sound properties of cfn ullness allow it to find classes of bugs that the other tools cannot.
for example cfn ullness also found bugs due to concurrency field initialization generics and reflection.
the lack of necessaryannotations in the projects under study inhibits cfn ull ness s ability to find all of the bugs in those categories.
b eradica te eradica te found bugs where dereferenced a method return value 3dereferenced an object field 1retrieved a value from a map object and the rest dereferenced a method parameter.
despite using a partial 299model of the jdk e radica te missed bugs in other thirdparty libraries.
e radica te does not handle concurrency and reflection.
these limitations explain some of the false negatives while others can be explained by the lack of full fieldinitialization checks and dynamic dispatch.
c i nfer infer found bugs that included 4dereferences of a method parameter 4dereferences of a method return value one of which is from a jdk library a derefer ence of a list and a dereference of an object field.
thesenpes are interprocedural in nature which aligns with ourcharacterization of i nfer in section iii.
however i nfer did not find the remaining npes that involve method parameters method return values or object fields which we would expectto be captured by interprocedural analysis.
one reason is that i nfer does not take into account existing null checks.
infer has an internal partial model of the jdk which enables reasoning about certain library methods.
surprisingly despite the fact that i nfer supports field sensitivity and was successful at finding such bugs in our tests it missed manyother field sensitive bugs.
note that i nfer does not have a check for field initialization so it does not find uninitializedfields but it does support fields set to null.
such an example is shown in figure 5b.
additionally i nfer does not find npes that involve reflection concurrency maps or use of third partylibraries outside of the jdk.
d n ull away null away found bugs all of which dereference a return value.
this shows the challenge in placingannotations in the right place to be beneficial.
n ull away s main sources of false negatives are its assumptions thatunannotated code is not null and that third party libraries do not return null.
while manual tests written during our categorization revealed correct warnings about dereferencedfields real bugs that share these characteristics were notdetected.
such an example is shown in figure 5b wherean unannotated field considered non null is being assignednull.
this represents a strict violation of the assumption thatthe field cannot hold a null value and should result in a warning.
finally in the process of running n ull away one of the programs crashed the tool.
the problem was due toa buggy treatment of certain methods in the standard javalibrary.
we reported the bug to n ull away developers and it is now fixed in the latest release.
e spot bugs spot bugs found npes of which occur when dereferencing a method parameter 3when dereferencing a method return value and another when dereferencinga field.
in all cases there is at least one null check within themethod for the object being dereferenced but the programmerdereferences the object in a path that is not checked.
thenull checks enable s pot bugs to reason about the npes intraprocedurally section iii .
the remaining npes in oursample that dereference a method s return value or parameterare not found because they require interprocedural reasoning.additionally the npes that involve the dereference of anobject field are not found by s pot bugs .s pot bugs fails to find any bugs dealing with reflection concurrency third party libraries maps and lists.
this conforms to our toolcharacterization s pot bugs does not provide complete field sensitivity.
rq4 s pot bugs misses npes that require interprocedural analysis.
i nfer performs interprocedural analysis but does not have a field initialization check nor does ithandle some path sensitive information from null checks.
n ull away relies on nullness annotations but does not handle maps nor third party libraries.
e radica te deals with third party libraries better than other tools but itstill misses bugs due to partial field initialization check ing.
cfn ullness provides sound analyses to handle reflection and initialization which allows finding bugs thatother tools cannot.
however the lack of annotations canstill lead to missed bugs.
e. threats to v alidity although we conducted this study on a substantial number of real world npes our results cannot be generalized.
weattempted to reduce this threat by including a large numberof npe bugs from a diverse set of projects from two javabug datasets.
it is possible that we may have missed othertools that are eligible for our study.
we still believe that thefive tools considered are good representatives of popular andwidely used state of the art static bug detectors for npes.
thefour different mapping methods used in this paper are notperfect and may lead to false positives.
to alleviate this threat we manually inspected all warnings that were deemed to bebug candidates.
anything requiring human intervention can beerror prone and subjective.
to mitigate this threat and reducebias we involved two people external to our project in thecategorization of bugs.
finally we consulted tool developers toconfirm our findings regarding tool capabilities and limitations as discussed in section iii.
v. l essons learned this section describes some opportunities for improvement.
a need for reducing or ranking warnings over npe warnings were generated across all tools and programs with npes being in the top warnings for every tool.
theaverage number of warnings per program was in the hundreds which is a cumbersome amount.
because of this we hadto employ a combination of mapping methods and manualverification to determine if a bug was found.
in our case it isknown that an npe exists and the goal is to determine whetherthe tools find it.
however this is not the usual setting for toolusage developers do not know beforehand of the existenceof bugs or else the tools would not be needed.
thus thelarge number of warnings is especially problematic in a realsetting where true bugs are unknown and all warnings mustbe inspected.
a bug ranking system could help in navigating the large number of warnings.
all tools studied except for n ull away provide severity warning information but this information didnot correlate to finding the npes under study.
for example 300spot bugs provides a severity ranking concerning troubling scary and scariest .
however the true bugs found were not associated with the most severe category but with the troubling and scary categories.
this shows the need formore conservative strategies to process warnings or to labelwarnings that are more likely to be true bugs.
two main approaches for ranking warnings are found in the literature and could be applied in the context of staticbug detectors for npes.
the first solely focuses on rankingwarnings of a specific program version without consideringinformation such as warnings produced for other versionsof the program.
examples in this category learn a classifiervia methods ranging from bayesian networks decision trees and neural networks .
the second approach uses thedifference of warnings between a previous and the currentversion of the program or self adapts through user feedback .
a promising approach to aid static bug detectors fornpes would be to learn a project specific classifier that hasuser feedback on predictions.
this would benefit users as thetool learns over time domain specific project characteristics which would eventually lead to higher precision.
b need for automatically inferring nullability annotations there is an inherent burden in writing annotations.
analyzers that depend on annotations could benefit from au tomated inference of nullability annotations.
running intellijidea s infer nullity on programs enabled the tools tofind an additional bugs.
this shows that there is promise inannotation based approaches for bug finding.
however there isroom for improvement in annotation inference as the analysisstill missed annotations that could have lead to finding morebugs.
furthermore it was difficult to automate the process ofannotating code using intellij which may prevent its use inmany scenarios.
there exists work that applies static analysisto infer non null annotations for object fields in a subset ofjava which could be potentially used to aid annotation based npe bug detectors but it is not publicly available.
c need for reasoning about collection like data structures a pain point for all tools studied is reasoning about the nullability of objects inside a collection like data structuresuch as an array.
users can add annotations to indicate thata data structure can be null but there is no mechanism to annotate the nullability of individual elements in the data struc ture.
cfn ullness e radica te and n ull away overcome this challenge for map like objects by assuming that the get interface may return a nullable value.
a similar approachcould be adopted each time an element from other collection like data structure is retrieved.
incorporating such strategywould enable the tools to successfully find additional bugs.
d need for reasoning about reflection reasoning about reflection imposes a challenge for any static analysis.
allof the tools in our study are unsound when it comes toreflection except cfn ullness .
since most of the tools can leverage annotations a potential approach for handlingreflection is user provided annotations.
this is exactly what cfn ullness does.
this is done via a list of targets a priori of what class or method is being operated on for certainreflection calls.
this approach has been implemented in otheranalyses for java where analysis precision wasobserved to improve.
indeed incorporating the above strategywould enable the npe bug detectors to find additionalbugs from which cfn ullness successfully finds one given the existing annotations.
vi.
r ela ted work a static analyzer studies rutar et al.
compare the static analyzers pmd findbugs jlint bandera andesc java on a small suite of programs.
the authors presenta taxonomy of bugs found by each tool showing that no toolsubsumes the other.
the study focuses on runtime and numberof warnings produced.
johnson et al.
conduct a study inwhich developers are interviewed on their experiences usingstatic analysis tools.
the study finds that the main reason whydevelopers do not use tools is false positives.
habib and pradel study the static analyzers i nfer error prone and s pot bugs to determine how many of all bugs in d efects 4j can be found by these tools.
the authors use the code diff and the bug report mapping methods.
thestudy finds that only bugs out of bugs .
weredetected of which only were npes.
tomassi conductsa study that compares e rror prone and s pot bugs to find how many of allbugs in a sample of b ugswa r m artifacts are found.
the author found that only one bug was foundby s pot bugs .
instead we focus on a specific kind of bug npes and present a detailed analysis of the capabilities andthe limitations of five popular tools that find npes.
ayewah and pugh run coverity eclipse findbugs fortify and xylem on different versions of the build systemant.
the authors classify the null dereferences reported byeach tool plausible implausible or impossible and explorethe usefulness of using null related annotations.
most recently banerjee et al.
presented the tool n ull away and performed a comparison to the checker framework s nullnessanalysis and i nfer s eradicate looking at build time overhead.
while ayewah and pugh study false positivesin one version of ant banerjee et al.
focus on measuringfalse negatives in uber s android apps.
we study the recallof five popular bug detectors including n ull away on real and reproducible npes from open source projects.
b tools to find null pointer dereferences ayewah et al.
present a static analysis tool called f ind bugs the predecessor of s pot bugs .f ind bugs finds a wide variety of bugs including null pointer dereferences.
hovemeyer andpugh extend f ind bugs s npe finding capabilities by improving the precision of the analysis.
these improvementswere a result of a better model of the core api of jdk changing how errors on exception paths are handled improv ing field tracking and finding guaranteed dereferences.
weinclude s pot bugs in our study.
papi et al.
introduce the checker framework which allows for pluggable type systems for java.
they evaluatefive checkers including the nullness checker running themover significant sized code bases.
the checkers find real bugs 301and confirmed the absence of others.
we include the checker framework in our study.
nanda and sinha develop a demand driven dataflow analysis for null dereference bugs in java.
by being path sensitive and context sensitive the analysis allows for a lowfalse positive rate and an improved precision over f ind bugs and jlint.
romano et al.
use the analysis from nanda andsinha to find variables and paths that lead to possible nullpointer dereferences.
the authors use a genetic algorithm togenerate tests that trigger the null pointer dereferences.
logi nov et al.
develop a sound interprocedural analysis basedon abstract interpretation called expanding scope algorithm.
madhavan and komondoor demonstrate a sound demand driven interprocedural context sensitive dataflow analysis toverify whether a dereference will be safe or not.
none of theabove tools are publicly available.
vii.
c onclusion in this experience paper we studied the effectiveness of popular java static bug detectors cfn ullness e radica te infer n ull away and s pot bugs on real npes from open source projects.
we identified the capabilities of the tools and the characteristics of the npe bugs in our dataset.
wediscussed the problem of mapping tool warnings to actual npebugs and investigated four mapping methods including twonew approaches that leverage stack trace and code coverageinformation from which the stack trace based was the mosteffective.
overall the tools detected a total of out of bugs.
we conducted an additional experiment annotating programs using intellij which resulted in new bugsfound.
finally we leveraged the characteristics of the toolsand the bugs in our dataset to gain insights into why the toolsmissed certain types of bugs.
we concluded by discussingopportunities for improving npe bug detection.
we providethe link to a public repository that contains both our scriptsand the data produced in our experimental evaluation.
a cknowledgment this work was supported in part by national science foundation award cns a facebook testing and v er ification research award and a uc davis graduate fellowship.we would like to thank aditya v .
thakur and premkumar t.devanbu for their feedback and suggestions.
we also thankamy cu raisa putri robert furth and ryan jae for their helpmanually classifying npes and replicating our experimentalresults.
lastly we would like to thank the developers of eachtool for their prompt answers to our questions.
r eferences cve .
cve .
checkstyle.
.
cve null pointer.
null pointer .
eradicate.
.
error prone.
.
infer.
.
intellij.
.
nullaway.
.
pmd.
.
spotbugs.
.
a. v .
aho m. s. lam r. sethi and j. d. ullman.
compilers principles techniques and tools 2nd edition .
addison wesley longmanpublishing co. inc. usa .
n. ayewah and w. pugh.
null dereference analysis in practice.
in proceedings of the 9th acm sigplan sigsoft workshop on programanalysis for software tools and engineering paste pages new y ork ny usa .
acm.
.
.
.
url n. ayewah d. hovemeyer j. d. morgenthaler j. penix and w. pugh.
using static analysis to find bugs.
ieee softw.
.
.
ms. .
.
url s. banerjee l. clapp and m. sridharan.
nullaway practical type based null safety for java.
in proceedings of the 27th acm joint meeting on european software engineering conference and symposium on thef oundations of software engineering esec fse pages new y ork ny usa .
acm.
.
.
.
url c. calcagno and d. distefano.
infer an automatic program verifier for memory safety of c programs.
in m. g. bobaru k. havelund g. j. holzmann and r. joshi editors nasa f ormal methods third international symposium nfm pasadena ca usa april .
proceedings volume of lecture notes in computer science pages .
springer .
.
.
url .
c. calcagno d. distefano p .
w. o hearn and h. yang.
compositional shape analysis by means of bi abduction.
in z. shao and b. c. pierce editors proceedings of the 36th acm sigplan sigact symposium on principles of programming languages popl savannah ga usa january pages .
acm .
.
.
.
url c. calcagno d. distefano j. dubreil d. gabi p .
hooimeijer m. luca p .
w. o hearn i. papakonstantinou j. purbrick and d. rodriguez.moving fast with software verification.
in k. havelund g. j. holz mann and r. joshi editors nasa f ormal methods 7th international symposium nfm pasadena ca usa april pro ceedings volume of lecture notes in computer science pages .
springer .
.
.
url .
m. christakis and c. bird.
what developers want and need from program analysis an empirical study.
in d. lo s. apel and s. khurshid editors proceedings of the 31st ieee acm international conference on automated software engineering ase singapore september pages .
acm .
.
.
.url w. dietl s. dietzel m. d. ernst k. muslu and t. w. schiller.
building and using pluggable type checkers.
in r. n. taylor h. c.gall and n. medvidovic editors proceedings of the 33rd international conference on software engineering icse waikiki honolulu hi usa may pages .
acm .
.
.
.
url a. habib and m. pradel.
how many of all bugs do we find?
a study of static bug detectors.
in m. huchard c. k astner and g. fraser editors proceedings of the 33rd acm ieee international conference on auto mated software engineering ase montpellier france september3 pages .
acm .
.
.
.url q. hanam l. tan r. holmes and p .
lam.
finding patterns in static analysis alerts improving actionable alert ranking.
in p .
t. devanbu s. kim and m. pinzger editors 11th working conference on mining software repositories msr proceedings may june hyderabad india pages .
acm .
.
.
.
url k. heo m. raghothaman x. si and m. naik.
continuously reasoning about programs using differential bayesian inference.
in k. s. mckinleyand k. fisher editors proceedings of the 40th acm sigplan conference on programming language design and implementation pldi2019 phoenix az usa june pages .
acm .
.
.
.
url d. hovemeyer and w. pugh.
finding bugs is easy.
in j. m. vlissides and d. c. schmidt editors companion to the 19th annual acm sigplan conference on object oriented programming systems languages andapplications oopsla october v ancouver bc 302canada pages .
acm .
.
.
.
url d. hovemeyer and w. pugh.
finding more null pointer bugs but not too many.
in m. das and d. grossman editors proceedings of the 7th acm sigplan sigsoft workshop on program analysis for softwaretools and engineering paste san diego california usa june13 pages .
acm .
.
.
.url l. hubert t. p .
jensen and d. pichardie.
semantic foundations and inference of non null annotations.
in g. barthe and f. s. de boer editors f ormal methods for open object based distributed systems 10th ifipwg .
international conference fmoods oslo norway june4 proceedings volume of lecture notes in computer science pages .
springer .
.
.
url .
b. johnson y .
song e. r. murphy hill and r. w. bowdidge.
why don t software developers use static analysis tools to find bugs?
ind.
notkin b. h. c. cheng and k. pohl editors 35th international conference on software engineering icse san francisco ca usa may pages .
ieee computer society .
.
icse.
.
.
url r. just d. jalali and m. d. ernst.
defects4j a database of existing faults to enable controlled testing studies for java programs.
in c. s. pasareanuand d. marinov editors international symposium on software testing and analysis issta san jose ca usa july pages .
acm .
.
.
.
url o. lhot ak and l. j. hendren.
scaling java points to analysis using spark.
in g. hedin editor compiler construction 12th international conference cc held as part of the joint european conferenceson theory and practice of software etaps warsaw poland april7 proceedings volume of lecture notes in computer science pages .
springer .
.
.
url .
a. loginov e. yahav s. chandra s. fink n. rinetzky and m. g. nanda.
v erifying dereference safety via expanding scope analysis.
inb.
g. ryder and a. zeller editors proceedings of the acm sigsoft international symposium on software testing and analysis issta seattle wa usa july pages .
acm .
.
.
.
url r. madhavan and r. komondoor.
null dereference verification via over approximated weakest pre conditions analysis.
in c. v .
lopesand k. fisher editors proceedings of the 26th annual acm sigplan conference on object oriented programming systems languages andapplications oopsla part of splash portland or usa october pages .
acm .
.
.
.
url g. j. myers t. badgett t. m. thomas and c. sandler.
the art of software testing volume .
wiley online library .
m. g. nanda and s. sinha.
accurate interprocedural null dereference analysis for java.
in proceedings of the 31st international conference on software engineering icse pages washington dc usa .
ieee computer society.
.
icse.
.
.url m. m. papi m. ali t. l. c. jr. j. h. perkins and m. d. ernst.
practical pluggable types for java.
in b. g. ryder and a. zeller editors proceedings of the acm sigsoft international symposium on software testing and analysis issta seattle wa usa july pages .
acm .
.
.
.url d. romano m. d. penta and g. antoniol.
an approach for searchbased testing of null pointer exceptions.
in f ourth ieee international conference on software testing v erification and v alidation icst berlin germany march pages .
ieee computersociety .
.
icst.
.
.
url n. rutar c. b. almazan and j. s. foster.
a comparison of bug finding tools for java.
in proceedings of the 15th international symposium on software reliability engineering issre pages washington dc usa .
ieee computer society.
url h. shen j. fang and j. zhao.
efindbugs effective error ranking for findbugs.
in f ourth ieee international conference on software testing v erification and v alidation icst berlin germany march pages .
ieee computer society .
.
icst.
.
.
url m. sridharan s. artzi m. pistoia s. guarnieri o. tripp and r. berg.
f4f taint analysis of framework based web applications.
in c. v .
lopesand k. fisher editors proceedings of the 26th annual acm sigplan conference on object oriented programming systems languages andapplications oopsla part of splash portland or usa october pages .
acm .
.
.
.
url f. thung lucia d. lo l. jiang f. rahman and p .
t. devanbu.
to what extent could we detect field defects?
an empirical study of falsenegatives in static bug finding tools.
in m. goedicke t. menzies andm.
saeki editors ieee acm international conference on automated software engineering ase essen germany september pages .
acm .
.
.
.
url f. tip c. laffra p .
f. sweeney and d. streeter.
practical experience with an application extractor for java.
in b. hailpern l. m. northrop and a. m. berman editors proceedings of the acm sigplan conference on object oriented programming systems languages applications oopsla denver colorado usa november pages .
acm .
.
.
.
url f. tip p .
f. sweeney c. laffra a. eisma and d. streeter.
practical extraction techniques for java.
acm trans.
program.
lang.
syst.
.
.
.
.
url d. a. tomassi.
bugs in the wild examining the effectiveness of static analyzers at finding real world bugs.
in proceedings of the acm joint meeting on european software engineering con ference and symposium on the f oundations of software engineering esec sigsoft fse lake buena vista fl usa november pages .
.
.
.
url d. a. tomassi n. dmeiri y .
wang a. bhowmick y .
c. liu p .
t. devanbu b. v asilescu and c. rubio gonz alez.
bugswarm mining and continuously growing a dataset of reproducible failures and fixes.inproceedings of the 41st international conference on software engineering icse pages piscataway nj usa .
ieeepress.
.
icse.
.
.
url l. y u w. tsai w. zhao and f. wu.
predicting defect priority based on neural networks.
in l. cao j. zhong and y .
feng editors advanced data mining and applications 6th international conference adma2010 chongqing china november proceedings part ii volume of lecture notes in computer science pages .
springer .
.
.
url https .
m. zhivich and r. k. cunningham.
the real cost of software errors.
ieee secur .
priv.
.
.
msp .
.
.
url .
.
.