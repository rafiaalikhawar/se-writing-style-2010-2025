how incidental are the incidents?
characterizing and prioritizing incidents for large scale online service systems junjie chen college of intelligence and computing tianjin university tianjin china junjiechen tju.edu.cnshu zhang microsoft research beijing china v shuzh microsoft.comxiaoting he microsoft research beijing china v xiah microsoft.com qingwei lin microsoft research beijing china qlin microsoft.comhongyu zhang the university of newcastle callaghan australia hongyu.zhang newcastle.edu.audan hao peking university beijing china haodan pku.edu.cn yu kang microsoft research beijing china kay microsoft.comfeng gao microsoft azure redmond usa fgao microsoft.comzhangwei xu microsoft azure redmond usa zhangxu microsoft.com yingnong dang microsoft azure redmond usa yidang microsoft.comdongmei zhang microsoft research beijing china dongmeiz microsoft.com abstract although tremendous effortshave been devoted to thequality assurance of online service systems in reality these systems still come across many incidents i.e.
unplanned interruptions and outages which can decrease user satisfaction or cause economic loss.
tobetterunderstandthecharacteristicsofincidentsandimprove the incident management process we perform the first large scale empirical analysis of incidents collected from real world online service systems in microsoft.
surprisingly we find that although a largenumberofincidentscouldoccuroverashortperiodoftime many of them actually do not matter i.e.
engineers will not fix them with a high priority after manually identifying their root cause.wecalltheseincidents incidentalincidents.ourqualitative andquantitativeanalysesshowthatincidentalincidentsaresignifi cantintermsofbothnumberandcost.therefore itisimportantto prioritize incidents by identifying incidental incidents in advance to optimize incident management efforts.
in particular we pro pose an approach called deepip deeplearning based incident this work was mainly done when he was visiting microsoft research.
corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn ... .
to prioritizing incidents based on a large amount of historical incident data.
more specifically we design an attentionbasedconvolutionalneuralnetwork cnn tolearnaprediction model to identify incidental incidents.
we then prioritize all incidents by ranking the predicted probabilities of incidents being incidental.weevaluatetheperformanceofdeepipusingreal worldincidentdata.theexperimentalresultsshowthatdeepipeffectively prioritizes incidents by identifying incidental incidents and significantly outperforms all the compared approaches.
for example the auc of deepip achieves .
while that of the best compared approach is only .
on average.
ccs concepts software and its engineering maintaining software.
keywords incidents online service systems prioritization acm reference format junjie chen shu zhang xiaoting he qingwei lin hongyu zhang dan hao yu kang feng gao zhangwei xu yingnong dang and dongmei zhang.
.
how incidentalare the incidents?
characterizing and prioritizing incidents for large scale online service systems.
in 35th ieee acm international conference on automated software engineering ase september virtual event australia.
acm new york ny usa pages.
introduction in recent years online service systems such as microsoft azure and office have been widely used by millions of users around 35th ieee acm international conference on automated software engineering ase ase september virtual event australia j. chen et al.
the world.
to assure their quality practitioners put dedicated efforts butsuchonlineservicesystems still encounter many incidents i.e.
unplanned interruptions and outages .
these incidents can decrease user satisfaction or cause serious economic loss.
for example the one hour downtime foramazon.com on prime day in its biggest sale event of the year caused the loss of up to million .
therefore high availability and reliability are essential to online service systems.
once an incident occurs to an online service system it needs to be mitigated as soon as possible so as to reduce the loss caused by the incident .
however an online service system is quite complex i.e.
involvingmanycomponentssuchashardware virtual machines network anddatabase andinthemeanwhileallthese components can lead to incidents in the daily operation of the system.
therefore incidents tend to occur frequently in practice.
moreover the number of engineers who are responsible to deal with incidents and computing resources is limited and the cost spent on incident management is considerable.
therefore it is scarcelypossibletomitigateeveryincidenttimely.toreducethe impactsofincidentsasmuchaspossible intuitively oneofthemost cost effective solutions is to deal with more important incidents earlier.
that is it is necessary to prioritize incidents for engineersto optimize the incident management process.
to achieve the goal of incident prioritization we first need to understandwhathigh priorityincidentsandlow priorityincidents are.
however to date there lack extensive studies on incidents.
therefore we perform the first empirical analysis for incidents of real world online service systems in microsoft including many worldwidepopularsystems.foreachsystem wecollectincident dataoverasix monthperiod.indeed therearealargenumberof incidents reported over a short period.
for example for service xtherearenearly3 000incidentspertimeunit1.however many of them actually are not important i.e.
they do not really affectcustomers and engineers will not fixthem with a high priority afterthey manually find the reasons why the incidents occur.
in thispaper wecalltheseincidents incidentalincidents.incontrast we call the remaining incidents essential incidents.
more specifically since essential incidents can be caused by a variety of factors e.g.
various source code bugs and hardware failures itisdifficulttocharacterizethemthoroughly.here weaim toprioritizeincidentsfromtheoppositedirection i.e.
identifying incidentalincidentsandthenputtingthemintheend.therefore we conduct a qualitative analysis to characterize incidental incidents.wefindthattheincidentsfallintoseveralcategories.also we conduct a quantitative analysis to investigate the impacts of incidental incidents.
we find that for out of studied systems the percentage of incidental incidents is more than and thepercentage of maintenance time spent on incidental incidents is alsomorethan30 !theresultsdemonstratethatalargenumber of engineers efforts were spent on incidental incidents which can largely delay the mitigation of really important incidents.
those also empirically motivate the necessity of incident prioritization.
further inthispaperweproposeadeep learningbasedapproach calleddeepip deeplearningbased incidentprioritization toprioritizing incidents by identifying incidental incidents based on a 1due to the company policy we hide the time unit and service name.large amount of historical incident data.
in particular there aretwo main challenges in the problem which features are help ful to identify incidental incidents how to effectively utilizethese features to identify incidental incidents.
for the first challenge our empirical study provides some guidelines on effective featuresandhelpsusidentifythreetypesoffeatures i.e.
textual descriptions i.e.
title and summaryof an incidentreport special terms e.g.
api names and component names occurring in an incidentreport andincident occurringenvironmentinformation e.g.
incident occurring device .
to overcome the second challenge we drawsupportfromdeeplearning.sincethefeaturesweusedaremainly textual information deep learning can achieve semanticunderstanding of natural language descriptions and outperformtraditional machine learning algorithms as demonstrated by existing studies .
more specifically we design a cnn based deepneuralnetworkandincorporateanattentionmechanism.the incidentalincidentscanbepredictedbytheattention basedcnn model.
then we prioritize all the incidents based on the ascendingorder ofthepredicted probabilitiesofbeing incidental.inthis way engineers canoptimizetheincidentmanagement processby handling the incidents ranked higher first.
toinvestigatetheeffectivenessofourapproachdeepip weconductanextensiveevaluationusingreal worldincidentdatafrom microsoft the same data as the one used in the empirical study .
theresultsdemonstratethatdeepipisabletoeffectivelyandefficientlyprioritizeincidentsforlarge scaleonlineservicesystems andsignificantlyoutperformallthecomparedapproachesinthe areaofsoftwarebugseverityprediction2.forexample theaverage auc measuringtheaccuracythatessentialincidentsareranked higher than incidental incidents of deepip is .
while that of the best compared approach is just .
.
the results demon strate that as the first attempt to solve the practical problem of incidentprioritization ourdeep learningbasedapproachdeepip is indeed promising.
our study results also show that each type of features i.e.
specialtermsandincident occurringenvironments cansignificantlyimprovetheeffectivenessofdeepip confirming the contributions of each of them.
in particular the practical value of deepip has been appreciated by engineers in microsoft.
the major contributions of the paper are as follows weperformthefirstlarge scaleempiricalstudyonincidents of 18real world onlineservice systems characterizing incidents qualitatively and quantitatively.
we propose the first approach to prioritizing incidents byidentifying incidental incidents in order to optimize the incident management process.
we conduct an extensive study to evaluate the performance of deepip based on real world incident data of largescaleonlineservicesystems.ourresultsshowthatdeepip significantly outperforms all the compared approaches.
background in this section we introduce the background of incidents and incident management icm for online service systems in practice.
2since there is no existing incident prioritization approach for online service systems we adapt the typical approaches of traditional software bug severity prediction for comparison in our study.
374how incidental are the incidents?
ase september virtual event australia online service systemauto alert manual reporticm system teamteamincident reporting calling incident triageincident mitigation incident resolutionincident status update oces figure workflow of incident management figure1showstheworkflowoficmforlarge scaleonlineservice systemsinmicrosoft.theicmconsistsoffourstages.thefirststage isincident reporting.
in an online service system a large number of monitorsareusedtowatchforsomekeyperformanceindicators e.g.
latency and network status .
most incidents are actually reportedbyvariousmonitorsautomatically whichisdifferentfrom the manualreporting of traditionalsoftware bugs.
inparticular a monitor automatically reports an incident to the icm system when some predefined anomalous conditions are met.
besides engineers could observe incidents during their daily operation and thus they couldalsoreportincidentsmanuallytotheicmsystem.afteran incident is reported to the icm system the icm system first makes a phone call to a set of on call engineers oces to trigger the investigation process of the incident.
ideally the oces can directly identify the root cause and then mitigate the incident based on the information in the incident report.
however in most cases they cannotfindtherootcausewithinashorttime.therefore theoces have to assign the incident to a team that they think is the most suitable to handle it which is the second stage incident triage.
the third stage is incident mitigation.
when the incident is assigned to the correct team the engineers in the team begin to diagnose the problem and then take all necessary actions to mitigate the incident e.g.
reboot the server or replace failure hardware .
after mitigation theengineersfurtheranalyzetheunderlyingrootcause of the incident through offline postmortem analysis and finally completely resolve the incident which is the last stage incident resolution.
moreover the engineersupdate thestatus e.g.
mitigated or resolved of an incident in the icm system.
incident mitigation should be timely since long time to mitigate ttm could leadto poor serviceavailability andcause huge financial loss.
however it is often costly for engineers to manu ally mitigate an incident due to the complexity and scale of thesystem.consideringthelargenumberofincidentsaswellasthe limited number of engineers and computing resources it is essential to handle more important incidents earlier.
however to our best knowledge none of existing work has studied the priority and influence of incidents before.
therefore in this paper we conduct the first extensive study to characterize incidents presented in section3 andfurtherproposeaneffectiveapproachtoprioritizing incidents to optimize the incident management process presented in section .
an empirical study of incidents tobetterunderstandthepriorityandinfluenceofincidentsforlargescaleonlineservicesystems weconductthefirstextensivestudy onreal worldincidents.aspresentedinsection1 inthisstudy weaim to understand the characteristics of incidental incidents.
based ontheidentificationoftheincidentalincidents wecanprioritize incidentsbyputtingtheincidentalincidentsintheend.here we target at the following research questions rq1 which incidents are incidental in large scale online service systems?
rq2 what is the percentage of incidental incidents?
rq3 what is the cost spent on incidental incidents?
rq4 isthecurrentincidentmanagementpracticegoodenough?
rq1 is qualitative analysis to investigate what are incidental incidents whiletheotherrqsarequantitativeanalysistostudy incidentalincidentsintermsofnumberandcost.inparticular rq4 aimstoexplorewhetherthecurrentpracticeofincidentmanagement is sufficiently good from the view of incident priority.
.
subjects we used large scale online service systems in microsoft as subjects.
these subjects include many worldwide popular products andareusedbymillionsofusersworldwide.allthe18systemsare in different application areas and developed by different product groups indicating the diversity of subjects.
for each online service system we collected real incident data over a six month period.
the size of all the collected incident reports is up to .2gb.
the total number of monitors used to monitor these systems is more than 80k.
due to the policy of microsoft we hid some details such asthespecifictimeperiodforincidentcollectionandthespecific number of collected incidents.
.
rq1 qualitative analysis after diagnosing an incident engineers tend to manually record whether the incident needs to be fixed with a high priority and give a simple explanation for the incident in the icm system.
if the incidentindeedneedstobefixedwithahighpriority i.e.
itisan essential incident engineers also record the fixing steps.
that alsomeans althoughanincidentisanincidentalincident engineersstill have to spend time and resources on diagnosing the reason why it occurs and finallyfind thatit actuallyis an incidentalone.
with the help i.e.
manual recording of engineers incidental incidents can bedivided into sixcategories by design customer error won t fix unable to reproduce transient and false alarm.
we analyze each category of incidental incidents in the following.
.
.
by design.
the incidents belonging to this category are producedintentionally anddonotneedtobedealtwith.thiscategory of incidents tends to have the purpose of testing.
one of such in cidents is shown in example .
according to the title one line description oftheincidentreportandtheexplanationgivenbythe engineerswhodiagnosedtheincident obviously thisincidentis anintentionalincidentfortesting odataapi.theoccurrencesof this category of incidents are as expected and thus they should be assigned low priority in practice.
375ase september virtual event australia j. chen et al.
example incident testincident2018 23t00 36z.
explanation odata api test.
.
.
customer error.
this category of incidents is caused by customer errors rather than the problems of online service systems.
inotherwords customersmisusethesystemsorincorrectlyconfigure the systems causing the occurrences of the incidents.
for example as shown in example the incident is that sending emailnotificationfailed.however thecauseforthisincidentwasthattheinboxofthecustomerwasfull.similarly inexample3 thecausefor the incident badge preview missing at dsm was that the dymo driverwasnotcorrectlyinstalledbycustomers.thiscategoryof incidents canbe directly handledby the technicalsupporters and thus do not need to notify engineers.
example incident failed to send email notification on tenant 022d9fca 60a3 4aac 9a90 c18e51ac527e at frequency daily.
explanation inbox is full insufficient storage error.
example incident badge preview missing at dsm.
explanation customerinstalleddymodriverandresolved the issue.
.
.
won t fix.
the incidents belonging to this category are real incidents buttheytendtooccuratthepartsthatareout of date i.e.
notmaintainedanymore .therefore itisnotworthtakingthe engineers efforts to solve them.
as shownin example engineers think that it is not necessary to solve the incident node service stuck in crash loop since the occurring part of the incident has been deprecated.
example incident node service stuck in crash loop on br1 nns207.
explanation deprecated fabric.
.
.
unabletoreproduce.
theincidentsbelongingtothiscategory are not able to be reproduced during diagnosis.
in this case it ishardtosaywhethertheyarerealincidents anditisscarcelypossibleto checkwhether wecan solvethemsuccessfully.therefore even if the incidents are reported they have to be ignored.
.
.
transient.
this category of incidents is real things but they can be automatically recovered.
these incidents tend to be caused by other operations factors.
when these operations factors are corrected eliminated the incidents can be automatically resolved.
therefore it should be low priority for engineers to look into these incidents.
for example as shown in example the test endtoenddatapushandpull was not executed during a period of time.
actually it was caused by another factor which is that the correspondingmachineshavenotbeencompletelyrebootedatthat time.
when the machines finished rebooting the test would run.
similarly inexample6 theincidentoccurred sincethe msfforest was still at the stage of deployment.
after the deployment finished the incident was automatically resolved accordingly.
example incident westcentralus gip2 test endtoenddatapushandpull didn t execute at least once during the last minutes.
explanation theargowasdownbecausethemachinestook longtimetoreboot ntdevtexaspasswordwaschanged .argo is up now and tests are running.
example incident red alert system level issue detected in msf forest.
explanation transient issue due to deployments.
there are no usersin thisforest andserver is notmember ofany dag.
.
.
false alarm.
the incidents belonging to this category are actually not real incidents.
they tend to be caused by the problems of monitors.
for example as shown in example this incident is a false alarm and the real cause lay in the monitor reportingtheincident.morespecifically thedatawasupdatedeverythree minutesbutthemonitorcheckedeveryoneminute andthusthe monitor reported the incident refresh time exceeded threshold .however the incident was actually due to the sensitive monitor improper threshold .
that is this category of incidents should not be investigated by engineers since they are not real incidents.
example incident ds002 mdm refresh time of delta store storageaccountname xtlcsuse tablename deltastore name envindex exceeded threshold.
explanation mdm was configured for this at a threshold of minute but the new code is at minutes.
we did not getenough3minuteoutagestotriggerthis sothisisafalse alarm.
.
rq2 percentage of incidental incidents we investigated the percentage of incidental incidents in online service systems whose results are shown in figure .
in this figure thevalueaboveeachbarrepresentsthepercentageofincidentalin cidentsamongalltheincidentsforthecorrespondingsubject.from thisfigure wefindthatthepercentageofincidentalincidentsfor all the studied systems is significant which ranges from .
to .
.
the average percentage of them is up to .
.
that is morethan halfof incidentsare actuallyincidental indicatingthat a great deal of engineers efforts were spent on these low priority incidentsduring historical diagnosis.therefore itisquite necessary tounderstand andthen prioritizeincidents foronline service systems.inparticular weinvestigatedwhy s9hasthesmallestrate and found that the number of monitors used for checking s9is the smallest whichmayleadtomanyincidentsthatcannotbereported and hard to capture complex interactions among components.
3we use to replace some words due to the company policy.
376how incidental are the incidents?
ase september virtual event australia .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 s12 s13 s14 s15 s16 s17 s18percentage of trivial incidents g5 g9 g16 g7 g9 g14 g18 g6 g11 g9 g1 g15 g10 g1 g12 g14 g7 g12 g8 g9 g14 g18 g6 g13 g1 g12 g14 g7 g12 g8 g9 g14 g18 g17 g1 g3 g2 g4 figure percentage of incidental incidents g23 g34 g33 g3 g38 g1 g19 g30 g40 g6 g6 g4 g5 g8 g2 g21 g36 g24 g33 g37 g30 g28 g33 g38 g10 g9 g4 g9 g11 g2 g19 g24 g31 g37 g28 g1 g14 g31 g24 g36 g32 g6 g11 g4 g6 g13 g2 g15 g41 g1 g17 g28 g37 g30 g29 g33 g6 g7 g4 g12 g11 g2 g22 g33 g24 g25 g31 g28 g1 g21 g34 g1 g20 g28 g35 g36 g34 g27 g39 g26 g28 g8 g4 g6 g12 g2 g16 g39 g37 g38 g34 g32 g28 g36 g1 g18 g36 g36 g34 g36 g7 g4 g7 g12 g2 figure3 percentageofeachcategoryofincidentalincidents we further investigated the percentage of each category of incidentalincidents whoseresultsareshowninfigure3.thenumbers inthisfigurerepresenttheaveragepercentageofthecorrespondingcategoryofincidentalincidentsonthe18studiedsystems.in thisfigure wefindthatthepercentagesof customererror and unable to reproduce are small while the percentage of transient is large.
the large percentage i.e.
.
for transient is asexpected since thereexist many interactionsamong various components in a large scale online service system.
when one componentis abnormal the componentsinteractingwith itare likely toreportincidentsthatarecausedbythefirstabnormalone which may lead to many transient incidents.
.
rq3 effort spent on incidental incidents we explored the effort spent on incidental incidents in terms of ttr timetoresolve .ttrreferstothetimeperiodfromincident creationtoincidentresolution.figure4showsthepercentageof ttrspentonincidentalincidentsforeachonlineservicesystem.
fromthisfigure wecanseethatthepercentageofttrspenton incidentalincidentsissignificant rangingfrom10.
to76.
.
theaveragepercentageisupto55.
.thatis thecostspenton incidentalincidentsisalmostthesameasthatspentonessential incidentsintermsofttr whichmaydelaytheresolutionofessential incidents and thus result in greater economic loss.
we also find that for out of18 studied systems the percentage of resolution time spent on incidental incidents is more than .
these results further motivate the necessity of understanding and prioritizing incidents for large scale online service systems.
wefurtherexploredthettrspentoneachcategoryofincidental incidents.
we first calculated the average ttr of each category53.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 s12 s13 s14 s15 s16 s17 s18percentage of ttm spent on trivial incidents g5 g11 g19 g9 g11 g16 g21 g8 g13 g11 g1 g17 g12 g1 g7 g7 g6 g1 g20 g18 g11 g16 g21 g1 g17 g16 g1 g14 g16 g9 g14 g10 g11 g16 g21 g8 g15 g1 g14 g16 g9 g14 g10 g11 g16 g21 g20 g1 g3 g2 g4 figure percentage of ttr spent on incidental incidents g gg g gg gggg by design customer error won t fix unable to reproduce transient false alarmaverage ttm g2 g9 g6 g8 g5 g7 g6 g1 g4 g4 g3 figure distribution of ttr ofincidentalincidentsforeachstudiedsystem andthenshowed the average ttr distribution across all the subjects in figure .
due to the policy of microsoft we hid the specific time and its unit.
in figure the violin plots show the density of average ttr at different values and the box plots show the median and interquartile ranges.
among all these categories of incidental incidents themedianofaveragettrfor unabletoreproduce isthelargest.
the reason could be that developers spent long time trying to reproduce these incidents but failed.
.
rq4 investigation of incident management practice the current incident management practice in microsoft is that engineersinvestigatethereportedincidentsbasedonthenumber of potentially impacted customers which is estimated accordingto the region cluster where the incidents occurred.
based on the number of potentially impacted customers there are five levels of incidentsinmicrosoft i.e.
where0referstothehighestlevel and4referstothelowestlevels.however inthecurrentpractice engineers may still investigate some incidental incidents first since these incidents have larger estimated impacts which is harmfulto incident management of systems.
therefore we explored thedistribution of incidents at each level to investigate whether the current practice is good enough.
table shows the distribution of incidents at each level.
in this table rows present the distribution of each category of incidental incidents at each level across all the studied systems.
rows 8and9summarizetheoveralldistributionofincidentalincidents and essential incidents at each level.
from this table we can see 377ase september virtual event australia j. chen et al.
table distribution of incidents at each level severity by design .
.
.
.
.
customer error .
.
.
.
.
won t fix .
.
.
.
.
unable to reproduce .
.
.
.
.
transient .
.
.
.
.
false alarm .
.
.
.
.
incidental incidents .
.
.
.
.
essential incidents .
.
.
.
.
that at each level there are both incidental incidents and essential incidents and their rates are relatively similar.
that is there are indeedmanyincidentalincidentsthatareassignedwithahigher levelthanactualessentialincidents.evenatthehighestlevel the percentageofincidentalincidents i.e.
.
islargerthanthat of essential incidents i.e.
.
.
that indicates many incidental incidents wereactually investigated preferentially causing the waste of engineers efforts.
therefore the current incident managementpracticeshouldbefurtherimproved andonepromising directionistoprioritizeincidentsbyidentifyingessentialincidents and incidental incidents.
incident prioritization duringtheincidentmanagementprocess ahugeamountoflabeled incident data is accumulated.
each incident is reported along with variousinformationsuchasthesymptomdescriptionandoccurring environment.
the abundance of data provides an opportunity to automaticallyidentifywhetheranincidentisincidentaloressential.
here we treat the problem of identifying incidental incidents as a supervised classification problem which can produce a probability ofanincidentbeingincidental.then allincidentscanbeprioritized based on the ascending order of the predicted probabilities.
in this way engineerscanhandletheincidentsbasedontheprioritiesand the incident management process could be improved.
here weproposeadeep learningbasedapproach called deepip toprioritizingincidentsbyidentifyingincidentalincidents.figure6 shows the overview of deepip.
we identify three types of features tohelppredictincidentalincidentsbasedontheguidelinesacquired fromtheempiricalstudy section4.
.also wedesignacnn based deepneuralnetworkandincorporateanattentionmechanismto effectively utilize these features for the identification of incidental incidents section .
.
here we draw support from deep learning sincethefeaturesweusedaremainlytextualinformation anddeep learningcan achievesemantic understandingof natural language descriptions and has been demonstrated to outperform traditional machine learning algorithms .
.
feature identification whenanincidentisreported itisprovidedwiththetextualdescription about the symptom i.e.
the title and summary of the incident report.
the textual description is the core information about an incident whichcandirectlyreflecttheincidenttosomedegree andthusitcouldbehelpfultodistinguishwhethertheincidentisessen tialorincidental.besides fromsection3andtheexistingstudy many incidents are actually correlated in a system.
for example anincidentinonecomponentofasystemcouldcauseaseriesofincidentsinothercomponentsofthesystem.also anincidentmay becontinuouslyreportedseveraltimes sincemonitorscheckthe statusofasystemregularly.
transient incidentsarealsorelatedto incident correlations.
for ease of presentation we call the incident to bepredicted target incident and theincidents correlated with it relevant incidents.
the relevant incidents are helpful to predict the target incident.
therefore we consider the textual descriptions of both the target incident and its relevant incidents in deepip.
astherelevantincidentstendtobereportedatclosetime with the target incident we identify them by setting atime window andcollectingtheincidentswhosereportingtimeiswithinthewindowandbeforethetimeofthetargetincident.insummary thefirsttype offeaturesusedindeepipisthetextualdescriptionsinboththetarget incident report and its relevant incident reports.
based on the observations in section most of incident reports includespecialterms suchasapinamesandcomponentnames andmanyofthemarehelpfultoidentifyincidentalincidents.for example asshowninexample4 br1 nns207 wasdeprecated and thus this incident did not need to resolve belonging to won t fix .here br1 nns207 isaspecialterm.asshowninexample msfforest isalsoaspecialterm.thisincidentis transient whichoccurred since msfforest wasstillat thestageof deployment.
therefore the second type of features used in deepip is special termsinthetargetincidentreport.actually specialtermshavebeenincludedintextualdescriptionsinincidentreports thefirsttypeof features .
however during the learning of textual descriptions the knowledgeofspecialtermsishardtolearnsincethefrequencies of special terms are much smaller than those of other words in textualdescriptions.
therefore toeffectivelylearn theknowledge ofspecialterms weextractspecialtermsasakindoffeaturesbased on their frequencies.
according to section the incident occurring environments are also related to the identification of incidental incidents.
for example theincidentsbelongingto falsealarm tendtobecaused by the problems of monitors and thus the monitor id reporting an incidentis helpfultodistinguish whethertheincident isessential or incidental.
therefore the third type of features used in deepip is the incident occurring environmental information.
in particular we consider the following environmental information monitor id incident occurring device and incident reporting type.
.
design of deep neural network toeffectivelyutilizethethreetypesoffeaturestoidentifyincidental incidents we design a deep neural network for deepip.
in the following we first present feature embedding in section .
.
thenintroduceattention basedtextencodinginsection4.
.
andfinally present incidental incident prediction in section .
.
.
.
.
feature embedding.
since the values of the second and third typesoffeaturesusedindeepipareafinitesetofdiscretevalues weconductfeatureembeddingforthem.onesimplemethodisto express all these discrete values as one hot vectors .
however in this way the dimension of an one hot vector may be very high and it ignores the possible relations among different feature values.
to overcome these problems we adopt representation learning to embed each feature value into a vector.
representation learning is able to embed a value to a fixed dimension vector and gradually 378how incidental are the incidents?
ase september virtual event australia g38 g59 g49 g55 g50 g51 g59 g64 g1 g37 g55 g63 g64 g60 g62 g69 g1 g44 g30 g42 g70 g27 g1 g1 g44 g47 g62 g53 g51 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g1 g1 g42 g71 g27 g1 g42 g51 g57 g51 g66 g47 g59 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g42 g72 g27 g1 g42 g51 g57 g51 g66 g47 g59 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g42 g73 g27 g1 g42 g51 g57 g51 g66 g47 g59 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g42 g74 g27 g1 g42 g51 g57 g51 g66 g47 g59 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g44 g51 g68 g65 g47 g57 g1 g34 g51 g63 g49 g62 g55 g61 g64 g55 g60 g59 g63 g44 g47 g62 g53 g51 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g35 g59 g66 g55 g62 g60 g59 g58 g51 g59 g64 g63 g39 g60 g59 g55 g64 g60 g62 g38 g50 g1 g1 g34 g51 g66 g55 g49 g51 g40 g47 g58 g51 g1 g38 g59 g49 g55 g50 g51 g59 g64 g44 g69 g61 g51 g1 g28 g42 g51 g57 g51 g66 g47 g59 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g1 g45 g51 g49 g64 g60 g62 g63 g44 g47 g62 g53 g51 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g1 g45 g51 g49 g64 g60 g62 g35 g59 g66 g55 g62 g60 g59 g58 g51 g59 g64 g1 g45 g51 g49 g64 g60 g62 g1 g35 g39 g60 g59 g55 g64 g60 g62 g38 g50 g31 g1 g45 g51 g49 g64 g60 g62 g34 g51 g66 g55 g49 g51 g40 g47 g58 g51 g27 g1 g45 g51 g49 g64 g60 g62 g38 g59 g49 g55 g50 g51 g59 g64 g44 g69 g61 g51 g27 g1 g45 g51 g49 g64 g60 g62 g28 g44 g30 g42 g70 g27 g6 g12 g17 g8 g18 g23 g15 g10 g1 g7 g12 g10 g23 g19 g21 g1 g42 g71 g27 g6 g12 g17 g8 g18 g23 g15 g10 g1 g7 g12 g10 g23 g19 g21 g42 g72 g27 g6 g12 g17 g8 g18 g23 g15 g10 g1 g7 g12 g10 g23 g19 g21 g42 g74 g27 g6 g12 g17 g8 g18 g23 g15 g10 g1 g7 g12 g10 g23 g19 g21 g44 g51 g68 g64 g1 g35 g59 g49 g60 g50 g55 g59 g53 g32 g64 g64 g51 g59 g64 g55 g60 g59 g46 g51 g55 g53 g54 g64 g46 g74 g46 g72 g46 g71 g46 g70 g1 g2 g23 g23 g12 g18 g23 g15 g19 g18 g29 g9 g8 g22 g12 g11 g1 g1 g5 g12 g16 g12 g25 g8 g18 g23 g1 g7 g12 g10 g23 g19 g21 g1 g3 g36 g55 g59 g47 g57 g1 g37 g55 g50 g50 g51 g59 g1 g43 g64 g47 g64 g51 g33 g57 g47 g63 g63 g55 g52 g55 g49 g47 g64 g55 g60 g59 g1 g41 g62 g60 g48 g47 g48 g55 g57 g55 g64 g55 g51 g63 g43 g61 g51 g49 g55 g47 g57 g1 g44 g51 g62 g58 g63 g43 g61 g51 g49 g55 g47 g57 g1 g44 g51 g62 g58 g1 g45 g51 g49 g64 g60 g62 g1 g41 g42 g51 g57 g51 g66 g47 g59 g64 g1 g38 g59 g49 g55 g50 g51 g59 g64 g63 g36 g51 g47 g64 g65 g62 g51 g1 g35 g58 g48 g51 g50 g50 g55 g59 g53 g44 g51 g68 g65 g47 g57 g1 g34 g51 g63 g49 g62 g55 g61 g64 g55 g60 g59 g1 g45 g51 g49 g64 g60 g62 g63 g33 g40 g40 g76 g48 g47 g63 g51 g50 g1 g39 g60 g50 g51 g57 g33 g60 g59 g66 g60 g57 g65 g64 g55 g60 g59 g47 g57 g1 g57 g47 g69 g51 g62 g1 g67 g55 g64 g54 g1 g58 g65 g57 g64 g55 g61 g57 g51 g1 g52 g55 g57 g64 g51 g62 g1 g67 g55 g50 g64 g54 g63 g1 g47 g59 g50 g1 g52 g51 g47 g64 g65 g62 g51 g1 g58 g47 g61 g63 g39 g47 g68 g1 g60 g66 g51 g62 g76 g64 g55 g58 g51 g1 g20 g19 g19 g16 g15 g18 g14 g75 g33 g60 g60 g57 g55 g59 g53 g6 g26 g22 g23 g12 g17 g15 g22 g4 g8 g16 g13 g24 g18 g10 g23 g15 g19 g18 g8 g18 g11 g15 g17 g20 g8 g10 g23 g12 g11 g4 g24 g16 g23 g15 g20 g16 g12 g28 g42 g47 g59 g56 g55 g59 g53 g1 g38 g59 g49 g55 g50 g51 g59 g64 g63 figure overview of deepip updates the vector during the training process.
in this way each of these features is embedded into a fixed dimension vector.
more specifically we denote the jthfeature vector in the second types of features as pj pj1 pj2 ... pjn and denote the kthfeature vectorinthethird typesoffeaturesas ek ek1 ek2 ... eks where nandsrefer to the pre defined fixed dimensions in representation learning for the second and third types of features respectively.
here we concatenate all the second types of feature vectors into a vectorp p1 p2 ... pt andconcatenateallthethirdtypesof feature vectors into a vector e e1 e2 ... er wheretis the numberofthesecondtypeoffeaturevectors risthenumberofthe third type of feature vectors and is the concatenation operator.
.
.
attention based text encoding.
after acquiring the target incidentanditsrelevantincidents foreachoftheseincidents deepip first applies standard text mining method to process the textual description including tokenization removing stop words and splitting .deepipthenembedseachwordinthetextualdescription ofanincidentreportintoavectorbyusingawordvector which ispre trained onhistoricalincident datausingthe fasttextalgorithm .
in this way the textual description of an incident is transformed into a matrix in which thenumber ofrows is equal to the number of words in the textual description.
then deepipencodesthematrixforanincidentintoavector.
weuseacnnbasedneural languagemodelratherthantraditional languagemodelstoconductencoding sincetheformerhasbeen demonstratedtobeabletoencodemorecomplexpatternsandfocusonword levelknowledgetoachievebetterperformance .in particular we adopt the simple single layer cnn based model forencoding sinceithasbeendemonstratedthatsuchamodelcan achieve better or comparable results and is easy for training andprediction .
an overview of the cnn based model is shown in the left figure of figure .
more specifically the cnn based model contains multiple 1d dimension convolution kernels andmax over timepooling.byusingmultipleconvolutionkernelswithseveraldifferentwidths severalfeaturemapsareproducedfromthe matrix wheremultipleconvolutionkernelswithdifferentwidths cancapturethecorrelationamongdifferentnumbersofadjacent words.
then the max over time pooling is applied to produce a vector for each feature map in order to extract the most important words.
finally all produced vectors are concatenated to generate avectorforanincident.inthisway thetextualdescriptionofthetargetincidentoreachoftherelevantincidentsisencodedintoavector.
wedenotethevectorofthetargetincidentas t t1 t2 ... tm andthevectorofthe ithrelevantincidentas ri ri1 ri2 ... rim wheremis the total number of convolution kernels.
since different relevant incidents may have different degrees ofcorrelationwiththetargetincident itisnecessaryfordeepipto learn these different degrees.
the relevant incident that has astronger correlation with the target incident should be assigned withalargerweight.here weintroduceanattentionmechanismto automatically learn theweights of relevant incidents.
actually it ispossiblethatalltheidentifiedrelevantincidentshavenocorrelation with the target incident and thus we also consider the correlation of the target incident with itself when learning weights so as to avoid assigning weights to the irrelevant incidents in this case.
for ease of description we call the vector of the target incident the0th relevantincident anddenote tasr0 r01 r02 ... r0m .theinput totheattentionmechanismisthevectorsofthetargetincidentand its relevant incidents.
the output is the attention based relevant vector integrated bythese vectors denoted as c c1 c2 ... cm whereci summationtext.1n j wj rji andwjisthelearnedweightofthe jth relevant incident.
the calculation of wjis shown as formula .
wj ef r0 rj summationtext.1n k 0ef r0 rk where f a b vttanh waa wbb aandbare two vectors andv wa andwbare parameters learned in the mlp .
.
.
predicting incidental incidents.
after acquiring the four vectors i.e.
t c p ande deepip first utilizes the four vectors to constructthefinalhiddenstate.here deepipconcatenatesthefour producedvectors t c p ande i.e.
t c p e.then deepip converts the final hidden state into a probability distribution of labels by the last layer i.e.
the softmax layer.
in particular deepip minimizesthelossbygradientdescentandgraduallyupdatesthe weight of the network.
the classification cross entropy loss is used fortraining.
inthisway theincidentalincidents canbepredicted andeachincident isassignedwitha probability ofbeingincidental.
at last all the incidents are prioritized based on the ascending order of the predicted probabilities.
the higher the incidents 379ase september virtual event australia j. chen et al.
are ranked the larger the probabilities that the incidents are essential incidents are.
engineers can then optimize their incident management process by handling the incidents ranked higher first.
moreover since our attention mechanism is able to learn the correlationdegreesofrelevantincidentswiththetargetincident deepip also recommends the most relevant incident together with the target incident which could facilitate engineers to understand the nature of the incident and diagnose it.
evaluation toinvestigatetheperformanceofdeepip weconductanextensive studyusingreal worldincidentdata.weusethe18industrialonline servicesystemsstudiedinsection3assubjects.inparticular we usetheincidentdatafromthefirstfourmonthsasthetrainingdata and the incident data from the last two months as the testing data.
in the study we address the following research questions rq5 howdoesdeepipperformforreal worldlarge scale online service systems?
rq6 does each type of features contribute to deepip?
.
evaluation design .
.
compared approaches.
since our work is the first to prioritizeincidentsbypredictingincidentalincidentsforonlineservice systems there is no direct comparative approach.
for traditional software systems there are several work on predicting severity of bug reports which can be adapted to prioritize incidents .
therefore we select two typical bug severity prediction approaches as the comparative approaches in this study.
both approaches are also based on textual descriptions of reports.
menzies and marcus which applies the standard text miningmethod toprocesstextualdescriptionsinreports andthenusestf idf termfrequencyandinversedocument frequency to transform the textual descriptions in a bugreporttoavector.finally theirapproachusestherule classifierbased onentropy andinformationgain topredict bug severity .
lamkanfi et al.
which applies the standard text mining method to process textual descriptions.
then this approach counts token frequency and uses the naive bayes algorithm to predict bug severity.
whenadaptingtheseapproaches theincidentseverityisincidentalandessential andalltheincidentsareprioritizedbasedon the ascendant order of the predicted probabilities that incidents areincidental whicharegivenbythecorrespondingapproach.for ease of presentation in this paper we call the two approaches rule andbayesrespectively based onthe way theyperform prediction.
actually we alsotriedtouse anotherstate of the artapproach to bug severity prediction as a comparative approach.
this approach calculates the similarities between a new bug report and historical bug reports using bm25f and lda .
however it cannot work well on incidental incident prediction since it is very timecostly.
itstime complexity is o mn wheremandnare thenumberofincidentsintrainingandtestingdata respectively.
for each instance in testing data it has to calculate the similarities with all incidents in training data thus its cost is very considerable duetothelargescaleoftheincidentdataforasysteminpractice.for example we applied it to the system with the smallest number of incidents in our study i.e.
s7 .
the time spent on prioritizing incidentsintestingdataisupto3 330seconds whilethetimerequiredbydeepip rule and bayesisonly2.54seconds .01seconds and .
seconds as shown in table .
for larger datasets the re quired time could be much longer.
therefore we did not include this approach as a comparative approach in our study.
in rq6 we evaluate the contribution of each type of features.
here we always keep the first type of features i.e.
textual descriptions since itis thecore informationaboutincidents.
we remove the second or third type of features and produce two variants ofdeepip denoted as deepip nopand deepip noe respectively.
we then compare the performance of the three versions.
.
.
implementations and parameters.
since the implementations of compared approaches are unavailable we re implemented them following descriptions in the papers.
for the involved machinelearning algorithms we adopted the implementations providedby scikit learn .
for deepip we implemented cnn based on apache mxnet a scalable deep learning framework.
for the compared approaches we used the same values of the parameters as given in the corresponding papers.
if a parameter s value is not explicitly given in the paper we used the default value provided by the adopted tools.
for the parameters in deepip we determined themthroughgridsearchandsetthesameparametersforallthe studiedsystems.morespecifically wesettheparametersasfollows thecnnusesthreesetsofconvolutionkernelswithdifferentwidths i.e.
each of which has kernels and the used epoch is .
the time window is set to be the time interval backwards 10incidentsfromthetargetincident.insection6 wediscussthe impact of the time window on deepip.
our study is conductedon windows server with core dual intel xeon e5 2690cpu .60ghz gb memory bit operating system and a singlenvidiateslak80gpuaccelerator.wecannotreleasethe incident data used in our study due to the policy of microsoft but we release the source code for these approaches in the project homepage .
.
metrics.
in this study we consider both effectiveness and efficiency to measure the performance of deepip.
we first measure theeffectivenessofdeepipinincidentprioritizationbyadopting the widely used aucmetric which measures the accuracy that essential incidents are ranked higher than incidental incidents in our context.
that is auc can be viewed as a metric based on pairwisecomparisonsbetweenclassificationsofthetwoclasses.followingexistingwork supposingtheoutputprobabilitiesof an approach on the essential incidents are x1 x2 ... xm and the output probabilities on the incidental incidents are y1 y2 ... yn the auc is computed as formula .
larger is better.
auc summationtext.1m i summationtext.1n j 11xi yj mn besides sincetheidentificationofincidentalincidentsisthecore ofdeepip wealsomeasuretheeffectivenessoftheclassification of incidental and essential incidents.
here we adopted the widelyusedprecision andrecallmetrics.precision is computed bytp tp fp whilerecalliscomputedbytp tp fn wheretp fp andfnrefer tothenumberoftruepositives tp falsepositives fp andfalse 380how incidental are the incidents?
ase september virtual event australia table performance comparison among the deepip rule and bayesapproaches subauc precision recall training time s predicting time s deepip rule bayes deepip rule bayes deepip rule bayes deepip rule bayes deepip rule bayes s1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s2 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s3 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s4 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s5 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s6 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s7 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s8 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s9 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s10 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s11 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s12 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s13 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s14 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s15 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s16 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s17 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s18 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
avg .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
negatives fn respectively.inparticular asdemonstratedinthe existing work we calculate the mean of all the classes for the two metrics.
larger is better.
for efficiency we record the time spent on the training process andthetimespentonprioritizingalltheincidentsintestingdata.
we call the former training time and the latter predicting time.
.
results and analysis .
.
overall effectiveness of deepip.
table shows the performancecomparisonamongthethreeapproaches i.e.
deepip rule andbayes where bold values represent the best results among the three approaches.
from columns in table deepip outperforms the two compared approaches i.e.
ruleandbayes o n all the studied systems in terms of auc showing the significant advantageofdeepipforincidentprioritization.inparticular the averageaucofdeepipis0.
whiletheothertwoapproaches are just .
and .
respectively.
also the range of auc for deepip is from .
to .
demonstrating that deepip is able to achieve stably good prioritization effectiveness.
furthermore in terms ofprecision andrecallshown in columns in table deepipalsoperformsmuchbetterthan ruleandbayesonallthe subjects.
the average precision andrecallof deepip are .
and .
while those of ruleare .
and .
and those of bayes are0.584and0.
.theseresultsalsoreflectthattheadaptedapproaches fromtraditional bug severityprediction arenot suitable to solvethe problemof incidentsof onlineservice systemsdue to theirdifferences.wefurtheranalyzethereasonisthat incidents aremainlyautomaticallyreportedbymonitorsandhavesignificanttimeandlocationcorrelations whilebugreportsaremanually reportedbyusersandthusthecorrelationsarenotassignificantas in incident reports.
therefore existing approaches for bug reports ignoring correlations cannot perform well for incidents.
that is it isquitenecessarytoproposenewapproachesbyconsideringthe characteristicsofincidents.forincidentprioritization deepipisthe first attempt to solve this problem and our results have shown that it is a promising approach.
columns11 16intable2showtheefficiencycomparisonamong deepip rule and bayes.
for the offlinetraining time bayesspends the shortest time i.e.
.
hours while our approach deepipspends the longest time i.e.
.
hours on average.
however the training is offline and thus several hours are acceptable in practice.
for the onlinepredicting time ruleis the most efficient one i.e.
.18seconds while bayesspendsthelongesttime i.e.
.
seconds and deepip is the medium i.e.
.
seconds on average.
actually theonlinepredictingtimeofallthethreeapproachesis short and eventhe timespent onpredicting oneincident isnegligible.
therefore our approach deepip is practical due to the short online predicting time and acceptable offline training time.
.
.
contributions of different types of features.
figure shows the comparison among deepip deepip nop and deepip noe where the y axis represents the average metric value of the subjects.
from the left figure deepip performs better than both deepip nop anddeepip noeinallthemetrics.wefurtherconductedawilcoxon signed ranktest atthesignificantlevelof0.05betweendeepip anddeepip nop deepip noetoinvestigatewhethertheformersignificantly outperforms the latter two.
from the right of figure we find that all the p values are much smaller than .
demonstratingthatdeepipindeedsignificantlyoutperformsdeepip nop and deepip noein terms of auc precision and recall.
the results indicate that both special term features and incident occurring environmentfeaturescansignificantlyimprovetheeffectivenessof deepip confirming the contributions of these features.
discussion communicationwithengineersinmicrosoft.
wehavereported ourresultstotheresponsibleengineersinmicrosoftandcommunicated with them by emails.
they expressed their troubles on incidental incidents and also experienced and largely appreciated 381ase september virtual event australia j. chen et al.
g2 g8 g10 g4 g12 g19 g12 g11 g1 g15 g8 g7 g11 g6 g5 g21 g14 g3 g11 g9 g1 g16 g6 g15 g16 g1 g13 g21 g18 g3 g10 g17 g6 g20 g2 g10 g3 g23 g4 g14 g14 g19 g9 g6 g7 g22 g24 g21 g24 g1 g4 g14 g14 g19 g9 g6 g7 g17 g18 g11 g23 g1 g25 g24 g25 g25 g27 g26 g4 g14 g14 g19 g9 g6 g7 g22 g24 g21 g24 g1 g4 g14 g14 g19 g9 g6 g7 g17 g18 g5 g23 g1 g25 g24 g25 g25 g25 g30 g7 g20 g14 g13 g15 g21 g15 g18 g17 g23 g4 g14 g14 g19 g9 g6 g7 g22 g24 g21 g24 g1 g4 g14 g14 g19 g9 g6 g7 g17 g18 g11 g23 g1 g25 g24 g25 g25 g27 g29 g4 g14 g14 g19 g9 g6 g7 g22 g24 g21 g24 g1 g4 g14 g14 g19 g9 g6 g7 g17 g18 g5 g23 g1 g25 g24 g25 g25 g25 g28 g8 g14 g13 g12 g16 g16 g23 g4 g14 g14 g19 g9 g6 g7 g22 g24 g21 g24 g1 g4 g14 g14 g19 g9 g6 g7 g17 g18 g11 g23 g1 g25 g24 g25 g25 g29 g25 g4 g14 g14 g19 g9 g6 g7 g22 g24 g21 g24 g1 g4 g14 g14 g19 g9 g6 g7 g17 g18 g5 g23 g1 g25 g24 g25 g25 g26 g250.
.
.
.
.
auc precision recallaverage metric valuedeeptip deeptip nov deeptip noe g3 g8 g8 g11 g5 g6 g3 g8 g8 g11 g5 g6 g1 g9 g10 g7 g2 g3 g8 g8 g11 g5 g6 g1 g9 g10 g4 g2 g1 g6 g6 g9 g3 g4 g1 g6 g6 g9 g3 g4 g1 g6 g6 g9 g3 g4 g1 g6 g6 g9 g3 g4 g1 g6 g6 g9 g3 g4 g1 g6 g6 g9 g3 g4 g1 g6 g6 g9 g3 g4 g7 g8 g5 g1 g6 g6 g9 g3 g4 g7 g8 g2 g1 g6 g6 g9 g3 g4 g7 g8 g5 g1 g6 g6 g9 g3 g4 g7 g8 g2 g1 g6 g6 g9 g3 g4 g7 g8 g5 g1 g6 g6 g9 g3 g4 g7 g8 g2 figure contribution of each type of features the functionality i.e.
prioritizing incidents by identifying incidentalincidents providedbyus.forexample oneengineercomplained that she he spent too much time on investigating false alarm incidents and noticed the real issue much later.
another engineer also pointedoutthatthecurrenticmsystemisoverloadedandhasmany incidental incidents.
in particular they believed that the current performanceofdeepipisusefulandgaveussomesuggestionsto make our tool more user friendly e.g.
it would be better if there is a prioritized view of incidents in the icm system.
generality of deepip.
although deepip is proposed and evaluated for incidents of online service systems the framework of deepip is actually general.
to investigate the generality of deepip weappliedittopredicttheseverityoftraditionalbugreports.in particular wecompareddeepipwiththestate of the artbugseverity prediction approach introduced in section .
.
.
here we used the same mozilladataset released by the compared work and used the results reported in their paper the precision of .
and therecallof0.
.byapplyingdeepiptothesamedataset deepip achievestheprecisionof0.610andtherecallof0.
improvingthe state of the artapproachby41.
and10.
respectively.there sultconfirmsthegeneralityofdeepip.thereasonwhydeepipcan performwellforbugreportsisthat itsattentionmechanismcan determine whether there are relevant bugs for the target bug and it can understand semantics of textual descriptions outperforming traditionaltext similarity based approaches.wealso releasedthe mozilla dataset on our project webpage.
impactofthesettingoftimewindow .weinvestigatedtheimpact of the time window on deepip.
the default setting of the time windowindeepipis10.wealsoexperimenteddifferentwindow sizes such as and .
the results show that the default setting performsthebestingeneral.thesmallsettings and5 perform relatively worse than the large settings and indicating the necessity of considering a relatively large number of relevant in cidents of a target incident.
in addition we conducted wilcoxon signed ranktestatthesignificantlevelof0.05betweenthesettings of10and0toinvestigatewhetherconsideringrelevantincidents cansignificantlyimprovetheeffectivenessofdeepipintermsof auc precision and recall.
the resulting p values are all less than .
confirming the contribution of relevant incidents in deepip.
threats to validity.
the internalthreat to validity mainly lies in theimplementationsofourapproachandthecomparedapproaches.
to reduce this threat two authors have carefully checked the code.for the various machine learning and information retrieval algorithmsusedinourwork weadoptedtheimplementationsprovided by mature tools which has been presented in section .
.
.
theexternalthreats to validity mainly lie in the subjects and comparedapproaches.inthiswork westudied18real worldonline service systems in microsoft.
all the used data are real in indus try.
to our best knowledge this is the first large scale study inthis area.
even so the used subjects may not represent systemsin other companies.
in the future we will investigate more systemsfromdifferentcompanies.sincetheframeworkofdeepipis general itiseasytoapplyittoothercompaniesaslongasthecom panieshavehistoricaldatafortraining.also somespecificfeaturesmaybedifferentfordifferentcompanies.inparticular wehavecon ductedastudyabovebyapplyingdeepiptoanopen source mozilla dataset demonstrating the generality of deepip.
for the compared approaches we selected two typical bug severity prediction approachesandalsodiscussedthestate of the artapproach in section5.
.
.however theymaynotrepresentotherapproaches.
in the future we will consider more approaches for comparison.
theconstruct threatstovaliditymainlylieintheusedmetrics used parameters and labeled data.
to evaluate the performance of deepip weusedwidely usedauc precision andrecallformeasuring effectiveness and used training time and predicting timefor measuring efficiency.
in the future we will use more metrics to more sufficiently measure the performance of these approaches.
fortheparametersinthecomparedapproaches wesetthemusingthevaluesgiveninthepapersorprovidedbytheusedmaturetools.
for theparameters indeepip we setthem viagrid search whose specific settings have been presented in section .
.
.
also we discussedtheimpactofthemainparameter timewindowsize above.
inthefuture wewillfurtherinvestigatetheimpactofotherparameters.theincidentdatawerelabeledmanuallybyengineers and theremaybenoise.however theseengineershaverichexperiences and domain knowledge thus this threat may not be serious.
related work incident management .
the most related work to ours is incident management.
for example lou et al.
presented an experience report on applying software analytics to incident management of online service systems including incident diagnosisand mitigation.
chen et al.
conducted an extensive study to investigateincidenttriageforonlineservicesystemsandevaluatedtheperformanceoftraditionalsoftwarebugtriagetechniquesintheincident triagecontext.someworkaimstoassociateanewincident with a previous known incident .
for example duan and babu proposedanapproachtoimproving theaccuracybased on active learning which maximizes the benefits gained from new unknowninstancestofacilitatemanuallabelingefforts.different fromthem ourworkaimstocharacterizeincidentsofonlineservice systems and then prioritize incidents by identifying incidental incidents to improve the incident management process.
bug report management .
there are many common characteristicsbetweenincidentreportsofonlineservicesystemsandbug reports of traditional software systems.
over the years there have been many empirical studies on bug reports and bug fixing performance .forexample lietal.
manuallycollected 382how incidental are the incidents?
ase september virtual event australia 709bugsfrommozillaandapachewebserver andanalyzedthe bugcharacteristics.mockusetal.
proposedqualitymetrics e.g.
the percentage of defective files to understand software maintenance efforts quantitatively.
guo et al.
performed an empirical studytocharacterizefactorsthatdeterminewhichbugsgetfixed inwindows .some researchers alsostudied defectlife cycles bugdistributions bugtriage andbug reportbased fault localization .
furthermore there are also many papers on automatic assessment of the severity and priority of bug reports .
for example menzies and marcus p r o posed a tool named severis which utilized standard information retrieval techniques and a rule learner to infer the connections betweenthemostinformativetokensinabugreportandtheseverity level.
tian et al.
proposed a machine learning based approach thatcanrecommendaprioritylevelbasedoninformationavailableinbugreports.differentfromthem weperformanempiricalstudy ofincidents usingindustrialdataandproposeanapproachto prioritizingincidents.althoughincidentandbugreportshavemuch in common they havesome differentcharacteristics.
forexample bugreportsareoftenreportedandtreatedindividually whilemany incident reports tend to be correlated.
one major reason is thatan incident can lead to a series of other incidents which can be detected by different monitors.
empirical analysis of failures of cloud systems .
over the years therehavebeenmanyempiricalstudiesonthecharacteristicsoffailuresofdatacentersandcloudsystems .for example schroederandgibson describedalarge scalestudy offailuresinhigh performancecomputingsystems.zhouetal.
performed an empirical study on quality issues of a real world big data platform.
researchers also investigated the root causes of the systemfailures .forexample gray foundthatadministrator errors were responsible for of system failures in high end mainframes.
yin et al.
studied real world misconfigurations and found that a large portion of misconfigurations can cause hard to diagnose failures.
different from them we focus on incidents rather than failures.
our study shows that not all incidents can lead to system failures.
many incidents i.e.
incidentalincidents are not important and will not get fixed with a high priority.
in this work we characterize the incidental incidents and proposeadeep learningbasedapproachtoprioritizingincidents.
ourworkallowsengineerstomoreefficientlyspendtheirefforts on incident management.
conclusion tobetterunderstandreal worldincidents weconductalarge scale empirical study on incidents of online service systems in microsoft.wefindthatalargenumberofincidentsarereportedwithin ashortperiod butmanyincidentsareincidental.ourqualitative and quantitativeanalysis showthat onaverage morethan halfof incidents are incidental and the percentage of maintenance timespent on them is up to .
.
therefore it is quite necessary to prioritize incidents by identifying incidental incidents in advance soastooptimizetheincidentmanagementprocess.towardsthis direction weproposedeepip adeeplearningbasedapproachto prioritizing incidents by predicting the probabilities of incidents beingincidental.ourexperimentalresultsshowthatdeepipcanachieve the auc value of .
on average with acceptable cost whichsignificantlyoutperformsallthecomparedapproaches.in the future we will further improve deepip to predict multiplecategories of incidents instead of directly identifying incidental incidents and essential incidents.