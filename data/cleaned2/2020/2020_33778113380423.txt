trader trace divergence analysis and embedding regulation for debugging recurrent neural networks guanhong tao taog purdue.edu purdue universityshiqing ma shiqing.ma rutgers.edu rutgers universityyingqi liu liu1751 purdue.edu purdue university qiuling xu xu1230 purdue.edu purdue universityxiangyu zhang xyzhang cs.purdue.edu purdue university abstract recurrent neural networks rnn can deal with textual input with various length and hence have a lot of applications in software systems and software engineering applications.
rnns depend on word embeddings that are usually pre trained by third parties to encode textual inputs to numerical values.
it is well known that problematic word embeddings can lead to low model accuracy.
in this paper we propose a new technique to automatically diagnose how problematic embeddings impact model performance by comparing model execution traces from correctly and incorrectly executed samples.
we then leverage the diagnosis results as guidance to harden repair the embeddings.
our experiments show that trader can consistently and effectively improve accuracy for real world models and datasets by .
on average which represents substantial improvement in the literature of rnn models.
acm reference format guanhong tao shiqing ma yingqi liu qiuling xu and xiangyu zhang.
.
trader trace divergence analysis and embedding regulation for debugging recurrent neural networks.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
introduction deep learning dl models are becoming an integral part of many modern computing systems.
for example a self driving car system often makes use of dl models to recognize objects and even maneuver vehicles online advertisement leverages dl models to identify potential customers and deliver the corresponding ads latest mobile wearable devices use various dl techniques to authenticate users detect and monitor user behaviors.
engineering dl models is becoming a critical step of engineering such intelligent computing systems.
among the various kinds of dl models recurrent neural networks rnns are particularly useful in software related applications as they are designed to deal with textual inputs of arbitrary length and inputs in sequence.
note that many software artifacts permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
in the form of text or sequences.
for example a program can be considered as a piece of text in some special language program comments are essentially texts in natural language with specific semantics and execution traces are a sequence of values of arbitrary length.
as such rnn models find their way to many software engineering applications.
wang et al.
leveraged rnns to construct semantic program embeddings which are a way to encode textual programs to numerical values.
the embeddings were further employed in a searchbased program repair system to correct errors in programs .
henkel et al.
used a dl model called glove to construct word embeddings for abstract symbolic traces of programs.
the learned embeddings were used to find bugs which were further confirmed by traditional static analysis.
panichella et al.
employed a model to assess the polarity of app reviews which can provide developers with informative feedback to improve application quality and facilitate software maintenance.
du et al.
modeled rnn as an abstract state transition system for test generation and adversarial sample detection.
tian et al.
proposed a testing tool for automatically detecting erroneous behaviors of dnn driven vehicles with cnn or rnn as the internal model.
rnn models are also widely used in processing textual software artifacts such as code comments developer commits and app reviews .
dl model reliability is hence a critical part of the overall reliability of many software systems.
just like software dl models may have undesirable behaviors such as exceptionally low test accuracy.
they are called model bugs in the literature .
such model bugs may lead to undesirable system wide behaviors.
for example sentistrength is a state of the art tool that can predict sentiment of developer comments.
such sentiment information is further used to extract problematic api features .
however a recent study showed that its underlying model achieved recall and precision lower than on negative sentences.
since negative sentences are critical indicators for problematic apis the low model accuracy will cause many problems for the downstream analyses.
different from normal programs dl models are difficult to debug due to their black box unexplainable nature .
most existing works focused on providing more data to improve model performance .generative adversarial networks gans are also widely used to generate additional data for further training .
however these methods can hardly be considered as debugging techniques as they lack the diagnosis step that identifies the root cause.
mode is a recent model debugging technique for ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea guanhong tao shiqing ma yingqi liu qiuling xu and xiangyu zhang convolutional neural networks cnns that often deal with fixed size inputs such as images.
it leverages differential analysis to identify faulty neurons and selects additional training inputs to correct such neurons behavior.
however mode cannot handle rnns.
in this paper we focus on debugging rnn models for textual inputs e.g.
sentiment analysis for developer comments especially for a type of bugs in which problematic word embeddings lead to suboptimal model accuracy.
many studies have shown that word embeddgings are critical for rnn model accuracy.
for those textual tasks input words tokens are always converted to embeddings first before training testing.
although embeddings seem external to the model the model itself cannot be studied debugged separately without considering embeddings.
inspired by software debugging we view an rnn model as a program with very specific semantics.
therefore the traditional trace analysis in software debugging can be adopted to debug rnn models as long as the specific semantics are properly modeled.
in particular given a buggy model our technique performs trace divergence analysis that identifies the problematic internal model state vector dimensions responsible for the misclassification called the faulty state dimensions.
intuitively the state vectors are a number of buffers that are updated after the model processes each word or input element.
a dimension is essentially a buffer element at a specific index which semantically encodes some feature of the current input word and its preceding context.
hence the faulty dimensions represent the features of words and their contexts that the model has confusing buggy behavior.
then an embedding regulation algorithm is proposed to mitigate the problem by hardening the model behaviors for those dimensions.
intuitively it applies small mutations to those dimensions and then forces the model to learn to disambiguate the perturbations.
the more the model can disambiguate the better accuracy it can achieve as it is less confused on those dimensions .
our contributions are summarized in the following.
we identify buggy behaviors of rnn models through a trace divergence analysis and locate faulty state dimensions responsible for misclassification.
we propose an rnn repair technique a new training procedure that freezes model parameters and regulates word embeddings according to observed trace divergences.
we develop a prototype trader tra cedivergence analysis and embedding regulation .
experimental evaluations are conducted on five public datasets three word embeddings and three model structures with a total of models.
trader can consistently and effectively improve the performance by .
on average substantially outperforming a state of the art embedding regulation technique based on four regularization strategies which improves model accuracy by .
on average.
note that due to the need of dealing with inputs of arbitrary length it is challenging to improve rnn accuracy in general.
most reported improvement in the literature not using debugging techniques but rather new model architecture or new optimizers range from .
.
with a median of .
.
our implementation datasets configurations and model checkpoints are publicly available at .
c x0h0 c xtht c x1h1 c xtht xt tanh tanh ht a unrolled rnn structure c x0h0 c xtht c x1h1 c xtht tanhtanh ht 1ct ft it u1d5bc u1d5cdot htct ht xt b lstm cell figure architecture of recurrent neural networks.
a an unrolled representation of rnn architecture.
b the internal structure of long short term memory networks.
background .
recurrent neural networks recurrent neural networks rnns are a family of neural networks designed to tackle problems with sequential inputs.
different from traditional neural networks that require fixed length inputs rnns can handle sequential inputs of arbitrary length.
that is input is received continuously through many steps via a loop structure as shown in figure 1a.
the sequential inputs are fed into the rnn model one by one.
at each time step the model leverages the previous hidden value and the current input so as to update the hidden value.
for specific tasks the prediction outputs are obtained by adding an output layer using the hidden value such as in machine translation speech recognition and image caption generation .
more specifically xt blue circle is the input at step t andht green circle is the hidden value.
intuitively htencodes the history context in the previous t steps.
at each time step an input xtand the previous hidden value ht 1are fed into the rnn cell yellow rectangle and the hidden value for the next step ht is computed.
a vanilla rnn cell contains a regular feed forward neural network with layers of neurons.
we can obtain the hidden value htat step tusing the following formula.
ht wh bh where is the activation function.
whdenotes the weight matrix andbhthe bias.
the operation concatenates two vectors.
for a specific task e.g.
sentiment analysis the final prediction is computed using the last hidden value hn prediction w hn b where wandbare the weight matrix and bias of the output layer respectively and ndenotes the length of an input sequence which can be arbitrarily large.
the output prediction is normally a vector of logits and the final predicted class can be obtained by applying function arg max on the output prediction vector.
vanilla rnns are not able to remember temporal context of long sequences .
in order to deal with long term dependencies a new type of rnn model called long short term memory lstm networks was proposed by hochreiter et al.
.
lstms inherit the same loop structure to deal with arbitrary input length.
for the cell structure instead of using regular feed forward neural networks lstms are designed with multiple gates to control how much information from the previous and current contexts is being passed on to later computation.
figure 1b illustrates the internal 987trader trace divergence analysis and embedding regulation for debugging recurrent neural networks icse may seoul republic of korea structure of an lstm cell.
the leftmost two inputs are hidden values from the previous step where the top ct 1is called cell state and the bottom ht 1is called hidden state.
cell state encodes the contextual information through the entire sequence a kind of long term memory .
hidden state is similar to the hidden state in a vanilla rnn representing recent historic information.
an lstm cell can be formalized as follows.
ft wf bf it wi bi ot wo bo ct tanh wc bc ct ft ct it ct ht ot tanh ct where operators and denote matrix multiplication and elementwise vector multiplication respectively andtanh denote sigmoid and tanh activation functions that crop normalize activation values ftdenotes the forget gate that controls how much information from previous steps needs to be forgotten remembered it acts as the input gate that determines how information needs to be added to cell state otis the output gate that decides the degree of output information being accumulated to hidden state cell state ctis updated according to the preceding cell state ct 1and the current context ct and finally the hidden state htis updated based on current cell state ctand output ot.
.
word embeddings in natural language processing nlp tasks the inputs are normally texts containing various numbers of words.
existing machine learning ml models e.g.
rnns require numerical inputs so as to do mathematical computation.
to integrate nlp tasks into ml models word embeddings are adopted to address this issue.
that is each word is represented as a numerical vector.
for instance in the sentence i like movies word i is represented as word like as and word movies as .
this type of word embeddings is called one hot embeddings where the length of each embedding is the size of the dictionary and only one dimension has value .
it is straightforward to encode words into one hot embeddings.
such word embeddings however are too sparse for storage and computation.
a more concise way of representing words is to leverage all the dimensions of word embeddings with continuous values which is called distributed representations.
for instance word i will be represented as word like as and word movies as .
researchers have been exploring different approaches to achieve such a dense form of word embeddings.
a typical approach is to train a neural network model with a large corpus e.g.
wikipedia pages .
the task of the neural network is to predict the center word given a sequence of usually words in a sentence.
the learned weight of the neural network is regarded as word embeddings .
such learned word embeddings have a nice property that words with similar meanings have small embedding distances e.g.
euclidean distance between two word embeddings .
this allows the model to generalize.
intuitively even though a model may not have seen some words sentences during error original regulated errors errors correct mistake mistake difference difference correctgreat original regulated good good well well little much much experiencereinstall original regulated reinstalling reinstalling uninstall install refresh uninstall install refresh allocate original regulated generate resources enable generate savings necessary resources enableregex original regulated getpost webaddress autowired hashset appbarlayout nativesystem creates jodatimefigure nearest neighbors of words according to their embeddings.
the top row denotes the target words and the following rows are their nearest words measured by cosine similarity.
column original denotes words using glove word embeddings and column regulated denotes word embeddings after regulation.
training it can still perform prediction based on their embedding neighbors that appear during training.
distributed representations of word embeddings are widely used in nlp tasks as well as software engineering se tasks .
according to many studies word embeddings are the dominating factor in model accuracy in rnn applications.
for example in sentiment analysis according to schnabel et al.
the same ml model using different word embeddings as features can have divergent prediction accuracy ranging from .
to .
indicating its importance.
figure demonstrates examples of words represented using the glove word embeddings .
the top row denotes the target words and the following rows are the nearest neighbors of target words measured by cosine similarity.
column original lists the nearest words based on the original glove word embeddings while column regulated are based on our regulated word embeddings.
it can be observed that for target word error word correct is the second nearest word using glove while it is moved down the list after embedding regulation.
word little is the third nearest word for great using glove and it is not in the top list after regulation.
it is similar for the case reinstall .
one can easily tell that models generalize better with the regulated embeddings.
.
model debugging just like software inevitably contains bugs and software debugging is a key step in software development dl models may have undesirable behaviors called model bugs .
model debugging is becoming an essential step in intelligent software engineering.
model bugs are different from traditional coding bugs.
they are misconducts in the model engineering process such as biased training data and problematic model structure which lead to undesirable consequences such as low model accuracy and vulnerabilities to adversarial sample attacks in which normal inputs are mutated e.g.
by perturbations not human perceptible to induce mis classification.
in our context model debugging is a procedure to study model internals to understand the root cause of mis classification and then conduct counter measure to fix the root cause.
model debugging is difficult as dl models are not interpretable .
there are techniques that use data augmentation e.g.
image reflection cropping and rotations for cnn models to provide additional data to improve model performance .
another method is to use gans to generate additional training data .
however these methods are not feedback driven meaning that they do not intend to understand what causes the low accuracy before trying to fix the problem which limits their effectiveness.
988icse may seoul republic of korea guanhong tao shiqing ma yingqi liu qiuling xu and xiangyu zhang def count data output for i in range len data embed embedding data map to integer if embed and embed output return output def main data print count data def rnn text outputs hidden zeros size for i in range len text map to word embedding embed embedding text input concatenate hidden embed hidden matmul input w h b h output matmul hidden w out b out outputs .append output return outputs figure comparison between code snippets of a simple counting program and an rnn model.
the left code snippet shows a simple program for counting the number of data points within range .
the right code snippet gives a simplified rnn model for predicting the label of an input sentence.
mode is a recent feed back driven technique for cnns.
it analyzes model internals to identify faulty neurons and then selects additional training inputs to correct such neuron behaviors.
these existing approaches including mode are mostly designed to improve image related models e.g.
handwritten digit recognition and object classification .
for text related models e.g.
sentiment analysis they are hardly applicable.
for example using gans to generate text inputs often suffers from low quality and lack of diversity .
according to wang et al.
most generated texts have fewer than words whereas sentences in real world training datasets have more than a few hundreds words.
in this paper we focus on debugging text input oriented rnn models that have a lot of software engineering applications .
while there are many possible kinds of bugs for these models such as biased training inputs sub optimal model structures and incorrect hyper parameter settings.
we focus onproblematic word embeddings as the literature has indicated that embeddings are critical for rnn model accuracy .
in our view an rnn model is essentially a program with special semantics.
therefore our overarching idea is to adapt existing software debugging techniques e.g.
especially execution trace analysis to debug rnn models by properly modeling rnn models special semantics.
next we will use a program example and an rnn example side by side to intuitively illustrate our idea.
the left part of figure shows a simple program for counting the number of data points within range .
the functionality of method embedding at line is to convert string values to numerical values and then map them to discrete values.
the mapping can be implemented as a rounding operation where values are converted to their closest discrete numbers.
for instance value .
becomes while .
becomes .
when the developer executes this piece of code value is printed as the output which is incorrect.
to locate the bug the developer prints out the value of variable output at each iteration of the loop and obtains the value trace of .
for this simple program the developer has the oracle that the value trace of variable output should be .
by comparing the actual trace to the oracle the developer can easily locate the trace diverged at the fourth iteration and finally identify the buggy implementation of method embedding .
interestingly rnns have a very similar loop structure as shown on the right of figure .
method embedding at line maps each word to its corresponding embedding.
method concatenate at also jodatime makes calculations with time much simpleroracle trace buggy trace also jodatime makes calculations with time much simpleroracle trace buggy trace trace divergencepositive neutralfigure the trace of a sample text from stack overflow dataset predicted by a real world lstm model .
the blue line denotes the oracle trace with correct prediction of positive sentiment.
the green line denotes the buggy trace produced by the lstm model with incorrect prediction of neutral sentiment.
line concatenates two vectors and matmul is the matrix multiplication method.
analogous to the simple program on the left we can use the same trace divergence analysis to inspect the state at each iteration if undesired behaviors happen.
figure demonstrates a sample text from the stack overflow dataset also jodatime1makes calculations with time much simpler .
it is labeled as having positive sentiment.
an lstm model however predicts a neutral sentiment.
we record the state values at each iteration i.e.
after each word and also query the oracle for the same step.
the green line in figure shows the trace of the lstm model while the blue line is the trace acquired from the oracle.
as we will discuss in section .
having an oracle model that always produces the correct intermediate model states is infeasible just like having a correct reference program for regular program debugging is infeasible in general.
in the literature various techniques were proposed to approximate the reference e.g.
using a similar but correct execution as in delta debugging .
similarly in our context of rnn model debugging we train a model from validation data set to approximate the reference model see section .
.
from figure it can be observed that at the step with word much the two traces start to diverge which finally leads to different output labels.
we hence further inspect the state differences at the divergence step.
figure presents the comparison.
in the figure the input sentence 2 is in the middle.
the blue arrow to b denotes the model state after the word much .
here a model state is the concatenation of the input cell state and hidden state vectors followed by the output denotes neutral sentiment and denotes 1a data and time library for java.
989trader trace divergence analysis and embedding regulation for debugging recurrent neural networks icse may seoul republic of korea also jodatime makes calculations with time much simpler.create the number of buttons that you want with different button id.
databases are much better at handling data than java.rnn oracle x 3a b c d oraclernn figure analysis of an example text shown in 2 .
vectors a d denote the model states i.e.
at the step of the underlined words in sentences 1 3 followed by the prediction result at the end gray background for neutral and for positive.
a and b are states generated by a buggy rnn model.
c and d are states from the oracle.
a is a state closest to b produced by a buggy rnn model whereas d is a state closest to c by the oracle.
2 is a test sentence 1 is from the training set and 3 from the validation set.
positive .
as sentence 2 is not in the training data set the model has to generalize based on what it has seen during training.
further inspection shows that sentence 1 is in the training set and its state a after word different is very close to b and the corresponding output is neutral which explains why the model predicts neutral sentiment.
below sentence 2 we show the state after word much by the oracle model which approximates model output when given the concatenation of the input cell state and hidden state vectors for all the correctly classified sentences in the validation set.
its construction will be discussed in section .
.
when we provide the concatenated vector of sentence 2 to the oracle model it predicts positive as shown in c .
this is because c is close to state d after word better in sentence 3 from the validation set which has the positive sentiment.
the state vector values heavily depend on the word embeddings.
if we consider c denotes the state derived from the ideal embeddings the root cause lies in that the current problematic embeddings lead to the state divergence of b and c which are highlighted by the red and blue rectangles.
there may exist multiple state divergence dimensions we only highlight one for demonstration.
as the oracle has the knowledge of d this is the reason it produces different prediction in contrast with the buggy rnn model.
the essence of our technique is hence to harden the word embeddings to minimize such differences.
note that although we use a single input sentence to intuitively explain the idea our technique essentially has to minimize such differences for all misclassified sentences in the training set to achieve the effect of improving overall accuracy.
design given an rnn model to debug we leverage the validation dataset to inspect the problematic behaviors.
figure illustrates the overall design of our approach.
data in the validation set can be first processed by the model to identify the correctly classified and misclassified samples.
we consider that traces of the correctly classified samples to some extent denote the desired behaviors of the model while traces of the misclassified samples represent undesired behaviors.
a trace divergence analysis is then performed on the traces from these two sets of samples.
that is we utilize the traces to input textsc xtht pre trained modelstrace divergence analysisdefective dimension identificationembedding regulationmodel retrainingfigure overview of trader.
construct two models called the oracle machine and the buggy machine which approximate the distributions of state values from the correctly classified samples and from misclassified samples respectively.
these two machines are the reference models for identifying diverged steps section .
.
we aggregate all the diverged steps of misclassified samples in the validation dataset and inspect the difference of their state vectors to identify the critical dimensions which have large aggregated differences.
we consider them the faulty state dimensions.
intuitively they denote the sub space that the model gets confused .
in the fixing step we target on further training these faulty dimensions to alleviate the confusion.
specifically we add small perturbations to these dimensions and then retrain the word embeddings using the original training set so that the perturbations only cause minimal output variations.
intuitively we are tuning the embeddings so that the model becomes more affirmative and have stable prediction even when confusion perturbation is intentionally injected in the faulty dimensions.
as we observed during experiments identifying the faulty dimensions is critical as perturbing all dimensions leads to accuracy degradation.
one may wonder why not simply train the model using the validation set or even both the training set and validation set.
note that the essence of our technique is not to leverage the additional samples in the validation set to train.
instead we utilize the validation set just to locate the dimensions that do not generalize well to new data and then further harden these dimensions.
in fact we will show in section that training the model using both the training set and the validation set cannot achieve the same level of improvement as trader.
.
trace divergence analysis dl models are normally trained on a training set and then tested on a test set which is unseen to dl models during training.
it is essential to have another set also unseen during training for debugging models and avoiding over fitting on the training set which is referred to as the validation set.
following a similar philosophy our technique leverages the validation set for model debugging.
as shown in figure text samples in the validation set are fed to the model.
by comparing to the ground truth labels we can acquire two sets of samples the correctly classified samples in the top box and the misclassified samples in the bottom box .
these text samples can be further processed by the same model separately to record their traces.
more specifically given a text sample for each step an input word is fed into the model we record the input embedding xtand the previous contexts ct 1and ht 1as the state vector pt.
the output vector qtproduced by the output layer is also recorded.
the state vector ptand the output vector qtare regarded as a trace entry.
hence a sequence of trace entries can be generated for each input sample.
we use the same procedure to generate two separate trace sets called the oracle traces generated from the correctly classified samples and the 990icse may seoul republic of korea guanhong tao shiqing ma yingqi liu qiuling xu and xiangyu zhang also jodatime makes... but i want to connect... i m looking for a well... i understand the boolean... however i d suggest... as others have already... ... pre trained modelsbut i want to connect... i m looking for a well... however i d suggest... ... also jodatime makes... i understand the boolean... as others have already... ...lstm x0h0 lstm xtht ci hilstm x1h1 lstm xthtoutput layerq0 q1 qt x0 ci hi p0 p1 ptq0 q1p0 p1 qt pt validation datapredicted samplesoracle traces buggy traces trace generation figure trace generation for samples in the validation set.
words in input sentences are mapped to their corresponding word embeddings xt.
internal states ciandhiare the initial internal state vectors for lstm models.
the output layer is used to predict the final output label as discussed in equation .
here it has been extended to the whole sequence for acquiring the internal output at each step.
oracle traces buggy tracesfitting approachesoracle machine buggy machinetrace divergence also jodatime makes... q0 p0 qt pt figure construction of oracle machine andbuggy machine and trace divergence analysis.
trace divergence analysis is conducted on a sample text by feeding its traces to the two machines and comparing the output values.
buggy traces from the misclassified samples .
these two set of traces are crucial for debugging rnn models as they represent models internal behaviors on unseen data.
we utilize the two sets of traces acquired from the validation set to learn the distributions of model s proper and buggy behaviors.
figure illustrates the procedure of trace divergence analysis.
to model the distribution of oracle buggy traces we employ the linear regression approach to approximate the relation between state vector ptand output value qtusing the following equation qt wr pt br where wrandbrare weight and bias of linear regression respectively.
these parameters will be updated based on all the traces and each dimension of weight wrdenotes the importance of the corresponding state vector dimensions with respect to the output value.
the fitted models for oracle buggy traces are called oracle buggy machine.
in other words these machines predict output qt from given state pt.
note that they are notrnn models but rather simple classifiers to predict one step of model behavior.
the two machines approximate the desired and undesired behaviors of the model respectively in the presence of unseen data.
for a given misclassified sample from the validation set boxed text in the bottom traces are extracted from the rnn model and fed to both the oracle machine and the buggy machine.
we then compare the outputs from the two machines to identify the divergedalgorithm aggregated divergence analysis function divergence dataset s d zero vector with size of step input forsample insdo t enerate trace sample forpintdo qo arg max om .predict p qb arg max bm.predict p if not qo qbthen d add vector d p wo wb et wei ht om bm wd sub vector wo wb d abs mul vector d wd return d steps.
note that such divergence cannot be directly identified by monitoring the original model operations.
as we aim to identify the root cause of trace divergence i.e.
the faulty dimensions we aggregate the state vectors from the diverged steps.
algorithm details the aggregation procedure.
the algorithm loops over all the misclassified samples in the validation set.
for each sample it first generates the corresponding traces from the rnn model line .
the trace divergence analysis is conducted on each step.
the oracle machine om is provided with the state vector pand outputs an oracle value qo line .
similarly the buggy machine bm is also provided with the same state vector p and outputs a buggy value qb line .
these two output values qoandqb are compared to identify the diverged steps.
those diverged steps are aggregated in d line .
the comparison is needed because not all the steps in a buggy trace are wrong.
in line we acquire the weights from both the oracle machine and the buggy machine which indicate the importance of state vector for oracle traces and buggy traces.
intuitively the difference between these two weight vectors denotes the importance divergence of the individual dimensions of state vector line .
at the end we multiple dwith wdto compute the weighted differences for individual dimensions line .
the faulty dimensions are the ones with exceptionally large values.
figure shows an example of vector dfor an lstm model the red bars .
observe that there are a number of dimensions that have much larger values than the others.
they denote the split confusing behaviors of the subject model in the presence of 991trader trace divergence analysis and embedding regulation for debugging recurrent neural networks icse may seoul republic of korea oracle traces buggy tracesfitting approachesoracle machine buggy machinetrace divergence also jodatime makes... q0 p0 qt pt divergence losslstm xtht 1ct htct lstm xtht 1ct htct !
!
q q figure structure of embedding regulation.
the left lstm has the original model structure.
the right lstm is extended with perturbations for input embeddings xtas well as internal states ct andht qandq are the final outputs from the original model and the perturbed model respectively.
unseen data.
while these dimensions are not human interpretable they provide sufficient guidance for embedding tuning as shown in the next section.
.
embedding regulation after identifying the faulty state vector dimensions which intuitively are the places the model is very unstable and has diverging behaviors for correctly and incorrectly classified samples we next aim to mitigate the problem by regulating word embeddings.
the essence of state divergence lies in that the model is so sensitive for these dimensions that small changes can lead to substantial output changes.
a key feature of rnn type of models is that the encoded values of state vectors are largely determined by word embeddings.
that is words close to each other in the embedding space tend to lead to state vector values close to each other.
our fixing strategy is hence to change word embeddings so that the model becomes less sensitive along the faulty dimensions by enlarging the embedding distances of the words that could lead to substantial output variations.
this is done by applying perturbations to the faulty dimensions and then searching for minimal output variations by tuning word embeddings.
since rnn type of models have a loopy structure the perturbations are applied to each iteration.
figure demonstrates the detailed procedure of our embedding regulation.
the left lstm model is the original model which takes an input embedding xtat each time and outputs the final result q. the right lstm model is the perturbed lstm model where a perturbation vector is added to the input embedding xtand a perturbation vector is added to both cell state ct 1and hidden state ht 1at each step.
the output q from the perturbed model is compared to the output qfrom the original model.
the difference between the two outputs is then propagated to the input word embeddings.
we propose a divergence loss to propagate error information from the output differences to the input embeddings.
the divergence loss is formalized as follows.
ldiv lce ll2 wherelceis cross entropy loss andll2is l2 squared error loss.
the loss functions are used to express our objective to minimize output variations in the presence of perturbations.
cross entropy loss is widely used in classification tasks.
the following formula defines its essence.
lce nnx n 1cx c 1yo c nln po c n where nis the number of training samples and cis the number of classes.
for each sample n if the final output ois different fromalgorithm embedding regulation function regulation model m datasets embeddinge divergence d u zero vector with dimension size of embedding v zero vector with dimension size of hidden neurons fordinddo ifd then idx d .index d ifidx belongs toethen u random normal else v random normal e et variable e e add vector e u ct ht initialized with dimension size of hidden neurons foriinran e max step do ct add vector ct v ht add vector ht v ct ht lst m ct ht s embeddin s e m.f reeze lst m .train m s ldiv returne ground truth label c thenyo c nis otherwise .
po c nis the predicted probability of output oat class c. intuitively cross entropy loss gauges the scale of output differences.
note that in our method perturbations are added to faulty dimensions for all the steps.
such perturbations may accumulate over time and have inappropriate impact on the final output.
we hence employ l2 squared error loss to reduce the influence from perturbations.
it is commonly used for regression tasks .
in our scenario it is formalized as follows.
ll2 2nx n 1cx c pc n pc n where nis the number of training samples and cis the number of classes.
pcnis the original prediction and pcnis the regulated prediction.
intuitively it minimizes the difference between the original prediction and the perturbed prediction.
dl models are usually trained by minimizing the loss function during which model parameters are updated through backpropagation .
different from general dl training we introduce a new training procedure where model parameters are frozen and only input embeddings are updated during training as our purpose is to regulate input embeddings according to the divergence loss.
that is the gradients calculated from our divergence loss is backpropagated to only the embedding variables which are updated during training.
algorithm illustrates the procedure of embedding regulation.
in section .
aggregated divergence analysis is conducted on all the misclassified samples in the validation set.
a vector of dimension divergence is generated for identifying faulty state vector dimensions.
here we utilize this divergence vector to only apply perturbations to the faulty dimensions which are essentially the most influential dimensions.
more specifically we traverse over all the dimensions and find the ones that are faulty line .
for dimensions denoting input xt a random value sampled from a normal distribution n i.e.
mean of variance of is added to those dimensions line .
the variance value is chosen based on the standard 992icse may seoul republic of korea guanhong tao shiqing ma yingqi liu qiuling xu and xiangyu zhang 175original regulatedcorrect traces incorrect tracesfitting approachesoracle machine confusion machinetrace divergence analysis lstmht ct xt htct p lstmht 1ct xt 1htct p diff losstanhtanh htct xtht 1ct 1output layer ct ht xt s insout01020304050 175original regulated embedding cell state hidden state figure an example of vector dfor an lstm model.
deviation of original word embeddings as it should not overshadow the original values.
for dimensions denoting the hidden states a random value sampled from a normal distribution with mean of and variance of is added to those dimensions.
different from that is only added to the input vector the variance value is added to internal states at each step.
a large value of will accumulate over time and can significantly affect normal behaviors of models.
thus is much smaller than .
lines apply the input perturbations.
rnn kind of models have a loopy structure where internal states are computed through multiple steps.
thus for internal hidden states perturbations are added for every step line .
training inputs of text tasks are sequences of words which are mapped to the corresponding word embeddings before training line .
model parameters are frozen during training as we aim to regulate embeddings line .
finally we leverage the divergence loss to tune word embeddings line .
the blue bars in figure presents the trace divergence analysis results for the same model after embedding regulation.
observe that the significance of the faulty dimensions are substantially reduced.
after we acquire the new embeddings we freeze the embeddings and retrain the model by updating model parameters .
this is a typical procedure for training rnn type of models when embeddings are changed.
evaluation we evaluate trader on various datasets word embeddings and rnn model structures.
most experiments were conducted on a server equipped with two xeon e5 .20ghz core processors gb of ram tesla k40c gpu geforce gtx titan x gpu and titan xp gpu cards.
.
setup we use five datasets three well known word embeddings and three widely used rnn model structures each having three different settings with a total of models.
the scale of our experiments is much larger than similar works on rnn models which use models.
datasets.
five datasets are employed in the evaluation.
three of them stack overflow discussions mobile app reviews jira issue comments are from the software engineering se community provided by lin et al.
.
imdb dataset is a large dataset for movie reviews.
another dataset yelp reviews is one of thetable statistics of datasets.
dataset samples negative neutral positive max length app reviews imdb jira issues stack overflow yelp table word embeddings.
embedding dimensions mean standard deviation glove .
.
word2vec .
.
adversarial .
.
largest datasets for sentiment analysis.
table shows the statistics of these five datasets.
the app reviews dataset has samples with sentiment classes.
the longest sentence in this dataset has words.
the imdb dataset has samples with two sentiment classes.
the max length of sentences in imdb is .
the jira issues dataset has samples with two sentiment classes.
the longest sentence in this dataset has words.
the stack overflow dataset has samples with three sentiment classes.
most of the samples are from the neutral class.
the yelp reviews dataset is obtained from the yelp dataset challenge in containing around million samples.
the max length of sentences in yelp is .
for the three se datasets and the yelp dataset we partition them into three disjoint sets training set validation set testing set which is consistent with the setting in .
the original imdb dataset has already been split into two sets with samples for training and samples for testing.
we follow the convention by preserving the test set and further partition the training set to two parts samples in training and in validation.
thus the imdb dataset is split into three parts training validation and testing .
word embeddings.
three kinds of word embeddings are studied in our experiments.
the glove word embedding was proposed by jeffrey et al.
.
it leverages statistical information in a large corpus and only trains on the nonzero elements in a word word cooccurrence matrix.
we employ a pre trained glove embedding from a real word application .
the word2vec embedding was introduced by mikolov et al.
.
it is one of the most widely employed embeddings with many applications .
we also obtain a pre trained word2vec from an existing project .
the adversarial word embedding was especially optimized for text classification .
we utilize the original implementation from the authors to train the embedding.
table illustrates the statistics of these three embeddings.
glove has dimensions for each word and has the largest mean value compared to the other two embeddings.
word2vec has dimensions the largest number of dimensions among all three embeddings.
the standard deviation of word2vec is smaller than other embeddings meaning the perturbation variance should be small for word2vec.
the adversarial embedding has dimensions.
it has the largest standard deviation meaning a large variance value of perturbation should be chosen.
models.
we use three popular rnn model structures each having three different settings on the number of hidden neurons namely and .
the vanilla rnn is a basic rnn model with 993trader trace divergence analysis and embedding regulation for debugging recurrent neural networks icse may seoul republic of korea table trace divergence analysis overhead.
overhead datasetvanilla rnn lstm gru glove word2vec adversarial glove word2vec adversarial glove word2vec adversarial time s app reviews .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
imdb .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
jira issues .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
stack overflow .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
yelp .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
space m app reviews .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
imdb .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
jira issues .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
stack overflow .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
yelp .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table fitting scores of oracle traces and buggy traces generated for each model.
dataset tracevanilla rnn lstm gru glove word2vec adversarial glove word2vec adversarial glove word2vec adversarial app reviewsoracle .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
buggy .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
imdboracle .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
buggy .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
jira issuesoracle .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
buggy .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
stack overfloworacle .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
buggy .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
yelporacle .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
buggy .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
one hidden state see section .
.
lstm has a complicated model structure with three different types of control gates as discussed in section .
.
gru is a more advanced rnn model introduced by cho et al.
.
it has been shown to be one of the state of the arts.
a batch size of samples is used for each training iteration except for yelp which has the size of its default setting .
we use the adam optimizer with the learning rate of .
.
note that we train these models by ourselves which is consistent with existing works on rnn .
the accuracy of the trained models align well with the literature .
hyper parameters.
three hyper parameters i.e.
are used for embedding regulation.
parameter is used for selecting faulty dimensions.
the value of can vary from the minimum value to the maximum of the divergence vector.
parameter and are used to perturb embedding vectors and internal states with ranging from and .
the values of and are chosen using the validation set.
specifically we uniformly sample ten values from their range and select the one that produces the best result on the validation set.
in most cases is close to the mean and is in .
.
depending on the model.
concrete settings can be found in .
note that such parameter tuning is typical in deep learning.
baseline.
we compare our technique with a state of the art rnn hardening technique that does not use debugging feedback but rather standard model hardening strategies including penalizing weights embeddings which adds l2 norm of weights embeddings to the cost function e.g.
lnew lold w 2where wis the model weights re embedding words which minimizes difference between pre trained embeddings and the embeddings fine tunedduring supervised training and dropout which sets each neuron to with a probability pduring training.
since it is a general technique likes ours without requiring any model structure enhancement and reports state of the art results we use it as the baseline.
note that we cannot use gans as a baseline like in mode because high quality gans for rnn models are still an open challenge as pointed out in .
to reduce the uncertainty introduced by random perturbation.
we ran each experiment times and report the average except yelp which we can only afford running it times due to its extremely large size.
.
evaluation of trace divergence analysis we leverage traces acquired from the validation set to learn the distributions of model behaviors.
we first collect the time and space cost of the trace divergence analysis.
we then study the effectiveness of the linear regression approaches in approximating distributions of the oracle traces and the buggy traces.
table presents the overhead introduced by the trace divergence analysis.
from the table it can be observed that for se datasets the analysis time is less than seconds and the space overhead is mostly around a few mbs.
thus it is negligible compared to the millions of weights and hours of training.
for the large datasets imdb and yelp the analysis time is around a few minutes and the space overhead is around thousands of mbs.
note that their results have different scales from the others indicated by the parentheses in column .
we argue the analysis cost is still reasonable.
994icse may seoul republic of korea guanhong tao shiqing ma yingqi liu qiuling xu and xiangyu zhang embedding datasetvanilla rnn lstm gru original rs trader original rs trader original rs trader gloveapp reviews .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
imdb .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
jira issues .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
stack overflow .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
yelp .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
word2vecapp reviews .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
imdb .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
jira issues .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
stack overflow .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
yelp .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
adversarialapp reviews .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
imdb .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
jira issues .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
stack overflow .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
yelp .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table results of regulating all dimensions of embeddings.
embedding datasetvanilla rnn lstm gru gloveapp reviews .
.
.
.
.
.
.
.
.
imdb .
.
.
.
.
.
.
.
.
jira issues .
.
.
.
.
.
.
.
.
stack overflow .
.
.
.
.
.
.
.
.
yelp .
.
.
.
.
.
.
.
.
word2vecapp reviews .
.
.
.
.
.
.
.
.
imdb .
.
.
.
.
.
.
.
.
jira issues .
.
.
.
.
.
.
.
.
stack overflow .
.
.
.
.
.
.
.
.
yelp .
.
.
.
.
.
.
.
.
adversarialapp reviews .
.
.
.
.
.
.
.
.
imdb .
.
.
.
.
.
.
.
.
jira issues .
.
.
.
.
.
.
.
.
stack overflow .
.
.
.
.
.
.
.
.
yelp .
.
.
.
.
.
.
.
.
linear regression is utilized to approximate the distributions of oracle traces and buggy traces to construct the oracle machine and the buggy machine.
to evaluate the performance of the approach we demonstrate the results in table .
the first column denotes the datasets.
the second column denotes the trace types.
the following columns denote different models vanilla rnn lstm and gru word embeddings glove word2vec adversarial and model settings that are used for training the original application models.
the fitting score in table denotes the coefficient of determination r2 which is used to measure the fitting performance.
it ranges from worst to best .
almost all the scores are over .
which indicates that our oracle buggy machine effectively approximates the distribution of oracle buggy traces.
.
evaluation of fixing model bugs the results of bug fixing are presented in table ?
?.
the first column denotes the three word embeddings.
the second column denotes the five applications.
the following columns denote the test accuracy for different models and settings.
column original denotes the results for original models.
column rs detotes the baseline a stateof the art embedding regulation technique .
the original and rs models are trained on both the training and the validation sets.
we chose to do that as trader essentially makes use of the validation set in its debugging procedure.
we also evaluate the effectiveness of defective dimension identification in table .
particularly we use our proposed embedding regulation technique to regulate allthe dimensions of embeddings and retrain models based on those embeddings.
we have the following observations.
for various applications using different word embeddings and model structures trader can consistently improve the test accuracy compared to the original models trained on both the training set and the validation set.
the baseline rs can improve a subset of models some with substantial improvement e.g.
.
for app reviews dataset using lstm with neurons and word2vec embeddings .
however it leads to degradation in a number of models as well e.g.
.
for yelp dataset using vanilla rnn with neurons and adversarial embeddings .
the average improvement is .
.
in comparison trader achieves .
improvement on average over the original models which is substantially larger than rs and in fact also much larger than the improvement reported in the literature for rnn types of models which is typically .
.
with a median of .
.
the improvement on the largest dataset yelp is relatively smaller than the others especially for the setting gru structure adversarial embedding .
this is because the original model already achieves very high accuracy.
when all the dimensions are considered during embedding regulation the improvement on the test accuracy is inconsistent comparing to trader.
especially in some cases e.g.
app reviews dataset using vanilla rnn and glove embedding the result even drops lower than original models.
this observation supports the importance of identifying faulty dimensions when regulating embeddings.
.
case study in this section we study individual cases to show why the buggy model mis predicts input samples and how the fixed model performs.
figure shows four text samples from the app reviews dataset and the stack overflow dataset.
for each sentence we present a pair of results with the first predicted by the buggy model and the second predicted by the fixed model.
the color from red to green and then to blue denotes the sentiment from negative to neutral and then to positive.
the brightness of colors represents the degree of sentiment values.
brighter the color larger the degree towards the corresponding sentiment.
for the first case the ground truth label is positive but the buggy model predicts neutral.
it can be observed that the sentiment output stays neutral at the step with 995trader trace divergence analysis and embedding regulation for debugging recurrent neural networks icse may seoul republic of korea and this code worked.
but sadly this is not working.and this code worked.
legendbut sadly this is not working.
very good indeed well impressed how good a tool it is.
very good indeed well impressed how good a tool it is.seems very accurate even on lower energy settings.
seems very accurate even on lower energy settings.
earlier i was writing the file to local machine then it was working fine.
earlier i was writing the file to local machine then it was working fine.positive negative positive positive figure prediction by the buggy model and the fixed model.
each pair shows the prediction results by the buggy model top and the fixed model bottom .
the color from red to green and then to blue denotes the sentiment from negative to neutral and then to positive.
the brightness of colors represents the degree of sentiment values.
brighter the color larger the degree towards the corresponding sentiment.
word worked .
in this context word worked has positive sentiment and should significantly contribute to the final prediction.
the fixed model acts as expected.
in the second case the buggy model treats word working non negatively.
however in this context it comes after word not which should be considered jointly.
the third case shows that in long sentences the buggy model may focus locally without considering the whole context lower energy settings which produces wrong prediction.
in the fourth case the buggy model focuses too much on the previous context without considering the local information fine .
we think that after regulating the embeddings the model substructures e.g.
forget gates have more appropriate behaviors e.g.
remembering the right context and forgetting the undesirable ones as their behaviors are not perturbed by words that have different meanings but similar embeddings.
threat to validity since we use random perturbation during training which is typical in model hardening the results may have uncertainty.
to reduce the threat we run our experiments multiple times and report the average.
the results are achieved on specific settings such as batch size optimizer learning rate and hyper parameter values.
to achieve fair comparison we follow the same setting in existing works as much as possible e.g.
regarding how to partition datasets .
we also release our settings in for reproduction.
note that although cross validation is often used to reduce uncertainty in machine learning results due to the large scale of data most existing works on rnn especially those considering datasets like imdb and yelp cannot afford cross validation .
the original models may have bugs other than problematic embeddings e.g.
data bias .
the good results we achieve could be partially attributed to that the hardening alleviates some of those bugs.
however the fact that we only perform guided hardening on embedding instead of on weights like in indicates that the other bugs if they exist have substantial confounding with embeddings.
the evaluations are conducted on sentiment analysis task.
the proposed trader however is not application specific.
for instance in sequence tosequence tasks e.g.
neural machine translation two rnn modelsare usually used one encoder for encoding input sequences to hidden states and the other one decoder for decoding target sequences from hidden states together with the output of the previous step.
the decoder is similar to rnn models used in sentiment analysis where hidden states and an input element are fed to the model to obtain an output.
we can use trader to identify the divergence steps of decoder and locate faulty dimensions in hidden states and input elements.
the embedding regulation can be conducted on both source language and target language embeddings.
related work our technique is inspired by software debugging e.g.
.
many techniques use trace analysis and differential analysis.
they locate bugs by tracing program execution and comparing buggy runs with correct runs.
similarly we trace rnn executions and locate divergence.
unlike traditional software rnn uses high dimension embeddings and has much more complex data dependences between the embeddings and neuron activation values so we use embedding regulation and retraining to repair rnn models.
there are many works that employ general machine learning methods and some works specifically use rnn models in software engineering tasks.
trader can help software engineering researchers debug their rnn models.
researchers have also proposed different methods to debug the machine learning models .
however these works focused on specific machine learning models or feedforward neural networks and are not applicable to rnn models.
in the article researchers aim at debugging nlp models by generating adversarial examples as training data.
in articles researchers propose methods to debug models by cleaning up the wrongly labeled training data.
these approaches debug rnn models by providing better training data and do not analyze model internals.
trader is orthogonal to these works.
there are also works that explain nlp models and use model explanations to help data engineers debug models.
these approaches require human efforts while trader is fully automated.
conclusion we develop a novel technique to automatically diagnose how problematic word embeddings influence model accuracy by collecting and comparing model execution traces for correctly and incorrectly classified samples.
a new embedding regulation tuning algorithm is proposed to leverage the diagnosis results to harden the embeddings.
our experiments show that our technique can consistently and effectively improve accuracy for real world models and datasets by .
on average.