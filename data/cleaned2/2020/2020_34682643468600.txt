varfix balancing edit expressiveness and search effectiveness in automated program repair chu pan wong carnegie mellon university pittsburgh pa usapriscila santiesteban coe college cedar rapids ia usa christian k stner carnegie mellon university pittsburgh pa usaclaire le goues carnegie mellon university pittsburgh pa usa buggy program test suite e1 e2 e3 e1 e1 e2 e1 e3 e1 e2 e3 e1e1 e2e1 e3e1 e2 e3 fault localization edit factory step edits generation with genprog step meta program generationsingle edits step variational executionmeta program plausible patches step patch ranking ranked patches figure overview of our program repair approach.
abstract automatically repairing a buggy program is essentially a search problem searching for code transformations that pass a set of tests.
various search strategies have been explored but they either navigate the search space in an ad hoc way using heuristics or systemically but at the cost of limited edit expressiveness in the kinds of supported program edits.
in this work we explore the possibility of systematically navigating the search space without sacrificing edit expressiveness.
the key enabler of this exploration is variational execution a dynamic analysis technique that has been shown to be effective at exploring many similar executions in large search spaces.
we evaluate our approach on introclassjava anddefects4j showing that a systematic search is effective at leveraging and combining fixing ingredients to find patches including many high quality patches and multi edit patches.
ccs concepts software and its engineering software testing and debugging error handling and recovery.
keywords automatic program repair variational execution acm reference format chu pan wong priscila santiesteban christian k stner and claire le goues.
.
varfix balancing edit expressiveness and search effectiveness in automated program repair.
in proceedings of the 29th acm joint european esec fse august athens greece copyright held by the owner author s .
acm isbn .
engineering conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa 13pages.
introduction we propose a novel search strategy for automated program repair to systematically explore possible repairs in rich search spaces with diverse fixing ingredients including multi edit patches.
bugs are pervasive and costly and traditional manual repair is expensive and time consuming .
automated program repair is a promising idea aimed at automatically finding patches to a program such that the program passes all provided tests.
automated program repair has seen significant research attention as well as initial industrial adoption .
automated program repair techniques generate patches for a buggy program to satisfy a given partial specification of program behavior usually provided as a set of tests .
a patch typically contains one or more code edits that are generated by instantiating edit templates for different fixing ingredients similar to how mutation operators are used to generate mutations in mutation testing research.
given a program and its test suite with at least one failing test repair approaches search for patches such that the test suite passes.
existing approaches to automatic program repair essentially solve a search problem.
the search space is defined by the set of possible edits e.g.
copying code or modifying expressions it is typically large and grows exponentially if combinations of multiple edits are considered.
to navigate such a huge search space different search strategies have been explored such as genetic programming guided search using statistical models and program synthesis .
there are two keys to solving the search problem edit expressiveness andsearch effectiveness.
these concerns are in tension and existing techniques usually prioritize one of them 354this work is licensed under a creative commons attribution international .
license.
esec fse august athens greece chu pan wong priscila santiesteban christian k stner and claire le goues heuristics based approaches like genprog par and capgen excel at edit expressiveness.
they explore a large space of potential edits by executing the test suite for one patch candidate at a time.
this process is well suited for trying many different kinds of edits including adding and removing statements mutating expressions and edits following specific patterns such as inserting null checks .
but as search spaces grow search effectiveness typically declines .
semantics based approaches like angelix and s3 excel at search effectiveness by encoding the search as a synthesis problem using classic ai search techniques focused on pruning infeasible parts quickly as in sat and smt to find expression level changes that meet the constraints collected with program analysis usuallysymbolic execution from tests.
the synthesis technique limits expressiveness and scalability resulting typically in a narrow focus on few kinds of edits e.g.
edits of expressions of boolean and integer types in conditions or assignments .
in this work we pursue higher search effectiveness without sacrificing edit expressiveness .
our goal is to perform an efficient systematic search in a search space of allowing many different kinds of edits as in heuristics based approaches.
our key insight is that repeated test executions for many potential patches are very similar as edits tend to be focused in a relatively small part of the trace as narrowed down by fault localization techniques and exploiting those similarities can speed up the search.
to exploit test execution similarity we use variational execution .
variational execution is a dynamic analysis that executes a program for multiple inputs or multiple variants once sharing the execution whenever possible and systematically exploring all alternatives and interactions.
reminiscent of many model checking strategies when an edit is encountered variational execution splits the execution to compute the program states with and without the edit.
also importantly variational execution then merges executions again to execute the rest of the program only once.
conceptually given a finite search space of edits as fixing ingredients a single run of variational execution is equivalent to running all edits and their combinations in isolation.
with sufficient sharing variational execution often can systematically explore large search spaces efficiently as shown in recent work on tracking sensitive information flow testing highly configurable systems and finding higher order mutants .
as we will explain in more detail our approach consists of four steps also illustrated in figure we collect a set of possible edits similar to traditional heuristics based techniques.
we merge all collected edits into a meta program where all edits are guarded by if conditions that control whether to include the edit at runtime.
we execute the meta program with variational execution to observe which combinations of edits in terms of the boolean variables that guard the edits pass each test returned as propositional formulas from which we enumerate all patches that pass all tests within the search space.
to identify likely high quality patches among all plausible patches we further filter and rank patches using heuristics based on their influence on program state and control flow.1if a b a c a d smallest a else if b1 a b c b d smallest b else if c a c b c d smallest c else if d a d b d c smallest d 3smallest c figure incorrect program with suggested edit patch simplified from smallest 1b31fa5c .
intuitively edit makes cthe default output edit handles cases where aand bare equal and smallest and finally edit checks for cases where dis the smallest.
we evaluate our approach both with the bugs from introclassjava and with bugs from defects4j .
we show that our approach can fix introclassjava bugs and defects4j bugs including many that require edits in multiple locations can scale to fairly large programs and search spaces can generate very large sets of patches for bugs up to correct patches for a single bug and can effectively rank correct patches highly.
we make the following contributions in this work we prototype a repair tool named varfix built on top of genprog andvarexc the state of the art implementation of variational execution for java.
we demonstrate that it is promising to systematically explore large search spaces for program repair using variational execution e.g.
fixing out of evaluated bugs .
we demonstrate the ability to find high quality patches made possible by a systematic exploration of the search space e.g.
generating thousands of correct patches .
we demonstrate the ability to better find multi edit patches as a key benefit of the more efficient search strategy e.g.
finding hundreds of patches that require edits .
we demonstrate the benefit of enumerating and ranking many plausible patches over just reporting the first one found in terms of improved patch quality e.g.
ranking the correct patch in top in out of cases .
repair challenges we use an example to discuss limitations of existing work and benefits of our approach.
in figure we show a buggy program taken from introclassjava and a patch found by our approach.
the program should output the smallest of four inputs.
due to the use of incorrect relational operators it fails if the smallest number appears more than once in the inputs.
our patch consists of three edits two modify operators in boolean expressions while the third inserts a statement taken from the existing code.
for the same program other patches can be found all requiring multiple edits.
.
edit expressiveness vs. search effectiveness the success of existing program repair techniques largely depends on the balance between edit expressiveness and search effectiveness which affects their ability to fix programs like our example.
355varfix balancing edit expressiveness and search effectiveness in automated program repair esec fse august athens greece heuristics based repair.
heuristics based approaches usually can experiment with many different kinds of edits including the statement and expression changes in figure .
for example genprog can add replace delete statements in the original program such as edit in figure jmutrepair uses classic mutation operators to tweak existing expressions such as edits in our example others specialize edits for certain classes of faults such as patterns mined from human patches and patterns for common mistakes used in par spr and prophet .
overall the community is moving toward increasingly larger search spaces of edits.
the larger the space of possible fixing ingredients the more challenging the search for a patch .
even just executing tests for single edit patches can take a long time and a systematic exploration of multi edit patches is usually not considered feasible.
instead existing approaches largely rely on different heuristic search such as random search genetic programming deterministic heuristic traversal of single edits and probabilistic exploration favoring certain kinds of edits possibly informed by distributions of human patches .
mechtaev et al .
divide individual fixing ingredients into test equivalence classes to reduce test execution cost and thus improve search efficiency of existing repair techniques.
none of the current approaches can systematically explore larger search spaces and current search heuristics often do not work well for multi edit patches e.g.
fitness functions in genetic programming cannot well recognize partial correctness in multi edit patches it is possible but unlikely that they find the right combinations of the three edits in our motivating example.
indeed empirical evidence suggests that existing search strategies perform worse in larger search spaces generating fewer correct patches due to timeout or stopping with plausible but ultimately incorrect patches .
semantics based repair.
semantics based approaches can effectively explore search spaces by delegating the search to program synthesis techniques but they usually restrict themselves to small edits at the expression level e.g.
tweaking boolean expressions inifconditions to make program synthesis tractable.
edit expressiveness is mainly restricted by the scalability of constraint solvers and the types of theory they can reason about .
thus existing approaches are unlikely to find patches for our motivating example because statement level changes are not supported and synthesizing multiple expression level changes in different locations poses a scalability challenge for synthesis especially for large programs in practice.
for example directfix needs to symbolically execute the whole program under repair to synthesize edits at multiple locations angelix mitigates this issue by applying symbolic execution exclusively to a few suspicious expressions but requires buggy locations to be physically close .
s3 essentially repairs each buggy location separately putting more pressure on the underlying program synthesizer .
.
open challenges several open challenges of automatic program repair boil down to maintaining a good balance between edit expressiveness and search effectiveness.
our approach strives for a balance by pursuing a more systematic search within a search space of more expressive edits.
in the following we discuss some open challenges our approach can potentially shed light on general purpose repair.
usually the more expressive edits are supported the larger the search space becomes and the more difficult it becomes to explore that search space systematically.
approaches with more expressive edits have the theoretical ability to repair more bugs but may find it harder to find actual repairs in practice.
our approach can easily integrate different kinds of edits just like heuristics based approaches promising high edit expressiveness.
it then enables an efficient search among a finite number of edits and their interactions more similar to test execution in heuristics based approaches without being limited by the capabilities of synthesis approaches.
multi edit repair.
recent empirical studies suggest that making multiple edits is common when developers fix bugs but automatically generating multi edit patches remains challenging.
in theory many repair approaches can find multi edit patches.
in practice they struggle with finding them because techniques do not explore edit interactions systematically and do not have a good way of judging partial correctness that may help to guide the search for multiple fixing ingredients.
our approach can explore interactions among multiple edits systematically up to a configurable bound ensuring that if our search terminates we can identify all available multi edit patches within a given search space.
patch quality.
the research community has identified the tendency of program repair to produce low quality patches that pass all provided tests but do not generalize beyond them as a key challenge .
we follow the typical distinction between plausible patches as those that pass all tests and correct patches that meet the intended specification typically not easily available and may require human judgement .
long and rinard found that plausible patches often starkly outnumber correct patches making automated repair possibly less useful especially those techniques that simply report the first identified plausible patch.
recent work primarily focuses on anti patterns to skip low quality patches or on tweaking search strategies to prioritize edits that are less likely to overfit .
in contrast we use a different strategy of embracing a rich and diverse edit space then enumerating all plausible patches within the search space but adding a final filtering and ranking step to suggest those patches that are likely of higher quality.
in line with prior suggestions our ranking step uses information beyond just the test suite to evaluate patch quality and additionally compares the severity of data and control flow changes for the enumerated plausible patches.
ranking patches from a large pool of plausible patches provides a more promising way of identifying high quality patches than simply returning the first plausible patch as in heuristics based approaches or the smallest plausible patch as in semantics based approaches .
meta program generation the first part of our approach cf.
figure steps and is to generate a large set of edits and combine them into a single metaprogram where each edit is guarded by a control flow condition.
with this encoding we can later use variational execution to efficiently run the tests across all combinations of edits.
the edits in the meta program define the finite search space of patches.
356esec fse august athens greece chu pan wong priscila santiesteban christian k stner and claire le goues 1if a b a c a d smallest a else if b1 e1 ?
b a b a a b c b d smallest b else if c a c b c d smallest c else if 2e2?
d a d b d c d a d b d c smallest d else if e3 smallest c else smallest integer.max value test original passing condition assert smallest true assert smallest e3 assert smallest e1 assert smallest e2 whole test suite e1 e2 e3 figure the upper part is an example of meta program that encodes edits for smallest .
the lower part is a manually constructed test suite for demonstrating how variational execution is used.
the original column reports test outcomes of the original buggy program.
for generating edits we build our approach on top of a genprog implementation for java because of its conceptual simplicity and extensibility.
we first use genprog s fault localization technique to narrow down where to generate edits.
in those likely faulty locations we use genprog s edit templates to generate edits one at a time.
we inherit the three classic edit templates append replace anddelete that modify statements as well as five additional classic mutation operators arithmetic operator replacement aor relational operator replacement ror logical connector replacement lcr absolute value insertion abs and unary operator insertion uoi .
we selected these five operators for several reasons.
first they mutate expressions allowing our search space to include finer grained edits than genprog s original statement level changes.
second research has shown the usefulness of these operators in mutating programs .
finally they can be applied to a wide variety of programs including simple programs in introclassjava .
other edit templates e.g.
those that target specific fault classes can be easily integrated as extensions.
we modified genprog to repetitively mutate the given buggy program until a specified number of different edits are generated or all possible edits from the templates are exhausted.
we then discard edits that are not compilable a standard genprog step .
finally we merge those edits into one meta program.
similar to prior work that uses meta programs we encode all edits as optional code paths guarded by if then else statements expressions into a single meta program.
for each edit we introduce a boolean option e.g.
global static field in java that decides whether the original or the edited code is executed in runtime as illustrated in figure .while the approach is simple and flexible supporting many different edits there are two technical challenges in the implementation first putting too many edits into a single java method can exceed size limits of java bytecode.
we refactored a few gigantic java methods e.g.
more than lines of code in some of the closure programs into smaller methods because of size limits.
this is unique to the specific bytecode transformation implemented invarexc the tool we use for variational execution rather than to variational execution in general.
whenever possible we push edits into small methods after performing semantics preserving refactoring.
we run all existing tests to validate the refactoring changes.
second our approach inherits nondeterminism from genprog when generating edits thus while we will systematically explore the search space the generated edits in the search space may differ between runs.
systematic search after creating the meta program we execute the test suite using variational execution to determine what combinations of edits can pass all tests cf.
figure .
adopting variational execution raises search effectiveness because with it we can explore the search space in an efficient andcomprehensive way rather than checking one patch at a time.
.
background on variational execution variational execution can be seen as a specialized form of symbolic execution or model checking that aggressively joins state and that limits symbolic inputs to those with finite domains usually boolean values .
for the purpose of this paper a mental model of symbolic execution will provide a close enough approximation of how the approach works.
given that we largely reuse variational execution as an off the shelf black box technique we will only provide a quick overview and refer interested readers to existing literature for a more in depth explanation and formalization .
using variational execution we execute the test suite of a metaprogram with the test suite s concrete inputs but with symbolic values for all boolean variables introduced in the meta program to guard the edits to be explored e.g.
e1 e2in fig.
.
variational execution will execute a test normally with concrete values until it hits a decision that depends on an a symbolic value representing an edit where it explores both branches.
after exploring both branches under corresponding symbolic path conditions variational execution joins the state again to execute subsequent statements only once while representing state differences as if then else expressions.
for example x e1?
e2?
1represents concrete value or depending on whether edits e1and e2were selected.
when the execution hits an assertion we can derive a propositional formula describing the set of assignments to symbolic values i.e.
the set of edit combinations that violate the assertion for example assert x fails under condition e1 e2.
similarly we can record the path condition when an exception is thrown.
that is for each test execution we can collect the set of edit combinations for which the test passes as a propositional formula without having to execute the test for every edit combination separately.
if edits interact too much variational execution can run into the same state explosion problem as other analysis techniques 357varfix balancing edit expressiveness and search effectiveness in automated program repair esec fse august athens greece the key question is whether the program repair problem contains sufficient sharing to make variational execution feasible.
the key insight in using variational execution is that most test executions are similar or even identical when edits modify the buggy program.
many edits have only minor and local effects on control flow and program state of some test executions and most computations are the same or similar independent of whether an edit is applied.
variational execution exploits those sharing opportunities among many similar executions with minor differences regarding both data flow and control flow.
but it also systematically explores all interactions among options if they lead to state differences.
note that variational execution is unusually aggressive in how it always merges all program state at the level of variables and fields after each statement helped by its restriction to finite search spaces.
similar state merging techniques have also been discussed and adopted for model checking and symbolic execution e.g.
achieving significant improvement over conventional state merging.
.
using variational execution to find plausible patches to identify which combinations of edits can pass all tests and fix the buggy program we execute each test for the meta program with symbolic values representing all edits and capture for each test the passing condition a propositional formula compactly describing the combinations of edits for which the test passes.
any combination of edits that meets the passing conditions of alltests represents a plausible patch.
to enumerate all plausible patches we use a sat solver or bdd to enumerate all solutions that satisfy the conjunction of all passing conditions.
for example in figure assert smallest passes under condition true meaning that the test passes without any edits and no edit breaks the test either.
however the second test assert smallest passes under condition e3 meaning that it can pass only when edit is applied independent of the other edits.
finally the conjoint passing condition for the whole test suite is e1 e2 e3 suggesting that we need all three edits to fix the program.
if variational execution and the sat solver terminate we have explored the entire given search space of patches.
we can be sure that we will have found all edit combinations that pass the test suite and no additional ones.
if the joint passing condition is unsatisfiable we know that there is no edit combination in the search space that passes all tests that is we simply do not have the right fixing ingredients to patch the program.
.
implementation and limitations we use varexc a state of the art variational execution engine for java developed in prior work .
in practice especially for large search spaces that contain thousands of edits we still often experience slow executions and executions that do not terminate within time budget due to state space explosion.
to address these we made several adjustments to make it better fit the characteristics of program repair problems usually by focusing the search on smaller spaces.
we name our overall repair tool varfix .
early termination.
we use variational execution to execute test cases one at a time with all edit combinations but prioritizingtest cases that the original buggy program fails.
after each test execution we check if there exist any combinations that can pass the tests executed so far and continue to the next test only if there remain solutions in the search space.
this way we can often terminate the search early knowing that no combination of the edits in the meta program will pass all tests.
bounded search.
while variational execution can conceptually explore all possible interactions within the search space so may be expensive when many edits interact.
in addition patches that combine more than a few edits may be too complex to be useful.
we extended varexc to optionally bound the search space to limit the number of individual edits in a patch.
technically we simply prune states and execution paths that are only feasible with more than nactivated edits.
note that we still systematically explore all edit combinations within the bound .
partitioning edits.
orthogonal to bounding the degree of interactions we can also explore interactions among fewer edits.
we implement an option to partition the edits considering at most n edits and their interactions at a time.
the partition strategy can be customized including random default or partition by location or fault localization suspiciousness.
within each partition we still explore interactions among edits but we would not detect patches that require combinations of edits from different partitions thus may miss patches that would be feasible in the larger search space.
fast mode.
we noticed that variational execution spends a lot of time exploring exception handling paths e.g.
division by zero which is expensive in varexc .
while successful patches might conceivably involve throwing and catching exceptions we optionally prune those execution paths where exceptions are thrown due to one or more edits.
note that we may miss patches due to this optimization unless we explore the pruned paths later.
this optimization is similar to how s3 uses symbolic execution to run failure free execution paths .
limitations.
similar to symbolic execution variational execution needs to handle the environment barrier when interacting with an external runtime environment for example via i o and native method calls.
this issue can typically be mitigated with engineering effort such as implementing model classes to mimic behavior of the environment .
as a research prototype varexc provides model classes for many common apis but not for all hence we performed minor refactoring in some of the closure programs to use functionally equivalent model classes that varexc already supports such as replacing stringwriter with stringbuilder .
in some systems we still observed a small number of tests that we could not execute without investing significant engineering effort.
here we adopted a hybrid strategy first we collect passing conditions from all tests we can execute with variational execution skipping the problematic ones.
second we execute the skipped tests normally without variational execution for all edit combinations that pass the joint pass condition to see whether they fail any of the skipped tests.
this way variational execution significantly prunes the search space but some final exploration remains limited to executing the remaining tests one patch candidate at a time.
358esec fse august athens greece chu pan wong priscila santiesteban christian k stner and claire le goues finally edits often introduce infinite loops in some execution paths.
since we do not want to terminate the test case for all executions we prune execution paths that exceed an upper limit for the number of executed basic blocks in a method or a maximal stack height.
patch filtering and ranking with variational execution we can enumerate all plausible patches in a search space often finding large numbers of plausible patches that can pass alltests.
however not all patches generalize well beyond the test suite.
our approach opens new opportunities to try to identify higher quality patches among a pool of plausible patches rather than simply returning the first patch found.
we demonstrate the benefits of this strategy with a simple filtering and ranking strategy that can easily be extended in future work.
filtering by patch minimization.
for every plausible patch we often find additional patches with a superset of edits.
this often happens when some edits are needed to pass the tests and other edits can be added that do not influence the test outcome or are not even executed by the tests.
the extra changes may fix issues for inputs not tested by the test suite may break behavior for inputs not tested or may simply be behavior preserving for all possible inputs we have no way of telling.
patch quality is often measured with held out tests in academic evaluations or by comparing against another oracle but neither of those is available in practical settings.
in apatch minimization step we filter all patches for which we found another patch with a strict subset of edits.
that is we remove all edits that are not necessary for passing all tests.
this way we avoid showing many similar patches with the same core edits to developers and we generally favor shorter patches.
this is conceptually equivalent to patch minimization using delta debugging in the original genprog implementation .
patch ranking.
since all plausible patches are indistinguishable from the test suite s perspective i.e.
all tests pass for all plausible patches we need to judge patch quality using other information .
our solution is inspired by insights from xiong et al .
who observed that a correct patch should have little effect on passing tests in terms of similarity between execution traces but should cause failing tests to behave differently.
a side benefit from variational execution is that we can easily track rich information about differences between executions by tracking path conditions and conditions that describe state differences.
note that variational execution is not essential here just convenient such information could conceptually also be collected with other tools as in the work of xiong et al.
.
in a nutshell we compute a distance between the unpatched and the patched program.
we experimented with five different distance measures.
in addition to two static edit distance measures number of ast transformations measured with gumtree and number of characters changed measured with levenshtein distance we measure the difference between a test s execution on the original unpatched program and the test s execution on the patched program frequency with which we assign different values in statements that change program state frequency ofdifferent branches taken at control flow statements and differences in terms of executed lines.
for the last three measures we aggregate distances across tests similar to xiong et al .
adding the maximum distance among all previously passing test and the average distance of all previously failing tests with the intuition that large changes even to a single passing test are undesirable whereas larger changes to failing tests are sometimes expected.
we rank all patches by distance reporting those patches with the smallest distance between patched and unpatched programs first.
a detailed description of the distance computations can be found in the supplementary material.
evaluation we evaluate our approach along multiple dimensions.
first central to any automatic program repair tool is its ability to identify patches so we measure repair effectiveness in terms of the number and the quality of repaired bugs rq1 how effective our approach is in finding patches within a large search space of fixing ingredients?
rq2 to what extent do our generated patches overfit to the provided tests?
our approach should benefit from increased edit expressiveness without suffering much in terms of search effectiveness and easily incorporate more fixing ingredients hence rq3 to what extent can our approach make use of different kinds of fixing ingredients?
another key benefit of a systematic search in a rich space of fixing ingredients is the ability to find multi edit patches.
we expect to find more multi edit patches than prior approaches rq4 how effective is our work in generating multi edit patches?
finally enumerating all plausible patches opens new opportunities for selecting high quality patches from a pool of many plausible patches hence rq5 how effective is our patch ranking?
where available we compare our results with the state of theart approaches by taking numbers verbatim from prior work because reproducing previous results can be expensive and timeconsuming .
experimental conditions of prior work e.g.
fault localization and edit templates used are different so numbers should be compared with care.
we report numbers from existing work nonetheless to put our approach into context.
our experiment setup and evaluation data are publicly available in the supplementary material.
.
experimental setup while the specific experimental design differs between research questions all research questions are evaluated on the same set of bugs and with the same generated meta programs.
bugs analyzed.
to enable comparison with other approaches we build our evaluation on bugs in eight subject systems from two commonly used benchmarks characterized in table .
each bug consists of an implementation and a test suite in which at least one test fails.
the two benchmarks have very different characteristics allowing us to triangulate the evaluation results.
359varfix balancing edit expressiveness and search effectiveness in automated program repair esec fse august athens greece table evaluation subjects subject description loc test loc bugs tests median median of integers smallest smallest of integers digits digits of an integer grade compute letter grade checksum checksum of a string syllables count syllables math math library 85k 19k closure javascript compiler 90k 83k loc for introclassjava are counted using sloccount and averaged over all bugs.
loc fordefects4j are taken from the original work .
bugs denote the total number of bugs available in the datasets.
tests denotes the number of test cases.
the first set of subject systems drawn from the introclassjava benchmark is derived from student solutions to assignments in an introductory programming course .
the small size of these programs minimizes the impact of fault localization and allows us to comprehensively evaluate our approach under different experimental conditions the simplicity of these programs also allows us to often evaluate correctness of patches formally.
to evaluate our approach at a more realistic scale we also analyze bugs from the math and closure open source projects in the defects4j benchmark broadly used in repair research to evaluate effectiveness and scalability on real bugs .
we limit our evaluation to the two largest subject systems in the dataset to balance between ability to compare to other reported results and required engineering effort wrt.
environment barrier see section .
and evaluation cost.
meta program generation.
to reduce nondeterminism and computational effort we generate one meta program for each buggy program and use it consistently in all experiments.
we use all eight edit templates section and repeatedly apply edit templates at all locations identified by the fault localization technique.
in programs with very large numbers of possible edits we generate edits randomly until we reach edits for introclassjava programs and for the larger defects4j programs.1generated edits are then compiled individually and only compilable ones are merged into the meta program.
threats to validity.
we encountered technical issues with out of defects4j bugs mostly due to unsupported api calls a challenge shared by semantics based tools and research prototypes of analysis tools in general that can be addressed with more engineering effort cf.
sec.
.
.
although varfix did not produce any results for these bugs we do not exclude these bugs when we report numbers from prior work.
we conjecture that a more mature variational execution engine would allow us to repair more bugs.
randomness might affect several components of our experiment such as generating meta programs sampling edits for variational execution and genetic search of genprog .
to limit the impact of randomness we intentionally generate a large pool of applicable edits when we generate meta programs.
we also take different samples or seeds when applicable.
1we assign a times lower chance to uoiandabsedits because they can easily create lots of edits around constants and numeric variables that are often of little value.as with all existing approaches our approach is evaluated on a limited number of bugs and thus results must be generalized with care.
we expect that overfitting to the benchmark is less of an issue as we only use generic edit templates and focus on search effectiveness.
.
rq1 effectiveness rq2 patch quality the first obvious questions are how many bugs we can fix and how good those patches are.
experiment setup finding patches rq1 .
we run our approach on each subject s meta program for up to 3hours for introclassjava and 6hours for defects4j in line with recent prior work .
with this time budget variational execution would typically not be able to explore all combinations of edits hence we carefully set a number of options to limit the search discussed in section .
.
we run multiple experiments with increasingly larger bounds until we reach the time limit.
for introclassjava we bound the search to combinations of at most edits cf.
sec.
.
for programs without loops in programs with loops which are often copied by edits so we start with a bound of and continue with 3if there is time left.
for math and closure where loops and recursions are common we start with bound and all edits then explore combinations of randomly selected edits at a time with bound and finally combinations of edits with bound .
we continue sampling in restricted edit spaces until the time limit is reached.
we experimentally compare our approach directly to genprog s genetic programming based search strategy which still provides a competitive baseline despite years of program repair research executing tests against one patch at a time.
for fairness we exclude edit generation and compilation and run tests against the same meta program.
we configure genprog to run up to and seeds for introclassjava anddefects4j subjects respectively with the same 3h and 6h time limits and record all patches found within the time limit rather than stopping after the first plausible patch.
to complement the effectiveness comparison we additional compare efficiency by measuring the time it takes to generate the first plausible patch.
we configured genprog to search more efficiently by sampling of the provided tests when validating patch candidates.
only when all the tests in the sample pass will genprog continue validation with the rest of the tests.
we set up the experiments in docker containers and ran all performance measurement on amazon fargate.
each fargate instance has vcpu and gb of ram.
altogether the experiments for rq1 took more than hours of cpu time.
for other repair approaches we report previous findings from the literature gathered on the same subjects with similar setups .
while not directly comparable this provides a reasonable context without having to invest enormous additional computational resources.
experiment setup evaluating patch quality rq2 .
to measure patch quality we aim to distinguish plausible patches that pass the test suite i.e.
all results found by repair approaches from correct patches that actually meet the program specification if available and would pass all possible tests.
since correctness is often difficult 360esec fse august athens greece chu pan wong priscila santiesteban christian k stner and claire le goues to establish we adopt the common notion of generalizable patches that additionally pass a high quality held out test suite which was not available to the repair approach a pragmatic approach to evaluate patch quality common in repair research .
we use a best effort approach to identify high quality patches among all plausible patches judging correctness where feasible and generalizability otherwise.
forintroclassjava the specifications are simple enough that we can verify patch correctness formally via symbolic execution for most of the bugs.
we implemented a small symbolic execution engine to verify equivalence between a patched program and a reference solution considering only correct patches as high quality patches.
for the digits subject the frequent use of loops prevents full verification so we consider only symbolic inputs in the range and classify programs that are behaviorally equivalent to a reference solution for those inputs as high quality patches.
for three syllables and checksum bugs where advanced language features prevented verification we do not attempt to identify high quality patches.
fordefects4j verification is infeasible so we follow the standard practice to use an additional held out test suite .
we reuse existing high quality held out tests that were previously generated for evaluating patch quality and classify a patch as a high quality patch if it passes all held out tests.
for patched bugs we were not able to acquire held out tests but instead manually examined each generated patch and classify it as high quality only if it is syntactically or semantically close to the developer patch.
we use the term semantically close to conservatively refer to cases where programs are behaviorally similar but not strictly semantically equivalent.
one example is math while the developer patch removes an if statement our patch replaces the same if statement with a code snippet that is unlikely to affect program state see supplementary material for code examples .
results.
varfix is effective at finding high quality patches in all subject systems.
for introclassjava it significantly outperforms all other approaches on the number of bugs for which it finds plausible and high quality patches see table for details.
varfix did not attempt repairing out of bugs that do not pass any provided test because fault localization inherited from genprog fails.
as expected bugs repaired by varfix are a strict superset of those repaired by genprog in the same search space.
importantly varfix produces high quality patches for bugs that no other approach fixed.
for the much larger subjects in defects4j we observe similar patterns though fewer patched bugs overall shown in table .
varfix again strictly outperforms genprog for searching in the same search space in terms of bugs fixed with plausible and highquality patches the effect is larger for closure because the larger test suite slows down genprog s search more.
other approaches often repair a similar number or slightly more bugs likely because recent work uses more diverse or more tailored fixing ingredients.
for example hercules can fix math by inserting a method call that is absent from the buggy source file a fixing ingredient not available in our evaluated implementation.
in all cases where varfix fails to produce any patches it is because varfix exceeds the time budget at higher search bounds bugs or because oftable number of repaired bugs for introclass highquality plausible subject varfix genprog capgen s3 nopol jmutrepair median smallest digits grade checksum syllables total a hyphen denotes missing data.
for varfix genprog capgen and s3 each cell shows the number of bugs patched by high quality plausible patches.
for nopol and jmutrepair each cell shows the number of bugs patched by plausible patches since patch quality is not evaluated .
table number of repaired bugs for defects4j highquality plausible subject varfix genprog hercules simfix ssfix capgen math closure total each cell shows the number of bugs patched by high quality plausible patches.
numbers for existing approaches are taken from the corresponding papers .
capgen was not evaluated on closure and the paper only reports high quality patches.
bugs closure and closure are the same.
we count only one of them and manually adjust numbers of other approaches for consistency.
000varfixgenprog a median0 b smallest 000varfixgenprog c grade0 d digits 000varfixgenprog e checksum500 f syllables 000varfixgenprog g math0 h closure figure efficiency comparison between varfix andgenprog .
in each box plot we show the time taken to find the first patch for all the bugs of the given subject.
the horizontal axis displays time in seconds.
technical limitations of the variational execution engine bugs cf.
sec.
.
.
importantly varfix can uniquely fix bugs with highquality patches for math and for closure not fixed by any other approaches.
we observed that varfix can repair bugs that existing approaches did not fix because our search space is more expressive i.e.
we do not restrict the types of edits and our search is systematic with regard to the given search space i.e.
we do not use heuristics to traverse the space .
interestingly manual verification of the fixed bugs showed that varfix found the actual developer 361varfix balancing edit expressiveness and search effectiveness in automated program repair esec fse august athens greece patch among all the patches in all the cases where the needed fixing ingredients were in the search space in the other cases the exact ingredients were not in the search space because of inaccurate fault localization and limited edit templates .
in addition to patching more bugs than genprog varfix also finds vastly more plausible and high quality patches per bug often more than patches per program and still dozens of patches after minimization as summarized in tables and for details on individual bugs see supplementary material .
this shows not only plausible but also high quality patches are abundant both for tiny programs like the ones in introclassjava and larger ones indefects4j in contrast to prior observations that found many plausible but only few high quality patches possibly caused by a less efficient search strategy .
in terms of search efficiency varfix tends to take slightly more time than genprog to find the first patch for introclassjava as shown in figure .
however varfix can often find many more plausible patches at the same time as opposed to one at a time for genprog .
for defects4j varfix can search more efficiently than genprog because the overhead of variational execution is offset by larger search spaces and more expensive test executions when fixing bugs in large programs.
overall varfix s more effective search strictly outperforms genprog in the same search space it significantly outperforms prior work onintroclassjava and can uniquely fix defects4j bugs.
it is effective not only at finding plausible patches but also at identifying high quality patches.
search efficiency of varfix is on par with genprog despite a more heavyweight search the cost of which can be offset in large repair problems.
.
rq3 fixing ingredients to demonstrate varfix s ability to incorporate and take advantage of different fixing ingredients we explore it s ability to fix bugs with different ingredients.
experiment setup.
we conduct two separate experiments for introclassjava bugs we compare varfix s ability to find patches with different fixing ingredients.
specifically we compare the results from rq1 which used eight edit templates with a separate trial where only a subset of the edit templates was available namely thethree original edit templates of genprog that append replace and delete statements.
for defects4j bugs we do not repeat the entire experiment due to high computational costs but instead investigate whether failure to fix bugs can be explained by missing fixing ingredients.
to this end we randomly selected multi edit bugs that have not been fixed by any prior work characteristics shown in tab.
and manually enhanced the meta programs with fixing ingredients of the developer s patch.
we specifically select multi edit bugs that need two or three edits to demonstrate the ability to fix even challenging bugs when the fixing ingredients are available.
in both experiments we run varfix andgenprog otherwise with the same settings as in rq1 same timeouts maximum edits considered search bounds etc .
results.
as expected our results in table columns bugpl hq confirm that varfix can fix more bugs when more fixing ingredients are available whereas genprog benefits from additional fixingingredients to a much lesser degree.
for example varfix can fix instead of just bugs when given more ingredients whereas genprog improves only from to moreover genprog actually fixed fewer smallest bugs when more ingredients were available indicating that search in a larger space is not necessarily more effective.
if comparing the number of patches found rather than the number of bugs fixed we see more variance and fewer consistent trends.
we conjecture that using more edit templates can increase the likelihood of a bug being fixed but can also decrease the number of patches if certain important fixing ingredients are squeezed out of the search space because of bounds on edit combinations and the maximum number of edits considered where some edits may squeeze out others.
our experiments with manually injected fixing ingredients in challenging multi edit defects4j bugs show that varfix can find the developer patch within the search space for all bugs even when the needed edits span multiple methods and classes whereas genprog can only fix of those bugs within the same time limit as shown in table .
interestingly varfix found patches that contain fewer edits than the developer patch for bugs and patches that only use some of the developer ingredients for bugs suggesting that developer patches sometimes contain edits that are not necessary to pass all tests and that parts of developer patches can be sometimes swapped out for other ingredients i.e.
one does not need to have the exact ingredients in the search space.
in summary we find that varfix can effectively make use of extra fixing ingredients in the search space whereas the traditional search strategy in genprog more easily misses patches when searching in larger search spaces.
.
rq4 multi edit to understand the importance of varfix s ability to find multi edit patches we break down found patches by the number of edits.
experiment setup.
for each bug that varfix can fix with highquality patches in rq1 we recorded the minimum number of edits needed for each found high quality patch.
we also count the total number of patches grouped by their number of edits after filtering down to minimized patches cf.
sec.
.
results.
while many bugs can be fixed with a single edit the number of bugs that can be fixed with high quality patches increases significantly if we search for combinations of up to three edits from to in introclassjava and from to in defects4j as shown in tables and .
many of the introclassjava bugs that only varfix can fix require multiple edits which explains why varfix can fix significantly more bugs than existing approaches cf.
tab.
.
for many introclassjava bugs we actually find a much larger number of minimized multi edit patches than single edit patches.
code examples of generated multi edit patches are available in the supplementary material.
overall we find that varfix s search is effective at finding patches with multiple edits and that this ability helps to fix more bugs.
.
rq5 patch ranking finally we explore varfix s ability to filter and rank patches to suggest high quality patches in a large pool of plausible patches.
362esec fse august athens greece chu pan wong priscila santiesteban christian k stner and claire le goues table number of patches generated for introclass using eight edit templates versus three edit templates eight templates three templates varfix genprog subject bug pl bughq pl mini pl hq mini hq bug pl bughq pl mini pl hq mini hq median smallest digits grade checksum syllables each cell contains two numbers the left number uses all eight edit templates and the right number uses only three edit templates.
numbers on the right will be discussed in rq3 fixing ingredients .
bugpl reports the number of bugs fixed by plausible patches.
bughqreports the number of bugs fixed by high quality patches.
plreports the average number of plausible patches.
mini pl reports the average number ofminimized plausible patches.
hqreports the average number of high quality patches.
mini hq reports the average number of minimized high quality patches.
a hyphen indicates we cannot use our symbolic execution engine to evaluate patch quality.
table number of patches generated for math and closure plausible patches high quality patches bug dev genprog varfix genprog varfix edits math math math math math math math math math math math math math math math math math math math math math math math math closure closure closure closure closure closure closure closure closure closure closure closure dev denotes developer patch.
denotes that varfix found the developer patch.
means the developer patch can in theory be generated by our edit templates but the exact fixing ingredients are missing in the meta programs due to inaccurate fault localization.
an empty cell means the developer patch can not be generated by our edit templates.
edits column breaks down varfix s high quality patches second to last column by the number of composing edits from edit to edits.
closure and closure are duplicate.
we show them in this table for consistency with prior work but only count one of them when we report repaired bug counts .
experiment setup.
we experiment with introclassjava patches found in rq1 skipping defects4j patches because in most cases there are too few patch candidates to make ranking interesting or necessary.table analyzed bugs with manually encoded fixing ingredients bug edits methods classes varfix genprog math math math math math closure closure closure closure closure edits denotes the number edits in the developer patch methods the number of methods modified and classes the number of classes modified in the developer patch.
table varfix patches for introclassjava by number of edits patched by minim.
high qual.
patches subject bug hq 1e 2e 3e total 1e 2e 3e median smallest digits grade bughqdenotes the number of bugs that can be fixed by high quality patches.
1e 2e 3e represents one edit two edit three edit patch respectively.
we omit checksum andsyllables as we cannot verify them with symbolic execution due to advanced language features used as discussed in the experiment setup of rq2.
for all introclassjava patches found in rq1 we compare the number of patches before and after minimization.
subsequently we rank the minimized patches to measure where high quality patches are ranked.
among the bugs with at least one high quality patch we analyze the bugs that have at least one plausible but incorrect patch because ranking a pool of all high quality patches is not interesting.
we report the position of the highest ranked highquality patch.
we report ranking results separately for the ranking criteria introduced in section .
results.
as expected the number of minimized patches is much smaller than the number of all patches found often by two orders of magnitude as shown in table .
interestingly patch minimization reduced patch quality for a few patches where the test suite still passes after removing an edit from a high quality patch but that 363varfix balancing edit expressiveness and search effectiveness in automated program repair esec fse august athens greece table patch ranking results excerpt bug mini.
pl.
patchesmini.
hq.
patchesast leven.
state cf line m 1bf7 m 317a m 6e46 s 3b23 .
.
.
more in the supplementary material top top top numbers in the last columns denote the rank of the first correct patch in the ranking ast denotes ranking based on edit distance leven.
based on levenshtein distance state based on state differences in assignments cfbased on branch differences in control flow statements and line based on differences in executed lines.
reduced patch no longer generalizes.
that is an edit is needed to repair the bug that is indistinguishable from the test suite s perspective.
given that these cases are very rare we expect that the benefits of having orders of magnitude fewer patch candidates outweigh the rare drawback of losing a correct patch through minimization.
while none of our ranking heuristics can reliably rank highquality patches always in the first position some heuristics can rank high quality patches in the top patches for most bugs and even within the top patches for many.
ranking based on comparing executed statements similar to prior work seems to be the most promising ranking strategy.
while more research on patch ranking is needed potentially exploring other measures and combinations of measures we argue that having to inspect to patches among hundreds or thousands if not minimized is a promising starting point for a practical setting.
in summary filtering by minimization reduces the number of plausible patches by orders of magnitude without much loss in quality and patch ranking can usually report correct patches among the highest ranked results.
related work we already discussed general trends and tradeoffs in program repair in section focusing on pros and cons of different search strategies.
a recent comprehensive survey provides an excellent overview of the field.
here we focus on details related to technical considerations of our approach.
patch quality.
the tendency of automated repair approaches to overfit patches to the test suite has received extensive attention .
there is little agreement on how to best measure patch quality or correctness.
commonly patches are compared against developer patches but our results show that there are often many different patches for a bug that are all semantically equivalent but often syntactically different from the developer patch.
another common strategy is to evaluate patches with held out tests which we adopt in this work for patches we cannot formally verify against a reference implementation.
multi edit patches.
empirical studies of developer patches have shown that multi edit patches are common .
as discussed while most repair approaches can theoretically find multi edit patches they often struggle to find them in large search spaces.we are aware of only two approaches that specifically target this problem angelix can target multiple suspicious expressions at the same time by using symbolic execution to capture inter location dependencies as constraints but often require multiple suspicious locations to be close for symbolic execution to be effective .
hercules exploits the fact that similar code changes are often made to similar locations termed sibling relationship to pro actively derive similar edits at multiple locations at the same time .
in contrast when variational execution succeeds our approach can efficiently search for multi edit changes even if the locations are scattered and ingredients are different.
patch ranking.
many existing program repair approaches guide the search to favor certain kinds of patches prioritizing those that are more likely to pass all tests or have higher quality .
to rank patch candidates existing approaches exploit different information such as the number of passing and failing tests syntactic and semantic distance to the original program and probabilistic models learnt from existing human patches .
in contrast we rank plausible patches after the search instead of ranking patch candidates during the search.
we additionally use runtime information from test executions for ranking and show that it outperforms edit distance based measures.
closest to our ranking approach jaid also finds multiple plausible patches and rank them but based on fault localization suspiciousness .
our ranking strategy is inspired by xiong et al .
who attempt to classify whether found patches are correct by comparing their execution traces.
conclusions existing approaches to automatic program repair essentially solve a search problem in which a trade off is made between edit expressiveness and search effectiveness.
while most existing work prioritizes one or the other our work uses variational execution to effectively navigate a large search space of diverse fixing ingredients.
we evaluate our work on introclassjava anddefects4j showing that systematically exploring the search space of program repair has numerous benefits comparing to prior work including effectively leveraging fixing ingredients to fix more bugs systematically finding more high quality patches and multi edit patches and comprehensively revealing dynamic information that is useful for distinguishing highquality patches from a larger pool of plausible patches.
we hope that our work can inspire future research on effective search strategies patch ranking patch quality and multi edit patch generation.