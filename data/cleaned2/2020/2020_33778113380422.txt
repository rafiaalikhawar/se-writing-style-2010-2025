deepbillboard systematic physical world testing of autonomous driving systems husheng zhou the university of texas at dallas dallas usa husheng.zhou utdallas.eduwei li southern university of science and technology shenzhen china liw7 mail.sustc.edu.cnzelun kong the university of texas at dallas dallas usa zelun.kong utdallas.edu junfeng guo the university of texas at dallas dallas usa junfeng.guo utdallas.eduyuqun zhang southern university of science and technology shenzhen china zhangyq sustech.edu.cnbei yu the chinese university of hong kong hong kong china byu cse.cuhk.edu.hk lingming zhang the university of texas at dallas dallas usa lingming.zhang utdallas.educong liu the university of texas at dallas dallas usa cong utdallas.edu abstract deep neural networks dnns have been widely applied in autonomous systems such as self driving vehicles.
recently dnn testing has been intensively studied to automatically generate adversarial examples which inject small magnitude perturbations into inputs to test dnns under extreme situations.
while existing testing techniques prove to be effective particularly for autonomous driving they mostly focus on generating digital adversarial perturbations e.g.
changing image pixels which may never happen in the physical world.
thus there is a critical missing piece in the literature on autonomous driving testing understanding and exploiting both digitalandphysical adversarial perturbation generation for impacting steering decisions.
in this paper we propose a systematic physicalworld testing approach namely deepbillboard targeting at a quite common and practical driving scenario drive by billboards.
deepbillboard is capable of generating a robust and resilient printable adversarial billboard test which works under dynamic changing driving conditions including viewing angle distance and lighting.
the objective is to maximize the possibility degree and duration of the steering angle errors of an autonomous vehicle driving by our generated adversarial billboard.
we have extensively evaluated the efficacy and robustness of deepbillboard by conducting both experiments with digital perturbations and physical world case studies.
the digital experimental results show that deepbillboard is effective cong liu is the corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
various steering models and scenes.
furthermore the physical case studies demonstrate that deepbillboard is sufficiently robust and resilient for generating physical world adversarial billboard tests for real world driving under various weather conditions being able to mislead the average steering angle error up to .
degrees.
to the best of our knowledge this is the first study demonstrating the possibility of generating realistic and continuous physical world tests for practical autonomous driving systems moreover deepbillboard can be directly generalized to a variety of other physical entities surfaces along the curbside e.g.
a graffiti painted on a wall.
acm reference format husheng zhou wei li zelun kong junfeng guo yuqun zhang bei yu lingming zhang and cong liu .
.
deepbillboard systematic physical world testing of autonomous driving systems.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
https introduction deep neural networks dnns are being widely applied in many autonomous systems for their state of the art even human competitive accuracy in cognitive computing tasks.
one such domain is autonomous driving where dnns are used to map the raw pixels from on vehicle cameras to the steering control decisions .
recent end to end learning frameworks make it even possible for dnns to learn to self steer from limited human driving datasets .
unfortunately the reliability and correctness of systems adopting dnns as part of their control pipeline have not been formally guaranteed.
in practice such systems often misbehave in unexpected or incorrect manners particularly in certain corner cases due to various reasons such as overfitted underfitted dnn models biased training data or incorrect runtime parameters.
such misbehaviors may cause severe consequences given the safety critical nature of autonomous driving.
a recent example of tragedy is that an uber ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea husheng zhou wei li zelun kong junfeng guo yuqun zhang bei yu lingming zhang and cong liu figure the top subfigure shows an example customizable roadside billboard.
the bottom two subfigures show an adversarial billboard example where the dave steering model diverges under our proposed approach.
self driving car struck and killed an arizona pedestrian because the autopilot system made an incorrect control decision that it didn t need to react right away when the victim was crossing the road at night.
even worse recent dnn testing research has shown that dnns are rather vulnerable to intentional adversarial inputs with perturbations .
such adversarial inputs can be digitally crafted by adding malicious perturbations to the original inputs causing the targeted dnn to output incorrect control decisions.
the root cause of adversarial inputs and how to systematically generate such inputs are being studied in many recent dnn testing works .
while these works propose various testing techniques that prove to be effective particularly for autonomous driving they mainly focus on generating digital adversarial perturbations which may never happen in physical world.
the only exception is a recent set of works which take first step in printing robust physical perturbations that lead to misclassification of static physical objects i.e.
printouts in human face in and stop sign in .
our work seeks to further enhance physical world testing of autonomous driving by enhancing test effectiveness during a realistic continuous driving process.
focusing on generating adversarial perturbations on any single snapshot of any misclassified physical object is unlikely to work in practice as any real world driving scenario may encounter driving conditions e.g.
viewing angle distance that are dramatically different from those in that static single snapshot view.
in this paper we propose a systematic physical world testing approach namely deepbillboard targeting at a quite common and practical continuous driving scenario an autonomous vehicle drives by roadside billboards.
deepbillboard contributes to the systematic generation of adversarial examples for misleading steering angle when perturbations are added to roadside billboards in either a digital orphysical manner.
note that the basic idea can also be directly generalized to a variety of other physical entities surfaces besides just billboards along the roadside e.g.
a graffiti painted on a wall in this work we choose the roadside billboards as our targeted physical driving scenario for several practical considerations billboards are available to rent for advertising everywhere.
attackers who rent billboards can customize their sizes and contents as illustrated in fig.
billboards are usually considered irrelevant or benign to the safety of transportation and there are no strict rules regulating the appearance of a billboard billboards are usually large enough toread by drivers and thus dashcams for cars with different distances viewing angles and light conditions an attacker may easily construct a physical world billboard to affect the steering decision of driving by autonomous vehicles without others noticing e.g.
the actual core adversarial painting can only be a part of the entire billboard while the other parts of the billboard can still look normal e.g.
some bottom text bar showing art museum this saturday .
the objective of deepbillboard is to generate a single adversarial billboard image that may mislead the steering angle of an autonomous vehicle upon every single frame captured by onboard dashcam during the process of driving by a billboard.
to generate effective perturbations a major challenge is to cover a set of image frames exhibiting different conditions including distance to the billboard viewing angle and lighting.
simply applying existing dnn testing techniques to generate digital perturbations upon any specific frame clearly does not work in this case because a realistic driving scene may not incur any frame with same or similar conditions e.g.
inserting sky black holes as done in the recent award winning deepxplore work .
besides the effectiveness of single frame perturbation may be not effective since a mis steering upon a frame may be quickly corrected by the next frame.
to resolve this critical challenge we develop a robust and resilient joint optimization algorithm which generates a printable billboard image with perturbations that may mislead the steering angle upon every single frame captured by the dashcam during the entire driving process.
to maximize the adversarial effectiveness we develop various techniques to minimize interferences among per frame perturbations and design the algorithm towards achieving global optimality considering all frames.
moreover by inputting videos that record the process of driving by a roadside billboard with different driving patterns e.g.
driving speed and route our algorithm can be easily tuned to generate printable adversarial image that is robust and resilient considering various physical world constraints such as changing environmental conditions and pixel printability due to printer hardware constraints.
contributions.
considering such a real world driving scenario and developing a corresponding digital and physical adversarial test generation method yield obvious advantages in terms of test effectiveness the possibility degree and duration of misled steering decisions of any driving by vehicles due to the adversarial billboards can be reliably increased.
our key contributions are summarized as follow.
we propose a novel angle of testing autonomous driving systems in the physical world that can be easily deployed.
we introduce a robust joint optimization method to systematically generate adversarial perturbations that can be patched on roadside billboards both digitally andphysically to consistently mislead steering decisions of an autonomous vehicle driving by the billboard with different driving patterns.
we propose new evaluation metrics and methodology to measure the test effectiveness of perturbations for steering models in both digital and physical domains.
we prove the robustness and effectiveness of deepbillboard through conducting extensive experiments with both digital perturbations and physical case studies.
the digital experimental results show that deepbillboard is effective for 348deepbillboard systematic physical world testing of autonomous driving systems icse may seoul republic of korea various steering models and scenes being able to mislead the average steering angle up to .
degrees under various scenarios.
the physical case studies further demonstrate that deepbillboard is sufficiently robust and resilient for generating physical world adversarial billboard tests for real world driving under various weather conditions being able to mislead the average steering angle error from .
up to .
degree.
to the best of our knowledge this is the first study demonstrating the possibility of generating realistic and continuous physical world tests for practical autonomous driving scenarios.
background and related work dnn in autonomous driving.
an autonomous driving system captures surrounding environmental data via multiple sensors e.g.
camera radar lidar as inputs processes these data with dnns and outputs control decisions e.g.
steering .
in this paper we mainly focus on the steering angle component with camera inputs and steering angle outputs as adopted in nvidia dave .
convolutional neural network cnn which is efficient at analyzing visual imagery is the most widely used dnn for steering angle decisions.
similar to regular neural networks cnns are composed of multiple layers and pass information through layers in a feed forward way.
among all layers the convolutional layer is a key component in cnns which performs convolution with kernels on the output of previous layers and sends the feature maps to successor layers.
different from another widely used dnn architecture recurrent neural networks rnns which is a kind of neural network with feedback connections cnn based steering model makes steering decisions based only on the currently captured image.
in this paper we focus on the testing of cnn steering models and leave rnn testing as future work.
we nonetheless note that deepbillboard can be adapted to apply to rnn testing.
intuitively this can be achieved by modifying the gradient calculation method according to rnn s specific characteristics.
digital adversarial examples.
recent research shows that deep neural network classifier can be tested and further fooled by adversarial examples .
such testing can be performed in both black box and white box settings.
goodfellow et al.
proposed the fast gradient method that applies a first order approximation of the loss function to construct adversarial samples .
optimization based methods have also been proposed to create adversarial perturbations for targeted attacks .
meanwhile the recent deeptest and deeproad techniques transform original images to generate adversarial images via simple affine filter transformations or generative adversarial networks gans .
overall these methods contribute to understanding digital adversarial examples and the generated adversarial examples may never exist in reality e.g.
the rainy driving scenes generated by deeptest and deeproad are still far from real world scenes .
by contrast our work examines physical perturbations on real objects billboards under dynamic conditions such as changing distances and view angles.
physical adversarial examples.
kurakin et al.
showed that adversarial examples when photoed by a smartphone camera can stilllead to misclassification .
athalye et al.
introduced an attacking algorithm to generate physical adversarial examples that are robust to a set of synthetic transformations .
they further created 3d printed replicas of perturbed objects .
the main differences between aforementioned works and our work include previous works only use a set of synthetic transformations during optimization which can miss subtle physical effects while our work can sample from both synthetic transformations and various real world physical conditions.
our work modifies real world true sized objects and our work targets the testing of realistic and continuous driving scenarios.
sharif et al.
presented dodging and impersonation attacks for dnn based face recognition systems by printing adversarial perturbations on the eyeglasses frames .
their work demonstrated successful physical attacks in relatively stable physical conditions with little variation in pose distance angle from the camera and lighting.
this contributes an interesting understanding of physical examples in stable environments.
however environmental conditions can vary widely in general and can contribute to reducing the effectiveness of perturbations.
therefore we choose the inherently unconstrained environment of drive by billboards classification.
in our work we explicitly design our perturbations to be effective in the presence of diverse and continuous physical world conditions particularly large distances angles and resolution changes .
lu et al.
performed experiments with physical adversarial examples of road sign images against detectors and show that current detectors can be attacked .
several more recent works have demonstrated adversarial examples against detection segmentation algorithms digitally .
the most recent work for attacking autonomous driving systems are the works conducted by eykholt and evtimov et al.
they showed that physical robust attacks can be constructed for road signs classifiers and such attacks can be further extended to attack yolo detectors .
our work differs from such works due to the fact that we target attacking steering models by constructing printable perturbations on drive by billboards which can be anywhere and have much more impacts than road signs our proposed algorithm considers a sequence of contiguous frames captured by dashcams with gradually changing distances and viewing angles and seeks to maximize the possibility and the degree of misleading the steering angles of an autonomous vehicle driving by our adversarial roadside billboard and we introduce a new joint optimization algorithm to efficiently generate such attacks both digitally and physically.
generating adversarial pattern .
adversarial scenarios the goal of deepbillboard is to mislead the steering angle of an autonomous vehicle causing off tracking from the center of the lane by painting the adversarial perturbation on the billboard alongside the road.
our targeted dnns are cnn based steering models without involving detection segmentation algorithms.
the steering model takes images captured by dashcam as inputs and outputs steering angle decisions.
we use off tracking distance to measure the test effectiveness i.e.
the strength of steering misleading which has been applied in nvidia s dave system to trigger human interventions.
assume 349icse may seoul republic of korea husheng zhou wei li zelun kong junfeng guo yuqun zhang bei yu lingming zhang and cong liu the vehicle s speed is vm s the decision frequency of using dnn inference is isecond s the ground truth steering angle is and the misleading steering angle is then the off tracking distance is calculated by v i sin .
in a potential physical world attack the speed of the vehicle usually are not controllable by the tester attacker.
thus we use steering angle error which is the steering angle divergence between ground truth and misled steering to measure the test effectiveness.
instead of misleading the steering decision only at a single fixed distance and view angle we consider the actual driving by scenario.
specifically when a vehicle is driving towards the billboard we seek to generate a physical adversarial billboard that may mislead the steering decision upon a sequence of dashcam captured frames viewing from different distances and angles.
the number of captured frames clearly depends on the fps of the dashcam and the time used for the vehicle to drive from the starting position till physically passing the billboard.
considering such a real world dynamic driving scenario yields obvious advantage in terms of attacking strength the possibility and the degree of misled steering decisions of any driving by vehicles due to the adversarial billboards can be reliably increased.
we emphasize that this consideration also fundamentally differentiate the algorithmic design of deepbillboard from applying simpler strategies such as random search average max value pooling different order etc.
applying such simpler methods would improve a misleading angle for a single frame yet lowering the overall objective.
after a few iterations such methods hardly improve the objective.
.
evaluating matrices our evaluating metrics aim to reflect the attacking strength and possibility .
vehicles may pass by our adversarial billboard with different speeds and slightly different angles which may impact the number of image frames captured by the camera and the billboard layout among different frames.
assume x x0 x1 x2 ... xn denotes an exhaustive set of image frames possibly captured by a drive by vehicle with any driving pattern e.g.
driving speed and route then frames captured by any drive by vehicle are clearly a subset x x. our objective is to generate the physical printable billboard which can affect almost every frame in x such that any subset xcorresponding to a potential real world driving scenario may have a maximized chance to be affected.
to meet this objective we define two evaluating metrics denoted m0 m1as follows.
m0measures the average angle error aae for frames in x m0 av g i x f x i f xi where f denotes the prediction result of the targeted steering model x denotes the perturbed frame.
this metric measures the average strength of attacks to the frame super set.
a larger m0intuitively would imply a higher chance and a larger error of misleading the steering angle during the process of driving by the billboard.
m1measures the percentage of frames in x whose angle error exceeds a predefined threshold denoted by .
can be calculated based on the physical driving behavior.
a formal definition of m1isgiven by m1 xi f x i f xi i x x .
for example if we want to mislead a 40mph autonomous vehicle by an off track distance of one meter within a time interval of .
seconds 1then can be calculated as .
.
we mainly adopt m1as an evaluating metric for our physical world case studies as m1can clearly reflect the number of frames that incur unacceptable steering decisions e.g.
those that may cause accidents given any reasonable predefined threshold according to safety stands in practice.
.
challenges physical attacks on an object should be able to work under changing conditions and remain effective at fooling the classifier.
we structure our discussion of these conditions using our targeted billboard classification.
a subset of these conditions can also be applied to other types of physical learning systems such as drones and robots.
spatial constraints.
existing adversarial algorithms mostly focus on perturbing digital images and add adversarial perturbations to all parts of the image including background imagery e.g.
sky .
however for a physical billboard the attacker cannot manipulate the background imagery other than the billboard area.
furthermore the attacker cannot assume that there exists a fixed background imagery as it will change depending on the distance and viewing angle of the dashcam of a drive by vehicle.
physical limits on imperceptibility.
an attractive feature of existing adversarial learning algorithms is that their perturbations to a digital image are often small in magnitude such that the perturbations are almost imperceptible to a casual observer.
however when transferring such minimal perturbations to a real world physical image we must ensure that a camera is able to perceive the perturbations.
therefore there are physical constraints on perturbation imperceptibility which is also dependent on the sensing hardware.
environmental conditions.
the distance and angle of a camera in a drive by autonomous vehicle with respect to a billboard may consistently vary.
the captured frames that are fed into a classifier are taken at different distances and viewing angles.
therefore any perturbation that an attacker physically adds to a billboard must be able to survive under such dynamics.
other impactful environmental factors include changes in lighting weather conditions and the presence of debris on the camera or on the billboard.
fabrication error.
to physically print out an image with all constructed perturbations all perturbation values must be valid colors that can be printed in the real world.
furthermore even if a fabrication device such as a printer can produce certain colors there may exist certain pixel mismatching errors.
context sensitivity.
every frame in x must be perturbed considering its context in order to maximize the overall attacking strength maximizing m0for instance .
each perturbed frame can be mapped 1we note that an autonomous vehicle would likely not run classification on every frame due to performance constraints but rather classify every j th frame and then perform simple majority voting.
350deepbillboard systematic physical world testing of autonomous driving systems icse may seoul republic of korea to a printable adversarial image with a certain view angle and distance.
each standalone frame has its own optimal perturbation.
however we need to consider all frames context to generate a single printable adversarial image that is globally optimal w.r.t.
all frames.
in order to physically attack deep learning classifiers an attacker should account for the above physical world constraints for otherwise the effectiveness can be significantly weakened.
.
the design of deepbillboard we design deepbillboard which generates a single printable image that can be pasted on a roadside billboard by analyzing given driving videos where vehicles drive by a roadside billboard with different driving patterns for continuously misleading the steering angle decision of any drive by autonomous vehicle.
deepbillboard starts with generating perturbations for every frame fiof a given video without considering frame context and other physical conditions.
we then describe how to update the algorithm to resolve the aforementioned physical world challenges.
we finally describe the algorithmic pseudocode of deepbillboard in detail.
we note that it may not be practically possible to construct the exhaustive set of image frames i.e.
x possibly captured by a drive by vehicle with any driving pattern e.g.
driving speed and route .
nonetheless processing a larger number of driving videos will clearly strengthen the testing effectiveness of deepbillboard due to a larger x at the cost of increased time complexity.
the single frame adversarial example generation searches for a perturbation to be added to the input x such that the perturbed input x x can be predicted by the targeted dnn steering model f as max h f x ax where his a chosen distance function and axis the ground truth steering angle.
typically the ground truth in our evaluation is the original prediction steering angle without applying the adversarial billboard which is f x by our definition.
to solve the above constrained optimization problem we reformulate it in the lagrangianrelaxed form similar to prior work arg min l f x ax where lis the loss function which measures the difference between the model s prediction and ground truth ax.
the attacking scenario in this paper can be treated as inference dodging which aims to not being correctly inferred.
joint loss optimization.
as discussed earlier our objective is to generate a single adversarial image that may mislead the steering angle of an autonomous vehicle upon every single frame the dashcam may capture during driving by the billboard.
the appearance of the adversarial billboard may vary when being viewed from different angles and distances.
as a result to meet the objective we need to generate one single printable adversarial perturbation that can mislead every single frame captured during the driving by process.
this is clearly an optimization problem beyond a single image.
it is thus necessary to consider all frames jointly since one modification on the billboard affects all frames.
to this end the problem becomes finding a single perturbation that optimizes eq.
for every imagexin an image set x. we formalize this perturbation generation as the following optimization problem.
arg min i x l f xi pi ax where piis the projection function of printable perturbation into every single frame i. handling overlapped perturbations.
every single frame may generate a set of perturbations which is composed of multiple pixels to be updated on the ultimate printable adversarial image.
perturbations of multiple frames may encounter overlapped pixels which may produce interferences among those frames.
to maximize the attacking strength deepbillboard seeks to minimize the overlapped perturbations among multiple frames by only updating a fixed number of k pixels for each single frame in order.
the kpixels are those that have the most impact on misleading the steering decision.
we assume the final adversarial billboard image covering ndashcam captured frames is composed of mpixels.
kis a value satisfying n k m which helps reduce the overall chance of perturbation overlapping among frames.
for each overlapped pixel we update it by greedily choosing a value that maximizes the objective metric e.g.
m0 .
enhancing perturbation printability.
for the perturbation to work in the physical world each perturbed pixel needs to be a printable value by existing printer hardware.
let p 3be the set of printable rgb triples.
we define non printability score nps of a pixel to reflect the maximum distance between this pixel and any pixel in p. a larger nps value would imply a smaller chance of accurately printing out the corresponding pixel.
our algorithm thus seeks to minimize nps as part of the optimization.
we define the nps of a pixel p as nps p p p p p .
we generalize the definition of nps of a perturbation as the sum of nps values of all the pixels in this perturbation.
adjust color difference under various environment conditions.
for different environmental conditions the observable color of the same pixel belonging to the billboard image may look different in the video captured by a dashcam.
such a difference may impact the adversarial efficacy under different conditions.
in our physical world experiments we pre fill the entire billboard with unicolor p r b .
under a specific environment condition e its actual color shown in camera may become p r b .
based on our preliminary experiments we observe that such color differences of pixels in the same image are almost the same.
to simplify the problem we introduce a color adjustment function adji di p p for each image xito adjust the color difference.
algorithm overview.
the procedure of deepbillboard for generating an adversarial billboard image is illustrated in fig.
.
to generate an adversarial billboard image we first pre fill the billboard with unicolor and paint its four corners with contrasting colors for the purpose of locating the coordinates of the billboard digitally and getting the color adjustment function adji.
then we record video using dashcam and drive by the billboard with different driving behaviors e.g.
different driving speeds and driving patterns along 351icse may seoul republic of korea husheng zhou wei li zelun kong junfeng guo yuqun zhang bei yu lingming zhang and cong liu c0a0 a1b1p0 x xi b a p1 x xi m0 p0 xi x p1 xi x m1 uni color image adversarial patterndnn model adversarial generationjoint gradientb0 d0 d c c1d1p pi figure work flow of deepbillboard to generate adversarial perturbations for contiguous frames where pirepresents the ithframe.
algorithm generating attacks for maximizing m0 require imgs list of images of the same scene require coord list of coordinates of billboards in imgs require iter number of enhance iterations require bsz number of images in a batch require adj list of adjustment for environment factors require dim dimensions of printable perturbation require direction desired misleading direction represents left represents right function generate perturb color init dim pert data zero bsz dim last diff fori in iter do random.shuffle imgs forj in range len imgs bsz do batch imgs pert data.clear forx in batch do grad obj x direction grad domain constrnts grad pert data rev proj grad adj pert data handle overlap pert data atmpt pert pert data s perturb atmpt pert nps ctl atmp per adj atmpt imgs update imgs atmpt pert coord this diff calc diff atmp imgs ifthis diff last diff orrand sathen perturb apply perturb imgs update imgs perturb coord last diff this diff return perturb the road.
then we send the pre recorded videos to our algorithm as inputs to generate the printable adversarial billboard image.
as discussed earlier inputting a larger number of driving videos will clearly strengthen the testing effectiveness of deepbillboard at the cost of increased time complexity.
the pseudocode of our adversarial algorithm is illustrated in alg.
.
our algorithm is essentially iteration based.
in each iteration we first obtain perturbation proposals for a batch of randomly chosen images according to their gradients which reflect the influence of every pixel to the final objective.
we then greedily apply only thoseproposed perturbations that may lead to better adversarial effect.
we apply a sufficient number of iterations to maximize steering angle divergence and the perturbation robustness.
as seen at the beginning of alg.
the inputs include a list of frames in the pre recorded videos a list of coordinates of the four corners in the billboard in every frame number of enhancing iterations batch size a list of color adjustment factors and the dimension of targeted digital perturbation.
as illustrated in alg.
perturb is a printable perturbation matrix that is composed of rgb pixel values line .
we use color init to pre fill the printable perturbation matrix with one unicolor c .
based on our extensive digital and physical experiments using unicolor prefilled matrix may result in better results and faster convergence.
according to our experiments gold blue and green are the most efficient unicolors for our testing purposes.
pert data is a list of matrices which store the proposed perturbations for a batch of images line .
lines to loop through enhanced iterations which aim to maximize the adversarial effectiveness and the perturbation robustness.
at line we randomly shuffle the processing order of captured frames.
the purpose is to avoid quick convergence to a non optimal point at early video frames similar to deep neural network training .
starting from line we loop over all the images which are split into batches.
for each image batch we initialize and clear pert data lines before looping over every single image inside the batch line .
for each image xwithin a batch we calculate its gradient which is the partial derivative of object function to the input image line .
by iteratively changing xusing gradient ascent the object function can be easily maximized.
we note that we can intentionally mislead targeted steering model to steer left or right by selecting a positive or negative value of gradient which is controlled by a direction value of line .
we then apply domain constraints to the gradient line to ensure that we only update the pixels belonging to the corresponding area of the billboard and the pixel values after gradient ascent are within a certain range e.g.
to .
in the implementation as discussed earlier we introduce a parameter kto only apply top kgradient values that have the most impact on adversarial efficacy.
this is to reduce the overlapped perturbations among all images.
different from the saliency map used in jsma which represents the confidence score of xbeing classified into targeted class for the current image we consider the 352deepbillboard systematic physical world testing of autonomous driving systems icse may seoul republic of korea table studied scenes for digital experiments.
scenes img size bb min bb max dave straight1 dave curve1 udacity straight1 udacity curve1 kitti straight1 kitti straight2 kitti curve1 influence to the joint objective function for all images in this scene seeking to maximize the average steering angle difference from ground truth.
after constraining the applicable gradients we project the gradient values for each image xto the proposed perturbations of the batched images line .
adj i.e.
the input list of adjustments for environment factors is used to correct color difference for different lighting conditions.
for example if a pure yellow color becomes then adjis set to be .
when projected to the physical billboard the gradient value should be increased by .
after all images in the batch get their gradients there may exist overlapped perturbations among them.
that is for each pixel corresponding to overlapped perturbations it may have multiple proposed update values for the ultimate printable adversarial example.
to handle such overlaps line we implemented three methods update the overlapped pixels with the max gradient value among proposed perturbations update the overlapped pixels with the sum of all gradient values and update the overlapped pixels with one of the proposed values that has the greatest overall influence to the objective function.
then at line we calculate the proposed update atmpt pert by adding gradients to the current physical perturbationperturb .
after color corrections and non printable score control line the proposed perturbations for the physical billboard are projected to the images according to the coordinates line .
we calculate the total steering angle difference for perturbed images line .
if the proposed perturbations can improve the objective or meet the simulated annealing to avoid the local optimum line indicated by sa we accept the proposed perturbations line and update all images with these perturbations line .
then we record the current iteration s total steering angle divergence and use it as the starting point in the next iteration.
when all enhanced iterations are finished we return the physical perturbation perturb as the resultant output.
we note that although our major goal is to generate physical perturbations the output can be directly patched to digital images as well.
ev aluation in this section we evaluate the efficacy of deepbillboard both digitally and physically for various steering models and road scenes.
.
experiment setup datasets and steering models.
we use four pre trained popular cnns as targeted steering models which have been widely used in autonomous driving testing .
specifically we test three models based on the da ve self driving car architecture fromnvidia denoted as dave v1 dave v2 dave v3 and the epoch model from the udacity challenge .
specifically dave v1 is the original cnn architecture presented in nvidia s dave system .
dave v2 is a variation of dave v1 which normalizes the randomly initialized network weights and removes the first batch normalization layer.
dave v3 is another publicly available steering model which modifies the original dave model by removing two convolution layers and one fully connected layer and inserting two dropout layers among the three fully connected layers.
as the pre trained epoch weights are not publicly available we train it following the instructions provided by the corresponding authors using the udacity self driving challenge dataset .
the datasets used in our experiments include udacity selfdriving car challenge dataset which contains training images captured by a dashboard mounted camera of a driving car and the simultaneous steering wheel angle applied by the human driver for each image dave testing dataset which contains images recorded by a github user to test the nvidia dave model and kitti dataset which contains images from six different scenes captured by a vw passat station wagon equipped with four video cameras.
the dataset used for our physical case studies consists of videos recorded by a tachograph mounted behind the windshield of a driving car for driving by a pre placed roadside billboard on campus.
we use aforementioned pre trained steering models to predict every frame and use the resultant steering angle decisions as the ground truth.
experiment design.
based on our discussion from section .
we evaluate the efficacy of our algorithm by measuring the average angle errors of all frames in a scene both digitally and physically.
for digital tests our scene selection criteria is that the billboard should appear entirely in the first frame with more than pixels since billboards containing less than pixels when being printed out and applied in physical world are too small to be meaningful and useful towards adversarial purposes .
we then randomly select seven scenes that satisfy this criteria from aforementioned datasets and evaluate on all the selected scenes.
the selected scenes in each dataset cover both straight and curved lane scenarios.
since all these datasets do not contain coordinates of billboards we have to label the four corners of billboards in every frame of the selected scenes.
to make the labeling process semi automated we use the motion tracker functionality of adobe after effects to automatically track the movement of billboard s four corners among consecutive frames.
we then perform necessary adjustments for certain frames whose coordinates are not accurate enough.
we list the statistics about all the studied scenes in table where the first column lists the names of scenes the second column shows the number of images in every scene the third to fifth columns indicate the resolutions of images and the min max sizes of billboards in each scene.
in digital tests there is no color adjustment under different environmental conditions.
the final adversarial example is patched into every frame according to the projection function.
then we use the steering models to predict the patched images and compare them against the ground truth steering decisions recorded in the given datasets.
our compared baseline is the inference steering angle for each given trained model.
our approach seeks to maximize the distance from the baseline regardless whether baseline is ground truth or 353icse may seoul republic of korea husheng zhou wei li zelun kong junfeng guo yuqun zhang bei yu lingming zhang and cong liu table average steering angle errors for various scenes.
dave udacity kitti straight1 curve1 straight1 curve1 straight1 straight2 curve1da ve v1 da ve v2 da ve v3 epoch a dave straight1 50angle error frame index b dave curve1 35angle error frame index c udacity straight1 20angle error frame index d udacity curve1 90angle error frame index e kitti straight1 20angle error frame index f kitti straight2 20angle error frame index g kitti curve1 20angle error frame index figur e steering angle error variations along the timeline inference results.
we choose to present results associated with using inference as the baseline because the driving datasets used in experiments may not have ground truth steering angle.
since there exists many physically correct driving behaviors we use statistical methods i.e.
average percentage to test the effectiveness during the entire driving segment rather than within each individual frame.
for physical tests we record multiple videos using a tachograph mounted on a vehicle at various realistic driving speeds.
we place a billboard alongside the road and drive towards the billboard straightly along the central of the road.
we start recording at approximately ft away from the billboard and stop recording once the vehicle passes the billboard.
we perform multiple physical tests under three different weather conditions including sunny cloudy and dusk weather.
the physical test is composed of the following two phases phase i we use a white billboard with its four corners painted as black and then use a golden billboard with four blue corners.
for each board we record and drive along the central of the road with a slow speed of 10mph in order to capture sufficient frames i.e.
training videos .
phase ii we send the input videos to our testing algorithm to automatically generate the adversarial perturbation which will then be pasted on the billboard.
we then drive by the adversarial billboard with normal speed at mph and record the video i.e.
testing video .
we calculate the average angle error compared to the ground truth steering angle for every frame of the video.
we note that strictly speaking a real world test would involve actually autonomous vehicles driving by the billboard to observe 354deepbillboard systematic physical world testing of autonomous driving systems icse may seoul republic of korea the adversarial impact.
unfortunately due to lacking actualy autonomous vehicles to validate deepbillboard in real world settings we took a similar approach applied in the following state of the art autonomous driving research which also has not involved actual autonomous vehicles in the evaluation.
specifically we take videos with different driving patterns as inputs which can be as exhaustive as possible to cover all potential viewing angles at different vehicle to billboard distances.
in the physical world evaluation we tried to pre record as many abnormally driving videos as possible to cover a majority of the possible misled driving scenarios of an actual autonomous vehicle.
such videos have been applied in the adversarial construction training phase.
we show such an abnormally driving video in the following anonymous link this video shows that deepbillboard is able to continuously deviate a car within each frame.
this would mimic one of the many actual autonomous driving scenarios where the vehicle is continuously misled by deepbillboard at each frame i.e.
the misled angle within each frame is similar to the one shown in this video .
.
digital perturbation results the results of digital perturbations are shown in table where each column represents a specific scene and each row represents a specific steering model.
every image in a cell shows a representative frame that has the median steering angle divergence.
for example the image in cell dave v1 udacity scene1 represent the image in udacity dataset scene1 has the average angle error among all frames in the same scene when predicted by dave v1 steering model.
two arrows show the steering angle decision divergence in each image where the blue one is the ground truth and the red one is the steering angle of the generated adversarial examples.
we observe that in all scenes deepbillboard makes all steering models generate observable average steering angle divergences.
specifically deepbillboard misleads the dave v1 model by more than in out of scenes except for kitti straight1 in which the billboard occupies a small space.
dave v2 incurs the largest average divergence more than .
among all scenes.
the test cases of dave v2 model show that even with underfitted model deepbillboard can still greedily enlarge such divergence.
deepbillboard causes the smallest divergence for the dave v3 model .
.
.
the reason is because dave v3 introduces three dropout layers between four fully connected layer and use augmented training data which both contribute to the enhanced robustness and generalization of the trained model.
particularly the adoption of dropout layer which randomly deactivates half of the neurons can cause part of the perturbations on billboards being deactivated thus reducing the efficacy of adversarial perturbations.
we note that the epoch model also adopts dropout layers so its average angle error is also small compared to dave v1 and dave v2 in all scenes.
however epoch does not apply the training data augmentation used by dave v3 which crops the images to train only the road pavement thus the perturbations on the roadside billboard has more influence to the prediction compared to dave v3 resulting in a larger average angle error.
we further show the results on steering angle error along the timeline for each studied scene from the first frame to the last frame where the billboard size increases monotonically among these 600avg angle error iterationy max g max y max y max y sum a 1000avg angle error iterationy max y max y sum y sum b figure convergence of aae w.r.t different parameters.
frames.
the results are shown in fig.
where each sub figure indicates a specific scene the x axis is the indexes of images along the timeline and the y axis is the steering angle error .
we observe that in most scenes the steering angle errors increase when the billboard size increases as indicated by the dave v1 lines shown in fig.
d e f g .
the reason behind is intuitive larger billboards in images may activate stronger perturbations.
on the contrary certain lines do not follow this trend as indicated by fig.
a b c .
for example in fig.
b frames in the middle contribute more steering angle errors for the dave v1 model.
we learn that in such scenarios even though the billboard is quite small in the image it can still lead to large steering angle divergence when applying adversarial perturbations indicating the test effectiveness and robustness of deepbillboard.
.
parameter tuning in this set of experiments we show that how parameter tuning may affect the aae average angle error.
fig.
shows the convergence trend when applying different parameters.
the x axis is the enhanced iteration y axis is aae and the lines represent different parameter settings.
for example line yindicates that the iterations begin with initializing the billboard as yellow y indicates setting the batch size as .
similar settings apply to y and indicates an initialized green billboard.
line y sum indicates that besides using batch size it also uses sum to update gradient instead of the default max pooling.
we observe from fig.
a that starting iterations from yellow is overall better than starting from green in this example.
additionally we observe that two lines behave much better than other lines y max and y sum .
to further explore the tradeoff of batch size and sum max method we conduct another set of experiments which iterate up to iterations whose results are shown in fig.
b .
we observe that two lines representing y max andy sum outperform the other two lines.
what we learn from these two figures are carefully choosing the initial color of the billboard can efficiently increase the converge speed and yield a better results and there is no clear indications showing there exists a better parameter choice between choosing a large or small batch and choosing max or sum to update gradient.
to figure out how the training set affects the convergence and the objective we use the same initial color batch size and overlapping handling y max for different subsets among the total frames in udacity curve1.
the results are shown in fig.
where four subfigures represent a the first frames b the last frames c the frames with even indexes and d all frames respectively.
lines in each sub figure represent different kvalues to be updated.
355icse may seoul republic of korea husheng zhou wei li zelun kong junfeng guo yuqun zhang bei yu lingming zhang and cong liu 1000avg angle error iterationk k k k a 1000avg angle error iterationk k k k k b 1000avg angle error iterationk k k k c 1000avg angle error iterationk k k k k d figure converge over iterations with different parameter tunings a first frames b frames in the middle c interleaving half frames d all frames.
we observe that all lines ascend fast at early iterations and the increase rates drop after around iterations.
the lines in fig.
a converge to a lower aae compared to lines in the other three sub figures.
lines using the last frames clearly achieve better results.
from this observation we learn that the chosen training set does affect the final objective in the sense that images with larger billboards can achieve better results.
additionally a larger k value usually achieves better results and faster convergence in most scenarios except for fig.
a .
the reason is that in this specific scenario the billboard occupies a rather small number of pixels.
thus aggressively increasing the number of updated pixels would cause severe interferences among frames thus leading to lower aae.
from the parameter tuning experiments we learn that choosing images with larger billboard space aggressively updating more pixels would result in faster convergence and better results.
.
physical case study as described in section .
our physical case study is composed of two phases.
specifically for both training and testing videos we start recording at ft far away and stop recording when the vehicle physically passes the billboard.
the driving speed is set to be 10mph for training videos in order to capture sufficient images and the speed for the testing video is 20mph to reflect ordinary on campus driving.
we perform our physical tests on a straight lane without curves under three different weather conditions including sunny cloudy and dusk weather.
to make the training robust we record three training videos through three slightly different routes central left shifting and right shifting.
the billboard used in our experiment has a size of .
we adopt dave v1as the steering model due to its proved efficacy in various real world driving tests .
we define exp aae to indicate the expected average angle error according to the training videos which is the m0metric defined in section .
based on digital perturbations.
we use test aae to indicate the actual average angle error for all images in the testing 120angle error frame indexad left ad rightfigure per frame steering angle error.
video which is the m0metric defined in section .
for physical perturbations.
we also record the m1metric defined in section .
for the test video.
we set the steering angle error threshold to .
since when the driving speed is 20mph such mis steering would cause at least an off track distance of one meter within a time interval of .
second duration of frames for a fps camera which is large enough for causing dangerous driving behaviors as demonstrated by nvidia dave .
we note that our chosen evaluation metrics using average angle error and percentage of large angle error can reasonably reflect the overall possibility and strength of misleading for consecutive frames.
in the physical experiment we calculate the angle error threshold according to the speed which can cause at least one meter off tracking defined as dangerous driving behaviors by nvidia .
the visible results are shown in table where each row shows a sunny scene of a testing video including one video with empty billboard and two videos with adversarial billboards.
the second column shows the printable perturbations.
columns present different distances between the vehicle and the billboard.
we observe that with white billboard the steering angles are almost straight in all distances.
with the first bright adversarial billboard the steering angles turn left to a certain degree on the contrary the second dark adversarial billboard leads steering to the right.
as mentioned in sec.
.
this is controlled by setting gradient flag .
the values of test effectiveness are shown in table where three rows show our experiments under three weather lighting conditions sunny cloudy and dusk weather.
the values in this table reflect steering angle compared to the baseline steering without perturbation.
under each condition the table shows the three aforementioned metrics for two adversarial settings i.e.
left misleading right misleading denoted by the ad left ad right column .
we use two adversarial direction settings mis steering to the left or right to show that deepbillboard can actually control the desired misleading direction.
we observe that two adversarial perturbations both yield relatively large exp aae denoted by exp in the table andtest aae denoted by test for all weather conditions.
for instance deepbillboard yields a left mis leading steering angle of .
degree for sunny weather.
in many cases the test aae value is only slightly smaller than exp aae indicating deepbillboard s efficacy in physical world settings.
the percentage of frames having a mis steering angle larger than the pre defined threshold i.e.
m1 356deepbillboard systematic physical world testing of autonomous driving systems icse may seoul republic of korea table illustration of physical billboard perturbation.
perturbation whiten a adv ersarial left adv ersarial right t able test effectiveness of physical case study cond.ad left ad right exp t est m1 exp t est m1 sunn y .
.
.
.
dusk .
.
.
.
cloudy .
.
.
.
is more than in most scenarios out of and can even reach up to .
overall we detected frames out of frames that exhibit a mis steering angle larger than the safety threshold.
to better interpret the results we also report the per frame steering angle for the physical tests under the sunny condition in fig.
due to space constraints we omit the other two scenarios which show similar result trends where the x axis represents the frame index and the y axis represents the steering angle.
we note again that a positive negative steering angle value indicates a left right steering.
the two curves indicated in this figure represent the testings of applying two adversarial billboards left misleading and rightmisleading .
both two tests are clearly effective.
this trend becomes mores observable at later frames since the billboard occupies larger space in the corresponding frame.
conclusion in this paper we propose deepbillboard a systematic physicalworld testing of autonomous driving systems.
deepbillboard develops robust joint optimization to systematically generate adversarial perturbation that can be patched on roadside billboards to consistently cause mis steering in a scene of multiple frames with different viewing distances and angles.
extensive experiments demonstrate the efficacy of deepbillboard in testing various steering models in different digital and physical world scenarios.
we believe that the basic deepbillboard approach can be generalized to a variety of other physical entities surfaces besides billboards along the curbside e.g.
a graffiti painted on a wall.acknowledgement this work was supported by nsf grants cns ccf cns career and ccf .
it was also supported by the natural science foundation of china grant no.
shenzhen peacock plan grant no.
kqtd2016112514355531 and science and technology innovation committee foundation of shenzhen grant no.
jcyj20170817110848086 .