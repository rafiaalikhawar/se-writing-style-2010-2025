biases and differences in code review using medical imaging and eye tracking genders humans and machines yu huang univ.
of michigan ann arbor mi usa yhhy umich.edukevin leach univ.
of michigan ann arbor mi usa kjleach umich.eduzohreh sharafi univ.
of michigan ann arbor mi usa zohrehsh umich.edu nicholas mckay univ.
of michigan ann arbor mi usa njmckay umich.edutyler santander univ.
of california santa barbara santa barbara ca usa t.santander psych.ucsb.eduwestley weimer univ.
of michigan ann arbor mi usa weimerw umich.edu abstract code review is a critical step in modern software quality assurance yet it is vulnerable to human biases.
previous studies have clarified the extent of the problem particularly regarding biases against the authors of code but no consensus understanding has emerged.
advances in medical imaging are increasingly applied to software engineering supporting grounded neurobiological explorations of computing activities including the review reading and writing of source code.
in this paper we present the results of a controlled experiment using both medical imaging and also eye tracking to investigate the neurological correlates of biases and differences between genders of humans and machines e.g.
automated program repair tools in code review.
we find that men and women conduct code reviews differently in ways that are measurable and supported by behavioral eye tracking and medical imaging data.
we also find biases in how humans review code as a function of its apparent author when controlling for code quality.
in addition to advancing our fundamental understanding of how cognitive biases relate to the code review process the results may inform subsequent training and tool design to reduce bias.
ccs concepts software and its engineering collaboration in software development human centered computing empirical studies in collaborative and social computing .
keywords code review fmri gender eye tracking automation acm reference format yu huang kevin leach zohreh sharafi nicholas mckay tyler santander and westley weimer.
.
biases and differences in code review using medical imaging and eye tracking genders humans and machines.
in permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november virtual event usa association for computing machinery.
acm isbn .
.
.
.
of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
figure we investigate the relationship between code review activities participants and biases.
experimental controls systematically vary the labeled author man vs. woman vs. machine while controlling for quality.
introduction code review is a common and critical practice in modern software engineering for improving the quality of code and reducing the defect rate .
generally a code review consists of one developer examining and providing feedback for a proposed code change written by another developer ultimately deciding whether the change should be accepted.
in modern distributed version control code review often centers around the pull request ormerge request mechanism for requesting that a proposed change be reviewed.
the importance of code review has been emphasized both in software companies e.g.
microsoft google facebook and open source projects .
while code review is widely used in quality assurance developers that conduct these reviews are vulnerable to biases .
in this paper we investigate objective sources and characterizations of biases during code review.
figure shows a high level view of our study does the authorship of a pull request influence reviewer behavior and do men and women evaluate pull requests differently?
such an understanding may help reduce bias to improve developer productivity.
while there are many potential sources of bias in code review including perceived expertise perceived country of origin 456esec fse november virtual event usa yu huang kevin leach zohreh sharafi nicholas mckay tyler santander and westley weimer and reviewer fatigue of particular interest are biases associated with the perceived gender of the author.
these are relevant from a moral perspective e.g.
broadening participation in computing from a process efficiency perspective e.g.
arriving at the correct code review judgment and even from a market perception perspective e.g.
recent scandals involving gender fairness in hiring and development processes .
prior work.
previous studies have shed light on the effects of gender bias in software development by analyzing behavioral data.
for example large scale analyses of github pull request data found that women s acceptance rate is higher than men s when their gender is not identifiable but the trend reverses when women show their gender in their profiles .
similarly another study using behavioral data on github found that women concentrate their efforts on fewer projects and exhibit a narrower band of accepted behavior .
furthermore research has shown that developers may not even recognize the potential effects of biases of code authors when performing code reviews .
such biases may not only decrease the quality of code reviews but also the productivity of software development especially in fields like software engineering that are dominated by men despite gender diversity significantly positively influencing productivity .
moreover not all code changes are generated by humans.
in the last decade there has been a flurry of research into automated program repair apr tools in both academia and industry .
recently apr tools have seen increased adoption among larger e.g.
facebook s sapfix and smaller e.g.
janus manager companies.
however many developers express reluctance about incorporating machine generated patches into their code bases and expert programmers are less accepting of patches generated by apr tools .
in such situations human biases may interfere with the potential business benefit associated with the careful deployment of such automation .
unfortunately research studying how developers perceive and evaluate patches as a function of their provenance i.e.
source or author has been limited.
although the software engineering community has realized the importance of overcoming the negative effects of bias we still lack a fundamental understanding of how bias actually affects the cognitive processes in code review.
this lack of objective basis in understanding bias hinders the development and assessment of effective strategies to mitigate productivity and quality losses from biases in code review.
in the psychology literature researchers have explored the effects of bias in myriad daily life scenarios.
for example behavioral studies have revealed biases in gender and race in fields such as the labor market self evaluations of performance publication quality perceptions and collaboration interest online product reviews and peer reviews .
furthermore psychologists have also adapted medical imaging techniques to investigate the cognitive processes associated with bias in different activities.
in controlled experiments of using medical imaging techniques psychologists have found several specific brain regions that are associated with bias in humans cognitive processes .
these psychology studies provide a model for the investigation of the behavioral and neurological effects of biases in software development tasks.experimental approach.
our experiment involves measuring humans as they conduct code review.
in particular we make use of a controlled experimental structure in which the same code change is shown to some participants with one label e.g.
written by a man but is shown to other participants with a different label e.g.
written by a woman or machine .
beyond measuring behavioral outcomes e.g.
whether or not the change is accepted how long the review takes etc.
we also use functional magnetic resonance imaging fmri which enables both the analysis of neural bases underlying code review activities and also the inference of biases if they exist .
however fmri does not provide significant evidence about participants visual interaction with the code itself.
we build on previous work and address this problem by capturing participants attention patterns and interaction via eye tracking which has been used to understand developers visual behavior in code reading as well as the impact of perceived gender identity in code review .
using eye tracking in combination with fmri allows assessing both neural activity and higher level mental and visual load in human subjects as they complete cognitive tasks.
we desire an understanding of code review that explicitly incorporates gender bias is based on multiple types of rigorous physiological evidence and uses controlled experimentation to provide support and guidance for actionable bias mitigations.
previous studies have considered these goals pairwise but not all simultaneously.
for example there have been behavioral studies in both computer science and psychology on biases e.g.
medical imaging studies of biases in psychology e.g.
eye tracking studies of biases and eye tracking and medical imaging studies of other factors in computer science.
however to the best of our knowledge we present the first experimentallycontrolled study investigating biases in computing activities by measuring multiple neurophysiological modalities.
contributions.
we present the results of a human study involving participants github pull requests three provenance labels man woman and machine fmri based medical imaging and eye tracking.
men and women participants conduct code reviews differently behaviorally the gender identity of the reviewer has a statistically significant effect on response time p .
.
using medical imaging we can classify whether neurological data corresponds to a man or woman reviewer significantly better than chance p .
.
using eye tracking we find that men and women have different attention distributions when reviewing p .
.
in addition we find universal biases in how all participants treat code reviews as a function of the apparent author participants spend less time evaluating the pull requests of women t .
.
participants are more likely to accept the pull requests of women and less likely to accept those of machines p .
.
even when quality is controlled participants acknowledge a bias against machines but do not acknowledge a gender bias even as evaluation and acceptance differ .
we also make our dataset available for analysis and replication.
457biases and differences in code review using medical imaging and eye tracking genders humans... esec fse november virtual event usa background and related work in this section we provide background on code review as well as relevant material on bias medical imaging eye tracking and automated program repair.
.
code review change based code review is one of the most common software quality assurance processes employed in modern software engineering .
prior work has studied the mechanisms and factors behind acceptance or rejection of pull requests such as transparency for distributed collaborators of large scale projects socio technical associations and impression formation .
while such post factum studies advance our understanding of code review they do not provide first hand observation of the decisionmaking process involved.
other studies have used medical imaging or eye tracking methods to shed some light on the cognitive process associated with code review cf.
section .
.
in this paper we use both fmri and eye tracking to provide a more granular understanding of the cognitive process behind the code review by observing both the reported and measured biases on carefully labeled stimuli.
.
medical imaging and eye tracking for se broadly there is significant interest in using physiological measurements such as medical imaging or eye tracking to augment behavioral e.g.
did you accept this patch?
and self reported e.g.
what influenced you?
data with more objective assessments.
functional magnetic resonance imaging fmri is a non invasive popular high fidelity medical imaging technique .
fmri admits modeling and monitoring of neurological processes by observing the relative change in neuronal blood oxygen flow the hemodynamic response in the brain as a proxy for neural activity .
while fmri has a rich history in the field of psychology its presence in software engineering has been much less pronounced.
following pioneering work by siegmund et al.
about a dozen studies in major software engineering venues have used fmri to investigate software engineering activities .
we follow this line of work leveraging fmri to investigate bias in code reviews.
fmri studies analyze differences in time series data collected while participants complete a cognitive task e.g.
code comprehension decision making .
for example brain activity for a participant at rest can be compared against that participant s brain activity while completing a task.
so allows isolating confounding sources of brain activity e.g.
motor cortex activity from moving the lungs to breathe .
fmri study design requires careful consideration as brain activity is inferred from blood oxygenation over time which is an inherently noisy signal.
when a region of the brain is engaged in a cognitive activity it consumes more oxygen.
however the body s physiological response to increased activity is delayed for a brief period of time this hemodynamic lag is wellunderstood and modeled using the hemodynamic response function .
brain activity can be compared to determine when a brain region is implicated in a cognitive task.
modern eye tracking is unobtrusive and provides a reliable recording of eye gaze data .
eye trackers capture a participant s visuospatial attention in the region of highest visual acuity fovea .
visual attention triggers the mental processes required for comprehending and solving a given task while cognitive processes guide the visual attention to specific locations.
thus by providing a dynamic pattern of visual attention eye tracking offers useful information to study the participant s cognitive processes and workload while performing tasks .
the data recorded consists of a time series of fixations stable state of eye movement lasting approximately 300ms and saccades rapid movement between fixations lasting approximately 50ms .
cognitive state is typically inferred from a combination of fixations saccades pupil size variation blink rates and paths of eye movement over a visual stimulus .
researchers usually define areas of interest aois within a stimulus eye tracking data can then be used to measure when and for how long a subject s eyes focus on a specific area.
a handful of eye tracking studies investigated the viewing strategies of developers while performing a code review task.
uwano et al.
conducted a code review experiment of c programs to analyze the gaze patterns of developers performing the task.
they reported that a complete scan of the whole code helps students to find the defects faster.
sharif et al.
replica ted uwano et al.
s study and reported the same results while discussing the impact of expertise.
in the same vein begel et al.
performed an eyetracking study with professionals working on code reviews to detect suspicious code elements while reporting similar findings of code reading visual patterns.
ford et al.
studied the influence of supplemental technical signals such as the number of followers activity names or gender on pull request acceptance via an eye tracker.
we follow practices established by ford et al.
in our study however we present a combination of behavioral medical imaging and eye tracking measurements.
in our study we measure how participants review proposed code changes in pull requests and the faces of their authors.
this paper is the first study to employ both fmri and eyetracking to observe potential bias in code review.
conversely while there have been multiple studies in the field of software engineering dealing with bias none have employed two psychophysiological modalities to achieve their goals.
.
gender biases and differences previous studies have found that the field of software engineering has very low participation from women .
this is in spite of multiple studies that have found a positive correlation between team diversity and team performance in this field .
several candidate explanations for low participation among women have been proposed in multiple studies for example women in software engineering and more generally in male dominated fields tend to see more criticism on the quality of their work more rejection of work more harassment in the workplace lower chances of promotion and more ridicule for both success and failure than men .
while there has been extensive research into the measurement of and the social causes for these biases there has been no research into the psychological basis behind code review decisions.
because early detection of defects has been shown to provide super linear cost savings over the lifetime of software we seek to avoid potential bias on behalf of the reviewer to make code review as effective as possible.
our 458esec fse november virtual event usa yu huang kevin leach zohreh sharafi nicholas mckay tyler santander and westley weimer study contrasts the neurological patterns associated with subjective developer judgments of pull requests.
.
trust and automated program repair automated program repair apr procedurally generate bug fixes for existing source code.
while a significant amount of research has focused on techniques efficiency and quality concerns for apr see for surveys we focus attention on human judgments of trust in machine generated repairs.
existing work has investigated the human trust process in automation covering various aspects such as analyzing the links between user personality and perceptions of x ray screening tasks or personal factors in ground collision avoidance software .
however little research has investigated apr from human factors perspectives .
ryan et al.
found inexperienced programmers trust apr more than human patches.
fry et al.
found that there is a mismatch between what humans report as being critical to patch maintainability and what is actually more maintainable.
monperrus et al.
employed a bot called repairnator to propose candidate patches to compete with patches produced by humans in a continuous integration pipeline.
kim et al.
leveraged common patterns to generate candidate patches targeting specific types of bugs finding that human developers view these pattern based candidates as acceptable but did not compare acceptability against a control group of humanwritten patches for the same set of bugs.
long et al.
learned models of correct patches by examining previously accepted realworld patches though without a corresponding human study of acceptability.
in this paper we examine the reported and measured biases toward patches of controlled quality labeled as generated by either machine or human developers.
experimental methodology we present a human study of participants.
in our experiment every participant underwent an fmri scan and eye tracking simultaneously while completing code review tasks.
the eye tracker is integrated into the fmri machine and two sets of fmri safe buttons were positioned in each of the participant s hands to record inputs.
in this section we discuss the recruitment of our participants the preparation of our code review stimuli the experimental protocol and our fmri and eye tracking data collection methodology.
all of our de identified data are available at umich.edu weimerw fmri.html.
.
participant demographics and recruitment table summarizes demographic information for our participant cohort.
we recruited undergraduate and graduate computer science students at the university of michigan the study was irb approved.
we required participants to be right handed with normal or corrected to normal vision and to pass a safety screening for fmri.
in addition we required participants to have completed data structures and algorithms undergraduate courses.
participants were offered cash incentives and scan data supporting the creation of 3d models of their brains upon completion.table demographics of the participants in our study.
demographic number of participants total version i version ii men women undergraduate graduate .
materials and design participants underwent an fmri scan and eye tracking during which they completed a sequence of code review tasks.
more specifically a single code review task consisted of evaluating an individual pull request and deciding whether to accept orreject the proposed changes.
participants were shown a sequence of pull requests adjusted to fit the fmri s built in monitor.
the technical contents of the pull requests e.g.
the code change context and commit message were taken from historical github data the identifying information e.g.
purported names and faces of developers was experimentally controlled.
we designed the code review stimuli following the best practices in previous fmri research in software engineering each code review stimulus consisted of a loading image that displayed an author profile followed by the corresponding pull request.
each loading image was presented for seconds and each pull request page was presented for seconds.
a red cross fixation image randomly ranging from seconds was presented between code review stimuli.
pull requests in our study we included real world pull requests in total from open source c c projects on github.
these pull requests consisted of code review stimuli adopted from a previous fmri study conducted by floyd et al.
and pull requests obtained from the top starred c c projects on github in february .
for each of the github projects we requested the most recently committed pull requests on february retaining that contained no more than two files with changes fewer than lines of changes to fit the fmri monitor and at least one c c file being changed.
finally we randomly selected pull requests from different github projects that meet the filtering requirements.
the pull requests have an average of .
lines of code .
and an average of .
lines of changes .
.
author profile pictures we used human photos from the chicago face database which are controlled for race age attractiveness and emotional facial expressions.
to avoid bias from other variables of human faces we randomly selected pictures each for white women and men between and years old with neutral emotional facial expressions and average attractiveness xattractiveness .
then we conducted equivalence hypothesis tests of age and attractiveness between the men and women picture sets.
both tests were significant p .
using the x bound which indicated there was no significant difference between the women s and men s pictures with respect to age and attractiveness.
code review stimuli construction we designed two versions of code review stimuli in this study.
each version contained 459biases and differences in code review using medical imaging and eye tracking genders humans... esec fse november virtual event usa code review tasks which were constructed with the selected pull requests human photos and a computer avatar examples shown in figure .
in version i we randomly paired the pull requests and author profile pictures so that the final set of code review tasks contained pull requests labeled as being written by women pull requests written by men and pull requests generated by machines automated repair tools .
then in version ii we relabeled all the pull requests assuring that each received a different author label than in version i while preserving a split.
for example a pull request paired with a woman s picture in version i would be paired with a man s picture or the computer avatar in version ii.
this two version approach supports our experimental control.
no single participant is shown the same patch twice.
however across the entire experiment each patch pwill be constructed with two different author labels and shown once to all participants.
for example participant a will review patch pwith a man author while participant b will review pwith a woman author.
since the technical content of patch premains constant and only the label changes given enough samples differences in responses to patch pcan be attributed to differences in the labels.
each code review task started with a second loading image that briefly introduced the purported author shown in figure 2a .
the loading image also showed a grayed out area indicating that the author s name affiliation and title were omitted for privacy protection.
participants were then presented with the pull request contents for seconds similarly the author s name was grayed out .
an example of a code review stimulus is shown in figure 2b.
on the bottom right corner of each code review stimulus we displayed an indicator image to remind participants of which finger buttons to press to accept or reject the current pull request.
this stimulus structure is broadly similar to that used by ford et al.
.
.
experimental protocol we recruited participants via email lists and in class invitations.
candidate participants were required to complete an fmri safety screening e.g.
age between and right handed correctable vision etc.
.
each participant was also required to complete a pre scan survey to assess minimum coding competence.
we split participants into two approximately equally sized groups of men and women.
participants in each group received either the version i or version ii stimuli.
table summarizes demographic information for each group.
participants gave informed consent and could withdraw from the study at any time.
scans required minutes.
pre scan surveys after participants elected to participate in the study we first collected basic demographic data sex gender age cumulative gpa and years of experience .
we also administered a short programming quiz to assess basic c c programming skills.
participants could only proceed with the study if they answered all the questions in the programming quiz correctly.
training we showed each participant a training video explaining the study design and purpose.
because many view gender bias as a moral or social issue we expect that telling participants that gender bias was being studied would influence their behavior .
thus by design we deceptively described this study only as understanding code reviews using fmri and involving only code reviews a example loading image.
b example code review stimulus.
figure examples of code review stimuli including a loading image top shown for seconds before a pull request with author profile picture bottom .
from real world software companies.
we claimed the researchers had merely adjusted the stimuli presentation to fit the fmri environment.
we told the participants that the goal of this study was to understand how programmers think when deciding to accept or reject a pull request.
we explicitly elided any mention of author gender or provenance as a basis for evaluating pull requests.
per irb regulations this deception required a formal debriefing session upon completion of the experiment to explain the true motivation of the study.
fmri scan after consenting participants underwent an fmri scan during which they completed four blocks of code review tasks.
additionally we used an eye tracking camera to record gaze data.
each block contained randomly ordered code review tasks and dummy stimuli for eye calibration that were presented at the beginning and middle of a block.
for each code review task participants were asked to review the pull request as a real world software developer and use the fmri safe buttons positioned in their hands to provide a binary decision accept or reject that pull request.
post scan surveys after the fmri scan participants were asked to take an implicit association test iat .
such assessments are widely used in both psychology and engineering for investigating implicit relative associations between liberal arts and women and between science and men .
then participants finished a paper based post survey regarding the experiment see section .
.
460esec fse november virtual event usa yu huang kevin leach zohreh sharafi nicholas mckay tyler santander and westley weimer debriefing after completing the experiment we formally debriefed participants about the true motivation of the study.
in particular we disclosed to each participant the nature of the experiment was to evaluate gender based biases and that in fact the author identity information associated with each pull request did not correspond to actual authors.
additionally we explained that knowing the nature of the experiment a priori might introduce social desirability bias .
we conducted a correlation analysis between psychology measures from pre scan surveys i.e.
ses data iat results from postscan surveys behavioral data eye data and brain activity.
while no simple correlations survived a significance test p .
we report other significant findings in section .
.
data collection fmri acquisition mri data were acquired with protocols ensuring high spatial and high temporal resolution.
we summarize the details e.g.
for the purposes of replication and meta analysis but generally attest that the scanning measurement hardware and steps align with contemporary best practices .
all scans were conducted on a 3t general electric mr750 scanner with a channel head coil at the functional mri laboratory at the university of michigan.
first high resolution anatomical scans were collected with a t1 weighted spoiled gradient recall spgr sequence tr .
ms t e ms ti ms fa slices mm thickness .
an estimate of magnetic field homogeneity was then acquired using a spin echo fieldmap tr ms t e ms .
mm slice thickness .
all four subsequent task runs employed a t weighted multiband echo planar imaging sequence tr ms t e ms fa acceleration factor with whole brain coverage over slices .
mm3isotropic voxels or three dimensional pixels .
eye tracking acquisition we used an mri compatible avotec re eye tracker to monitor and track participants eye movements while undergoing an fmri scan.
using a slide projector and a galvanometer driven mirror stimuli were back projected onto a screen on top of the head coil.
the mirror reflected the picture of a computer screen with a resolution of 1920x1080 with fonts sized to approximately pixels in height.
participants viewed the stimuli via a mirror while supine and a second mirror reflected images of the eyes to the eye tracker installed at the head end of the scanner.
modeling approach in this section we describe the mathematical modeling applied to our measurements.
key considerations include accounting for noisy physiological data correcting for multiple comparisons i.e.
avoiding spurious conclusions resulting from repeated analysis attempts and statistical significance.
.
fmri anaylsis preprocessing functional mri data require careful preprocessing prior to statistical analysis these procedures correct systematic sources of noise in the signal e.g.
due to head motion and spatially align brains to a standardized anatomical space.
here we implemented a robust preprocessing pipeline using the statistical parametric mapping spm12 software in matlab.
first we usedthe retroicor technique to remove signal confounds associated with cardiac and respiratory noise.
we then slice time corrected the blood oxygen level dependent bold timeseries to account for minor differences in the relative timing of signal acquisition within a tr i.e.
the ms window during which the whole brain is sampled .
images were then realigned to correct for head motion during the scan and geometric deformations due to motion and magnetic field inhomogeneity were unwarped using data from the fieldmap sequence.
finally we skull stripped the high resolution anatomical image coregistered it with the functional data and spatially normalized all images to the standard mni152 template.
first level analysis task related changes in bold activity were assessed on a within subject basis using the general linear model glm .
for each of the four scanning runs we specified regressors corresponding to the author prime i.e.
the 5s loading screen preceding each pull request and the code review block pull requests with author labels separated by author identity e.g.
man prime and man pr .
this yielded six event types per scanning run with review block durations defined by the participant s response time.
the design matrices were convolved with the canonical hemodynamic response function hrf and data were high pass filtered 128s to remove low frequency noise.
model parameters were estimated using restricted maximum likelihood reml with robust weighted least squares rwls this technique ensures maximally unbiased parameter estimation by first estimating the residual noise variance associated with each image and subsequently re weighting scans by a factor of variance.
thus noisy images e.g.
those contaminated with motion artifact are given less influence in the model.
following model estimation it is necessary to compute contrasts in brain activity task related changes in the bold signal can only be understood relative to other conditions in the experiment.
a contrast is therefore simply a subtraction of the average activity associated with any two stimulus types a b also commonly represented as a bto identify regions showing greater activity in condition aversus condition b .
here we generated contrasts for all pairwise comparisons between author prime and code review conditions.
for example womanprime manprime andwomanpr manpr .
in subsequent analyses however we focus on the womanpr manpr contrast because it represents a direct comparison in brain activity related to author gender note that the reverse manpr womanpr is symmetric about zero and therefore it would only flip the sign of the estimated parameters in our machine learning model notchange the fit or the results .
these contrast maps for each participant were smoothed with a mm3full width at half maximum fwhm gaussian kernel prior to group level analysis.
gaussian process classification to test the hypothesis that men and women participants differentially process code written by women versus men we implemented a multivariate pattern analysis using gaussian process classification gpc .
machine learning techniques such as gpc can be more powerful than conventional mass univariate analyses because they harness the multivariate nature of fmri data rather than estimating voxel by voxel models of differences in brain activity requiring conservative corrections for multiple comparisons gpc considers whole brain patterns of activity that may distinguish between groups or stimulus categories.
461biases and differences in code review using medical imaging and eye tracking genders humans... esec fse november virtual event usa for this analysis we used the gaussian processes for machine learning gpml software v3.
in matlab.
the details of our approach follow floyd et al.
s previous use of gpc in a software engineering context .
in short the extremely high dimensionality of fmri images tens of thousands of voxels requires that data be compressed into a feature space .
we used a simple linear kernel whose elements indicated the degree of similarity the dot product between all pairs of images.
a key advantage to the linear kernel as opposed to nonlinear methods such as the radial basis function is the ability to project model hyperparameters back into the original data space yielding a spatial representation of the decision function i.e.
brain regions where greater activity pushes the classifier towards predicting man or woman .
classification is ultimately a two step procedure the model is first trained to identify patterns that distinguish between men and women participants and performance is then tested using a new image without a class label.
we therefore implemented a leave one out cross validation scheme where participants were iteratively removed from the training data models were fit and a predicted class was obtained for the left out participant.
this yields a percent classification accuracy for each group and the average balanced accuracy bac of the classifier on the whole.
to determine whether performance was significantly greater than chance we ran iterations of nonparametric permutation testing in this procedure class labels were randomly permuted the entire cross validation scheme was performed and classification accuracies were recorded to build empirical null distributions for classifier performance.
performance is considered significant if the true model outperformed the random models more than of the time.
.
eye tracking analysis preprocessing preprocessing eye tracking data includes removing outliers and fixing offsets.
an offset is the difference in the location of a sampled gaze point and its true coordinates offsets grow when the participant s head falls outside the range of camera or as a result of calibration deterioration over time.
we use ogama1 to manually identify horizontal and vertical offsets by replaying the eye gaze data.
if the offset is the same for all gaze samples of the stimulus then we correct it by shifting them all.
when this is not the case we exclude outlier captured data from the analysis.
we end up obtaining a complete data set for out of participants.
this drop out rate while high agrees with the literature for eye tracking data recorded by fmri pre installed eye trackers it is difficult to avoid noise when conducting fmri scans and eye tracking simultaneously.
aoi and metrics anarea of interest aoi corresponds to when and for how long a subject s eyes focus on a specific area.
following the guidelines of goldberg and helfman for defining aois in terms of size and granularity we manually divide every stimulus into four two dimensional rectangular aois pull request message code author picture and indicator image .
the aoi sizes are identical across all stimuli and they are always present on screen.
the pull request message aoi is provided by the author of the pull request to present some information about the proposed code i.e.
a commit message .
the code aoi presents the proposed code changes visually i.e.
as a diff while the author picture and indicator image aois display the author of the pull request and how to use two fmri safe buttons respectively.
we use the following standard metrics to investigate the impact of provenance on participants cognitive load and problem solving strategy.
a problem solving strategy models attention distribution and navigation trends over time throughout a task.
the fixation count indicates the number of attention shifts required to complete the task .
fixation counts often correlate highly with the time spent on a task.
the fixation time is the total duration of all the fixations on an aoi or the stimulus.
longer fixation time indicates either a relatively high level of interest or difficulty in extracting information and an increased strain on the working memory .
the saccade length indicates the distance that the eye travels .
larger saccades indicate more meaningful cues while comparing aoi as attention is drawn from a distance .
results and analysis we consider the following research questions rq1.
how do the identities of code reviewers and authors change or bias the code review process?
rq2.
can we classify the gender identities of code reviewers based on patterns of brain activity?
rq3.
can we differentiate the gender identities of code reviewers based on their visual attention patterns?
rq4.
how do self reports of the role of identity in code review align with reality?
we make our de identified dataset behavioral data fmri scan data eye tracking data and survey data available for analysis and replication at .
rq1 behavioral differences we examine how code review behaviors response times and acceptance rates change as a function of the identities involved using behavioral data from participants.
first to mitigate false positives we built a linear mixed effects model lmm to investigate the joint effects of pull request author and participant identities on response times rt .
here we use the notation rta w oman to refer to the response time for a pull request purportedly authored by a woman and rtp man to refer to the response time for a pull request reviewed by a man participant.
in this model we treated individual participants as random effects and the authors and participants identities as fixed effects.
we employed a contrast based analysis women participants and machine authors were used as the reference levels these baselines were chosen by lmm by default and it does not affect the analysis results .
we find that both the identities of reviewers participants and pull request authors have a significant effect on response time participants identities b .
se .
ci t .
authors identities b .
se .
ci t .
.
based on the fixed effects results from the linear mixed effect model we further investigated the relationship between response time and participants and authors identities.
first we used 2one participant did not complete the scan due to physical discomfort.
462esec fse november virtual event usa yu huang kevin leach zohreh sharafi nicholas mckay tyler santander and westley weimer figure normalized mean weight map for participant gender classification using the womanpr manpr contrast.
when there is stronger activity for woman authored pull requests in hot brain regions the classifier is pushed towards predicting men participants more activity in cool brain regions pushes the classifier towards predicting women participants.
shapiro wilk tests to confirm the response time did not follow a normal distribution p .
we thus used the mann whitney u test to assess the relationship between response times and identities in code review.
our results show that all participants spent significantly less time on pull requests that were written by women rta w oman .8s rta man .7s rta machine .7s p .
.
furthermore women reviewers spent significantly less time on all pull requests than men rtp woman .5s rtp man .1s p .
.
comparing among woman man and machine author labels the effect size is large all rank biserial r .
.
we also examined the relationship between the acceptance rates and identities using pearson s chi squared test for significance.
we found that machine written pull requests have a lower acceptance rate .
comparing to man written .
and woman written pull requests .
2 d f n p .
.
the gender bias magnitudes measured here are in line with previous work e.g.
and on average human are less likely to accept pull requests labeled as written by machine.
the effect size of author labels on acceptance rate is small all cramer sv .
which aligns with observations in previous studies on gender biases in code reviews .
men and women conduct code reviews differently behaviorally the gender identity of the reviewer has a significant effect on response time p .
.
universal biases exist all participants spend less time evaluating the pull requests of women t .
and all participants are less likely to accept the pull requests of machines p .
.
.
rq2 neurological differences we use multivariate pattern classification to determine whether men and women participants exhibit differential neural responses to woman vs. man authored pull requests i.e.
the contrast in brain activity for womanpr manpr .
thirty six participants fmri data is included in this analysis see section .
.
following cross validation and nonparametric permutation testing the classifier indeed distinguished between men and women participants significantly better than chance bac .
p .
.
this was primarily driven by the ability to accurately identify women participants accwomen .
p .
while identification of men participants was similarly high after cross validation accuracytable pair wise gender comparisons of eye gaze data using non parametric wilcoxon test .
for fixation count fixation time fixation rate and saccade length.
significant results p .
are bolded.
mean standard deviation women men p fix.
count .
.
.
.
.
fix.
time s .
.
.
.
.
fix.
rate .
.
.
.
.
sacc.
length px .
.
.
.
.
was nonsignificant after permutation testing accmen .
p .
.
a spatial representation of the classifier decision function is shown in figure note however that because these are multivariate weights localized spatial inferences cannot be made.
ultimately these results suggest that relative to women participants men show less consistent differences in their responses to woman vs. man authored pull requests.
that is patterns of activity observed in women participants are more similar to one another than men participants are to one another enabling easier identification of women participants when the model is presented with new data.
it is possible to distinguish women and men conducting code review at a neurological level bac .
p .
.
men and women conduct code reviews differently in terms of associated cognitive processes and patterns of neural activation.
.
rq3 visual attention differences we analyze eye movements on two levels globally over the whole stimuli as well as locally with respect to aois.
twenty four participants eye tracking data is included in this analysis see section .
.
we measure fixation counts total fixation times fixation rates and saccade lengths over the whole stimulus.
the fixation rate is the ratio between fixation count and the total fixation time.
as shown in table we observe a higher level of activity for men participants compared to women.
specifically men fixated more frequently and made shorter saccades with regards to the distance traveled when they were looking at stimuli to evaluate the pull request.
we also analyze these metrics according to the author s identity machine man or woman via friedman tests.
no significant effect of author identity was found on these high level metrics in isolation.
however we calculated the metrics mentioned above within each aoi to determine whether a difference exists between the attention distribution of men and women participants while evaluating pull requests.
we used a general align and rank non parametric factorial analysis .
we find that there is a significant interaction between genders f .
p .05for fixation count and f .
p .005for fixation time.
figure shows participants attention distribution across aois.
women participants spent significantly more time analyzing pull request messages wilcoxon test with bonferroni adjustment p 463biases and differences in code review using medical imaging and eye tracking genders humans... esec fse november virtual event usa .
.
.
.
.
.
.
.
women participants men participants author picture code pull request message indicator image figure distribution of fixation times across aois for men and women participants.
women participants put more attention on reading and processing pull request messages and author pictures compared to men.
.
and author picture wilcoxon test with bonferroni adjustment p .
.
these results confirm that aoi relevance varies significantly between men and women participants.
specifically men and women used different patterns of scanning behavior and attention distribution while reviewing code.
we summarize a participant s visual attention using a heat map .
figure displays example heat maps of a man and woman participant analyzing three different stimuli.
these heat maps represent visual activity on a color scale red orange green and blue warmer to cooler colors indicate fixation duration.
intuitively warmer colors indicate locations on the stimulus where a participant focused the most visual attention while evaluating a pull request.
these heat maps indicate men participants employed a more active scanning pattern shorter fixation cooler colors associated with more frequent attention switching.
additionally women spent more time and cognitive effort evaluating pull request messages and author pictures regardless of its identity while men spent more time reading the code.
men and women differ substantially in their visual attention patterns.
previous work has found that gender differences are likely in problem solving activities including programming .
sharafi et al.
also reported different attention distribution trends based on gender and showed that women participants pay more attention to analyzing and ruling out wrong identifiers.
our results are in broad agreement with the findings of beckwith et al.
that men tend to tinker and explore more within an unfamiliar environment and approach the new unknown features earlier than do women.
eye tracking results suggest that men and women participants employ different high level problem solving strategies during code review.
men fixated more frequently p .
while women spent significantly more time analyzing pull requests messages and author pictures p .
.
.
rq4 self reporting and code review in our study all participants provided answers for post scan questions regarding the tasks and their own experience.
to minimize directing participants self reports in any particular direction we employed free response questions.
we summarize the six postsurvey questions here what factors do you check what do you look at how do you check the content when you made decisions in code reviews?
what were the three most important factors in order when you were making decisions in code reviews?
how would you compare the machine generated code changes i.e.
by automated repair tools with the human generated changes?
do you think there are any difference between code written by men and women?
if there were some what might they be?
have you observed or thought about any differences between men and women code reviewers?
as a software developer would you be willing to commit machinegenerated code into your code base?
we conducted a qualitative analysis of participants self report data.
the most commonly reported factors in code review that affect participants decisions were the quality of comments whether the description in comments matched code code readability and code functionality.
these four aspects combined account for of all the reported factors.
thirty five of the participants reported they did not notice any difference between the code written by women and men.
only five out of the participants indicated they believed there were behavioral difference between men and women reviewers e.g.
women can be more descriptive with the comments perhaps men code reviewers will be more skeptical of code written by women and women code reviewers will be more cautious in reviewing code written by men .
only four participants indicated they would consider if a pull request was generated by human or machine.
however more participants reported machine generated pull requests in our study to be worse in overall quality matching intuition and comments occurrences than the other direction occurrences .
indicative quotes from participants are i think the code generated by machine was more confusing and harder to read.
it seemed more complicated than the human generated code.
and machine generated changes are imo less readable a little worse in quality capable in fewer scopes .
without knowing all the pull requests and comments were actually written by human programmers participants expressed negative judgements on those labeled as machine written.
that is although there were no real differences between the pull requests humans held negative attitudes or biases against machinegenerated code.
this aligns with the results in section .
humans are less likely to accept pull requests generated by machine.
similarly though the majority of participants reported they believed there was no difference regarding genders of programmers in code reviews their behaviors displayed significant differences in code reviews see section .
.
although humans exhibit biases in their acceptance rates of identical code labeled as written by human vs. machines section .
464esec fse november virtual event usa yu huang kevin leach zohreh sharafi nicholas mckay tyler santander and westley weimer a a stimulus with a machine author b a stimulus with a woman author c a stimulus with a man authorman participant woman participant figure examples of the visual attention heatmaps for a man participant top row and a woman participant bottom row .
hotter colors indicate regions with more intense visual attention.
more activity is displayed for the men while women on average spent more time and effort analyzing the pull request messages and author pictures.
participant self reports acknowledge the bias against machines but do not acknowledge a gender bias.
when pull request author information changes participants report seeing quality differences where none exist.
.
discussion of results reviewer differences our results suggest that men and women conduct code reviews differently.
we support this claim with three measurement modalities.
behaviorally the gender identity of the reviewer has a statistically significant effect on response time.
using medical imaging we can classify whether neurological data corresponds to a man or woman reviewer.
using eye tracking we find that men and women have different attention distributions when reviewing.
note that our results do notsupport any inferences about whether men or women are more accurate at code review.
regardless of the direction of the bias the code review process overall benefits by identifying and mitigating it .
humans tend to claim no differences between men and women as code reviewers.
however our results indicate the opposite.
despite no overt behavioral differences i.e.
no significant interaction between participant gender and author identity the pattern of brain regions recruited when evaluating woman vs. man authored code significantly distinguished between men and women participants with women participants generally showing more reliable patterns of activity as evidenced by significant classification accuracy for that group .
similarly our analysis of the distribution of visual attention and the intensity of visual processing reveals that men and women participants have different implicit aoi preferences.
while women put more effort into analyzing the pull request messages and author pictures men fixated more on source code.
this finding emphasizes that any a priori assumptions about the importance of different features and various types of information may negativelyinfluence the participants performance.
it may be beneficial to have various sources of information easily accessible to the participants to make an effective judgment without interrupting their train of thought.
in finding statistically significant differences in how men and women participants carry out software analysis tasks our results are broadly in line with previous studies e.g.
.
we note that a recent medical imaging study of code writing did not find any gender differences but did suggest that code reading and writing are distinct neural tasks.
author differences our results suggest that the contributions of women and machines are not held to the same standards as those of men they are accepted at different rates and scrutinized for different amounts of time.
one null hypothesis is that reviewers are simply correctly favoring better patches e.g.
machine patches may be worse or less maintainable .
however our controlled experiment in which patch qualities are actually equal rules out that explanation here.
dual formulations e.g.
women authored pull requests may be of higher quality are also ruled out by our post survey data section .
as well as previous studies .
we thus hypothesize that the observed differences result from systematic biases.
such biases have been previously found in software engineering in general and code review in particular .
in our study we observed that humans are .
more likely to accept woman labeled pull requests than man labeled pull requests.
further they are less likely to accept pull requests labeled as machine generated and humans may hold negative opinions against machine generated code.
these results align with ryan et al.
s findings on trust issues against automated repair tools and other studies on program repair bots .
implications these neurological and eye tracking differences donotimply inborn biological differences.
indeed previous fmri studies on code review using the same classification analysis found such similar differences between experts and novices regardless of 465biases and differences in code review using medical imaging and eye tracking genders humans... esec fse november virtual event usa sex .
this suggests that these observations are more likely attributable to differences in training or feedback.
for example if women are more likely to experience ridicule for failure e.g.
they may logically adopt different strategies for code review than do men because they perceive different penalties for false positives and false negatives.
we view this study as part of a line of work to clarify such biases so that they can be mitigated.
for example follow on work might benefit from investigating which patches and thus which syntactic or semantic properties of code were most and least vulnerable to bias section .
.
similarly if some participants look more at author information section .
a direct measurement of the reduction in bias that occurs when anonymizing names and author pictures is merited cf.
.
threats to validity one threat to validity associated with generality is that our selected stimuli may not be indicative.
we mitigate this by choosing the pull requests randomly from real world open source projects.
similarly many of our participants are undergraduates.
we mitigate this by including a large proportion of graduate students and note that as evaluating the impact of expertise is not the goal of this study using students as participants is more acceptable .
to reduce stereotype threat and social desirability bias and alleviate hypothesis guessing and apprehension we did not inform the participants about the precise goals of the study.
also by minimizing the interaction between our team and participants and analyzing de identified data we mitigate biases associated with learning or using the identities of individual participants.
our research team contained both men and women we conducted a set of pilot studies to help identify biased procedures or results.
to account for conclusion validity we choose well documented eye tracking metrics and analyses as well as well established and previously used fmri analyses .
summary code review is a critical practice in software engineering.
we conducted a study of participants including behavioral eye tracking and medical imaging measurements.
our experiment used historical github pull requests but carefully controlled their author information labels holding quality constant while varying provenance.
we find that men and women conduct code reviews differently in terms of associated visual and cognitive processes and patterns of neural activation.
men and women participants employ different high level problem solving strategies during code review men fixated more frequently p .
while women spent significantly more time analyzing pull request messages and author pictures p .
.
also the gender of the reviewer has a significant effect on response time p .
.
it is possible to distinguish women and men conducting code review at a neurological level bac .
p .
.
we also find general biases when assessing pull requests labeled as written by women or machines.
participants spent less time evaluating the pull requests of women t .
and all participants are less likely to accept the pull requests of machines p .
.
however while participant self reports acknowledgethe bias against machines they do not acknowledge a gender bias.
when pull request author information changes participants report seeing quality differences where none exist.
we hypothesize that these differences in behaviors and outcomes are related to training and feedback but more work remains.
our results shed light on potential sources of bias and the physiological mechanisms and behaviors through which they manifest.
this paper presents the first study to employ both fmri and eye tracking to observe potential bias in code review while controlling for quality.
acknowledgment the authors gratefully acknowledge the partial support of the functional mri laboratory at the university of michigan ann arbor which provided pilot support.
this research was partially supported by a google faculty research award.
we thank our participants for their involvement.
we also thank ian bertram and michael flanagan for their help on data collection.
finally we are indebted to kevin angstadt colton holoday and emerson murphy hill for discussions and comments on earlier drafts.