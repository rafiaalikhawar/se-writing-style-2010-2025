heterorefactor refactoring for heterogeneous computing with fpga jason lau aishwarya sivaraman qian zhang muhammad ali gulzar jason cong and miryung kim university of california los angeles lau dcssiva zhangqian gulzar cong miryung cs.ucla.edu equal co first authors in alphabetical order abstract heterogeneous computing with field programmable gate arrays fpgas has demonstrated orders of magnitude improvement in computingefficiencyformanyapplications.however theuseof suchplatformssofarislimitedtoasmallsubsetofprogrammers withspecializedhardwareknowledge.high levelsynthesis hls toolsmadesignificantprogressinraisingthelevelofprogramming abstraction from hardware programming languages to c c but theyusuallycannotcompileandgenerateacceleratorsforkernel programs with pointers memory management and recursion and require manual refactoring to make them hls compatible.
besides experts alsoneed to provide heavilyhandcrafted optimizations to improve resource efficiency which affects the maximum operating frequency parallelization and power efficiency.
we propose a new dynamic invariant analysis and automated refactoringtechnique called heterorefactor .first heterorefactormonitorsfpga specificdynamicinvariants therequiredbitwidth of integer and floating point variables and the size of recursivedatastructuresandstacks.second usingthisknowledge of dynamic invariants it refactors the kernel to make traditionally hls incompatible programs synthesizable and to optimizethe accelerator s resource usage and frequency further.
third to guarantee correctness it selectively offloads the computation from cputofpga onlyifaninputfallswithinthedynamicinvariant.
on average for a recursive program of size loc an expertfpga programmer would need to write more loc to implementanhlscompatibleversion while heterorefactor automates such transformation.
our results on xilinx fpga show that heterorefactor minimizes bram by and increases frequency by forrecursiveprograms reducesbramby41 throughinteger bitwidthreduction andreducesdspby50 throughfloating point precision tuning.
keywords heterogeneouscomputing automatedrefactoring fpga high level synthesis dynamic analysis permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea copyright held by the owner author s .
publication rights licensed to association for computing machinery.
acm isbn ... .
reference format jasonlau aishwaryasivaraman qianzhang muhammadaligulzar jason cong miryung kim.
.
heterorefactor refactoring for heterogeneouscomputingwithfpga.in proceedingsof42ndinternationalconference onsoftwareengineering seoul republicofkorea may23 icse pages.
introduction in recent years there has been a growing interest in architectures thatincorporateheterogeneityandspecializationtoimproveperformance e.g.
.fpgasarereprogrammable hardware that often exceeds the performance of general purpose cpus by several orders of magnitude and offer lower cost across awidevarietyofdomains .tosupportthedevelopmentof sucharchitectures hardwarevendorssupportcpu fpgamultichippackages e.g.
intelxeon andcloudproviderssupport virtual machines with fpga accelerators and application development frameworks e.g.
amazon f1 .
althoughfpgasprovidesubstantialbenefitsandarecommercially available to a broad user base they are associated with a high development cost .
programming an fpga is a difficult task hence it is limited to a small subset of programmers withspecialized knowledge on fpga architecture details.
to addressthis issue there has been work on high level synthesis hls for fpgas .
hls tools take a kernel written in c c as input and automatically generates an fpga accelerator.
however to meet the hls synthesizability requirement significant code rewriting isneeded.
for example developers must manually remove the use of pointers memorymanagement andrecursion sincesuchcodeis notcompilablewithhls.toachievehighefficiency theusersmust heavilyrestructurethekerneltosupplyoptimizationinformation manually at the synthesis time.
carefully handcrafted hls optimizationsarenon trivialandoutofreachforsoftwareengineers who usually program with cpus .
our observation is that software kernels are often over engineeredinthesensethataprogramisgeneralizedtohandlemore inputs than what is necessary for common case inputs.
while this approachhasnoorlittleimpactontheprogramefficiencyonacpu in an fpga accelerator the design efficiency could be impacted considerably by the compiled size that depends on actual ranges of valuesheldbyprogramvariables theactualsizeofrecursivedata structures observed at runtime etc.
for example a programmermay choose a bit integer data type to represent a human age whose values range from to in most cases.
consider another example where in of executions the size of a linked list is ieee acm 42nd international conference on software engineering icse bounded by 2k however the programmer may manually flatten it to an array with an overly conservative size of 16k.
we propose a novel combination of dynamic invariant analysis automated refactoring and selective offloading approach called heterorefactor toguidefpgaacceleratorsynthesis.thisapproach guarantees correctness behavior preservation as itselectively offloads the computation from cpu to fpga only if the invariant is met but otherwise keeps the computation on cpu.
it also does not require having a representative data set for identifying dynamic invariants as its benefit is to aggressively improve fpga accelerator efficiency for a common case input without sacrificing correctness.
inthisapproach aprogrammerfirstimplementsherkernelcodeinahigh levellanguagelikec c .thensheexecutesthekernelcode on existing tests or a subset of input data to identify fpga specific dynamic invariants.
heterorefactor automatically refactors the kernelwithpointersintoapointerless non recursiveprogramto make it hls compatible and to reduce resource usage by lowering bitwidth for integers and floating points which in turn reduces resource usages and increases the frequency at the fpga level.
we evaluate heterorefactor on ten programs including five handwritten recursive programs three integer intensive programs fromrosettabenchmark andtwofloating point intensiveprograms from opencv .
we generate kernels targeting to a xilinx virtexultrascale xcvu9pfpgaonavcu1525reconfigurable acceleration platform and achieve the following results for recursive programs that are traditionally unsynthesizable heterorefactor refactorspointers andrecursionwith the accesses to a flattened finite size array making themhls compatible.
on average for a recursive program of size175loc anexpertfpgaprogrammerwouldneedto write185 moreloctoimplementanhls compatibleversion while heterorefactor requires no code change.
using atightboundforarecursivedatastructuredepth theresult ingacceleratorisalsoresource efficient anacceleratorwith acommon caseboundof2ksizecanachieve83 decrease in bram and increase in frequency compared to the baseline accelerator with an overly conservative size of 16k.
forintegers heterorefactor performstransparentoptimization andreduces the number ofbits by which leads to reduction in flip flops ff reduction in look up tables reduction in bram and decrease in dsp.
forfloating points heterorefactor automaticallyreduces the bitwidth while providing a probabilistic guarantee for a user specificqualitylossandconfidencelevel.theoptimizedacceleratorcanachieveupto61 reductioninff reduction in lut and decrease in dsp when an acceptable precision loss is specified as 4at confidence level.
in summary this work makes the following contributions traditionally automated refactoring has been used to im prove software maintainability.
we adapt and expand au tomated refactoring to lower the barriers of creating customized circuits using hls and to improve the efficiency of the generated fpga accelerator.
whilebothdynamicinvariantanalysisandautomatedrefactoring have a rich literature in software engineering we designanovelcombinationofdynamicinvariantanalysis automatedkernelrefactoring andselectiveoffloading for transparent fpga synthesis and optimization withcorrectnessguarantee whichisuniquetothebestofourknowledge.
wedemonstratethebenefitsoffpga specificdynamicinvariant and refactoring in three aspects conversion of recursive data structures integer optimization and floating point tuning with a probabilistic guarantee.
heterorefactor ssourcecodeandexperimentalartifactsarepublicly available at background thissectionoverviewsadeveloperworkflowwhenusingahighlevel synthesis hls tool for fpga and describes the types of manual refactoring a developer must perform to make their kernel synthesizable and efficient on fpga.
.
overview of fpga programming with hls modern fpgas include millions of look up tables luts thousands of embedded block memories brams thousands of digitalsignal processing blocks dsps and millions of flip flop registers ffs .
each k input lut can implement any boolean function uptokinputs.anfpgamustbeprogrammedwithaspecificbinary bitstream tospecifyallthelut bram dsp andprogrammable switch configurations to achieve the desired behavior.
fortunately hls has been developed in recent years to aid the translation of algorithmicdescriptions e.g.
kernelcodeinc c toapplicationspecific bitstreams .
specifically hls raises the abstraction of hardware development by automatically generating rtl register transfer level descriptions from algorithms.
generation of fpga specific bitstream consists of a frontendresponsible for c simulationanda backendresponsibleforhardwaresynthesis.inthe frontend afteranalysisofc c code hls schedules eachoperation from the source code to certain time slots clock cycles .
next itallocates resources i.e.
thenumberandtypeofhardwareunits used for implementing functionality like luts ffs brams dsps etc.finally the bindingstagemapsalloperationstotheallocated hardware units.
this frontend process generates an rtl whichis sent to a backend to perform logic synthesis placement and routingtogeneratefpgabitstreams.softwaresimulationisfast however hardware synthesis can take anywhere from a few hours toacoupleofdays dependingonthecomplexityofthealgorithm.
for example even for tens of lines of code hardware synthesis can take hours for our subjects in section .
therefore suchlonghardwaresynthesistimejustifiesthecost ofmanualrewritingofkernelsforoptimizedresourceallocation frequency and power utilization.
in other words this motivates heterorefactor toinvest timein a prioridynamic analysisas opposed to just in time compilation to optimize fpga as frequent iterations of hardware synthesis are prohibitively expensive.
.
refactoring for high level synthesis hls tools aim to narrow the gap between the software program anditshardwareimplementation.whilehlstoolstakekernelcode in c or c a developer must perform a substantial amount ofmanual refactoring to make it synthesizable and efficient on anfpga chip.
such refactoring is error prone and time consuming 494refactoring for hlssynthesizabilitypointer support memory managementrecursion functiondevice host interface efficiency optimizationparallelization optimization for data movement reducing resource consumptionbit width precisionarray size in related work figure overview of refactoring for high level synthesis.
sincecertainlanguageconstructsforreadabilityandexpressiveness inc c arenotallowedinhls .adevelopermusthaveinterdisciplinary expert knowledge in both hardware and software and knowobscureplatform dependentdetails .below wecategorizemanualrefactoringsforhlsintotwokinds synthesizabilityand efficiencyoptimization.inthispaper wefocusonimproving the vivado hls tool from xilinx which is the most widely used fpga hlsin the community althoughour techniques can be easilygeneralizedtootherhlstools suchasintelhlscompiler catapult hls from mentor and cyberworkbench from nec.
.
.
synthesizability.
pointer support.
to transformkernel code intoits equivalent hlssynthesizableversion adevelopermustmanuallyeliminate pointerdeclarationsandusages thereareonlytwotypesofpointers thatarenativelysupportedinhls pointerstohardwareinterfaces such as device memory or pointers to variables.
pointer reinter pretationislimitedtoprimitivedatatypes.arraysofpointersor recursive data structures are strictly forbidden in vivado hls.
memory management and recursion.
because vivado hls hasnocapabilityof memorymanagement functioncallstomemory allocation such as malloccannot be synthesized.
thus developersmustcreateanoverlyconservative large sizedstaticarrayin advance and manage data elements manually.
similarly vivado hlscannotsynthesizerecursions.thus developersmustmanually convert recursions into iterations or create a large stack to store program states and manage function calls manually.
device and host interface.
vivado hls requires a strict description of parameters of the top level function that acts as the deviceandhostinterface.thefunctioniscalledfromthehostandis offloadedintofpga.afunctionparametercanbeeitherascalar or pointer to the device memory with a data size in the power of bytes and a developer must write specific pragmas e.g.
pragma hls interface m axi port input touseaxi4interconnectinterfaceforpassingtheparameternamed inputtothefpgadesign.
.
.
efficiency optimization.
parallelization.
reprogrammable hardware provides an inherent potential to implement parallelization.
such parallelization can be done through pipelining of different computation stages and by duplicating processing elements or data paths to achieve aneffect similar to multi threading.
to guide such parallelization a developermustmanuallywritehlspragmassuchas pragma hls pipeline and pragma hls unroll for suitable loops or must expose parallelization opportunities through polyhedral model based loop transformations .hetero refactor workflow hetero refactor recursive data structure support and optimizationdynamic analysis and software refactoring invariantbased char integer bit width optimizationprobabilistic samplingbased floating point optimizationc c program input data double det double a int n m malloc ... m ... det det m n ... c c programtraditional workflow rewrite by expertsynthesizable fpga code resource efficient fpga code understand algorithmseveral per son month rewrite codeinput data resource efficient fpga a flopoco det flopoco a ap uint n while ... m elemalloc ... array ... push det m n continue restorehere det pop det ... selective offloading to fpga .
bool devicefail false if hostcheck ... hostkernel ... else fpgakernel ... devicefail if devicefail hostkernel ... rose kvasir based invariants detection rose based automatic refactoring figure approach overview of heterorefactor .
optimization of data movement.
accessing of the device memory can be more efficient by packing bits into the width of dramaccessof512bits.tooverlapcommunicationwithcomputation adevelopercouldexplicitlyimplementadoublebuffering technique .tocachedata developersneedtoexplicitlystore them on chip through data tiling batching or reusing .
reducingresourceconsumption.
provisioningmoreprocessing elements or a larger cache will require using more on chip resources limiting the potential of parallelization and data movementoptimizationsbyduplicatingprocessingelementsoradding cache.
a higher resource utilization ratio can lower the maximum operatingfrequencyandconsumemorepower thus itdegrades the performance and efficiency.
besides a resource efficient design is economical as it can to be implemented on a smaller fpga chip.
traditionally developers allocate integers and floating point variables with a fixed size bitwidth large enough for all possible input values or create a static array for the largest possible size.
such a practice may cause wasting on chip resources.
in particular in modernapplicationssuchasbigdataanalyticsandmlapplications whereon chipresourceusageisinput dependent fpgaresource optimization becomes increasingly difficult.
figure1illustratesournewcontributions highlightedwith bold andred relative to the prior hls literature.
there exists many automated approaches for generating device and host interfaces exploring parallelization opportunities 495integer recursive data structure floating pointscollect invariants transformationguard checkingsource c c program refactoring based instrumentation kvasir based instrumentation rewrite memory management monitor malloc failureinput check on host selective offloading program to fpgadata structure shaperecursion depth transformed device program modify pointer accessconvert recursionmodify typemodify operatorassess fp error pre transformed programs with different precisions precision loss from differential execution monitor stack overflowintermediate check on device probabilistic verification offloading to fpga value range unique elements modify integer type figure heterorefactor incorporates three techniques dynamic invariant detection kernel refactoring and selective offloading with guard checking.
its profiling concerns three aspects the length of recursive data structures required integer bitwidth and required floating point bitwidth to meet a specified precision loss.
and optimizing data movement .
but general methods for reducing resource consumption pointer support memory management and recursion support remain as open research questions and no automated kernel refactoring exists yet.
heterorefactor addresses three important scopes of such refactoring transformations converting a program with pointers and recursion to a pointerless and non recursive program by rewriting memorymanagementandfunctioncalls reducingon chipresource consumptionof integer bitwidth and reducingon chip resource consumption by tuning floating point precision.
approach heterorefactor asshowninfigure2 isanovelend to endsolution that combines dynamic invariant analysis automated refactoring andselectiveoffloading forfpga.itaddressesthree kindsofhls refactorings rewriting a recursive data structure to an array of finite size section .
reducing integer bitwidth section .
and tuningvariable widthfloating pointoperations section3.
.all three refactorings are based on the insight that a priori dynamicanalysis improves fpga synthesizability and resource efficiency andthatdynamic input dependentoffloadingcanguaranteecorrectness.figure3detailsthethreecomponentsthatworkinconcert a instrumentation for fpga specific dynamic invariant analysis b source to source transformation using dynamic invariants and c selective offloading that checks the guard condition when offloading from cpu to fpga.
the first two kinds of refactorings followsimilarimplementationforselectiveoffloadingusingaguard condition check described in section .
.
for floating point operations our dynamic analysis provides a probabilistic guarantee that the precision loss is within a given bound.
.
recursive data structure many applications use recursive data structures built on malloc free and recursive function calls.
as mentioned in section .
hls tools have strict restrictions on the types of pointers allowed and do not support memory allocation and recursion.
for example vivaldo hls throws the following error for figure 4a an unsynthesizable type .
this severely limits the type of programs that can be automatically ported for heterogeneous computing.expertfpgadevelopersmanuallyrewritetherecursive data structure into a flattened array to be hls compliant however as they may not know the common maximum size required for the application theyoftenover provisionanddeclareanunnecessarily large size.
they also have to manually convert recursion into loop iterationsandover provisionthestackrequiredforkeepingtrack of program state involved in recursive calls.
heterorefactor uses a source to source compiler framework rose toinstrument code foridentifying thesize of recursive data structures and the corresponding stack depth and performs source to source transformation based on the size.
.
.
refactoring basedinstrumentation.
heterorefactor instruments memory allocation and de allocation function calls e.g.
allocation of a linked list node and adds tracing points at the entry and exit of recursive functions to monitor a stack depth.
heterorefactor then determines the number of elements allocated for each data structure based on the collected sizes.
in figure 4a heterorefactor sets a tracing point at line to record the number ofallocatednodesandanothertracingpointatline16torecordthe released count.
to monitor the recursion depth heterorefactor insertstracingpoints callatthefunctionentrypointand retat thefunctionexitpointofeachrecursivefunction.infigure4a call is inserted before line and retis inserted at line and after line .heterorefactor then maintains a variable stack size for each function which is incremented every time the program reaches callanddecrementedwhenitreaches ret.thehighestvalueattainedby stack size duringexecutionisreportedandusedasthe bound for a flattened array and the corresponding stack.
.
.
refactoring.
heterorefactor isimplementedbasedon rose to rewrite recursive data structures.
it takes c c kernelcodeandthearraysizesandrecursiondepthsfoundviadynamicanalysis andoutputsanhls compatibleversionwithon chipmemory allocation removes all pointers except for those with native 4961struct node node left right int val 2void init node root root node malloc sizeof node 4void insert node root int n int arr 5void traverse node curr 6if curr null return 7visit curr val 8traverse curr left 9traverse curr right 10void top int n int output if pragma hls interface m axi port output if node root init root ... int values insert root values int curr output if traverse root ... free root a original kernel code using pointers and memory allocation.
1bool guard error false 2struct node node ptr left right int val 3struct node node arr 4typedef unsigned int node ptr 5node ptr node malloc size t size 6void node free node ptr buddy allocation 7void init node ptr root root node ptr node malloc sizeof node 9if !root guard error true 10void insert node ptr root int n int arr 11void traverse node ptr curr stack context s traverse stack size curr curr loc while !s.empty context c s.pop goto l c.loc l0 if c.curr null continue visit node arr .
data .val if s.full guard error true return c.loc s.push c s.push curr node arr c.curr .
data .left loc continue traverse left l1 traverse right ... l2 21void top int n int output if bool fail pragma hls interface m axi port output if node ptr root init root ... int values insert root values int curr output if traverse root ... node free root fail guard error b refactored kernel code schematic .
figure example of recursive data structures binary tree.
hlssupport tobeexplainedfurtherunderrule2 andrewrites recursive functions.
the transformation is semantics preserving and consists of the following transformation rules rule1 rewritememorymanagement.toreplacecallsto malloc andfree foreachdatatype wepre allocateanarraywhosesize is guided by instrumentation line in figure 4b .
the per type allocationstrategywithanarrayisbasedontworeasons hlsonly supportspointerreinterpretationonprimitivedatatypes anditcanoptimizearrayaccessesifthesizeofoneelementisknown.foreach node allocation and de allocation we implement a buddy memory system andallocatefromthearray.thebuddymemorysystem requires less overhead and has little external fragmentation making it suitable for fpga design.
we identify all calls to malloc andfree therequestedtypesandelementcounts andtransform themintocallstoourlibraryfunction node malloc line8infigure4b whichreturnsanavailableindexfromthearray.section4.
detailsperformancebenefitsintermsofincreasedfrequencyand reducedresourceutilizationusinganarraysizeguidedbydynamic analysis rather than declaring an overly conservative size.
rule2 modifypointeraccesstoarrayaccess.thereareonlytwotypesofpointers nativelysupported inhls andwedonotneed to convert them into array access.
one is a pointer of interfaces whichwecanidentifybylookinguppragmasinthecode line22in figure 4b .second isa pointerto variables which canbe detected by finding all address of operators or array