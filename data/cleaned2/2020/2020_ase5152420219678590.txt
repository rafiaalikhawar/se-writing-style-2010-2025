distribution models for falsification and verification of dnns felipe toledo dept.
of computer science university of virginia ft8bn virginia.edudavid shriver dept.
of computer science university of virginia dls2fc virginia.edusebastian elbaum dept.
of computer science university of virginia selbaum virginia.edumatthew b. dwyer dept.
of computer science university of virginia matthewbdwyer virginia.edu abstract dnn validation and verification approaches that are input distribution agnostic waste effort on irrelevant inputs and report false property violations.
drawing on the large body ofwork on model based validation and verification of traditionalsystems we introduce the first approach that leverages environ mental models to focus dnn falsification and verification on therelevant input space.
our approach dfv automatically buildsan input distribution model using unsupervised learning prefixesthat model to the dnn to force all inputs to come from thelearned distribution and reformulates the property to the inputspace of the distribution model.
this transformed verificationproblem allows existing dnn falsification and verification tools totarget the input distribution avoiding consideration of infeasibleinputs.
our study of dfv with falsification and verificationtools two dnns defined over different data sets and distinctdistribution models provides clear evidence that the counter examples found by the tools are much more representative ofthe data distribution and it shows how the performance of dfvvaries across domains models and tools.
index t erms neural networks input distribution model verification falsification i. i ntroduction a deep neural network dnn is trained to accurately approximate a partial target function f rn rm.
the domain of definition of f referred to as the data distribution d is typically an infinitesimal portion the full domain d rn .
however much of the recent literature on validation and verification of dnns ignores the partiality of a dnn s definition with significant negative consequences.first existing test generation techniques have been shown to produce a majority of inputs that lieoff of the data distribution .
second white box dnncoverage criteria do not take the distribution intoaccount and this can drive coverage directed test generators offthe distribution and give misleading reports of the coverageachieved .
third faults that are detected for off distributioninputs constitute false reports which can lead to wastedeffort in fault triage localization and fixing.
whereas recent research has begun to explore how to leverage models of the data distribution for testing in this paper we present the first approach to use such modelsto support techniques for dnn verification and falsification aform of property driven validation .
our distribution based falsification and verification dfv approach for dnns draws inspiration from the large body of research exploiting environ mental models of the feasible input domain for software sys tems to focus verification and validation v v .
these mod els are typically built from the system requirements and can beexpressed in a variety of forms e.g.
simulations state machines or logical specifications .
such environment models have become an essential component of validation and verification approaches for software systems and this has led them to be adopted in severaldomains .
to be amenable for v v environment models must satisfy three requirements.
first they must be accurate in defining the set of feasible inputs.
for example for an underapproximatinganalysis e.g.
an underapproximating model is requiredto guarantee feasible counter examples dually an overapprox imating analysis requires an overapproximating environmentmodel.
second they must be generative providing the ability to be executed interpreted or solved so they can be leveragedto generate feasible inputs.
for example generating feasiblecounter examples when verifiers or falsifiers detect propertyviolations .
third for verification they must be amenable to constraint based encoding in a form that can be leveraged by the verification algorithm.
for example for a smt basedverification method e.g.
an environment model mustbe convertible to logical formulae in a supported theory.
forabstract interpretation e.g.
an environment model mustbe convertible to supported abstract domains.
in this paper we adapt the concept of an environment model to support existing dnn verification and falsificationtechniques .
to do this wehave to address the challenge that it is intractable in general tospecify an accurate model of the feasible inputs for a complexdnn like those that process images captured by a forwardfacing camera see figure 3b .
a key insight of this workis that we can leverage the rich body of research that themachine learning ml community has developed for learninggenerative models of the data distribution which we use asenvironment models.
dfv transforms a dnn and a correctness property into a falsification or verification problem focused on the datadistribution in three steps.
first a generative model of thedata distribution for a dnn is trained .
unlike man ually developed environment models for traditional software 36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee v v these environment models are constructed automatically through an unsupervised training process.
the design andtraining of the model of the data distribution can leverageml best practices to produce a suitably accurate model .
second the approach modifies the original dnn to usethe appropriate component of the trained generative model e.g.
the decoder of a variational autoencoder v ae as a setof prefix layers to the dnn under analysis.
this forces allinputs to the dnn to come from the learned data distribution.third the approach reformulates the correctness property overthe input space of the generative model.
dfv supports thereporting of feasible on distribution counter examples whenproperty violations are detected and reporting that specifiedsubsets of the data distribution are free of violations whenverifiers are able to discharge such proofs.
we evaluate dfv on dnns trained to recognize images of clothing and trained to control a drone from imagedata for a range of challenging correctness properties.we find clear evidence that dfv enables existing falsificationand verification techniques to produce counter examples thatare much more representative of the data distribution than arecomputed otherwise both visually and in terms of standardmeasures of similarity.
while scaling of verification tech niques is challenging we also find evidence that distributionmodels can enable them to prove properties over the datadistribution.
building on these promising findings we studyhow varying the architecture of the model and how shiftingbetween different families of generative models impacts theeffectiveness of the technique.
our results can be used to guidethe development of models to support dfv.
the primary contributions of this work are the formulation of the first model based verification and falsificationmethod for dnns demonstration that distribution modelsyield substantially better counter examples from verificationand falsification and exploration of different models ofthe data distribution and their trade offs.
ii.
b ackground in this section we provide background on deep neural networks dnn verification and falsification and dnn testingapproaches that exploit the data distribution.
a. deep neural networks a deep neural network n is a type of machine learning model that is trained to approximate a partial target function f r n rm.
for example fmay classify some ndimensional input e.g.
an image as one of mpossible classes e.g.
a digit in the range to .
fis partial in the sense that it is trained to generalize to a target data distribution d rn.
for inputs off of the distribution x negationslash d its behavior n x should be considered as undefined.
dnns are comprised of layers l0 ... l k each of which performs some computation on their input e.g.
matrix multi plication or convolution .
a typical linear architecture definesa dnn as the composition of layers n l k l l0.
layers are comprised of neurons.
the input of a neuron ised x x z n dq z x p x z a va e with encoder e trained to learn the parameters of the latent dis tribution and decoder d trained to learn the like lihood of an input givenvalues in the latent space.t g n d circleplustext d p x?
d xx x?
b gan with trainable input generatorgand discriminator dthat predicts the probability that an input is from thetrue data distribution.
fig.
generative latent distribution models that produce unseen samples from the data distribution.
defined as the weighted sum of the outputs of a set of neurons in a preceding layer where the connections between neuronshave trainable parameters.
the output of a neuron applies a non linear activation function to the input.
training involves initializing the parameters and then applyingnto samples x y from the training set t and repeatedly updating parameters based on bardbln x y bardbl.
while the goal of training is to learn the partial function fdefined over d dis generally unmanageably large e.g.
the set of road images visible on a forward facing camera .
consequently the training set is defined as a representative sample of thedata distribution t d .
a well trained network is said to generalize to the data distribution .
b. models of the data distribution the field of machine learning has long understood the importance of modeling the data distribution.
broadly speaking the field has developed two types of approaches.
out of distribution detectors are designed to determine whethera data point lies on the data distribution but are generallyunable to generate new data from the distribution.
in contrast generative models are designed to generate unseen samples from the data distribution.
there are three broad classes ofgenerative models variational autoencoders v ae gen erative adversarial networks gan and autoregressivemodels such as pixelcnn .
among these v aes andgans can be classified as latent variable models since they make explicit the mathematical structure of the learned latentspace which models d. we leverage generative latent variable models of the data distribution in this work.
fig.
1a depicts a v ae as comprised of a pair of trainable models an encoder e and a decoder d .
the encoder or inference network is trained to learn the parameters ofthe latent distribution q z x that through a regularization term seeks to match a given prior distribution usually amultivariate gaussian n d. the decoder or generative network is trained to learn the likelihood of an input givenvalues in the latent space p x z .
these networks are trained together on inputs drawn from the data distribution d b y minimizing the difference between posterior and latent prior 318and maximizing the likelihood estimation of the input.
a v ae is generative in the sense that one can sample from the latentspace z n d and then run the decoder d z x to produce a sample that lies on the data distribution.
v aescan be leveraged for out of distribution detection by exploitingthe fact that for x d e x produces a distribution that can be sampled to generate inputs x. computing bardblx x bardblfor a number of samples yields the encoder stochastic reconstruction error esre .
we adapt esre to use the structural similarity index measure ssim to assess the quality ofgenerated image data in iv.
fig.
1b depicts a gan as comprised of a pair of trainable generator g r d rn and discriminator d rn r .
the generator produces an input x from a set of latent variables.
the discriminator predicts the probabilitythat an input is from the true data distribution p x d .
the gan is trained by presenting generated x and training inputs x to the discriminator without disclosing their source x ?.
the generator loss function is high when the generated data is classified as generated data by the discriminator i.e.
p x d is low.
the loss function of the discriminator is high when it incorrectly classifies data i.e.
p x d is high orp x d is low and a low value when it is correct.
the weights of the generator and discriminator are updated todecrease their respective loss values.
through this process thegenerator learns to produce data close to the data distribution.
there is a rich literature on the design of v aes and gans exploring the impact of latent dimension complexity of modelarchitectures and variation in loss functions on the accuracyof the learned model.
generally gans are thought to possessbetter precision i.e.
produce sharper images but suffer frompoor recall whereas v aes are thought to be the opposite i.e.
good recall but produce blurry images.
leveraging distributionmodels for v v requires a measure of both but the mlliterature continues to improve in this regard.
for example v aes can now achieve precision that outperforms well tunedgans while retaining good recall .
c. dnn v erification and falsification a correctness problem is a pair angbracketleftn angbracketright of a dnn n r n rm and a property specification formed to determine whether n is valid or invalid.
the property specification defines a set of constraints over the inputs x the pre condition and a set of constraints over the outputs y the post condition.
verification of n seeks to prove or falsify x rn x x y n x .
falsification seeks only to falsify that formula.
two common types of dnn properties are robustness and reachability.
robustness originated with the study of adver sarial examples and specifies that inputs from agiven input region are all classified the same.
this type ofproperty is common for evaluating verifiers .
reachability properties define the post condition usingconstraints over output values specifying that inputs from agiven input region reach outputs within a given safe outputregion.
this type of property has been used to evaluate severaldnn verifiers .
a recent survey on dnn verification classifies approaches for verifying dnn correctness problems based ontheir type reachability optimization or search or a combina tion of these.
tools implementing a range of these approachesand their combination have been developed over the past threeyears .
despite the significant researchinto this topic scalability remains a challenge but usabilityhas been improved by the availability of frameworks likednnv which we use in our work.
complementary to verification falsification checks properties of dnns by attempting to find examples that violate thespecification for a given model.
two categories of techniquesthat have been developed for falsifying dnn correctness prob lems are adversarial attacks and fuzzing.
adversarial attacks are methods optimized for detecting violations of robustnessproperties .
fuzzing methods randomly generate inputs within a given input region and checking whether the outputsthey produce violate the post condition.
fuzzing techniquesinclude tensorfuzz and deephunter .
more recently the range of applicability of adversarial attacks and fuzzinghas been increased to correctness properties by dnnf whichreduces general dnn correctness properties to robustnessproperties .
d. distribution aware dnn testing recent work in testing has begun to explore models of the input domain to support dnn testing.
riccio and tonella construct explicit models of the input space using domainknowledge to generate test cases in order to characterize thespace of dnn misbehaviors .
dola et al.
show that notconsidering the input distribution can bias the assessment ofdnn testing techniques and then use v aes to model theinput distribution and to augment the objective functions oftest generation techniques to remedy that bias .
byun andrayadurgam also describe how to model the input distributionwith a v ae and use it to generate test inputs .
ourapproach differs in that it composes the distribution model e.g.
a v ae decoder with the dnn under analysis and because we focus on verification and falsification developsconstraint based encodings that over approximate designatedportions of the input space of that model.
iii.
a pproach we present dfv our approach for focusing dnn verification and falsification techniques on the data distribution.
a.dfv overview fig.
2a depicts the generic structure of dfv.
our insight is that properties should be verified not over the entire input domain rn of a dnn but rather over the data distribution d used to train the dnn i.e.
its domain of definition.
since dis a small subset of the domain there is the potential to enable property verification when violating inputs lie off of 319nm z y .
x .
a general dfv framework.
zis the latent space distribution mis the generative model nis the network with pre condition xand post condition y.m dn y .
zc d b instance of dfv framework with a vae decoder dasm precondition x x true andcbounds on the m required by falsifiers and verifiers .czc l l2 c forddimensions a l2d ball of radius ccontains all points within cstandard deviations of the mean.
since verifiers do not support non linear constraints torepresent l we approximate it with l .
fig.
distribution based falsification and verification framework with bounding constraints the distribution.
moreover by restricting verification to inputs on the distribution x d counter examples will be feasible and worth fixing.
to define d we advocate the use of a latent variable generative model m rd rnwhered lessmuchn.
with manalyses can be formulated over the low dimensional latent space z n d to reason about the behavior of systems on d. two classes of such models that we explore introduced earlier in ii are variational autoencoders v ae and generative adversarial networks gan .
our goal is to define the set of inputs that lay on the data distribution and that satisfy the property pre condition i.e.
x d x x .
fig.
2a depicts the enforcement of these constraints using two mechanisms the use of mas a prefix network and the forwarding of generated inputs toenable the enforcement of the pre condition prior to checkingpost conditions as described in .
we note that it is alsopossible to combine mand xby defining a generative model capable only of producing inputs satisfying the precondition in which case the forwarding generated inputs is not needed.with these elements the verification problem can be reformu lated as z z x m z y n m z .
in this paper we explore in detail an instantiation of dfv depicted in fig.
2b that uses a v ae as the generative modeland targets output properties of the dnn i.e.
where theprecondition is true.
as explained in ii the v ae s encoderand decoder are trained together but we only exploit thedecoder m d for dfv.
since the dimension of the latent space of the v ae is generally much smaller than the input dimension the generated setof inputs m z z z takes up an infinitesimal portion of the ambient input space.
for falsification this allows theproblem to be reformulated from the input space x d y n x to the latent space z z y n m z .
more importantly since existing falsification algorithms can not test that x d this approach is the first to yield counterexamples that lie on the data distribution subject to theprecision of min modeling d. similarly verification can be reformulated to the latent space z z y n m z .
existing verification and falsification tools require that their input space be bounded.
when using mthat input space isthe latent space of the distribution model and its gaussianstructure allows us to formulate a meaningful bound.
forad dimensional latent space the l 2d ball of radius c a s depicted in fig.
2c contains all points within cstandard deviations of the mean.
the value of ccan be specified to contain an arbitrarily large portion of the distribution e.g.
c specifies verification of .
of the distribution.
however existing dnn falsifiers and verifiers do not supportthe non linear constraints necessary for defining the l 2d ball so we formulate hypercube approximations.
as depicted in fig.
2c the l d ball is the smallest hypercube that overapproximates the l2d ball.
we denote withzcthe hypercube with radius c side length 2c.
formulating constraints that restrict each of the ddimensions to the interval yields a verification problem z zc y n m z that will soundly verify cstandard deviations inz.
b.dfv algorithm algorithm defines dfv through a series of transformations followed by the invocation of the verifier or falsifier.
the dfv algorithm accepts a correctness problem comprised of a dnn n and correctness property .
in addition it takes a model mof the data distribution d a verifier or falsifier v and a radius c which defines how much of the data distribution should be subjected to analysis.
its outputindicates that either a property violation has been detected the property is valid within radius c for verifiers or the result isunknown due to limitations in the verifier or falsifier used.
when a violation is reported a counter example ce is returned as well.
we now describe the algorithm in more detail.
decoupling the training of the distribution model from dfv .algorithm consumes m separating the training of m from dfv.
this is important because there are many degreesof freedom when training m often dependent on the type of model and training used.
for example for a v ae suchas those used in iv the effectiveness of the learned modeldepends on many factors including the architecture of themodel e.g.
number type and configuration of layers and thetraining parameters e.g.
optimizer batch size and learningrate .
independent of the model and training process the goal 320algorithm dfv input correctness problem angbracketleftn angbracketright distribution modelm verifier falsifier v radiusc output violation ce valid unknown 1begin 2n prime n m 3 prime z rm.d z m.d x m z y n prime z 5 prime angbracketleft n prime prime angbracketright 6result check v prime ifresult violation then returnviolation m getcounterexample result returnresult of this pre stage to dfv is for mto approximate d.w e note that the development of distribution models that have high precision and recall is an active area of ml research and that recent research has defined high precision v aes .we note however that models with lower levels of precisioncan still be quite valuable.
as we show in iv rather sim ple v ae models can yield much more meaningful counter examples than those produced without using a distributionmodel.
in this work we explore v ae variations but we leaveto future work a broader study of how model accuracy impactsthe cost and benefit of dfv.
problem transformation.
dfv transforms the correctness problem as described in lines of algorithm .
line 2modifies the original dnn by prefixing it with a generativemodel as shown in fig.
2a.
this transformation prefixesthe original dnn with a latent variable generative model such as the decoder of a v ae.
because the generative modelmaps inputs from a known distribution to the learned datadistribution this step ensures that verification and falsificationwill only check inputs from the data distribution learned bythe prefixed model.
that is the tools can focus on the inputsthat are within the distribution.
line replaces the input pre condition of the original property with a new pre conditionspecifying that inputs come from the latent space of thegenerative model m.ddenotes its dimension and that these inputs satisfy the pre condition.
because the verifiersand falsifiers require inputs to be bounded we assert boundson the latent space.
when the latent space distribution of thegenerative model is gaussian we require zto be within c standard deviations of the mean.
we approximate this with ahypercube of radius ccentered at the origin.
line joins the outcomes of the transformation from line and to redefinethe correctness problem on the data distribution.
v erification and falsification.
after transforming the problem on lines falsifiers and verifiers can be run on the mod ified correctness problem prime angbracketleftn prime prime angbracketright.
if a counter example to primeis found then it can be mapped to a valid counterexample of the original property by performing inference with a fashionmnist training images.
b dronet training images.
fig.
samples from fashionmnist and dronet training sets.
the generative model m. dfv will report violation along with the counter example otherwise it will report the valid or unknown result returned by v. iv .
s tudy in this section we assess the cost effectiveness and scalability of dfv by applying it in conjunction with multiple falsifiers and verifiers.
our evaluation will answer the followingresearch questions what is the cost effectiveness of applying falsification and verification with dfv?
how does the configuration of the model used by dfv affect the quality and quantity of counter examples?
how well does dfv scale to more complex input domains that required more sophisticated models?
a. design we now describe the problem benchmarks generative models falsifiers verifiers and metrics that constitute the threeexperiments in our study.
we describe the experimental pro cedures using these items under each research question.
problem benchmarks our criteria for the selection of problem benchmarks required for them to have modelsdeveloped by others that offer a range of challenges in terms ofarchitectural complexity domains and tasks and architecturesand training data.
they also had to have global reachabilityproperties that are supported by dfv and be amenable to theapplication of existing tool sets.
in the end we identified twobenchmarks of correctness problems that fit our criteria.
the ghpr fmnist benchmark is a new dnn correctness problem benchmark based on the ghpr mnist benchmarkfrom the evaluation of dnnf .
the benchmark con sists of global reachability properties applied to a smallfashionmnist network.
a sample of images from thefashionmnist training set is shown in fig.
3a.
the networkused is based on the architecture of the small mnist networkfrom the evaluation of the neurify verifier .
there are2 formulations of properties in this benchmark.
the first 10properties which we will refer to as type a are of the form for all inputs if class ahas the maximal value then the output values for classes aandbare closer to one another than the output values for classes aandc.
for example one of the properties states that for all inputs if that input is classified 321table i generative models rq name latent layers output dim.
neurons activation vae mrs sigmoid vae rq1 sigmoid vae d l h sigmoid fc vae dronet sigmoid conv vae dronet sigmoid 3gan dronet sigmoid as asneaker then the class sandal will be ranked higher than class shirt .
the other properties type b are weaker variations that drop the maximal value constraint.
the ghpr dronet benchmark introduced in dnnf consists of global reachability properties applied to the dronet dnn which predicts a steering angle and prob ability of collision for a quadrotor from by blackand white images.
dronet is a large dnn model consistingof residual blocks and over neurons.
a sample ofimages from the dronet training set is shown in fig.
3b.
theproperties are of the form for all inputs if the probability ofcollision is between p minandpmax then the steering angle is withinddegrees of .
as pminincreases so does d capturing the intuition that if the probability of collision is low then thequadrotor vehicle should not make sharp turns.
generative models we consider two powerful types of latent variable generative models to learn the data distributionof the training set v aes and gans.
we selected these mod els because they meet the requirements of the approach they are among the most popular unsupervised learningapproaches to encode a data distribution and they workin different ways and provide different tradeoffs.
given thenumber of variables involved in our experiments we chosev aes for rq1 and rq2 and incorporated gans for rq3.through the study we explored a total of models 91to characterize the distribution of ghpr fmnist a n d2t o characterize the distribution of ghpr dronet.
all models used in the study are shown in table i. details for theconfiguration of those models is provided in the experimentalprocedures for each of the research questions.
falsifiers and v erifiers for the falsifiers we will use four common adversarial techniques included in the dnnftool .
dnnf reduces correctness problems to adversarialrobustness problems to allow them to be falsified by off the shelf adversarial attacks.
we chose to use fgsm basiciterative method bim deepfool and projectedgradient descent pgd as they were the top performingfalsifiers in the dnnf study.
we use the same parameters foreach adversarial attack method as used in that study.
we will also use three top performing dnn verifiers.
we chose to use neurify verinet and nnenum which are all supported by dnnv and have performedwell in recent benchmarks .
in addition each of theseverifiers have the ability to return counter examples.
metrics for each run of the falsifiers and verifiers we report the number of counter examples found and the timeto find each counter example.
to judge the quality of eachcounter example we compute the mean reconstruction simi larity mrs which as discussed in ii adapts esre to usethe ssim metric.
given a reference v ae v mrs computes for a given input x the expected similarity for a set of reconstructed inputs mrs x v n summationtextn i 1ssim v x x .in this work we estimate the mean using a sample size n o f reconstructions.
for each problem domain we also require a v ae model to use as a ground truth for measuring the mrs. for fashionmnist we trained a fully connected v ae model vae mrs with a dimensional latent space and symmetric encoderand decoder each with two hidden layers one of neuronsand one of neurons and relu activations.
the decoderuses a sigmoid activation so that output values are in the range0 to .
we chose to use a model significantly larger than thoseused for dfv for evaluating mrs under the assumption thata larger model would be able to better model the distributionand thus provide accurate mrs measures for all modelstested.
for dronet we trained a convolutional v ae model conv vae dronet with symmetric encoder and decoder and a dimensional latent space.
the decoder consists of 8blocks each composed of a convolutional transpose operationfollowed by batch normalization and an elu activation exceptfor the final block which uses a sigmoid activation so thatoutput values are in the range to .
we chose to usethis model as the baseline for mrs since we expected aconvolutional model to perform well on the image data ofthe dronet benchmark.
computing resources the experiments in this work were run on nodes with intel xeon silver processors at2.
ghz and 512gb of memory.
for rq1 and rq2 each jobwas allowed to use processor core and unrestricted memory and had a time limit of hour while falsification jobs in rq2 exploring the factors of the v ae had a time limit of 5minutes.
for rq3 each job was allowed to use processorcores and had a time limit of hour.
v. r esults a. rq on dfv efficacy in this first experiment we quantitatively and qualitatively assess the effectiveness of dfv and its costs when applied inconjunction with falsifiers and verifiers.
experimental procedure.
to answer rq1 we use the ghpr fmnist benchmark.
we run both the verifiers andfalsifiers on this benchmark with and without our dfvwith vae rq1.
we designed vae rq1so that all existing tools could successfully run on it.
this meant that we hadto constrain its size and type of activation functions sothat existing verifiers could process it.
more specifically wedesign vae rq1with a single hidden layer of neurons in the decoder and instead of a sigmoid activation on theoutput it uses an approximation of the sigmoid functionwith relu activations since of the verifiers explored inthis work only verinet supported non relu activation func tions.
the approximation used is as follows sigmoid x relu relu .
x .
.
we run each tool times 322fig.
mrs for generated counter examples across falsifiers and verifiers with and without dfv.
solid horizontal line indicates the median mrs of the test set images reconstructed with vae mrs .
the shaded columns measured in the y2 axis represent the number of counter examples found.
falsifiers and verifiers applied with dfv generate fewer counter examples and onaverage those counter examples have four times higher mrs. on every problem to account for random noise and we recordthe number of problems that return a sat result indicating that a counter example was found as well as the mrs of eachcounter example.
each falsification and verification job had atimeout of hour and used a radius of in the latent space.
analysis and findings.
we start by examining the mean reconstruction similarity mrs measures for the counter examples generated by dfv.
the mrs values are computedbased on their reconstruction with vae mrs .
fig.
shows box plots representing the distribution of the mrs of thecounter examples found by each of the tools x axis whenapplied to the original dnn red and the dnn with thevae rq1decoder blue generated by dfv.
we find that across all tools the use of a model with dfv renders counter examples that are reconstructed better by vae mrs than those found in the original dnn.
indeed the median mrs for thecounter examples found in the original dnn is under .
while the median mrs for the tools applied with dfv isabove .
.
this implies that they are closer to the distributionlearned by vae mrs and thus may be closer to the true input distribution.
a statistical analysis of variance with the kruskal wallis method 1confirmed that the differences between using and not using dfv on any given tool are significant at p .
.
fig.
also includes a horizontal line representing the median mrs of the fashionmnist test set.
this line providesanother guideline to judge the quality of the counter examples.counter examples found by the tools without dfv seem to bewell below the median mrs of the test data indicating thatthey are constructed poorly likely due to being far from thedistribution.
counter examples found with dfv tend to have 1we had to perform the non parametric kruskal wallis test given the different standard deviations observed across the distributions.mrs higher than the median of the test set indicating thatthey come from the distribution.
the shaded columns in fig.
measured on the y2 axis show the number of counter examples found.
these datashow that as expected the number of counter examples foundwhen a tool is applied with a generative model decreases asirrelevant parts of the input space are pruned.
for example deepfool found counter examples on the original dnnand when applying dfv .
this portion of the study also revealed an interesting opportunity for verifiers.
based on the property design we expectedthat the verifiers would not be able to prove a property oftype b and were unlikely to prove one of type a on theoriginal dnn which was indeed the case.
however whenwe used dfv the nnenum verifier was able to prove 25problems that held under the reduced input space encodedby the vae rq1.
this observation points to an opportunity for enabling verification to prove properties that may not holdover the whole input space but may hold over the relevantinput space as per the training distribution.
in order for suchan approach to be effective further studies are needed toguarantee that the generative model encodes a faithful modelof the input distribution.
we discuss this further in future work.
we now qualitatively examine the counter examples generated with and without dfv.
the tabulated images in fig.
5aare the counter examples with the highest ssim generated byeach tool on the dnn and the ones in fig.
5b with dfv.without using dfv we see in fig.
5a the images generated 2one exception to this trend was nnenum which reported a floating point error when attempting to verify many properties on the original dnn but it did not do the same with dfv.
we conjecture that this is because dfvmay be steering the the tool away from inputs that cause the failure.
we willcontact the developers to address this issue.
a without dfv b with dfv fig.
counter examples with highest mrs found for ghprfmnist.
rows correspond to properties while columns corre spond to tools.
when applied with dfv the counter examplesappear to be much better aligned with the training distribution.
fig.
times to find counter examples by each tool.
blue boxplots represent the times of our approach while red box plotsrepresent the times for a dnn alone.
the shaded columns measured in the y2 axis represent the number of counter examples found.
by all the falsifiers look like random noise while the images generated by the verifiers have a bit more structure with largerblocks of similarly valued pixels but still have little discerniblepattern.
on the other hand most of the counter examplesgenerated with dfv in fig.
5b bear some resemblance tothe training images e.g.
boots pants sandals and some ofthem are clearly identifiable.
we also notice that the counter examples found with dfv for some properties correspondto distinct classes.
we argue that when no counter examplesare found for a property with a model but are found for theoriginal dnn like for property a and a those counter examples are likely to be invalid as they reside outside thedata distribution.
by the same token when counter examplesare found with a model but not found without a model likefor property a we argue that the model reduction enablestools to explore the pruned space more extensively enablingtheir generation.
last we briefly examine the time distribution for each tool to generate the counter examples.
fig.
presents box plots foreach of the tools and we again plot the number of counter examples on the y2 axis.
as expected falsifiers are faster thanverifiers.
looking at the .
quartiles of the times spent bythe different tools we can see that all falsifiers took under .5seconds while the verifiers took up to .
seconds.
pgddetected the most counter examples on the original dnnand with the approach while its median execution timewas just over a second.
when comparing the boxes within atool we find that incorporating dfv did not have a majorimpact on the time taken by any of the tools .
major findings tools applied in conjunction with dfv generate fewer counter examples with four times higher mrs in negligible time and that visually appear to be much betteraligned with the training distribution.
3the larger variation for neurify can be attributed to the smaller number of counter examples it generated.
a mrs of the counter examples found by pgd using dfv for each latent spacesize.
the blue columns show the number ofcounter examples found.
b mrs of counter examples found by pgdusing different decoder architectures with alatent space of size .
c mrs of counter examples found by pgdusing dfv with vae 256across different radii.
fig.
study of impact of varying dimension architecture and radius of v ae in dfv.
b. rq on vae structure effects on dfv we now explore the effects of the v ae s latent space size number and size of layers and radius from the center of the latent space distribution on the efficacy of dfv.
experimental procedure.
to answer rq2 we again use the ghpr fmnist benchmark while exploring several fac tors that may affect the efficacy of dfv.
given that there isa large number of configurations to explore that the largerv ae configurations are not runnable by all verifiers and thatthe performances of all falsifiers were similar in the firstexperiment we selected to run all configurations and dfvwith only the pgd falsifier.
we first explore factors relatedto the v ae architecture varying the size of the latent space the number of hidden layers and the size of each layer.
weexplored latent space sizes of and hiddenlayer counts of and and layer sizes of and .
for each combination of factors we trained a v aeon the fashion mnist data and transformed the correctnessproblems using dfv and ran pgd on the resulting problems.we will refer to each as vae d l h wheredis the latent space size lis the number of hidden layers and his the size of each hidden layer.
the model vae has an dimensional latent space with hidden layers each with neurons.second we explore how the size of latent space region ofthe model affects the quality of the found counter examples.we will specify the size of the input region by restricting theradius of the l d ball in the latent space of the v ae.
we will explore this factor with radii of .
to in .
increments.to reduce the number of experiments we use only the v aethat performed best in the first part of the experiment witha high number of counter examples found and high mrs. forthis question each falsification job was run times to reducethe effects of random noise and each job was given a timeoutof minutes.
for each combination of factors we report thenumber of counter examples found as well as the mrs ofeach counter example.
analysis and findings.
we explored a total of v ae configurations that work in conjunction with dfv.
to controlfor randomness we run each configuration five times.
we start by examining the effect of the latent space size across all of the v ae architectures on the quality ofcounter examples found as measured by the mrs and thenumber of counter examples found.
fig.
7a shows across thelatent spaces that the median mrs varies between .
and0.
and the number of counter examples between and1306.
the maximum possible number of counter examples inthis plot is since there are v ae architectures for eachlatent space size and properties that were checked timeseach for each architecture.
we observe that smaller latent spaces ls appear to generate counter examples with slightly higher mrs mainlybecause the model renders a less diverse set of images butof really good quality.
the differences in mrs are confirmedwith an anov a test of significance and a multiple comparisonof latent space means with a bonferroni correction acrossthe latent spaces.
more specifically the mrs for ls issignificantly different from the rest of the latent spaces anda ls is significantly different from the rest at p .
.we conjecture that larger spaces are able to encode richerdata distributions enabling the generation of more and morediverse counter examples that are sometimes farther from thedistribution i.e.
a sandal that appears as printed on a shirt .still for this particular benchmark the gains in the numberof counter examples found and the losses in mrs seem tosaturate after latent spaces of size .
across all of the latentspaces sizes pgd required a median of .
seconds to findcounter examples.
the timing data for these experiments isavailable in the appendix.
we then selected the v ae architectures with ls which contained the architecture with the tying highest mrs withthe most counter examples to examine their variance.
the x axis of fig.
7b contains the v ae architectures we exploredspecified in the x axis by the latent space size the numberof layers and the number of neurons.
we note that thearchitectures with more layers appear to be able to producecounter examples with higher mrs. for example the medianfor the architectures with layer was .
with layers was0.
and with layers was .
.
an anov a confirms thatthe differences across architectures are significant at p .
and a pair wise comparison with a bonferroni correctionreveals that all the architectures with layer are significantlydifferent from the ones with layers.
the figure also seems to 325indicate that given the same number of layers having more neurons would render slightly higher mrs. for example themedian for the architecture with neurons was .
andfor the three architectures with neurons it was .
.
wenotice however that the number of counter examples foundwas higher when fewer layers are used.
we conjecture thathaving more layers further restricts the size of the input spacelearned by the v ae perhaps due to the extra expressivepower of the additional layers.
as with latent spaces thetime to find counter examples did not vary significantly acrossarchitectures with most of them requiring a median of lessthan second to find a counter example.
the timing data forthese experiments is available in the appendix.
the last piece of this experiment explores changing the radius of the constraints in the latent space.
we examinethe effect of such changes on vae the architecture with the most counter examples and greatest mrs in fig.
7b.fig.
7c shows that the mrs slightly decreases after the firstbound of .
and then starts to increase with higher bounds from a median of .
for a radius of .
to a medianof .
for a radius of .
and back to a median of over0.
mrs with a radius of .
an anov a test across radiiwas significant at p .
and a multple comparison with abonferroni correction showed that radius .
was deemedsignificantly different from radii .
.
and .
butnon significantly different from the higher radii timing detailsare provided in the appendix .
we also note that the numberof counter examples found increases as the space to explorearound the captured data distribution increases from a radiusof .
counter examples found to .
counter examples found .
major findings v ae configurations with very limited capacity in layers neurons or latent space size can have anoticeable effect on the dfv effectiveness specially in thenumber of counter examples being found.
if more counter examples are desirable then one should increase the dimen sionality of the latent space reduce the number of layers and increase the radius.
if higher quality counter examples aremore desirable then favoring a lower dimensional latent spaceor smaller radius or reducing the number of layers is indicated.
c. rq on dfv scalability in this experiment we assess the scalability of dfv by applying it to a large dnn model for autonomous ua v control using different input distribution models.
experimental procedure.
to answer rq3 we use the larger and more complex ghpr dronet benchmark.
we applythe pgd falsifier to the benchmark both as is and using dfv both with a v ae model as well as with a gan as the generative model.
we train a fully connected v ae fc vae dronet with a symmetric encoder and decoder.
the decoder of fc vae dronet has hidden layers in the decoder with sizes and all withelu activations except the final layer which uses a sigmoidactivation.
for gan dronet we train a dcgan model on the dronet dataset with a sigmoid on the final layer.
fig.
the mean reconstruction similarity solid box time dashed box and numbers of counter examples color bar tothe dronet properties.
both models use a dimensional latent space.
as before we run each falsifier times to account for random noise and werecord the number of counter examples found and the time tofind each counter example.
each job had a timeout of hour.
analysis and findings.
fig.
shows box plots with solid outlines for the distributions of the reconstruction similaritiesof counter examples found using pgd on the dronet dnnwithout dfv as well as using dfv with the decoder offc vae dronet and the generator of gan dronet .
fig.
also shows the number of counter examples found using eachmodel using bars with the count labeled above each bar.
wefind that for dfv with both models while fewer counter examples are found they clearly have higher reconstructionsimilarities than those found using the dronet model alone.
in deed the mrs differences between dronet fc vae dronet gan dronet are shown to be statistically significant overall by a kruskal wallis test with p .
and so do their pairwisedifferences.
corroborating the previous findings this impliesthat the counter examples found using dfv are closer to thedistribution learned by conv vae dronet the model used to compute the mrs values and thus may be closer to the actualinput distribution.
without dfv violations were found for all10 properties across all seeds.
using fc vae violations were found for properties.
using gan violations were found across properties.
while the lowest mrs for a counter example found using dfv was .
the mrs without dfvnever exceeded .
.
we now proceed to visually examine the counter examples generated with and without dfv for properties.
fig.
showscounter examples generated by pgd.
the images generatedwithout dfv look like random noise while the imagesgenerated with dfv independent of the chosen model havestructure and contain features seen in the training imagessuch as roads trees or horizon lines.
the model used for dfv has an impact on the images produced.
while the v ae model tended to produce blurrier counter examples thegan model produced counter examples with sharper lines but fewer recognizable road features.
finally fig.
shows box plots with dashed outlines of the time to generate each counter example using each model.
a no model b fc vae dronet c gan dronet fig.
counter examples to dronet properties with distinct input models.
the counter examples shown are from the final run of the falsifier on each of the properties.
when applied in conjunction with dfv whether using a v ae or a gan thegenerated counter examples visually appear to be much better aligned with the training distribution.
the median time to falsify dronet alone was seconds while dfv with fc vae dronet took seconds and dfv withgan dronet took seconds but there is enough performance variance that those differences are not deemedstatistically significant.
major findings dfv can be applied with various models without significant time penalty while also producing counter examples with up to a nine fold improvement in reconstructionsimilarity.
d. threats to v alidity external validity.
three threats to the generalization of our findings are our choice of tools benchmarks and generative models to evaluate dfv.
we mitigate the concern abouttools generality by selecting multiple falsifiers and verifiersas part of the first research question.
for the next questionswe traded generality across tools for more insights about theperformance of dfv under different models which impliedthat we had to drop dnn verifiers from the rest of theassessment because they did not scale to the networks andmodels we were targeting.
regarding benchmarks we selectedones from different domains one a classification task and theother being a regression task with very different architecturesand training data.
still more benchmarks are needed to morebroadly explore the cost effectiveness of dfv.
to mitigatethe threat about model selection we explored an extensive setof models in a systematic way.
still the examination of moregenerative models is part of the future work.
construct validity.
our choice of mrs as a quality measure and our personal qualitative judgment of generatedcounter examples pose a threat in that the relevance of acounter example could be judged by many means.
we miti gated this threat by basing mrs on a popular measure esre and specializing it to images with ssim.
we also provideresults using esre in the appendix and we will exploreadditional measures including those for outlier detection inthe future and perform studies with users to help us judge thecounter examples quality.
internal validity.
our training processes for the networks and the models constitute a threat to the internal validity ofthe study as their correctness could have affect the findings.we have documented and programmed those processes whenpossible through scripts to facilitate their reproduction.
wealso mitigate this threat by making our data and scripts forrunning our experiments and analyzing our results publiclyavailable see below .
another threat to validity is the ran domness involved in training of networks and models and inthe tools performance.
we mitigated that threat by runningthose tools multiple times and showing their variability.
vi.
c onclusion this work introduces a novel approach dfv which enables existing dnn verification and falsification techniquesto target the data distribution.
dfv composes learned latentvariable generative distribution models with the dnn underanalysis reformulating the problem so that generated counter examples are on the data distribution.
we explore different datadistribution models and find that using even simple modelsyield substantially better counter examples across a rangeof verification and falsification techniques for two differentbenchmarks.
these findings along with recent work on distribution aware testing suggest that models of the data distribution canplay an important role in v v of dnns.
we plan to pursuefurther work along these lines.
for example how performancemetrics for latent variable generative models that assess theirprecision and recall can guide the development of distri bution models that are customized to best suite different v vactivities for dnns.
a rtifact av ailability we provide an artifact containing the tool as well as the data and scripts required to replicate our study at a cknowledgment this material is based in part upon work supported by national science foundation awards and .
327references y .
tian k. pei s. jana and b. ray deeptest automated testing of deep neural network driven autonomous cars in proceedings of the 40th international conference on software engineering icse gothenburg sweden may june pp.
.
.
available k. pei y .
cao j. yang and s. jana deepxplore automated whitebox testing of deep learning systems in proceedings of the 26th symposium on operating systems principles shanghai china october pp.
.
.
available a. odena c. olsson d. andersen and i. goodfellow tensorfuzz debugging neural networks with coverage guided fuzzing inproceedings of the 36th international conference on machine learning ser.
proceedings of machine learning research k. chaudhuri andr.
salakhutdinov eds.
vol.
.
long beach california usa pmlr jun pp.
.
.
available x. xie l. ma f. juefei xu m. xue h. chen y .
liu j. zhao b. li j. yin and s. see deephunter a coverage guided fuzz testing frame work for deep neural networks in 28th acm sigsoft international symposium on software testing and analysis .
y .
sun m. wu w. ruan x. huang m. kwiatkowska and d. kroening concolic testing for deep neural networks in proceedings of the 33rd acm ieee international conference on automated software engineer ing pp.
.
d. berend x. xie l. ma l. zhou y .
liu c. xu and j. zhao cats are not fish deep learning testing calls for out of distribution awareness in2020 35th ieee acm international conference on automated softwareengineering ase .
ieee pp.
.
s. dola m. b. dwyer and m. l. soffa distribution aware testing of neural networks using generative model in proceedings of the international conference on software engineering .
l. ma f. juefei xu f. zhang j. sun m. xue b. li c. chen t. su l. li y .
liu j. zhao and y .
wang deepgauge multi granularity testing criteria for deep learning systems inproceedings of the 33rd acm ieee international conference onautomated software engineering ase montpellier france september pp.
.
.
available t. byun and s. rayadurgam manifold for machine learning assurance in proceedings of the acm ieee 42nd international conference on software engineering new ideas and emergingresults ser.
icse nier .
new york ny usa associationfor computing machinery p. .
.
available d. shriver s. g. elbaum and m. b. dwyer reducing dnn properties to enable falsification with adversarial attacks in proceedings of the international conference on software engineering .
c. e. tuncali g. fainekos h. ito and j. kapinski simulationbased adversarial test generation for autonomous vehicles with machinelearning components in ieee intelligent v ehicles symposium iv .
ieee pp.
.
s. r. choudhary a. gorla and a. orso automated test input generation for android are we there yet?
e in 30th ieee acm international conference on automated software engineering ase .ieee pp.
.
s. a. khalek g. yang l. zhang d. marinov and s. khurshid testera a tool for testing java programs using alloy specifications in2011 26th ieee acm international conference on automated softwareengineering ase .
ieee pp.
.
o. tkachuk m. b. dwyer and c. s. pasareanu automated environment generation for software model checking in 18th ieee international conference on automated software engineering .proceedings.
ieee pp.
.
d. giannakopoulou c. s. pasareanu and j. m. cobleigh assumeguarantee verification of source code with design level assumptions inproceedings.
26th international conference on software engineering.ieee pp.
.
c. cadar d. dunbar d. r. engler et al.
klee unassisted and automatic generation of high coverage tests for complex systems programs.
inosdi vol.
pp.
.
p. dhaussy j. c. roger and f. boniol reducing state explosion with context modeling for model checking in ieee 13th international symposium on high assurance systems engineering.
ieee pp.
.
d. kroening and m. tautschnig cbmc c bounded model checker in international conference on tools and algorithms for the constructionand analysis of systems.
springer pp.
.
m. r. gadelha f. r. monteiro j. morse l. c. cordeiro b. fischer and d. a. nicole esbmc .
an industrial strength c model checker inproceedings of the 33rd acm ieee international conference on automated software engineering pp.
.
m. markthaler s. kriebel k. s. salman t. greifenberg s. hillemacher b. rumpe c. schulze a. wortmann p. orth and j. richenhagen improving model based testing in automotive software engineering in2018 ieee acm 40th international conference on software engineering software engineering in practice track icse seip .
ieee pp.
.
c. s. p as areanu m. b. dwyer and w. visser finding feasible counter examples when model checking abstracted java programs ininternational conference on tools and algorithms for the constructionand analysis of systems.
springer pp.
.
a. gurfinkel t. kahsai a. komuravelli and j. a. navas the seahorn verification framework in international conference on computer aided v erification.
springer pp.
.
t. gehr m. mirman d. drachsler cohen p. tsankov s. chaudhuri and m. vechev ai2 safety and robustness certification of neural networkswith abstract interpretation in ieee symposium on security and privacy sp may pp.
.
w. ruan x. huang and m. kwiatkowska reachability analysis of deep neural networks with provable guarantees in ijcai.
ijcai.org pp.
.
g. singh r. ganvir m. p uschel and m. t. vechev beyond the single neuron convex barrier for neural network certification in advances in neural information processing systems annual conference onneural information processing systems neurips 14december v ancouver bc canada h. m. wallach h. larochelle a. beygelzimer f. d alch e buc e. b. fox and r. garnett eds.
pp.
.
.
available beyond the single neuron convex barrier for neural network certification g. singh t. gehr m. p uschel and m. t. vechev an abstract domain for certifying neural networks pacmpl vol.
no.
popl pp.
.
w. xiang h. tran and t. t. johnson output reachable set estimation and verification for multilayer neural networks ieee transactions on neural networks and learning systems vol.
no.
pp.
nov .
o. bastani y .
ioannou l. lampropoulos d. vytiniotis a. v .
nori and a. criminisi measuring neural net robustness withconstraints in proceedings of the 30th international conference on neural information processing systems ser.
nips .
usa curran associates inc. pp.
.
.
available k. dvijotham r. stanforth s. gowal t. mann and p. kohli a dual approach to scalable verification of deep networks in proceedings of the thirty f ourth conference annual conference on uncertainty inartificial intelligence uai .
corvallis oregon auai press pp.
.
a. raghunathan j. steinhardt and p. liang certified defenses against adversarial examples in iclr.
openreview.net .
v .
tjeng k. y .
xiao and r. tedrake evaluating robustness of neural networks with mixed integer programming in international conference on learning representations .
.
available e. wong and j. z. kolter provable defenses against adversarial examples via the convex outer adversarial polytope in icml ser.
proceedings of machine learning research vol.
.
pmlr pp.
.
t. weng h. zhang h. chen z. song c. hsieh l. daniel d. s. boning and i. s. dhillon towards fast computation of certified robustnessfor relu networks in icml ser.
proceedings of machine learning research vol.
.
pmlr pp.
.
x. huang m. kwiatkowska s. wang and m. wu safety verification of deep neural networks in ca v ser.
lecture notes in computer science vol.
.
springer pp.
.
g. katz c. w. barrett d. l. dill k. julian and m. j. kochenderfer reluplex an efficient smt solver for verifying deep neural networks in computer aided v erification 29th international conference ca v heidelberg germany july proceedings part i pp.
.
.
available r. ehlers formal verification of piece wise linear feed forward neural networks in automated technology for v erification and analysis 15th international symposium atva pune india october3 proceedings pp.
.
.
available r. r. bunel i. turkaslan p. h. s. torr p. kohli and p. k. mudigonda a unified view of piecewise linear neural network verification inneurips pp.
.
d. shriver s. g. elbaum and m. b. dwyer dnnv a framework for deep neural network verification in computer aided v erification 33rd international conference ca v virtual event july proceedings part i ser.
lecture notes in computer science a. silvaand k. r. m. leino eds.
vol.
.
springer pp.
.
.
available a. loquercio a. i. maqueda c. r. d. blanco and d. scaramuzza dronet learning to fly by driving ieee robotics and automation letters .
d. p. kingma and m. welling auto encoding variational bayes in 2nd international conference on learning representations iclr banff ab canada april conference track proceedings .
i. goodfellow j. pouget abadie m. mirza b. xu d. warde farley s. ozair a. courville and y .
bengio generative adversarial nets inadvances in neural information processing systems z. ghahramani m. welling c. cortes n. d. lawrence and k. q. weinberger eds.curran associates inc. pp.
.
.
available m. f. naeem s. j. oh y .
uh y .
choi and j. yoo reliable fidelity and diversity metrics for generative models in international conference on machine learning.
pmlr pp.
.
a. m. alaa b. van breugel e. saveliev and m. van der schaar how faithful is your synthetic data?
sample level metrics for evaluating andauditing generative models arxiv preprint arxiv .
.
h. xiao k. rasul and r. v ollgraf.
fashion mnist a novel image dataset for benchmarking machine learning algorithms.
i. goodfellow y .
bengio and a. courville deep learning.
mit press l. ruff j. r. kauffmann r. a. vandermeulen g. montavon w. samek m. kloft t. g. dietterich and k. r. m uller a unifying review of deep and shallow anomaly detection proceedings of the ieee .
t. salimans a. karpathy x. chen and d. p. kingma pixelcnn improving the pixelcnn with discretized logistic mixture likelihood andother modifications arxiv preprint arxiv .
.
a. vasilev v .
golkov m. meissner i. lipp e. sgarlata v .
tomassini d. k. jones and d. cremers q space novelty detection with varia tional autoencoders in computational diffusion mri e. bonet carne j. hutter m. palombo m. pizzolato f. sepehrband and f. zhang eds.cham springer international publishing pp.
.
z. wang a. c. bovik h. r. sheikh and e. p. simoncelli image quality assessment from error visibility to structural similarity ieee transactions on image processing vol.
no.
pp.
.
b. dai and d. p. wipf diagnosing and enhancing v ae models in 7th international conference on learning representations iclr new orleans la usa may .
.
available c. szegedy w. zaremba i. sutskever j. bruna d. erhan i. j. goodfellow and r. fergus intriguing properties of neural networks in2nd international conference on learning representations iclr banff ab canada april conference track proceedings y .
bengio and y .
lecun eds.
.
x. yuan p. he q. zhu and x. li adversarial examples attacks and defenses for deep learning ieee transactions on neural networks and learning systems vol.
no.
pp.
.
s. wang k. pei j. whitehouse j. yang and s. jana efficient formal safety analysis of neural networks in neurips pp.
.
g. katz d. a. huang d. ibeling k. julian c. lazarus r. lim p. shah s. thakoor h. wu a. zelji cet al.
the marabou frameworkfor verification and analysis of deep neural networks in international conference on computer aided v erification pp.
.
c. liu t. arnon c. lazarus c. barrett and m. j. kochenderfer algorithms for verifying deep neural networks corr vol.
abs .
.
d. shriver s. g. elbaum and m. b. dwyer dnnf .
available v .
riccio and p. tonella model based exploration of the frontier of behaviours for deep learning system testing in proceedings of the 28th acm joint meeting on european software engineering conferenceand symposium on the f oundations of software engineering ser.
esec fse .
new york ny usa association forcomputing machinery p. .
.
available t. byun a. vijayakumar s. rayadurgam and d. cofer manifoldbased test generation for image classifiers in ieee international conference on artificial intelligence testing aitest .
ieee pp.
.
i. j. goodfellow j. shlens and c. szegedy explaining and harnessing adversarial examples in 3rd international conference on learning representations iclr san diego ca usa may conference track proceedings y .
bengio and y .
lecun eds.
.
a. kurakin i. j. goodfellow and s. bengio adversarial examples in the physical world in 5th international conference on learning representations iclr toulon france april workshoptrack proceedings.
openreview.net .
s. moosavi dezfooli a. fawzi and p. frossard deepfool a simple and accurate method to fool deep neural networks in ieee conference on computer vision and pattern recognition cvpr las v egas nv usa june .
ieee computer society pp.
.
a. madry a. makelov l. schmidt d. tsipras and a. vladu towards deep learning models resistant to adversarial attacks in 6th international conference on learning representations iclr v ancouver bc canada april may conference track proceedings.openreview.net .
p. henriksen and a. lomuscio efficient neural network verification via adaptive refinement and adversarial search in ecai 24th european conference on artificial intelligence august september2020 santiago de compostela spain august september including 10th conference on prestigious applications of artificialintelligence pais ser.
frontiers in artificial intelligence andapplications g. d. giacomo a. catal a b. dilkina m. milano s. barro a. bugar n and j. lang eds.
vol.
.
ios press pp.
.
.
available s. bak h. d. tran k. hobbs and t. t. johnson improved geometric path enumeration for verifying relu neural networks in computer aided v erification s. k. lahiri and c. wang eds.
cham springerinternational publishing pp.
.
d. xu d. shriver m. b. dwyer and s. elbaum systematic generation of diverse benchmarks for dnn verification in computer aided v erification ca v .
c. liu and t. t. johnson vnn comp .
available a. radford l. metz and s. chintala unsupervised representation learning with deep convolutional generative adversarial networks in4th international conference on learning representations iclr san juan puerto rico may conference trackproceedings y .
bengio and y .
lecun eds.
.
.
available