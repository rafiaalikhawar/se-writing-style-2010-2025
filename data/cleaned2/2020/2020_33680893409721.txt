global cost quality management across multiple applications liu liu rutgers university new brunswick new jersey usasibren isaacman loyola university maryland baltimore maryland usaulrich kremer rutgers university new brunswick new jersey usa abstract approximation is a technique that optimizes the balance between application outcome quality and its resource usage.
trading quality for performance has been investigated for single application scenarios but not for environments where multiple approximate applications may run concurrently on the same machine interfering with each other by sharing machine resources.
applying existing single application techniques to this multi programming environment may lead to configuration space size explosion or result in poor overall application quality outcomes.
our new rapid m system is the first cross application configuration management framework.
it reduces the problem size by clustering configurations of individual applications into local similarity buckets .
the global cross applications configuration selection is based on these local bucket spaces.
rapid m dynamically assigns buckets to applications such that overall quality is maximized while respecting individual application cost budgets.
once assigned a bucket reconfigurations within buckets may be performed locally with minimal impact on global selections.
experimental results using six configurable applications show that even large configuration spaces of complex applications can be clustered into a small number of buckets resulting in search space size reductions of up to orders of magnitude for our six applications.
rapid m constructs performance cost models with an average prediction error of .
for our application execution traces rapid m dynamically selects configurations that lower the budget violation rate by .
with an average budget exceeding rate of .
as compared to other possible approaches.
rapid m successfully finishes .
more executions which translates to a .
global output quality increase under high system loads.
the overhead of rapid m is within of application execution times.
ccs concepts software and its engineering development frameworks and environments software configuration management and version control systems .
keywords approximate computing global configuration management performance prediction multi programming permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november virtual event usa association for computing machinery.
acm isbn .
.
.
.
reference format liu liu sibren isaacman and ulrich kremer.
.
global cost quality management across multiple applications.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
.
introduction a significant number of important applications can be configured approximated to trade off application outcome quality for execution time reduction.
this property can be crucial when applications are executed on resource constrained devices under soft execution deadlines including edge devices and mobile phones.
since multiple applications execute on the same hardware platform they interfere with each other through resource sharing e.g.
memory hierarchy cpu cores buses communication networks .
further different configurations may have different resource footprints and different quality outcomes making optimal or near optimal selection of configurations across all applications challenging.
in previous work single application performance cost models are constructed by applying machine learning strategies to all or a subset of the application s configuration space.
treating a set of napplications as a single meta application would allow these strategies to be applied to the multi programming case.
however the resulting size of the combined configuration space is exponential in n making this approach infeasible in practice.
moreover the performance model is constructed based on the observations obtained from running the application under a stable environment.
online adaption is only designed to deal with single application input dependencies or runtime noise but not interference from other applications.
this paper discusses the design and evaluation of rapid m reconfiguration approximation preferences implementation anddependencies for multi programming a new cross application configuration management framework which uses a novel localglobal local approach that allows a systematic exploration of the combined configuration search spaces of all active applications.
to the best of our knowledge our work is the first to address this problem.
the main steps of rapid m are local first the problem space size is reduced by clustering individual application configuration spaces into equivalence groups called buckets .
buckets combine configurations according to their similar resource demands and performance slowdown characteristics the two dimensions of the summary strategy for reducing exploration space sizes.
since the performance degradation of an application is due to resource availability on the machine each bucket also comes with a performance model that predicts the application slowdown given the system environment p model and the common resource demand by configurations in the bucket esec fse november virtual event usa liu liu sibren isaacman and ulrich kremer global across applications a machine model m model is constructed to predict the overall system workload for any bucket combinations from active applications including the option of not selecting a bucket for an application.
these combinations are exhaustively evaluated resulting in the optimal bucket combination with the highest overall global quality.
this bucket combination has to be feasible i.e.
each bucket in the combination has to contain at least one configuration that satisfies the execution time constraint budget of the associated application as provided by the user.
local second finally a selection within each bucket is performed to allow individual applications to react to minor platform uncertainties and input dependencies that can be handled without a global reconfiguration thereby avoiding reconfiguration overhead.
machine learning models are used to model the platform specific configuration interactions on the level of target system footprints m model and to determine application specific models for configuration slow downs in response to varying overall system loads p model .
together m model andp model s allow the prediction of system and configuration behaviors i.e.
assessing the mutual interference and benefits of configuration selections.
if the multiprogramming environment changes due to initiation or termination of applications this approach will recompute the overall global configuration using the interference and prediction models.
the target applications of rapid m have to be adaptive i.e.
must have configurable components parameters that can be manipulated during runtime resulting in different cost quality trade offs.
six applications were selected from different domains financial analysis image analyses machine learning with three applications used in multiple related works e.g.
caloree powerdial esp on single application adaptations.
the applications differ in their configuration space sizes and cost quality trade offs.
experimental results on the six applications and different execution traces show the effectiveness of rapid m and its implementation against five other heuristics.
application configurations can be partitioned into a small number of buckets allowing the system to produce global configurations of high quality.
the runtime overhead includes the execution time needed to solve the global selection problem the local problem and any resulting dynamic reconfigurations.
training times for the m model andp model s are also reported capturing rapid m s offline overhead.
compared to existing approaches in which each application adapts itself individually and application interference is treated as noise on a core machine rapid m achieves .
higher success rate when the system is not busy active apps and .
higher when busy.
this translates to .
not busy and .
busy higher overall output quality.
furthermore rapid m achieves such improvement with an average of fewer performed reconfigurations.
rapid m framework overview rapid m uses the standard notion of a configuration as defined by most existing adaptive configuration management approaches .
an application s configuration is a set of discrete knob values where knobs are entities e.g.
program variables that impact the quality and cost of the application s outcome.
rapid m is a framework that manages the configurations of concurrent applications with the goal of choosing individual configurations suchthat all individual resource constraints are satisfied while maximizing the combined quality of active applications.
in other words rapid m solves the global configuration problem defined below.
the particular cost metric used throughout this paper is execution time though one might use for instance energy consumption as an alternative possible metric.the quality of an application execution is defined by an application specific quality metric applied to its final output outcome e.g.
the accuracy of a computed numeric value or the precision recall of the set of identified faces in a face detection application.
if an application fails to successfully terminate its execution does not have any measurable quality.
further to enable dynamic reconfiguration applications are broken into a collection of work units with configurations dynamically assigned to work units at runtime.
work units are also used to keep track of an application s progress towards successful termination.
global configuration problem at system defined points in time tx determine a global configuration vector with one entry for each active application i n where an entry is either a valid configuration ciorterminate such that n iqual metrici ci is maximized terminate entries are ignored and for each active application i its remaining work units at time txcan be successfully executed within its remaining execution time budget under ci or the application is terminated.
a single application s configuration space is the cartesian product of all knob value ranges where each knob has finitely many value settings.
assuming that a single application has kknobs with discrete ranges of mvalues each the resulting configuration space iso mk .
existing approaches construct performance models to rank all configurations in the space according to some optimization objective.
a brute force approach towards the global configuration problem is to treat all active applications as a single meta application.
a configuration in this meta application is then a combination of all configurations in each component application.
the size of the resulting configuration space is o mk n fornapplications.
it is exponential in n which may be infeasible large to effectively explore.
however configuration space exploration is necessary because of the interdependence of the individual application configurations due to shared target system resources.
to the best of our knowledge the rapid m framework is the first to address configuration management of multiple active applications.
a key design feature of rapid m is to model cross application configuration interference not at the configuration space level but on the system footprints associated with each configuration.
a system footprint is a vector of hardware counters that characterize the use of different system resources by an executing application i.e.
are used to represent a configuration s resource demands.
in addition footprints can represent resource demands of groups of active applications including entire system workloads.
since resource sharing and contention happens at the machine level system footprints are the right abstraction to represent the impact of such sharing.
this strategy has two main advantages many configurations of an application may have the same system footprint and the impact of other applications and their configurations on the performance of a given application s configuration can be modeled based on the combined system footprint of these other 351global cost quality management across multiple applications esec fse november virtual event usa application configurations.
in other words for the assessment of a configuration s performance modeled as an expected slow down only the combined system footprint workload of other applications is relevant and not their particular configuration selections.
the resulting summary information is the key to allowing effective configuration space exploration management across multiple applications.
this summary information is computed and exploited with a local offline model training phase followed by an online global configuration and online local configuration selection phase.
in the offline phase single application configurations are clustered into groups with similar system footprints and similar slowdown behavior in response to overall system workloads.
such groups of configurations are referred to as buckets .
the individual application configuration spaces are exhaustively explored and each configuration s system footprint is recorded together with its execution time cost and quality under different system workloads.
this data is used to train the p model that captures the slowdown for each configuration in response to different system workloads.
the interaction of different workloads and configuration footprints is captured by the m model which is trained on data obtained by measuring runtime properties of configuration system footprints executing with randomly generated stresser workloads.
this stresser workload is introduced by running either another application or an instance of stress tool e.g.
the linux stresser .
at runtime the global optimization manager uses the constructed p model s and m model to assess the impact of global events e.g.
start exit of applications on resource availability and to select the combination of application configuration buckets that maximize the overall quality under the changed resource availability.
the selected buckets together with their predicted slowdown are assigned to their respective applications.
the local controller relies on optimization strategies used in single application scenarios for configuration selection within the assigned bucket.therefore we will concentrate our discussion in this paper on rapid m s offline component and the online global configuration manager.
rapid m offline phase the three key models and abstractions that are generated in rapidm s offline phase are the target system s m model and the application s p model s with their associated configuration buckets.
.
resource usage prediction m the performance of an application can significantly degrade when the overall system resource utilization is high.
for example one of our applications bodytrack has a slow down in execution time under heavy system loads.
predicting the overall system load i.e the system environment is crucial before estimating the performance degradation of an application under multi programming environments.
the key questions to answer is how a system workload will change when a new application starts or an existing application terminates in the context of other active applications.
rapid m trains the m model with a set of experiments each with a pair of running instances involved.
such instance can be a realistic application e.g.
one of our benchmark application or a linux stress tool that introduces arbitrary workloads to thesystem including i o cpu utilization and hard disk access.
the system footprint generated from the two instances can vary in different experiments by using different applications or different configurations.
we use intel s performance counter monitor pcm to measure the footprint and represent it by a vector vwhere each entry corresponds to a particular system metric feature considered byrapid m .rapid m uses exec freq inst instnom ipc l2miss l2mpi l3hit l3miss l3mpi physipc mem .
for each experiment training data point rapid m measures and collects the footprints when each instance executes in isolation v1 v2 and together v1 all with the same length mwheremis the number of features to observe in our case m .rapid m then constructs a separate model for each feature using the standard regression method.
equation shows the model construction for thek th feature.xis a matrix of size n 2m wherenis the number of experiments.
the first mcolumns of xare list ofv1 s and the lastmcolumns are list of v2 s i.e.
each row of xis a concatenated vector .
the goal is to locate kthat minimizes the error .
h v1 v2 ...vn it x k them model is a collection of such models each predicting a particular feature in v1 .
when running napplications together the overall system footprint is estimated by applying miteratively v m ... m m v1 v2 v3 ...vn .
performance prediction p rapid m predicts the performance degradation for each application under different environments by a performance regression model p model .p model is trained by collecting the application slow down under different configurations and workload environments.
during training rapid m first records the execution time for an application under configuration cwhen running alone.
it then runs the configuration under different environments induced by adding extra workloads from different stressers .
under each environment rapid m records the overall system footprint vand the execution slow down .
the regression model minimizes the error between prediction and observed slow down .
a unique p model is constructed for each bucket.
during construction configurations that are not part of the bucket are not considered.
different types of models e.g.
linear regression bayesianridge may be a better fit for a particular footprint feature or slowdown predicted by m model andp model respectively and different candidate models may produce accurate predictions based only on a subset of vector features.
the latter issue is addressed in esp by first filtering out insignificant features then training a higher order model with the remaining features.
however the drawback is that it uses a single linear model approach for all applications and does not distinguish between different configurations.
also to support the slowdown prediction for up to kapplications esp needs to collect the training data by actually runningkapplications together.
in contrast the p model s and mmodel are trained on single applications.
to address the first issue rapid m maintains a model pool with multiple models including regular linear regression lr regression elastic net en regression with cross validation lasso ls regression with 352esec fse november virtual event usa liu liu sibren isaacman and ulrich kremer cross validation bayesian ridge br regression and a neural network with a single hidden layer with and relu activation function nn .
when constructing the models rapid m trains all models in the pool and picks the one with highest accuracy.
for each of these candidate models except nn rapid m first iteratively selects the top k important features in the footprint.
then it decides whether to use a higher order regression by comparing the models from linear and higher order features.
.
bucket determination an application s configurations may have significantly different behaviors in terms of the system footprint they introduce and their performance degradation under different system workloads.
however these configurations can be clustered into a limited number of groups with configurations within each group sharing similar behavior i.e.
introduce similar workloads to the system and suffer from similar slow down given a particular environment.
this is a key observation that allows rapid m to summarize configuration spaces with only limited information loss.
figure shows the dendrogram of hierarchically clustered configurations in one of our benchmark applications ferret by system footprints using wards minimum variance method .
the x axis shows the index of all configurations.
for simplicity we truncate the indexes of nconfigurations on the x axis and represent them by n .
branches in the graph show the result of clustering.
for example all configurations are clustered together at the root of the tree black dot .
when moving downward two sub tree s clusters are formed with size and yellow dots .
the y axis shows the distance between clusters at certain levels.
the height of each sub tree reveals the distance between the inter sub cluster e.g.
the distance between the two yellow dots is the height of the black dot .
thus configurations can be clustered into buckets with certain granularity.
configurations within each bucket have higher similarity in terms of system footprints.
the number of buckets can be determined by the distance threshold closeness of configurations in a cluster .
in figure if the threshold is all configurations can be clustered into bucket dashed line .
for each bucket a performance model is constructed to capture the relationship between slow down and the execution environment.
in figure the red number on the left represents the average prediction error mean relative error for all buckets.
using buckets reduces the configuration search space size for ferret by two orders of magnitude buckets instead of configurations .
the bucket design captures two aspects of similarity namely same system footprint switching between configurations in to the same bucket will not change the contribution of the application to the overall system workload and same slow down all configurations within a bucket suffer from the same performance degradation under a given environment.
the number of buckets could range from similar footprint for all configurations to n all configurations have a unique footprint .
having more buckets results in higher configuration similarity but increases the problem size while fewer buckets could hurt the accuracy of m model and the p model s.rapid m implements a variant of hierarchical clustering as described in algorithm .
first a standard hierarchical clustering procedure generates the initial buckets satisfyingthe distance threshold tdis first cut .
then we evaluate each bucket by training the p model with of its observations then validating with the remaining .
if the p model accuracytaccthreshold is not satisfied we iteratively refine the bucket that have the worst p model accuracy until the threshold is satisfied.
lower tdisand taccmay result in more buckets or a more accurate p model but will increase the size of the problem.
in rapid m we usetdis andtacc .
the particular choice of these numbers was based on our experiences with our sample applications.
input all configs tdis tacc result buckets buckets buckets h cluster buckets criterion dis tdis first cut err worst id evaluate buckets while err taccdo refine clustering of the worst bucket tmp buckets h cluster buckets criterion number buckets tmp buckets err worst id validate buckets end return buckets algorithm bucket determination online configuration manager the goal of rapid m is to find a global optimal configuration for all active applications.
by grouping configurations into buckets the size of the global search space is reduced from all combinations of application configurations to all combinations of application buckets reducing the search space by multiple orders of magnitude.
the global optimization problem is solved in two steps finding the globally optimal bucket for each application and finding the optimal configuration within each bucket.
the global manager provides each local manager with a particular globally optimal configuration together with all feasible configurations in the bucket to which the optimal configuration belongs.
the latter information allows the local manager to change configurations if needed without impacting configuration choices in other applications.
algorithm describes the runtime algorithm to compute the optimal global configuration.
it has the property that if the predicted slow downs p model s and the predicted configuration interactions m model are correct accurate within an error threshold then the selected local configurations are globally optimal under the user defined time constraints and priority weights assuming all active applications can successfully finish the remainder of their execution.
the global configuration manager is invoked each time an application starts an active application terminates or an active application requires a new bucket assignment.
global reconfiguration may also be triggered every fixed time interval or may be requested by local configuration managers i.e.
a local controller if due to system uncertainties no feasible configuration in the assigned fcgs set meets the application s execution time constraint.
353global cost quality management across multiple applications esec fse november virtual event usa figure dendrogram of clustering configurations into buckets vertical bar shorter higher inner cluster similarity dots with numbers number of configurations in a cluster sub tree percentage number p model prediction error sample applications to assess the practical end to end effectiveness of rapid m we implemented and evaluated a prototype system.
the evaluation uses six sample applications which have been used in multiple related works in approximation swaptions bodytrack ferret facedetection svm and neuralnet nn .
swaptions financial analysis application.
computation is based on iterative simulation.
output quality is defined as the average accuracy loss across all swaptions calculated.
it has 10configurations.
bodytrack computer vision application that tracks a set of human body components from a video frame by frame.
the output quality is calculated by evaluating the position accuracy loss percomponent in all frames.
bodytrack hastwo knobs number of annealing layers from number of particles to track sampled within with 50configurations in total.
ferret image similarity application that returns the top kimages in a database for a query image ranked by content similarity using a multi probe lsh algorithm.
we use a common ranking score function shown in eq err k z k i z rank i rank i i srank i i trank i withq err k k here z is the set of result images appearing in bothlist1andlist2.
s and t are the sets of images appearing exclusively in list1andlist2.kis the size of set s or t and zis the size of z. rank 1is the rank of an image in list1 andrank the rank inlist2.
in our case we use the execution output as list1 and the default output as list2.ferret has three knobs number of probe bucket sampled within number of hash tables and number of iterations to compute earth mover s distance .
ferret has emph700 configurations in total.facedetection object detector that detects human faces from a series of input images based on haar cascade .
we adopt the standard measurement of recognition performance the f score .
facedetection has three knobs pyramid levels sampled within neighbors pixels to examine and the minimum number of eyes with 90configurations in total.
svm andnn two supervised image classifiers.
they run iterations on a set of labeled data and construct a support vector machine and a neural network model.
classification accuracy is used as the quality.
both svm andnnhave three knobs learning rate sampled within batch size regularization rate resulting in 250configurations.
all our applications are input dependent i.e.
the cost execution time for each work unit can vary for different inputs.
ferret has the most significant deviation of cost per work unit mean .85ms std .
has the least deviation mean .22ms std .
such dependency shows the necessity of adjusting the configuration dynamically re configuration even when the application is running alone.
the problem gets more complex in multi programming environments with cross application interference.
rapid m implementation therapid m framework is implemented as a set of offline and online modules.
during new application development or adapting an existing application for execution within rapid m the application developer has to provide information to rapid m s offline local module via provided simple apis.
such information includes the arguments needed to run each application quality notions to evaluate application outcomes through profiling and configuration space specification.
items and are implemented as a python module and item is a separate configuration file.
this information enables the offline application profiler to automatically 354esec fse november virtual event usa liu liu sibren isaacman and ulrich kremer input set ofnapplications with user specified execution time constraintsti for i n. for each application set of buckets with associated p model s bucket footprints and cost quality models.
a target machine m model .
result termination or bucket selection for each application i bi.
foreach bucket combinations do determine global footprint gfp using m model gfp m fp b1 fp b2 ...fp bn determine vector of slow down factors sdf for each bucket using the bucket specific p models pb sdf foreach bucketbido determine set of feasible configurations fcgs that satisfy the execution time constraint trem ifor the remainder of the execution fcgs bi c bi sdf cost c remaining workunits c trem i iffcgs then reject bucket combination and break end compute the maximal quality configuration mqcg bi of all feasible configurations of bi mqcg bi cwithqual c qual cx for all cx fcgs bi end compute the global quality gq as a n iqual mqcg bi end select valid non rejected combination of buckets with maximal gq bmaxq bmaxq ... bmaxq n return to each application iits bucketbmaxq iand feasible configurations fcgs bmaxq i .
if no bucket assignment for an application select terminate .
algorithm global configuration manager collect profiling data for an application and is necessary for any system where offline modeling is required e.g.
opentuner .
the information is needed for offline construction of p m model s and bucket partitioning and online configuration management to track application progress through monitoring completion of work units.
the offline model training is performed on the target platform to produce the system footprints and stresser workloads.
the artificial stresser workloads are generated by linux s stress tool .
in contrast to other approaches e.g.
esp rapid m collects each application s profile data and constructs the models independently of other applications making rapid m easily scalable.
the offline generated information is represented in an application profile and stored on the rapid m server which also hosts the online global configuration manager.
just before application execution the application user specifies an execution time budget cost budget .
during application executions the global configuration manager keeps track of all active applications progress and their remaining budgets.
it then determines bucket assignments for each application using algorithm .
application start and termination figure rapid m overview solid border boxes provided byrapid m dashed border required from developers.
events trigger the reevaluation of the local bucket assignments in addition to explicit requests from local controllers.
each active application has its own local controller which communicates with the global configuration manager to receive bucket assignments or to request global bucket reassignments.
the local controller is responsible for selecting the optimal configuration within its assigned bucket.
configurations in the same bucket shares similar footprints thereby local reconfiguration can be performed safely without impacting the overall system footprint visible by other applications i.e.
performance impact on others is small.
figure shows the rapid m framework overview.
the rapidmprofiler and learner for model construction and prediction are implemented in python.
the local runtime controller is a c library with api s to be integrated into source code.during runtime it communicates with the online global configuration manager in php .
the manager communicates with the learner via sockets.
local application profile it is designed as a data collector for the developers to train the application for rapid m required models.
the profiler requires the developer to specify individual knob settings the output quality evaluation and application execution instructions.
table shows the profiling strategy of rapid m .
for each configuration ci rapid m s profiler runs ktests.
the first run is a base run where applications execute alone on the target system using ci measuring the base cost c output quality q and system footprint v. then the profiler runs the application ktimes each with a different stresser .
for each run rapid m records the system footprint of the stresser when running alone vs the overall system footprint vas and the execution time of the application cas executing with the stresser.
the value of kcan be set by developers with a default value of .
larger kwill collect more slow down observations resulting in higher profiling overhead.
global learner after the profiler s collect the training data the data is sent over to a global server for model construction.
during the training the learner constructs updates the m model for the machine uses all observed system footprint from all applications x y 355global cost quality management across multiple applications esec fse november virtual event usa table data collected by rapid m profiler data description usage base runc cost when alone calculate slow down v footprint when alone m model construction q output quality online selection stress run cost when app stressers calculate slow down footprint of stressers m model construction overall footprint of app stressersm model construction p model construction computes the bucket for the application uses the observed system footprint of all configurations constructs the p model for the bucket uses overall system footprint and slowdown for the application x y update the bucket based on the prediction accuracy global manager during the initialization phase after the learner finishes the bucketization p model construction for the application and updates the m model the models will be stored on the server.
summary information will be kept as app profile for runtime control.
during runtime the manager keeps track of the state of all applications on the target machine.
there are four cases when running applications need to contact the server before execution the application notifies the server that it is about to run so that the server can predict the slow down for all the currently active applications.
re configuration the application actively requests a new bucket assignment when no configuration in the current bucket can satisfy the budget constraint.
routine check the application periodically checks with the server for updated bucket assignments.
this is needed since the assignment can be changed when new applications start on the same machine.
by default rapid m performs a routine check after each of the total work units.
after execution the application reports the termination of the execution to let the server re evaluate the slow down for the remaining applications.
each application on the machine is in a state of either active or idle.
all active applications will also be associated with a budget .
the manager updates the global bucket selection whenever a new request comes in except routine check.
local controller the global manager returns the optimal bucket assignment for an application along with an optimal configuration within the bucket based on the remaining budget and execution progress reported by the application.
the local controller deploys the configuration.
however unexpected disturbances like input dependencies may affect the real execution time for the application.
the local controller adapts the application behavior by re selecting the optimal configuration within the assigned bucket.
model validation rapid m predicts the performance degradation slowdown of an application by first predicting the overall system footprint using the m model and then the per application slowdown with the corresponding p model .
the prediction accuracy relies on the quality oftable selected model and features.
poly polynomial features used mre slowdown prediction error configs buckets model poly mre swaptions br t bodytrack br br t t ferret 5en br br br ent t t t f2 facedetect en br br t t t svm 4ls lr br brt t f t1 nn 5br br br ls brt t t f t2 both m model andp model s.rapid m constructs the p m models from a set of publicly available models as discussed in section neural net nn with hidden layer and neurons using relu as the activation function linear regression lr lasso ls regression with cross validation elastic net en regression with cross validation and bayesianridge br regression.
the rapid m framework uses a modular design and allows developers to add more models to the model pool.
bucketing with p model the purpose of bucketing configurations is to reduce the search space size from the number of all configuration combinations to the number of combinations of buckets.
however this approach requires a good prediction of both system environments and bucket slowdowns.
therefore besides the footprint similarity the number of buckets is determined by the accuracy of the per bucket slowdown model p model .
in table the column named configs buckets shows the number of buckets constructed from the total number of configurations.
column model and poly report the type of model and whether the model use polynomial features or not.
column mre reports the per bucket meanrelative error of slow down prediction.
the different models types and features selected by rapid m show the need for model customization.
comparing to esp where elastic net is used across multiple applications rapid m locates the best model on an application bucket level.
rapid m reduces the overall problem size by clustering large configuration spaces into a few buckets while still providing an accurate slowdown prediction with an error below and .
on average which justifies the feasibility of this approach.
system profile prediction with m model m model validation uses system footprints consisting of features.
for space reasons we do not list per feature prediction accuracy.
on average rapidmhas an r2 score of .
for all features with an mre of .
.
optimality validation though the prediction accuracy of the p model is high see table m model predicted overall system footprint is used when applying the p model during runtime since the future behavior of the system cannot be measured.
errors due tom model prediction errors can impact slow down prediction accuracy which negatively effects bucket and configuration selection.
we conduct another simulation to investigate how the error propagation from m model top model would affect selection optimality.
the experiment first runs an application with a stresser and records the footprint of the application fpa the footprint 356esec fse november virtual event usa liu liu sibren isaacman and ulrich kremer figure impact of error propagation on optimality hit rate and quality loss under different budget scales.
of the stresser fps the overall environment env and the application slowdown sd.
with the performance profile of the application the optimal configuration coptcan be computed using sd.
we then compute the selected optimal configuration cpby using the slowdown predicted by applying the p model toenv.
finally we predict the environment envmby applying the m model to and predict the slowdown using the p model onenvm then make the selection cm p. the difference between coptand cm porcpis caused by the error in the p model with or without them model .
we evaluate such difference in terms of hit rate whether the selection is identical and quality loss relative loss of quality caused by the error calculated by q q qwhere q andqdenote the quality of the configuration picked by the strategy and the optimal configuration respectively.
since coptis the optimal configuration found offline any selection that yields a higher quality than coptwill also be considered a loss of quality for under estimation of the cost.
we run the simulation covering the whole range of possible budgets for each application from to ofmax min wheremax andmin represent the highest and lowest cost of all configurations when running alone.
figure shows the optimality evaluation result of the simulation.
the x axis represents the available budget percentages.
the lines following the left y axis report the average prediction correctness of the configuration selection across all applications e.g means that the optimal configuration from rapid m gives the exact same configuration as the oracle.
the bars following the right y axis show the relative loss of quality.
the loss of quality is computed by comparing the quality outcome with optimal configuration under the budget as determined by offline measurement against the configuration computed by p model with or without them model .
note that p strategy cannot be used in the real deployment of rapid m but is only intended to show the impact of prediction errors caused by the p model alone.
bucket selection is performed at runtime using the m model however we assume the same bucket selection for both the p and m p models in this simulation.
as shown in the graph if the environment is known the error in p model contributes to of selection difference as the optimal.
the errors of combining m model andp model result in different configuration selections on average in .
of the cases.however the wrongly selected configuration is close to the optimal configuration i.e.
suffers only up to a output quality loss with an average of .
.
this indicates that the embedded errors in m model andp model affect the output quality to a limited extent.
rapid m experimental evaluation we conduct several experiments to show the effectiveness of key components of our approach.
these experiments concentrate on showing the ability of rapid m to produce configuration selections of high quality.
the evaluation methodology compares possible configuration selection strategies with rapid m on different sets of concurrently active applications.
we define the following alternative configuration selection strategies which are constructed either as extensions to existing single application approaches or multi application strategies for other problems e.g.
esp for scheduling .
the strategies differ in what information they use to determine each application s configuration.
contextoblivious co applications are not aware of each other.
slowdown caused by other applications is treated as noise.
awareshare as this strategy is partially inspired by esp .
it measures the overall environment of different combinations of benchmark applications offline using their default configurations ignoring buckets .
then it applies the p model on the recorded environment to select optimal configurations.
this strategy is only used as an oracle in static evaluation where the application combination is known before execution.
rapid m rm this strategy utilizes the full power of rapid m configurations are clustered into buckets the m model predicts the system environment and p model s predict slowdown.
rapid m with rush to end rm rush this strategy extends rapid m with a rush to end feature that artificially increases the predicted slowdown up to .5x when of the work units are completed and the remaining budget is no more than of predicted cost.
this is designed as an insurance policy that tries to avoid failing an execution after most of the work has been done.
equalshare es each application divides its assigned resource budget by the number of concurrently active applications.
this reduced budget is used to determine the application s configuration.
always low low use lowest cost configuration for execution.
table strategies used for comparison utilizes m modelslowdown for n appsavailable in evaluation co .
static dynamic as p measured static rm p m static dynamic rm rush rush p m dynamic es n static dynamic low dynamic table summarizes the differences between the strategies.
the slowdown prediction aggressiveness increases going down the table.
for each possible group of two to six sample applications and three 357global cost quality management across multiple applications esec fse november virtual event usa a low budget scale b medium budget scale c high budget scale figure static configuration selection comparison under different budgets scales.
different budget constraint levels high medium low we measured the overall combined quality outcomes of the applications.
.
global reconfigurations static the first set of experiments assesses the effectiveness of the different strategies under a controlled static environment where the number of executed applications is fixed.
an optimal strategy would select single configurations for each application that together maximize the global quality.
each application starts at the same time and reconfiguration is disabled.
the result will indicate how well the strategies work in modeling the interactions across active applications.
if an application finishes before other applications it will restart with the same configuration until all applications finish at least once thereby maintaining the overall system environment.
strategies are evaluated on three aspects violation execution time provided budget.
misprediction no feasible configuration can be found by the strategy though there exists at least one.
exceeding rate fraction the execution time exceeds the budget e.g.
rate .
indicates twice the budget.
figures 4a 4b and 4c show the performance of the computed global configurations by the different selection strategies for low medium and high resource budgets time deadlines for each application.
the scales are defined the same as in figure .
note that even if an application gets of budget scale it still may not be able to run with the highest configuration because of the overall system workload.
the results show that .
of executions using coviolate the budget when the system is not busy active apps and .
when busy.
rapid m has a violation rate of .
and .
respectively.
as a comparison the designed oracle asviolates .
and .
due to either errors in thep model input dependencies or minor system effects since no reconfiguration is performed.
for executions that violates the budget rapid m exceeds the budget by an average of .
.
coexceeds the budget by .
on average and up to .
espredicts the slowdown too aggressively and .
of executions die because no feasible configuration can be provided resulting in misprediction .
generally budget violation could be rescued by reconfiguration during runtime.
however more frequent violations along withhigher exceeding rate puts more pressure on the dynamic reconfiguration.
this experiment shows that rapid m lowers the violation rate by .
compared to cowith a small exceeding rate of .
.
.
global reconfigurations dynamic the second set of experiments shows the overall performance of rapid m with local and global reconfigurations.
we evaluate the performance of rapid m by dispatching different applications starting at random times to mimic the unpredictable real world execution pattern each with a given budget.
each application gets to reconfigure during the execution.
we first generate a series of execution traces showing when to start which application by giving each application infinite budget such that all applications finish successfully with the highest setting i.e.
best configuration producing the highest possible output quality mission in figure .
for each generated trace mission we repeat the trace with shrinking budgets to force reconfiguration using different strategies.
different strategies are evaluated on four aspects rejection failing to find a feasible configuration at application start time.
reported as a rate.
success finishing the execution within budget reported as rate.
reconfiguration number of reconfigurations in response to changes in performance.
more frequent reconfiguration is usually caused by the mismatch between the real and predicted execution.
output quality normalized overall output quality from to .
for applications that successfully finish.
the quality achieved by the lowest setting is .
a failed execution is penalized by a negative quality of .
.
an application has to terminate successfully with a valid configuration in order to be considered in the overall quality.
to demonstrate the performance in different scenarios we run the experiment with a threshold nsuch that the simulator will stop dispatching new applications when there are nactive applications.
figure shows an example of the experimental results for executions using coandrapid m with a minute execution trace where n .
as shown in the graph executions using co are more likely to fail shown as dashed lines followed by crosses during the middle of execution due to underestimating the slowdown.
however only two runs failed using rapid m excluding the two runs that got rejected shown as crosses .
we omitted the 358esec fse november virtual event usa liu liu sibren isaacman and ulrich kremer figure sample execution using different strategies for a mission trace top left length min n budget scale .
.
figure averages from dynamic configuration selection on mission traces and low medium high cost budgets.
trace for other strategies due to space limitation.
low finishes all executions indicating that there exists at least one solution that successfully executes the trace.
esrejects most executions due to overestimating the slowdown.
as for rm rush one of the failed runs is rescued by adding the rush to end strategy.
figure summarizes the results of traces of minutes each repeated with multiple budget settings using different strategies.
quality is calculated as the average per run quality across all traces.
quality per application run is calculated by the raw quality value normalized by its quality range as discussed above.
.
and .
indicate the lowest and the highest quality .
different quality notions are application specific and discussed in section .
to summarize espredicts the slowdown so aggressively that it rejects most executions and has .
of rapid m s success rate.
on a core machine rapid m achieves a .
higher success rate than existing approaches modeled by co when the system is not busy active apps and .
higher when busy.
this translates to .
and .
higher output quality.
furthermore rapid m achieves its improvement while reducing the number of reconfigurations to40 ofco.rm rush further improves the quality by an average of .
higher by enabling more applications to finish.
.
off line and runtime overheads we evaluate rapid m on both off line profiling model training and runtime reconfiguration on a single socket machine with cores at .7ghz and 16gb of ram at 2666mhz.
off line overhead rapid m and existing approaches for single application configuration selections occur overheads due to training of different models.
these off line training times can be substantial sometimes in the order of days.
if fact meantime reported training times of up to two weeks for a single application.
the overhead is determined by the configuration space and the length of per configuration training needed for collecting meaningful results.
table summarizes the offline overheads of using rapid m .
the second column reports the number of lines of code changes required from the developer to integrate rapid m library calls into the original source code.
the column configs reports the total number of configurations for each application.
the column profiling shows the time required to collect the performance data.
the last column reports the time to construct the buckets and their pmodel s. as shown in the table the effort required from the developer is minimal as compared to the relatively large configuration space.
however the data collecting phase can be time consuming with an overhead proportional to the complexity of the application.
table rapid m implementation with offline overheads loc changesoffline training overhead configs profilingbucket and p model constr swaptions .
mins .
secs bodytrack .
mins .
secs ferret .
hours .
secs facedetect .
hours .
secs svm .
hours .
secs nn .
hours .
secs runtime overhead the dynamic overhead is measured as the average time an application has to wait for the server s answer and 359global cost quality management across multiple applications esec fse november virtual event usa the local reconfiguration time if the bucket assignment changed.
overall the average turnaround time of requesting a bucket assignment is 201ms using an off the shelf system.
the major part of the overhead comes from the online application of the m model andp model s. therefore the overhead can be further reduced by selecting a more powerful server and or a network with lower latency.
the average execution time overhead experienced by each application was less than of their execution time.
challenges and limitations rapid m uses the system footprint as a key abstraction to represent configurations.
however this assumes the availability of hardware counters metrics for cost model construction.
in our experience the model accuracy dramatically relies on the training coverage the stresser .
with growing diversity of the target applications we expect rapid m to need more training to refine its models.
since we predict the combined global execution environment through iteratively applying the m model the error may propagate resulting in decreased prediction accuracy.
related work exploiting application interference has been explored by several research groups in the context of non configurable applications.
in addition using approximation and reconfiguration as an optimization opportunity has been discussed in multiple works recently.
configuration management several control theoretical approaches aim to deal with runtime disturbance.
jouleguard and caloree combine machine learning with control theory to overcome the shortcomings in each strategies when used separately.
probabilistic and approximate programming use probability variables and their distributions .
this research focuses on how to represent such distributions and operations on these distributions induced by operations on their associated probabilistic approximate variables.
in the database community approximation has been used to provide statistical error bounds on queries and more recently in the context of hadoop map reduce applications .
these works target single user environments and interference between multiple active applications is ignored.
these approaches could be deployed in rapid m as the local controller selection strategy.
performance prediction significant research focuses on constructing cost models.
learning based models predict performance through either input or execution features with model accuracy bound by the richness of the data set and introducing runtime overheads.
our work uses a similar approach to predict the slowdown for each configuration rather than the base performance in the single application scenario.
control theoretical approaches aim to deal with runtime disturbance.
however to directly extend these approaches to multiprogramming environments the model has to be built on the entire search space which is infeasible due to the size.
even getting the profile for a single large application may take weeks .
interference prediction optimizing the behaviors of groups of applications in a multi programming environment has been the goal of different research efforts.
models for predicting application interference have to deal with the non linear impact of resource sharing on individually observed application performance slowdowns.
d factor explores the inter application performancedegradation through computing the slow down factor measured by the degradation when running with computation or memoryintensive stressers.
however d factor requires the measurement of current system footprints to perform the prediction.
the esp system is similar to our approach since it measures specific system footprints for different applications.
since approximation is not considered each application has only a single footprint resulting in a very small set of samples over which to train their model.
also esp requires the actual training process of kapplication running simultaneously to support the prediction of slow down among up tokapplications.
in contrast our approach is based on large configuration spaces for each application.
each application is trained individually making our approach more flexible since groups of applications do not have to be known and trained in advance which makes rapid m s approach much more scalable.
conclusion to the best of our knowledge rapid m is the first framework that enables effective and efficient approximation configuration management across reconfigurable applications that execute concurrently on the same system.
rapid m dynamically adapts multiple applications together at the same time allowing the selection of configurations across all active applications that together result in the highest overall quality while respecting each application s resource budget here execution time .
without the global optimization applications with only local adaptation may encounter a higher failure rate and lower overall quality.
the global impact of a local configuration selection is predicted through local configuration system footprints a global model that combines different footprints and a performance model that considers the overall system environment.
rapid m significantly reduces the configuration search space of each application by up to two orders of magnitude through clustering configurations with similar behaviors into buckets thereby allowing the exploration of the entire overall global search space.
for each of such bucket rapid m constructs a specialized performance model with average prediction error of and a machine model for predicting overall system environments.
applications can be trained independently.
such a design along with the reduced search space makes rapid m scalable.
experimental results using six applications and different concurrent traces of application start and exit events show that rapid m is able to select globally optimal configurations.
compared to other possible approaches rapid m makes configuration selections that lower the average budget violation rate by .
with an average exceeding rate of .
.
at runtime rapid m successfully finishes .
more executions which results in a .
improvement of output quality under high system loads.
for our benchmark applications the overhead of rapid m is within of the application s execution time.
all code and raw data sets are available on github at https github.com niuye8911 rapid m.