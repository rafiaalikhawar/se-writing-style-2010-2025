automatically matching bug reports with related app reviews marlo haering university of hamburg hamburg germany haering informatik.uni hamburg.dechristoph stanik university of hamburg hamburg germany stanik informatik.uni hamburg.dewalid maalej university of hamburg hamburg germany maalej informatik.uni hamburg.de abstract app stores allow users to give valuable feedback on apps and developers to find this feedback and use it for the software evolution.
however finding user feedback that matches existing bug reports in issue trackers is challenging as users and developers often use a different language.
in this work we introduce deepmatcher an automatic approach using stateof the art deep learning methods to match problem reports in app reviews to bug reports in issue trackers.
we evaluated deepmatcher with four open source apps quantitatively and qualitatively.
on average deepmatcher achieved a hit ratio of .
and a mean average precision of .
.
for problem reports deepmatcher did not find any matching bug report.
when manually analyzing these problem reports and the issue trackers of the studied apps we found that in cases users actually described a problem before developers discovered and documented it in the issue tracker.
we discuss our findings and different use cases for deepmatcher .
index terms app store analytics natural language processing deep learning mining software repositories software evolution i. i ntroduction the app market is highly competitive and dynamic.
google play store andapple app store offer together more than million apps to users.
in this market it is essential for app vendors to regularly release new versions to fix bugs and introduce new features as unsatisfied users are likely to look for alternatives .
user dissatisfaction can quickly lead to the fall of even popular apps .
it is thus indispensable to continuously monitor and understand the changing user needs and habits for a successful app evolution.
however identifying and understanding user needs and encountered problems is challenging as users and developers work in different environments and have different goals in mind.
on the one hand software developers professionally report bugs in issue trackers to document and keep track of them as illustrated in figure .
on the other hand users voluntarily provide feedback on apps in e.g.
app reviews as shown in figure using a different often non technical and potentially imprecise language.
consequently seriously considering and using app reviews in software development and evolution processes can become time consuming and error prone.
app vendors can regularly receive a large number of user feedback via various channels including app stores or social media .
manually filtering and processing such feedback is challenging.
in recent years research developedapproaches for filtering feedback e.g.
by automatically identifying relevant user feedback like bug reports and feature requests or by clustering the feedback to understand how many users address similar topics .
while these approaches are helpful to cope with and aggregate large amounts of user feedback the gap between what happens in the issue tracker and what happens online in the user space remains unfilled.
for instance developers remain unable to easily track whether an issue reported in an app review is already filed as a bug report in the issue tracker or to quickly find a related bug they thought is already resolved.
additionally user feedback items often lack information that is relevant for developers such as steps to reproduce or versions affected .
to address this gap we introduce deepmatcher which is to the best of our knowledge the first approach that matches official and technically written bug reports with informal colloquially written app reviews.
deepmatcher first filters app reviews into problem reports using the classification approach by stanik et al.
subsequently our approach matches the problem reports with bug reports in issue trackers using deep learning techniques.
we use the state of the art contextsensitive text embedding method distilbert to transform the problem report and bug report texts into the same vector space.
given their vector embeddings we then use cosine similarity as a distance metric to identify matches.
for randomly sampled problem reports submitted by users of four google apps deepmatcher identified matching bug reports when configured to show three suggestions per problem report.
in about cases deepmatcher did not find any matches.
we manually searched for these cases in the issue trackers to check whether there are indeed no matching bug reports.
we found that in cases developers would have benefited from deepmatcher as no corresponding bug reports were filed.
we also qualitatively analyzed the context sensitive text embeddings which identified recurring bug reports and cases in which users reported problems before developers documented them.
we found that our approach can detect semantically similar texts such as draining vs. consuming battery and download vs. save pdf filling the gap between users and developers language.
our qualitative analysis further revealed cases of recurring and duplicated bug ieee acm 43rd international conference on software engineering icse .
ieee fig.
.
list of bug reports from the issue tracker of the app signal messenger.
reports.
we share our replication package1for reproducibility.
the remainder of the paper is structured as follows.
first we introduce deepmatcher in section ii explaining our design rationales.
section iii introduces our evaluation setting including the research questions data and process.
section iv presents our quantitative and qualitative evaluation results.
then we discuss how developers can use and modify deepmatcher to detect bugs earlier and enrich existing issue descriptions with information extracted from user feedback in section v. finally we discuss the threats to validity in section vi related work in section vii and conclude the paper in section viii.
ii.
a pproach figure shows an overview of deepmatcher s technical approach.
the input of deepmatcher is a problem report an app review describing a problem with an app and a bug report summary.
in section ii a we discuss how we automatically identified problem reports from the review.
section ii b describes the text embedding creation process shown in the middle part of the figure.
this represents the transformation of textual data into numeric values which we then use to calculate a similarity value as explained in section ii c. a. automatic problem reports classification challenges.
one of the major problems when working with user feedback is the vast amount that software developers receive.
particularly in app stores pagano and maalej showed that developers of popular apps receive about app reviews daily.
when considering twitter as an alternative feedback source twitter accounts of popular software vendors receive about tweets daily .
besides the amount the quality of the written feedback differs.
most of the received app reviews simply praise e.g.
i like this app or dispraise e.g.
i hate this app!
.
however developers are particularly interested in the user experience feature requests and problem reports .
our approach uses automatically classified problem reports from app reviews and subsequently matches them to bug reports in issue trackers.
fig.
.
example problem report for nextcloud answered by the app developer.
approach and rationale.
we applied a four step process to filter relevant app reviews.
first we removed all user feedback containing less than ten words as previous research has shown that such feedback is most likely praise or spam and does not contain helpful information .
second we downloaded the replication package of stanik et al.
and applied thebug report feature request and irrelevant classification approach to also filter the user feedback for bug reports.
the classification reduced the initial number of app reviews to problem reports.
fourth to check the reliability of the classification we randomly sampled and manually analyzed automatically classified app reviews for each of the four studied apps for manual analysis.
two coders manually checked if the classified problem reports were correctly classified.
in case of disagreement we did not include the app review but sampled a new one.
we repeated this step until we had verified problem reports for each app which is in total.
b. text representation with word embeddings challenges.
we further convert the text into a numerical presentation for further interpretation.
in natural language processing practitioners usually transfer texts into vectors by applying techniques including bag of words tf idf or fasttext .
when representing text in a vector space we can perform calculations such as comparing text similarity which becomes essential in a later step for identifying matches.
selecting the right word embedding technique is crucial as it decides how precisely the vectors represent the text.
we face two major challenges.
first users and developers usually use different vocabularies.
user feedback is more prone to spelling mistakes often contain emoticons.
moreover users write mostly in an informal colloquial and non technical way.
second bug reports are usually written in a more formal way e.g.
following templates containing metadata and may provide technical information like stack traces .
approach and rationale.
both data sources consist of different text components.
while user feedback consists of a single text body bug reports have a summary and a detailed description.
the description may contain a long explanation including steps to reproduce stack traces and error logs.
we determined which text components of the bug report to include for the calculation of the text embedding.
previous research showed that the detailed bug report description contains noise 971when i type into the search box s it type s random words on it s own even when i delete the random words it adds words in it s not my prediction keyboard that s messing up it only happens on firefox.
i am able to type words in firefox search bar but unable to type anything in the websitesproblem report bug report summarydistilber t tokenizer spacy tokenizerdistilber t pos t aggercontextualized embeddings nounstoken mappingembedding text embedding bug report embeddingproblem report embedding cosine similarity .
automatic problem report classificationapp reviews relevant matchfig.
.
overview of the deepmatcher approach.
for information retrieval tasks .
in particular it contains technical details that users usually omit in their user feedback .
further research shows that the summary already contains the essential content of the long description .
therefore we calculated the word embeddings only based on the bug report s summary.
regarding the word embedding technique we chose distilbert a light weight version of bert that is trained with a fewer number of parameters but has a similar generalization potential.
alternative techniques would be e.g.
bert xlnet or roberta.
but as distilbert requires significantly fewer hardware resources and training time it is more applicable for various development teams.
our technique first tokenizes the input text and then calculates vectors for each token.
compared to other text representations like bag ofwords or tf idf these vectors are contextualized they consider the context of the surrounding words.
for example the two sentences i love apples and i love apple macbooks contain the token apple .
contextualized embeddings take into account that the token s semantics differs in these two sentences.
in our approach distilbert creates a dimensional contextualized embedding for each token.
we calculated the document embedding from the individual token embeddings.
to reduce the weight of frequent but unimportant words such as i have or to previous research in text mining suggests removing stopwords .
in our approach we went one step further and only included embeddings of nouns which we can automatically detect with a part of speech pos tagger.
we carefully decided to remove other parts of speech like the verb tokens as first trials showed that including frequent verbs like crash freeze and hangs heavily biased our results toward these terms.
for example deepmatcher would match the app crashes when i open a new tab problem report with firefox crashes on the home screen bug report because the verb crash puts the vectors of both texts closer together.
based on this design decision deepmatcher weights essential words i.e.
nouns that describe components or features higher while the contextualized token embeddings still contain information about the surrounding context e.g.
the verbs.
as a result deepmatcher e.g.
emphasizes the nouns new tab and home screen in the previous example and therefore would not consider the bug and problem report as a potential match.
another positiveside effect of the surrounding context is that it helps to deal with misspelled words as their surrounding context is usually similar to the correct word s context.
therefore distilbert calculates similar embeddings for them.
the automatic noun detection of the input texts is part ofdeepmatcher and uses spacy s tokenizer and pos tagger .
as spacy s tokenizer and the distilbert s tokenizer split the input text into different token sequences we mapped the two sequences to each other by aligning them using pytokenizations.
for calculating the embedding for the full text of the problem report or bug report s summary we added all noun word vectors of the text and averaged them.
alternatively we could have summed up the noun word vectors but decided to average them as the cosine similarity function depends on the vector angles and not on their lengths.
therefore the choice of summing or averaging would not influence the cosine similarity score in our approach.
c. identifying relevant bug reports for a problem report challenges.
given the numerical representation of the problem report and the bug report deepmatcher finally requires a method to decide whether a bug report is relevant for a problem report or not.
the main challenge in this task is calculating matching problem reports and bug reports with short text similarity .
besides semantic features research tried text similarity approaches like simple substring comparisons lexical overlap or edit distances .
kenter and de rijke state that these approaches can work in some simple cases but are prone to mistakes.
approach and rationale.
we considered two options for this task.
one option is to model this task as a binary classification problem using the two classes relevant or not relevant .
however this approach would require a large labeled dataset to train a classifier for this task which is expensive and timeconsuming .
therefore we chose the second option which models this task as an information retrieval task.
given a problem report as a query we designed deepmatcher to return a ranked list of suggested relevant bug reports.
we chose a distance function to measure the similarity between the two text embeddings and further rank the bug report summaries in decreasing order.
two popular similarity measures for text embeddings are the euclidian similarity and cosine similarity .
the 972euclidian distance can increase depending on the number of dimensions.
in contrast the cosine similarity measures the angle of the two text vectors and is independent of their magnitude.
the benefit is that it results in a similarity value of if the two vectors have a zero degree angle.
a non similarity occurs when the vectors have a degree angle to each other.
previous research showed that cosine similarity performs equally or outperforms other similarity measures for dense text embedding vectors which is why we also used it fordeepmatcher .
iii.
e mpirical evaluation a. research questions apps usually receive user feedback as app reviews which may contain the user s opinion and experience with the software.
our study focuses on the app review category problem reports which is about users describing a faulty app behavior.
figure shows an example of a problem report.
bug reports are issues in an issue tracker complying with a certain template and contain information including summary body app version timestamp and steps to reproduce.
figure shows a list of four bug report summaries of the signal messenger app in github.
our evaluation focuses on the following research questions rq1 how accurate can deepmatcher match app reviews with bug reports?
in this research question we analyze if we can identify bug reports in issue tracker systems for which users wrote app reviews.
for example a developer filed the following bug report i am able to type words in firefox search bar but unable to type anything in the websites .
can we find app reviews that describe the same issue like the following app review?
when i type into the search box s it type s random words on it s own even when i delete the random words it adds words in it s not my prediction keyboard that s messing up it only happens on firefox.
rq2 what can we learn from deepmatcher s relevant and irrelevant matches?
to answer this question we checked a sample of relevant and irrelevant matches.
we analyzed cases in which contextual embeddings identify words with similar meanings the language gap between developers and users recurring bug reports and a potential chronological dependency between problem reports and bug reports.
we highlight our findings and explain them with examples from our dataset.
b. evaluation data for creating the evaluation data we first collected app reviews and issues of four diverse apps.
we selected the apps firefox browser vlc media player signal messenger and nextcloud cloud storage to cover different app domains and usage scenarios in our analysis.
as pagano and maalej showed most app reviews rather represent noise for software developers as they only contain praise like i like this app or insults like this app is trash .
therefore wetable i overview of the evaluation data.
app name bug reports app reviews time periodcounttime periodcountproblem reports firefox browser01 vlc media player05 signal messenger12 nextcloud06 total applied the bug report classification approach from stanik et al.
to identify problem reports.
we chose this classification approach as it uses state of the art approaches achieves high f1 scores of for english app reviews and we could include the replication package in our pipeline without major modifications.
eventually we created a random sample from the collected data that we then used in the evaluation.
as our study is concerned with matching problem reports found in app reviews with bug reports documents in issue trackers we collected both problem reports and bug reports.
in our study we decided to evaluate our approach against four popular open source android apps which stretch over different app categories.
we cover the categories browsing firefox media player for audio video and streaming vlc a cloud storage client nextcloud and a messaging app signal .
as these apps use different issue tracker systems to document bug reports we developed crawlers for bugzilla firefox trac vlc and github nextcloud and signal .
for each app we collected all bug reports from the issue tracker systems.
as a requirement for our analysis each bug report contains at least an id summary and status e.g.
open and resolved as well as the creation date.
additionally we also collected the remaining data fields provided by the issue tracker systems such as issue descriptions and comments.
a complete list of the collected data fields is documented in our replication package.
we then collected up to app reviews of the corresponding apps following google s default sort order by helpfulness .
sorting by helpfulness helped us to not only considering the most recent app reviews sort by date but also emphasized the app reviews that other users deemed helpful.
for nextcloud we could not collect more than app reviews as it seems that from their total reviews in the google play store reviews only contain a star rating without any text.
our app review dataset covers a time frame of two to four years.
in total we were able to collect app reviews from the google play store.
after applying the problem report classifier we could reduce the number of app reviews to problem reports.
table i summarizes our study data.
the table reveals that while the time range of bug reports covers at least four years firefox has the highest number of bug reports filed from 973january to august .
in total we collected bug reports of which belong to firefox.
we focused on bug reports but ignored other issues like feature or enhancement requests by filtering the issues that developers labeled as such in the issue tracker systems.
c. evaluation method we evaluated deepmatcher with respect to quantitative and qualitative aspects.
starting from a set of manually verified problem reports deepmatcher suggested three bug reports for each.
we evaluated how accurately deepmatcher finds matching bug reports based on their summaries for a given problem report.
we conducted a manual coding task which consisted of two steps.
in the first step we classified the app reviews using an existing approach into problem reports to remove irrelevant feedback such as praise and dispraise f1 score of .
for english app reviews .
then we randomly sampled problem reports per app and manually verified whether the classified app reviews are problem reports.
two coders independently annotated the classification results according to a coding guide from previous research .
we randomly sampled new problem reports until we reached verified problem reports per app which made in total.
in the second step we used deepmatcher to calculate three suggestions of potentially matching bug reports for each of the problem reports.
again two coders independently read each problem report and the three suggested bug reports.
for each matching the coders annotated whether the match is relevant or irrelevant.
we consider the match relevant if the problem report and the bug report describe the same app feature e.g.
watch video and behavior e.g.
crashes in full screen .
for example for the problem report latest update started consuming over battery.
had to uninstall to even charge the phone!
deepmatcher suggested the relevant bug report match only happening with latest version but keep getting ffbeta draining battery too fast .
we documented the inter coder agreement and resolved disagreements by having the two coders discussing each.
we report further analysis results based on the resolved annotations.
to answer rq1 we calculated deepmatcher s performance.
we report the number of relevant irrelevant matches found per app and the mean average precision map .
it describes the average precision avep for each problem report pand its suggestions and then calculates the mean over all problem reports p map pp p 1avep p p this is a conservative evaluation metric because it assumes that we have at least three relevant bug reports per problem report.
if this is not the case even a perfect tool cannot achieve the highest average precision .
however in our setting the actual number of relevant bug reports is unknown.
therefore we additionally report on the hit ratio which describes theshare of problem reports for which deepmatcher has suggested at least one relevant match.
for the irrelevant matches we further tried to manually find relevant bug reports in issue trackers.
we further analyzed deepmatcher s similarity score to identify a possible threshold which users can use for the relevance assessment.
to answer rq2 we conducted a qualitative analysis of the data.
for each app we analyzed the language of app reviews and bug reports by counting the nouns used in both datasets in relation to the nouns used overall.
we highlight the strength of contextual word embeddings and show how deepmatcher matches different words with similar semantic meaning.
we further analyze the cases in which developers report a bug report after a user submitted a related problem report in the app store.
iv.
e valuation results this section reports the results of our evaluation study.
we analyze deepmatcher s cosine similarity values to understand if we could use a certain similarity score threshold to identify matching problem reports and bug reports.
further we report on our qualitative analysis and describe relevant and irrelevant suggestions to find potential ways to improve automatic matching approaches.
a. matching problem reports with bug reports rq1 as introduced earlier we sampled problem reports per app in total and applied deepmatcher to suggest matching bug reports.
in the first step deepmatcher suggested one matching bug report per problem report.
then we changed that parameter and let deepmatcher suggest two matching bug reports.
finally deepmatcher suggested three matching bug reports per problem report which led to suggestions.
since deepmatcher suggests bug reports based on the highest cosine similarity it added one additional suggestion per step while keeping the previous ones.
this way we could evaluate deepmatcher s performance based on this parameter number of suggestions .
two authors independently annotated each of the bug report suggestions as either a relevant or irrelevant match.
table ii summarizes the overall result of the peer coding evaluation.
the table shows that the inter coder agreement for the whole dataset suggested bug reports per problem report is .
from the matching bug report suggestions the two coders identified developer relevant matching suggestions.
these suggestions occurred in problem reports with the parameter number of suggestions set to three.
multiple relevant matches occurred either for generic problem reports like the app crashes often or for similar recurring or duplicated bug reports in the issue tracker.
suggestions without relevant matches .
for problem reports deepmatcher could not find a relevant match within the three suggestions.
the reason for this is twofold either no relevant bug report actually exists in the issue tracker system ordeepmatcher missed relevant matches.
to understand why deepmatcher did not identify any matches for problem 974table ii results of the manual coding for o pen source apps each with a ppreviews .
legend m ean average precision map number of suggested bug reports .
app suggestion suggestions suggestions maphit ratio maphit ratio maphit ratio relevant matchescoder agreement firefox .
.
.
.
.
.
.
vlc .
.
.
.
.
.
.
signal .
.
.
.
.
.
.
nextcloud .
.
.
.
.
.
.
total ?
.
?
.
?
.
?
.
?
.
?
.
?
.
reports we manually searched the issue tracker systems by building a query using different keyword combinations from the problem reports.
for example table iii shows a problem report of vlc for which deepmatcher could not find a relevant matching bug report.
however in our manual check we found the bug report when the device s ui language is rtl no controls are shown in the notification card which the two coders consider a relevant match.
for problem reports we could not find any relevant match in the issue tracker system while deepmatcher missed potentially relevant matches in cases.
consequently deepmatcher identified problem reports that were undocumented in the issue trackers.
this can help developers create new bug reports.
average mean precision and hit ratio .
we calculated the mean average precision map and the hit ratio of our manual annotated data for all three parameters one suggestion two suggestions and three suggestions .
the map is a conservative score which assumes that each problem report has at least as many relevant bug reports in the issue tracker as the parameter states.
for example if we set the parameter for the number of suggested bug reports to three the map score assumes that at least three relevant matching bug reports exist.
in case the problem report has less than three relevant bug reports the average precision for that problem report cannot get the maximum value of one .
for our calculation we excluded the problem reports for which we could not find a relevant bug report manually.
the hit ratio on the other hand is the number of problem reports for which deepmatcher found at least one relevant match divided by the number of all problem reports.
table ii shows the map and the hit ratio scores for each parameter setting.
increasing the parameter from one to two shows that the map score increases by while the hit ratio increases by which means that we increase the chance of finding a relevant match to .
when further increasing the parameter to three we observe that the probability of having at least one relevant match increases to however as the map score reveals developers might have to consider more irrelevant matches.
we found that for nextcloud deepmatcher achieved the highest mean average precision .
and hit ratio .
.
in contrast vlc achieved the lowest scores with a map of .
and a hit ratio of .
.
averaged over all apps deepmatcher achieved a mean average precision of .
and firefox vlc signal nextcloud app0.
.
.
.
.
.95similarity matching bug report false truefig.
.
similarity values for relevant and irrelevant matches per app.
a hit ratio of .
.
cosine similarity analysis .
we analyzed the cosine similarity values of relevant bug report suggestions and the irrelevant bug report suggestions.
figure shows the cosine similarity values for the manual labeled suggestions for each app.
it shows that the medians of the similarity scores of relevant bug report matches are higher than the irrelevant matches.
however the similarity scores vary between their min and max values by up to .
all similarity scores are overall high as all texts are in the technical domain.
we found that vlc has the lowest cosine similarity score compared to the other apps which is also the app for which deepmatcher found the fewest relevant bug report matches matches .
the lower cosine similarity indicates a higher language gap between vlc problem reports and bug reports.
to further analyze this indication we calculated the overlap of nouns used in problem reports with the nouns used in bug report summaries.
we only checked the noun overlap as this is the part of speech category deepmatcher uses to generate matches.
for each app we calculated the ratio between the number of nouns used in problem reports and bug reports and the number of nouns used overall.
the apps ratios are firefox vlc signal and nextcloud .
the noun overlap calculation strengthens our assumption that the language between the vlc problem reports and the bug report summaries diverge more than the other apps which negatively 975affects deepmatcher s automatic matching approach.
b. qualitative analysis of deepmatcher s relevant wrong and missed suggestions rq2 we summarize and describe qualitative insights to learn about deepmatcher s relevant and irrelevant suggestions.
table iii provides examples of problem reports deepmatcher suggested bug report summaries and our coding of whether we think that there is a relevant match for developers.
in the table we selected one problem report per app and searched for cases that highlight some of our insights like recurring bug reports for signal or a problem report submitted long before a bug report was filed in the nextcloud app.
in the following we discuss our findings.
strength of contextual embeddings .
one strength of our approach is to learn the context of words which words belong together .
other approaches like bag of words or tf idf do not consider the context of words and therefore fall short in representing a deeper understanding of the language.
the following two examples illustrate the strength of word context.
deepmatcher suggested matches that included the phrases automatic synchronization and auto upload in nextcloud bug reports as well as download pdf and save pdf for the firefox browser.
one full example is shown in table iii.
the firefox problem report discusses a consuming battery problem that happens since the latest update .
the relevant matching bug report states that the battery draining becomes a problem in the latest version .
it shows that the contextual embeddings of the noun tokens e.g.
synchronization and upload reach a high text similarity score as they are considered closely related.
language gap leads to fewer relevant matches .
during the manual coding task we noticed that the phrasings in vlc s bug reports often contain technical terms for example freeze entire android os when playing a video.
libvlc stream unknown box type ctim incompletely loaded .
however users are typically not part of the development team and do not include technical words like specific library names used by the developers.
our previously reported plot of the cosine similarity values in figure quantitatively indicated that there might be a language gap as the text similarity scores between problem reports and bug reports were the lowest for vlc.
we then performed a noun overlap analysis which strengthened the indicator for the language gap as vlc has the lowest noun overlap with .
eventually we looked into the problem reports bug reports the google play store and the issue trackers.
we found that the developers of nextcloud sometimes reply to problem reports in the google play store and ask the users to also file a bug report in the issue tracker systems.
we do not know how many users are actually going to the issue tracker to report a bug.
but this could also explain why nextcloud has the highest cosine similarity score and highest noun overlap .
consequently deepmatcher is more accurate if bugreport summaries contain non technical phrases as users rarely use technical terms.
sometimes users do not understand the app features.
the following example from a signal problem report shows a user confusing a feature with a bug works well but gives me check marks immediately after sending my text.
i know the receivers are not reading the texts so fast.
why checkmarks?
the two checkmarks in signal are shown as soon as the addressed user successfully received the message.
signal has an optional feature that changes the color of the two checkmarks to blue if the recipient reads the message.
recurring bug reports .
table iii shows an example of recurring bug reports.
the problem report of the signal app states that the user did not receive notifications of incoming messages.
we considered all three matching bug report suggestions of deepmatcher as relevant as they state the same problem.
the interesting insight in this example is that with deepmatcher we were able to identify a recurring bug report as the first one was filed in september the second in january the third in april .
the problem report of the user happened in october more than one year after the last suggested match.
in section v c we discuss how deepmatcher can help systematically find such cases.
date case analysis .
regarding the date analysis we found that in of relevant matches developers reported the bug reports after the users submitted the corresponding review in the google app store.
the time differences of the cases in which the problem report submission happened before the bug report is days later on average.
in the following we illustrate three examples.
table iii shows one problem report for nextcloud submitted in october while the matching bug report was filed in july .
another user submitted the following problem report on the nextcloud app autoupload not working android otherwise all seems good.
happy with app and will increase stars to when auto upload is working.
deepmatcher identified the matching bug report android auto upload doesn t do anything that was created days after the problem report.
in the last example a developer documented a matching bug report days after the corresponding problem report for the signal app.
both the user and the developer address the in app camera feature newest update changes camera to add features but drastically reduces quality of photos.
now it seems like the app just takes a screenshot of the viewfinder rather than taking a photo and gaining from software postprocessing on my phone.
.
the bug report stated in app camera shows different images for preview and captured .
v. d iscussion this section discusses potential use cases of deepmatcher to support developers in their software evolution process.
a. detecting bugs earlier it is essential for app developers to address users problems as their dissatisfaction may lead to the fall of previously 976table iii example problem reports from app reviews and deepmatcher s suggested matching bug reports .
the relevant column shows whether the two coders annotated the suggestions as relevant for developers .
problem report suggested bug report summary relevant date report only happening with latest version but keep getting ffbeta draining battery too fastyes date report the topbar on android phone becomes white which makes the time and battery life invisible.noapp firefox date report latest update started consuming over battery.
had to uninstall to even charge the phone!
date report offline version snackbar is displayed when device is very low on power and in battery saving modeno date after update no notification sent with textsecure message.
i have to open the app to see if there s something newyes date report no notifications show up until the app is manually openyesapp signal date report it is a good app.
i am mostly satisfied with it but sometimes the notifications would not work so i would not know that someone messaged me until i open the app.
it might have been fixed because it hasn t been happening in the last month or so.
would recommended.date report not getting notification in real time unless i open the appyes date report android navigation bar shown after a click shifts and resizes full screen videono date report play pause button icon is not shifting while pausing the audio on notification areanoapp vlc date report so many bugs... plays in background but no controls in notifications.
when you tap the app to bring up the controls the video is a still screen.
navigating is a pain.
resuming forgets my place constantly.
basically unusabledate report on video playing the navigation bar is not hidden on some tabletsno date report nextcloud android client can t login but android webdev clients dono date report autoupload stuck on waiting for wifi when using vpnyesapp nextcloud date report i have a nextcloud server and the way i access my server is via openvpn.
the problem now is the nextcloud native app doesn t work through vpn.
it is an odd behavior.
i highly recommend to use owncloud app instead.date report securityexception in ocfilelistadapter uid cannot get user data for accounts of type nextcloudno successful apps .
one way to cope with user satisfaction is to quickly fix frustrating bugs which may cause users to switch to a competitor and submit negative reviews.
however bugs may occur for different reasons.
some bugs affect only a few users with specific hardware or software versions while others affect a large user group.
further not all bugs are immediately known to developers particularly non crashing bugs which are hard to discover in automated testing and quality assurance .
our results show that some users submit problem reports in the google play store months before developers document them as bug reports in the project s issue tracker.
when considering additional feedback channels such as social media and other stores this might get even worse.
our qualitative analysis of bug reports shows that these earlier submitted problem reports contain valuable information for app developers such as the affected hardware.
therefore we emphasize that developers should continuously monitor user feedback in app stores to discover problems early and document them as bug reports in their issue trackers .for this purpose developers can first apply the automatic problem report classification of app reviews and subsequently usedeepmatcher to find existing matching bug reports.
in case deepmatcher does not find matching bug reports we suggest that developers should consider the problem report as an unknown bug.
however to avoid the creation of duplicate bugs we further suggest checking the issue tracker beforehand.
mezouar et al.
suggest a similar recommendation for developers when considering tweets instead of app reviews.
they show that developers can identify bugs .
days earlier for firefox and .
days earlier for chrome on average .
we envision different ways to suggest new bugs to developers.
first we could build a system that shows newly discovered bugs to developers.
from that system developers can decide to file a new issue in the issue tracker delay or reject it.
alternatively a bot can e.g.
file a new issue in the issue tracker systems automatically .
for the latter future research could develop e.g.
approaches could prepare certain text artifacts including steps to reproduce meaningful issue description or context information in a template for creating 977a new issue.
furthermore deepmatcher s application is not limited to user feedback in the form of app reviews.
our approach can generally process user feedback on various software which developers receive via different channels including app stores social media platforms like twitter and facebook or user support sites.
deepmatcher s main prerequisite is written text.
b. enhancing bug reports with user feedback martens and maalej analyzed twitter conversations between vendors support accounts like spotifycares and their users.
similarly to our statement the authors highlight that users who provide feedback via social media are mostly non technical users and rarely provide technical details.
as support teams are interested in helping users they initiate a conversation to ask for more context and details.
they ask for context information like the affected hardware device the app version and its platform.
their objective is to better understand the issue to potentially forward that feedback to the development team and provide more helpful answers.
hassan et al.
show that developers also communicate with their users in the app stores to better understand their users.
zimmermann et al.
show that the most important information in bug reports are steps to reproduce stack traces and test cases.
the participants of their survey found that the version and operating system have lower importance than the previously mentioned information.
however the authors also argue that these details are helpful and might be needed to understand reproduce or triage bugs.
nevertheless the authors did not focus on apps but developers and users of apache eclipse and mozilla.
developers could further use deepmatcher to understand the popularity of bugs.
they can achieve this in two steps.
first change deepmatcher to take bug reports as an input to suggest problem reports inverting the order as reported in the approach .
second the parameter for the number of suggestions can either be increased or removed to enable suggesting all problem reports sorted by the similarity to the given bug report.
this leads to an aggregated crowd based severity level a bug popularity score or an indicator of how many users are affected by a certain bug report.
we further envision extracting context information and steps to reproduce from user feedback to enhance the issue tracker s bug report description.
having this information at hand can help developers narrow down the location of an issue and understand how many users are affected.
developers can use deepmatcher to find problem reports related to bug reports by simply using a bug report summary as the input in our approach.
then developers can skim through the suggested problem reports select those that seem relevant and then check whether they contain relevant context information.
in case users did not provide useful information developers can take the ids of the relevant problem reports and request more information from users in the google play store.
this process can partly be automated e.g.
using bots.c.
extending deepmatcher to identify duplicated recurring or similar bug reports in section iv we found that deepmatcher identified recurring bug reports.
the signal example in table iii shows a recurring bug report.
within the three bug report suggestions deepmatcher found three relevant matches.
while the first bug report was filed in september the second in january the third in april a user reported the problem again in october .
consequently developers might want to adapt deepmatcher to either find recurring similar or duplicated bug reports even though it is not deepmatcher s primary goal.
however since the approach evaluates the matches based on contextsensitive text similarity it could lead to promising results.
developers interested in these cases could for example increase deepmatcher s parameter number of matching bug report suggestions and use a bug report summary as the input fordeepmatcher to identify these cases.
future work could investigate and evaluate the use of deepmatcher for such cases by utilizing our replication package.
vi.
t hreats to validity we discuss threats to internal and external validity.
concerning the internal validity we evaluated deepmatcher by manually annotating suggested bug reports for problem reports.
we performed two annotation tasks.
one task to verify that the automatically classified app reviews are problem reports and one to annotate whether deepmatcher s suggested matches are relevant for developers.
as in every other manual labeling study human coders are prone to errors.
additionally their understanding of a relevant match may differ which could lead to disagreements.
to mitigate this risk we designed both annotation tasks as peer coding tasks.
two coders each with several years of app development experience independently annotated the bug report matches.
for the verification of problem reports we used a well established coding guide by maalej et al.
which stanik et al.
also reused for the automatic problem report classification.
to mitigate the threat to validity regarding the annotation of relevant matches we performed test iterations on smaller samples of our collected dataset and discussed different interpretations and examples to create a shared understanding.
further we tried to collect a representative sample of meaningful app reviews.
thereby we collected up to app reviews for each app ordered by helpfulness covering more than two years.
we did not aim for a comprehensive app review sample for a specific time frame but prioritized a meaningful app review sample from a larger time frame.
thereby we could identify diverse insights within our qualitative analysis.
another potential limitation is that we only considered app reviews per app in total which we automatically classified as problem reports.
this classification might only find a specific problem report type neglecting other informative problem reports.
other kinds of app reviews including 978feature requests or praises might also contain valuable information for developers which deepmatcher could match to bug reports.
therefore our observations might differ for another sample of app reviews.
in the case deepmatcher could not find any matching bug report among the three suggestions we manually searched for relevant bugs in the issue trackers.
we queried different term combinations and synonyms for certain features and components similar to how developers would proceed.
however not finding a relevant match in the issue tracker systems does not prove the non existence of a relevant bug report in the issue tracker as we could have missed important terms in the query.
concerning the external validity our results are only valid for the four open source apps of our dataset.
we considered different app categories covering many tasks that users perform daily by including firefox as an app for browsing the internet signal for messaging nextcloud for cloud storage and vlc as a media player for music videos and streaming.
however these app categories include popular apps that we do not cover in our study like chrome or safari.
further the bug report suggestions could differ for closed source projects or apps of other mobile operating systems.
vii.
r elated work a. user feedback analytics feedback driven requirements engineering is an increasingly popular topic in research often focusing on app reviews tweets product reviews such as amazon reviews or a combination of reviews and product descriptions .
all of them have in common that a software product already exists and that users rate and write their experience with it after using it .
user feedback and involvement are important to both software engineers and requirements managers as they often contain insights such as introduced bugs and feature requests .
the classification of user feedback was a first step towards understanding user needs.
further studies looked at the classified feedback more closely by analyzing and understanding user rationale the reasoning and justification of user decisions opinions and beliefs.
once a company decides to integrate for example an innovative feature request in the software product it will be forwarded to the release planning phase .
in our approach we build on top of the existing body of research by in particular applying the machine learning approach of stanik et al.
to identify problem reports in app reviews.
we used that approach as an initial filter of the app reviews because pagano and maalej showed that popular apps receive about app reviews daily which would be unfeasible for us to filter manually.
since the classification approach has an f1 score of .
for identifying problem reports in english app reviews we had to manually check the classified app reviews as described in section iii b.b.
combining user feedback and bug reports el mezouar et al.
present a semi automatic approach that matches tweets with bug reports in issue tracking systems.
they look at the bug reports of the two browsers firefox and chrome.
they use natural language processing techniques to preprocess the text of both data sources and apply the lucene search engine to suggest potentially matching bug reports.
the approach crawls preprocesses filters and normalizes tweets before they match them with issues.
during the crawling process the authors include tweets that either mention the browser with the symbol or hashtag.
then they remove misspellings abbreviations and non standard orthography.
afterward the authors filter tweets with a list of bug related keywords like lagandcrash while also considering negated bug terms with a part of speech analysis.
in a final step the approach removes symbols punctuation non english terms and stems the words using the porter stemmer .
for matching tweets with issues the authors extract keywords from the tweets and use them as a search query in the lucene search engine2.
in contrast to el mezouar et al.
we consider app reviews from app stores.
while tweets allow for lengthy conversations with stakeholders that may lead to in depth insights into e.g.
the users context like the app version and steps to reproduce app stores enable developers to reply to app reviews and users to update their review .
app reviews also contain metadata like the hardware device and the installed app version that information is only available to the app developers .
further stakeholders can ensure that users address the app the user wrote reviews for.
when analyzing tweets and the software is available on multiple platforms like windows mac ios and android it is often difficult to understand which platform the user addressed without interacting with the user.
third in app reviews users can write longer texts than in tweets.
besides considering two platforms as our data source we further applied more sophisticated technical solutions by applying state of the art nlp approaches that have a deeper understanding of the language than a search engine.
we also build on top of previous research to extract problem reports from app reviews leading to more relevant results than a simple keyword based approach .
viii.
c onclusion in this paper we introduced deepmatcher an approach that extracts problem reports from app reviews submitted by users and then identifies matching bug reports in an issue tracker used by the development team.
our approach primarily addresses the challenge of integrating user feedback into the bug fixing process.
developers may receive thousands of app reviews daily which makes a manual analysis hard to unfeasible.
additionally most user feedback is either praise like i love this app.
or a dispraise like i hate it!
.
for the latter reason we first filtered the problem reports from the reviews by reusing recent related work.
after manually 979validating the problem reports we applied deepmatcher which takes a problem report and a bug report summary as the input.
deepmatcher then transforms the text into contextsensitive embeddings on which we applied cosine similarity to identify potential matching problem reports and bug reports.
in total from problem reports deepmatcher was able to identify relevant matches with bug reports.
in cases deepmatcher did not find any match.
to understand whether indeed no match exists we manually looked into corresponding issue trackers and found that in cases deepmatcher missed a potential match while in cases no bug report existed.
our results show that our approach can help developers identify bugs earlier enhance bug reports with user feedback and eventually lead to more precise ways to detect duplicate or similar bugs.
acknowledgment this work was partly supported by the city of hamburg within the forum .
project as part of the ahoi.digital funding line by the european union within the horizon eu project openreq grant nr.
and by the german federal government bmbf project ventcore .