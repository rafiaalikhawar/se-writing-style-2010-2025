pipelining bottom up data flow analysis qingkai shi the hong kong university of science and technology hong kong china qshiaa cse.ust.hkcharles zhang thehong kong university of science and technology hong kong china charlesz cse.ust.hk abstract bottom up program analysis has been traditionally easy to parallelize because functions without caller callee relations can be analyzed independently.
however such function level parallelism issignificantlylimitedbythecallingdependence functionswith caller callee relations have to be analyzed sequentially becausethe analysis of a function depends on the analysis results a.k.a.
functionsummaries ofitscallees.weobservethatthecallingdepen dence can be relaxed in many cases and as a result the parallelism can be improved.
in this paper we present coyote a framework of bottom up data flow analysis in which the analysis task of each function is elaborately partitioned into multiple sub tasks to gener ate pipelineable function summaries.
these sub tasks are pipelined and run in parallel even though the calling dependence exists.
we formalize our idea under the ifds ide framework and have im plemented an application to checking null dereference bugs andtaint issues in c c programs.
we evaluate coyoteon a series of standard benchmark programs and open source software systems which demonstrates significant speedup over a conventional paralleldesign.
ccsconcepts software and its engineering software verification and validation.
keywords compositionalprogramanalysis modularprogramanalysis bottomup analysis data flow analysis ifds ide.
acm reference format qingkai shi and charles zhang.
.
pipelining bottom up data flow analysis.
in 42nd international conference on software engineering icse may23 seoul republicofkorea.
acm newyork ny usa 13pages.
introduction bottom upanalysesworkbyprocessingthecallgraphofaprogramupwardsfromtheleaves beforeanalyzingafunction allitscallee functionsareanalyzedandsummarizedasfunctionsummaries .theseanalyseshavetwokeystrengths the permissionto make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may23 seoul republic of korea 2020association for computing machinery.
acm isbn ... .
h call graphtimefh gg figure conventional parallel design of bottom up program analysis.
each rectangle represents the analysis taskfora function.
timef0h0 f1h1 f2h2g0 g1 g2 figure the analysis task of each function is partitionedinto multiplesub tasks.all sub tasksare pipelined.
functionsummariesthey computeare highly reusable and they are easy to parallelize because the analyses of functions are decoupled.
while almost all existing bottom up analyses take advantage of suchfunction levelparallelization thereislittleprogressinimproving its parallelism.
as reported by recent studies it still needs to takeafewhours eventensofhours topreciselyanalyzelarge scale software.
for example it takes to hours for saturn and calysto toanalyzeprogramsof685kloc .ittakesabout5 hours for pinpoint to analyze about million lines of code.
with regard to the performance issues mcpeak et al .
pointed out that the parallelism often drops off at runtime and thus thecpu resources are usually not well utilized.
specifically this is becausetheparallelismissignificantlylimitedbythe callingdependence functionswithcaller calleerelationshavetobeanalyzed sequentiallybecausetheanalysisofacallerfunctiondependsonthe analysis results i.e.
function summaries of its callee functions.
to illustratethisphenomenon letusconsiderthecallgraphinfigure where the function fcalls the functions gandh.
in a conventional bottom up analysis only functions without caller callee relations e.g.
thefunction gandthefunction h canbeanalyzedin parallel.
the analysis of the function fcannot start until the analyses of the functions gandh complete.
otherwise when analyzing a call site of the function gorh in the function f we may miss some effects of the callees due to the incomplete analysis.
1thisisdifferentfromatop downmethodthatcanlettheanalysisofthefunction f runfirstbutstoptowaitfortheanalysisresultsofthefunction gwhenanalyzinga callstatementcallingthefunction g. .
oe oufsobujpobm pogfsfodf po 4pguxbsf ohjoffsjoh icse may23 seoul republic of korea qingkaishiandcharleszhang in this paper we present coyote a framework of bottom up data flow analysis that breaks the limits of function boundaries so that functions having calling dependence can be analyzed in parallel.
as a result we can achieve much higher parallelism than the conventional parallel design of bottom up analysis.
our key insight is that many analysis tasks of a caller function only depend on partial analysis results of its callee functions.
thus the analysis of the caller function can start before the analyses of its calleefunctions complete.
therefore our basic idea is to partition the analysistaskofafunctionintomultiplesub tasks sothatwecan pipeline the sub tasks to generate function summaries.
the key to the partition is a soundness criterion which requires a sub task onlydependsonthesummariesproducedbythesub tasksfinished in the callees.
violating this criterion will cause the analysis to neglect certain function effects and make the analysis unsound.
toillustrate assumethattheanalysistaskofeachfunctionin figure1 e.g.
the function f is partitioned into three sub tasks f0 f1 andf2 each of which generates one kind of function summaries.
these sub tasks satisfy the constraints that the sub task fionlydependsonthefunctionsummariesproducedbythesubtaskgjand the sub task hj j i .
as a result these sub tasks can be pipelined as illustrated in figure where the analysis of the function fstartsimmediatelyafterthesub tasks g0andh0finish.
clearly the parallelism in figure 2is much higher than that in figure1 providing a significant speedup over the conventional paralleldesign of bottom up analysis.
inthispaper weformalizeourideaundertheifds ideframework for a wide range of data flow problems known as the interproceduralfinitedistributivesubsetorinter proceduraldistributive environment problems .
in both problems the data flow functionsarerequiredtobedistributiveoverthemergeoperator.
although this is a limitation in some cases the ifds ide framework has been widely used for many practical problems such as secureinformationflow typestate aliassets specification inference and shape analysis .
given any of those ifds ide problems conventional solutions compute function summaries either in a bottom up fashion e.g.
or in a top downmanner e.g.
dependingontheirspecificdesign goals.inthispaper wefocusonthebottom upsolutionsandaimto improve their performance via the pipeline parallelization strategy.
we implemented coyoteto path sensitively check null dereferencesandtaintissuesinc c programs.ourevaluationof coyote is based on standard benchmark programs and many large scale software systems which demonstrates that the calling dependence significantly limits the parallelism of bottom up data flow analy sis.
by relaxing this dependence our pipeline strategy achieves2 speedup over the conventional parallel design of bottomup analysis.
such speedup is significant enough to make many overlylengthyanalysesusefulinpractice.insummary themain contributionsof this paper include the following weproposethedesignofpipelineablefunctionsummaries whichenablesthepipelineparallelizationstrategyforbottomup data flow analysis.
weformallyprovethecorrectnessofourapproachandapply it to a null analysis and a taint analysis to show its generalizability.id s.s f s. a g s. if a s s b else s b 0ab 0ab.
.. .
..0ab 0ab.
.. .
..0ab 0ab.
.. .
.. figure3 dataflowfunctionsandtheirrepresentationinthe exploded super graph .
we conduct a systematic evaluation to demonstrate that our approach can achieve much higher parallelism and thus runs faster thanthe state of the arts.
background and overview inthissection weintroducethebackgroundoftheifds ideframework section .
and provide an example to illustrate how we improvetheparallelismofabottom upanalysisbypartitioningthe analysisof a function section .
.
.
theifds ideframework theifds ideframeworkaimstosolveawiderangeofdataflow problemsknownasinter proceduralfinitedistributivesubsetor inter procedural distributive environment problems .
its basicideaistotransformadataflowproblemtoagraphreachability problemonthe explodedsuper graph whichisbuiltbasedonthe inter procedural control flow graph of a program.
the ifds framework.
in the ifds framework every vertex si d in the exploded super graph stands for a statically decidable dataflowfact orsimply fact dataprogrampoint si.everyedge models the data flow functions between data flow facts.
in thepaper to ease the explanation we use sito denote the program point at line iin the code.
for example in an analysis to check null dereference the vertex si d could denote that the variable d isanullpointeratline i.asfortheedgesordataflowfunctions figure3illustratesthree examples that show how thecommonlyuseddata flowfunctionsare representedas edgesinthe exploded super graph.theverticesatthetoparethedataflowfactsbeforea program point and the vertices at the bottom represent the facts after theprogram point.
the first data flow function idis the identity function which mapseachdataflowfactbeforeaprogrampointtoitself.itindicatesthatthestatementattheprogrampointhasnoimpactsonthedata flow analysis.
thespecialvertexforthefact 0isassociatedwitheveryprogram pointintheprogram.itdenotesatautology adataflowfactthat always holds.
an edge from the fact 0to a non 0fact indicates that the non 0fact is freshly created.
for example in the second functionin figure thefact aiscreated which isrepresentedby anedgefromthefact 0tothefact a.atthesametime since aisthe onlyfactafterthedataflowfunction thereisnoedgeconnecting the factbbefore and after the program point.
pipeliningbottom updataflow analysis icse may23 seoul republic of korea .bool y ... .
.int bar int a .
.
int b null .
.
... .
.
int c y ?
a b .
.
return c .
.
.... .
.
int foo .
.
int p bar null .
.
int q p .
.
int r q .
.
return r .
.
.... .... .... .... ....0q r p ............ .... ....0b c a normal flow function call flow function return flow functionto callers figure an example of the exploded super graph for a null dereference analysis.
the third data flow function is a typical function that models theassignment b a.intheexplodedsuper graph thevariable a has the same value as before.
thus there is an edge from the data flow fact ato itself.
the variable bgets the value from the variable a which is modeled by the edge from the fact ato the fact b. itisnoteworthythatthedataflowfactsarenotlimitedtosimple values like the local variables in the examples of the paper.
for example in alias analysis the facts can be sets of access paths .
in typestate analysis the facts can be the combination of different typestates .
figure4illustrates the exploded super graph for a data flow analysis that tracks the propagation of null pointers.
since line assigns a null pointer to the variable b we have the edge from the vertex s17 to the vertex s19 b meaning that we have the data flow fact b nullat line .
since line does not change the value of the variable a we have the edge from the vertex s17 a to the vertex s19 a which means the data flow fact about the variableadoes not change.
assuming that smainis the program entry point the ifds framework aims to find paths or determine the reachability relations between the vertex smain and the vertices of interests.
each of such paths represents that some data flow fact holds at a program point.
for instance the path from the vertex s4 to the vertex s12 r in figure 4impliesthat the fact r null holds at line .
the ifds method is efficient because it computes function summaries only once for each function.
each summary is a path on the explodedsuper graphconnectingapairofverticesattheentryandtheexitofafunction.thepathfromthevertex s17 a tothevertex s25 c in figure 4is such a summary of the function bar.
when analyzing the callers of the function bar e.g.
the function foo w e can directly jump from the vertex s4 to the vertex s6 p using the summary without analyzing the function baragain.
the ide framework.
theideframeworkisageneralization of the ifds framework .
similar to the ifds framework it also works as a graph traversal on an exploded super graph.
there are threemajordifferences.first eachvertexontheexplodedsupergraph is no longer associated with a simple data flow fact d but anenvironmentmappingafact dtoavalue vfromaseparatevalue domain denotedas d mapsto v .second duetothefirstdifference the data flow functions i.e.
the edges on the exploded super graph transform an environment d mapsto v to the other d prime mapsto v prime .
the third important difference is that each edge on the exploded supergraphislabeledwithanenvironmenttransformfunction which makes ide no longer only a simple graph reachability problem.instead ithastofindthepathsbetweentwoverticesofinterestsand meanwhile compose the environment transform functions labeledontheedgesalongthepaths.thesedifferenceswidenthe class of problems that can be expressed in the ifds framework.
inthispaper forsimplicity wedescribeourworkundertheifds framework.
this does not lose the generality for the ide problems because intuitively both problems are solved by a graph traversal on the exploded super graph.
.2coyotein a nutshell let us briefly explain our approach using the code and its corre sponding exploded super graph in figure where the analysis aimsto track the propagation of null pointers.
bottom up analysis.
for the example in figure a conventional bottom up analysis firstly analyzes the function barand produces function summaries to summarize its behavior.
with the functionsummariesin hand the function foothen is analyzed.
using the symbol leadstoto denote a path between two vertices a common ifds ide solution will generate the following two intraprocedural paths as the summaries of the function bar the path s17 a leadsto s25 c summarizes the function behavior that a null pointer created in a caller of the function bar i.e.
a null maybe returned back to the caller.
the path s17 leadsto s25 c summarizes the function behavior that a null pointer created in the function barmay be returned to the caller functions.
note that we do not need to summarize the path s17 leadsto s25 forthefunction bar becausethefact 0isatautologyand always holds.
icse may23 seoul republic of korea qingkaishiandcharleszhang s17 s25 c time s17 a s25 c s4 s17 a s25 c s6 p s10 r s4 s17 s25 c s6 p s10 r analyzing the function bar analyzing the function foo foo foo 2bar bar figure the pipeline parallelization strategy.
next we analyze the function fooby a graph traversal from the vertex s4 which aims to track the propagation of null pointers and produce function summaries of the function foo.
during the graphtraversal whenthecallflowfunctions i.e.
thedashededges arevisited weapplythesummariesofthefunction barandproduce two summaries of the function fooas following llbracket rrbracketbarare the summariesof the function bar the path s4 leadsto llbracket s17 a leadsto s25 c rrbracketbar leadsto s6 p leadsto s12 r summarizesthefunctionbehaviorthatanullpointer in the function foowill be returned to its callers.
the path s4 leadsto llbracket s17 leadsto s25 c rrbracketbar leadsto s6 p leadsto s12 r summarizesthefunctionbehaviorthatanullpointer in the callees of the function foowill be returned to the callers of the function foo.
our approach.
as discussed before in a conventional bottomupanalysis theanalysisofacallerfunctionneedstowaitforthe analysisofitscalleestocomplete.differently coyoteaimstoimprove the parallelism by starting the analysis of the function foo beforecompletingtheanalysisofthefunction bar.tothisend coyotepartitions the analysis of each function finto three parts based on where a data flow fact is created.
such a partition categorizes the function summaries into three groups f0 f1 andf2 which we refer to as the pipelineable summaries f0summarizes the behavior that some data flow facts created in the caller functions will be propagated back to the callersthroughthecurrentfunction.thefirstsummaryof the function baris an example.
f1summarizesthebehaviorthatsomedataflowfactscreated in the current function will be propagated back to the caller functions.
the second summary of the function barand the firstsummary of the function fooare two examples.
f2summarizesthebehaviorthatsomedataflowfactscreated inthecalleesarepropagatedtothecurrentfunctionandwillcontinuetobepropagatedtothecallerfunctions.thesecond summary of the function foois an example.
accordingtothepartitionmethod thesummariesofthefunction foois partitioned into two sets foo1andfoo2 just as illustrated in figure .
since the function foodoes not have any function parameters the set foo0is empty and thus omitted.
similarly thesummariesofthefunction barispartitionedintotwosets bar0and bar1.
since the function bardoes not have any callees the set bar2 is empty and thus omitted.
as detailed later the above partition is sound because it satisfies the constraint that summaries in the set fooionly depends on the summaries in the set barj j i .
thus we can safely pipeline the analyses of the function fooand the functionbar we can start analyzing the function fooimmediately after summariesin the set bar0are generated.
intheremainderofthispaper undertheifdsframework we formally present how to partition the analysis of a function to generatepipelineablefunctionsummaries sothattheparallelism of bottom up analysis can be improved in a sound manner.
3coyote pipelined bottom up analysis to explain our method in detail we first define the basic notations andterminologiesinsection .1andthenexplainthecriteriathat guideourpartitionmethodinsection .
.basedonthecriteria we present the technical details of our pipeline parallelization strategy from section .3to section .
.
.
preliminaries to clearly present our approach we introduce the following notations and terminologies.
program model.
given an ifds problem a program is modeled as an exploded super graph gthat consists of a set of intraprocedural graphs gf gg gh ... of the functions f g h ... .
given a function f its local graph gfis a tuple lf ef xf df ef lfis the set of program locations in the function.
ef xf lfare the entry and exit points of the function.
dfis the set of data flow facts in the function.
lf dfis the set of vertices of the graph.
ef lf df lf df is the edge set see figure .
asillustratedinfigure thelocalgraphsofdifferentfunctionsare connected by call and return flow functions respectively.
function summaries.
for any function f its function summaries are a set of paths between data flow facts at the entry point anddataflowfactsatitsexitpoint denotedas sf ef a leadsto xf b a b df .apparently wecangeneratethesesummaries by traversing the graph gffrom every vertex at the function entry.
owingtofunctioncallsinaprogram thesummariesofafunction oftendependonthesummariesofitscallees.wesayasummaryset sdepends on the other summary set s primeif and only if there exists a pathintheset sthatsubsumesapathintheset s prime.asillustrated in section .
the summaries of the function foodepend on the summariesof the function bar.
summary dependence graph.
to describe the dependence between summary sets we define the summary dependence graph whereavertexisasetoffunctionsummariesandadirectededge indicates the source summary set depends on the destination summary set.
the summarydependencegraph isbuilt based onthe callgraph.
conventionally vertices of the summary dependence graph are thesummarysets sf sg sh... andanedgefromthesummary pipeliningbottom updataflow analysis icse may23 seoul republic of korea setsfto the summary set sgexists if and only if the function f calls the function g. a bottom up analysis works by processing thesummary dependence graph upwards from the leaves.
it starts generatingsummariesin a summary set if it does not depend on other summary sets or the summary sets it depends on have been generated.
summary sets that do not have dependence relations can be generated in parallel.
problem definition.
in this paper we aim to find a partition forthesummarysetofeachfunction say sf s0 f s1 f s2 f ... suchthat a vertex of the summary dependence graph is no longer a complete summary set sfbut a subset si f i .
meanwhile to improve the parallelism the bottom up analysis based on the dependence graph should be able to generate summaries for a pair ofcallerandcalleefunctionsatthesametime.indetail thepartition needs to satisfy the criteria discussed in the next subsection.
.
partitioncriteria given a pair of functions where the function fcalls the function g weusetheset sf sg sf sg todenotethedependence relationsbetweensummarysets.generally aneffectivepartition methodmustmeetthefollowingcriteriatoimprovetheparallelism of a bottom up analysis.
theeffectivenesscriterion.
thiscriterionconcernswhether thedependencebetweensummarysetsintheconventionalbottomup analysis is actually relaxed so that the parallelism can be improved.
we say the partition is effective if and only if sf sg sf sg .
intuitively this means that some summaries in thecallerfunctiondonotdependonallsummariesincalleefunctions.thus thedependencerelationintheconventionalbottom up analysisis relaxed.
thesoundnesscriterion.
thiscriterionconcernsthecorrectnessafterthedependencebetweensummarysetsisrelaxed.wesay thepartitionissoundifandonlyifthefollowingconditionissatisfied iftheset si fdependsontheset sj g then si f sj g sf sg .
violating this criterion will cause the analysis to neglect certain functionsummariesand make the analysisunsound.
the efficiency criterion.
thiscriterionconcernshowmany computationalresourcesweneedtoconsumeinordertodetermine how to partition a summary set.
since summaries in the summary sets sfandsg areunknownbeforeananalysiscompletes theexact dependencerelationsbetweensummariesinthetwosetsarealso undiscovered.
this fact makes it difficult to perform a fine grained partition unless the analysis has been completed and we have known what summaries are generated for each function.
asatrade off conventionalbottom upanalysisdoesnotpartitionthesummarysets orequivalently sf sf and sg sg .
it conservatively utilizes the observation that all summaries in the set sfmay depend on certain summaries in the set sg i.e.
sf sg sf sg .
such a conservative method satisfies the soundnesscriterionanddoesnotpartitionthesummarysets.however apparently itdoesnotmeettheeffectivenesscriterionbecause sf sg sf sg .
2a set partition needs to satisfy i 0si f sfand i j si f sj f .
.
pipelineablesummary set partition generally it is challenging to partition a summary set satisfyingthe above criteria because the exact dependence between summaries are unknown before the summaries are generated.
we now present a coarse grained partition method that requires few precomputations and thus meets the efficiency criterion.
meanwhile italsomeetstheeffectivenessandsoundnesscriteriaand thus can soundlyimprovetheparallelismofabottom upanalysis.wealso establisha few lemmas to prove the correctness of our approach.
intuitively given a summary set sf we partition it according to where a data flow fact is created in a caller of the function f i n the current function f and in a callee of the function f. formally sf s0 f s1 f s2 f where s0 f ef a leadsto xf b a nequal0 s1 f ef leadsto eg a leadsto xf b f g a nequal0 s2 f ef leadsto eg leadsto xf b f nequalg by definition there is no edge from a non 0data flow fact to the fact0on the exploded super graph.
an edge from the fact to a non 0fact means that the non 0fact is freshly created .
thus any summary path in the set s0 fdoes not go through the fact0 meaningthatthedataflowfactiscreatedinacallerofthe functionf.ontheotherhand sinceasummarypathintheset s1 f or the set s2 fstarts with the fact it means that the non 0data flow fact on the summary path must be created in the function for a callee of the function f. specifically since a summary path in the sets1 fdoes not go through the fact 0in callee functions the non data flow fact on the summary path is created in the function f. similarly thenon 0dataflowfactonapathfromtheset s2 fmust be created in a callee of the function f. the following lemma states that generating summaries in the sets s0 f s1 f ands2 f doesnotmissanysummaryintheset sfand meanwhile does not repetitively generate a summary in the set sf.
lemma3.
.
uniontext i 0si f sfand i j si f sj f .
proof.thisfollowsthedefinitionsofthesets s0 f s1 f ands2 f. square next we study whether such a partition method follows the effectivenessandsoundnesscriteria.thekeytotheproblemisto computetheset sf sg ofdependencerelationsbetweenapair ofsummarysets si fandsj g givenanypairofcaller calleefunctions fandg.
lemma3.
.
thesetss0 f s1 f ands2 fdepend on the set s0g.
proof.this follows the fact that any summary path in a caller function may go through a callee s summary path and the set s0gis a part of the callee s summaries.
square lemma .
.
thesets2 fdepends on the sets s1gands2g.
proof.by definition a summary path in the set s2 fneedstogo through the vertex eg .
given the function g summary paths in both the set s1gand the set s2gstart with the vertex eg .
thus the sets2 fdepends on the sets s1gands2g.
square todemonstratethattheabovelemmasdonotmissanydependence relations we establish the following two lemmas.
icse may23 seoul republic of korea qingkaishiandcharleszhang s0 f s1 f s2f s0 g s1 g s2g figure6 thesummarydependencegraphforacaller callee functionpair fandg.
lemma3.
.
thesets0 fdoes not depend on the sets s1gands2g.
proof.this follows the fact that a non 0data flow fact cannot be connected back to the fact but a summary path in the setss1gands2gmuststart withthe fact .
square lemma3.
.
thesets1 fdoes not depend on the sets s1gands2g.
proof.by definition a summary path in the set s1 fdoes not go throughthefact 0inacalleefunction.however asummarypath in the sets s1gands2gmust start with the fact .
thus the set s1 f does not depend on the sets s1gands2g.
square puttinglemma .2tolemma .5together wehavethedependence set sf sg s0 f s0g s1 f s0g s2 f s0g s2 f s1g s2 f s2g whichdoesnotmissanydependencerelationbetweentheset si f andtheset sj g.thus thepartitionmethodsatisfiesthesoundness criterion.meanwhile sf sg sf sg .thus theeffectivenesscriterionissatisfied meaningthatthedependence betweenthesummarysetsisrelaxedand basedonthepartition the parallelism of a bottom up analysis can be improved.
figure6illustrates the summary dependence graph for a pair ofcaller calleefunctions fandg.apparently basedonthegraph when the summaries in the set s0gare generated a bottom up analysis does not need to wait for summaries in the sets s1gands2g but can immediatelystart generatingsummariesin the sets s0 fands1 f. .
pipeline scheduling asillustratedinfigure givenacaller calleefunctionpair fand g wehaveanalyzedthedependencerelationsbetweentheset si f and the set sj gand shown that the relaxed dependence provides an opportunity to improve the parallelism of a bottom up analysis.
however weobservethatakeyproblemhereisthatthereareno dependence relations between the sets si fandsj ffor a function f and scheduling the summary generation tasks for si fandsj fin a randomorder significantly affects the parallelism.
figure7 a illustratestheworstschedulingmethodwhenonly one thread is available for each function respectively.
in the sched ulingmethod thesets s0 fands0ghavethelowestschedulingpriority compared to other summary sets.
since all summary sets of the functionfdepend on the set s0g they have to wait for all summary sets of thefunction gto generate whichis essentially the same as a conventional bottom up analysis.
thus tomaximizetheparallelperformance givenanyfunction g weneedtodeterminetheschedulingpriorityofthesets s0g s1g andtimes1 g s2 g s0g s1 f s2 f s0f times0 g s2 g s1 g s0 f s2 f s1f times0 g s1 g s2g s0 f s1 f s2f a b c figure different scheduling methods when one thread availableforeach function.
s2g.
first as shown in figure since more summary sets depend on the set s0gthan the sets s1gands2g scheduling the summarygeneration task for the set s0gin a higher priority will release more tasksfor othersummary sets.
figures7 b and7 c illustratethetwopossibleschedulingmethodswhenforanyfunction g thesets0gisinthehighestpriority.in figure7 b the set s2ghasahigher priority than theset s1g.
since thesets2 fdependsonthesets s0g s1g ands2g ithastowaitforall summaries ofthe function gto generate leading to asub optimal scheduling method.
in contrast figure c illustrates the best case where the summary generation tasks are adequately pipelined.
to conclude the scheduling priority for any given function g should be s0g s1g s2g so that the parallelism of a bottom up analysis can be effectively improved when a limited number ofidle threads are available.
such prioritization does not affect the parallelismwhenthere are enough idle threads available.
.5 bounded partition and scheduling ideally the aforementioned partition method evenly partitions a summarysetsothattheanalysistasksforgeneratingsummariesareadequatelypipelined asshowninfigure c .however inpractice itisusuallynotthecasebutworksasfigure a wherethesets s0g ands1gare much larger than other summary sets.
apparently ifthereareextrathreadsavailableandwecanfurther partitionthesummarysets s0gands1gintotwosubsets theanalysis performancethenwillbe improvedby generatingsummariesinthe subsetsinparallel justasillustratedinfigure b .unfortunately beforea bottom upanalysisfinishes wecannot knowthe actual sizeofeachsummarysetand thus cannotevenlypartitionaset.as an alternative what we can do is to approximate an even partition.
pipeliningbottom updataflow analysis icse may23 seoul republic of korea times0 g s1 g s2g s0 f s1 f s2f times0 g s1 g s2g s0 f s1 f s2fs0 g s1 g a b figure bounded partition and its scheduling method.
considering that the analysis task of summary generation is actuallytoperformagraphtraversalfromavertex wetrytofurther partitionasummaryset si fbasedonthenumberofstartingvertices of the graph traversal.
to this end we introduce a client definedconstant 3so that after the approximately even partition the graphtraversalforgeneratingfunctionsummariesinasummary set startsfrom no more than vertices.
forexample togeneratesummariesintheset s0 f theanalysis needs to traverse the graph gffrom each non 0data flow fact at thefunctionentry.supposethefunction fhasfournon 0dataflow facts w x y z and .then theset s0 fisfurtherpartitioned into two subsets ef a leadsto xf b a w x and ef a leadsto xf b a y z .afterthepartition thegraphtraversalforboth summary sets starts from two vertices.
similar partition can be performed on the sets s1 fands2 fbut the following explanation needs to be considered.
by definition it seemsdifficulttofurtherpartitionsets s1 fands2 fbasedontheabove method because all summary paths in them start with a single vertex ef .
the key is that since the fact 0is a tautology and vertices with the fact 0are always reachable from each other thegraphtraversaltogeneratesummariesinthesets s1 fands2 fare not necessary to start from the vertex ef .
for instance since the sets1 fcontains the summary paths where data flow facts are created in the function f we can traverse the graph gffrom every vertex that has an immediate predecessor s lf .4similarly consideringthattheset s2 fcontainsthesummarypathswheredata flowfactsare createdinacalleeofthe function f wecan traverse thegraph gffromeveryvertexthathasanincomingedgefromthe callees.
with multiple startingvertices for the graph traversal we then can partitionthe sets s1 fands2 fsimilarlyas the set s0 f. itisnoteworthythatsuchaboundedpartitionaimstoparallelize the analysis in a single function and thus is applicable to both ourpipeliningapproachandtheconventionalbottom upapproach.
nevertheless it is particularly useful to improve the pipeline approach as discussed above.
3we use 5in our implementation.
4recall that anedge from the fact 0to anon 0dataflow factmeans the non 0factis freshly created.master process cyclethread process cycles queue of tasksnew task to generate summaries completed taskthread pool summary dep.
graph figure pipelining bottom up data flow analysis using athreadpool.
implementation we have implemented coyoteon top of llvm5to path sensitively analyzec c programs.thissectiondiscussestheimplementation details.
in the evaluation for a fair comparison except for the parallelstrategywestudyinthepaper allotherimplementation details are the same in both coyoteand the baselineapproaches.
.
parallelization as illustrated in figure we implement a thread pool to drive our pipelineparallelizationstrategy.inthefigure themasterprocess cyclemaintainsthesummarydependencegraphforallfunctions.
each vertex in the graph represents a task to generate certain function summaries.
whenever all of the dependent tasks have been completed it pushes the current task referred to as the active task into a queue and waits for an idle thread to consume it.
when a task is completed the master process cycle is notified so that it can continueto find more active tasks on the dependence graph.
inourimplementation insteadofrandomlyschedulingthetasks in thethread pool wealso seek todesign a systematicscheduling method so that we can well utilize cpu resources.
however itis known that generating an optimal schedule to parallelize thecomputations in a dependence graph is a variant of precedent constraintscheduling whichis np complete .
therefore we employagreedycriticalpathscheduler .acriticalpathisthe longest remaining path from a vertex to the root vertex on the dependencegraph.wethenreplacethetaskqueueinfigure 9with a priority queue and prioritize tasks based on the length of critical paths.
it is noteworthy that this heuristic scheduling method does not conflict with the pipeline scheduler presented in section .
.
the pipeline scheduler prioritizes the analysis tasks in the same function whilethecritical pathscheduleronlyprioritizesthetasks from different functions.
.
taint analysis to demonstrate that our approach is applicable to a broad range ofdataflowanalysis inadditiontothenullanalysisdiscussedin thepaper wealsoimplementataintanalysistochecktwokinds of taint issues.
first we check relative path traversal which allows 5llvm icse may23 seoul republic of korea qingkaishiandcharleszhang an attacker to access files outside of a restricted directory.6it is modeledasapathontheexplodedsuper graphfromanexternal input to a file operation.
a typical example is a path from a user inputinput gets ... to a file operation fopen ... .
second we check transmission of private resources which may leak private data to attackers.7itismodeledasapathontheexplodedsuper graphfrom sensitivedatatoi ooperations.atypicalexampleisapathfromthe password password getpass ... to an i o operation sendmsg ... .
.
pointersandpath sensitivity the null analysis and the taint analysis in coyoterequire highly precisepointerinformationsothattheycandeterminehowdata flowfactspropagatethroughpointer loadandstore operations.to resolvethepointerrelations wefollowthepreviouswork to perform a path sensitive points to analysis.
the points to analysis isefficientbecauseitdoesnotexhaustivelysolvepathconditions butrecordstheconditionsonthegraphedges.whentraversingthe graphforananalysis wecollectandsolveconditionsonapathinademand drivenmanner.in coyote weusez3 astheconstraint solvertodeterminepathfeasibility.accordingtoourexperience andmanyexistingworks path sensitivityisacritical factortomakeananalysispracticalandmaketheevaluationcloser to a real application scenario.
for instance a path insensitive nullanalysisreports false positives and thus is impractical.
afterbuildingtheexplodedsuper graphwiththepoints toanalysis we simplify the graph via a program slicing procedure which removesirrelevantedgesandvertices therebyimprovingtheperfor manceofthesubsequentnullandtaintanalyses.thissimplificationprocessisalmostlineartothegraphsizeand thus isveryfast .
as an example figure a is a program where a null pointer is propagated to the variable cthrough the store and load operations atline5andline9.weusethepoints toanalysistoidentifythe propagationandbuildtheexplodedsuper graphasillustratedin figure10 b .inthisgraph theconditionofthepropagation yand y arelabeledontheedges.figure c illustratesthesimplifiedform of the original graph where unnecessary edges like s10 ob leadsto s12 ob and unnecessary vertices like s8 ob are removed.
.
soundness our implementation of coyoteis soundy meaning that it handlesmostlanguagefeaturesinasoundmannerwhilewealso make some well identified unsound choices following the previous work .notethat coyoteaimstofindasmanybugs as possible rather than rigorously verifying the correctness of a program.inthiscontext theunsoundchoiceshavelimitednegativeimpactsasdemonstratedinthepreviousworks.inourimplementation like the previous work we use a flow insensitive pointer analysis to resolve function pointers.
we unroll each cycle twiceonboththecallgraphandthecontrolflowgraph .followingtheworkof saturn arepresentativestaticbugdetection tool wedo notmodel inlineassembly and libraryutilities suchas std vector std set and std map from the c standard template library.
6cwe 7cwe y ... .
.int bar int a int b .
.
b null .
.
... .
.
int c y ?
a b .
.
c .
.
.. .
.
..0o b co a .... ........ .... ....0o bco a y y y y a b c figure a a code snippet.
b the exploded super graph built basedon a points toanalysis.
c thesimplified graph.o aand obrepresentthememoryobjectpointedtoby aandb respectively.
yand yon the edges are the path conditions.
evaluation wenowpresenttheexperimentalsetupandtheexperimentalresults to demonstrate the effectiveness of our new parallel data flowanalysis.wealsodiscussthefactorsaffectingtheevaluationresults at the end of this section.
.
experimentalsetup our goal is to study the scalability of coyote a pipeline parallelization strategy for bottom up data flow analysis.
we did thisby measuring the cpu utilization rates and the speedup over a conventional parallel implementation.
more specifically a conventional parallel implementation only analyzes functions withoutcalling dependence in parallel just as illustrated in figure .t o precisely measure and study the scalability of our approach we introduce an artificial throttle that allows us to switch between our pipeline strategy and the conventional parallel strategy.
in this manner wecanguaranteethat exceptfortheparallelstrategies allotherimplementationdetailsdiscussedinsection 4arethesame forbothourapproachandthebaselineapproach.forinstance both approachesacceptthesameexplodedsuper graphastheinput.particularly as discussed in section .
since the bounded partition aims to parallelize the analysis in a single function it is adopted in bothourapproachand thebaselineapproachforafaircomparison.
therefore thespeedupofourapproachdemonstratedinthissectionisachievedbythepipelinestrategy i.e.
thekeycontribution ofthispaper inisolation.likethepreviouswork wedidnot compare our implementation with other tools like saturn and calysto .thisisbecausethecomparisonresultswillnotmake any sense due to a lot of different implementation details that may affect the runtime performance.
ourevaluationof coyotewasoverthestandardspeccint2000 benchmarks 8whichiscommonlyusedintheliteratureonstatic analysis .wealsoincludeeightindustrial sizedopen source c c projects such as python openssl and mysql.
these realworld subjects are the monthly trending projects on github that we are able to set up.
table 1lists the evaluation subjects.
the size 8speccint2000benchmarks pipeliningbottom updataflow analysis icse may23 seoul republic of korea table subjects for evaluation.
origin id program size kloc functions spec cint20001 mcf bzip2 gzip parser vpr crafty twolf eon gap vortex perlbmk gcc open source13 bftpd shadowsocks webassembly redis python icu openssl mysql total4 avg.
of these subjects is more than four million lines of code in total ranging from a few thousand to two million lines of code.
thenumberoffunctionsofthesesubjectsrangesfromtenstonearly eighty thousand functions with about seven thousand on average.
weranourexperimentsonaserverwitheighty intel r xeon r cpu e5 v4 .20ghz processors and 256gb of memoryrunning ubuntu .
.
we set our initial number of threads tobe twenty and added twenty for every subsequent run until themaximum number of available processors i.e.
eighty.
all the experiments were run with the resource limitation of twelve hours.
.
study of the null analysis we first present the experimental results of the null analysis in detail followed by a brief discussion on the taint analysis in the next subsection.
.
.
speedup.
table2lists the comparison results of the conventional parallel mechanism conv and our pipeline strategy pipeline for the bottom up program analysis.
each row of the table represents the results of a benchmark program including the timecostinsecondsandthespeedupforthesetwokindsofparallel mechanisms.
the speedup is calculated as the ratio of the time taken bycoyoteto that of the conventional parallel approach with the same number of threads.
we observe that the speedup achieved with threads is .
on average.
however a sthenumberofthreadsisincreasedto80 the observed speedup also increases up to faster.
using several typical examples figure 11illustrates the relation between the numberofthreadsandthespeedup.thegrowingcurvesshowthat thespeedupincreaseswiththegrowthofthenumberofthreads demonstratingthatwecanalwaysachievespeedupandhavehigher parallelismthan the conventionalparallel approach.
.
.
.
.
.
.
.
.
.
.
.
id id id id id thread speedup figure11 speedupvs.thenumberofthreads.
itisnoteworthythatsuch2 speedupissignificantenoughto makemanyoverlylengthyanalysesusefulinpractice.forexample originally it takes more than hours to analyze mysql id size 2mloc typicalsizeinindustry .thetimecostcannot satisfy the industrial requirement of finishing analysis in to hours .withthepipelinestrategy itsavesmorethan6hours makingthe bug findingtaskacceptablein the industrial setting.
.
.
cpu utilization rate.
the speedup over the conventional parallel design is due to the higher parallelism achieved by the pipelinestrategy.toquantifythiseffect weprofilethecpuutilizationratesforboththeconventionalparalleldesignandthepipeline method.figure 12demonstrates thecpuutilizationrates against the elapsed running time.
due to the page limit we only show severaltypicalonesforsomeoftheprogramsrunningwith80threads.
in the figure the solid line represents the cpu utilization rate ofour pipeline method while the dashed line represents that of the conventionalparallel design.
we can observe that for each project in the initial phase of the analysis the cpu utilization rates for both parallel designs are similar almost occupying all available cpus.
this is because the call graph of a program is usually a tree like data structure.
in the bottom half of the call graph it usually has enough independent functionsthatwecananalyzeinparallel.thus bothparalleldesigns can sufficientlyutilize the cpus.
our pipeline strategy unleashes its power in the remaining part oftheanalysis where itapparentlyhasmuchhighercpuutilization rates thus finishing the analysis much earlier.
this is because thetophalfofacallgraphismuchdenser wheretherearemore callingrelationsthanthebottomhalf.sincetheconventionalparal leldesigncannotanalyzefunctionswithcallingrelationsinparallel it cannot sufficiently utilize the cpus.
in contrast our approach splitstheanalysisofafunctionintomultiplepartsandallowsusto analyze functions with calling relations in parallel thus being able to utilize more cpus.
.
study of the taint analysis in order to demonstrate that our approach is generalizable to other analyses we also conducted an experiment to see whether the pipeline approach can improve the scalability of taint analysis.
icse may23 seoul republic of korea qingkaishiandcharleszhang table2 runningtime seconds andthespee dup over the conventional parallel design of bottom up analysis.
id thread thread thread thread conv pipeline speedup conv pipeline speedup conv pipeline speedup conv pipeline speedup .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.8hr .5hr .
.8hr .4hr .
.2hr .6hr .
.9hr .3hr .
.8hr .2hr .
.9hr .2hr .
.7hr .9hr .
.6hr .8hr .
20time out .6hr timeout .8hr timeout .4hr .8hr .6hr .
bftpd icu timetimecpu utilization rate cpu utilization rate webassembly openssltime timecpu utilization rate cpu utilization rate python mysql timetimecpu utilization rate cpu utilization rate figure12 cpuutilizationratevs.theelapsedtime.thesolidlinesrepresentthecpuutilizationrateofourpipelinemethod whilethe dashed lines represent that of the conventional parallel design.
sincetheresultof taintanalysisarequitesimilartothat ofthenull analysis we briefly summarize the experimental results in table wheretheresultsofourlargestbenchmarkprogram mysql are presented.theresultsdemonstratethat withtheincreaseofthe number of available threads the speedup of our approach overthe conventional approach also grows to in analyzing both therelativepathtraversal rpt bugorthe transmissionofprivate resources tpr bug.
.
discussion there are two main factors affecting the evaluation results the densityof the call graph and the number of available threads.
as discussed above when the call graph is very sparse the advantage of our approach is not very obvious.
for instance if functionsareallindependentoneachother allfunctionscanberun inparallel.thus bothapproachescanalwayssufficientlyutilizethe availablethreadsand thus havesimilartimeefficiency.inpractice asdemonstratedinourevaluation thecallgraphisusuallytree like.
pipeliningbottom updataflow analysis icse may23 seoul republic of korea table results of the taint analysis on mysql.
taint issues thread thread thread thread conv pipeline speedup conv pipeline speedup conv pipeline speedup conv pipeline speedup rpt time out .2hr time out .7hr time out .1hr .9hr .7hr .
tpr .3hr .6hr .
.1hr .0hr .
.4hr .9hr .
.1hr .8hr .
thus our approach can present its power in the second half of the analysisandachieves up to speedup in practice.
the number of threads is also a key factor affecting the observed speedup of our approach.
for instance if we only have one threadavailable althoughourapproachcanprovidemoreindependent tasks these tasks cannot be run in parallel.
thus both of our approach and the conventional one will emit similar results.
as illustratedbytheevaluation ourapproachcanworkbetterwhen we have more available threads.
in the cloud era we can expect that we have unlimited cpu resources and thus can expect more benefits from our approach in practice.
related work parallel and distributed algorithms for data flow analysis is an active area of research.
in this section we survey existing parallel or distributed techniques and compare them with coyote.
inordertoutilizethemodularstructureofaprogramtoparallelize the analyses in different functions developers usually implement a data flow analysis in a top down fashion or a bottom up manner.albarghouthietal .
presentedagenericframeworkto distributetop downalgorithmsusingamap reducestrategy.parallel worklist approaches a kind of top down analysis also canaddress the ifds ide problems.
they operate by processing the elementsonananalysisworklistinparallel .theseapproaches are different from ours because this paper focuses on bottom upanalysis.inouropinion thetop downapproachandthe bottom up approach are two separate schools of methodologies to implement program analysis.bottom up approaches analyze each function onlyonce and generate summaries reusable at all calling contexts.top downapproachesgeneratesummariesthatarespecific to individual calling contexts and thus may need to repeatanalyzing a function.
for analyses that need high precision likepath sensitivity repetitively analyzing a function is costly.
thus we may expect better performance from bottom up analysis when highprecision is required.
comparedtotop downanalysis bottom upanalysishasbeen traditionallyeasier toparallelize.
existingstatic analyses suchas saturn calysto pinpoint andinfer have utilized the function level parallelization to improve their scalability.
however none of them presented any techniques to further improve itsparallelism.
mcpeak et al .
pointed out that the cpu utilization ratemaydropinthedensepartofthecallgraphwheretheparallelism is significantly limited by the calling dependence.
although they presented an optimized scheduling method to mitigate theperformance issue the calling dependence was not relaxed and thefunction levelparallelismwasnotimproved.webelievethat their scheduling method is complementary to coyoteand their combinationhas the potential for the greater scalability.in contrast to top down and bottom up approaches partitionbased approaches do not utilize the modularstructureofaprogrambutpartitionthestatespaceanddistributethestate spacesearchtoseveralthreadsorprocessors.
anothercategoryofdataflowanalyses e.g.
aremodeled as datalog queries rather than the graph reachability queries in theifds ideframework.theycanbenefitfromparalleldatalog engines to improve the scalability .
recently some other parallel techniques have been proposed.
many of them focus on pointer analysis rather than general data flow analysis.
mendez lojo et al.
proposed a gpu based implementation for inclusion based pointer analysis.
eigencfa is a gpu based flow analysis for higherorder programs.
graspan andgrapple turn sophisticated code analysis into big data analytics.
they utilize recent advances onsolid statediskstoparallelizeandscaleprogramanalysis.these techniquesarenotdesignedforcompositionaldataflowanalysis and thus are different from our approach.
inadditiontoautomatictechniques balletal .
usedmanually createdharnessestospecifyindependentdevicedriverentrypoints so that an embarrassingly parallel workload can be created.
conclusion wehave presented coyote a pipelineparallelization strategythat enablestoperformbottom updataflowanalysisinafasterway.thepipelinestrategyrelaxesthecallingdependence whichconventionally limits the parallelism of bottom up analysis.
the evaluation of our approach demonstrates higher cpu utilization rates and signif icantspeedupoveraconventionalparalleldesign.inthemulti core era webelievethatimprovingthe parallelismisanimportantapproach to scaling static program analysis.