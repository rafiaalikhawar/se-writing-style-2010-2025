cats are not fish deep learning testing calls for out of distribution awareness davidberend nanyangtechnological university singaporexiaofei xie nanyang technological university singaporelei ma kyushu university japan lingjun zhou tianjinuniversity chinayang liu nanyang technological university zhejiang sci tech university chinachi xu singapore institute of manufacturing technology a star jianjun zhao kyushu university japan abstract as deep learning dl is continuously adopted in many industrial applications its quality and reliability start to raise concerns.
similar to the traditional software development process testing the dl software to uncover its defects at an early stage is an effective way to reduce risks after deployment.
according to the fundamental assumption of deep learning the dl software does not provide statistical guarantee and has limited capability in handling data that falls outside of its learned distribution i.e.
out of distribution ood data.
although recent progress has been made in designing noveltestingtechniquesfordlsoftware whichcandetectthousandsoferrors thecurrentstate of the artdltestingtechniques usually do not take the distribution of generated test data into consideration.
it is therefore hard to judge whether the identified errors areindeedmeaningfulerrorstothedlapplication i.e.
due toqualityissuesofthemodel oroutliersthatcannotbehandled bythecurrentmodel i.e.
duetothelackoftrainingdata .tofill this gap we take thefi rst step and conduct a large scale empirical study withatotalof451experimentconfigurations 42deepneural networks dnns and .
million test data instances to investigate and characterize the impact of ood awareness on dl testing.
we furtheranalyzetheconsequenceswhendlsystemsgointoproductionbyevaluatingtheeffectivenessofadversarialretrainingwith distribution awareerrors.theresultsconfirmthatintroducingdata distribution awareness in both testing and enhancement phases outperformsdistributionunaware retraining by up to .
.
ccsconcepts computingmethodologies neuralnetworks software and its engineering software testing and debugging .
keywords deep learning testing quality assurance out of distribution acm reference format davidberend xiaofeixie leima lingjunzhou yangliu chixu andjianjun zhao.
.
cats are not fish deep learning testing calls for outof distributionawareness.in 35thieee acminternationalconferenceon automatedsoftwareengineering ase september21 virtual event australia.
acm new york ny usa 12pages.
.
xiaofeixie xfxie ntu.edu.sg is the corresponding author.
introduction recently deeplearning dl achievedtremendoussuccessandis continuously adopted in many applications such as image classification speechr ecognition naturallanguageprocessing video gaming etc.
serviceoperations are supported bysimple administrative tasks outsourced to deep learning software while manufacturing further accelerates through automationvia intelligentrobotics .furthermore anincreasingdemandforautomationandintelligentsupportisalsowitnessedinsomesafety critical areas such as autonomous driving and healthcare .
as more and more dl software is applied to diverse application domains impacting our daily activities and lives its quality and reliabilityquicklyraiselotsofconcerns especiallyinthecontextof safety critical and security critical scenarios.
we have already witnessed the accidents and negative social impacts that were caused by quality issues of dl software e.g.
tesla uber accidents wrongdiagnosisinhealthcare e.g.cancerordiabetes .therefore systematic testing to uncover the incorrect behavior and understandthecapabilityofthedlsoftwareispressingandimportant which not only provides confidence in its quality but also reduces the risksafter deployment.
however different from traditional software whose decision logicismostlyprogrammedbythedeveloper deeplearningadoptsadata drivenprogrammingparadigm.inparticular themajortasks of a dl developer are preparing the training data labeling thedata programming the architecture of the deep neural network dnn andspecifyingthetrainingconfiguration.allthedecision logic is automatically learned during the runtime training phase and encoded in the obtained dnn e.g.
by weights bias and their combinations .duetothedifferencesofprogrammingparadigm the logic encoding format and the tasks that a dnn is often developedfor e.g.
imagerecognition testingtechniquesfortraditionalsoftware cannot be directly applied and new testing techniques are needed for dnns.
while somerecent progress hasbeen madein proposing novel testing criteria and test generation techniques for quality assurance of dnns it still lacks interpretation and understanding on the detected errors by such techniquesandtheirimpact.forexample itisnotclearwhethererrors are indeed caused by missing training data or insufficient training etc.
the fundamental assumption of deep learning is that ui .
oufsobujpobm pogfsfodf po vupnbufe 4pguxbsf ohjoffsjoh ase september virtual event australia david berend xiaofei xie lei ma lingjun zhou yang liu chi xu and jianjun zhao the training data follows some distribution based on which the learning algorithms train the dnn to obtain its decision logic and are able to handle future data that follow the similar distribution.
if the new unseen input data has a similar distribution as the training data deep learning provides some statistical guarantee on itspredictioncorrectnessintermsofaccuracy.however ifthenew inputdatadoesnotfollowthetrainingdata i.e.
out of distribution ood deep learning does not provide statistical guarantee on its prediction.
for example if a dnn is only trained on cat and dog data for binary classification given an input data offi sh the dnn can still produce a prediction result.
however this input data does notfollowthedistributionofcatanddogdata.hence handlingthefish datagoesbeyond the capabilityof this dnn andshould not be considered as valid input.
intuitively erroneousinputsthatfollowthedistributionoftrainingdatamayreveal thereal weaknessofthe dnnsince thednn is expected to handle such data.
on the other hand input errors thatareconsideredout of distributionmayeitherinheritnewinformation benefitting generalization as well as a domain shift or aresimplyirrelevanttothedlapplication.thereby therootcause of an error may be identified through analyzing its distribution behavior which makes us rethink how to define errorsand how to test the dnn by considering the effect on its trained distribution.
so far the data in and out of distribution analysis is still an earlyandactiveresearcharea .thechallengeofooddetection is that there is no perfect ground truth for validating whether one sampleisin distribution id orout of distribution.thecommon approach of existing techniques to overcome this problem is utilizingsignificantlydifferentdatasetstoapproximatethegroundtruth.forexample cifar 10isusedastheiddataandmnistisusedas ooddata.whenmovingintothefieldofdltesting thedifferences betweendatacanbecomemuchlessasonlyminorperturbations are employed for generating new test cases making the ood analysisofdltestdataevenmoredifficult.tothebestofourknowledge itiscurrentlystillunknownhowstate of the artdnntesting techniquesareperformingunderconsiderationoftheirdistribution behavior using existing ood detection techniques.
to bridge the gap from data distribution to dl testing activities we conduct a large scale empirical study of the impact of data distributionawarenessonthestate of the artdltestingtechniques.
inparticular weinvestigatethefollowingresearchquestionsalong four important perspectives rq1.
accuracy on the ood detection techniques.
canexisting ood detection techniques detect the ood data that is close and far to the training data?
which technique can achieve the best performance in the context of dl testing?
rq2.
relationship between mutation operators and data distribution.
mutation operators are used to generate new test cases.
thus which mutation operator is more likely to generate ood data andwhich one is more likely to generate id data?
rq3.relationshipbetweentestingcriteriaanddatadistribution.
testingcriteriaprovidethecoverageguidance which filter new test cases to cover diverse internal behaviors of dnn.
thus whatistherelationoftestingcriteriaanddatadistribution i.e.
which testing criterion is more likely to keep ood data and whichone is more likely to keep id data?
rq4.
root cause estimation for id and ood errors and robustness enhancement.
finally we estimate root causes for id and ood errors and ask which type of errors in terms ofdistributionismoreeffectivewhenusedforretraininginenhancingrobustness?
throughansweringthesequestions weaimtoidentifytheimpacts of the data distribution in deep learning testing.
in particular we use three popular datasets from computer vision domain as subjectbenchmarksandnineooddatasets togetherwithatotal of42dnnsforevaluation amongwhichwetrained32dnnsto identifytheoptimalooddetectiontechniquefordltesting.then to evaluate the effect of ood for dl testing we generate a total of over1.2milliontestcasesandtrain10dnnforrobustnessenhancement.
regarding dl testing our study further focuses on two of its key elements i.e.
mutation operators for new test generation and6coveragecriteria.allthedatasetsandresultscanbefound on our website .
to summarize this paper makes the following contributions we perform a large scale empirical study on how deep learning testingaffectsthedatadistributionofthegeneratedtestcases and how distribution aware testing influences dnn model robustness.
our study identifies the impact of mutation operators and coverage criteria on the distribution of the generated test cases.
we findthatimagerotation contrastandbrightnesstendtogenerate moreiddatawhileimageblurismorelikelytogenerateood data.
in terms of the coverage criteria nbc and snac facilitate to generate more ood data than others.
wedemonstratetheeffectivenessofdistributionawareretraining outperforming the state of the art by up to .
.
based on our results we provide guidelines on distribution aware error selectionforrobustnessenhancement by studyingthe effectof root cause of id and ood errors.
tothebestofourknowledge thisisthefirstworkthatperformed alarge scalestudyontheimpactofdatadistributionbehavioron dltesting.thisworkpointsoutanimportantdirectionandcalls fortheattentionofdata awarenesswhendesigningnewdltesting techniques.
background .
deep learning testing to test the data driven deep neural networks a common way is to generatenewdatainputssoastocapturethednnmodelbehavior and identifyerrors e.g.
incorrect prediction .the simplistic form of deep learning testing involves splitting the collected data into a training and testing set.
after training the dnn model withthe training set its accuracy is tested with the testing set.
one drawback is that it relies solely on the initially collected spectrum of information that usually does not cover all of the observable cases foran intended application.
currently quite a few techniques areproposedtotestthenewdata drivendlsoftware.coverageguidedtestingisarepresentativeandwidelyusedtechnique whichusuallycontainsthreemaincomponents the mutationoperator the coveragecriteria andthe oracle.themutationoperatorisusedto cats are not fish deep learning testing calls for out of distribution awareness ase september virtual event australia !
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
figure study workflow and research questions generate diverse test cases such that more behaviors can be tested.
for example in image classification mutation operators such as image brightness blur or contrast are applied under consideration of realistic settings.
the coverage criteria measure the degree of howmuchthednnistested.thenewlygeneratedtestcasesare keptwhentheyhaveachievednewcoverageofthednn.atlast the oracle is used to judge whether a new test case is a benign test case i.e.
correctlypredicted oranerrortestcase i.e.
incorrectly predicted .
the assumption is that the test cases are generated by adding minor perturbations on the original input so they should have the similar prediction result.
however the existing testing tools do not consider the distribution of the training data which determines what data can or cannot be handled by the target dnn.
the errors may be caused by the defects of the dnn model itself e.g.
inappropriatemodelarchitecture learningprocess orthelackof the training data.
hence it is important to distinguish the different types of errors e.g.
the id and ood errors which provides more feedback for the developers.
.
datadistributionand analysistechniques givenadatasetgiventwodatabsets aandb whichfollowthedata distributionof daanddb respectively adnnistrainedon a.if aandbhavesimilardistributions thewelltraineddnnismore likelytohandledatafrom bcorrectly.iftheyhaveatotallydifferent distribution e.g.
cat andfi sh images the dnn is not expected to handle the data from b. out of distribution techniques are mostly evaluated by distinguishing two totally different datasets from one another where a large gap in corresponding distributions of scores between daanddbis considered ood and a large overlap is considered id.
more specifically it calculates an ood score for thenewinput.ifthescoreisbelowthedefinedthreshold itisid.
otherwise it is ood.
inpractice detectingtheout of distributiondataisachallenging problem especiallyforthehigh dimensionaldata.someooddetectionhasbeenrecentlyproposedtoaddressthehigh dimensional issues such as .
these techniques provide different ways to evaluate the distribution of trainingdata.
this work inherits those techniques and studies the distribution of the test cases generated by different dl testing strategies e.g.
mutation operators coverage criteria .
overview of our study fig.1shows the overview of our study that focuses on the data distribution and its effect on test cases generated by the coverage guided testing cgt .
specifically we focus on the three main componentsofthecgtfordl theeffectof mutation ondatadistributionofthetestcases theeffectof coveragecriteria and3 the effectiveness of the outputtestcaseson robustness enhancement.
to perform the study we select three widely used datasets i.e.
mnist cifar 10andfashionmnist andfivestate ofthe art ood detection techniques i.e.
baseline odin mahalanobis outlierexposure andlikelihood ratio .
these ood detection techniques are mainly proposed to distinguish two totally different datasets e.g.
cifar and mnist .
however in this work the generated test cases are often similar to thetrainingdata.therefore wefirstdesignanexperimenttoinvestigate the effectiveness of existing ood techniques in a novel and morechallengingscenariowherethedifferencebetweendatasets forcomparisonis low i.e.
rq1 .
basedontheresultsof rq1 weselectthebestoodmetricto evaluatetherelationshipbetweenthedatadistributionandthemutationoperators.inthiswork weselectthedatasetsintheimage classificationdomain.hence weselect8popularimagetransformations which are mainly used in the existing cgt tools e.g.
deeptest deephunter andtensorfuzz .then we studywhichmutatorstendtogenerateiddataandwhichonestendtogenerateooddata i.e.
rq2 .next weevaluatetherelationship betweenthedatadistributionandthecoveragecriteriaguidance in cgt.
we select popular testing criteria to study whichcoverage criteria are more likely to guide the generation of ood or id data i.e.
rq3 .
adversarial training is a common way to enhance the robustness of dnns by including the detected error dataduringtraining.therefore wefinallystudythepossibleroot cause for id and ood errors and study the effectiveness of the oodand id data for dnn robustness enhancement i.e.
rq4 .
.
subject datasets and dnn models we select three publicly available datasets i.e.
mnist cifar10 andfashion mnist that are widely used in previous work.
for each dataset we follow the best dl practice and choose diverse dnn models that are able to achieve competitive results in ase september virtual event australia david berend xiaofei xie lei ma lingjun zhou yang liu chi xu and jianjun zhao table subject datasets and dnn models.
dataset description dnn train test acc.
cifar 10generalimages vgg .
.
e.g.
cats dogs densenet .
.
resnet .
.
mnist digitimages lenet .
.
fashionmnist fashionimages lenet .
.
terms of training and testing accuracy.
table 1shows the details about the datasets and the dnn models.
.
ood detection techniques weselect5state of the artood detectiontechniquesthatarecommonlyusedamongrelatedliterature .ood techniquesusedifferentapproachestoretrieveanoodscore.some use input perturbation and others require a specifically trained new dnn.therefore this workincludes techniqueswith various approachesas follows simple baseline .
the baseline identifies that in and outof distributionsamplesareclassifiedwithdifferentprobability distributions.thesoftmaxpredictionprobabilityisusedtodeterminewhetheran input is id or ood.
odin .
in addition to calculate the softmax prediction probability proposed by the baseline odin adds temperature scaling totheinputaswellassmallinputperturbations.theyshowthat small perturbations have stronger effects on in distribution samples rather than out of distribution samples achieving higher id oodclassificationperformance.
mahalanobis .
mahalanobis detection technique integrates the information from all layers into the score calculation.
it takes the closest class for each layer adds small noise to the test sample andfinally computes the score by measuring the mahalanobisdistance betweenthetestsampleandtheclosest class conditionalgaussiandistribution.
outlierexposure .outlierexposurestandsoutbyclassifyinginputswithaseparatelytraineddnnwhichisexposedtothe sametrainingdataasthednnusedfortheapplication.however inaddition out of distributiondataisintegratedintothetraining procedure of the outlier exposure dnn model.
afterward the maximumsoftmaxprobabilityistakensimilartothebaselinefor out of distributiondetection.
likelihood ratio .
the latestcontribution of thefi eld utilizes a separately trained dnn namely a generative dnn model withpixelcnn architecture .theyuseanestimateofinputcomplexitytoderiveaparameter freeoodscore whichcan be seen as a likelihood ratio .
.
evaluation metrics of ood detection out of distributiondetectionfordltestingimposesnewchallenges to the ood detectionfi eld as the compared data inherits more similarities whiletheood detectiontechniquesaredesignedon datasetswithsignificantdifferencessuch ascomparing imagesof birds cifar and street signs of houses svhn .
therefore we firstselectauroctocomparetheeffectivenessofdifferentood detectiontechniques for rq1 ingeneral andadditionally tprnto selectathresholdbasedonwhichtheooddetectorcandistinguish iddataandooddata for rq2 .aswewillseelater havingtable mutation operators and coverage criteria.
mutationpixel level affine trans .
tools contrast blur translation scale deeptest deephunter brightness noise shear rotation tensorfuzz criterianeuralcoverage nc deepxplore deeptest k multisectionneuron coverage kmnc deepgauge strongneuron activation coverage snac top kneuron coverage tknc deephunter neuron boundary coverage nbc fastapproximate nearest neighbor fann tensorfuzz multiple thresholds available is beneficial for analyzing differences formore similar data.
auroc.givenanunknowninput ooddetectiontechniques need to identify a threshold to classify it as id or ood.
the area under the receiver operating characteristic curve auroc is usually used to evaluate the performance of a classification method across multiple thresholds.
the auroc can be thought ofastheprobabilitythatananomalousexampleisgivenahigher oodscorethananin distributionexample .thus thehigher auroc thebetter the ood detector.
tprn whichisthetruepositiverateatn truenegativerate tprn .
we regard ood data as the positive class.
first we use n true negative rate to select one threshold for the ood detector.
then with this threshold we evaluate the true positive rateof the detector.
note that for the parameter nintprn a larger nmeans we select a bigger threshold such that more data is perceived under the threshold as id i.e.
higher true negative rate .
thus a larger nprovides more confident measurement for detecting ood datawhileasmaller nprovidesmoreconfidentmeasurementfor detecting id data.
.
mutation operators and coverage criteria fora thorough analysis of dl testing we select mutation operators and coverage criteria which represent the state of the art andarewidelyusedintheexistingtestingtools i.e.
deeptest deephunter andtensorfuzz .table2showsthedetailed information about the selected mutation operators and coverage criteria.
column toolsrepresents which techniques are utilized by whichtools.allmutationoperatorparametersarecarefullychosen byfollowingpreviousworkandmaintainingrealisticbounds e.g.
rotation iscapped at40 degree.all configuration canbe foundon ourwebsite .
.
study design theempiricalevaluation for each rq is designed as follows rq1.
accuracy on ood detection techniques.
for rq1 we select five aforementionedood detection techniques which are widely used to distinguish two totally different datasets.
to compare their effectiveness we design three different experiments as follows first liketheusualway weevaluatethetechniquesindistinguishing the id data and ood data in two different datasets i.e.
the training data as id data and another dataset as ood datawithsignificantlydifferentfeatures.forthetargetdatasets cifar mnist and fashionmnist we select different datasetsthatare regarded as ood datasets.
second we evaluate the inverse extreme case by taking the distribution difference between the training data and test data cats are not fish deep learning testing calls for out of distribution awareness ase september virtual event australia ofthesamebenchmarkdataset e.g.cifar 10trainvscifar test .sincewecanexpectbothdatasetstofollowthesimilardis tribution wevalidatethattheood techniquesareabletoidentify in distributions inputs too highlighting that the trained distributionencompassesunknowndata whichisrelevantto the dl application.
third we present an evaluation technique by splitting thebenchmark s training dataset into subsets based on theirclasses i.e.
half of the classes are taken as the training data and the rest half of the classes are taken for ood test set.
even though the other half of classes are not trained overall simi larities exist as they are from the same domain.
thereby we present a similar scenario as encountered for deep learning testing.
the three settings are designed to showcase a difference in data distribution.
in setting the two datasets are expected to have totally different distributions.
in setting the two distributionsshould be almost the same.
finally setting should lie between thefi rst two settings as the classes are not known however the compared datasets are from the same domain.
rq2.relationshipbetweenmutationoperatorsanddistribution.
in dl testing mutation operators are used to generate diverse test cases.hence rq2aimstostudytheeffectofthemutationoperator byobservingthedatadistributionofthegeneratedtestcases.we use each of the aforementioned mutation operators to randomly generate test cases based on seed inputs from the test set.
based on the results of rq1 we select the best ood detection technique to compare the distribution of generated test cases with the original training data.
rq3.
relationship between testing criteria and distribution.
in deep learning testing coverage criteria provide the guidance for testcasegeneration.specifically theyareusedtofiltersometest casesfromrandomlygeneratedmutantsandkeeponlythemutants that can improve the coverage.
rq3 aims to study which coverage criteriaaremorelikelytogenerateidorooddata.toanswerthis question wegenerateforeachdnnmodel2 000testcasesforeach mutationoperatorforeachcoveragecriterionbasedontheseedsofrq2.
then we compare the distribution of the test cases generated with different coverage criteria guidance.
rq4.
root cause for id and ood errors and robustness enhancement.afteridentifyingthe optimal ood detectiontechnique setting for deep learning testing from rq1 and analyzing the effect ofmutationoperatorsandcoveragecriteria fromrq2andrq3 weaimtostudytherootcauseforidandooderrorsandwhether distribution aware test cases are more effective in enhancing robustness by retraining.
for robustness enhancement we select uniformly classdistributed seeds extracted from the training set.
based on these seeds wegenerate5differentsetsofdata id errorswhere tpr85 id errorswhere tpr95 ood errorswhere tpr95 ooderrorswhere tpr99 1andrandomerrors.eachsetcontains10 errortestcases.then weaddeachsetoferrortestcasesintothe original training set consisting of samples for retraining the dnn.
!
figure visualization of the distribution difference be tween different datasets on densenet empirical study we summarize the important results andfi ndings in this paper while complete results can be found on our website .
table average results auroc of different ood detection techniques in dataset dnn base.
odin maha.
oe like.
cifar 10densenet .
.
.
.
.
resnet .
.
.
.
.
vgg .
.
.
.
.
mnist lenet .
.
.
.
.
fashion mnist lenet .
.
.
.
.
.
rq1 ood detection accuracy.
wefi rst evaluate the state of the art of ood detection techniques to identify the optimal technique.
the results see section .
a r e visualized by examples in figure 2and are as follows .
.
results on totally different datasets.
first we perform a comparative study to investigate the performance of existing ooddetection techniques.
we prepare frequently used ood datasets and the training data of the dnn as id data.
we selecttheooddatasets svhn isun picsum andomniglot .
detailed description of each ood dataset can be found in .
in addition we scale the benchmark datasets imagenet cifar mnistandfashionmnisttothesamedimensionsas thetraineddatasetandconvertthemintograyscalewhennecessary e.g.
for mnist or fashionmnist.
due to the significant difference in datasets a ground truth of id and ood can be assumed.
for each dnn we evaluate the ood detection performance on differentooddatasets.table 3showstheaverageaurocscoreof eachooddetectiontechniqueoneachdnn.thebestresultsare inbold.wecanobservethat exceptforthelikelihood ratio other ood detectiontechniques are effective in detectingsignificantly different ood data.
overall outlier exposure shows the highest overall performance while mahalanobis is the second best.
for example forvgg oe achieves .
aurocscore that is muchhigherthanothersandmahalanobishas87.
aurocscore.likelihood ratiohasthesameresultsforthethreednnsofcifar10asitsdnn independent.ourresultsshowthatlikelihood ratio performs the worst for cifar mnist and fashionmnist theaverage score of auroc is .
.
.
.
results on the training data and test data.
in the previous section weevaluatetheoodtechniquesfordetectingooddata ase september virtual event australia david berend xiaofei xie lei ma lingjun zhou yang liu chi xu and jianjun zhao table results of ood detection on the test set.
in oodtech.
base.
odin maha.
oe like.
tprn .
.
.
.
.
densenet .
.
.
.
.
.
.
.
.
.
resnet .
.
.
.
.
.
.
.
.
.
vgg .
.
.
.
.
.
.
.
.
.
mn.lenet .
.
.
.
.
.
.
.
.
.
fmn.lenet .
.
.
.
.
.
.
.
.
.
table5 resultsofooddetectionwhentraininghalfofthe classes of the training set while testing ood with the other half of untrained classes.
in oodtech.
base.
odin maha.
oe like.
tprn densenet .
.
.
.
.
.
.
.
.
.
resnet .
.
.
.
.
.
.
.
.
.
vgg .
.
.
.
.
.
.
.
.
.
mn.lenet .
.
.
.
.
.
.
.
.
.
fmn.lenet .
.
.
.
.
.
.
.
.
.
that is very different from the training data.
in this section weevaluate the techniques for distinguishing id ood data in the test set ofthe same benchmark datasetthat follows a very similar distribution as the training set.
table4summarizes the results on the test data for each dataset.
weselecttwometrics tpr99andtpr99.
inthesecondrow which meansthatweselecttwothresholdswithhighaccuracyindetecting id data i.e.
and .
high accuracy in detecting id data .
then we observe how much of the test data is detected as ood data under these two thresholds.
the results show that the overall valuesareverysmallandfollowourexpectationsthatthereislittle ooddatainthetestset.italsodemonstratesthatalltechniquesare effective in identifying id data.
most importantly it demonstrates that the test set data follows almost an identical distribution as the trainingdata highlightingthatthetraineddistributionofthednnintegrates unknown data which is considered relevant to the dnn application middle of figure .
.
.
results of splitting the training data.
after evaluating the ability in detecting ood and id data in their extreme cases i.e.
section4.
.1and4.
.
we design afi nal study that is between these two extreme cases.
we split the training dataset equally in two separate sets based on their labels.
then we train the same dnnarchitecturesasbeforebutwithonlyfiveoutputs sincewe only use half of the classes e.g.
.
similarly we evaluate the capabilityofthedetectiontechniquesbydistinguishingthetrained classes from the non trained classes of data.
table5showshowmuchofthenon trainedclassdataisdetected as ood data.
we can clearly see that the values lie between the values in table 3and table .
another observation is that more ood data can be identified in the grayscale images i.e.
mnist andfashionmnist whilelessooddataisidentifiedinthecolor images.thereasonmaybethatthegrayscaleimageshavelower dimensionality.
thereby it is easier to capture the content changes betweenthetwosubsets.however forthecomplexcolorimages theymayshareasimilarstyleinthesamedomain e.g.
thebackground which makes it more difficult in distinguishing the twoclasses.
we also found that tpr95 can identify more ood datatable ood data by different mutation operators.
in mutatorsdensenet resnet lenet mnist tpr85 tpr99 tpr85 tpr99 tpr85 tpr99benigntranslation scale .
.
shear .
.
rotation contrast .
.
brightness blur noise average .
.
.
.
.
.8errortranslation scale .
.
shear .
.
rotation contrast .
.
brightness blur noise average .
.
.
.
.
.
than tpr99 as tpr95 selects a smaller threshold of the trained distribution.
theoverallresultsgiveusdirectionsonhowtoselectthethreshold for different datasets.
if the two datasets are very similar but suspectedtobefromdifferentdistributions wecanselectasmaller nintprn whichcandetectmoreooddata.ifthetwodatasets are very different we can select a larger nthat can distinguish the two datasets.
answertorq1 overall ourresultsshowthatoutlierexposure on densenet architecture performs the best and the results are consistent on all benchmark datasets.
the existing techniquescandetecttheiddata effectivelywheremostofthetestdataarecorrectlyclassifiedas in distribution.splitting the classes of the training set imposes a challenge to the detection techniques and grants a new perspective on their performance for application realistic settings.
.
rq2.
relationship between mutation operators and data distribution.
in the following experiments we select outlier exposure as the optimal ood detection technique for dl testing based on the results ofrq1.inaddition duetothespacelimit formutationoperator evaluationweonlyshowtheresultsofdensenet resnet andlenet 5formnist.vgg 11haslowercomplexityandfashionmnistisverysimilartomnist.toevaluatetheeffectofthemutationoperators werandomlyselect200datasampleswithuniformly distributedclassesfromthebenchmark stestsetastheseedimages.
then we apply each mutation operator to the seeds generating benign test cases and error test cases.
table 6shows theresultsoftheooddatageneratedbyeachmutationoperator.
columnmutators showseachmutationoperator.theparameters arechosen very conservativelyandfollowprevious contributions while changing the original image slightly .
the exact settings for realistic mutation is at .
the generated test cases and the original dataset are similar.
therefore webuild on ourfi ndingsfrom rq1 andintroduce both tpr85 and tpr99 settings to detect the ood test cases.
we can be more certain that samples tend to be ood with the threshold cats are not fish deep learning testing calls for out of distribution awareness ase september virtual event australia of .
nevertheless if tpr85 shows a low score the likelihood is more samples tend to be in distribution.
considering the results of the benign test cases and error test cases wefi nd that the errors test cases are considered out ofdistributionatahigherratethanthebenigntestcases.errortest cases for dnns trained on cifar namely densenet and resnet haveanaveragetpr99 scoreof50.
whilethebenign test cases only show .
.
for example focusing on the mutationoperatorimagenoise wecanobservethatbenigntestcases seem to be entirely in distribution tpr99 while the error test cases show a tpr99 score of and respectively for all three dnns.
this behavior indicates that error test cases are more likely to be out of distribution and thus they are more likely to be predicted incorrectly.
considering the results between different dnns wefi nd that densenet 121andresnet trainedoncifar sharesimilar averages between all three evaluation metrics.
however they have different trends when compared with lenet which is trained on mnist.
this behavior shows that the results are data driven highlydependingonthetraineddatasetsingeneral.forasimple grayscale image mnist which has low dimensionality the mutationoperatorsmaychangeitalotandgenerateooddata.however formorecomplexcolorimages themutationoperators withthe defined conservative parameter setting will change little on the high dimensional data which makes lower ood data in cifar .
for example in mnist the average results are .
and .
for benign test cases and error test cases respectively.
while for resnet 18on cifar the results are .
and .
.
comparing different mutation operators individually wefind thatimageblurtendstogenerate themost ooddata.
thebenign anderrortestcasesofblurareconsidered77 and86 asooddata basedontpr99 .
imagescalefollowsa similarpatternespecially forerrortestcasesoncifar and90 fordensenet 121and resnet respectively .
for image scale after the image is becom ing smaller the black color is used to complement the background andthereforeismorelikelytobeood.however inerrortestcases ofmnist thebackgroundoftheoriginalimagesisblackalready.
hence the image scale only generates ood data which is the smallestvalueinallmutationoperators.inaddition wefindthat mutationoperators i.e.
translation shear rotationandbrightness tend to generate fewer ood data.
for example brightness only generates ooddata for densenet and rotationgenerates ooddatafor both densenet and resnet .
answertorq2 thedatadistributiongeneratedbymutation operators is dependent on the datasets.
considering the same mutation operators more test cases tend to be more oodfor grayscale images and less for color images.
image blur and image scale are the mutations strategies where the highest ood score is observed whereas image rotation shear brightness and contrast generate fewer ood data.
the error testcasesare more likely to be ood than benign test cases.table7 ooddata undertpr99 generatedbydifferentcoverageguidance.
in rand nc kmnc nbc snac tknc fannbenign densenet 121rotation contrast brightness blur all average 22resnet 18rotation contrast brightness blur all average 17lenet 5rotation contrast brightness blur all average 0error densenet 121rotation contrast brightness blur all average 56resnet 18rotation contrast brightness blur all average 52lenet 5rotation contrast brightness blur all average .
rq3.
relationship between testing criteria and data distribution.
in rq2 we have identified the behavior of the mutation operators withoutapplyinganyguidancetothedltestingflow.now weadd coveragecriteriatothetestingflowtoguidethetestcasegeneration.
therefore weevaluatetheeffectofcoveragecriteriaonthedata distribution and compare it with the results of rq2 as the baseline.
based on the results of rq2 we select mutation operators i.e.
rotation contrast and brightness which are more likely togenerateiddataandblurwhichismorelikelytogenerateooddata.
table 7shows the results of how many test cases are ood data with different coverage guidance.
the results are evaluated byoutlierexposurewithtpr99.thethirdcolumnshowsthemutation operators.
row allmeans we use all default mutation operators fortestcasegeneration.column randshowstheresultswithout coverage criteria guidance which is from table .
the columns following randshow the results for each coverage criterion.
note that in coverage guided testing benign test cases are generated withtheguidanceofthecoveragecriteriawhileerrortestcasesare notfi ltered by the coverage criteria.
considering the results of benign test cases i.e.
under coverage guidance wefindthat comparedwiththerandomgeneration i.e.
without coverage guidance kmnc tknc and fann decrease the ood data ratio whereas nbc and snac increase the ood dataratio.forexample indensenet theaveragevaluewith random generation is while the average values with kmnc tknc and fann guidance are and respectively.
the average values with nbc and snac are and respectively.
ase september virtual event australia david berend xiaofei xie lei ma lingjun zhou yang liu chi xu and jianjun zhao figure train test and error test case distributions colored in different ranges defined by quantiles of train testdistribution itis consistentwiththeirdefinitions.forexample kmnc mainly considers major behaviors of the dnn and fann generates test cases thatare near the originalseeds.
thus iddata is more likely tobegeneratedwiththeguidanceofthesetwocoveragecriteria.however nbc and snac mainly consider the boundary of the dnn.hence they can generate more ood data.
consideringthespecificmutationoperatorsindividually wefind thatmutation andcoverage criteria influence eachother.
for example for densenet and resnet when using image contrast mostofthecoveragecriteriaincreasetheooddataratioincluding kmnc tknc and fann where usually these coverage criteria tendtodecreasetheooddataratioinalldata.itindicatesthatthe coveragecriteriaguidethetestcasegenerationbycoveringmore diverse dnn behaviors for this particular mutation operator.
in the contrary image blur changes the image a lot causing most test cases to be ood under the random mutation setting already.
in this case all coverage criteria decrease the ood data ratio compared to the random mutation setting.
this behavior means that mostoodtestcasesgeneratedbyimageblurmaybefilteredby thecoveragecriteria.forexample thecoveragecriteriaindeepgauge are defined based on the profiling of training data.
the blurred images are far from the training data thus they cannot achievenewcoverageunderthesecriteria.theresultsdemonstrate that existing coverage criteria have obvious effects on mutation operatorsbutvaryintheirbehaviordependingontheunderlyingmutationoperator.
another interesting observation is found for mnsit trained on lenet 5whichisdifferentfromtheresultsforcifar .forthe benigntestcasesoflenet almostallcoveragecriteriadecrease theooddataratio whereforcifar 10thisbehaviorcouldonlybe observedforselectedmutationoperators.itseemsthatforsimple blackandwhiteorgrayscaleimages therandommutationrequires much change to produce a test case which is why a lot of ood dataaregenerated.however thetestingcriteriafiltermostofthese datapoints as they do not contribute to increasing the coverage.
fortheerrortestcases wefindthat comparedwithrandommutation almost all the coverage criteria increase the ood data ratio in resnet and densenet .
in lenet most of the erroneous testcasestendtobeooddata tpr99 .actually errortestcases havenodirectrelationshipwiththecoveragecriteriaastheyare notfi ltered by the criteria directly .
however the y are generated by mutating the benign data that are generated under the coverage guidance.answer to rq3 our results show that existing coverage criteria affect the data distribution of generated test cases which is important to address when designing a test scenario.
kmnc tknc nc and fann tend to decrease the number ofoodbenigntestcaseswhilencandnbctendtoincreasethe oodbenigntest cases.forthemutation operatorsthattend togeneratefewerooddatasuchasrotationandcontrast the existing coverage criteria can increase the number of ood databycoveringmorebehaviorsofthednn.forthemutationthattendstogeneratemoreooddatasuchasblur the existingcoveragecriteriacandecreasethenumberbyfiltering some data with the coverage guidance.
for grayscale images thecoveragecriteriamaydecreasethenumberofooddata withrandommutationoperators.thecoveragecriteriamay increasetheooddataforgenerated error test cases.
.
rq4.
root cause of id and ood errors and robustnessenhancement.
wehypothesizethatiderrortestcasestendtobearesultofdefects inthednnmodelwhileooderrortestcasestendtobearesult of missing data in the training set.
therefore two experiments are designed to study the hypothesis.
first we use other dnn models withdifferentarchitecturesbuttrainedonthesametrainingdatato predict the id and ood errors of the model under test.
following our hypothesis we expect other dnn models to predict id errors more correctly than ood errors.
second we retrain the model under test with additional id and ood error test cases.
we expect thatthenewlyaddeddatahelpsincorrectlypredictingooderrors more effectively.
.
.
robustnessenhancementwithadjustingmodels.
forthefirst hypothesis i.e.
id error test cases tend to be a result of defects in the dnn model we select six other dnn variants vgg vgg13 resnet resnet densenet densenet which differintheirarchitecturebutarelearnedfromthesametraining dataset.notethatthesemodelscanberegardedasthesimulation ofthepotentialimprovementoftheoriginalmodel e.g.
finetuneor change in architecture .
we expect errors found on e.g.
resnet tobepredictedcorrectlybysomeoftheotherfivednnvariants with special attention on whether id errors tend to be predicted correctly more likely than ood errors.
table8shows the results of the cross validation on otherfi ve models.
full evaluation can be found on the website .
for each model wecollect10 000iderrorsand10 000ooderrors respectively.theaccuracyshowshowmuchdataiscorrectlypredicted on average by the other models i.e.
it could be handled well by improvingthemodel .overall theresultsindicatethatiderrors tend to befi xed at a higher likelihood than ood errors through dnnadjustmentssuchaschangingitsneuralarchitecture which is consistent with our hypothesis.
for example by changing the models .
iderrorscouldbefixedwhileonly20.
ooderrors couldbefi xed.
.
.
robustnessenhancementbyaddingtrainingdata.
forthe second hypothesis i.e.
ood error test cases tend to be a result cats are not fish deep learning testing calls for out of distribution awareness ase september virtual event australia table dnn model agreement on id and ood errors.
test model error type cross validation tpr85 tpr99 accuracy resnet 18id error .
ood error .
densenet 121id error .
ood error .
table results for robustness enhancement on different datasetanddnns.
in test set cifar random id85 id95 ood95 ood99resnet 18cifar test .
.
.
.
.
.
id error .
.
.
.
.
.
ood error .
.
.
.
.
.
rand error .
.
.
.
.
.0densenetcifar test .
.
.
.
.
.
id error .
.
.
.
.
.
ood error .
.
.
.
.
.
rand error .
.
.
.
.
.
total average .
.
.
.
.
of missing training data we generate multiple id ood data and evaluate the robustness by retraining with them.
specifically we proposefi ve datasets each of which contains original training data and error test cases which are generatedfrom1 000initialseedinputsbutvaryintheiroodscore presentedbycolorandthresholdinfigure orangeandyellow areasindicateiderrortestcaseswithtpr85andtpr95tobe0 respectively related to as id85 and id95 .
green and red areasindicateooderrortestcaseswithtpr95andtpr99tobe100 respectively related to as ood95 and ood99 .
we further use errorsdrawnrandomlyfrom the distribution as another dataset.
in addition we prepare four test sets the original test set id errors ood errors and random errors which are usedto test the new dnns.
here we only include two dnns trained oncifar 10duetomostoftheerrorsforlenet 5onmnistare considered ood.
table9shows the results of the retrained dnns.
overall for thenewdnns theaccuracyontestsetisreducedonaverageby .
.
at the same time the performance on correctly classifying randomerrorsisimprovedupto61.
percentagepoints.however theresultsvaryquitea lotwith thedatadistribution.
ooderrortest cases green area column ood95 show the highest overall accuracywith60.
averageaccuracy whileid85andid95only classify53.
and49.
correctly.thispromotestheideathatood errors are more effective in generalizing the model towards new data.however notallooderrorscanbeconsideredeffectivefor retraining.
column ood99 shows the lowest total average which indicates that at some point error test cases can not be considered directly benefiting the overall dnn application as they are too different from the overall distribution.
compared with random retraining which can be considered a baseline of recent work distribution aware retraining increases robustness on average by .
and up to .
for random error test set on densenet .answertorq4 theresultsdemonstratethatid errorstend tobefixedviadnnadjustments whileood errorsseemtore quirefurthertrainingdataforbeingcorrectlyclassified.when retraining ooderrorstendtobeonaverage10.
moreeffectiveinimprovingtherobustnessofthednnthaniderrors or randomly chosen ones.
furthermore not all ood errors helpthemodeltogeneralize indicatingthattheood score distance towards the trained tested dnn distribution matters whenchoosingtheright dataforenhancingrobustness.
.
discussion and research guidance basedonourresults wepinpointthefollowingresearchdirections ooddetectionfordl testing rq1 .
in dl testing it is still challenging to distinguish id and ood data especially when more similarities between the two tested data types exist.
therefore fi ne grained thresholds seem helpful in gaining a better understanding in similar cases.
our results in fig.
2provide the following guidance if the testing tool aims at generating id test cases a smaller nshould be selected.
if we want to generate oodtestcases a larger nshouldbe selected.
research guidance a possible direction is to develop ood techniques which can effectively detectfi ne grained ood datafor deep learning testing.
mutation operators and coverage criteria rq2 .
our results show that the existing mutation and coverage criteriahave different effects on id data or ood data generation.
to buildthedistribution awaredltestingtools wecoulddevelop distribution based coverage criteria that canfi lter some ood dataor id data.researchguidance dl testing tools should be aware of distribution.
a promising direction is to develop morefi ne grained distribution aware criteria for the test selection.
robustnessenhancement rq4.
ourinitialresultshaveshown thatdistribution awareretrainingismoreeffectiveinrobustness enhancement than the distribution unaware retraining.
it seems thatrootcausesforiderrorsarepartiallymodeldependentwhile ooderrorscan be effectivelyfi xed with new training data.
research guidance a future research direction is to further analyze the root cause of id and ood errors especially in an evenmorefinegrainedsettingwhichcanprovideguidanceforrepairing the model from a data and dnn architecture perspective underregard of the presented threshold of this work.
.
threatto validity theselectionofthedatasetsanddnnscouldbeathreattovalidity.
wetrytocounterthisbyusingeightpubliclyavailableandpopularlyuseddatasetsandcross validatingresultsonthreedifferent dnnarchitectures.ooddetectionisaverychallengingproblemas thereisnoperfectgroundtruth whichcouldbeathreattovalidity.
to this end we select multiple state of the art ood techniques for a comparative study.
in addition we also design threefi ne grained experiments in rq1 where the ground truth can be approximated bytheinheriteddifference.thereby wecanidentifytheoptimal ooddetectiontechniquefordltestingtocomparethedistribution performance for dl testing associated data.
the results of tables ase september virtual event australia david berend xiaofei xie lei ma lingjun zhou yang liu chi xu and jianjun zhao 8and9maybebiasedontheseedsandthegenerateddata.
we try to counter this by randomly selecting the same number of seeds for each class generate a large number of mutants and compare the averaged results.
related works deep learning testing.
adversarial attacks have been extensively studied to perform perturbation on input data to fool a dnn indifferentapplications .however suchperturbationsareoftenobtainedthroughgradient oroptimized based searching which may rarely happen in a physical environment.
in addition it has been demonstrated that there are many issuesduring the dl development and depolyment phases which callsfortherequirementofsystematicdltesting.differentfrom theadversarialattack dltestingconsidersgeneratingnewtests by performing mutations that simulate noise patterns from the physicalenvironment e.g.
imagebrightnesschange rotation with definedboundstomaintainrealism e.g.
rotationislimitedto40 degrees.
to estimatethe dltesting sufficiencyand providingtesting guidance many testing criteria have been proposed.
deepxplore originally proposed the neuron coverage.
inspired by this deepgauge proposedasetofmorefine grainedtesting criteria such as kmnc nbc etc.
deepconcolic proposed mc dc testcriteria .furthermore combinatorialtestingcriteria and surprise adequacy are also proposed.
the testing criteria above mainly focus on feed forward neural networks while deepstellar proposedthemodel basedtestingcriteriaforrecurrent neuralnetworks.
theseproposedtestingcriteriafordnnareusedtoguidethe test generation process such as in .
in addition deeptest anddeeproad alsogenerateimages withgenerativeadversarialnetworks gans .comparedwiththe basic transformations e.g.
adding noise rotation the gan based techniques can perform advanced scene transformation but are computation intensive requiring training a gan the quality of the generated images can not be easily guaranteed.
similarly we also leverage the basic mutation operators and coveragecriteriainexistingtestingtoolsforthestudy.however this paper is orthogonal to existing dl testing work in that our focusistoinvestigatetheimportanceofdatadistributionandhowit impactsexistingtestingtechniques.ourresultsshowthat although existing testing techniques are able to detect thousands of errors as discussed in their original papers a large portion of these errors maynotcontributedirectlytothedesiredresultwhenretraining or to the overall dl application.
therefore considering the data distributionduringdltestingisofgreatimportancetoproperly identifythereal weakness of a dnn for further processing.out of distribution detection techniques.
while being important theout of distributionanalysisischallengingespecially for high dimensional data.
dan hendrycks et.
al introduced a baseline approach which utilizes the maximum softmax probability.
correctly classified examples tend to have greater maxi mum softmax probabilities than erroneously classified and outof distributionexamples allowingfortheirdetection.theodin andmahalanobistechnique proposetoapplyinputperturbationsbyaddingnoiseortemperaturetotheinput bywhich theyintensifytheability ofthebaselinealgorithmtodifferentiateconfidencebetweeninandout of distributionerrors.outlierexpo sure takesadifferentapproach.here aseparatednnistaken andtrainedwithanadditionalinfusionofdeclaredood samples such aslarge scale data imagestinyimages whilethe score is calculated in a similar fashion to the baseline.
one advantage of thetechniqueisindependencetowardsthednnusedfortheapplication.
just towards the data.
thereby a bias for ood detection caused by a given dnn may be overcome more efficiently.
finally more recent contributions propose to use likelihoodratiosattheircore andutilizegenerativepixelcnn architecturetoretrievebitsperdimensiontocalculateoodscores.
othertechniques whicharenotcapableofclassifyingsingleinputs require heavy dnn architectural adjustments such as adding an additional class or taking multiple techniques as ensemble .
this is not considered in this work due to their imposed limitationstowards dl testing.
existingooddetectionmethodsaremostlyproposedtoworkon datasetswithalargedifference.therefore itisstillunclearwhetherandtowhatextentexistingooddetectionmethodscanbeusedfor the challenging dl testing scenario where the generated test data oftendiffersfromitsoriginalcounterpartinaminorway.inthis work weselectedthestate of the artood detectiontechniquesto investigatetheireffectiveness itsconnectionandusefulnessfordl testingpurposes.wefindthatdata distributionawarenesscouldbe a key for more effective and interpretable dl testing towards providing better quality assurance.
conclusion inthispaper weconductalarge scaleempiricalstudyonthestateof the art ood techniquestowards understanding the datadistributionanditsimpactondltestingactivities.ourresultsshowthat the existing ood detection techniques can distinguish the ooddata from the newly generated test cases even for challenging caseswherethetestdataisverysimilartothetrainingdata.our study further shows that existing image mutation operators and testingcriteriacangreatlyaffectthedistributionofthegenerated test cases.
finally we demonstrate that distribution aware dataset tendstobemoreeffectiveinrobustnessenhancement.thisstudy makesthefirststepalongthisdirectiontowardsunderstandingthedata driven nature of dl software for testing activities.
the results ofthispapercallfortheattentionofdata distributionawareness during designing testing and analysis techniques for dl software which builds the foundation towards developing more effective dl testingtechniques.