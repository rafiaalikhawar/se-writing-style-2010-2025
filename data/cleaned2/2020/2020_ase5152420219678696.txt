vizsmith automated visualization synthesis by mining data science notebooks rohan bavishi university of california berkeley rbavishi cs.berkeley.edushadaj laddad university of california berkeley shadaj cs.berkeley.eduhiroaki y oshida fujitsu research of america hyoshida fujitsu.com mukul r. prasad fujitsu research of america mukul fujitsu.comkoushik sen university of california berkeley ksen cs.berkeley.edu abstract visualizations are widely used to communicate findings and make data driven decisions.
unfortunately creating bespoke and reproducible visualizations requires the use ofprocedural tools such as matplotlib.
these tools present a steeplearning curve as their documentation often lacks sufficient usageexamples to help beginners get started or accomplish a specifictask.
forums such as stackoverflow have long helped developerssearch for code online and adapt it for their use.
however developers still have to sift through search results and understandthe code before adapting it for their use.
we built a tool called v izsmith which enables code reuse for visualizations by mining visualization code from kagglenotebooks and creating a database of reusable python functions.
given a dataset columns to visualize and a text queryfrom the user v izsmith searches this database for appropriate functions runs them and displays the generated visualizationsto the user.
at the core of v izsmith is a novel metamorphic testing based approach to automatically assess the reusability offunctions which improves end to end synthesis performance by10 and cuts the number of execution failures by .
i. i ntroduction visualizations are increasingly being used across various domains including academic research journalism and business intelligence to communicate insights and enable data drivendecision making .
the need for bespoke visualizationsand reproducible analytical workflows requires the use ofpowerful procedural visualization tools such as ggplot andmatplotlib .
however these tools also have a steeplearning curve for novices and domain experts with littleprogramming background.
tool documentation pages functionwell as a reference but often lack sufficient snippets orexamples to help beginners get started.
this has led to a huge surge in popularity of technical q a forums such as stackoverflow and social programming plat forms like github as they facilitate code reuse .
analysts can search for usage examples or even complete recipes to incorporate directly into their workflow.
in practice however code reuse in software development has largely been sub optimal due to two main reasons.first the code results returned by stackoverflow may beincomprehensible to relatively new users making it difficultfor them to modify and reuse that code .
second there isa proliferation of similar questions on stackoverflow whichends up pushing the burden of selecting the right solution tothe end user who may not be familiar with the specifics ofthe visualization tools.
facilitating better code reuse has been a subject of active research .
this includes improving the quality ofsearch results as well adapting the code using additionalspecifications such as test cases or type signatures of targetmethods .
none of these are however applicable in thecontext of visualizations.
wang et al.
use a synthesis powered approach to generate visualization programs in a lim ited dsl given partial or incomplete visualizations.
however this can be insufficient when a helpful partial visualization isdifficult to provide such as when visualizing the correlationmatrix of a large table.
in this paper we present and evaluate an approach for facilitating code reuse in generating visualizations.
we leveragethe fact that machine learning platforms such as kaggle host scores of executable data science notebooks that alsoinclude the raw dataset.
we developed a tool v izsmith that analyzes these notebooks and mines a knowledge base ofvisualization functions which are python functions that takean input table and the set of columns to visualize as inputand produce a visualization as output.
v izsmith provides a frontend where users can provide a dataframe and thecolumns to visualize along with a text query.
v izsmith finds ranks and executes the functions best matching the query anddisplays the synthesized bespoke visualizations.
at the heart of v izsmith lies a novel analysis for determining the quality or reusability of a mined visualization function.
the analysis allows it to discard low quality codeupfront which greatly helps in improving both quality andspeed of synthesis.
to the best of our knowledge we are thefirst to provide a precise conceptual definition of reusability in the context of visualization code.
we also develop a novelapproach based on metamorphic testing that approximatesthis definition for automatically evaluating reusability of anyarbitrary visualization function.
in summary our contributionswithin v izsmith are as follows a framework for mining visualization functions from kaggle that yields a knowledge base of reusable functions mined across notebooks and competitions.
36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee !
!
!
!
!
!
!
!
!
!
fig.
v izsmith s jupyter notebook frontend.
v izsmith is provided with a table as a pandas dataframe along with columns to visualize as input.
it has a search bar to input text queries.
a shows how alice uses v izsmith to search for normalized stacked bar charts for her call quality dataset.
b and c show the visualization selected by alice and its code respectively.
a conceptual definition of reusability in the context of visualizations along with a novel decision procedure based on metamorphic testing that achieves precision and71 recall with respect to a ground truth obtained viamanual inspection.
a synthesis engine that takes as user input a dataframe and the columns to visualize.
in a cross project experiment the target visualization is contained in the top resultsreturned by v izsmith for of our benchmarks.
a publicly available front end and demo at com rbavishi vizsmith demo.
ii.
m otiv a ting example alice is a researcher working on a project on analyzing the voice call quality dataset released by the indian government containing customer ratings.
as part of her project aliceneeds to build a visual dashboard that updates every time newdata comes in.
she has heard about rich data transformationand visualization libraries in python such as pandas and matplotlib and decides to use them for this purpose.
in her dashboard alice wants to include a visualization of the distribution of customer ratings for every network operatorindividually normalized by the number of records for everyoperator.
she decides that a normalized stacked bar chart with a bar for every operator would be appropriate for this purpose.
alice promptly writes code to load the dataset into a pandas dataframe.
unsure about how to create a stacked bar chart shevisits the matplotlib gallery entry for this chart only to find it insufficient for her needs.
she is also uncertain aboutexactly how to transform her dataframe in order to create the bar chart.
she turns to stackoverflow for help and browsesthe results for the query matplotlib pandas normalized stacked bar chart .the top result contains a visualization close to what alice needs but she has trouble understanding the code letalone adapting it for her data.
this experience is in line withthe findings of previous work .
figure demonstrates how alice uses v izsmith to find the visualization of her choice along with code to produceit.
first alice fires up the frontend of v izsmith which is implemented as a jupyter notebook widget.
alice provides vizsmith with her dataframe as well as the columns she wants to visualize.
v izsmith then presents a search bar where alice provides the same query as before.
vizsmith then consults its knowledge base of visualization functions that it has mined from the machine learning notebooks written by data scientists on kaggle.
v izsmith utilizes dynamic program analysis and metamorphic testingto construct these functions.
these visualization functions areregular python functions that take a dataframe as an argumentalong with column arguments and produce a visualizationafter performing any necessary dataframe transformations.
v izsmith indexes these functions using the names of the api functions and their keyword arguments along with thenatural language comments found in the kaggle notebooks.given alice s keywords v izsmith finds the best matching functions runs them and presents the resulting visualizationsin a gallery view as shown in figure .
v izsmith allows alice to expand a particular visualization to a full screen viewas well as study the code for the visualization.
alice finds her desired visualization in this list right away shown in b in figure .
v izsmith also produces many similar visualizations with small styling variations.
the codefor the visualization is shown in c and illustrates the inherentcomplexity of the task as it needs a combination of three pandas functions namely crosstab div and sum followed !
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
fig.
overview of v izsmith .
by the call to plot .
alice copies the code into her workflow and adjusts the title and y axis labels.
thus v izsmith enables better code reuse by eliminating the burden of understanding and adapting code found online.
iii.
o verview of vizsmith figure presents a high level overview of v izsmith .i n the offline phase v izsmith collects and mines visualization functions from python notebooks hosted on the machine learning platform kaggle section iv .
v izsmith also analyzes the functions using a novel metamorphic testing scheme section v to discard functions ill suited for synthesis.
in theonline phase v izsmith receives from the user a dataframe as well as the set of columns in the dataframe that participate inthe desired visualization along with a search query.
v izsmith first uses the query to collect a ranked list of functions toexplore section vi a .
then it finds appropriate arguments tothe parameters of each function and executes them all.
finally v izsmith collects and displays the generated visualizations in a jupyter notebook user interface.
iv .
m ining we first describe the component of our system responsible for collecting notebooks from kaggle replaying them andharvesting visualization code from the notebook runs.
a. collecting and replaying notebooks we sort the list of competitions on kaggle by the number of teams participating in the competition.
from the top such competitions we pick those where the dataset corresponds toasingle csv tsv file.
we additionally include the titanic and house prices competitions as they are the most well known classification and regression tasks on kaggle respectively resulting in a total of competitions table ii .
within these competitions we only select kernels that have an associated docker image id which can be downloaded fromkaggle s gcr repository .
to conserve resources we ignore gpu based kernels and impose a timeout of minutes oneach kernel run.
for competitions with large datasets 50k rows we take a sample of the dataset in order to reduce theexecution time.
instrumentation and execution we perform source level instrumentation of the scripts collected before execution to facilitate the construction ofthe dependency graph.
we define the dependency graph of a program pas a graph gsuch that the nodes correspond to the simple statements in p. a dependency edge exists between nodes n 1andn2if the statement corresponding to n2is data dependent or control dependent on the statement atn1.
data dependence implies that n2uses some variables or data defined or modified at n1.
control dependence means that ifn1determines whether n2executes or not which is the case when n1is an if statement or a looping statement.
our source level instrumentation adds wrapper functions to record essential runtime information such as variable readsand writes as well as types and memory locations of ob jects.
this information helps us construct the dependencygraph.
note that we do not instrument code corresponding tobuilt in or third party libraries.
therefore to capture librarydependencies correctly we construct a separate database offunction specs with one entry for each built in and api function.
for every function we determine if it has side effects based on the arguments to the function.
we writesuch specs for methods of inbuilt types such as lists setsand dictionaries as well as api functions from popular datascience libraries namely pandas matplotlib seaborn numpy and scikit learn .
these specs are quite coarse given the function call df.drop columns inplace true our spec for drop only records that the dataframe dfis modified instead of the precise column low that was updated.
this keeps our implementation simple at the cost of spuriousdependency edges.
c. visualization objects and visualization slices over the course of execution of a program p we collect the python objects corresponding to individual visualizations.
in our implementation we focus on the matplotlib library as well as its wrapper library seaborn so we track all unique python objects of the type matplotlib.pyplot.figure .w e call such an object a visualization object or simply visualization.
we say that visualizations 1and 2are the same if the corresponding images obtained after serialization renderingare a pixel by pixel match.
for matplotlib this corresponds to the output of the matplotlib.pyplot.figure.savefig api function.
for every visualization seen over the execution of program p we construct a visualization slice defined as follows definition visualization slice .
we define the visualization slice of a program pwith respect to a visualization object denoted as vizslice p as a program p primethat can be obtained by removing statements from psuch that when executed p prime produces the same visualization and only .
thus a visualization slice contains all the statements in a program necessary for recreating a particular visualization.figure contains a slice of the linked kaggle notebook for 1311import pandas aspd 2import seaborn assns sns.set style white df train pd.read csv .. input train.csv df train.fillna df train.mean inplace true 6d f df train 7a x sns.distplot df kde false 8a x .set xlabel age ylabel frequency fig.
example of a visualization and a corresponding slice extracted from kaggle.
1import pandas aspd 2import seaborn assns df train pd.read csv .. input train.csv df train.fillna df train.mean inplace true 5a x sns.distplot df train kde false 6a x .set xlabel age ylabel frequency fig.
minimized version of visualization slice in figure .
the shown visualization.
furthermore the slice should only produce a single visualization.
we use standard dynamic program slicing to obtain a visualization slice.
specifically we remove all statementsinpthat are not reachable via a backward traversal of the dependency graph of pstarting from any of the statements in in the set vizstmts p defined below definition vizstmts p .vizstmts p is the set of all statements in the program pthat directly create modify the visualization object .
in figure the statements in lines correspond to the set returned by vizstmts for the program corresponding to the parent notebook and the visualization object beingthe actual plot at the top of figure .
the first creates thedistribution plot while the second sets the labels of the axes.the remaining statements in figure modify the style loadthe dataframe and modify it before visualization and are henceincluded in the slice.
d. minimizing visualization slices recall that our dependency graph construction is not precise as we use coarse specifications for third party libraries.
as a result the visualization slice obtained via dynamic programslicing may still contain irrelevant statements whose removalwill not affect the visualization.
consider the slice in figure .the call to set style in line is unnecessary as the style is white by default.
it is included in the slice because it writes to an internal styling dictionary which is then read in the callto distplot thereby establishing a dependency.
taking the subset of columns in line is also unnecessary as distplotonly receives the target column anyway.
we can remove boththese operations to yield a simpler minimized visualization slice as shown in figure .
how do we obtain the minimized visualization slice in figure from the slice in figure ?
note that it is not enoughto simply remove or delete code as one might do if they wereusing delta debugging removing lines and in figure3 would lead to an undefined variable error for df.
essentially we need transformations that go beyond code removal.
we instantiate the generalized syntax guided program reduction framework developed in perses to enable this minimization.
in particular we use standard statement leveldelta debugging to remove top level statements whose removaldoes not change the generated visualization.
additionally we use a transformation where we replace a usage of avariable holding a dataframe with the usage of a previouslydefined variable also holding a dataframe.
we keep alternatingbetween these two transformations until the slice cannot beminimized further without altering the visualization.
alter nation helps here because one transformation may introduceminimization opportunities for another.
algorithm describesthis procedure.
algorithm minimization algorithm pseudocode function minimize p current p change true while change is true do change false variant delta debug current ifvariant negationslash current then current variant change true for variant in dfvarreplace current do ifvariant produces same visualization then current variant change true break pmin current returnpmin we walk through how the algorithm minimizes the slice in figure .
in the first iteration delta debugging line wouldremove the call to set style in line figure .
then we iterate over variants returned by dfvarreplace .dfvarreplace replaces a use of a variable holding a dataframe by a use of an other previously defined variable holding a different dataframe.if there are many possibilities dfv arreplace explores variants in the descending order of the gap between the original and replacing definitions of the variables measured in the numberof statements.
the variant where dfis replaced with df train is retained.
then line in figure gets removed in the seconditeration and the algorithm exits after the third iteration asno further minimization occurred successfully returning thedesired slice in figure .
the reasons behind selecting these two transformations are two fold.
first data science code has minimal control flow.hence focusing on top level statements is sufficient.
secondly data transformation logic almost always involves applying apifunctions on variables holding the data dataframes .
since 1321import pandas aspd 2import seaborn assns df train pd.read csv .. input train.csv df train .fillna df train .mean inplace true ax sns.distplot df train kde false ax.set xlabel age ylabel frequency fig.
dependencies between top level statements for code in figure .
edges labeled and capture depen dency between the use and definition of a variable df train df train ax sns and pdrespectively while captures the dependency between attribute reads and writes of an object the dataframe in df train .
1def visualization df col1 import seaborn assns 3d f .fillna df.mean inplace true 4a x sns.distplot df kde false 5a x .set xlabel col1 ylabel frequency a visualization function using b and variable as df train .
1def visualization df col1 import seaborn assns 3a x sns.distplot df kde false 4a x .set xlabel col1 ylabel frequency b visualization function using b and variable as df train .
fig.
visualization functions extracted from slice in figure .
visualization slices can be slow to execute as they use heavyweight libraries our restricted set of transformations strike abalance between scalability and quality of minimization.
e. extracting visualization functions in this section we describe how v izsmith creates visualization functions from a visualization slice.
visualization functions form the basic unit of v izsmith s mined database which it uses for synthesis.
throughout this section whenever we refer to a visualization slice we assume it is minimized.
a visualization function is formally defined as follows definition visualization functions .
a visualization functionfis a python function with a single dataframe parameter dfandmcolumn parameters col1 ... colmthat produces a visualization.
note that while the above definition restricts a visualization function to a single dataframe parameter our technique has nosuch inherent restriction.
we adopt this definition to simplifythe discussion and the notation used throughout the paper.
at a high level visualization functions can be extracted from a visualization slice by converting variables holding ref erences to dataframes into parameters and abstracting concretereferences to columns into column parameters.
the body of thefunction contains only the statements from the slice required toreproduce its visualization given the new dataframe argument.figure shows two visualization functions from the visual ization slice in figure .
each of them has a single columnparameter col1 .
both produce a visualization containing thedistribution plot of the supplied column with the functionin figure 6a performing an extra imputation step to replacemissing values by the mean of their respective columns.
wecall the slice p from which a visualization function fis obtained as the parent slice off.
algorithm formalizes the idea.
given a visualization slice p producing visualization and its dependency graph g for every program point bbetween the top level statements of the slice line and every variable var holding a reference to a dataframe object val dfthat is in scope at b line we extract a visualization function as follows.
we set the bodyof the function to be a subset of the statements in p with the variable var renamed to df the dataframe parameter .
this subset is the smallest such that if the function is executed withthe initial value of dfasval dfin the exact same state it was at program point bin the slice the resulting visualization is the same as .
this subset is obtained using backward slicing lines but on a subgraph grofg.grhas the same set of nodes as g but does not contain any dependency edges in gthat originate before the boundary and that arise because of the use of the variable var or the dataframe val df.
this helps us pick only the statements necessary to reproduce visualization ifvar is already assigned to val dfto begin with.
algorithm extracting visualization functions getvardf s p b returns the set of dataframe variables in scope at program point binp along with their values.
isdata frame edge e var dfvar returns true if the edge eis a data dependency edge resulting from the use of variable var or dataframe val df.reachable si gr root checks if siis reachable from root via a backwards traversal of gr.
function extract vizfunctions p g angbracketlefts1 ... s k angbracketright top level statements in p funcs for each program point b do sb s1 ... s b for each var dfvar getvardf s p b do er e e edges g src e sb isdata frame edge e var dfvar gr induced subgraph of gby removing edges in er root vizstmts p body si si s1 ... s k reachable si gr root sforbid s s sb var is used in s ifsforbid body then f.df param df f.body rename var body var df f.col params f.body infer colparams f dfvar ifverify f then funcs funcs f return funcs for example suppose b and var df train and the slice under consideration is the one in figure .
the graph gr would not contain the edges and in figure as they originate right after the statement at line before b and arise due to the use of the dataframe variable df train .
the edge 2i s included as it originates afterb.
lines confirm that the selected statements which appear before the selected program point bdo not involve 1331def visualization df import seaborn assns sns.heatmap df.corr fig.
a visualization function taking no arguments.
the use of variable var.
this prevents any dependency on a possibly stale version of val df.
then we infer column parameters by simply replacing all string constants that correspond to a column name in val dfwith parameter variables line .
in figure this corresponds to the string age in lines and .
we also rewrite attribute based column accessesof dataframes such as df.column asdf prior to applying this procedure.
we denote the mapping from thesecolumn parameters to the string constants as origcols f .
we refer to the selection of val dfasorigdf f .
finally in line we verify if running the visualization function with val dfi.e.
origdf s f and origcols f reproduces the visualization from the parent visualization slice.figure contains the two visualization functions extractedfrom the visualization slice in figure .
observe that nochoices for a dataframe variable would be available if we pickthe program point bas either or .
in this way we are able to obtain visualization functions across kaggle notebooks.
additionally for eachvisualization function we also have access to the original dataframe and column arguments needed to reproduce thevisualization as seen in the parent notebook via origdf and origcols.
we utilize this information heavily when analyzing these functions and using them for synthesizing visualizationsin the next two sections.
f .
participating columns vs. column parameters visualization functions have dataframe and column parameters.
it is important to note that column parameters do not necessarily correspond to the exact subset of columnsthat actually participate in the visualization.
for example the function in figure accepts no column arguments butproduces a correlation heatmap of all the numeric columnsin the passed dataframe.
we call such columns implicitly participating columns.
consequently we call a column asexplicitly participating if it is passed as a column argument.
we can decide if a column is implicitly participating using a simple mutation based strategy for every column cin origdf f that is not mapped in origdf s f we drop cfrom origdf f and check if the visualization is the same after executing the function.
if it is not the column cis implicitly participating.
we denote the set of columns visualized explicit or implicit by ffor the dataframe origdf f as origparticipa ting cols f .
this notion of participation is at the heart of the reusability analysis as well as visualizationsynthesis as we shall see next.
v. a nalysis of mined visualiza tion functions before we use the generated visualization functions for synthesis we need to assess their quality.
what makes a mined1def visualization df col1 import matplotlib.pyplot asplt counts df .value counts porct counts label for iinrange len counts label.append counts.index .2f sizes colors steelblue skyblue navy blue red green fig ax plt.subplots ax.pie sizes colors colors shadow false startangle ax.axis equal ax.legend label shadow true fig.
a visualization function with hard coded values.
1def visualization df col1 col2 import seaborn assns sns.set font scale .
df .hist fig.
a visualization function using a specialized predicate.
visualization function good or bad in the context of synthesis?
since synthesis by its very nature involves the con struction of visualizations for an unseen dataframe a visualization function should be considered good or reusable if given appropriate assignments to column parameters it producesmeaningful visualizations for a broad class of dataframes and bad or non reusable otherwise.
we illustrate our notions of meaningful and broad using examples.
consider the visualization function in figure .
note that the data values passed to ax.pie in line are hard coded in the function.
that is regardless of the dataframe and categoricalcolumn passed to the function the produced visualization willbe exactly the same.
the produced visualization is thus notmeaningful.
if this function is used in a visualization synthesissetting its resulting visualization would most likely make nosense to the user and could undermine trust in the system.thus we deem this function to be non reusable.
this also illustrates why a successful execution of a function does notnecessarily entail a meaningful visualization.
in contrast we consider the function in figure as good orreusable.
it will correctly produce a correlation heatmap for the class of dataframes that have at least one numeric column.this class clearly includes a wide variety of dataframes andhence we consider this function reusable.
figure presents a much more subtle scenario.
the function plots a histogram of the values in col2 but only considers the rows where the value corresponding to col1 is1.
this filtering criteria is quite arbitrary and only meaningful for dataframesthat contain a .
we thus deem this function non reusable.. a. defining reusability we consolidate the ideas developed in the above discussion in the following definition of reusability definition reusable visualization function .
we consider a visualization function freusable if there exists a set sdfof dataframes such that fproduces a meaningful visualization for every dataframe dfinsdf given an appropriate assignment of df s columns tof s parameters.
a meaningful visualization is non empty and represents all the information in dfor a filtered view ofdfwhere the filtering criterion is independent of the concrete data values in df.
sdfcan be characterized using high level properties of a dataframe and its columns including types of columns and types of data values but excluding properties relying onarbitrary constants or values in the data.
note that a meaningful visualization need not follow best visualization design practices that would make it meaningful for an end user.
with reusability we are only concerned aboutits relationship to the data and the visualization function code.
ideally we would like to be able to automatically classify our mined visualization functions as reusable and non reusable and discard the non reusable functions.
however itis hard to automatically check if a visualization functionis reusable according to definition as we do not haveaccess to s df.
essentially we are faced with the problem of a missing test oracle .
we present a novel approach of using metamorphic testing to alleviate this issue.
b. metamorphic testing for checking reusability metamorphic testing relies on a metamorphic relation mr a property that must be satisfied by the outputs of a function for different inputs.
our choice of this property for a visual ization function fis defined as follows definition mr for approximating reusability .
visualizations produced by fon mutated copies of its original dataframe i.e.
origdf f must all be different from each other as well as the original visualization of f. these mutated dataframes are produced using column level type aware mutation operators.
definition along with these mutation operators approximates the concept of reusability indefinition in two ways.
first these operators only modifyone column and take the column type categorical quantita tive etc.
into account.
this helps increase the likelihood ofstaying within the class of dataframes fis appropriate for.
it also ensures that this class is characterizable using simpleproperties like column types.
second the mutations appliedare large enough to warrant a change in the visualizationifftruly produces a visualization that represents all the information in the dataframe or a meaningful subset of it.
thishelps catch cases like figure and figure algorithm formalizes our metamorphic testing strategy.
for every visualized columnc origparticipa ting cols f we check if there exists a mutation operator for which themetamorphic relation is satisfied for the mutated dataframes itgenerates.
every mutation operator has a guard that must betrue for it to be applicable line .
our mutation operators for columns take the type of the column into account and are listed in table i. we recognize fourdistinct types of columns namely categorical quantitative idalgorithm checking reusability using metamorphic testing function isreusable f dforig origdf f orig origviz f for each c origparticipa ting cols f do success false for each mutation operator mfor coltype c dforig do s initialize m ifguard m dforig c s then df1 ... dfk m dforig c s 1 ... k viz produced by fondf1 ... dfk if i. i negationslash orig i negationslash j. i negationslash j then success true break ifsuccess is false then return false return true and nominal.
at a high level for each type of column wedesign a mutation operator for each of the different ways inwhich a column of that type may participate in a visualization.we walk through the operators for the two most common typesof columns categorical and quantitative.
a categorical columns the visualization may be a function of either the individual category labels in thecolumn or the count distribution of categories or whether a value is a nan missing value .
note that thevisualization may represent a function of these properties which may not necessarily be identity.
the first operator intable i selects a fixed subset of values and replaces themwith one or more unseen categories.
thus if a function relieson hard coded values or too arbitrary a filtering process theresulting visualizations should be the same and thus fail thecheck.
the second operator enables the check of whether thevisualization is sensitive to whether values are nans or not rather than their concrete values themselves.
it also has a guardwhich checks whether substituting the same missing valueswith different categories yields the same result as the original.this ensures that cases like figure do not pass the check.
b quantitative columns the visualization may be a function of either the values or a statistical function ofthose values or whether a value is a nan.
the first operatorshifts and scales the data by different amounts and addssome gaussian noise thus testing and .
we add noisebecause some statistical functions such as pearson correlationare robust to uniform scaling and shifting.
the magnitude ofthe shift is at least as large as the range of values to ensurezero overlap with the original range of values.
null values arehandled similarly as in categorical columns.
the mutation operators for id and nominal columns are designed using similar principles.
v izsmith is able to discard of mined functions by classifying them as non reusablevia this approach.
we evaluate how well the metamorphic test ing approach approximates the main definition of reusabilityin section vii b.
135table i column mutation operators column type mutation operator guard categorical replacing a fixed subset of values with new categories quantitative shifting and scaling v alues gaussian noise categorical quantitative replacing a fixed subset of values with missing values replacing the same subset with arbitrary values does not change visualization id random permutation nominal replace a subset of values with a sample from the remaining values nominal replacing a fixed subset of values with missing values replacing the same subset with values sampled from the column does not change visualization vi.
v isualiza tion synthesis vizsmith accepts a user specification comprising dataframes a list of columns in each dataframe that need toparticipate in the visualization and a search query.
vizsmith uses the search query to get a ranked list of visualization functions from the database obtained usingthe mining and analysis components from sections iv andv.
then for each function v izsmith determines the best possible assignments to the dataframe and column arguments runs the function collects the visualizations generated andpresents them to the user after deduplication.
a. search v izsmith associates each mined visualization function with a text document that contains a the natural language comments around the visualization statements in the parentnotebook b the text in the title and axis labels of thevisualization in the parent notebook c the names of theapi functions used and d the api documentation of the apifunctions used in the visualization function.
we collect com ments from the notebook under the assumption that authorsoften attach meaningful comments describing the logic in andbefore after cells although this may not always be true.
given a search query we rank documents according to their similarity with the search query using bm25 .
to obtaina ranked list of visualization functions we simply map thedocuments back to their respective visualization functions.
b. generating visualizations v izsmith adapts the ranked visualization functions to the user provided dataframe using the instantia te function in algorithm .
it takes as input the mined visualization function f the user supplied dataframe dfand the columns that must participate in the visualization vcols.
in the first phase lines the set of mappings from the column parameters of fto a subset of vcols is computed.
a mapping is valid if a it has a non zero score and b thecolumns in vcols that have not been assigned to a parameter as per the mapping are eligible to be visualized implicitly.
the score function computes the score of a mapping mfor a visualization function fby comparing mtoorigcols f .
recall that origcols f is the mapping column parameters to the string values in the parent visualization slice of f. essentially score checks the compatibility between the columns using high level properties such as column data types andpresence of null values.
we consider a column eligible to participate implicitly isimplicit cand if there exists a column in the original setalgorithm instantiating visualization functions function instantia te f df vcols v params colparams f m set of all injective maps from params to vcols score is non zero and every col in vcol is mapped to a param or potentially implicit mvalid m m m score f df m c vcols.
isimplicit cand f df c p params.m c for each minrank m valid score do f df m if is valid then v v return v function score f df m dforig origdf f morig origcols f score for each p colparams f do cm m corig morig column types must match for the mapping to be valid ifcoltype dforig corig negationslash coltype df cm then return dorig dt ypes dforig corig dm dt ypes df cm score score dorig dm dorig dm ifhasnulls dforig corig hasnulls df cm then score score return score of implicitly participating columns of fwhich has the same column type and data types.
the rationale is that if a columnparticipates implicitly the criteria determining its participatingis most often a function of the column and data types.
in the second phase lines the mappings are tried oneby one highest score first.
all the unique valid non empty visualizations collected are returned at the end.
vii.
e v alua tion we focus on three main research questions rqs to evaluate vizsmith .
in rq1 we analyze the diversity of the mined visualization functions.
specifically we explore the distributionsover the size of the functions the apis explored and whethera function performs data pre processing.
rq2 evaluates ourmetamorphic testing approach to computing reusability againsta ground truth established via a manual study.
finally in rq3 we evaluate end to end synthesis performance of v izsmith .
a. rq1 how diverse is the collective functionality of allvisualization functions?
as it is infeasible to manually examine each function and classify its functionality we approximate it as the set ofapi functions used in the body of the visualization function.note that we only consider functions classified as reusable 136table ii competition statistics.
notebooks is the number of notebooks eligible for execution.
check latticetop indicate that at least one viz was mined no visualizations mined timeout anderror respectively.
viz.
funcs is the number of visualizationfunctions mined with reusable count in brackets.
competition viz.
funcs passed quality assurance lanl earthquak e prediction covid19 global forecasting week house prices mercari price suggestion challenge mercedes benz greener manufacturing otto group product classification santander customer satisfaction santander value prediction challenge titanic tmdb box office prediction total table iii top api functions in each category and thenumber of reusable viz.
functions that use the api.
plotting transform computation styling sns.heatmap pd.groupby pd.corr mpl.title sns.countplot pd.drop pd.isnull sns.set sns.distplot pd.fillna pd.mean mpl.ylabel sns.barplot pd.sort values pd.sum mpl.xlabel sns.boxplot pd.dropna pd.value counts mpl.xticks sns.factorplot pd.concat pd.replace sns.set style mpl.scatter pd.reset inde x pd.isna mpl.set title sns.scatterplot pd.pivot table pd.median mpl.legend mpl.hist pd.get dummies pd.nlargest sns.add legend sns.catplot pd.head pd.count mpl.set ylabel by v izsmith .
we find that all mined functions collectively exercise a total of api functions across third party libraries.
we further bucket each api function manually intofour categories using simple criteria namely a plotting ifit draws a visualization b transformation if it involves re shaping or filtering operations such as transpose groupby anddropping null rows c computation if it involves mathematicaloperations such as correlation and skew and d styling if itonly modifies the look of a visualization or the text inside it.
we find that and of visualization functions use apis in categories a b c and d respec tively.
the top api functions in each category with respectto the number of visualization functions using the api arelisted in table iii.
evidently v izsmith s database covers a wide variety of plotting styling and transformation operations.
b. rq2 how accurate is our metamorphic testing approach?
section v introduced the conceptual definition of reusability of visualizations.
we also proposed an approach using metamorphic testing where the metamorphic relation approximatedthis concept of reusability.
in this rq we measure the accu racy precision and recall of this metamorphic testing approachwith respect to a ground truth obtained via manual inspectionof the visualization functions using the conceptual definition.
we sampled reusable and non reusable visualization functions as judged by our metamorphic testing approach.
wethen designed an interface that displays these functionstable iv characterization of misclassifications by our meta morphic testing approach.
fp and fn stand for false positiveand false negative respectively id category num.
cases a arbitrary filtering using multiple columns fp b undetected over specialization fp c visualization design choices bucketing axis limits fn d overaggressive mutation fn e adequately general filtering criterion fn one by one in a random order.
three of the authors labelledeach function as reusable or non reusable as per definition .we computed the ground truth label via majority vote.
in par ticular the authors try to assess the intent of the visualization the class of dataframes where a similar visualization would bemeaningful and whether the implementation would be able toproduce that visualization without any modifications.
we find the accuracy of the metamorphic approach to be with a precision of and recall of .
therewere false positives ground truth non reusable classifiedreusable and false negatives.
we categorized these casesin table iv.
the category column summarizes the reasonfor the misclassification of the metamorphic testing approach.examples of these categories are shown in figure .
the false positives occur because our mutation operators are only applied on one column at a time category a or thecode performs overly specific transforms that are not triggeredby mutations category b and hence pass metamorphic test ing check.
the majority of the false negatives occur because ofover aggressive mutation category d .
the example in figure10 uses a log function that throws an error when our mutationintroduces negative values.
in cases the design choice ofusing bucketing or changing the axis limits led to the samevisualizations being produced despite the mutations categoryc .
finally there were cases in category e where thefiltering was not arbitrary all positive values but was judgedto be the case by our approach.
all categories except e canbe handled by a more sophisticated mutation scheme or finer grained operators.
category e would require a pre definednotion of what is an adequately general filtering criterion.
c. rq3 effectiveness of synthesis approach finally we evaluate the end to end synthesis performance of v izsmith .
we reuse the kaggle notebooks utilized for mining to create benchmarks.
for every visualization slice we extracted in section iv c we select a visualization functionand create a benchmark where the dataframe corresponds tothe original dataframe i.e.
origdf f and the columns to visualize are origparticipa ting cols f .
the natural language query is set to the text document associated with fas described in section vi a. we select the largest visualization function interms of statements whose statements all come from the samecell in the parent notebook.
the rationale is that this simulatesa real usage scenario for v izsmith as notebook cells often correspond to a single semantic unit of work.
we also only 137defvisualization df col1 col2 import matplotlib.pyplot asplt train df df.drop df df 4e3 df 3e5 .index plt.scatter train df train df defvisualization df col1 import seaborn assns df df .fillna s df df .map s c q sns.heatmap df .corr annot true defvisualization df col1 import matplotlib.pyplot asplt df .hist bins grid false plt.xlabel col1 defvisualization df col1 col2 import numpy asnp import matplotlib.pyplot asplt df np.log df plt.scatter df df defvisualization df col1 import seaborn assns ms df sns.barplot ms .index ms fig.
examples of each category in table iv.
consider reusable functions as benchmarks.
this yields benchmarks in total.
for each benchmark we create an instantiation of v izsmith using only visualization functions mined from competitions other than the one corresponding to the benchmark leave one out cross project .
we then run v izsmith as well as a baseline version of v izsmith called v izsmith all that searches over all visualization functions including non reusable functions on each benchmark till they generate 10visualizations or timeout after seconds whichever is earlier.
we find that both v izsmith and v izsmith allhave a top10 accuracy of .
that is both have an exactly matching visualization in the top for only of the cases.
there aretwo possible reasons for this low performance a the qualityof the natural language query is poor and b styling variationssuch as color schemes rotation of tick labels and legendpositions will fail the matching visualization test.
in a separatemanual study of a sample of visualization functions withassociated natural language comments we found only to actually describe the kind of plot and the columns beingvisualized.
thus a is a distinct possibility.
to mitigate theeffects of b we sample benchmarks and examine theresults of both the tools manually.
in particular we ignorestylistic variations such as color schemes rotations of ticklabels legend positions etc.
while comparing the visualizationswith the ground truth.
the top accuracy in this case is56 and for v izsmith and v izsmith allrespectively.
although the numbers are close the difference lies in thenumber of functions explored.
v izsmith explores less visualization functions than v izsmith allwhile still getting slightly better accuracy as it only searches over reusablefunctions which we hypothesized to be more useful duringsynthesis than their non reusable counterparts.
hence wedemonstrate the utility of reusability analysis to improve end to end synthesis performance.
viii.
l imita tions and threa ts to validity a. real world usage we have not performed an explicit user study to gauge the performance of users using v izsmith on real world visualization authoring tasks.
hence the results in section vii cmay not apply to real use cases.
note that performing sucha study would require careful experimental design to decou ple the techniques behind v izsmith from the quality ofthe mined code as well as the associated natural languagecomments which are often imprecise or even irrelevant.
toenable external assessment we have released a fully func tioning prototype of v izsmith along with a simple ui at b. code licensing and security vizsmith s database is populated using code written by data scientists and machine learning practitioners that is publicly available on the internet.
as such code snippetsreturned by v izsmith may not be appropriate for use in certain contexts due to the license of the parent notebookcontaining the code snippet.
this can be mitigated by passingan appropriately vetted corpus to v izsmith .
security may also be a concern since v izsmith executes every function in its database as part of its metamorphic testing phase.
we couldmitigate this by adding extra checks to filter out functionswith excessive resource consumption unauthorized file systemaccess or network requests.
c. construct v alidity all three research questions involve manual analysis and thus have a subjective component.
for rq1 we classified the functions manually.
to reduce the effect of subjectivity weprovided simple and easily reproducible criteria for arrivingat this classification.
for rq3 we analyzed the generatedvisualizations manually because it is hard to automaticallyidentify stylistic variations in a reliable manner.
we preciselylisted down the classes of stylistic variations that we ignorewhile comparing two visualizations.
judging reusability as perdef.
involves manual inspection of the code the data and thevisualization.
thus rq2 has a higher risk of imprecision thanrq1 and rq3.
we mitigated this by having three reviewersindependently judge reusability and taking the majority vote.we also assessed the misclassifications qualitatively and cameup with general characterizations of the failure cases.
ix.
r ela ted work we compare v izsmith against existing visualization authoring systems along the dimensions of intended usage theuse of code templates the kind of specifications used and theaspect of learning from data.
we also compare and contrastapplications of code mining and reuse in other domains.
138a.
visualization authoring systems exploratory data analysis to facilitate data exploration systems such as v oyager and draco accept partial visual specifications containing the columns to visualize as well as wildcards to generate a collection ofvisualizations capturing different views of the data in a targetgrammar such as v ega lite .
these visualizations are fil tered and ranked based on either manually designed heuristics or using constraint solving .
these heuristicsensure conformance to best visualization design practices.these systems are very useful for quickly exploring data andgathering insights while v izsmith is mostly intended for searching for a specific visualization.
nevertheless v izsmith can also benefit from incorporating the design heuristics tobetter rank its output visualizations.
reusable visualization templates ivy allows users to build a specific visualization by choosing from a cata logue of visualization templates which are similar in spiritto the reusable functions mined by v izsmith .
however these templates are manually derived while v izsmith uses a combination of program analysis and metamorphic testingto collect its reusable functions.
visualization specifications similar to v izsmith a number of visualization authoring systems accepting natural language specifications from the user have been developed .
these systems use a carefully designed grammaror automaton to parse natural language queries describingthe desired visualization and keep track of the interactioncontext.
this grants users fine grained control over the pro duced visualization.
however the use of such a fixed grammarlimits the space of visualizations that can be generated.
dueto its use of mining v izsmith can target different kinds of visualizations such as word clouds visualizations usingdifferent apis and richer data transformation code such ascomputing correlations and cross tabulations on top of thesorting filtering and aggregation functionalities offered bythe above systems.
finally although this work only exploresa simple keyword based search to match snippets with userqueries recent advances in natural language processing nlp could be leveraged to improve the search.
richer modes of specification have also been explored.
falx allows users to provide pieces of the targetvisualization and the system utilizes program synthesis to gen erate the required data transformation and visualization code.this form of specification captures a lot more informationabout the desired visualization and thus falx can complement v izsmith in cases where a very specific visualization is desired and cannot be described accurately with keywords.
learning from data data2vis trains deep learning models on pairs of dataset and visualization specificationsobtained from the v ega lite corpus and recommendsvisualizations given a dataset at inference time.
however itdoes not grant control over the columns or fields that arevisualized which would force the user to pick out the desiredvisualization from a large set.
plotcoder is the closestto v izsmith in that it generates visualization code fromnatural language that contains information about columns tovisualize.
however it restricts the set of visualizations to asubset of matplotlib and cannot generate transformation codelike v izsmith .
b. code mining and reuse code mining and reuse has been employed in a number of other applications.
the eg system uses static analysisacross large code bases to build a database of usage examplesfor apis which can be queried.
however the examples are notalways executable and thus their output cannot be shown onthe user s input.
for visualization synthesis it is essential forthe user to see the output visualization on their data to selectthe one that meets their needs thus such an approach wouldnot work in our problem setting.
autotype and tde synthesize executable programs using mined code corpora for type validation and stringtransformation respectively.
phoenix and getafix induce repair patterns from mined static analysis repairs.
allthese domains offer precise specifications positive and nega tive examples for a type input output pairs for transformationsand a pass fail from the static analyzer.
this greatly simplifiesthe filtering of bad mined code as one can simply check themagainst the specification.
in v izsmith s setting the lack of such a precise target necessitates the use of techniques such asmetamorphic testing to weed out bad visualization functions.
aroma takes a different approach to reusability.
it accepts a partial code snippet as input and performs codecompletion by searching over a large indexed code corpus andintersecting the search results.
this intersection step ensuresthe completed code only contains elements that are commonacross a sufficiently diverse set of snippets and thus reusable.
x. c onclusion we presented v izsmith a tool which accepts a dataset columns to visualize and a text query from the user and synthe sizes visualization code.
first in an offline phase v izsmith mines kaggle notebooks to create a database of reusable python functions.
it uses a novel metamorphic testing ap proach to automatically assess reusability of functions.
whenpresented with the user query v izsmith efficiently searches this database to find relevant functions execute them andreturn the generated visualizations.
we evaluated v izsmith and found that it can suggest the right visualization for ofthe benchmarks.
we also found that using reusability analysishelps improve the quality of visualizations and reduces thesearch space by .
v izsmith is available publicly at xi.
a cknowledgements we thank caroline lemieux karan bavishi and all our anonymous reviewers for their invaluable feedback on thispaper.
this research is supported in part by a grant fromfujitsu research of america and nsf grants ccf ccf and cns .
139references e. segel and j. heer narrative visualization telling stories with data ieee transactions on visualization and computer graphics vol.
no.
p. nov. .
.
available s. kandel a. paepcke j. m. hellerstein and j. heer enterprise data analysis and visualization an interview study ieee transactions on visualization and computer graphics vol.
no.
pp.
.
t. kluyver b. ragan kelley f. p erez b. granger m. bussonnier j. frederic k. kelley j. b. hamrick j. grout s. corlay p .
ivanov d. avila s. abdalla c. willing and j. d. team jupyter notebooks a publishing format for reproducible computational workflows inelpub .
h. wickham ggplot2 elegant graphics for data analysis.
springerv erlag new y ork .
.
available j. d. hunter matplotlib a 2d graphics environment computing in science engineering vol.
no.
pp.
.
m. gharehyazie b. ray and v .
filkov some from here some from there cross project code reuse in github in proceedings of the 14th international conference on mining software repositories ser.
msr .
ieee press p. .
.
available c. sadowski k. t. stolee and s. elbaum how developers search for code a case study in proceedings of the 10th joint meeting on f oundations of software engineering ser.
esec fse .new y ork ny usa association for computing machinery p. .
.
available y .
wu s. wang c. p .
bezemer and k. inoue how do developers utilize source code from stack overflow?
empirical softw.
engg.
vol.
no.
p. apr.
.
.
available y .
wang y .
feng r. martins a. kaushik i. dillig and s. p .
reiss hunter next generation code reuse for java in proceedings of the 24th acm sigsoft international symposium on f oundationsof software engineering ser.
fse .
new y ork ny usa association for computing machinery p. .
.available s. bajracharya j. ossher and c. lopes sourcerer an infrastructure for large scale collection and analysis of open source code sci.
comput.
program.
vol.
p. jan. .
.
available s. p .
reiss semantics based code search in proceedings of the 31st international conference on software engineering ser.
icse .
new y ork ny usa association for computing machinery p. .
.
available s. wang d. lo and l. jiang active code search incorporating user feedback to improve code search relevance in proceedings of the 29th acm ieee international conference on automated softwareengineering ser.
ase .
new y ork ny usa associationfor computing machinery p. .
.
available r. cottrell r. j. walker and j. denzinger semi automating small scale source code reuse via structural correspondence inproceedings of the 16th acm sigsoft international symposiumon f oundations of software engineering ser.
sigsoft fse .new y ork ny usa association for computing machinery p. .
.
available x. xia l. bao d. lo p .
s. kochhar a. e. hassan and z. xing what do developers search for on the web?
empirical softw.
engg.
vol.
no.
p. dec. .
.
available s. sachdev h. li s. luan s. kim k. sen and s. chandra retrieval on source code a neural code search in acm sigplan workshop on machine learning and programming languages mapl .
j. cambronero h. li s. kim k. sen and s. chandra when deep learning met code search in industry track of 27th acm joint european software engineering conference and symposium on thef oundations of software engineering esec fse .
acm pp.
.
c. wang y .
feng r. bodik i. dillig a. cheung and a. j. ko falx synthesis powered visualization authoring arxiv e prints p .
arxiv .
feb. .
c. wang y .
feng r. bodik a. cheung and i. dillig visualization by example proc.
acm program.
lang.
vol.
no.
popl dec. .
.
available the kaggle data science platform.
.
available https v oice call quality customer experience.
.
available https data.gov.in catalog voice call quality customer experience stacked bar chart.
.
available gallery lines bars and markers bar stacked.html how can i normalize data and create a stacked bar chart?
.
available h. agrawal and j. r. horgan dynamic program slicing sigplan not.
vol.
no.
p. jun.
.
.
available a. zeller and r. hildebrandt simplifying and isolating failureinducing input ieee trans.
softw.
eng.
vol.
no.
p. feb. .
.
available c. sun y .
li q. zhang t. gu and z. su perses syntaxguided program reduction in proceedings of the 40th international conference on software engineering ser.
icse .
new y ork ny usa association for computing machinery p. .
.
available e. weyuker on testing non testable programs computer journal vol.
.
t. y .
chen s. c. cheung and s. m. yiu metamorphic testing a new approach for generating next test cases technical report hkustcs98 .
g. amati bm25.
boston ma springer us pp.
.
.
available k. wongsuphasawat d. moritz a. anand j. mackinlay b. howe and j. heer v oyager exploratory analysis via faceted browsingof visualization recommendations ieee trans.
visualization comp.
graphics proc.
infovis .
.
available d. moritz c. wang g. l. nelson h. lin a. m. smith b. howe and j. heer formalizing visualization design knowledge as constraints actionable and extensible models in draco ieee transactions on visualization and computer graphics vol.
no.
p. jan. .
.
available a. satyanarayan d. moritz k. wongsuphasawat and j. heer v ega lite a grammar of interactive graphics ieee transactions on visualization and computer graphics vol.
no.
p. jan. .
.
available j. mackinlay automating the design of graphical presentations of relational information acm trans.
graph.
vol.
no.
p. apr.
.
.
available a. mcnutt and r. chugh integrated visualization editing via parameterized declarative templates arxiv e prints p. arxiv .
jan. .
t. gao m. dontcheva e. adar z. liu and k. karahalios datatone managing ambiguity in natural language interfacesfor data visualization proceedings of the 28th annual acm symposium on user interface software technology uist pp.
.
.
available v .
setlur s. e. battersby m. tory r. gossweiler and a. x. chang eviza a natural language interface for visual analysis proceedings of the 29th annual symposium on user interface softwareand technology uist pp.
.
.
available e. hoque v .
setlur m. tory and i. dykeman applying pragmatics principles for interaction with visual analytics ieee transactions on visualization and computer graphics no.
c .
.
available dx.
j. devlin m. w. chang k. lee and k. toutanova bert pre training of deep bidirectional transformers for language understanding inproceedings of the conference of the north american chapterof the association for computational linguistics human languagetechnologies v olume long and short papers .
minneapolis 140minnesota association for computational linguistics jun.
pp.
.
.
available t. b. brown b. mann n. ryder m. subbiah j. kaplan p .
dhariwal a. neelakantan p .
shyam g. sastry a. askell s. agarwal a. herbert v oss g. krueger t. henighan r. child a. ramesh d. m. ziegler j. wu c. winter c. hesse m. chen e. sigler m. litwin s. gray b. chess j. clark c. berner s. mccandlish a. radford i. sutskever and d. amodei language models are few shot learners .
v .
dibia and c .
demiralp data2vis automatic generation of data visualizations using sequence to sequence recurrent neural networks arxiv e prints p. arxiv .
apr.
.
j. poco and j. heer reverse engineering visualizations recovering visual encodings from chart images computer graphics f orum vol.
no.
pp.
.
.
available x. chen l. gong a. cheung and d. song plotcoder hierarchical decoding for synthesizing visualization code in programmatic context inproceedings of the 59th annual meeting of the association for computational linguistics and the 11th international joint conferenceon natural language processing acl ijcnlp v olume longpapers virtual event august c. zong f. xia w. li andr.
navigli eds.
association for computational linguistics pp.
.
.
available c. barnaby k. sen t. zhang e. glassman and s. chandra exempla gratis e.g.
code examples for free in proceedings of the 28th acm joint meeting on european software engineering conferenceand symposium on the f oundations of software engineering ser.
esec fse .
new y ork ny usa association forcomputing machinery p. .
.
available c. yan and y .
he synthesizing type detection logic for rich semantic data types using open source code in proceedings of the international conference on management of data ser.
sigmod .
new y ork ny usa association for computing machinery p. .
.
available y .
he k. ganjam k. lee y .
wang v .
narasayya s. chaudhuri x. chu and y .
zheng transform data by example tde extensibledata transformation in excel in proceedings of the international conference on management of data ser.
sigmod .
new y ork ny usa association for computing machinery p. .
.
available r. bavishi h. y oshida and m. r. prasad phoenix automated data driven synthesis of repairs for static analysis violations inproceedings of the 27th acm joint meeting on europeansoftware engineering conference and symposium on the f oundationsof software engineering ser.
esec fse .
new y ork ny usa association for computing machinery p. .
.available j. bader a. scott m. pradel and s. chandra getafix learning to fix bugs automatically proc.
acm program.
lang.
vol.
no.
oopsla oct. .
.
available s. luan d. yang c. barnaby k. sen and s. chandra aroma code recommendation via structural code search proc.
acm program.
lang.
vol.
no.
oopsla oct. .
.
available