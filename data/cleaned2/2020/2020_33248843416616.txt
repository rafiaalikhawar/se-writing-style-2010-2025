buildfast history aware build outcome prediction for fast feedback and reduced cost in continuous integration bihuan chen school of computer science and shanghai key laboratory of data science fudan university shanghai chinalinlin chen school of computer science and shanghai key laboratory of data science fudan university shanghai china chen zhang school of computer science and shanghai key laboratory of data science fudan university shanghai chinaxin peng school of computer science and shanghai key laboratory of data science fudan university shanghai china abstract longbuildtimesincontinuousintegration ci cangreatlyincrease thecostinhumanandcomputingresources andthusbecomeacom monbarrierfacedbysoftwareorganizationsadoptingci.buildout comepredictionhasbeenproposedasoneoftheremediestoreducesuchcost.however thestate of the artapproacheshaveapoorpre dictionperformanceforfailedbuilds andarenotdesignedforpracti calusagescenarios.toaddresstheproblems wefirstconductanempirical study on builds to characterize build times in realworldprojects andasurveywith75developerstounderstandtheir perceptionsaboutbuildoutcomeprediction.then motivatedbyourstudyandsurveyresults weproposeanewhistory awareapproach namedbuildfast topredictcibuildoutcomescost efficientlyandpractically.wedevelopmultiplefailure specificfeaturesfromclosely related historical builds via analyzing build logs and changed files andproposeanadaptivepredictionmodeltoswitchbetweentwo modelsbasedonthebuildoutcomeofthepreviousbuild.weinves tigateapracticalonlineusagescenarioof buildfast wherebuilds are predicted in chronological order and measure the benefit from correct predictions and the cost from incorrect predictions.
our experiments on projects have shown that buildfast improved the state of the art by .
in f1 score for failed builds.
ccs concepts software and its engineering maintaining software.
keywords continuous integration build failures failure prediction acm reference format bihuan chen linlin chen chen zhang and xin peng.
.
buildfast history awarebuildoutcomepredictionforfastfeedbackandreduced permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn ... .
in continuous integration.
in 35th ieee acm international conference onautomatedsoftwareengineering ase september21 virtual event australia.
acm new york ny usa pages.
.
introduction continuousintegration ci isasoftwaredevelopmentpracticewhere developersarerequiredtomergetheircodeintoasharedrepositoryfrequently .eachintegrationisthenverifiedthroughanautomatedbuild includingdependencyinstallation codecompilationandtestcaseexecution.cibringsmultiplebenefitstoasoftwareor ganization e.g.
ithelpstofindandfixintegrationerrorsearlierandfaster improvedeveloperpr oductivity improvepro ductqualityand reduce development and delivery time .
apartfromthebenefits cicanincurhighcosts .inparticular oneofthewell recognizedcostsinciiscausedbythetimedurationofabuild a.k.a.buildtime .asreportedbyarecentstudyon open sourceprojects over40 ofthebuildshaveatimedurationofover30minutes whichfarexceedstheacceptablebuildtimeof minutes .
such long build times greatly increase the cost in human and computing resources and hence become a common barrier faced by software organizations adopting ci .
ontheonehand developersneedtowaitforalongtimetogetintegrationfeedbackbeforetheycontinuetoworkontheverified lat estcodebase.asaresult developerslosefocusandbecomelessproductive which hinders parallel development and overshadows the benefitsofci.ontheotherhand computingresourcesrequiredforrunningbuildsareusuallyinproportiontobuildtimes .hence a tremendous investment in computing resources e.g.
millions of dollars in google is needed to support slow builds.
toreducesuchcostinci anumberoftechniqueshavebeenproposedfromdifferentperspectives.onelineofworkisfocusedondevelopingtestcaseprioritizationtechniques andtest caseselectiontechniques intociinordertominimizetestexecutiontimesandspeedupbuilds.complementarytothem oneline of work attempts to skip specific builds e.g.
only having nonsourcecodechanges forsavingtheirwholebuildtimesviamanual configurations or automated rule based learning based methods .
more aggressively build outcome prediction leverages machine learning techniques 35th ieee acm international conference on automated software engineering ase topredictbuildoutcomessuchthatthecostofthebuildsthatare predicted to pass can be reduced.
as our empirical study reports that over of the builds are passed sec.
.
build outcome prediction can potentially lead to high cost reduction.
despiterecentadvances buildoutcomepredictionstillsuffersthe followingproblems heavilyhinderingtheirpracticaladoptioninci.
first failed builds have a poor prediction performance.
since passed buildsoftenaccountforaverylargeportionofallbuildsinaproject existingtechniquestendtopredictbuildsaspassedsuchthattheycanstillyieldanoverallgoodperformancealthoughtheyhaveapoorper formanceonfailedbuilds.however failedbuilds ifincorrectlypre dicted canincurhighcost.moreimportantly existingtechniquesfailtoutilizefeaturesthatcanbettercapturethecharacteristicsofbuildfailures.specifically sometechniques leveragesocial andtechnicalfactorstolearnpredictionmodelswithoutdistinguish ingpassedandfailedbuilds.morerecently sometechniques trytoleveragefailure specificfeatures butinacoarse grainedway e.g.
failure ratio and types of build failures .
second practicalusagescenariosarenotwellconsidered.ascibuilds arriveinchronologicalorder abuild soutcomeshouldbepredictedbasedonapredictionmodellearnedfromitspreviousbuilds.hence theperformanceofexistingtechniquesobtainedbywidely usedcrossvalidationdeviatestheperformanceinpractical onlinescenarios.such negativedeviationshavealsobeenempiricallyreported .moreover thecostfromincorrectpredictionsandthebenefitfromcorrect predictions are important indicators which are closely relevant to practical usage scenarios.
however without accounting for usage scenarios existing techniques only measure the prediction performance but do not systematically analyze the cost and benefit.
inthispaper wefirstconductalarge scaleempiricalstudy using builds from github projects to investigate the timedurationofcibuilds.ourstudyisdesignedtocharacterizethesever ityofslowbuildsinpracticeandmotivatethepotentialofbuildout comeprediction.wealsoconductanonlinesurveywith75develop erstoretrievefirst handinformationaboutdevelopers perceptions ofbuildoutcomeprediction.oursurveyresultsrevealconsistent concernswiththeabovetwoproblemsofbuildoutcomeprediction.
then toaddressthetwoproblems weproposeahistory awareapproach buildfast topredictcibuildoutcomescost efficientlyandpractically.itcanhelptoobtainfastintegrationfeedbackandreduceintegrationcost.specifically toaddressthefirstproblem wedesign multiple failure specific features via digging deep into historical builds i.e.
analyzingbuildlogs andchangedfilesfromcloselyrelatedhistoricalbuilds.wealsodevelopanadaptivepredictionmodeltoswitchbetweentwomodelsbasedontheoutcomeofthepreviousbuild.thesetwomodelsareseparatelytrained respectivelyusinga representative set of builds.
to address the second problem we investigateapracticalonlineusagescenarioof buildfast wherethe builds are predicted in chronological order to measure the benefit from correct predictions and the cost from incorrect predictions.
toevaluatetheeffectivenessandefficiencyof buildfast wecomparedbuildfastwiththreestate of the artapproaches on20javaopen sourceprojects.ourevaluationresultshavedemon stratedthatbuildfastcansignificantlyimprovethebestofthestate of the artapproachesby47.
inf1 scoreforfailedbuildswithoutlosingf1 scoreforpassedbuilds.thebenefitof buildfastexceeds its cost and the average time overhead to predict a build is .3seconds which is practical.
we also demonstrated the contribution of each component in buildfast to its effectiveness improvement.
in summary this paper makes the following contributions.
weconductedanempiricalstudytocharacterizebuildtimesinrealworldprojectsaswellasadevelopersurveytounderstandtheirperceptions on build outcome prediction.
weproposedahistory awareapproach namedbuildfast topredict ci build outcomes cost efficiently and practically.
weconductedlarge scaleexperimentson20open sourceprojects to demonstrate the effectiveness and efficiency of buildfast.
the rest of the paper is structured as follows.
section presents anempiricalstudyofbuildtimesandadevelopersurveytomotivate build outcome prediction.
section introduces the proposed ap proach in detail.
section evaluates the proposed approach.
section reviews related work before section draws conclusions.
motivation inthissection wefirstpresentanempiricalstudyofbuildtimesinalargecorpusofopen sourceprojectsandthenreportoursurveywith developers to better motivate build outcome prediction.
.
build time study ourempiricalstudyofbuildtimesisfocusedonopen sourceprojectsduetotheirpubliclyavailablebuilddata.westartwiththedatasetpro posedbyzhangetal.
whichcontainsthecibuildhistoryof3 open sourcejavaprojectshostedongithub.tothebestofourknowl edge thisisthelargestdatasetofcibuilds.tofurtherensurethattheprojectsusecifrequently weexcludetheprojectsthathavelessthan builds which results in projects with a total of builds.indetail .
ofthemhaveabuildstateof passed erroredorfailed.
an errored or failed build is called a brokenbuild.
thedifferenceisthattheerrorthatcausesanerroredbuildoccursin anearlierbuildphasethantheerrorthatcausesafailedbuild.there maining21 .
ofbuildshaveuncommonstates i.e.
canceled andstarted and thus are not considered in this study.
using2 917buildsfrom1 621projects ourstudyisdesignedto answer the following three research questions.
rq1 howlongisthetimedurationofpassed erroredandfailedci builds across all the projects?
rq2 howmanypassed erroredandfailedcibuildscanbeconsidered as slow in each project?
rq3 howmuchbuildtimeisconsumedbythepassed erroredand failed ci builds in each project?
inrq1 wereporttheoverallbuildtimedistributionrespectivelyfor allpassed erroredandfailedbuildsinthe2 917builds.in rq2 we measureforeachprojecttheratioofslowbuildsamongallpassed er roredandfailedbuildsrespectively andreporttheratiodistributionacrossallprojects.here weregardabuildasslowifithasabuildtimeofmorethan10minutes becausetheacceptablebuildtimeis10min utes .ourresultsfrom rq1andrq2aimtocharacterizethe generalityandseverityoftheincurredhighcostsbybuildtimes andmotivatethepotentialvalueofbuildoutcomepredictioninreducingcosts.in rq3 wemeasureforeachprojectthetotalbuildtimeofall passed erroredandfailedbuildsrespectively analyzeitsratiotothe a build time b ratio of slow builds c ratio of build time figure distributions of build time ratio of slow builds and ratio of build time w.r.t.
build states totalbuildtimeofallbuildsineachproject andreporttheratiodistributionacrossallprojects.ourresultsfrom rq3aimtorepresent thespaceofcostreductionthatcanbepotentiallyexploredbybuildoutcomeprediction.itisalsoworthmentioningthat ofthe2 917builds .
.
and17.
arepassed erroredandfailed respec tively.onlyaboutonequarterofthebuildsarebroken andsuchimbalance between passed and broken builds can challenge learningbased build outcome prediction as discussed in sec.
.
overallbuildtime rq1 .
fig.1agivestheoverallbuildtimedistributionforallbuilds passedbuilds erroredbuilds failedbuildsand brokenbuildsinviolinplotinlogarithmicscale.thethreelinesineach plotrespectivelydenotetheupperquartile themedianandthelowerquartile.weobservethatthemediantimedurationofallbuildsis9.3minutes whichismuchshorterthanreportedinapreviousstudy i.e.
20minutes .thislargedifferencecouldbeattributedtothesmall dataset i.e.
442buildsin67projects ofthepreviousstudy .
wealsoobservethatpassed errored failedandbrokenbuildshavea mediantimedurationof9.
.
.5and8.9minutesrespectively.ex ceptforerroredbuilds themediantimedurationofpassed failedandbrokenbuildsisveryclosetotheacceptable10 minutebuildtime denotedbythebluelineinfig.1a.morespecifically .
.
.
and47.
ofthepassed errored failedandbrokenbuildsareslowbuilds.further onequarterofthepassed errored failedandbro kenbuildshaveatimedurationofover22.
.
.2and28.9min utes while8.
.
.
and13.
ofthepassed errored failedandbrokenbuildseventakemorethananhourtorun.theseresultsdemonstratethatcibuildsoftentakeamoderatelylongtimetorun.inthatsense developersneedtowaitforamoderatelylongtimeto get the integration feedback which incurs moderately high costs.
ratioofslowbuilds rq2 .
fig.1bshowsthedistributionofthe ratioofslowbuildsamongpassed errored failedandbrokenbuildsacrossallprojectsinviolinplot.usingthemedians weobservethatatleast15.
.
.
and12.
ofthepassed errored failedandbrokenbuildsareslowinhalfoftheprojects.
.
projectshave noslowbuild.atfirstglance thisresultseemstobeinconsistent withtheresultinfig.1a i.e.
aroundhalfofthebuildsareslow .this canbeexplainedbytheobservationthatprojectswithalargerlinesofcodearemorelikelytohavealargernumberofbuildsandahigherratioofslowbuilds andthedifferenceisstatisticallysignificant i.e.
p .0001inwilcoxonsigned ranktest .moreover usingtheupper quartiles wesurprisinglyobservethatmorethan61.
.
.
and42.
ofthepassed errored failedandbrokenbuildsareslowintable survey questions q1are you a professional or part time software developer?
q2how large is your company?
q3how many years of java programming experience do you have?
q4how many projects have you worked on?
q5how many years of ci experience do you have?
q6how often does your team trigger ci builds of your projects?
q7are ci builds of your projects time consuming?
q8would ci build outcome prediction techniques be useful for cibased software development?
q9why would ci build outcome prediction be useful?
q10why would ci build outcome prediction not be useful?
onequarteroftheprojects.theseresultsindicatethatslowbuildsareamoderatelycommonproblemfacedbydevelopersadoptingci especially in large scale projects.
ratioofbuildtime rq3 .
fig.1cpresentsthedistributionof theratioofbuildtimeconsumedbythepassed errored failedandbro kenbuildsacrossallprojectsinviolinplot.wecanobservethatmorethan72.
.
and90.
ofthebuildtimeisconsumedbypassedbuildsin75 and25 oftheprojects whereasatmost9.
.
and27.
ofthebuildtimeisconsumedbybrokenbuildsin25 and75 oftheprojects.thisisconsistentwiththeimbalancednumber of passed and broken builds.
these results demonstrate that a considerablylargeamountoftimeisspentinpassedbuilds whichrep resentstheoptimalcostreductionthatcanbepotentiallyachievedby build outcome prediction see sec.
.
for a detailed discussion .
.
developer survey ouronlinesurveyisdesignedfordeveloperswhoparticipatedinci basedsoftwaredevelopment.therefore werandomlyselect15 000developersfrom57 939developerswhotriggeredcibuildsinthe1 projectsusedinourempiricalstudy.wesendanemailtoeachofthe 000developerstointroducethebackgroundonbuildoutcomepredictionandinvitethemtotakeouronlinequestionnairesurvey.wepromisethattheirparticipationwouldremainconfidential andouranalysis and reporting would be based on aggregated responses.
inresponsetoourinvitation 75developersfinishedthequestionnaire within one week i.e.
a participation rate of .
.
asreportedintable1 oursurveyconsistsof10questionstolearn aboutalltheparticipants professionalbackground ciusage and 44perceptions ofbuild outcome prediction.the completequestionnaire with options is available at our website .
professionalbackground q1 q4 .ofallparticipants .
are professionaldevelopers andonly6.
arepart timedevelopers.
.
workinacompanyofmorethan100employees .
workinacompanyof51to100employees and42.
workinacompanyofupto50 employees.
.
haveover10yearsofexperienceinjavaprogramming .
have6to10years and25.
haveupto5years.
.
have participatedinthedevelopmentofmorethan15projects .
haveparticipatedin11to15projects and36.
haveparticipatedinupto 10projects.webelievethattheparticipantshaveconsiderablygood experience in parallel software development.
ciusage q5 q7 .
.
oftheparticipantshaveusedciforover 10years .
and34.
haverespectivelyusedcifor6to10years and2to5years andonly8.
haveusedciforlessthan2years.withrespecttothebuildfrequency for52.
oftheparticipants theirteamaveragelytriggersacibuildeveryhour andfor34.
ofthepartici pants theirteamaveragelytriggersacibuildeveryminute.
.
alsocommenttheirteamtriggersacibuildforeverycommit.whenaskedaboutwhethercibuildsaretime consuming .
fullyagree while .
clearly disagree and are not sure.
perceptionofbuildoutcomeprediction q8 q10 .
.
of theparticipantsthinkthatbuildoutcomepredictionwouldbeuseful but26.
thinkthatitwouldnotbeuseful.
.
arenotsuremostlybecauseitdependsonhowitworksandhowwellitworks.further theparticipantsreportthreemajorreasonsfortheusefulness i.e.
obtainingfastfeedbackofcibuilds .
savingtimeoverheadofcibuilds .
andacceleratingsoftwaredevelopment .
.ontheotherhand theparticipantsalso revealfourmajor reasonsforthe uselessness i.e.
lackingpredictionperformance especiallyforfailed builds .
delaying the discovery of bugs due to incorrect predictions .
lackingexplainability andhencedevelopersdonottrustit .
andincreasingthedifficultyofbugfixingduetoincorrect predictions .
.
besides around half of the participants commentedthatcibuildshadtoberantoobtainthebuildartifactsthatwouldbeneededbyotherprojects especiallyforpassedbuilds.
insights.
fromoursurveyresults webelievethatbuildoutcome predictionhasitsownpotentialmeritforfastfeedbackandreducedcostinci.however thepredictionperformance especiallyforfailedbuilds shouldbetakengreatcareof asamajorityofthedevelopers have concerns on it.
the cost and benefit of build outcome prediction should be holistically investigated under a practical usage scenariosothatdeveloperscanhaveaholisticviewratherthanfearing the cost andcan have more trust to trybuild outcome prediction.
methodology inthissection wefirstpresentanoverviewof buildfast andthen elaborate each step of buildfast in detail.
.
overview ourhistory awarebuildoutcomepredictionapproachusesmachinelearningtechniques andhencehastwobasicphases trainingphaseandpredictionphase.inthetrainingphase buildfastfirstextractsthreesetsoffeaturesforeachbuildinatargetproject i.e.
featureextractioninsec.
.
.then buildfasttrainsanoveladaptivepredictionmodelwiththe extractedfeaturesfromasetof builds i.e.
table features about the current build idfeature description c1src churn of lines of production code changed c2test churn of lines of test code changed c3src ast diff whetherproductioncodeischangedinast c4test ast diff whether test code is changed in ast c5line added of added lines in all files c6line deleted of deleted lines in all files c7files added of files added c8files deleted of files deleted c9files modified of files modified c10src files of production files changed c11test files of test files changed c12config files of build script files changed c13doc files of documentation files changed c14class changed of classes modified added or deleted c15met sig modified of method signatures modified c16met body modified of method bodies modified c17met changed of methods added or deleted c18field changed of fields modified added or deleted c19import changed of import statements added or deleted c20class modified of classes modified c21class added of classes added c22class deleted of classes deleted c23met added of methods added c24met deleted of methods deleted c25field modified of fields modified c26field added of fields added c27field deleted of fields deleted c28import added of import statements added c29import deleted of import statements deleted c30commits of commits included c31fix commits of bug fixing commits included c32merge commits of merge commits included c33committers of unique committers c34by core member whether a core member triggers the build c35is master whetherthebuildoccursonmasterbranch c36time interval time interval since the previous build c37day of week day of week when the build starts c38time of day time of day when the build starts prediction model generation in sec.
.
.
in the prediction phase buildfast extracts the same sets of features for a build under prediction and uses the trained model to predict its build outcome.
moreover wesystematicallyexploreapracticalusagescenarioof buildfast to measure the cost and benefit i.e.
cost benefit analysisinsec.
.
.althoughcurrentlyimplementedforjavaprojects thatusetravisastheciservice buildfastcanbeeasilyextended to support other programming languages and other ci services by providing specific implementations for feature extraction.
.
feature extraction wesurveythefeaturesadoptedinthestate of the artapproaches andfindthattheirfeaturesaremostlydirectlytakenfrom thetravistorrentdatabase whichisageneral purposedatabase butisnotspecializedforbuildoutcomeprediction.asaresult high levelcoarse grainedfeaturesareusedwithoutfurtherdiggingdeep 45table features about the previous build idfeature description p1pr state build state i.e.
passed errored or failed p2pr compile error whether compilation error occurs p3pr test exception whether tests throw exceptions p4pr tests ok of tests passed p5pr tests fail of tests failed p6pr duration overall time duration of the build p7pr src churn of lines of production code changed p8pr test churn of lines of test code changed intothecharacteristicsaboutbuildfailures.therefore weintroduce severalfine grainedfailure specificfeaturestoenhancetheexistingfeaturesbasedonadetailedanalysisofbuildlogsandchangedfiles.
buildlogscontainhistoricalknowledgeaboutpreviousbuildfailures whichcanbelearnedtopredictfuturebuildoutcomes whilehowfilesarechangedinabuildcanaffectitsbuildoutcome.
in general we derive the features of a build i.e.
the current build inthreedimensions i.e.
featuresaboutthecurrentbuild features about the previous build and features about historical builds.
featuresaboutthecurrentbuild.
asthebuildlogofthecurrentbuildisunavailable atpredictiontime wederivethefeaturesfromfilechangesinthecurrentbuild.table2givesthefeatureswithournewfeaturesinbold.c c6representline levelchanges where c3and c4are newly derived to analyze changes at the level of abstractsyntaxtree ast sothatformattingchanges e.g.
removingaspace thatwillnotfailabuildaredistinguished.c c13denotefilelevel changes by distinguishing various kinds of files.
c c19are class method field and import level changes.
however they failtodistinguishhowaclass method fieldandimportischanged.forexample adeletedclasshasahigherprobabilitytocauseabuildfail urethananaddedclassbecausethedeletedclassmightbeusedbutitsusageisnotaccordinglyupdated.hence wederivenewfeatures c20 c29to distinguish modified added and deleted classes methods fieldsandimports.c c33denotecommit levelknowledge.
asabuildincludesasetofcommits weintroducec c32todistinguishthetypesofcommitsasbug fixingandmergingcommitshaveahighprobabilitytocausebuildfailuresduetopotentialincompletefix or merging conflict and c 33to measure the degree of collaborationinthecurrentbuildasahighdegreeofcollaborationmightleadtoahighpossibilityofconflicts.finally c c38representthemeta dataaboutthecurrentbuild i.e.
whotriggersthecurrentbuild and where andwhen thecurrent buildis triggered.
herewe introduce c34and c35because core members may less likely to fail a build and developers work more carefully on master branches.
featuresaboutthepreviousbuild.
asbuildfailuresoftenconsecutivelyoccur thecharacteristicsofthepreviousbuildoften serveasagoodindicator.table3reportsthefeaturesaboutthepreviousbuildofthecurrentbuildwithournewfeaturesinbold.specifically p1 p6arederivedfromthebuildlogofthepreviousbuild.we introducep 4andp5tomeasurethedegreeoffailurecausedbytesting.intuitively alargernumberoffailedtestsindicatesahigherdifficulty to fix the failed build and thus a higher probability to have a consecutive build failure.
p 6measures the build time of the previous build.
a longer build time indicates a higher complexity of the code and thus a higher possibility to fail.
p 7and p8measure thetable features about historical builds idfeature description h1fail ratio pr of broken builds in all the previous builds h2fail ratio pr incincrementoffail ratio pratlastbrokenbuild to fail ratio pr at penultimate broken build h3fail ratio re of broken builds in recent builds h4fail ratio com pr ofbrokenbuildsinallthepreviousbuilds thatweretriggeredbythecurrentcommitter h5fail ratio com re ofbrokenbuildsinrecent5buildsthatwere triggered by the current committer h6last fail gap of builds since the last broken build h7consec fail max maximum of of consecutive broken builds h8consec fail avg average of of consecutive broken builds h9consec fail sum sum of of consecutive broken builds h10commits on files of commits on the files in last months h11file fail prob maxmaximum of the probability of each changed file involved in previous broken builds h12file fail prob avgaverageoftheprobabilityofeachchangedfile involved in previous broken builds h13file fail prob sumsumoftheprobabilityofeachchangedfileinvolved in previous broken builds h14pr src files ofproductionfileschangedbetweenthelatest passed build and the previous build h15pr src files insize of the intersection of src files and pr src files h16pr test files of test files changed between the latest passed build and the previous build h17pr test files insize of the intersection of test files and pr test files h18pr config files ofbuildscriptfileschangedbetweenthelatest passed build and the previous build h19pr config files insize of the intersection of config files and pr config files h20pr doc files ofdocumentationfileschangedbetweenthe latest passed build and the previous build h21pr doc files insize of the intersection of doc files and pr doc files h22log src files of production files reported in thebuild log of the previous build h23log src files insize of the intersection of log src files and src files h24log test files oftestfilesreportedinthebuildlogofthe previous build h25log test files insizeoftheintersectionoflog test filesand test files h26team size size of team contributing in last months degree of code changes in the previous build and a high degree of code changes may also increase the difficulty to fix the failed build.
featuresabouthistoricalbuilds.
table4reportsthefeatures about historical builds with our new features in bold.
in particular h1 h5represent statistics about previous broken builds by distinguishing all previous builds the recent five builds and all previous builds and the recent five builds triggered by the committer of the current build.here we introduceh 2to measurethe increment between the failure ratio at the last and penultimate broken build.
a positivevalueindicatesanincreasingtrendinbuildfailures.h h9 arenewlyintroducedtomodelthedistancetothelastbrokenbuild andthenumberofhistoricalconsecutivebrokenbuilds.alarger 46valueofthesefeaturesindicateahigherpossibilityofbuildfailures.
h10 h25arenewlydesignedtomeasuretheconnectionofthefiles changedinthecurrentbuild hereafterreferredtoascurrentfilesfor theeaseofpresentation tohistoricalbuilds.indetail h 10measures thenumberofcommitsinthelastthreemonthsthatchangethecur rentfiles.ahighvalueofthisfeaturedenotesthatthecurrentbuildchangesfrequentlychangedfiles.asfrequentlychangedfilesoftenhavehighpotential ofbugs itislikely tofailthecurrentbuild.
h11 h13measuretheprobabilitythateachcurrentfileischangedin previousbrokenbuilds.thehigherthevalue thehigherpossibilitytofailthecurrentbuild.h h16 h18andh20measurethenumber ofproduction test buildscriptanddocumentationfileschanged between the latest passed build and the previous build.
if the previous build is broken they actually measure the files changed in the previous consecutive broken builds.
therefore a higher value indicatesahigherdifficultytofixpreviousbrokenbuilds.h h17 h19 andh21measuretheintersectionbetweenthecurrentfilesandthe changedfilesinpreviousconsecutivebrokenbuilds.thesmallertheintersection thelowerpossibilitytofixpreviousbrokenbuilds.sim ilarly h 22andh24measurethenumberofproductionandtestfiles reportedinthebuildlogofthepreviousbuild.suchfilesarelistedinbuildlogsmostlyduetoexceptionsinproductionandtestfiles and hence indicate the potential root causes of exceptions.
therefore a higher value indicates a higher difficulty to fix exceptions.
h 23and h25measuretheirintersectiontocurrentproductionandtestfiles.a smaller intersection indicates a lower possibility to fix exceptions.
h26measures the degree of collaboration in the last three months.
duetospacelimitation weomittheimplementationdetailoffeature extraction.
the implementation and a detailed explanation of each feature are available at our website .
.
prediction model generation ourpredictionmodelisdesignedtohavetwocharacteristics i.e.
feature selection and adaptive model to improve the performance.
featureselection.
asshownintable2 3and4 atotalof72featuresareintroducedfromthreedimensions.consideringthepotentially different characteristics of different projects we leverage featureselectionmethods toautomaticallyselectthefeaturesthat contributemosttobuildoutcomepredictionforaspecificproject in steadofmanuallydeterminingafixedsetoffeaturesforallprojects.
aswillbediscussedinourevaluation seesec.
.
differentsetsof features are selected for different projects.
adaptivemodel.
whetherthepreviousbuildfailsorpasseshasa differentimpactonthedevelopmentactivitiesinthecurrentbuild.ifthepreviousbuildfails developersmainlyconductcorrectiveorpreventiveactivitiesduringthecurrentbuild.ifthepreviousbuildpasses developers mainly perform adaptive or perfective activities during thecurrentbuild.thus tolearnsuchdifferenceswithoutconfusingthemodel weseparateourtrainingdatasetintotworepresentative datasets i.e.
the first dataset includes the builds whose previous buildfailsandtheseconddatasetincludesthebuildswhoseprevious build passes.
however both datasets still have imbalanced data for passed and failed builds which might hinder the prediction performance for failed builds.
to partially solve this problem we include allthefailedbuildsintothetwodatasetswithoutdistinguishingthe buildoutcomeoftheirpreviousbuild i.e.
wefurtherincludethefailed builds whose previous build passes into the first dataset andfurther include the failed builds whose previous build fails into the seconddataset.basedonthesetwodatasets werespectivelytrainamodeltopredictbuildoutcomes.inthisway inthepredictionphase if the build under prediction has a failed previous build we use the first model and if the build under prediction has a passed previous build we use the second model.
.
cost benefit analysis practicalusagescenarioshavetobeanalyzedtomeasurethecostandbenefitofbuildoutcomeprediction.ascibuildsarriveinchronolog icalorder buildoutcomehastobepredictedinanonlinewayinchrono logicalorder.exceptfor alltheexistingapproachesdonot predict in chronological order but in a cross validation way i.e.
a buildmaybepredictedbasedonamodellearnedfromfuturebuilds .
following this online scenario build outcome prediction can be usedintwoscenarios dependingonwhetherthepredicted to passbuildsareranornot.first eachbuildisactuallyran.however teammembersandprojectmanagerscouldhavemoreconfidencetostartusingthelatestcodebaseandconductingprojectplanwithoutwait ingforthebuildtofinishifitispredictedtopass.hence computingresourcesarenotreduced butwaitingtimesarereduced promotingparalleldevelopmentandspeedingupthereleasecycle.second thepredicted to failbuildsareactuallyran whilethepredicted to passbuildsareskipped.therefore computingresourcesarealsoreduced.inbothscenarios however developersmayworkonthebuggycodebaseandneedtoredoorrollbacktheirworkifthepredictionisnot correct i.e.
predicted to pass builds actually fail .
in the latter scenario thoseintegrationerrorsmayaccumulateforalongtimewithout timely correction increasing the fixing efforts.
asindicatedbyoursurvey seesec.
.
developershavemoreconcernsonthesecondaggressiveusagescenario e.g.
delayingthedis coveryofbugsduetoincorrectpredictions increasingthedifficultyofbugfixingduetoincorrectpredictions andrequiringthebuildar tifactsthatwouldbeneededbyotherprojects.therefore wedecidetotakethefirstconservativeusagescenario.underthisscenario thebenefitcomesfromthecorrectpredictionforpassedbuilds.hereweusethebuildtimeofsuchbuildsastheindicatorofthe benefit.aswe donotdirectlypinpointtherootcauseofbuildfailures weconsidernobenefitfromthecorrectpredictionforfailedbuilds.correspond ingly the cost comes from the incorrect prediction for failed builds.hereweusethebuildtimeofsuchbuildsastheindicatorofthe cost andconsidernocostfromtheincorrectpredictionforpassedbuildsbecausedeveloperswouldwaitforthebuildtocompleteinthesame wayasnobuildoutcomepredictionapproachisused.finally we define the gainas the difference between benefit and cost.
evaluation wehaveimplementedbuildfastin13.1klinesofpython rubyand javacode using scikit learn formachinelearningandcldiff for code change analysis.
we have released the code of buildfast at our website with the dataset used in our evaluation.
.
evaluation setup to evaluate the effectiveness and efficiency of the proposed approach wecomparedourapproachwiththreestate of the artbuild 47table project statistics id projectcreation dateloc starspassed buildsfailed builds p1 hikaricp .5k p2caelum vraptor4 .6k p3 checkstyle .7k p4 achilles .3k p5 dspace .9k p6jackson databind .1k p7closure compiler .9k p8 graylog .8k p9 jooq .6k p10 optiq .7k p11 kill bill .5k p12lwicket bootstrap .4k p13 vectorz .5k p14 mybatis .1k p15 owl api .4k p16 pushy .2k p17 quickml .3k p18 retrofit .4k p19 rexster .4k p20 weld .5k outcome prediction approaches and measured the contribution of eachcomponentinbuildfasttoitseffectiveness using20github javaprojects.ourevaluationisdesignedtoanswerthefollowing research questions.
rq4 howistheeffectivenessof buildfastinpredictingbuildoutcomes compared with the state of the art approaches?
sec.
.
rq5 howistheefficiencyof buildfastinpredictingbuildoutcomes compared with the state of the art approaches?
sec.
.
rq6 howisthecontributionofeachcomponentinbuildfastto the achieved effectiveness of buildfast?
sec.
.
dataset.
werandomlyselected20projectsfromthe1 621projects used in our empirical study see sec.
.
.
the statistics about these projectsarelistedintable5 includingtheircreationdate linesofcode thenumberofstars andthenumberofpassedandfailedbuilds.we can see that these projects are mostly large in size and have a longevolutionhistory whichensuresdiversebuilddata.foreachproject we split the builds into the training and testing dataset by .
comparisonapproaches.
forrq4andrq5 weselected bs1 bs2 andbs3 asthebaselinesbecause bs1andbs2are thestate of artapproachesthatpredictinacross validationwayand bs3isthestate of artapproachthatpredictsinchronologicalorder.
forrq6 weranbuildfastbyremovingfeatureselection bytrainingonlyonemodelwithallbuilds bytrainingtwomodelswithout including all failed builds and by excluding our new features.
evaluationmetrics.
followingpriorworks weusedprecision recall f1 scoreandauctomeasuretheaccuracyofbuildoutcomeprediction.wedistinguishedprecision recallandf1 scoreforpassed buildsandfailedbuildsforadetailedcomparisonacrossdifferent approaches.wealsousedbenefit costandgain seesec.
.
tomea surethecost efficiency.as bs3isdesignedforoptimizingauc we canonlymeasureitsauc.insummary weusedaccuracyandcostefficiency to indicate the effectiveness.
modelconfiguration.
duringmodelgeneration seesec.
.
we adoptedchi squaredtesting toselectthetop30featuresforour first model and information gain to select the top features for our second model.
besides we used xgboost with defaultparametersastheclassifier.thisconfigurationwasempiricallyestablishedasgood.forspacelimitation detailedcomparisonsto other configurations are available at our website .
.
effectiveness evaluation rq4 table6presentstheresultsof bs1 bs2 bs3andbuildfastwithrespecttotheseveneffectivenessmetrics.thefirstcolumnshowsthebuildoutcomepredictionapproaches thesecondcolumnliststhemet rics andthenexttwentycolumnsreportthemetricvaluesforeachprojectundereachapproach andthelastcolumngivestheaverageforprecision recall f1 scoreandaucandthesumforbenefit costandgainacrossallprojects.theunitofbenefit costandgainishour.
comparedwith bs1 buildfastsignificantlyimprovedtheprecision recallandf1 scoreforfailedbuildsby16.
.
and47.
andsuchdifferenceswerestatisticallysignificantusingwilcoxonsigned ranktest.meanwhile buildfastslightlyimprovedthef1 scoreforpassedbuilds.overall buildfastimprovedf1 scoreandaucof bs1 by3.
and5.
withthedifferencesstatisticallysignificant.forbenefit costandgain therewasnostatisticallysignificantdifference due to the minority of failed builds and the variance of build times.
still buildfasthadatotalgainof2 131hoursforallprojectsfromone fourthofthebuilds i.e.
testingdata withitsbenefitexceeding its cost.
thus buildfast is cost efficient and can save ci cost.
comparedwith bs2whichwasdesignedto improvetheaccuracy forfailedbuilds buildfastsignificantlyimprovedalltheaccuracymetricsexceptfortherecallforfailedbuilds.overall buildfastim provedf1 scoreforfailedbuilds f1 scoreforpassedbuilds f1 scoreandaucby55.
.
.
and19.
andthedifferenceswere statistically significant.
due to such a large accuracy improvement for passed builds buildfast improved gain by .
.
comparedwith bs3whichwasspecificallydesignedtooptimize auc buildfaststillsignificantlyimprovedaucby27.
andthe differencewasstatisticallysignificant.surprisingly bs3achievedthe lowestaucamongthefourapproaches.thiscouldbeattributed to the seven coarse grained features in their work.
buildfastsignificantlyoutperformedthebestofthestate of the art approaches bs1 by .
in f1 score for failed builds without losing the f1 score for passed builds.
besides buildfast saved a sum of hours for all the projects.
.
efficiency evaluation rq5 table7reportsthetimeoverheadofthefourapproaches.thefirstcolumn lists the specific approach phases i.e.
training phase and predictionphase.thetimeoverheadofpredictionphaseiscomposedoftwo parts in form of a b where adenotes feature extraction time andbdenotesoutcomepredictiontime.wecanseethat bs2tookthe longesttimefortraining i.e.
averagely469.8secondsforeachproject because it used cascaded classifiers while buildfast took .
seconds whichwaslongerthan bs3butshorterthan bs1.astraining isaone timejob thistimeoverheadisacceptable.ontheotherhand buildfast took .
seconds to extract features for each build and another0.004secondstoobtainthepredictedbuildoutcome.while being the slowest due to the large number of used features buildfast is still practical for real world projects.
48table effectiveness comparisons to the state of the art a.metric p1p2p3p4p5p6p7p8p9p10p11p12p13p14p15p16p17p18p19p20allbs1pre.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
benefit .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cost .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gain .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
121bs2pre.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
benefit .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cost .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gain .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
223bs3auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.614buildfastpre.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
benefit .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cost .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gain .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table efficiency comparisons to the state of the art phase bs1 bs2 bs3buildfast training sec .
.
.
.
prediction sec .
.
.
.
.
.
.
.
buildfasttook6.9secondsfortraining and1.3secondsto predict for a build which was acceptable for practical usages.
.
ablation study rq6 table8showstheresultofourablationstudytomeasurethecontributionofvarioussettingsinbuildfasttotheeffectivenessinsec.
.
.
removingfeatureselection.
buildfasthadadegradationin almostalltheaccuracymetricsafterremovingfeatureselection.significantly theprecisionforfailedbuildsdecreasedby9.
from0.572to0.
andtherecallforpassedbuildsdecreasedby6.
from0.926to0.
.overall f1 scorehadadegradationof5.
.therewasnosig nificantdifferenceforauc benefit costandgain.theseresultsshowthatfeatureselectioncontributestotheimprovedaccuracyforboth failed and passed builds by selecting representative features.
trainingonemodelwithallbuilds .whenonlyonemodelwas trainedin buildfast withall builds buildfast suffereda significant degradation in all the precision recall f1 score and auc met ricsexceptfortherecallforfailedbuilds.overall f1 scoreforfailed builds f1 scoreforpassedbuilds f1 score andaucdecreasedby20.
.
.
and5.
.becauseofsuchalargedegradationforpassedbuilds gaindecreasedby11.
.theseresultsindicatethatouradop tionoftwomodelsgreatlycontributestoaccuracyandcost efficiency by learning specialized knowledge from distinguishable build data.
trainingtwomodelswithoutallfailedbuilds.
whenwedid notincludeallfailedbuildsintothetrainingdataofthetwoseparate models buildfasthadadegradationinallmetrics.significantly 49table contributions of each component in buildfast a.metric p1p2p3p4p5p6p7p8p9p10p11p12p13p14p15p16p17p18p19p20allbuildfast without feature selectionpre.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
benefit .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cost .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gain .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
274buildfast with one modelpre.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
benefit .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cost .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gain .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
897buildfast without all failed datapre.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
benefit .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cost .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gain .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
087buildfast without our new metricspre.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pre.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rec.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1f.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1p.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
f1.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
benefit .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cost .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gain .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
thef1 scoreforfailedbuildsdecreasedby4.
.thisisconsistentto ourmotivationofincludingallfailedbuildsintothetwomodeltrain ingprocess i.e.
partiallysolvingtheunbalancedsizeoffailedbuilds in order to improve the prediction accuracy for failed builds.
excludingournewfeatures.
afterweexcludednewfeatures buildfast had a significant degradation in accuracy metrics forfailed builds.
overall the f1 score for failed builds decreased by .
.
this indicatesthe importance of ournew features to model the characteristics of build failures.
to further look into the importanceofournewfeatures weanalyzedthemostimportantfeatures inourtwomodelsacrossallprojectsbyaccumulatingafeature s importancevalue computedduringfeatureselection acrossallthe 50table important features in our two models first model second model feature imp.proj.
feature imp.proj.
pr state .
pr state .
fail ratio pr .
1fail ratio com re .
log src files in .
log src files in .
pr test exception .06920file fail prob sum .
pr src files .
team size .
field modified .
files added .
last fail gap .
class changed .
pr src churn .
met deleted .
commits on files .
3file fail prob max .
pr tests ok .
test ast diff .
file fail prob sum .
field deleted .
fail ratio com re .
9merge commits .
consec fail sum .
src churn .
file fail prob max .
line deleted .
pr duration .
commits .
by core member .
is master .
src files .
import added .
met body modified .
line added .
log src files .
last fail gap .
import added .
3commits on files .
projects.thetop20importantfeaturesforourtwomodelsarereported in table where imp.denotes the accumulated importance value of a feature and proj.denotes the number of projects that select a feature.
we can see that more than half of the important features are newly introduced in this work highlighted in bold .
this indicates the usefulness of our new features.
besides these important features are actually selected in various number of projects meaningthatdifferentprojectsselectdifferentsetsoffeatures.this demonstrates the importance of feature selection.
feature selection adaptive models and newly introduced features all contribute positively to the achieved effectiveness of buildfast especially for failed builds.
.
discussion we discuss the threats to and limitations of this work.
threats.
first wedesignedanonlinesurveywithgithubdevelopers instead of face to face interviews because it can allow us to recruitarelativelylargenumberofparticipants althoughtheparticipant rate was low .
second we decided to not offer compensation butaskparticipantstovoluntarilytakethesurvey.weexpectedthat developers who were really interested in build outcome prediction andwellmotivatedwouldparticipateinthissurveyandthusthe survey quality couldbe improved.
third buildfast was only evaluatedagainstopen sourceprojectswithoutdevelopers feedback.
experiments with industrial projects and developers are needed to better measure the practical usages of buildfast.
limitations.
first although buildfast outperforms the stateof the artapproachessignificantlyinpredictionaccuracyforfailed builds wehavetoadmitthatthereisstillaroomforimprovements.onepotentialwayistounderstandthesemanticsofcodechangesbyrecentadvancesindeepcoderepresentationlearning asweonly focusoncodechangesatsyntacticlevel.second buildfastonly predictswhetherabuildfails butcannotidentifytherootcauses which would be useful for developers to fix the failure in advance.
we plan to extend buildfast to classify a failed build into several root causes e.g.
compilation errors and testing failures .
related work wereviewthemostcloselyrelatedworkonbuildprediction costreduction in ci empirical studies about ci and defect prediction.
buildprediction.
hassanandzhang useddecisiontreesto predictbuildoutcomewithcombinedfeaturesrelatedtosocial technical coordinationandprior buildfactors.theirmodelcorrectly predicted of the failed builds and of the passed builds on alargeprojectattheibmtorontolabs.wolfetal.
adoptedsocial networkanalysistoobtaincommunicationstructuremeasures andleveragedsuchmeasuresintoabayesianclassifiertopredicttheout comeofabuild.theyachievedprecisionandrecallbetween50 and onibm sjazzproject.then schroter extendedwolfetal.
s work byaddingtechnicaldependenciesintothesocialnetwork.
kwan et al.
analyzed the effect of social technical congruence i.e.
thematchbetweenthecoordinationneedsestablishedbytechnical domain and the coordination activities carried out by project members onbuildoutcome.theirstudyontheibmrationalteamconcertprojectshowedthatsocial technicalcongruencehadanegativeeffectonintegrationbuildsuccessrate.thesocialfactorsin these approaches are often organization specific greatly hindering the generalizability of predictive models over a wider audience.
instead buildfast is specifically designed for ci environment and thus can be applied to any project as long as it adopts ci.
finlayetal.
useddatastreamminingtechniquesbasedoncode metrics i.e.
basicmetrics dependencymetrics complexitymetrics cohesionmetrics andhalsteadmetrics to predictbuildoutcome.
they achieved accuracy on ibm s jazz project.
as only source codefileswereincludedinmetriccomputation thisapproachcould not predict build failures caused by errors in non source code files e.g.
configurationfiles .recently niandli usedcascadedclassifierstopredictbuildoutcomeincibasedonfile levelmetricsfrom the current and previous build and failure statistics from historical builds.similarly hassanandwang leveragedmetricsfromthe currentandpreviousbuild.differently theyincludedmetricsabout failure type of the previous build and coarse grained code changes inthecurrentbuild anddidnotconsiderhistoricalbuilds.differentfromsuchapproaches weextractfine grainedcodechangefeaturesfromhistoricalbuilds.niandli proposedtodynamicallyadapt a pool of classifiers learned from various projects to a new project thatdoesnothavesufficientdataofbuilds.thisapproachisorthog onaltothepreviousapproachesandourapproach becauseitreusestheclassifierstrainedbythepreviousapproachesandourapproach.
xiaandli investigatedtheaccuracyofnineclassifiersintheonlinebuildoutcomepredictionscenario andfoundthattheaccuracyfelltoafairlylowlevel.xieandli targetedtheonlinescenario and proposed a semi supervised online auc optimization method.
however thecoarse grainedfeatureshinderitseffectiveness.exceptforthreeapproaches allthepreviousbuildoutcome prediction approacheswere evaluated in thecross validation way and thus they might not work well in the practical online scenario.
instead buildfast targets the online scenario.
moreover apart fromtheaccuracyindicators weanalyzethebenefitfromcorrect predictionsandthecostofincorrectpredictionstosystematically evaluate the cost effectiveness of buildfast.
recently jin and servant proposedsmartbuildskiptopredictthefirstbuildsina sequence of build failures with a machine learning classifier and 51then determine that all subsequent builds will fail until it observes a passed build.
this approach targets a different usage scenario of buildfast andourclassifiercanbeintegratedintotheirapproach.
besides bisongetal.
developedapredictivemodeltopredict thebuildtimeofabuildjobinci.mcintoshetal.
xiaetal.
and macho et al.
used machine learning techniques to predict whether source code changes will induce changes in the build system i.e.
build configuration co changes .
these techniques target a different prediction problem than buildfast.
costreductioninci.
apartfrombuildoutcomeprediction varioustechniqueshavebeenproposedtoreducecostinci.forexample toreducebuildcost someplugins aredesignedintociservicesfordeveloperstoskipsomebuildsbymanuallyconfiguring thebuildprocess abdalkareemetal.
proposedarule basedtechniquetoautomaticallyidentifycommitsthatcanbeciskipped followed by a machine learning based approach and gambi et al.
developedanovelbuildsystemthatcanlazilyretrieveparts oflibrariesthatareneededduringtheexecutionofabuildtarget.tufanoetal.
proposedtoanalyzedeveloper schangesandpredict whether it impacts the longest critical path whether it may lead to buildtimeincreaseandthedelta andthepercentageoffuturebuilds that might be affected by such changes.
to reduce testing cost celik et al.
consolidated repetitive and expensive setup activities into pre configured testing virtual machines and a number of test case prioritization and test case selection havebeendevelopedintocitominimizetestexecutioncost.these techniques are orthogonal to buildfast as they focus on different aspects in ci.
ideally they can be combined together to achieve optimal cost reduction.
empiricalstudiesaboutci.
withthewidespreadadoptionof ci empiricalstudieshavebeenwidelyconductedtoinvestigatedif ferentaspectsofci e.g.
usage cost benefits barriersandneedswhendevelopersuseci typeandfrequencyofbuildfailuresin ci buildfailurescausedbycompilation testing andstaticviolationsinstaticanalysis noiseandheterogeneity inhistoricalbuilddataset characteristicsoflong buildduration anti patternsinci andtestcodeevolution in ci .
some studies reported concrete evidence on expensive build cost and some studies revealed that waiting for builds to finish is a common barrier faced by developers.
there fore thesestudiesmotivatetheneedforbuildoutcomepredictionto save build cost.
besides studies about build failures shed light on our feature selection.
defect prediction.
defectpredictionhasbeenwidelystudied.
generally defectpredictionmethods e.g.
build machinelearningmodelsbasedondifferentkindsofmetricsand predictdefectsatdifferentgranularitylevels.asdefectprediction mostlyfocusesondefectsinsourcecodefilesandbuildfailurescanbecausedbyerrorsinnon sourcecodefiles defectpredictiontechniquescannotdirectlytranslatetobuildoutcomepredictioninci.
conclusions in this paper motivated by our empirical study on build times and ourdevelopersurveyonbuildoutcomeprediction weproposea newhistory awareapproach namedbuildfast topredictcibuild outcomes cost efficiently and practically.
our experiments on 20projects have demonstrated that buildfast can improve the stateof the artapproachesby47.
inf1 scoreforfailedbuildswithoutlosingtheaccuracyforpassedbuilds andthebenefitof buildfast exceeds its cost bringing fast feedback and reduced ci cost.