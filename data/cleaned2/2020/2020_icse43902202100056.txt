program comprehension and code complexity metrics an fmri study norman peitek leibniz institute for neurobiology magdeburg germanysven apel saarland university saarland informatics campus saarbr ucken germanychris parnin nc state university raleigh north carolina usa andr e brechmann leibniz institute for neurobiology magdeburg germanyjanet siegmund chemnitz university of technology chemnitz germany abstract background researchers and practitioners have been using code complexity metrics for decades to predict how developers comprehend a program.
while it is plausible and tempting to use code metrics for this purpose their validity is debated since they rely on simple code properties and rarely consider particularities of human cognition.
aims we investigate whether and how code complexity metrics reflect difficulty of program comprehension.
method we have conducted a functional magnetic resonance imaging fmri study with participants observing program comprehension of short code snippets at varying complexity levels.
we dissected four classes of code complexity metrics and their relationship to neuronal behavioral and subjective correlates of program comprehension overall analyzing more than metrics.
results while our data corroborate that complexity metrics can to a limited degree explain programmers cognition in program comprehension fmri allowed us to gain insights into why some code properties are difficult to process.
in particular a code s textual size drives programmers attention and vocabulary size burdens programmers working memory.
conclusion our results provide neuro scientific evidence supporting warnings of prior research questioning the validity of code complexity metrics and pin down factors relevant to program comprehension.
future work we outline several follow up experiments investigating fine grained effects of code complexity and describe possible refinements to code complexity metrics.
prelude let us begin with a short subjective assessment of code complexity.
consider the following code snippet1 1publiclist integer compute int a intb intc if a b inttemp b b a a temp if a c inttemp c c a a temp if b c inttemp c c b b temp returnarrays.aslist a b c before going further putting aside concerns of performance or coding style we would like you to spend a few moments and calculate the result of compute .
based on this experience please rate the complexity i.e.
how difficult it is to understand the parts of the code and their dependencies 1the code snippet is an example of an unrolled insertion sort which is fast for sorting a small number of inputs .of this code snippet on a point scale from very simple to very complex.
well how did it go?
how did you rate this snippet?
software engineering research has developed several complexity metrics calculated based on various structural properties of the code .
for example halstead s complexity a metric for vocabulary size would yield a score of .
mccabe s cyclomatic complexity a metric for the number of linearly independent paths through a program would yield a score of .
beyer s depdegree a metric that considers complexity arising from low level data flow results in a score of .
finally a simple metric of counting lines of code would provide a score of .
apparently these values differ considerably although it is difficult to tell without a common scale.
i. i ntroduction in the past years the software engineering community has been using various complexity metrics to predict how programmers understand code implement quality gates in continuous integration and predict the likelihood of defects .
for example from to a total of studies proposed or analyzed nearly code metrics alone with code complexity being one of the most frequent categories of study .
many of these metrics are widely used in software analysis tools.
for example sonar qube a popular static analysis tool used in continuous integration supports a multitude of metrics such as cyclomatic complexity across dozens of programming languages.
for this particular metric the tool will report a methods should not be too complex violation for any method that exceeds the default threshold of .
while code metrics help to describe properties of code they are notoriously limited in capturing human cognition and behavior already years ago kaner and bond warned that too simplistic software metrics could do more harm than good because it is doubtful whether they actually measure what we think they measure .
several studies underline this point.
for example scalabrino et al.
found in an empirical study at most minuscule correlations between complexity metrics and code understanding .
ajami et al.
found that complexity ieee acm 43rd international conference on software engineering icse .
ieee metrics fail to consider how humans process code for example flat structures are easier to comprehend than nested ones .
in the same vein jbara and feitelson provide evidence that complexity metrics miss the increased ease of comprehension of repeated code constructs .
despite these warnings it is tempting to use complexity metrics to predict how programmers perceive the complexity of code or how much cognitive load it would require to understand a piece of code.
despite substantial research the big picture is still unclear.
so the overarching question that drives our work is can variations in classes of code complexity metrics explain differences in programmer cognition during program comprehension?
to address this question we draw on insights from neuroscience studies on cognitive load and from linguistic studies on sentence complexity.
an extensive body of previous research has examined how syntax complexity in natural language can influence brain activation and processing difficulty.
for example complex sentences such as the girl that the boy is tickling is happy can be difficult to process for patients with broca s aphasia a cognitive deficiency due to an acute brain lesion these patients cannot reliably distinguish between the girl or the boy being happy.
in healthy patients such sentences will cause distinct activation of specialized language processing regions in the brain not seen with simpler grammatical structures.
to perform these studies neuro linguists typically conduct a parameterized analysis of sentences where they intentionally construct sentences that vary along several metrics of interest such as left branching complexity movement distance or filler gap dependencies observing differences in behavioral measures and brain activation.
such studies provide deep insights into why not only whether comprehension of certain language constructs can be difficult gaining insights into the inner processing of language cognition.
in the current work we have conducted a study in which participants comprehended code snippets which were systematically selected to contrast different values of code complexity metrics among four major classes of code complexity metrics code size vocabulary size control flow complexity and data flow complexity .
for each we picked a commonly used representative metric as a baseline before exploring further metrics.
the underlying idea is that the more code lines code size loc as representative or vocabulary vocabulary size halstead to understand or the more possible execution paths control flow mccabe or data dependencies to keep track of data flow depdegree the more cognitive resources a programmer needs.
to this end we explore the relation of code complexity metrics to behavioral and cognitive correlates of program comprehension .
we investigate the reliability of subjective perception of code complexity to include the programmer s perspective.
based on their aim and definition as well as prior neurolinguistic studies we expect different outcomes for different kinds of complexity metrics a a higher number of symbols as measured by vocabularysize metrics induces higher cognitive processing demands as seen when increasing the number of words in a sentence .
this is also supported by early studies on the relationship of halstead s complexity and comprehensibility b an increased number of control paths as measured by control flow metrics increases activation of areas associated with rule guided conditional reasoning such as reading conditional propositions and counterfactual sentences if mike pressed the brake pedal then the car would have stopped c a higher number of data flow dependencies as measured by depdegree increases activation of broca s area syntactic working memory as seen with sentences where an assignment of values must occur later in the sentence i.e.
filler gap dependencies which cowgirl did mary expect to have injured herself due to negligence?
.
in a nutshell we found that changes in complexity metrics can explain differences in programmer cognition to different extents.
size based and vocabulary based metrics correlate with the anticipation of work whereas data flow metrics correlate with higher cognitive demands in a network of brain areas activated during program comprehension.
simple control flow metrics e.g.
number of branches predict cognitive load better than more complex control flow metrics e.g.
mccabe .
in general not many code complexity metrics incorporate data flow which seem to capture a distinct aspect of cognition showing a promising avenue of further work.
in summary we make the following contributions we devise a multi modal experiment framework that links complexity metrics to cognitive processes of program comprehension.
we provide empirical evidence for the relation of code complexity metrics on the one hand and neuronal and behavioral correlates on the other hand.
we show that behavioral data are the best predictor for subjective complexity.
we present a non exact refined replication of our previous fmri study with a larger set of more varied and targeted code snippets .
we share an online replication package2to share experiment design tasks and analysis protocols.
ii.
s tudy design our study of neuronal and behavioral correlates of code complexity metrics builds on an observation that we made in previous work as a side product of studying another research question identifying neuronal correlates of program comprehension we found first indications of a measurable correlation between neuronal activity and some code complexity metrics .
however this has not been explored further so the existence and kind of relationship between complexity metrics and cognitive processes remained unclear.
we specifically 3access to actual fmri data is granted upon request.
525designed our study to unveil this relationship including a multi modal experiment setup tailored to this question with proper code snippets that vary across different metrics and by analyzing a total of metrics regarding their predictive power.
a. research goals in this paper we aim at answering the following research questions rq do different classes of code complexity metrics correlate with programmers behavior during program comprehension?
rq do different classes of code complexity metrics correlate with programmers cognitive load in terms of brain de activation during program comprehension?
rq do different classes of code complexity metrics correlate with programmers subjective perception of code complexity?
b. pilot studies to answer our research questions we carefully designed our experiment.
first we compiled a set of java code snippets by obtaining snippets from previous studies on program comprehension and by augmenting this set by searching for code snippets with similar complexity.
second from this pool of code snippets with a wide range of complexities we selected the most suitable snippets for an fmri study by running two pilot studies at the authors institutions.
we asked pilot study participants professional programmers and phd students to understand the snippets as quickly and accurate as possible and to verbally share their thoughts afterwards.
unlike in the fmri scanner we did not set a time limit per snippet because the actual comprehension time is an important factor to select appropriate snippets for an fmri study.
in the pilot studies we also asked for a subjective evaluation of each snippet s complexity but unlike in the subsequent fmri study we did not ask them to rank all presented snippets.
third we selected snippets for the fmri study that were associated with a range of complexity metrics values balancing our final selection across the four classes of complexity metrics.
for illustration we show one of the snippets in listing which computes the length of the last word in a string the code exhibits large values for some of the metrics not being trivial to solve pilot participants took about seconds while still staying within the seconds limit allowed in the fmri study.
feedback from participants indicated that they needed a high level of cognitive effort to understand the snippet but could still succeed.
in particular they noted that the snippet did not allow them to take a mental break .
that is it was difficult to analyze individual statements while keeping other statements in mind and that they were unable to match the code to any known algorithm.
finally consistent with previous studies we excluded all context information from snippets to enforce bottom up comprehension .
this way we reduce theinfluence of previous experience on cognitive load because employing a more efficient top down approach is impeded and because expertise can moderate the relationship between complexity and performance .
in table i we provide information on the code snippets and code complexity metrics that we selected for the fmri study see the supplementary web site for all code snippets and all metrics .
in table ii we show the correlations among the four metrics for all code snippets.
although we designed the snippets to vary in complexity we were restricted by the requirements of the fmri scanner especially the limited screen size to show a maximum of lines of code and that each snippet is comprehensible within seconds .
thus a certain correlation among the metrics is unavoidable.
1public static void main 2string text the quick brown fox jumps 3system.out.print compute text 6static int compute string text intresult boolean flag false for inti text.
length i i charc text.
charat i if c a c z c a c z flag true result else if flag break returnresult listing complex code snippet that computes the length of the last word in a string.
the output for this snippet is .
c. fmri study research context when brain regions activate or deactivate during program comprehension or any other cognitive process their oxygenation levels change.
this is reflected in a change in the proportion of oxygenated and deoxygenated blood blood oxygenation level dependent bold response both of which have different magnetic properties .
an fmri scanner measures these changes and localizes them to specific brain areas which are associated with different cognitive processes.
thus we can associate activated brain areas to how participants proceeded in comprehending a snippet.
in addition research on the brain s default mode network dmn suggests that cognitive load is linked to the level of deactivation of the dmn during cognitively demanding tasks .
this way we can determine the cognitive load of program comprehension during the tasks.
participants participants were including one whose fmri data had to be excluded from analysis due to excessive head movements late undergraduate or graduate students at the university magdeburg female male .
.
years old .
we determined their programming experience based on a validated questionnaire .
we found that they had a medium 4m sdenotes a mean of mand standard deviation of s. 526table i code snippets used in the study with four selected complexity metric scores and experimental results behavioral data correctness time and subjective complexity.
a higher intensity of a cell s background color indicates a higher complexity.
the histogram plots show the distribution of subjective complexity skewness to the right represents higher subjective complexity.
complexity metrics experiment results snippetcode size loc 1v ocabulary halstead 1control flow mccabe 1data flow depdegree 2correctness in time in sec.
subjective complexity low!medium!highloopaverage of array .
.
contains substring .
.
count vowels in string .
.
greatest common divisor .
.
h index .
.
length of last word .
.
palindrome check .
.
square root of array .
.
recursionbinary to decimal .
.
cross sum .
.
factorial .
.
fibonacci variation .
.
power .
.
if elsecontains yes or no .
.
hurricane check .
.
sort four elements .
.
.com basleijdekkers metricsreloaded dbeyer depdigger level of programming experience .
.
years and sufficient experience with object oriented programming selfestimated level of .
.
on a likert scale of to and java self estimated level of .
.
on a likert scale of to .
thus the participants are intermediate programmers according to dreyfus taxonomy of skill acquisition .
all participants had normal or corrected to normal vision and were right handed.
they received monetary compensation and could abort the experiment at any time.
the study was approved by the local ethics board.
design and tasks our study design builds on a previous fmri study .
we presented three tasks in the fmri scanner.
first participants should comprehend a code snippet.
to this end they should determine what would be printed on the screen if the snippet was executed.
when they responded the experiment moved on but there was an upper limit of seconds for a comprehension task.
a second distractor task5followed to reduce reflective thoughts .
finally a second rest condition followed.
after three comprehension snippets a control condition followed in which participants saw another snippet and should click whenever they spotted an opening bracket.
this process was repeated until the participant completed all comprehension snippets.
in figure we illustrate one out of five experiment trials.
5we used the d2 task a psychological test of attention in which participants scan through a row of letters and decide for each letter whether it is a dwith two marks .
data collection we carried out the imaging sessions which lasted around minutes on a tesla fmri scanner6 equipped with a channel head coil.
the heads of participants were fixed with a cushion with attached earmuffs containing fmri compatible headphones.7participants wore earplugs for further noise protection.
we obtained a t1 weighted anatomical scan of the participants brain with mm isotropic resolution.
we captured a whole head fmri using a continuous multi band echo planar imaging epi sequence with a dynamic number of volumes as it depended on participant performance echo time ms repetition time ms flip angle multi band acceleration factor slices of mm thickness with .
mm gaps .
during the fmri session we collected behavioral data with an fmri compatible two button response device.
participants indicated whether they could compute the result of a snippet.
we showed a warning after seconds that the time was almost up.
after the fmri session we conducted a semi structured interview with each participant which was based on the results of the pilot studies.
in addition to open ended questions investigating the participants individual perception of snippet complexity we showed them the code snippets again and asked them to order the snippets regarding complexity.
such categorization tasks can produce insights into how participants 6philips achieva dstream best the netherlands 7mr confon gmbh magdeburg germany p d p p d d .
distractor public static void main intresult intnum while num result result num num system.out.println result .
code comprehension4.
control locating brackets no comprehension public static void main int result int num while num result result num num system.out.println result .
distractor .
rest .
distractor2.
compre hension .
distractor .
rest .
compre hension .
rest...... max.
s s s ... max.
s .
rest ...fig.
illustration of one out of five experiment trials.
approach a task e.g.
physics novices and experts categorize problems based on different aspects .
we allowed participants to self choose the number of categories because we noticed in the pilot runs that participants had difficulties when a fixed number of piles did not match their expectation of different complexity levels.
as in the pilot studies this helps us to understand what made a snippet difficult or easy to comprehend.
if participants made only two piles simple and complex we encouraged them to distinguish it further often leading to three or four piles see section iii c .
data analysis while our fmri study of code complexity is novel the fmri data analysis represents best practices from neuroscience and follows previous studies in software engineering .
to analyze the fmri data we used brainv oyager tmqx .
.
.
we transformed each participant s anatomical scan into the standard talairach brain which allows us to correct for differences between the participants brain sizes.
we preprocessed the fmri data with standard 3d motion correction slice scan time correction temporal filtering high pass glm fourier cycles and spatial smoothing gaussian filter fwhm mm .
we conducted a random effects general linear model glm analysis defining one predictor per condition program comprehension distraction control and rest.
to identify brain areas related to program comprehension we filtered the data to all voxels that showed a positive deflection of the bold response during the comprehension condition.
we computed the contrast between program comprehension and control condition p false discovery rate fdr corrected minimum cluster size mm3 .
to identify deactivated brain areas we obtained all voxels that show a negative bold deflection when contrasting comprehension and rest p fdr corrected minimum cluster size mm3 .
for correlation analysis we computed the mean amplitude of positive or negative bold deflection in percent for each cluster task snippet and participant and correlated with the complexity metrics.
in addition to brain activation we collected two further dependent variables first we observed participant behavior response time response correctness .
this helped us to evaluate whether participants actually worked on understanding the snippets.
we excluded snippets where participants accidentally responded too fast response time less than seconds which happened in out of comprehension tasks.
second we recorded subjective complexity in a post interview we converted the piles into equidistant values between and .
for example if a participant created piles we assigned snippets of the first pile a complexity score of the second pile a score of the third and the fourth .
piles translate to and and piles to and .
to analyze the relationship between complexity metrics and cognitive processes we use kendall s to compare each metric s complexity value with the observed brain de activation across all snippets.
we use kendall s rather than pearson s correlation coefficient because of its power with interval data and robustness against outliers .
iii.
r esults in this section we present the results of our data analysis including behavioral fmri and subjective complexity data.
we summarize the correlation results in table ii.
we separate results from discussion see section iv to prevent mixing interpretation with data.
to streamline the presentation we concentrate here on the four representative metrics.
in section iv a we consider further metrics providing more evidence on the link between complexity metrics and cognitive processes.
a. complexity metrics and behavioral data on average participants needed seconds to solve a task and solved of the tasks correctly.
all participants were able to complete all tasks before the maximum experiment time was reached.
regarding the relationship to complexity metrics mccabe has no correlation to neither response time nor correctness.
loc halstead and depdegree all show a small correlation with response time and a medium correlation with correctness.
528table ii kendall s and the explained variance r2 in brackets of the dependent variables.
a darker cell shading indicates a stronger correlation none small medium and strong .
complexity metrics activation deactivation subjective loc halstead mccabe depdegree ba ba ba ba ba ba complexity loc .
.
halstead .
.
.
mccabe .
.
.
.
complexity metrics depdegree .
.
.
.
.
ba .
.
.
.
.
.
.
.
.
.
ba .
.
.
.
.
.
.
.
.
.
activationba .
.
.
.
.
.
.
.
.
.
ba .
.
.
.
.
.
.
.
.
.
ba .
.
.
.
.
.
.
.
.
.
deactivationba .
.
.
.
.
.
.
.
.
.
correctness .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
behavioral data time .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
l r ap l r a p fig.
visualization of the activated brain areas all in the left hemisphere ba voxel tal ba voxel tal ba voxel tal and ba broca s area voxel tal .
a anterior p posterior l left r right.
l r ap l r a p fig.
visualization of the deactivated brain areas ba voxels tal and ba voxels tal which both are part of the default mode network.
a anterior p posterior l left r right.
b. complexity metrics and fmri data brain activation in fig.
we visualize the activated brain clusters.
in our study four brain areas are significantly activated during program comprehension brodmann area ba ba ba and ba broca s area .
notably these activation clusters were found also in previous fmri studies of program comprehension .
the relationship of the complexity metrics and activation strength of the four areas corroborates the behavioral data but provides a stronger and more nuanced view cf.
table ii .
again mccabe shows no correlation.
loc has a medium correlation with ba and a small correlation with ba ba and ba .
halstead and depdegree show a small correlation with ba cf.
fig.
and consistent medium correlations across ba ba and ba .
brain deactivation fig.
visualizes the specific positions of the two clusters that we found in ba and ba which belong to the default mode network.
regarding the relationship with the metrics mccabe again shows no correlation with brain deactivation.
depdegree shows a small correlation that explains almost none of the observed variance in brain deactivation.
loc and halstead have medium correlations with both deactivated areas cf.
table ii .
8brodmann areas serve as an anatomical classification system.
the entire brain is split into several areas on the basis of cytoarchitectonic differences which suggest to serve different functional brain processes .
behavioral data and fmri data we analyzed the relation of the behavioral data with the de activated areas we found strong correlations with the response correctness for ba ba ba and a medium correlation with ba .
for response time we found mostly small correlations and one medium correlation ba .
in summary mccabe shows no correlation with the strength of brain activation or generic cognitive load.
loc halstead and depdegree show small to medium correlations with brain activation and cognitive load.
c. subjective complexity in addition to objective measures of brain activation we investigated the relationship between code complexity metrics and subjective complexity based on the participants rating.
two participants created two piles cf.
section ii c5 nine participants created three piles and eight participants created four piles of complexity.
participants generally balanced the size of each pile.
we transformed the piles into numerical values .
.
.
regarding the relationship to the metrics we observe only low correlations with mccabe showing no correlation and the other metrics a small correlation only.
subjective complexity and behavioral data we observe a medium correlation between response time and the subjective complexity rating.
with the number of correctly solved tasks the subjective rating shows the strongest correlation in general.
uni000003ed uni000003f1 uni000003ee uni000003ec uni000003ee uni000003f1 uni0000003e uni0000004b uni00000012 uni000003ed uni00000358 uni000003ec uni000003ed uni00000358 uni000003f1 uni000003ee uni00000358 uni000003ec uni00000004 uni00000110 uni0000019a uni0000015d uni000001c0 uni00000102 uni0000019a uni0000015d uni0000017d uni00000176 uni00000003 uni0000015d uni00000176 uni00000003 uni00000439 uni00000011 uni0000018c uni0000017d uni00000110 uni00000102 uni0000003c uni0000011e uni00000176 uni0000011a uni00000102 uni0000016f uni0000016f uni00000003 uni00000357 uni00000003 uni000003ec uni00000358 uni000003ed uni000003ec uni0000018c uni00000003 uni00000190 uni0000018b uni000001b5 uni00000102 uni0000018c uni0000011e uni0000011a uni00000357 uni00000003 uni000003ec uni00000358 uni000003ec uni000003ee uni000003ed uni000003ec uni000003ee uni000003ec uni000003ef uni000003ec uni000003f0 uni000003ec uni0000002c uni00000102 uni0000016f uni00000190 uni0000019a uni0000011e uni00000102 uni0000011a uni000003ed uni00000358 uni000003ec uni000003ed uni00000358 uni000003f1 uni000003ee uni00000358 uni000003ec uni0000003c uni0000011e uni00000176 uni0000011a uni00000102 uni0000016f uni0000016f uni00000003 uni00000357 uni00000003 uni000003ec uni00000358 uni000003ef uni000003ee uni0000018c uni00000003 uni00000190 uni0000018b uni000001b5 uni00000102 uni0000018c uni0000011e uni0000011a uni00000357 uni00000003 uni000003ec uni00000358 uni000003ed uni000003f2 uni000003f0 uni000003f2 uni000003f4 uni00000044 uni00000110 uni00000012 uni00000102 uni0000010f uni0000011e uni000003ed uni00000358 uni000003ec uni000003ed uni00000358 uni000003f1 uni000003ee uni00000358 uni000003ec uni0000003c uni0000011e uni00000176 uni0000011a uni00000102 uni0000016f uni0000016f uni00000003 uni00000357 uni00000003 uni00000372 uni000003ec uni00000358 uni000003ec uni000003f5 uni0000018c uni00000003 uni00000190 uni0000018b uni000001b5 uni00000102 uni0000018c uni0000011e uni0000011a uni00000357 uni00000003 uni000003ec uni00000358 uni000003ec uni000003ed uni000003ee uni000003ec uni000003f0 uni000003ec uni000003f2 uni000003ec uni00000018 uni0000011e uni00000189 uni00000018 uni0000011e uni00000150 uni0000018c uni0000011e uni0000011e uni000003ed uni00000358 uni000003ec uni000003ed uni00000358 uni000003f1 uni000003ee uni00000358 uni000003ec uni0000003c uni0000011e uni00000176 uni0000011a uni00000102 uni0000016f uni0000016f uni00000003 uni00000357 uni00000003 uni000003ec uni00000358 uni000003ee uni000003ee uni0000018c uni00000003 uni00000190 uni0000018b uni000001b5 uni00000102 uni0000018c uni0000011e uni0000011a uni00000357 uni00000003 uni000003ec uni00000358 uni000003ec uni000003f4fig.
relationship of the four complexity metrics with broca s area ba .
each dot represents the mean activation for a single snippet.
mccabe shows no correlation.
loc halstead and depdegree show small positive correlations meaning that higher complexity values increase load in broca s area.
however each metric only explains part of the observed variance in activation.
subjective complexity and fmri data all de activated areas show mostly stronger correlations with the subjective complexity ratings than with the code complexity metrics.
the deactivated areas of ba and ba show a medium and strong correlation respectively.
the four activated brain areas show only small correlations with subjective complexity.
in summary while subjective complexity has small correlations with complexity metrics it accurately depicts whether participants could solve a task.
subjective complexity also correlates with our measure of cognitive load.
iv.
d iscussion we start the discussion by answering our overarching research question followed by a detailed discussion of the relationship of code complexity metrics with cognitive processes.
we conclude by formulating a set of hypotheses and outlining perspectives that arise from our study.
a. overarching research question are complexity metrics connected to how programmers process code?
yes and no.
based on plausibility and prior neuro linguistic studies we hypothesized some definitive relationships between code complexity metrics and programmers cognition.
for example we expected that code with more data flow shows a direct positive correlation with ba due to increased memory load .
while we indeed observe a positive correlation between depdegree as an indicator for data flow complexity and ba we also observe small to medium strength correlations with all other cognitive processing measures i.e.
all activated and deactivated brain areas and their levels as well as behavioral data i.e.
response time and correctness .
similarly loc and halstead exhibit small to medium strength correlations with all behavioral and cognitive processing measures.
mccabe however consistently lacked any significant correlation with our observed measures.
all of the observed relationships between complexity metrics and cognitive processing measures are nuanced and contextual into which we delve next in more detail.
deactivated areas cognitive load when we must allocate attention to a task with perceived difficulty areas of the brain associated with wandering and reflective thinking default mode network are deactivated.
the level of deactivation is an indicator for cognitive load .
two classes of complexity metrics exhibited medium correlations with this deactivation code size loc and vocabulary halstead .
in other words the size of code either as pure textual length or in terms of vocabulary size drives cognitive load.
we also observed a small correlation of data flow depdegree but no correlation of control flow mccabe with deactivation.
perhaps sizebased metrics naturally interact with a programmer s sense of gestalt and thus induce stronger anticipation for a higher cognitive load.
our study results on complexity metrics substantiate our possibly spurious findings but differ in a few key ways we previously also observed a default mode network deactivation relationship with vocabulary size but not code size.
in contrast now with more varied snippets and complexity values we found that code size also exhibits a medium correlation in the same range as vocabulary size.
activated areas link to cognitive processes when faced with solving a complex task we perform additional cognitive operations e.g.
extracting the meaning of identifiers and recruit additional cognitive resources and processes to fulfill the task s extra demands.
the brain areas that are stronger activated in a complex task as compared to a simple task indicate increased demands for cognitive processes and resources hosted by these particular areas.
the loc metric hints at an increased demand on a single area as indicated by a medium strength correlation the middle temporal gyrus ba .
ba is typically associated with semantic processing during language comprehension and program comprehension .
its role for program comprehension is interpreted as extracting the meaning of individual identifiers and symbols from code .
when processing complex sentences increased activation of ba indicates a higher grammatical processing load .
so we conclude that merely increasing loc increases the cognitive processing of identifiers and symbols but otherwise does not necessarily pose a strong demand on other cognitive resources.
halstead and depdegree hint at increased demands as indicated by medium strength correlations across three areas ba ba and ba .
the middle frontal gyrus ba is activated when attention and working memory are required .
several fmri studies on program comprehension found strong activation albeit with slightly changing location in the brain .
the angular gyrus ba is a part of the brain that is associated with complex cognitive processes 530it acts as a hub for integrating incoming information.
like a reservoir as processing areas are filled to capacity other areas are recruited to share the load.
collectively this result indicates that increasing the number of symbols and the number of data dependencies requires a broader network of processing than with increases in other factors.
mccabe showed no relationship with an increased demand in any brain area.
our results align well with the study by schuster et al.
who found that an increasing number of words in a sentence leads to higher activation in ba .
furthermore we found support for the early results of curtis et al.
that program size relates to whether programmers successfully comprehend a piece of code.
however we did not find a link to mccabe as curtis et al.
did.
exploration of further complexity metrics so far our analysis concentrated on commonly used representatives of each complexity metric class.
however while in widespread use some of the selected representatives exhibit alleged limitations regarding human cognition.
for example mccabe s controlflow metric fails to consider the added complexity of nested structures such as nested loops or recursion with complex break conditions.
more recent control flow metrics such as cognitive complexity take code repetition layout and modern program constructs into account and promise relief of such weaknesses.
to understand whether a more advanced or any metric predicts cognitive load better we computed our snippets complexity values of further metrics provided by our analysis tools i.e.
metricsreloaded and s onar qube .
we included metrics that target the method level.
then we excluded all complexity metrics that were unable to differentiate between our snippets e.g.
a metric counting the number of todos would yield for all snippets and have no differentiating value for our analysis which left metrics partially shown in table iii.
we categorized the metrics into size metrics vocabulary metrics control flow metrics data flow metrics and others.
overall the complexity metrics show a wide range of correlations with the observed brain activation.
interestingly some simple control flow metrics such as the number of branching statements or the maximum loop depth correlate more strongly than mccabe.
s onar qube s cognitive complexity shows an improvement over mccabe but only a small correlation at best.
this corroborates a prior meta analysis on the limitations of the cognitive complexity regarding physiological data .
in addition to halstead the number of parameters is a second vocabulary based metric that shows a strong correlation with brain activation in ba .
these findings corroborate that program comprehension is a complex cognitive process.
while some simple metrics are wellsuited to predict cognitive load in some brain areas there is no single metric that predicts the overall cognitive effort.
advanced methods that try to capture all aspects are not an accurate predictor for cognitive load.
rather than trying to devise complex metrics with sophisticated and all encompassing views on complexity it may instead be worthwhile to use a basket ofsimple but targeted metrics with well understood relationships with code and cognitive effort.
for example a continuous integration process could check simple metrics with wellunderstood cognitive relationships maximum loop depth for constraints on programmers working memory or the number of parameters as an indicator for load on semantic processing.
summary considering the four representative complexity metrics the vocabulary size based metric halstead s complexity followed by the data flow based metric depdegree has shown the most consistent relationship with the various cognitive effort measures.
control flow complexity as measured by mccabe consistently lacked any relationship with cognitive effort.
an exploration of other method level metrics did not reveal any individual metric that accurately predicts cognitive load.
however besides depdegree none considered data flow despite promising results.
future research shall consider data flow as a predictor for cognitive effort.
while no single metric of complexity is sufficient for comprehensively explaining all observed data we conclude that programmers should minimize the number of variables branching depth and amount of data flow within methods to reduce cognitive load when comprehending code.
size based metrics halstead and loc align well with the anticipation of work and therefore with the amount of attention needed to allocate toward a task.
data flow based metrics depdegree were less likely to capture this anticipation yet demonstrated increased cognitive demands during program comprehension.
these results imply that complexity estimates that use an assessment of the appearance of code as is common in readability studies rather than requiring actual comprehension of code could misrepresent complexity.
finally a useful metric may involve the subjective complexity rating after the completion of a comprehension task.
in other words when participants struggled in grasping the meaning of a code snippet they find it the most complex and they seem to be well aware of their struggle.
they are likely to predict their correctness and their rating often matches their level of concentration and relates to increases in cognitive effort.
b. hypotheses during the analysis and interviews we found some further interesting insights that we formulate in terms of hypotheses to be addressed in future studies.
size is a preattentive indicator for cognitive load we found that when a snippets consisted of more lines of code the deactivation of the default mode network was rather strong.
thus participants might simply use the amount of material to comprehend as a heuristic of how much cognitive load they expect.
this is an easy to assess property which might not even require attention and might be a feature of perception .
however this could also lead to overestimation as the comprehension process progresses.
data flow versus control flow although depdegree builds on mccabe mccabe shows no relationship to cognitive effort whereas depdegree does.
thus everything that 531table iii kendall s correlation between brain activation and the unique differentiating top of the explored complexity metrics.
the metric s text color indicates its class size vocabulary control flow data flow other .
the cell shading highlights strong correlations cf.
table ii .
all metrics raw data and results are available on our supplementary web site.
metric branch np nbd d loop exp n v crct maint iv g rloc n call rlbty e ifnest cogcompl contr stat ev g v g exec return called cdens ba .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ba .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ba .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ba .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
distinguishes depdegree from mccabe might be responsible for the small to medium correlations.
thus a metric capturing only the part that differs between depdegree and mccabe might be a good predictor for cognitive load.
thus our results let us conclude that the delta between control flow measured by mccabe and data flow measured by depdegree may be a promising novel metric that resembles programmers cognition and shall be explored in future research.
c. perspectives mental shortcuts during program comprehension programmers tend to minimize efforts for program comprehension by actively looking for efficient ways to solve a task .
in the context of our experiment this means that participants will try to find the simplest path to solve the task.
for example a participant reported upon recognizing a list of square numbers they expected an algorithm dealing with square roots see topdown comprehension .
complexity metrics seem to neglect that programmers try to take such mental shortcuts.
for example mccabe counts the number of allpossible execution paths but programmers often do not have to consider all paths just enough to solve the current task.
for example in our hurricane check snippet participants could skip some if statements after they have found the solution.
further work shall investigate this phenomenon by carefully controlling which mental shortcuts during comprehension are available.
this would produce further insights into the context sensitivity of complexity metrics.
the effects of extreme complexity some metrics may not have a relationship with human cognition until the values exceed some extreme threshold.
although a higher number of possible execution paths did not increase the cognitive load of participants there are only different values for mccabe and the largest i.e.
might not even be considered sufficiently complex.
still we selected them for their widespread use in practice.
some static analysis tools such as s onar qube consider a mccabe value of to be so complex that it should not even be checked into a repository.
unfortunately it is almost impossible to vary the code along all classes of metrics while also adhering to presenting the full code on one screen within the fmri scanner.
thus future studies could either use longer code which would require the participants to scroll up and down or could focus more on control flow tohave more extreme ranges so that the relationship of complexity and cognitive load can be observed in more depth.
activation of broca for high performers we confirmed the activation of the ba broca s area which is crucially involved in establishing a unified understanding between alternatives e.g.
combining the meaning of words to a sentence and which was consistently activated in previous fmri studies on program comprehension and sentence complexity .
correlations between our complexity metrics and the observed activation in broca s area are mostly small.
one reason could be that activation of broca s area was modulated by individual performance.
that is some participants finding the code too complex fail to activate later stages of language processing.
another possibility could be that the code snippets were more mentally challenging than in previous studies and as a result some participants needed to recruit broca s area as syntactic working memory .
both explanations are consistent with our data as we found stronger activation in broca s area among thehigh performing participants i.e.
who correctly solved at least of the comprehension tasks n .
studies examining complex sentence comprehension of individuals have also observed activation differences between high performing individuals with good comprehension increased activation of broca s area and poor comprehension decreased activation of broca s area .
future experiments shall examine when and why broca s area is activated by high performers increasing our understanding of expertise.
furthermore if we want code to be understandable byeveryone then we can use these methods to design metrics that predict truly simple code code that does not require the brain circuity associated with complexity.
overcoming shortcomings of complexity metrics based on the participants feedback and the observed relationships to various measures of programmer cognition we found that popular complexity metrics fail to capture some comprehension aspects that participants used in their subjective rating long diffuse code lines can cause particular difficulties.
for example line of listing obfuscates the intention is it a non letter?
which needs to be extracted from the code.
identifiers with similar names lead to confusion e.g.
number1 number2 numbers in one snippet likely because participants have to pay specific attention not 532to confuse these.
thus code readability may be just as important as structural complexity as suggested in previous studies .
depdegree fails to consider the distance or the locality of data flow relationships.
for example in the sort example in the prelude of the paper the swap operations are localized to each line and can be abstracted away once a line has been processed.
incorporating other factors such as the variable lifetime or lexical distance would be worthwhile to explore.
these and other aspects shall be considered when using code complexity metrics to describe human cognition e.g.
jbara and feitelson consider repeated statements .
our experiment design provides a structured way to test and refine code complexity metrics to make them a more accurate proxy for program comprehension and elevate them beyond simple code size predictors .
v. t hreats to validity a. construct validity we carefully designed our experiment to limit threats to validity.
with regard to construct validity we operationalized code complexity with four widely used metrics covering different concepts of code complexity e.g.
control flow or dataflow complexity .
an exploration into further metrics did not reveal any candidates with consistently strong correlations.
the four selected metrics correlate with each other even with a carefully designed experiment.
nevertheless in addition to our conceptual insights our study outlined how to investigate a possible cognitive complexity metric with a multi modal experiment.
another threat arises from our operationalization of program comprehension which is a multi faceted phenomenon in which the chosen experiment task is decisive for observed cognitive processes .
in our study we asked programmers to evaluate snippets regarding input and output and we found at most a medium correlation with code complexity metrics.
an experiment with another type of task e.g.
deriving program invariants may emphasize a different facet of program comprehension and thus may show stronger or weaker correlations with complexity metrics.
however our task operationalization is typical to specify program behavior and in line with previous fmri studies on program comprehension .
while no single metric of complexity is sufficient for comprehensively explaining all observed data we can conclude that programmers should minimize the number of variables branching depth and amount of data flow within methods to reduce cognitive load when comprehending the code.
b. internal and external validity several threats to validity arise from our participant sample.
participants first we have a skewed gender distribution which however is close to the population in computer science for most universities.
second participants may have encountered algorithms used in our snippets before.
however we mitigated this threat by enforcing bottom up comprehension.code snippet selection due to the nature of controlled fmri experiments we intentionally focused on high internal validity to control for confounding parameters as much as possible.
our snippets are rather small in one programming language and we selected a homogeneous sample in terms of programming experience.
thus our results apply only to similar circumstances and cannot easily be generalized for example to expert programmers or large code bases.
this is an unavoidable trade off between targeting either high internal or high external validity .
code complexity granularity we need to be aware that in our experiment we studied program comprehension at the method level but software systems consist of many methods and higher level components.
nevertheless our results still have practical impact when we know that intermediate programmers work at the method level code complexity metrics can help to predict their cognitive effort and that they might need longer than expected.
furthermore different complexity metrics have been devised beyond the method level e.g.
weighted methods per class lack of cohesion in methods which shall be addressed in future research.
our study provides a starting point for dedicated follow up studies that shall investigate these metrics and associated cognitive processes.
vi.
r elated work besides the work that evaluates how software metrics are related to human cognition cf.
section i several neuroimaging studies exist that shed light on how programmers work with code.
closest to our study are studies on cognitive load and neural efficiency.
siegmund et al.
conducted an fmri study and found that the strength of activation depends on expertise .
specifically top down comprehension resulted in a lower bold signal change than bottom up comprehension.
crk and kluthe found different strengths in electroencephalography eeg alpha and theta power depending on the expertise of participants .
yeh et al.
also observed a difference in alpha and theta waves linked to the cognitive load of participants .
both results suggest that cognitive load and expertise are directly linked i.e.
with lower expertise the same tasks require higher cognitive load .
nakagawa et al.
found an increased blood flow with functional near infrared spectroscopy fnirs in the prefrontal cortex depending on task difficulty .
fakhoury et al.
combined fnirs and eye tracking to show that unsuitable identifier names increase cognitive load .
kosti et al.
replicated the seminal fmri study of siegmund et al.
with eeg and confirmed its capability as a mental load measure by correlating the eeg functional connectivity with subjective rating of difficulty .
fritz et al.
used eeg heart rate and electrodermal activity to successfully predict task difficulty .
ikutani et al.
used fmri to contrast different levels of programmer expertise with a program categorization task.
their classifier achieved a higher accuracy of distinguishing different program categories on expert programmers brain activation patterns than for novices indicating that expertise leads to a fine tuning of programmers brains .
the results of these studies motivated us to keep 533the level of programming experience constant and to focus on bottom up comprehension.
siegmund et al.
have brought this line of research into software engineering with a study to unraveling the neuronal correlates of program comprehension .
a follow up paper which includes a protocol to link software metrics to cognitive load has directly inspired this work .
peitek et al.
suggested that neuronal correlates can be interpreted in more detail by simultaneously observing eye gaze .
floyd et al.
conducted a study to predict the tasks that participants completed based on the observed brain activation .
they could successfully predict whether participants comprehended code reviewed a code change or reviewed a prose change.
follow up studies investigated mental rotations tasks and contrasted the use of fmri with fnirs they found that brain activation is much different when writing code rather than comprehending it .
lee et al.
also built on the first fmri study but used eeg and eye tracking to describe neuronal correlates of program comprehension in two studies .
duraes et al.
and castelhano et al.
used fmri to observe the neuronal activation during the location of defects finding an activation in the right anterior insula when a bug was spotted and confirmed .
ikutani and uwano used fnirs and found an increased activation in the frontal pole when participants memorized variable names as compared to mental arithmetic .
two recent studies by liu et al.
and ivanovo et al.
contrasted program comprehension with language and memory tasks and found activation in brain areas involved in formal logic as well as domain general executive resources .
while all these studies considered neuronal correlates of processes related to program comprehension none establishes a link to software metrics.
vii.
c onclusion code complexity metrics are relevant for researchers and practitioners alike especially as a proxy for difficulty during comprehending code.
despite their widespread use the validity of code complexity metrics is debated and despite substantial research the big picture is still unclear.
to shed light on this issue in an fmri study we investigated complexity metrics and their behavioral and neuronal correlates during program comprehension.
we found corroborating evidence with mostly weak to medium correlations with programmers correctness and response time.
more importantly since we observed participants brain activation with fmri we enriched previous research by offering a novel perspective and explaining why code and certain aspects of it are difficult to comprehend.
in particular we found that the code s textual size drives cognitive load due to programmers expected attention and that vocabulary size of code particularly burdens programmers working memory.
the data flow metric depdegree showed the strongest correlations to our observed brain activation.
we also observed that subjective complexity accurately mirrors the participants need for concentration.
despite these encouraging results further studies shall dig deeper to better understand the suitability of code complexitymetrics as a proxy for programmers cognition.
data flow based metrics such as depdegree showed promise and need further investigation.
future work shall also address the gap on how individual programmer behavior and knowledge enables mental shortcuts and thus reducing generic precision of complexity metrics.
data availability along with our study we provide a replication package which includes all code snippets their complexity metric values and experiment scripts results of our analyses for possible further hypotheses generation by other researchers and an analysis pipeline that generates all correlations statistics and plots based on our input data.
acknowledgment we thank all participants of our pilot studies and the fmri study.
furthermore we thank andreas f ugner anke michalsky and j org stadler for their technical support during fmri data acquisition as well as annabelle bergum for her assistance with analyzing all complexity metrics.
apel s work has been supported by the german research foundation ap .
brechmann s and siegmund s work is supported by dfg grants br and si .
siegmund s work is further funded by the bavarian state ministry of education science and the arts in the framework of the centre digitisation.bavaria zd.b .
parnin s work is supported by the national science foundation under grant number .