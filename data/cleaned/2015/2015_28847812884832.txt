efficient large scale trace checking using mapreduce marcello m. bersani1 domenico bianculli2 carlo ghezzi1 sr dan krsti c1and pierluigi san pietro1 1deepse group deib politecnico di milano milano italy 2snt centre university of luxembourg luxembourg luxembourg marcellomaria.bersani polimi.it domenico.bianculli uni.lu carlo.ghezzi polimi.it srdan.krstic polimi.it pierluigi.sanpietro polimi.it abstract the problem of checking a logged event trace against a temporal logic speci cation arises in many practical cases.
unfortunately known algorithms for an expressive logic like mtl metric temporal logic do not scale with respect to two crucial dimensions the length of the trace and the size of the time interval of the formula to be checked.
the former issue can be addressed by distributed and parallel trace checking algorithms that can take advantage of modern cloud computing and programming frameworks like mapreduce.
still the latter issue remains open with current stateof the art approaches.
in this paper we address this memory scalability issue by proposing a new semantics for mtl called lazy semantics.
this semantics can evaluate temporal formulae and boolean combinations of temporal only formulae at any arbitrary time instant.
we prove that lazy semantics is more expressive than point based semantics and that it can be used as a basis for a correct parametric decomposition of any mtl formula into an equivalent one with smaller bounded time intervals.
we use lazysemantics to extend our previous distributed trace checking algorithm for mtl.
the evaluation shows that the proposed algorithm can check formulae with large intervals on large traces in a memory e cient way.
.
introduction software systems have become more complex distributed and increasingly reliant on third party functionality.
the dynamic behavior of such systems makes traditional designtime veri cation approaches unfeasible because they cannot analyze all the behaviors that can emerge at run time.
for this reason techniques like run time veri cation and trace checking have become viable alternative for the veri cation of modern systems.
while run time veri cation checks the behavior of a system during its execution trace checking is work partially funded by national research fund luxembourg fnr p10 ec grant no.
eu h2020 dice italian prin project 2010lya9rh .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
technique.
in other words to perform trace checking one must rst collect and store relevant execution data called execution traces or logs produced by the system and then check them o ine against the system specications.
this activity is often done to inspect server logs crash reports and test traces in order to analyze problems encountered at run time.
more precisely trace checking1is an automatic procedure for evaluating a formal speci cation over a trace of recorded events produced by a system.
the output of the procedure is called verdict and states whether the system s behavior conforms to its formal speci cation.
the volume of the execution traces gathered for modern systems increases continuously as systems become more and more complex.
for example an hourly page tra c statistics for wikipedia articles collected over a period of seven months amounts to 320gb of data .
this huge volume of trace data challenges the scalability of current trace checking tools which are centralized and use sequential algorithms to process the trace.
one possible way to e ciently perform trace checking over large traces is to use a distributed and parallel algorithm as done in and also in our previous work .
these approaches rely on the mapreduce framework to handle the processing of large traces.
mapreduce is a programming model and an underlying execution framework for parallel and distributed processing of large quantities of data stored on a cluster of di erent interconnected machines or nodes .
in we proposed a mapreduce algorithm that checks very large execution traces against formal speci cations expressed in metric temporal logic mtl the algorithm exploits the structure of the formula to parallelize its evaluation.
mtl is a class of temporal logic used for the speci cation and veri cation of real time systems.
it extends the well known until temporal operator of the classic ltlwith an interval that indicates the time distance within which the formula must hold.
for example the property a covered entity must retain the documentation for years from the date of its creation.
is a simpli ed version of a policy taken from the us hipaa .
it can be expressed for a particular document as g create!
delete u years delete where the operator u called until states that its right operand the delete event must occur in exactly six years i.e.
billion ms assuming a millisecond granularity in the log from the moment of creation expressed with the event create .
it also states that the left operand delete must hold until that happens.
operator g called globally states that property holds over the whole 1also called trace validation or history checking .
ieee acm 38th ieee international conference on software engineering trace.
in this logic time can be expressed using either integer or real time stamps.
mtl speci cations may express properties that refer to di erent parts of the trace or to large portions of the trace at once by using large time intervals.
in the example above to check if the until subformula holds in a single position of the trace the algorithm needs to consider a portion of the trace corresponding in the worst case to six years of logged data.
to check the whole formula this process needs to be performed for every position in the trace because of the outer globally operator.
generally speaking trace checking algorithms scan a trace and bu er the events that satisfy the temporal constraints of the formula.
the bu er is incrementally updated as the trace is scanned and the algorithms incrementally provide verdicts for the positions for which they have enough information to determine the verdict .
the lower bound for memory complexity of trace checking algorithms is known to be exponential in the numeric constants occurring in the mtl formula encoded in binary .
therefore the strategy of bu ering events creates a memory scalability issue for trace checking algorithms.
this issue also a ects distributed and parallel solutions including our previous work .
specifically the memory scalability of a trace checking algorithm on a single cluster node depends exponentially on the numeric constants de ning the bounds of the time intervals in themtl formula to be checked.
the goal of this paper is to address this memory scalability issue by proposing a trace checking algorithm that exploits a new semantics for mtl called lazy semantics.
unlike traditional point based semantics our lazy semantics can evaluate both temporal formulae and boolean combinations of temporal only formulae at any arbitrary time instant while it evaluates atomic propositions only at timestamped positions of the trace.
we propose lazy semantics because it possesses certain properties that allow us to decompose any mtl formula into an equivalent mtl formula where the upper bound of all time intervals of its temporal operators is limited by some constant.
this decomposition plays a major role in the context of distributed trace checking of formulae with large time intervals.
in practice if we want to check a formula with a large time interval applying the decomposition entails an equivalent formula with smaller time intervals.
this new formula can be checked in a more memory e cient way by using our new trace checking algorithm which applies lazy semantics.
we show that lazy semantics does not hinder the expressive power of mtl we prove that mtl interpreted over lazy semantics is strictly more expressive than mtl interpreted over point based semantics.
in other words any mtl formula interpreted over point based semantics can be rewritten using an mtl formula interpreted over lazy semantics.
moreover there are mtl formulae interpreted over lazy semantics that do not have an equivalent formula that can be interpreted over point based semantics.
we have integrated lazy semantics and the modi ed distributed trace checking algorithm into our mtlmapreduce tool implemented using the apache spark framework.
the evaluation shows that the proposed approach can be used to check formulae with very large time intervals on very large traces while keeping a low memory footprint.
this footprint is compatible with the available con guration of common cloud instances.
moreover our tool performs better in terms of memory scalability than our previous implementation .we have also assessed the time and memory tradeo s of the algorithm with respect to the decomposition parameter.
in summary the speci c contributions of this paper are a new semantics for mtl called lazysemantics we prove that it is strictly more expressive than point based semantics.
a parametric decomposition of mtl formulae into mtl formulae where the upper bound of all time intervals is limited by some constant a new trace checking algorithm that exploits lazy semantics and parametric decomposition to check mtl formulae in a memory e cient way the evaluation of the proposed algorithm in terms of memory scalability and time memory tradeo s. the rest of the paper is structured as follows.
section brie y introduces mtl interpreted over point based semantics and the mapreduce programming model.
section overviews our approach and motivates the need for lazy semantics and the parametric decomposition of mtl formulae.
lazy semantics is introduced in section .
section details the parametric decomposition of mtl formulae.
section introduces our distributed trace checking algorithm that supports lazy semantics.
section reports on the evaluation of our implementation.
section surveys related work while section concludes the paper.
.
preliminaries .
point based semantics for mtl letibe any non empty interval over rwith endpoints innand let be a nite set of atomic propositions or atoms .
the syntax of mtl is de ned by the following grammar where p2 and uiis the metric until operator pj j j ui .
additional boolean and temporal operators can be derived using the usual conventions eventually is de ned as fi ui globally is de ned asgi fi .
we adopt the convention that an interval of the form is written as i .
the interval in temporal operators is omitted for simplicity.
we introduce the following shorthand notation fk ff f z ktimes with f0 .
hereafter we refer to point based semantics for mtl asmtl psemantics.
mtl psemantics.
we focus on the nite word semantics ofmtl since we apply it to the problem of trace checking.
a timed sequence of lengthj j is a sequence j j 1of values i2rsuch that i i 1for each i j j i.e.
the sequence is strictly monotonic .
aword over the alphabet is a sequence j j such that i22 for all i j j wherej jdenotes the length of the word.
a timed word !
!
!
!j!j 1is a word over r i.e.
a sequence of pairs !i i i where j!j 1is a word over and j!j 1is a timed sequence.
a pair !iis also called an element of the timed word.
moreover notice that in this de nition irefers to a particular position of the element !iin the timed word !
while irefers to the time instant ortime stamp of the element!i.
we abuse the notation and represent a timed word equivalently as a pair containing a word and a timed sequence of the same length i.e.
!
.
a timed language over is a set of timed words over .mtl psemantics on timed words is given in figure where the point based satisfaction relation j pis de ned with respect to a timed word a position i2n atomp2 and mtl for889 i j ppi p2 iforp2 i j p i i 6j p i j p i i j p or i j p i j p ui i 9j i j j jand j i2iand j j p and8k i k j then k j p figure mtl psemantics on timed words.
mulae and .
note that due to the strictly monotonic de nition of the timed sequence the metric next operator can be de ned as xi ?
ui f0g .lp is a timed language de ned by a formula when interpreted over the mtl psemantics i.e.
lp f j j p g. .
the mapreduce programming model mapreduce is a programming model developed by google for processing and analyzing large data sets using a parallel distributed infrastructure.
the mapreduce programming model uses two user de ned functions map and reduce that are inspired by the homonymous functions that are typically found in functional programming languages.
the map function receives a key value pair associated with the input data and returns a set of intermediate key value pairs its signature is map k k v v list .
the reduce function is applied to all the intermediate values that have the same intermediate key in order to combine the derived data appropriately its signature is reduce k k list v v list .
in the de nitions above k1and k2are types for keys and v1and v2are types for values.
besides the actual programming model mapreduce is also a framework that provides in a transparent way to developers parallelization fault tolerance locality optimization and load balancing.
the mapreduce framework is responsible for partitioning the input data scheduling and executing the map and reduce tasks also called mappers and reducers respectively on a cluster of available nodes and for managing communication and data transfer usually leveraging a distributed le system .
more in detail the execution of a mapreduce operation called job proceeds as follows.
first the system splits the input into blocks of a certain size and parses them using an inputreader generating input key value pairs.
it then assigns each input key value pair to a mapper which processes it in parallel on the nodes of the distributed infrastructure.
a mapper passes the set of key value pairs to the map function which generates a set of intermediate key value pairs.
notice that each run of the map function is stateless i.e.
the transformation of a single key value pair does not depend on any other key value pair.
the next phase is called shu e and sort it takes the intermediate data generated by each mapper sorts them based on the intermediate key divides these data into regions to be processed by reducers and distributes these data on the nodes where the reducers will be executed.
the division of intermediate data into regions is done by a partitioning function which depends on the user speci ed number of reducers and the key of the intermediate data.
each reducer executes the reduce function which produces the output data.
this output is appended to a nal output le for this reduce partition.
the output of the mapreduce job is available in several les one for each used reducer.
multiple mapreduce calls can be chained together to perform complex data processing.atoms fpg fpg fqg fp qg fp qg fqg fqg time stamps time instants p ?
?
?
f p ?
?
?
?
figure evaluation of formula f p .
.
motivation and overview of the approach as mentioned in section trace checking is an automatic procedure for evaluating a formal speci cation over a trace of recorded events produced by a system.
since traces can be seen as a sequence of time stamped elements where each element records one or more events we use timed words as abstract models of traces.
hence a pair !i i i corresponds to the i th element of the trace where atoms in irepresent all the events with time stamp i. trace checking algorithms handle metric temporal operators by bu ering elements of the trace.
the time interval speci ed in the metric temporal formula to be checked determines the portion of the trace to be considered for emitting a verdict in a single position of the trace.
depending on the particular mtl formula to be checked in the worst case this process needs to be repeated for every position in the trace2.
what trace checking algorithms typically do is to keep the relevant portion of the trace in a bu er as they scan the trace.
the bu er is updated incrementally while the algorithm scans and produces verdicts for the next elements in the trace.
the procedure for updating the bu er consists of adding a newly scanned element eof the trace and removing the elements whose time stamps do not satisfy the temporal constraint of the formula to be checked when evaluated with respect to the time stamp of e. bu ering elements presents a memory scalability issue if a metric temporal formula with a large time interval needs to be checked.
let us present an example to motivate the need for lazy semantics.
example .consider formula f p and its evaluation on the following trace represented as a timed word fpg fpg fqg fp qg fp qg fqg fqg .
the timed word shown in figure is de ned over the set of atoms fp qg its length is and it spans over time units.
the rst two rows in the picture represent its atoms and time stamps the last two rows show respectively the evaluation of subformula pand formula f p using point based semantics.
as shown in the last row of figure according to point based semantics formula f p holds at time instants and .
for a formula of the form3f p the algorithm needs to bu er in the worst case i.e.
in case there exists an element at every time instant at most b elements.
for example to evaluate formula f p at time instant in the worst case the algorithm will bu er elements i.e.
all the elements whose time stamp ranges from to .
the elements 2for example if a globally temporal operator is used.
3we consider the most general case in which mtl formulae can be arbitrarily nested.
this means that a trace checking algorithm has to evaluate every subformula in every position of the trace.
nevertheless more speci c cases could use heuristics based on the actual values of the temporal intervals in the formula and hence reduce the number of positions in the trace in which the formula is evaluated.
890with time stamps ranging from to satisfy the time interval constraint of the formula the others are kept for the evaluation of the formula at subsequent positions.
let us assume that the execution infrastructure could only store elements in the bu er because of the limited available memory.
the worst case requirement of keeping elements in the bu er would then be too demanding for the infrastructure in terms of memory scalability.
to lower the memory requirement for the bu er we would need a formula with a smaller time interval and expressing the same property as .
in other words one might ask whether there is an mtl formula equivalent to with all the intervals bounded by the constant and thus requiring to store at most elements in the bu er .
let us consider formula f p f f p a na ve and intuitive interpretation might lead us to think that it de nes the same property as .
roughly speaking instead of checking if peventually occurs within the entire time interval 0checks ifpeither occurs in the interval as speci ed by subformula f p or in the interval when evaluated exactly time instants in the future as speci ed by subformula f f p .
figure shows the evaluation of formula 0over the same trace used in figure .
as you can see formula 0does not have the same evaluation as on the same trace.
more speci cally at time instant 0is false while is true see the values circled in both gures .
by analyzing the evaluation of one can notice that subformula f f p at time instant refers to the value of f p at time instant which does not have a corresponding element in the trace.
if there was an element at time instant f p would be true sincepholds at time instant .
the above example shows that the evaluation of temporal subformulae according to point based semantics depends on the existence of certain elements in the trace.
it also shows that point based semantics is not suitable to support the intuitive decomposition of mtl formulae into equivalent ones with smaller time intervals like the one from to 0shown above.
we maintain that this constitutes a limitation for the application of point based semantics in the context of trace checking.
therefore in this paper we propose a new alternative semantics for mtl called lazy semantics.
the main feature of lazy semantics is that it evaluates temporal formulae and boolean combinations of temporalonly formulae at any arbitrary time instant regardless of the existence of the corresponding elements in the trace.
the existence of the elements is only required when evaluating atoms.
this feature allows us to decompose any mtl formula into an equivalent mtl formula in which the upper bound of all time intervals of its temporal operators is limatoms fpg fpg f qg fp qg fp qg fqg fqg time stamps time instants p ?
?
?
f p ?
?
?
?
?
f p ?
?
f f p ?
?
?
?
?
?
?
?
?
?
figure evaluation of formula f p f f p .
t j lpi 9i i j jandt iandp2 i t j l i t 6j l t j l i t j l or t j l t j l ui i 9t0 t0 tandt0 t2iand t0 j l and8t00 t t00 t0and9i i j jand t00 i then t00 j l figure mtl lsemantics on timed words.
ited by some constant.
such a decomposition can be used as a preprocessing step of a trace checking algorithm which can then run in a more memory e cient way.
in the following sections we rst introduce lazy semantics section and formalize the notion of the decomposition exempli ed above section .
afterwards in section we describe the modi cations to our previous trace checking algorithm required to preprocess the formula and support lazy semantics.
.
lazy semantics for mtl the following example shows an anomalous case of mtl p semantics that lazy semantics for mtl denoted as mtl l semantics intends to remedy.
consider a timed word w fqg fpg and two mtl formulae f 6p and f 3f 3p.
the intuitive meaning of the two formulae is the same pholds time units after the origin i.e.
at time stamp .
however when evaluated on wusing themtl psemantics the two formulae have di erent values 1correctly evaluates to true but 2to false.
indeed in 2the outermost f 3subformula is trivially false because there is no position that is exactly time instants in the future with respect to the origin.
the two formulae instead are equivalent over the mtl lsemantics where they both evaluate to true.
indeed this is true also over signal based semantics however signals are not very practical for monitoring and trace checking which operate on logs that are best modeled as a sequence of individual time stamped observations i.e.
timed words.
mtl lsemantics.
mtl lsemantics on timed words is given in figure in terms of the satisfaction relation j l with respect to a timed word and a time instant t2 r pis an atom and and aremtl formulae.
an mtl formula when interpreted over mtl lsemantics de nes a timed language ll f j j l g. the main di erence between mtl pandmtl lsemantics is that mtl p evaluates formulae only at positions iof a timed word while mtl linherits a feature of signal based semantics namely it may evaluate non atomic formulae at any possible time instantt even if there is no time stamp equal to t. for example according to the mtl psemantics an until formula 1ui 2evaluates to false in case there are no positions in the interval i due to the existential quanti cation onj see figure .
conversely over the mtl lsemantics the evaluation of depends on the evaluation of .
if the latter is an atom then formula also evaluates to false because of the existential quanti er in the mtl l semantics of atoms.
however if 2is a temporal formula or a boolean combination of temporal only formulae e.g.
other until formulae it will be evaluated in the part of the timed word that satis es the interval of .
hereafter we refer to the mtl formulae interpreted over the mtl l 891semantics as mtl lformulae similarly mtl pformulae aremtl formulae interpreted over the mtl psemantics.
letm be the set of all formulae that can be derived from the mtl grammar shown in section .
using as the set of atoms.
we show that any language lp dened using some mtl pformula can be de ned using an mtl lformula obtained after applying the translation l2p m !m to i.e.
lp ll l2p for any .
thel2ptranslation is de ned as follows l2p p p p2 l2p l2p l2p l2p l2p l2p ui l2p ui act l2p where act a afor somea2 .
the goal of l2pis to prevent the occurrence of direct nesting of temporal operators i.e.
to avoid the presence of sub formulae like f 3f 3p.
as discussed in the example above nested temporal operators are interpreted differently over the two semantics.
direct nesting is avoided by rewriting the right argument of every until i.e.
the existential component of until .
the argument is conjuncted with a formula actthat evaluates to true over both semantics if there exists a position in the underlying timed word otherwise actevaluates to false.
to explain this intuition let us evaluate actover a timed word over the alphabet fag.
over point based semantics i j p act i j pa a is true for any positioni since either abelongs to ior not.
however the same does not hold for lazy semantics.
according to lazy semantics t j l actis true only in those time instants tfor which there exists isuch that i tand therefore exists the corresponding i to whichacan belong or not .
lemma .given an mtl formula and a timed word !
for anyi the following equivalence modulo l2ptranslation holds i j p i i j ll2p .
proof.
see the extended version of the paper.
theorem .any timed language de ned by an mtl p formula can be de ned by an mtl lformula over the same alphabet.
proof.
by lemma for i .
notice that the translation l2pde nes a syntactic mtl fragment where temporal or boolean combination of temporalonly operators cannot be directly nested.
in this fragment mtl pandmtl lformulae de ne the same languages.
however if we consider the complete de nition of mtl without syntactic restrictions the class of timed languages de ned bymtl lformulae strictly includes the class of languages dened by mtl pformulae.
in other words mtl interpreted over lazy semantics is strictly more expressive than mtl interpreted over point based semantics this result is established by the following theorem.
theorem .there exists a timed language de ned by some mtl lformula that cannot be de ned by any mtl p formula.
proof.
consider the language of timed words l f j 9i9j i j i j lb j j lc j g.lis de ned by the mtl lformula 1 2 where f b f c f b f c f b f c and f f b f c .lcannot be de ned by anymtl pformula see reference proposition .
.
parametric decomposition in this section we show that lazy semantics allows for a parametric decomposition of mtl formulae into mtl formulae where the upper bound of all intervals of the temporal operators is limited by some constant k the parameter of the decomposition .
this structural characteristic will then be used in the trace checking algorithm presented thereafter.
we rst introduce some notation and show some properties of lazy semantics that will be used to prove the correctness of the decomposition.
we de ne the operator over intervals in rwith endpoints in nsuch thati j fi jj 8i2iandj2jg.
lemma .for any timed word andt t j lfifj i t j lfi j corollary .for any timed word andt n t j lfn k i t j lf k n lemma .for any timed word andt t j lfi fj i t j lfi j ifi j6 the proofs of the above corollary and lemmata are in the extended version of the paper.
hereafter we focus on bounded mtl formulae i.e.
formulae where intervals are always nite.
notice that it is this class of formulae that causes memory scalability issues in trace checking algorithms.
we present the parametric decomposition by referring to the bounded eventually operator.
the bounded until and globally operators can be expressed in terms of the bounded eventually operator using the usual equivalences moreover we remark that the decomposition does not a ect atoms and is applied recursively to boolean operators.
we use angle brackets symbols h and i in the de nition of the decomposition to cover all four possible cases of open denoted with round brackets and closed denoted with square brackets intervals the definition is valid for any instantiation of the symbols as long as they are consistently replaced on the right hand side.
the decompositionlkofmtl formulae with respect to parameterkis the translation lk m !m such thatlk fha bi fha bilk b k fba kc k fhamodk b ba kc kilk k b ba k 1c k fba kc k fhamodk k lk b ba k 1c k f k df lk k b ba k 1c k where df k h f hi h k f f k df k h k h k the decomposition lkconsiders three cases depending on the values of a b andk.
in the rst case we have b k which means that the upper bound of the temporal interval in the input formula is smaller than k therefore no decomposition is needed.
the other two cases consider input formulae where b k .
the second case is characterized by b ba k 1c k b ba kc k k. the decomposition yields a formula of the form fba kc k where 892f k k f k f p f k f p f k f b ba k 2c k p a bamodk figure lkdecomposition of formula f p. f amodk b ba kc k lk is equivalent to the input formula f evaluated at time instant ba kc k. notice that according to corollary the argument infba kc k is evaluated at time instant ba kc k. the third case is characterized by b ba k 1c k. we illustrate the decomposition of f pwithp2 by referring to the example in figure where the black squares divide the timeline into segments of length k. we refer to each position in the timeline pinpointed by a black square as ak position.
the big brackets enclose the interval relative to time instant .
moreover we assume some values foraandksuch thatba kc hence in the gure the position of ain the timeline is between the marks corresponding to kand 3k .
the application of lk f p returns the formula f k f k f p f k f p f k f b ba k 2c k p which is shown above the timeline spanning through its length such that each subformula highlighted in red is written above the corresponding kposition where it is evaluated.
since ba kc there are two subformulae of the form f kevaluated in the rst two k positions.
unlike the previous case the interval is too big to allow for rewriting the input formula into another formula with a single foperator with bounded length.
hence we use three subformulae f pevaluated at the third k position f pevaluated at the fourthk position and f b ba k 2c k pevaluated at the fthk position the last two subformulae are obtained from the de nition ofdf.
notice that if k thelkdecomposition boils down to the reduction of mtl toltl.
theorem .given an mtl lformula a timed word and a positive constant k we have that j l i j llk and the upper bound of every bounded interval in all temporal subformulae oflk is less than or equal to k. proof.
we can prove this statement by showing that lk can always be rewritten back as and vice versa using lemmata and .
the complete proof is provided in the extended version of this paper.
.
trace checking mtl lformulae with mapreduce the theoretical results presented in section can be applied to improve the memory scalability of the distributed trace checking algorithm based on the mapreduce programming model and introduced by some of the authors in previous work .
although the algorithm presented in was designed to perform trace checking of properties written in soloist an extension of mtl with aggregating temporal modalities here we consider without loss of generality see only its mtl subset.
in the rest of this section after introducing some additional notation we give an overview of the algorithm s execution ow and detailthe modi cations emphasized with gray boxes in figure applied to the original algorithm de ned in to support mtl lsemantics.
additional notation.
let and bemtl formulae.
the set of all proper subformulae of is denoted with sub notice that for atoms p2 sub p .
the size of a formula denotedj j is de ned as the number of its non proper subformulae i.e.
j j jsub j .
the set suba fpjp2sub sub p gis the set of atoms of formula .
the set subd f j 2sub sub 2sub gis called the set of all direct subformulae of is called the superformula of all formulae in subd .
the set sup f j 2sub 2subd g is the set of all subformulae of that have formula asdirect subformula .
the height of h is de ned recursively as h if then maxfh j 2subd g else .
for example given the formula f a b u c we have sub fa b c a b c f a b gis the set of all proper subformulae of suba fa b cgis the set of atoms in subd ff a b cgis the set of direct subformulae of sup a sup b fa bg shows that the sets of superformulae of aandbin coincide and the height of is sinceh a h b h c h c h a b h f a b and therefore h maxfh f a b h c g .
overview.
the algorithm takes as input a non empty execution trace tand an mtl formula and provides a verdict indicating whether the trace satis es the formula or not.
before the algorithm is used we assume that the execution infrastructure i.e.
the cluster of machines is congured and running.
we also assume that one can easily estimate through experimentation kcluster which is the largest time interval bound that can be used in a formula without triggering memory saturation in the cluster.
this bound depends on the memory con guration of the node in the cluster with the least amount of memory available.
once we have this information we can preprocess the input formula leveraging the theoretical results of section .
if the temporal operators in have bounded intervals less thankcluster we apply the unmodi ed version of the original algorithm which evaluates formulae over point based semantics.
otherwise we have to transform the original formula into an equivalent one that can be checked in a memory e cient way.
this transformation is achieved by rst interpreting the input formula over lazy semantics to preserve its meaning we apply the l2ptransformation.
afterwards given the parameter kcluster we rewrite the formula using thelkclusterdecomposition i.e.
the lkdecomposition instantiated with parameter kcluster and obtain the formula kcluster l lkcluster l2p .
thanks to theorem this formula contains intervals no greater than kcluster and is equivalent to .
the trace is modeled as a timed word with integer4time stamps.
we assume that the execution trace is saved in the distributed le system of the cluster on which the distributed algorithm is executed.
this is a realistic assumption since in a distributed setting it is possible to collect logs as long as there is a total order among the time stamp induced by some clock synchronization protocol.
the trace checking algorithm processes the trace iteratively through a sequence of mapreduce executions.
the 4since integers are isomorphic to a subset of real numbers the theoretical results of the previous sections are still valid for integer time stamps.
893number of mapreduce iterations is equal to the height of the mtl formula .
the rst mapreduce iteration parses the input trace from the distributed le system applies the map andreduce functions and passes the output a set of tuples to the next iteration.
each subsequent iteration l where l h receives the set of tuples from iteration l in the expected internal format hence parsing is performed only in the rst iteration .
the set of tuples contains all the positions where the subformulae of of height l hold.
note that the trace itself is a similar set containing all the positions where the atoms with height hold.
based on the set it receives the l th iteration can then calculate all the positions where the subformulae of height lhold.
each iteration consists of three phases read phase that reads and splits the input map phase that associates each formula with its superformula and reduce phase that applies the semantics of the appropriate subformula of .
the nal set of tuples represents all the positions where the input formula holds.
hence producing the verdict is only a matter of checking if the input formula holds in the rst position.
read phase.
the input reader component of the mapreduce framework is used in this phase this component can process the input trace in a parallel way.
the trace saved in a distributed le system is split into several blocks replicated times and distributed among the nodes.
the mapreduce framework exploits this block level parallelization both during the read and map phases.
for example the default block size of the hadoop deployment is 64mb which means that a 1gb trace is split in parts and can be potentially processed using parallel readers and mappers.
however if we executed the algorithm on nodes with cores each we could process up to blocks in parallel.
the input reader is used only in the rst iteration and can be seen as a parser that converts the trace into a uniform internal representation that is used in the subsequent iterations.
as shown in figure 6a the k th instance of the input reader handles thek th blocktkof the trace t. for each element in tkand every atom poccurring in the mtl formula the reader emits a key value pair of the form p p2 .
the key is the atom pitself while the value is a pair consisting of the truth value of pat time obtained by evaluating the expressionp2 and the time stamp .
the emit function incrementally builds the list of outgoing tuples.
map phase.
each tuple generated by an input reader is passed to a mapper on the same node.
mappers associate the formula in the tuple with all its superformulae in .
for example given a b a if the input reader returns a tuple a the mapper will associate it with formulaea band a emitting tuples a b a and a a .
the mapper shown in figure 6b receives tuples in the form v from the input reader and emits all tuples of the form v where 2sup .
to support lazy semantics the algorithm needs to consider all the time instants where we want to evaluate the temporal operators.
if any of these instants does not have a corresponding element in the trace then the original algorithm would evaluate a formula to false.
however to support lazy semantics we do not need to introduce an element in the trace for each time instant we know a priori that only formulae of the form f k explicitly introduced by thelkdecomposition may be evaluated incorrectly if the appropriate elements are not in the trace see figure .
therefore we modify the algorithm for the mapper1 function input reader l tk for all 2tk do for allp2suba do emit p p2 end for end for end function a input reader algorithm1 function mapper k l v for all 2sup do emit v iflazy then emit act ?
k end if end for end function b mapper algorithm function reducerfi l t val ?
win for all v 2checkdup t do win win v if v whiledwine bwinc 620uido win winnargmax win end while val 02fwing 2i emit val end for end function c reducer for operator fi1 function reducergi l t val win for all v 2checkdup t do win win v if v whiledwine bwinc 620uido win winnargmax win end while val 02fwing 2i emit val end for end function d reducer for operator gi figure reader mapper and reducer algorithms.
see figure 6b to introduce one element at konly when the parent formula is of the form f k this condition is captured by the lazy predicate.
the emitted tuple contains the tuple act ?
k as its value.
in this tuple the truth value of actis false by convention to represent a non existent trace element.
since the mapper is stateless and cannot check if a tuple exists at time instant k it is the reducer s responsibility to discard tuple act ?
k if there is already a tuple at k. reduce phase.
the reducers exploit the information produced by the mappers to determine the truth values of the superformula at each position i.e.
reducers apply the appropriate mtl semantics for the operator used in the superformula.
the total number of reducers running in parallel at thel th iteration is the minimum between the number of subformulae with height lin the input formula and the number of available reducers5.
each reducer calls an appropriate reduce function depending on the type of formula used as key in the received tuple.
for space reasons we focus only on two algorithms the one for the metric eventually operator fiand the one for the metric globally operator gi.
we refer the reader to our previous work for the full description of all the reducer algorithms.
figure 6c shows the algorithm for formulae of the form fi .
it uses an auxiliary boolean variable valand a queue win.
the algorithm receives the tuples in talready sorted in the shu e and sort phase of the mapreduce framework in descending order with respect to the time stamps6.
these tuples are incrementally processed by the checkdup function which discards the tuples of the form act ?
if tuples with the same time stamp already exist.
the queue winkeeps track of all the tuples with positive truth value that fall in the convex union7 denoted asu of the intervals andi.
this is ensured by the inner while loop which compares the minimal bwinc and maximal dwin e timestamp in the queue and keeps removing the maximal tuple 5this depends on the con guration of the cluster.
typically the number of reducers is the number of nodes in the cluster multiplied by the number of cores available on each node.
6sorting intermediate tuples is called secondary sorting and for simplicity we omit the implementation details.
7a convex union of intervals is de ned as a convex hull of the union of the intervals.
894latoms fpgfpg fqg fp qgfp qgfqgfqg time stamps time instants 1p ?
?
?
f p ?
?
?
?
f p ?
?
act ?
?
???
?
?
f f p ?
?
?
?
?
?
?
?
3l4 l2p ?
????????????
?
?
figure evaluation of the l4 l2p f p f f p formula over mtl lsemantics.
argmax win until the loop condition is satis ed.
the nal truth value of fi depends on whether the queue win contains a tuple with a time stamp 0that is in the interval i. notice that the size of the queue windepends directly on the size of the interval i hence the memory scalability of the algorithm on individual nodes depends on the size of the intervals in formula .
the reducer algorithm in figure 6d implements the semantics of formulae of the form gi .
the code is similar to the one for the operator fi.
the only di erence is that the queue winkeeps track of all the tuples with negative truth value hence the truth value of gi depends on whether the queue wincontains a tuple in the interval ithat is a witness to the violation of gi .
examples of application of the algorithm.
let us use our algorithm to evaluate the formula from example on the same trace using mtl psemantics.
in the read phase the algorithm parses the trace in parallel and creates the input tuples for the map phase.
from the rst element fpg the input reader creates only the tuple p since refers only to atom p. tuples p p p ?
p p p ?
p ?
are thus received by the map phase.
the mapper associates the formulae from the input tuples with their superformulae.
in the case of tuple p it generates only tuple f p p since f p is the only superformula ofp.
the reduce phase therefore receives tuples f p p ?
f p p ?
f p p f p p f p p ?
f p p f p p all shu ed and sorted in descending order of their time stamps.
since all the tuples have the same key only one reducer is needed.
the reducer applies the algorithm shown in figure 6c and outputs the truth values of f p for every position in the trace f p ?
f p ?
f p ?
f p ?
f p f p f p .
notice that the boolean values in the tuples correspond to the values in figure row .
assuming again that the memory requirement of keeping positions is too demanding for our infrastructure we can now use parametric decomposition and lazy semantics to limit the upper bound of the interval in to k .
we obtain formulal4 l2p f p f f p .
let us evaluate formula l4 l2p on the same trace from example over mtl lsemantics.
table shows the truth values of the emitted tuples for every evaluated subformulae ofl4 l2p .
since h l4 l2p the al gorithm performs three iterations whose index is indicated in the left most column l .
the truth values of the subformulae from the di erent iterations are separated by the horizontal dashed lines.
in the rst iteration the trace is parsed to obtain the truth values of atom p. after that two reducers in parallel calculate the truth values of the f p and f p subformulae.
in the second iteration themapper emits the additional acttuples since the superformula is of the form f .
the reducer evaluating formula f f p receives the tuples with the evaluation off p and act.
the acttuples with the crossed truth values are discarded because of the already existing f p tuples shown in the row above.
finally in the third iteration we can see that the truth values l4 l2p circled in figure are the same at all time instants in common as the truth values of shown in figure .
.
evaluation we have implemented our trace checking algorithm in themtlmapreduce tool which is publicly available .
the tool is implemented in java and uses the apache spark framework which supports iterative mapreduce applications in a better way than apache hadoop .
in this section we report on the evaluation of our tool in terms of scalability and time memory tradeo s. more speci cally we evaluate our new trace checking algorithm by answering the following research questions rq1 how does the proposed algorithm scale with respect to the size of the time interval used in the formula to be checked?
section .
rq2 when compared to state of the art tools does the proposed algorithm have a better memory scalability with respect to the size of the time interval used in the formula to be checked?
section .
rq3 what are the time memory tradeo s of the proposed algorithm with respect to the decomposition parameter k?
section .
.
evaluation settings to evaluate our approach we used six t2.micro instances from the amazon ec2 cloud based infrastructure with a single cpu core and 1gb of memory each.
we used the standard con guration for the hdfs distributed le system and the yarn data operating system.
hdfs block size was set to mb and block replication was set to .
yarn was congured to allocate containers with memory between mb and gb with core.
in all the executions we limited the memory of our algorithm to gb.
measuring the actual memory usage of user de ned code in spark based applications requires to distinguish between the memory usage of the spark framework itself and the one of user de ned code.
this step is necessary since the framework may use the available memory to cache intermediate data to speed up computation.
hence to measure the memory usage of the auxiliary data structures used by our algorithm e.g.
the winqueue we instrumented the code.
this instrumentation which has a negligible overhead monitors the memory usage of the algorithm s data structures and reports the maximum usage for each run.
for the evaluation described in the next two subsections we used synthesized traces.
by using synthesized traces we are able to control in a systematic way the factors such as the trace length and the frequency of events that impact on 895the time and memory required for checking a speci c type of formula.
in particular we evaluated our approach by triggering the worst case scenario in terms of memory scalability for our trace checking algorithm.
such scenario is characterized by having the auxiliary data structures used by the algorithm always at their maximum capacity.
to synthesize the traces we implemented a trace generator program that takes as parameters the desired trace length nand the numbermof events i.e.
atoms per trace element.
the program generates a trace with ntrace elements such that the i th element with i n hasias time stamp value.
each trace element has between and mevents denoted as fe1 emg wheree1 pand the other m events are randomly selected from the set of atoms fp2 pmgusing a uniform distribution.
we generated ten traces with nset to and mset to the average size of each trace before saving it in the distributed le system is gb.
these traces and the other artifacts used for the evaluation are available on the tool web site .
.
scalability the performance of our distributed trace checking algorithm with respect to the length of the trace and the size of the formula has been already investigated in our previous work .
the same conclusions regarding these two parameters apply also to the new algorithm which uses lazy semantics.
therefore in this section we only focus on evaluating the memory scalability of the new algorithm.
to address rq1 we evaluate the memory usage of the algorithm for di erent sizes of the time interval used in the mtl formula to be checked.
as discussed in section the largest time interval that does not trigger memory saturation in a cluster depends on the memory con guration of the node in the cluster with the least amount of memory available.
hence we evaluate the memory usage on a single node by using formulae of height nevertheless the map phase is still executed in parallel.
we consider the two metric formulae g qandf p parametrized by the value nof the bound of their time interval.
formula f prefers to atomp notice that our trace generator guarantees that pis present in every trace element.
formula g qrefers to atomq we con gured our trace generator so that event qis absent in all trace elements.
these two formulae exercise the trace checking algorithm in its worst case.
indeed according to line in figure 6c the reducer for fibu ers all the elements where atom pis true hence when checking formula f p at any point in time the queue winwill be at its maximum capacity.
dually when checking formula g q the absence of the event qfrom the trace will force the algorithm to maintain the queue winat its maximal capacity line in figure 6d .
as mentioned in section our trace checking algorithm deals with mtl formulae in the most general case therefore it evaluates formulae g q andf pat every position to allow for arbitrary nesting.
to address rq2 we need a baseline for comparison.
among the non distributed non parallel trace checking tools the only tool supporting mtl and publicly available ismonpoly which was the best performing tool in the o ine monitoring track of the rst international competition on software for runtime veri cation csrv .
monpoly when executed on the traces described above produced a stack over ow error hence we could not use it for comparison.
among distributed and parallel approaches theonly tool supporting mtl and publicly available is the one described in our previous work to which we compare.
plots in figures 8a and 8b show the execution time and the memory usage required to check respectively formula g qandf p instantiated with di erent values of parametern.
each data point is obtained by running the algorithm over the ten synthesized traces and averaging the results.
the plots colored in black show the average time and memory usage of our previous algorithm which applies mtl psemantics.
the plots colored in gray represent the runs of our new algorithm that applies mtl lsemantics and decomposes all the formulae with time interval n strictly greater than .
the decomposition parameterk is the maximal value that our infrastructure can support before saturating its memory.
we answer rq1 by observing the trend in the gray plots of figures 8a and 8b the proposed algorithm can check on very large traces formulae that use very large time intervals up to using at most 1gb of memory and taking a reasonable time at most 200s .
to answer rq2 the plots show that the proposed algorithm is more scalable in terms of memory usage than the algorithm from .
indeed for the evaluation of both formulae the latter exhausts the memory bound of 1gb when the time interval nis higher than .
nevertheless the proposed algorithm is on average .35x slower that the previous algorithm when the time interval nis higher than .
this additional time is needed to process the new formula obtained through thelkdecomposition.
.
time memory tradeoffs as suggested above the parametric decomposition used in the proposed trace checking algorithm leads to a reduced memory usage but increases the execution time.
in this section we dig into and generalize this result by investigating the time memory tradeo s of our algorithm with respect to the decomposition parameter k. more speci cally to address rq3 we evaluate the execution time and the memory usage of the algorithm for di erent values of parameter k when checking formulae g qandf p. these formulae are processed using the lkdecomposition with values of kthat are taken from v f5 iji grepresenting an in nite harmonic series scaled by a 107factor.
by using set v we can study the performance of the algorithm for di erent values of kwithout exhaustively exploring its large domain.
since set vis in nite we put a threshold of one hour on the execution time.
the plots in figure 8c show the execution time and the memory usage to check the two formulae.
each data point is obtained by running the algorithm over the ten synthesized traces and averaging the results.
the value of kis represented in both plots on the x axis using the logarithmic scale.
the smallest value of kthat satis es the execution time threshold is obtained from set vwith i for this value of kthe algorithm used 14mb of memory and took minutes to complete.
the plots show that using a lower value for kdecreases the memory footprint of the algorithm.
however a lower value for kalso yields a longer execution time for the algorithm.
this longer execution time is due to the fact that a lower value for k increases the size and the height of the formula obtained after applying the lkdecomposition.
the increased height of the decomposed formula triggers more iterations of the i nterval length n ti me s p revious algorithm n ew algorithm i nterval length n m emory mb p revious algorithm n ew algorithm a e xecution time top and memory usage bottom to check g q0 i nterval length n ti me s p revious algorithm n ew algorithm i nterval length n m emory mb p revious algorithm n ew algorithm b execution time top and memory usage bottom to check f p106 d ecomposition parameter kti me min g q f p d ecomposition parameter km emory mb g q f p c execution time top and memory usage bottom when varying parameter k figure scalability and time memory tradeo s for the proposed trace checking algorithm.
algorithm yielding longer execution times.
we answer rq3 by stating that there is a tradeo between time and memory determined by the value of parameter k. a good balance between these two factors can be achieved when kis set to the largest possible value supported by the infrastructure in this way it is possible to reduce the size of the decomposed formula without incurring a longer execution time for the algorithm.
nevertheless our algorithm is completely parametric ink allowing engineers to tune the algorithm to be either more time or more memory intensive depending on the application s requirements.
.
related work the approach presented in this paper is strictly related to work done in the areas of alternative semantics for metric temporal logics and of trace checking run time veri cation.
alternative semantics for metric temporal logics.
the work closest to our lazy semantics is the one in which proposes an alternative mtl semantics used to prove that signal based semantics is more expressive than pointbased semantics over nite words.
despite the similarity between the two semantics the de nition of the until operator over our lazy semantics is more practical for the purpose of trace checking since it requires the left subformula of an until operator to hold in a nite number of positions.
reference revises the model parametric semantics of the trio temporal logic in order to overcome counterintuitive behaviors of bounded temporal operators on a nite temporal domain.
the proposal shares the same intuition behind our de nition of lazy semantics but overall the two semantics are quite di erent in particular in the interpretation of bounded and unbounded temporal operators .
trace checking run time veri cation.
several approaches for trace checking and run time veri cation and monitoring of temporal logic speci cations have been proposed in the last decade.
the majority of them see for example are centralized and use sequential algorithms to process the trace or in online algorithms the stream of events .
the centralized sequential nature of these algorithms does not allow them either to process largetraces or properties containing very large time bounds.
in the last years there have been approaches for trace checking and runtime veri cation that rely on some sort of parallelization.
however they mostly focus on splitting the traces based on the data they contain rather than on the structure of the formula.
these approaches adopt rst order relations with nite domains to represent the events in the trace.
the trace can then be split into several unrelated partitions based on the terms occurring in the relations.
we consider these approaches orthogonal to ours since we focus on the scalability with respect to the temporal dimension rather than the data dimension.
as for the speci c application of mapreduce for trace checking an iterative algorithm for ltl is proposed in .
similarly to the algorithm presented in this paper and to our previous work the algorithm in performs iterations of mapreduce jobs depending on the height of the formula to check.
however it does not address the issue of memory consumption of the reducers.
moreover the whole trace is kept in memory during the reduce phase making the approach unfeasible for very large traces.
.
conclusions and future work this work addresses the memory scalability issue that affects trace checking algorithms when dealing with temporal properties that use large time intervals.
we have proposed an alternative lazysemantics for mtl whose properties allow for a parametric decomposition of any mtl formula into an equivalent mtl formula with bounded time intervals.
as shown in the evaluation such decomposition can be used to improve distributed trace checking algorithms making them more memory e cient and able to deal with both very large traces and very large time intervals.
a future research direction is to study lazy semantics with respect to the signal based semantics for mtl.
another direction is the investigation of techniques for determining the most appropriate value for kin thelkdecomposition of formulae based on the con guration of the available cloud infrastructure.
.