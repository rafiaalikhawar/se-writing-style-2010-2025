floating point symbolic execution a case study in n v ersion programming daniel liew daniel schemmel cristian cadar alastair f. donaldson rafael z ahl klaus wehrle imperial college london united kingdom daniel.liew c.cadar alastair.donaldson imperial.ac.uk rwth aachen university germany daniel.schemmel klaus.wehrle comsys.rwth aachen.de in memoriam abstract symbolic execution is a well known program analysis technique for testing software which makes intensive use of constraint solvers.
recent support for floating point constraint solving has made it feasible to support floating point reasoning in symbolic execution tools.
in this paper we present the experienceof two research teams that independently added floating point support to klee a popular symbolic execution engine.
since the two teams independently developed their extensions this createdthe rare opportunity to conduct a rigorous comparison between the two implementations essentially a modern case study on nversion programming.
as part of our comparison we report on the different design and implementation decisions taken by eachteam and show their impact on a rigorously assembled and tested set of benchmarks itself a contribution of the paper.
i. i ntroduction symbolic execution has become a popular program analysis technique that can be used for test case generation and bug detection in a wide variety of domains .
underpinning any symbolic execution tool is a constraint solver often a satisfiability modulo theories smt solver which does the heavy lifting associated with determining whether execution paths are feasible at runtime and whether there exist values of the symbolic inputs that cause correctness conditions to fail.
due to the challenges associated with constraint solving for floating point arithmetic most symbolic execution tools do not directly support symbolic floating point reasoning instead either using approximations using structural equivalence of expressions as a proxy for equality or rejecting programs that use floating point as out of scope .
a widely used smt based symbolic execution tool is klee which reasons about symbolic constraints with bit level accuracy and supports the entire c language with a few exceptions the most notable of which is symbolic floating point computation.
the original reason for the lack of floatingpoint support was the absence of a suitable solver.
in lieu of this klee handles floating point programs by concretizing symbolic floating point expressions essentially reasoning about a single set of floating point values on each explored path.
however recent advances in solver technology have led to several smt solvers adding support for floating point reasoning along with an effort to provide a standardized theory of floating point arithmetic .
thus it is a natural idea to add floating point support to klee.
coincidentally we the two research groups who co authored this paper undertook suchan extension of klee independently and at roughly the same time.
when we became aware of each other s activities via communication on the klee mailing list we set up a meeting to understand the status and maturity of each implementation aiming to avoid duplication of effort.
it became clear that we were too late both teams had already invested significant effort and created mostly complete implementations.
this coincidence gave us a rare and valuable opportunity to empirically compare in a very direct manner two distinct and independent implementations of the same functional specification in the same framework via a case study in n version programming .
we describe in detail our methodology for independently developing floating point benchmarks without knowledge of each other s implementations exchanging these benchmarks and using the combined benchmark suite to independently improve our respective tools in isolation and finally exchanging tools and conducting a detailed head to head comparison with respect to the benchmark suite.
key contributions.
our major contribution is an experience report on n version programming with n in the context of floating point symbolic execution.
this contributes a rigorous experimental methodology for controlled n version programming that can be followed or adapted for future studies two complementary open source extensions to klee that support floating point symbolic execution and a discussion of lessons learned from this experience.
summary of lessons learned and supporting contributions.
independent preparation of benchmarks pays dividends.i n a domain with such subtle semantic issues as floating point reasoning having each team independently prepare a setof benchmarks was useful in providing both a practicalspecification for floating point symbolic execution and a target for tool optimization.
the benchmarks from each team provide a relatively unbiased target for evaluating the other team s tool.
the benchmark creation process has also led to a supporting contribution an open source set of floating point benchmarks tailored for symbolic execution tools .
dual implementation leads to rich design space exploration.
while our tools feature several similar design decisions their independent development has led to notably different solutions to various floating point related issues e.g.
in how the tools support the long double data type.
having two complementary tools enables differential testing cross checking results .
c circlecopyrt2017 ieeease urbana champaign il usa t echnical research experience report601 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
between tools to find tool bugs portfolio analysis where both tools are applied to a program in parallel and puts us in a good position in the future to combine the strengths of each to yield a high quality implementation of floating point support in klee.
floating point constraint solving remains a challenge.
although our tools complement each other neither offers a silver bullet for floating point symbolic execution surmounting the inherent difficulty of reasoning about floating point constraints will require advances in constraint solving.
to this end as a supporting contribution we have extracted a set of floating point smt queries generated by our tools which have been accepted as benchmarks for the annual smt competition providing a rich source of challenging examples for solver developers.
in this set of benchmarks belong to a new logic added to competition that combines the array bitvector and floating point theories.
rigorous n version programming can be limiting .
the rigor associated with the methodology that we have followed to enable a controlled study created a somewhat artificial development environment in which the teams did not ask one another for advice on technical matters despite being ideally placed to do so.
we believe our methodology is mainly suitable for future rigorous studies in n version programming to gain insights into the software engineering process rather than for regular software development projects.
however for regular development projects we strongly recommend the independent preparation of benchmark suites by multiple teams.
structure.
after reviewing essential background ii we describe the methodology for our experimental comparison iii .
we then detail the benchmarks we developed iv remark on notable features of the independent designs of the two floating point extensions to klee v and compare the tools experimentally vi .
we finally discuss related work in this area vii and conclude with by recapitulating the main conclusions and lessons learned viii .
ii.
b ackground we provide relevant background on symbolic execution ii a and floating point arithmetic ii b .
a. symbolic execution symbolic execution is a program analysis technique that provides the ability to automatically explore multiple paths through a program.
it has been implemented in many different tools and applied to many different areas such as software engineering systems and security .
instead of running the program on concrete input where a particular input component might e.g.
take the value symbolic execution runs the program on symbolic input where each input component is represented by a placeholder for an initially unconstrained value e.g.
x. as the program runs symbolic execution keeps track of how program variables depend on the symbolic input.
for instance after executing the statement y x symbolic execution will remember that variable yholds the symbolic value where is whatever symbolictable i x8664 floa ting point types .
name size p emax leading bit mexplicit?
fp32 bits no fp64 bits no x86 fp80 bits yes value is being held by xat the point this instruction is executed.
if symbolic execution reaches a branch that depends directly or indirectly on the symbolic input it first uses a constraint solver to check the feasibility of each branch side.
if only one side is feasible it will follow only that side.
if both sides are feasible it forks execution and follows each side separately adding appropriate constraints on each path.
for instance if in our example the branch if y is reached symbolic execution will add the constraint that 0on the true side and on the false side.
when a path terminates the conjunction of all the constraints collected at branch points called the path condition is sent to a constraint solver which can provide a concrete solution.
this solution represents a test input that follows the same path as the one on which the path condition was collected.
using this mechanism symbolic execution can systematically explore paths through a program.
b. floating point arithmetic in general floating point number representations provide finite approximations to the real numbers trading range and precision for storage space.
they utilize scientific notation of the form s m bewheresis either or and controls the sign mis a real number called the significand typically in the range b bis an integer base typically or and eis an integer exponent.
for example .75can be written as .
.
by using a fixed number of digits for exponent and significand floating point number representations restrict the range and precision respectively of representable numbers.
in this work we are interested in analysis of c programs that operate on floating point data.
the ieee standard also known as iec formalizesa number of floating point representations.
if an implementationof c respects annex f of the c language specification then most of its floating point types and operations are ieee compliant some exceptions to this are detailed below .
ieee floating point on x86 .
we provide details of ieee floating point representation implemented by the x86 family of processors both tools assume this target.
three primitive floating point types are available on this target bit wide single precision ieee binary32 64bit wide double precision ieee binary64 and bit wide double extended precision not an ieee basic format .
we refer to these types as fp32 fp64 and x86 fp80 respectively.
each type has a precision p number of bits representing the significand and maximum exponent value emax.
a full list can be found in table i. the last column leading bit mexplicit?
states whether the binary encoding of the type contains the leading bit i.e.
the integer portion of m o ri fi t is inferred from the remaining bits.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
in an annex f compliant implementation of c on x86 fp32 and fp64 are the float anddouble types respectively.
the c standard with annex f only weakly specifies how thelong double type should be implemented.
all c implementations that target x86 that we are aware of treat long double as x86 fp80.
the ieee binary format contains several classes of data normal denormal zero infinity and nan.
most floating point numbers belong to the normal class which provides a unique encoding for representable numbers where the leading bit of the significand is always 1and the exponent is in the range .
the denormal class represents numbers close to zero and exists to provide a smoother transition from the smallest positive normal largest negative normal number to positive negative zero.
denormal numbers always have the exponent and leading bit of the significand set to emax and 0respectively.
the zero and infinity classes each contain two values positive and negative zero and infinity respectively.
the nan class represents not a number .
nan values arise from invalid computations such as .
.
.
there are many different binary encodings for nan but ieee only distinguishes between two types quiet and signaling.
the x86 fp80 type is not an ieee binary format.
it consists of bit sign bit exponent and bit significand.
the binary encoding is similar to that of the ieee binary format except that the integer portion of the significand is stored explicitly.
this additional bit permits extra classes known as pseudo nan pseudo infinity unnormal and pseudo denormal.
modern intel processors consider all these classes apart from pseudo denormals as invalid operands .
rounding modes and exceptions.
ieee provides several different rounding modes e.g.
round toward positive a subset of which can be used from within the c language.
ieee also defines several different exceptions e.g.
division by zero that can be raised when operations are performed.
the default handling of these is to set one or more status flags and then continue execution.
reasoning about floating point.
given the complexity of floating point arithmetic with the background information above covering only a small fraction of the standard reasoning about floating point code is difficult and error prone.
common programming errors are often caused by incorrectly assuming that the arithmetic laws for real numbers hold unfortunately certain basic laws such as associativity and distributivity do not hold for floating point resulting in subtle bugs that may be triggered by a subset of input values.
iii.
m ethodology on first point of contact both teams had relatively featurecomplete floating point extensions to klee that had undergone preliminary correctness testing and performance benchmarking.
we structured our controlled n version programming experiment around three phases benchmark preparation iii a benchmark and tool improvement iii b and in depth comparison iii c .a.
phase i benchmark preparation during a period of approximately one month each team devoted resources to independently preparing benchmark programs to be used for evaluation.
each team prepared benchmarks divided into synthetic and real world benchmarks.
the real world benchmarks were adapted from existing open source applications.
the synthetic benchmarks were written from scratch with some designed to test particular aspects of floating point semantics and others encoding simple algorithms.
the benchmarks are described in iv.
both sets of benchmarks were prepared with symbolic analysis in mind the teams ensured that most benchmarks had at least some inputs marked as symbolic though a fewfully concrete benchmarks were included to thoroughly test concrete interpretation.
due to the known limited scalability of solvers with respect to floating point reasoning symbolic data was restricted to aim for a sweet spot where symbolic execution would issue interesting yet not intractably hard floating point queries.
importantly this fine tuning was performed by each team in isolation with respect to their own tool.
each benchmark includes a specification stating how the benchmark should be compiled and whether the benchmark is expected to be correct.
an incorrect benchmark s specification states a number of expected property violations e.g.
that anassert should fail or a division by zero or invalid memory dereference should occur.
in each case a set of allowed error locations source file and line number are provided.
during this phase the teams were free to improve their tool with respect to their own benchmarks.
at the end of phase i all benchmarks were pushed to a common repository.
phase i resulted in a set of floating point benchmarks suitable for evaluation of symbolic execution tools with one half knownto be somewhat tractable for aachen s tool and the other half for imperial s tool but importantly with no single benchmark having been prepared knowing the capabilities of both tools.
b. phase ii benchmark and tool improvement the full set of benchmarks allowed each team to assess the correctness and performance of their independently developed tool through semantic problems and optimization opportunities raised by the other team s benchmarks.
each team spent approximately one month fixing and optimizing their tools.notable tool changes arising from benchmark exchange are discussed in v. during this phase the teams communicated any benchmark problems not already identified during phase i but did not exchange tool implementation details.
these benchmark problems are discussed in vi a. at the end of phase ii the teams froze development of their tools and exchanged source code enabling each teamto subsequently a understand the design decisions of theother team via source code inspection and b compare experimentally with the other team s tool.
c. phase iii in depth comparison the teams now set about comparing the tools on the finalized benchmarks.
since both teams tools leveraged z3 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
and llvm it was agreed that both should share the same z3 version 4c664f1c and llvm version .
.
so as to restrict behavioral differences to design decisions in the klee extensions themselves rather than in their dependencies.
tool changes based on preliminary experiments.
our intent had been to conduct our in depth comparison using exactly the tool versions frozen at the end of phase ii.
however preliminary experiments revealed a number of remaining tool bugs that were easy to fix and whose fixes were not influenced by implementation details of the opposite team s tool.
we also realized that the tools were forked from different versions of klee leading to potential behavioral differences unrelated to the innovations of each team.
finally a dynamic solver timeout feature v b implemented by imperial and orthogonal to floating point support allowed klee to terminate in a more reliable manner that influenced tool comparison.
based on this experience we upgraded both tools by rebasing to use a common klee revision 2852ef63 donating the dynamic solver timeout feature to aachen and applying a number of bug fixes following an inter team review to confirm that fixes were not inspired by details of the opposite tool.
running the tools.
we ran the finalized versions of both teams tools on the finalized benchmark suite on a machine with twointel r circlecopyrtxeonr circlecopyrte5 v4 cpus physical cores each with 256gib of ram running arch linux.
hyper threading andturbo boost were disabled.
each tool was run times perbenchmark.
each tool was executed in parallel over the set of benchmarks running on at most benchmarks in parallel.
each klee process was pinned to a single cpu core andthe cpu s nearest numa node.
the cpu cores used forpinning were isolated from the kernel scheduler using the isolcpus kernel parameter.
the pstate cpu governor was set to performance requesting the same min max frequency .5ghz and a 0performance bias.
we enforced a gib memory limit per klee process.
each tool was executed in a docker container to keep the processes isolated.
klee has distinct phases for path exploration and subsequent test case generation.
we enforce a time limit of hour for each phase.
each team s tool was configured to use the same path exploration strategy non uniform random search prioritizing coverage with a fixed random seed .
comparing the tools.
in order to compare the tools we extracted the following information from each run.
the validity of a reported bug i.e.
whether it is a true or false positive.
a test case that detects a particular issue at a certain benchmark source location is considered to detecta true positive if and only if the benchmark s specification indicates that an issue of this type is expected at that location.
checking validity was achieved by replaying klee generated cases natively for reported bugs and verifying that the bug type source file and line number match what klee reported.
to check for out of bounds memory accesses and division by zero undefined behaviors in c that are not guaranteed to raise a runtime exception we instrumented the benchmarks using asan and ubsan respectively.branch coverage achieved on each benchmark.
this was measured by replaying all klee generated tests natively on a coverage instrumented via gcov build of the benchmarks.
coverage excludes the c library to avoid bias e.g.
a team s tool might interpret a c library function may lead to additional test cases rather than modeling it in z3 no additional testcases possibly leading to greater coverage of the c library which upon replay could inflate the team s coverage artificially.
execution time and crashes.
we recorded execution time for each run of a tool on a benchmark and noted cases where a tool crashed due to an internal error or running out of memory.
memory and time limits of gib and minutes were used when replaying test cases.
we merged the repeated runs of the same tool configuration as follows.
the true and false positives for a tool with respect to a benchmark were identified by replaying the test casesgenerated across allruns crediting a tool for finding a true positive during any run but similarly penalizing for any instances of false positives.
we computed branch coverage and execution time for a tool with respect to a benchmark as the arithmetic mean across all runs.
we counted the number of crashes for a tool with respect to a benchmark as the total number of crashes observed across all runs.
we then ranked the tools on a per benchmark basis using the following rules applied in order a a tool wins if it reports no false positives and the other tool reports at least one false positive.
b most true positives wins.
c highest mean branch coverage wins.
d if at least one tool crashed smallest crash count wins.
e otherwise smallest mean total execution time wins.
the tools draw if they are not distinguished by these rules.
the rationale for ranking is a symbolic execution tool should never exhibit false positives a because its primary goal is toaccurately find bugs b with a secondary goal of producing a high coverage test suite c .
thereafter we prefer a tool that does not crash d and a fast tool when neither crashes e .
it is hard to meaningfully compare false positives two distinct false positives might not be equally serious so in a we do not rank tools by number or nature of false positives.
when comparing mean branch coverage and execution time we use and .
confidence intervals respectively regarding results as indistinguishable if intervals overlap.
mean execution time differences of less than one second are also treated as indistinguishable.
iv .
b enchmark suite as mentioned in iii a both teams independently contributed benchmarks in total written in c99 or c11 .
each team aimed to choose examples that would be challenging yet not intractable for symbolic execution being free to choose benchmarks that played to the strengths of their tool withbenchmarks prepared by the other team posing an unknownchallenge.
the suite contains benchmarks expected to be correct and expected to be incorrect.
the suite uses kleespecific functions e.g.
to introduce symbolic data for our authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
convenience however it would be easy to port the benchmarks to a different interface e.g.
sv comp s so that they are applicable to other analysis tools.
branch counts reported below are the number of static branches in the compiled llvm ir.
a. aachen s benchmarks synthetic correct incorrect these focus on checking a wide range of floating point semantic features split up so that each benchmark tests as few individual features as possible allowing floating point symbolic execution errors to be easily pinned to underlying causes.
some check properties that are uncommon in real world programs to ensure that unusual and erroneous uses of floating point numbers are handled accurately.
these benchmarks have between and median branches and request between and median symbolic bytes.
real world correct incorrect these were drawn from multiple publicly available sources with care taken to include both large and well tested software reflected by benchmarks built upon the gnu multiple precision arithmetic library and sample programs not intended for production use e.g.
numerical code taken from .
these benchmarks havebetween and median branches and request between and median symbolic bytes.
b. imperial s benchmarks synthetic correct incorrect these comprise of simple algorithms e.g.
binary search and tests for fundamental properties of floating point e.g.
commutativity and non associativity of addition .
we include a port of williamkahan s paranoia benchmark .
these benchmarks have between and median branches and request between and median symbolic bytes.
real world correct incorrect these were written against the gnu scientific library libgsl adapted from tutorial examples included with the library source code.
creating these benchmarks involved iteratively increasing the presence of symbolic input stopping just before the tipping point beyond which imperial s tool could not make reasonable progress.
some of the libgsl benchmarks used long doubles a feature that imperial s early tool did not support we modified the associated benchmarks to avoid long doubles.
these benchmarks have between and median branches and request between and median symbolic bytes.
v. d esign details at the end of phase ii iii b we exchanged tool source code allowing comparison of tool designs that had previously been unknown across teams.
we discuss noteworthy similarities and differences between the designs of both tools as determined by discussion and source code examination.
both tools build on top of klee so they share mostly the same architecture which is discussed in the original klee paper .
exchanging benchmarks at the end of phase i clearly led to improvements in the design of both tools.
we consider this a positive outcome illustrating how a shared set of independentlygathered benchmarks can drive tool development.a.
notable similar design decisions constraint solver.
both teams used z3 as the constraint solver this was a natural choice as z3 supports floating point and was already integrated into open source klee.
floating point types operations and functions.
klee is primarily designed to execute programs written in c but actually executes llvm intermediate representation ir .
both teams assumed the x86 target and thus that the float double and x86 fp80 llvm types map to the ieee fp32 fp64 and x86 fp80 types.
assumption of ieee semantics was key as they are used by the smt lib floatingpoint theory that z3 implements.
both teams assumed that the primitive arithmetic llvm ir instructions e.g.
fadd map to corresponding ieee operations except for frem whose semantics are not the same as the ieee remainder function .
both teams assumed that operations on llvm types consistently use the same precision and range so that excess precision range are not used during computation.
this assumption holds if during nativecode generation the compiler uses sse instructions rather thanthe legacy x87 fpu to do floating point computations on fp32 and fp64 types .
vector instruction support.
llvm ir provides vector types derived from the basic floating point types enabling compiler optimizations can cause vector instructions to be emitted.
to process these both teams adapted llvm s scalarizer pass to scalarize as much as possible prior to symbolic execution sothat klee can assume that most instructions e.g.
fadd only take scalar operands.
a few instructions insertelement extractelement and shufflevector required special handling both teams added varying levels of support sufficient to run the benchmarks iv .
it is worth noting that at the end of phase i aachen and imperial s support for vector instructions differed greatly.
imperial compiled their benchmarks with optimizations en abled necessitating vector support aachen compiled theirbenchmarks without optimizations thus did not need vectorsupport.
during phase ii it became necessary for aachen to add vector support in order to handle imperial s benchmarks.
ieee rounding modes.
both teams implemented support for all ieee rounding modes available from the c standard library interface by having a per execution state flag that stores the current concrete rounding mode and ensuring that this is used when constructing constraints e.g.
floating point addition is affected by the rounding mode making it a ternary operator .
klee has the ability to call external functions functions missing from the program under analysis that can nevertheless be executed by the running klee process on behalf of the program under analysis.
both teams ensuredthat when calling external functions the rounding mode of the klee process is changed to that of the calling execution state and reverted back on return.
one slight difference in imperial s implementation is that the rounding mode is allowed to be symbolic whereas aachen s implementation concretizes a symbolic mode.
imperial s implementation achieves this by authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
forking on symbolic rounding modes i.e.
one path per rounding mode plus an extra path for an invalid rounding mode .
standard math functions.
the teams initially used different approaches for handling c standard library math functions.
aachen represented these functions as operations in klee s constraint language in several cases e.g.
fabs sqrt while imperial simply interpreted the implementation of each function in klee s c library.
imperial s approach suffers from path explosion when operands to the functions are symbolic.
upon exchanging benchmarks at the end of phase i imperial discovered their tool performed poorly on several of aachen s benchmarks due to path explosion and so switched to handling fabs andsqrt as operations in klee s expression language.
ieee exceptions and flags.
neither team implemented this portion of the ieee specification because it would significantly complicate symbolic execution one would need to maintain the symbolic value of the flags and check if any exceptions could be raised by every floating point instruction executed.
a consequence of this and of the smt lib floatingpoint theory is that symbolically neither tool can distinguish between quiet and signaling nans.
b. notable differences extending klee s expression language.
both teams extended klee s expression language to incorporate floatingpoint expressions in similar ways but with some notable differences related to how comparison operations and constantsare handled.
aachen added operations that correspond directlyto the opcodes of the ll vm fcmp instruction.
the instruction has ordered and unordered variants which return false and true respectively if either argument is a nan.
instead imperial only added operations that correspond to the ordered comparison opcodes because the unordered operations can be expressed in terms of the ordered comparison operations and the isnan predicate.
we consider imperial s approach to be a better choice because it is a simpler extension to klee s expression language.
aachen represented floating point constants as a separate expression type whereas imperial represented floatingpoint constants as implicitly bitcasted integer constants.
representation of types.
klee s expression language is based solely on bitvectors which was problematic when introducing floating point operations.
imperial handled this by making conversion between floating point and bitvector types implicit so that e.g.
the bitvector operands to a floating point add instruction are first converted to floating point types.
aachen instead made this explicit by introducing type conversion operations.
we consider aachen s choice to be superior here because implicit conversion has ambiguities.
in particular if an if then else expression has a mixture of bitvector and floatingpoint types for its then and else expressions the type of the if then else is ambiguous.
array ackermannization.
klee represents all symbolic data including primitive symbolic variables as arrays of bit bitvectors.
imperial observed that in a floating pointcontext if all arrays of bitvectors are replaced with simplebitvector variables and given to z3 in such a way that the new query is equisatisfiable with the original query then performance usually improves.
we refer to this transformation asarray ackermannization.
the z3 developers confirmed this suggesting that z3 is not currently well optimized for queries mixing the theory of quantifier free bitvector arrays with the theory of quantifier free floating point .
imperial s tool performs array ackermannization in the case where all array reads are at concrete indices and no writes have been performed to the array.
this is a fairly common case because symbolic variables in the original c program being analyzed are typically represented as a concatenation of byte reads at successive concrete indices of a symbolic array.
x86 fp80 support.
at the end of phase i only aachen added support for x86 fp80 and benchmarks to exercise it.
thus during phase ii it became necessary for imperial to implement support for symbolic reasoning over this type too.
our designs differed due to several characteristics of the x86 fp80 type.
first it is a padded type its bits are padded to bits on x86 and klee does not handle such padding properly.
both teams handled this issue in the same way makingsure klee allocates the necessary padding during the allocation of x86 fp80 stack and global variables.
second because x86 fp80 is not an ieee binary type constant folding expressions of this type required careful consideration and expressions of this type could not be directly modeled in the smt lib floating point theory.
klee already had support for constant folding the x86 fp80 via llvm s apfloat which performs arbitrary precision floating pointing arithmetic in a hardware independent manner.
however one of aachen s benchmarks caused both teams to discover that apfloat has a bug where unnormal operands are not handled correctly.
imperial solved this issue by evaluating all x86 fp80 operations natively within klee itself.
aachen solved this by storing a flag in every expression which is set to true iff the expression represents a member of one of the ieee classes.
when the value is accessed through a x86 fp80 operation this flag is examined and if it is false for any operands a nan is returned which mirrors how unnormal operands are treated on x86 .
a fix for the bug inapfloat would avoid the need for these workarounds.
to handle evaluating symbolic expressions over x86 fp80 with z3 both teams used the floatingpoint type abbrv.
fp15 which has a bit exponent a bit significand and an implicit integer significand bit.
it has exactlythe same range and precision as x86 fp80 but a different bit binary encoding due to the smt lib floating point theory onlybeing able to represent ieee classes.
the different binary encoding requires special handling of conversions between a bitvector that represents x86 fp80 data and fp15 .
imperial chose to only allow the ieee classes of the x86 fp80 type.
when converting to fp15 from a bitvector the explicit leading significand bit is removed and an additional constraint is added that asserts that the bit has the correct value for the bitvector to represent an ieee value.
when converting a fp15 to a bitvector the explicit leading authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
significand bit is added back and its value is inferred from the other bits to be an ieee value.
aachen chose to allow the non ieee classes of the x86 fp80 type in addition to the ieee classes.
this was achieved by representing expressions of the x86 fp80 type as a tuple.
the first value in the tuple is of type fp15 .
the second value is a boolean flag that is true iff the value represented by the tuple belongs to one of the ieee classes.
these tuples are then handled by each floating point operation.
if one of the tuple operands does not represent a value from one of the ieee classes it returns the tuple nan true .
imperial s implementation results in simpler constraints being given to z3 but is incomplete.
aachen s implementation is complete but the constraints are more complicated and alsocontradict the goals of array ackermannization because the tuple is represented as a two element array.
dynamic solver timeout.
although klee can limit the time allowed for path exploration before switching to test case generation klee does not try to interrupt the solver ifthe path exploration timeout is reached.
for long running solver queries especially frequent when using floating point constraints this can cause the path exploration timeout to fire much later than intended.
this leaves less time for test case generation see iii c and may cause test cases to be lost.
klee supports setting a fixed i.e.
static solver timeout but this does not interact well with the path exploration timeout.
a small solver timeout may leave paths unexplored despite there being available time for further path exploration while too large a timeout may cause the path exploration timeout to be missed as discussed above.
imperial implemented a dynamic approach to solve this problem.
every time the solver is invoked the per query solver timeout is set based on klee s current state.
if klee is path exploration the solver timeout is set to be the remaining path exploration time.
when klee switches to test case generation the solver timeout is set to the total allowed time for test case generation divided by the number of test cases to generate.
this means that each test case is given an equal share of solver time.
while aachen did not originally implement such a feature as noted in iii c to ensure compatibility this feature was donated to aachen s implementation.
nan representation.
neither tool can distinguish between quiet and signaling nans.
ieee does not precisely specify the binary encoding for either of these nans which means there are many different encodings that represent the same type of nan.
therefore when converting a floating point expression to a bitvector expression if it is feasible for the expression to be nan it means the converted bitvector expression can take on many values that all represent nan.
in practice this is rarely a problem however one of imperial s synthetic benchmarks deliberately tries to branch on the value of the lower order bits of a nan whose value is not defined by ieee .
during phase ii imperial discovered that this would sometimes crash their implementation due to inconsistent constraints.this was partly due to some bugs in z3 and llvm s apfloat which imperial worked around by consistently using the same bitvector constant to represent nan.
aachen did not handle this issue.
however the under specified nature of ieee nan bit patterns are a general problem.
even if klee s expression language was modified to have identical semantics to z3 they may still differ from those of the target machine or other smt solvers.
vi.
e xperimental comparison we now turn to the comparison of the tools.
we discuss problems with the benchmarks flagged by tool comparison vi a and results comparing the finalized tool versions headto head during phase iii vi b .
a. benchmark issues non termination.
when replaying tests generated by the tools we found that two benchmarks did not terminate for certain inputs.
in one case this was unintentional due to abug in the implementation of a binary sort algorithm used by the benchmark.
we handled these cases by setting atimeout when replaying test cases see iii c .
due to gcov implementation details branch coverage is not recorded for non terminating tests.
this affected only a few benchmarks and gave neither tool an advantage in our ranking scheme.
unnormal values.
we found several problems with a benchmark that operated on the x86 fp80 type involving unnormal values see ii b .
first clang would incorrectly optimize the benchmark by performing erroneous constant folding .
we thus disabled optimizations for this benchmark.
we also discovered it is possible to exploit this problem to crash clang .
second we found that several operations on unnormal numbersused in this benchmark behaved inconsistently across compilers e.g.isnan and casting to integers .
we concluded that this was due to these operations exhibiting undefined behavior and removed them from the benchmark.
the remaining issues are cases where our tools found a benchmark to be incorrect contrary to its specification for each issue we applied a simple fix failing to account for nans.
a benchmark that sorted an array of partially symbolic floating point values was incorrect when infinity values were added to yield nan values later triggering an assertion failure when checking correctness of sorting.
a benchmark performing matrix multiplication on a partially symbolic matrix was similarly incorrect.failing to account for scientific notation.
a benchmark that verifies the output of atof 1intended to constrain the characters of the symbolic input string to represent a small decimal value asserting that the result of atof was in the expected range.
the input constraints accidentally allowed scientific notation e.g.
1e10 so that atof could generate a value outside the expected range.
failing to take poor approximation into account.
a benchmark that checks the result of x2 wherexis a symbolic 1converts a string to a floating point value.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii ranking of the tools .each count shows the number of wins for a tool except the last row which shows the number of draws .
reason aachen imperial other tool has false positives finds more bugs highest branch coverage fewest crashes smallest execution time draws floating point value did not account for denormal numbers.
as the computation may cause a gradual underflow to a denormal number its precision may be reduced to a single bit in the worst case causing a very high relative error.
b. head to head tool comparison tool ranking.
table ii summarizes the number of benchmarks for which each team won according to the procedure for ranking tools described in iii c. neither tool reported false positives.
for one benchmark aachen found more bugs than imperial and for another benchmark imperial found more bugs than aachen.
both benchmarks use the sqrt function and come from aachen s set of synthetic benchmarks and both tools exhibit poor performance on them due to long query solving times.
in cases where the tools found the same number of bugs imperial achieved higher branch coverage in four cases and aachen in one.
imperial achieved higher coverage whenaachen s tool crashed while trying to generate test cases thus missing out on coverage that the generated tests would have achieved.
in all cases the crashes were either due to an internal z3 error case or there being a semantic mismatch between the expression languages of klee and z3 causing z3 generated models to be unsatisfiable in klee s expression language cases .
for the single benchmark where aachen s tool achieved higher coverage imperial s tool reached a path exploration timeout whereas aachen s tool explored all pathsin the benchmark.
for benchmarks where the tools were as yet indistinguishable there were three cases where imperial s tool did better dueto aachen s tool crashing cases where neither tool crashedbut where the tools were distinguished by execution time with aachen and imperial winning and times respectively.
of the draws two are due to the tools both crashing the same number of times and are cases where neither toolcrashes but where either the confidence intervals associated with mean execution time overlap or the difference in the mean execution time is less than one second.
the crashes here are internal to z3 which have been reported .
aside from cases where the tools crashed we attribute the differences in effectiveness of the tools to the performance of the constraint solver which is discussed later in this section.
coverage.
figure compares the branch coverage for aachen s and imperial s tools on a per benchmark basis.
for each benchmark there are two bars showing the percentage of branchestable iii ev alua tion of the tools in terms of bug finding exhaustive explora tion number of crashes and number of timeouts .thet and t rows show the number of true positives and true nega tives respectively .
aachen imperial both neither t .
.
.
.
t .
.
.
.
crashes .
.
.
.
timeouts .
.
.
.
that have been covered one striped yellow bar for imperial and one solid green for aachen.
benchmarks are ordered along the x axis such that the ones where imperial s aachen s toolachieved a higher coverage are on the left right .
benchmarks with identical coverage are sorted alphabetically.
the figure shows that for most benchmarks both tools achieve the same coverage.
while neither tool strictly dominates the other it canbe seen that imperial s tool has a slight advantage in this area.
the results are mostly deterministic have a confidence interval of below except for the rightmost benchmark which has a confidence interval not shown in the figure for clarity of .25percentage points for the aachen tool only.
we attribute this to aachen s tool crashing non deterministically on this benchmark.
note that while is the theoretical maximum branch coverage it is not reachable in every case especially for the real world benchmarks many of which use a library but only exercise a small portion of it.
tool complementarity and limitations.
the results so far show that the tools overlap somewhat in their capabilities.
we now examine the extent to which the tools are capable of effective analysis of our benchmarks whether they are hindered by common problems and cases where they are complementary.
table iii shows the extent to which each tool is capable of correctly finding bugs in the benchmarks.
the t row shows for each tool the number of total bugs found out of the number of bugs expected to be present from the benchmark specifications in the benchmarks with erroneous paths we expect to find a total of bugs .
the t row shows for each tool the number of bug free benchmarks total that the tool is able to fully explore.
that is allfeasible paths are enumerated so that correctness is exhaustively verified.
in each row tool complementarity is indicated by showing the extent to which bugs can be found or correctness proven by both tools or by neither tool.
both tools found the same bugs with each tool finding one one additional bug that the other did not.
this shows that both tools perform reasonably well at bug finding with neither dominating the other.
there were bugs that neither tool found indicating that the benchmark suite was challenging.
both tools determined the same benchmarks to be correct with aachen showing one addition benchmark to be correct that imperial did not and imperial showing four additional benchmarks to be correct that aachen did not.
this shows that authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
hqfkpdun udqfk ryhudjh fig.
.
branch coverage achieved by the two tools.
on the left imperial yellow bars with black stripes did better while on the right aachen solid green bars achieved higher coverage.
the long middle section shows benchmarks for which both teams reached the same coverage.
both tools perform reasonably well at exhaustive exploration with neither dominating the other.
there were benchmarks expected to be correct that neither tool could show to be so indicating that benchmark suite was challenging enough that exploration was not exhaustive.
non exhaustive exploration was due to timeouts crashes and memory exhaustion.
table iii also provides details of the number of benchmarks on which each tool crashed incorporating cases of memory exhaustion or timed out.
aachen s tool crashed more than imperial s due to the semantic inconsistencies discussed in vi b .
for two of the benchmarks both tools crashed due to hitting an internal z3 error .
imperial s tool timed out on three benchmarks where aachen s did not.
on those three benchmarks aachen s tool fully verified one of them and crashed on the other two.
solver performance.
we attribute the performance difference in the tools to the performance of z3 as constraint solving accounts for the majority of execution time for both tools.
we observed that for some paths the tools would send equisatisfiable but different constraints to z3 e.g.
due to imperial s array ackermannization optimization as well as differences in the tools extensions to klee s expression language sometimes resulting in wildly different executiontimes.
smt solvers rely heavily on heuristics to gain goodperformance so it is not unexpected that slight differences in constraints could result in different performance.
however we discovered that in klee z3 was used in a sub optimalway.
the z3 api used by klee bypasses all of z3 s logicspecific strategies and uses the dpll t method lazy translation to sa t of solving constraints.
this is frequently slower than using z3 s logic specific strategies.
on re running our experiments after modifying the tools to use the more appropriate z3 api the performance of aachen s tool increased slightly and that of imperial s dramatically.
when ranking the modified tools imperial ranked better on benchmarks with aachen ranking better on only one and tying on the remaining benchmarks.
the better performance of imperial s tool is dueto the array ackermannization optimization which causes z3 to use a logic specific strategy eager bit blasting to sa t inplace of the frequently slower dpll t based approach .
to maintain the integrity of our study the results we present are of the tools using the sub optimal z3 api but we shall use this insight when fully integrating floating point support into upstream klee.c.
threats to v alidity our study has both internal and external threats to validity.
both tools use klee and z3 so errors in these components may lead to bugs that go undetected when comparing the two implementations.
however the manual effort we put in writing specifications for the benchmarks renders this risk minimal.
since both our tools were built on top of klee and z3 our respective design decisions might be more similarthan they would be had different frameworks been used.
however we found that in spite of this common infrastructure building the extensions required important design decisionsthat resulted in significant differences.
moreover having a common infrastructure made it possible to conduct a rigorous comparison that would not have been possible otherwise.
our benchmarks might not be representative of floatingpoint code found in large deployed applications.
however our synthetic benchmarks are meant to systematically test challenging floating point features that real applications wouldexercise while our real world benchmarks are based on existing applications or widely used libraries.
finally due to the computational complexity of floatingpoint constraint solving all benchmarks contain comparativelyfew floating point operations and symbolic data.
this is due to the fact that constraint checking large numeric applications is currently infeasible in the presence of floating point numbers.
vii.
r ela ted work testing of floating point programs has received significant attention from the research community e.g.
and various methods have been proposed for verifying floating point properties through abstract interpretation decision procedures theorem proving and combinations of techniques .
recent work has also focused on estimating bounds on round off error in floating point computation .
several works have investigated extending symbolic analysis to floating point programs .
ours is one of the few that integrates floating point reasoning witha mature symbolic execution tool klee and our study is distinguished by our n version programming approach.
thanks to our combined suite we believe this is one of the largestscale studies in terms of number and diversity of benchmark programs of symbolic execution in the context of floating point.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
reasoning about floating point constraints in the context of symbolic execution has often been conducted in a manner that avoids the full complexity of floating point e.g.
by approximating floating point numbers with mathematical reals in ariadne and approximate solving of floating point constraints using search based methods in coral and flopsy .
klee fp and klee cl are twoextensions of klee which add support for floating point inthe limited context of reasoning about program equivalence.
that is these extensions can only test whether two purportedly equivalent floating point implementations are indeed equivalent but cannot perform general symbolic execution of floating point code nor can they perform test input generation.
a very recent study provides a large corpus of numerical software bugs categorized as accuracy bugs special value bugs convergence bugs and correctness bugs .
the corpus includes bugs originating from c source code including gsl which could be adapted into a form suitable for analysis using our klee based tools.
with further effort example bugs originating from software written in other languages could be ported to be suitable for analysis using our tools.
viii.
c onclusion and lessons learned we have presented a case study on n version programming for the independent benchmark driven development of twoextensions to klee to support symbolic reasoning over floating point arithmetic.
we hope that our rigorous procedure for independently developing benchmarks improving tool versions in response to the benchmarks and then exchanging tools to evaluate similarities and differences will providea useful basis for future researchers in the position wherean analogous controlled study is feasible.
we conclude by recapitulating the main contributions and key lessons we have learned from the experience.
independently developed benchmarks.
our independentlydeveloped benchmarks served both as a practical specification and a target for tool optimization.
each team s benchmarks highlighted non trivial correctness issues in the other team s tool leading to a more reliable comparison overall.
we stronglyrecommend the preparation of multiple independent benchmarksuites when exploring other problem domains with equally rich design spaces.
benchmark suite for floating point symbolic execution and constraint solving.
we regard the combined benchmark suite itself as an important contribution of this case study it provides a source of benchmarks in a domain where existing suitable benchmarks may be hard to find.
in our case where manypublicly available programs employ floating point a set ofbenchmarks that is interesting enough to warrant symbolicanalysis yet not so large to be intractable was not readily available our study has led to such a benchmark suite which is available publicly.
furthermore our experiments generated a large number of smt queries that we have contributed to the annual smt competition .
our queries helped start a new competition division involving a logic that combines thearray bitvector and floating point theories this should have a direct impact on software engineering research.
dual implementations of floating point symbolic executors.
the very similar settings in which the two teams were innovating enabled a close comparison of design choices.
often this was interesting allowing us to compare in detaile.g.
the manner in which the teams supported long doubles and approaches to handling floating point types in klee sexpression language.
on the other hand the similar settingperhaps reduced the chances of the teams making radicallydifferent design choices which might have been harder tocompare but might have yielded more fundamental insightsinto how to approach floating point symbolic execution.
as discussed in the introduction having two complementary tools enables differential testing to find tool bugs and portfolioanalysis to speed up and improve analysis results both advocated in the deployment stage of n version programming.
a downside of having dual implementations is the rigor associated with n version programming in which the twoteams have to work independently and to a strict schedule which often felt unnecessarily restrictive.
combining design choices.
our case study places us in a good position to combine the strengths of each tool to yielda higher quality implementation of floating point support in klee than either would have achieved individually.
we brieflydiscuss four relevant aspects.
support for vector instructions was handled in a very similar way by both teams and has already been incorporated upstream .
klee s expression language is not typed so a necessary first step is to makeit typed.
once that is complete imperial s implementationof floating point expressions could be used as it has fewer comparison operations but then combined with aachen s more robust explicit casting operations.
to support the long double type we lean toward aachen s approach as it is more complete by supporting non ieee classes of floating point numbers but at the expense of more complicated constraints.
imperial s array ackermannization optimization combined with the appropriate z3 api resulted in notable performance gains and should be incorporated.
breakthroughs still needed.
our experience is that despite significant recent advances in the field breakthroughs are still required before floating point constraint solving is efficient enough for scalable analysis on a number of benchmarks both tools missed bugs or achieved low coverage due tothe intractability of the constraints to be solved.
as well as innovating at the solver level we envisage opportunities for using higher level program analyses to simplify constraints.