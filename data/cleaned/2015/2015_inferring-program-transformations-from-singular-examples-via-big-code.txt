inferring program transformations from singular examples via big code jiajun jiang luyao ren yingfei xiong lingming zhang key laboratory of high confidence software technologies ministry of education pku department of computer science and technology eecs peking university beijing china university of texas at dallas usa jiajun.jiang rly xiongyf pku.edu.cn lingming.zhang utdallas.edu abstract inferring program transformations from concrete program changes has many potential uses such as applying systematic program edits refactoring and automated program repair.
existing work for inferring program transformations usually rely on statistical information over a potentially large set of program change examples.
however in many practical scenarios we do not have such a large set of program change examples.
in this paper we address the challenge of inferring a program transformation from one single example.
our core insight is that big code can provide effective guide for the generalization of a concrete change into a program transformation i.e.
code elements appearing in many files are general and should not be abstracted away.
we first propose a framework for transformation inference where programs are represented as hypergraphs to enable fine grained generalization of transformations.
we then design a transformation inference approach g enpat that infers a program transformation based on code context and statistics from a big code corpus.
we have evaluated g enpatunder two distinct application scenarios systematic editing and program repair.
the evaluation on systematic editing shows that g enpatsignificantly outperforms a state of the art approach s ydit with up to .5x correctly transformed cases.
the evaluation on program repair suggests that g enpat has the potential to be integrated in advanced program repair tools g enpat successfully repaired realworld bugs in the defects4j benchmark by simply applying transformations inferred from existing patches where bugs have never been repaired by any existing technique.
overall the evaluation results suggest that g enpat is effective for transformation inference and can potentially be adopted for many different applications.
index t erms pattern generation program adaptation code abstraction i. i ntroduction modern program development is often repetitive where the same changes are applied over and over again in different positions or in different projects by the same or different developers.
inferring program transformations from change examples could automate the changes of the same type and has many potential uses such as systematically editing many places in the source code fixing bugs based on patches of recurring bugs porting commits among forked projects adapting client code for incompatible api changes refactoring etc.
yingfei xiong is the corresponding author.
this work was partially done when jiajun jiang was a visiting student in ut dallas.a key challenge in transformation inference is to decide what can be generalized in the transformation.
as an example let us consider the following change f a b f g a b a possible transformation could be the following one wrapping with gany element that is a variable has type integer has identifier name a we may also consider making the transformation more general such as the following one wrapping with gany element that is a variable has type integer we may also consider the context of the change to make the transformation more specific such as the following one wrapping with gany element that is a variable has type integer is the first argument of a call to f making the transformation too specific may decrease recall i.e.
missing cases that should be transformed.
making the transformation too general may decrease precision i.e.
transforming cases that should not be transformed.
therefore selecting a suitable level of generalization is critical to the quality of the inferred program transformation.
a typical method adopted by many existing techniques is to learn from many examples where the statistical information from many examples is used to decide which part should be concrete in the transformation and which part should be abstracted away.
in the above example if there are many change examples that wrap the first arguments of f with gand the first arguments have many different names we know that the last transformation should be the desirable one and information such as variable name ashould be abstracted away.
however such an approach requires many examples as the training set.
in practice we often do not have so many examples.
for example genesis uses hundreds of patches for the same type of bugs to generate transformations while in practice the repetitiveness of patches tends to be tenuous 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
and only one or a few patches can be located for many types of bugs.
on the other hand a few approaches have tried to reduce the needed number of examples by using predefined rules to decide what part in the concrete changes should be abstracted away in the transformation i.e.
always ignore the variable names and allow to match variables with any name .
however as shown in the next section predefined rules cannot capture different situations and often fail to produce the desired transformation.
in this paper we address the challenge of inferring a program transformation from one single example.
our core insight is to learn from big code utilizing the statistical information in a large code corpus to guide the generalization from a change example to a transformation.
more concretely the elements that appear in many files are potentially general and should be kept in the transformation in order to capture the transformation for all such instances.
along this line we first propose a general framework for transformation inference from an example where a hypergraph is used to represent source code and fine grained transformation tuning is enabled by selecting elements and their attributes from the hypergraph.
we then instantiate the framework with a transformation inference algorithm that fine tunes the hypergraph information based on code statistics from a big code corpus.
we have already implemented our approach as a tool g enpat and evaluated g enpatin two distinct application scenarios.
in the first scenario we employed g enpatto perform systematic editing as studied by meng et al.
but with a much larger dataset.
the result shows that g enpatsignificantly outperforms state of the art s ydit with an up to .5x improvement in terms of correctly generated transformations.
in the second scenario we explore the potential of using g enpatto repair bugs by simply mining and applying fixing patterns from existing patches.
although not designed as a comprehensive and standalone repair technique g enpatsuccessfully fixed bugs in a subset of the commonly used defects4j benchmark.
particularly bugs have never been fixed by any existing technique as far as we know.
the results suggest that genpatis potentially useful in both systematic editing and program repair and indicate a promising future for adopting genpatin practical systems with program transformations.
in summary this paper makes the following contributions a framework for transformation inference from a single example by representing code as a hypergraph to allow fine grained generalization of the transformation.
an algorithm to instantiate the framework by defining the rules for selection based on the code context and statistics in a large code corpus.
an implementation of the proposed technique in java language called g enpat which can be publicly accessed at an evaluation with g enpat on two distinct practical application scenarios showing the effectiveness of the proposed framework and calling for future research to integrate g enpatfor advanced program transformation based systems including systematic editing and programrepair systems.
ii.
r ela ted work in this section we introduce the most related works to this paper.
existing techniques have explored different strategies for transformation extraction and two categories of transformations have been proposed.
the first one is executable transformations which can be applied directly to modify a code snippet.
the second one is abstract transformations which cannot be applied directly but constrain a space of possible transformation results.
in other words executable transformations are functions while abstract transformations are binary relations that are not functions.
abstract transformations are useful in guiding other technical processes such as ranking candidates in automatic program repair .
in the following we will introduce the most related approaches from these two categories in detail.
also we will discuss few shot learning problem in machine learning domain of which the transformation inference problem can be seen as an instance.
a. executable transformation generation as explained in the introduction the key challenge of transformation inference is to decide how to generalize a change into a transformation.
to approach this challenge existing techniques proposed to utilize different strategies such as learning from many examples or employing predefined rules.
learning from many examples.
multiple existing techniques learn practical transformations from a set of examples with similar code changes.
the basic idea is that shared code elements across change examples are critical parts for the transformation and should be preserved while the other parts tend to be specific to some individual examples and thus will be discarded.
andersen et al.
proposed spdiff which extracts a set of term replacement patches from each example and then takes the longest common subpatches as a transformation pattern.
meng et al.
proposed l ase that learns edit scripts from multiple examples.
l ase extracts a set of edit operations from each example keeps the common operations and extracts the context of the common operations to form a transformation.
reudismam et al.
proposed refazer which learns syntactic code transformations from examples.
r efazer takes a program synthesis perspective and searches for a transformation program that is consistent with all the examples.
long et al.
proposed genesis.
it infers a template ast from existing patches which can cover all mined examples.
bavishi et al.
proposed to mine repair strategies or repair patterns from examples for fixing bugs reported by static analyzers which clusters similar edit examples for pattern abstraction i.e.
synthesis of contextmatchers via leveraging a dsl for representation.
nguyen et al proposed cp atminer that aims to mine semantic code change patterns from code corpus and represents patterns as graphs.
cp atminer also depends on the repetitiveness of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
code changes and leverages graph isomorphism for pattern clustering.
similarly molderez et al leveraged frequent itemset mining algorithm to learn edit scripts of code changes from histories of open source repositories and employed them for code change recommendation.
as discussed in the introduction to achieve a good level of generalizability these approaches require a non trivial number of examples which are often difficult to obtain in practice.
for example in the scenario of program synthesis these approaches have been successfully applied to only the most common bugs or the bugs in student assignments where a large number of patches can be found for the same type of bug.
however in practice the repetitiveness of patches tend to be tenuous and only one or a few patches can be located for many types of bugs.
inferring transformations with predefined rules.
several approaches rely on predefined rules to infer a suitable transformation.
a typical approach is s ydit which also infers a transformation from one example and is similar to our goal.
given a change s ydit first selects all related statements that have dependencies with the changed statement then abstracts away all names variable name type name method name etc in the statements and leaves only the structure of the statements.
then the structure is used to match other places and perform the change.
however there are many cases that we may need to abstract away part of the structure or keep some names in the transformation where s ydit cannot extract the desirable transformation.
as our evaluation will show later our approach significantly outperforms s ydit with an up to .5x improvement.
approaches relying on multiple examples may also use predefined rules to select the desired transformation if the examples are not enough to ensure the quality of the transformation.
for example r efazer employs a set of rules to rank the transformations if the synthesizer found multiple possible transformations.
defining transformation manually.
there are some other approaches that perform code changes with manually defined transformations.
for example kim et al.
manually defined a set of transformations for automatic program repair after analyzing a corpus of human patches.
similarly liu and zhong defined transformations a.k.a.
repair templates with analyzing code samples from stackoverflow.
molderez and de roover proposed to refine a manually defined template with a suite of mutation operations which recommends changes to the templates iteratively.
additionally to ease the description of transformations a set of dsls have been proposed by previous studies for program migration or api updating.
these techniques provide a way for developers to systematically update a current program with manually defined transformations.
however even with the help of dsl manually defining transformations is not easy and automatic transformation inference is desirable in many situations.b.
abstract transformation as guidance recently a number of existing techniques were proposed to extract transformations from a set of examples for guiding other technical processes.
in particular transformations are often used in automatic program repair to guide the patch generation as the complete search space can be too huge .
for example xuan et al.
and wen et al.
leveraged transformations from historical bug fixes as program repair templates.
similarly jiang et al.
proposed to use such transformations to refine the search space of patch generation.
also other researches proposed to use such transformations for patch prioritization .
the core insight behind these techniques is that frequently appeared transformations in history bug fixes have higher possibility to repair a bug and thus can be utilized to refine the patch space.
however these transformations cannot be directly applied and can be much more abstract compared to those executable transformations.
c. few shot learning few shot learning attempts to train a machine learning model with a very small set of training data and is often considered a grand challenge in the machine learning domain.
a typical approach to few shot learning is to utilize data that are beyond the current task and train a meta level model with these data which can be used as a basis for the few shot learning task.
our problem is similar to few shot learning as we try to generalize a transformation from just one example.
also we learn meta level information from big code for the transformation inference where the idea is similar to the approach of few shot learning.
on the other hand the current few shot learning techniques are still designed for classic classification problem over feature vectors and thus cannot be applied to the transformation inference problem since it is not a classification procedure.
iii.
m otiv a ting example in this section we motivate the problem of transformation inference with an example in the systematic editing scenario .
in a typical systematic editing scenario the programmer would like to perform the same change on a series of places.
she would first change one place and ask the system to extract a transformation from the change then navigate to the next place and invoke the transformation there.
the process is similar to a copy paste clipboard operation process except that only the transformation is copied and pasted .
listing shows an example requiring systematic editing.
here denotes deleted code lines and denotes newly introduced code lines.
the grayed description on the top gives the detailed information related to the code changes including the github link of the corresponding commit fix message and changed classes.
particularly there are two separate code changes where the first one at line is the change from which a transformation would be inferred and the second one at line is the ideal change that we expect the transformation to produce.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
commit github.com junit team junit4 commit 75f7892 message removed nascent category implementation source src.main.java.org.junit.runner.description first case for pattern generation description createdescription class ?
testclass return new description testclass.getname null return new description testclass.getname testclass.getannotations candidate place to apply the above pattern sydit failed to apply the above pattern because the variable name cannot match the method getname while genpat successfully applies it.
description createdescription string name annotation... annotations return new description name null annotations return new description name annotations listing .
an example that s ydit fails to apply pattern.
as we can analyze from the two examples a desirable transformation should delete the second argument of a call todescription if it is null .
in other words the first argument testclass.getname and the third argument testclass.getannotations are specific to the local change and should not be considered as part of the context of the transformation.
the challenge is to know which part should be kept in the transformation and which part should be abstracted away i.e.
deciding how to generalize the change.
as discussed previously existing approaches rely on either multiple examples or predefined rules.
however providing multiple examples is often not desirable or feasible.
for example in systematic editing the examples are provided by the user and asking the user to provide multiple and preferably diverse examples significantly increases the cost of using this approach.
in the scenario of bug repair for many types of bugs only one existing patch can be found and we have to produce a transformation out of the patch.
for example listing shows a patch that inserts an equality check between two object arguments into a method returning boolean .
from this patch our approach successfully inferred a transformation and fixed bug mockito in defects4j benchmark which is shown in listing and has never been fixed by any previous technique.
however we found only one such change instance from more than million historical code change examples of open source java projects on github from to .
commit github.com clitnak mcrailo commit 8e76da8 message solved ticket railo source railo java.railo core.src.railo.runtime.op.operator boolean equalscomplexel object left object right ... if left right return true if decision.issimpv left decision.issimpv right listing .
referenced history patch to fix mockito .
public static boolean areequal object o1 object o2 if o1 o2 return true if o1 null o2 null listing .
patch of mockito .on the other hand predefined rules hardly meet the divergent requirements of different situations.
for example s ydit has a predefined rule to abstract away all variable method type names and keep only the structure.
however in this case it would keep the structure of the first and the third arguments requiring them to take the o.m form.
it would also discard the name of the method call description .
both are not desirable.
our approach decides how to generalize the change by analyzing the big code .
we count the number of files where an element appears in a large code corpus.
if an element appears in many files it is probably a general element and should be kept in the transformation to transform other sibling instances otherwise it is probably specific to the current change and should be abstracted away.
in this example testclass.getname and testclass.getannotations can be seldomly found in the codebase and thus is abstracted away.
on the other hand description andnull are both frequent and thus are kept in the transformation.
while the general idea is simple realizing the idea is not easy and faces multiple challenges abstraction.
we need to have a flexible representation of the transformation where the level of generalization can be adjusted at a fine grained level.
match.
the representation should be flexible to allow matching code with different attributes such as the static value type or different relations such as data dependency .
transformation.
the matched code pieces should be consistent with the transformation i.e.
when some code pieces are matched the transformation must be able to be replayed on these code pieces.
in the next section we will propose a framework for transformation inference to address the above challenges.
iv .
f ramework of transforma tion inference in this section we introduce the framework of transformation inference.
here we consider a transformation as first a pattern to match code pieces and a sequence of modification operations to change the code pieces.
to address the challenges mentioned above we make the following design decisions.
match.
to ensure the code elements could be flexibly matched by their attributes and relations we abstract source code into a hypergraph where the nodes are ast nodes with their attributes called code elements and the hyperedges are relations among nodes.
abstraction.
we further introduce a match relation between hypergraphs such that a graph can be matched by a more abstract graph with possibly fewer elements and attributes.
in this way we can abstract a hypergraph into a pattern at a fine grained level by selecting elements and attributes that should be kept in the pattern.
transformation.
to ensure the matched code elements are transformable we use elements and attributes as the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
interface between the pattern and the modifications.
the modifications specify the elements and attributes that must be matched to make the transformation applicable and the pattern ensures to match these elements and attributes.
now we introduce the design in detail.
we start by defining code elements.
intuitively a code element captures a node in an ast and the attributes of the ast node that we are interested in.
definition code element .a code element is a pair angbracketleftid attrs angbracketrightwhereidis an element id and attrs is a set of attributes where each attribute is a pair angbracketleftname value angbracketright.
in our current implementation we mainly consider three attributes ast node type such as statement orvariable content such as a b or which is the string representation of the complete subtree and static value type such as string orint .
the code element captures a single ast node and its attributes but not the relation between ast nodes.
to capture the relations we further define code hypergraph as a collection of code elements and their relations.
definition code hypergraph .a code hypergraph is a pair angbracketlefte r angbracketright whereeis a set of elements and ris a set of hyperedges where each hyperedge is a pair angbracketleftrname r angbracketright consisting of a relation name rname and a relation r ek for some k whereekdenotes the k ary cartesian power of e. the relation rcan be either directed or undirected but in our implementation we consider mainly three directed relations the parent relation in an ast the ancestor relation which is the transitive closure of the parent relation and the intra procedural data dependency between l values in the program.
we only consider data dependencies ignoring control flow dependencies to avoid over approximations for lightweight analysis.
please also note that when the parent relation is included a hypergraph subsumes an ast.
additionally the ancestor relation is necessary as it may still guarantee the program structure match even when two nodes do not have direct parent child relation.
for example figure shows the code hypergraph of the two code snippets in listing .
each node in the graph represents a code element where their ids and attributes are listed.
three types of relations are shown in the graph the black lines represent the parent relation and the blue lines represent the data dependency relation.
note that there is no data dependency between p3and node p6while the omitted child node of p3has data dependency on p6.
for clarity we ignore the ancestor relation in the figure e.g.
node p1is the ancestor of node p3.
after we have a code hypergraph we can define a pattern that matches elements in the graph.
here we treat a pattern uniformly also as a hypergraph.
a pattern matches some code elements if both the attributes and the relations on the patternhypergraph match those of the target code elements.
formally we first define the match between elements.
definition element match .an element angbracketleftid attrs angbracketrightis said to match another element angbracketleftid prime attrs prime angbracketright i f angbracketleftname value angbracketright attrs angbracketleftname value angbracketright attrs prime.
based on the match between code elements we define the match between hypergraphs.
definition hypergraph match .a code hypergraph angbracketlefte r angbracketright matches another code hypergraph angbracketlefte prime r prime angbracketrightvia a mapping match e e primesuch that e e e matchesmatch e and angbracketleftrname r angbracketright r angbracketleftrname prime r prime angbracketright r prime r n a m e rname prime r r prime.
we say a code hypergraph gis more abstract than another code hypergraph g primeif there exists a match from gtog prime.
given a code hypergraph we can abstract it into a pattern by removing elements and attributes from the hypergraph.
the result is ensured to match the original hypergraph.
in this way we turn the generalization problem into a problem of selecting elements and attributes in a hypergraph where the selected elements their selected attributes and their relations form a new hypergraph as a pattern.
please note that our framework also allows to select relations but in this paper we only consider the selections of elements and attributes and keep all relations among the selected elements.
for example in figure the red elements their red attributes and their relations form a new hypergraph that would match both code snippets.
the elements with solid frame are the matched elements while the elements in the dashed frame are not matched.
after an element is matched we can apply the modification operations to the elements.
our framework does not enforce a particular set of modification operations and treats modifications as uninterpreted atomic elements denoted by set m. furthermore we assume the existence of two functions preids and preattrs .
function preids m denotes the element ids that must be matched to make the modification mfeasible.
function preattrs m id returns the attribute name on element idthat must be matched to make the modification mfeasible whereid preids m .
in our current approach we consider the following types of modifications.
insert id id prime i inserts an ast subtree rooted at id primeas theithchild of the element id.
insertstr id str i inserts the text str as theithchild of the element id.
replace id id prime replaces an ast subtree rooted at id with another ast rooted at id prime.
replacestr id str replaces an ast subtree rooted at idwith the text str.
delete id id prime deletes an ast subtree rooted at idfrom its parent id prime.
for any modification mof the above modification type preids m returns the set of element ids appearing as the argument e.g.
preids insert id id prime i id id prime authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
!
!!
!
!!
!
!
!
!!
!
!!
!
!!
!
!!
!
!
!
!
!
!
!
!!
fig.
.
transformation instance inferred from the first case in listing and its matched instance.
in the figure we use ... to represent omitted code content for simplicity.
besides the ancestor relations are omitted as well.
preattrs m id always returns ast node type for any id preids m as we need to keep consistency of the node type to ensure the ast is well formed.
in our running example the change can be captured by the modification delete p4 p2 while preids requiresp4andp2 to be matched and preattrs requires the matched elements have the same ast node types.
finally we give the definition of a transformation.
definition transformation .a transformation is a pair angbracketleftg vectorm angbracketright wheregis a code hypergraph and vector mis a sequence of modifications such that for any m vector m id preids m andattrname preattrs m id there exists an element angbracketleftid prime attrs prime angbracketrightingsuch that id id primeandattrs primecontains attrname .
given a code hypergraph g prime angbracketlefte prime r prime angbracketright a transformation angbracketleftg vectorm angbracketright and a match match fromgtog prime applying the transformation generates a sequence of modifications vector m id0 id prime ... id n id prime n where angbracketleftid0 id prime angbracketright ... angbracketleftidn id prime n angbracketright match .
in other words the element ids in original sequence of modifications are replaced by the matched element ids.
then we apply the sequence of modifications to obtain the changed code.
v. t hegenpatapproach based on the framework we can now proceed to our approach.
given two code snippets before and after the change our approach extracts a code hypergraph from the snippet before the change extracts a sequence of modifications by comparing the two snippets infers a transformation by selecting elements and attributes from the hypergraph and matches and applies the transformation when given a new code snippet.
in this section we introduce how we implement the four components.
a. extracting hypergraphs to extract the hypergraph we need to extract the elements their attributes and their relations.
in our current implementation we extract them as follows.
elements.
we parse the code and extract the ast nodes.
ast node type content parent relation ancestor relation.
we directly obtain them from the ast.
v alue type.
we apply type analysis in eclipse jdt to infer the value types of all expressions and parameters.
for the rest of the elements i.e.
statements we set its value type to .
data dependency.
we perform a simple flow insensitive intra procedural define use analysis to extract data dependency relations.
the variables are assumed to have no aliases during the analysis.
we assume the change occurs within a method and consider only the code within the method body in our current implementation.
b. extracting modifications in the current implementation we employed the gumtree algorithm to extract the modifications.
please note that the original gumtree algorithm also returns a move operation which can be combined by a deletion and an insertion using our modification types.
c. inferring transformations to infer a transformation we select elements and attributes from the hypergraph.
please note that we do not select relations in this paper and consider all relations among the selected elements.
element selection.
since the definition of the transformation requires the elements in preids i.e.
elements corresponding to the modifications to be included in the transformation we first select these elements.
next we add elements related to these elements as context.
here we follow the parent relation and the data dependency relation both forwardly and backwardly and include all elements that can be reached within klevels of the relations.
in this study we set k the default configuration .
in the future we plan to conduct a more thorough investigation of different configurations.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
for example for the program in figure we first select p2andp4since they are modified.
then following the parent relation we include p1 p3 andp5.
attribute selection.
same as elements we first add the attributes required by preattrs to form a well formed transformation.
in our example we would add the ast node type attributes of p2andp4.
then we select from other attributes in the selected elements.
for the attributes of content and value type we compute the frequency for a given attribute.
that is we collect the element content and value types from a large code corpus and then compute the cross project frequency for a given attribute.
if the frequency is larger than a threshold we select the attribute.
in current implementation we use the following formula to compute the frequency of each attribute.
in the experiment we set the threshold as .
.
freq attr f attr exists in file f all files in dataset finally we select the attribute of ast node type when the corresponding code element is a statement.
this is to avoid inconsistent matching such as matching a statement with a variable.
in the example we select the node type of p1.
d. matching and applying transformations now suppose we have a transformation t angbracketleftg vectorm angbracketright and we would like to apply the transformation to a code snippet sp.
we first transform spto a hypergraph g prime angbracketlefte prime r prime angbracketright and then find a match match fromgtog primeto perform the transformation.
in order to find the match we proceed with the following two steps.
greedily matching each element einewith all elements ine primeby considering only the attributes.
exhaustively checking all possible matching combinations generated in the first step with the relations between elements.
in our running example by considering only the attributes we can obtain the following mapping.
match p1 n1 match p2 n2 match p3 n3 match p4 n4 match p5 n2 n3 n7 then further considering the relations between elements we can filter out the extra elements for p5 forming a valid match.
match p1 n1 match p2 n2 match p3 n3 match p4 n4 match p5 n5 based on this match we can generate the following transformation on the target snippet.
delete n2 n4 it is possible that multiple matches exist for a target code snippet.
in some applications we would like to find only one match.
for example in program repair we usually assume that there is only one fault for a failed test.
as a result we need to rank the matches to find the best one.
in our current approach we use the similarity between the ast node type and the content attributes to rank the matches.node sim e e e samenodet ype e match e e text sim e e elcs tokenize e tokenize match e tokenize e score nodesim textsim in the formulas samenodetype e e prime is used to judge whether element eis with the same node type as e prime tokenize e is the tokenized sequence for the content of elemente andlcs s1 s2 computes longest common token sequence between two token lists s1ands2.
finally we use the sum of the two similarities for match ranking.
our intuition for the ranking heuristic is that if the buggy code has more common parts with the pattern code more confidence can be gained to apply the transformation.
as a result in the formulas we consider both the node type and token sequence similarity information since they correspond to code syntax and semantics respectively.
vi.
e v alua tion to evaluate the effectiveness of g enpat we choose two application scenarios systematic editing section vi a and automatic program repair section vi b .
a. systematic editing subjects we employ two datasets in our evaluation both collected in existing studies for evaluating systematic editing.
the first one is the s ydit dataset collected by meng et al.
.
the second one is the dataset collected by kreutzer et al.
which we call c3.
both datasets contain similar changes collected from commits in open source projects where all modifications within a method in a commit are considered as a change.
the difference is how they measure similarity s ydit uses changedistiller to extract changes for method pairs and requires they share at least one common syntactic edit and their content is at least similar and c3represents a code change as a list of edit operations and then clusters the changes by calculating distances over the feature vector of code changes.
the s ydit dataset consists of pairs of similar changes.
for each pair one change is used for pattern extraction and the other one is used to test the extracted transformation.
the c3 dataset consists of clusters of similar changes where each cluster may have multiple changes.
to unify the format of the two datasets we randomly select a pair from each cluster of thec3dataset.
we summarize the detailed information of the subjects in table i. procedure in this experiment we use s ydit as a baseline for comparison which is a state of the art technique that uses predefined rules for inferring program transformations.
for each pair of code changes va va prime vb vb prime in the dataset we apply g enpat and s ydit to extract the transformation from va va prime and apply the transformation authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i ev alua tion da taset for systematic editing .
dataset source project pairs sydit c3 junit cobertura jgrapht checkstyle ant fitlibrary drjava eclipsejdt eclipseswt total tovb.
if the transformation can be applied and produces vb we compare vb withvb prime.
since the complete dataset is large in this experiment the adapted code vb is considered correct only if it is syntactically identical with the ground truth vb prime.
we also sample a small proportion of the programs that are not syntactically identical to the ground truth and check its semantic equivalence manually.
for each pair we set the timeout as minute.
we also need a code corpus for calculating the frequencies of attributes.
for simplicity we use the same corpus of patches as in the second program repair experiment section vi b1 .
please note while this is not an ideal choice for systematic editing as we will see later we already achieved significantly better performance than the state of the art technique.
table ii genpa t on complete experiment da taset for systematic editing .
projects total pairs adapted syn eq sydit .
.
junit .
.
cobertura .
.
jgapht .
.
checkstyle .
.
ant .
.
fitlibrary .
.
drjava .
.
eclipsejdt .
.
eclipseswt .
.
total .
.
note the ratio in the table denotes the portion of total pairs .
in the table s ydit represents the corresponding dataset.
results first we evaluate g enpaton the complete dataset as shown in table i and the experimental results are listed in table ii.
in the table the second column shows the total number of cases for transformation in each project and the last column syn eq denotes the number ratio that genpat makes a syntactically identical adaptation among all the test cases.
we also report the number of cases that genpatcan successfully match the generated transformation to the target code shown in the third column adapted .
in total g enpatcan successfully match and produce a result on39.
cases while on .
cases the result is syntactically identical to the ground truth.
then we further compare the result of g enpat with state of the art s ydit on the same dataset.
note that we directly borrow the experimental result of s ydit on the sydit dataset as reported in the original paper .
for the other projects we successfully ran s ydit on three projects s ydit reported errors on other projects such as missing dependencies as it requires the projects compilable encountering exceptions like nullpointerexception and indexoutofboundexception etc.
.
therefore we compare the results of g enpat and s ydit on the subset of our experiment dataset where they both apply.
the details of the experimental results are listed in table iii.
please also note that s ydit requires code change pairs for transformation extraction and application coming from the same versions ref.
section vi a2 vaandvbshould come from the same project version .
to satisfy this constraint we select only those pairs in this experiment.
in table iii for each technique we report both the number ratio of cases adapted and the number ratio of cases that are transformed with syntactically identical editing columns .
particularly since the result of s ydit on the s ydit dataset is based on the semantic equivalence between the adapted code and the ground truth.
for a fair comparison we also perform a manual inspection on the results of g enpat on the s ydit dataset.
however for the other projects we compare their results based on syntactic equivalence.
from the table we can see that g enpatsignificantly outperforms sydit on the numbers of both adapted and syntactically or semantically correctly transformed cases.
overall g enpat produces .0x the adapted cases and .5x the correctly transformed cases as s ydit .i fw e consider the ratio of false positives i.e.
the cases where a transformation result is produced but not identical to the ground truth g enpat .
still significantly outperforms s ydit .
.
moreover we found that g enpatcan still achieve a much better result vs64 even only on the cases where s ydit can find a match sydit adapted .
to conclude g enpatsignificantly outperforms state of the art s ydit .
the results suggest that using predefined rules may produce undesired transformations in many cases which either cannot match or incorrectly match the target code.
considering the performance of the tools on different datasets we can find that on the s ydit dataset g enpat only slightly outperforms s ydit vs46 adapted and vs correctly transformed while on the c3dataset g enpat significantly outperforms s ydit vs495 adapted and vs64 correctly transformed .
the reason is that the sydit dataset has stricter requirements on the similarity of the changes and thus predefined rules already achieve good performance.
on the other hand c3contains more diverse pairs such that better transformation inference is needed.
please note that syntactical equivalence may not be a precise measurement as two changes may be syntactically different but authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii comparing genpat w i t h sydit on systematic editing .
dataset projects total adapted syn eq sem eq syn eq of g enpat pairs genpat sydit genpat sydit in s ydit adapted sydit .
.
.
.
c3jgrapht .
.
.
.
junit .
.
.
.
cobertura .
.
.
.
total .
.
.
.
overall .
.
.
.
in the table the ratio denotes the portion of total pairs and we use to denote missing data or directly omit .
semantically equivalent.
to further understand how much of the syntactically different cases can be semantically equivalent we perform a manual inspection on the transformed results.
since we do not have the detailed result of s ydit on its own dataset we randomly choose cases in each project from c3dataset where the transformed code is not syntactically identical with the ground truth.
as a result we choose cases for g enpatand cases for s ydit only cases in project jgrapht cf.table iii .
the results are .
semantically correct cases for g enpat while .
semantically correct cases for s ydit .
the results suggest that the number of semantically equivalent cases would be slightly higher than the syntactically equivalent cases and g enpat would probably still significantly outperform s ydit .
we further investigate the reasons why g enpat do not produce syntactically or semantically equivalent cases.
we randomly sampled cases that are not equivalent to the ground truth.
by manually analyzing these cases we found the following four main reasons.
i the dominating reason is that the dataset contains noise where the given code change examples do not conform to the target code.
in other words we cannot obtain the desired code after applying the transformation inferred from the corresponding example.
for example the given code change example is updating a variable runners tofrunners while the desired change is updating frunners torunners .
it is impossible to infer the latter transformation from the former example.
in total incorrect cases are due to this reason.
ii some types of changes are not supported by our implementation.
for example some cases change the method signature and some cases change two methods at the same time.
both situations are not supported by our current implementation.
in total cases are due to this reason.
iii our current modification types do not allow some transformations.
for example the desired transformation should insert a statement after some other statements while our modification operation only allows inserting at an absolute position i.e.
the ith child of the parent rather than a relative position.
in total cases are due to this reason.
iv our inference algorithm does not infer the correct transformation.
for example we may extract a too strong context that cannot match the target code.
in total cases are due to this reason.
note that first two reasons are notdirectly related to our approach.
the latter two reasons point out future directions to further develop the approach.
in other words with a better implementation our approach may show even better results.
b. automated program repair our second experiment aims to explore the capability of repairing real world bugs using g enpat.
in this experiment we infer transformations from a large dataset of existing patches and then apply these transformations to repair new bugs.
subjects we prepare two datasets one of which is used as a training set for transformation extraction while the other one is used as the dataset for program repair.
for the first dataset we downloaded more than million code change examples from all open source java projects on github corresponding to all their commits from to .
in this process we leverage a set of keywords for filtering such as fix repair bug issue problem error etc.
following previous studies we further filter out code change examples involving more than five java files or six lines of source code since they may include benign changes.
moreover we remove commits in the projects to repair i.e.
defects4j projects or their forked projects to avoid using their own patches.
as a result we build a training set consisting of more than million bug fixing examples which will be used to extract transformations for program repair.
besides this dataset is used as the big code corpus for attribute selection as well where each changed file in each commit is treated as a code file.
for the second dataset we employ a commonly used benchmark defects4j v1.
which consists of realworld bugs from six open source projects.
we select bugs from defects4j for our experiment.
the reason is that g enpat is not designed to be a comprehensive and standalone repair tool and is not possible to fix many specific types of bugs e.g.
bugs requiring additional invocations of specific methods only from the current projects .
to save experiment time we filtered these bugs that cannot be fixed and used the remaining bugs.
the details of the benchmark are listed in table iv.
procedure as suggested by existing studies that same bug fixes may recursively exist among the historical bug fixes.
to avoid repetitive computation we first authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv ev alua tion benchmark for program repair .
project bugs kloc tests jfreechart chart closure compiler closure apache commons math math apache commons lang lang joda time time mockito mockito total in the table column bugs denotes the total number of bugs used in our evaluation column kloc denotes the number of thousands of lines of code and column tests denotes the total number of test cases for each project.
perform a transformation clustering which collects the same transformations together to form a cluster.
in this process two transformations belong to the same cluster only if they can match each other and they have the same modifications.
as a result after clustering unique transformation clusters are left which are finally employed for patch generation.
following existing apr techniques we first leverage an existing fault localization framework to obtain a ranked list of candidate faulty locations.
particularly we employ the ochiai spectrum based fault localization to compute suspicious scores.
however the fault localization result is at the statement level while g enpatmatches a code snippet rather than a single line.
therefore we further apply method level aggregation to obtain a ranked list of faulty methods from statement level results since it has been demonstrated to outperform direct method level fault localization .
given a faulty method g enpatlocates a set of transformations whose attributes can be found in the faulty method.
then transformations will be ranked according to the size of corresponding clusters.
thereafter g enpattries to apply each transformation to a given faulty method and generates patches.
in the matching process we discard matches that involve no elements in a faulty line in the method.
in our experiment we collect at most compilable patches for each faulty method and then rank them with the ranking method introduced in the approach section v d .
finally we validate each candidate patch with the test suites and set a timeout of hours to repair one bug.
in this paper following recent repair work we consider a patch as correct only if it is semantically equivalent to the developer s patch in defects4j with manual check.
results in this section we present the experimental result of g enpaton repairing real world bugs and compare it with state of the art apr techniques that are recently published on se conferences.
the results are shown in table v. in the table we listed the number of bugs correctly fixed by each technique when considering top k k plausible patches.
we use to represent those missed data.
from the table we can observe that surprisingly although g enpatis not designed as a comprehensive and standalone repair technique it still successfully repairs bugs when only considering top plausible patch even outperforming some recent approaches such as sketchfix and jaid.
when considering top plausible patches g enpatcan successfully repair bugs.
moreover among all the bugs fixed by g enpat bugs have never been fixed by any existing technique as far as we know such as the example shown in listing .
the results demonstrate that it is possible to repair real world bugs by learning executable program transformations from historical bug fixes directly.
furthermore the results also suggest that it would be promising to consider integrating g enpatwhen designing advanced apr techniques to repair more bugs which calls for future research in this direction.
table v comparing genpat w i t h s tat e of the art apr techniques .
conf.
tech.
top pos.
top pos.
issta prapr issta simfix icse sketchfix icse capgen ase jaid icse acs saner hd repair genpat in an investigation of the patches we found that the fixed bugs are often non trivial and may not be easily fixed by approaches with a predefined search space.
for example listing shows the patch for lang which is successfully generated by applying the transformation extracted from the example in listing .
it is not easy to predefine a search space to include this constant replacement.
cal1.get calendar .minute cal2.get calendar .minute cal1.get calendar .hour cal2.get calendar .hour cal1.get calendar .hour of day cal2.get calendar .
hour of day cal1.get calendar .year cal2.get calendar .year listing .
patch of lang .
commit github.com cbsoftware pressurenet commit 9d00742 message fixing time display bugs source src.ca.cumulonimbus.barometernetwork.barxxactivity if start.get calendar .hour end.get calendar .
hour if start.get calendar .hour of day end.get calendar .hour of day listing .
referenced history patch to fix lang .
meanwhile though g enpatis promising to repair realworld bugs it still faces challenges.
in our experiment g enpat generates plausible but incorrect patches for other bugs among all bugs.
compared with some state ofthe art techniques such as simfix and capgen the repair precision of g enpatis slightly lower.
by analyzing those incorrect patches we found that the reasons for its low precision are mainly threefold.
first though we have already preprocessed the training dataset for transformation extraction authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
there still exist code changes that are not relevant to bug fixes which may produce incorrect patches.
second the inferred transformation is too general and can be applied frequently such as inserting a return statement in an ifbody.
since genpatonly expands one level dependency relation the generated transformation can be applied wherever there is an if statement and can easily introduce incorrect patches.
third genpatis not designed to be a standalone repair tool and thus does not include the patch correctness checking mechanisms that mature tools use.
in the future recent advanced patchcorrectness checking techniques can also be further integrated with g enpatto mitigate this issue.
vii.
t hrea ts to v alidity in this section we discuss the threats to validity of g enpat.
first the external threats to the validity fall into the data collection in our evaluation.
we employed a subset of the c3 data set i.e.
we choose one pair of similar code changes from each cluster for the experiment which may cause data selection bias.
however to mitigate this threat we employed all clusters in the data set shown in table i with a random sample which leaves us pairs of examples.
we believe that this big dataset can alleviate the threats.
on the other hand since the dataset is constructed automatically by previous research which may involve noises as discussed in the previous section.
as a consequence we employed the manually constructed dataset as well in our evaluation which can mitigate this issue to some extent.
second the internal threats to validity are related to the implementation of g enpat.
to ensure the correctness of its implementation two authors of the paper collaborate with code review to make sure all functions are properly implemented.
however it is still possible to unintentionally get some implementation bugs involved.
to further reduce this threat we have also released both the source and test code of g enpat as well as the replication package and invite other researchers to contribute to this promising direction.
viii.
c onclusion in this paper we propose a framework for transformation inference from a single example by representing code as a hypergraph which allows fine grained generalization of transformations with big code.
based on this framework we further propose a transformation inference algorithm and implement it in a tool called g enpat.
finally we evaluated the effectiveness of g enpatin two distinct application scenarios i.e.
systematic editing and automatic program repair.
the experimental results show that g enpatsignificantly outperforms the state of the art s ydit with up to .5x correctly transformed cases in the first application.
additionally although not designed as a comprehensive and standalone repair technique genpatalready shows potentialities in automatic program repair it successfully fixed bugs in the defects4j benchmark of which have never been repaired by any existing technique.
in all the evaluation results suggest that g enpat is effective and potentially can be adopted in many differentapplications.
on the other hand in the current implementation we do not consider the context information while computing the attribute frequencies which potentially can further improve the quality of the inferred transformations.
also there are also other attributes and relations besides those considered in our current implementation such as the node position attributes in ast or control dependency relations both of which may impact the quality of inferred program transformations.
we leave a more thorough investigation to these variations to our future study.
acknowledgment this work was partially supported by the national key research and development program of china under grant no.2017yfb1001803 national natural science foundation of china under grant nos.
and and national science foundation under grant nos.
ccf and ccf and amazon.
special thanks should go to xia li ut dallas who shared the big code base with us making it possible to conduct our large scale evaluation.