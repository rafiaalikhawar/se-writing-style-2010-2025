applications of psychological science for actionable analytics di chen wei fu rahul krishna tim menzies north carolina state university usa raleigh nc dchen20 wfu rkrish11 ncsu.edu tim.menzies gmail.com abstract actionable analytics are those that humans can understand and operationalize.
what kind of data mining models generate such actionable analytics?
according to psychological scientists humans understand models that most match their own internal models which they characterize as lists of heuristic i.e.
lists of very succinct rules .
one such heuristic rule generator is the fast andfrugal trees fft preferred by psychological scientists.
despite their successful use in many applied domains ffts have not been applied in software analytics.
accordingly this paper assesses ffts for software analytics.
we find that ffts are remarkably effective.
their models are very succinct lines or less describing a binary decision tree .
these succinct models outperform state of the art defect prediction algorithms defined by ghortra et al.
at icse .
also when we restrict training data to operational attributes i.e.
those attributes that are frequently changed by developers ffts perform much better than standard learners.
our conclusions are two fold.
firstly there is much that software analytics community could learn from psychological science.
secondly proponents of complex methods should always baseline those methods against simpler alternatives.
for example ffts could be used as a standard baseline learner against which other software analytics tools are compared.
keywords decision trees heuristics software analytics psychological science empirical studies defect prediction acm reference format di chen wei fu rahul krishna tim menzies.
.
applications of psychological science for actionable analytics.
in proceedings of florida fse .
acm new york ny usa pages.
introduction data mining tools have been applied to many applications in software engineering se .
for example it has been used to estimate how long it would take to integrate new code into an existing project where defects are most likely to occur or how long will it take to develop a project etc.
large organizations like microsoft routinely practice data driven policy permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for third party components of this work must be honored.
for all other uses contact the owner author s .
fse nov copyright held by the owner author s .
acm isbn zz yy zz qq a. .
.
.
where organizational policies are learned from an extensive analysis of large datasets .
despite these successes there exists some drawbacks with current software analytic tools.
at a recent workshop on actionable analytics at ase business users were very vocal in their complaints about analytics saying that there are rarely producible models that business users can understand or operationalize.
accordingly this paper explores methods for generating actionable analytics for software defect prediction predicting close time for github issues.
there are many ways to define actionable but at the very least we say that something is actionable if people can read andusethe models it generates.
hence for this paper we assume actionable comprehensible operational.
we show here that many algorithms used in software analytics generate models that are not actionable.
further a data mining algorithm taken from psychological science called fast and frugal trees ffts1 are very actionable.
note that demanding that analytics be actionable also imposes certain restrictions on a the kinds of models that can be generated and b the data used to build the models.
a drawing on psychological science we say an automatically generated model is comprehensible if the model matches the models used internally by humans i.e.
it comprises small rules.
further for expert level comprehension the rules should quickly lead to decisions thus freeing up memory for other tasks .
for more on this point see section .
.
b as to operational we show in the historical log of software projects that only a few of the measurable project attributes are often changed by developers.
for a data mining algorithm to be operational it must generate effective models even if restricted to using just those changed attributes.
using three research questions this paper tests if these restrictions damage our ability to build useful models.
rq1 do ffts models perform worse than the current stateof the art?
we will find that 1the reader might be aware that fft is also an acronym for fast fourier transform .
apparently the psychological science community was unaware of that acronym when they named this algorithm.arxiv .05067v1 mar 2018fse nov di chen wei fu rahul krishna tim menzies when compared to state of the art defect prediction algorithms surveyed by ghotra et al.
ffts are more effective where effective is measured in terms of a recall false alarm metric or the poptmetric defined in .
.for defect prediction ffts out perform the state of art.
rq2 are ffts more operational than the current state ofthe art?
this research question tests what happens when we learn from less data i.e.
if we demand our models avoid using attributes that are rarely changed by developers.
we show that when data is restricted to attributes that developers often change then ffts performance is only slightly changed while the performance of some other learners can vary by alarmingly large amounts.when learning from less data ffts performance is stabler than some other learners.
the observed superior performance of fft raises the question rq3 why do ffts work so well?
our answer to this question will be somewhat technical but in summary we will say se data divides into a few regions with very different properties and ffts are good way to explore such data spaces.ffts match the structure of se data in summary the contributions of this paper are a novel inter disciplinary contribution of the application of psychological science to software analytics.
a cautionary tale that for software analytics more complex learners can perform worse .
a warning that many current results in software analytics make the possibly unwarranted assumption that merely because an attribute is observable that we should use those attributes in a model.
three tests for actionable analytics a does a data mining produce succinct models?
b do those succinct models perform as well or better than more complex methods?
c if the data mining algorithm is restricted to just the few attributes that developers actually change does the resulting model perform satisfactorily?
a demonstration that the restraints demanding by actionable analytics very simple models access to less data need not result in models with poor performance.
a new very simple baseline data mining method ffts against which more complex methods can be compared.
a reproduction package containing all the data and algorithms of this paper see the rest of this paper is structured as follows.
in section we introduce the concepts of operational and comprehensible as the preliminaries.
our data experimentation settings and evaluation measures will be described in section .
in section we show our results and answer to research questions.
threats and validity of our work is given in section .
in section we conclude this paper with the following figure only some metrics change between versions iand i 1of a software system.
for definitions of the metrics on the x axis see table .
to create this plot we studied the versions of the ten datasets in table .
first we initializetotal then for all pairs of versions i i 1from the same data set we a incremented total by one b collected the distributions of metric mseen in version iand i 1of the software c checked if those two distributions were different and if so d added one to changed m. afterwards the y axis of this plot was computed using changed m total.
there is much the software analytics community could learn from psychological science.
proponents of complex methods should always baseline those methods against simpler alternatives.
finally we discuss future work.
preliminaries .
operational this paper assumes that for a data mining algorithm to be operational it must generate effective models even if restricted to using just those attributes which in practice developers actually change.
we have two reasons for making that assumption.
firstly this definition of operational can make a model much more acceptable to developers.
if a model says that say x .
leads to defective code then developers will ask for guidance on how to reduce x in order to reduce the chances of defects .
if we define operational as per this article then it is very simple matter to offer that developer numerous examples from their own project s historical log of how x was changed.
secondly as shown in figure there exist attributes that are usually not changed from one version to the next.
figure is important since as shown in our rq2 results when we restrict model construction to just the most frequently changed attributes this can dramatically change the behavior of some data mining algorithms but not ffts .applications of psychological science for actionable analytics fse nov technical aside in figure we defined changed using the a12 test which declares two distributions different if they differ by more than a small effect.
a recent icse article endorsed the use of a12 due to its non parametric nature it avoids any possibly incorrect gaussian assumptions about the data.
.
comprehensible why demand comprehensibility?
this paper assumes that better data mining algorithms are better at explaining their models to humans.
but is that always the case?
the obvious counter argument is that if no human ever needs to understand our audited model then it does not need to be comprehensible.
for example a neural net could control the carburetor of an internal combustion engine since that carburetor will never dispute the model or ask for clarification of any of its reasoning.
on the other hand if a model is to be used to persuade software engineers to change what they are it needs to be comprehensible so humans can debate the merits of its conclusions.
several researchers demand that software analytics models needs to be expressed in a simple way that is easy for software practitioners to interpret .
according to kim et al.
software analytics aim to obtain actionable insights from software artifacts that help practitioners accomplish tasks related to software development systems and users.
other researchers argue that for software vendors managers developers and users such comprehensible insights are the core deliverable of software analytics.
sawyer et al.
comments that actionable insight is the key driver for businesses to invest in data analytics initiatives .
accordingly much research focuses on the generation of simple models or make blackbox models more explainable so that human engineers can understand and appropriately trust the decisions made by software analytics models .
if a model is not comprehensible there are some explanation algorithms that might mitigate that problem.
for example insecondary learning the examples given to a neural network are used to train a rule based learner and those learners could be said to explain the neural net .
incontrast set learning for instance based reasoning data is clustered and users are shown the difference between a few exemplars selected from each cluster .
such explanation facilities are post processors to the original learning method.
an alternative simpler approach would be to use learners that generate comprehensible models in the first place.
the next section of this paper discusses one such alternate approach for creating simple comprehensible models.
theories of expert comprehension.
psychological science argues that models comprising small rules are more comprehensible.
this section outlines that argument.
larkin et al.
characterize human expertise in terms of very small short term memory or stm used as a temporary scratch pad for current observation and a very large long term memory or ltm.
the ltm holds separate tiny rule fragments that explore the contents of stm to say when you see this do that .
when an ltm rule triggers its consequence can rewrite stm contents which in turn can trigger other rules.short term memory is very small perhaps even as small as four to seven items .
experts are experts says larkin et al.
because the patterns in their ltm patterns dictate what to do without needing to pause for reflection.
novices perform worse than experts says larkin et al.
when they fill up their stm with too many to do s where they plan to pause and reflect on what to do next.
since experts post far fewer to do s in their stms they complete their tasks faster because a they are less encumbered by excessive reflection and b there is more space in their stm to reason about new information.
while first proposed in this stm ltm theory still remains relevant .
this theory can be used to explain both expert competency and incompetency in software engineering tasks such as understanding code .
phillips et al.
discuss how models containing tiny rule fragments can be quickly comprehended by doctors in emergency rooms making rapid decisions or by soldiers on guard making snap decisions about whether to fire or not on a potential enemy or by stockbrokers making instant decisions about buying or selling stock.
that is according to this psychological science theory humans best understand a model when they can fit it into their ltm i.e.
when that model comprises many small rule fragments further to have an expert level comprehension of some domain meaning having rules that can very quickly lead to decisions without clogging up memory.
psychological scientists have developed ffts as one way to generate comprehensible models consisting of separate tiny rules .
a fft is a decision tree with exactly two branches extending from each node where either one or both branches is an exit branch leading to a leaf .
that is to say in an fft every question posed by a node will trigger an immediate decision so humans can read every leaf node as a separate rule .
for example table at left is an fft generated from the log4j java system of table .
the goal of this tree is to classify a software module as defective true or defective false .
the four nodes in this fft reference four static code attributes cbo rfc dam amc these metrics are defined in table .
ffts are a binary classification algorithm.
to apply such classifiers to mulit classes problems a build one ffts for each class for classx or not classx b run all ffts on the test example then c then select conclusion with most support number of rows .
an fft of depth dhas a choice of two exit policies at each level the existing branch can select for the negation of the target denoted or the target denoted .
the left hand side log4j tree in table is hence an tree since the first level exits to the negation of the target hence .
while the next tree levels exit first to target hence .
and the final line of the model exits to the opposite of the penultimate line hence the final .
to build one fft tree select a maximum depth d then follow the steps described in table for trees of depth d there are 16possible trees which we denoted ... .
here the first four digits 2recently ma et al.
used evidence from neuroscience and functional mris to argue that stm capacity might be better measured using other factors than number of items .
but even they conceded that the concept of a limited stm has considerable explanatory power for behavioral data .fse nov di chen wei fu rahul krishna tim menzies table the c k oo metrics studied in figure .
note that the last line.
defect denotes the dependent variable.
metric name description amc average method complexity number of java byte codes avg cc average mccabe average mccabe s cyclomatic complexity seen in class ca afferent couplings how many other classes use the specific class.
cam cohesion amongst classes summation of number of different types of method parameters in every method divided by a multiplication of number of different method parameter types in whole class and number of methods.
cbm coupling between methods total number of new redefined methods to which all the inherited methods are coupled cbo coupling between objects increased when the methods of one class access services of another.
ce efferent couplings how many other classes is used by the specific class.
dam data access ratio of private protected attributes to total attributes dit depth of inheritance tree it s defined as the maximum length from the node to the root of the tree ic inheritance coupling number of parent classes to which a given class is coupled includes counts of methods and variables inherited lcom lack of cohesion in methods number of pairs of methods that do not share a reference to an instance variable.
locm3 another lack of cohesion measure ifm aare the number of methods attributes in a class number and a is the number of methods accessing an attribute then lcom a a j aj m m .
loc lines of code total lines of code in this file or package.
max cc maximum mccabe maximum mccabe s cyclomatic complexity seen in class mfa functional abstraction number of methods inherited by a class plus number of methods accessible by member methods of the class moa aggregation count of the number of data declarations class fields whose types are user defined classes noc number of children number of direct descendants subclasses for each class npm number of public methods npm metric simply counts all the methods in a class that are declared as public.
rfc response for a class number of methods invoked in response to a message to the object.
wmc weighted methods per class a class with more member functions than its peers is considered to be more complex and therefore more error prone defect defect boolean where defects found in post release bug tracking systems.
table three example ffts.
if cob then false else if rfc then true else if dam then true else if amc .
then true else false 0if cbo then true else if max cc then true else if wmc then true else if rfc .
then true else false 0if dam then false else if noc then false else if wmc then false else if moa then false else true denote the exit policies and the last digit denotes the last line of the model which makes the opposite conclusion to the line above .
for example a tree does it all it can to avoid the target class.
only after clearing away all the non defective examples it can at levels one two three four does it make a final true conclusion.
table right shows the log4j tree.
note that all the exits except the last are to false .
as to trees these fixate on finding the target.
table center shows the log4j tree.
note that all the exits except the last are to true .
during fft training we generate all 2dtrees then using the predicate score select the best one using the training data .
this single best tree is then applied to the test data.
table some open source java systems.
used for training and testing showing different details for each.
all data available on line at training testing data set versions cases versions cases defective jedit .
.
.
.
.
ivy .
.
.
camel .
.
.
.
synapse .
.
.
velocity .
.
.
lucene .
.
.
poi .
.
.
xerces .
.
.
.
log4j .
.
.
xalan .
.
.
.
99following the advice of for all the experiments of this paper we use a depth d .
note that ffts of such small depths are very succinct see above examples .
many other data mining algorithms used in software analytics are far less succinct and far less comprehensible see table .
the value of models such as ffts comprising many small rules has been extensively studied these models use very few attributes from the data.
hence they tend to be robust against overfitting especially on small and noisy data and have been found to predict data at levels comparable with regression.
see for example .
table steps for building ffts first discretize all attributes e.g.
split numerics on median value.
for each discretized range find what rows it selects in the training data.
using those rows score each range using some user supplied score function e.g.
recall false alarm or the popt defined in .
.
divide the data on the best range.
if the exit policy at this level is then exit to false true using the range that scores highest assuming that the target class is false true respectively.
if the current level is at d add one last exit node predicting the opposite to step .
then terminate.
else take the data selected by the non exit range and go to step1 to build the next level of the tree.applications of psychological science for actionable analytics fse nov table comprehension issues with models generated by data mining algorithms used in software analytics.
for very high dimensional data there is some evidence that complex deep learning algorithms have advantages for software engineering applications .
however since they do not readily support explainability they have been criticizing as data mining alchemy .
support vector machines and principle component methods achieve their results after synthesizing new dimensions which are totally unfamiliar to human users .
other methods that are heavily based on mathematics can be hard to explain to most users.
for example in our experience it is hard for e.g.
users to determine minimal changes to a project that mostly affect defect proneness just by browsing the internal frequency tables of a naive bayes classifier or the coefficients found via linear regression logistic regression .
when decision tree learners are many pages long they are hard to browse and understand .
random forests are even harder to understand than decision trees since the problems of reading one tree are multiplied ntimes one for each member of the forest .
instance based methods do not compress their training data instead they produce conclusions by finding older exemplars closest to the new example.
hence for such instance based methods it is hard to generalize and make a conclusion about what kind of future projects might be e.g.
most defective prone .
other work has shown that these rule based models can perform comparably well to more complex models in a range of domains e.g.
public health medical risk management performance science etc.
.
neth and gigerenzer argue that such rule bases are tools that work well under conditions of uncertainty .
brighton showed that rule based models can perform better than complex nonlinear algorithms such as neural networks exemplar models and classification regression trees .
methods the use of models comprising many small rules has not been explored in the software analytics literature.
this section describes the methods used by this paper to assess ffts.
.
data .
.
defect data to assess the ffts we perform our experiments using the publicly available seacraft data gathered by jureczko et al.
for object oriented java systems .
the jureczko data records the number of known defects for each class using a post release defect tracking system.
the classes are described in terms of nearly two dozen metrics such as number of children noc lines of code loc etc see table .
for details on the jureczko data see table .
the nature of collected data and its relevance to defect prediction is discussed in greater detail by madeyski jureczko .table metrics used in issue lifetimes data commit comment issue ncommitsbyactorst meancommentsizet issuecleanedbodylen ncommitsbycreator ncomments nissuesbycreator ncommitsbyuniqueactorst nissuesbycreatorclosed ncommitsinproject nissuescreatedinproject ncommitsprojectt nissuescreatedinprojectclosed nissuescreatedprojectclosedt nissuescreatedprojectt misc.
nactors nlabels nsubscribedbyt we selected these data sets since they have at least three consecutive releases where release i 1was built after release i .
this is important for our experimental rig see section .
.
.
.
issue lifetime data this paper will conclude that ffts are remarkable effective.
to check the external validity of that conclusion we will apply fft to another se domain .
our github issue lifetime data3consists of projects used to study issue lifetimes.
in raw form the data consisted of sets of json files for each repository each file contained one type of data regarding the software repository issues commits code contributors changes to specific files as shown in table .
in order to extract data specific to issue lifetime we did similar preprocessing and feature extraction on the raw datasets as suggested by .
.
experimental rig for the defect prediction data we use versions i j kof the software systems in table .
using versions i j we track what attributes change by from version itoj using the calculation shown in figure .
then we build a model using allthe attributes from version jor just the top most changed attributes.
note that this implements our definition of operational as discussed in our introduction.
after building a model we use the latest version kfor testing while the older versions for training.
in this way we can assert that all our predictions are using past date to predict the future.
for the issue lifetime data we do not have access to multiple versions of the data.
hence for this data we cannot perform the operational test.
hence for that data we conduct a crossvalidation experiment that ensures that the train and test sets are different.
for that cross val we divide the data into ten bins then for each bin biwe train on data bithen test on bin bi.
to control for order effects where the conclusions are altered by the order of the input examples this process is repeated five times using different random orderings of the data.
.
data mining algorithms the results shown below compare ffts to state of the art algorithms from software analytics.
for a list of state of algorithms we used the icse paper from ghotra et al.
which compared classifiers for defect prediction.
their statistical analysis showed that the performance of these classifiers clustered into four groups shown in table .
for our work we selected one classifier at random from each of their clusters i.e.
simple logistic sl naive bayes nb nov di chen wei fu rahul krishna tim menzies table for the purposes of predicting software defects ghotra et al.
found that many learners have similar performance.
here are their four clusters of data mining algorithms.
for our work we selected learners at random one from each cluster see the underlined entries .
overall rankclassification techniquemedian rankaverage rankstandard deviation 1rsub j48 sl rsub sl bag sl lmt rf sl rf j48 bag lmt rsub lmt and rf lmt1.
.
.
2rbfs bag j48 ad sl knn rf nb ad lmt nb rsub nb and bag nb2.
.
.
3ripper em j48 ad nb bag smo ad j48 ad smo and k means5.
.
.
4rf smo ridor smo and rsub smo6.
.
.
expectation maximization em sequential minimal optimization smo .
simple logistic and naive bayes falls into the 1st and 2nd rankings layers.
they are both statistical techniques that are based on a probability based model .
these techniques are used to find patterns in datasets and build diverse predictive models .
simple logistic is a generalized linear regression model that uses a logit function.
naive bayes is a probability based technique that assumes that all of the predictors are independent of each other.
clustering techniques like em divide the training data into small groups such that the similarity within groups is more than across the groups .
em is a clustering technique based on cluster performance expectation maximization em technique which automatically splits a dataset into an approximately optimal number of clusters .
support vector machines svms use a hyperplane to separate two classes i.e.
defective or not .
in this paper following the results of ghotra et al.
we use the sequential minimal optimization smo svm technique.
smo analytically solves the large quadratic programming qp optimization problem which occurs in svm training by dividing the problem into a series of possible qp problems .
.
evaluation measures our rig assess learned models using an evaluation function called score .
for ffts this function is called three times once to rank discretized ranges then once again to select the best fft out of the 2dtrees generated during training.
then finally score is used to score what happens when that best fft is applied to the test data.
for all the other learners score is applied on the test data.
for this work we use the two score measures dis2heaven andpopt.
ideally a perfect learner will have perfect recall with no false alarms.
recall truepositive truepositive falsenegative loc0102030405060708090100 defectspopt effortoptimal learner proposed learner random learner worst learnerfigure effort based cumulative lift chart .
far falsepositive falsepositive truenegative we combine these two into a distance to heaven measure called dis2heaven that reports how far a learner falls away from the ideal point of recall andfar score dis2heaven s recall far2 as to popt ostrand et al.
report that their quality predictors can find of the files contain on average of all defects in the project.
although there is nothing magical about the number it has been used as a cutoff value to set the efforts required for the defect inspection when evaluating the defect learners .
that is poptreports how many defects have been found after a the code is sorted by the learner from most likely to be buggy to least likely then b humans inspect of the code measured in lines of code where that code has how many defects can be detected by the learner.
this measure is widely used in defect prediction literature .
poptis defined as opt where optis the area between the effort cumulative lift charts of the optimal model and the prediction model as shown in figure2 .
in this chart the x axis is the percentage of required effort to inspect the code and the y axis is the percentage of defects found in the selected code.
in the optimal model all the changes are sorted by the actual defect density in descending order while for the predicted model all the changes are sorted by the actual predicted value in descending order.
according to kamei et al.
and xu et al.
poptcan be normalized as follows score popt m s optimal s m s optimal s worst where s optimal s m ands worst represent the area of curve under the optimal model predicted model and worst model respectively.
this worst model is built by sorting all the changes according to the actual defect density in ascending order.applications of psychological science for actionable analytics fse nov note that for our two score functions fordis2heaven the lower values are better .
forpopt the higher values are better .
results .
rq1 do ffts models perform worse than the current state of the art?
figure compares the performance of fft versus learners taken from ghotra et al.
in this figure datasets are sorted left right based on the fft performance scores.
with very few exceptions fft s dis2heaven s results lower hence better than the other learners.
fft s poptresults are much higher hence better than the other learners.
therefore our answer to rq1 is when compared to state of the art defect prediction algorithms surveyed by ghotra et al.
ffts are more effective where effective is measured in terms of a recall false alarm metric or popt .for defect prediction ffts out perform the state of art.
.
rq2 are ffts more operational than the current state of the art?
please recollect from before that a model is operational if its performance is not affected after avoiding attributes that are rarely changed by developers.
figure compares model performance when we learn from all attributes or just the most changed attributes.
for this study these group of most changed attributes was computed separately for each data set.
note that the top row of figure shows the dis2heaven results the bottom row of figure shows the poptresults.
figure reports the deltas in performance scores seen between using and of the data.
these deltas are computed such that larger values are better i.e.
for dist2heaven popt we report since fewer more values are better respectively .
there are several key features for these results the fft s red dots for dis2heaven arebelow the rest also fft s orange dots for poptareabove the rest.
this means that regardless of whether we use all attributes or just the most changed attributes the fft results are nearly always better than the other methods.
as seen in figure the deltas between using all data and just some of the data is smallest for ffts and em the instance based clustering algorithm .
in popt those deltas are very small indeed the fft and em results lie right on the y axis for most of that plot .
also see in figure the deltas on the other learners can be highly variable.
while for the most part using just the most changed attributes improves performance smo sl and nb all have large negative results for at least some of the data sets.
in summary the learners studied here fall into three groups table frequency heatmap of best exit polices seen for fft and defect prediction.
best fff exit policy d2h popt d2h popt totals those that exhibited a wide performance variance after restricting the learning to just the frequently changed data sl nb smo and those that are not fft em those with best performance across the two performance measures studied here fft and the rest sl nb em smo those that generate tiny models fft and the rest sl nb em smo .
accordingly fft is the recommended learner since it both performs well and is unaffected by issues such as whether or not the data is restricted to just the most operational attributes.
in summary when data is restricted to attributes that developers often change then ffts performance is only slightly changed while the performance of some other learners can vary by alarmingly large amounts.when learning from less data ffts performance is stabler than some other learners.
.
rq3 why do ffts work so well?
to explain the success of ffts recall that during training ffts explores 2dmodels then selects the models whose exit policies achieves best performances exit policies were introduced in section .
.
the exit policies selected by ffts are like a trace of the reasoning jumping around the data.
for example a policy shows a model always jumping towards sections of the data containing most defects.
also a policy show another model trying to jump away from defects until in its last step it does one finalfse nov di chen wei fu rahul krishna tim menzies figure on the left in the dis2heaven results less isbetter .
on the right in the poptresults more isbetter .
on both sides the ffts results are better than those from state of the art defect prediction algorithms as defined by ghotra et al.
.
figure for each learner in figure this plot shows the difference between the results obtains using the top or all of attributes.
for dist 2heaven popt values that are lesser greater respectively are better .
note that all the results were also shown in figure .
jump towards defects.
table shows what exit policies were seen in the experiments of the last section the policy was used sometimes.
a more common policy is which shows a tree first jumping to some low hanging fruit see the first then jumping away from defects three times see the next before a final jump into defects see the last .
that said while was most common many other exit policies appear in table .
for example the poptpolicies are particularly diverse.table suggests that software data is lumpy i.e.
it divides into a few separate regions each with different properties.
further the number and importance of the lumps is specific to the data set and the goal criteria.
in such a lumpy space a learning policy like fft works well since its exit policies let a learner discover how to best jump between the lumps .
other learners fail in this coarse grained lumpy space when they divide the data too much e.g.
like randomforests which finely divide the data multiple times down the branches of the trees and across multiple trees applications of psychological science for actionable analytics fse nov figure deltas between results and of the data.
computed from figure .
calculated such that larger values are better i.e.
for dist2heaven popt we report since less more values are better respectively .
all values for each learner are sorted independently.
fit some general model across all the different parts of the data e.g.
like simple logistic regression.
in summary in answer to the question why do ffts work so well we reply se data divides into a few regions with very different properties and ffts are good way to explore such data spaces.ffts match the structure of se data threats to validity .
sampling bias this paper shares the same sampling bias problem as every other data mining paper.
sampling bias threatens any classification experiment what matters in one case may or may not hold in another case.
for example even though we use open source datasets in this study which come from several sources they were all supplied by individuals.
as researchers we can adopt two tactics to reduce the sampling bias problem.
first we can document our tools and methods then post an executable reproduction package for all the experiments that package for this paper is available at url blind for review .
secondly when new data becomes available we can test our methods on the new data.
for example table shows results were ffts and four different state of the art learners i.e.
decision tree random forest logistic regression k nearest neighbors were applied to the task of predicting issue close time the other four learners were used since that was the technology recommended in a recent study in that domain .
unlike the defect predictiontable which learners performed better in terms of median dis2heaven in cross value experiments predicting for different classes of how long to close an github issue .
gray areas denote experiments where ffts were outperformed by other learners.
note that in experiments fft performed better than the prior state of the art in this area .
days till closed data of instances cloudstack fft fft fft fft fft dt lr node fft fft fft fft fft dt lr deeplearning fft fft fft fft fft fft rf cocoon fft fft fft fft fft fft fft ofbiz fft fft fft fft fft fft fft camel rf knn knn fft knn dt fft fft fft fft hadoop knn dt dt fft fft fft fft qpid dt dt rf dt fft fft fft fft the goal here is to classify an issue according to how long it will take to close i.e.
less than day less than days and so on.
values collected via a 5x10 cross validation procedure.
cells with a white gray background means ffts are statistically better worse than all any of the state of the art learners as determined by a mann whitney test confidence respectively.
knn dt rf and lr represents k nearest neighbors decision tree random forest and logistic regression respectively.
data we did not have multiple versions of the code so for this domain we used a way cross validation analysis.
white cells show where the fft results were statistically different and better than all of the state of the art learners results.
note that in most cases ffts performed better.
while this result does not prove that ffts works well in all domains it does show that there exists more than one domain where this is a useful approach.
.
learner bias for building the defect predictors in this study we elected to use simple logistic naive bayes expectation maximization support vector machine.
we chose these learners because past studies shows that for defect prediction tasks these four learners represents four different levels of performance among a bunch of different learners .
thus they are selected as the state of the art learns to be compared with ffts on the defect prediction data.
while for table k nearest neighbors decision tree random forest and logistic regression are used to compare against ffts because a recent work has summarized all the best learners that were applied on the issue lifetime data.
.
evaluation bias this paper uses two performance measures i.e.
poptanddist 2heaven as defined in equation and .
other quality measures often used in software engineering to quantify the effectiveness of prediction .
a comprehensive analysis using these measures may be performed with our replication package.
additionally other measures can easily be added to extend this replication package.
.
order bias for the performance evaluation part the order that the data trained and predicted affects the results.
for the defect prediction datasets we deliberately choose an ordering that mimics how our software projects releases versionsfse nov di chen wei fu rahul krishna tim menzies so for those experiments we would say that bias was a required and needed.
for the issue close time results of table to mitigate this order bias we ran our rig in a the bin cross validation times randomly changing the order of the data each time.
conclusions this paper has shown that a data mining algorithm call fast andfrugal trees ffts developed by psychological scientist is remarkably effective for creating actionable software analytics.
here actionable was defined as a combination of comprehensible and operational.
measured in terms of comprehensibility the fft examples of table show that ffts satisfy requirements raised by psychological scientists for easily understandable at an expert level i.e.
they comprise several short rules and those rules can be quickly applied recall that each level of an fft has an exit point which if used means humans can ignore the rest of the tree .
despite their brevity ffts are remarkably effective measured in terms of popt ffts are much better than other standard algorithms see figure .
measured in terms of distance to the heaven point of recall and no false alarms ffts are either usually better than other standard algorithms used in software analytics random forests naive bayes em logistic regression and svm .
this result holds for at least two se domains defect prediction see figure issue close time prediction see table .
as to being operational we found that if learning is restricted to just the attributes changed most often then the behavior of other learning algorithms can vary wildly see figure .
the behaviour of ffts on the other hand remain remarkable stable across that treatment.
from the above our conclusions is two fold there is much the software analytics community could learn from psychological science.
ffts based on psychological science principles out perform a wide range of learners in widespread use.
proponents of complex methods should always baseline those methods against simpler alternatives.
for example ffts could be used as a standard baseline learner against which other software analytics tools are compared.
future work numerous aspects of the above motivate deserve more attention.
.
more data this experiment with issue close time shows that ffts are useful for more just defect prediction data.
that said for future work it is important to test many other se domains to learn when ffts are useful.
for example at this time we are exploring text mining of stackoverflow data.
.
more learners the above experiments should be repeated comparing ffts against more learners.
for example at this time we are comparing fftsagainst deep learning for se datasets.
at this time there is nothing as yet definitive to report about those results.
.
more algorithm design these results may have implications beyond se.
indeed it might be insightful to another field machine learning.
for the reader familiar with machine learning literature we note that ffts are a decisionlist rule covering model.
ffts restrict the a number of conditions per rule to only one comparison and b the total number of rules is set to a small number often often just d .
other decision list approaches such as prism induct ripper and ripple down rules produce far more complex models since they impose no such restriction.
perhaps the lesson of fft is that prism induct ripper etc could be simplified with a few simple restrictions on the models they learn.
also the success of fft might be credited to its use on ensemble methods i.e.
train multiple times then select the best.
the comparison between ffts and other ensemble methods like bagging and boosting could be useful in future work.
.
applications to delta debugging there is a potential connection between the figure results and the delta debugging results of zeller .
as shown above we found that sometimes focusing on the values that change most can sometimes lead to better defect predictors though caveat empty or sometimes it can actually make matters worse see the large negative results in figure .
note that this parallels zeller s approach which he summarizes as initially variable v1 was x1 thus variable v2 became x2 thus variable v3 became x3 ... and thus the program failed .
in future work we will explore further applications of ffts to delta debugging.