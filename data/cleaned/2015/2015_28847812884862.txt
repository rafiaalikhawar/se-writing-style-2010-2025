from word embeddings to document similarities for improved information retrieval in software engineering xin ye hui shen xiao ma razvan bunescu and chang liu school of electrical engineering and computer science ohio university athens ohio usa xy348709 hs138609 xm108210 bunescu liuc ohio.edu abstract the application of information retrieval techniques to search tasks in software engineering is made difficult by the lexical gap between search queries usually expressed in natural language e.g.
english and retrieved documents usually expressed in code e.g.
programming languages .
this is often the case in bug and feature location community question answering or more generally the communication between technical personnel and non technical stake holders in a software project.
in this paper we propose bridging the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space.
in the proposed architecture word embeddings are rst trained on api documents tutorials and reference documents and then aggregated in order to estimate semantic similarities between documents.
empirical evaluations show that the learned vector space embeddings lead to improvements in a previously explored bug localization task and a newly de ned task of linking api documents to computer programming questions.
ccs concepts information systems !multilingual and crosslingual retrieval similarity measures learning to rank software and its engineering !software testing and debugging computing methodologies !lexical semantics keywords word embeddings skip gram model bug localization bug reports api documents .
introduction and motivation recently text retrieval approaches have been applied to support more than software engineering se tasks .
in these approaches the lexical gap between user queries and code is usually identi ed as signi cant impediment.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c 2016 acm.
isbn .
.
.
.
feature location and bug localization for example the information need may be expressed as an issue report written in natural language whereas the functions and les to be retrieved mainly contain code.
in automatic code search there is a mismatch between the high level intent in user queries and the low level implementation details.
in community question answering cqa questions and answers are expressed in natural language code or a combination of both .
consequently standard information retrieval ir methods based on vector space models vsm are plagued by the lexical gap between the natural language used in the user query and the programming language used in the source code .
even when the query and the source les use a mix of statements in natural language and programming language code snippets in queries and natural language comments in code the performance of the ir system is sub optimal due to the signi cant language mismatch.
an example of language mismatch in the bug localization task is illustrated in figures and .
figure shows a bug report1from the eclipse project in which the author reports an abnormal behavior of the view icon when the view is minimized.
correspondingly the bug report contains relevant keywords such as view icon and minimize .
the bug is later xed by changing the source le partserviceimpl.java2 which contains the code managing view behaviors.
however the code does not contain any of the keywords found in the bug report.
instead the code contains keywords such as stack and placeholder .
overall because the code and the bug report have no words in common their cosine similarity in the standard tf id f vector space models used in ir would be .
nevertheless it can be determined automatically that the two sets of keywords are semantically related through the use of the distributional hypothesis .
according to this linguistic hypothesis words that appear in the same contexts tend to have similar semantic meanings.
figures and show types of documents where keywords from both the bug report and the source code appear in the same context.
figure shows a fragment from the eclipse user guide3that talks about minimizing views.
in this fragment the two types of keywords appear together in the same sentences.
this is further illustrated in figure which shows a fragment from the plug in developer guide4 and in figure that contains a fragment from an api document.
in fact bug.cgi?id ieee acm 38th ieee international conference on software engineering bug id summary junit view icon no longer shows progress while executing tests description before i upgraded to juno this morning i used to happily run tests with the junit view minimized and enjoy seeing the progress of the tests on it.
now i don t see any change on the icon until if passes where a green check appears or fails where a red x appears ... figure eclipse bug report with keywords inred.
public class partserviceimpl implements epartservice f ... private void record stackactivation mpart part f... mplaceholder placeholder part.getcursharedref ...g ... private void adjust placeholder mpart part f... mplaceholder placeholder part.getcursharedref ...g ...g figure code from partserviceimpl.java with keywords in blue.
throughout the user guide developer guide and api documents the words view andplaceholder frequently appear in the same context.
the distributional hypothesis has provided the basis for a number of methods that use word co occurrences in order to create vector representations of words i.e.
word embeddings such that words with similar meaning have similar vectors.
inspired by the success of unsupervised learning of word representations in natural language processing we propose a general method in which natural language statements and code snippets are projected as meaning vectors in a low dimensional shared representation space.
when applied on contexts such as the ones shown in figures to the method is expected to automatically determine that the keywords view andplaceholder are related semantically and therefore the corresponding bug report and source code should have a non zero semantic similarity.
while word embeddings have been shown to help in various nlp tasks to the best of our knowledge they have not been used to support text retrieval in software engineering.
a number of recent approaches explore the mining of semantically related software terms.
tian et al.
introduce sewordsim a software speci c word similarity database trained on stack over ow questions and answers.
howard et al.
and yang et al.
infer semantically related words from code.
wang et al.
mine word similarities from tags in freecode.
however these previous proposals for word similarities do not extend them to computing similarities between documents.
in this paper we incorporate word embeddings into a modi ed version of the text totext text similarity introduced by mihalcea et al.
such that word embeddings can be used to calculate the semantic similarity between se queries and their candidate answers.
the main contributions of this paper include an adapta section working with views and editors topic maximizing and minimizing in the eclipse presentation content the minimize behavior for the editor area is somewhat different minimizing the editor area results in a trim stack containing only a placeholder icon representing the entire editor area rather than icons for each open editor ... figure text from eclipse workbench user guide.
section making ui contributions topic adding the perspective content the browser perspective de nes two views one visible with a placeholder for the other ... figure text from eclipse platform plug in developer guide.
interface ipagelayout description a page layout de nes the initial layout for a perspective within a page in a workbench window... view placeholders may also have a secondary id.
... for example theplaceholder some view will match any occurrence of theview that has primary id someview and that also has some non null secondary id.
note that this placeholder will not match the view if it has no secondary id ... figure api description for ipagelayout .
tion of the skip gram model to the task of learning word embeddings for text and code in a low dimensional shared vector space a method for estimating the semantic similarity between queries and documents that utilizes word embeddings an evaluation of the proposed semantic similarity features that shows their utility in two ir tasks in se a previously explored bug localization task and a newly de ned task of linking api documents to java questions posted on stack over ow.
the rest of this paper is organized as follows.
section introduces the word embeddings idea with a subsection detailing the skip gram model for learning word embeddings.
section introduces techniques to adapt the skip gram model for training word embeddings on software documents that contains both free text and code.
section introduces two similarity features that are aimed at capturing the semantic similarity between documents using word embeddings.
section describes the general ranking model used to implement the two ir systems evaluated in this paper.
section presents a comprehensive evaluation of the impact that the newly proposed features have on the ranking performance.
section discusses related work followed by conclusions in section .
.
word embeddings harris distributional hypothesis which states that words in the same context tends to have similar meanings has given rise to many distributional semantic models dsms in which individual words are no longer treated as unique symbols but represented as d dimensional vectors of real numbers that capture their contextual semantic meanings 405such that similar words have similar vector representations.
traditional dsms create word vectors from a word context matrix m where each row corresponds to a word wi each column to a context cjthat contains wi and each cell mijto the co occurrence counts e.g.
the occurrences of wiincj .
for example pantel and lin compute mijas the pointwise mutual information pmi between wiandcj.
landauer and dumais introduced latent semantic analysis lsa which applies truncated singular value decomposition svd to reduce mto a low dimensional latent space.
these models are referred to as count based models.
recently a set of neural network based approaches were proposed to represent each word with a lowdimensional vector called neural embedding or word embedding .
unlike the traditional dsms that initialize vectors with co occurrence counts these neural language models directly learn the vectors to optimally predict the context and are called predictive models.
such models were successfully applied in a variety of nlp tasks .
among these models mikolov s skip gram model is popular for its simplicity and efficiency during training.
the skip gram model was also shown to signi cantly outperforms lsa and other traditional count based approaches in a set of tasks in ir and nlp .
.
learning word embeddings learning word embeddings refers to nding vector representations of words such that words that are similar in meaning are associated with similar vector embeddings where the similarity between vectors is usually de ned as cosine similarity.
to learn embeddings for natural language words and code tokens we use the unsupervised skip gram model of mikolov et al.
.
the skip gram model learns vector representations of words that are useful for predicting the surrounding words in a sentence.
figure illustrates the training procedure employed by the skip gram model when it reaches the current word wt numbers .
figure positive and negative training examples in the skip gram model.
the vector representation wtis used as the parameter vector of a binary logistic regression model equation that takes an arbitrary word wkas input and is trained to predict a probability of if the wkappears in the context of wtand otherwise.
p wk2ctjwt wt twk exp wt twk thus given an arbitrary word wk its vector representationwkis used as a feature vector in the logistic regressionmodel parameterized by wt.
if the word wkis in the context ofwt it is considered to be a positive example w .
any other word can serve as a negative example w .
the contextctis usually de ned as a xed size window centered at the current word wt.
the set of noisy negative examples ntis constructed by randomly sampling from the domain vocabulary a xed number of words for each word in the context ct. when trained on a sequence of twords the skip gram model uses stochastic gradient descent to minimize the negative of the log likelihood objective j w shown in equation .
j w t t w 2ct log wt tw w 2n tlog wt tw when applying the skip gram model for learning embeddings of natural language words and source code tokens we considered the following two scenarios .one vocabulary setting a single vocabulary is created to contain both words and tokens.
this means that the natural language word clear referring to an adjective and the source code token clear referring to a method name would be represented with the same vocabulary entry.
.two vocabulary setting two vocabularies are created.
one is used for words appearing in the natural language text and the other is used for tokens appearing in the code.
this means that the natural language word clear referring to an adjective and the source code token clear referring to a method name will belong to different vocabularies.
one difference between the one vocabulary setting and the two vocabulary setting is that the former uses the context of the method name clear to train the word embedding for the adjective clear while the second one does not.
.
learning word embeddings on software documents tutorials api documents and bug reports often contain sentences that mix natural language with code.
figure shows sentences extracted from an eclipse tutorial5on using opengl with swt.
the rst sentence creates a context for a context must be created with a drawable usually an swt canvas on which opengl renders its scenes.
the application uses glscene which is a utility class for displaying opengl scenes.
the glscene class is similar to swt s canvas .
glscene uses the entire area of the canvas for drawing.
in the constructor a new swt canvas is created.
this is the canvas that is associated with a glcontext instance.
figure tutorial sentences mixing natural language with code.
opengl.html 406the natural language word render whereas the next sentences create a context for the code token glscene .
the two contexts have a signi cant number of words tokens in common c render c glscene fswt canvas opengl scene g. when run over a large number of sentences that contain similar contexts for the two words render and glscene the skip gram model will automatically create vector representations for the two words that are similar in the same shared vector space.
the number of sentences that mix natural language words with source code tokens is often insufficient for training good vector representations in the skip gram model.
since the necessary size of the corpus is proportional with the size of the vocabulary we reduce the natural language vocabulary by pre processing the text with the porter stemmer.
this effectively collapses derivationally related words such asdraw draws drawing drawable into the same vocabulary entry draw.
furthermore using the same corpus we increase the number of training examples for the skip gram model as follows .
whenever a code token has a name that matches a natural language word use both the token and the word to create training examples for the logistic regression models section .
.
.
apply the logistic regression models on pairs of text and code that are known to have the same meaning or related meanings such as class description and method description in api documentations section .
.
.
heuristic mapping of tokens to words so far under the two vocabularies setting the word canvas and the token canvas belong to different vocabularies and therefore are associated different vector representations.
however when naming code artifacts such as classes methods or variables programmers tend to use natural language words that describe the meaning of the artifact.
furthermore when referring to the artifact in natural language programmers often use the natural language word instead of the code token.
for example the third section of figure mentions the creation of an object of class canvas which is later referred to using the natural language word canvas .
we exploit this naming tendencies and create additional training examples for the skip gram model by instructing the model to also train for the natural language word canvas whenever it sees an occurrence of the code token canvas .
this is done for each code token whose string representation is identical with the string representation of a word in the natural language vocabulary.
this rule is further generalized to composite token names such as workbenchwindow by rst splitting them into atomic names based on capitalization patterns and then checking to see if the atomic code names match words in the natural language vocabulary.
for example workbenchwindow will generate the natural language words workbench and window whereas glscene will generate the words gl and scene gl is considered a natural language word because it appears in natural language sentences such as each gl command consists of the library pre x followed by the command name .
note that the application of this heuristic rule implicitly leads to richer contexts.
in the example from figure the code tokendrawable from the context of render is mapped to the natural language word drawable which has the same stem figure example of semantically related text and code from the same tutorial.
void connect istreamsproxy streamsproxy connects this console to the given streams proxy.
this associates the standard in out and error streams with the console.
keyboard input will be written to the given proxy.
figure example of semantically related text and code from api documents.
as the word draw that appears in the context of glscene .
.
semantic pairings between text and code source code is often paired with natural language statements that describe its behavior.
such semantic pairings between text and code can be automatically extracted from tutorial examples figure and api documents figure .
to force the two meaning representations the bag of wordembeddings and the bag of token embeddings to be similar we augment the skip gram model to predict all code tokens from each text word and all text words from each code token as shown in figure .
this effectively pushes the embeddings for the text words and the code tokens towards each other if wtis a word embedding and wkis a token embedding both with the same norm the logistic sigmoid in equation is maximized when wk wt.
figure positive pairs generated from semantically related text and code.
.
from word embeddings to document similarities given two words wtandwu we de ne their semantic similarity as the cosine similarity between their learned word embeddings sim wt wu cos wt wu wt twu wt w u this is simply the inner product of the two vectors normalized by their euclidean norm.
to compute the similarity 407between two bags of words t e.g.
natural language text ands e.g.
source code we modi ed the text to text similarity measure introduced by mihalcea et al.
.
according to the similarity between a word wand a bag of words tis computed as the maximum similarity between wand any word w int sim w t max w 2tsim w w an asymmetric similarity sim t!s is then computed as a normalized id f weighted sum of similarities between words intand the entire bag of words in s sim t!s w2tsim w s id f w w2tid f w the asymmetric similarity sim s!t is computed analogously by swapping sandtin the formula above.
finally the symmetric similarity sim t s between two bagsof words tandsis de ned in as the sum of the two asymmetric similarities sim t s sim t!s sim s!t to keep the system self contained we could compute the id f weights from the collection of documents tin the dataset.
for example in the bug localization task the id fweights would be computed from the collection of source code les.
however this is bound to result in small document frequencies for many english words which in turn make the id f estimates unreliable.
to avoid this problem we eliminated theid fweighting from the asymmetric similarities.
furthermore we simpli ed the asymmetric similarity formula by ignoring words that had a zero similarity with the target document i.e.
words that either do not have a word embedding or that do not appear in the target document.
thus if we de ne p t!s fw2tjsim w s 0gto be the set of words in tthat have non zero positive similarity with s the modi ed asymmetric similarity between documents tandsis computed as follows sim t!s w2p t!s sim w s jp t!s j the asymmetric similarity sim s!t is computed analogously by swapping sandt.
.
from document similarities to ranking scores the information retrieval systems evaluated in this paper take as input a query document texpressing a user information need and rank all documents sfrom a large corpus of documents such that the documents ranked at the top are more likely to answer the information need i.e.
relevant documents .
this is usually implemented through a ranking model that computes a ranking score f t s for any query candidate answer pair.
in our work we consider ranking functions that are de ned as a weighted sum of k features where each feature k t s captures a prede ned relationship between the query document tand the candi date answer s f t s wt t s k k 1wk k t s the feature weights wkwill be trained on a dataset of automatically acquired ranking constraints using a learningto rank technique.
in this setting evaluating the impact of the new document to document similarities based on word embeddings can be done simply by adding the asymmetric similarities sim t!s and sim s!t as new features in an existing ranking model.
.
evaluation of word embeddings for bug localization in this section we describe an extensive set of experiments that are intended to determine the utility of the new document similarity measures based on word embeddings in the context of bug localization.
this is an information retrieval task in which queries are bug reports and the system is trained to identify relevant buggy les.
.
text pre processing there are three types of text documents used in the experimental evaluations in this section the eclipse api reference developer guides java api reference and java tutorials that are used to train the word embeddings the bug reports and the source code les.
when creating bag of words for these documents we use the same pre processing steps on all of them we remove punctuation and numerical numbers then split the text by whitespace.
the tokenization however is done differently for each category of documents.
in the one vocabulary setting compound words in the bug reports and the source code les are split based on capital letters.
for example workbenchwindow is split into workbench and window while its original form is also reserved.
we then apply the porter stemmer on all words tokens.
in the two vocabulary setting a code token such as a method name clear is marked as clear so that it can be distinguished from the adjective clear .
then we stem only the natural language words.
we also split compound natural language words.
in order to separate code tokens from natural language words in the training corpus we wrote a dedicated html parser to recognize and mark the code tokens.
for bug reports we mark words that are not in an english dictionary as code tokens.
for source code les all tokens except those in the comments are marked as code tokens.
inside the comments words that are not in an english dictionary are also marked as code tokens.
.
corpus for training word embeddings to train the shared embeddings we created a corpus from documents in the following eclipse repositories the platform api reference the jdt api reference the birt api reference the java se api reference the java tutorials the platform plug in developer guide the workbench user guide the plug in development environment guide and the jdt plug in developer guide.
the number of documents and words tokens in each repository are shown in table .
all documents are downloaded from their official web408table benchmark projects eclipse refers to eclipse platform ui.
project time range of bug reports of bug reports of bug reports total used for testing used for training used for tuning birt eclipse jdt swt site67.
code tokens in these documents are usually placed between special html tags such as code or emphasized with different fonts.
table documents for training word embeddings.
data sources documents words tokens platform api reference jdt api reference birt api reference java se api reference the java tutorials platform plug in developer guide workbench user guide plug in development environment guide jdt plug in developer guide total table the vocabulary size.
word embeddings trained on vocabulary size one vocabulary setting two vocabulary setting table number of word pairs.
approach of word pairs one vocabulary embeddings two vocabulary embeddings sewordsim swordnet to learn the shared embeddings we used the skip gram model modi ed such that it works in the training scenarios described in section .
table shows the number of words in each vocabulary setting.
table compares the number of word pairs used to train word embeddings in the one and two vocabulary settings with the number of word pairs used in two related approaches.
thus when word embeddings are trained on the one vocabulary setting the vocabulary size is which leads to word pairs during training.
this number is over times the number of word pairs in sewordsim and is more than times the number of word pairs in swordnet .
.
benchmark datasets we perform evaluations on the ned grained benchmark dataset from .
speci cally we use four open source java projects birt8 eclipse platform ui9 jdt10 and swt11.
each of the bug reports in this dataset we checkouta before xed version of the source code within which we rank all the source code les for the speci c bug report.
since the training corpus for word embeddings shown in table contains only java se documents for testing we use only bug reports that were created for eclipse versions starting with .
which is when eclipse started to add java se support.
the birt jdt and swt projects are all eclipse foundation projects and also support java se after the eclipse .
release.
overall we collect for testing and bug reports from birt eclipse platform ui jdt and swt respectively.
older bug reports that were reported for versions before release .
are used for training and tuning the learning to rank systems.
table shows the number of bug reports from each project used in the evaluation.
the methodology used to collect the bug reports is discussed at length in .
here we split the bug reports into a testing set a training set and a tuning set.
taking eclipse platform ui for example the newest bug reports which were reported starting with eclipse .
are used for testing.
the older bug reports in the training set are used for learning the weight parameters of the ranking function in equation using the svmrankpackage .
the oldest bug reports are used for tuning the hyper parameters of the skip gram model and the sv mrank model by repeatedly training on and testing on bug reports.
to summarize we tune the hyper parameters of the skip gram model and the svmrankmodel on the tuning dataset then train the weight vector used in the ranking function on the training dataset and nally test and report the ranking performance on the testing dataset.
after tuning the skip gram model was train to learn embeddings of size with a context window of size a minimal word count of and a negative sampling of words.
.
results and analysis we ran extensive experiments for the bug localization task in order to answer the following research questions rq1 do word embeddings help improve the ranking performance when added to an existing strong baseline?
rq2 do word embeddings trained on different corpora change the ranking performance?
rq3 do the word embedding training heuristics improve the ranking performance when added to the vanilla skip gram model?
rq4 do the modi ed text similarity functions improve the ranking performance when compared with the original similarity function in ?
we use the mean average precision map which is the mean of the average precision values for all queries and 409table map and mrr for the ranking systems.
project metric lr we1lr we2lr we1we2 1 8 1 8 1 6 7 8 7 8 eclipse map .
.
.
.
.
platform ui mrr .
.
.
.
.
jdt map .
.
.
.
.
mrr .
.
.
.
.
swt map .
.
.
.
.
mrr .
.
.
.
.
birt map .
.
.
.
.
mrr .
.
.
.
.
the mean reciprocal rank mrr which is the harmonic mean of ranks of the rst relevant documents as the evaluation metrics.
map and mrr are standard evaluation metrics in ir and were used previously in related work on bug localization .
.
.
rq1 do word embeddings help improve the ranking performance?
the results shown in table compare the lrsystem introduced in with a number of systems that use word embeddings in the one and two vocabulary settings as follows lr we1refers to combining the one vocabulary word embedding based features with the six features of the lr system from lr we2refers to combining the two vocabulary word embedding based features with the lr system we1refers to using only the one vocabulary wordembedding based features and we2refers to using only the two vocabulary word embedding based features.
the parameter vector of each ranking system is learned automatically.
the results show that the new word embeddingbased similarity features when used as additional features improve the performance of the lrsystem.
the results of bothlr we1andlr we2show that the new features help achieve .
.
and .
relative improvements in terms of map over the original lrapproach for eclipse platform ui jdt swt and birt respectively.
in lrwas reported to outperform other state of the art bug localization models such as the vsm based buglocator from zhou et al.
and the lda based bugscout from nguyen et al.
.
another observation is that using word embeddings trained on one vocabulary and using word embeddings trained on two vocabulary achieve almost the same results.
by looking at a sample of api documents and code we discovered that class names method names and variable names are used with a consistent meaning throughout.
for example developers use window to name a class that is used to create a window instance and use open to name a method that performs an open action.
therefore we believe the two vocabulary setting will be more useful when word embeddings are trained on both software engineering se and natural language nl corpora e.g.
wikipedia especially in situations in which a word has nl meanings that do not align well with its se meanings.
for example since eclipse is used in nl mostly with the astronomical sense it makes sense for eclipse to be semantically more similar with light than ide.
however in se we want eclipse to be more similar to ideand platform than to total color or light.
by training separate embeddings for eclipse in nl contexts i.e.
eclipse nl vs. eclipse in se contexts i.e.
eclipse se the expectation is that in an se setting the eclipse seembed table results on easy t1 vs. difficult t2 bug reports together with of bug reports size and average of relevant les per bug report avg .
t1 t2 lr we1lr lr we1lr size avg .
.
eclipse map .
.
.
.
mrr .
.
.
.
size avg .
.
jdt map .
.
.
.
mrr .
.
.
.
size avg .
.
swt map .
.
.
.
mrr .
.
.
.
size avg .
.
birt map .
.
.
.
mrr .
.
.
.
ding would be more similar with the ideseembedding than thetotal seorcolor seembeddings.
kochhar et al.
reported from an empirical study that the localized bug reports which explicitly mention the relevant le names statistically signi cantly and substantially impact the bug localization results.
they suggested that there is no need to run automatic bug localization techniques on these bug reports.
therefore we separate the testing bug reports for each project into two subsets t1 easy and t2 difficult .
bug reports in t1 mention either the relevant le names or their top level public class names whereas t2 contains the other bug reports.
note that although bug reports in t1 make it easy for the programmer to nd a relevant buggy le there may be other relevant les associated with the same bug report that could be more difficult to identify as shown in the statistics from table .
table shows the map and mrr results on t1 and t2.
because lr we1andlr we2are comparable on the test bug reports here we compare only lr we1with lr.
the results show that both lr we1andlrachieve much better performance on bug reports in t1 than t2 for all projects.
this con rms the conclusions of the empirical study from kochhar et al.
.
the results in table also show that overall using word embeddings helps on both t1 and t2.
one exception is birt where the use of word embeddings hurts performance on the easy bugs in t1 a result that deserves further analysis in future work.
to summarize we showed that using word embeddings to create additional semantic similarity features helps improve the ranking performance of a state of the art approach to bug localization.
however separating the code tokens from the natural language words in two vocabularies when training word embeddings on the se corpus did not improve the performance.
in future work we plan to investigate the utility of the two vocabulary setting when training with both se and nl corpora.
.
.
rq2 do word embeddings trained on a different corpora change the ranking performance?
to test the impact of the training corpus we train word embeddings in the one vocabulary setting using the wiki data dumps12 and redo the ranking experiment.
the ad12 410table the size of the different corpora.
corpus vocabulary words tokens eclipse and java wiki table comparison of the lr we1results when using word embeddings trained on different corpora.
corpus metric eclipse jdt swt birt metric platform ui eclipse and java map .
.
.
.
documents mrr .
.
.
.
wiki map .
.
.
.
mrr .
.
.
.
vantage of using the wiki corpus is its large size for training.
table shows the size of the wiki corpus.
the number of words tokens in the wiki corpus is times the number in our corpus while its vocabulary size is times the vocabulary size of our corpus.
theoretically the larger the size of the training corpus the better the word embeddings.
on the other hand the advantage of the smaller training corpus in table is that its vocabulary is close to the vocabulary used in the queries bug reports and the documents source code les .
table shows the ranking performance by using the wiki embeddings.
results show that the project speci c embeddings achieve almost the same map and mrr for all projects as the wiki embeddings.
we believe one reason for the good performance of the wiki embeddings is the preprocessing decision to split compound words such as workbenchwindow that do not appear in the wiki vocabulary into their components words workbench and window which belong to the wiki vocabulary.
correspondingly table below shows the results of evaluating just the word embeddings features we1 on the eclipse project with the two types of embeddings with and without splitting compound words.
as expected the project speci c embeddings have better performance than the wiki trained embeddings when compound words are not split the comparison is reversed when splitting is used.
overall each corpus has its own advantable project speci c vs. wikipedia embeddings performance of we1features with and without splitting compound words.
project metric no split split eclipse java map .
.
mrr .
.
wikipedia map .
.
mrr .
.
tages while the embeddings trained on the project speci c corpus may better capture speci c se meanings the embeddings trained on wikipedia may bene t from the substantially larger amount of training examples.
given the complementary advantages in future work we plan to investigate training strategies that exploit both types of corpora.
.
.
rq3 do the word embedding training heuristics improve the ranking performance?
table shows the results of using the original skip gramtable lr we1results obtained using the enhanced vs. the original skip gram model.
project metric lr enhanced skip gram original skip gram 1 8 1 6 1 8 eclipse map .
.
.
platform ui mrr .
.
.
jdt map .
.
.
mrr .
.
.
swt map .
.
.
mrr .
.
.
birt map .
.
.
mrr .
.
.
model without applying the heuristic techniques discussed in sections .
and .
.
it shows that both the enhanced and the original skip gram model achieve the same results most of the time.
these results appear to indicate that increasing the number of training pairs for word embeddings will not lead to further improvements in ranking performance which is compatible with the results of using the wiki corpus vs. the much smaller project speci c corpora.
.
.
rq4 do the modified text similarity functions improve the ranking performance?
table below compares the new text similarity functions shown in equation with the original text similarity function from mihalcea et al.
shown in equation .
inwe1 ori the new features 7and 8are calculated using the one vocabulary word embeddings and the original id fweighted text similarity function.
the results of lr we1 andlrare copied from table for which 7and 8are calculated using the new text similarity functions.
table comparison between the new text similarity function lr we1 and the original similarity function lr we1 ori .
project metric lr lr we1lr we1 ori 1 8 1 6 7 8 eclipse map .
.
.
platform ui mrr .
.
.
jdt map .
.
.
mrr .
.
.
swt map .
.
.
mrr .
.
.
birt map .
.
.
mrr .
.
.
results show that the new text similarity features lead to better performance than using the original text similarity function.
the new features obtain a relative improvement in terms of map over the lrapproach while features calculated based on the original text similarity function achieve only a relative improvement.
.
evaluation of word embeddings for api recommendation to assess the generality of using document similarities based on word embeddings for information retrieval in software engineering we evaluate the new similarity functions on the problem of linking api documents to java questions posted on the community question answering cqa website stack over ow so .
the so website enables users to ask 411and answer computer programming questions and also to vote on the quality of questions and answers posted on the website.
in the question to api q2api linking task the aim is to build a system that takes as input a user s question in order to identify api documents that have a non trivial semantic overlap with the as yet unknown correct answer.
we see such a system as being especially useful when users ask new questions for which they would have to wait until other users post their answers.
recommending relevant api documents to the user may help the user nd the answer on their own possibly even before the correct answer is posted on the website.
to the best of our knowledge the q2api task for cqa websites has not been addressed before.
in order to create a benchmark dataset we rst extracted all questions that were tagged with the keyword java using the datadump archive available on the stack exchange website.
of the extracted questions we used a script to automatically select only the questions satisfying the following criteria .
the question score is larger than which means that more than people have voted this question as useful .
.
the question has answers of which one was checked as the correct answer by the user who asked the question.
.
the correct answer has a score that is larger than which means that more than people gave a positive vote to this answer.
.
the correct answer contains at least one link to an api document in the official java se api online reference versions or .
this resulted in a set of high quality questions whose correct answers contain links to java api documents.
we randomly selected questions and asked two pro cient java programmers to label the corresponding api links as helpful ornot helpful .
the remaining questions were used as a noisy training dataset.
out of the randomly sampled questions the questions that were labeled by both annotators as having helpful api links were used for testing.
the two annotators were allowed to look at the correct answer in order to determine the semantic overlap with the api document.
although we allow api links to both versions and we train the word embeddings in the one vocabulary setting using only the java se api documentations and tutorials.
there are documents in total containing word tokens.
we use the vector space model vsm as the baseline ranking system.
given a question t for each api document swe calculate the vsm similarity as feature 1 t s and the asymmetric semantic similarities that are based on word embeddings as features 2 t s and 3 t s .
in the vsm we system the le score of each api document is calculated as the weighted sum of these three features as shown in equation .
during training on the questions the objective of the learning to rank system is to nd weights such that for each training question the relevant helpful api documents are ranked at the top.
during evaluation on the questions in the test dataset we rank all the javatable results on the q2api task.
approach map mrr vsm .
.
vsm we .
.
api documents sfor each question tin descending order of their ranking score f t s .
table shows the map and mrr performance of the baseline vsm system that uses only the vsm similarity feature vs. the performance of the vsm we system that also uses the two semantic similarity features.
the results in this table indicate that the document similarity features based on word embeddings lead to substantial improvements in performance.
as such these results can serve as an additional empirical validation of the utility of word embeddings for information retrieval tasks in software engineering.
we note that these results are by no means the best results that we expect for this task especially since the new features were added to a rather simple vsm baseline.
for example instead of treating so questions only as bags of undifferentiated words the questions could additionally be parsed in order to identify code tokens or code like words that are then disambiguated and mapped to the corresponding api entities .
given that like vsm these techniques are highly lexicalized we expect their performance to improve if used in combination with additional features based on word embeddings.
.
related work related work on word embedding in nlp was discussed in section .
in this section we discuss other methods for computing word similarities in software engineering and related approaches for bridging the lexical gap in software engineering tasks.
.
word similarities in se to the best of our knowledge word embedding techniques have not been applied before to solve information retrieval tasks in se.
however researchers have proposed methods to infer semantically related software terms and have built software speci c word similarity databases .
tian et al.
introduce a software speci c word similarity database called sewordsim that was trained on stackover ow questions and answers.
they represent words in a high dimensional space in which every element within the vector representation of word wiis the positive pointwise mutual information ppmi between wiand another word wjin the vocabulary.
because the vector space dimension equals the vocabulary size the scalability of their vector representation is limited by the size of the vocabulary.
when the size of the training corpus grows the growing vector dimension will lead to both larger time and space complexities.
recent studies also showed that this kind of traditional count based language models were outperformed by the neural network based low dimensional word embedding models on a wide range of word similarity tasks.
howard et al.
and yang et al.
infer semantically related words directly from comment code commentcomment or code code pairs without creating the distributional vector representations.
they rst need to map a 412line of comment or code to another line of comment or code and then infer word pairs from these line pairs.
similarly wang et al.
infer word similarities from tags in freecode.
the main drawback of these approaches is that they rely solely on code comments and tags.
more general free text contents are ignored.
many semantically related words e.g.
placeholder and view are not in the source code but in the free text contents of project documents e.g.
the eclipse user guide developer guide and api document shown in figure to figure .
however these types of documents are not exploited in these approaches.
more importantly all the above approaches did not explain how word similarities can be used to estimate document similarities.
they reported user studies in which human subjects were recruited to evaluate whether the word similarities are accurate.
however these subjective evaluations do not tell whether and how word similarities can be used in solving ir tasks in se.
.
bridging the lexical gap to support software engineering tasks text retrieval techniques have been shown to help in various se tasks .
however the system performance is usually suboptimal due to the lexical gap between user queries and code .
to bridge the lexical gap a number of approaches have been recently proposed that exploit information from api documentations.
these approaches extract api entities referenced in code and use the corresponding documentations to enhance the ranking results.
speci cally mcmillan et al.
measure the lexical similarity between the user query and api entities then rank higher the code that uses the api entities with higher similarity scores.
bajracharya et al.
augment the code with tokens from other code segments that use the same api entries.
ye et al.
concatenate the descriptions of all api entries used in the code and directly measure the lexical similarity between the query and the concatenated document.
the main drawback of these approaches is that they consider only the api entities used in the code.
the documentations of other api entities are not used.
figure shows the eclipse bug .
figure shows its relevant le partserviceimpl.java .
figure shows the description of an api entry ipagelayout.
although ipagelayout is not used inpartserviceimpl.java its api descriptions contains useful information that can help bridge the lexical gap by mapping the term view in bug with the term placeholder in partserviceimpl.java .
therefore to bridge the lexical gap we should consider not only the descriptions of the api entities used in the code but also all api documents and project documents e.g.
the user guide shown in figure and the developer guide in figure that are available.
latent semantic indexing lsi and latent dirichlet allocation lda have been used in the area of feature location and bug localization.
poshyvanyk et al.
use lsi to reduce the dimension of the term document matrix represent code and queries as vectors and estimate the similarity between code and queries using the cosine similarity between their vector representations.
similarly nguyen et al.
and lukins et al.
use lda to represent code and queries as topic distribution vectors.
rao et al.
compare various ir techniques on bug localization and report that traditional ir techniques such as vsm and unigram model um outperform the more sophisticated lsi and lda techniques.
these approaches create vector representations for documents instead of words and estimate query code similarity based on the cosine similarity between their vectors.
mcmillan et al.
introduced a lsi based approach for measuring program similarity and showed that their model achieve higher precision than a lsa based approach in detecting similar applications.
all these works neither measure word similarities nor try to bridge the lexical gap between code and queries.
.
future work we plan to explore alternative methods for aggregating word level similarities into a document level similarity function such as the word mover s distance recently proposed in .
in parallel we will explore methods that train document embeddings directly such as the paragraph vectors of le and mikolov and investigate their generalization from shallow bags of words inputs to higher level structures such as sequences and abstract syntax trees.
.
conclusion we introduced a general approach to bridging the lexical gap between natural language text and source code by projecting text and code as meaning vectors into a shared representation space.
in the proposed architecture word embeddings are rst trained on api documents tutorials and reference documents and then aggregated in order to estimate semantic similarities between documents.
empirical evaluations show that the learned vector space embeddings lead to improvements when added to a previous state of theart approach to bug localization.
furthermore preliminary experiments on a newly de ned task of linking api documents to computer programming questions show that word embeddings also improve the performance of a simple vsm baseline on this task.
.