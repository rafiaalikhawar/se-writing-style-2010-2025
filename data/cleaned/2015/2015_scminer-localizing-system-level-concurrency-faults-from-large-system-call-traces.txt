scminer localizing system level concurrency faults from large system call traces tarannum shaila zaman xue han tingting yu department of computer science university of kentucky tarannum.zaman uky.edu xha225 g.uky.edu tyu cs.uky.edu abstract localizing concurrency faults that occur in production is hard because detailed field data such as user input file content and interleaving schedule may not be available to developers to reproduce the failure it is often impractical to assume the availability of multiple failing executions to localizethe faults using existing techniques it is challenging to searchfor buggy locations in an application given limited runtime data and concurrency failures at the system level often involvemultiple processes or event handlers e.g.
software signals which cannot be handled by existing tools for diagnosing intra process thread level failures.
to address these problems we presentscminer a practical online bug diagnosis tool to help developers understand how a system level concurrency fault happens basedon the logs collected by the default system audit tools.
scminerachieves online bug diagnosis to obviate the need for offline bugreproduction.
scminer does not require code instrumentation on the production system or rely on the assumption of the availability of multiple failing executions.
specifically after thesystem call traces are collected scminer uses data mining andstatistical anomaly detection techniques to identify the failure inducing system call sequences.
it then maps each abnormalsequence to specific application functions.
we have conducted an empirical study on real world benchmarks.
the results show that scminer is both effective and efficient at localizingsystem level concurrency faults.
i. i ntroduction due to the worldwide spread of multi core architecture concurrent systems are becoming more pervasive.
debugging con current programs is difficult because of the non deterministicbehavior and the specific sequences of interleaving in the execution flow.
it often takes a tremendous amount of time and effort to reproduce and localize concurrency faults .
a concurrency fault may occur either during testing or in the production environment.
if the failure occurs in pro duction developers often have to diagnose it in a different debugging environment to identify the root cause.
however this is challenging primarily because a program can behavedifferently in a different environment for each execution especially for a concurrent system with non deterministic behaviors.
in addition customers may not be willing to sharetheir inputs for being used to reproduce failures due toprivacy concerns.
therefore it is hard to apply existing offlinedebugging tools to diagnose concurrency failures that cannot be reproduced outside the production environment.while previous research have been conducted this research is supported in part by the nsf grant ccf .to help developers in debugging concurrency faults it takes advantage of fine grained logging for deterministic record and replay which is infeasible in the production environment dueto the unbearable performance overhead.
to relieve the burden of debugging there has been some research on analyzing the runtime information and automatically localize faults .
for example falcon collects both passing and failing execution traces by instru menting each memory access of a concurrent program.
itthen uses statistical analysis to rank interleaving patternsinvolving the memory accesses.
this approach is intended to be used in the pre deployment environment because of the heavy weighted instrumentation.
cooperative concurrentbug isolation cci leverages statistical debugging andviews interleavings as predicates which are collected at theruntime and analyzed to find the location of the concurrency fault.
cci induces less overhead than falcon but still requires code instrumentation on the predicates.
therefore the twoapproaches can be impractical for being used in the produc tion environment.
in addition both falcon and cci requiremultiple failed and passed runs to perform the statisticalanalysis.
however this assumption often does not hold in the production environment it is difficult to obtain multiple failed runs because a concurrency fault often manifests itself underspecific interleavings and inputs .
in this work we propose scminer a practical online failure diagnosis tool to help developers understand why a concurrency failure occurs in production and localizes the cause of the failure in specific application functions.
scminer focuseson inter process concurrency faults where multiple operating system components e.g.
processes software signals andinterrupts incorrectly share resources .
the main differ ence between an inter process system level concurrency fault and an intra process thread level concurrency fault is that a system level concurrency fault corrupts the persistent storageand the other system wide resources which can crash theentire system whereas a thread level concurrency fault oftencorrupts the volatile memory within a process .
research has shown that more than of the race conditions reported in the linux distributions were system level races .
scminer works as follows.
when an anomaly failure is discovered by the user scminer is triggered to perform onlinefault localization that outputs a list of abnormal system callsequences and their associated application functions ranked in ui .
oufsobujpobm pogfsfodf po vupnbufe 4pguxb sf ohjoffsjoh authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
terms of their likelihood of causing the failure.
to achieve this goal scminer analyzes a window of recent system calls.the rationale behind our approach is twofold.
first a systemcall trace can be easily collected via system audit tools in production e.g.
cloud computing infrastructures with lowoverhead .
second system level concurrency failures are often caused by incorrect synchronizations of system calls on shared resources between two application processes.
there fore we can detect buggy locations by monitoring systemcalls.
however it is challenging to identify the abnormalsystem call sequences from a trace potentially containing millions of system calls.
even if the sequences are identified a modern server system typically consists of tens of thousandsof functions mapping a sequence to specific functions in theprograms is a non trivial task.
to address the above challenges scminer is designed to have two major phases.
in the first phase scminer uses principal component analysis pca an unsupervised learning approach to identify abnormal system call sequences.since the number of system calls in the trace can be enormous scminer splits the trace into a list of execution segments andgenerates a feature vector representation for each segment where each element in the vector is a system call sequence.
the segments together with their feature vectors are used toperform pca for identifying abnormal system call sequences.pca is efficient because its runtime is linear with the numberof vectors so the detection can scale to large traces.
in the second phase scminer maps each abnormal sequence to specific application functions.
since scminer does not assume the availability of source code it is impossible touse static analysis to link system calls to application functions.instead scminer obtains multiple system call traces outsidethe production environment by using binary instrumentation for building a map between system calls and function names.
however due to inconsistencies between production and non production environment and the lack of inputs an exact match ing is almost impossible.
to address this problem scmineruses frequent pattern mining to extract the frequently executedsystem calls from each function as a function signature .
the function signatures can serve as a high level matching to detect and rank a list of functions that potentially map to an abnormalsystem call sequence.
scminer has several distinguishing features which make it more advantageous over existing approaches.
first scminer does not require developers to reproduce bugs on their side toachieve fault localization.
second scminer uses the default auditd daemon in linux and does not require heavy program instrumentation which makes the tool transparent andpractical for production use.
third existing techniques oftenrequire multiple failing and passing executions to localize faults but it is hard to collect multiple failing executions especially for concurrent programs.
instead scmineronly assumes the existence of one failing system call tracegenerated by the auditd daemon.
finally scminer can capture the buggy functions for inter process failures whereas existingtechniques focus on intra process failures.
rcvmsg execve write open close.
figure .
a partial system call trace to evaluate scminer we conducted an empirical study on applications with known real world concurrency failures.
our results show that scminer effectively identifies the abnormal system call sequences and their associated applicationfunctions leading to the concurrency failures.
we also foundthat the use of optimization and function signature techniquescan improve the effectiveness and efficiency of scminer.
finally we found that scminer was highly robust in handling system call traces with different sizes.
overall we considerthese results to be strong and they indicate that scminer couldbe a useful approach for helping developers to automaticallylocalize system level concurrency failures in production givenan arbitrarily sized system call trace.
in summary this paper makes the following contributions we propose scminer the first fully automated tool for fault localization in multi process applications.
we implement scminer and conduct an empirical study to demonstrate its effectiveness and efficiency on real world linux applications .
ii.
b ackground and motiv ation in this section we first define our problem and then show a motivating example.
we also discuss the principle componentanalysis pca briefly.
a. problem statement we define the production level fault localization in multiprocess applications as follows.
given the binaries of a setof processes under debugging puds and system call tracesgenerated by these puds from the system built in auditd daemon we compute a short system call sequence sleading to the failure and the associated the application functions f of the system calls in s. we assume that a concurrent system consists of a set of processes p ...pm and a set of software signals s1...sn .
each process may create multiple threads but for ease ofpresentation we focus only on the process level concurrencyfailure in this work while assuming each process has onethread.
a failing process p fis a process that generates the failure or anomaly .
a system call trace contains a sequence of system calls generated from all applications running on the system.
each entryin the trace includes system call number process id process authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
name parent process id resource name inode number and execution command parameters.
each system call number ismapped to a specific system call name which can be obtainedfrom the system call table .
system level concurrency faults.
a system level concurrency fault occurs when multiple processes signals or interruptsaccess a system wide resource e.g.
file device etc.
withoutproper synchronization .
such resources are often accessedthrough system calls.
thus handling system level concurrencyfault requires the modeling of read write effects and synchronization operations involving system calls.
for example the lstat system call on file freads the metadata of f. the clone system call creates a new process inode under the proc directory write .
synchronization operations control process interactions through kernel process scheduler.
common process level synchronization primitives include fork wait exit pipe and signal .
b. a motivating example debian is a real world bug in bash version .
.
bash is an intuitive and flexible standard gnu shell for common users .
it keeps a history of executedcommands in a history file so that users can easily viewthe commands that are recently executed.
however problem occurs when multiple bash shells execute concurrently and corrupts the shell history file.
figure shows a piece of system call trace recorded by linux auditd .
the full trace contains around 000k system calls from processes recorded within minuteswhile bash was actively running.
to simplify presentation we show system call number process id process name resourcename and inode number.
the trace can grow quickly depend ing on how users interact with the shell and the behaviors of other programs running in the system.
when applying scminer to diagnosing the bug generated bybash the goal is to identify abnormal system call sequences leading to the concurrency failure and their associatedapplication functions.
in figure the system call sequence the grey area open file write file write file from two different bash processes indicates the root cause of the failure.
when one bash process pid opens bash .
history file before writing to it another bash process pid opens this file too and writes to it.
the failed executionproduces only one history message whereas two messages areexpected from the two processes.
this is because the secondprocess overwrites the message generated by the first process.
the abnormal system call sequence is then mapped to theapplication functions where the root cause is stemming from the function history do write in the bash application.
this function is responsible for reading and writing the bashhistory file.
challenges.
in practice it is difficult to localize the root cause of abnormal system call sequence and the associatedapplication from only system call traces.
the first challenge isto identify the processes involved in the erroneous execution.in the above example only the bash processes are actually relevant.
therefore we need to quickly weed out irrelevantprocesses.
moreover in some cases the failing process mightnot be the process that contains the bug.
a bug in one processmay propagate to another process e.g.
when a corrupted filegenerated by bash is accessed by a cat process and it is the cat process that reports the error .
the second challenge is that a system call trace can easily become massive.
identifyingthe abnormal system call sequences are difficult especially inthe absence of multiple failed executions where existing faultlocalization techniques cannot be applied.
third even if the abnormal system call sequences are identified searching the buggy functions associated with them among thelarge number functions in the target application is challenging.for example the bash program contains functions.
since the linux system has only system calls and a sequencecould appear in many functions an exact match between the system call names and the abnormal system call sequences could return a number of irrelevant functions.
c. principal component analysis principal component analysis pca analyzes a data matrix x where each row is an observation and each column is afeature.
the data points in x are described by several inter correlated quantitative dependent variables features .
ifwe have data with a large number of features some might be correlated.
the correlation between features can cause redundancies in the information.
therefore in order to reducethe computational cost and complexity we can use pca totransform the original features into their independent linearcombinations pcs .
for example in figure 2a we displayed a dimensional variable space and plotted the observations.
applying pca to xyields a set of mprincipal components.
the first principal component e.g.
pc 1in figure 2a captures the variance of the data to the greatest degree possible on asingle axis.
the next principal components pc 2to pc m then each captures the maximum variance among the remaining orthogonal directions.
variance measures how far a data set isspread out which provides us a general idea of the spread ofthe data .
each observation a dot in figure 2a may nowbe projected onto the pcs to obtain a coordinate value along with each pc line.
this new coordinate value is known as the pca score .
in this way we can identify the first k principal components and conclude that the k thprincipal component corresponds to the maximum variance of the residual.
thedifference between the original data and the data mapped ontothe first k principal axes is called the residual .
here kis the number of dimensions required to capture at least n of the variance in data .
therefore in the case of abnormal items detection where these items areassumed to be rare pca can capture the dominant itemsand construct a k dimensional normal subspace s d. the remaining dimensions construct the abnormal subspace sa.
the abnormal items can be identified by calculating the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a first two pcs in a plane b a sample data set t c score plot of pc1 and pc2 d loading plot of pc1 and pc2 figure .
principle component analysis distance of each item form the normal subspace.
the item with the longest distance from sdis marked as an abnormal item.
an example.
figure 2b shows an example of applying pca to an example of dataset t. the dataset has five features and observations which represents food consumption habit ofpeople from different countries.
each data point in the table represents the percentage of the population in a country who eat a specific kind of food.
after applying pca to t w e find that the first two principal components pcs can explainalmost of the data variance.
hence kis set to which divides the original data set into k normal sub spaces and the rest as abnormal sub spaces.
when plotting the pca score vector for the example of figure 2b data points that are correlated are placed together.figure 2c shows that countries from the same regions aregrouped together.
this is because people in the same region eatthe same kind of food.
on the other hand the country inside the red circle which is far from the other countries and hasthe longest distance from the first pc indicates that it has a distinct food consumption criteria i.e.
an abnormal item .likewise we can find the correlation between the features e.g.
rice bread etc.
by plotting the loading vector of thefirst two pcs.
the loading vector contains the data in a rotated coordinate .
features contributing similar information aregrouped together which means they are correlated.
in this example the feature seafood separates the country stika from the other countries.
this country is characterized as having ahigh consumption of seafood.
therefore we can conclude thatstika which is the farthest country from the normal subspace in figure 2c has some rare kind of food habit.
by observing the loading plot 2d we can identify that the feature seafood has the strongest impact to make stika s food consumption criteria rare.
iii.
scm iner approach figure provides an overview of scminer.
it consists of two major steps identifying abnormal system callsequences mapping abnormal sequences into a rankedlist of buggy functions.
to carry out the first step scminerprocesses the system call trace into trace segments that aresuitable for pca by using filtering and a set of optimizationtechniques.
it uses pca to identify a set of potential abnormalinter process system call sequences.
to map these sequencesinto the application s functions scminer performs dynamic analysis outside the production environment to extract func tion signatures where each function signature indicates thefrequently executed system call sequences within that function.it then uses function signatures to match against the abnormalsystem call sequences to identify and rank a list of functions that are likely to be the root cause of the system levelconcurrency failure.
a. identifying abnormal system call sequences algorithm in figure shows the steps of identifying abnormal system call sequences.
the input to the algorithmincludes a set of system call traces tcollected by built in tools such as linux auditd daemon .
the output is a set of potential abnormal system call sequences seq a. scminer first merges the traces into a single trace according to theirtimestamps in ascending order.
it then extracts informationthat is relevant to system level concurrency faults from the raw system call traces line .
next it groups related system calls from the extracted information to construct feature vectors i.e.
a data table for pca lines .
specifically scminersplits the trace into segments line where the segments areexpected to contain similar program behaviors i.e.
handlingan http request so system calls grouped into each segmentare intrinsically determined by program logic.
scminer thenencodes the feature vector by generating a set of system callsequences from each segment and counting their appearance lines .
next we apply pca to analyze the feature vectorsfor finding the most uncommon segments line .
finally from those selected uncommon segments scminer identifies the unique system call sequences which describe the data points that deviate from the others.
extracting relevant system calls since our target is diagnosing system level concurrency failures we need to identify system calls and their associated processes that canpotentially lead to system level concurrency failures.
as dis cussed in section ii a system level concurrency faults are dueto incorrectly shared resource accesses between processes so a system call sis considered relevant if its associated shared resource passed as a parameter is accessed by at least oneother process that is different from the one associated with s. in addition the execve system call is always considered to be relevant because it indicates the start of the execution authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
g11 g30 g27 g18 g33 g17 g32 g22 g27 g26 g11 g2 g11 g3 g37 g15 g33 g18 g22 g32 g18 g13 g35 g31 g32 g19 g25 g1 g6 g15 g24 g24 g1 g14 g30 g15 g17 g19 g8 g22 g24 g32 g19 g30 g22 g26 g21 g1 g15 g26 g18 g1 g10 g28 g32 g22 g25 g22 g36 g15 g32 g22 g27 g26 g11 g30 g22 g26 g17 g22 g28 g15 g24 g1 g6 g27 g25 g28 g27 g26 g19 g26 g32 g1 g4 g26 g15 g24 g35 g31 g22 g31 g7 g34 g32 g30 g15 g17 g32 g22 g26 g21 g10 g20 g20 g24 g22 g26 g19 g1 g8 g33 g26 g17 g32 g22 g27 g26 g13 g22 g21 g26 g15 g32 g33 g30 g19 g31 g9 g18 g19 g26 g32 g22 g20 g35 g22 g26 g21 g1 g5 g33 g21 g21 g35 g1 g8 g33 g26 g17 g32 g22 g27 g26 g31 g12 g15 g26 g23 g22 g26 g21 g5 g33 g21 g21 g35 g1 g8 g33 g26 g17 g32 g22 g27 g26 g31 g4 g16 g26 g27 g30 g25 g15 g24 g1 g13 g35 g31 g32 g19 g25 g1 g6 g15 g24 g24 g1 g13 g19 g29 g33 g19 g26 g17 g19 g31 figure .
the overview of scminer framework abnormal system call identification algorithm inputs t outputs seq a begin tr extracttrace t seg createsegments tr foreach segi seg list seqi generatesequences segi p v ector .update list seqi endfor pc computepca seg p v ector seq a identifyabnormalseq pc return seq a figure .
identifying abnormal system call sequences of a program which will be used to build feature vectors for pca.
therefore scminer iterates through all system callentries in the traces and retain only relevant system calls.
ourobservation on real world linux applications shows that on average only column nos fof table iii system calls are relevant.
in the example of figure the system callsrelated to bash are retained for further analysis.
pca based anomaly detection we use principal component analysis pca an unsupervised learning approachto identify abnormal system call sequences from the relevanttraces.
we use unsupervised learning because it does notrequire manually labeling the data to build training sets whichneeds extensive manual effort and the large training data issometimes difficult to obtain in the production environment.the key idea of using pca in our context is to discover the statistically dominant system call segments and thereby detect therare segments as well as the abnormal system call sequences i.e.
outliers inside rare segments.
the insight behind usingpca is that we observe low effective dimensionality in thedata table where each row i.e.
dimension is a system callsegment corresponding to a certain program behavior e.g.
an http request and each column is a candidate abnormal system call sequence.
representing system call traces.
we need to convert the trace containing relevant system calls to a numerical representationsuitable for applying pca detector.
the whole set of systemcalls in the trace can be represented by an m n matrix section ii c .
in scminer each row i.e.
observation in the matrix corresponds to the trace segments by splitting the traces.
each segment contains a set of consecutive systemcalls describing a certain program behavior e.g.
processing an http request .
for each segment scminer generates a set of system call sequences with different lengths to create feature vectors where each index in the vector represents a system call sequence and the corresponding value represents the numberof times the sequence appears in the segment.
table i shows an example of the numerical representation of a system call trace.
here each row indicates a vectorrepresentation of a trace segment.
each item in the vector is asequence of system calls where a system call sc svnindicates system call scaccesses a shared resource svfrom the process idn.
identifying trace segments.
scminer splits the extracted system call traces into fine grained segments of closely relatedsystem calls.
to do this for each trace scminer divides it into a set of segments based on the execution system call execv where each segment begins with execv .
the execv is called when a new process starts and the first parameterofexecv is the execution command.
the intuition is that most segments go through similar program execution paths andprocess interleaving patterns.
this results in high correlation and thus low intrinsic dimensionality which is suitable for applying pca.
for example each time when the user issuesa command in bash it will cause the execution to start from main for triggering the execv system call.
on the other hand the minority components may contain sequences with interleaved system calls which are the root causes ofconcurrency fault.
however any bug can occur during thetransition from one process to another which means theexecv system call may also present in the buggy system call sequence.
to make sure that this kind of system call sequenceis detected by our technique we keep the last system call s s form the previous segment as the first system call of the new segment.
generating vector representations.
scminer generates a feature vector representation for each trace segment.
each item feature in the vector is a system call sequence which isa candidate of the abnormal sequence.
to generate a list of features ffor each vector scminer first identifies sequences of semantically related system calls according to the sharedresources.
the intuition behind this is that most system level concurrency failures occur in the case of a particularinterleaving of system calls accessing a shared resource .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the output of this step is a set of system sequences seq sv where system calls in each sequence access the same sharedresource.
each sequence in seq svcan still be long and may not be helpful in understanding the bug.
for example in the apache server bug the length of sequence with respect to a shared resource is .
to reduce the size of the sequenceencoded as a feature in the vector scminer utilizes the a priori candidate generation algorithm to generate a setof shorter sequences for each s sv.
basically the a priori candidate generation algorithm uses a lattice structure toenumerate the list of all possible item sets resulting inan overly expensive computational cost o n where nis the number of system calls in seq sv.
to minimize the number of system call sequences and reduce the computational cost scminer employs three op timization methods.
first the traditional a priori algorithm exhaustively computes the short sequences regardless of the orders of the system calls in each execution.
however we need to consider the program execution flow and thuskeep only system call sequences actually appeared in thetrace.
therefore the computational cost is reduced to o n .
for example given a sequence s1 s2 s3 s4 inseq sv our modified candidate generation algorithm will output six instead of sequences s1 s2 s1 s2 s3 s1 s2 s3 s2 s3 s2 s3 s4 s3 s4 .
each sequence is encoded as a feature in the feature vector.
second scminer removes the system call sequences that are not relevant to system level concurrency bugs.
specifically a sequence is removed if both of them involve read access.
third we propose a sequence abstraction method to minimize the size of seq svand thus reduce the number of short sequences generated by the a priori algorithm.
the key idea is to detect system call sequences that are frequentlyexecuted sequences in all seq svs and replace each frequent sequence with a symbolic name.
we use frequent patternmining algorithm to obtain the frequent sequences.
forexample given seq sv1 s1 s2 s3 s4 andseq sv2 s2 s3 s5 .
suppose s1 s2 is a frequent pattern it is replaced with a symbolic name a. as a result seq sv1 s1 a s4 andseq sv1 a s5 .
in this case the cost of candidate generation algorithm can be reduced to o n p where nis the number of system calls and pis the number of frequent patterns.
at the end of the first phase if an abnormal system call contains a symbolicname it will be replaced with the real system calls.
ultimately a feature vector is generated for each trace segment in which each item or observation corresponds toa system call sequence extracted from the segment and thevalue of the item indicates the number of times the sequenceappears in the segment.
the size of the vector is the uniquenumber of system call sequences from all trace segments.
applying pca detector .
we create a feature matrix dto perform pca where each row corresponds to a feature vectorfrom a trace segment.
in the example of table i each columnis a feature i.e.
candidate system call sequence and eachtable i an numerical representation of a system call trace open f2 read f2 write f2 open f2 read f2 write f2 stat f2 .
.
... ... ... figure .
variance plot and biplot of pca on bash traces row is an observation i.e.
trace segment .
pca finds a lowdimensional representation of the matrix dthat contains as much as possible of the variation .
in our benchmark programs even though there are segments on average we found that of the variance can be captured by five principal components on average whichshows the low effective dimensionality in the feature metrics of our benchmarks.
for our feature vector each dimension corresponds to a certain execution sequence in the program.as the execution sequences are determined by the programlogic the sequences in a group are correlated.
in the passingexecutions it is natural that we find most of the sequences tobe highly correlated with each other.
for example figure left one shows the plot of the variances y axis associatedwith the pcs x axis .
this indicates that only principle components can capture variance of the data of bash program which have segments and unique system callsequences.
the plot in the right side of the figure represents both the pca score and loading in the normal subspace s dand in the abnormal subspace sa.
this plot indicates that segment has a significantly different score than the other segmentsand has the longest distance from the normal subspace.
thus we can separate this segment from the other data points.we then calculate the distances of the features and select the unique features of segment and obtain system call sequences.
furthermore these features are less co related withthe other features and mostly co related with each other.
finalize abnormal system call sequences with the help of pca we isolate the anomalous system call sequencesand after that we prepare different sets of them.
in order toprepare the sets we identify the shortest unique system callsequences first.
then sort out the supersets of a system callsequence and group them all in the same set.
in the same set the smallest system call sequence will be placed in the top.if a system call sequence does not have any supersets weconsider that sequence as a set.
for example we have five system call sequences p 1p2p3 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
p1p8 p1 p4 p4p5 .
these five sequences can be divided into two different sets .
p1 p1p8 p1p2p3 and .
p4 p4p5 .
the top item of a set is the most frequent subset of all system call sequences of that set.
b. localizing buggy functions in applications mapping an abnormal system call sequence to specific bugrelated application functions is challenging especially when the source code is not available.
we propose to leverage off line profiling to associate application functions with theabnormal system call sequences.
specifically we obtain sys tem call traces using dynamic binary instrumentation outsidethe production environment and match against the abnormalsequence.
one challenge is that an offline execution trace is unlikely to be exactly the same as the production trace due to envi ronmental inconsistencies the unavailable inputs or the nondeterministic interleavings.
to address this problem scminerproposes an offline function signature mapping method that creates a signature for each function outside the productionenvironment.
the signature is obtained by a set of closed frequent system call sequences for each function across multiple executions.
therefore we can map the abnormal sequenceback to each function signature to determine the suspectedbuggy function.
the benefits of using a signature are that we do not require the exactly same inputs environment or workload to localizethe buggy functions.
since the mapping table is obtained offline outside the production environment it does not induce production runtime overhead.
extracting offline function signatures given an abnormal system call sequence we obtain the processes containedin the sequence as the process under debugging puds .
wethen use pin a dynamic binary instrumentation tool toinstrument puds and execute them against a set of randomly generated inputs multiple times.
at the end of each execution we obtain a function execution list where each entry in the list contains system call numbers resource id and the functionname associated with them.
once all executions are finished scminer groups all entries for all function execution lists by the same function andthe same process name together.
next scminer extracts the function signature which is the maximal frequent system call sequence from each group.
the signature can characterize thebehavior of a function.
for example suppose there are threefunction execution lists for a function fin application ais open write close stat open read and lstat open write close .
the function signature of fwith respect to r the minimum support is open write close because it is the maximal frequent system call sequence .
identifying and ranking buggy functions.
algorithm in figure shows the steps of localizing bug related functions.scminer takes as input the offline function signatures sig a for puds and one item set of the abnormal system callsequences sc ab.
it outputs a list of top nranked applicationbuggy function identification algorithm inputs scab sig a outputs fbug begin foreach scin ordered scab foreach scainsc rm sig a.match sca fbug.add sca rm endfor fbug fbug.rank endfor return fbug figure .
algorithm for locating the buggy sequence in the buggy function functions fbugthat are likely to contain bugs.
each function infbugis associated with a ranking score.
specifically scminer iterates through scab beginning with the top ranked system abnormal call sequence and for eachfound sequence sc scminer extracts the system calls sharing the same application name into an application specific systemcall sequence sc a. for example in a sc write read write suppose the two writes are from the same function f1 and the read is from function f2 then scf1 write write andscf2 read .
specifically scminer treats each scain application afrom scas a query and searches scaagainst all function signatures in a. the search problem is formulated as the the longest common sub string matching problem.
thematching score r mis determined by the percentage of the matched system calls in each function signature.
for example suppose there are three function signatures f stat read write f2 unlink rename read and f3 read write .
the abnormal system sequence scais read write .
when matching scaagainst the three functions the scores are and .
therefore f3is ranked at the top.
iv .
e xperiments we developed scminer as a software tool based on several open source platforms.
specifically we used a linux builtin audit daemon auditd to collect system traces.
our abnormal system call sequence identification algorithm isimplemented by spmf an open source data mining tooland principle component analysis pca library defined inr programming language .
the offline trace collection in fault localization is implemented by pin .
in order to evaluate scminer we consider three research questions rq1 how effective is scminer at localizing abnormal system call sequences and buggy functions?rq2 how efficient is scminer at localizing abnormal system call sequences and buggy functions?rq3 what are the roles of pca optimization and signature function matching in improving the effectiveness and the efficiency of scminer?
a. benchmarks and evaluation metrics all our benchmarks are real linux applications with known concurrency failures due to incorrectly shared resources be authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii benchmark description and resource information of the failures application nloc nof bug id bug description nop nor nosr nos mv bugzilla another process terminates file is missing rm bugzilla rm terminates directory not empty mkdir debian file permission mode is modified mknod debian file permission mode is modified mkfifo debian file permission mode is modified ln debian ln terminates file does not exist tail changelog output not updated after attached process exits chmod gnu file permission mode is modified pxz bugzilla file permission mode is modified cp1 changelog file permission mode is modified cp2 changelog directory creates fails directory exists gzip debian file permission mode is modified bzip2 debian file permission mode is modified bash debian corrupted history file findutils debian new database would be empty lighttpd lighttpd http timeout lighttpd lighttpd incorrect output apache apache server shutdown command is ignored locate debian file is missing nloc the number of non comment lines of code.
nof the number of functions.
nop the number of processes.
nor the number of unique system wide resources accessed by the system calls in the log.
nosr the number of unique system wide shared resources accessed by the system calls in the log.
nos the number of system calls.
tween processes and or signal handlers.
these benchmarks are identified by searches from open source repositories such asgnu bugzilla and debian.
there are program versions from unique applications among which applications were from linux coreutils.
to minimize bias searches fromthese open source repositories are conducted by a student whois not involved in the scminer project.
these benchmarkshave been used in other research for handlingprocess level concurrency bugs.
the total number of benchmarks in this experiment is also comparable with prior work.
the student collected a system call trace for each benchmark by running multiple test cases multiple times and at least one execution can trigger the failure described in the bug report.
the offline traces are collected by running a set of black box or functional test cases to mimic the production runsagainst different input scenarios.
the black box test cases areoften designed based on system parameters and knowledge of functionality .
the student followed this approach usingthe category partition method which employs a test specification language tsl to encode choices of parametersand environmental conditions that affect system operations andcombine them into test cases.
however we did not know theroot causes of these failures until we finished running and analyzing the results of scminer.
table ii shows the statistics for each benchmark.
the last column indicates the size of thesystem call traces.
b. evaluation metrics identifying abnormal system call sequences.
to evaluate the effectiveness of abnormal system call sequence identification we use the measurement of precision .
precision representsthe percentage of the ground truth i.e.
the actual abnormal system call sequences from the system call sequence generatedby our technique.
to determine the ground truth we manually examined the solution discussed in the corresponding issue report and the patch used for fixing the issue.localizing buggy functions.
scminer reports top nfunctions that are likely to be buggy and by default n .
in order to assess the effectiveness of localizing buggy functions we measure two metrics.
the first metric measures the ranknumber position of functions identified as bug related.
again the ground truths are determined by manually examining the solution discussed in the corresponding issue report and thepatch used for fixing the issue.
for the second metric we use mean average precision map .
map is a single figure measure of ranked retrievalresults independent of the size of the top list .
it is designedfor general ranked retrieval problems where a query canhave multiple relevant documents e.g.
an abnormal system call sequence may associate with more than one function we compute the average ranking.
to compute map it firstcalculates the average precision ap for each individual queryq i and then calculates the mean of aps on the set of queries map q summationdisplay qi qap qi to illustrate the map calculation suppose there are bugrelated functions f1andf2if technique i ranks the two options at the 1stand2ndpositions among all functions and technique ii ranks the two functions at the 1stand3rd positions then the map of technique i is and the map of technique ii is .
.
c. results and analysis table iii summarizes the results of applying scminer to the benchmark programs.
the results showed that of system calls were removed after the filtering process.
column scseq shows the abnormal system call sequence in the format of systemcall process .
column func shows the function names associated with the abnormal system call sequence.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii results of applying scm iner over benchmark applications prog nos f seg.
ftr .
syscall seq.
func.location root cause time seq.
prec.
rank map scseq func sec mv unlink mv open cat rename mv mv copy internal cat main .
rm .
fstatat rm symlink ln opentat rm rm fts open fts build ln do link .
mkdir mkdir mkdir symlink ln chmod mkdir mkdir main ln do link .
mknod mknod mknod symlink ln chmod mknod mknod main ln do link .
mkfifo mknod mkfifo symlink ln chmod mkfifo mkfifo main ln do link .
ln stat ln unlink rmsymlink ln ln do link rm remove entry .
tail .
read tail rename mv fstat tail tail tail forever inotify dump reminder mv copy internal .
chmod stat chmod symlink ln fchmodat chmod chmod fts open main ln do link .
pxz .
umask pxz symlink ln chmod pxz pxz main ln do link .
cp1 .
mkdir cp fchmod chmod stat cp cp1 copy internal chmod main .
cp2 .
stat cp mkdir mkdir mkdir cp cp2 copy internal mkdir main .
gzip close gzip symlink ln chmod gzip gzip treat file ln do link .
bzip2 close bzip2 symlink ln chmod bzip2 bzip2 compressstream compress ln do link .
bash open bash write bash write bash bash history dowrite .
findutils unlink mv opentat rm rename mv mv copy internal rm rm .
lighttpd .
.
exit cgi rtsigreturn light wait light lighttpd fdevent event del .
lighttpd .
.
close light wait cgi wait light lighttpd fdevent unregister plugins call handle subrequest .
apache .
rtsigpromask httpd rtsigaction bash apache ap mpm run bash set signal handler .
locate unlink mv fchmodat chmod rename mv mv copy internal chmod fts open .
nos f the number of system calls after filtering.
seg.
the number of segments.
ftr .
the number of features system call sequences .
seq the number of abnormal sequence sets.
rank the ranking position of the ground truth.
map the map score.
scseq the abnormal system call sequence.
func the buggy functions.
time the time spent on the analysis.
rq1 effectiveness of scminer scminer is successful infinding abnormal system call sequences and bug related functions in all programs.
the number of abnormal systemcall sequences computed by scminer ranged from to .the size of each system call sequence ranged from to across all applications.
given the total number of system callsin the trace column nos in table ii the results indicatethat developers only need to examine from .
to .
system calls among all system calls in the trace with anaverage of .
.
the results also show that the identification of the buggy system call sequence is .
to precise column prec.
in table iii with an average of for all benchmark applications.
in addition scminer successfullylocalized buggy functions in all applications.
the average ranking position is .
overall applications.
the rank columncontains multiple ranks because we have multiple ground truth functions.
the map score ranged from .
to withan average of .
.
the map score indicates that all buggyfunctions identified scminer are ranked at the top .
giventhe total number of functions in a program column nof intable ii developers are required to examine at most .
to of all functions across all applications with an average of .
we conclude that scminer is effective at detecting abnormal system call sequences and localizing buggy functions withrespect to system level concurrency failures in production.
rq2 efficiency of scminer the last column of table iii reports the end to end total run time of scminer includingfiltering pca analysis optimization and buggy function localization.
the overhead of collecting system call traces by the auditd daemon is almost negligible ranging from zero to 2x with an average of .31x overall applications.
for the binary instrumentation used to localize buggy functions the overhead ranged from .3x to 36x with anaverage of .5x.
these overheads are in the similar order of magnitude as that of other profilers .
we considerthese overheads to be acceptable for out of production usage which is the intended usage of collecting function signatures.
the above results indicate that scminer is efficient and practical for being used for localizing system level concurrency faults.
rq3 the role of optimization and function signature to evaluate the role of the optimization techniques used infinding abnormal system calls i.e.
removing irrelevant sys tem calls sequence abstraction we computed the total timeof scminer without optimization denoted by scminer nop.
figure shows the time spent by scminer and scminer nop respectively.
compared to scminer nop scminer is .
times faster on average in terms of the end to end analysis timeacross all applications.
the speedup is more significant inlarger applications e.g.
bash apache .
this is primarily because the optimization reduced the size of feature vectors used for pca reduced the overall number of system call se quences and thus also reduced the time of searching frequent system call sequences in the source code.
overall these resultsindicate that the use of optimization techniques contributed to enhancing the efficiency of scminer .
to evaluate whether the use of function signatures can improve the effectiveness of identifying buggy functions weuse a baseline version scminer nfsto compare with scminer.
scminer nfs does not compute function signatures.
instead it collects a single trace outside the production environmentand then uses a simple exact string matching approach to determine if an abnormal system call belongs to certain functions.
for example a system call from the buggy sequence is considered as a query and will be searched in the systemcall sequence of the single execution trace.
figure shows themap scores of both scminer and scminer nfs across the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
figure .
comparing the time taken by scminer and scminer nop figure .
comparing the effectiveness of scminer and scminer nfs applications.
the results show that the use of function signature increased the effectiveness of scminer in applications ranging from .
to with an average of .
on the bash program we observed a improvement because the buggy function was not ranked in the top functions byscminer nfs.
the above results indicate that the function signature technique is more effective in localizing buggy functions than asimple string matching approach.
v. l imitations and dicussion a. limitations scminer assumes each logged system call contains sufficient information on resources being accessed.
scminermay not process logs in which resource information is notavailable in each system call.
second function signatures are collected from the execution traces.
therefore the accuracy of the signatures largely depend on the quality of inputs.existing automated test case generation techniques can beleveraged to cover as many functions as possible for improvingthe quality of traces.
b. discussion quality of traces.
we investigated how the quality of system call traces influence the effectiveness of scminer.
we variedthe percentage of the passing and failing executions in thelog under analysis.
as shown in figure the x axis indicates figure .
precision changes with the content of traces.
figure .
precision changes with the size of traces.
the ratio of the percentage of passing and failing executionsand the y axis indicates the precision scores of scminer indetecting abnormal system call sequences.
for example the ratio score means there are passing executions and failing executions.
the precision score is when the buggy sequence cannot be captured by scminer and it happens whenthe failing executions occupy a large percentage than thepassing executions.
these results show that there is a trendwhen the ratio between the passing and failing executions increases the precision increases.
the precision score reachesits peak for all applications when the percentage of passing executions is about .
the above results indicate that scminer is most useful when the number of normal system call sequences is a dominantmajority in the trace and they appear frequently.
this is due to the pca algorithm used in the approach.
scalability.
we further examined the effectiveness and efficiency of scminer when handling system call traces withdifferent sizes.
in addition to the original traces we consider two variations of the original traces generated from the applications small size trace and large size trace.
tocreate small size traces we removed of executions from each original trace.
to create large size traces we added anadditional of executions to each original trace.
figure plots the precision scores of scminer.
the results indicate that precision varied on all applications when changing the size of the trace from small to original .on all applications the precision scores generally remainthe same when the trace size is increased from original to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
figure .
time changes with the size of traces.
large .
figure plots the efficiency.
the results indicate that compared to the original traces the time spent on analyzingsmall traces was .
seconds on average less andthat on analyzing large traces was .
seconds onaverage more.
the above results imply that scminer is able to handle large size traces with little extra cost.
vi.
r elated work fault localization for concurrent programs.
there has been a lot of work on fault localization for concurrent pro grams .
for example park et al.
monitormemory access patterns associated with a program s pass failresults.
wang et al.
identify shared memory access pairs that behave distinctively in failed and successful runs and pinpoint root causes using different test procedures.
thistechnique targets order violations and does not rank concur rency violation patterns.
cci ranks only shared variableaccesses predicates and thus provides less contextual infor mation.
however these techniques assume multiple failing and passing executions which are often hard to obtain in practice.
in addition they require instrumenting memory ac cesses and thus are intended to work outside of the productionenvironment.
in contrast scminer is a production level faultlocalization tool that uses system generated system call traceswith little overhead.
in addition scminer assumes that failing executions happen more rarely than normal executions whichis a practical assumption in the production environment.
process level concurrency failures.
racepro leverages the vector clocks algorithm to detect a process level race if it happens during test execution.
it tracks the accesses of shared kernel resources via system calls and records exe cutions of multiple processes.
simracer and racepro aim to detect process level concurrency faults by testingfor different interleavings of system calls.
descry can reproduce system level concurrency failures by combining static and dynamic analysis techniques to generate test inputs.
however all of these techniques have different goals fromscminer none of them focus on detecting abnormal systemcalls from traces or localizing buggy functions.
anomaly detection from runtime logs.
there has been some research on detecting anomalies fromlogs.
for example xu et al.
mine console logs andidentify the abnormal log message patterns.
liu et al.
and du et al.
analyze the characteristics of system logsto identify the abnormal behaviors of a system that are caused by attacks.
lakhina et al.
use pca anomaly detectionalgorithm to diagnose network wide traffic anomalies.
thismethod uses principal component analysis to identify ananomalous subspace of the network traffic which is noisier andcontains significant traffic spikes.
in contrast scminer focuseson finding system call sequences for diagnosing system levelconcurrency faults.
moreover scminer can pinpoint the rootcauses of failures associated with abnormal system calls.
vii.
c onclusions we have presented scminer the first automated tool to diagnose system level concurrency failures in multi processapplications.
scminer can detect abnormal system call sequences from the traces generated by the default systemauditd daemon by using a combination of dynamic analysis data mining and statistical analysis techniques.
scminer can also localize buggy application functions associated with the abnormal system call traces.
we have evaluated scminer on19 real world multi process applications.
the results showedthat scminer is both effective and efficient in diagnosingsystem level concurrency failures.
r eferences r. capuano interactive visualization of concurrents programs in 19th ieee international conference on automated software engineering ase pp.
.
g. altekar and i. stoica odr output deterministic replay for multicore debugging in proceedings of the acm sigops 22nd symposium on operating systems principles sosp pp.
.
h. cleve and a. zeller locating causes of program failures in international conference on software engineering pp.
.
j. clause and a. orso a technique for enabling and supporting debugging of field failures in international conference on software engineering pp.
.
a. v .
thakur r. sen b. liblit and s. lu cooperative crug isolation inproceedings of the international workshop on dynamic analysis held in conjunction with the acm sigsoft international symposiumon software testing and analysis issta woda pp.
.
s. park r. w. vuduc and m. j. harrold falcon fault localization in concurrent programs in proceedings of the 32nd acm ieee international conference on software engineering v olume icse pp.
.
j. d. choi and a. zeller isolating failure inducing thread schedules inproceedings of the acm sigsoft international symposium on software testing and analysis ser.
issta pp.
.
h. cleve and a. zeller locating causes of program failures in proceedings of the 27th international conference on software engineering icse pp.
.
n. jalbert and k. sen a trace simplification technique for effective debugging of concurrent programs in proceedings of the eighteenth acm sigsoft international symposium on f oundations of software engineering fse pp.
.
j. huang p. liu and c. zhang leap lightweight deterministic multi processor replay of concurrent java programs in proceedings of the 18th acm sigsoft international symposium on f oundations ofsoftware engineering pp.
.
o. laadan n. viennot c. c. tsai c. blinn j. yang and j. nieh pervasive detection of process races in deployed systems in proceedings of the twenty third acm symposium on operating systems principles sosp pp.
.
c. zamfir and g. candea execution synthesis a technique for automated software debugging in proceedings of the 5th european conference on computer systems eurosys pp.
.
a. thakur r. sen b. liblit and s. lu cooperative crug isolation in proceedings of the seventh international workshop on dynamic analysis woda pp.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
s. park r. w. vuduc and m. j. harrold falcon fault localization in concurrent programs in international conference on software engineering pp.
.
w. wang c. wu p. yew x. yuan z. wang j. li and x. feng concurrency bug localization using shared memory access pairs inacm sigplan symposium on principles and practice of parallelprogramming ppopp pp.
.
s. park r. w. vuduc and m. j. harrold a unified approach for localizing non deadlock concurrency bugs in fifth ieee international conference on software testing v erification and v alidation icst pp.
.
t. yu t. s. zaman and c. wang descry reproducing system level concurrency failures in proceedings of the 11th joint meeting on f oundations of software engineering esec fse pp.
.
t. yu w. srisa an and g. rothermel simracer an automated framework to support testing for process level races in proceedings of the international symposium on software testing and analysis ser.
issta pp.
.
auditd linux man page.
.
available principal component analysis pca procedure.
.
available d. engler and k. ashcraft racerx effective static detection of race conditions and deadlocks in proceedings of the nineteenth acm symposium on operating systems principles sosp pp.
.
m. naik a. aiken and j. whaley effective static race detection for java in proceedings of the 27th acm sigplan conference on programming language design and implementation pldi pp.
.
scminer.
.
available f. valsorda.
searchable linux syscall table for x86 and x86 .
.
available o. laadan n. viennot c. c. tsai c. blinn j. yang and j. nieh pervasive detection of process races in deployed systems in acm symposium on operating systems principles pp.
.
debian bug report logs .
.
available bash guide for beginners.
.
available sect .html h. abdi and l. j. williams principal component analysis wiley interdisciplinary reviews computational statistics vol.
no.
pp.
.
j. shlens a tutorial on principal component analysis in systems neurobiology laboratory salk institute for biological studies .
s. h. to.
variance simple definition step by step examples.
.
avail able l. eriksson.
what is principal component analysis pca and how it is used?
.
available a. lakhina m. crovella and c. diot diagnosing network wide traffic anomalies in proceedings of the conference on applications technologies architectures and protocols for computer communica tions sigcomm pp.
.
w. xu l. huang a. fox d. patterson and m. i. jordan detecting large scale system problems by mining console logs in proceedings of the acm sigops 22nd symposium on operating systems principles sosp pp.
.
i. jolliff principal component analysis 2nd ed.
springer .
h. lohninger.
pca loadings and scores.
.
available fundstat eng ccpcaloadscore .html s. lu s. park e. seo and y .
zhou learning from mistakes a comprehensive study on real world concurrency bug characteristics ininternational conference on architectural support for programming languages and operating systems pp.
.
apache deadlock r. agrawal and r. srikant fast algorithms for mining association rules in large databases in proceedings of the 20th international conference on v ery large data bases vldb pp.
.
p. n. tan m. steinbach a. karpatne and v .
kumar introduction to data mining 2nd edition 2nd ed.
pearson .
s. m. holland.
principal components analysis pca .
.
available pin a dynamic binary instrumentation tool.
.
available b. ziani and y .
ouinten mining maximal frequent itemsets a java implementation of fpmax algorithm in proceedings of the 6th international conference on innovations in information technology iit pp.
.
p. fournier viger a. gomariz t. gueniche a. soltani c. w. wu and v .
s. tseng spmf a java open source pattern mining library j. mach.
learn.
res.
vol.
no.
pp.
jan. .
principal component analysis based unsupervised anomaly detection.
.
available tyu research descry.
a. causevic d. sundmark and s. punnekkat an industrial survey on contemporary aspects of software testing in ieee international conference on software testing v erification and v alidation pp.
.
t. j. ostrand and m. j. balcer the category partition method for specifying and generating fuctional tests commun.
acm pp.
.
w. koehrsen beyond accuracy precision and recall march .
p. r. .
h. s. christopher d. manning.
evaluation of ranked retrieval results.
.
available l. gong m. pradel and k. sen jitprof pinpointing jit unfriendly javascript code in acm sigsoft symposium on f oundations of software engineering pp.
.
a. nistor l. song d. marinov and s. lu toddler detecting performance problems via similar memory access patterns in international conference on software engineering pp.
.
a. reyes.
exact string matching algorithms.
.
available j. pei j. han b. mortazavi asl j. wang h. pinto q. chen u. dayal and m. hsu mining sequential patterns by pattern growth the pre fixspan approach ieee trans.
knowl.
data eng.
vol.
no.
pp.
.
w. xu l. huang a. fox d. patterson and m. jordan online system problem detection by mining patterns of console logs in proceedings of the ninth ieee international conference on data mining icdm pp.
.
z. liu t. qin x. guan h. jiang and c. wang an integrated method for anomaly detection from massive system logs ieee access vol.
pp.
.
m. du f. li g. zheng and v .
srikumar deeplog anomaly detection and diagnosis from system logs through deep learning in proceedings of the acm sigsac conference on computer and communica tions security ccs pp.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.