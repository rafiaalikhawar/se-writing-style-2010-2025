bugswarm mining and continuously growing a dataset of reproducible failures and fixes david a. tomassi naji dmeiri yichen wang antara bhowmick yen chuan liu premkumar t. devanbu bogdan v asilescu cindy rubio gonz alez university of california davis datomassi nddmeiri eycwang abhowmick yclliu ptdevanbu crubio ucdavis.edu carnegie mellon university vasilescu cmu.edu abstract fault detection localization and repair methods are vital to software quality but it is difficult to evaluate their generality applicability and current effectiveness.
large diverse realistic datasets of durably reproducible faults and fixes are vital to good experimental evaluation of approaches to software quality but they are difficult and expensive to assemble and keep current.
modern continuous integration ci approaches like t ra vis ci which are widely used fully configurable and executed within custom built containers promise a path toward much larger defect datasets.
if we can identify and archive failing and subsequent passing runs the containers will provide a substantial assurance of durable future reproducibility of build and test.
several obstacles however must be overcome to make this a practical reality.
we describe b ugsw arm a toolset that navigates these obstacles to enable the creation of a scalable diverse realistic continuously growing set of durably reproducible failing and passing versions of real world open source systems.
the b ugsw arm toolkit has already gathered fail pass pairs in java and python all packaged within fully reproducible containers.
furthermore the toolkit can be run periodically to detect fail pass activities thus growing the dataset continually.
index t erms bug database reproducibility software testing program analysis experiment infrastructure i. i ntroduction software defects have major impacts on the economy on safety and on the quality of life.
diagnosis and repair of software defects consumes a great deal of time and money.
defects can be treated more effectively or avoided by studying past defects and their repairs.
several software engineering subfields e.g.
program analysis testing and automatic program repair are dedicated to developing tools models and methods for finding and repairing defects.
these approaches ideally should be evaluated on realistic up to date datasets of defects so that potential users have an idea of how well they work.
such datasets should contain fail pass pairs consisting of a failing version which may include a test set that exposes the failure and a passing version including changes that repair it.
given this researchers can evaluate the effectiveness of tools that perform fault detection localization static or dynamic or fault repair.
thus research progress is intimately dependent on high quality datasets of fail pass pairs.
there are several desirable properties of these datasets of fail pass pairs.
first scale enough data to attain statistical significance on tool evaluations.
second diversity enough variability in the data to control for factors such as projectscale maturity domain language defect severity age etc.
while still retaining enough sample size for sufficient experimental power.
third realism defects reflecting actual fixes made by real world programmers to repair real mistakes.
fourth currency a continuously updated defect dataset keeping up with changes in languages platforms libraries software function etc.
so that tools can be evaluated on bugs of current interest and relevance.
finally and most crucially defect data should be durably reproducible defect data preserved in a way that supports durable build and behavior reproduction robust to inevitable changes to libraries languages compilers related dependencies and even the operating system.
some hand curated datasets e.g.
siemens test suite the sir repository defects4j provide artifact collections to support controlled experimentation with program analysis and testing techniques.
however these collections are curated by hand and are necessarily quite limited in scale and diversity others incorporate small sized student homeworks which may not reflect development by professionals.
some of these repositories often rely on seeded faults natural faults from real programmers would provide more realism .a t time of creation these are or rather were current.
however unless augmented through continuous and expensive manual labor currency will erode.
finally to the extent that they have dependencies on particular versions of libraries and operating systems their future reproducibility is uncertain.
the datasets cited above have incubated an impressive array of innovations and are well recognized for their contribution to research progress.
however we believe that datasets of greater scale diversity realism currency and durability will lead to even greater progress.
the ability to control for covariates without sacrificing experimental power will help toolbuilders and empirical researchers obtain results with greater discernment external validity and temporal stability.
however how can we build larger defect datasets without heavy manual labor?
finding specific defect occurrences and creating recompilable and runnable versions of failing and passing software is difficult for all but the most trivial systems besides the source code one may also need to gather specific versions of libraries dependencies operating systems compilers and 1while it is impossible to guarantee this in perpetuity we would like to have some designed in resistance to change.
ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
other tools.
this process requires a great deal of human effort.
unless this human effort can somehow be automated away we cannot build large scale diverse realistic datasets of reproducible defects that continually maintain currency.
but how can we automate this effort?
we believe that the devops and oss led innovations in cloud based continuous integration ci hold the key.
ci services like t ra vis ci allow open source projects to outsource integration testing.
oss projects for various reasons have need for continuous automated integration testing.
in addition modern practices such as test driven development have led to much greater abundance of automated tests.
every change to a project can be intensively and automatically tested off site on a cloud based service this can be done continually across languages dependencies and runtime platforms.
for example typical g ithub projects require that each pull request pr be integration tested and failures fixed before being vetted or merged by integrators .
in active projects the resulting back and forth between pr contributors and project maintainers naturally creates many fail pass pair records in the pull request history and overall project history.
two key technologies underlie this capability efficient customizable container based virtualization simplifies handling of complex dependencies and scripted ci servers allows custom automation of build and test procedures.
project maintainers create scripts that define the test environment platforms dependencies etc.
for their projects using these scripts the cloud based ci services construct virtualized runtimes typically d ocker containers to build and run the tests.
the ci results are archived in ways amenable to mining and analysis.
we exploit precisely these ci archives and the ci technology to create an automated continuously growing large scale diverse dataset of realistic and durably reproducible defects.
in this paper we present b ugsw arm a ci harvesting toolkit together with a large growing dataset of durably reproducible defects.
the toolkit enables maintaining currency and augmenting diversity.
b ugswa r m exploits archived ci log records to create detailed artifacts comprising buggy code versions failing regression tests and bug fixes.
when a successive pair of commits the first whose ci log indicates a failed run and the second an immediately subsequent passing run is found b ugsw arm uses the project s ci customization scripts to create an artifact a fully containerized virtual environment comprising both versions and scripts to gather all requisite tools dependencies platforms os etc.
bugswa r m artifacts allow full build and test of pairs of failing passing runs.
containerization allows these artifacts to be durably reproducible.
the large scale and diversity of the projects using ci services allows b ugswa r m to also capture a large growing diverse and current collection of artifacts.
specifically we make the following contributions we present an approach that leverages ci to mine fail pass pairs in open source projects and automatically attempts to reproduce these pairs in d ocker containers section iii .
we show that fail pass pairs are frequently found in open source projects and discuss the challenges in reproducingsuch pairs section iv .
we provide the b ugswa r m dataset of artifacts for java and python to our knowledge the largest continuously expanding durably reproducible dataset of failpass pairs and describe the general characteristics of the bugswa r m artifacts section iv .
we provide background and further motivation for bugsw arm in section ii.
we describe limitations and future work in section v. finally we discuss related work in section vi and conclude in section vii.
ii.
b ackground and motiv a tion modern oss development with ci services provides an enabling ecosystem of tools and data that support the creation of b ugswa r m .
here we describe the relevant components of this ecosystem and present a motivating example.
a. the open source ci ecosystem gitand g ithub.gitis central to modern software development.
each project has a repository .
changes are added via a commit which has a unique identifier derived with a sha hash.
the project history is a sequence of commits.
gitsupports branching.
the main development line is usually maintained in a branch called master .g ithub is a webbased service hosting g itrepositories.
g ithuboffers forking capabilities i.e.
cloning a repository but maintaining the copy online.
g ithub supports the pull request pr development model project maintainers decide on a case by case basis whether to accept a change.
specifically a potential contributor forks the original project makes changes and then opens a pull request.
the maintainers review the pr and may ask for additional changes before the request is merged or rejected.
tra vis ci continuous integration.
tra vis ci is the most popular cloud hosted ci service that integrates with g ithub it can automatically build and test commits or prs.
t ra vis ci is configured via settings in a .travis.yml file in the project repository specifying all the environments in which the project should be tested.
a t ra vis ci build can be initiated by a push event or a pull request event .
a push event occurs when changes are pushed to a project s remote repository on a branch monitored by t ra vis ci.
a pull request event occurs when a pr is opened and when additional changes are committed to the pr.
t ra vis ci builds run a separate job for each configuration specified in the .travis.yml file.
the build is marked as passed when all its jobs pass.
docker .docker is a lightweight virtual machine service that provides application isolation immutability and customization.
an application can be packaged together with code runtime system tools libraries and os into an immutable stand alone custom built persistent d ocker image container which can be run anytime anywhere on any platform that supports d ocker .
in late t ra vis ci began running builds and tests inside d ocker containers each customized for a specific run as specified in the t ra vis 2the b ugsw arm dataset is available at .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
lifecycle of a t ra vis ci built and tested pr ci.travis.yml files.
t ra vis ci maintains some of its base images containing a minimal build environment.
b ugswa r m harvests these containers to create the dataset.
b. leveraging tra vis ci to mine and reproduce bugs we exploit t ra vis ci to create b ugsw arm .
figure depicts the lifecycle of a t ra vis ci built and tested pr.
a contributor forks the repository and adds three commits up to prv1 she then opens a pr asking that her changes be merged into the original repository.
the creation of the pr triggers tra vis ci which checks whether there are merge conflicts between the pr branch and master when the pr was opened prv1 andbasev1 .
if not t ra vis ci creates a temporary branch from the base branch into which the pr branch is merged to yield temp1 .
this merge is also referred to as a phantom merge because it disappears from the g ithistory after some time.3tra vis ci then generates build scripts from the.travis.yml file and initiates a build i.e.
runs the scripts to compile build and test the project.
in our example test failures cause the first build to fail tra vis ci notifies the contributor and project maintainers as represented by the dashed arrows in figure .
the contributor does her fix and updates the pr with a new commit which triggers a new build.
again t ra vis ci creates the merge between the pr branch now at prv2 and the base branch still at basev1 to yield temp2 .
the build fails again apparently the fix was no good.
consequently the contributor updates the pr by adding a new commit prv3 .at ra vis ci build is triggered in which the merge temp3 between the pr branch at prv3 and the base branch now at basev2 is tested.4this time the build passes and the pr is accepted and merged into the base branch.
each commit is recorded in version control archiving source code at build time plus the full build configuration .travis.yml file .
t ra vis ci records how each build fared pass or fail and archives a build log containing output of the build and test process including the names of any failing tests.
our core idea is that t ra vis ci built and tested pull requests and regular commits from g ithub available in large volumes for a variety of languages and platforms can be phantom merges present special challenges which are discussed later.
4tra vis ci creates each phantom merge on a separate temporary branch but figure shows the phantom merges on a single branch for simplicity.used to construct fail pass pairs .
in our example the version of the code represented by the merge temp2 is defective as documented by test failures in the corresponding t ra vis ci build log.
the subsequently fixed version no test failures in the build log is represented by temp3 .
therefore we can extract a failing program version a subsequent fixed program version the fix i.e.
the difference between the two versions the names of failing tests from the failed build log a full description of the build configuration.
since each t ra vis ci job occurs within a d ocker container we can re capture that specific container image thus rendering the event durably reproducible.
furthermore if one could build an automated harvesting system that could continually mine t ra vis ci builds and create d ocker images that could persist these failures and fixes this promises a way to create a dataset to provide all of our desired data g ithublevel scale g ithub level diversity realism of popular oss projects currency via the ability to automatically and periodically augment our dataset with recent events and finally durable reproducibility via d ocker images.
iii.
b ugswa r m infrastructure a. some terminology a project s build history refers to all t ra vis ci builds previously triggered.
a build may include many jobs for example a build for a python project might include separate jobs to test with python versions .
.
.
etc.
acommit pair is a tuple of g itcommit shas that each triggered a t ra vis ci build in the same build history.
the canonical commit pair consists of a commit whose build fails the tests followed by a fix commit whose build passes the tests.
the terms build pair and job pair refer to a tuple of tra vis ci builds or jobs respectively from a project s build history.
for a given build the trigger commit is the commit that when pushed to the remote repository caused t ra vis ci to start a build.
bugsw arm has four components p airminer p airfilter r eproducer and a nalyzer .
these components form the pipeline that curates b ugsw arm artifacts and are designed to be relatively independent and general.
this section describes the responsibilities and implementation of each component and a set of supporting tools that facilitate usage of the dataset.
b. design challenges the tooling infrastructure is designed to handle certain specific challenges listed below that arise when one seeks to continuously and automatically mine t ra vis ci.
in each case we list the tools that actually address the challenges.
pair coherence.
consecutive commits in a g ithistory may not correspond to consecutive t ra vis ci builds.
a build history which t ra vis ci retains as a linear series of builds must be traversed and transformed into a directed graph so that pairs of consecutive builds map to pairs of consecutive commits.
git s non linear nature makes this non trivial.
p airminer authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm pairminer algorithm input project slug p output setjof fail pass job pairs jf jp 1j b the list of t ra vis ci builds for p 2g g g band b gbelong to the same branch pr 3foreach gingdo order the builds in gchronologically foreach bi gdo ifbiis failed and bi 1is passed then assigncommits bi assigncommits bi j j jf jp jf biandjp bi 1andjf has the same configuration as jp 10return j commit recovery.
to reproduce a build one needs to find the trigger commit.
there are several sub challenges here.
first temporary merge commits like temp1 in figure are the ones we need to extract but these are not retained by tra vis ci.
second g it s powerful history rewriting capabilities allow commits to be erased from history developers can and do collapse commits like prv1 into a single commit thus frustrating the ability to recover the consequent phantom merge commits.
p airminer pairfilter image recovery.
in principle t ra vis ci creates and retains docker images that allow re creation of build and test events.
in practice these images are not always archived as expected and so must be reconstructed.
p airfilter r eproducer runtime recovery.
building a specific project version often requires satisfying a large number of software dependencies on tools libraries and frameworks all or some of these may have to be time traveled to an earlier version.
r eproducer test flakiness.
even though t ra vis ci test behavior is theoretically recoverable via d ocker images tests may behave non deterministically because of concurrency or environmental e.g.
external web service changes.
such flaky tests lead to flaky builds which both must be identified for appropriate use in experiments.
r eproducer log analysis.
once a pair is recoverable b ugsw arm tries to determine the exact nature of the failure from the logs which are not well structured and have different formats for each language build system and test toolset combination.
thus the logs must be carefully analyzed to recover the nature of the failure and related metadata e.g.
raised exceptions failed test names etc.
so that the pair can be documented.
a nalyzer c. mining fail pass pairs pairminer extracts from a project s g itand build histories a set of fail pass job pairs algorithm .
p airminer takes as input a g ithub slug and produces a set of failpass job pairs annotated with trigger commit information for each job s parent build.
the p airminer algorithm involves delinearizing the project s build history extracting failpass build pairs assigning commits to each pair and extracting fail pass job pairs from each fail pass build pair.algorithm assigncommits algorithm input tra vis ci build b 1mark bas unavailable by default 2clone the g itrepository for b 3ifbis triggered by a push event then assign trigger commit tfrom t ra vis ci build metadata iftin g ithistory or tin g ithubarchive then mark bas available 7else if bis triggered by a pull request event then assign trigger commit t base commit b and merge commit mforbfrom t ra vis ci build metadata iftandbin g ithistory or min g ithubarchive then mark bas available analyzing build history.
pairminer first downloads the project s entire build history with the t ra vis ci api.
for each build therein p airminer notes the branch and if applicable the pull request containing the trigger commit pairminer first resolves the build history into lists of builds that were triggered by commits on the same branch or pull request.
p airminer recovers the results of the build and its jobs passed failed errored or canceled the .travis.yml configuration of each job and the unique identifiers of the build and its jobs using the t ra vis ci api.
identifying fail pass build pairs.
using the build and job identifiers p airminer finds consecutive pairs where the first build failed and the second passed.
builds are considered from all branches including the main line and any perennials and both merged and unmerged pull requests.
next the triggering commits are found and recovered from g ithistory.
finding trigger commits.
if the trigger commit was a push event then p airminer can find its sha via the t ra vis ci api.
for pull request triggers we need to get the pull request and base branch head shas and re create the phantom merge.
unfortunately neither the trigger commit nor the base commit are stored by t ra vis ci recreating them is quite a challenge.
fortunately the commit message of the phantom commit which is stored by t ra vis ci contains this information we follow beller et al.
to extract this information.
this approach is incomplete but is the best available.
tra vis ci creates temporary merges for pull request builds.
while temporary merges may no longer be directly accessible the information for such builds the head shas and base shas of the merges are accessible through the g ithub api.
we resort to g ithub archives to retrieve the code for the commits that are no longer in g ithistory.
even if the trigger commit is recovered from the phantom merge commit one problem remains developers might squash together all commits in a pull request thus erasing the constituent commits of the phantom merge right out of the githistory.
in addition trigger commits for push event builds can sometimes also be removed from the g ithistory by the project personnel.
as a result recreating this merge is not always possible we later show the proportion for which we authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
were able to reset the repository to the commits in the failpass pairs.
the two steps of phantom recovery first finding the trigger commits and then ensuring that the versions are available in g ithub are described in algorithm .
extracting fail pass job pairs.
pairminer now has a list of fail pass build pairs for the project.
as described in section ii each build can have many jobs one for each supported environment.
a build fails if any one of its jobs fails and passes if all of its jobs pass.
given a failing build p airminer finds pairs of jobs executed in the same environment where the first failed and the second passed.
such a pair only occurs when a defective version was fixed via source code patches and not by changes in the execution environment see algorithm .
d. finding essential information for reproduction pairs identified by p airminer must be assembled into reproducible containers.
to stand a chance of reproducing a job one must have access to at a minimum these essentials the state of the project at the time the job was executed and the environment in which the job was executed.
for each job in the pipeline p airfilter checks that these essentials can be obtained.
if the project state was deemed recoverable by p airminer pairfilter retrieves the original t ra vis ci log of the job and extracts information about the execution environment.
using timestamps and instance names in the log pairfilter determines if the job executed in a d ocker container and if so whether the corresponding image is still accessible.
if the log is unavailable the job was run before tra vis ci started using d ocker or the particular image is no longer publicly accessible then the job is removed from the pipeline.
e. reproducing fail pass pairs reproducer checks if each job is durably reproducible.
this takes several steps described below.
generating the job script.
travis build 5a component of tra vis ci produces a shell script from a .travis.yml file for running a t ra vis ci job.
r eproducer then alters the script to reference a specific past version of the project rather than the latest.
matching the environment.
to match the original job s runtime environment r eproducer chooses from the set of tra vis ci s publicly available d ocker images from quay and dockerhub based on the language of the project as indicated by its .travis.yml configuration and a timestamp and instance name in the original job log that indicate when that image was built with d ocker s tools.
reverting the project.
for project history reversion r epro ducer clones the project and resets its state using the trigger commit mined by p airminer .
if the trigger was on a pull request r eproducer re creates the phantom merge commit using the trigger and base commits mined by p airminer .
if any necessary commits were not found during the mining i b ugswa r m s main metadata attributes attribute type description project g ithubslug primary language build system and test framework reproducibility total number of attempts and number of successful attempts to reproduce pair pull request pull request merge timestamp and branch tra vis ci job t ra vis ci build id t ra vis ci job id number of executed and failed tests names of the failed tests trigger commit and branch name image tag unique image tag simultaneously serves as a reference to a particular d ocker image process r eproducer downloads the desired state of the project directly from a zip archive maintained by g ithub.
finally r eproducer plants the state of the project inside the execution environment to reproduce the job.
reproducing the job.
reproducer creates a new d ocker image as described in section iii e runs the generated job script and saves the resulting output stream in a log file.
reproducer can run multiple jobs in parallel.
r eproducer collects the output logs from all the jobs it attempts to reproduce and sends them to a nalyzer for parsing.
f .
analyzing results analyzer parses a t ra vis ci build log to learn the status of the build passed failed etc.
and the result of running the regression test suite.
if there are failing tests then a nalyzer also retrieves their names.
a challenge here the format of build logs varies substantially with the specific build system and the test framework so parsers must be specialized to each build and test framework.
for java we support the most popular build systems maven gradle and ant and test frameworks junit and testng .
for python we support the most popular test frameworks unittest unittest2 nose and pytest .
analyzer has a top level analyzer that retrieves all language agnostic items such as the operating system used for a build and then delegates further log parsing to languagespecific and build system specific analyzers that extract information related to running the regression test suite.
the extracted attributes number of tests passed failed and skipped names of the failed tests if any build system and test framework are used to compare the original t ra vis ci log and the reproduced log.
if the attributes match then we say the run is reproducible.
writing a new language specific analyzer is relatively easy mostly consisting of regular expressions that capture the output format of various test frameworks.
g. tools for bugswa r m users bugsw arm includes tools to support tasks such as artifact selection artifact retrieval and artifact execution.
6github allows one to download a zip archive of the entire project s file structure at a specific commit.
since this approach produces a standalone checkout of a project s history without any of the g itdata stores reproducer uses this archive only if a proper clone and reset is not possible.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii mined fail pass pairs push events pull request events language failed jobs all pairs available d ocker w image failed jobs all pairs available d ocker w image java python grand total greaterorequalslant0 greaterorequalslant10 greaterorequalslant20 greaterorequalslant30 greaterorequalslant40 number of projectspercentage of fail pass pairsjava python a percent of fail pass pairs per language50 number of projectsnumber of fail pass pairsjava python b cumulative number of fail pass pairs0 number of projectsnumber of pairs w imagejava python c cumulative number of pairs w image fig.
frequency of fail pass pairs artifact selection retrieval.
a given experiment may require artifacts meeting specific criteria.
for this reason each artifact includes metadata as described in table i. the bugswa r m website provides an at a glance view of the metadata for all artifacts.
simple filtering can be done directly via the web interface.
for more advanced filtering we provide a rest api a python api is also available.
to facilitate retrieval of artifact d ocker images we provide a b ugswa r m command line interface that masks the complexities of the d ocker ecosystem to use our artifacts.
given any b ugswa r m artifact identifier the cli can download the artifact image start an interactive shell inside the container and clean up the container after use.
artifact execution.
a typical workflow for experiments with bugswa r m involves copying tools and scripts into a container running jobs and then copying results.
we provide a framework to support this common artifact processing workflow.
the framework can be extended to fit users specific needs.
see the b ugsw arm website for example applications.
iv .
e xperimental ev alua tion our evaluation is designed to explore the feasibility of automatically creating a large scale dataset of reproducible bugs and their corresponding fixes.
in particular we answer the following research questions rq1 how often are fail pass pairs found in oss projects?
rq2 what are the challenges in automatically reproducing fail pass pairs?
rq3 what are the characteristics of reproducible pairs?
the b ugsw arm infrastructure is implemented in python.
uses a modified version of the travis build component from t ra vis ci to translate .travis.yml files into shell scripts.
the initial java specific a nalyzer was ported to python from t ra vis torrent s implementation in ruby.
a nalyzer has been extended to support junit for java and now also supports python.
bugswa r m requires that a project is hosted on g ithub and uses t ra vis ci.
we randomly selected projects among the g ithub projects with the most t ra vis ci builds for each of java and python.
a. mining fail pass pairs we inspected a total of jobs across projects from which are failed jobs.
we mined a total of fail pass pairs.
as described in section iii c pairs can originate from push events or pull request events.
table ii shows the breakdown push events contribute to of the fail pass pairs and pull requests contribute to .
note that fail pass pairs represent an under approximation of the number of bug fix commits bugswa r m pairs do not capture commits that fix a bug whose build is not broken.
we calculate the percentage of fail pass pairs with respect to the total number of successful jobs potential fixes to a bug per project.
figure 2a plots a cumulative graph with the results.
in general we find that java projects have a slightly higher percentage of fail pass pairs at most than python projects at most .
for example there are java projects and python projects for which at least of the passing jobs fix a build.
figure 2b plots the cumulative number of fail pass pairs per project.
the java and python projects with the most pairs have and pairs respectively.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii reproduced pairs fully reproducible flaky language pairs to reproduce w failed test w failed job error pass total pairs unreproducible pending java python grand total greaterorequalslant0 greaterorequalslant20 greaterorequalslant40 greaterorequalslant60 greaterorequalslant80 number of projectspercentage of reproduced pairsjava python a cumulative percentage of reprod.
pairs20 number of projectsnumber of reproduced pairsjava python b cumulative number of reprod.
pairsw failed testw failed joberror pass0200400600800 48number of pairsjava python c breakdown of reproduced pairs fig.
reproduced pairs we run p airfilter to discard fail pass pairs that are unlikely to be reproducible.
table ii shows the number of failpass pairs after each filter is applied.
specifically columns available show the pairs we can reset to or which are archived columns d ocker show the number of remaining pairs that use a d ocker image and columns w image show the number of remaining pairs for which we can locate t ra vis ci base images.
figure 2c plots the cumulative number of w image pairs which are passed to r eproducer .
a total of java projects and python projects have w image pairs.
rq1 at most and of all pairs of java and python projects respectively follow the fail pass pattern figure .
among projects we find a total of fail pass pairs from which pairs may be reproducible.
b. reproducing fail pass pairs we successfully reproduced out of attempted pairs pairs are pending reproduction due to time constraints .
recall from section iii c that p airminer mines job pairs .
the corresponding number of reproducible unique build pairs is for java and for python .
the rest of the paper describes the results in terms of number of job pairs.
the artifacts belong to java projects and python projects.
table iv lists the projects with the most artifacts for each language.
we repeated the reproduction process times for each pair to determine its stability.
if the pair is reproducible all times then it is marked as reproducible.
if the pair is reproduced only sometimes then it is marked as flaky.
otherwise the pair is said to be unreproducible.
numbers for each of these categories can be found in table iii.figure 3a shows the cumulative percentage of reproduced pairs across projects.
we achieve a pair reproduction rate for java projects and python projects at least for java projects and python projects and at least pair is reproducible in java projects and python projects.
figure 3b shows the cumulative number of reproduced pairs.
the java and python projects with the most reproducible pairs have and respectively.
we further classify reproducible and flaky pairs into three groups pairs that have failed tests pairs that do not have failed tests despite a failed build and pairs whose build finishes with an error.
and are labeled failed and errored .
this naming convention is from t ra vis ci and is defined by the part of the job lifecycle that encounters a non zero exit code.
typically errored builds have dependency related issues.
figure 3c shows the breakdown for both java and python.
we find that .
.
and .
of reproducible pairs correspond to each of the above categories respectively.
surprisingly only pairs were flaky.
we suspect a number of unreproducible pairs are indeed flaky but running them times was not sufficient to identify them.
we plan to investigate how to grow the number of flaky pairs in bugsw arm .
an initial direction could involve selecting pairs based on keywords in their commit messages e.g.
.
among all the pairs that we attempted to reproduce most were not reproducible.
in other words the log of the original job and the log produced by r eproducer were different.
to gather information about the causes of unreproducibility we randomly sampled unreproducible job pairs and manually inspected their logs two logs per job pair .
for this task we also examined the corresponding original logs authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv top projects with artifacts java pairs python pairs raphw byte buddy terasolunaorg guideline checkstyle checkstyle scikit learn scikit learn square okhttp numpy numpy hubspot baragon python mypy tananaev traccar marshallward f90nml table v sources of unreproducibility reason pairs failed to install dependency url no longer valid or network issue tra vis ci command issue project specific issue reproducer did not finish permission issue total produced by t ra vis ci to compare the differences between logs and categorize the various sources of unreproducibility.
as shown in table v we identified sources of unreproducibility.
from the jobs around are unreproducible due to missing or incompatible dependencies.
another referenced stale urls or experienced network issues.
exceptions from invoking travis build when creating build scripts are responsible for another .
the rest of the jobs are unreproducible due to project specific issues failure to terminate within the time budget or permission errors.
interestingly jobs are actually reproducible but since the corresponding failed or passed job is not reproducible the entire pair is marked as unreproducible.
we have not included unreproducible pairs in this iteration of b ugsw arm but we think these could also be potentially useful to researchers interested in automatically fixing broken builds.
rq2 reproducing fail pass pairs is indeed challenging with a .
success rate.
based on the manual inspection of unreproducible artifacts we identified main reasons for unreproducibility listed in table v. c. general characteristics of bugswa r m artifacts we have aggregated statistics on various artifact characteristics.
figure 4a shows the number of artifacts with a given number of changes additions or deletions .
inserting or removing a line counts as one change.
modifying an existing line counts as two changes an addition and a deletion .
commits with zero changes are possible but rare and are not included in figure 4a.
we report the number of changes of the fixed version with respect to the failing version of the code e.g.
of the artifacts have at most changes and have at most .
figure 4b shows the number of projects with a given number of files changed e.g.
of the artifacts have at most changed files.
figure 4c shows the artifacts with a given number of failed tests.
we find that our artifacts are diverse in several aspects table vi diversity of artifacts type artifacts type artifacts language longetivity java python build system test framework maven junit gradle unittest ant others language build system test framework and longevity.
table vi shows the number of reproducible and flaky artifacts for each of these categories.
the current dataset has over a thousand artifacts for java and python with a wide range of build systems and testing frameworks being used.
from these the most common build system is maven with artifacts and the most common testing framework is junit with .
we plan to add support for other languages such as javascript and c in the near future which will increase the number of build systems and testing frameworks being used.
our artifacts represent a variety of software bugs given the diverse set of projects mined.
to better understand the types of bugs in b ugswa r m we conduct a manual classification of randomly sampled maven based java artifacts first described in .
the top classification categories are shown in figure 5a.
the classification is not one to one an artifact may fall under multiple categories depending on the bug.
to correctly classify an artifact we examine the source code diff commit message and t ra vis ci log.
we find that the largest category is logic errors.
examples of logic errors include off by one errors and incorrect logical operations.
we also conduct an automatic higher level classification of artifacts based on the encountered exceptions or runtime errors.
we analyze the build logs and search for the names of java exceptions and python runtime errors.
figures 5b and 5c show the exceptions errors for which b ugswa r m has the most artifacts.
for example java artifacts fail with a nullpointerexception.
an example is shown in figure .
using the b ugsw arm framework presented in section iii g we successfully ran the code coverage tool cobertura and two static analyzers google s errorprone and spotbugs on the randomly selected artifacts used in the manual classification with minimal effort.
rq3 we investigated various characteristics of artifacts such as the distribution in the size of the diff location of the diff and number of failing tests figure .
we also examined the reason for failure figure .
for example artifacts have between and changes artifacts modify a single file artifacts have failing test and the top reason for a build failure is an assertionerror.
d. performance pairminer and r eproducer can be run in the cloud in parallel.
the b ugswa r m infrastructure provides support to run these as batch tasks on microsoft azure .
running time of p airminer depends on the number of failed jobs authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
1537946number of artifacts a number of changes1 1124527104number of artifacts b number of files changed1 2331721314326105number of artifacts c number of failing tests fig.
artifact characteristics 100resource leakcasting errorvisibility erroridentifier errordependency errorconfiguration errornullpointerexceptionassertion errortest errorlogic error number of artifacts a manual classification of java bugs0 400saxparseexc.filenotfoundexc.socketexc.illegalargumentexc.ioexc.classnotfoundexc.runtimeexc.illegalstateexc.nullpointerexc.assertionerr.
number of artifacts b most frequent java exceptions0 500ioerr.runtimeerr.syntaxerr.filenotfounderr.nameerr.importerr.typeerr.v alueerr.attributeerr.assertionerr.
number of artifacts c most frequent python errors fig.
artifact classification protected void loadcommandverificationsheet spacesystem spacesystem string sheetname sheet sheet switchtosheet sheetname false if sheet null return int i while i sheet.getrows search for a new command definition ... fig.
example of nullpointerexception bug and its fix.
to examine taking between a few minutes to a few hours.
reproduction time varies per project as it depends on the project s build time and the number of tests run.
mining and reproducing the pairs reported in this paper required about hours of compute time in azure.
we will continue our effort to mine and reproduce pairs in additional projects.
v. l imita tions and future work pairminer searches for two consecutive failed and passed builds first then looks for failed and passed job pairs within these two builds.
however failed and passed job pairs can occur between two consecutive failed builds because a build marked as failed requires only one unsuccessful job.
in addition the fail pass pattern does not guarantee that the difference between the two commits is actually a fix for the failure thesupposed fix could simply delete or revert the buggy code or disable any failing tests.
using only the pattern p airminer would also fail to identify a fix for a failure if the fix is committed along with the test cases that expose the fail point.
finally the fix may not be minimal.
we plan to address some of these challenges in the future.
in particular we would like to explore other mining approaches that involve new patterns as well as bug reports.
note that r eproducer is already capable of reproducing any pair of commits that triggered t ra vis ci builds regardless of how these commits are gathered.
reproducible artifacts may still break later on due to stale urls among other reasons.
to keep b ugswa r m up to date we periodically test artifacts.
we are currently exploring ways to make the artifacts more robust.
in the future we would like to crowdsource the maintainability of b ugswa r m .
thus far our mining has been blind.
however it is possible to extend our mining tools to find pairs with specific characteristics e.g.
pairs that have at most changes and a single failed test caused by a nullpointerexception .
such guided mining will allow b ugswa r m to grow in directions of interest to the research community.
finally we plan to extend bugsw arm to continuously monitor t ra vis ci events for real time mining and reproducing of new artifacts.
vi.
r ela ted work some other defect repositories aim to provide experimental benchmarks for defect location and repair.
on the whole these authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
repositories do not exploit ci and virtualization mechanisms they generally pre date the widespread adoption of these techniques.
they do not achieve the same scale diversity and currency and are not as durably reproducible .
the siemens test suite small c programs and about manually seeded bugs is among the earliest.
bugbench is one of the earliest datasets of real world bugs.
bugbench is limited in scale and diversity consisting of memory and concurrency bugs found across c c os projects.
each buggy program version includes failing tests.
begbunch contains two suites to measure the accuracy and scalability of bug detection tools for c. ibugs is a dataset drawn from the year history of the aspectj compiler with faulty versions of the project.
ibugs provides metadata such as number of methods and classes involved in the bug fix.
unlike b ugsw arm the above datasets were manually constructed.
metadata such as that included in ibugs could be built from b ugswa r m artifacts with additional effort.
the software artifact infrastructure repository sir comprises source code tests and defects from os projects along with needed infrastructure e.g.
automated build and test scripts .
currently sir consists of projects in four languages of which c c c and java include fault data real ones seeded ones and a combination of real seeded and mutated.
a project may contain multiple versions and each version may contain multiple faults with a total of bugs.
sir provides a useful amount of scale and diversity while archiving sufficient tooling for durable reproducibility.
however since it pre dates ci and d ocker each defect datum therein is manually assembled.
thus sir is difficult to scale up further and requires substantial effort to keep current.
b ugsw arm already has reproducible defects the automated mining of ci and d ocker image artifacts lowers the cost of keeping the dataset growing.
many bugs is a benchmark for program repair with defects and fixes from large c projects.
each defect and fix includes tests and is manually categorized.
to facilitate the reproduction of these defects m any bugs provides virtual machine images recently extended to use d ocker .
unlike b ugswa r m mining and reproducing bugs requires significant manual effort and thus m any bugs is not as easy to extend.
on the other hand m any bugs provides a detailed bug categorization that can be useful for experiments and its artifacts are collected from c programs a programming language that b ugsw arm does not currently support.
defects4j is a dataset of real reproducible bugs from large java projects.
defects4j provides manually constructed scripts for each project s build and test the entire setup relies on a functioning jvm.
defects4j provides an interface for common tasks and provides support for a number of tools.
the bugs.jar dataset contains real reproducible java bugs collected from apache projects by identifying commit messages that reference bug reports.
bugs.jar artifacts are stored on g itbranches.
by contrast bugswa r m relies on virtualized d ocker packaged build and test environments automatically harvested from the cross platform t ra vis ci archives thus it is neither limited to java nor does it require manual assembly of build and test tools.
in addition to the test fail pass pairs we include build failures and even flaky tests.
the above allows b ugswa r m to achieve greater scale diversity and currency.
urli et al.
describe an approach to mining builds that fail tests from t ra vis ci.
this work can only handle mavenbased java builds these are reproduced directly without docker .
their dataset includes maven java builds for the purpose of automatic repair.
delfim et al.
develop bears which mines maven based java g ithubprojects that use t ra vis ci.
b ears attempts to reproduce every mined build in the same environment which does not account for the developer tailored .travis.yml file whereas b ugswa r m leverages d ocker images to match each job s original runtime environment.
compared to b ugswa r m b ears has a similar reproduction success rate of builds .
b ears pushes artifacts to g itbranches instead of providing them as d ocker images and relies on maven for building and testing so new infrastructure must be implemented to include artifacts from other build systems.
our d ocker based approach allows other languages and build systems and reflects our designed in pursuit of greater diversity and reproducibility.
note that the b ugswa r m toolset supports the creation of fully reproducible packages for any pair of commits for which the t ra vis ci builds are archived.
there are over 900k projects in g ithub that use tra vis ci so our toolkit enables the creation of datasets and ensuing experiments at a scale substantially larger than previous datasets allow.
vii.
c onclusions this paper described b ugswa r m an approach that leverages ci to mine and reproduce fail pass pairs of realistic failures and fixes in java and python oss.
we have already gathered such pairs.
we described several exciting future directions to further grow and improve the dataset.
we hope bugswa r m will minimize effort duplication in reproducing bugs from oss and open new research opportunities to evaluate software tools and conduct large scale software studies.