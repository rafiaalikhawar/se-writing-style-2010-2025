lifting datalog based analyses to software product lines ramy shahin rshahin cs.toronto.edu university of toronto canadamarsha chechik chechik cs.toronto.edu university of toronto canadarick salay rsalay cs.toronto.edu university of toronto canada abstract applying program analyses to software product lines spls has been a fundamental research problem at the intersection of product line engineering and software analysis.
different attempts have been made to lift particular product level analyses to run on the entire product line.
in this paper we tackle the class of datalog based analyses e.g.
pointer and taint analyses study the theoretical aspects of lifting datalog inference and implement a lifted inference algorithm inside the souffl datalog engine.
we evaluate our implementation on a set of benchmark product lines.
we show significant savings in processing time and fact database size billions of times faster on one of the benchmarks compared to brute force analysis of each product individually.
ccs concepts software and its engineering automated static analysis software design techniques .
keywords software product lines datalog program analysis pointer analysis lifting doop souffl acm reference format ramy shahin marsha chechik and rick salay.
.
lifting datalog based analyses to software product lines.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.acm new york ny usa pages.
introduction software product lines spls are families of related products usually developed together from a common set of artifacts.
each product configuration is a combination of features.
as a result the permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
of potential products is combinatorial in the number of features.
this high level of configurability is usually desired.
however analysis tools syntax analyzers type checkers model checkers static analysis tools etc... typically work on a single product not the whole spl.
applying an analysis to each product separately is usually infeasible for non trivial spls because of the exponential number of products .
since all products of an spl share a common set of artifacts analyzing each product individually usually referred to as brute force analysis would involve a lot of redundancy.
how to leverage this commonality and analyze the whole product line at once bringing the total analysis time down is a fundamental research problem at the intersection of product line engineering and software analysis.
different attempts have been made to liftindividual analyses to run on product lines .
those attempts show significant time savings when the spl is analyzed as a whole compared to brute force analysis.
the downside though is the amount of effort required to correctly lift each of those analyses.
in this paper we tackle the class of datalog based program analyses.
datalog is a declarative query language that adds logical inference to relational queries.
some program analyses in particular pointer and taint analyses can be fully specified as sets of datalog inference rules.
those rules are applied by an inference engine to facts extracted from a software product.
results are more facts inferred by the engine based on the rules.
the advantage of datalog based analyses is that they are declarative concise and can be efficiently executed by highly optimized datalog engines .
instead of lifting individual datalog based analyses we lift a datalog engine.
this way any analysis running on the lifted engine is lifted for free.
our approach is not specific to a particular engine though and can be implemented in others.
contributions in this paper we make the following contributions we present infer a datalog inference algorithm lifted to facts extracted from software product lines.
we state the correctness criteria of lifted datalog inference and show that infer is correct.
we implement our lifted algorithm as a part of a datalog engine.
we also extend the doop pointer analysis framework to extract facts from spls.
we evaluate our implementation on a sample of pointer and taint analyses applied to a suite of java benchmarks.
we show significant savings in processing time and fact database sizes compared to brute force analysis of one product at a time.
for one of the benchmarks our lifted implementation is billions of times faster than brute force analysis with savings in database size of the same order of magnitude .arxiv .02192v2 jul 2019esec fse august tallinn estonia ramy shahin marsha chechik and rick salay the rest of the paper starts with a background on spls and datalog sec.
.
we provide a theoretical treatment of datalog inference how the inference algorithm is lifted together with correctness criteria and a correctness proof in sec.
.
in sec.
we describe the implementation of our algorithm in the souffl engine.
evaluation process and results are discussed in sec.
.
we compare our approach to related work in sec.
and conclude sec.
.
background in this section we summarize the basic concepts of software product lines horn clauses datalog and datalog based analyses.
.
software product lines asoftware product line spl is a family of related software products developed together.
different variants of an spl have different features i.e.
externally visible attributes such as a piece of functionality support for a particular peripheral device or a performance optimization.
definition spl .
an spllis a tuple f d where fis the set of features s.t.
an individual product can be derived from l via a feature configuration f. prop f is a propositional formula over fdefining the valid set of feature configurations.
is called a feature model fm .
the set of valid configurations defined by is called conf l .
dis a set of program elements called thedomain model .
the whole set of program elements is sometimes referred to as the representation .
d prop f is a total function mapping each program element to a proposition feature expression defined over the set of features f. e is called thepresence condition pc of element e i.e.
the set of product configurations in which eis present.
example.
consider the annotative java product line with feature setf fa fb shown in listing .
features are annotated using the c pre processor cpp conditional compilation directives.
by defining or not defining macros corresponding to features different products can be generated from this product line.
one example is the product on listing with fanot defined and fbdefined.
here a single code base domain model d is maintained where different pieces of code are annotated with feature expressions.
for example tokens on line are annotated with fa.
that is fais the pc of these tokens.
similarly tokens on line have the pc fb.
this spl allows all four feature combinations so its feature model istrue .
.
horn clauses and datalog .
.
horn clauses.
ahorn clause hc is a disjunction of unique propositional literals with at most one positive literal.
for example a b c d is an hc which can be also written as a reverseimplication c a b d where cis called the head and a b d is called the body of the clause.
the language of hcs is a fragment of propositional logic that can be checked for satisfiability in linear1 c l a s s p a r e n t public o b j e c t f c l a s s classa extends p a r e n t c l a s s classb extends p a r e n t classa o1 new classa classb o2 new classb i f d e f fa p a r e n t o3 o1 else p a r e n t o3 o2 endif i f d e f fb o2 .
f o1 else o2 .
f o2 endif o b j e c t r o3 .
f listing a product line with features faand fb.
c l a s s p a r e n t public o b j e c t f c l a s s classa extends p a r e n t c l a s s classb extends p a r e n t classa o1 new classa classb o2 new classb p a r e n t o3 o2 o2 .
f o1 o b j e c t r o3 .
f listing a product with a configeration fa fb .
time as opposed to general propositional satisfiability which is np complete .
.
.
datalog.
datalog is a declarative database query language that extends relational algebra with logical inference .
datalog inference rules are hcs in first order logic where atoms are predicate expressions not just propositional literals.
a factis a ground rule with only a head and no body.
syntactically the symbol is usually used instead of backward implication and atoms in the body are separated by commas instead of the conjunction symbol.
fig.
1a defines the grammar of datalog clauses as follows building blocks are finite sets of constants variables and predicate symbols a term is a constant or a variable symbol a predicate expression is an n ary predicate applied to arguments a factis a ground predicate expression i.e.
all of its arguments are constants a ruleis a horn clause of predicate expressions and a datalog clause is either a fact or a rule.
a datalog program is a finite set of rules usually referred to as theintensional database idb which operates on a finite set of facts called the extensional database edb .
the inference algorithmlifting datalog based analyses to software product lines esec fse august tallinn estonia explained next repeatedly applies the rules to the facts inferring new facts and adding them to the edb until a fixed point is reached i.e.
no more new facts can be inferred .
.
.
inference algorithm algorithm .
for each rule r the algorithm checks to see if the edb has facts fulfilling the premises of r with a consistent assignment of variables to constants .
if it does the head of that rule is inferred as a new fact f. iff doesn t already exist in the edb it is added to it.
newly inferred facts may trigger some of the rules again this process continues until a fixed point is reached i.e.
no new facts are inferred.
this algorithm called the forward chaining algorithm is guaranteed to terminate because it does not create any new constants and runs in polynomial time w.r.t.
the number of input clauses .
data input idb edb result edb inferred clauses repeat fixpoint true foreach c s1 ... sn idbdo foreach f1 ... fn fi edb si fido if c edb then fixpoint false edb edb c end end end until fixpoint return edb algorithm inference algorithm infer forward chaining .
.
example of a datalog analysis some program analyses can be written in datalog as sets of clauses.
facts relevant to the analysis are extracted from the program to be analyzed and then fed into a datalog engine together with the analysis clauses.
fact extraction is usually analysis specific because different analyses work on different aspects of the program.
one example of datalog based analyses is pointer analysis.
pointer analysis determines which objects might be pointed to by a particular program expression.
this whole program analysis isover approximating in the sense that it returns a set of objects that might be pointed to by each pointer possibly with false positives.
fig.
2a shows a set of datalog rules for a simple pointer analysis .
each predicate defines a relation between different artifacts.
for example varpointsto v h states that pointer vmight point to heap object h. the first three rules specify the conditions for this predicate to hold either a new object is allocated and a pointer is initialized a pointer that already points to an object is assigned to another pointer or an object field points to a heap object and that field is assigned to another pointer.
the fourth rule states that assigning a value to an object field results in that field pointing to the same object as the right hand side of the assignment.fig.
2b shows the facts corresponding to the program in listing .
the first two are object allocation facts the third is an assignment fact and the fourth and the fifth are store and load facts respectively.
fig.
2c is the results of running the datalog inference algorithm on those rules and facts.
the example in fig.
2a is called acontext insensitive pointer analysis because it does not distinguish between different objects call sites and types in a class hierarchy.
more precise context sensitive pointer analyses take different kinds of context into consideration.
for example a call site sensitive analysis considers method call sites.
a object sensitive analysis similarly type sensitive includes object allocation sites types of objects allocated as part of the context.
lifting datalog in this section we present our approach to lifting datalog abstract syntax and the datalog inference algorithm.
we also formally state the correctness criteria for lifted datalog inference and outline a correctness proof of our lifted algorithm.
.
annotated datalog clauses when analyzing a single software product an initial set of facts is extracted from product artifacts and analysis rules are applied to those facts eventually adding newly inferred facts to the initial set.
in the case of spls a fact might be valid only in a subset of products and not necessarily the entire product space.
we have to associate a representation of that subset with each of the extracted facts.
similar to spl annotation techniques a presence condition pc is a succinct representation that can be used to annotate facts.
facts annotated with pcs are called lifted facts and are stored in a lifted extensional database dedb.
given a feature expression we define dedb to be the set of facts from dedb which only exist in the product set defined by dedb f f pc dedb sat pc when the datalog inference algorithm is applied to annotated facts we have to take the pcs attached to facts into account.
whenever the inference algorithm generates a new fact we need to associate a pc to it.
if fnew is generated from premises f1 f2 ... fn with pcs pc1 ... pcn then pcnew attached to fnew should be the conjunction of the input pcs i.e.
pc1 ... pcn.
intuitively pcnew represents the set of products in which fnew exists which is the intersection of the sets of products in which the premises exist.
to avoid having too many generated facts that are practically vacuous we check pcnew for satisfiability.
if it isn t satisfiable then its corresponding fact exists in the empty set of products i.e.
nonexistent.
those facts can be safely removed from dedb potentially improving the performance of inference.
.
lifted inference algorithm algorithm takes a set of datalog rules idb and a set of annotated facts dedb as input and returns all inferred clauses annotatedesec fse august tallinn estonia ramy shahin marsha chechik and rick salay s finite set of constant symbols v finite set of variables p finite set of predicate symbols t s v l p t1 ... tn f p s1 ... sm r l0 l1 ... lk d f r a datalog grammar.
v s c c for each free variable vinc b variable assignment function and substitution for clause c. pc f pc pc pc pc pc bd f pc r c grammar for lifted datalog clauses.
syntactic category fis set of feature names.
figure a grammar of datalog clauses b variable assignment function and substitution and c lifted datalog clauses.
varpointsto v1 h1 new v1 h1 .
varpointsto v1 h2 assign v1 v2 varpointsto v2 h2 .
varpointsto v1 h2 load v1 v2 f varpointsto v2 h1 heappointsto h1 f h2 .
heappointsto h1 f h2 s t o r e v1 f v2 varpointsto v1 h1 varpointsto v2 h2 .
a pointer analysis rules.new o1 a .
l i n e new o2 b .
l i n e assign o3 o2 .
l i n e s t o r e o2 f o1 .
l i n e load r o3 f .
l i n e b facts extracted from listing .
varpointsto o1 a .
varpointsto o2 b .
varpointsto o3 b .
heappointsto b f a .
varpointsto r a .
c results of applying the rules to the extracted facts.
figure a context insensitive pointer analysis rules simplistic b input facts and c output facts for program in listing .
c s1 ... sn s1 f1 ... sn fn i n fi edb v s cmp c s1 ... sn s1 f1 ... sn fn i n fi pci dedb v s c pc1 ... pcn dmp figure modus ponens for a datalog clauses and b lifted datalog clause inference.
with their corresponding presence conditions.
the structure of this algorithm is similar to that of algorithm with the exception of conjoining the presence conditions of the facts used in inference and assigning the conjunction as the presence condition of the result.
there are four cases for c pcc to consider if sat pcc is false pccis not satisfiable then this result is ignored because it doesn t exist in any valid product if c pcc dedb then this result is also ignored because it already exists for the same set of products if c pcd dedb where pcd pcc then c pcd is replaced with c pcd pcc indedb .
this means we are expanding the already existing set of products in which cexists to also include the set denoted by pcc if cdoesn t exist at all in dedb we add c pcc to it.
for example when the lifted inference algorithm is applied to the rules in fig.
2a and annotated facts in fig.
the result is the following varpointsto o1 a true .
varpointsto o2 b true .
varpointsto o3 a fa .
varpointsto o3 b !
fa .
heappointsto b f a fb .
heappointsto b f b !
fb .
varpointsto r a fa .
varpointsto r b !
fa .
.
correctness criteria when applying the lifted inference algorithm infer to a set of rules idb and a set of annotated facts dedb we expect the result to be exactly the union of the results of applying infer to facts from each product individually.
moreover each clause in the result of inferlifting datalog based analyses to software product lines esec fse august tallinn estonia data input idb dedb result dedb annotated inferred clauses repeat fixpoint true foreach c s1 ... sn idbdo foreach f1 pc1 ... fn pcn fi pci dedb si fido pcc pc1 ... pcn ifsat pcc then if c pcc dedb then fixpoint false if pcd c pcd dedb then pcc pcc pcd dedb dedb c pcd end dedb dedb c pcc end end end end until fixpoint return dedb algorithm lifted inference algorithm infer .
has to be properly annotated i.e.
its presence condition has to represent exactly the set of products having this clause in their un lifted analysis results .
theorem .
given an spll f d a set of rules idb and a set of lifted facts dedb annotated with feature expressions over f conf l infer dedb infer dedb proof.
c infer dedb c infer dedb by structural induction over the derivation tree of c base case c pc dedb where sat pc .
then c dedb by definition of restriction operator .
since inputs are already included in the output of infer c infer dedb .
induction hypothesis given a rule r c s1 ... sn and a variable assignment i n si infer dedb si infer dedb induction step cis derived by dmp from rule r. since all the premises of care in infer dedb induction hypothesis then so is c mp .
c infer dedb c infer dedb by structural induction over the derivation tree of c base case assume c pc dedb for some pc where sat pc .
then c pc infer dedb input included in output of infer .
since pc is satisfiable then c infer dedb definition of restriction .
figure the doop architecture.
induction hypothesis given a rule r c s1 ... sn and a variable assignment i n si infer dedb si infer dedb induction step cis derived by mp from rule r. since all the premises of care in infer dedb induction hypothesis then so is c dmp .
implementation in this section we explain how we lift the doop pointer and taint analysis framework together with its underlying souffl datalog engine.
.
lifting doop to illustrate and evaluate the datalog lifting approach outlined in sec.
we modified the doop datalog based pointer analysis framework1 together with its underlying souffl datalog engine2.
fig.
outlines the doop architecture.
doop is an extensible family of pointer and taint analyses implemented as datalog rules.
in addition it includes a fact extractor from java bytecode.
doop users select a particular analysis among the available analyses through a command line argument.
the rules corresponding to the chosen analysis the idb together with the extracted facts the edb are then passed to souffl .
since doop extracts syntactic facts we need to identify the pcs of each of the syntactic tokens contributing to a fact and associate the conjunction of those pcs as the fact pc.
we had to do this for each type of fact extracted by doop.
the fact pc is just added to a fact as a trailing pc field prefixed with .
facts with no pc field are assumed to belong to all products an implicit pc of true .
our doop modifications were only in the fact extractor.
none of the doop datalog rules were changed.
our fact extraction modifications were scattered because extractors for different kinds of facts are 1available online at 2available online at august tallinn estonia ramy shahin marsha chechik and rick salay new o1 a true .
l i n e new o2 b true .
l i n e assign o3 o1 fa .
l i n e assign o3 o2 !
fa .
l i n e s t o r e o2 f o1 fb .
l i n e s t o r e o2 f o2 !
fb .
l i n e load r o3 f true .
l i n e figure annotated facts extracted from listing .
figure souffl architecture.
implemented separately in doop.
however all those changes were systematic and non invasive.
in total we modified only about lines of code in the doop fact extractor.
.
lifting souffl as seen in fig.
a souffl program is first parsed and translated into a relational algebra machine ram program.
ram is a language with relational algebra constructs in addition to a fixed point looping operator.
based on a command line argument souffl then either interprets the ram program on the fly or synthesizes c code that is semantically equivalent to the ram program.
since c programs are compiled typically by optimizing compilers into native machine code native executables are at least an order of magnitude faster than interpreted analyses .
in this paper we only cover the souffl interpreter.
at the syntax level we extend the souffl language with fact annotations .
those are propositional formulas prefixed with .
the souffl parser is extended with a syntactic category for propositional formulas.
ast nodes for facts are extended with a pc field with a default value of true.
propositional variables are added to a symbol table separate from that holding souffl identifiers.
as a part of compiling souffl programs into ram we turn syntactic presence conditions into binary decision diagrams bdds .
we use cudd as a bdd engine and on top of it maintain a mapfrom textual presence conditions to their corresponding canonical bdds.
as stated in infer when facts are resolved with a rule the conjunction of their pcs becomes the conclusion s pc.
souffl implements several indexing and query optimization techniques to improve inference time.
to keep our changes independent of those optimizations we add the presence condition as a field opaque to the query engine.
we only manipulate this field as a pc when performing clause resolution which takes place at a higher level than the details of indexing and query processing.
this way we avoid touching relatively complex optimization code while preserving the semantics of our lifted inference algorithm.
some relational features of souffl were not lifted.
for example aggregation functions sum average max min etc... still return singleton values.
none of those functions is used by doop on lifted facts so this does not affect the correctness of our results.
we still plan to address this general limitation in the future though.
evaluation table java product lines used for evaluation.
benchmark size kloc features valid configurations berkeleydb gpl .
lampiro mm08 .
prevayler .
we evaluate the performance of our lifted version of doop together with lifted souffl on five java benchmark product lines previously used in the evaluation of other lifted analyses .
for each of the benchmarks table lists its size in thousands of lines of code number of features and number of valid configurations according to its feature model.
for example berkeleydb is about lines of code comprised of features and has about .
billion valid product configurations.
we evaluate three doop analyses context insensitive pointer analysis insens onetype heap sensitive pointer analysis 1type heap and one call site heap sensitive taint analysis taint 1call heap .
for taint analysis we use the default sources sinks transform and sanitization functions curated in doop for the jdk and android .
all experiments were performed on a quad core intel core i7 processor running at .4ghz with 16gb ram and hyper threading enabled running bit ubuntu linux kernel version .
.
pointer and taint analyses work on the whole program including library dependencies.
since general purpose libraries usually do not have any variability the comparison between lifted and singleproduct analyses is independent of them.
moreover time spent in analyzing library code and space taken by their facts might skew the overall results.
we restrict our experiments to application code and direct dependencies only using the doop command line argument xfacts subset app n deps .
doop extracts its facts from java byte code.
however spl annotation techniques work at the source code level.
feature selectionlifting datalog based analyses to software product lines esec fse august tallinn estonia usually takes place at compile time which means an spl codebase is compiled into a single product.
to get around this limitation we had to choose benchmarks that only have disciplined annotations in the sense that adding or removing an annotation preserves the syntactic correctness of the representation.
this is not a limitation of our lifted inference algorithm though.
the benchmarks we chose are annotated using cide which uses different highlighting colors as presence conditions.
we had to extract this color information from cide together with the mapping from colors to locations of tokens line and column number in source files.
our fact extractor uses byte code symbol information to locate tokens and assign their presence conditions based on cide colors.
the primary goal of our experiments is to compare the performance of lifted analyses applied to the spls to that of running the corresponding product level analyses on each of the valid configurations individually.
since the number of valid product configurations for some benchmarks is relatively big it is neither practical nor particularly useful to enumerate all of the valid products and analyze them.
instead for each spl we run the product level analysis on two code base subsets the base code common across all variants and the representation the whole spl code base implementing all feature behaviors .
although those two extremes are not necessarily valid products they are the lower bound and the upper bound in terms of code size and averaging over them gives an average valid product approximation.
the expected brute force performance is the average valid product performance p avg multiplied by the number of valid configurations.
we split our evaluation into two parts fact extraction and inference and evaluate performance in terms of both the processing time and space size of the fact database in kilobytes kb .
our primary research questions are rq1 how do fact extraction time and size of the extracted fact database of lifted analyses compare to brute force fact extraction?
rq2 how do the souffl inference time and the size of the inferred database of lifted analyses compare to brute force analysis?
.
fact extraction table summarizes the average performance of product level fact extraction p avg and that of the lifted fact extraction for the entire product line spl .
for each of the three analyses we compare fact extraction time in milliseconds and the size of the extracted database in kb .
for example for context insensitive analysis average fact extraction time of a single product of prevayler is 416ms and the average size of the extracted fact database is 230kb.
on the other hand extracting facts from the whole prevayler spl at once takes 554ms and the extracted fact database is 407kb.
the difference between p avg time and spl time is very small for all three analyses and five benchmarks which is expected since extraction is syntactic and thus its time is proportional to code base size not the number of features.
size of the extracted database is figure context insensitive fact extraction speedup and db savings factors spl vs average product.
noticeably bigger for lifted extraction db spl columns because lifted facts are augmented with presence conditions.
to evaluate the savings attributed to lifted fact extraction compared to brute force extraction in terms of time and space we compute the speedup and space saving factors p avg conf l spl .
fig.
shows a log scale bar graph of lifted fact extraction speedup and space savings for context insensitive analysis.
the other two analyses exhibit a similar trend and are omitted here.
the figure shows that the time and space savings are proportional to the number of valid configurations of the product line.
for example lampiro has valid configurations and its lifted fact extraction is times faster than brute force with a database times smaller than the total space of brute force databases.
on the other hand prevayler has only valid configurations with an insens lifting speedup factor of and a space savings factor of .
since different analyses typically require different facts the size of the fact database also varies from one analysis to another.
experimental results do not show a direct correlation between an analysis and the size of its fact database.
for example in lampiro the taint 1call heap databases are significantly bigger than those of 1type heap .
berkeleydb on the other hand exhibits the opposite trend.
.
inference table summarizes the performance of lifted analyses on the entire product line spl and that of product level analyses on an average product p avg .
for example running 1type heap on an average mm08 product inference is estimated to take 596ms resulting in a database of 788kb.
running the same analysis on the whole mm08 product line though takes 788ms resulting in a 021kb database.
fig.
is a log scale bar graph of the speedup factor and the db space savings factor for insens .
speedup and space savings trends are again proportional to the number of valid configurations.
for example for berkeleydb lifted insens is about .
billion times faster than brute force with a db .
billion times smaller.
all three analyses show similar speedup and disk space savings trends.esec fse august tallinn estonia ramy shahin marsha chechik and rick salay table fact extraction time in ms and db size in kb average product p avg vs spl for all three analyses.
insens 1type heap taint 1call heap time ms db kb time ms db kb time ms db kb p avg spl p avg spl p avg spl p avg spl p avg spl p avg spl berkeleydb gpl lampiro mm08 prevayler table inference time in ms and inferred db size in kb average product p avg vs spl for the three analyses.
insens 1type heap taint 1call heap time ms db kb time ms db kb time ms db kb p avg spl p avg spl p avg spl p avg spl p avg spl p avg spl berkeleydb gpl lampiro mm08 prevayler figure context insensitive inference speedup and db savings factors spl vs average product.
recall that the theoretic bottleneck of the lifted inference algorithm algorithm is the satisfiability checks performed when conjoining two pcs.
since propositional satisfiability is np complete we wanted to evaluate whether it is a bottleneck in practice.
while sat checks are not required to maintain correctness of the lifted inference algorithm we perform them in order to avoid generating spurious facts that do not exist in any product.
an unsat presence condition denotes an empty set of products but what about pcs denoting sets of invalid product configurations?
the feature model fm of a product line specifies which product configurations are valid and which are not.
if a fact belongs only to a set of configurations excluded by the fm then this fact can be removed.
removing spurious facts saves db space but more importantly keeps the set of facts searched by the inference algorithm as small as possible improving the overall performance.
we study the impact of sat checking and using the fm below.
figure inference time spl vs. spl with sat checking disabled for all three analyses.
rq2.
how much does sat checking contribute to the processing time of the lifted datalog engine?
table summarizes the performance of our lifted analyses and the same analyses with sat checking disabled nosat .
fig.
and fig.
show the nosat associated speedup and database size savings respectively.
recall that we represent pcs using bdds.
sat checking over bdds is a constant time operation .
since conjoining and disjoining bdds can take exponential time we disable all bdd operations keeping only the textual representation of pcs.
a speedup factor below .
means that disabling sat checks slows down inference.
this is what we observed for most of the benchmarks.
we believe that the slowdown is because of the use of textual representation of pcs which resulted in a much bigger pc table with slower lookup times.
we also do not see any db savings because non canonically represented pcs tend to be longer than bdd based ones resulting on average in more characters and bytes per pc.
we note that the number of features is relativelylifting datalog based analyses to software product lines esec fse august tallinn estonia table sat vs. nosat.
time in milliseconds inferred db in kb.
insens 1type heap taint 1call heap time ms db kb time ms db kb time ms db kb spl nosat spl nosat spl nosat spl nosat spl nosat spl nosat berkeleydb gpl lampiro mm08 prevayler figure inferred database size kb spl vs. spl with sat checking disabled for all three analyses.
figure inference time spl vs. spl with fm for all three analyses.
low in all of our benchmarks.
bdd based sat solving is known to perform well on such small number of propositional variables.
with product lines of hundreds or thousands of features it is possible that nosat might result in performance improvements.
rq2.
what is the effect of taking the feature model fm of an spl into consideration when running datalog variability aware analyses in terms of inference time and db size?
table compares the performance of our lifted analyses against the same analyses using the feature model sat fm .
sat fm entails conjoining the feature model to each pc before performing the figure inferred database size kb spl vs. spl with fm for all three analyses.
satisfiability check.
if the pc encodes a set of products excluded by the fm the conjunction is unsatisfiable.
fig.
and fig.
show the sat fm associated speedup and space savings respectively.
for most of the experiments using the fm results in slowdowns and larger dbs.
fm usage reduces the number of inferred facts as observed in table but the reduction is relatively small.
on the other hand pcs now conjoined with the fm are more complex taking longer to construct hence the performance penalty and more bytes to store hence the bigger dbs .
.
threats to validity for internal threats we note that all of our benchmarks are cide product lines.
while our lifting approach and implementation are not specific to cide cide limitations make the benchmarks biased towards specific annotation patterns.
for example only wellbehaved annotations are allowed.
furthermore since feature expressions do not support feature negation all input pcs are satisfiable as well as conjunctions over those pcs.
we experimented with disabling satisfiability checks to see how much they affect performance while they always return true for this set of benchmarks .
as noted previously the overhead of those checks is marginal.
another internal threat is that we approximate average product performance using only two samples the maximum and the minimum .
these averages are not expected to be completely accurate but are used to give a brute force estimate.
our experiments show performance improvement of several orders of magnitude so we believeesec fse august tallinn estonia ramy shahin marsha chechik and rick salay table spl vs. spl fm.
time in milliseconds inferred db in kb.
insens 1type heap taint 1call heap time ms db kb time ms db kb time ms db kb spl spl fm spl spl fm spl spl fm spl spl fm spl spl fm spl spl fm berkeleydb gpl lampiro mm08 prevayler table the number of inferred facts with and without the feature model fm .
insens 1type heap taint 1call heap spl spl fm spl spl fm spl spl fm berkeleydb gpl lampiro mm08 prevayler that our approximation compared to more elaborate configuration sampling techniques can be tolerated.
finally all of the the analyses we used come from the doop framework.
again nothing in our lifted inference engine is doop specific but extraction of annotated features is a part of doop.
other frameworks can extract fact annotations in a similar fashion.
related work different kinds of software analyses have been re implemented to support product lines .
for example the typechef project implements variability aware parsers and type checkers for java and c. the superc project is another c language variability aware parser.
the henshin graph transformation engine was lifted to support product lines of graphs .
those lifted analyses were written from scratch without reusing any components from their respective product level analyses.
our approach on the other hand lifts an entire class of product level analyses written as datalog rules by lifting their inference engine and extracting presence conditions together with facts .
spllift extends ifds data flow analyses to product lines.
model checkers based on featured transition systems check temporal properties of transition systems where transitions can be labeled by presence conditions.
both of these spl analyses use almost the same single product analyses on a lifted data representation.
at a high level our approach is similar in the sense that the logic of the original analysis is preserved and only data is augmented with presence conditions.
still our approach is unique because we do not touch any of the datalog rules comprising the analysis logic itself.
syntactic transformation techniques have been suggested for lifting abstract interpretation analyses to spls .
this line of work outlines a systematic approach to lifting abstract interpretationanalyses together with correctness proofs.
yet this approach is not automated which means lifted analyses still need to be written from scratch albeit while being guided by some systematic guidelines.
datalog engines have been used as backends by several program analysis frameworks.
in addition to doop examples of analysis frameworks based on logic programming include xsb bddbddb and paddle .
dimple is another declarative pointer analysis framework where rules are written in prolog.
to the best of our knowledge all those program analysis frameworks have been targeting single products.
our primary contribution is lifting this class of analyses to spls in a generic way without making any analysis specific assumptions.
in addition our approach can be systematically implemented in any datalog engine used by any of those frameworks.
conclusion in this paper presented an algorithm for lifting datalog based software analyses to spls.
we implemented this algorithm in the souffl datalog engine and evaluated performance of three program analyses from the doop framework on a suite of spl benchmarks.
comparing our lifted implementation to brute force analysis of each product individually we show significant savings in terms of processing time and database size.
our souffl implementation only lifts the interpreter but not the code generator compiler .
aggregation functions e.g.
sum count are not currently lifted either.
we plan to address these implementation level limitations in future work.
we also plan to evaluate lifted souffl on analyses frameworks other than doop.
another track for future work is lifting datalog rules not just facts.
this would allow us to apply a product line of analyses to an spl all at once.
our work can also be extended to lift horn clause based analysis and verification tools to support spls.