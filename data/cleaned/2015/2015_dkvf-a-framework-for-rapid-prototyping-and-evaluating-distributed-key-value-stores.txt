dkvf a framework for rapid prototyping and evaluating distributed key value stores mohammad roohitavaf computer science and engineering department michigan state university east lansing mi usa roohitav cse.msu.edusandeep kulkarni computer science and engineering department michigan state university east lansing mi usa sandeep cse.msu.edu abstract wepresentourframeworkdkvfthatenablesonetoquicklyprototypeandevaluatenewconsistencyprotocolsforkey valuestores.
dkvf is designed based on the separation of concerns in creating distributed data stores.
this separation of concerns allowsthe designers of consistency protocols to only focus on the high level consistency protocols which gives them the opportunity to quicklydeployaconsistencyprotocolandevaluateitsperformance.
moreover theloosecouplingofthedifferentcomponentsallowsus to easily change different components e.g.
storage engine of animplementation.wedemonstratedkvfbyimplementingfour existing protocols eventual consistency cops gentlerain and causalspartan withit.theimplementationoftheseprotocolswas very convenient with dkvf as it only required to write a piece of code for the consistency component that is very close to the pseudocodeoftheoriginalpapers.hence itwaspossibletoachieve thisinjust1 daysperprotocol.dkvfalsocomeswithatoolset that facilitates running clusters and performing experiments.
tutorial video plertsvehsnbjvoqqi6iqgn61onruvvust ccs concepts computer systems organization cloud computing keywords distributeddatastores key valuestores framework prototyping ycsb geo replication acm reference format mohammad roohitavaf and sandeepkulkarni.
.
dkvf a framework for rapid prototyping and evaluating distributed key value stores .
in proceedings of the 33rd acm ieee international conference on automated software engineering ase september montpellier france.
acm newyork ny usa 4pages.
this work is supported in part by nsf xps .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
introduction with the huge amount of data and very high query throughput produced by a large number of users across the world storing data in a single machine does not work for any major business.
thus wehavetodistributethedataacrossseveralmachines.when wedistributeourdata animportantchallengeistheconsistency betweendifferentcopies i.e.
replicas ofthedata.thereisaninherent trade off between consistency and availability performance .
different levels of consistency come with different levels of availability performance overhead.
even to achieve a certain level of consistency two different protocols may have different levels of overhead.
ingeneral thissuggeststhatdevelopersneedtodevelopnewprotocolstoimproveperformance providehigherlevelsofconsistency reduce communication requirements reduce storage requirements andsoon.whenthedevelopersintuitivelyidentifyanewapproachtodesignsuchaprotocol thenaturalquestionthatarisesishowto evaluatethenewprotocolbycomparingitwithdifferentexisting protocols.distributeddatastoresarecomplexsystemswhichmakes an accurate analytical performance evaluation infeasible for them.
a more practical option is experimental performance evaluation via benchmarking a prototype running the protocol.
in this paper we introduce distributed key value framework dkvf that allows protocol designers to quickly create prototypesrunningtheirprotocolstoseehowtheyworkinpractice.
using separation of concerns dkvf allows researchers to onlyfocus on their high level protocol and rely on dkvf for all the lower leveltasks.thisapproachgreatlyexpeditesimplementing aprototypeforagivenprotocolcomparedwithcreatingaprototypefromscratch.
forinstance considerthe gentlerainprotocol proposed in .
the server side of this protocol is only lines of pseudocode provided in algorithm of .
however to have a prototype running this protocol we need to write hundreds of linesofcodetohandlelower leveltasksthatareindependentoftheprotocol.ourgoalistoprovideaframeworkthathelpsresearchers to create their prototypes by writing codes that are very close tothe pseudocodes that they publish in their research papers.
we believe this framework together with a toolset that helps us to runexperimentscansignificantlysavetimeinimplementingand benchmarking new protocols.
therestofthispaperisorganizedasfollows section 2discusses the separation of concerns in designing distributed data stores section3reviews the implementation using dkvf.
section 4introduces the tools that comes with dkvf.
section 5provides some of theexperimentalresults.finally section 6concludesthepaperand provides future work.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france mohammad roohitavaf and sandeep kulkarni separation of concerns dkvfisdesignedbasedontheseparationofconcernsofimplementing a distributed key value store.
figure 1shows three different componentsofadistributeddatastore.thestoragecomponentisresponsibleforthestorageandretrievalofthedatainasinglemachine.
it does not interact with either the clients or other servers.
it only serves the read write requests from the consistency component.
the communication component is responsible for server server andclient servercommunications.thecommunicationcomponent can provide different guarantees.
for instance it may provide total order per channel fifo or no ordering guarantee be reliable or unreliable besynchronousorasynchronous andsoon.theconsistency component is responsible for defining replication strategy and consistency protocol that guarantees clients always observe a consistent view of the data.
different levels of consistency is defined for replicated data stores.
the highest level of consistency is called strong consistency thatprovidestheillusionthatthereisonly a single copy of the data.
on the other end eventual consistency only guarantees that all replicas finally converge to the same data if westop writing newvalues.
in between we have differentlevelsofintermediateconsistencymodelssuchas causal consistency .aconsistencyprotocolrequiresasetofrequirementsforthe storageandcommunicationcomponents.however theconsistency protocolshouldnotbeinvolvedinprovidingtheserequirements.
thisloosecouplingletsuseasilychangedifferentcomponentsin both design and implementation of a distributed data store.
lj figure components of a distributed data store.
implementation using dkvf to implement a protocol using dkvf the protocol designer needs to provide three sub components of the consistency component of figure1.
.
metadata description for a consistency protocol in addition to actual data consisting ofthe key valuepairs wewilllikely needto storesomemetadata with eachrecord.
for example we may needto store atimestamp with each version or we may need to store the id of the replicawhere the version has been written.
each protocol requires its own metadata.
dkvf relies on google protocol buffers for marshaling unmarshalingdataforstorageand transmission.
the protocoldesignerneedstowritea .prototextfiledescribingthe metadata.thisfilealsodescribesthestructureofthemessagessent in the system.
.
server side toimplementtheserver sideofaprotocol theprotocoldesigner needstowriteaclassthatextendstheabstractclass dkvfserver .dkvffollowsanevent drivenapproachtodefineaprotocol.specifically we can define a protocol as a set of event handlers.
the two main event handlers that will be calledby the framework are handleservermessage andhandleclientmessage ofdkvfserver class.inside thesetwo maineventhandlers theprotocol designercan call detailed event handlers for different events.
while we are processingserverorclientmessagesin handleservermessage and handleclientmessage we may need to send messages to other servers orsendclientresponses.dkvfprovidesmethodstoreliably send receive messages to from clients and servers.
we also needtostore retrievedatafromthestorageenginethatcanbedone via that dkvf storage interface.
any data storage engine can be usedwithdkvf.touseastorageengine wehavetoprovidedkvf driver for it by implementing the dkvf storage interface.
dkvf comes with a driver for oracle berkeley db .
.
client side toimplementtheclient sideofaprotocol weneedtoextendthe clientpart ofthe framework.specifically weneed towrite aclass thatextendsclass dkvfclient .whenweextend dkvfclient w e have to implement two abstract methods putandgetthat are the basicputandgetoperationsofakey valuestore.thesemethods are operationsthat the protocoldesigner needs toprovide for the applicationdeveloper.theapplicationdeveloperlatercanusethese methodstousethedatastore.theprotocoldesignercanalsoadd more complex operations for its implementation but these two methods are required for any implementation.
toolset in this section we reviews tools that come with the framework.
.
cluster manager cluster manager is a command line application to facilitate managingclustersrunningkey valuestorescreatedwithdkvf.cluster manageralsoenablesustomonitortheservers.forinstance we canseeifservershaveproperlystartedandconnectedtoeachother how much are the network latencies or how many clients are connected to each server.
cluster manager also helps us to test and debugour key valuestore.
specifically after runninga clusterwe can connect to any server in the cluster and run commands on the servers.
italsohelpsustorundistributedycsb experiments.ycsbis atoolforevaluatingtheperformanceofkey valueorcloudserving stores .
to use ycsb we need to write a ycsb driver that lets ycsb client class use our key value store.
dkvf comes with its ycsbdriver.thus anykey valuestoreusingdkvfhasitsycsb driver ready.
also using cluster manager tool we can benchmark ourkey valuestorewithoutdirectlysettingupycsb weonlyneedtodefineourdesiredworkload andclustermanagertakescaresof the rest.
it runs all clients and obtains the results.
cluster manager provides an interactive environment with a query language that lets us aggregate the results.
.
cluster designer althoughclustermanagerisaconvenienttoolthatcansignificantly reduce time and headache of debugging and benchmarking our authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
dkvf a framework for rapid prototyping and evaluating distributed... ase september montpellier france figure the graphical interface of cluster designer protocol writingclusterandexperimentdescriptorfilescanbea tedious and error prone task for larger clusters.
to solve this issue weprovideclusterdesignertool.clusterdesignerisagraphical toolthatallowsustodefineourclusterandexperimentsvisually.
the tool provides an area where we can add servers and clients.
we can connect servers and clients by lines to specify network connections.
when we have several components that need to be allconnectedtoeachother wecanusehubstoavoidconnecting them one by one.
figure 2shows the interface of cluster designer.
in this network we have servers and clients.
we will talk about this network in more details in .
experimental results inthissection wepresentsomeoftheresultsthatweobtainedfrom implementing and evaluating three causal consistency protocols namely cops gentlerain and causalspartan using dkvf.
we also implemented eventual consistency for comparison.
duetolackofspace wecannotprovidethesketchoftheseprotocols.
thereadercanrefertotheoriginalpaperstolearnmoreaboutthese protocols.
we assume the reader is familiar with these protocols in the rest of this section.
weconsiderareplicatedandpartitioneddatastoreshowninfigure2.
the data store consists of two replicas.
each replica consists ofthreepartitions.replica0includespartitions0 0 0 1 and0 2. replica on the other hand consists of partitions 0 1 1 and 1 2. we assume full replication i.e.
each replica has a copy of the entirekeyspace.thekeyspaceinsideeachreplicaispartitioned among servers.
in figure we have connected servers inside each replicatogetherwithahub.partitionsarealsoconnectedtotheir peers in the other replica.
for servers we use aws m3.medium instances with the following specification vcpus .
ghz intel xeone5 2670v2 .75gibmemory 1x4 gb ssdstoragecapacity.
connected to each replica we have a set of clients.
we allocate three client machines to run clients.
we run threads of ycsb clients on each client machine.
all causal consistency protocolsthat we study here assume locality of traffic i.e.
clients always access one replica.
thus clients are connected to only one replica as shown figure .
we run clients on c3.large machines with the following specification vcpus .
ghz intel xeon e5 2680v2 1we have implemented a simplified version of cops without garbage collection.
.
gib memory x gb ssd storage capacity.
we have used more powerful machines for clients to better utilize our servers.
.
the effect of workload on performance the workload of different applications has different characteristics.
some workloads are write heavy others like those in data ana lytics are read heavy.
in this section we want to study how thecharacteristics of our workload affect the performance of different consistency protocols.
in all experiment we set the size of the values written by clients to bytes.
figure3ashows how get putproportion affects thethroughput.
as we move from the left side of the plot to its right side the workload nature changes from write heavy to read heavy.
the throughputs of all protocol increase as the proportion of get operationsincreases.thisresultsconfirmpreviousstudies and are expected as get operations are lighter than put.
as expected eventual consistency has the highest throughput.
cops on the other hand has the lowest throughput.
this results confirm results publishedin andisduetotheoverheadofdependencycheck messages that partitions send to each other to make sure causal dependencies of an update in other partitions are visible .
figure3bshows how get put proportion affects the response time of put operations.
in all protocols the response time of put operationsdecreases aswemoveto read heavierworkloads.this isduetothelessloadonserversforread heavierworkloads.the eventualconsistencyhastheshortestresponsetimethankstoits minimal metadata.
causalspartan has more metadata than gentlerainresultinginhigherputresponsetime.copshasthehighest response time because of its dependency check messages and itsexplicitdependencytrackingapproach.likeotherprotocols thetrend of put response time for cops is decreasing as we move towardread heavierworkloadsthatcanbeexplainedbylessload on the machines.
however for .
.
the put response time increases.thisincreasecanbeunderstoodbyconsideringthedependency tracking mechanism of cops.
at point .
.
clients read many keys before writing a key.
that results in longer dependency lists which make put messages heavier to transmit and process.notethatwehaveimplementedabasicversionofcops protocol without client metadata garbage collection.
cops authors suggest a garbage collection mechanism to cope with this problem .
figure3cshows how get put proportion affects the response time of get operations.
like the case of put operations the re sponse time of get operations also decreases as we move towards read heavier workloads.
it is interesting that gentlerain and causalspartan have a lower response time for get operations comparing to the eventual consistency for write heavy workloads.
this can be explained by the synchronization that occurs between threads in gentlerain and causalspartan.
specifically there is a contentionbetweenthreadswhileperformingputoperationsin gentlerain causalspartan.
this contention occurs for obtaining a lock that we used toguarantee updates with smaller timestampsare replicated to other nodes before updates with higher timestamps.thisincreasestheputresponsetimethatresultsinalower overallthroughputofgentlerain causalspartanforwrite heavy workloads.whilethreadsservingputoperationsarewaitingfor authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france mohammad roohitavaf and sandeep kulkarni synchronization the server can handle get operations.
on the other hand in the eventual consistency there is no competition between put operations.
thus there are more active threads servingputoperationsleadingtohighercompetitionovercputhat finally results in higher get response time comparing to gen tlerain causalspartan.
note that this happens for write heavy workloadswithlowgetproportion.therefore theeventualconsistency still has the highest overall throughout in all cases see figure3a .
.
the effect of query amplification inthissection westudytheeffectofqueryamplificationthatcauses a single end user request translate to several internal operations.in this section we only consider one replica consisting of three partitions.weconsideraworkloadthatpurelyconsistsofamplified insert operations.
each amplified insert consists of several internal putoperations.thenumberofinternalputoperationsisdefined by the amplification factor.
figure3dshowstheeffectofamplificationfactorontheclient request throughput.
note that this throughput represents the numberofclientmacrooperations notindividualputoperations that are served in one second.
as the amplification factor increases the throughput of all protocol decreases which is expected as requests withhigheramplificationfactorincludemoreinternaloperations which meanmore jobto dofor each request.the eventualconsistencyhasthehighestthroughput.thepure writeworkloadisan idealwritescenarioforcops asdependencylistshaveatmostone entry.
thus thethroughputofcops isthehighest aftereventual consistencyforthisscenario.gentlerainhasthelowestthroughput.
thatisduetothedelaythatgentlerainimposesonputoperations in case of clock skew between servers.
note that we synchronized the physical clocks of the system with ntp but the effect of clockskewstillshowsupintheresults.theseresultsconfirmprevi ousresultspresentedin .causalspartanhashigherthroughput thangentlerain ascausalspartaneliminatestheneedforthedelay before put operations by utilizing hlcs instead of physical clocks .
figure 3eshows the request response time for differentprotocols.again becauseofdelaysthatgentelrainforceson put operations request response time has the highest value for gentlerain.
conclusion in this paper we introduced dkvf which is a framework for rapid prototyping and benchmarking distributed key value stores.
it streamlines the evaluation of the performance of consistency protocolsfordistributedkey valuestores.toshowtheeffectivenessof our framework we implemented four consistency protocols using dkvf.thankstotheconvenienceofdkvf wewereabletoimplementeachoftheseprotocolsinlessthan2days.wewereableto implement causalspartan and gentlerain with significantly less effort than our previous implementations without dkvf.
the toolset that comes with the framework helps protocol designers to easily evaluate their prototype.
using these tools we can easily run and manage clusters of machines running our protocol.
we can also run clients to benchmark the performance of our key value store.
dkvf relies on ycsb for benchmarking.
.
.
.
.
.
.
.
.
.
.
get put proportion1.
.
.
.5throughput op s eventual consistency cops gentlerain causalspartan a throughput0.
.
.
.
.
.
.
.
.
.
get put proportion24681012put response time ms eventual consistency cops gentlerain causalspartan b put response time .
.
.
.
.
.
.
.
.
.
get put proportion34567get response time ms eventual consistency cops gentlerain causalspartan c get response time20 amplification factor02004006008001000 throughput request s eventual consistency cops gentlerain causalspartan d request throughput amplification factor050100150200250300request response time ms eventual consistency cops gentlerain causalspartan e requestresponsetime figure some of results obtained from dkvf we can use any storage systems as the storage engine for the key valuestoresthatwedevelopwithdkvf.thisenablesprotocol designers to flexibility change their storage engine.
to use a given storage system with dkvf we need to write a driver for it that enables dkvf to interact with it.
dkvf comes with a driver for berkeley db.writingdriversforotherstoragesystemsispartof the future work.