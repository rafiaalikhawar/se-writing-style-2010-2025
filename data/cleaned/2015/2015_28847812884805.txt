behavioral log analysis with statistical guarantees nimrod busany shahar maoz school of computer science tel aviv university israel abstract scalability is a major challenge for existing behavioral log analysis algorithms which extract nite state automaton models or temporal properties from logs generated by running systems.
in this paper we present statistical log analysis which addresses scalability using statistical tools.
the key to our approach is to consider behavioral log analysis as a statistical experiment.
rather than analyzing the entire log we suggest to analyze only a sample of traces from the log and most importantly provide means to compute statistical guarantees for the correctness of the analysis result.
we present the theoretical foundations of our approach and describe two example applications to the classic k tails algorithm and to the recently presented bear algorithm.
finally based on experiments with logs generated from real world models and with real world logs provided to us by our industrial partners we present extensive evidence for the need for scalable log analysis and for the e ectiveness of statistical log analysis.
ccs concepts software and its engineering !dynamic analysis software veri cation keywords log analysis speci cation mining .
introduction running systems be it web servers virtual machines on the cloud industrial robots or network routers generate logs that document their actions.
the analysis of these logs carries much potential to improve software engineering tasks from documentation and comprehension to test generation and veri cation.
existing algorithms and tools for behavioral log analysis include various speci cation mining and model inference approaches which extract nite state aupermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
fsa models or temporal properties.
example approaches include .
however a major challenge for all behavioral log analysis algorithms is scale.
indeed recent work has reported that existing implementations of several well known log analysis algorithms run out of memory or take hours to complete when executed over logs of several hundred mbs .
in this work we propose statistical log analysis which addresses scalability of behavioral log analysis using statistical tools.
rather than analyzing the entire log we suggest to analyze only a sample of entries from the log and most importantly provide means to compute statistical guarantees for the correctness of the analysis result.
speci cally we develop an approach to adding statistical guarantees to behavioral log analyses.
given an analysis of interest and a sample of entries from a log we compute the statistical con dence one may have in the analysis results.
conversely given an analysis of interest and a required level of con dence we compute a stopping criteria e.g.
a sample size for which indeed the analysis results can be trusted at the required statistical con dence level.
following the presentation of our general approach we demonstrate it by concretely applying it to two di erent previously published analyses.
first we apply statistical log analysis to the well known k tails algorithm which extracts a candidate behavioral model from a log of execution traces based on the set of sequences of kconsecutive events found in the log we use the variant presented by beschastnikh et al.
in .
second we apply statistical log analysis to the bear algorithm recently presented by ghezzi et al.
in which builds a set of discrete time markov chains dtmc of users navigational behaviors recorded in logs based on the frequencies of transitions found in the log.
we have implemented our approach and evaluated it on three sets of logs.
our experiments show that as the size of the logs grow their analysis becomes challenging and that statistical log analysis can be used to signi cantly reduce the computation e ort of the analysis while still providing highly reliable results.
we provide a detailed account of the evaluation we have performed in sect.
.
it is important to note that the scalability we aim for in statistical log analysis is sub linear the complexity of the analysis we do is less than linear to the size of the input log.
note that this is a rather strong notion of scalability.
in fact our experiments show that as the log size increases the size of the sample we analyze approaches a constant!
indeed the stopping criteria we compute depend on the con dence one ieee acm 38th ieee international conference on software engineering may want in the correctness of the results but are independent of the log size.
as real world log sizes are unbounded this strong notion of scalability is indeed required.
we further note that our present work does not make any new claims regarding the usefulness of the results of behavioral log analyses such as k tails and bear.
based on claims and evidence provided in previous works by others as cited above we assume that these analyses results could be useful for software engineers and focus in the present work solely on the challenge of scalability and on the statistical means we propose to use in order to address it.
the approach we suggest is a pure black box approach.
we do not look at the code of the program that created the log and take only the log itself as input.
in many real world situations indeed the code is not available or is just too complex and too large to be a subject for static analysis.
finally we note that our approach assumes that relevant entries e.g.
traces are randomly and independently sampled from the log and that the log adequately re ects the behavior of the system under investigation.
this assumption may not always hold e.g.
if traces and logs depend on running tests that were generated according to some strategy.
our approach should therefore not be used as is as a means to evaluate the quality of test suites.
paper organization.
we start o with a short discussion of related work.
sect.
presents an overview of our approach and its unique features using two concrete example applications.
sect.
presents an extensive evaluation over three sets of logs.
finally sect.
concludes with a summary of contributions and future work directions.
.
related work while there has been much research on developing behavioral log analysis algorithms see e.g.
only very little has been published on their scalability and on the con dence one may have in their output.
recently cohen and maoz have presented k con dence a con dence measure for k tails which computes the probability that the log is complete this work is extended to two other algorithms in .
these works do not provide statistical guarantees.
in contrast our work is based on statistical log analysis and is thus much more robust and general than the one presented in it can answer many other questions beyond log completeness as we later demonstrate and provides engineers with much exibility in adapting to di erent algorithms and setting up required levels of accuracy on the one hand and statistical con dence on the other hand.
one means to achieve scalability in log analysis is distributed computing.
in the authors cast several different speci cation mining algorithms to the mapreduce model.
in the authors present the use of mapreduce to scale k tails.
we consider distribution to be an orthogonal approach to ours.
we note that a distributed computing framework is not always available or easy to use.
moreover the scale up in running time is in theory at most linear in the number of computing resources and in practice even less in the results reported in both works the marginal contribution of adding more resources quickly decreases.
finally in a recent fse nier track short paper we presented an overview of our approach with preliminary evaluation.
our present paper extends signi cantly witha comprehensive presentation of our approach and an extensive evaluation performed over real world data.
.
statistical log analysis the key to statistical log analysis is to consider behavioral log analysis as a statistical experiment .
for example if the log is partitioned into traces each new trace in the log is considered a trial which may contribute to the acceptance or rejection of an hypotheses about the system that generated the log.
the granularity of the partition is up to the user to de ne based on the speci c analysis of interest.
the key property for the selection of partition granularity is that its parts e.g.
traces can be independently sampled from the log.
to cast the behavioral analysis into a statistical experiment we assume that the log is a good representation of the system generating it.
further we assume that the system and its environment do not change over time to exclude in uence of external biases on the traces.
in stochastic terms we assume that the system corresponds to a timehomogeneous process.
the traces are assumed to be generated identically and independently from the same underlying distribution.
finally our approach as presented here can only be applied to incremental inference algorithms where each trace can be processed independently and its contribution can be determined with respect to the current state of the algorithm.
still this most general setup allows us to apply well known tools for statistical inference.
we present basic de nitions and show two example concrete applications.
.
basic definitions a trace over an events alphabet is a nite word he1 e2 emiwheree1 em2 .
letsbe a system generating traces over an alphabet .
we denote by d s !
the discrete probability distribution of traces when executing the system in its environment.
a log ofs denoted by l is a nite set of traces from d s .
in the behavioral log analysis setup sandd s are unknown.
all we know is a log lfromd s .
we assume that the distribution of traces in lclosely resembles the distribution of traces ind s i.e.
that the log includes typical uses of the system under investigation.
we have no information about the system sother than the log l. filters may be applied to the log l so as to remove events that should not be considered by the analysis.
without loss of generality we further assume that the log l possibly after ltering is partitioned according to some user de ned criteria such that each event that appears in lbelongs to exactly one part of the partition.
an example partition is one that is based on traces.
another example is a partition where each part consists of exactly one event.
.
example i k tails k tails is a well known algorithm for extracting a candidate behavioral model from a log of execution traces.
it has been extensively used in the dynamic speci cation mining literature and tools in several variants e.g.
.
one variant of k tails presented in reads each trace and collects k sequences i.e.
sequences of kconsecutive events.
it then uses these k sequences to construct the k tails fsa.
most importantly the fsa is uniquely de ned by the set of k sequences observed in the log.
878since a log may be too large to analyze one would like to de ne a stopping criterion to indicate that enough traces were seen.
for this purpose we de ne a notion of similarity as follows a log lis similar when the total probability of all the unobserved k sequences to be observed in the next trial i.e.
in the next randomly selected trace from d s is smaller than or equals .
is a statistical bound.
intuitively in our context can be viewed as a target insensitivity level to infrequent sequences.
hypothesis testing as a stopping criteria.
our null hypothesis is that the log is not similar i.e.
that the probability of a new random trace to reveal new information include ak sequence that has not appeared in previously analyzed traces is larger than .
we stop reading new traces when this hypothesis can be rejected.
the experiment protocol is iterative.
at each step we pick a random trace from the log and check if the trace includes previously unobserved k sequences if so we start a new experiment for the new knowledge base i.e.
the new set of all observed sequences so far otherwise we increment the number of trials since the last new k sequence was observed when this number is larger than n the null hypothesis can be safely rejected.
but where does ncome from?
we model our analysis as a series of binomial experiments .
given a target insensitivity and a statistical signi cance level we apply a binomial proportion test to compute n the number of consecutive trials new traces that do not reveal new information required to reject the null hypothesis i.e.
to safely conclude that the log is similar.
more formally we describe the setup of iteratively randomly selecting a trace from a log and comparing the facts extracted from it i.e.
k sequences in our example against a knowledge base in terms of a binomial experiment model this corresponds to a single experiment in the series the experiment consists of nrepeated independent trials in our context traces we have read since the last trace that revealed at least one new k sequence each trial has a probability of success p in our context a success is a trace that reveals at least one new ksequence the probability of success does not change throughout the experiment in our context the knowledge base of k sequences observed so far determines p given the above modeling as a binomial experiment the distribution to observe ssuccessful trials i.e.
traces revealing at least one new k sequence out of ntrials is bin n s n s!
ps p n s ideally we would stop analyzing traces once all the ksequences have been observed i.e.
when p .
however in our context we do not know the complete set of k sequences andpis unknown.
therefore we bound it inside a binomial proportion con dence interval .
de nition binomial proportion con dence interval .let pdenote the proportion of successful trials over nrandom trials from bin n s letzdenote the percentile of a standard normal distribution where we refer to as the error percentile.
then phas a probability of to be contained within the binomial proportion con dence interval p zr n p p p zr n p p remark .
the above formula relies on normal approximation to a binomial.
we chose to present it due to its relative simplicity.
however it is inadequate when p .
other superior methods to compute a binomial proportion con dence interval exist in the literature.
in our calculations in the evaluation sect.
we used wilson interval recommended by which provides high coverage probability for a broad range of pvalues.
we note that for p andp agresti coull interval may be more appropriate.
lastly we note that je reys prior interval is less conservative and tends to yield coverage probability closer to .
de nition con dence .a con dence re ects a con dence that the true but unknown probability of successpis less than i.e.
pupperbound based on the binomial proportion con dence interval formula we nd the stopping criteria by computing the number of unsuccessful consecutive trials nrequired to guarantee con dence.
remark .
the proportion of success changes every time a new fact is learned.
in k tails when the knowledge base is empty i.e.
no event sequence is known the probability of success on any trace longer than k equals one.
on the other extreme when the knowledge base is complete i.e.
all possiblek sequences are known the probability of success is zero.
therefore when computing the proportion con dence interval we must re approximate pafter learning a new fact as the probability of success changes.
for this reason we start a new binomial experiment after every success i.e.
after observing a trace with a new k sequence .
we conclude with a concrete example.
if we select a target insensitivity level of and a signi cance level of willson s interval gives us n .
if we follow the protocol presented above we can stop reading traces from the log once we analyze n consecutive traces without new information.
the statistical guarantees are about the completeness of the obtained set of k sequences.
when the analysis terminates and the null hypothesis is rejected we have a con dence that the total probability of any of the unobserved k sequences to appear in a random trace denoted by p is less than .
in short we say that the sample is similar with a signi cance level .
remark .
interestingly and perhaps surprisingly note thatndepends on p and but noton any speci c detail of the k tails algorithm not even the chosen k. however this independence can be explained the details of the ktails algorithm and the choice of the parameter ka ect the very success or failure of each trial in the experiment.
this points to a major advantage of our approach also in contrast to it can be easily extended to any analysis algorithm that one can cast into the binomial experiment protocol.
remark .
note that while reading additional data is expected to increase the reliability of the resulting model by de nition of the stopping criteria it is redundant and a waste of resources in terms of the required statistical bound.
.
example ii bear inference algorithm bear is a recently presented inference algorithm that constructs a set of discrete time markov chains dtmc of users navigational behaviors recorded in logs.
the inferred models are then analyzed in order to verify quantitative properties by means of probabilistic model checking.
the algorithm constructs dtmcs according to user classes.
each user is assigned to one or more of these classes and her user sessions i.e.
traces are used in the construction of the corresponding dtmc.
dtmcs are constructed according to transitions frequencies in the log from which they are mined.
most importantly the set of transitions frequencies found in the log determines the dtmc model that will be built.
consider an engineer applying bear over a log from a particular user class.
running bear over the entire log may be very slow therefore we apply our statistical log analysis to the problem.
rather than reading the entire log we sample events from it.
each sampled event is a trial in an experiment.
a transition is created by connecting each event in a user session to its preceding event.
we estimate the transitions frequencies and would like to stop sampling once we know that the con dence interval around the estimated frequencies is smaller than for a given statistical signi cance level .
we describe the procedure for a single transition then simply apply it over the set of all observed transitions.
we refer to the true but unknown transition frequency in the system under investigation i.e.
in d s byp and the estimated frequency by p. we de ne a notion of similarity as follows a log lis similar if the estimated frequency p computed as the proportion of transitions which equal to the desired transition in the traces in l satis esj p pj .
given this notion we propose the following iterative experiment protocol pick a random trace from the log and traverse its transitions.
if a transition equals to the transition at hand increase the transition occurrence counter and the total transitions occurrence counter and update its frequency p. otherwise if a transition is not equal to the transition at hand increase the total transitions occurrence counter and update its frequency p compute d j pupperbound plowerbound j ifdis smaller than stop sampling.
but where would the bounds come from?
con dence interval as a stopping criteria.
as done in the previous section we de ne a binomial experiment.
here we change the interpretation of a successful trial.
first a new trial is de ned every time a transition is read.
second a new transition is considered a success if it equals to the transition at hand.
the analysis of the con dence interval remains the same.
in this context the null hypothesis is that the true frequency pof the transition lays outside of the con dence interval.
we stop sampling i.e.
reject the null hypothesis once we observe that the size of the con dence interval is su ciently small.
that is when we stop the log we have analyzed so far is similar with a statistical signi cance level .
in other words the probability that the true frequency of a transition p is far from pby more than is less than .
as an example for a transition of interest consider web application of a hotel.
a log from such an application can be partitioned into traces based on ip addresses and a time window.
now consider a user browsing through the catalog of rooms selecting a room and reaching the make a reservationpage.
then instead of making a reservation the user hits the back button.
an engineer may be interested in the frequency of users who take this transition in order to make an informed decision regarding a possible change in the makea reservation page.
consider a concrete example.
if we set after observing a transition in out of transitions with a frequency p we achieve con dence that the true frequency of the transition p is in the interval p d1 .
by reading more user sessions we may be able to narrow this interval and get a more precise result at the same signi cance level.
for example after observing the desired transition in out of transitions for the same con dence we achieve p d2 .
thus if we set and use the procedure presented above we would stop reading new traces at this stage.
further reducing the signi cance level narrows the intervaldas well e.g.
after observing the desired transition in out of transitions p with we get p d3 .
this occurs since increasing increases the probability for an error i.e.
the probability that the true frequency lays outside of the interval .
finally an observation pa ects the interval size as well e.g.
with and after observing the desired transition in out of transitions we get p d4 .
the interval size d4is nearly half the size of d2 obtained for the same sample size and signi cance level.
in this experiment the statistical guarantees are about the accuracy of the obtained frequency.
when the analysis terminates we have con dence that the distance between the true and obtained frequencies is smaller than .
remark .
as in the k tails example here too the stopping criteria depends on p and but does notdepend on the transition of interest.
note that the interval size is monotonically decreasing in the signi cance level and monotonically decreasing in the sample size n. we note that the may not be symmetric around the estimated proportion p depnding on the selected interval .
therefore to achieve similarity the interval size dmust be less than .
remark .
note that our key assumption is that the analysis is able to decide given a transition whether it equals to the transition at hand.
thus the example application to the bear algorithm which estimates the frequencies of transitions is actually an instance of a more general approach to estimate the frequency of satisfaction of any property of interest given that satisfaction in a sampled part e.g.
a trace can be decided.
in this experiment multiple independent trials are performed.
in each we check for the satisfaction of a property of interest.
a trial is considered a success if the sampled part satis es the property of interest and a failure otherwise.
calculating bounds for property satisfaction frequency is done similarly to the way we have done it for bear in the special case of transitions.
remark .
one may notice that the trials in the procedure above are not entirely independent violating an important assumption .
in fact transitions in the same part i.e.
a user session are in most cases highly correlated.
nevertheless our method is applied over large logs containing many parts whose length is usually signi cantly smaller than the log size.
furthermore parts are randomly selected which eliminates correlation between events from di erent parts.
therefore 880the correlation between events in similar sessions may not have a signi cant e ect on the analysis.
we empirically test the soundness of our approach in sect.
.
.
ev aluation the research questions guiding our evaluation are rq1 as real world logs become larger will existing log analysis algorithms scale?
rq2 does our approach reach a required high reliability soundness ?
rq3 does our approach allow one to reduce the number of traces read while maintaining high reliability?
rq4 what is the overhead of computation time in our approach and does it actually allow scalable sub linear execution times?
.
logs used in evaluation in the evaluation we have used three sets of logs.
.
.
log set i logs generated from fsa models we conducted the k tails experiment sect.
.
over logs that we have generated from four fsa models of real systems taken from three previously published works .
the models varied in size and complexity alphabet size ranged from to mean .
number of states from to .
and number of transitions from to .
.
to generate the logs from the models we used the trace generator from with path coverage.
we xed the number of traces in all logs to 25k the number of events ranged from about 252k to about 605k and the average trace length from .
to .
.
to parse the above logs we used the parser from the implementation of synoptic .
.
.
log set ii daily regression logs from a telecommunications company we repeated the k tails experiment sect.
.
with a set of ve real world logs which we received from our partner a team in a large multi national telecommunications equipment company.
the set includes logs of high level api calls system events distribution of tasks db queries and communication between processes over di erent machines.
all logs were generated by a single run of a daily regression which was executed in debug mode.
again to parse the logs we used synoptic s parser cited above.
as the parser requires the user to specify regular expressions we have dened these for each of the ve logs after consulting with our colleagues at the company.
the logs varied in size and complexity alphabet size ranged from to number of events from .7k to 40k number of traces from to and average trace length from .
to .
.
the number of traces contained in the logs above was rather small as they only contained a single day of regression run .
since gaining statistical con dence requires large logs we decided to duplicate the original les by duplicating each entry multiple times thus creating multiple copies of the same day.
to duplicate the logs we rst read the entire log then duplicated indexes which we mapped to the parsed traces.
we duplicated each index multiple times shu ed them popped one index at a time and read its corresponding trace.
the advantage of duplicating the original logs is that it enables us to x the amount of informationthat the log contains while increasing its size.
this allows us to better interpret the experiments results.
.
.
log set iii real estate rest application logs to conduct the bear algorithm experiment sect.
.
we used bear s dataset generously given to us by the authors of .
the set consists of a single log which was generated by a real estate rest application executed by an it consultancy company.
the log contains rows which record requests of web resources issued by clients to the application s web server.
each request is considered to be an event.
to parse the log we used the code and lters expressed by regular expressions provided by the authors of .
the log consists of about 390k events collected over two years.
the alphabet size is .
we followed and ltered out events i.e.
requests that correspond to secondary resources e.g.
requests for css or javascript resources as they do not represent users navigational behaviors.
after applying the lters about .5k events are used in the construction of the dtmcs.we partitioned the events in the log into users sessions based on ip addresses and a user window of minutes.
events with similar ip separated by a longer time period were assigned to di erent traces i.e.
user sessions .
this ltering and partitioning are consistent with the ones chosen by the authors of .
finally since almost all of the events originate from users of the mozilla firefox browser about 38k events we focused on constructing a model for this user class.
this yielded a single dtmc which captures these users interactions with the application.
we ltered out events that did not belong to this user class.
for more details about the log and lters used we refer the reader to the original paper about the bear approach .
.
setup and methodology we executed the experiments on an ordinary laptop computer dell xps intel core i7 4712hq cpu .3ghz 16gb ram samsung ssd pm851 msata 512gb.
.
.
binomial confidence interval calculator we implemented the binomial con dence interval calculator used in the evaluation with the confidenceinterval class included in apache commons math .
.
.
.
k tails experiment to implement the k tails experiment sect.
.
we modi ed the code of invarimint to support the use of the binomial con dence interval calculator when analyzing traces.
to apply our approach with k tails we rst read the entire log and shu ed the traces.
we then run the k tails algorithm with invarimint s implementation which we modi ed to identify if new information was revealed after a new trace is read.
then we performed con dence check after reading each trace with the binomial con dence interval calculator.
we ended the experiment once the desired level of con dence was obtained.
the k tails parameters we used were k .
.
.
bear algorithm experiment in this experiment we rst selected a set of transitions whose frequencies we want to bound.
we decided to consider any transition observed as we process the log as an ex88105001000150020002500 3time ms k cvs.net datagramsocket socket zipoutputstream 128time ms duplication factor log1 log2 log3 log4 log5figure running k tails over log set i left and log set ii right see section .
.
.
periment i.e.
once a new transition is observed it initiates a new experiment that is added to the set of running experiments.
we stopped processing the log once all the running experiments had achieved the desired con dence.
to test how reliable is the stopping criterion we stop updating the frequency of transitions whose experiment has ended.
in other words we avoid updating transitions for which we already achieved a con dence interval smaller than .
to implement we modi ed bear s implementation to support the use of the binomial con dence intervals.
first for the binomial con dence interval to be correctly computed user interaction sessions must be randomly selected from the log.
to cope with this we modi ed bear s parser to rst split the log into user sessions according to ip and a user window.
then at each iteration of the algorithm we select a user session and pop its events sequentially.
after we read all the user session events we remove it and randomly select a new user session.
when selecting an event we use the bear algorithm to construct a transition that connects it to the preceding event in the user session initial events are connected with a dummy start node .
then we update the transitions frequencies for all of the active experiments accordingly as explained in sect.
.
.
further if the transition is observed for the rst time we initiate a new experiment for it.
to do this we initialize a new binomial con dence intervals calculator setting its initial trials count to the number of read events and its number of successes to one.
finally we compute the con dence intervals around all transitions with active experiments and terminate any experiment with a calculated interval of size smaller than .
we stop reading events once all the experiments are terminated i.e.
when the desired con dence level is obtained for all transitions or when the entire log is read.
.
.
measures the measures we use to evaluate the results of our experiments are similarity reliability absolute and ratio of sample size and absolute and ratio of analysis execution time.
1we note that an experiment is not initiated for a new transition after we obtained a tight con dence interval for nonobserved transitions.
for example if we already saw transitions then the con dence interval of any unobserved transition is between to .
hence smaller than so we treat it as a completed experiment.similarity.
we de ne similarity as the distance between the true parameter that the experiment estimates and its estimated value when the experiment is completed.
in the k tails experiment the parameter used in the hypothesis testing as stopping criteria experiment is the probabilitypof a new random trace to reveal new information see sect.
.
.
since we do not know p we use the maximum likelihood estimator mle ofpover the entire log denoted by pmle.
we compute it by taking the ratio between traces containing k sequences missing from the partial log and the total number of traces in the entire log.
then similarity is de ned as jpmle pj.
since the k tails experiment only ends when p the similarity is simply jpmlej and can also be interpreted as a measure of completeness.
in the bear algorithm experiment the property used in the con dence interval as stopping criteria experiment is the true frequency of a transition denoted by p. since we do not knowp we compute the mle ofp denoted by pmle which is the frequency of the transition in the entire log.
then we compute the distance between the transition s frequencies in the partial log denoted by p andpmle.
again similarity is de ned as jpmle pj.
intuitively when the two are identical similarity equals and when the two are most distant similarity equals .
reliability precision .
we de ne reliability as the experiment s precision where a true positive false positive is the case where the experiment was correctly incorrectly terminated.
in the k tails experiment the null hypothesis is that the true probability of a new random trace to reveal new information i.e.
a new k sequence p is greater than .
the experiment terminates once we have con dence that pis smaller than .
since we use the pmle ofp we declare the experiment successful if pmle .
since captures the theoretical reliability of the experiment assuming the underlying assumptions hold see sect.
we expect the success rate i.e.
the reliability of a set of experiments to be .
in the bear algorithm experiment we stop once we gain con dence that the estimated frequency pof a transition and the true frequency of a transition pare within a distance of .
since we use the pmle ofp we declare the experiment successful if jpmle pj .
again since captures the theoretical reliability of the experiment we expect the reliability of a set of experiments to be .
absolute and ratio sample size.
the absolute sample size is the number of trials performed traces or transitions analyzed in the experiment.
the ratio sample size is the ratio between the absolute sample size and the size of the entire log number of traces or transitions .
absolute and ratio of analysis execution time.
the absolute sample analysis execution time is the time required to analyze the sample e.g.
to extract k sequences .
the ratio of analysis execution time is the ratio between the absolute sample analysis execution time and the time required to analyze the entire log.
.
results .
.
rq1 to answer rq1 we conducted the following experiments.
we run k tails over log set i and computed the execution time of extracting k sequences from traces.
execution times as function of k are presented in fig.
left .
these results illustrate that the complexity of analysis i.e.
the chosen k can greatly a ect the execution time of mining k sequences.
furthermore the richness of the log is a prominent factor.
as an example one may observe the large gap between the results for the datagramsocket log and the zipoutputstream log.
indeed the datagramsocket model contains a larger alphabet and more transitions than the zipoutputstream model.
as a result its traces tend to be longer and so is the log size.
moreover while the number of events in thedatagramsocket log is .
times larger the computation time it requires is .
and .
times longer than that of the zipoutputstream log for k resp.
we run k tails over log set ii.
since these logs were rather small we also run k tails over the duplicated logs.
fig.
right shows the execution times for duplication factors .
these experiments illustrate a linear increase in the execution time as the logs increase in size which shows that for truly large logs even a simple collection ofk sequences may not be feasible.
finally we run the original implementation of bear over log set iii and measured the execution time.
we repeated it times.
the average time measured was minutes.
to answer rq1 we see that the size and complexity of logs and the complexity of the analysis algorithms can greatly a ect the analysis computation time.
as the size of the logs grow their analysis becomes challenging.
.
.
rq2 to answer rq2 we conducted the following experiments.
first we run the k tails experiment over log set i and log set ii.
for log set i we xed the target insensitivity at and used three di erent statistical signi cance levels and .
we invoked the binomial interval con dence calculator after reading each trace.
the numbers of unsuccessful consecutive trials nrequired to guarantee con dence are and resp.
we repeated each experiment times for each of the four logs and the three values of andk.fig.
left 2reports the similarity levels obtained when reaching the stopping criteria.
as can be seen the values of the rst quartile for in all models are higher than .
this shows that in the large majority of experiemnts the desired similarity level was indeed obtained with these signi cance levels.
furthermore of all experiments obtained an average similarity level of and higher.
this illustrates reliability for log set i. interestingly in deeper analysis of results not shown in the gure we observed that the average reliability levels for are for all models.
moreover when setting the reliability levels for the four logs were and .
for the reliability levels for the four logs were and .
this shows that for low values of the intervals tend to be too conservative while for high values of the intervals may be not conservative enough.
for log set ii we conducted these experiments in a similar way experimenting with similar parameters .
fig.
right reports the average similarity levels obtained when reaching the stopping criteria.
since the original logs are small the stopping criteria for many of them was never reached and the logs were fully read yielding similarity of .
therefore we repeated the experiments for the duplicated logs.
the gure reports the average similarity levels with and k .
as can be seen the similarity levels obtained for all logs exceed the threshold with a moderate reduction as the log size increases.
furthermore of all experiments obtained an average similarity of and higher which demonstrases high reliability.
for lack of space we do not provide the reliability levels here.
the trend for the average reliability levels observed earlier was repeated in these experiments with being too conservative and not being strict enough.
second we run the bear experiment over log set iii.
as many of the transitions of the dtmc have very low frequencies in this experiment we included low insensitivity values.
we used and and repeated the experiment times with each .
fig.
shows similarity values as function of a target insensitivity level for the transitions observed during the experiments and achieving con dence.
these values capture the absolute distances between the true transitions frequencies and the estimated frequencies.
as expected these distances reduce with .
further for a large majority of the transitions the obtained distance lays below .
the average similarity values measured are for resp.
showing a consistent increase in similarity as insensitivity decreases.
finally the reliability levels measured not shown in the gure are for resp.
which illustrates that reducing insensitivity level increases the error rate of the experiments.
this is explained by the fact that reducing the insensitivity level requires capturing more transitions with higher precision.
we conclude that the results demonstrate that our method reaches high reliability levels which is re ected by the small distances high similarity values reported above.
2we did not include the cvs.net log in fig.
as both its rst and third quartiles equal which shrinks the body of its boxplot to a single point.
.
.
.
.
.
.
.
.
.
.981similarity .
.
.
.
.
.
.
128similarity duplication factor log1 log2 log3 log4 log5figure similarity obtained for log set i and log set ii see section .
.
.
.
.
.
.
.
.
.
.
.
similarity abs.
distance insensitivity .
.
.
.05read transitions insensitivity figure the gures report the results for log set iii.
left similarity distance between the true and estimated transitions frequencies as function of see section .
.
.
right number of read transitions as function of see section .
.
.
remark .
the reader may notice that we discarded unobserved transitions from our analysis.
we did so since large majority of the transitions had frequencies lower than the values we used.
therefore they would nearly always be considered within a distance of from the estimation.
this makes the similarity and reliability values so high that the in uence of changes in can no longer be observed.
by discarding these transitions we excluded the long tail of the transitions distribution from our results and facilitated their comprehension.
to answer rq2 our method is able to obtain high similarity levels which in the case of k tails indicate that most of the information is indeed captured.
further the expected reliability level of is obtained when the selected con dence level is above .
our experiments with bear provide evidence that the sampled transitions frequencies guarantee the required similarity of maintaining as required an error rate of or less for .
.
.
rq3 and rq4 to answer rq3 and rq4 we run the k tails experiment over log set i and log set ii with the same setup and parameters as in rq2.
for better visualization of the data we present the average results for the experiments with and k and note that we ob tained similar results with other values of .
we repeated all experiments times.
for log set i fig.
top left presents the percentage of read traces when reaching the desired con dence.
as can be seen this increases as the complexity of the analysis increases.
this is not surprising as increasing k increases the amount of information that needs to be extracted from the log.
as an example the number of k sequences extracted from the datagramsocket log is and for k resp.
therefore con dence is quickly reached for k but is never reached for k in which on average of the traces revealed at least a single new k sequence when they were processed.
this shows that for logs with high redundancy levels where the information can be extracted from a fairly small set of randomly selected traces our method is able to signi cantly reduce the number of read traces.
it also shows that when the log does not contain much redundancy as in the case of the datagramsocket and socket logs withk all of the traces are read.
we interpret this as the cost required to ensure the high reliability levels discussed in rq2.
the trend was repeated with not shown in the gure with a higher percentage of read traces for and a lower one for as one would expect.
fig.
top right presents the ratio between the sample analysis execution time and the entire log analysis execution time.
two encouraging conclusions can be derived.
first when the log contains much redundancy our method 3read traces k cvs.net datagramsocket socket zipoutputstream 3ratio of analysis execution time k cvs.net datagramsocket socket zipoutputstream 128read traces abs.
number duplication factor log1 log2 log3 log4 log5 128ratio of analysis execution time duplication factor log1 log2 log3 log4 log5figure read traces and execution times for log set i and log set ii see section .
.
.
achieves signi cant reduction in execution time.
as an example when setting k the sample times were between and of the log times.
second even in the cases where all traces are sampled applying our method increases the required time by only a reasonable factor of to .
note that our implementation is rather simple and may be further optimized.
fig.
bottom left presents the absolute number of read traces when increasing the size of the di erent logs in log set ii.
since the logs were duplicated the same information is contained in all versions of each log.
the di erence between the versions of the logs is the amount of redundancy they contain.
as can be seen starting with a duplication factor of the number of read traces stabilizes and does not increase with the size of the log anymore.
the trend shows that our method is able to not be fooled by the redundancy and to capture the meaningful information using a constant number of traces!
this justi es the claim that our method allows for sub linear log analysis.
in fact as demonstrated by the trend in fig.
bottom left the analysis indeed converges to a constant sample size.
finally fig.
bottom right shows the ratio between the sample times and log times for the di erent logs.
as can be seen the gap between these two measures widens as the log size increases.
this can be explained by our earlier observation that the number of sampled traces converges to a constant from a certain point on in comparison with reading the entire log.
one may also note that for the majority of the logs a bene t is obtained with a duplication factor of four and more.
finally similarly to the experiments over log set i one may observe an acceptable overhead when the entire log is read ranging from to with an average overhead of .
indeed the statistical analysis does not come for free.
still note that the entire log is read if and only if con dence is not obtained.
in such cases the extra computations we perform provide the engineer with an indication that the computed model does nothave the required sta tistical guarantees.
we consider this to be an important useful side contribution of our work.
to further investigate rq3 and rq4 we run the bear algorithm experiment over log set iii.
to answer rq3 we used the same parameters as in rq2.
first we measured the number of read transitions required for each of the transitions to obtain con dence.
fig.
right reports these numbers as function of as before we did not include transitions that did not obtain con dence .
the results show as expected that reducing the insensitivity level comes at the cost of reading more transitions.
the average numbers of transitions read were and for resp.
we also report the average number of read transitions when each run was terminated.
as described in the setup a run was terminated once all of the observed transitions achieved con dence.
the values were and the entire log transitions for resp.
finally to answer rq4 we present the average execution times recorded for each of the experiments.
the measured times in minutes are .
.
.
.
for resp.
in contrast we measured an average of minutes for the original bear implementation as stated in rq1.
this shows that our method can indeed lead to signi cant time reductions.
further one can observe that even in the cases where the experiment only ended after all the transitions have been read such as in the case of very low insensitivity the overhead is very moderate with an average of additional execution time.
here again we claim that the extra computation is not for nothing as it provides the user with important information about the reliability of the constructed model.
we conclude that the results demonstrate our method s ability to yield major reduction in the number of read transitions and in total computation time.
further the results emphasize the trade o between sensitivity and scalability.
885to answer rq3 after experimenting with values that were shown to achieve high reliability levels in rq2 we conclude that our method is able to reduce the number of traces or transitions read.
our method e ectively addresses redundancy and converges to a constant sample size while still capturing the information available in the log.
further the method is able to identify logs that do not contain much redundancy and in these cases read most traces or transitions to ensure high reliability.
to answer rq4 our method is able to dramatically reduce the analysis time of large logs with high redundancy.
it also has an acceptable overhead in cases where the entire log needs to be read i.e.
when con dence is never obtained.
in such cases it indicates that more data is required to construct a more reliable model.
.
threats to validity and limitations we now discuss threats to validity of our answers to the research questions and additional limitations of our work.
one may argue that the duplication of logs in log set ii may not be representative of real world long logs.
still as every system has a certain degree of complexity with respect to an algorithm as logs become longer redundancy with respect to the k tails algorithm is inevitable this holds for many other behavioral log analysis algorithms as well .
our use of duplications allowed us to control for this redundancy in our experiments.
that said we have also used real world large logs without duplications log set iii .
the similarity measure does not compare the nal output of the selected algorithms.
we have decided to focus on the data elements from which models are constructed k sequences transitions and not on the nal output of the algorithms.
our decision is motivated by the fact that these elements determine the nal output of the algorithms.
there may be di erent ways on how to measure similarity between the nal outputs choosing between them may depend on the speci c intended use.
the lters and criteria used to partition the log into traces can have a dramatic e ect on the entire analysis and on the resulting model e.g.
de ning user classes in bear .
for di erent lters and di erent partition criteria one may obtain results that are di erent than the ones we have seen in our experiments.
note though that our method does not restrict the partition but only requires that the traces which are derived from the partition e.g.
read traces in k tails single events in bear can be randomly and independently selected.
the analysis of traces may only take a small part of the complete analysis computation time .
in this work we focus on applying statistical means to reduce the amount of analyzed data.
clearly there are other steps in applying a behavioral log analysis algorithm such as parsing the log ltering and partitioning it into traces and constructing a model from the extracted data.
these are all important practical aspects which are beyond the scope of our present paper.
for example in the present work to obtain a random trace we read the entire log or duplicated it in memory .
as part of future work we will explore means to randomlysample traces from a log without rst reading it entirely and without assuming a prede ned log structure .
the log may not represent the behavior of the system that generated it.
generating a representative log of a system is a problem that deserves its own investigation and is beyond the scope of the present paper.
in the present paper we limit our focus to investigate if behavioral log analysis can be made scalable by sampling a portion of the available log and obtaining results that are similar to the results that may be obtained by processing the entire available log with required statistical guarantees.
the results of statistical log analysis albeit correct may not be useful when the given log has a long tailed distribution with many very infrequent properties.
for example in the case of the bear algorithm if of the transitions in the log have frequency of less than setting the insensitivity to be greater than will cause most of the transitions to be missed completely.
we do not know whether many real world logs exhibit such long tailed distributions.
note that the distribution depends on the chosen lters and partition see above .
.
contributions and future work in this paper we presented statistical log analysis which uses trace sampling and statistical inference to address the scalability challenge in the behavioral analysis of large logs.
the key to the approach is to consider each new part in a log as a trial in an experiment.
we demonstrated the application of our approach to two di erent analyses the classic k tails algorithm and the recently introduced bear inference algorithm.
extensive evaluation with logs generated from real world models and with real world logs provided by our industrial partners provides evidence for the need for scalability and for the e ectiveness of statistical log analysis.
we believe that statistical log analysis has much potential to help in scaling up existing behavioral log analysis algorithms and thus in bringing these algorithms to the hands of software engineers in practice.
we consider the following future directions.
first we investigate other more elaborated and robust stopping criteria which can result in less conservative yet still correct analysis results.
second together with our industrial partners we look for additional analysis algorithms where statistical log analysis can be applied for example in scenario based trigger e ect analysis and in log comparisons in the context of software evolution.
lastly we investigate a more sophisticated machinery to remove some of the underlying assumptions of our approach i.e.
time homogeneity incrementality .