automatic text input generation for mobile testing peng liu xiangyu zhang marco pistoia y unhui zheng manoel marques and lingfei zeng ibm t. j. watson research center y orktown heights new y ork usa email liup pistoia zhengyu manoel us.ibm.com purdue university west lafayette indiana usa email xyzhang cs.purdue.edu zengl purdue.edu abstract many designs have been proposed to improve the automated mobile testing.
despite these improvements providing appropriate text inputs remains a prominent obstacle which hinders the large scale adoption of automated testing approaches.
the key challenge is how to automatically produce the most relevant text in a use case context.
for example a valid website address should be entered in the address bar of a mobile browser app to continue the testing of the app a singer s name should be entered in the search bar of a music recommendation app.
without the proper text inputs the testing would get stuck.
we propose a novel deep learning based approach to address the challenge which reduces the problem to a minimization problem.
another challenge is how to make the approach generally applicable to both the trained apps and the untrained apps.
we leverage the word2vec model to address the challenge.
we have built our approaches as a tool and evaluated it with ios mobile apps including firefox and wikipedia .
the results show that our approach significantly outperforms existing automatic text input generation methods.
i. i ntroduction mobile devices have become an integral part of our life.
mobile apps are the vehicle to deliver a wide variety of convenient and high quality services such as web browsing entertainment transportation information assistance banking and social networking.
in response to the increasing need the mobile market is growing rapidly in a speed of new apps per day .
accordingly the development teams are constantly in fierce competition with great pressure of meeting release deadlines.
this unfortunately often leads to bugs in mobile apps such as run time app crashes flaws in ui designs and functions that are not fully implemented.
the goal of mobile testing is to find bugs in an app before it is released.
there are two mainstream mobile testing methods manual testing and automated monkey testing .
in manual testing the testers manually perform actions to exercise as many use cases as possible.
the disadvantage of this approach is that it requires substantial human efforts as testers need to closely interact with the app throughout the entire testing period.
moreover the human testers who usually focus on demonstrating the functionality in common use cases may often miss the corner cases which could trigger exceptions.
automated monkey testing was proposed to reduce human efforts and maximize use case coverage.
monkey is a metaphor to describe how this type of testing works like a monkey the tool performs random sequences of actions including clicking thebuttons on a ui view or ui screen and performing random keystrokes.
to cover as many action sequences as possible researchers have proposed various novel search algorithms in contrast to the monkey random search strategy.
despite these improvements providing appropriate text inputs during monkey testing remains a prominent obstacle which hinders the large scale adoption of monkey testing approaches.
most existing techniques can hardly provide meaningful text inputs in many use cases.
as an example for a movie app monkey testing can hardly provide meaningful inputs such as star trek .
instead it would produce irrelevant inputs such as 4t6 .
as a consequence no results would be found thereby making monkey unable to proceed to the screen that displays appropriate results.
manual specification may mitigate this problem but incur substantial human effort.
in this paper we present a solution that lets monkey automatically produce relevant text inputs.
with such inputs monkey can proceed to ui screens deep in the workflow for short deep ui screens through long action sequences instead of getting stuck at the very beginning.
once it reaches a deep ui screen monkey can apply other bug disclosure oriented testing techniques such as search based testing symbolic test generation or even random testing to identify bugs in the complex workflow.
a. generating relevant inputs a key requirement of input generation is to produce inputs that are relevant to the context.
movie search star trek weather search new york in use case after the menu item labeled movie is clicked and a search bar labeled search is triggered the app expects the title of a movie from the user.
hence the input star trek is relevant in use case after the menu item labeled weather is clicked and the search bar labeled search is triggered the app expects the name of a city from the user.
therefore the input new york is relevant.
in contrast an input that is relevant in one context may not be relevant in a different context.
for example the input star trek would be inappropriate when menu item weather is clicked.
we also refer the readers to more real world examples in section vii.
challenges.
the above requirement imposes great challenges to automatic text input generation.
first the relevance is specific to the natural language semantics which only human ieee acm 39th international conference on software engineering ieee acm 39th international conference on software engineering .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
testers can understand.
therefore traditional automated input generation approaches such as symbolic execution based testing are not applicable.
second the action e.g.
clicking menu item movie orweather that contains the information that determines the relevant text inputs may not immediately precede the input action in the action sequence.
therefore maintaining and looking up the mapping between a text input and the information of immediately precedent action is an approach that will hardly work.
our deep learning based approach.
we propose a novel deep learning based approach to solve the challenges described above.
at the high level our solution consists of two phases in the training phase the monkey learns the testers manual inputs and statistically associates them with the contexts such as the action history and the textbox label in the prediction phase the monkey automatically predicts text inputs based on the observed contexts.
the core of our approach is a recurrent neural network rnn model.
this type of model has achieved great success in many natural language processing nlp applications such as machine translation and input method auto completion.
take the input method auto completion for example the rnn model quantifies semantic connections among words as a non linear function of which the parameters are trained with a large corpus of texts.
given a word the nonlinear function calculates the probability distribution of the word next to it then the next word is sampled from the distribution.
in addition the rnn model maintains a memory state to summarize important information from previous words and uses it as another source of input while recommending the next word.
to the best of our knowledge we are the first ones to apply deep learning to the problem of text input generation for automated mobile testing.
according to the empirical study of mikolov et al.
the rnn model is significantly more accurate than traditional statistical models such as the n gram model and the hidden markov model .
specifically rnn leads to error reduction in comparison with the traditional models assuming they are trained on the same data and leads to error reduction even when the traditional model is trained on times more data than the rnn model.
b. app independent input generation another important requirement of input generation is app independence .
this means that the rnn model trained atop a set of apps should also apply to other apps.
challenges.
using different words in different apps to represent the same concept imposes a significant challenge to app independence.
film search ?
suppose that label film has not been seen in the training phase.
a human tester can easily figure out the semantic similarity between labels film and movie in use case .
accordingly we can predict the relevant text input for example star trek .
however the rnn model is completely oblivious of label film since it did not appear in the training phase.
as aconsequence the rnn model cannot predict the relevant text input from the label film .
our word2vec based solution.
we address the challenge by statistically learning the human knowledge of synonyms from thegoogle news corpus.
synonyms are stored in equivalence classes.
the representative of each equivalence class is used to replace the words that fall into the class during training and prediction.
our approach is built upon the word2vec model a statistical model recently proposed by the nlp researchers.
this model maps a word to a vector and the distance between vectors measures the similarity of words.
the word2vec model learns the vector encoding by solving an optimization problem.
specifically it minimizes the distance between similar words and maximizes the distance between irrelevant words.
word2vec is an unsupervised learning algorithm meaning that it does not require manual labeling of training data.
word2vec outperforms other existing models in the quality of results .
this is mainly because word2vec can train on to orders of magnitude more data than prior work within just a fraction of the time required by prior work.
we have built a tool and evaluated it with ios apps including popular apps such as firefox and wikipedia .
the evaluation results confirmed the effectiveness of our approach.
the rnn prediction improves the coverage of monkey testing by on average while the combination of the rnn model and the word2v ec model improves the coverage by .
besides if we exclude the simple apps with very few ui screens available from the benchmark suite we find the rnn prediction improves the coverage by and the combination of both models leads to improvement.
equally important our prediction is very efficient which typically completes within ms. in summary we make the following contributions in this paper we propose a novel approach based on deep learning to automatically produce the relevant text inputs for the mobile ui testing.
we propose a novel combination of the word2vec nlp model with the learning to make the input generation app independent .
we have implemented our approach as a system and conducted experiments over ios apps including firefox and wikipedia .
the results show that our approach significantly increases the coverage of monkey testing.
ii.
o verview of system design the system design is shown in figure .
the monkey testing engine explores the mobile app by clicking the buttons in the screen.
when it encounters a textbox it requests the relevant input from the text input server as denoted by circlecopyrt2 circlecopyrt.
the server resolves the request by further dispatching it to either a human tester or the rnn running instance which authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
workflow of the system corresponds to two modes the manual mode and the ai mode.
in the manual model upon the receipt of the request for help circlecopyrt the human tester can either enter a text input relevant in the context circlecopyrt or ignore it if she does not think the context corresponds to any action sequence in practice.
the inputs entered by the tester and the corresponding contexts are then recorded in the database associated with the server.
in the ai mode we first train the rnn model with the training dataset recorded in the database circlecopyrt after which the rnn instance can predict the text input automatically circlecopyrt.
in the prediction phase circlecopyrt monkey leverages the rnn model to predict the text input value in a given context.
basically given the context maintained by the monkey testing engine the model predicts the text input value.
however since the apps that we predict inputs for are different from the apps that we train the model upon the rnn model may not recognize some context information encountered during the monkey testing.
to address this challenge we improve the rnn model with a word2vec model which helps recognize the semantically similar contexts despite their different syntactical forms e.g.
movie and film .
through the novel combination of the rnn model and the word2vec model we effectively address the problem.
in the following we first introduce the background in section iii and then explain how we apply the deep learning techniques to automatically predict the text input in section iv.
in section v we explain the implementation details.
in section vi we discuss the assumptions of this work.
section vii presents the evaluation results.
iii.
b ackground ondeep learning this section introduces the background of recurrent neural network rnn and word2vec .
both rnn and word2vec fig.
.
a neural network.
b neuron are special forms of neural network.
in order to discuss these two we first have to briefly introduce neural network.
neural network nn has two forms graphical form and mathematic form .
in the graphical form figure 2a nn has an input layer an output layer one or more hidden layers.
each layer except the input layer comprises multiple neurons that connect with the neurons in the previous and next layers.
each neuron as shown in figure 2b is a basic computation unit.
it first linearly combines the values passed along the incoming edges as summationtext ipixi b wherepiandbare parameters to be trained.
then it applies an activation function fa e.g.
the tanh function or the sigmoid function .
the activation function is important in making the neuron nonlinear.
without the activation function the neuron is merely a linear function and the neural network is also a linear function which cannot characterize many complex models.
in the mathematic form nn is a composition of the functions represented by the neurons.
let f rn mapsto rmdenote the composite function represented by a neural network.
let the input vector vectori rndenote the inputs to the nneurons in the input layer.
let the output vector vectoro rmdenote the output by the mneurons in the output layer.
the training of a neural network can be viewed as an optimization problem minimize pi b ... summationdisplay vectori vectoro trainloss f vectori vectoro the parameters are updated to minimize the total loss between the predicted output and the real output over the training dataset where the loss function can be defined as distance or other forms.
regardless of the complexity of the loss function the gradient descent algorithm is generally applied to minimize its value.
a. recurrent neural network rnn is a special form of neural network that has a feedback loop as shown in figure .
for clarity we use arrows to denote the connections between neurons.
the loop allows the information derived in a step of the network execution to be passed to the next analogous to human s long term memory.
figure shows a conceptually unfolded version where the neural network is conceptually authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
copied to serve a sequence of inputs through multiple steps.
note the connection between the neural network copies.
fig.
.
rnnconsider the application of the input method autocompletion we apply rnn to generate the sentence how are you .
the words are fed to the input layer one by one.
each word is encoded in the one hot vector representation to enable learning e.g.
the word how is encoded as .
simply put each entry of the vector corresponds to a word in the vocabulary and the location of value in the vector indicates the word encoded.
from the perspective of probability the vector represents the word with probability and others with probability.
with the initial parameter settings given an input word combined with the information passed from the last step the neural network outputs a probability vector where the ith entry estimates the probability that the ith word in the vocabulary will appear next.
for instance based on the input how assume that it predicts the next word as .
.
.
.
i.e.
the most likely next word is how .
however we observe from the training dataset that the next word should be are .
therefore the training algorithm needs to update the parameters so that the predicted probability of the word are becomes significantly larger than other words.
similarly given the word are the neural network needs to predict you a s the next word with higher probability than others.
fig.
.
recurrent neural network unfolded b. word2v ec the word2vec algorithm learns the vector representation of each word in a space rk where similar words are likely to have similar vectors.
word2vec is typically applied to very large corpus.
for better scalability word2vec adopts the traditional neural net structure.
the vector representation adopted by word2vec is significantly different from the one hot representation used in the aforementioned rnn.
word2vec maps each word to a realvalued vector in the space rk wherekis much smaller thanthe vocabulary size s while the one hot representation maps each word to a vector in the space s. first by encoding vectors in a low dimensional space word2vec reduces the space complexity of computation.
more importantly the vector representation of word2vec is in a continuous space and the distance i.e.
cosine similarity distance between two vectors effectively measures the similarity of the words.
in contrast the one hot representation cannot measure similarity.
in our work we treat the word2vec as a blackbox.
iv .
a ppl ying deep learning to input genera tion at the high level our approach statistically learns the correlations between a text input value and its context in the training phase section iv b .
then in the prediction phase section iv c once monkey needs to provide some value in a textbox our approach predicts the value based on the context observed by monkey so far.
section iv d further explains how we generalize the input generation to make it app independent.
to facilitate the discussion we first introduce the training dataset section iv a which is used in the training phase.
a. training dataset without loss of generality we assume a simplified user action model .
in the model we are only interested in two types of ui elements button and textbox domain tui.
a wide range of clickable ui elements such as menu and tableview cell have behaviors similar to button and hence have the same abstraction in our model.
similarly a range of text fields that accept user input such as secure text field and search field are abstracted as textbox .
note our implementation fully supports all these ui elements.
we are only interested in two types of actions tap and typet ext taction which are the most representative behaviors of the ui elements tui.
a user action a is a tuple that includes the ui element type ui tui the action type action taction the label lscript displayed in the ui element e.g.
movie in the button in figure and optionally the value vinvolved in the action e.g.
the text input value.
the training dataset essentially records action sequences angbracketleft 0 1 ... n angbracketrightwith ithe user action at the ith step.
the subsequence preceding nrefers to the actions that the user takes to reach the ui screen on which noccurs.
more details about the action sequence are discussed in section vi.
we observe that label lis the most prominent information that the user perceives when he she uses the app thinking of what to provide as the input value.
based on this observation we represent every action in the action sequence with a label lscript while abstracting away all other information.
besides we are also interested in the input value v nentered in the action n. therefore the above action sequence is simply represented as angbracketleft lscript 0 lscript ... lscript n v n angbracketright.
for ease of presentation we also refer to lscript 0 lscript ... lscript nas the context of the input value v n. consider the example in figure suppose the tester performs actions to trigger the ui screen transitions and to enter authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the input value.
in the first screen the tester clicks or taps the button labeled with movie leading to the second screen with the search bar labeled with search .
in the third screen the tester enters the input value star trek 1in the search bar.
following the user action model we have two actions clicking the button with the label movie and entering star trek in the search bar with the label search .
accordingly the sequence recorded is angbracketleftmovie search star trek angbracketright.
fig.
.
ui screen transitions triggered by user actions b. training phase without loss of generality we assume each label lscriptor input valuevis a single word rather than a phrase.
section vi presents a simple preprocessing that assures the assumption.
let v ocabulary v l val denote the list of all the labels and the input values that appear in the training dataset.
in the following we do not distinguish the label and the input value unless otherwise specified.
instead we refer to them with the general term word .
in order to enable learning we propose the following vector representation of each word.
given a word its vector form vector has the same size as the vocabulary.
and every entry of the vector is defined as vector braceleftbigg vectorv 0otherwise since only one entry can take the value the vector representation is also referred to as the one hot representation.
consider figure .
at step the input vector is as shown in the input layer.
at each step the rnn model accepts the vector representation of a word as an input.
the input as well as the previous state of the hidden layer also encoded as a vector is used to predict the output a probability vector which characterizes the probability of each word appearing next in the sequence.
the goal of training is to update the parameters of rnn model so that the predicted probability distribution of the next word is close to the true probability distribution observed from the dataset.
1alternatively the value can be star trek n where the trailing symbol is equivalent to initializing the search.we formalize the training as an optimization problem argmax xp v n x lscript 0 lscript ... lscript n given the context lscript 0 lscript ... lscript n we find the input value v n xthat has the maximum conditional probability.
in the training phase we build a rnn model to predict the conditional probability.
the internal parameters of the model are automatically calculated so that the predicted probability distribution approximates the true probability distribution observed from the training dataset.
the trained model is then used for prediction under the assumption that the probabilistic association between the context and the input value of a textbox does not change significantly.
we explain more details about the formalization in our website .
c. prediction phase after the model is trained it can be used for prediction.
in general the rnn model accepts a sequence of words as the input and outputs a probability vector which characterizes the probability that each word in the vocabulary appears immediately after the sequence which we refer to as the next word .
the sampling of the probability distribution will select a word with the probability described in the distribution.
in our problem settings when monkey encounters a textbox it serializes the action history and the label of the textbox into a sequence and then it sends the sequence to the trained model to predict the probability distribution of the next word.
lastly it samples the probability distribution to get the value of next word.
in general any word in the vocabulary can be the next word.
the words in the vocabulary may correspond to action labels textbox labels or text input values but we are only interested in predicting the text input values.
if a sampled result does not represent a text input value i.e.
it does not belong to the vocabulary of the text input values we discard it and re sample the distribution.
the idea of sampling a probability distribution is as follows.
let odenote the output vector of the rnn model which characterizes the probability distribution.
we first separate the range between and into o intervals.
interval i i o starts at summationtexti j o and ends at summationtexti j o .
a uniform random variable x u falls into the interval with the probability o i.e.
the length of the interval.
in other words the probability that the uniform random variable xfalls into intervaliis identical to the probability that we select the word v .
therefore if the random variable falls into interval i w e return the word v .
consider the following example.
suppose the output probability vector is as shown in figure .
figure shows the four intervals.
suppose the uniform random variable is assigned the value .
then it falls into interval note there is interval .
therefore we return the word v i.e.
the word are .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
sampling the probability distribution.
d. app independent input generation our ultimate goal is to predict inputs for apps that we have not trained upon.
the main challenge is to make the input generation app independent.
our idea is that if we encounter a word that has not been seen in the training phase we may be able to connect it to some similar word that has been seen in the training phase leveraging word2vec .
we use a word2vec model trained beforehand using the very large google news corpus .
when encountering a word that is not in the vocabulary for example a textbox label that does not occur in any of the apps during training our system queries the word2vec to look for the most similar word in the vocabulary more precisely the vocabulary of the action labels and the textbox labels .
if the similarity which can be computed from the vector representations of the two words is lower than a preset threshold .
we consider that the word does not have the counterpart in the training dataset and simply ignore it during the prediction.
in the worst case if the word is important in determining the text input value our technique hence degrades to the traditional monkey testing.
these cases happen mostly because the app is in a new category that is very different from the kinds of apps that we have trained on.
v. i mplement a tion we presented the overview of our system design in section ii.
in this section we explain the implementation details of each component shown in figure .
a monkey testing engine our monkey adopts a depthfirst search strategy in exploring action sequences i.e.
it clicks the available buttons one by one after filling the values for all the textbox elements in the current screen.
the buttons inside the same screen can be clicked either in the random order or in some sequential order e.g.
the alphabetic order of the button label .
we implemented both options and adopted the random order in our experiment.
in addition to avoid the repeated exploration of the same screen we constructed the signature of each screen which consists of the title of the screen and the labels of the buttons in the screen.
the screens with the identical signature are treated as the same screen which are explored only once.
note our system can be easily extended to predict next actions in addition to text inputs.
however we consider this would undesirably limit monkey s ability to achieve good coverage as it would tend to follow human testers action sequences which are limited.
hence one of the important design principles of our system is to use the random exploration for actions and the rnn prediction for text inputs.we implemented the ios monkey with the test automation framework xct est shipped with the xcode ide.
the framework provides a set of apis that allow us to find the button or textbox elements in the screen.
for example we can use the following api call to easily find all the buttons in the current screen descendantsmatchingtype .button b text input server the text input server implemented using the python web framework bottle is an abstraction layer that hides the details of how the inputs are generated.
since it is implemented in python and the monkey testing engine is implemented in swift there is a programming language barrier between the two components.
to break the barrier they communicate with each other by sending the http messages in the json format.
the input server communicates with the rnn instance through the function calls since both are implemented in python.
in addition we maintained a database for the input server to store the inputs entered by the human testers in certain contexts.
we adopted the mongodb .
the input server interacts with the database using the python driver pymongo .
c rnn instance we built the rnn model on top of the python deep learning framework t ensorflow which provides the high level apis while hiding many low level details.
with the abstraction of tensorflow one can build the rnn model with merely lines of code as shown in our website .
we trained the model by first preprocessing the dataset with word2vec and then feeding them into the rnn model.
besides the trained rnn model can be saved to the disk and loaded for further use at any time.
vi.
d iscussion in this section we discuss the assumptions that we make in this work.
an assumption that we make in training prediction is that a label or an input value is a single word rather than a phrase or a sentence.
in case the label is indeed a phrase we break it into words and treat each word as a separate label context.
by reasoning at the word level our approach can handle any phrase as long as the words in it belong to our vocabulary.
in contrast for text input values that are phrases we treat the phrases as atomic units so that they are not partitioned throughout the training and the prediction.
another important assumption of our approach is that the apps that we train the monkey upon and the apps that monkey will test should share some similarity e.g.
they fall into the same category on the app market.
otherwise if we train the monkey upon entertainment apps and apply it to test tax apps the predicted text inputs would make no sense.
to avoid such situations we collect apps of as many different types as we can and use them as the training subjects.
in our approach we assume the context comprises only textual labels.
in real world apps developers may use icons such as instead of textual labels.
we currently do not support non textual labels.
we note that our approach can be authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
extended to support non textual labels for example leveraging the image2text tools .
when we record the action sequence we maintain a list and append each action to the list.
however if we encounter the action that undoes the previous action we discard the action and remove the previous action from the list if we encounter the action that leads to the home screen of the app we simply clear the list.
lastly our work complements the large body of recent advances on automatic action sequence generation .
while we anticipate great synergy we will leave it to our future work.
vii.
e v alua tion in our experiments we are interested in the following research questions how effective is our automated approach compared to other automated input generation approaches for mobile testing?
does word2vec allow better results compared to using the rnn model only?
what is the performance overhead incurred by our tool?
to address the first question we compare with the automatic random input generation method which randomly picks an input value from a pool of commonly used input values.
we measure the effectiveness by computing the screen coverage i.e.
how many different ui screens have been explored within a fixed time window.
monkey testing is usually adopted for exploring as many use cases as possible.
however identification of the unique use cases requires domain knowledge.
instead we use the screen coverage to objectively approximate the use case coverage.
note that screen coverage is different from the classic coverage criteria e.g.
statement coverage and path coverage in functional testing.
we argue both are important.
in particular our approach complements functional testing in the sense that by providing the meaningful input values our technique allows monkey to reach the interesting ui screens.
starting from such ui screens existing functional testing work can be applied to expose app crashes.
additionally we argue that some ui screens are interesting even if they do not correspond to any app crash.
we refer the readers to our website for such examples.
note that our approach is orthogonal to automatic event sequence generation approaches.
in this work we adopt the existing depth first search strategy.
our contributions mainly lie in producing relevant text inputs based on contexts and tolerating the use of different words in different apps.
to address the second research question we compare the version with only rnn enabled and the version with both rnn and word2vec enabled.
section vii b addresses the above two questions by comparing three versions together.
lastly the performance overhead matters especially given that the prediction happens interactively during monkey testing.
ideally the approach should achieve effectiveness withlow performance overhead.
the measurement of the performance is presented in section vii a. a experiment settings we run the experiments on a macbook pro with os x ei capitan.
the ios apps are run in the simulator of iphone 6s plus ios .
.
we collect open sourced ios apps from github mostly from https github.com dkhamsing open source ios apps.
they fall into different categories including movie news image browser travel radio calendar weather and tasks.
they include popular apps such as firefox and wikipedia .
we trained on apps and tested the capability of prediction on the remaining apps.
our training dataset contains words in total.
when we collect the training dataset we try to reuse input values as much as possible.
for example when we need to enter a movie name in different apps we stick to the same movie name.
a. performance overhead the learning training process entails many iterations.
the model that we used for prediction was trained for hours but we measure the performance within a much shorter period.
we measure the computation time for every iterations and report the average time for an iteration.
we also use the model generated after every iterations to predict the next word using a random sequence from the dataset.
this is to sample the accuracy of the model.
we also measure the time taken by the rnn model for the training and the prediction.
as shown in figure the training prediction time remains constant except at the initial steps.
this is because each iteration handles a fixed amount of data and the neural network structure does not change dynamically.
another important observation is that each prediction takes .
ms on average which is negligible compared to other actions in the testing e.g.
entering the text .
fig.
.
running time of rnn model we also measure the loading time of the word2vec model and the time for each query for a similar word.
the loading takes around seconds while every query takes around .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ms. due to the space limit we do not show the figures.
the loading time is long because the model is large which is trained on google news corpus with billion running words.
our text input server tackles this problem by loading the model during the initialization of the server.
once loaded the model can be used for all the incoming queries.
b. effectiveness of our approach to measure the effectiveness we compare three versions random which randomly picks a value from the pool of commonly used input values.
note that random version is oblivious of the context information.
rnn which applies the rnn prediction model and hence is aware of the context information rnn word2vec which enables both the rnn prediction and the word2v ec model.
we count the number of screens explored by different versions within minutes.
for each version we repeated the experiment three times and reported the maximal number.
the results over the apps are reported in figure .
the rnn version detected .
more screens than the random version while the rnn word2vec version detected .
more screens than the random version.
as there are a number of apps that have simple functionalities and hence a small number of screens the three versions explore the same number of screens for those apps.
by excluding those cases we observe that the rnn version outperforms the random version by whereas the rnn word2vec version outperforms it by .
note the difference between the rnn version and the rnn word2vec version highlights the effectiveness of using the word2vec .
we manually inspect the detailed results and have a few interesting observations.
first the three versions produce the same results for apps.
the reason is that these apps either do not require any user input or work with any kind of input values.
for instance in propertyfinder even when monkey enters in the search bar a meaningless input value which should lead to no matches the app still retrieves and displays a list of real estate properties for sale.
in another app chats the app is for receiving sending messages it works regardless of what the message is.
second we observe that the rnn version can explore many ui screens that the random version cannot explore.
intuitively when the textbox requires the input value of special format or special meanings the rnn version is aware of the context and produces the proper input value based on the experience it learned from the training dataset.
in contrast the random version which is oblivious of the context usually produces the input values that do not meet with the special requirements.
for instance in the sip calculator app there is a textbox with the label amount meaning that it expects some numeric input i.e.
the app will perform some arithmetic computation over the input number .
monkey with our rnn model is aware of the context information and has learned that the context is strongly correlated with a numeric input value.
as a result monkey enters a numeric input value and proceedsto a new screen.
in contrast the random version does not produce any numeric input and hence cannot proceed.
in an extremal case the alzprevent app i.e.
a research lab s survey app requires the users to fill in a registration form before they can proceed to a survey.
alzprevent has screens for the registration process including the user name height weight and some other information.
the random version got stuck in the first page while our rnn version and also the rnn word2vec version knows how to fill in the input values since it has been trained over multiple apps that need registration.
as a result our rnn version outperforms the random version by and the rnn word2vec version outperforms it by .
third we find the rnn word2vec version performs better than the rnn version when the contexts are slightly different from those in the trained apps.
with the word2vec model the version recognizes the semantic similarity among the contexts from different apps.
based on the similarity information the version predicts the relevant input values based on the knowledge associated with the contexts from the trained apps.
the improvement over the rnn model shows the importance and effectiveness of combining the rnn model and the word2vec model.
we also present case studies in section vii c to demonstrate the strength of our technique.
c. case studies a firefox the first case is from the official firefox ios app.
this case illustrates the importance of producing relevant input values and demonstrates how our approach produces them.
as shown in figure on screen the home button is missing by default so that the functionality associated with the button cannot be tested.
to make the home button appear one has to tap the setting button to change the setting.
however a valid webpage url is required as the input value on screen .
otherwise the home button will not show up.
our monkey can predict a valid url for the textbox based on its label enter a webpage and the action history setting homepage on screen and hence enables the home button as shown on screen .
the random version which is oblivious of the label enter a webpage in the textbox produces a random input value new york .
the firefox app does not accept the input and accordingly does not enable the home button.
in fact firefox does not record invalid inputs in its database.
after monkey navigates to another screen and then back the input value entered by the random version is lost.
by manually searching for the predicted webpage url in the training dataset we identify some interesting connections.
the url was used by a web crawler app and was associated with the label website in the app.
our approach first recognizes based on word2vec the similarity between website and webpage screen then it predicts based on the rnn model the most likely input value.
this example demonstrates the effectiveness of our technique in authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
the measurement of effectiveness g3 g9 g7 g4 g1 g2 g12 g11 g11 g9 g8 g1 g7 g6 g10 g10 g6 g8 g5 g4 g13 g11 g9 g1 g2 g17 g16 g16 g13 g12 g3 g12 g16 g9 g15 g1 g6 g1 g18 g9 g7 g14 g6 g10 g9 g5 g8 g15 g9 g9 g12 g1 g19 g5 g8 g15 g9 g9 g12 g1 g20 g5 g8 g15 g9 g9 g12 g1 g21 fig.
.
the official firefox app exploring new ui screens even when the two apps have different use cases or business logic.
b third party github app figure shows the case from a third party app for github .
in this case our tool taps the search menu item screen and then selects the repositories category screen .
it also successfully predicts the input value java for the search bar which leads to further progress with a few matching repositories returned screen .
our tool further clicks each of the repositories which leads to the discovery of an exception.
as shown in figure the exception occurs at line .
by using the exclamation mark in swift language the developer assumes that the variable repodescription which is the description of the repository cannot be nil i.e.
g4 g6 g13 g7 g7 g10 g1 g19 g4 g6 g13 g7 g7 g10 g1 g18 g4 g6 g13 g7 g7 g10 g1 g17 g2 g5 g16 g5 g4 g7 g5 g13 g6 g8 g3 g7 g12 g11 g14 g9 g15 g11 g13 g9 g7 g14 fig.
.
the third party github app monkey fig.
.
the bug found in the github app no value .
however in practice some repository does not have any description which breaks the developer s assumption.
as a consequence the mobile app crashes when it attempts to unwrap the optional value that is nil .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
in contrast the random version produces an input value benjamin franklin which is inappropriate in the current context.
accordingly this version fails to find the above bug.
this case clearly shows the usefulness of our tool.
c frameless frameless is a full screen web browser which adopts the minimalist ui design.
fig.
.
the bug found in frameless our tool found a bug similar to the bug found in the github app as shown in figure .
finding the bug requires monkey testing to produce valid inputs.
consider figure in the first screen the search bar shows website url or search .
given such a context our tool produces a valid website in the second screen based on the statistical correlation learned from the training dataset.
the mobile app then transits to the third screen.
by clicking the sign in button our tool exposed the exception shown in figure .
by inspecting the code we found that clicking the sign in button leads to the internal execution of some bug fixing code which unfortunately mishandles the content of the url.
in this case the context consists of four words all of which are sent to the rnn model to produce a valid input in the search bar.
in contrast the random version did not produce the valid url and therefore cannot find the above bug.
fig.
.
the bug found in frameless viii.
r ela ted work our work is closely related to automated test generation for android apps.
monkey and dynodroid are random exploration based ui events generation tools.
guiripper mobiguit ar orbit a3e swifthand and puma build finite state models for ui and generate events to systematically explore states in the model.
contest generates events based on a concolic execution approach and prunes search space by checking conditions among event sequences.
ermuth and pradel introduced the macro event that summarizes recurring sequences of low level ui eventsfor a single step.
by combining macro events with random testings they leverage recorded user interaction sequences and automatically generate new tests.
compared to our approach most of automated test generation work focuses on generating event sequences or action sequences .
besides events and intents generating test input values is also important as some behaviors can only be exposed if the predicates on input values are satisfied.
symbolic execution and evolutionary algorithm based techniques have also been applied.
jpf android extends java pathfinder jpf and is a model checking tool to explore all paths and identify runtime failures.
evodroid generates tests both events and inputs based on an evolutionary algorithm framework.
it uses a random approach to generate inputs.
sapienz is a multi objective search based testing tool for android apps.
it combines random fuzzing systematic and search based exploration exploiting seeding and multi level instrumentation.
although it can provide strings as test inputs these strings are extracted from the app by reverse engineering the apk and randomly seeded into the text fields.
the randomly selected inputs are unlikely to be relevant in a specific context.
afshan et al.
apply the guided search based on the n gram language model to produce the readable string inputs rather than random character sequences.
however the approach is not designed to produce the string inputs in a use case context.
our work is also related to machine learning based text modeling and generation techniques.
sutskever et al.
demonstrated the power of large trained rnns by applying them to the task of predicting the next character in a stream of text.
melicher et al.
proposed a neural network based approach to model human chosen password and measure its resistances to guessing attacks.
ix.
c onclusion we have developed a deep learning based approach to automatically generate the text inputs for the mobile testing.
it produces the most relevant input values in a context.
besides we have leveraged the word2vec model to achieve the appindependence.
the evaluation over ios apps confirms the effectiveness and efficiency of our designs.
acknowledgment we thank the anonymous reviewers for their constructive comments.
this research was supported in part by darp a under contract fa8650 c nsf under awards and onr under contract n000141410468 and cisco systems under an unrestricted gift.
any opinions findings and conclusions in this paper are those of the authors only and do not necessarily reflect the views of our sponsors.