sketch guided gui test generation for mobile applications chucheng zhang haoliang cheng enyi tang xin chen lei bu xuandong li state key laboratory for novel software technology nanjing university nanjing china software institute of nanjing university nanjing university nanjing china corresponding author eytang nju.edu.cn abstract mobile applications with complex guis are very popular today.
however generating test cases for these applications is often tedious professional work.
on the one hand manually designing and writing elaborate gui scripts requires expertise.
on the other hand generating gui scripts with record and playback techniques usually depends on repetitive work that testers need to interact with the application over and over again because only one path is recorded in an execution.
automatic gui testing focuses on exploring combinations of gui events.
as the number of combinations is huge it is still necessary to introduce a test interface for testers to reduce its search space.
this paper presents a sketch guided gui test generation approach for testing mobile applications which provides a simple but expressive interface for testers to specify their testing purposes.
testers just need to draw a few simple strokes on the screenshots.
then our approach translates the strokes to a testing model and initiates a model based automatic gui testing.
we evaluate our sketch guided approach on a few real world android applications collected from the literature.
the results show that our approach can achieve higher coverage than existing automatic gui testing techniques with just minute sketching for an application.
i. i ntroduction until november the number of available mobile applications in the google play store is over .
million .
many of these applications provide rich features that help billions of users to communicate with each other.
hence testing these applications is important.
however as most of the mobile applications interact with users through a graphical user interface gui generating test cases for these gui applications is a challenge.
two classical approaches have been widely applied to gui testing manually writing gui scripts as test cases that describe sequences of gui actions or recording the sequences of gui events as test cases for playback later when testers execute the application under test.
both approaches strongly rely on manual work of professional testers.
on the one hand testers need to design and write quite a number of elaborate gui scripts with their expertise in gui testing.
on the other hand record and playback sequences of gui events often depend on repetitive work that testers need to interact with the application over and over again because only one path is recorded in an execution.
to free testers from the burden of tedious manual work researchers have proposed a few techniques that generate fig.
.
an example of sketching to generate high score gui inputs in the game of angry birds gui test cases automatically .
these techniques generate sequences of gui events essentially by exploring the possible event combinations in applications.
as the number of combinations of gui events is often huge how to reduce the exploring space search space for the automatic testing techniques is an important problem.
in this paper we propose a sketch guided gui test generation approach for testing mobile applications which covers combinations of gui events following a sketch based specification from testers.
testers just draw a few simple strokes on the screenshots as the sketches to specify their testing purposes.
then our approach translates the sketches to a testing model and initiates a model based automatic gui testing.
for example when testers want to explore the gui events effectively in the the game angry birds1 shown in figure they need to generate test cases that shoot a bird at the slingshot every time by dragging it as shown in figure 1a.
with different shooting angles and power they get different scores.
existing techniques are difficult to uncover the high score gui test case in the game which is hidden in a lot of gui event sequences .
c ieeease urbana champaign il usa technical research new ideas38 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
that dragging the bird in different ways.
the manual techniques need tedious labor effort to replay the shooting over and over again with various shooting angles and power while other automatic techniques try to traverse all the gui components in the application other than just dragging the bird in different ways.
our sketch guided approach is good at working on such testing tasks.
testers just simply draw a few strokes as figure 1b which specifies their testing purposes.
in other words they specify a range of gui event sequences that they want our test engine to explore deeply by a simple sketch.
the sketch in figure 1b consists of stroke components with different colors a dragging action in blue a range specifier in purple and an existential quantifier in red.
the dragging stroke makes our test engine focus on the bird shooting gui inputs during the testing and the range specifier specifies the range to which the generated test scripts should drag the bird.
at last testers draw a quantifier to specify the target of the testing which is just to find one gui event sequence that get the score higher than a value in the game.
ii.
s ketch guided approach this section presents the technical details of our sketchguided gui test generation.
testers provide a subject program for testing and draw a few input sketches on the screenshots taken by our testing framework.
our framework processes the sketch with stages and outputs gui test scripts accordingly.
in the first stage the framework recognizes the input sketches to a symbolic layout with attributes ripping from the subject program.
then in the second stage it builds a model from the symbolic layout defined by the input sketches and generates gui test cases by traversing paths in the model.
the rest of this section describes the technical details of every stage separately.
a. sketching language sketch recognition the first stage of our workflow recognizes primitive shapes in the input sketches and generates a symbolic sketch layout that holds the information of shapes and matches the gui widgets to each corresponding shape.
we design an expressive but simple sketching language which defines only types of primitive shapes the action strokes range specifiers quantifiers and boolean connectors.
figure present the primitive shapes in our sketching system.
every action stroke describes a user action in the gui testing such as touching on a button or dragging an icon.
after drawing an action stroke the tester draws immediately a range specifier to delineate a set of gui components that are affected by the action.
quantifiers and boolean connectors further specify the logical conditions and logical relations of the actions with different gui components so we also call them logical shapes.
for example the tester can draw an existential quantifier after a range specifier which means the testing system just needs to find one gui component in the specified range that makes the event sequence satisfy the test oracle.
note that not everything in our framework is represented by the sketch.
specifically testers specify the text input actions t ouch poi nt a touch touch point b long touch start point end point c drag fig.
.
typical types of action strokes in our system a a range specifies buttons in the middle of screen b a range specifies widgets at the bottom of screen fig.
.
examples of range specifiers on screenshots a exists b forall c exists a subsequent action d for all subsequent actions fig.
.
types of quantifiers in our system a boolean and b boolean or c boolean not fig.
.
types of boolean connectors in our system and the test oracle directly through a textbox in our system and links them to the symbolic layout later after other sketches are recognized.
the test oracle is some constraints that should be satisfied when the generated test cases are performed such ascolor x y rgb wherexandy are coordinates of a user specified point.
if the application crashes during testing the test oracle is always unsatisfied.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
figure shows several typical types of action strokes which specify the user actions in the application s gui systems.
for a touchscreen based mobile application the typical actions such as touching long touching a gui widget or dragging a widget to another place are expressed separately as strokes in figure 2a figure 2b and figure 2c.
testers can further extend the system with more gui actions when necessary.
our sketching system not only recognizes the action strokes but also records the coordinates of key points and its corresponding gui widgets specified by the strokes.
for example when a tester draws a drag action on the screenshot our system records the coordinates of its start point and end point along with the information of gui widgets at these points.
our system rips the information of gui widgets from the application under test when we take the screenshots and binds every screenshot with the bound of widgets on it.
when the tester draws an action on a screenshot our system directly obtains the information of widgets from the binding.
the range specifiers shown in figure also use such a technique to collect the widget information in the range.
usually the range specifiers denote a set of gui widgets in the application as figure 3a and figure 3b show.
in some games it also denotes a set of coordinates on the screen when our system does not get any widgets in the range like figure 1b.
for every range specifier we designate a quantifier in our sketching language.
the quantifier specifies the quantity of events in the range that satisfy the oracle which affects the search condition in our test generation.
for example the universal quantifier in figure 4b requires all events in the range to eventually satisfy the condition in the test oracle whereas the existential quantifier in figure 4a drives the test engine to search for just one event that satisfies the condition which is often used in generating a gui event that triggers the bug.
we introduce recursive quantifiers in our sketching language shown in figure 4c and figure 4d.
we call them the recursive existential quantifier and the recursive universal quantifier separately which recursively specify the quantity of all subsequent actions of the current event in the range.
we also introduce the boolean connectors in our sketching language to make it expressive and powerful.
figure presents the boolean connectors in our system which represents boolean and in figure 5a or in figure 5b and not in figure 5c.
the following context free grammar also called bnf backus naur form defines the syntax of our sketching language sketch tracelist tracelist eventtrace divides.alt0tracelist eventtrace eventtrace eventstep divides.alt0eventtrace eventstep divides.alt0eventtrace tracelist eventstep actionset divides.alt0eventstep boolconactionset actionset act divides.alt0act range quant where the act range quant andboolcon in the grammar means an action stroke range specifier quantifier and booleanconnector separately and the punctuation marks in the grammar such as and are gestures or buttons in our sketching system that specify the relations of shapes in the sketch.
the grammar defines the drawing order for testers in producing their sketches.
testers start their sketching by drawing an action stroke to specify an event such as touch on a gui widget.
then they optionally add a range specifier to make the event affect on a set of widgets and a quantifier to present the quantity of events in the range that satisfy the oracle.
at this point testers have specified an actionset with actions on different widgets and they draw boolean connectors to connect multiple actionset s and build an eventstep in their testing.
aneventtrace is either a sequence of eventstep s connected with semicolons in the grammar or a fork from an eventstep in the trace to a list of eventtrace s with a colon at the fork point.
a sketch is finally a tracelist that consists of multiple eventtraces.
b. event flow modeling script generation the second stage of our workflow builds a gui model for test generation from the symbolic sketch layout generated by the previous stage.
the symbolic sketch layout lis defined as a tuple l w o e wherelis a symbolic tracelist organized as the grammar in equation wis a mapping that maps the coordinates in lto the widgets in the application under test andoeis another mapping that maps every eventtrace inl to a test oracle specified by the tester.
the coordinate widget map l.w in the sketch layout l stores the bound of every widget in the application under test.
when our framework queries the coordinates of a point pton a screenshot the map l.w pt analyzes the bound of every widget and returns the widget that the sketch locates the point in.
we translate all coordinates to widgets in our gui model.
so the output test scripts can directly perform actions on the gui widgets which generalizes the testing on devices with different screen resolutions.
our framework models the sketch layout as a partial abstract event flow graph p aefg which is a variation of the event flow graph efg defined by memon et al.
for gui testing .
not as the efg models representing all possible event sequences on a gui our p aefg just partially extracts the abstract event flow that represents possible interactions defined by the sketch.
hence the p aefg is often smaller.
in our paefg a vertex represents an abstract event that summarizes the events may be performed at the same application state.
and an edge in a p aefg from the vertex v1tov2means that an event e2in the abstract event v2may be performed immediately after every event e1in the abstract event of v1 and every sequence ofe1 e2should be tested when it is specified by the sketch.
we formally define a p aefg g as a tuple v e v o where vis a vertex set and each vertex v vis an abstract event specified in the sketch.
an abstract event represents a set of events that may be performed at the same application state.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm abstract ev ent flow modeling input l l w o e output g v e v o for alles eventstep l.l do tv syntaxtree es for allpt pointcoodinate t v do tv tv substitute coordinates to widget end for v es tv hold the vertex for every eventstep g.v g.v tv end for for all es1 es2 substring l.l do g.e g.e v es1 v es2 end for for all et tlist substring l.l et tlist do es1 lasteventstep et es2 firsteventstep et g.e g.e v es1 v es2 end for for allet eventtrace l.l do es firsteventstep et g.v0 g.v0 v es end for g.o oracleparse l v algorithm oracleparse marks every test oracle on the path of the abstract event flow graph input l l w o e v the map holds the vertex for each eventstep output o the map binds every oracle to the path for allet eventtrace l.l do p v firsteventstep et p p p put the path pto the setp p pdo if es1 es2 substring et v es1 lastvertex p then p addvertex p v es catenate a vertex at the end else if et tlist substring et v lasteventstep et lastvertex p then p p p for allet tlist do p addvertex p v firsteventstep et p p p end for end if end for p p o p l.oe et p end for e v vis a directed edge set between vertices.
an edge v1 v2 eiff e1 v1 e2 v2 e1may be performed immediately after e2 and the combination of e1 e2should be tested according to the specification.
v0is a set of start vertices representing the events that are available for the testers when the application starts.
ois a map that binds every test oracle to the path in the graph.
a path pin the p aefg is a sequence of vertices v1 v2 ... vn v v ... v while a test oracle ois a constraint that the application should satisfy when the corresponding sequence of events have been performed.
algorithm parses the sketch layout land builds the paefg model gfor test case generation.
it first generates the vertices of the graph from the sketch layout line .
the functioneventstep at line returns a set of all top level eventstep s that is syntactically not a substring of any other eventstep in the sketch layout.
as every eventstep denotes the events may be performed at the same application state we generate the vertex of our p aefg by substituting the coordinates of points to the corresponding widgets in the syntax tree of an eventstep .
after the substitution every range specifier in the symbolic sketch layout becomes a set of corresponding gui widgets in the abstract event.
line of algorithm links vertices with edges depending on the gestures a semicolon or a colon in the sketch layout.
then it stores all the start vertices in g.v0 line .
finally the algorithm marks every test oracle on the path of the p aefg by callingoracleparse at line and stores it in the map g.o of the p aefg.
algorithm depicts details of the function oracleparse which extracts the oracle constraints from the symbolic layout l.oeand marks them on the path pin the p aefg.
since testers have specified the oracle constraints for every eventtrace during sketching algorithm seeks the set of paths pthat corresponds to the symbolic event trace et line and marks the oracle constraints in the returned map line .
after building the p aefg model g our framework generates test cases directly by traversing the p aefg model.
generally every gui test case corresponds to a path in g which is defined by a sequence of gui events and an oracle constraint in our testing system.
for every path pin the model g our framework picks the first event from the start set g.v0 develops a sequence of gui events by picking the events one by one along the path gets the oracle constraint from g.o p and outputs the test case to a gui test script.
iii.
e valuation we have implemented a prototype of our sketch guided testing system2 and performed our evaluation on android applications collected by choi et al.
which are listed in table i. all the applications are open source projects from f droid app market.
the smallest project is music note with instructions in its bytecode whereas the largest one isanymemo with bytecode instructions.
further details of each project can be referred to .
we recruited volunteers who were 3rd year college students in computer science from our university to evaluate the system.
all of them are familiar with android devices but only of them have taken the software testing class in our university.
we pair every one of them with a student who has authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i cod ecoverage comparison of the sketch guided testing and a few recent automatic gui t esting techniques app line coverage branch coverage monkey androidripper mobiguitar sketch guided swifthand sketch guided music note .
.
.
.
.
.
whohas .
.
.
.
.
.
explorer .
.
.
.
.
.
weight .
.
.
.
.
.
tippy .
.
.
.
.
.
myexpense .
.
.
.
.
.
mininote .
.
.
.
.
.
mileage .
.
.
.
.
.
anymemo .
.
.
.
.
.
sanity .
.
.
.
.
.
average .
.
.
.
.
.
table ii bra nch coverage of the sketch guided testing with different sketching time app min min min min minafter minute extra feedback music note .
.
.
.
.
.
whohas .
.
.
.
.
.
explorer .
.
.
.
.
.
weight .
.
.
.
.
.
tippy .
.
.
.
.
.
myexpense .
.
.
.
.
.
mininote .
.
.
.
.
.
mileage .
.
.
.
.
.
anymemo .
.
.
.
.
.
sanity .
.
.
.
.
.
not taken the software testing class so every test group consists of two volunteers.
with a minute training we ensure that all volunteers work with our testing system correctly.
every test group is assigned only minutes to complete their sketching in the evaluation.
then our testing system generates test cases and performs the testing with a minute time limit on an apple macbook pro with intel core i5 cpu .6ghz and 8gb physical memory.
after that testers have an extra minutes to provide a feedback and fix the sketches which can further be processed with our testing system for minutes.
hence the total time of our sketch guided testing is up to minutes.
we compare the code coverage of our sketch guided testing with minute running of a few recent automatic gui testing tools monkey androidripper mobiguitar and swifthand .
monkey is an automated fuzz testing tool provided by the android development kit which creates random inputs without considering application s state.
androidripper and mobiguitar are two state of theart model based gui testing tools for mobile applications.
swifthand is a recent tool that optimizes the exploration strategy of test generation with a machine learning algorithm.
we perform every tool on the same platform and environment as our sketch guided testing and collect the line coverage with emma3.
because the internal instrumentation of swifthand which is a critical part of swifthand s functionality conflicts withemma as choudhary et al.
mentioned we just compare the branch coverage of our sketch guided approach with swifthand.
table i depicts the results of our comparison.
to reduce the randomness and non deterministic nature introduced by different test groups we present the average results in the table.
from the results our sketch guided approach obtains higher code coverage than the automatic gui testing techniques which means the guidance of the sketches is helpful in gui testing.
the line coverage of our sketch guided approach is .
higher than monkey .
higher than androidripper and .
higher than mobiguitar in average.
and the average branch coverage of our sketch guided approach is higher than swifthand.
our comparison results of monkey androidripper and swifthand are in accordence with the experiments in .
an exception in table i is that the branch coverage of swifthand on explorer is a little higher than the sketchguided testing.
the reason is that explorer only provides simple features of browsing files in the current device and testers cannot specify meaningful guidance other than randomly surfing in the file system.
so the line coverage of monkey which creates random inputs to test the application is similar to our sketch guided testing on explorer .
however swifthand applies a machine learning strategy to the control flow which focuses on the internal structure of the application and achieves higher coverage on explorer .
nonetheless our sketchguided testing achieves higher branch coverage than swifthand on most applications which indicates that testers guidance is still better than machine learning algorithms with current technology.
from the results in table i all the gui testing techniques achieve low coverage on a few applications such as sanity because a large number of modules and features in the application are not activated by gui actions but the environments such as sensors gps etc.
our sketch guided approach does not support the environment testing currently.
such limitation can be overcome by extending our sketching system in future.
we collect the sketches at different scheduled time from testers in our testing and compute the code coverage from the sketches of different sketching time to estimate the necessary manual effort in our sketch guided testing.
table ii presents the branch coverage that our sketch guided testing achieves with different sketching time.
from table ii simple mobile applications only need a very short sketching time just less than minutes to achieve a stable code coverage and all the applications in our evaluation can achieve good coverage in about minute sketching time.
hence the manual effort in our sketch guided testing is acceptable.
iv.
r elated work as smartphones and tablets become very popular today various techniques focus on testing guis of mobile applications such as guiding random testing with different strategies authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
applying static analysis to improve the testing quality combining gui ripping with other testing techniques testing mobile applications with symbolic execution and even the computer vision technique .
some recent research on the record and replay techniques proposes lightweight approaches to reproduce high bandwidth stream of inputs and concurrency events .
choi et al.
present the tool swifthand which generates test scripts for mobile applications with a machine learning algorithm.
a few empirical studies compare different testing tools publicly available .
all these techniques do not provide the sketch guided interface as ours which conveniently helps testers to specify their testing purposes.
memon et al.
provide a survey on model based testing techniques for gui based applications and define a gui model called event flow graph efg .
the efg model has later been improved by the observe model exercise paradigm and a few regression testing techniques .
nguyen et al.
integrate these techniques in guitar a tool for testing guis of pc applications.
and two branches of the tool androidripper and mobiguitar are further developed for testing mobile applications with different model traversing strategy.
different from these model based approaches our sketch guided gui testing provides a natural interface for testers to specify their testing purposes.
the sketches both guide the model generation and the model traversing stages and effectively improve the test coverage.
v. c onclusion and future work we present a sketch guided gui test generation approach for testing mobile applications.
testers just need to draw a few simple strokes on the screenshots following the syntax of the sketching language we defined in our system.
then our approach translates the strokes to the partial abstract eventflow graph p aefg and initiates a model based automatic gui testing.
we evaluate our sketch guided approach on a few real world android applications collected from the literature.
the results show that our approach can achieve higher coverage than existing automatic gui testing techniques with just 10minute sketching for an application.
in the future we will extend our approach to support in testing the environment of mobile applications which guides the application in different device environments and uncovers more bugs consequentially.