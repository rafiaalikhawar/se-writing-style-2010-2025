finding and understanding bugs in software model checkers chengyu zhang dale.chengyu.zhang gmail.com east china normal university chinating su tingsu inf.ethz.ch eth zurich switzerlandyichen yan sei yichen outlook.com east china normal university china fuyuan zhang fuyuan mpi sws.org mpi sws germanygeguang pu ggpu sei.ecnu.edu.cn east china normal university chinazhendong su zhendong.su inf.ethz.ch eth zurich switzerland abstract software model checking smc is a well known automatic program verification technique and frequently adopted for checking safety critical software.
thus the reliability of smc tools themselves i.e.
software model checkers is critical.
however little work exists on validating software model checkers an important problem that this paper tackles by introducing a practical automated fuzzing technique .
for its simplicity and generality we focus on control flow reachability e.g.
whether or how many times a branch is reached and address two specific challenges for effective fuzzing oracle and scalability .
given a deterministic program we leverage its concrete executions to synthesize valid branch reachability properties thus solving the oracle problem and fuse such individual properties into a single safety property thus improving the scalability of fuzzing and reducing manual inspection .
we have realized our approach as the mcfuzz tool and applied it to extensively test three state of the art c software model checkers cpachecker cbmc and seahorn.
mcfuzz has found unique bugs in all three model checkers have been confirmed and have been fixed.
we have further analyzed and categorized these bugs which are diverse and summarized several lessons for building reliable and robust model checkers.
our testing effort has been well appreciated by the model checker developers and also led to improved tool usability and documentation.
ccs concepts software and its engineering model checking software reliability software testing and debugging .
keywords software testing software model checking fuzz testing acm reference format chengyu zhang ting su yichen yan fuyuan zhang geguang pu and zhendong su.
.
finding and understanding bugs in software model checkers.
co first and corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn .
.
.
.
of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
introduction software model checking smc is a well known verification technique that statically proves program correctness w.r.t.
properties or specifications of interest .
specifically given a program pand a safety property the primary goal of smc is to prove that the property holds on all executions of p. it returns safeif every execution of psatisfies orunsafe otherwise.
in practice this goal is formulated as reachability checking of a particular error location einpbecause any safety property e.g.
expressed in a temporal logic reduces to checking the reachability of e pis safe w.r.t.
if the error location eis unreachable otherwise pis unsafe and a counterexample i.e.
an execution that reaches e is given.
significant recent advances have made smc a practical automated approach for verifying real world software.
for example it was successfully applied in verifying os device drivers and generating test cases for bug detection .
these successes have further driven active research e.g.
the annual sv comp competition and industrial adoption .
however like all software smc implementations i.e.
software model checkers also have bugs and may give wrong verification results even for simple programs.
the bugs in software model checkers can lead to missed program errors which may be disastrous for safety critical software e.g.
aerospace airborne and railway signal systems .
however no prior work exists that systematically validates the correctness of software model checkers themselves.
the goal of this paper is to fill this important gap.
to this end we develop an effective fuzzing technique that can automatically generate a large number of verification tasks i.e.
a program pand a valid property forp to test software model checkers.
we stress automatically as creating manual tests is laborintensive and error prone.
for example the de facto sv comp benchmarks were manually created by injecting artificial bugs or collecting real world bugs cf.
section .
the prominent challenge is the oracle problem .
to tackle it in our problem setting we focus on control flow reachability and specifically branch reachability.
in particular given a valid deterministic and terminating program p our key idea is to leverage information on p s concrete executions to synthesize a valid branch reachability property for p and couple it with pto generate a verification task.
more specifically for a particular branch binp given an input i we monitor the control flow information of b e.g.
whether bis reached or howesec fse august tallinn estonia chengyu zhang ting su yichen yan fuyuan zhang geguang pu and zhendong su many times it is reached .
this information is used to synthesize aguaranteedly valid safety property forp.
if a model checker concludes that the oracle does not hold for p the model checker has an actual bug.
the above approach allows us to test model checkers as blackboxes despite many state of the art software model checkers e.g.
cpachecker seahorn cbmc combine different techniques e.g.
cegar ic3 bmc .
in particular we realize our approach as two distinct propertysynthesizing strategies for each individual branch i.e.
enumerative reachability er and enumerative counting reachability ecr .
however these approach instances face scalability issues because a seed program pcan have a large number of branches and the model checkers can spend much time checking each test program.
to tackle this scalability issue we develop an optimized strategy fused counting reachability fcr by validating all branch properties at once to improve fuzzing performance.
section details our approach and the three testing strategies.
we implemented our approach for validating c software model checkers in a tool called mcfuzz model checker fuzzer and applied it to test three state of the art model checkers cpachecker seahorn and cbmc .
for evaluation we selected seed programs from the gcc regression test suite from which we systematically generated test programs.
finally we found unique bugs bugs have been confirmed and have already been fixed.
our bug reports and testing effort have been very well received by the developers.
we have also carefully analyzed these bugs and the developer comments and found that the bugs are diverse and reside in different modules of the model checkers including front end memory model pointer alias analysis thirdparty components etc.
our work has also led to improvements in the usability e.g.
better warning messages and documentation of these model checkers.
this paper makes the following main contributions it proposes a fully automated branch reachability fuzzing approach to validating software model checkers.
to our knowledge this is the first systematic and extensive effort to automatically validate the correctness of software model checkers.
it realizes the approach as a tool mcfuzz with three propertysynthesizing strategies which can effectively and efficiently validate c software model checkers.
mcfuzz is general and flexible to test any software model checker and will be made publicly available to benefit the community once our paper is deanonymized.
we have already made our detailed bug reports available from an anonymized github repository .
it reports our experience in applying mcfuzz to test three stateof the art model checkers cpachecker seahorn and cbmc and found unique bugs were confirmed and already fixed.
we analyzed the characteristics of these bugs and summarized several lessons for building reliable and robust model checkers.
the rest of the paper is organized as follows.
section motivates and illustrates our approach via two examples and section formulates the problem and presents our approach and implementation details.
next section reports the evaluation of mcfuzz and discusses some representative bugs that we found.
finally we survey related work section and conclude section .
illustrative examples this section presents two examples to motivate the problem and illustrate our approach.
both examples are real bugs that we found in cpachecker a state of the art cegar based model checker.
.
cpachecker bug figure 1b shows the test program that manifests an incorrect checking result of cpachecker.
it is generated from the seed program in figure 1a by inserting the error label verifier error before line .
here the error label verifier error can be interpreted as an error location under checking which enforces cpachecker to do reachability querying.
obviously by concretely executing the program in figure 1b the error label should be reached since iis assigned to on line thus after the first loop iteration.
however cpachecker concludes the program as safe which means the error label is unreachable.
this incorrect result is caused by an intricate bug in the predicate analysis component which is the core component of such cegar based model checkers as cpachecker.
the reason is the following firstly cpachecker detects a spurious counterexample in the first loop iteration.
then the refinement procedure produces the predicate i which rules out the counterexample.
the analysis continues and encounters the last statement line of the loop body.
it notices that the address of iis taken.
the predicate analysis thus switches from tracking idirectly to tracking iindirectly via its address as if it were on the heap .
when the analysis encounters the loop head again after the first loop iteration the counterexample trace formula is something like !
i i !
p with pbeing the formula that indirectly increments the value of i. unfortunately when applying the predicate i the variable igets matched with the old value i from the beginning of the first loop iteration which is outdated and its value is always equal to .
this leads to the wrong proof since the trace formula is always unsatisfiable .
the cpachecker developers confess this bug is very difficult to fix and they are still working on it at the time of submission.
approach i enumerative reachability .
as the above example shown the test program in figure 1b is created by inserting an error label at a particular program branch line .
thus our basic approach is designed to enumeratively checking the reachability of each program branch2 which we called enumerative reachability .
for example figure illustrates this approach.
figure 1a is the seed program.
figure 1b 1c and 1d are the three test programs created from figure by inserting the error labels at the three branches respectively.
by running the executables of these test programs we can get the test oracles i.e.
whether the error labels are reachable .
then we run model checkers to do reachability checking on each test program.
if the checking result is different from the oracle a bug may exist.
this approach is effective but has two limitations.
querying the reachability of an error label only checks whether the target branch is reachable or not but cannot check how many times the branch can be reached.
thus it may miss those intricate bugs related to the computations of loops.
1the clause !
i denotes the previous state before the loop against the predicate i in the first loop iteration.
i 2denotes the value of iduring the second iteration of cegar analysis.
2note that checking the reachability of each branch is semantically equal to checking each program location.finding and understanding bugs in software model checkers esec fse august tallinn estonia 1void main int i while if i break if i i i a seed program1void main int i while if i verifier error break if i i i b test program which leads to the bug in cpachecker.1void main int i while verifier error if i break if i i i c test program .1void main int i while if i break if i verifier error i i d test program .
figure illustrative example for the bug of cpachecker.
1int main void int a int i while i if a i continue i return a seed program1int main void int a int i int br while i if a br i continue i if br !
verifier error return b test program which leads to the bug in cpachecker.1int main void int a int i int br while i br if a i continue i if br !
verifier error return c test program .1int main void int a int i int br1 int br2 while i br1 if a br2 i continue i if br1!
br2!
verifier error return d test program generated by approach iii.
figure illustrative example for the bug of cpachecker.
the number of test programs could be large if the given set of seed programs have many branches.
it may bring high overhead and reduce the testing performance.
section .
will use the example in figure to illustrate how we tackle these limitations.
.
cpachecker bug approach ii enumerative counting reachability .
to solve the first limitation we evolve the basic approach by synthesizing a safety property of the number of times a branch should be reached.
figure 2a 2b and 2c illustrate this enumerative counting reachability approach.
given the seed program in figure 2a it introduces a counter variable brand initializes it to .
it then inserts the counting instruction br at each branch to create the two test programs in figure 2b and 2c.
by running the executables of these test programs we can get the exact value of brfor each test program.
we then insert a reachability query in the form of value equivalent checking e.g.
the code of lines in figure 2b and 2c before the program exit.
specifically it checks whether bris equal to the exact value obtained in the concrete executions.
if the check fails the error label verifier error is reachable.
obviously the two test programsshould always be safe.
if a model checker answers unsafe i.e.
the error label is reachable a bug may exist.
we can see approach ii is stronger than approach i since approach ii not only checks the reachability of each branch but also checks the number of times that each branch should be reached.
figure 2b shows an intricate bug in cpachecker bug that can only be manifested by approach ii .
the bug is introduced because cpachecker fails to correctly handle the array initializer with a single element.
according to the c standard if there are fewer initializers in a brace enclosed list than the elements of an aggregate the remainder of the aggregate shall be initialized implicitly the same as objects that have static storage duration.
for example the object with an arithmetic type will be initialized to positive or unsigned zero.
in figure 2b the array ashould be initialized to and has only one element the value of brshould be .
the error label verifier error should be unreachable.
however cpachecker incorrectly initializes the array a to .
as a result cpachecker answers unsafe which means the error label is reachable.
in fact we find this bug is a regression error caused by the fix of another bug .
approach i will miss this bug since cpachecker returns correct checking results when reachability querying of each branch while approach ii canesec fse august tallinn estonia chengyu zhang ting su yichen yan fuyuan zhang geguang pu and zhendong su find such deeper bugs by countering the number of times that each branch is reached.
approach iii fused counting reachability .approach ii is more effective than approach i but may still generate a large number of test programs.
to solve the second limitation we evolved approach ii to the fused counting reachability approach.
figure 2d illustrates this approach which is as effective as approach ii but only generates one test program.
specifically this approach introduces the counting variables br1 br2 .
.
.
brnfor each branch and inserts the corresponding loop counting instructions brk k ...n at each branch.
it then checks the equivalence between these counting variables and their actual values altogether before the program exit e.g.
the codes of lines .
obviously the test program generated byapproach iii should be always safe if a model checker answers unsafe a bug may exist.
approach iii effectively reduces the testing time from o n too by creating the disjunction checking for all of the counting variables.
section will give the formal definition of these approaches and discuss their effectiveness.
approach and implementation this section gives the details of our approach and implementation.
in particular section .
gives the problem definition and our high level approach section .
shows the three instances of our approach to effectively validating software model checkers and section .
details the implementation.
.
definition and high level approach definition .
test program .a valid test program for a software model checker mis a source program pwith a safety property .
given a test program a software model checker mverifies whether the safety property is satisfied on p. specifically this safety verification problem is formulated to a check for the reachability of a particular error location einp.
here the reachability of erepresents the safety property .
ifeis unreachable mconcludes thatpissafe i.e.
holds on all computations of p .
otherwise p isunsafe i.e.
is violated by one computation ending at e .
problem definition .
our problem is to generate a set of valid test programs to validate the correctness of a model checker m. given a test program if the answer of mis contradictory to the ground truth a potential bug is reported.
the key challenge of this problem is how to generate valid test programs with known oracles i.e.
the ground truth of the safety forpw.r.t.
.
to resolve this problem we propose the approach of branch reachability fuzzing that can automatically generate safe or unsafe test programs.
assume that we are given a seed program pseed.
we insert to pseed counter variables to monitor branches of pseed.
for an arbitrary branch in pseed we are interested in whether the branch is reachable and how many times the branch can be reached.
the values of counter variables are updated accordingly whenever the corresponding branches are executed.
we construct safety properties based on the final values of counter variables derived through dynamic execution .
in the rest of the paper we assume that seed programs are valid terminating and deterministic.
we formalizeour way of generating test programs for software model checkers in the following definition.
definition .
branch reachability fuzzing .letpseed be a seed program and pbe derived by inserting counter variables c1 ... cn tondifferent branches of pseed.
assume that we execute pwith a valid input and that ci vi i n on the final state of p i.e when pterminates.
the test program we construct is ptogether with a safety property c1 v1 ... cn vn which is meant to be satisfied on the final state of p. in practice for a test program pand we can construct a corresponding program p with an error location esuch that whether psatisfies is reduced to whether eis reachable in p .
in the following we also refer to the programs with an error location as test programs for software model checkers.
our high level approach .
to validate software model checkers we apply definition .
to generate a large number of test programs with known oracles.
if the conclusion of a model checker is inconsistent with the known oracle a bug will be reported.
in this way our approach can stress test model checkers as black box.
note that since the reachability problem is in general undecidable a model checker may give unknown i.e.
the model checker cannot terminate within a given time bound .
in this case we cannot conclude any oracle violation.
.
approach instances we introduce in this section three specific approach instances to construct test programs with known oracles.
we first introduce approach i which is a simplified application of definition .
.
the safety properties involved there specify the reachabilities of branches in the seed programs.
approach i enumerative reachability er .
let pseed be a seed program.
for each branch binpseed we construct a test program pbby adding an error label eto branch bofpseed.
the oracle of the test program in approach i can be derived as follows.
imagine that we construct an intermediate program pby initializing a boolean variable cto0at the beginning of pseed and then inserting the instruction c 1to branch bofpseed.
assume thatvis the value of cwhen pterminates.
it is easy to see that branch bis reachable resp.
unreachable in pseed iffv resp.
v .
therefore we have that pbis safe iffv .
example .
for the seed program in figure 1a approach i generates three test programs in figure 1b figure 1c and figure 1d.
all of these programs are unsafe since the error labels are reachable in the concrete executions.
approach ii further considers safety properties that constrain the number of times a branch can be executed.
for each branch in a seed program we insert a counter variable and increment its value by1in each execution of the branch.
approach ii enumerative counting reachability ecr let pseed be a seed program.
for each branch binpseed we first construct a program pby initializing a counter variable cto0at the beginning of pseed and then inserting instruction c c 1to branch bofpseed.
let c vbe a safety property where v is the value of cwhen pterminates.
we construct a test program pb p if e and we have that pbis safe.finding and understanding bugs in software model checkers esec fse august tallinn estonia software model checker instrument checking resultsprofile comparebug reports seed programstest programsintermediate program s oracles mutate 4validate figure workflow of our testing framework mcfuzz .
example .
for the seed program in figure 2a approach ii generates two test programs in figure 2b and figure 2c where bris the counter variable.
all of these two programs are safe.
for a seed program with nbranches both approach i and ii construct ntest programs each of which monitors a different branch in the seed program.
to optimize the test cost we propose approach iii that reduces testing time from o n too .
approach iii fused counting reachability fcr .
let pseed be a seed program.
assume that b1 ... bnare all the branches inpseed.
we construct a program pby initializing counter variables c1 ... cnto0at the beginning of pseed and then inserting instruction ci ci i n into branch biofpseed.
let c1 v1 ... cn vnbe a safety property where vi i n is the value of ciwhen pterminates.
we construct a test program pall p if e and we have that pallis safe.
example .
for the seed program in figure 2a approach iii generates the test program in figure 2d where br1andbr2are the two counter variables.
obviously this test program subsume the two test programs in figure 2b and figure 2c.
since the test program generated in approach iii subsumes all test programs that approach ii generates approach iii can be viewed as an optimization of approach ii.
approach iii is the most efficient and scalable one among the three approach instances without sacrificing effectiveness.
the evaluation of these three approach instances will be given in section .
in the next subsection we will introduce the workflow of our tool mcfuzz and its implementation with approach iii.
.
implementation figure gives the overview of our testing framework mcfuzz .
given a set of seed programs mcfuzz instruments the seed programs and transforms them to intermediate programs.
by profiling the execution of these intermediate programs mcfuzz generates the test programs with the corresponding oracle.
given a test program if the checking result and the oracle is inconsistent a bug is reported for further inspection.
the three approach instances presented in section .
can be easily adapted to this framework.
algorithm details our implementation by using approach iii.
it takes as input a model checker mand a closed program p and then follows the following four steps.
step instrument .
in the function instrument mcfuzz instruments probes i.e.
counter variables into the program p. specifically the declarations of counter variables are inserted at the beginning of p and the counting instructions are inserted at each branch.algorithm fused counting reachability procedure test software model checker m program p p c instrument p c v profile p c dp mutate p c v ifm.check dp unsafe then reportbug function instrument program p p p i b p .branches c foreach b bdo p p .firstloc .insert ci p p .getbr b .firstloc .insert ci ci c c ci i i return p c function profile program p counters c e p.execute pair c v e.getfinalvalue c return c v function mutate program p pair c v o true foreach c v c v do o o c v dp p.lastloc .insert o e return dp at last an intermediate program p is created and ccontains all inserted counter variables.
step profile .
in the function profile mcfuzz compiles p by using an off the shelf compiler e.g.
gcc and executes p .
the final values of counter variables in c when p terminates are recorded in v. step mutate .
in the function mutate mcfuzz exploits the execution results from the profiling step to generate a safety property.
this property is represented as a reachability query o e and inserted before the program exit.
at last it generates the test program dpfrom p with the oracle safe.
step validate .mcfuzz runsdpto get the verification result.
if the result is inconsistent with the provided oracle i.e.
unsafe for approach iii a bug is reported.
in our actual implementation algorithm is realized using python scripts and c .
in particular we use llvm s libtooling library to instrument and mutate the seed program and generate test programs.
gcc is used to compile the intermediate programs for concrete execution.
mcfuzz has approximately lines of python scripts and lines of c code.esec fse august tallinn estonia chengyu zhang ting su yichen yan fuyuan zhang geguang pu and zhendong su empirical evaluation in this section we applied mcfuzz on three state of the art software model checkers i.e.
cpachecker cbmc seahorn to demonstrate its effectiveness.
we finally found unique bugs with diverse types.
our testing effort has been well appreciated by the model checker developers also leads to improved tool usability and documentation.
all the detailed bug reports submitted by us to the developers can be accessed at .
.
evaluation setup testing environment .mcfuzz and the three model checkers all run on a workstation with the following configurations ubuntu .
intel i7 7800x .5ghz core cpu and 32gb memory.
software model checkers .
we selected the three model checkers i.e.
cpachecker cbmc and seahorn as the testing subjects.
we chose them based on the following considerations.
first they implemented different smc techniques including cegar bmc and ic3.
second they all support c programs which makes the tool comparison and result analysis more fair and convenient.
third they are mature and widely used in both industry and academia.
validating their correctness is of importance.
cpachecker is a state of art cegar based model checker proposed by beyer et al.
.
it is the champion in sv comp and performs the best in the reachsafety track .
besides cegar cpachecker also supports other smc techniques e.g.
kinduction .
in the evaluation we use the default predicate abstraction configuration predicateanalysis.properties with skiprecursion .
the cpachecker version is svn .
cbmc is a state of art bmc based software model checker proposed by clarke et al.
.
it won the silver medal in sv comp falsification overall track .
cbmc is an under approximation model checker with bit precision.
if the given checking bound is not large enough it is allowed to answer safeforunsafe programs.
thus we only generate safeprograms in the evaluation for approach ii and iii.
we used the default cbmc configuration without specifying any checking bounds.
the cbmc version is .
.
seahorn is a state of art llvm based model checker .
it employs several ic3 based model checking engines.
it also supports abstract interpretation and bmc.
in the evaluation we use the default configuration pf which uses the ic3 engine spacer .
the seahorn version is 21a1c0 .
although the outputs of these tools can be different we consistently record safeif the tool concludes the error label is unreachable or unsafe if reachable.
for each model checker we set the time bound of each checking as minutes.
if the tool timeouts we record the conclusion as unknown .
seed programs .
in theory the seed program can be any program that can be handled by software model checkers.
in the evaluation we selected seed programs from the gcc regression test suite which is a set of programs for testing gcc.
most of them are closed program which can be directly handled by model checkers.
specifically we only selected the programs that can be independently compiled with a single file since most model checkers cannot handle programs with multiple files.
we selected out of gcc regression test cases as seed programs which contains lines of code.table bugs overview.
cpachecker cbmc seahorn total fixed confirmed unconfirmed total .
results this section presents our results and anlysis via the following three research questions rq1 rq3.
rq1 can mcfuzz find model checker bugs?
the answer is yes.mcfuzz discovered unique bugs in the three software model checkers of which were confirmed.
in particular we found bugs in cpachecker bugs in cbmc and bugs in seahorn respectively.
since the semantics of undefined behaviors are not defined in c standard the undefined behaviors in general allow a model checker to output any result.
thus we did not report any undefined behaviors related issues as bugs.
table gives an overview of the bugs we found by using mcfuzz .
the numbers in table represent the bugs that have been fixed confirmed but not fixed or unconfirmed in each software model checker respectively.
fixed means developers have confirmed the bugs and fixed them by committing to the up to date version.
confirmed means developers have confirmed and explained the reason but have not fixed yet.
unconfirmed means we have confirmed the bugs and reported to the developers but they have not replied yet.
we used both manual inspection and automated filtering via scripts to facilitate bug reporting from the generated incorrect test programs.
for automated script filtering we used compcert s c interpreter to automatically remove invalid bugs caused by undefined behaviors ubs .
through reporting and discussing bugs with the smc developers we gained more domain knowledge which helped further automatically remove duplicate cases e.g.
we used the keywords float and double to remove duplicate cases for seahorn as it does not support floating point types .
we then manually inspected the remaining cases.
in total it took us about person weeks for bug reporting.
we tried our best to report high quality bugs and not to burden the developers unnecessarily.
in summary mcfuzz can indeed find many bugs in all three stateof the art software model checkers.
specifically mcfuzz discovered unique bugs of which were confirmed.
rq2 which fuzzing approach instance is more effective and efficient?
as we proposed the three fuzzing approach instances in section .
we intend to evaluate which approach instance is more effective i.e.
find more bugs and efficient i.e.
cost lower testing time .
we evaluated these three approaches respectively by running mcfuzz on the three model checkers.
table shows the statistics of the evaluation.
column mutants means the number of test programs generated by the corresponding approach instance from the selected gcc test suite.
column incorrect cases means the number of test programs which lead to inconsistent checking results.
in particular for approach ii and iii the oracles of test programs generated by mcfuzz aresafe so all unsafe results given by model checkers are incorrect cases for approach i the oracle can be safeorunsafe so any inconsistent results are incorrect cases.
note that each incorrect case in table may not indicate a valid bug finding and understanding bugs in software model checkers esec fse august tallinn estonia table statistics of the three approach instances in terms of the generated test programs mutants incorrect cases average checking time of one test program in seconds and the total fuzzing time in hours .
the time is measured in cpu time.
approach instance mutants incorrect cases average time s total time h cpachecker cbmc seahorn cpachecker cbmc seahorn cpachecker cbmc seahorn approach i er .
.
.
.
.
.
approach ii ecr .
.
.
.
.
.
approach iii fcr .
.
.
.
.
.
51ecr fcr er figure relation of the bugs found by the three fuzzing approach instances since the case could be duplicated caused by undefined behaviors or invalid for software model checkers e.g.
macro third party library .
column average time means the average checking time of a model checker for one test program.
column total time means the total fuzzing time of an approach instance.
from table we can see approach iii generated the least number of test programs i.e.
tests while approach i and ii generated the same number of test programs i.e.
tests respectively.
approach iii reduced over of test programs.
from the total testing time approach iii saved hundreds of hours compared with approach i and ii.
in particular approach iii reduced more than of fuzzing time in total.
this huge performance improvement is enabled by fusing all the reachability checkings into one test program.
additionally although approach i and ii generated the same number of test programs approach ii can find more incorrect cases.
it indicates approach ii is stronger than approach i i.e.
approach ii may find more bugs.
the venn diagram in figure shows the relation of the bugs found by three approach instances.
we can see approach i found bugs in total while approach ii and iii found the same number of bugs i.e.
bugs.
approach ii and iii can find all the bugs found by approach i except one bug which is shown in figure 1b.
the reason is that cpachecker reports safewhen this bug was triggered.
this cannot be detected by approach ii and iii as they use safeas the oracle.
on the other hand there are bugs that can only be found by approach ii and iii but cannot be found by approach i. figure is one sample bug of these ten bugs.
in summary approach iii is the most effective and efficient fuzzing approach instance.
it fuses oracles to achieve testing scalability without sacrificing effectiveness.
rq3 what types of bugs can be found by mcfuzz ?in total we found unique bugs in the three software model checkers.
to understand these bugs found by mcfuzz we categorized them into seven categories according to the module in which the bug resides front end related memory model related pointer alias related third party component related c standard library related language feature related and configuration related bugs.
front end related bugs are usually caused when incorrectly compiling or optimizating the program source code.
incomplete memory modeling usually cpachecker cbmc seahornfigure numbers of the bugs found by mcfuzz across different categories.
causes memory model related bugs.
incorrect pointer alias analysis may lead to pointer alias related bugs.
the bugs in third party components of software model checkers cause third party component related bugs.
the incomplete supporting for c standard library functions and language features causes c standard library and language feature related bugs respectively.
configuration related bugs are the bugs that can be solved by switching the configurations of software model checker via the command line options.
figure shows the number of bugs in each category.
most bugs of cpachecker found by us are related to pointer alias analysis and language features while most bugs of seahorn are related to the unexpected behaviors of the front end and tool configurations.
as for cbmc we found a few front end and memory model related bugs but most bugs are related to standard library functions and language features.
in the next subsection we will explain and discuss more details about each bug category and give assorted bug samples for each bug category.
in summary the bugs found by mcfuzz in software model checkers are diverse and categorized into seven groups of which front end pointer alias and language features related bugs are common.
.
assorted bug samples figure gives eight bug samples to illustrate each bug category we found.
all of the samples are reduced from more complicated test programs and all these error labels verifier error should be unreachable i.e.
all these test programs are safe.
front end related bugs .
in software model checkers the frontend component is used to transform and optimize the program source code to an intermediate representation for model checking.esec fse august tallinn estonia chengyu zhang ting su yichen yan fuyuan zhang geguang pu and zhendong su 1void f int a int b if a !
b verifier error 5int main int c d int e f d c e return a the program triggers front end related bug in cpachecker.1int main int array for int i i i array if array !
verifier error return b the program triggers front end related bug in seahorn.1union int a int b u 2int main u.a u.b if u.a !
verifier error return c the program triggers memory model related bug in cpachecker.1typedef int t 2struct f int w t x 3static struct f f 5int main for int i i f.w i if f.x !
i verifier error return d the program triggers memory model related bug in cbmc.
1int x p x 2int main int i x p if x !
verifier error return e the program triggers pointer alias related bug in cpachecker.1typedef bool bool 2const bool false 4int main bool a if a !
false verifier error return f the program triggers third party component related bug in cpachecker.1struct 2int a int 3int b int c x 5int main if x.b !
verifier error return g the program triggers language feature related bug in cbmc.1void test int x int y int q if x y !
q verifier error 6int main test test return h the program triggers configuration related bug in seahorn.
figure assorted samples that trigger software model checker bugs.
for example in seahorn the front end clang transforms and optimizes the c language code into llvm ir bitcode before model checking .
in cpachecker the front end cdt constructs the control flow automata cfa which consist of control flow locations and edges.
the cegar algorithm later runs on cfa.
incorrect transformations or optimizations could lead to incorrect checking results.
figure 6a is a program which triggers a front end bug in cpachecker.
cpachecker answers unsafe because the front end creates a temporary variable cpachecker tmp 0 for the c e expression but d cpachecker tmp 0 is added to the cfa before the value of the temporary variable is computed.
this bug is due to the incorrect transformation.
figure 6b is a program that triggers a font end bug in seahorn.
the loop lines is silently optimized into a memset a standard library function which however is not supported in seahorn and leads to the unsafe conclusion.
this bug is due to the incorrect optimization.
these front end bugs affects the first step of smc.
the model checker developers should be careful when choosing the front end implementations and pay more attention to the reliability and the unexpected behavior.
memory model related bugs .
the memory model is a key component that simulates the memory operations when model checking.
it would be error prone when some memory operations involve complex data structures e.g.union s and struct s. figure 6c is the program which triggers the union related bug in cpachecker.
in figure 6c u.ashould be assigned to at line since the variables a andbshare the same memory location in the union u .
cpachecker should always treat the union as heap memory.
unfortunately it fails on this case and answers unsafe unless the union address isexplicitly taken in the program.
similarly cbmc does not initialize the nested struct correctly in the case of figure 6d and thus answers unsafe .
such memory model bugs usually involve complex data structures or corner cases that were easily ignored.
pointer alias related bugs .
the pointer alias analysis is a challenging problem in program analysis area and also difficult for smc.
to precisely check programs software model checkers analyze pointer aliases in the front end or during the checking process.
for example seahorn analyzes pointer aliases by transforming the source code into the static single assignment ssa form of llvm irs.
cpachecker analyzes pointer aliases while predicate analysis.
figure 6e is the program that triggers a pointer alias related bug in cpachecker.
cpachecker has an optimization in the predicate analysis component which reduces a program by ignoring the irrelevant variables w.r.t.
the property under check.
the problem here is that the predicate analysis does not detect that the address of xis taken and thus regards xas a primitive variable instead of a potentially aliased variable.
as a result it ignores the assignment of xvia the pointer alias pat line .
thus to avoid the pointer alias related bugs it is important to implement the pointer alias analysis algorithm correctly.
third party component related bugs .
in practice software model checkers usually integrate a few third party components.
for example cpachecker integrates cdt as the front end and smtinterpol as the smt solver while seahorn integrates the llvm framework into its implementation.
however the third party components are not always reliable.
figure 6f is the program that crashes cpachecker due to an issue of using smtinterpol.
in thefinding and understanding bugs in software model checkers esec fse august tallinn estonia program a variable named false is defined which is a reserved token in smtinterpol.
in fact the variables false true orselect are all reserved tokens in smtinterpol.
using any of them will crash smtinterpol and then fail cpachecker.
it is usually hard for developers to note such issues when using third party components.
additionally the bugs of third party components themselves can also affect the correctness of model checkers.
thus ensuring the reliability of these components e.g.
compilers solvers is important for building a more reliable software model checker.
c standard library related bugs .
in c there are many standard library functions.
for example malloc allocates a block of memory memset s c n replaces each of the first ncharacters of sbycand returns s and isdigit c returns nonzero if cis a numeric digit.
however we find such standard library functions are not well supported in most software model checkers.
seahorn and cpachecker do not support most of the standard library functions and usually give incorrect checking results silently without any warning.
it lets user erroneously believe that the checking results are correct.
as for cbmc it supports quite a number of standard library functions by implementing the corresponding built in functions.
but the built in functions are not always reliable.
for example cbmc sometimes falls into infinite unwindings while there are some string related c standard library functions e.g.strlen in the program .
it may be infeasible for model checkers to support all functions in the standard library.
but model checkers should give clear warning messages if some unsupported functions exist in the program or conservatively answer unknown .
language feature related bugs .
there are many language features defined in c standard.
in principle model checkers for c program should support all of the language features in c standard to correctly comprehend the semantics of program.
in practice it is difficult for software model checker developers to completely follow the c standard.
for example figure 6g is the program that leads to an incorrect checking result of cbmc.
in this program there is an unnamed member in the struct x .
the c standard says unnamed members of objects of structure and union type do not participate in initialization and unnamed members of structure objects have indeterminate value even after initialization .
thus the variables a b and cshould be assigned as respectively.
but cbmc does not follow these rules and the member bis not correctly assigned as .
the bug in figure 2b is also a language feature related bug.
although it may not be possible to follow every rule in c standard software model checkers should clearly explain which rules are supported and define the boundary of their abilities.
configuration related bugs .
software model checkers usually have many configuration options.
for example cbmc has the options to set the loop unwinding bounds and cpachecker has the options to setup the specification file smt solver and model checking mode e.g.
k inductive bmc .
figure 6h shows the program which triggers a bug in seahorn but can be solved by changing the configuration.
seahorn incorrectly gives the unsafe result on this program.
this bug appears when using both the ic3 and bmc engines of seahorn.
the developers comment that seahorn can give the expected saferesult with the inline configuration.
besides this bug seahorn gives different answers in many other cases when switching between the pfandbpfconfigurations.
while pfis the default configuration in seahorn which unrolls the loop dynamically bpfmeans unrolling the loop statically.
in many cases seahorn gives incorrect answers when using pf because pfunrolls the loop incorrectly.
using bpfcan avoid these issues.
however without clear documentations it is hard for users to figure out which configurations should be used to get the correct results.
.
discussions sv comp benchmarks undefined behaviors .
we also selected the seed programs from sv comp benchmarks which are the de facto benchmarks for software verification competition.
these benchmarks consist of six categories of programs with different features.
we selected the programs from two categories i.e.
reachsafety andsoftwaresystems as the seed programs since these categories focus on reachability checking.
to adapt the benchmark programs for our purposes we removed the original error labels and replaced the symbolic inputs e.g.
specified by verifier nondet int in each program with the randomly generated concrete values for the variables of different types.
in particular we generated groups of random inputs for each program.
at last we selected seed programs and generated test programs and used approach iii to test the three model checkers.
we finally found unique bugs seahorn bugs and cpachecker bugs .
among these bugs bug in seahorn and bug in cpachecker are duplicate with the bugs we found by the gcc regression test suite and the rest are new bugs.
figure 7a shows a new bug found by a sv comp program in seahorn.
the variables st1andst2 are less than so that st1 st2 should be less than .
then br1 should be 1andbr2should be the error label should be unreachable.
however seahorn answers unsafe to this case which means the error label should be reachable.
the seahorn developers have confirmed this bug and fixed in the newest version.
compared with the gcc test suite the sv comp benchmarks only found a few bugs.
then we carefully inspected the test programs and found this can be explained by three main reasons.
first the software model checkers have been thoroughly tested by these benchmark programs when participating in the competition.
if some bugs were found they have already been fixed.
second most of the inconsistent cases reported by using sv comp benchmarks are related to undefined behaviors e.g.
uninitialized arrays and local variables visiting the memory out of bound and some unsupported features e.g.
floating point variables and recursions .
figure 7b shows a case reduced from a sv comp program with undefined behavior.
the array argis uninitialized and thus the elements in this array are non deterministic.
the variable br1equals to at line when mcfuzz profiles the program.
however br1 may not be equal to since the elements in argcould be assigned by any value due to the undefined behavior.
in such a case model checkers are allowed to output any checking result.
therefore all the inconsistent cases due to undefined behaviors cannot be concluded as bugs of model checkers.
usability of software model checkers .
the usability of software model checkers is very important in practice.
however we find it is not that satisfactory due to unclear user manuals lack of necessary warning messages or even crash failures.
first we find the user manuals are not very informative for us as experienced users of program analyzers to choose appropriate configurations.
especiallyesec fse august tallinn estonia chengyu zhang ting su yichen yan fuyuan zhang geguang pu and zhendong su 1int st1 st2 br1 br2 2void check if st1 st2 br1 else br2 7int main st1 st2 br1 br2 check if br2 !
verifier error return a sample bug found in seahorn1int main int arg int i br1 br2 int num while i num if arg br1 i if br1 !
verifier error return b undefined behavior example figure evaluation on sv comp benchmarks for seahorn sometimes when we chose different configurations the opposite verification results may be given.
we believe it should not be the obligation for users to infer the effect of different configurations.
an informative user manual with clear examples can greatly improve usability.
second we find the model checkers do not fully support the features of c language.
however they sometimes silently give incorrect verification results without any warnings if some unsupported library functions or language features exists in the program under check.
it is necessary for model checkers to give some warning messages to alert the users or conservatively answer unknown .
third it is also better to clearly define which language features are supported in user manual.
benefited from our bug reports the developers of software model checkers have improved their user manuals and warning messages.
developers feedback .
we have received very positive feedback from the developers of software model checkers.
the cpachecker developers said thank you very much for finding and reporting these cases!
this is very helpful for us .
they enhanced the original test suite by the test programs we reported and further found more bugs in other verification modes by using these programs.
the seahorn developers said i am working on improving soundness on such small examples.
thank you for the examples.
they are very useful.
.
the cbmc developers also thanked for the bugs we reported and added the test programs to their test suite.
generality and limitations .
in this paper we propose the branch reachability fuzzing approach to validate software model checkers.
in general our approach could be adapted to any other static analysers or verifiers.
the modular design of mcfuzz is flexible to test any software model checker.
our approach can also be used to generate benchmark programs for the software model checker competition.
but our approach requires the seed program should be valid deterministic and terminating for generating test oracles.
related work the reliability of program analysis tools is very crucial since these tools are now widely used to improve the quality or ensure the correctness of software systems .
there exists work on validating various program analyzers e.g.
static analyzers symbolic execution engines pointer analyses refactoring engines abstract interpreters and compliers .kapus et al.
use random program generation with differential testing to find bugs in several symbolic execution tools e.g.
klee crest and fuzzball .
wu et al.
cross check the pointer aliases during concrete program execution with the aliases found by static pointer alias analyzers to find bugs.
daniel et al.
detect potential bugs in refactoring engines by inspecting whether the two tools yield different refactored programs.
bugariu et al.
automatically test the soundness and precision of the implementations of abstract domains which is the core of abstract interpretationbased tools.
qiu et al.
compare the results of three static analyzers e.g.
flowdroid amandroid and droidsafe for identifying information flows in mobile applications and reveal many inaccuracies based on a same set of benchmark.
pauck et al.
similarly evaluate several taint analysis tools for android applications to see whether they keep their promises.
different from these ours is the first work to systematically validate software model checkers a type of formal program verifier and uncover many diverse bugs.
compilers can be viewed as another particular type of program analyzer.
yang et al.
propose csmith which uses differential testing to hunt bugs in c compilers.
csmith found more than previously unknown bugs in compilers.
later the equivalence modulo inputs emi technique and its variants were applied to stress test c compilers and found over unique bugs in gcc and llvm.
inspired by emi lidbury et al.
test opencl compilers to find miscompilation bugs.
these work mainly use the idea of differential testing or metamorphic testing since the test oracles are not available.
in contrast our work leverage dynamic execution to produce test oracles which can directly validate model checkers.
as for differential testing since the smc implementations do not have rigorous standardisation e.g.
cpachecker supports floating point while seahorn does not it may not work well for testing software model checkers.
conclusion in this paper we have proposed a branch reachability fuzzing approach to automatically validating software model checkers and realized it in the mcfuzz tool.
mcfuzz discovered unique bugs in three state of the art software model checkers almost all of which have been confirmed or fixed clearly demonstrating its effectiveness.
we have also carefully analyzed these bugs and how they have been triaged by the developers.
the bugs are diverse which we classified into seven categories.
the developers appreciated our bug reports and promptly responded to them further highlighting the importance of the problem.
our approach is also general and can be adapted to validate other static analyzers or verifiers.