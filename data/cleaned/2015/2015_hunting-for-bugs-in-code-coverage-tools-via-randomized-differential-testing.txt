hunting for bugs in code coverage t ools via randomized differential t esting yibiao yang yuming zhou hao sun zhendong su zhiqiang zuo lei xu and baowen xu state key lab.
for novel software technology nanjing university nanjing china unaffiliated department of computer science eth zurich switzerland computer science department uc davis usa abstract reliable code coverage tools are critically important as it is heavily used to facilitate many quality assurance activities such as software testing fuzzing and debugging.
however little attention has been devoted to assessing the reliability of code coverage tools.
in this study we propose a randomized differential testing approach to hunting for bugs in the most widely used c code coverage tools.
specifically by generating random input programs our approach seeks for inconsistencies in code coverage reports produced by different code coverage tools and then identifies inconsistencies as potential code coverage bugs.
t o effectively report code coverage bugs we addressed three specific challenges how to filter out duplicate test programs as many of them triggering the same bugs in code coverage tools how to automatically reduce large test programs to much smaller ones that have the same properties and how to determine which code coverage tools have bugs?
the extensive evaluations validate the effectiveness of our approach resulting in and confirmed fixed bugs for gcov and llvm cov respectively.
this case study indicates that code coverage tools are not as reliable as it might have been envisaged.
it not only demonstrates the effectiveness of our approach but also highlights the need to continue improving the reliability of code coverage tools.
this work opens up a new direction in code coverage validation which calls for more attention in this area.
index terms code coverage differential t esting coverage t ools bug detection.
i. i ntroduction code coverage refers to which code in the program and how many times each code is executed when running on the particular test cases.
the code coverage information produced by code coverage tools is widely used to facilitate many quality assurance activities such as software testing fuzzing and debugging .
for example researchers recently introduced an emi e quivalence m odulo i nputs based compiler testing technique .
the equivalent programs are obtained by stochastically pruning the unexecuted code of a given program according to the code coverage information given by the code coverage tools e.g.
llvm cov gcov .
therefore the correctness of equivalence relies on the reliability of code coverage tools.
in spite of the prevalent adoption in practice and extensive testing of code coverage tools a variety of defects still remain.
fig.
a shows a buggy code coverage report produced by llvm cov a c code coverage tool of clang .
note that all the test cases have been reformatted for presentation in this study.
the coverage report is an annotated version of source code where the first and second column list the line number and the execution frequency respectively.
we can see that the code at line is marked incorrectly as unexecuted by1 include stdio .h int main int g v g v !v printf d n g include stdio .h int main int g v g v !v printf d n g a b fig.
.
a bug of llvm cov and b the equivalent program obtained by pruning the unexecuted code line of the program in a llvm cov.
given the program pand its corresponding code coverage as shown in fig.
a emi compiler testing generates its equivalent program p as shown in fig.
b by removing unexecuted code statement .
the program p and p will be compiled by a compiler under testing and then executed to obtain two different outputs i.e.
and resulting in a bug reported by the emi approach.
however this is obviously not a real compiler bug.
the incorrect code coverage report leads to the false positive in compiler testing.
as the code coverage tools offer the fundamental information needed during the whole process of software development it is essential to validate the correctness of code coverage.
unfortunately to our best knowledge little attention has been devoted to assessing the reliability of code coverage tools.
this work makes the first attempt in this direction.
we devise a practical randomized differential testing approach to discovering bugs in code coverage tools.
our approach firstly leverages programs generated by a random generator to seek for inconsistencies of code coverage reports produced by different code coverage tools and identifies inconsistencies as potential code coverage bugs.
secondly due to the existence of too many inconsistency triggering test programs reported and a large portion of irrelevant code within these test programs reporting these inconsistency triggering tests directly is hardly beneficial to debugging.
before reporting them the reduction to those test programs is required .
however it is usually very costly and thus unrealistic to reduce every and each of the test programs .
we observe that many test programs trigger the same coverage bugs.
thus we can filter out many duplicate test programs.
note that duplicate test programs in this study indicates multiple test programs triggering the same code coverage bug.
overall to effectively report coverage bugs we need to address the following key challenges challenge filtering out test programs.
to filter out potential test programs triggering the same code coverage bugs the most intuitive way is to calculate similarities between ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
programs using the whole text.
however we use csmith as the random program generator and two csmith generated programs are not meaningfully comparable as they diverge in many ways .
in addition calculating similarities between programs using the whole text is expensive.
to tackle this challenge only lines of code triggering inconsistencies are used for computing similarities between programs.
challenge reducing test programs.
reducing test programs for code coverage bugs is much more complex than reducing test programs for compiler bugs as the later one only requires testing the behavior of the compiled executables or the exit code of compilers .
however reducing test programs for code coverage bugs involves processing textual code coverage reports and identify inconsistencies.
after each iteration of reduction we need to specify the inconsistency of interest we would like to preserve.
in this study we design a set of inconsistency types over coverage reports as the interest.
challenge inspecting coverage bugs.
with the reduced test program we need to inspect which code coverage tools have bugs before reporting bug.
in practice it is usually done manually .
in other words developers manually inspect the coverage reports to determine which coverage tools are buggy.
to relieve the burden of manual intervention we summarize a number of rules that code coverage reports must follow.
with those rules we develop a tool to examine part of the inconsistent coverage reports and determine which tools have bugs automatically.
we implemented a differential testing prototype called c2v code c overage v alidation for code coverage tools.
in order to evaluate the effectiveness of our approach we have applied c2v to gcov and llvm cov two widely used c code coverage tools respectively in the production compilers gcc and clang .
our evaluation confirms that c2v is very effective in finding code coverage bugs bugs were found bugs confirmed fixed for gcov while bugs were found bugs confirmed fixed for llvm cov.
contributions.
we made the following contributions we introduce an effective testing approach to validating the code coverage tools and have implemented it as a practical toolc2v for testing c coverage tools.
c2v mainly consists of a random program generator a comparer to identify inconsistencies between coverage reports a filter to remove test programs triggering same coverage bugs a test program reducer and an inspector to automatically determine which coverage tools have bugs for bug reporting.
we adopted c2v to uncover and bugs for gcov and llvm cov both of which are widely used and extensively tested c code coverage tools respectively.
specifically for gcov bugs have already been confirmed fixed for llvmcov bugs have been confirmed fixed.
our evaluation indicates that code coverage tools are not as reliable as it might have been envisaged.
it opens up a new research direction to improve the reliability of code coverage tools which calls for more attention in this area.
besides there is a need to examine the influence of those bugs on other techniques which depend on code coverage.organization.
the rest of this paper is structured as follows.
section ii introduces the background on code coverage.
section iii describes our approach for code coverage validation.
section iv reports the experimental results in detail.
section v surveys related work.
section vi concludes the paper and outlines the direction for future work.
ii.
c ode coverage in this section we introduce the preliminary knowledge the importance and the bug categories of code coverage.
a. preliminaries code coverage is a quality assurance metric used to describe the degree to which the code of a given program is executed when a particular test suite executes .
it is suggested that a program with a high test coverage will have a lower chance of containing undetected software bugs compared to a program with a low test coverage.
the code coverage analysis process is generally divided into three tasks code instrumentation data gathering and coverage analysis .
specifically code instrumentation inserts additional code instructions or probes to monitor whether the specific program chunk is executed or not at runtime.
the instrumentation can be done at the source level in a separate pre processing phase or at runtime by instrumenting byte code.
data gathering aims to collect the coverage data produced at test runtime.
finally coverage analysis aims to analyze the collected results and to provide test strategy recommendations in order to reduce to feed or to modify the relevant test suite.
currently many code coverage tools are available which support different languages e.g.
c c and java instrumentation levels e.g.
source code and byte code level or coverage criteria.
coverage criteria are the rules or requirements that a test suite needs to satisfy .
in the literature many coverage criteria have been proposed including statement coverage branch coverage path coverage condition coverage decision coverage and data flow coverage .
these criteria can be used to guide the generation of a test suite or to evaluate the effectiveness of a test suite .
b. importance of code coverage code coverage is widely used in but not limited to the following software techniques coverage based regression testing.
in the context of regression testing test case prioritization and test suite augmentation are the two widely used techniques .
the former aims to improve the ability of test cases to find bugs by scheduling test cases in a specific order .
one common practice is to achieve a high code coverage as fast as possible .
the latter is to generate new test cases to strengthen the ability of a test suite to find bugs .
in practice it is often to generate new test cases to cover the source code affected by code changes.
coverage based compiler testing.
recent years have seen an increasing interest in compiler testing which aims to validate authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
include stdlib .h int main void static int p p malloc sizeof int if p null return p return fig.
.
spurious marking bug of llvm cov int func int i if i return return int main int i j func i i j return fig.
.
wrong frequency bug of gcov the correctness of compilers.
one of the most attractive compiler testing techniques is based on the code coverage of a program s execution to generate equivalence modulo inputs by stochastically pruning its unexecuted code .
with the equivalence modulo inputs we can differentially test compilers.
coverage based fuzzing.
fuzzing technique is one of the most effective testing techniques to find vulnerabilities in software.
in practice coverage based fuzzing has been widely used .
based on the code coverage information of test cases it aims to determine which test cases should be retained for fuzzing.
in general a test case is retained if a new basic block is covered.
coverage based debugging.
debugging is a common activity in software development which aims to find the root cause of a fault.
spectrum based fault localization sbfl is one of the most extensively studied debugging techniques which is heavily based on code coverage .
under a specific test suite sbfl leverages the code coverage and the corresponding failed passed information to infer which code is the root cause of a fault.
as can be seen the above mentioned software techniques heavily depend on the code coverage information produced by code coverage tools.
therefore it is of great importance to guarantee the correctness of the code coverage reports.
otherwise they might inevitably produce incorrect results or lead to suboptimal decisions.
c. categories of code coverage bugs code coverage bugs can be categorized into the following three general classes spurious marking.
spurious marking denotes that a program chunk is unexecuted at runtime but is wrongly marked as executed by a code coverage tool.
figure gives such an example.
in the main function the two return statements at line and line cannot be executed at the same time.
thus one of them must be wrongly marked by llmv cov.
at runtime function main returns indicating that line was wrongly marked.
a code coverage tool with spurious marking bugs will cause non executed code wrongly marked as executed.
consequently for a program under test a part of elements are indeed untested and hence may have latent bugs undetected.
missing marking.
missing marking denotes that a program chunk is actually executed at runtime but is wrongly marked as unexecuted by a code coverage tool.
the coverage bug as shown in figure belongs to this class.
a code coverage tool with missing marking bugs will cause a predefined coverage goal never achieved regardless of how much testing time and resource are allocated.
wrong frequency.
wrong frequency denotes that a program chunk is executed mtimes at runtime but is wrongly marked as executed ntimes by a code coverage tool m negationslash n m n .
figure shows a gcov coverage report in which the first column lists the execution frequency and the second column lists the line number.
as can be seen the code at line is wrongly marked as executed twice but it was actually executed only once.
a code coverage tool with wrong frequency bugs might lead to a suboptimal decision in many coverage based software engineering activities.
iii.
m ethodology figure presents our framework for code coverage validation.
in the following we describe the key steps in this framework.
in particular we will use gcov and llvm cov as the subject code coverage tools to illustrate our approach to hunting for code coverage bugs if necessary.
a. generating test programs our approach starts with a random program generator.
the generator randomly generates a large program set p. each program p pwill be used as a test program for differentially testing two code coverage tools under examination.
in other words each program will be fed to the two code coverage tools to obtain two raw coverage reports.
in our study test programs refer to a collection of compilable c programs with the corresponding inputs.
we choose csmith to generate the test programs because of the following reasons it supports many c language features and can avoid generating programs with undefined behaviors thus outperforming some random c program generators each generated program is one single file with input selfcontained which does not require extra inputs and it is fast enough to generate programs with tens of thousands of lines within a few seconds.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ips inconsistency triggering program set r ips reduced ips bug report s ips ips p ic ur ur i p program set pgenerator parserreducer i i 1ip s comparerinspectorp p r ipsyes duplicate?
yesno noi coverage tool t1coverage tool t2 report r1 report r2 unified report ur1 unified report ur2 filter consistent?
no yes fig.
.
the framework for code coverage validation b. parsing code coverage reports for each test program pin the generated program set p we obtain the raw code coverage reports r1andr2emitted from the coverage tools t1andt2respectively.
however the raw coverage reports cannot be directly compared since they are presented in different formats.
we thus develop a parser to transform riinto uriin a unified format i .
specifically uriis a sequence of two tuple including the monitored program chunk and the corresponding execution frequency.
given a program pwith nlines of source code uriis a sequence of ntwo tuples nj fj in ascending order according to the value of nj j n. here njis the line number and fjis the corresponding execution frequency.
if linenjis not an instrumentation site for a particular coverage tool fjis assigned .
in our study gcov and llvm cov are selected as the subject code coverage tools which are integrated with the mature production compilers gcc and clang respectively.
in the following we give an illustrating example to demonstrate how the parser works in real world.
figure a shows the code coverage report r1produced by gcov for a program andfigure b shows the code coverage report r2produced by llvm cov for the same program.
r1andr2are two annotated versions of the source file.
however there are three differences between r1andr2.
first they have different instrumentation sites.
on the one hand lines and are treated as the instrumentation sites by llvm cov but not by gcov.
on the other hand lines and are treated as an instrumentation site by gcov but not by llvm cov.
hence only the common instrumentation sites used by gcov and llvm cov need to be compared later.
second gcov and llvm cov have different annotation formats for execution frequency.
a noninstrumentation site is noted as hyphen in r1but is noted as a null string in r2 e.g.
line .
besides an unexecuted line is noted as hashes in r1 e.g.
line while it is noted as in r2 e.g.
line .
third coverage statistics are included in r1but are not available in r2.
figure c lists the unified coverage reports produced by our parser for gcov and llvm cov respectively.
as can be seen there are common instrumentation sites between them lines and .
c. comparing unified coverage reports after obtaining the unified coverage reports ur1andur2 w e use a tool comparer to determine whether they are consistent.
if not the corresponding pand associated coverage reports will be added to a set named ips inconsistency triggering test program set .
when comparing the unified coverage reports comparer only takes into account the execution frequencies of the common instrumentation sites among the ncoverage tools.
during the comparison of ur1andur2 the following types of cases might occur typ e a one line code is marked as executed by t1but as unexecuted by t2 typ e b one line code is marked as unexecuted by t1but as executed by t2 typ e c one line code is marked as executed ktimes by t1and as executed ltimes by t2while k negationslash l. consequently the inconsistent unified reports can be divided into seven categories c001 typ e c c010 typ e b c100 typ e a c011 typ e b c c101 typ ea c c110 typ ea b c111 typ ea b c .
if the unified coverage reports corresponding to the test program pare found to have an inconsistency category ic it will be handled by the filter.
considering the two unified coverage reports shown in fig.
comparer will compare the execution frequencies of the common instrumentation sites to determine whether ur1 andur2are consistent.
as can be seen there are four inconsistent execution frequencies in the unified coverage reports between gcov and llvm cov typ e c at line typ e c at line typ ea at line and typ eb at line .
consequently the inconsistency category of ur1andur2is found to be c111.i n other words the inconsistency introduced by the test program pbelongs to the c111category.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
int g int f int arg for int i i !
i int f if break if arg break for g return return int main f f return int g int f int arg for int i i !
i int f if break if arg break for g return return int main f f return a raw coverage report by gcov .
.
and unified report ur1 b raw coverage report by llvm cov .
.
and unified report ur2 fig.
.
an illustrating example.
d. filtering out test programs intuitively using a test program set pwith a larger size has a higher chance to discover code coverage bugs.
therefore in practice we prefer to generate a very large number of test programs and further resulting in a large number of inconsistency triggering test programs.
this will lead to the following two problems.
on the one hand it may be unrealistic to inspect all the inconsistency triggering test programs as the reduction is very costly and inspection resources are often limited.
on the other hand we observe that many test programs trigger the same code coverage bugs.
therefore we can filter out duplicate test programs.
in fig.
we use filter to determine whether the inconsistency triggering test program is duplicate i.e triggering the same code coverage bug with other test programs.
to filter out potential duplicate test programs the most intuitive way is to calculate similarities between programs using the whole text.
however we use csmith as the random program generator and two csmith generated programs are not meaningfully comparable as they diverge in many ways .
in addition calculating similarities between programs using the whole text is expensive.
to tackle this challenge only lines of code triggering inconsistencies are used for computing similarities between programs.
more specifically we first transform the inconsistency triggering lines of code in each program into a token based string with variable names insensitive and then use a token based similarity algorithm to calculate similarities between programs.
we calculate program similarity with variable name insensitive since the variable names in csmith generated programs have no specific meaning.
for example we assume int i i are inconsistency triggering lines of code in program p. we first transform these two statements into int identifier equal numeric constant semi identifier equal numeric constantsemi with the help of the clang compiler.
after that we calculate its similarities with other programs.
in this study we use jaccard index similarity as it is the most widely used token based similarity algorithm .
if all the similarity coefficients between pand each of the programs in ipsare less than .
a tuple p ic ur u r2 will be added to the set ips.
otherwise pwill be filtered out.
e. reducing test programs an inconsistency triggering test program only indicates that some of the two code coverage tools are buggy but does not inform which one contains bugs.
therefore there is a need to inspect the inconsistency triggering test program to obtain the correct coverage report as the coverage oracle .
after that for each code coverage tool we can easily determine whether it is buggy by comparing the corresponding coverage report with the coverage oracle.
since a test program may have a large code size it is time consuming and error prone to determine the corresponding coverage oracle.
furthermore if a large test program is submitted as a bug report it is also difficult for developers to determine the location of bugs in the code coverage tool s .
to tackle this problem we use reducer to reduce each inconsistency triggering test program in ipsby removing the code irrelevant to the inconsistency.
for each inconsistency triggering test program pinips reducer takes the following steps to obtain the reduced test program.
at step the tool c reduce is applied to pto obtain the reduced version p prime.i fp primehas a smaller size than p go to step otherwise stop the reduction.
at step feed p primeto the ncoverage tools collect the coverage reports and determine the inconsistency category.
if the inconsistency category triggered by p primeis the same as the inconsistency category triggered by p assign p primetop.
the above process is repeated until pcannot be further reduced.
consequently we reduce ipsto obtain r ips the set of reduced test programs.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
f .
inspecting reduced test programs with the reduced test program we need to inspect which code coverage tools have bugs before reporting.
in practice it is usually done manually .
in other words developers manually inspect the coverage reports to determine which coverage tools are buggy.
to relieve the burden of manual intervention we summarize the following rules that code coverage reports must comply with identical coverage assuming statements s1ands2in the same block s1 s2 .i fs1is not a jump statement i.e break goto return exit o rabort statement and s2is not a label statement nor a loop for orwhile statement s1ands2should have identical coverage.
unexecuted coverage assuming statements s1 and s2 in the same block s1 s2 .i fs1is areturn break goto o rexit statement and s2is not a labeled statement s2should be never executed.
ordered coverage assuming statements s1ands2form s1 if ... s2 ... .i fs2is not a labeled statement the execution time of s1should be no less than s2.
with the above rules we develop the tool inspector to examine the inconsistent coverage reports and determine which tools have bugs automatically.
there is still some inconsistent coverage reports in r ips that can not be inspected automatically by our tool.
we inspect those coverage reports manually.
this process does not require too much human inspection effort as the reduced test programs only have a few lines usually less than lines in our study .
g. reporting test programs to developers for each test program in rs ips this step simply generates bug reports for the corresponding buggy tool s .
a bug report mainly consists of the reduced test program and the affected versions.
if a test program triggers multiple bugs multiple separate bug reports will be generated.
iv .
e v aluation in this section we first present the subject coverage tools and the testing environment.
then we describe our experimental results in detail.
a. subject code coverage tools in this study we select gcov and llvm cov as our subject code coverage tools.
we choose these two code coverage tools since they have been widely used in software engineering community and they have been integrated with the most widely used production compilers i.e.
gcc and clang.
more specifically we chose gcov in latest development trunk of gcc and llvm cov in the latest llvm development trunk.
for gcov the command flags we used to compile a given source file e.g.
t.c and produce the corresponding coverage report is as follows gcc o0 coverage t.c .
a.out gcov t.c the gcov generated coverage report is stored in a file named t.c.gcov .
for llvm cov we use the following command clang fprofile instr generate fcoverage mapping o0 t.c .
a.out llvm profdata merge default.profraw o t.profdata llvm cov show instr profile t.profdata .
a.out t.c t.c.lcov the llvm cov generated coverage report is stored in a file named t.c.lcov .
then these two produced coverage reports will be parsed into unified format and compared to detect inconsistency.
it is worth noting that we are using o0 option to turn off compiler optimizations.
it make sense to compare the coverage reports produced in this way.
b. testing environment setup our evaluation was conducted on a linux server with intel r xeon r cpu .00ghz cores and 32gb ram.
the server is running on ubuntu .
x86 .
we spent non continuous four months of which over one month we devoted to developing various tools.
the rest of time was spent in testing the two code coverage tools filtering out test programs reducing test programs and inspect test programs.
initially we only used csmith generated programs as the test programs.
later we made use of the programs selected from gcc s and clang s test suites as our test programs since they may cover many c semantics that csmith does not cover.
this is further confirmed in section iv c as a number of bugs are detected by programs inside test suites.
c. experimental results inconsistent coverage reports.
table i shows the statistics of inconsistency triggering test programs over csmithgenerated programs gcc s test suite and clang s test suite.
column shows the total number of test programs and column shows the number of test programs which run out of time seconds in our experiment .
we used million csmith generated programs and collected and c compilable programs respectively from gcc s and clang s test suites.
note that there are more than tens of thousands of test programs in gcc and clang s test suites.
only those c files that can be compiled independently are considered here.
among them programs executed more than seconds and hence were excluded for further analysis.
the remaining test programs were fed to c2v.
column is in the form of a b where a refers to the total number of test programs which can lead to inconsistencies and b refers to the percentage of a over the number of all the test programs c2v analyzed i.e.
column column .
we found 347programs leading to inconsistent coverage reports and 20respectively from csmithgenerated programs gcc s test suite and clang s test suite .
about .
csmith generated programs caused inconsistent coverage reports much higher than those from gcc s testsuite and clang s test suite.
columns to display the distributions of inconsistency triggering test programs over different categories.
in the third rows of these columns the number in parentheses indicates the number of test programs after filtering potential test programs that trigger the same code coverage bugs.
most of inconsistent reports fell into the c010 category indicating that the majority of inconsistencies belong authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i statistics of inconsistency triggering testprograms .
test programs time outinconsistency triggering test programs after filtering num after filtering p c001 c010 c100 c011 c101 c110 c111 csmith generated .
gcc s test suite .
clang s test suite .
table ii statistics of lines of code for the original and reduced version of csmith generated test programs min mean median max original reduced relative .
.
table iii information of allreported bugs gcov llvm cov total confirmed pending duplicate rejected reported table iv bugtypes of confirmed bugs gcov llvm cov total spurious marking missing marking wrong frequency total to the cases where some code is marked as unexecuted by gcov but as executed by llmv cov.
c101category has the minimal number of inconsistent reports indicating that inconsistencies oftyp e a and typ e c rarely occur simultaneously.
in addition we can found that our method is very efficient for filtering potential duplicate test programs.
for those csmith generated inconsistency triggering programs our filtering strategy led to test programs for reduction and inspection.
table ii lists their code size before and after reduction.
we can see that the mean lines of code drops from to thus helping effectively report code coverage bugs.
for those inconsistency triggering test programs from gcc s and clang s test suites we intended to inspect all of them.
the reasons are two fold.
first programs in these testsuites are usually unique in program structures unlike the randomly generated programs produced by csmith .
second the total number is not large i.e.
from gcc s test suite and20from clang test suite .
in summary we analyzed about inconsistency triggering test programs.
bug count.
we filed a total of 83bug reports for gcov and llvm cov during our testing period.
they can be found under yangyibiao nju.edu.cn in gcc s and llvm s bugzilla databases.
table iii shows the details of all the bugs we have reported so far.
as shown in column till april we have reported 83bugs of which 70bugs are confirmed by developers.
of the 70confirmed bugs 11are resolved as fixed 17as won t fix and 2as works for me in latest version.
it is worth noting that won t fix indicates a confirmed bug but will not be fixed by developers.
there are total 6bugs are pending for developers responses which are not listed in table v. consistent with c. sun et al s and v .
le et al s studies due to the bug management process of llvm is not organized as that of gcc if a llvm cov bug report has been cced by clang developers and there is no objection in the comments we label the bug as confirmed.
in addition as stated by developers if someone does not close the reported bug as invalid then the bug is real in llvm bugzilla.
another 4reported bugs were marked as duplicate by developers since similar test programs trigger the same coverage bug inside gcov or llvm cov.
the remaining 3reports were rejected by gcc developers.
two of them is gcc s default optimization strategy and the other is with invalid code.
table v lists all the confirmed bugs in detail including the identity priority current report status bug types the origins of the bug triggering test programs i.e.
csmith generated gcc s or clang s test suite and affected versions.
note that new indicates confirmed in gcc s bugzilla and assigned refers to that the confirmed bugs are under the process of fixing .
bug type.
we categorize coverage bugs into three classes as mentioned in section ii c spurious marking missing marking and wrong frequency .
table iv shows the breakdown of the bug types of all the confirmed bugs.
most of the bugs are spurious marking bugs i.e.
unexecuted code is wrongly marked as executed.
bug importance.
as shown in column of table v all our confirmed bugs have the default priority p3 except of them are reset to p5 by developers.
besides of our reported coverage bugs have been fixed by developers.
note that bugs are confirmed as works which means that they are fixed in developers version.
thus we consider these three bugs as fixed by developers.
this together shows that our reported bugs are important and worth the effort.
program source.
as shown in column of table v test programs from all the three main sources i.e.
csmithgenerated gcc s test suite and clang s test suite can trigger coverage bugs.
two programs from clang test suite trigger coverage bugs of gcov and a number of programs from gcc s test suite can also help find coverage bugs for llvmcov as well.
it is worth noting that test programs from different sources may induce the same coverage bugs.
it indeed happened in our experiment and we only reported once.
affected versions.
we only tested gcov and llvm cov inside the latest development trunks of gcc and clang respectively.
when we find a test case that reveals a bug in gcov or llvm cov we also check the corresponding compiler s stable releases against the same test case.
column of table v shows the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table v confirmed bugs idprio.
status type source affected ver.
gcov p4 new missing csmith v7 trunk gcov p3won t fix missing csmith v4 trunk gcov p3won t fix missing csmith v4 trunk gcov p5 new spurious csmith v4 trunk gcov p5 new missing csmith v7 trunk gcov p4assigned missing csmith v7 trunk gcov p3 works wrong freq.
csmith v4 gcov p3won t fix spurious csmith v4 trunk gcov p3 fixed missing cmsith trunk gcov p5 new wrong freq.
csmith trunk gcov p3won t fix missing csmith v4 trunk gcov p4assigned missing csmith trunk gcov p3assigned spurious csmith v4 trunk gcov p3won t fix wrong freq.
csmith v4 trunk gcov p4assigned missing csmith v4 trunk gcov p5assigned wrong freq.
csmith trunk gcov p3won t fix spurious csmith v4 trunk gcov p3 fixed spurious csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p5assigned wrong freq.
csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p5 new wrong freq.
csmith trunk gcov p3won t fix spurious csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p3won t fix spurious csmith v4 trunk gcov p3 fixed wrong freq.
gcc v7 trunk gcov p3won t fix missing gcc v4 trunk gcov p4 new wrong freq.
gcc v4 trunk gcov p5 new wrong freq.
clang v7 trunk gcov p3 fixed wrong freq.
clang v4 trunk gcov p5 new spurious gcc v6 trunk gcov p3 fixed spurious gcc v4 trunk gcov p5assigned missing gcc v4 trunk gcov p3 works wrong freq.
gcc v5 trunk gcov p3 fixed spurious gcc trunk gcov p3 fixed missing gcc trunk gcov p4 new missing gcc v4 trunk 43llvm cov p3 fixed missing csmith v3 trunk 44llvm cov p3confirmed spurious csmith trunk 45llvm cov p3 fixed spurious csmith trunk 46llvm cov p3 fixed missing csmith trunk 47llvm cov p3 fixed missing csmith trunk 48llvm cov p3confirmed spurious csmith trunk 49llvm cov p3confirmed spurious csmith trunk 50llvm cov p3confirmed spurious csmith trunk 51llvm cov p3confirmed spurious csmith trunk 52llvm cov p3confirmed spurious csmith trunk 53llvm cov p3confirmed spurious csmith trunk 54llvm cov p3confirmed missing clang v3 trunk 55llvm cov p3confirmed spurious clang trunk 56llvm cov p3confirmed wrong freq.
gcc trunk 57llvm cov p3confirmed missing clang v3 trunk 58llvm cov p3confirmed wrong freq.
gcc trunk 59llvm cov p3confirmed wrong freq.
gcc trunk 60llvm cov p3confirmed spurious gcc trunk 61llvm cov p3confirmed spurious gcc trunk 62llvm cov p3confirmed spurious gcc trunk 63llvm cov p3confirmed spurious gcc trunk 64llvm cov p3confirmed spurious gcc trunk 65llvm cov p3confirmed wrong freq.
gcc v3 trunk 66llvm cov p3confirmed spurious gcc trunk 67llvm cov p3confirmed wrong freq.
gcc v3 trunk 68llvm cov p3confirmed wrong freq.
gcc trunk 69llvm cov p3confirmed wrong freq.
clang v3 trunk 70llvm cov p3confirmed spurious gcc v3 trunkgcov llvm cov n source code 13void func int i switch i case break case default break int main for int i i i func i return fig.
.
one program triggering multiple bugs affected various versions of gcc and clang for each bug.
note that as for gcc we select gcc .
.
gcc .
.
gcc6.
.
gcc .
.
and the latest trunk version gcc .
and for clang we select clang .
clang .
clang .
and the latest trunk version clang .
.
as can be seen 42out of all the bugs can affect stable releases and a considerable number of bugs have been latent in the old stable releases such as gcc .
.
and clang .
for many years.
d. interesting bugs f ound one program triggering multiple bugs.
in figure column lists a code snippet and column shows the line numbers.
column and column display the coverage results by gcov and llvm cov respectively.
this code snippet is a simple switch statement inside a for loop from the caller.
the code at line and line actually executes only one time however they are wrongly marked as executed times by llvm cov and line is wrongly marked as executed times by gcov.
we have reported this case as bug of gcov and bug of llvm cov.
this case is quite simple and common in real world.
unfortunately this single case triggers coverage bugs for both gcov and llvm cov indicating that coverage bugs are subtle and prevalent.
coverage bugs or compiler bugs?
figure shows the coverage report for bug of clang.
a definition of strcmp function is first given at line while strcmp is redefined as the libc function.
as a result the calling of strcmp at line will invoke the libc function with internal linkage instead of the self defined function line .
however in our test gcc outputs whereas clang outputs for this case.
that means gcc invokes the correct libc function but clang still invokes the self defined function at line .
that is why line is reported as executed one time by llvm cov but as not executed by gcov.
as for this case the root cause of producing the incorrect coverage report is not the bugs inside llvm cov but the bugs inside clang instead.
code formatting problem.
figure shows the coverage report for bug of clang.
line is marked as executed twice by gcov but wrongly marked as executed only once in llvm cov.
along the execution we can see that each of the four statements at line i.e.
foo goto l2 l1 bar executes actually only one time before the main function finishes.
however from the perspective of line coverage the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
include stdio .h static int strcmp return define strcmp builtin strcmp int main int ret strcmp a b printf d n ret return fig.
.
coverage or compiler bug bug of llvm cov int a void foo a void bar a int main foo goto l2 l1 bar l2 if a goto l1 fig.
.
code formatting problem bug of llvm cov code at line executes twice.
for the first time the first two statements i.e.
foo andgoto l2 get executed and then the control flow jumps to line .
after executing the gotostatement at line the control flow jumps back to line .
then the last two statements i.e.
l1 bar get executed.
note that the coverage result will be correct if we put the four statements at line into four separate lines.
non trivial inspection.
figure follows the same notions with figure .
lines and are marked as executed by gcov but as unexecuted by llvm cov.
human inspection is conducted to determine whether gcov or llvm cov produces the incorrect coverage report.
but this process is non trivial.
intuitively the two branches of the if statement at line should not be executed simultaneously implying that the coverage report by gcov is incorrect.
besides this code outputs instead of at runtime further supporting the implication.
however it is actually llvm cov that produces the incorrect report bug of clang .
function setjmp and function longjmp are provided to perform complex flow of control in c. due to their existence the execution flows for this code are the if statement at line takes the false branch then the if statement at line also takes the false branch assigning variable ret as1and calling function foo at line function longjmp restores the program state when setjmp at line are called and returns hence taking the true branch at line .
as a result variable ret is assigned as .
the main function returns after printing the value of variable ret.
e. limitations in this study we assess the reliability of code coverage tools via differential testing.
this is a first effort towards this direction.
however our technique has a number of limitations.
first most of the test programs we used were generated by csmith.
the csmith generated programs only cover a subset of c semantics which might cause c2v to miss a number of code coverage defects.
as a complement we collected cgcov llvm cov n source code include stdio .h include setjmp .h int foo jmp buf b longjmp b int main int ret jmp buf buf if setjmp buf foo buf if setjmp buf !
ret else ret foo buf printf d ret fig.
.
non trivial inspection bug of clang programs from gcc s and clang s test suites and fed them to c2v which can mitigate this problem to some extent.
second we only take account inconsistency triggering lines of code for computing program similarities to filter out test programs that potentially trigger the same code coverage bugs.
in this study a large number of inconsistency triggering test programs are filtered out which may miss a number of quality test programs.
if we can inspect all csmith generated inconsistencytriggering test programs it is reasonable to expect that more code coverage bugs would be found.
third it is possible that both code coverage tools may have the same bugs.
in other words these two coverage tools might produce same but incorrect code coverage reports for a given program.
our approach can not identify any inconsistencies from such paired coverage reports and further miss this kind of bugs.
therefore in the future more research efforts should be paid in this area to improve the quality of code coverage tools.
f orth different code coverage tools having different implementations may make the coverage reports difficult to be compared.
to mitigate this problem we have taken the following steps we reformatted the generated test programs before feeding them to the coverage tools which led to formatted and comparable coverage reports before comparing coverage reports we identified and excluded specific behavioral differences of the coverage tools and before reporting bugs we inspected inconsistent coverage reports to determine which tools are buggy.
during inspection false alarms are manually identified.
therefore we have taken careful steps to reduce false positives resulting from the variability among different tools.
besides it is also interesting to develop more accurate techniques for coverage reports comparison in the future.
v. r elated work this section introduces the related work on randomized differential testing coverage directed differential testing and testing via equivalence modulo inputs.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a. randomized differential testing differential testing is originally introduced by mckeeman which attempt to detect bugs by checking inconsistent behaviors across different comparable software or different software versions.
randomized differential testing is a widely used black box differential testing technique in which the inputs are randomly generated .
yang et al.
developed csmith a randomized test case generation tool that can support a large subset of c features and avoid introducing undefined and unspecified behaviors to find c compiler bugs.
lidbury et al.
developed clsmith a tool built on top of csmith to validate opencl compilers based on differential testing and testing via equivalence modulo inputs emi .
they presented several strategies for random generation of opencl kernels and an injection mechanism which allowed emi testing to be applied to kernel in order to avoid little or no dynamically dead code.
their study revealed a significant number of opencl compiler bugs in commercial implementations.
sun et al.
applied randomized differential testing to find and analyze compiler warning defects across gcc and llvm.
in less than six months they successfully found confirmed fixed bugs.
different from prior studies we apply randomized differential testing to find code coverage bugs which we believe is an important topic.
b. coverage based differential testing a number of recent studies leverage coverage to improve the effectiveness of differential testing.
chen et al.
proposed a coverage directed fuzzing approach to detecting inconsistencies between different implementations of java virtual machine jvm .
they mutated seeding classfiles executed mutants on a reference jvm implementation and used coverage uniqueness as a discipline for accepting representative mutants.
the accepted mutants were then used as the inputs to differentially test different jvm implementations.
pei et al.
proposed deepxplore a whitebox coverage directed differential testing for detecting inconsistencies between multiple dnns.
they first introduced neuron coverage as a systematic metric for measuring how much of the internal logic of a dnns had been tested and then used this information to guide the testing process.
as can be seen the prerequisite of the above techniques is to obtain the correct coverage.
our work provides a general and practical approach to finding coverage bugs thus helping improve the quality of code coverage tools.
c. testing via equivalence modulo inputs testing via equivalence modulo inputs is a new testing technique proposed in recent years.
in nature emi testing is a kind of metamorphic testing which modifies a program to generate variants with the same outputs as the original program .
le et al.
proposed to generate equivalent versions of the program by profiling program s execution and pruning unexecuted code.
once a program and its equivalent variant are constructed both are used as input of the compiler under test checking for inconsistencies in their results.
so far this method has been used to detect confirmed bugs in two open sourcec compilers gcc and llvm.
based on this idea athena and hermes are developed subsequently.
athena generates emi by randomly inserting code into and removing statements from dead code regions.
hermes complements mutation strategies by operating on live code regions which overcomes the limitations of mutating dead code regions.
le et al.
first used csmith to generate single file test programs and transformed each single file test program into multiple compilation units.
then they stochastically assigned each unit an optimization level to thoroughly exercise linktime optimizers.
they discovered and reported lto bugs for gcc and llvm in months.
these techniques heavily depend on the code coverage information.
vi.
c onclusion and future work we proposed a randomized differential testing approach to hunting code coverage bugs and implemented a tool named c2v to test two c code coverage tools gcov and llvm cov.
our evaluations where 42and28bugs confirmed from gcov and llvm cov respectively in a short few months provided a strong evidence that code coverage tools are not as reliable as they might have been envisaged.
overall our approach has the following main advantages it simplifies the difficult code coverage validation problem as a simple comparison problem the comparison between code coverage reports not only checks whether a program chunk gets executed or not but also the exact execution frequencies.
any discrepancy in these dimensions would alert a potential bug report which helps find subtle but deep semantic bugs in code coverage tools and our approach is simple straightforward and general.
it can be easily applied to validate different code coverage tools under various programming languages and coverage criteria.
in the future more efforts should be paid on this area and there is a need to examine the influence of those bugs on other techniques which depend on code coverage.
acknowledgment we thank yanyan jiang zhaogui xu and the anonymous reviewers for their constructive comments.
we also thank the gcc and llvm developers especially martin li ska for analyzing and fixing our reported bugs.
this work is supported by the national natural science foundation of china the natural science foundation of jiangsu province bk20170652 the china postdoctoral science foundation 2018t110481 the fundamental research funds for the central universities the national key r d program of china 2018yfb1003901 .
zhendong su was supported by united states nsf grants and and google and mozilla faculty research awards.
yuming zhou zhouyuming nju.edu.cn and baowen xu bwxu nju.edu.cn are the corresponding authors.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.