focus a recommender system for mining api function calls and usage patterns phuong t. nguyen juri di rocco davide di ruscio universit degli studi dell aquila l aquila italy firstname.lastname univaq.itlina ochoa thomas degueule centrum wiskunde informatica amsterdam netherlands firstname.lastname cwi.nlmassimiliano di penta universit degli studi del sannio benevento italy dipenta unisannio.it abstract software developers interact with apis on a daily basis and therefore often face the need to learn how to use new apis suitable for their purposes.
previous work has shownthat recommending usage patterns to developers facilitates the learning process.
current approaches to usage pattern recom mendation however still suffer from high redundancy and poorrun time performance.
in this paper we reformulate the problemof usage pattern recommendation in terms of a collaborative filtering recommender system.
we present a new tool focus which mines open source project repositories to recommend api method invocations and usage patterns by analyzing how apisare used in projects similar to the current project.
we evaluatefocus on a large number of java projects extracted fromgithub and maven central and find that it outperforms the state of the art approach pam with regards to success rate accuracy and execution time.
results indicate the suitability of context aware collaborative filtering recommender systems to provide api usage patterns.
i. i ntroduction leveraging the time honored principles of modularity and reuse modern software systems development typically entails the use of external libraries.
rather than implementing new systems from scratch developers look for and try to integrate into their projects libraries that provide functionalities of interest.
libraries expose their functionality through application programming interfaces apis which govern the interaction between a client project and the libraries it uses.
developers therefore often face the need to learn new apis.
the knowledge needed to manipulate an api can be extracted from various sources the api source code itself the official website and documentation q a websites such as stackoverflow forums and mailing lists bug trackers other projects using the same api etc.
however official documentation often merely reports the api description without providing nontrivial example usages.
besides querying informal sourcessuch as stackoverflow might become time consuming and error prone .
also api documentation may be ambiguous incomplete or erroneous while api examples found on q a websites may be of poor quality .
over the past decade the problem of api learning has garnered considerable interest from the research community.several techniques have been developed to automate the extraction of api usage patterns in order to reduce developers burden when manually searching these sources and toprovide them with high quality code examples.
however these techniques based on clustering or predictive modeling still suffer from high redundancy and as we show later in the paper poor run time performance.
to cope with these limitations we propose a new approach for api usage patterns mining that builds upon concepts emerging from collaborative filtering recommender systems .
the fundamental idea of these systems is to recommend to users items that have been bought by similar users in similar contexts.
by considering api methods as products and client code as customers we reformulate the problem of usagepattern recommendation in terms of a collaborative filteringrecommender system.
informally the question the proposed system can answer is which api methods should this piece of client codeinvoke considering that it has already invoked these other api methods?
implementing a collaborative filtering recommender system requires to assess the similarity of two customers i.e.
twoprojects.
existing approaches assume that any two projectsusing an api of interest are equally valuable sources of knowledge.
instead we postulate that not all projects are equal when it comes to recommending usage patterns a project that is highly similar to the project currently being developed should provide higher quality patterns than a highly dissimilar one.
our recommender system attempts to narrow down the search scope by considering only the projects that are the most similar to the active project.
thus methods that are typically usedconjointly by similar projects in similar contexts tend to be recommended first.
we incorporate these ideas into a recommender system that mines open source software oss repositories to providedevelopers with api function calls and usage patterns focus.
our approach represents mutual relationships betweenprojects using a 3d matrix and mines api usage from the most similar projects.
we evaluated focus on different datasets comprising java projects from github and jar archives from the maven central repository.
in the evaluation we simulate different stages of a development process by removing portions of client code and assessing how focus can recommend snippets with api invocations to complete them.
we find that ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a initial version b final version fig.
.
motivating example focus outperforms pam a state of the art tool for api usage patterns mining with regards to success rate accuracy and execution time.
this paper is organized as follows.
section iiintroduces a motivating example and background notions.
our recommender system for api mining focus is introduced in section iii.
the evaluation is presented in section iv with the key results being analyzed in section v. section vidiscusses the threats to validity.
in section vii we present related work and conclude the paper in section viii.
ii.
b ackground this section presents a motivating example for introducing the problem addressed by this paper and the main components of the proposed solution.
then we introduce the main notions underpinning our approach mostly originating from schafer et al.
and chen .
a. motivating example the typical setting considered in the paper is as shown in fig.
a developer is implementing some method to satisfy the requirements of the system being developed.
in the specific case shown in fig.
b the findboekrekeningen method queries the available entities and retrieve those of type boekrekening .
to this end the criteria api library1is used.
fig.
a depicts the situation where the development is at an early stage and the developer already used some methods of the chosen api to develop the required functionality.
however she is not sure how to proceed from this point.
in such cases different sources of information may be consulted such as stackoverflow video tutorials api documentation etc.
in this paper we propose an approach aiming at providing developers with recommendations consisting of a list of api method calls that should be used next and with usage patterns that can be used as a reference for completing the development of the method being defined e.g.
code snippets that could support in completing the method definition with the framed code in fig.
b .
b. api function calls and usage patterns asoftware project is a standalone source code unit that performs a set of tasks.
furthermore an api is an interface that abstracts the functionalities offered by a project by hiding its implementation details.
this interface is meant to support reuse and modularity .
an api xbuilt in an object oriented programming language e.g.
the criteria api in fig.
consists of a set txof public types e.g.
criteriabuilder and criteriaquery .
each type in txconsists of a set of public methods and fields that are available to client projects e.g.
the method createquery of the type criteriaquery .
amethod declaration consists of a name a possibly empty list of parameters a return type and a possibly empty body e.g.
the method findboekrekeningen in fig.
.
given a set of declarations din a project p an api method invocation iis a call made from a declaration d dto another declaration m. similarly an api field access is an access to a field f ffrom a declaration dinp.
api method invocations mi and field accessesfa inpform the set of api usages u mi fa.
finally an api usage pattern or code snippet is a sequence u1 u2 ... un uk u .
c. context aware collaborative filtering as stated by schafer et al.
collaborative filtering cf is the process of filtering or evaluating items through the opinions of other people.
in a cf system a user who buys or uses an item attributes a rating to it based on her experience and perceived value.
therefore a rating is the association of a user and an item through a value in a given unit usually in scalar binary or unary form .
the set of all ratings of a given user is also known as a user profile .
moreover the set of all ratings given in a system by existing users can be represented in a so called rating matrix where a row represents a user and a column represents an item.
the expected outcome of a cf system is a set of predicted ratings aka.
recommendations for a specific user and a subset of items .
the recommender system considers the most similar users aka.
neighbors to the active user to suggest new ratings.
a similarity function simusr ua uj computes the weight of the active user profile uaagainst each of the user profilesujin the system.
finally to suggest a recommendation for an item ibased on this subset of similar profiles the cf system computes a weighted average r ua i of the existing ratings where r ua i varies with the value of simusr ua uj obtained for all neighbors .
context aware cf systems compute recommendations based not only on neighbors profiles but also on the context where the recommendation is demanded.
each rating is associated with a context .
therefore for a tuple cmodeling different contexts a context similarity metricsimctx ca ci forca ci cis computed to identify relevant ratings according to a given context.
then the weighted average is reformulated as r ua i ca .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
iii.
p roposed approach to tackle the problem of recommending api function calls and usage patterns we leverage the wisdom of the crowd and existing recommender system techniques.
in particular we hypothesize that api calls and usages can be mined from existing codebases prioritizing the projects that are similar to the one from where the recommendation is demanded.
more specifically our tool focus adopts a context aware cf technique to search for invocations from closely relevant projects.
this technique allows us to consider both project and declaration similarities to recommend api function calls and usage patterns.
following the terminology of recommender systems we treat projects as the enclosing contexts method declarations asusers and method invocations asitems .
intuitively we recommend a method invocation for a declaration in a given project which is analogous to recommending an item to a user in a given context.
for instance the set of method invocations and the usage pattern cf.
framed code in fig.
b recommended for the declaration findboekrekeningen can be obtained from a set of similar projects and declarations in a codebase.
the collaborative aspect of the approach enables to extract recommendations from the most similar projects while the context awareness aspect enables to narrow down the search space further to similar declarations.
a. architecture the architecture of focus is depicted in fig.
.
to provide its recommendations focus considers a set of oss repositories .
the code parser 2component extracts method declarations and invocations from the source code or bytecode of these projects.
the project comparator a subcomponent of the similarity calculator computes the similarity between projects in the repositories and the project under development.
using the set of projects and the information extracted by the code parser the data encoder 4component computes rating matrices which are introduced later in this section.
afterwards the declaration comparator computes the similarities between declarations.
from the similarity scores the recommendation engine generates recommendations either as a ranked list of api function calls using the api generator or as usage patterns using the code builder which are presented to the developer.
in the remainder of this section we present in greater details each of these components.
code parser focus relies on rascal m3 an intermediate model that performs static analysis on the source code to extract method declarations and invocations from a set of !
fig.
.
overview of the focus architectureprojects.
this model is an extensible and composable algebraic data type that captures both language agnostic and java specific facts in immutable binary relations.
these relations represent program information such as existing declarations method invocations field accesses interface implementations class extensions among others .
to gather relevant data rascal m3leverages the eclipse jdt core component2to build and traverse the abstract syntax trees of the target java projects.
in the context of focus we consider the data provided by the declarations and methodinvocation relations of the m3 model.
both of them contain a set of pairs angbracketleftv1 v2 angbracketright wherev1 andv2are values representing locations .
these locations are uniform resource identifiers that represent artifact identities aka.
logical locations or physical pointers on the file system to the corresponding artifacts aka.
physical locations .
the declarations relation maps the logical location of an artifact e.g.
a method to its physical location.
the methodinvocation relation maps the logical location of a caller to the logical location of a callee .
we refer the reader to a dedicated paper for the technical details of the inference of java m3models .
listing .
excerpt of the m3model extracted from fig.
m3.declarations java method standaardboekrekeningservice findboekrekeningen file ... standaardboekrekeningservice.java m3.methodinvocation java method standaardboekrekeningservice findboekrekeningen java method entitymanager getcriteriabuilder listing 1depicts an excerpt of the m3model extracted from the code presented in fig.
a .
the declarations relation links the logical location of the method findboekrekeningen t oi t s corresponding physical location in the file system.
the methodinvocation relation states that the getcriteriabuilder method of the entitymanager type is invoked by the findboekrekeningen method in the current project.
data encoder once method declarations and invocations are extracted focus represents the relationships among them using a rating matrix.
for a given project each row in the matrix represents a method declaration and each column represents a method invocation.
a cell is set to 1if the declaration in the corresponding row contains the invocation in the column otherwise it is set to .
for example fig.
3shows the rating matrix of a project with four declarations p1 owner d1 d2 d3 d4 and four invocations i1 i2 i3 i4 .
i1i2i3i4 d11011 d20110 d31001 d40100 fig.
.
rating matrix for a project with declarations and invocations to capture the intrinsic relationships among various projects declarations and invocations we come up with a 3d contextbased rating matrix .
the third dimension of this matrix authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
?
?
active project p a similar project p similar project p w sim pa p1 .8w sim pa p2 .
active declaration d a similar declaration d similar declaration d fig.
.
3d context based rating matrix represents a project which is analogous to the so called context in context aware cf systems.
for example fig.
4depicts three projectsp pa p1 p2 represented by three slices with four method declarations and four method invocations.
project p1 has already been introduced in fig.
3and for the sake of readability the column and row labels are removed from all slices in fig.
.
there pais the active project and it has an active declaration .active here means the artifact project or declaration being considered or developed.
both p1andp2 are complete projects similar to the active project pa. the former projects i.e.
p1andp2 are also called background data since they are already available and serve as a base for the recommendation process.
in practice the higher the number of complete projects considered as background data the higher the probability to recommend relevant invocations.
similarity calculator exploiting the context aware cf technique the presence of additional invocations is deduced from similar declarations and projects.
given an active declaration in an active project it is essential to find the subset of the most similar projects and then the most similar declarations in that set of projects.
to compute similarities we derive from a weighted directed graph that models the relationships among projects and invocations.
each node in the graph represents either a project or an invocation.
if project pcontains invocation i then there is a directed edge from ptoi.
the weight of an edgep irepresents the number of times a project p performs the invocation i. fig.
5depicts the graph for the set of projects introduced in fig.
.
for instance pahas four declarations and all of them invoke i4.
as a result the edge pa i4has a weight of .
in the graph a question mark represents missing information.
for the active declaration in pa it is not known yet whether invocations i1andi2should be included.
the similarity between two project nodes pandqis computed by considering their feature sets .
given that phas a set of neighbor nodes i1 i2 .. il the feature set of pis the vector 1 2 .. l with kbeing the weight of nodeik.
this weight is computed as the term frequency inverse document frequency value i.e.
k fik log p aik wherefikis the weight of the edge p ik p is the numberi2 i3pa?p1 p22 1i1?
3i44 fig.
.
graph representation of projects and invocations of all considered projects and aikis the number of projects connected to ik.
eventually the similarity between pandq with their corresponding feature vectors k k .. land j j .. m is sim p q summationtextn t 1 t t radicalbig summationtextn t t radicalbig summationtextn t t the similarities among method declarations are calculated using the jaccard similarity index as follows sim d e f d intersectiontextf e f d uniontextf e where f d andf e are the sets of invocations made from declarations dande respectively.
api generator this component which is part of the recommendation engine is in charge of generating a ranked list of api function calls.
in fig.
the active project paalready includes three declarations and the developer is working on the fourth declaration which corresponds to the last row of the slice.
pahas only two invocations represented in the last two columns of the matrix i.e.
cells filled with .
the first two cells are marked with a question mark ?
indicating that it is unclear whether these two invocations should also be added into pa. the recommendation engine attempts to predict additional invocations for the active declaration by computing the missing ratings using the following formula rd i p rd summationtext e topsim d re i p re sim d e summationtext e topsim d sim d e eq.
3is used to compute a score for the cell representing method invocation i declaration dof project p where topsim d is the set of top similar declarations of d sim d e is the similarity between dand a declaration e computed using eq.
rdandreare the mean ratings of dande respectively andre i p is the combined rating of declaration dforiin all similar projects computed as follows re i p summationtext q topsim p re i q sim p q summationtext q topsim p sim p q wheretopsim p is the set of top similar projects of p andsim p q is the similarity between pand a project q computed using eq.
.
eq.
4implies that a higher weight is given to projects with higher similarity.
in practice it is reasonable since given a project its similar projects contain authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
real source code recommended by focus more relevant api calls than less similar projects.
using eq.
we compute all the missing ratings in the active declaration and get a ranked list of invocations with scores in descending order which is then suggested to the developer.
code builder this subcomponent is also part of the recommendation engine and it is responsible for recommending usage patterns to developers.
from the ranked list top n method invocations are used as a query to search the database for relevant declarations.
to limit the search scope only the most similar projects are considered.
the jaccard index is used to compute similarities between the selected invocations and a given declaration.
for each query we search for declarations that contain as many invocations of the query as possible.
once we identify the corresponding declarations we retrieve their source code using the declarations relation of the rascal m3 model.
the resulting code snippet is then recommended to the developer.
for the sake of illustration we now present an example of how focus suggests real code snippets considering the declaration findboekrekeningen in fig.
a as input.
the invocations it contains are used together with the other declarations in the current project as query to feed the recommendation engine .
the final outcome is a ranked list of real code snippets.
the top one named findbyidentifier is depicted in fig.
.
by carefully examining this code and the original one in fig.
b we see that although they are not exactly the same they indeed share several method calls and a common intent both exploit a criteriabuilder object to build perform a query and eventually get back some results.
furthermore the outcome of both declarations is of the list type.
interestingly compared to the original one the recommended code appears to be of higher quality since it includes a try catch construct to handle possible exceptions.
thus the recommended code coupled with the corresponding list of function calls i.e.
get equal where select etc.
provides the developer with helpful directions on how to use the api at hand to implement the desired functionality.
iv .
e v aluation the goal of this study is to evaluate focus and compare it with another state of the art tool pam with the aim of assessing its capability to recommend api usage patterns to developers while they are writing code.
the quality focus is twofold studying the api recommendation accuracy and completeness as well as the time required by focus and pam to provide a recommendation.
the context consists of java open source projects and jar archives from the mavencentral repository.3for the sake of reproducibility and ease of reference all artifacts used in the evaluation together with the tools are available online .
we choose pam as a baseline for comparison as it has been shown to outperform other similar tools such as mapo and up miner .
to conduct the comparison with pam we leverage its original source code made available online by its authors .
in the following we detail our research questions datasets evaluation methodology and metrics.
a. research questions our research questions are as follows rq 1t o what extent is focus able to provide accurate and complete recommendations?
this research question relates to the capability of focus to produce accurate and complete results.
having too many false positives would end up being counterproductive whereas having too many false negatives would mean that the tool is not able to provide recommendations in many cases where this is needed.
rq 2what are the timing performances of focus in building its models and in providing recommendations?
this research question aims at assessing whether from a timing point of view focus compared to pam could be used in practice.
we evaluate the time required by both tools to provide a recommendation.
we mainly focus on the recommendation time because while it is acceptable that the model training phase is relatively slow i.e.
the model could be built offline the recommendation time has to be fast enough to make the tool applicable in practice.
rq 3how does focus perform compared with p am?
finally this research question directly compares the recommendation capabilities of focus and pam.
b. datasets to answer our research questions we relied on four different datasets.
the first dataset shl has been assembled starting from5 randomly selected java projects retrieved from github via the software heritage archive .
to comply with the requirements of pam we first restricted the dataset to the list of projects that use at least one of the third party libraries listed in table i. most of them were used to assess the performance of pam .
each row in table ilists a thirdparty library the number of projects that depend on it and the number of classes that invoke methods of this library.
to comply with the requirements of focus we then restricted the dataset to the list of projects containing at least one pom.xml as it eases the creation of the m3models.
we thus obtained our first dataset consisting of java projects.
from shl we extracted a second dataset shsconsisting of the200 smallest in size projects of shl.
as a third dataset we randomly collected a set of jar archives from the maven central repository which we name mvl.
through a manual inspection of mvl we noticed authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i excerpt of the third party libraries used by dataset shl project name of client projects of client classes com.google.gson io.netty org.apache.camel org.apache.hadoop org.apache.lucene org.apache.mahout org.apache.wicket org.drools org.glassfish.jersey org.hornetq org.jboss.weld org.jooq org.jsoup org.neo4j org.restlet org.springside twitter4j that many projects only differ in their version numbers ant1.
.
.jar and ant .
.
.jar for instance are two versions of the same project ant .
these cases are interesting as we assume two versions of the same project share many functionalities .
the collaborative filtering technique works well given that highly similar projects exist since it just copies invocations from similar methods in the very similar projects see eq.
3and eq.
.
however a dataset containing too many similar projects may introduce a bias in the evaluation.
thus we decided to populate one more dataset.
starting from mvl we randomly selected one version for every project and filtered out the other versions.
the removal resulted in a fourth dataset consisting of1 projects which we name mvs.
three datasets i.e.
shl mvland mvsare used to assess the performance of focus rq .
the smallest dataset shsis used to compare focus and pam rq 2and rq .
eventually the process of creating required metadata consists of the following main steps for each project in the dataset the corresponding rascal m3model is generated for each m3model the corresponding arff representations4are generated in order to be used as input for applying focus and pam during the actual evaluation steps discussed in the next sections.
c. study methodology performing a user study has been accepted as the standard method to validate an api usage recommendation tool .
while user studies are valuable they are limited in the size of the task a participant can conduct and are highly susceptible to individual skills and subjectiveness.
in this paper to study if focus is applicable in real world settings we perform a different offline evaluation by simulating the behavior of a developer working at different stages of a development project on partial code snippets.
specifically we consider a programmer who is developing a project p. to this end some parts of pare removed to mimic an actual development.
given an original project p the total number of declarations it contains is called .
however only declarations are used as input for recommendation and the rest is discarded.
in practice this corresponds to the situation when the developer already finished declarations and she is now working on the active declaration da.f o rda originally there are invocations however only the first invocations are selected as query and the rest is removed and saved as ground truth data for future comparison.
in practice is small at an early stage and increases over the course of time.
similarly is small when the developer just starts working on da.
the two parameters are used to stimulate different development phases.
in particular we consider the following configurations.
configuration c1.
almost the first half of the declarations is used as testing data and the second half is removed.
the last declaration of the first half is selected as the active declaration da.f o rda only the first invocation is provided as a query and the rest is used as ground truth data which we call gt p .
this configuration mimics a scenario where the developer is at an early stage of the development process and therefore only limited context data is available to feed the recommendation engine.
configuration c1.
similarly to c1.
almost the first half of the declarations is kept and the second half is discarded.
dais the last declaration of the first half of declarations.
for da the first four invocations are provided as query and the rest is used as gt p .
configuration c2.
the last method declaration is selected as testing i.e.
daand all the remaining declarations are used as training data .
inda the first invocation is kept and all the others are taken out as groundtruth data gt p .
this represents the stage where the developer almost finished implementing p. configuration c2.
similar to c2.
dais selected as the last method declaration and all the remaining declarations are used as training data .
the only difference with c2.
is that inda the first four invocations are used as query and all the remaining ones are used as gt p .
when performing the experiments we split a dataset into two independent parts namely a training set and a testing set .
in practice the training set represents the oss projects that have been collected a priori.
they are available at developers disposal ready to be exploited for mining purposes.
the testing set represents the project being developed or the active project .
this way our evaluation mimics a real development scheme the system should produce recommendations for the active project based on the data from a set of existing projects .
we opt for k fold cross validation as it is widely chosen to evaluate machine learning models.
depending on the availability of input data the dataset with nelements is divided into kequal parts so called folds .
for each validation round one fold is used as testing data and the remaining k 1folds are used as training data.
for our evaluation we select two values authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
i.e.
k andk n. the former corresponds to ten fold cross validation and the latter corresponds to leave one out cross validation .
d. evaluation metrics for a testing project p the outcome of a recommendation process is a ranked list of invocations i.e.
rec p .i ti so u r firm belief that the ability to provide accurate invocations is important in the context of software development.
thus we are interested in how well a system can recommend api invocations that eventually match with those stored in gt p .
to measure the performance of the recommender systems i.e.
pam and focus we utilize two metrics namely success rate and accuracy .
given a ranked list of recommendations a developer typically pays attention to the top n items only.
success rate and accuracy are computed by using nas the cut off value .
given that recn p is the set of top n items andmatch n p gt p intersectiontextrecn p is the set of items in the top n list that match with those in the ground truth data then the metrics are defined as follows.
success rate given a set of ptesting projects this metric measures the rate at which a recommendation engine can return at least a match among top n recommended items for every projectp p. success rate n countp p match n p p where count counts the number of times the boolean expression given as parameter evaluates to true.
accuracy precision and recall are employed to measure accuracy .precision n is the ratio of the top n recommended items belonging to the ground truth dataset precision n match n p n and recall n is the ratio of the ground truth items being found in the top n items recall n match n p gt p recommendation time as mentioned in rq we measure the time needed by both pam and focus to perform a prediction on a given infrastructure which is a laptop with intel core i5 7200u cpu .50ghz 8gb ram and ubuntu .
.
v. r esults rq t o what extent is focus able to provide accurate and complete recommendations?
to answer this research question we use the dataset shl and vary the length of the input data for every testing project.
two main configurations are taken into account with two sub configurations for each as introduced in section iv c .
table iishows the success rate for all the configurations.
for a smalln i.e.
n the developer expects a very brief list of items focus is still able to provide matches.
for example the success rates of c1.
and c1.
are24.
and .
respectively.
when the cut off value n is increased table ii success rate for shl n nshl c1.
c1.
c2.
c2.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
the corresponding success rates improve linearly.
for example whenn focus obtains .
success rate for c1.
and47.
forc1.
.
by comparing the results obtained for c1.
and c1.
we see that when more invocations are incorporated into the query focus provides more precise recommendations.
in practice this means that the accuracy of recommendations improves with the maturity of the project.
we now consider the outcomes obtained for c2.
and c2.
.
in these configurations more background data is available for recommendation.
for c2.
the success rates for the smallest values of n i.e.
n andn are23.
and31.
respectively.
in other words it improves with n. the same trend can be observed with other cut off values i.e.
n the success rates for these settings increase correspondingly.
we notice the same pattern considering c2.
and c2.
together or c1.
and c1.
together if more invocations are used as query focus suggests more accurate invocations.
fig.
7and fig.
8depict the precision and recall curves prcs for the above mentioned configurations by varying n from1to30.
in particular fig.
7represents the accuracy when almost the first half of the declarations together with one c1.
and four invocations c1.
from the testing declaration daare used as query.
as a prc close to the upper right corner indicates a better accuracy we see that the accuracy of c1.
is superior to that of c1.
.
similarly with c2.
and c2.
as depicted in fig.
the accuracy improves substantially when the query contains more invocations.
these facts further confirm that focus is able to recommend more relevant invocations when the developer keeps coding.
this improvement is obtained since the similarity between declarations can be better determined when more invocations are available as comprehended in eq.
.
the results reported so far appear to be promising at the first sight.
however by considering table ii fig.
and fig.
together we realize that both success rate and accuracy are considerably low the best success rate is .
forc1.
whenn which means that more than half of the queries do not get any matches at all.
in this sense it is necessary to ascertain the cause of this outcome is focus only capable of generating such moderate recommendations or is it because of the data?
our intuition is that shlis rather small in size which means the background data available for the recommendation process is limited.
thus to further validate the performance of focus we perform additional experiments by considering more data using both mvland mvs.
for this evaluation we authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
precision and recall for c1.
andc1.
onshl fig.
.
precision and recall for c2.
andc2.
onshl just consider the case when only one invocation together with other declarations are used as query i.e.
c1.
and c2.
.
this aims at validating the performance of focus given that the developer just finished only one invocation in da.
table iiidepicts the success rate obtained for different cut off values using both datasets.
the success rates for all configurations are much better than those of shl.
the scores are considerably high even when n the success rates obtained by c1.
and c2.
are72.
and72.
respectively.
for mvs the corresponding success rates are lower.
however this is understandable since the set has less data compared to mvl.
the prcs for mvland mvsare shown in fig.
9and fig.
respectively.
we see that for mvl a superior performance is obtained by configuration c2.
i.e.
when more background data is available for recommendation compared to c1.
.f o r mvs we witness the same trend as with success rate the difference between c1.
and c2.
is negligible.
considering both fig.
and fig.
we observe that the overall accuracy for mvlis much better than that of mvs.
the maximum precision and recall table iii success rate for mv land mv s n nmvl mvs c1.
c2.
c1.
c2.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
fig.
.
precision and recall for c1.
andc2.
onmvl fig.
.
precision and recall for c1.
andc2.
onmvs formvlare0.75and0.
respectively.
whereas the maximum precision and recall for mvsare0.52and0.
respectively.
this further confirms the fact that with more similar projects focus can provide better recommendations.
referring back to the outcomes of shl we see that the performance on mvl and mvsis improved substantially.
to sum up we conclude that the performance of focus relies on the availability of background data.
the system works effectively given that more oss projects are available for recommendation.
in practice it is expected that we can crawl as many projects as possible and use them as background data for the recommendation process.
rq what are the timing performances of focus in building its models and in providing recommendations?
to measure the execution time of pam and focus for the very first attempt we ran both systems on the shldataset consisting of projects.
with pam for each testing project we combined the extracted query with all the other training projects to produce a single arff file provided as input for the recommendation process .
nevertheless we then realized that the execution of pam is very time consuming.
for instance for one fold containing 1testing and training projects i.e.
9training folds with 80mb in size pam takes around320 seconds to produce the final recommendations.
instead the corresponding execution time by focus is quite faster than pam around .80seconds.
given the circumstances it is not feasible to run pam on a large dataset.
therefore we decided to use the shsdataset consisting of projects for this purpose.
for the experiments we opt for leave one out cross validation i.e.
one project is used authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
precision and recall for pam and focus using shs.
as testing and all the remaining projects are used for the training.
the rationale behind the selection of this method instead of ten fold cross validation is that we want to exploit as much as possible the projects available as background data given a testing project.
the validation was executed times and we measured the time needed to finish the recommendation process.
on average pam requires 9seconds to provide each recommendation while focus just needs .
seconds i.e.
it is two orders of magnitude faster and suitable to be integrated into a development environment.
rq how does focus perform compared with p am?
for the reasons explained in rq the comparison between pam and focus has been performed on the shsdataset.
focus gains a better success rate than pam does i.e.
.
compared to .
.
furthermore as depicted in fig.
there is a big gap between the prcs for pam and focus with the one representing focus closer to the upper right corner.
this implies that the accuracy obtained by focus is considerably superior to that of pam.
a statistical comparison of pam and focus using fisher s exact test indicates that for n focus always outperforms pam we achieved p values .
adjusted using the holm s correction in all cases with an odds ratio between .21and3.
and equal to .54forn .i n other words focus has over twice the odds of providing an accurate recommendation than pam.
it is worth noting that the overall accuracy of focus achieved and reported in this experiment is although better thanthat of pam still considerably low.
following the experiments onmvland mvsfrom rq we believe that this attributes to the limited background data available for the evaluation since we only consider projects.
in summary by considering both rq 2and rq we come to the conclusion that focus obtains a better performance incomparison to pam with regards to success rate accuracy and execution time.
lastly since pam takes considerable time to produce the final recommendations it might be impractical to deploy pam in a development environment.
vi.
t hreats to validity the main threat to construct validity concerns the simulated setting used to evaluate the approaches as opposed to performing a user study.
we mitigated this threat by introducing fourconfigurations that simulate different stages of the development process.
in a real development setting however the orderin which one writes statements might not fully reflect oursimulation.
also in a real setting there may be cases in which a recommender is more useful and cases obvious code completion where it is less useful.
this makes a further evaluation involving developers highly desirable.
threats to internal validity concern factors internal to our study that could have influenced the results.
one possible threat can be seen through the results obtained for the datasets shl and shs.
as noted these datasets exhibit lower precision recall with respect to mvland mvsdue to the limited size of the training sets.
however these datasets were needed to compare focus and pam due to the limited scalability of pam.
the main threat to external validity is that focus is currently limited to java programs.
as stated in section iii however focus makes few assumptions on the underlying lan guage and only requires information about method declarationsand invocations to build the 3d rating matrix.
this informationcould be extracted from programs written in any object oriented programming language and we wish to generalize focus to other languages in the future.
vii.
r elated work in this section we summarize related work about api usage recommendation and relate our contributions to the literature.
a. api usage pattern recommendation acharya et al.
present a framework to extract api patterns as partial orders from client code.
while this approach proposes a representation for api patterns suggestions regarding api usage are still missing.
mapo mining api usage pattern from open source repositories is a tool that mines api usage patterns from client projects .
mapo collect api usages from source files groups api methods into clusters.
then it mines apiusage patterns from the clusters ranks them according totheir similarity with the current development context andrecommends code snippets to developers.
similarly up miner mines api usage patterns by relying on seqsim a clustering strategy that reduces patterns redundancy and improves coverage.
differently from focus these approaches are based on clustering techniques and consider all clientprojects in the mining regardless of their similarity with the current project.
fowkes et al.
introduce pam probabilistic api miner a parameter free probabilistic approach to mine api usage patterns .
pam uses the structural expectation maximization em algorithm to infer the most probable api patterns from client code which are then ranked according to theirprobability.
pam outperforms both mapo and up miner lower redundancy and higher precision .
we directly compare focus to pam in section iv.
niu et al.
extract api usage patterns using api class or method names as queries .
they rely on the concept of object usage method invocations on a given api class to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
extract patterns.
the approach of niu et al.
outperforms upminer and codota a commercial recommendation engine in terms of coverage performance and ranking relevance.
in contrast focus relies on context aware cf techniques which favors recommendations from similar projects and uses the whole development context to query api method calls.
the ncbup miner non client based usage patterns is a technique that identifies unordered api usage patterns from the api source code based on both structural methods that modify the same object and semantic methods that have the same vocabulary relations.
the same authors also propose mlup which is based on vector representation and clustering but in this case client code is also considered.
deepapi is a deep learning method used to generate api usage sequences given a query in natural language.
the learning problem is encoded as a machine translation problem where queries are considered the source language and api sequences the target language.
only commented methods are considered during the search.
the same authors present codenn code description embedding neural network where instead of api sequences code snippets are retrieved to the developer based on semantic aspects such as api sequences comments method names and tokens.
with respect to the aforementioned approaches focus uses cf techniques to recommend and rank api method calls and usage patterns from a set of similar projects.
in the end not only relevant api invocations are recommended but also code snippets are returned to the developer as usage examples.
b. api related code search approaches strathcona is a recommender system used to suggest api usage.
it is an eclipse plug in that extracts the structural context of code and uses it as a query to request a set of code examples from a remote repository.
six heuristics associated to class inheritance method calls and field types are defined to perform the match.
similarly buse and weimer propose a technique for synthesizing api usage examples for a given data type.
an algorithm based on data flow analysis k me clustering and pattern abstraction is designed.
its outcome is a set of syntactically correct and well typed code snippets where example length exception handling variables initialization and naming and abstract uses are considered.
moreno et al.
introduce muse method usage examples an approach designed for recommending code examples related to a given api method.
muse extracts api usages from client code simplifies code examples with static slicing and detects clones to group similar snippets.
it also ranks examples according to certain properties i.e.
reusability understandability and popularity and documents them.
swim synthesizing what i mean seeks api structured call sequences control and data flows are considered and then synthesizes api related code snippets according to a query in natural language.
the underlying learning model is also built with the em algorithm.
similarly raychev et al.
a code completion approach based on natural language processing which receives as input a partial program and outputs a set of api call sequences filling the gaps of the input.
both invocations and invocation arguments are synthesized considering multiple types of an api.
thummalapenta and xie propose spotweb an approach that provides starting points hotspots for understanding a framework and highlights where examples finding could be more challenging coldspots .
other tools exploit stackoverflow discussions to suggest context specific code snippets and documentation .
viii.
c onclusions in this paper we introduced focus a context aware collaborative filtering system to assist developers in selecting suitable api function calls and usage patterns.
to validate the performance of focus we conducted a thorough evaluation on different datasets consisting of github and maven open source projects.
the evaluation was twofold.
first we examined whether the system is applicable to real world settings by providing developers with useful recommendations as they are programming.
second we compared focus with a wellestablished baseline i.e.
pam with the aim of showcasing the superiority of our proposed approach.
our results show that focus recommends api calls with high success rates and accuracy.
compared to pam focus works both effectively and efficiently as it can produce more accurate recommendations in a shorter time.
the main advantage of focus is that it can recommend real code snippets that match well with the development context.
in contrast with several existing approaches focus does not depend on any specific set of libraries and just needs oss projects as background data to generate api function calls.
lastly focus also scales well with large datasets by using the collaborative filtering technique that helps sweep irrelevant items thus improving efficiency.
with these advantages we believe that focus is suitable for supporting developers in real world settings.
for future work we plan to conduct a user study to thoroughly study the system s performance.
moreover we will embed focus directly into the eclipse ide.
acknowledgment the research described has been carried out as part of the crossminer project which has received funding from the european union s horizon research and innovation programme under grant agreement no.
.
moreover the authors would like to thank claudio di sipio for his hard work on supporting the evaluation of focus and morane gruenpeter for her hard work on collecting the dataset from the software heritage archive.