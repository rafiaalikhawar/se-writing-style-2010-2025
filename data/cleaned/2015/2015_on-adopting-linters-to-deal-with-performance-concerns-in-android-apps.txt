on adopting linters to deal with performance concerns in android apps sarra habchi inria university of lille lille france sarra.habchi inria.frxavier blanc university of bordeaux bordeaux france xavier.blanc u bordeaux.frromain rouvoy university of lille inria lille france romain.rouvoy inria.fr abstract with millions of applications apps distributed through mobile markets engagingandretainingend userschallengeandroiddeveloperstodeliveranearlyperfectuserexperience.asmobileapps run in resource limited devices performance is a critical criterion for the quality ofexperience.
therefore developers are expected to pay much attention to limit performance bad practices.
on the one hand many studies already identified such performance bad practices and showed that they can heavily impact app performance.
hence many static analysers a.k.a.linters have been proposed to detect and fix these bad practices.
on the other hand other studies have shown that android developers tend to deal with performancereactivelyandtheyrarelybuildonlinterstodetectand fix performancebad practices.in thispaper wetherefore perform a qualitative study to investigate this gap between research and developmentcommunity.inparticular weperformedinterviews with14 experiencedandroid developerstoidentify theperceived benefits and constraints of using linters to identify performance bad practices in android apps.
our observations can have a direct impact on developers and the research community.
specifically wedescribewhyandhowdevelopersleveragestaticsourcecode analysers to improve the performance of their apps.
on top of that we bring to light important challenges faced by developers when it comes to adopting static analysis for performance purposes.
ccs concepts software and its engineering software performance software maintenance tools keywords android performance linters static analysis.
acm reference format sarrahabchi xavierblanc andromainrouvoy.
.onadoptinglinters to deal with performance concerns in android apps.
in proceedings of the 33rd acm ieee international conference on automated software engineering ase september3 montpellier france.
acm new york ny usa 11pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
introduction mobileapplications apps arenowadayscomplexsoftwaresystems that must be designed carefully to meet the user expectations and stayaheadoftheappstorescompetition.reportsshowthat75 of appsareuninstalledwithin3months andthatthesecondtop reason of these uninstalls is poor performance .
therefore app developers are expected to pay a careful attention to performance in their development and particularly avoid performance bad practices.
previous studies have already identified and characterised different development practices that hinder the performance of mobileapps .researchersalsoassessedtheimpact of such bad practices on different performance aspects .
to detectthesebadpractices differentstaticanalysers a.k.a.linters like paprika perfchecker and adoctor w e r ep r o posed.
the development community also proposed tools to detect andfixthesebadpractices.forinstance androidstudio theofficial ideforandroiddevelopment integratesalinter calledandroid lint that detects performance bad practices.
however despite the availability of these linters and evidences of performance penalties due to bad practices android developers donotrelyheavilyonlinterstodealwithperformanceconcerns.asurveyconductedbylinarez etal.
with485androiddevelopers showedthat whenusingtoolstomanageperformance mostdevelopersrelyonprofilersandframeworktools andonly5participants reportedusingalinter.inordertoconfirmthisphenomenonand laythefoundationforourstudy wepublishedanonlinesurveyand askedandroiddevelopersabouttheirlinterusage.allthedetailsof the survey and its results are available in our technical report .
theresultsofthissurvey reportedthatonly51 ofandroidlint users rely on it for performance purposes.
given that performance checksareenabledbydefaultinandroidlint suchobservations raisemanyquestionsabouthow androiddevelopersperceivethe usefulnessoflinterswhenitcomestoperformance.inparticular it isimportanttohighlightthebenefitsandchallengesofadopting linters for performance issues.
inthispaper wethereforeconductaqualitativestudytoinvestigatethebenefitsandconstraintsofusinglintersforperformance purposes.weinterview14experiencedandroiddeveloperswho use android lint for performance purposes in order to understand why do android developers use linters for performance purposes?
what are the constraints of using linters for performance purposes?
it is also important to understand what fashions would allow androiddeveloperstoachievetheeventualbenefitsoflintersfor performance thus we also investigate the question authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france sarra habchi xavier blanc and romain rouvoy howdoandroiddevelopersuselintersforperformancepurposes?
ourfindingsfromthisstudyhavedirectimplicationstodevelopers researchers and tool makers.
the remainder of this paper is organised as follows.
we start with a brief background about linters for android in section thenwedescribeourmethodologyinsection .section 4reports and discusses the results of our qualitative study.
we identify in section5theimplicationsofourresults andinsection 6thelimitationsofourstudy.wepresentinsection 7therelatedworksbefore concluding in section .
background thissectionprovidesgeneralbackgroundinformationonlinters for android.
many linters like pmd checkstyle infer and findbugs can be used to analyse android projects written in java.
pmd detects programming flaws like dead code.
checkstyle checks that codingconventions are respected.
infer identifiesissuesaspotentialbugs nullpointerexceptions resource leaks etc.
findbugs analyses the java bytecode to detect potential bugs.detekt isalinterthatcanbeusedonandroidprojects written in kotlin.
it computes source code complexity and identifies some code smells.
ktlint is another linter for kotlin but that focuses on checking code conventions.
all the mentioned lintersdetectissuesrelatedtoeitherjavaorkotlin buttheydonot consider issues or practices specific to the android framework.
android lint is the mainstream linter for android.
it is integrated in android studio the official ide for android.
it can be run on android projects from the command line or in android studio interactively.
it scans the code to identify structural code problemsthatcanaffectthequalityandperformanceofandroid apps.
lint targets issues related to correctness security performance usability accessibility andinternationalization.thecategory performance includes checks 1a.k.a.rules.
as an example weexplaintherule handlerleak thatchecksifa handler isusedas non static inner class or not.
this situation is problematic because thehandlerholdsareferencetotheouterclass.thus aslongas thehandler is alive the outer class cannot be garbage collected thus causing memory leaks.
this issue has been addressed in some research studies as a code smell named leaking inner class .
androidlintreportseachproblemwithabriefdescriptionmessage apriority andaseveritylevel.thepriorityisanumberfrom1to andtheseverityhasthreelevels ignore warning and error.
all the android lint checks have a default priority and severity.
the severity is a factor that can be configured by developers to classify the problems on which they want to focus.
wechose touseandroidlintinthisstudyasit isthemostused linter for android and it detects a large set of performance bad practices.
methodology our objective is to investigate with an open mind the benefits and limitations of using a linter for performance purposes in android.
therefore we follow a qualitative research approach based on 1as for march .classic grounded theory concepts .
with this approach we aimtodiscovernewideasfromdatainsteadoftestingpre designed researchquestions.specifically weconductedinterviewswith14 experienced android developers.
the interview design and the selectedparticipantsarepresentedinsections .1and3.
respectively.
afterwards we transcribed and analysed the interviews as explained in section .
.
.
interviews as commonly done in empirical software engineering research we designedsemi structuredinterviews.thiskindofinterviewsconsistsofalistofstarterquestionswithpotentialfollowupquestions thatareaskedthroughout.wefollowedtheadvicesgivenbyhoveandanda etal.
todesignandconducttheinterviews.inparticular we paid a careful attention to explaining the objectives of the interviews.
we explained that interviews are not judgemental and we incited the participants to talk freely.
we asked open questions such as why doyou thinkthat lint isuseful forperformance purposes?
andweaskedfordetailswheneverpossible.wedesigned the interview with basically questions and depending on partic ipants replies weaskedadditionalquestionstoexploreinteresting topics.
the main questions are the following why do you use the linter to deal with performance concerns?
what are the benefits that you perceived with this usage?
how do you use the linter to deal with performance concerns?
how do you configure the linter?
do you use it individually or in a team?
in acollaborative project how doyouconfigure the linter to optimize the app performance?
do you integrate the linter in the build or ci?
why?
doyouchangethepriorityorseverityofperformancechecks?
why?
do you ignore or suppress performance checks sometimes?
why?
are there any performance checks that you consider irrelevant?
why?
do you write your own performance checks?
why?
in your opinion what are the constraints of using the linter for performance purposes?
withthepermissionofinterviewees theinterviewswererecorded and they lasted from to minutes with an average duration of minutes.weperformed two interviewsface to face andthe otherswereperformedwithanonlinecall.oneparticipantwasnotabletoparticipateinthecallandinsteadreceivedalistofquestions via email and gave written answers.
.
participants ourobjectivewastoselectexperiencedandroiddeveloperswho use the linter for performance.
we did not wantto exclude opensource software oss developers nor developers working on commercial projects.for thatpurpose werelied on manychannels to contact potential participants.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
on adopting linters to deal with performance concerns in android apps ase september montpellier france github.first we selected the most popular android apps on github relying on the number of stars.
afterwards we selected the projects that use the linter by looking for configuration files e.g.
lint.xml or configurations in gradle files.
then we manuallyanalysedthetop 100projectstoidentifythedeveloperswho actively work with the linter.
we only found developers thatcontributed to the linter configuration.
as it is complex to guess ifdevelopersaremotivatedtousethelinterforperformanceonly from the configuration files we contacted these developers to ask them if they use the linter for performance or not.
out of mails sent wereceived18answers i.e.
aresponserateof43 .13developers answered that they use the linter for performance and others answered negatively.
we replied to the developers to explain the objectivesof ourinterview andinvite themto participate.we received6acceptancesand2rejects theotherdevelopersdidnot answer.
forums and meetups.
to select commercial android developers wesentformsindeveloperforums .intheforms weexplicitly explained that we are looking for android developers who usethe linter for performance.
we received answers from forums of them was irrelevant because the developer did not have a real experience with android lint.
we also communicated thesame message in android development meetups.
from meetups we selected persons who satisfied our criteria.
overall thisselectionprocessresultedin14participants.after conducting14interviews weconsideredthatthecollectedinformation is enough to provide us with theoretical saturation i.e.
all concepts in the theory are well developed.
thus we did not perform a second batch of selection and interviews.
to keepthe anonymity ofthe selected participants we refer tothemwithcodenames.wealsoomitallthepersonalinformation like company or project names.
table 1shows the participants codes their experience in android and android lint in terms of yearsofprofessionaldevelopment andthetypesofprojectsthey workon.itisworthmentioningthatwiththeterm commercial werefertoprojectsthataredevelopedinanindustrialenvironment andarenotbasedonanopen sourcecommunity.alsowefound that all the developers selected from github were also involved in commercialprojects andtwodevelopersspottedfromforumswere involved in both commercial and oss projects table1showsthat outof14participants 11have morethan5 yearsofexperienceinandroid.comparedtotheageoftheandroidframework 8years thisexperienceisquitestrong.asforandroidlint whichhasbeenintroducedwithandroidstudioin2013 10of our participants have more than four years of experience in using it.
.
analysis we carefully followed the analytical strategy presented by schmidt et al.
which is well adapted for semi structured interviews.
thisstrategyhasproveditselfinthecontextofresearchapproaches that postulate an open kind of theoretical prior understanding but donotrejectexplicitpre assumptions .beforeproceedingto the analysis we transcribed the interviews recordings into texts using a denaturalism approach.
the denaturalism approach allows us to focus on informational content while still working for a fulltable partcipants code name years of experience in android and android lint and the type of projects they workon participant android lint project code experience experience type p1 oss commercial p2 oss commercial p3 commercial p4 oss commercial p5 oss commercial p6 oss commercial p7 oss commercial p8 oss commercial p9 commercial p10 commercial p11 commercial p12 commercial p13 commercial p14 oss commercial and faithful transcription .
in what follows we show how we adopted the analytical strategy steps.
.
.
formmaterial orientedanalyticalcategories.
inthisstep wedefinethesemanticcategoriesthatinterestus.inourcase we investigatethemotivationandargumentsofandroiddevelopers thatusethelinterforperformancepurposes andtheconstraints of such usage.
therefore our categories are initially the following two topics whydoandroiddevelopersuselintersforperformancepurposes?
what are the constraints of using linters for performance purposes?
after our discussions with participants we noticed that an additional category is highlighted by developers namely howdoandroiddevelopersuse lintersforperformancepurposes?
we found this additional topic enlightening thus we included it inouranalyticalcategories.oncethecategoriesareset wereadand analysed each interview to determine which categories it includes.
in the analysis we do not only consider answers to our questions but also how developers use the terms and which aspects theysupplement or omit.
after this analysis we can supplement or correct our analytical categories again.
.
.
assembletheanalyticalcategoriesintoaguideforcoding.
weassemblethecategoriesintoananalyticalguide andforeach category different versions are formulated.
the versions stand for differentsubcategoriesidentifiedintheinterviewsinreferenceto oneofthecategories.inthefollowingsteps theanalyticalguidecan betestedandvalidated.indeed thecategoriesandtheirversions may be refined made more distinctive or completely omitted from the coding guide.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france sarra habchi xavier blanc and romain rouvoy .
.
codethematerial.
atthisstage wereadtheinterviews and try to relate each passage to a category and a variant formulation.aswefocusonlabellingthepassages wemayomitspecial features and individualdetails of each interview.yet these details will be analysed and highlighted in the last step.
to strengthen the reliabilityofourconclusions weuseaconsensualcoding.therefore eachinterviewiscodedbyatleasttwoauthors.initiallyevery author codes the interview independently afterwards the authors discussandcomparetheirclassification.incaseofdiscrepancies the authors attempt to negotiate a consensual solution.
results we present in table 2the results of the coding process in order to contribute to the transparency and verifiability of our study.
.
why do android developers use linters for performance purposes?
.
.
linter helps developers to learn about the framework.
as theandroidframeworkisrelativelyyoung developersareeager tolearnaboutitsunderlyingperformanceconstraints.
half ofthe participants stated that the linter is very instructive in that respect p1 p2 p3 p7 p9 p10 p11 .
lintwillactuallyhelpyoubecomea betterandroidprogrammer p3 .indeed theperformancechecks ofthelintermentorthedeveloperstousetheframeworkefficiently iseetheperformancechecksasaguideoftheandroidframework p7 .
other participants mentioned that their understanding of performance and their programming habits evolved thanks to the linter everytime i learn a new thing about performance and then it becomesahabit p11 .asanexampleofthesecases participantp9 mentioned drawallocation abadpracticethatconsistsofallocating newmemoryspacesinthe ondraw method iwascreatinganew object in a paint method so lint gave me a warning.
that was the first and last time i see it because now i pay attention to this p9 .
someparticipantsemphasisedthatjuniorandroiddevelopers should particularly use the linter for performance lint checks are extremelyusefulforhelpingoutbeginnerandroiddevelopersorjunior membersofmyteamtoenforcebettercodeperformance p2 .indeed junior android developers even if they have a prior experience in desktop development may lack understanding of mobile frameworkspecificities.thus theyarepronetoperformance relatedbad practicesandtheyneedthelintertolearnhowtokeeptheirmobile apps efficient.
discussion.
participantsfrompreviousstudieshavealsoreported that learning is one of the main benefits of using linters .
specifically thedeveloperslearnedwiththelinteraboutthesyntax of the programming language idioms or libraries.
in the case of ourstudy theparticipantsshowedthatevenimportantconcepts about the android framework can be learned through the linter.
this can be a great incentive for android developers to use linters with performance and other framework related checks.
.
.
lintercananticipatesomeperformancebottlenecks.
many participantsreportedthatthelintersupportsthemindetectingbad practices that can cause performance bottlenecks p1 p2 p5 p6 p10 p13 .
lint is very useful to tell in advance what is going wrong p1 .theparticipantsstatedthatthelinter isveryefficientindetecting code level performance issues lint is very good at finding patterned issues that follow a specific rule and can be solved very simply p2 .whenaskedwhytheywanttoanticipateperformance problems theparticipantsreportedthatperformanceissuesshould notbenoticedbyusers itisalwaysbettertodetecteventualproblems before they are reported by end users or managers.
p10 .
in fact when end users notice performance issues they can uninstall theapporgivebadreviews andfromthereitcanbehardtogain back users confidence.
moreover the participants explained that oncebottlenecksarereported byusers itcanbecomplex toidentify their root cause and fix them.
by using lint we try to detect performance issues as soon as possible because when they occur theyaregenerallyverydiffusesoitishardtodetectthemwiththeprofiler p5 .for instance wheni have8 threadswith cross threadmethod calls locatingaproblemwiththeprofilerbecomesverydifficult p5 .
in that respect anticipating performance bottlenecks saves also time for developers.
discussion.
previous studies have shown that developers prefer to manage performance reactively and hence to wait the problems to occur before handling them with the objective to gain time .
here our participants express a different point of view.
they ex plain that when performance bottlenecks occur they require somuch time and effort to be fixed.
they are hence in favour of a more pro actively approach that aims to detect and fix bottlenecks before they occur.
it is important to transmit this information to developerscommunity andespeciallynoviceandroiddevelopers.
the latter may be unaware of the complexity of locating and fixingperformancebottlenecks thustheycanmakewrongstrategic choices.
as there should be a trade off between reactive and proactiveapproaches wealsoencouragefutureworkstomakerealworld comparisons between them.
.
.
linter is easy to use.
many developers said that they use the performance checks of android lint because they found it simple and easy to use p2 p4 p6 p8 p11 p14 .
indeed android lint isalreadyintegratedintheideandallthechecks includingperformance are enabled by default it is built into android studio the checks performed by the linter appear automatically so we get those benefits just kind of immediately through the syntax highlighting p2 .
hence the usage ofthe linter isseamless and effortless it is just built into the tooling so well and so seamlessly and it does not really cost me anything to have lint running p2 .
the participants also appreciated the integration in other development tools we can easily integrate it in the gradle and continuous integration so we can ensure that performance and other lint checks are respected p6 .
discussion.
thisbenefitismorerelatedtotheuseofthelinter itselfratherthantoperformanceconcerns.previousstudiesshowed that static analysers should be easy and seamless to encourage developerstousethem .ourfindingsconfirmthisasparticipants stated clearly that they use the linter because it does not cost them anything.
now androidlint has anadditional privilege bybeing integrated in the official ide and activated by default and this motivated developers to adopt it.
this fact aligns with previous works where researchers suggested that the integration in the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
on adopting linters to deal with performance concerns in android apps ase september montpellier france table results of the coding process.
categories versions subcategories p1 p2 p3 p4 p5 p6 p7 p8 p9 p10 p11 p12 p13 p14 benefitslearn about the framework xxx x xxx anticipate performance bottlenecks xx xx x x the linter is easy to use x x x x x x develop the performance culture x x x x save time xx x contribute to credibility and reputation x xx raise awareness of app performance x x ease performance debugging x fashionsintegrate from scratch x x xxx x target milstones x xxx adopt performance sprints x x improve performance incrementally x support individual development x x x xx x x check performance rules in a team x x xx xx x x prioritise performance aspects xx xx x x constraintsstatic analysis is not suitable for performance xxxx x x nobody complained x xxx xx x we do not have time x xx performance is not important in our case x x x some rules are irrelevant x x results are not well presented x x x x xx the linter lacks precision xx x the linter does not have enough checks xx x it is difficult to write new rules x development workflow helps static analysers to accumulate the trust of developers.
.
.
lintercandeveloptheperformanceculture.
indevelopmentteams developerscanhavedifferentperceptionsandlevelsof interestregardingperformance.thus itsoundsimportanttorely on a linter for enforcing performance good practices p1 p5 p7 p10 .theuseofalinterensuresthatallteammembersfollowthe same performance guidelines we have to make sure that everyone respects the rules and understands why we are using the performance checksoflint p10 .ontopofthat theperformancechecksthat willoccurwillcertainlybethesourceofdiscussionsamongteam members theobjectiveistoshareandlevelourknowledgeonperformance.
when lint reports performance problems we can disagree with each other on whether to consider it or not so we will discuss andunderstandtheproblem thenmakeawisedecisionaboutit p5 .
that being said the usage of the linter at a team level is fruitful in many ways.
on one side it allows to keep all the team members at the same page about performancechoices.
besides it arises discussions about performance and thus enriches the performance culture in the team.
discussion.
previousstudyshowedthatdevelopersusethelinter to have an objective tool that avoids endless discussions about codestyle .thestatementsofourparticipantsshowthatthe linteritselfcantriggerdiscussionsinthecontextofperformance.
unlikecodestyle performanceisanimportantaspectthatrequires adeepthinkingfromdevelopersespeciallyinthecontextofmobileapps.
hence it is normal that developers appreciate the discussions triggered by the linter about it.
.
.
lintercan savethe developer stime.
someparticipants explainedthattheyusethelintertoautomatetime consumingtasks p2 p3 p9 .inparticular thelintercanfillinforrepetitivetasks lint helps you to save time in a lot of ways.
one that comes to my mindistheidentificationofunusedresources.thelintersavesmea lot of time as i don t have to cross check all resources manually p2 .
indeed keeping unused resources is a performance bad practice thatincreasestheapksize.developersusedtomanuallycheckand remove all the useless resources which can be tedious and error pronewhentherearemanyresourcesandwhentheappisbuiltwith many flavors.
using android lint to detect unused resources then helpsdevelopersandsavestheirtime.anothertaskwheretheusageoflinterhelpssavingtimeiscodereview itisaquickandeasycode review.itgivesyouabunchofinformation.now whetheriwantto implementthosemessagesornot thatisanotherdecision p3 .code reviewisanimportantrepetitivetaskinsoftwaredevelopmentthat can be very time consuming especially at team level.
as stated by the participants the linter can partially automate this task so that developers do not have to review trivial performance issues and can therefore focus on important aspects.
discussion.
lintersarealsoknownforsavingtimeincontexts whereeventualissuescanbeautomaticallydetected e.g.
bugdetection .theparticularityofthecasesreportedbyourparticipants isthatontopofsavingtimebydetectingeventualissues thelinterautomatesrepetitivetasks.asthesetasksareconcreteandconcernalltypesofandroidapps thiscanbemoreappealingfordevelopers to adopt the linter.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france sarra habchi xavier blanc and romain rouvoy .
.
linter contributesto increase credibilityand reputation.
developersalwayswanttomaintainagoodreputationamongtheir peers and the linter can help them to do that p1 p6 p7 .
first developers need to keep their credibility among colleagues i have to use lint before making a release to make sure that my work meets the expectations of my superiors and colleagues p6 .
another context where reputation is important is open source projects before releasing code to open source i am required to check that all the warningsareawayandthatmycodehasahighquality p1 .
p7 added i work on a company where we do some open source projects.
beforepublishingcodeialwayshavetorunthelintertomakesureof not making obvious performance mistakes.
this impacts not only my credibility but also the image of the company p7 .
discussion.
sinceperformanceiscriticalinandroidapps making obvious mistakes can seriously affect the credibility of the developer among her peers.
hence the linter performance rules can giveavaluablesupportforandroiddeveloperstomaintaintheir reputation.
.
.
linterraisestheawarenessoftheappperformance.
android apps are nowadays very complex software systems and it is hard fordevelopers tobeaware ofthe implicationsof theirdevelopment choices in terms of performance.
some participants stated thattheyusethelintertoalwaysbeawareoftheirappperformance p3 p5 .
sometimeslintwillcatchperformanceaspectsthatididnot reallythinkabout andsoitwillgivemeatimeoramomenttothinkaboutanddecide p3 .thisshowsthatthelintermessagesincitedevelopers to carefully think and give more attention to performance.
this awareness can be particularly important when developers are workingaloneontheproject ifiamtheonlydeveloper formethis thinkingiscriticalandlintisamust have p3 .thisappliesalsoto the cases where the issues reported by the linter are not applicable insomecasesiamnotabletoapplythechangesrequestedbylint.
butstillineedtohaveagoodandvalidreasonforthis.soiamaware of the trade off i made p5 .
discussion.
itisimportanttodistinguishtheawarenessofapp performancewiththelearningofperformancegoodpractices.here the linter incites the developers to think and understand their app performance.
when developers understand their apps they can make decisions or solve eventual problems more easily.
.
.
lintereasesperformancedebugging.
someparticipants didnotonlyusethelintertodirectlyimproveperformance buttheyalsoobeyednon performancerulestoensurehighcodequality and consequentlyeaseeventualperformanceprofilinganddebugging p9 .
by using lint and other static analysers like sonar i ensure thatmycodeiswelldesignedandreadable.sowhenaperformance issueisreported debuggingandprofilingbecomeseasier.ialsocan easilyandquicklyapplythefixes p9 .thelinterthenalsohelps tobuildcleanandmaintainableappsthatfurtherdeveloperscan easily debug and refactor for improving performance.
discussion.
thisrepresentsabenefitofusingthelinteringeneral and not related to the usage of performance checks.
however itis still interesting to observe that some developers have a deep understandingofthesoftwaredevelopmentprocess.linterscannotpreventallperformancebottlenecks bugsorotherissues.therefore developers should always keep their code clean and maintainable because it makes further maintenance operations easier.
.
how do android developers use linters for performance purposes?
.
.
linterintegratesalongtheprojectlifecycle.
theparticipants reported different strategies to use the linter through the projectlifecycleinordertokeeptheirappseffective.intheremainder we report on the strategies they identified.
integratingfromscratch.
manyparticipantsreportedthatthey preferusingthelinterfromtheprojectstartup p2 p5 p9 p10 p11 p13 .
participant p5 explained that when starting a project fromscratch she tries to keep the code very clean by considering allthe lint checks.
when asked about the configuration adopted inthis case the participants said that they keep the default config uration provided by the linter in this situation i do not need any additional setting lint is configured by default p9 .
we also asked these participants about the motivation behind this strategy.
they explainedthat whentheprojectadvanceswithoutthelinter itis more difficult to control performance a posteriori.
for instance we hadacasewhereweretrievedaprojectthatwasbuiltbyanotherteam withoutlint.wehavegotthousandsoferrorsandwarnings.sowe werelessmotivatedtoputbacklintandrecovertheappperformance p7 .
indeed it is easy with this strategy to motivate developers torespectperformancechecksbecausethecodebaseiscleanand there is no existing debt to tackle.
targetingmilestones.
fiveparticipantsmentionedthattheyextensively use the linter at the end of features or for releases p1 p5 p6 p7 .
i neveruse lintin thebeginning of theproject orwhile prototyping.
i use it for releases to make sure that my code meetsthe expectations p6 .
as for features towards the end of adding a new feature i will run through lint then i will go through all of themandideterminewhetherornotiwanttospendthetimetodo it p3 .
when asked about the configuration used for this strategy participantp5stated wehavedifferentlintprofiles intherelease profileweactivateadditionalrules .thisstrategyallowsdevelopers to go fast while producing new features or prototyping without hindering the final app performance.
adopting performance sprints.
two participants reported that they dedicate sprints for improving the app performance p5 p12 .
participant p12 stated while working we do not have concrete performance objectives.
but when we notice that the app starts lagging wedecidetodedicatetimeforthisandimprovetheappperformance .
asforparticipantp5 generallywhilecoding wetrytorespectthe performance checks just as other lint checks.
then we regularly program performance sprints and there we will be specifically interested inperformancerules .whilethestrategyreportedbyparticipant p12ispurelyreactive thestrategyofparticipantp5isstillproactive.
improving performance incrementally.
one participant explained howshedealswithlegacycodewherethelinterwasnotusedbefore p9 .
iconfigurelinttoincrementallyincreasetheappperformance.
i define a baseline then i work to decrease this baseline progressively.
ialsotrytoensurethatthenewcodeisalwaysmoreeffectivethanthe old one p9 .
android lint allows to define a baseline file i.e.
a authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
on adopting linters to deal with performance concerns in android apps ase september montpellier france snapshotofthecurrentwarningsoftheproject.thebaselineallows touselintwithoutaddressingoldissues.whenaskedabouthow theincrementalimprovementhappens theparticipantp9replied i change the severity of some checks for example i configure some rules to block the compilation .
discussion.
integratingthelinterfromprojectstart upiscommonly advised .
moreover previous studies show that developersarelesslikelytofixthelinterwarningsonlegacycode .
the statements of some participants are aligned with this common wisdom.however thestrategies b and c showthatdevelopers can adopt the linter differently according to their work style.
in particular developerswhoareprototypingorareinrushtorelease can adopt strategy b and apply the linter after finishing their core development.
interestingly developers who prefer to manage performance reactively can also leverage the linter by following strategy c .finally strategy d showsthattheconfigurabilityof the linter maximises its chances to be adopted.
.
.
linter can be used under different settings.
some participants reported using the linter individually while others explained how they use it with their team.
supportingindividualdevelopment.
halfoftheparticipantsreportedthattheusageofthelinterwasapersonalchoice p1 p3 p5 p8 p9 p11 p13 .
ionlyrunlintasmyselfaspartofareviewthat i want to do p3 .
these participants usually use it from the ide interactively it is through android studio interactively p13 .
checking performance rules in a team.
other participants reportedthattheusageofthelinterforperformancepurposeswas requiredonateamlevel p2 p4 p6 p7 p9 p10 p12 p14 .
inthe team lintavoidsaccumulatingproblems.wehaveadefinedsetof rulesandeveryteammembermustrespectthem p10 .inthiscases thelinterisgenerallyastepinthecontinuousintegrationchain it is set up with continuous integration so lint runs after every commit and you will get a report.
then you can choose to look at it or not p2 .
discussion.
thereportedsettingsofusingthelinterdonotapply exclusively for performance.
the participants explanations underlinetheimportanceofthelinterinteractivityandintegrationinthe development workflow.
.
.
linter prioritises performance aspects.
many participants said that while they use the linter they prioritise performance related issues p2 p3 p5 p6 p9 p13 .
for instance there are so manydifferentchecksbutiwouldsayperformanceusuallycatchesmyeye p2 .someparticipantsgavealsodistinctprioritiestodifferent performance aspects if it is anything about threading i will take a look at it and review it before deciding if i want to fix it or not p3 igivesomuchimportancetouiperformanceandallmemory related issues p13 .someparticipantsexpressedtheseprioritieswitha configuration i changed the severity of rules that interest me so they block the compilation p9 .
discussion.
eachappcanhavedifferentspecificitiesandneedsin termsofperformance.thankstoconfigurability thelintercanhelp developers to focus on performance aspects that sound relevant and critical for them.
.
what are the constraints of using linters for performance purposes?
theconstraintsreportedbyparticipantswerestructuredaround two main topics i social challenges and ii tool limitations.
.
.
linter faces social challenges.
the participants reported cultural elements that make the use of linter for performance challenging.
the participants encountered these issues in their work environment with colleagues or superiors.
static analysis is not suitable for performance.
many participants described that developers generally think that static analysis is not suitableforimprovingperformance p1 p2 p3 p4 p7 p12 .partici pantp1stated ithinkthatthereisagapinunderstandingwhystatic analysis is useful forperformance .
participants explained thatthis mindset is due to the nature of static analysis because lint is only looking at the code.
some developers feel that there should be a better tool that analyses the app while running p3 .
other participants thought this gap is due to the complexity of performance issues for the actual real world bottlenecks that most apps face it is not the lintthatwillhelpyou.performanceissuesareverycomplicatedor have multiple causes that cannot be pinpointed to a one line of java code p2 .
participant p4 stated that this gap may be due to the confusionoftheterm performanceissue foreachperformance issue there is a root cause and an observation.
the term performance issueisoftenusedtorefertoboth.butitisnecessarytodistinguish them.thedefaultlintrulescontainsomebasicandtrivialrootcauses which could statically be identified.
but in some cases you have an observation and you cannot guess the root cause.
so here lint cannot help you.
to sump up lint requires you to define in advance what youarelookingfor itishardtouseittomatchtheobservationand the cause .
nobody complained.
many participants reported that they regularly deal with colleagues and superiors who believe that performanceshouldbemanagedreactively p1 p3 p4 p5 p8 p9 p12 .
for example participant p5 stated that the common rule in her environmentis onlywhenthesuperiorsortheend userscomplain thattheappislaggingornotsmooth wesayokwehavetocareaboutperformance .participantp5highlightedacasewherethispressure came from a superior performance refactoring is a back office task that the product owner cannot see.
it is hard to negotiate these tasks .
some participants underlined that this mindset is particularly tied to performance more than any other software quality aspect with performance you do not want to do a lot you want to make sure that you are really looking at the issue and not trying to over optimise the code p3 .
wedonothavetime.
thismindsetisveryrelatedtotheprevious one.however weobservedcaseswherethedevelopersexplainthat the performance checks of the linter are not considered only for time constraints without any explicit agreement on the management of performance reactively p1 p6 p7 .
participant p1 reports observing this mindset in many companies why waste time on performancerules?letusmoveaheadandwewillfigureaboutthis later.unfortunatelythatlaterneverehappens orcomesonlywhen the problem is big enough .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france sarra habchi xavier blanc and romain rouvoy performanceisnotimportantinourcase.
someparticipantsreported working in contexts where performance was considered irrelevant p1 p8 p12 .
participant p1 reports experiencing this situation in young projects when you build a small app and do not know whether it will scale or not it does not seem useful to spend timeinmakingsurethatstaticanalysisofperformanceisdoneright .participant p8 described a case where performance was consideredirrelevantforatypeofapps wedidverybasicappdevelopmentand not particularly hardware based development.
we developed uberclones and all those apps did not require any specific performance from the device .
the linter rules are irrelevant.
two participants described that someperformancechecksareconsideredirrelevant p2 p12 .participantp12gaveexamplesoflintperformancerulesthatdonot reallyhaveanimpact overdrawisarulethat usedtoberelevanta long time ago but now with powerful smartphones it is not anymore.
moreover the android system detects all these trivial issues and fixes themautomatically.developersareobsessedwithoverdraw itbecame a cult actually but this is not what really hinders the performance ofyourapp .theproblem overdraw occurswhenabackground drawable is set on a root view.
this is problematic because thetheme background will be painted in vain as the drawable will completely cover it.
discussion.
calcagno etal.
have alreadyreferredto thesocial challenge while describing their experience in integrating astatic analyser into the software development cycle at facebook.
someofthereportedchallenges e.g.
wedonothavetime apply tolinters ingeneral.however theothermindsetsare particularly resistanttotheuseoflintersforperformance.thebeliefthatstatic analysis is not suitable for performance seems to be prevalent six participants mentioned it explicitly.
developers are used to linters as tools that report minor issues like styling violations and deprecations.theyarenotawareenoughofthecapabilitiesofstatic analysisindetectingperformanceissues.toolmakersshouldput moreeffortsoncommunicatingaboutlintersastoolsthatcanaccompanydevelopersindifferentdevelopmentaspects.themindset that performance should be managed reactively confirms previous observationsaboutandroidappsdevelopment .thisfinding shows that android developers stilllack understanding about the implicationsofperformancebottlenecks.asforlinterrulesthatare consideredirrelevant thisincitestheresearchcommunitytodig deeperintotheimpactofthesepractices.formanybadpractices likeoverdraw westilllackprecisemeasurementsoftheirpenalties on performance in real world contexts.
.
.
linter suffers from limitations.
the participants reported several linter limitations that make it complicated to use it for performance purposes.
notwellpresented.
severalparticipantsmentionedthatthelinter rulesarenotwellorganisedorexplained p1 p4 p6 p11 p13 p14 .
interestingly three participants said explicitly that for a long time theydid not even knowthat androidlint hadperformance related checks p1 p11 p14 ididnotknowtherearedifferentcategories in lint.
for me it is just lint i do not distinguish between them p1 .
furthermore participantp14explainedthatinthebeginningshe did not know that some rules are related to performance and thusshetreatedthemasotherchecksliketypography.otherparticipants complainedabouttheunclarityofthemessages itisnotalways clear for example performance checks about graphics i cannot really understand them at all .
on top of that some participants found that rules are not well organised there is a hierarchy with levels of importance butifindituseless itdoesnothelpme.soifiwanttofocus only on performance aspects i have to search everywhere p6 .
the same participant underlined the unclarity of the priorities given by the linter to the checks i try to obey but i do not really understand thelogicbehindthepriorityandseverity .indeed androidlintdoes not give explanations about the priority and severity attributed to each check so we cannot understand the rationales behind them.
imprecision.
some participants complained about the imprecisionofthedetectionperformedbythelinterforperformancechecks p9 p10 p13 .participantp9describedsituationswherethecode contained a performance bad practice but the corresponding lintercheckwasunabletodetectit insomedrawingmethods iwascalling a method that called another one that made an intensive computing with memory allocations.
lint did not detect this as drawallocation it actually does not look so deep into the code .
other participantsreported false positives in performance checks.
participant p13 said iregularlyhavefalsewarningsaboutunusedresourceswhen theresourceisusedviaalibrary andparticipantp10stated lint indicates an unused resource but the image is actually used with a variable .
poverty.some participants mentioned that the linter is not very rich with performance checks p5 p6 p9 .
participant p5 stated i do not see so many performance related lint checks.
and the existing ones are so generic .
in the same vein participant p9 said i rarely see suggestions or important warnings about performance aspects.
very few!
.
furthermore the participants complained about the absence of linter checks for kotlin p6 p9 .
the difficultyof writingnew rules.
participant p2describedher trial to write a linter check and the difficulties she faced i wanted towritespecificlintrulesandafterafewtrialsiendedupdiscovering that it is difficult to define something general enough to warrant a lintcheck.also theeffortputintobuildacustomlintcheckispretty high.
that is why it is not a common tactic for development teamsespeciallyonaperprojectbasis .theparticipantpointedalsothe complexityofusingthecreatedruleinateam tobuildalintcheck then distribute it to the team then have the whole team use it is difficult .
discussion.
thefactthatatleastthreeparticipantsreportedthat for a long time they used the linter without noticing that it has performance checks was striking.
tool makers have to work more on showcasing different checks categories.
also the linter messagesshouldhighlightmoretheimpactofperformancepractices tomotivatedeveloperstoconsiderthemseriously.theimprecision is a common limitation of linters and performance checks are no different in that respect.
similarly the participants statements about the difficulty to write linter rules align with previous works .asmanyothertools androidlintprovidesthepossibilitytowritenewrulesbutthistaskiscomplexandtime consuming.
thus developers are not motivated to write their own rules.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
on adopting linters to deal with performance concerns in android apps ase september montpellier france implications wesummariseinthissectiontheseveralimplicationsofourresults for developers researchers and tools creators.
our findings are based on the usage of linters for performance purposes in android.
nevertheless they can also apply to other development platforms.
.
for developers our results provide motivations for developers to use linters for performance and show them how to maximise their benefits.
.
.
benefits.
developerscanfindseveralbenefitsinusingthe linter for performance.
in particular developers can use the linter with performance checks to learnaboutthemobileframeworkanditsperformanceconstraints anticipate performance bottlenecks that can be arduous to identify and fix develop the performance culture in the team save time by automating concrete repetitive tasks save their reputation among peers increase their awareness and understanding of their apps performance.
developers should also be aware that the usage of the linter is seamlessandcanbeintegratedinalongthedevelopmentworkflow.
.
.
usage fashions.
our participantsrecommend touse the linter for performance in the following ways from project startup to motivate developers to keep the code clean only before releases to dedicate the early development stages only for prototyping and making the important features in performance sprints developers can configure the linter to focusonlyonperformanceinsomesprints.thisapproachworks also for developers who prefer to manage the performance reactively improveperformanceincrementally developersshouldconfigurethelintercarefullyonlegacycodetoavoidchaosanddevelopers discouragement individuallyinaninteractivewayintheideorinateamwith the continuous integration prioritising performance aspects developers can configure the linter to focus on performance aspect that interest them and fit with their app needs.
.
for researchers our findings confirm hypotheses from several previous works and open up perspectives for new research directions we confirm that the mindset of managing performance reactivelyisprevalent .asthereshouldbeatrade offbetween reactive andproactive approaches weencourage futureworks to make real world comparisons between them ourstudyshowsthatsomeandroiddevelopersareindifferent to performance bad practices.
future studies should further investigate this observation using quantitative methods.
somedeveloperschallengetherelevanceandimpactofperformancebadpractices.
wethereforeencouragefutureworkstoinvestigate and provide precise evidences about the impact of such practices.
some developers are eager to consider more performancerelated checks.
this should incite researchers to identify and characterise more practices that can hinder the performance of mobile apps.
.
for tool creators our findings confirm the importance of some linter features and highlight new needs and challenges our findings align with previous works that suggest that simplicity and integration in the development workflow help static analysers to increase the trust of developers .
we encourage tool creators to ease the integration of their linters in development tools our findings show that linters should be more clear and explicit about the categories of checks.
clarity is also required in the explanationsofthepotentialimpactsofperformancechecks.we cannot expect from developers to seriously consider the rules if wedonotprovideenoughinformationabouttheirnatureandimpacts providing the possibility to write linter rules is not enough.
writing a linter rule should be simple and less time consuming to motivate developers to do it tool makers should put more efforts in communicating about the capabilities of static analysis in detecting performance bad practices given the benefits reported by participants we invite more tool makers to include performance related checks in their linters.
threats to validity we discuss in this section the main issues that may threaten the validity of our study.
transferability.
onelimitationtothegeneralisabilityofourstudy is the sample size.
the sample size is not large and thus it may not berepresentativeofallandroiddevelopers.toalleviatethisfact we interviewed highly experienced android developers.
nonetheless thisselectionmayalsointroduceanewbiastothestudy.as a matter of fact the benefits and constraints reported by junior android developers can be different.
we would have liked more participants.
however transcribing interviews is a manual and time consuming task.
hence having more interviews may involve more workload and would affect the accuracy and quality of the analysis.
we found our results valuable and enough for theoretical saturations.
the study conducted by t masd ttir et al.
which we discuss in our related works approaches a similar topic with asimilarsamplesize 15participants .anotherpossiblethreatisthat we only interviewed android developers who use the linter forperformancepurposes.androiddeveloperswhousethelinter withoutperformancechecksmayalsohavetheirwordtosayabout thelimitationsofusingalinterforperformance.thus morestudies should be conducted to understand why some android developers usethelinteranddisableperformancechecks.aswefocusedour study on android lint our results cannot be generalisable to other android linters.
however we believe that the choice of android lint was sound for two reasons.
first it is a built in tool of an droid studio and is activated by default thus a large proportion authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france sarra habchi xavier blanc and romain rouvoy of android developers should be using it.
this fact was confirmed in our preliminary online survey where of the participants who used the linters were actually relying on android lint .
secondly it is the only linter that has performance checks specific to the android platform and this detail is the core of our study.
credibility.
one possible threat to our study results could be the credibilityofparticipantsanswers.weintervieweddeveloperswho haveastrongknowledgeaboutthe topic.however wecannotbe sure that their answers were based on real experience or knowledgeacquiredfromexternalresources.toalleviatethisissue we tried always to ask for details and relate to developers project and workingenvironment.also weemphasisedbeforetheinterviews that the process is not judgmental.
confirmability.
one possible threat could be the accuracy of the interviews analysis and particularly the coding step.
we use a consensual coding to alleviate this threat and strengthen the reliability ofourconclusions.eachinterviewhasbeenencodedbyatleasttwo authors.
initially every author coded the interview independently to avoid influencing the analysis of other authors.
afterwards the authors discussed and compared their classifications.
related work mobile performance bad practices.
mobile performance bad practices a.k.a.
code smells have been addressed in various studies.manystudiesinvestigatedtheenergyaspect theyconsidered code smells related to networking sensors non sleep and general .whileallthesestudiesreliedonapprepositories and forums linarez et al.
used power profiling and api calls analysis to identify energy code smells.
other studies focused onidentifyingandcharacterisingmobileperformancesmellsandde tectingthem.guo etal.
studiedresourceleaksinandroidapps.
theyproposedthereldatooltodetectresourcesthatareexclusive memory consuming orenergyconsuming.liu etal.
studied performance bugs from eight android apps and identified their characteristics and common patterns.
they also implemented perfchecker astaticanalyserthatdetectstheidentifiedperformance bugs.
the main identified bugs are lengthy operations in the main thread wasted operations for gui and frequently called heavycallbacks.
for bug characteristics they found that performancebugs are more difficult to debug and fix than non performance bugs.intermsofdebugging profilersandperformancemeasurement tools have demonstrated to be more helpful than traditional stacktraceinformation.additionally worksthatproposedcatalogs ofmobile specificcodesmellsalsoincludedperformancerelatedissues .asmobileperformancesmellswereidentified researcherswereinterestedinassessingtheirrealimpactondifferentperformanceaspects.hecht etal.
conductedanempiricalstudy abouttheindividualandcombinedimpactsofthreeandroidperformance smells.
they measured the performance of two apps withandwithoutsmellsusingthefollowingmetrics frametime number of delayed frames memory usage and number of garbage collection calls.
the measurements showed that refactoring themember ignoring method smell improves the frames metrics by .
.
carette et al.
studied the same code smells but focused ontheenergy impact.theyanalysed5open source androidappsand observed that in one of them the refactoring of the three code smells reduced the global energy consumption by .
performancemanagement.
linarezet al.
surveyeddevelopers to identify the common practices and tools for detecting and fixingperformance issuesin androidopen source apps.based on 485answers theydeductedthatmostofdevelopersrelyonreviews andmanual testingfordetectingperformance bottlenecks.when askedabouttools developersreportedusingprofilersandframework tools only five of them mentioned using static analysers.
developerswere alsoopenly questionedabout thetargetsof their performanceimprovementpractices.from72answers thestudy established the following categories gui lagging memory bloats energy leaks general performance and unclear benefits.
with the aim of helping developers understand and predict performanceproblems in mobile apps.
nistor et al.
proposed suncat a tooled approach that based on a run with small inputs explainshow would an app behave with large inputs.
in five apps suncat identified usage scenarios and five confirmed performance problems.
qualitative studies on linters.
t masd ttir et al.
conducted aqualitativestudytoinvestigatethebenefitsofusinglintersina dynamicprogramminglanguage.theyinterviewed15developers to understand why and how javascript developers use eslint in oss.
they found that linters can be used to augment test suites theysparenewcomers feelings whenmaking theirfirstcontribution andsavetimethatgoesintodiscussingcodestyles.christakis and bird conducted an empirical study combining interviews and surveys to investigate the needs of developers from static analysis.
among otherresults they found thatperformance issues are thesecondmostseverecodeissuesthatrequireanimmediateinterventionofdevelopers.performanceissueswerealsointhetopfour needs of developers.
johnson et al.
conducted interviews to understandwhy developers do notuse static analysistools like findbugs to find bugs.
they found that all the participants are convincedbythebenefitsofstaticanalysistools.ho wever thefalse positives and warnings presentation are the main barriers of tools adoption.
conclusion we investigated in this paper the benefits and the constraints of usinglintersforperformancepurposesinandroidapps.weconducted a qualitative study based on interviews with experienced androiddevelopers.ourresultsprovidemotivationsfordevelopers touselintersforperformanceandsharewiththemhowtomake this usage the most beneficial.
our findings highlight also the current challenges of using linters for performance.
these challenges openupnewresearchperspectivesandshownewneedsfortool makers.