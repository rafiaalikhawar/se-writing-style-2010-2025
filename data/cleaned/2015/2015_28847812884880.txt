a practical guide to select quality indicators for assessing pareto based search algorithms in searchbased software engineering shuai wang1 shaukat ali1 tao yue1 yan li3 marius liaaen4 1simula research laboratory oslo norway 2department of informatics university of oslo oslo norway 3beihang university beijing china 4cisco systems oslo norway shuai shaukat tao simula.no lyadeng79 gmail.com marliaae cisco.com abstract many software engineering problems are multi objective in nature which has been largely recognized by the search based software engineering sbse community.
in this regard pareto based search algorithms e.g.
non dominated sorting genetic algorithm ii have already shown good performance for solving multi objective optimization problems.
these algorithms produce pareto fronts where each pareto front c onsists of a set of non dominated solutions.
eventually a user selects one or more of the solutions fr om a pareto front for their specific problems .
a key challenge of applying pareto based search algorithms is to select appropriate quality indicators e.g.
hypervolume to assess the quality of pareto fronts.
based on the results of an extended literature review we found that the current literature and practice in sbse lacks a practical guide for selecting quality indicators despite a large number of published sbse works.
in this direction the paper presents a practical guide for the sbse community to select quality indicators for assess ing pareto based search algorithms in different software engineering contexts .
the practical guide is derived from the following complementary theoretical and empirical methods key theoretical foundations of quality indicators evidence from an extended literature review and evidence collected from an extensive experiment that was conducted to evaluate eight quality indicators from four different categories with six pareto based search algorithms using three re al industrial problems from two diverse domains .
ccs concepts software and its engineering search based software engineering keywords quality indicators multi objective software engineering problems pareto based search algorithms practical guide .
introduction many software engineering problems are multi objective in nature and can be formulated as multi objective optimization problems mops .
a substantial number of works in search based software engineering sbse has shown the capability to solve mops using pareto based search algorithms that are based on pareto optimality theory .
a pareto based search algorithm produces a pareto front consisting of a set of non dominated solutions i.e.
solutions with equivalent quality from which users can select one or more solutions for their specific needs.
it is therefore important to assess the quality of pareto fronts produced by these algorithms to determine the applicability of sbse for solving mops .
to evaluate the quality of pareto fronts the existing works in sbse have applied several quality indicators e.g.
hypervolume hv epsilon generalized spread gs generational distance gd and pareto front size pfs .
these quality indicators are further classified into different categories e.g.
and gd are defined to measure the convergence between solutions produced by search algorithms and optimal solutions and gs is defined to measure the diversity of solutions in a pareto front .
however based on the improved literature review that we conducted by extending the one reported in we discovered that the current literature of sbse lacks a practical guide to select quality indicators for different software engineering applications .
more specifically the current literature lacks the evidence for selecting quality indicators for the following three cases.
first there is no evidence to show whether it matters to select a particular quality indicator within the same category e.g.
convergence .
for example if the pareto front produced by non dominated sorting genetic algorithm ii nsga ii has a better value of gd convergence than the one produced by improved strength p areto evolutionary algorithm spea2 there is no evidence that we can observe the same phenomenon for convergence .
second there is no evidence whether it matters to select a particular quality indicator from different categories.
for example using gd from convergence and gs from diversity there is no evidence to show that the same trend of performance can be observed for nsga ii and spea2.
finally there is no evidence whether computation time can be used as a criterion for selecting quality indica tors.
it is important to note that the existing works usually chose a subset of the existing quality indicators without proper justification and in most cases hv was selected because of its popularity .
in this paper we propose a practical guide to select quality indicators for assessing pareto based search algorithms in sbse using the following theoretical and empirical methods theoretical foundations of quality indicators the extended literature review and an extensive experim ent.
an overview of the approach that we used to derive the guide is shown in figure .
as shown in figure first we studied the theoretical foundations of the quality indicators and conducted an extended literature review based on from the existing literature step .
in the second step step in figure we conducted an extensive experiment with eight quality indicators that have been applied in permissi on to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org .
icse may austin tx usa.
acm.
isbn .
ieee acm 38th ieee international conference on software engineering the existing works .
these quality indicators are classified into four different categories i.e.
convergence gd euclidean distance ed diversity pfs and gs combination of convergence and diversity combination inverted generational distance igd hv and coverage coverage c .
we evaluate these quality indicators together with six commonly used pareto based search algorithms e.g.
nsga ii by employing three industrial software engineering mops based on our long term collaboration from communication and subsea oil gas domains.
from the communication domain we selected two problems on testing video conferencing systems vcss including test suite minimization problem tm with four objectives and test case prioritization problem tp with four objectives.
from the subsea oil gas domain we selected one requiremen ts allocation problem ra with three objectives .
figure approach for developing the practical guide the remaind er of the paper is organized as section provides theoretical foundations of pareto optimality pareto based search algorithms and quality indicators followed by presenting the extended literature review section .
section presents the extensive experiment and section provides the practical guide .
last section concludes the paper and sketches the future work .
theoretical foundations this section presents theoretical foundations for pareto optimality theory section .
six pareto based search algorithms section .
and eight quality indicators section .
.
.
pareto optimality theory multi objective optimization is usually based on the pareto optimality theory which aims to balance several trade off objectives and produces a number of solutions with equal quality.
pareto optimality defines dominance to compare solutions i.e.
a solution a is said to dominate another solution b if for all objectives a is no worse than b at the same time at least one objective exists that a is better than b .
formally speaking suppose there are m objectives o o!
o!
... o!
to be optimized let s say minimization which can be defined as a set of object ive functions f f!
f!
... f!
.
solution a dominates solution b i.e.
a b if and only if i ... m f!a f!b and j ... m f!a f!b.
the set of solutions that cannot be dominated by others are considered as equally viable which is named as pareto front.
an optimal pareto front also called true pareto front includes all non dominated solutions that exist in a given search space for a problem while a pareto front obtained by a particular search algorithm is usually named as a computed pareto front .
thus multi objective search algorithms based on the pareto optima lity theory aim at exploring a g iven search space and outputs a pareto front with the aim to provide users with a number of alternative solutions from which users can choos e the most appropriate solution based on their specific requirements.
.
six pareto based search algorithms search algorithms aim at mimicking natural phenomenon e.g.
bird flocking to search optimal solutions for optimization problems .
to apply search algorithms fitness functions should be defined to assess the quality of obtained solutions.
this paper selects six pareto based search algori thms which are classified into three categories .
notice that our goal is to cover a representative set of existing search algorithms rather than limiting to commonly used ones e.g.
nsga ii and spea2 .
to achieve this the six algorithms were chosen systematically for covering at least one algorithm per category .
table .
classification of search a lgorithms algorithm category algorithm evolutionary algorithms eas gas sorting based nsga ii cellular based mocell strength pareto ea spea2 evolution strategies paes swarm algorithm particle swarm theory smpso hybrid algorithm cellular ga differential evolution cellde nsga ii sorts t he population into several non dominated fronts using a ranking algorithm followed by selecting individuals from these non dominated fron ts and generates new population by applying selection crossover and mutation operators .
moreover nsga ii defines a metric called crowd ing distance to measure the distance between an individual solution and the others.
if two individual solutions are in the same non dominated front the solution with a higher value of the crowd ing distance is selected.
the aim for crowd ing distance indicator is to maximize the diversity of the outputted non dominated solutions.
multi objective cellular mocell is based on the cellular model of gas cgas with an assumption that an individual only interacts with its neighbours during the search process .
moreover mocell stores a set of obtained non dominated individual solutions in an external archive.
after each generation mocell replaces a fixed number of solutions randomly chosen from the population by selecting the same nu mber of solutions from the archive until the termination conditions are met.
such replacement only takes place when newly generated solutions from the population are worse than the ones in the archive.
improved strength pareto evolutionary algorithm spea2 calculates t he fitness value for each solution by summing up a strength raw fitness based on the objective functions and density estimation .
the density estimation measures the distance between a solution and its nearest neighbours for maximizing the diversity.
spea2 stores a fixed number of best solutions into an archive by applying selection crossover an d mutation operators.
then a new population is created by combining solutions from the archive and the non dominated solutions of the original population.
if the combined non dominated solutions are greater than the maximum size of the population the sol ution with the minimum distance to any other solution is selected by applying a truncation operator to calculate the distances to its neighbourhood .
pareto archived evolution strategy paes applies the dynamic mutation operator for exploring the search space and manages to find optimal solutions .
paes also stores the obtained non dominated solutions into an archive and newly generated solutions can be added into the archive if they are better than existing solutions by calculating objective functions.
the speed constrained multi objective particle swarm optimization smpso is a biological metaheuristic inspired by the social foraging behaviour of animals such as bird flocking .
smpso selects the best solutions by calculating the crowding distance and stores the selected individual solutions in an ar chive.
smpso takes advantage of mutation operators to accelerate the step extensive experiment section existing literature input three industrial problems section .
input step .
theoretical foundations section step .
extended literature review section step practical guide section input input 632speed of convergence and adapts the velocity constriction mechanism to avoid the explosion of swarms .
the differential evolution de algorithm is considered as another kind of ea which generates solutions by a pplying recombination mutation and selection operators .
de calculates the weighted difference between two randomly selected parent solutions and integrates obtained weighted different parts into a third parent solution for generating an offspring .
cellde is a hybrid metaheuristic algorithm using mocell as a search engine and replacing the typical selection crossover and mutation operators for gas with the recombination mechanism of de .
cellde takes the advantage of cellular ga and de with good diversity and convergence .
.
quality indicators to assess the qua lity of pareto fronts produced by algorithms a certain number of quality indicators has been proposed and applied by the existing work s e.g.
generational distance gd inverted generation distance igd hypervolume hv epsilon generalized spread gs .
based on the existing literature we selected the most commonly used eight quality indicators and classified them into four categories based on their definitions convergence diversity combination of convergence and diversity combination and coverage shown in table .
as discussed in section .
the optimal pareto front and a computed pareto front obtained by an algorithm are referred as pf!
and pf!
respectively.
it is worth mention ing that obtaining pf!
for an optimizatio n problem is infeasible in practice due to the limited time or resources .
thus when applying quality indicators to evaluate pareto based search algorithms a reference pareto front pf!
is often computed to represent the optimal pareto front pf!
.
suppose n number of search algorithms produce n computed pareto fronts pf!!
pf!!
... pf!
pf!
is then a union of all the non dominated solutions from these n computed pareto fronts which can be calculated as pf!
!
!
!
!
!
!
!
!!s!
pf!
!
!
!!
s!
s!
.
table also denotes whether calculating a particular quality indicator requires a reference pareto front require column .
we detail ea ch quality indicator as follows.
table .
categories of quality indicators category name brief description require convergence gd the euclidean distance between solutions in pf!
and the nearest solutions in pf!
reference pareto front ed euclidean distance between the ideal solution and the closest solution in pf!
ideal solution smallest distance for transferring every solution in pf!
to dominate pf!
reference pareto front diversity gs the extent of spread for pf!
reference pareto front pfs number of solutions included in pf!
none combination igd euclidean distance between solutions in pf!
and the nearest solutions in pf!
reference pareto front hv the volume covered by solutions in pf!
reference point cove rage c the dominance between pf!
and pf!
reference pareto front convergence .
generational distance gd is defined to measure how far are the solutions that exist in pf!
from the nearest solutions in pf!
which can be calculated using the formula gd !
!
!
!
!
!
!
!
!
!!
!
!
where pf!
is the cardinality of pf!
i.e.
the number of solutions included in pf!
and d s!
pf!
refers to the minimum euclidean distance from the solution s!
in pf!
to pf !
i.e.
the euclidean distance between s!
in pf!
and the nearest solution in pf!.
a value of for gd indicates that pf !
and pf!
are the same i.e.
all the obtained solutions by a search algorithm are optimal.
euclidean distance from the ideal solution ed measures the euclidean distance between the ideal solution and the closest solution in pf !
.
the ideal solution s!
is created by including all the optimal values for each objective e.g.
minimum values for a minimization problem obtained from all the non dominated solutions in pf !.
ed can be calculated as ed d s!
pf!
i.e.
the shortest euclidean distance from s!
to pf!
and a value of for ed indicates that the computed pareto front includes the ideal solution.
notice that the main difference between ed and gd is that ed focuses on the shortest euclidean distance between the computed pareto front and the ideal solution while gd aims at measuring the average euclidean distance between solutions in the computed pareto front and the optimal pareto front.
epsilon measure s the shortest distance used to transform every solution in pf !
to dominate pf!
.
suppose a solution s can be represented as s f!
f!
... f!
where m is the number of objectives and f!
is the function value for the objective i. thus can be calculated as pf!
inf!
r s!
pf!
s pf!
s !s!
where inf!
r refers to the infimum for and s !s!
means the solution s!
in pf !
dominates the solution s in pf !
with a distance of i.e.
s !s!
if and only if i m f!!
f!!!.
notice that a lower value of denotes that the computed pareto front is closer to the optimal pareto front.
diversity .
generated spread gs is defined to extend the quality indicator spread which only works for two objective problems and measure the extent of spread for the solutions in pf!
.
gs can be computed using the formula gs !
!!
!
!
!
!
!
!
!
!!
!
!
!
!
!
!!
!
!!
!
!
!
!
!!!!
!
!
where e!
e!
... e!
refers to m extreme solutions for each objective in pf!
m is the number of objectives .
an extreme solution for a particular objective means a solution from pf !
that achieves the optimal value for the objective on the basis of sacrificing other objectives.
de!
pf!
refers to the shortest euclidean distance between the extreme solution e!
and pf!.
ds pf!
means the shortest euclidean distance between the solution s in pf !
and the other solutions in pf!
while d is the mean value of ds pf!
for all the solutions in pf!.
a lower value of gs shows that the solutions have a better distribution in pf!.
pareto front size pfs measures the number of solutions that are included in pf!
i.e.
pf!
.
it is used to reflect diversity on the basis that users can have more options to choose and thus a higher value of pfs shows a more diverse computed pareto front.
combination.
inverted generational distance igd measures the shortest euclidean distance from each solution in pf!
to the closest solution in pf!
.
igd can be calculated as igd !
!
!
!
!
!
!
!
!
!!
!
!
where pf!
refers to the number of solutions in the optimal pareto front and d s!
pf!
refers to the minimum euclidean distance from the solution s!
in pf!
to the computed pareto front.
notice a lower value of igd means the computed pareto front is closer to the optimal pareto front.
hypervolume hv is defined to measure the volume in the objective space that is covered by pf!
.
hv can be calculated by hv volume v!pfc !
!!
and for each solution s!
pf!
v!
means the diagonal corners of the hypercube between the solution s!
and a reference point that is a vector of worst objective function values.
the reference point is created by including all the worst values for each objective which can be obta ined from all the non dominated solutions in pf!
e.g.
maximum value for a minimization problem .
notice that a higher value of hv demonstrates a better performance of the computed pareto front.
coverage .
coverage c measures the dominance between pf!
and pf!
i.e.
the number of solutions in pf!
that are covered by pf!.
it can be calculated using c !
!
!
!
!
!
!
!
.
notice that c 633ranges from to and a higher value of c is preferable as it signifies that the com puted pareto front consists of more optimal solutions.
extended literature review search algorithms are increasingly becoming an efficient means for solving complex optimization problems in all phases of software development life cycle.
this area of resear ch is termed as search based software engineering sbse .
in the last two decades research in sbse has been significantly increased e.g.
the sbse repository hosted by the crest centre contains published papers as of august 18th .
initially sbse was mainly focused on solving single objective optimization problems sops using search algorithms e.g.
genetic algorithms.
however many se problems are multi objective by nature and thus it is becoming critical for sbse to deal with multi objective optimization problems mops e.g.
selecting a subset of test cases from a large number of test cases without significantly decreasing fault detection capability and at the same time achieving high coverage three objective test case selection problem .
one approach in sbse try to solve mops by converting them into sops by assigning weights to each objective .
such an approach has two key problems it is not possible to select precise and accurate weights for each objective several solutions with equivalent quality may be lost due to the conversion.
to overcome these problems pareto based search algorithms e.g.
nsga ii are increasingly being used to solve mops.
these algorithms p roduce pareto fronts where each pareto front contains a set of non dominated solutions and eventually a user can select one or more solutions for their problems based on their specific requirements.
to evaluate the performance of various par etobased search algorithms a number of quality indicators have been proposed e.g.
hypervolume hv for assessing the quality of pareto fronts produced by search algorithms .
a literature review has been conducted in to review the existing works on applying pareto based search algorithms for solving se problems coined as pareto optimal sbse posbse from the following perspectives algorithms used number of objectives to optimize framework to implement algorithms and quality indicators for evaluating pareto fronts.
the results show that only out of papers as of april have focused on mops suggesting that it is still a new area of research in sbse.
in addition we also observed that only out of these papers have applied standard quality indicators e.g.
hv to assess the quality of pareto fronts which is commonly used in the optimization community .
even for these papers there is no clear justification for selecting quality indicators.
for most of these works hv was selected as a quality indicator because it was commonly used and it combines convergence and diversity as discussed in section .
.
since this work focuses on providing a practical guide on how to choose quality indicators we have followed the same template and extended the review work in by selecting and reviewing the papers from the sbse repository related with posbse from april to august .
the goal for this extended literature review is to study which quality indicators have been used and how the quality indicators were chosen in the recent sbse works.
in addition we also report the number of objectives for optimization which can be used for proposing the practical guide .
notice that we do not report the applied multi objective algorithms and the tool for algorithm implementat ion as reported in since they are out of scope of this paper.
from our extended literature review we observe papers on posbse have increased from to until august and table lists all these incremental works in total .
we can see that the works applying the standard quality indica tors has increased from reported in by april to august .
however similarly as discussed in our extended literature review also shows that there is still no clear justification or explanation on the selection criteria for choosing quality indicators in various se applications.
for instance all the works applying hv simply justified that hv was selected either because of its definition based on convergence and diversity or just because of its popularity .
furthermore since quality indicators can be classified into different categories section .
there is no evidence to show whether applying a subset of quality indicators e.g.
ed and hv were used in while hv and gd were applied in is sufficient to evaluate pareto fronts produced by search algorithms.
there are also no practical guide s in t he existing sbse literature for choosing quality indicators in different se applications.
based on the extended literature review this paper is the first work in the sbse community that aims at providing a practical guide for selecting quality indicators when assessing pareto based search algorithms.
notice that the eight quality indicators chosen in this paper cover all the quality indicators that have been applied in the recent sbse works table .
table .
extended posbse w orks in sbse reference quality indicators of objectives not applied hv pfs spread igd epsilon pfs hv spread not applied c gd igd ed ed hv not applied not applied not applied hv gd hv igd hv igd c hv spread hv hv gd igd c hv gd igd epsilon hv c ed not applied not applied not applied not applied experiment this section presents the extensive experiment we co nducted for empirically evaluating the eight quality indicators together with the six pareto based search algorithms which includ es description of the industrial problems section .
experiment design section .
experiment results section .
discussion based on the results section .
and discussion related with threats to validity section .
.
.
description of the industrial problems this section presents three industrial problems from two distinct domains communication section .
.
and subsea oil gas section .
.
as shown in table .
.
.
communication case studies since we have established a close collaboration with cisco norway focusing on improving the cost and effectiveness of testing a variety of videoconferencing systems vcss developed by cisco .
the core functionality of a vcs is to establish a videoconference among participants at various physical locations.
there is also a possibility of transmitting 634presentations in parallel to a videoconference using vcss.
generally speaking vcss aim at offering efficient means to organize high quality face to face meetings without requiring physically gathering of participants from dif ferent geographic locations.
each vcs has on average three million lines of embedded c code.
notice that for testing saturn a product line of vcss focused in this paper a test case repository has been constructed by cisco s test engineers with more than test cases.
new test cases are continuously added to this repository.
table .
an overview of the industrial problems domain problem objective communication test suite minimization test minimization percentage tmp feature pairwise coverage fpc fault detection capability fdc overall execution time oet test case prioritization prioritized extent pe feature pairwise coverage fpc fault detection capability fdc overall execution cost oec subsea oil g as requirements allocation extent of assigned requirements assign familiarity of stakeholders faw overall differences of workloads owl for testing a new vcs we learned that two industrial problems are required to be addressed i.e.
cost effective test suite minimization eliminating redundant test cases without significantly reducing the effectiveness e.g.
feature pairwise coverage at the same time minimizing the cost execution time cost effective test case prioritization prioritizing test cases into an optimal order within a limited test resource b udget with the aim to maximize the effectiveness e.g.
fault detection capability and minimize the c ost e.g.
execution time .
considering the number of test cases is large i.e.
search space is huge for both industrial problems each of the two problems can be formulated as a multi objective optimization problem and applying search algorithms shows promising results as we previously studied .
.
.
.
test suite minimization problem test suite minimization aims at eliminating redundant test cases while maximizing the effectiveness and minimizing the cost.
to deal with this problem four cost effectiveness objectives table were defined together with test engineers at cisco.
a test m inimization percentage tmp measures the number of test cases that can be minimized as compared with the original test suite tmp can be measured as tmp !
!
!
!
!
where nt !
!
is the number of minimized test cases and nt!
is the number of original test cases b feature pairwise coverage fpc measures how many pairs of features testing functionalities can be covered by the minimized test cases fpc is measured as fpc !
!
!
!
!
!
!
where numfp !
!
refers to the number of feature pairs covered by the minimized test cases while numfp !
!
is the number of feature pairs that should be covered by vcs product p!
c fault detection capability fdc measures how many test cases can manage to find faults within a specified time period e.g.
one week in the past fdc can be measured as fdc !
!
!
!
!
!
!
!!
!
!
!
where sucr !
!refers to the success rate that a test case tc !
can manage to detect faults in a given time d overall execution time oet measures how long it take s for executing the minimized test cases.
oet can be measured as oet aet !
!
!
!
!
!
!!
where aet !
!refers to the average historical execution time for test case tc!.
more details about the object ive functions can be found in .
.
.
.
test case prioritization problem test case prioritization aims to cost effectively prioritize a set of test cases within a limited budget of available test resources .
in our case test resources refer to correct software versions deployed on hardware since te st cases aim at testing different software versions.
notice that it may take different time to allocate particular test resources for a specific test case.
similarly to address such a test prioritization problem we defined four cost effectiveness measures as below shown in table .
a prioritized extent pe measures the number of test cases that can be prioritized within the test resource budget pe can be measure d aspe !
!
!
where nt!
refers to the number of prioritized test cases within available test resources while nt is the total number of test cases to be prioritized b feature pairwise coverage fpc measures how many pairs of features can be covered by the prioritized test c ases fpc can be measured as fpc !
!
!
!
!
!
where numfp !
is the number of feature pairs covered by the prioritized test cases and numfp refers to the total number of feature pairs that should be tested c fault detection capability fdc measures the fault detection capability of the prioritized test cases.
it is measured as fdc !
!
!
!
!
!
!!
!
!
where sucr !
!refers to the success rate that a test case tc !
can manage to find faults in a given time d overall execution cost oec measures how long it take s to setup the required test resources and execute the prioritized test cases.
it can be calculated as oec aet !
!
!
!
!
!!
ttr !
!
where aet !
!
refers to the average historical execution time for test case tc !
and ttr !
!
is the total time for allocating relevant test resources for tc!.
more d etails can be found in .
.
.
subsea oil gas case study subsea production systems spss are large scale heterogeneous and highly hierarchical cyber physical systems cpss that control and monitor physical processes such as oil and gas production platforms .
spss manag e the exploitation of oil and gas production fields by integrating hundreds of hardware components and software.
at the early phase of developing such a large scale cps a large number of requirements are required to be inspected by different stakeholders from different organizations or departments of the same organization.
these requirements have different characteristics such as various extents of importance to an organization complexity and dependencies between each other thereby requiring different effort workload to inspect .
therefore one practical challenge has been identified i.e.
requirements allocation that aims to maximize stakeholders familiarities to the assigned requirements and at the same time balance the overall workload of each stakeholder.
the problem has been formulated as a multi objective optimization problem in our previous work s .
.
.
.
requirement s allocation problem to address this problem three cost effectiveness measures have been defined in .
a assign represents the extent of assigning all the requirements to stakeholders.
it can be measured as assign !
!
!
!!
!
!!
!
!
where n!
!
returns the number of requirements assigned to the i!!
stakeholder n!
is the total number of 635requirements and n!
is the total number of stakeholders b fam denotes the overall familiarity of the stakeholders to requirements allocated to them.
it can be measured as fam !
!
!
!
!
!
!
!
!
!
!
!
!
!
!!!!
!
!!
!
!
!
!!
!
!!
where fm !
represents the familiarity value of stakeholder s!
for requirement r!
and all familiarity values range from fm!
to fm !
c owl represents the overall differences of workloads of the stakeholders and it can be measured as owl !
!
!
!!
!
!!
!
!!!!!!
!
!
!
!!
!
!
!
!
!
!
where wl !
computes the workload for all the requirements assigned to i!!
stakeholder based on their complexity dependency index and importance wl !
!
!
!!
!
!
!
!
!
!
!
!
!
!!
!
!
!
!
!
!
!
!
!
!!
!
!
!
!
!
!
!
!
!
!
!!
!
!
!
!
in which cm !
dp!
and im!
represent the complexity dependency and importance of the requirement j!!
respectively.
.
experiment design in this section we present the exp eriment design from these aspect s research questions section .
.
case studies of the three industrial problem s section .
.
experiment t asks performed and statistical tests section .
.
evaluation metric and algorithm parameter settings section .
.
.
.
.
research questions our goal is to provide a practical guide for the sbse community to select quality indicators for se applications.
t o meet our objective we define the following research questions rq1 does it matter to select a particular quality indicator within each category?
answering this research question help s us to define a guide for selecting quality indicators within the same category for assessing pareto based search algorithms in different se contexts.
rq2 does it matter to select quality indicators from different categories?
answering this researc h question help s to define a guide for selecting quality indicators from different categories for assessing pareto based search algorithms in different se context s. rq3 does it matter to take calculation time into account when selecting quality indicators ?
answering this research question help s us to study whether calculation time can be an additional layer to define a guide for selecting quality indicators.
.
.
case studies in section .
we introduced three industrial problems test suite minimization problem tm test case prioritization problem tp and requirement s allocation problem ra .
we detail the case st udies used for each problem as below .
tm we chose four vcss from saturn c20 c40 c60 and c90 .
there are features testing functionalities in saturn and each vcs includes a subset of these features.
moreover c20 c40 c60 and c90 include and features respectively and and test cases relevant for testing these vcss respectively .
notice that each feature can be tested by at least one test case and each test case can be used to test at least one feature.
each test case tc!
has a success rate for execution sucr !
!
for calculating fdc an average execution time aet !
!
for measuring oet .
in general for saturn each feature is associated with test cases and each test case tc !
is associated with features with sucr !
!
ranging from to and aet !
!ranging from to minutes.
tp we chose a testing cycle that includes test cases for testing functionalities features .
each feature can be tested by at least one test case and one tes t case can be executed for testing one or more features.
each test case tc!
has a success rate for execution sucr !
!
ranging from to an average execution time aet !
!
ranging from to minutes and time for allocating relevant test resources ttr !
!
ranging from to minutes.
moreover there are available test resources used to setup the test environment e.g.
correct software for executing such te st cases.
notice that each test resource can be allocated for executing one or more test cases and execution of each test case requires o ne or more test resources.
ra we selected a real world case study i.e.
a large scale cps including requirements and identified stakeholders who are responsible for reviewing and checking these requirements .
each requirement r!
has three attribute s that include complexity cm ranging from to dependency index dp from to n!
n!
is the number of requirements and importance im ranging from to .
each stakeholder s!
has one attribute i.e.
familiarity for a specific requirement r!
fm !
ranging from to in our case.
it is worth mentioning that all the three industrial problems are complex based on our previous works since random search a baseline has been compared with search algorithms and results consistentl y show that search algorithms significantly outperform random search.
.
.
experiment tasks and statistical tests experiment tasks we first perform a task by running the six algorithms for the case studies in each industrial problem as shown in figure .
thus for each case study in an industrial problem values are obtained for each quality indicator in terms of each search algorithm.
table an o verview of the experiment design rqs experiment tasks statistical tests algorithm s quality indicators problem s case studies t!
t!!
compare each pair of the algorithms by analyzing the values of the quality indicators within category vargha and delaney statistics mann whitney u test nsga ii spea2 mocell cellde smpso paes convergence gd tm tp ra tm c20 ed c40 t!
analyze the correlations of each pair of the quality indicators within category kendall rank test c60 diversity gs c90 t!
t!
compare each pair of the algorithms by analyzing the values of the quality indicators across categories vargha and delaney statistics mann whitney u test pfs tp c20 combination igd c40 t!!
analyze the correlations for each pair of the quality indicators across categories kendall rank test hv c60 coverage c c90 t!
compare the quality indicators in terms of computation time average value mann whitney u test ra cps 636for each industrial problem for each case study run the six pareto based search algorithms with certain number of times in our case for each time of run obtain a reference pareto front by combining pareto fronts produced by the six algorithms calculate the values for the eight quality indicator so that each algorithm has eight values associated with each quality indicator end obtain the values for each quality indicator for each algorithm end end.
figure pseudo code for obtaining quality i ndicator values we defined a corresponding task as shown in table to answer each research question based on the obtained quality indicator values.
the t!
task is divided into t!!
and t!
where t!!
compares each pair of t he search algorithms using each quality indicator within the same category for each case study.
the t!
task answers rq1 from another perspective where we study the correlations of two quality indicators within category by ignoring the differences of the search algorithms.
t !
is also divided into two tasks.
t !
compares each pair of the algorithms by analyzing the values of quality indicators across categories.
t !
!
studies the correlations between the quality indicators across categories.
last in t!
we compare the quality indicators based on their calculation time to answer rq3 .
statistical tests for t!!
and t!
the vargha and delaney statistics and mann whitney u test are used by following the guides reported in to compare the results of the search algorithms based on the quality indicators within or across categories table .
the vargha and delaney statistics is used to calculate a!
which is a non parametric effect size measure.
in our context a!
is used to compare the probability of yielding higher values of each quality indicator for two algorithms a and b. each pair of algorithms is further compared using the mann whitney u test p value to determine the significance of the results with the significance level of .
i.e.
there is a significant difference if p value is less than .
.
for the qual ity indicators hv pfs c higher value better performance a significantly outperforms b if a!
is greater than .
and the pvalue is less than .
while a performs significantly worse than b if a!
is less than .
and the p value is less than .
.
there is no significant difference between a and b if the p value is greater than .
.
for the other quality indicators i.e.
gd ed epsilon igd and gs vice versa .
to study the correlation between each pair of quality indicators t !
and t!!
we choose the kendall rank correlation coefficient as shown in table .
the value ranges from to i.e.
there is a positive correlation if is equal to and a negative correlation when is .
a close to shows that there is no correlation between two sets of data.
moreover we also report significance of correlation using prob a value lower than .
means that the correlation is statistically significant.
notice that the test does not require the monotonic ity of two data sets which suits our case .
in addition the mann whitney u test is applied to determine whether there are significant differences for the time to calculate each quality indicator t !
.
.
.
metric and parameter settings evaluation metric to address rq1 and rq2 we define a metric matters to measure whether two quality indicators can demonstrate the same trend of performance when evaluating the algorithms matters qi!
qi!
matter !
qi!
qi!
!
!
!
!
!!
where n is the number of the algorithms and c n refers to the number of the algorithm pairs.
for instance there are c6 pairs for the selected six pareto based search algori thms in our case.
the matter !qi!
qi!
function denotes whether it matters to choose one of the quality indicators qi!and qi!
when comparing the i!!
algorithm pair.
in other words matter !qi!
qi!
is if both qi!
and qi!
revea l the sam e trend of performance for the i!!
algorithm pair i.e.
it doesn t matter which quality indicator to choose otherwise matter !qi!
qi!
is .
for example suppose that hv and igd are used to compare nsga ii and spea2.
if both h v and igd consistently indicate one of the three cases nsga ii performs significantly better than spea2 nsga ii performs significantly worse than spea2 and there is no significant difference between nsga ii and spea2 matter !hv igd will be .
otherwise if hv and igd demonstrate different trend s of performance for ngsa ii and spea2 matter !hv igd will be .
using matters rq1 and rq2 can be answered in a precise and compact manner.
in conclusion we can say that it does n ot matter if we choose qi !
or qi!
for assessing the algorithms if matters qi!
qi!
for all pairs of the search algorithms e.g.
pairs for the six search algorithms in our case otherwise it matters and therefore both qi !
and qi!
should be applied together if matters qi!
qi!
since there is at least one algorithm pair that the two quality indicators show the different trend s of performance.
parameter settings we employ jmetal to encode the three industrial problems together with the implementation of the six selected pareto based search algorithms.
a ll the parameters that are used for configuring these algorithms are shown in table which are suggested as default parameters from the jmetal library .
in addition we set the ma ximum number of fitness evaluations as i.e.
the search is terminated if the fitness function has been evaluated for times.
notice that tuning parameters may lead to different performance of search algorithms but standard parameter settings a re usually recommended .
furthermore all the eight quality indicators mentioned in section .
are implemented based on jmetal .
a s suggested in each algorithm was run times to account for random variations.
table .
parameter settings of the search algorithms algorithm parameter setting s nsga ii spea2 population size selection of parents binary tournament binary tournament recombination simulated binary crossover rate .
mutation polynomial mutation rate .
n mocell population size neighbourhood hop neighbours surrounding solutions selection of parents binary tournament binary tournament recombination simulated binary crossover rate .
mutation polynomial mutation rate .
n archive size paes mutation polynomial mutation rate .
n archive size smpso population size mutation polynomial mutation rate .
n archive size cellde population size neighbourhood hop neighbours surrounding solutions selection of parents binary tournament binary tournament recombination differential evolution crossover rate .
archive size .
experiment results this section presents the results for each research question1.
rq1 rq1 focuses on empirically evaluating the quality indicators within the same category.
table lists the values of for reproducibility we make all the data related with the experiment publicly available at tools.com icse2015.html 637matters for the quality indicators within each category by applying the six pareto based search algorithms in the four vcs product s case studies for solving the tm and tp problems and one cps for solving the ra problem .
from table we can observe that the three quality indicators within convergence i.e.
gd ed and show the same trend of performance when comparing the pairs of the six algorithms in the three industrial problems since all the values for matters are equal to .
similarly the two quality indicators i.e.
igd and hv within combination also demonstrate the same trend of performance when comparing the pairs of the six algorithms.
however we observe that in diversity gs and pfs show different trends of performance since all the values of matters are .
this observation shows that when using gs and pfs for measuring diversity we may observe different performance of search algorithms for the same problem.
notice that we only have one quality indicator in coverage and thus we cannot calculate matters within coverage .
table .
matte rs of the quality indicators within each category category quality indicators tm tp ra convergence gd and ed gd and ed and diversity gs and pfs combination igd and hv moreover we apply the kendall rank correlation coefficient test for studying the correlations between quality indicators within the same category.
table summaries the key results for pairs of quality indicators using the test.
from table one can observe that the three quality indicators ed gd and of convergence have significantly positive correlations for all the case studies of the three industrial problems since all the values of are greater than close to and the p values for prob are all less than .
due to the limited space we do not report the individual values for and prob .
therefore we can conclude that for convergence all the three quality indicators show the same trend of performance when comparing different algorithms and it therefore does not matter which one to choose.
table .
key results for the correlation analysis using the test for the quality indi cators within category category quality indicators tm tp ra convergence gd and ed p .
p .
p .
gd and ed and diversity gs and pfs p .
p .
p .
combination igd and hv p .
p .
p .
as for diversity the results in table show that there is no significant correlation between gs and pfs since the p values for prob are greater than .
and thus gs and pfs have to be selected together when evaluating the diversity of a pareto front.
for combination i.e.
hv and igd table show s that a significantly negative correlation exist s between hv and igd .
the correlation is negative since a higher value of hv shows a better pareto front which is represented by a lower value of igd.
thus for this category it also does not matter which indicator to choose when assessing the performance of the search algorithms.
based on the above results rq1 can be answered as follow s. for convergence and combination it doesn t matter which quality indicato r within the same category to choose however it does matter for diversity i.e.
both gs and pfs should be used together when assessing pareto fronts.
rq2 rq2 aims at empirically evaluating the quality indicators across categories.
based on the result s of rq1 i.e.
gd ed and have significant correlations and igd and hv also have a significant correlation we chose and hv for representing the categories of convergence and combination respectively since the results of gd and ed are consistent with for convergence and the results of igd are consistent with hv for combination .
therefore the five quality indicators from the four different categories i.e.
hv pfs gs and c are compared in the three industrial problems i.e.
tm tp and r a .
table summarizes the key results of matters when comparing each pair of the five quality indicators in the three industrial problems.
table .
matte rs of the quality indicators across categories category across pair tm tp ra convergence and diversity and gs and pfs convergence and combination and hv convergence and coverage and c diversity and combination gs and hv pfs and hv diversity and coverage gs and c pfs and c combination and coverage hv and c from table we observe that two quality indicators from different categories can result in different trends of performance of the search algorithms except for and c. in other words it does not matter which quality indicators to choose in terms of convergence and coverage but it does matter for the quality indicators from other categories since all values for matters .
table summarizes the key findings by studying correlations between each pair of quality indicators across categories using the kendall rank correlation coefficient test .
we can see that th ere is no significant correlation for all the pairs of the quality indicators except for and c since the p values for prob are greater than .
.
as for and c there is a significantly negative correlation since all the values for are less than close to and the p values for prob are all less than .
.
such a significant correlation is negative since a lower value of denotes a better pareto front which is represented by a higher value of c .
table .
key results for the correlation analysis using the test for the quality indicators across categor ies category across pair tm tp ra convergence and diversity and gs p .
p .
p .
and pfs convergence and combination and hv convergence and coverage and c p .
p .
p .
diversity and combination gs and hv p .
p .
p .
pfs and hv diversity and coverage gs and c pfs and c combination and coverage hv and c based on the above results rq2 can be answered as follows.
it does matter to choose quality indicators across categories except for convergence and coverage when assessing pareto based search algorithms in different se contexts .
rq3 this research questi on is designed to compare time to calculate each indicator.
notice that each algorithm is run for times in our case and each run provides a data point for the time.
since six algorithms are selected and three industrial problems are involved including case studies table data points of time can be obtained in total for calculating each quality indicator.
we report the average value of these time data points for each quality indicator table and perform the mann whitney u test to determine whether there are significant differences in terms of calculation time for each pair of quality indicators.
results show that for all the eight quality indicators pfs takes significantly less time than all the others since all the p values are less than .
which are not reported to save space.
within convergence and coverage calculating c takes significantly less 638time than the others i.e.
gd ed and .
within combination there is no significant difference for calculating hv and igd.
thus we can answer rq3 as follows there are significant differences in terms o f time for calculating quality indicators and thus calculation time can be used as additional criterion in our guide for selecting quality indicators.
however the practical differences for calculating these quality indicators may not be huge since all of them are in a few seconds .
table .
average time to calculate each quality indicator category quality indicator s average time seconds convergence gd .
ed .
.
diversity gs .
pfs .
combination igd .
hv .
coverage c .
.
discussion on results for rq1 we observe that within convergence all the three quality indicators i.e.
gd ed and show the same trend of performance when comparing pareto based search algorithms at the same time there are significantly positive correlations among them.
this can be explained from the fact that gd ed and are defined to measure the distance of solu tions in a computed pareto front to the optimal solutions in the optimal pareto front though different mathematical formulas are applied section .
.
it is worth mentioning that calculating ed only requires an ideal set of objective values i.e.
the optimal value that each objective can achieve section .
while gd and require obtaining a reference pareto front simulating the optimal pareto front .
in the context of our case studies we were not aware of ideal objective set beforehand which is obtained from the reference pareto front and the results show that gd ed and are equivalent in terms of convergence .
however for certain se problems if the ideal set of objective values is known beforehand e.g.
for testing the maximum value of feature pairwise coverage is ed should be a more accurate quality indicator as compared with gd and since these two indicators r equire a reference pareto front for representing the optimal pareto front .
as for combination both hv and igd are defined to measure how obtained solutions are close to optimal solutions and how obtained solutions are distributed in a computed front.
based on the results of the experiment hv and igd indicate the same trend of performance when comparing the algorithms.
furthermore calculating hv requires a reference point the worst objective set instead of a reference pareto front requ ired by igd section .
.
therefore hv is considered as a more accurate quality indicator when such a reference point is known beforehand for certain se problems e.g.
the minimum number of test cases to be elimin ated is for test suite minimization.
however within diversity the two quality indicators i.e.
gs and pfs do not demonstrate the same trend of performance when comparing the search algorithms and the correlation between them is not significant.
this can be explained based on the fact that pfs is defined based on the assumption that more solutions included into a pareto front more options a user can choose from and thus it reflects a more diverse pareto front.
however when all the solutions are close to each other in the front even higher values of pfs cannot necessarily demonstrate a pareto front with a higher diversity.
as compared with pfs gs is defined to measure how well solutions are distributed in a computed pareto front section .
.
thus gs and pfs provide two different perspectives of measuring diversity which should be a pplied together.
when calculating gs it requires calculating a reference pareto front section .
while pfs does not require anything.
as for rq2 the results show that the quality indicators of convergence show the same trend of performance as the quality indicator of coverage .
such interesting finding can be explained that when a computed pareto front shares more common solutions with the optimal pareto front i.e.
the value of c is higher the computed pareto front and the optimal solutions should be closer i.e.
the values for gd ed and are lower .
meanwhile significant correlations were observed among these four quality indicators which provide furt her evidence for the observation.
as for other quality indicators across categories no such phenomenon were found that denotes that quality indicators can not replace others that belongs to different categories except for the above mentioned ones i.e.
g d ed and c .
in terms of computation effort rq3 the results demonstrate that calculating quality indicators can take significantly different time e.g.
the calculation time for pfs is significantly less than the others section .
.
based on the theoretical foundations we observe that the computation effort for pfs is linear whereas the others except hv are in quadratic.
as fo r hv the calculation time will be increased exponentially with the increase in the number of objectives.
when the number of objectives is less e.g.
three and four objectives in our cases the practical differences are not very huge when looking into th e average calculation time for each indicator e.g.
.
seconds for pfs and .
seconds for .
notice that when the number of objectives is greater than as reported in hv is not applicable since it becomes very expensive to calculate.
based on these observations calculation time can be an additional criterion for selecting quality indicators.
.
threats to validity a threat to internal validity is that we have experimented with only one default configuration setting for algorithm parameters.
however these settings are in accordance with the common guides in the literature .
the conclusion validity threat in experiments involving algorithms is due to random variations.
to address it we repeated experiments times to reduce the possibility that the results were obtained by chance.
we also reported the results using the vargha and delaney statistics to measure the effect size mann whitney u test to determine the statistical significance and the kendall rank correlation coefficient to measure the correlations among the indicators .
the observed construct validity threat is that the measures used are not comparable across the algorithms.
in our context we used the same stopping criteria for all the algorithms i.e.
the number of fitness evaluations i.e.
.
as for external validity threat related with gene ralization of results three industrial problems were chosen from two different domains i.e.
communication and subsea oil gas which cover two different phases of software lifecycle i.e.
requirements and testing.
for the test suite minimization problem and test case prioritization problem four different vcs products with varying complexity were selected for the experiment.
for the requirement s allocation problem one large scale cps was chosen.
notice that such threat to external validity is common to all empirical studies .
practical guide this section provide s a practical guide figure for selecting quality indicators when assessing pareto based search algorithms.
as mentioned before the guide is derived based on a the theoretical foundations tf b the extended literature review lr and c the extensive experiment ee .
in figure we 639explicitly show this information inside the brackets when recommending a quality indicato r to apply .
as shown in figure a category of quality indicators should be first selected a1 select convergence or coverage if a user only cares whether obtained solutions are optimal or not.
in particular for some se problems e.g.
ra in our case only one optimal solution is required regardless of the diversity of solutions.
in this case a dedicated quality indicator for convergence is recommended.
moreover if an ideal set of objective values i.e.
optimal objective values is unknown for a specific se problem e.g.
ra in our case any of gd ed and c can be selected a3 based on ee i.e.
the results showed that all of them indicate the same trend of performance when comparing algorithms.
otherwise if an ideal objective set is known before ed should be selected a2 since it only requires an ideal objective set instead of a whole reference pareto front based on tf.
select combination if a user prefers more diverse solutions to choose from in addition to convergence .
for example a user can choose solutions based on the preference of objectives.
in this case the first selection criterion is based on the number of objectives to be optim ized since the computation effort of hv increases exponentially with the number of objectives .
from our experiment with three and four objectives tm tp and ra problems there is no significant time difference for calculating hv and igd and from the extended literature review section we observed that the number of objectives is always less than or equal to six for all the existing works that applied hv.
thus according to lr we set the threshold of the number of objectives as six for the guide i.e.
when the number of objectives for a problem are more than six igd should be selected a4 since the computation effort of igd is only in quadratic bas ed on tf.
when the number of objectives is less than or equal to six hv should be selected a5 if an accurate reference point is known i.e.
the worst values for all the objectives.
that is because calculating hv only requires a reference point rather t han an entire reference pareto front tf .
otherwise if a reference point is not known before e.g.
the ra problem in our case either hv or igd can be chosen a6 based on ee since hv and igd indicates the same trend of performance for comparing algorithms.
select convergence or coverage together with diversity .
it is also possible to evaluate convergence coverage and diversity of pareto fronts produced by search algorithms separately since dedicated quality indicators for convergence coverage and diversity may be more accurate than a combined quality indicator e.g.
hv .
notice that quality indicators of diversity cannot be applied separately since it does not make sense in realistic situations that users only care about the diversity of solutions without considering they are optimal or not.
in this case we need to learn whether the ideal objective set is known for a se problem.
if the ideal objective set is known ed from convergence should be applied together with pfs and gs diversity a7 based on tf and ee i.e.
pfs and gs indicate different trends of perfor mance when comparing algorithms .
otherwise any quality indicator from convergence or coverage can be chosen together with pfs and gs a8 based on ee.
notice that pfs and gs should be selected together since they reflect the diversity from two different perspectives i.e.
the number o f obtained solutions and distribution of solutions.
it is worth mentioning that the quality indicators from convergence and diversity may demonstrate completely different performance of algorithms and thus making it impossible to obtain a definite answer w hich algorithm is better.
in this case we recommend selecting the quality indicators from combination a9 since applying hv or igd can tell us which algorithm is better by combining both convergence and diversity .
conclusion and future work this paper provides a practical guide for the search based software engineering sbse community to select proper quality indicators when assessing pare to based search algorithms in different software engineering applications.
the guide is derived from theoretical foundations of quality indicators an extended literature review and an extensive experiment to evaluate eight quality indicators along with six pareto based search algorithms using three industrial problems .
in the future we plan to in volve more quality indicators into the guide which have not been investigated by the sbse community e.g.
purity dominance ranking .
we also plan to employ more industrial problems from other domains with th e aim to further improve the proposed practical guide .
acknowledgement this research was supported by the research council of norway rcn funded certus sfi.
shuai wang is also supported by rff hovedstaden funded mbe cr project.
tao yue and shaukat ali are also supported by rcn funded zen configurator project the eu horizon project funded u test rff hovedstaden funded mbe cr project and rcn funded mbt4cps project.
a1 select a category only convergence or coverage ?
a2 select ed tf yes ideal objective set known tf ?yes a3 select one from gd ed and c ee no a4 select igd tf combination ?no yes objectives lr yesno reference point known tf ?
a5 select hv tf yes a6 select one from hv and igd ee no no ideal objective set known ?
tf a7 select ed pfs and gs ee and tf yes same performance ?
yesno a8 select pfs gs and one from gd ed and c ee a9 go for combination categoryno figure a practical guide for choosing quality indicators 640references m. harman s.a. mansouri and y. zhang search based software engineering a comprehensive analysis and review of trends techniques and applications technical report tr department of computer science king college london .
m. harman making the case for morto mult i objective regression test optimization proc.
of the ieee fourth international conference on software testing verification and validation workshops pp.
.
s. ali l.c.
briand h. hemmati and r. k panesar walawege a systematic review of the application and empirical investigation of search based test case generation ieee transactions on software engineering pp.
.
s. yoo and m. harman pareto efficient multi objective test case selection proc.
of international sy mposium on software testing and analysis issta pp.
.
y. zhang a. finkelstein and m. harman search based requirements op timization existing work and challenges requirements engineering foundation for software quality pp.
.
s. wang s. ali and a. gotlieb cost effective test suite minimization in product lines using search techniques journal of systems and software vol .
c. henard m. papadakis m. harman and y.l.
traon combining multi objective search and constraint solving for configuring large software product lines proc.
of the 37th international conference on software engineering icse .
s. wang s. ali t. yue and m. liaaen upmoa an improved search algorithm to support user prefer ence multi objective optimization proc.
of international symposium on software reliability engineering pp.
.
j.j. durillo a.j.
nebro jmetal a java framework for multi objective optimization advances in engineering software pp.
.
.
s. wang s. ali and a. gotlieb and m. liaaen a systematic test case selection methodology for product lines results and insights from an industrial case study empirical software engineering journal pp.
.
y. li t. yue s. ali k. nie and l. zhang zen reqoptimizer a search based approach for requirements assignment optimization empirical software engineering journal .
a.s. sayyad t. menzies h. ammar on the value of user preferences in search based software engineering a case study in software product lines proc.
of the international conference of software engineering icse .
a.s. sayyad h. ammar pareto optimal search based software engineering posbse a literature survey proc.
of 2nd international workshop on realizing artificial intelligence synergies in software engineering .
y. zhang and m. harman and a. mansouri the sbse repository a repository and analysis of authors and research articles on search based software engineering crest centre ucl .
s. wang d. buchmann s ali a. gotlieb d. pradhan and m. liaaen multi objective test prioritization in software product line testing an industrial case study proc.
of the 18th international software product line conference pp.
.
s. wang s. ali and a. gotlieb minimizing test suites in software product lines us ing weighted based genetic algorithms proc.
of the genetic and evolutionary computation conference gecco pp.
.
j. brownlee clever algorithms nature inspired programming recipes isbn .
k. deb a. pratap s. agarwal and t. meyarivan a fast and elitist multiobjective genetic algorithm nsga ii ieee trans on evolutionary computation pp.
.
a.j.
nebro j.j. durillo f. luna b. dorronsoro and e. alba design issues in a multiobjective cell ular genetic algorithm evolutionary multi criterion optimization pp.
.
e. zitzler m. laumanns and l. thiele spea2 improving the strength pareto evolutionary algori thm proc.
of the eurogen evolutionary methods for design optimization and control with applications to industrial problems pp.
.
j.d.
knowles and d.w. corne approximating the nondominated front using the pareto archived evolution st rategy evolutionary computation .
a.j.
nebro j.j. durillo j. garcia nieto c.a.
coello coello f. luna and e. alba smpso a new pso based metaheuristic for multi objective optimization proc.
of the symposium on computational in telligence in multicriteria decision making mcdm pp.
.
j.j. durillo a.j.
nebro f. luna and e. alba solving three objective optimization problems using a new hybrid cellular genetic algorithm parallel problem solving from nature ppsn x .
lecture notes in computer science pp.
.
s. wang s. ali t. yue .
bakkeli m. liaaen enhancing test case prioritization in an industrial setting with resource awareness and multi objective search proc.
of the th international conference on software engineering .
t. yue and s. ali applying search algorithms for optimizing stakeholders familiarity and balancing workload in requirements assignment proc.
of acm genetic and evolutionary computation conference gecco pp.
.
j. knowles l. thiele and e. zitzler a tutorial on the performance assessm ent of stochastic multiobject ive optimizers computer engi neering and networks laboratory tik eth zurich tik report feb. .
k. deb multi objective optimization using evolutionary algorithms john wiley sons .
e. zitzler l. thiel e multiobjective evolutionary algorithms a comparative case study and the strength pareto approach ieee trans evol comput .
d.a.
van veldhuizen g.b.
lamont multiobjective evolutionary algorithm research a history and analysis tech.
rep. tr dept.
elec.
comput.
eng.
graduate school of eng.
air force inst.technol.
wright patterson afb oh .
t. yue s. ali and b. selic cyber physical system product line engineering comprehensive domain analysis and experience report proc.
of international conference on software product line pp.
.
l. briand d. falessi s. nejati m. sabetzadeh and t. yue research based innovation a tale of three project s in model driven engineering proc.
of acm ieee 15th international conference on model driven engineering languages and systems models pp.
.
j.l.
cochrane and m. zeleny multiple criteria decision making university of south carolina press .
c.m.
fonseca p.j.
flemming multiobjective optimization and multiple constraint handling with evolutionary algorithms part ii application example ieee trans system man cybern pp.
.
m. tanaka h. watanabe y. f urukawa t. tanino g a based decision support system for multicriteria optimization proc.
of the ieee international conference on systems man and cybernetics vol.
pp.
.
a.j.
nebro f. luna e. alba b. dorronsoro j.j. durillo and a. beham abyss adapting scatter search to multiobjective optimization ieee trans evol comput pp.
.
.
a. zhou y .
jin q. zhang b. sendhoff and e. tsang combining model based and genetics based offspring generation for multi objective optimization using a convergence criterion proc.
of ieee congress on evolutionary computation cec pp.
.
.
w. k. g. assun o t. e. colanzi a. t. r. pozo and s. r. vergilio establishing integration test orders of classes with several coupling measures proc.
of gecco dublin ireland pp.
.
.
j. t. de souz a c. l. maia f. g. de freitas and d. p. coutinho the human competitiveness o f search based software engineering proc.
of ssbse pp.
.
m. li s. yang and x. liu diversity comparison of pareto front approximations in many objective optimization ieee trans cybern pp.
.
j. m. chaves gonz lez and m. a. p rez toledano differential evolution with pareto tournament for the multi objective next release problem applied mathematics and computation vol.
pp.
.
amarjeet and j. k. chhabra an empirical study of the sensitivity of quality indicator for software module clustering proc.
of 7th international conference on contemporary computing ic3 pp.
.
w.k.g.
assun o t.e.
colanzi s.r.
vergilio and a. pozo a multi objective optimization approach for the integr ation and test order problem information sciences vol.
pp.
.
g. guizzo t.e.
colanzi and s.r.
vergilio a pattern driven mutation operator for search based product line architecture design proc.
of the 6th international symposium on search based software engineering ssbse pp.
.
m. harman y. jia j. krinke w.b.
lang don j. petke and y. zhang search based software engineering for software product line engineering a survey and directions for future work proc.
of the 18th international software product line conference splc pp.
.
v. hrub b. k ena z. letko h. pluh kov and t. vojnar multi objective genetic optimization for noise based testing of concurrent software proc.
of the 6th international sym posium on search based software engineering ssbse pp.
.
m.r.
karim and g. ruhe bi objective genetic search for release planning in support of themes proc.
of the 6th international symposium on search based software engineering ssbse pp.
.
l. li m. harman e. letier and y. zhang robust next release problem handling uncertainty during optimization proc.
of the conference on genetic and evolution ary computation gecco pp.
.
r.e.
lopez herrejon j. ferrer f. chicano a. egyed and e. alba comparative analysis of classical multi objective evolutionary algorithms and seeding strategies for pairwise testing of software product lines proc.
of ieee congress on evolutionary computation cec pp.
.
f. luna d.l.
gonz lez lvarez f. chicano and m.a.
vega rodr guez the software project scheduling problem a scalability analysis of multi objective metaheuristics applied soft computing vol.
pp.
.
m.w.
mkaouer m. kessentini s. bechikh k. deb and m. .
cinn ide high dimensional search based software engineering finding tradeoffs among objectives for automating software refactoring using nsga iii proc.
of the conference on genetic and evolutionary computatio n gecco pp.
.
m.w.
mkaouer m. kessentini s. bechikh and m. .
cinn ide a robust multi objective approach for software refactoring under uncertainty proc.
of the 6th international symposium on search based software engineering ssbse pp.
.
s. nejati and l.c.
briand identifying optimal trade offs between cpu time usage and temporal constraints using search proc.
of the international symposium on software testing and analysis issta pp.
.
a. ramrez j.r .
romero and s. ventura on the performance of multiple objective evolutionary algorithms for software architecture discovery proc.
of conference on genetic and evolutionary computat ion gecco pp.
.
l.s.
de souza r.b.c.
prudencio and f.a.
barros a comparison study of binary multi objective particle swarm optimization approaches for test case selection proc.
of the ieee congress on evolutionary computation cec pp.
.
a. sureka requirements prioritization and next release problem under non additive value conditions proc.
of the 23rd australian software engineering conference aswec pp.
.
w.k.g.
assun o t.e.
colanzi s.r.
vergilio and a. pozo on the application of the multi evolutionary and coupling based approach with different aspect class integration testing strategies proc.
of the 5th international symposium on search based software engineering ssbse pp.
.
m. bozkurt cost aware pareto optimal test suite minimisation for service centric systems proc.
of the conference on genetic and evolutionary computation gecco pp.
.
l.c.
briand y. labiche and k. chen a multi objective genetic algorithm to rank state based test cases proc.
of the 5th international symposium on search based software engineering ssbse pp.
.
m.w.
mkaouer m. kessentini s. bechikh and d.r.
tauritz preference based multi objective software modelling proc.
of 1st international workshop on combining modelling and search based software engineering cmsbse pp.
.
a. ouni m. kessentini h. sahraoui and m.s.
hamdi the use of development history in sof tware refactoring using a multi objective evolutionary algorithm proc.
of conference on genetic and evolutionary computation gecco pp.
.
a. arcuri and l.c.
briand a practical guide for using statistical tests to assess randomized alg orithms in software engineering proc.
of international conference on software engineering icse pp.
.
m.o.
barros and a.c. dias neto threats to validity in search based software engineering empirical studies unirio universidade federal do estado do rio de janeiro0006 .
d.j.
sheskin handbook of parametric and nonparametric statistical procedures .
m. kendall a new measure of rank correlation .
biometrika .
e. zizler j. knowles and l. thiele quality assessment of pareto set approximations multiobjective optimization lecture notes in computer science pp.
.