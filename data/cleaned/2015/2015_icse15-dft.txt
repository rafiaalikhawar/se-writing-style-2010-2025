combining symbolic execution and model checking for data flow testing ting su zhoulai fuygeguang pu zjifeng he zhendong suy shanghai key laboratory of trustworthy computing east china normal university shanghai china ydepartment of computer science university of california davis usa email tsuletgo gmail.com zlfu ucdavis.edu ggpu sei.ecnu.edu.cn zcorresponding author jifeng sei.ecnu.edu.cn su cs.ucdavis.edu abstract data flow testing dft focuses on the flow of data through a program.
despite its higher fault detection ability over other structural testing techniques practical dft remains a significant challenge.
this paper tackles this challenge by introducing a hybrid dft framework the core of our framework is based on dynamic symbolic execution dse enhanced with a novel guided path search to improve testing performance and we systematically cast the dft problem as reachability checking in software model checking to complement our dsebased approach yielding a practical hybrid dft technique that combines the two approaches respective strengths.
evaluated on both open source and industrial programs our dse based approach improves dft performance by in terms of testing time compared with state of the art search strategies while our combined technique further reduces testing time and improves data flow coverage by by eliminating infeasible test objectives.
this combined approach also enables the crosschecking of each component for reliable and robust testing results.
i. i ntroduction testing is the most widely adopted software validation technique.
structural coverage criteria such as statement branch and logical have been widely used to assess test adequacy.
in contrast to these structural criteria data flow criteria focus on the flow of data through a program i.e.the interactions between variable definitions and their corresponding uses.
the motivation is to verify the correctness of defined variable values by observing that all corresponding uses of these values produce the desired results.
according to several empirical studies dataflow criteria are more effective than control flow based testing criteria e.g.statement or branch .
however several reasons hinder the adoption of data flow testing in practice.
first few data flow coverage tools exist .
to our knowledge atac is the only available tool to compute data flow coverage for c programs developed two decades ago.
second the complexity of identifying data flow based test data overwhelms software testers test objectives w.r.t.
data flow criteria are much more than those of structural criteria more efforts are required to derive a test case to cover a variable definition and its corresponding use than just covering a statement or branch.
third infeasible test objectives i.e.paths from definitions to their uses are infeasible and variable aliases make data flow testing more difficult.
the aforementioned challenges underline the importance of effective automated data flow testing.
to this end this paper presents a combined approach to automatically generate data flow based test data.
our approach synergistically combines twotechniques dynamic symbolic execution and counterexampleguided abstraction refinement based model checking.
at the high level given a program as input our approach outputs test data for feasible test objectives and eliminates infeasible test objectives without any false positives .
dynamic symbolic execution dse is a widely accepted and effective approach for automatic test data generation.
it intertwines traditional symbolic execution with concrete execution and explores as many program paths as possible to generate test cases by solving path constraints.
as for counter example guided abstraction refinement based cegar model checking given the program source and a temporal safety specification it either statically proves that the program satisfies the specification or produces a counterexample path that demonstrates the violation.
it has been applied to automatically verify safety properties of os device drivers and generate test data w.r.t.
statement or branch coverage from counterexample paths.
although dse has been widely adopted to achieve different coverage criteria e.g.
branch logical boundary value and mutation testing little effort exists to adapt dse to data flow testing.
to mitigate path explosion in symbolic execution we design a guided path search strategy to cover data flow test objectives as quickly as possible.
with the help of concrete executions in dse we can also more easily and precisely detect definitions due to variable aliasing.
moreover we introduce a simple powerful encoding of data flow testing using cegar based model checking to complement our dsebased approach we show how to encode any data flow test objective in the program under test and systematically evaluate the technique s practicality and we describe a combined approach that combines the relative strengths of the dse and cegar based approaches.
an interesting by product of this combination is to let the two independent approaches cross check each other s results for correctness and consistency.
we have implemented our data flow testing framework and the guided path search strategy on top of a dse engine named caut which has been continuously developed and refined in previous work .
we perform data flow testing on four open source and two industrial programs in c. by comparing the performance of our proposed search strategy against other popular search strategies our dse based approach can improve data flow testing by in terms of testing time.
in addition we have adapted the cegar based approach to complement the dse based approach.
evaluation results show that it can reduce testing time by than using the cegar based approach alone and improve coverage by than using the dse based approach alone.
thus indeedour combined approach provides a more practical means for data flow testing.
in summary we make the following main contributions we design a dse based data flow testing framework and enhance it with an efficient guided path search strategy to quickly achieve data flow coverage criteria.
to our knowledge our work is the first to adapt dse for data flow testing.
we describe a simple effective reduction of data flow testing to reachability checking in software model checking to complement our dse based approach.
again to our knowledge we are the first to systematically adapt cegar based approach to aid data flow testing.
we realize the dse based data flow testing approach and conduct empirical evaluations on both open source and industrial c programs.
our results show that the dse based approach is both efficient and effective.
we also demonstrate that the cegar based approach effectively complements the dse based approach by further reducing data flow testing time and detecting infeasible test objectives.
in addition these two approaches can cross check each other to validate the correctness and effectiveness of both techniques.
the rest of the paper is organized as follows.
section ii introduces necessary background and gives an overview of our data flow testing approach.
section iii details our dsebased approach and our reduction of data flow testing to reachability checking in model checking.
next we present details of our implementation section iv and empirical evaluation section v .
section vi surveys related work and section vii concludes.
ii.
o verview a. problem setting a program path is a sequence of control points denoted by line numbers written in the form l1 l2 l n. we distinguish two kinds of paths.
a control flow path is a sequence of control points along the control flow graph of a program an execution path is a sequence of executed control points driven by a program input.
following the classic definition from herman a def use pairdu ld lu x occurs when there exists at least one control flow path from the assignment i.e.definition ordefin short of variable xat control point ldto the statement at control point luwhere the same variable xis used i.e.use on which no redefinitions of xappear i.e.the path is def clear .
definition data flow testing given a def use pair du ld lu x in program p the goal of data flow testing is to find an input tthat induces an execution path that covers i.e.
passes through ldand then luwith no intermediate redefinitions ofxbetween ldandlu.
the requirement to cover all def use pairs at least once is called all def use coverage criterion .
in this paper we use dynamic symbolic execution dse to generate test inputs to satisfy def use pairs.
the dsebased approach starts with an execution path triggered by an initial test input and then iterates the following from an execution path p l1 l i li l n dse picks an1double power int x int y int exp double res if y exp y else exp y res while exp!
res x exp if y if x abort else return .
res return res input x y5 exp y7 exp y8 res res x return .
res18 return res15 abort11 exp y y exp !
x 0tf fffttt fig.
.
an example power .
executed branch i.e.a branching node1 of a conditional statement at li the choice depends on an underlying search strategy .
it then solves the path constraint collected along l1 l i 1conjuncted with the negation of the executed branch condition at lito find a new test input.
this input will be used as a new test case in the next iteration to generate a new path p0 l1 l i li which deviates from the original path pat li the opposite branch direction of the original executed branch at li but shares the same path prefix l1 l i 1with p. if the target def use pair is covered by this new path p0 cf.definition we obtain the test case which satisfies this pair.
otherwise the process will continue until a termination condition e.g.a time bound is reached or the whole path space has been explored is met.
although the dse based technique is an effective way to generate test inputs to cover specified program points it faces two challenges when applied in data flow testing the dse based technique by nature faces the notorious path explosion problem.
it is challenging in reasonable time to find an execution path from the whole path space to cover a target pair .
the test objectives from data flow testing include feasible andinfeasible pairs.
a pair is feasible if there exists an execution path which can pass through it.
otherwise it is infeasible .
without prior knowledge about whether a target pair is feasible or not dsebased approach may spend a large amount of time in vain to cover an infeasible def use pair.
b. an illustrative example we give an overview of our approach via a simple program power figure which takes as input two integers xandyand outputs xy.
its control flow graph is shown in the right column in figure .
for illustration we will explain how our approach deals with the aforementioned challenges demonstrated by the 1abranching node is an execution instance of an original branch in the code.
when a conditional statement is inside a loop it can correspond to multiple branching nodes along an execution path.following two pairs w.r.t.
the variable res du1 l8 l17 res du2 l8 l18 res we combine dse to quickly cover du1and cegar to prove du2is infeasible.
the details of these two approaches are explained in section iii.
dse based data flow testing dse starts by taking an arbitrary test input t e.g.t x7!
y7!
.
this test input triggers an execution path p p l4 l5 l8 l9 l10 l11 l9 l10 l11 z repeated 42times l9 l13 l18 which covers the defofdu1atl8.
to cover its use the classical dse approach e.g.with depth first or random path search will systematically flip branching nodes on pto explore new paths until the useis covered.
however the problem of path explosion hundreds of branching nodes on path p including nodes from new paths generated from p can be flipped to fork new paths could greatly slow down the exploration.
we use two techniques to tackle this problem.
first we use the redefinition pruning technique to remove invalid branching nodes resis detected as redefined on pat l10in dynamic execution so it is useless to flip the branching nodes after the redefinition point the paths passing through the redefinition point cannot satisfy the pair .
to illustrate we cross out these invalid branching nodes on pand highlight the rest in .
as we can see a large number of invalid branching nodes can be pruned.
p l4 l5 l8 l9 l10 l11 l9 l10 l11 z repeated 42times l9 l13 l18 second we use the cut point guided search cpgs strategy to decide which branching node to select first.
the cut points w.r.t.
a pair is a sequence of control points that must be passed through when searching for a path to cover the pair.
they serve as intermediate goals during the dynamic search and narrow down the search space.
for example the cut points ofdu1 l8 l17 res arefl4 l8 l9 l13 l14 l17g.
since the pathpin covers the cut points l4 l8andl9 the uncovered cut point l13is set as the next search goal.
from p there are two unflipped branching nodes 4fand9f denoted by their respective line numbers followed with torfto represent the true orfalse branch direction .
because 9fis closer to cut point l13in control flow graph than 4f so9fis flipped.
as a result a new test input t x7!
y7!
can be generated and leads to a new path p0 l4 l6 l7 l8 l9 l13 l14 l15.
now the path p0has covered the cut points l4 l8 l9 l13andl14 and the uncovered cut point l17becomes the goal.
from all remaining unflipped branching nodes i.e.4f 13fand14f the branching node 14fis chosen because it is closer than the others toward the goal.
consequently a new test input t x7!
y7!
is generated which covers all cut points anddu1 l8 l17 res itself.
here the cut point guided path search takes only three iterations to cover this pair.
cegar based data flow testing the def use pair du2 l8 l18 res is infeasible if there were a test input that could reach the use it must satisfy y atl13.
since yhas not been modified in the code y also holds at l4.
as a result 1double power int x int y bool cover flag false int exp double res ... res cover flag true while exp!
res x cover flag false exp ... if cover flag check point return res fig.
.
the transformed function power and the encoded test requirement in highlighted statements.
reswill be redefined at l10since the loop guard at l9istrue.
clearly no such a path exists for this pair which can both avoid redefinitions in the loop and reach the use.
in this case if the dse based approach is used it may enter into an infinite loop unfolding and cannot conclude the infeasiblity of this pair.
to mitigate this problem we leverage the cegar based approach to check feasibility.
this approach starts with a coarse program abstraction and iteratively refines it.
if a property violation is found it analyzes the feasibility i.e.
is the violation genuine or the result of an incomplete abstraction?
.
if the violation is feasible a counterexample path is returned.
otherwise the proof of infeasibility is used to refine the abstraction and the checking continues.
in our context the basic idea is to encode the test requirement of a pair into the program under test and reduce the testing problem into this reachability checking problem.
figure shows the transformed function power which is encoded with the test requirement of du2in highlighted statements.
we introduce a variable cover flagat l2.
it is initialized to false and set as true immediately after the defatl7 and set to false immediately after the other definitions on variable resatl10.
before the use we set a checkpoint to see whether cover flagistrue atl14.
if the checkpoint is unreachable this pair can be proved infeasible.
otherwise a counter example i.e.a test case that covers this pair through a def clear path can be generated.
here the cegar based approach can quickly conclude du2is an infeasible pair.
combined dse cegar based data flow testing from the above two examples we can see that the dse based approach as a dynamic path based testing approach can efficiently cover feasible pairs while the cegar based approach as a static model checking based approach can eliminate infeasible ones.
it is beneficial to combine the two approaches respective strengths to tackle the challenges in data flow testing.
feasibleinfeasibledsecegar the figure above shows the relation between the two approaches the dse based approach is able to cover feasible pairs more efficiently but in general it cannot identify infeasible pairs because of path explosion while the cegar data flow analysisdominator analysisprogramcoverage testdse enginesyntax transformercegar engineinfeasible def use pairtest input covering the def use pairdef use pairprogram static analysisdse based approachrandom test input execution path cut points c1 c2...cn a new test inputcegar based approach infeasibility proofcounter example uncovered cut point ci fig.
.
the workflow of the combined dse cegar based approach based approach is capable of identifying infeasible pairs more effectively it can also cover feasible pairs as well .
figure illustrates the basic workflow of the combined dsecegar approach in our data flow testing framework.
the static analysis is used to find def use pairs and their cut points from the program under test.
the dse based approach is first used to cover as many feasible pairs as possible within a time bound on each pair .
after the dse based testing for the remaining uncovered pairs we use the cegar based approach to identify infeasible pairs and cover new feasible pairs which have not yet been covered in dse within a time bound.
after one run of the dse cegar based testing we can increase the time bound for both approaches and repeat the above process.
if testing budgets permit it can cover more feasible pairs and identify more infeasible pairs.
the details of these two approaches are explained in section iii.
iii.
a pproach in this section we explain the combined dse cegar based data flow testing framework in detail.
it consists of a static analysis phase and a dynamic analysis phase.
a. static analysis phase we use standard iterative data flow analysis algorithms to identify def use pairs from the program under test see section iv for details .
definition cut point given a def use pair its cut points are a sequence of control points that have to be passed through in succession by any control flow path covering the pair.
each control point in this sequence is called a cut point .
hqwu obxo obgo o o o o for illustration consider the figure above let du ld lu x be the target def use pair the sequence of cut points of duis l1 l3 ld l6andlu.
here l2is not a cut point because a pathl1 l3 ld l5 l6can be constructed to cover the def use pair without passing through l2.
the cut points of each def use pair are computed via a context sensitive dominator analysis on the inter procedural control flow graph.algorithm dse based data flow testing input du ld lu x a def use pair input c1 c2 cn cut points of du output input tthat satisfies duornilif none is found 1letwbe a worklist of branching nodes initialized as empty 2lettbe an initial test input 3repeat letpbe the execution path triggered by t ifpcovers duthen return t w w fbranching nodes on pg the redefinition pruning heuristic ifvariable x indu is redefined after ldonpthen letxdenote the set of branching nodes after the redefinition location w wnx lett guided search w 11until t nil 12return nil 14procedure guided search reference worklist w 15letb0denote the branch to be flipped 16ifwis empty then return nil jis the index of a cut point dis the distance variable 18j d 19forall the branching node b2wdo lbis the program location of b letppbe the path prefix of b i.e.l1 l2 lb c1 ci 1are sequentially covered while cinot yet i index of the uncovered cut point cionpp bis the opposite branch of b ifi j i j distance b ci d then b0 b j i d distance b ci 24w wnfb0g lb0is the opposite branch direction of the original b0atlb0 25if9input tdriving the program through l1 l2 lb0 then return t 27else return guided search w b. dse based approach for data flow testing this section explains the dse based data flow testing approach enhanced with our cut point guided path search strategy .
this search strategy embodies several intuitions to perform efficient path search to cover a target def use pair.
algorithm details this approach.
algorithm takes as input a target def use pair du ld lu x and the sequence of its cut points.
if an execution path pcovers the target pair the algorithm returns the input t at line .
otherwise it stores the branching nodes on pinto the worklist w which contains all branching nodes from the explored execution paths.
we first use the redefinition pruning technique explained later to remove invalid branching nodes at lines .
then we start the path search to generate a new test input in the procedure guided search .
in this procedure we first aimto find a branching node bwhose path prefix has covered the deepest cut point of the pair at lines .
the path prefix of a branching node bis the path prefix of the corresponding execution path which reaches up to the location of b i.e.
l1 l2 lb.
if the path prefix of bhas sequentially covered the cut points c1 c2 ci butciis uncovered then ci 1is the deepest covered cut point.
the intuition is that the deeper the cut point a path can reach the closer a path toward the pair is.
the cut points of a pair act as a set of search goals to follow during the dynamic search.
note the defanduseof a pair also servers as cut points.
if two branching nodes have reached the same deepest cut point indicated by i jat line the algorithm picks the branching node whose opposite branch has the shortest distance toward the uncovered cut point ci at lines .
here we use distance b ci to represent the distance between the opposite branch of b i.e.
b and the uncovered cut point ci.
the intuition is that a shorter path is easier to reach the goal.
here the distance is approximated as the number of instructions between one statement and another.
the shortest distance is the number of instructions along the shortest control flow path from the start statement to the target statement in the control flow graph .
if the picked branching node can be exercised i.e.
the corresponding path constraint is satisfiable a new test input will be returned at lines .
otherwise it will continue to pick another branching node from w at line .
in addition definition requires that no redefinitions appear on the subpath between the defand the use.
thus it is useless to pick the branching nodes that follow the redefinition locations.
we can prune these invalid branching nodes to reduce testing time in aglorithm lines .
further by taking advantage of concrete program executions in dse we can track variable redefinitions caused by variable aliases more easily than the static symbolic execution techniques .
variable aliases appear at a program statement during execution when two or more names refer to the same variable.
we use a lightweight algorithm to detect variable redefinitions w.r.t.
a target def use pair.
in our framework we operate upon a simplified threeaddress form of the original source code2.
so we mainly focus on the following statement forms where variable aliases and variable redefinitions may appear alias inducing statements p q pis an alias to q p v pis an alias to v variable definition statements p x pis defined byx v x vis defined by x here pandqare pointer variables v xare non pointer variables is an assignment operation.
the variable definitions are detected by static analysis beforehand.
the algorithm works as follows to dynamically identify variable redefinitions we maintain a set ato record variable aliases w.r.t.
a pair du ld lu v .
initially aonly contains the variable vitself.
if statement or is executed and qorv2a a new variable alias pwill be added into abecause pbecomes an alias to qorv.
if statement is executed and q 2abut p2 a then pwill be removed from abecause pbecomes an alias to another variable instead of v. if statement or is executed and porv2a then the variable vis redefined by another variable x.
2we use cil as the c parser to transform the source code into an equivalent simplified form using the dosimplify option where one statement contains at most one operator.c.
cegar based approach for data flow testing the counterexample guided abstract refinement cegar based approach has been extensively used to check safety properties of software as well as test case generation e.g.statement or branch testing .
the cegar based approach operates in two phases i.e.
model checking and tests from counter examples .
it first checks whether the program location lof interest is reachable such that a target predicate p i.e.
a safety property is true at l. if so from the program path that witnesses patl a test case can be generated from the counterexamples to establish the validity of patl.
otherwise iflis unreachable the model checker can conclude that no test input can reach this point.
in data flow testing due to the conservativeness of data flow analysis test objectives contain infeasible pairs .
in order to identify infeasible pairs we introduce a simple but powerful encoding of data flow testing using the cegar based approach.
we instrument the original program ptop0and reduce the problem of test data generation to reachability checking on p0.
a variable cover flagis introduced and initialized to false before the def.
this flag is set to true immediately after the def and set to false immediately after the other definitions on the same variable.
before the use we set the target predicate pas cover flag true .
as a result if the uselocation is reachable when pholds we obtain a counterexample and conclude that the pair is feasible.
otherwise the pair is infeasible or since the general problem is undecidable it does not terminate and the result can only be concluded as unknown .
iv.
i mplementation the data flow testing framework is built on top of a dse engine named caut3 which includes two analysis phases a static analysis and a dynamic analysis.
the static analysis phase collects def use pairs cut points and other static program information from programs by using cil4 an infrastructure for c program analysis and transformation .
we perform standard iterative data flow analysis to find intra procedural and inter procedural def use pairs for c programs.
we first build the control flow graph cfg for each function and then construct the inter procedural control flow graph icfg .
for each variable use we compute which definitions on the same variable may reach this use.
a defuse pair is created as a test objective for each use with its corresponding definition.
we consider local and global variables in our data flow analysis and treat each formal parameter variable as defined at the beginning of its function each actual parameter variable as used at its function call site e.g.library function calls global variables as defined at the beginning of the entry function e.g.main .
following recent work on data flow testing we currently do not consider def use pairs caused by pointer aliasing.
thus we may miss some def use pairs but this is an independent issue and does not affect the effectiveness of our approach.
more sophisticated data flow analysis techniques could be used to mitigate this problem.
the dynamic analysis phase performs dynamic symbolic execution on programs.
we extend the original dse engine to whole program testing which uses z35as the constraint solver.
function stubs are used to simulate c library functions 3caut 4cil 5z3 as string memory and file operations to improve symbolic reasoning ability.
we use cil to encode the test requirement of a def use pair into the program under test which is used as the input to model checkers.
the dse engine and the model checkers works on the same cil simplified code.
v. e valuation and results this section presents our evaluation to demonstrate the practical effectiveness of our approach for automated data flow testing.
our results on six benchmark programs show that our dse based approach can greatly speed up data flow testing it reduces testing time by than standard search strategies from state of the art symbolic executors crest and klee and our combined approach is effective it applies the dse based tool caut to cover as many feasible defuse pairs as possible and then applies the cegar based model checkers blast cpachecker to identify infeasible pairs.
overall it reduces testing time by than the cegarbased approach alone and improves data flow coverage by than the dse based approach alone.
a. evaluation setup all evaluations were run on a laptop with processors .67ghz intel r i7 and 4gb of memory running 32bit ubuntu gnu linux .
.
search strategies to assess the performance of our proposed guided path search strategy for data flow testing we choose the following search strategies to compare against random input ri it generates random test inputs to drive program executions which is a classic method to generate data flow based test data .
random path search rps it randomly chooses a path to exercise which is commonly adopted in many symbolic executors .
cfg directed search in crest it prefers to drive the program execution down the branch with the minimal distance toward uncovered branches on the icfg and also uses a heuristic to backtrack or restart the search under certain failing circumstances.
rp md2u search in klee it uses a roundrobin of a breadth first search strategy with a mindistance to uncovered heuristic.
the breadth first strategy favors shorter paths but treats all paths of the same length equally.
the min distance to uncovered heuristic prefers the paths with minimal distance to uncovered statements on icfg.
shortest distance guided search sdgs it prefers to choose the path that has the shortest distance toward a target statement in order to reach the statement as quickly as possible.
this strategy has been applied in single target testing .
in the context of data flow testing the search first sets the defas the first goal and then the useas the second goal after the defis covered.
bechmarks we use six benchmark programs.
four are from the software artifact infrastructure repository sir6 including tcas replace printtokens2 and space .
they are also used in other work on data flow testing .
we also take 6sir i. t estsubjects from sir and industrial research partners benchmark loc du description tcas collision avoidance system replace pattern matching and substitution printtokens2 lexical analyzer space array definition language interpreter osek os engine management system space control satellite gesture control two industrial programs from research partners.
one is an engine management system running on an automobile operating system osek os conforming to the osek vdx standard.
the other is a satellite gesture control program space control .
these two industrial programs feature complicated execution logic.
the detailed descriptions and statistics are listed in table i where loc denotes the number of lines of source code and du the number of collected def use pairs.
research questions in our evaluation we intend to answer the following key research questions rq1 in data flow testing w.r.t.
all def use coverage what is the performance difference among different search strategies i.e.
ri rps crest i.e.
cfgdirected search klee i.e.
rp md2u search sdgs and cpgs cut point guided search in terms of search time program iterations and coverage level?
rq2 how effective is the combined approach the dse based approach complemented with the adapted cegar based approach for data flow testing?
metrics and setup in the evaluation we use the following metrics and experimental setup in rq1 the search time number of program iterations and coverage are recorded to measure the performance of different search strategies in the dse based approach.
we target one def use pair at a time.
the coverage percentage is calculated by c nfeasible ntestobj ninfeasible nfeasible ninfeasible is the number of identified feasible infeasible pairs ntestobj is the total number of pairs.
in the dse based approach nfeasible is the number of covered pairs.
since this approach in general cannot identify infeasible pairs ninfeasible is set as 0in coverage computation.
the search time is calculated by t pncovered k 1nsearchtime i nsearchtime iis the time spent on the ith covered defuse pair .
the number of program iterations is calculated by i pncovered k 1niterations i niterations iis the iterations of theith covered def use pair .
since the testing budget e.g.
search time and program iterations spent on an uncovered def use pair maybe an infeasible pair cannot indicate which search strategy is better only the testing budget spent on covered pairs is tabulated.
the maximum search time on each pair is set to seconds in case of its infeasiblilty.
we repeat the testing process times for each program strategy and use their the average values as the final results for all measurements.
the total testing time requires about two days.
in rq2 both the latest versions of the two state of the art cegar based model checkers blast7and cpachecker8are respectively used as black box testing engines.
in the evaluation we use the following command options and configurations 7blast .
.
8cpachecker .
.
to the suggestions from the tool maintainers and usage documentations blast ocamltune blast enable recursion cref lattice noprofile nosserr timeout quiet cpachecker cpachecker config config predicateanalysis.properties skiprecursion timelimit here the maximum testing time on each def use pair is set to seconds.
we use ocamltune an internal script to improve memory utilization for large programs to invoke blast.
for cpachecker we use its default analysis configuration.
the options enable recursion in blast and skiprecursion in cpachecker are both used to set recursion functions as skip.
for each def use pair we run times and use the average execution time as its final value.
we run the single cegar based approach and the combined dsecegar based approach which operates as follows the dsebased approach use the cut point guided path search strategy with the same time setting in rq1 is first used to cover as many feasible pairs as possible for the remaining uncovered pairs the cegar based approach is used to identify infeasible paris and may cover some feasible pairs which have not been found by the dse based approach.
in the evaluation we conduct one run of the combined dse cegar based approach.
the distribution on testing time for one pair is also given median the semi interquartile range siqr i.e.
q3 q1 q1 the lower quartile q2 the upper quartile and the number of outliers which fall siqr below q1 or above q3.
comparison criterion a better search strategy or approach in data flow testing requires less testing time costs fewer program iterations and or achieves higher data flow coverage.
b. results and analysis rq1 the cut point guided search performs the best in table ii the performance statistics of different search strategies are listed.
in column evaluation ri rps crest klee sdsg cpgs respectively represents the corresponding search strategies introduced before.
in column performance result it shows the search time t program iterations i and data flow coverage percentage c .
in column distribution it shows the distribution on testing time for a single pair median m and siqr.
from table ii we can see that the cut point guided path search strategy cpgs achieves the overall best performance against the other search strategies.
as expected in general the cpgs strategy requires less testing time and costs much fewer iterations than other search strategies to achieve higher data flow coverage.
it narrows the search space by following the cut points and further improves the performance by pruning redefinition paths.
from column distribution the median search time of one def use pair in the cpgs strategy is lower than that of rp crest klee sdgs respectively.
thus cpgs is more efficient in data flow testing.
in figure we give the column diagrams on each strategy program in the terms of search time program iterations and data flow coverage respectively.
on average compared with crest klee and sdsg the cpgs strategy reduced .
.
and .
in search time and .
.
.
in program iterations respectively.
compared with rps it roughly improves data flow coverage by .
.
compared with these novel and widely used search strategies from manytable ii.
p erformance statistics of different search strategies in data flow testing .
ri random input rps random path search crest cfg directed search in crest klee rp md2u search in klee sdgs shortest distance guided search cpgs the cut point guided search means it exceeds minutes means we do not count time unit is in seconds .
evaluation performance result distribution benchmark strategy t i c m siqr tcasri rps crest klee sdgs cpgs1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
replaceri rps crest klee sdgs cpgs1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
printtokens2ri rps crest klee sdgs cpgs1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
spaceri rps crest klee sdgs cpgs1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
osek osri rps crest klee sdgs cpgs1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
space controlri rps crest klee sdgs cpgs1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
symbolic execution executors the data clearly shows that the cpgs strategy is a more effective strategy for data flow testing.
however there are some interesting phenomenons worth elaborating.
ri gains higher data flow coverage for the program printtokens because it is easier for ri to quickly generate random combinations of characters inputs than other pathoriented search strategies but in general it can only cover limited number of def use pairs.
rps is faster than all the other search strategies for the program tcas because it is a small program with finite paths and other advanced strategies incur higher path scheduling overhead.
two novel search strategies crest and klee can usually cover more pairs in most programs than rps but they require more testing time.
we note that rps incurs much lower computation cost on path scheduling than crest and klee.
these two advanced strategies try to satisfy a pair by improving as much branches statements coverage as possible which demands more testing time.
the sdgs strategy is more effective than the other three general strategies i.e.
rps crest klee since it is guided by the distance metric toward the target pair.
however it is less effective than the cpgs strategy because the latter0 tcas replace prin4okens2 space osek os space control time ri rps crest klee sdgs cpgs a the search time in seconds tcas replace prin4okens2 space osek os space control itera9on ri rps crest klee sdgs cpgs b the program iterations .
.
.
.
.
.
tcas replace prin4okens2 space osek os space control coverage ri rps crest klee sdgs cpgs c the data flow coverage percentage fig.
.
the column diagrams the search time the program iterations and the data flow coverage of each benchmark search strategy.
table iii.
p erformance statistics of the dse based cegar based and the combination approach on data flow testing .
dse cegar1 and cegar2 corresponding to the approach of caut blast and cpa checker respectively .
means it does not apply .
evaluation coverage result time result distribution benchmark approach c cd ft it tt mf s o mi s o tcasdse cegar1 cegar2 dse cegar1 dse cegar273.
.
.
.6s 12m21s 07m57s .6s .6s04m30s 02m38s 04m49s 02m58s23.3s 01h10m 10m25s 18m53s 03m01s1.
.
.
.
.
.
.
.
replacedse cegar1 cegar2 dse cegar1 dse cegar260.
.
.
.
.
8005m28s 01h23m 01h09m 31m02s 29m58s15m06s 13m50s 21m06s 23m30s55m28s 05h45m 05h16m 03h56m 03h58m4.
.
.
.
.
.
.
.
printtokens2dse cegar1 cegar2 dse cegar1 dse cegar256.
.
.
.
.
.8s 01h45m 02h55m 19m12s 31m51s23m21s 10m30s 37m41s 28m50s44m36s 07h22m 06h18m 03h54m 03h12m72.
.
.
.
.
.
.
.
spacedse cegar1 cegar2 dse cegar1 dse cegar230.
.
.
.
.
157610m57s 24h37m 26h50m 01h32m 01h47m06h14m 05h33m 08h00m 08h28m11h44m 88h34m 87h02m 72h06m 71h32m105.
.
.
.
.
.
.
.
osek osdse cegar1 cegar2 dse cegar1 dse cegar271.
.
.
.
.
.6s 49m19s 50m35s 10m02s 14m52s09m22s 08m06s 44m02s 44m06s51m22s 02h40m 01h39m 01h54m 01h27m5.
.
.
.
.
.
.
.
space controldse cegar1 cegar2 dse cegar1 dse cegar264.
.
.
.
.
6304m47s 05h23m 07h31m 01h26m 44m59s56m40s 01h10m 02h27m 02h06m03h02m 07h57m 10h47m 06h22m 05h18m4.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas replace prin4okens2 space osek os space control total time dse cegar1 cegar2 dse cegar1 dse cegar2 a the total time .
.
.
.
.
.
tcas replace prin4okens2 space osek os space control coverage dse cegar1 cegar2 dse cegar1 dse cegar2 b the data flow coverage dse cegar1 cegar2 dse cegar1 dse cegar2 dse cegar1 cegar2 dse cegar1 dse cegar2 dse cegar1 cegar2 dse cegar1 dse cegar2 dse cegar1 cegar2 dse cegar1 dse cegar2 dse cegar1 cegar2 dse cegar1 dse cegar2 dse cegar1 cegar2 dse cegar1 dse cegar2 tcas replace prin okens2 space osek os space control coverage details unknown infeasible feasible c the coverage details feasible infeasible unknown pairs fig.
.
the column diagrams the total testing time the data flow coverage and the coverage details of the dse cegar and dse cegar approach.
contains more optimization techniques.
rq2 the combined approach is effective table iii lists the performance statistics of different approaches in data flowtesting.
in column evaluation dse cegar1 andcegar2 represents the single testing approach from caut blast and cpachecker respectively.
dse cegar1 cegar2 representsthe combined approach of dse and cegar.
column coverage result lists the data flow coverage c and the coverage details cd the number of feasible infeasible unknown pairs.
if a testing approach cannot give a definite conclusion on the feasibility of a pair within the given time bound we call this pairunknown .
column time result lists the testing time spent on feasible pairs ft infeasible pairs it and total pairs tt .
note the total testing time ttis the sum of ft it and the time spent on unknown pairs so ttshould be longer thantt ft. in column distribution mfandmirepresent the median testing time in seconds on identifying a feasible and an infeasible pair respectively sstands for siqr and ois the number of outliers in the cegar based approach.
note in general the dse based approach can only identify the feasible and unknown i.e.
uncovered pairs so we treat the uncovered pairs as unknown pairs while the cegar based approach can identify both feasible and infeasible pairs.
from table iii we can observe that the dse based approach can cover a large portion of feasible pairs detected by the cegar based approach see column cd .
moreover by comparing the testing time spent on feasible pairs between the dse based and the cegar based approach see column ft we can see that the dse based approach is very effective in covering feasible pairs.
a reasonable explanation is that the dse based approach is a dynamic explicit path based testing method while the cegar based approach is a static model checking based testing method.
the static approach requires much higher testing overhead.
on the other hand it is easier for the cegar based approach to identify infeasible pairs see column it while the dse based approach has to check all possible paths before confirming which pairs are infeasible.
so it is beneficial to combine the dse based approach with the cegar based approach to gain their respective advantages i.e.
reduce testing time on feasible pairs and improve coverage by eliminating infeasible pairs.
in figure we present the column diagrams of the total testing time normalized in percentage the data flow coverage and the coverage details of the dse based cegar based and the combined approach.
in detail the combination strategy can on average reduce total testing time by than the cegarbased approach alone.
it can also eliminate infeasible pairs more easily and on average improve data flow coverage by than the dse based approach alone.
thus the combined approach can provide a more practical way of data flow testing.
in table iii we also find that the testing performances of the two model checkers and their conclusions on the number of feasible infeasible pairs have some differences within the constrained testing time see column cd .
a reasonable explanation is that their underlying constraint solvers implementation languages search heuristics have different impact on testing performance.
they also have different performances on programs exhibiting different features.
for example in tcas all program inputs are integral while space control involves much floatingpoint computation and many struct union manipulations.
in addition the number of infeasible pairs detected by blast is generally fewer than that of cpachecker see column cd .
blast is slightly faster in identifying feasible pairs while cpachecker can usually identify infeasible pairs more quickly see column mfandmi .
discussion we have developed a simple yet powerful method to reduce data flow testing into model checking and used twocegar based state of the art model checkers to evaluate its practicality.
from the evaluations on two combination instances caut blast and caut cpachecker we observe a consistent trend the combined dse cegar based approach can greatly reduce testing time and improve data flow coverage than the two approaches alone.
in addition we have also used the dse and cegar based approach to cross check each other by comparing their results on the same def use pairs.
this helps to validate the correctness and consistency of both techniques and also make our testing results more reliable.
c. threats to validity first we implemented all search strategies on our cil based tool caut.
the original rp md2u strategy in klee uses the number of llvm instructions to measure the minimal distance between one instruction to another while caut uses cil instructions as its distance metric.
klee is a static symbolic executor while caut is a dynamic symbolic executor.
these differences may affect the performance of the rp md2u strategy on the benchmarks.
in addition the implementation of the two search strategies from crest and klee may differ from their original versions.
for these threats we carefully inspected the relevant source code and technical reports to ensure our implementation conformance and correctness.
the decision to engineer the data flow testing framework on our dse based tool is based on the following considerations crest does not support real numbers composite structures or pointer reasoning but these features are required in testing realworld programs and klee is a static symbolic executor thus it is more difficult to reason about possible variable redefinitions caused by variable aliasing than dynamic symbolic executors.
implementing all search strategies on top of the same tool provides the convenience to record and compare the testing performances of different search strategies.
second in our current implementation we do not identify defuse pairs caused by pointer aliasing in the risk of missing some def use pairs.
more sophisticated static or dynamic analysis techniques could be adopted to identify more def use pairs.
however we believe that this is an independent issue and not the focus of the work.
the effectiveness of our dse based and cegar based approach should remain.
as for possible external threats we have evaluated our approach on a small set of benchmarks which include programs used in previous data flow testing research as well as industrial programs.
from these programs the effectiveness of our approach is evident.
although it is interesting to consider additional test subjects due to our novel general methodologies we believe that the results should be consistent.
vi.
r elated work this section discusses three strands of related work data flow testing dse based advanced coverage testing and directed symbolic execution.
data flow testing data flow testing has been empirically demonstrated to be more effective than other structural testing techniques but with much higher testing cost .
much research has considered how to aid data flow testing.
some efforts use random testing combined with program slicing while a few others use the collateral coverage relationship between branch statement and data flow criteria to generate data flow test data.
there is also work that applies search based techniques to perform dataflow testing.
for example ghiduk et al.
use a genetic algorithm which takes as input an initial population of random inputs and adopts a designated fitness function to measure the closeness of execution paths against a target def use pair.
it then uses genetic operations e.g.selection crossover and mutation to search the next promising input to cover this pair.
other efforts include nayak et al.
who use a particle swarm optimization algorithm and ghiduk who uses the ant colony algorithm to derive test data for the target def use pair.
recently vivanti et al.
also use a genetic algorithm to conduct data flow testing on classes .
they use a fitness function to guide the search to reach the defand then the use.
in contrast we adopt an enhanced dynamic symbolic execution technique to perform data flow testing and demonstrate how to combine our dse approach with our cegar based approach to effectively deal with infeasible test objectives which has not been investigated in prior work.
classic symbolic execution is also used to statically select control flow paths to do data flow testing.
buy et al.
combine data flow analysis symbolic execution and automated deduction to perform data flow testing on classes.
symbolic execution first identifies the relation between the input and output values of each method in a class and then collects the method preconditions from a feasible and def clear path that can cover the target pair.
an automated backward deduction technique is later used to find a sequence of method invocations i.e.
a test case to satisfy these preconditions.
however little evidence is provided on the practicality of this approach.
hong et al.
use a model checking approach to generate data flow oriented test data.
it models the program as a kriple structure and characterizes data flow criteria via a set of ctl property formulas.
a counterexample for a property formula represents a test case for a specific def use pair.
however this method requires manual annotation with unclear scalability since it is evaluated on only a single function.
baluda et al.
use a combined method of concolic execution and abstract refinement to compute accurate branch coverage.
it refines the abstract program from a sequence of failed test generation operations to detect infeasible branches.
in contrast we directly encode test objectives into the program under test and use interpolation based model checkers different from their refinement method as black box engines which is fully automatic and flexible.
advanced coverage testing via dse extensive work exists to apply the dse based technique for test case generation w.r.t.
certain advanced coverage criteria.
bardin et al.
propose a label coverage criterion to imply a number of advanced criteria mc dc and weak mutation criteria .
this label coverage criterion is both expressive and amenable to efficient automation.
however it cannot handle those criteria that impose constraints on paths e.g.
data flow criteria rather than program locations.
pandita et al.
propose a trade off approach to achieve a specified coverage criterion through source code transformations.
the block coverage in the transformed program implies the mc dc coverage in the original program.
augmented dse enforces advanced criteria such as boundary logical and mutation criteria by augmenting path conditions with additional conditions.
however in this paper we aim to automate data flow testing which has not been considered before in the context of dse.
we have designed an efficient search strategy to find paths thatcover def use pairs.
directed symbolic execution much research has been done to guide path search toward a specified program location in symbolic execution.
do et al.
make use of data dependency analysis to guide the search process to a program location of interest while we use a dominator analysis.
ma et al.
propose a call chain backward search heuristic to find a feasible path backward from the target program location to the entry.
however it is difficult to adapt this approach on data flow testing because it requires that a function can be decomposed into logical parts when the target locations e.g.thedefand the use are located in the same function .
but decomposing a function itself is a nontrivial task.
zamfir et al.
narrow the path search space by following a limited set of critical edges and a staticallynecessary combination of intermediate goals.
on the other hand our approach finds a set of cut points from the program entry to the target locations which makes path exploration more efficient.
xie et al.
integrate fitness guided path search strategy with other heuristics to reach a program point.
the proposed strategy is only efficient for those problems amenable to its fitness functions.
marinescu et al.
use a shortest distance based guided search method like the adapted sdgs heuristic in our evaluation with other heuristics to quickly reach the line of interest in patch testing.
in comparison we combine several search heuristics to guide the path exploration to traverse two specified program locations i.e.thedefand use sequentially for data flow testing.
vii.
conclusion we have proposed a combined symbolic execution and model checking approach to automate data flow testing.
first we have adapted dynamic symbolic execution dse for data flow testing and introduced a novel path search strategy to make the basic approach practical.
second we have devised a simple encoding of data flow testing via counterexample guided abstraction refinement cegar .
the two approaches offer complementary strengths dse is more effective at covering feasible def use pairs while cegar is more effective at rejecting infeasible pairs.
indeed evaluation results have demonstrated that their combination reduces testing time by than the cegarbased approach alone and improves coverage by than the dse based approach alone.
this work not only provides novel techniques for data flow testing but also suggests a new perspective on this problem to benefit from advances in symbolic execution and model checking.
in further work we would like to apply this data flow testing technique on larger programs and make deeper combinations between dse and cegar e.g.
learning some predicates from dse to help cegar avoid unnecessary explorations and save testing time.
acknowledgment we would like to thank the anonymous reviewers for their valuable feedback.
ting su is partly supported by ecnu project of funding overseas short term studies domestic academic visit and international conference and nsfc project no.
.
jifeng he is partially supported by nsfc project no.
.
geguang pu is supported by nsfc project no.
and shanghai collaborative innovation center of trustworthy software for internet of things zf1213 .
zhoulai fu and zhendong su are partially supported by united states nsf grants and .