subformula caching for model counting and quantitative program analysis william eiers uc santa barbara verification lab santa barbara ca weiers ucsb.eduseemanta saha uc santa barbara verification lab santa barbara ca seemantasaha ucsb.edutegan brennan uc santa barbara verification lab santa barbara ca tegan ucsb.edutevfik bultan uc santa barbara verification lab santa barbara ca bultan ucsb.edu abstract quantitative program analysis is an emerging area with applications to software reliability quantitative information flow side channel detection and attack synthesis.
most quantitative program analysis techniques rely on model counting constraint solvers which are typically the bottleneck for scalability.
although the effectiveness of formula caching in expediting expensive model counting queries has been demonstrated in prior work our key insight is that many subformulas are shared across non identical constraints generated during program analyses.
this has not been utilized by prior formula caching approaches.
in this paper we present a subformula caching framework and integrate it into a model counting constraint solver .
we experimentally evaluate its effectiveness under three quantitative program analysis scenarios model counting constraints generated by symbolic execution reliability analysis using probabilistic symbolic execution adaptive attack synthesis for side channels.
our experimental results demonstrate that our subformula caching approach significantly improves the performance of quantitative program analysis.
index t erms formula caching model counting quantitative program analysis i. i ntroduction in the last two decades constraint solvers have had a significant influence in automated software engineering especially in areas such as software verification analysis and security.
the key factor in increasing effectiveness of constraint solvers in automating software engineering tasks is the fact that the efficiency of the constraint solvers has improved significantly.
these research results demonstrate that despite the well known worst case complexity results in practice many software engineering tasks benefit from constraint solvers.
a model counting constraint solver computes the number of solutions for a given constraint within a given bound .
recently model counting constraint solvers have also been applied to automating quantitative software verification analysis and security tasks.
the goal in quantitative program analysis is not to just give a yes or no answer but to also quantify the result.
for example this material is based on research supported by an amazon research award by nsf under grant ccf and by darpa under the agreement number fa8750 .
the u.s. government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation thereon.
the views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements either expressed or implied of darpa or the u.s. government.rather than answering if there is information leakage in a program with a yes or no answer quantitative analysis techniques can compute the amount of information leaked.
this type of analysis is crucial for many domains since yes or no answers may not be possible.
for example every password checker leaks some information about the password even saying a password does not match a guess leaks information but a faulty password checker may leak more information than necessary.
a quantitative vulnerability detection tool can use a model counting constraint solver to quantify the amount of information leakage.
as another example most symbolic execution tools cannot guarantee absence of an assertion failure in general since they search the state space up to a certain execution depth.
when combined with a model counting constraint solver a symbolic execution tool can quantify the likelihood of reaching an unexplored part of the state space hence providing a probabilistic upper bound on observing an assertion violation.
model counting constraint solvers have been used in probabilistic analysis reliability analysis quantitative information flow and attack synthesis .
with respect to algorithmic complexity model counting problem is at least as difficult as satisfiability problem hence in the worst case model counting problem is also intractable like satisfiability.
however as recent results demonstrate like constraint solvers model counting constraint solvers can also be applied to realistic software verification analysis and security tasks.
and as with the constraint solvers improving the efficiency of model counting constraint solver can have a significant impact on automating software engineering tasks.
in this paper we focus on improving the performance of model counting constraint solvers.
in particular we present techniques for reusing results from prior model counting queries to solve new queries.
the idea of memoization caching prior results of expensive operations in order to reuse them to improve efficiency has been used for constraints in the past.
for example bdds a data structure commonly used for representing satisfying solutions to boolean logic formulas uses the concept of a compute cache to store prior results.
since bdds are a canonical form for boolean functions they enable a caching approach that guarantees a cache hit if an equivalent formula has been analyzed before.
however bdds 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
can only handle bounded domains and require bit blasting to handle numeric or string values which could be inefficient.
caching prior formulas based on normalization of their syntax for constraint satisfiability and model counting queries has also been investigated for more expressive theories such as linear artithmetic and string constraints and their combinations.
however these approaches rely on syntactic matching and hence can miss hits for equivalent formulas.
moreover they rely on full formula caching and therefore miss opportunities for cache hits among subformulas.
in this paper we present a novel approach for formula caching that combines features of caching techniques that are based on syntax and canonical representations building off of work done in cashew .
our approach has the following features that separates it from all prior results in this domain first our caching approach caches intermediate subformulas that arise in the pre order traversal of the full formula enabling cache hits for common subformulas.
second our approach combines syntax based caching with caching via a canonical representation in order to reduce the cost of caching while increasing the number of cache hits.
third our approach uses an automata based constraint representation which enables us to have a canonical representation of string and numeric constraints and their combinations.
we demonstrate the effectiveness of our approach in three different scenarios we consider model counting queries on constraints generated from programs via symbolic execution.
in this scenario model counting queries are generated for full path constraints after the symbolic execution is over.
we consider model counting queries on constraints generated during symbolic execution.
in this scenario model counting queries are generated on the current path constraint for each branch during symbolic execution in order to assess the reliability level that can be achieved by analyzing each branch.
we consider model counting queries on constraints generated while synthesizing side channel attacks.
in this scenario each attack step is generated by symbolic execution of the code followed by model counting queries to determine the input that reveals most information about the secret.
our experiments demonstrate that the subformula caching techniques we present in this paper can sometimes improve the performance for the first scenario they improve the performance in most cases for the second scenario and they improve the performance significantly sometimes more than an orderof magnitude for the third scenario.
we also observe that subformula caching is more effective for string constraints for which automata construction can be very costly than for numeric constraints.
the rest of the paper is organized as follows in section ii we provide motivation for our subformula caching approach.
in section iii we briefly go over automata based caching.
in section iv we describe our subformula caching approach.
in section v we discuss thee application scenarios for model counting constraint solvers.
in section vi we discuss some of the implementation details.
in section vii we present our experimental results in section viii we discuss the related a2 fig.
.
dfa that accepts the solution sets of the formulas char at v0 a andbegins v0 a .
work and finally in section ix we state our conclusions.
ii.
m otiv ation techniques we present in this paper aim to improve the performance of model counting queries generated during quantitative program analysis.
in particular we focus on automatabased model counting constraint solvers.
in automata based model counting the first task is to generate a deterministic finite automaton that accepts all solutions to a given formula.
once the automaton accepting the solutions for a given formula is generated the model counting query reduces to path counting to find out the satisfying solutions within a bound we need to count the number of accepting paths of a certain length or less that start with the initial state of the automaton and end in an accepting state.
the path counting problem in graphs can be solved using matrix exponentiation based on the adjacency matrix of the automaton solving recurrence equations automatically constructed based on the connections among the states of the automaton or using generating functions which can also be automatically constructed based on the connections among the states of the automaton .
given a formula the main difficulty in automata based model counting is constructing a dfa accepting all solutions to that formula.
automata construction is exponential in the worst case as it may require determinization of an intermediate result automaton.
our caching techniques try to minimize the number of calls to automata construction operation.
we use two types of caching which we call syntactic caching and automata caching to characterize the way the keys are generated for the intermediate results we cache.
in both cases the result we are caching is an automaton constructed for a given formula.
in syntactic caching the key for storing the automaton constructed for a formula is generated based on the formula syntax.
in automata caching we generate a key for each constructed automaton based on the structure of the automaton.
we use minimized deterministic finite automata dfa which are a canonical representation.
hence formulas with the same set of satisfying solutions are mapped to equivalent automata and the keys generated for them match if and only if the formulas are semantically equivalent.
consider the following formulas length x char at x b begins s d length s s t existing syntax based formula caching techniques can be used to normalize these formulas in order to detect equivalent formulas.
normalization involves transformations such authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
as variable renaming character renaming and sorting of the operations.
let us assume that the normalized form for the above formulas are length v0 char at v0 a length v0 begins v0 a v0 v1 note that syntactic normalization enables us to detect that formulas and have a common subformula length v0 .
however with full formula caching since these formulas and are not equivalent the fact that they share a subformula will not be exploited during automata construction or model counting.
in this paper we demonstrate that subformula caching which stores automata constructed for intermediate subformulas during evaluation of the model counting queries enables the reuse of the result for subformula length v0 .
for the above example if model counting query for constraint is processed before the model counting query for constraint then based on syntactic subformula caching we can detect that the subformula length s 10is equivalent to length x 10and use the stored automaton constructed for length x 10rather than constructing a new and equivalent automaton for length s .
above discussion explains our motivation for syntactic subformula caching however it does not explain why we need automata caching.
in syntactic caching we generate keys for the intermediate results using normalized syntax of the formulas.
by automata caching we refer to generation of keys based on the structure of the automata not the syntax of the corresponding formula.
for example the formulas char at v0 a and begins v0 a are syntactically different but they are semantically equivalent.
the set of solutions to both of these formulas is characterized by the automaton shown in figure .
again assume that a model counting query for formula is processed before a model counting query for the formula .
the automata constructed for subformulas length x andchar at x b and the full formula length x char at x b will be stored in the cache.
if we process a model counting query for formula next then syntactic caching will report a hit on subformula length s 10and will return the cached automaton for length x 10instead of reconstructing an equivalent one.
then the syntactic caching will report a miss for the subformula begins v0 a and an automaton for that subformula will be constructed.
next step is to construct the automaton for the subformula length v0 begins v0 a .
now syntax based caching will report a hit for the first argument of the conjunction operation and the automata based caching will report a hit for the second operand of the conjunction operation.
then instead of reconstructing the automaton corresponding to the conjuction the cached automaton for the formula length v0 char at v0 a will be returned.
then the automaton for the subformula v0 v1will be constructed followed by the construction of the automaton for the second conjunction.
note that syntaxbased caching is necessary to reduce the number of calls toautomata construction and automata caching is necessary to catch the cases where syntax based caching is not able to detect equivalent formulas.
in the following sections we will discuss the implementation of this caching approach.
iii.
a utomata based model counting in this section we given an overview of automata based constraint solving and model counting techniques which have been implemented in prior tools .
we implemented our sub formula caching approach by extending an existing automata based model counting constraint solver.
given an automaton a letl a denote the set of strings accepted by a and given a formula flet llbracketf rrbracketdenote the set of values that satisfy the formula f. in automata based model counting given a formula fthe goal is to construct an automaton afwherel af llbracketf rrbracket.
note that this requires encoding of the solutions to formula fas strings accepted by the automaton af.
in order to construct automata for formulas including string constraints it is necessary to handle string operations such as concat substring length char at begins contains etc.
using standard automata construction techniques such as concatenation and their extensions automata construction techniques for string constraints have been implemented in prior work where the alphabet for the constructed automaton corresponds to the string alphabet used for the string constraints.
boolean operators negation conjunction and disjunction are handled using automata complement and automata product respectively.
for constraints that involve multiple variables one can construct multiple single track automata one for each variable or one multi track automata that accepts tuples of strings.
multi track automata is a generalization of finite state automata.
a multi track automaton accepts tuples of values by reading one symbol from each track in each transition.
i.e.
given an alphabet ak track automaton has an alphabet k. in order to achieve better precision we use multi track automata representation.
automata can also be used to represent solutions to linear arithmetic constraints.
similar to string constraints the goal is to create an automaton that accepts solutions to the given formula.
for numeric constraints one can use the binary alphabet where the set of solutions to the given numeric constraint is represented as a string of binary symbols that corresponds to the 2s complement representation of the number which is the solution to the constraint.
the numeric automata accept tuples of integer values in binary form starting from the least significant digit.
numeric constraints consist of basic numeric constraints and boolean logic operators.
each basic numeric constraint is in the form summationtextn i 1ai xi a0op0 where op negationslash aidenote integer coefficients andxidenote integer variables.
the automata construction for basic numeric constraints can be implemented using a basic binary adder state machine construction .
the automata construction techniques we summarize above have been implemented in a tool called automata based counter abc model counting constraint solver .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the abc tool is a constraint solver for string and numeric constrains and their combinations with model counting capabilities.
given a formula f abc constructs a multi track deterministic finite state automaton dfa afcharacterizing the set of solutions which satisfy f. for each atomic formula finf abc constructs a dfa affor each and combines them into one dfa using automata operations complement product .
the resulting dfa is an over approximation of the set of all solutions to f. note that abc supports both string and numeric constraints and thus uses two different encodings ascii for strings binary encoding for integers.
abc keeps two different automata one for string constraints and one for integer constraints and implements special operations for keeping track of relations between the two .
abc solves the the model counting problem using automata based model counting.
given a formula fconstructing an automaton affor the set of solutions of f where l af llbracketf rrbracket reduces the model counting problem to a path counting problem.
note that the number of strings accepted by an automaton could be infinite in the presence of loops.
in applications of model counting such as probabilistic symbolic execution a model counting query is accompanied with a bound that limits the domain of the variable.
for string variables this is the length of the strings whereas for numeric variables it is the number of bits.
these correspond to the length of the accepted strings for our automata representation of string and numeric constraints.
the number of strings of length kin llbracketf rrbracketcorresponds to the number of accepting paths of length kin the dfa af.
since there is exactly one path for each string recognized by a dfa if we can count the number of path in afprecisely then we can answer the model counting query precisely.
note that this approach works both for numeric and string constraint automata.
hence using an automata based constraint solver provides a general approach to model counting.
computation of number of accepting paths within a bound can be done by constructing the adjacency matrix of the automaton based on its transition relation and then using matrix exponentiation to compute the number of accepting paths.
it is also possible to construct recurrence equations for the number of paths of a certain length that reach a particular state in terms of the number of paths that reach the adjacent states.
the recurrence equation can be derived based on the connections among the states of the automaton.
finally the number accepting paths of a certain length can be represented using generating functions where the generating function can be constructed based on the connections among the states of the automaton .
iv .
c aching for model counting formula caching benefits quantitative program analyses by improving the performance of their enabling technology model counting constraint solvers.
formula caching frameworks allow model counters to reuse previously computed results and avoid performing expensive model counting.
in the past formula caching has been shown to improve theperformance of model counting constraint solvers by more than 10x .
simple formula caching only attempts to reuse the results for the complete query f v b .
we instead integrate caching into the automata construction process of the modelcounting constraint solver.
this increases the potential for reuse.
when constructing the automata for a formula f w e can reuse the automata of subformulas of f. for example as we discussed earlier in constructing the automata for the formula begins s d length s s twe can reuse the automata constructed for the formula length x char at s b .
extending formula caching with subformula caching allows us to avoid expensive construction steps by reusing results.
to determine when results can be reused caching frameworks must be able to quickly detect when two queries are equivalent with respect to model counting.
a formula fis said to be equivalent to formula gwith respect to model counting if the cardinality of satisfying solutions to fmatches that of gfor any length bound b. note that two formulas might be equivalent according to this criterion even if they do not possess the same solution set.
determining if two formulas satisfy this criteria is non trivial.
syntactic caching and automata caching are two different normalization techniques to determine the equivalence of formula both of which we use in conjunction with subformula caching.
a. syntactic caching under syntactic caching the formulas of queries are transformed according to syntactic rules into a normal form.
this normal form is then used as a key to the cache under which to store the automata.
the constraint normalization procedure given in provides an effective albeit incomplete method of determining if two formula are equivalent with respect to model counting.
the normalization procedure takes a query f v b and produces a normalized query with variables vand bound b. two queries normalize to the same form only if they are equivalent with respect to model counting that is only if the cardinality of their solution sets match for every length bound.
we adopt the syntactic normalization procedure given in .
a query is normalized according to four subprocedures which act on its formula.
first the formula conjuncts are sorted.
then the variable names are normalized in order of appearance in the sorted formula.
third alphabet constants are normalized again in order of appearance and finally arithmetic constraints are shifted by an integral amount to center them about the origin.
note that normalized alphabet characters are still treated as characters regardless of which character they are normalized to.
as an example consider formula f b .com contains b url and formula g contains s link s .net authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
after sorting and renaming both fandgnormalize to the same form v0 abcd contains v0 v1 which means that the automata constructed for one formula can be found in the cache and reused should a query be made on the other.
we use syntactic caching for both full formula queries and sub formula queries.
when we receive a query on formula f we first syntactically normalize fand use its normal form as a key to query the cache as given in algorithm .
when a hit occurs we use the stored automata for path counting.
if a miss occurs we turn to subformula caching to determine if we can reuse intermediate results during automata construction of f. iff opf1...f nwhere opis any n ary operator then we perform two queries to the cache.
one is on the syntactically normalized opf1...f n 1or if n f1.
the other is onfn.
when a hit occurs the cached automata is used and the construction of opf1...f n 1orf2bypassed.
if a miss occurs querying continues recursively to opf1...f n 2and fn 1until an atomic1formula is reached.
when an atomic formula is reached the automaton is constructed.
each time an automaton is constructed we store the automaton in the cache under its syntactic key for future use.
in the example given above the constraint fhas two subformulas b .com and contains b url .
in the case where the normalized form of fis not found in the cache the normal forms of these two subformulas would be queried.
b .com normalizes to v0 abcd and contains b url normalizes to contains v0 v1 .
during the construction of g we get a hit since after normalization the key generated for gmatches the key for fwhich means that the two formulas are equivalent as far as model counting is concerned.
b. automata caching formulas that are semantically equivalent can have different syntactic normal forms.
to capture additional equivalent formulas we use automata caching.
under this caching the normal form of a formula is its automaton itself.
for deterministic and minimized automata two formula have the same automaton if and only if they are semantically equivalent formulas.
this is true since minimized deterministic dfas provide a canonical form for regular languages.
unlike syntactic caching this type of equivalence check captures all semantically equivalent formulas.
when syntactic caching results in a cache hit it is preferable to automata caching as its normalization is less expensive.
we use automata caching when syntactic caching has failed on a query on a formula f opf1...f nwhere opis any nary operator.
we construct the automata for each fi.
we then generate a key based on those automata and the operator op and query the cache with this key.
if the resulting automaton for ophas been previously constructed we can reuse the result.
this procedure is given in algorithm .
in cases where constructing the automaton for opis costly the overhead of 1for the definition of atomic formula see c a x x x x x x x x x x x x x x x x x x x x x x x x x x x x0 x x x x x x x x x x x x x x x x x x x x x x x x x x xx x x x x x x x2 b c fig.
.
dfa constructed for the formula match s a b c .
a dfa with ascii alphabet b dfa with binary encoding of the ascii symbols c multi terminal bdd that encodes the dfa.
the caching queries is a beneficial trade off.
each time we construct an automaton for a formula f opf1...f n w e generate its key for automata caching and store the result.
in our implementation of the automata caching we use the automata package provided by the mona tool .
generation of keys for deterministic finite automata require us to encode the automaton as a string.
consider the formula match s a b c which states that string variable scan take any value that matches the regular expression a b c .i n fig.
we show the automaton constructed for this constraint.
fig.
a shows the minimized dfa with the ascii alphabet.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
node terminal s s s fig.
.
key generated for the automaton in figure based on its multiterminal bdd representation.
initial state is is an accepting state and is the sink state.
transitions are labeled with character ranges for readability.
in order to improve the efficiency of automata manipulation mona uses a symbolic dfa representation.
the basic idea is to represent the transition relation of the automata symbolically using multi terminal binary decision diagrams mtbdds .
in order to do this we first have to use a binary encoding of the set of characters that can appear in a string.
fig.
b shows the dfa that is equivalent to the dfa shown in fig.
a where the ascii symbols are encoded using bit binary numbers x denotes a don t care value .
finally fig.
c shows the symbolic dfa representation based on the mtbdd data structure.
the second row in the table at the top represents the dfa states while the first row in that table represents state types which are either accepting state or rejecting state .
the circle shaped nodes are the bdd nodes.
each circle shaped node has a number nthat represents its level i.e.
which bdd variable n in other words which bitnin an alphabet symbol it corresponds to.
each rectangleshaped leaf node has a number nthat represents the destination state that the node corresponds to.
dashed line represents a bdd variable bit value of while a regular line represents a bdd variable bit value of .
in fig.
we show the key generated from the symbolic automata representation shown in fig.
c .
the key is a string that represents the nodes and the transitions in the mtbdd representation of the minimized dfa.
since minimized dfa representation is a canonical representation given two formulas the keys generated for them are identical if and only if the dfas generated for them are identical.
c. f ormula caching algorithm algorithm outlines how we leverage syntactic caching and automata caching in conjunction with subformula and fullformula caching.
given a formula f we first query whether the full formula fcan be found in the cache through syntactic caching.
this is the cheapest normalization scheme and would provide the most benefit so we check it first.
if this check fails and fis atomic the cache can be of no further use to us so we construct the automata and store it in the cache under the syntactic normal form of f. otherwise fis of the form f opf1...f nwhere opis some n ary operator.
inthis case sub formula caching may benefit our construction process.
as described above we first syntactically query for the normalized form of opf1...f n 1or if n f1 andfn.
this querying continues recursively until either an atomic formula is reached or a cache hit occurs.
once the two automata have been either retrieved or constructed and stored under the syntactic normal form of the subformula we use automata caching to potentially avoid an expensive construction of the opautomata.
we query using a key generated from the two automata and the opoperator and either use the stored result or construct and store the automata.
algorithm model counting f v b input a formula f set of variables v and bound b output the number of solutions to vthat satisfy fwithin bound b. af a utomata construction f return pathcount af v b algorithm automata construction f input a formula f. output an automata accepting all solutions of f. af s yntax caching f ifafis not null then return af end if ifisatomic f then af c onstruct dfa f s tore normalize f af return af else f opf1...f n a1 a utomata construction opf1...f n a2 a utomata construction fn af a utomata caching op a1 a2 s tore normalize f af return af end if algorithm syntax caching f input a formula f. output a cached automata that accepts all solutions of for null.
kf n ormalize f ifhit kf then return af l oad kf end if return null algorithm automata caching a1 a2 op input two automata a1 a2and an operator op.
output automata for a1opa2.
kf g enerate key op a1 a2 ifhit kf then return a l oad kf end if a c onstruct dfa a1opa2 s tore kf a return a authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
v. a pplications of model counting in this section we describe three different quantitative program analysis scenarios which use model counting constraint solvers.
for each scenario we introduce the experimental benchmark we use to evaluate the effectiveness of our caching technique for the scenario.
a. model counting constraints the most straightforward application of model counting is given a set of constraints to simply count the number of accepting solutions for each.
this is common in symbolic execution where model counting queries are generated for full path constraints after symbolic execution has completed.
for this scenario we consider two sets of full path constraints each generated from a different symbolic execution engine.
kaluza benchmark.
the kaluza benchmark is widely used benchmark for evaluating constraint solvers and model counting constraint solvers.
the benchmark is a set of satisfiable constraints generated via symbolic execution of javascript programs and were originally solved by kaluza string solver .
the constraints in this benchmark require a constraint solver to be able to reason over string and numeric constraints and their combinations.
all the constraints from this benchmark were later divided into two sets kaluzasmall and kaluzabig.
the input format of these constraints were translated into the smtlib2 input format by the authors of abc .
the kaluzasmall set contains constraints while kaluzabig constraints.
each constraint contains a query variable for which to model count.
we evaluate the performance of different caching techniques on this benchmark comparing the time taken to count the number of solution strings of length less than or equal to for each constraint.
sorting constraints.
we investigate the performance of our approach on constraints generated from symbolic execution of four different java sorting programs quicksort bubblesort insertionsort and selectionsort.
we fixed the array size of each to elements and symbolic execution to a depth of .
each consists solely of numeric constraints with the total number of constraints and respectively.
b. reliability analysis one measure of program reliability is the probability that the program executes successfully.
symbolic execution provides a means to compute program reliability.
one run of symbolic execution generates a series of path constraints characterizing complete program paths.
because symbolic execution requires a depth bound it is possible that not all complete program paths will be generated.
performing model counting over the generated path constraints and dividing the count by the domain size gives the probability that a randomly chosen input will execute that particular program path.
by computing this probability for each complete program path we can determine what percentage of the input space is captured by the path constraints generated by symbolic execution and therefore provide a lower bound on the reliability of the program.as an example consider the password checking function in figure .
if this function were symbolically executed with length bound for h five path constraints would be generated.
these constraints are given in table i. the probability of a given path can be computed by diving the model count of the path constraint by the size of the domain.
the bound of on his a small bound.
in general we have no guarantee on the length of h meaning symbolic execution will require a depth bound to terminate.
however by leveraging model counting we can execute a bounded symbolic execution and then compute what percentage of the input space leads to a program path that terminates within our depth bound.
this gives us the percentage of input space we can confidently say will execute without failure and thus provides a lower bound on the reliability of the program.
for the passwordchecker example imagine we limit the search depth so that the loop symbolically executes only times.
in this case all program paths for which the first three characters match would not complete their symbolic execution.
covered probability pc for reliability analysis will be then the summation of the probability of path constrains and from table i. in practice we are also often interested in guaranteeing a lower bound for program reliability.
in this case we can perform model counting at each step of symbolic execution to determine what percentage of input follows which path.
this would allow us to guide the symbolic execution along the most probable paths in order to increase coverage most efficiently and stop execution once a certain coverage is reached.
conversely one could also guide symbolic execution towards highly improbable paths in order to test corner cases.
table i path constraints for program in figure i path constraint observation probability char at l negationslash char at h .
char at l char at h .
char at l negationslash char at h char at l char at h .
char at l char at h char at l negationslash char at h char at l char at h .
char at l char at h char at l char at h char at l negationslash char at h char at l char at h .
char at l char at h char at l char at h char at l char at h reliability analysis benchmark.
this benchmark is a modified version of the experimental benchmark used in .
the original benchmark consists of numeric constraints only.
we add more example programs involving string constraints.
examples with numeric constraints cover couple of sorting algorithms plus daisychain a small program simulating a simplified flap controller of an aircraft and robotgame a program to determine and execute robot movements.
examples with string constraints cover several string manipulating methods passwordcheck compares secret password and user s input stringequals is a string library function which authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
public boolean pas swordcheck string h string l for int i i h. length i if h. charat i !
l .
charat i return false return true fig.
.
password checking example.
checks if two strings are equal or not stringinequality checks lexicographical order of two strings character by character editdistance checks minimum edit distance of two strings indexof is another string library function and compress is a simple string compression function.
c. attack synthesis we focus on adaptive attack synthesis for side channel vulnerabilities.
attack synthesis techniques generate inputs in an iterative manner which when fed to code that accesses the secret reveal information about the secret based on the sidechannel observations .
symbolic execution is used to extract path constraints automata based model counting is used to estimate probabilities of execution paths and optimization techniques are used to maximize information gain based on entropy.
consider the password checking function in figure .
the function has a timing side channel and one can reveal the secret by measuring execution time.
if handlhave no common prefix the program will have the fastest execution since the loop body will be executed only once if handl have a common prefix of one character a longer execution will be observed since the loop body executes twice.
the case when handlmatch completely the program has the longest execution.
an attacker can choose an input and use the timing observation to determine how much of a prefix of the input has matched the secret.
adaptive attack synthesis approach starts by automatically generating the path constraints using symbolic execution.
it then uses these constraints to synthesize an attack which determines the value of the secret h .
based on shannon entropy the remaining uncertainty of hcan be computed to measure the progress of an attack.
at each step of an adaptive attack attacker learns new information about hrepresented as a constraint on hbased on the observed execution time.
suppose that the secret is .
the initial uncertainty is log2104 .13bits of information assuming uniform distribution .
attack synthesis generates input at the first step and makes an observation with cost which corresponds to constraint char at h negationslash .
similarly a second input implies char at h negationslash .
at the third step the input yields a different observation leading to updated constraint on has below char at h negationslash char at h negationslash char at h char at h negationslash the updated constraint at an attack step has subformula from the previous step.
for example at attack step constraint char at h negationslash char at h negationslash has subformula char at h negationslash from earlier step and at attack step constraint char at h negationslash char at h negationslash char at h char at h negationslash has subformula char at h negationslash char at h negationslash .
a model counting tool without caching will re count a number of formulas which was counted in the earlier steps.
this is redundant and reduces the efficiency of attack synthesis.
results can be reused from prior iterations.
model counting is in the core of the attack synthesis process as it is repeatedly used to calculate information gain and progress of attack synthesis.
reusing model counting query results from earlier steps should improve the effectiveness of attack synthesis by reducing attack synthesis time.
attack synthesis benchmark.
this benchmark was previously used in to synthesize attacks for programs vulnerable to side channels.
example functions used in this benchmark includes different string manipulation and arithmetic operations setting different sizes and lengths to define the domain of secret value.
the function pci is an implementation of password checker comparing a user input and secret password but inducing a timing side channel due to early termination optimization.
seis a method from the java string library to check equality of two strings and known to be vulnerable to timing side channel .
a similar sidechannel was discovered in indexof io method from the java string library.
function edis an implementation of a dynamic programming algorithm to compute minimum edit distance between two strings.
function co is a basic compression algorithm which collapses repeated sub strings within two strings.
si scoi and sci functions check lexicographic inequality of two strings whereas first one compares the strings second one includes concatenation operation with inequality and third one compares characters in the strings.
vi.
i mplementation we implemented2the caching techniques presented in this paper into the automata based model counter abc .
internally automata within abc are represented as multiterminal binary decision diagrams implemented using the tool mona .
given the constraint formula fin smtlib2 format abc first constructs the abstract syntax tree ast in negation normal form representing fwhere the root node represents the satisfiability of f leaf nodes correspond to variables and constants and intermediate nodes represent string or integer terms with boolean connectives and or .
the ast is simplified before dfa construction using several heuristics.
dependency analysis identifies independent components which may be solved separately.
equivalence class generation detects equivalent variables through equality clauses and chooses a single representative for the class and term re write rules eliminate redundant terms and propagate constants.
abc then performs post order traversal on the simplified ast where the dfa for each node is constructed from the dfas of its children nodes.
we modify the constraint solving algorithm of abc with support for both syntactic and automata caching on the nodes of the ast.
in our implementation we use the popular open 2subformula caching implementation and dataset available at com vlab cs ucsb abc authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
source in memory database store redis as the cache.
we set the maximum database size to gb with a least recently used eviction policy lru .
note that the lru algorithm redis uses approximates the lru set using sampling in this case.
given a constraint formula abc constructs the simplified ast representing the formula using the approach mentioned above.
prior to the post order traversal for dfa construction the cache is recursively queried for a smaller subset of the original formula until either an atomic formula is found or a dfa is returned from a cache hit.
note that the key for each query is simply the string representation of the ast corresponding to the normalized form of a particular subformula.
in either case abc begins its post order dfa construction traversal from the corresponding ast node.
for each subformula solved from this point abc stores the solution dfa into the cache.
by exploiting the natural post order traversal of abc s constraint solving algorithm we maximize the probability of a cache hit while minimizing the number of cache queries.
vii.
e xperiments we evaluate our caching technique across the three different quantitative program analysis scenarios described above.
for each experimental scenario we evaluate four different caching approaches.
the n ocaching or nc approach performs the analysis with no caching of model counting queries and serves as a baseline for comparison.
the f ullformula or ff approach is an identical re implementation of cashew performs only syntactic normalization and only queries the cache for hits of the full formula of the model counting query.
the s ubformula or sf approach is also limited to syntactic normalization but performs recursive queries on the sub formulas of the query formula when the full formula is not found in the cache.
finally the s ubformula a utomata or sfa approach extends the sf approach with automata caching.
the sfa approach is the most expressive caching scheme.
we report the time in seconds for each benchmark program to complete end to end across these four caching scenarios.
we also report the speedup demonstrated by the sfa approach versus both the nc and ff approaches.
a. experimental setup for all experiments we use a desktop machine with an intel core i5 2400s .
ghz cpu and gb of ddr3 ram running ubuntu .
with a linux .
.
bit kernel.
we used the openjdk bit java vm build .
.
.
b. experimental results we discuss how each of the four caching approaches perform across the three different quantitative program analysis scenarios.
we evaluate under what kinds of analyses the sf and sfa approaches prove highly beneficial versus ff and nc and examine cases where the improvement was only marginal.
model counting.
the results for model counting constraints generated by symbolic execution are given in table ii.
we show results the simplified kaluza benchmark and linear arithmetic constraints generated from running symbolic executionon a suite of sorting benchmarks.
we found that out of of the constraints in kaluzasmall were unique constraints after normalization with the other being trivially satisfiable.
kaluzabig contained unique constraints out of constraints with the other constraints being of reasonable complexity.
for both cases sfa outperforms nc and ff.
for the numeric constraints sfa outperforms ff and nc in only one case.
for the other three cases the overhead of subformula caching outweighs any benefits gained due to the simplicity of the numeric constraints.
reliability analysis.
the results on the reliability analysis benchmark are given in table iii.
the upper half of the table shows the results on programs that produce only numeric constraints and the bottom half on programs that also contain string and mixed string and numeric constraints.
we found no caching approach to be significantly beneficial in the benchmarks where only numeric constraints are encountered.
in fact because of the additional overhead of the ff and sfa approaches we even observed a slight slowdown versus the nc or the more light weight ff approach on some benchmark programs.
nevertheless the additional overhead was never hugely debilitating and the sfa approach never took more than longer than the nc or ff approaches.
on benchmarks with string or mixed string and numeric constraints the sf approach demonstrated notable improvement over both the nc and ff approaches and the sfa approach was even more successful.
in some cases the sfa approach was more than four fold faster than either the nc or ff approaches.
in all cases some improvement was observed with the sfa approach.
the reason for the significant improvement observed on benchmarks with string and mixed constraints lies in the expensive automata constructions demanded by those constraints.
numeric constraints however do not require expensive automata constructions making the effects of caching less beneficial.
from these experiments we learned that the sfa approach potentially provides enormous benefit when string or mixed constraints are encountered during the course of the analyses and does not significantly degrade performance when only numeric constraints are encountered.
from this we believe that enabling sfa caching is generally beneficial for reliability analysis but also note that the analyst could make an informed choice to enable should they have suspicions about the type of constraints likely to be encountered.
attack synthesis.
the results on the attack synthesis benchmark are given in table iv.
as shown in the execution time under the nc approach this quantitative program analysis is the most expensive of the three with some benchmark programs taking hours to run when no caching is enabled.
in all cases the sf approach improved on the nc and ff approaches even reducing a run time of five hours to less than eighteen minutes for the sci benchmark program.
the sfa approach was able to even further improve these already impressive results.
on some benchmarks sfa demonstrated a more than twenty fold improvement versus the nc and ff approaches.
in all cases the sfa approach was the fastest evaluated caching approach.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii experimental results for model counting constraints benchmark nc time s ff time s sf time s sfa time s sfa speedup v nc sfa speedup v ff quicksort .
.
.
.
.87x .87x bubblesort .
.
.
.
.93x .93x insertionsort .
.
.
.
.05x .02x selectionsort .
.
.
.
.85x .84x kaluzasmall .
.
.
.
.18x .09x kaluzabig .
.
.
.
.87x .06x table iii experimental results for reliability analysis benchmark se depth nc time s ff time s sf time s sfa time s sfa speedup v. nc sfa speedup v ff bubblesort .
.
.
.
.96x .01x insertionsort .
.
.
.
.99x .01x daisychain .
.
.
.
.87x .88x robotgame .
.
.
.
.00x .00x passwordcheck .
.
.
.
.29x .29x stringequals .
.
.
.
.28x .34x stringinequality .
.
.
.
.56x .61x editdistance .
.
.
.
.29x .37x indexof .
.
.
.
.04x .11x compress .
.
.
.
.40x .48x all benchmark programs evaluated under this program analysis scenario contain string constraints.
based on our observations from the reliability program analysis benchmarks we think that the more expensive automata construction required for these constraints is part of the reason the sf and sfa approaches are so successful for these benchmarks.
viii.
r elated work model counting as the enabling technology for quantitative program analyses model counting constraint solvers have received increasing focus from the research community.
smc and s3 are two model counting constraint solvers over the string domain.
latte is a model counting constraint solver for linear integer arithmetic that uses the barvinok algorithm.
abc which can handle string numeric and mixed constraints is more expressive than any of these model counting constraint solvers and more precise than either of the string model counters.
caching cashew is a caching framework for modelcounting queries which provides notable improvement on a variety of program analyses.
cashew is built atop green an external solver interface for reusing the results of satisfiability or model counting queries.
cashew introduces an aggressive normalization scheme and parameterized caching allowing it to outperform green.
we adopt the normalization scheme used by cashew but introduce subformula caching into the automata construction process to enable more reuse of computation.
we also leverage automata caching a normalization technique guaranteeing completeness to leverage more information from the cache.
we show how both of these techniques benefits three different program analyses scenarioswith a direct comparison to the full formula only caching implemented by cashew.
greentrie another extension of green and recal are caching frameworks that detect implication between constraints to improve caching for satisfiability queries.
their techniques are specific to satisfiability queries and in the general case do not apply to model counting queries considered in this paper.
utopia proposes a technique to reuse results across formulas with similar solution sets but again is specific to satisfiability queries and would not aid in model counting.
incremental solving many modern smt solvers have built in support to expedite the solving of similar constraints.
cvc4 z3 yices and mathsat5 are smt solvers with incremental capabilities.
these tools learn lemmas which can later be re used to solve similar constraints.
during constraint solving these solvers use a stackbased approach to keep track of the current solver context pushing and popping learned lemmas as conjuncts are added or removed respectively.
incremental attack synthesis is an alternative approach that enables reuse of intermediate results obtained during attack synthesis .
however incremental attack synthesis approach is a specialized heuristic for attack synthesis whereas the subformula caching approach we present in this paper is general and it is applicable to any quantitative program analysis technique that relies on model counting queries.
ix.
c onclusions quantitative program analysis techniques rely on model counting constraint solvers and model counting queries can be very expensive.
in this paper we introduced sub formula authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv experimental results for attack synthesis benchmark nc time s ff time s sf time s sfa time s sfa speedup v nc sfa speedup v ff pci .
.
.
.
.12x .90x se .
.
.
.
.24x .30x si .
.
.
.
.27x .27x ed .
.
.
.
.89x .60x io .
.
.
.
.60x .20x co .
.
.
.
.7x .30x scoi .
.
.
.
.64x .65x sci .
.
.
.
.13x .05x caching to improve the efficiency of quantitative program analysis techniques.
we focus on automata based model counting for string and numeric constraints.
we use both syntactic and automata based caching in order to reduce the number of times automata are constructed.
we evaluate our approach in different scenarios and demonstrate that subformula caching can significantly improve the performance of quantitative program analysis techniques.