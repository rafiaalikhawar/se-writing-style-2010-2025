learning to log helping developers make informed logging decisions jieming zhu pinjia he qiang fu hongyu zhang michael r. lyu dongmei zhang shenzhen research institute the chinese university of hong kong shenzhen china ministry of education key laboratory of high confidence software technologies cuhk sub lab department of computer science and engineering the chinese university of hong kong hong kong microsoft washington dc usa microsoft research beijing china jmzhu pjhe lyu cse.cuhk.edu.hk qifu microsoft.com honzhang dongmeiz microsoft.com abstract logging is a common programming practice of practical importance to collect system runtime information for postmortem analysis.
strategic logging placement is desired to covernecessary runtime information without incurring unintendedconsequences e.g.
performance overhead trivial logs .
however in current practice there is a lack of rigorous specificationsfor developers to govern their logging behaviours.
logging hasbecome an important yet tough decision which mostly dependson the domain knowledge of developers.
to reduce the effort onmaking logging decisions in this paper we propose a learningto log framework which aims to provide informative guidanceon logging during development.
as a proof of concept weprovide the design and implementation of a logging suggestiontool logadvisor which automatically learns the common logging practices on where to log from existing logging instances and further leverages them for actionable suggestions to developers.specifically we identify the important factors for determiningwhere to log and extract them as structural features textual features and syntactic features.
then by applying machinelearning techniques e.g.
feature selection and classifier learning and noise handling techniques we achieve high accuracy oflogging suggestions.
we evaluate logadvisor on two industrial software systems from microsoft and two open source softwaresystems from github totally .1m loc and .6k loggingstatements .
the encouraging experimental results as well as auser study demonstrate the feasibility and effectiveness of ourlogging suggestion tool.
we believe our work can serve as animportant first step towards the goal of learning to log .
i. i ntroduction logging is a common programming practice in software development typically issued by inserting logging statements e.g.
printf console.writeline in source code.
as inhouse debugging tools e.g.
debugger all too often are inapplicable in production settings logging has become aprincipal way to record the key runtime information e.g.
states events of software systems into logs for postmortemanalysis.
to facilitate such log analysis the underlying loggingthat directly determines the quality of collected logs is a matterof vital importance.
due to the criticality of logging it would be bad to log too little which may miss the runtime information necessaryfor postmortem analysis.
for example systems may fail inthe field without any evidence from logs thus significantlyincreasing the difficulty in failure diagnosis .
however itis also not the case that the more logging the better.
as thepractical experiences reported in logging too muchcan yield many problems too.
first logging means more code which takes time to write and maintain.
furthermore loggingconsumes additional system resources e.g.
cpu and i o and can have noticeable performance impact on system operation for example when writing thousands of lines to a log file persecond .
most importantly excessive logging can producenumerous trivial and useless logs that eventually mask thetruly important information thus making it difficult to locatethe real issue .
as a result strategic logging placementis desired to record runtime information of interest yet notcausing unintended consequences.
to achieve so developers need to make informed logging decisions.
however in our previous developer survey wefound that even in a leading software company like microsoft it is difficult to find rigorous i.e.
thorough and complete specifications for developers to guide their logging behaviors.although we found a number of online blog posts e.g.
sharing best logging practices ofdevelopers with deep domain expertise they are usually high level and application specific guidelines.
even with loggingframeworks e.g .
microsoft s uls and apache s log4net provided developers still need to make their own decisions onwhere to log and what to log which in most cases dependon their own domain knowledge.
therefore logging hasbecome an important yet tough decision during development especially for new developers without much domain expertise.
current research has seldom focused on studying how to help developers make such logging decisions.
to bridge thisgap in this paper we propose a learning to log frame work which aims to automatically learn the common logging rules e.g .
where to log what to log from existing logging instances and further leverage them to provide informativeguidance for new development.
motivated by our observations detailed in section ii b we extract a set of contextualfeatures from the source code to construct a learning modelfor predicting where to log.
our logging suggestion tool builton this model named logadvisor can thus provide actionable suggestions for developers and reduce their effort on logging.as an initial step towards learning to log this paper focuseson studying where to log or more specifically whether to loga focused code snippet while leaving other aspects such aswhat to log of this research for future work.
we have conducted both within project evaluation and ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
table i summary of the studied softw are systems some entries are anonymized for confidentiality logging commitssoftware startdescription v ersion loc logging loc of commits patchessystems timestatements loggingtotalwith logging with logging system a online service .5m system b online service .7m sharpdevelop .net platform ide .
.
.4m .
.
monodevelop cross platform ide .
.
.5m .
.
total .1m .6k .6k .2k .0k .
.9k .
cross project evaluation on logadvisor using two industrial software systems from microsoft and two open source software systems from github.
additionally a user study isperformed to evaluate whether the suggestions provided bylogadvisor can help developers in practice.
the comprehensive evaluation results have demonstrated the feasibilityand effectiveness of our logging suggestion tool.
for ease ofreproducing and applying our approach to future research werelease our source code and detailed study materials e.g.
data questionnaire on our project page .
the rest of this paper is organized as follows.
section ii introduces our studied software systems and the motivation ofthis work.
section iii provides the overview and the detailedtechniques of learning to log.
section iv reports the evaluationresults and section v presents our user study.
we discuss thelimitations in section vi and the related work in section vii.finally we conclude this paper in section viii.
ii.
o bserv a tions and motiv a tion in this section we first introduce the subject software systems under study.
then we provide some key observationson logging practices and present the motivation of our study.
a. subject software systems in our study we investigate four large software systems including two industrial systems from microsoft denoted as system a and system b for confidentiality and two open source systems from github sharpdevelop and monode velop .
each of these systems contains millions of lines ofcode loc written in c language.
table i provides thesummary information of our studied software systems.
bothindustrial systems are online service systems developed bymicrosoft serving a huge number of users globally.
thesetwo systems were also used as subjects in our empiricalstudy on logging practices .
to allow for reproducing andapplying our approach to future research we choose anothertwo open source software systems as subjects.
they are twoide projects sharpdevelop supporting .net platform andmonodevelop supporting cross platform development .
bothof them are selected due to their popularity well known c projects active updates commits and long historyof development years .
our targeted systems are supposed to have reasonably good logging implementation because the produced logs by these have mostly met the requirements of usage analysis troubleshooting and operating after undergoing more than 10years of evolution.
this is especially true for the industrialsoftware systems because each of them is implemented by agroup of experienced developers at microsoft where the codequality has been strictly controlled.
consequently the sourcecode of these software systems is well suited for our studyon logging practices.
all of our code analysis is conductedbased on an open source c code analysis tool roslyn .
by using roslyn we can perform both syntax analysis andsemantic analysis on the source code.
b. observations pervasiveness of logging logging is pervasively used in software development.
as shown in table i our studied systems have a total of .6k logging statements containing327.6k lines of logging code out of .1m loc.
that is there is a line of logging code in every loc as similarlyreported in .
by drilling down according to thetype of software entities we find that about .
of thesource files .
of the classes .
of the methods and .
of the catch blocks are logged respectively.
inaddition by examining the revision histories of the systems we find that on average .
of the commits involvelogging modifications and further .
of them are modifiedalong with patches .
both its pervasive existence and active modifications reveal that logging plays an indispensable rolein software development and maintenance.
where to log the logging decisions can resolve to where to log and what to log.
where to log determines the locations to place logging statements while what to log denotes the contents recorded by these logging statements.
whereasthe goal of learning to log is to handle them both we studywhere to log in this paper.
our previous empirical study onwhere developers log has shown that there are sometypical categories of logging strategies for recording errorsites and execution paths.
error sites indicate some unexpectedsituations where the system potentially runs into a problem including exceptions and function return errors.
as two typicalways for error reporting exception mechanisms are widelyused in modern programming languages e.g.
c to handle abnormal situations and function return errors indicate thesituation where an unexpected value e.g.
null false empty 2we identify patches by searching commit logs for keywords such as fix bug crash or issue id like the same as in .
icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
table ii logging sta tistics software exception snippets return value check snippets systems exception types instances logged instances call types instances logged instances system a .
.
system b .
.
sharpdevelop .
.
monodevelop .
.
total .4k .7k .
.6k .4k .
a exception snippet c extracted contextual features from exception snippet in a qwdfwlf ihdwxuhv 6hw rjlf odj psw dwfk orfn 7kurz 2wkhu2shudwlrq 5hwxuq 5hfryhu odj 1xp2i0hwkrgv 7h wxdo ihdwxuhv fhswlrq w sh phwkrgv jhqgduph vhwwlqjv ordg uxohv iurp dvvhpeo v vwhp lr sdwk jhw ixoo sdwk uhiohfwlrq qdph iloh qrw irxqg h fhswlrq 9dldeohv dqdph dvvhpeo d rpphqwv deho rjjhg6wuxfwxudo ihdwxuhv fhswlrq sh vwhp loh1rw rxqg fhswlrq rqwdlqlqj phwkrg hqgduph 6hwwlqjv rdg5xohv urp vvhpeo qyrnhg phwkrgv vwhp 3dwk hw xoo3dwk vwhp 5hiohfwlrq vvhpeo 1dph hw vvhpeo 1dph vwhp 5hiohfwlrq vvhpeo rdg frgh h dpsoh wdnhq iurp 0rqr hyhors y dw iloh pdlq?h whuqdo?prqr wrrov?jhqgduph?frqvroh?6hwwlqjv fv olqh 6rph olqhv duh rplwwhg iru hdvh ri suhvhqwdwlrq sulydwh lqw rdg5xohv urp vvhpeo vwulqj dvvhpeo vvhpeo d qxoo wu vvhpeo 1dph dqdph vvhpeo 1dph hw vvhpeo 1dph 3dwk hw xoo3dwk dvvhpeo d vvhpeo rdg dqdph fdwfk loh1rw rxqg fhswlrq rqvroh uuru ulwh lqh rxog qrw ordg uxohv iurp dvvhpeo dvvhpeo uhwxuq frgh h dpsoh wdnhq iurp 0rqr hyhors y dw iloh pdlq?vuf?fruh?0rqr hyhors gh?0rqr hyhors gh?
pdjh6huylfh f v olqh rqyhuwv dq lpdjh vshf lqwr d uhdo vwrfn lfrq lgvwulqj vwrfnlg hw6wrfn g ru pdjh6shf qdph vl h li vwulqj v1xoo2u psw vwrfnlg rjjlqj6huylfh rj duqlqj dq w jhw vwrfn lg iru qdph qylurqphqw 1hz lqh qylurqphqw 6wdfn7udfh uhwxuq uhdwh roru orfn vl h b return value check snippet fig.
.
code examples and contextual features is returned from a function call.
we denote their associatedcode snippets as exception snippets and return value checksnippets respectively as examples shown in fig.
a b .they are the two most common logging strategies andthus become our focused code snippets.
although recording information of execution path is crucial for tracking down rootcauses from the error sites existing studies e.g.
control flow instrumentation have been conducted to achievethis goal which are orthogonal to our work.
why not log everything log information is immensely useful in maintaining software systems.
so the question whynot log everything?
e.g.
stackoverflow questions does sound reasonable.
y uan et al.
also proposed conser vative logging errlog which logs all the genericexceptions e.g.
exceptions and function return errors for failure diagnosis.
however as the logging statistics shownin table ii we observed that in our studied systems themajority of exceptions .
on average and return value check snippets .
on average are actually not logged.to understand this fact we posted our questions on whynot log all exceptions?
to the mail lists and websites ofmonodevelop sharpdevelp and stackoverflow and received some valuable feedback from the developers.according to their feedback logging all exceptions wouldproduce a ton of garbage and make it hard to zoom in on realissues which conforms with our argument not logging toomuch .
there are many reasons for not logging an exception.some exceptions are expected in normal operation whilesome others are satisfactorily handled or recovered withoutimpacting the user .
in a word not all exceptions are unex pected or errors .
strategic logging needs to determinewhether or not an exception is worth reporting .
logging decision and the context to understand this tradeoff in practice we attempt to study how developers makedecisions on whether to log a focused code snippet.
fig.
a presents a real world example of an exception snippet i.e.
try catch block .
the operations enclosed in the try blockattempt to load the rules from the input string assembly .if this assembly file cannot be found an exception with typeof filenotfoundexception will occur and then be caughtby the catch block.
here the exception has been logged withan error message by console.error.writeline .
intuitively from this example we can see that the logging decision ishighly dependent on the context of this code snippet includingtheexception type e.g.
filenotfoundexception the invoked methods e.g.
getfullpath getassemblyname load in a try block etc.
the contextual information is crucial becauseeach exception type generally denotes one specific type ofexceptional conditions while the invoked methods indicatethe functionality of operations.
driven by this intuition wemeasure the logging ratio of each exception type and eachmethod.
specifically the logging ratio with an exception type or an invoked method is measured by the number of loggedexceptions divided by the number of all the exception snippetswith this exception type or containing this method .
theresults show that a significant portion of exception types and methods have either high or low logging ratios which suggests their high correlations i.e.
icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
either positive or negative correlations with logging decisions of developers.
c. motivation with the ever growing scale and complexity of software systems it is common that each developer is only responsible for a part of a system e.g.
one or several components .
logging under this situation is notoriously challenging because deve lopers may not have full knowledge of the whole system.
forexample in our user study section v of the participantshave logging difficulties.
however there is a lack of rigorousspecifications or tool support for developers to aid their log ging decisions.
without a well structured logging strategy it isdifficult for developers to know how to make informed loggingdecisions and thus quite often the decisions are made basedon their own domain knowledge e.g.
understanding of system behaviours logging experience .
such domain knowledge isseldom documented and it is also hard to do so since thelogging behaviours of developers may vary widely not onlyfrom project to project but also from developer to developer.indeed the pervasively existing logging instances together canprovide strong indication of the developers domain knowledgeembedded with their logging decisions.
thus we intend toexplore whether the logging decisions of developers such aswhere to log can be learnt automatically from these existinglogging instances.
if so the constructed model can representthe common knowledge of logging and be further built intotool support to provide valuable suggestions e.g.
whether to log an exception snippet for developers.
such a tool canimprove the logging quality as well as reduce the effort ofdevelopers.
following this motivation we propose learningto log .
iii.
l earning to log in this section we present the overview as well as the detailed techniques of learning to log .
a. overview our goal referred to as learning to log is to automatically learn the common logging practice as a machine learning model and then leverage the model to guide developers tomake logging decisions during new development.
we furtherimplement the proposed learning to log approach as a tool logadvisor.
fig.
presents the overview of learning to log which can be described as the following steps instances collection as the first step we need to extract data instances focused code snippets from our tar get projects.
there are two types of frequently logged codesnippets exception snippets and return value check snippets.as shown in fig.
a and fig.
b exception loggingrecords the exception context e.g.
exception message after an exception is captured in the catch block while return value check logging is used to log the situation where an unexpectedvalue e.g.
null false empty is returned from a function call.
by employing roslyn we extract all these focused codesnippets and use them as training data to learn the loggingpractices of developers.
feature extractionfeature selectionmodel constructionsoftware repositoriesfocused code snippets instances collection logged instances unlogged instancescontextual features feature vectors label identificationfeature vectorpredictive model c o n t e x t u a new instance logging suggestiondeveloper log?
contextual features logging suggestion tool logadviosr fig.
.
the overview of learning to log label identification as a key step of preparing training data each data instance a code snippet is labelled logged if it contains a logging statement or unlogged otherwise.
alogging statement denotes a statement that has an invocationto a logging method e.g.
console.writeline .
we identify logging methods by searching some keywords in all methodnames such as log logging trace write writeline etc.
the logging statement identification and labelling procedures areautomatically performed based on roslyn.
f eature extraction in our study we need to extract useful features e.g.
exception type from the collected codesnippets for making logging decisions which is one of themost important steps to determine the performance of the pre diction model.
the details on feature extraction are describedin section iii b. f eature selection when there are too many features some of them are likely redundant or irrelevant since theyprovide little useful information or even act as noises todegrade the prediction performance.
feature selection is akey technique to remove such redundant or irrelevant featuresto enhance the prediction performance as well as shorten thetraining time.
model training through feature extraction and selection we can generate a corpus of feature vectors whereeach denotes a vector of feature values from a data instance.with these feature vectors and their corresponding labels wecan apply a set of machine learning models e.g.
decision tree to learn the common logging practice.
in our study we learn the decision on whether to log a focused code snippetas a classification model.
logging suggestion through the above learning process we can obtain a predictive model to perform accuratelogging predictions.
this predictive model can be trainedoffline and further be built into a logging support tool namelylogadvisor to provide online logging suggestions for developers.
for example when a developer composes a new pieceof code containing a try catch block logadvisor can detect and extract its feature vector in a transparent way.
thenlogadvisor can predict on whether to log and provide alogging suggestion for the developer through ide e.g.
like the warning message .
by using logadvisor developers can make informed logging decisions.
the above learning workflow is generic and works similarly to many other machine learning applications in softwareengineering e.g.
defect prediction .
icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
contextual featureserror type method1 method2identifiers comments method3 method4 method1 method5method6 throwsettingflag returnrecoverflag empty catchblock numofmethodsloc otheroperationmethod4 containing method syntactic featuresstructural featurestextual features labelfocused code snippet fig.
.
framework of contextual feature extraction b. contextual feature extraction feature extraction lies in the core of learning to log because the quality of extracted features directly determines the performance of the model.
the context information e.g.
the functionality of operations the impact of exceptions oflogging points are crucial for developers to make loggingdecisions.
however it is challenging to effectively extractsuch context information because the target code snippet isusually short and linguistically sparse compared to naturallanguage text.
to address this issue we propose a novel featureextraction framework as illustrated in fig.
which involvesthree types of features structural features textual features andsyntactic features.
structural features source code has a well defined structure.
it is desired to leverage the structure informationof source code to help extract context information.
to achievethis goal we extract two types of structural features error typeand associated methods.
error type the error type such as exception type or call type can largely reveal the context of our focused codesnippets which is highly correlated with logging decisions ofdevelopers as indicated in section ii b4 .
for an exception snippet the exception type generally denotes one specific typeof exceptional conditions with informative semantic meanings e.g.
filenotfoundexception in fig.
a .
for a return valuecheck snippet the call type is denoted as the prototype of thechecked function e.g.
string getstockidforimagespec string int in fig.
b which indicates one specific type of potential function return errors.
therefore we extract error type as akey feature.
each instance has a single error type but there exist a wide variety of error types among the training data.
we avoiddirectly using each error type as a feature dimension whichcan lead to highly sparse and ineffective feature vectors.
in stead we construct only one feature dimension as the loggingratio of each error type that is the ratio of logged instancesagainst all the instances within that error type.
fig.
c presents an illustration of the contextual features extractedfrom the code example in fig.
a .
in this example the filenotfoundexception type has a logging ratio of regarding training instances in monodevelop so we take thefeature value of error type as .
.methods the associated methods of a focused code snippet also provide indicative information to help understand thefunctionality of the operations.
for example we can figureout the intention of developers i.e.
to load an assembly file in the example of fig.
a according to the method names including loadrulesfromassembly getfullpath getassemblyname and load.
therefore we extract these methods as important contextual features.
specifically there are two types of methods the containing method and the invoked methods.
the former is the methodthat contains the focused code snippet e.g.
loadrulesfromassembly in fig.
a while the latter includes all the methods that are invoked by the snippet.
the operations can beseen as a sequence of api method invocations.
thus instead ofusing only the methods within the code snippet we also trackthe callee methods.
fig.
provides a prototype of our app roach where the arrows represent the invocation relationshipsbetween methods.
for example method1 and method2 areinvoked by the focused code snippet where method1 invokesmethod3 and method4 and method4 further invokes itselfand method6.
the extraction of methods continues trackingdown until the invoked method is a system api or externallibrary api method e.g.
system.io.path.getfullpath or until a certain number of levels has been attained.
the extractionprocess is implemented as a breadth first search bfs variant where all the recorded visited methods will be skipped.
inparticular all the logging methods are excluded in this process.due to space limits the details of the method extractionalgorithm is provided in our supplementary report .
after extracting the list of associated methods we obtain the full qualified name e.g.
system.io.path.getfullpath of each method as a feature dimension which contains namespace class name and its short method name.
fig.
c providesan example for these features.
t extual features source code is also text.
using code as flat text has been widely employed in the field of miningsoftware repositories and its effectiveness are demonstratedand reported in tasks such as api mining code example retrieval etc.
driven by these encouraging results we also emplo y the similar approach to extract textual features from source code text.
more specifically we extract all the texts in the focused code snippet excluding method names such as variables and types.then we combine them with the extracted list of structuralfeatures i.e.
error type and methods as the full text.
incontrast to extracting all the text directly our approach notonly excludes the text of logging methods but also includesthe names of the callee methods the containing method as well as their namespaces and classes.
with such text we can extract the textual features using the bag of wordsmodel through a set of widely used text processing operations including tokenization stemming stop words removal andtf idf term weighting .
since the use of these techniquesin code processing has been carefully reported in we omit the details here and refer the interested readersto our supplementary report .
in our study these processing icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
steps are performed using weka .
syntactic features as indicated in section ii b3 there are many situations of not logging even for typical error sites such as exceptions and function return errors.
some potentialerrors have no critical impact on the normal operation ofthe whole system some are resolved by recovery actionssuch as retry or walk around and some others are explicitlyreported e.g.
by setting flags re throwing or returning special values to the subsequent or upper level operations e.g.
caller method to handle.
to capture these contextual factors we also extract some key syntactic features from each focused code snippet settingflag.
we identify whether there is an assignment statementwith an assigned value like null false empty.
throw.
we identify whether there is a throw statement.
return.w e identify whether any special value e.g.
null false empty is returned.
recoverflag.
we check whether there is a new try statement inside.
otheroperation.
we check whether there is any other operations included except the above fiveones.
emptyblock.
we find that the developers sometimes catch and then do nothing.
we thus identify whether the catchblock is empty.
note that all these identification processeshave excluded logging statements at the first place and allthese features have boolean values.
in addition we employ the feature loc to measure the lines of code in the code snippet and the feature numofmethods to measure the number of the extracted methods.
an example is shown in fig.
c .
c. feature selection the above feature extraction process however can generate tens of thousands of features due to the large vocabulary of methods and textual terms extracted from the data instances.these features further lead to high dimensional e.g.
72k features in system b yet highly sparse feature vectors becausemost of the features are actually infrequent across all datainstances.
furthermore some of these features e.g.
textual features parsed from some specific variable names may beirrelevant and have negative impact on the performance of thepredictive model.
in such a setting we make use of a two step feature selection process to remove irrelevant features and reducethe dimensionality of feature vectors.
first we institute athreshold that constraints the minimum frequency of a featurethat occurs across all data instances.
we set the threshold to5 in our experiments and thus eliminate a significant number e.g.
in system b of infrequent features.
second we employ a well known approach information gain to perform further feature selection.
information gain is widely used and effective in text categorization .
we carefully setthe minimum information gain to filter out many irrelevantfeatures and reduce the feature dimensionality to around .
d. noise handling another challenge lies in the data noises.
in the framework of learning to log we implicitly assume good logging quality in the training data which therefore facilitates the0.
.
.
.
.
logged instanceunlogged instance synthetic instance fig.
.
illustration of noise handling automatic learning of good logging rules for new devel opment.
however there is no guarantee about the quality oflogging in reality due to the lack of ground truth on what isoptimal logging.
considering the active maintenance and thelong history of evolution of our studied software systems itis still reasonable to assume that most of the data instancesare enclosed with good logging decisions while only a smallportion of them may reveal incorrect decisions which we referto as data noises.
for example some instances that deserve logging are actually not logged while some others withoutthe need of logging are logged.
these data noises thus haveflipped logging labels.
we attempt to detect and eliminate such data noises and help the model learn the common knowledge of logging moreeffectively.
in many real world applications perfect data labelsare impossible or difficult to obtain .
kim et al.
haveproposed a simple and effective noise detection approach namely clni for defect prediction .
we adapt thisapproach to deal with our specific case and find that it workswell as demonstrated in section iv d .
traditionally clni identifies the k nearest neighbours for each instance and examines the labels of its neighbours.
ifa certain number of neighbours have an opposite label theexamined instance will be flagged as a noise.
however weobserve a high imbalance ratio for example up to .
in monodevelop between unlogged majority instances andlogged minority instances.
therefore the majority instancestend to dominate the neighbourhood of an examined instance which makes the identification of k nearest neighbours inclni biased to the majority class.
to handle this issue we apply a state of the art imbalance handling approach smote .
smote balances the data instances by creatingsynthetic logged instances as shown in fig.
.
consequently both classes have an equal number of data instances whicheliminates the inherent bias to the majority class when weidentify the k nearest neighbours of an instance.
next wequantify each examined instance iwith a noise degree value i summationtext j siwij wheresidenotes the set of neighbours with opposite label with i andwijis the weight to characterize the different impacts of different neighbours in si.
in contrast to clni that uses wij we take wijas the cosine similarity between features of iandj.
this is based on the intuition that instances with higher similarity between each other aremore likely to share the same label.
therefore the greater thevalue iis the higher probability the examined instance iis a noise.
for example in fig.
i .
.
we flag the instances with top ranked ivalues and remove them as noises while leveraging the remaining data for model training.
icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
table iii balanced accuracy of different approaches exception snippets return value check snippetsapproachessystem a system b sharpdev monodev system a system b sharpdev monodev random .
.
.
.
.
.
.
.
errlog .
.
.
.
.
.
.
.
error type .
.
.
.
.
.
.
.
methods .
.
.
.
.
.
.
.
textual features .
.
.
.
.
.
.
.
syntactic features .
.
.
.
.
.
.
.
logadvisor .
.
.
.
.
.
.
.
table iv balanced accuracy of different learning models exception snippets return value check snippetsmodelssystem a system b sharpdev monodev system a system b sharpdev monodev naive bayes .
.
.
.
.
.
.
.
bayes net .
.
.
.
.
.
.
.
logistic regression .
.
.
.
.
.
.
.
svm .
.
.
.
.
.
.
.
decision tree .
.
.
.
.
.
.
.
iv .
e v alua tion in this section we conduct comprehensive experiments to evaluate the effectiveness of logadvisor.
in particular we intend to answer the following research questions.
rq1 what is the accuracy of logadvisor ?
rq2 what is the effect of different learning models?
rq3 what is the effect of noise handling?rq4 how does logadvisor perform in the cross project learning scenario?
a. experimental setup after obtaining the feature vectors and their corresponding logging labels we employ weka to perform model train ing and evaluation.
due to the imbalanced nature of our data we apply the weka implementation of smote to balancethe training data for model construction.
by default we usedecision tree j48 as the learning model because of its goodperformance section iv c and ease of interpretation.
exceptfor the cross project evaluation section iv e all of theexperiments are evaluated on all of the extracted data instancesby using the fold cross evaluation mechanism .
as recommended in other related work we evaluate logadvisor using balanced accuracy ba which is the average of the proportion of logged instances and theproportion of unlogged instances that are correctly classified.ba is calculated as follows ba tp tp fn tn tn fp where tp fp tn and fn denote true positives false pos itives true negatives and false negatives respectively.
baweights the performance on each of the two classes equally thus avoiding inflated performance evaluation on imbalanceddata.
for example with an imbalance ratio of .
in monodevelop a trivial classifier that always predict notlogging unlogged can achieve accuracy but wouldresult in a low balanced accuracy of .
for referencepurpose the results on other metrics such as precision recalland f score are provided in our supplementary report .
b. results of rq1 prediction accuracy we compare logadvisor with two baseline approaches random and errlog .
by random we mimic the situation where a developer has no knowledge about logging andperform the logging decision with a random probability of .
.errlog is proposed in that makes conservative logging i.e.
log all the generic exceptions such as exceptions andfunction return errors for failure diagnosis.
the results areprovided in table iii.
as we can observe both random and errlog have balanced accuracy of approximately .
random logging has equalaccuracy of on either class.
errlog logs every instance achieving accuracy on logged class and on un logged class.
overall the balanced accuracy of logadvisor is high ranging from .
to .
indicating high similarityto the logging decisions manually made by developers.
thus logadvisor can learn a good representation of the common logging knowledge and serve as a good baseline for guidingdevelopers logging behaviors towards better logging practice.
we also evaluate the effect of different contextual features error type methods textual features and syntactic features on the prediction accuracy as presented in table iii.
we cansee that every type of contextual feature is useful which leadsto much higher balanced accuracy than random and errlog.logadvisor by combining all these useful features makes fur ther improvement and achieves the highest balanced accuracy.these results also reveal that the contextual features extractedfrom the focused code snippets provide good indication oflogging practices of developers.
c. results of rq2 the effect of different learning models by default we use decision tree j48 to train our model due to its simplicity as well as its effectiveness shown in our previous study .
we also examine the impact of icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
.
.
.
.
.
.
.
.
.81percentage of instances noise degreeexception snippets monodevelop normal instances noise instances a instance distribution over noise degreesystem a system b sharpdev monodev0.
.
.
.951balanced accuracyexception snippets w o noise handling w noise handling b the effect on exception snippetssystem a system b sharpdev monodev0.
.
.
.951balanced accuracyreturn value check snippets w o noise handling w noise handling c the effect on return value check snippets fig.
.
noise handling evaluation results different learning models on the prediction accuracy.
we have tried a number of popular learning models includingnaive bayes bayes net logistic regression supprot v ectormachine svm and decision tree by using their wekaimplementations.
the evaluation results in table iv showthat all the learning models lead to overall good predictionaccuracy.
in particular bayes based learning models are basedon probability theory.
unlike natural language text the featuresextracted from source code are short and linguistically sparse so bayes based learning models work slightly worse in oursettings.
logistic regression is a linear classifier thus it maynot fit well with our data.
decision tree achieves the bestoverall accuracy because this algorithm can solve non linearclassification problem.
furthermore this algorithm can implic itly perform feature selection which removes the redundant orirrelevant features and runs much faster than svm for our data.
d. results of rq3 the effect of noise handling to evaluate the effect of noise handling approach we first study the instance distribution across the noise degree i values and then compare the prediction results with noise handling and those without noise handling.
for ease ofpresentation we only plot the instance distribution regardingexception snippets of monodevelop in fig.
a while theresults of other systems are also similar.
in particular weset the number of nearest neighbours k t o5 .s o ihas a value range of .
it shows that the majority about of instances have a noise degree value close to indicatingthat each examined instance has the same logging label withalmost all of its nearest neighbours.
only a small proportion ofinstances are likely noise data e.g.
those with noise degree i .
to some extent this reveals the quality of data.
in our study we tune the threshold and flag about ofinstances with top ranked ivalues as noises which are removed them in the training phase.
as the evaluation resultsshown in fig.
b c the noise handling approach makesfurther improvement on the prediction accuracy.
it indicatesthat properly removing potential noise data can make ourmodel learn the common logging knowledge more effectively.
e. results of rq4 cross project evaluation in within project learning logadvisor leverages the existing logging instances within the same project as training data to construct the predictive model.
the above experiments providepromising results on the prediction accuracy of within projectsystem a system b sharpdev monodev0.
.
.
.
.
.0balanced accuracy s1 s2 s3 s4 within project learning cross project learning cross project learning settings s1 systemb g198systema s2 systema g198systemb s3 monodev g198sharpdev s4 sharpdev g198monodev fig.
.
cross project evaluation results evaluation strongly indicating that logadvisor likely work well in the scenario of developing some new components in the same project.
however many real world projects are small ornew which have limited training data for model construction.in such cases it is valuable to explore whether cross projectlearning can help.
in cross project learning we enrich the training data by incorporating the data instances extracted from a similarproject source project and then apply the trained model to the target project for logging prediction.
however in contrast to within project learning cross project learning issignificantly more challenging such as handling project specific features.
to address these challenges we extract thecommon features that are shared between projects.
we findthat many system apis and error types are actually commonamong different projects.
we further leverage these commonfeatures to evaluate the performance of cross project learningbetween different pairs of our studied systems one sourceproject for training and one target project for testing .
due to space limits we only provide four pairs of crossproject evaluation results in fig.
and others in our supple mentary report with comparison to their correspondingwithin project evaluations.
the settings of these cross projectevaluations are shown as well.
for example by using system a as the target project and system b as the source project we can get a balanced accuracy of .
compared with93.
in within project learning.
this result indeed indicatesthat the performance of cross project learning is largely deg raded compared with within project setting.
the reason is thatdifferent projects may follow different logging practices andsome project specific knowledge e.g.
domain exceptions and methods are challenging to adapt to other projects.
however these results can serve as a baseline for further improvementby exploring other sophisticated techniques such as transferlearning across projects .
icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
v. u ser study to further measure the effectiveness of logadvisor we conduct a controlled user study among engineers from microsoft and a local it company in china.
we invited participantsin total including staff developers and interns whohave an average of .
years of programming experience.
inaddition of them use logging frequently while of them use logging occasionally.
the user study isconducted through an online questionnaire which consists of11 questions questions for the background of participantsand their understanding on logging practices questions forcase studies on logging and questions for assessment of ourlogging suggestion results.
for reproducibility a copy of thequestionnaire is provided on our project page .
to perform logging case studies we randomly select exception snippets and return value check snippets frommonodevelop.
half of them are logged while the other halfare not.
we remove the logging statements in code snippetsand ask participants to make logging decisions on whetherto log.
the original logging labels made by code owners aretaken as the ground truth .
however sometimes it is hardfor participants not code owners themselves to understandthe code logic well by reading only a small code snippet.to mitigate this issue we group two code snippets withdifferent logging labels e.g.
one logged exception and one unlogged exception into a pair.
then we ask the participantsto choose which one is more likely to be logged from the pair because it is easier for an participant to make choice throughcomparison.
to evaluate the effectiveness of logadvisor t w o groups of pairs are provided one group with our loggingsuggestions and the other group without logging suggestions.the suggestion results are provided from our trained model with an accuracy of approximately on these case studysnippets.
to make a fair comparison each participant marks anequal number of pairs in each group and each pair is markedby at least three participants.
in particular we leverage theonline survey system qualtrics to build questionnaires each using different pairs of code snippets.
we distribute thesurvey links evenly to the participants.
furthermore we recordthe time they spend on making each logging choice using thetiming functionality of qualtrics.
results we evaluate the accuracy that the participants correctly recover the logging decisions of the code owners.
forthe group without logging suggestions the accuracy is while the group with logging suggestions achieves an accuracyof with a relative improvement of .
as for timeconsumption the participants took less time on averageto make a logging choice with our logging suggestions 28seconds v.s.
seconds .
in addition we query the feedbackfrom the participants by the question do you think thesuggestion result is useful for your logging choice?
and of participants think it is useful.
these results provide a strongevidence in the effectiveness of our logging suggestion.
d iscussions logging quality the approach of learning to log works under the premise that the training data have high loggingquality.
in such a setting the constructed model can representthe common and good logging knowledge and generalizewell to predictions of new instances.
however there is no ground truth on what is high quality or optimal logging.in our study we assume that our studied software systemshave reasonably good logging implementations due to theirhigh code quality active maintenance and long history ofevolution.
to a certain degree it has been endorsed by ourevaluation results e.g.
high prediction accuracy positive user feedback .
besides our noise handling approach can furthermitigate the data quality issue by detecting and omitting thenoisy logging instances from the training data thus improvingthe performance of logadvisor.
diversity of subject software systems our study was conducted on four software systems written in c thusits validity may be threatened by the limited diversity ofour studied systems.
to mitigate this threat we choose thesubjects including both commercial software systems from aleading software company like microsoft and popular open source software systems on github.
these systems are activelymaintained and have a long history of evolution which canserve as a representative of real practice.
besides two of themare online services while the other two are ides thus yieldingboth similar projects and dissimilar projects for our study.
webelieve that our approach and the results derived from thesesystems are easily reproducible and can be generalizable tomany other software systems.
future studies on more types ofsoftware systems may further reduce this threat.
where to log v.s.
what to log to achieve good logging quality developers need to make informed decisions on bothwhere to log and what to log.
the ideal of learning to log is to help developers resolve both decisions.
however as aninitial step towards this goal we focus primarily on whereto log in this paper because it is the first logging decisionto make and sometimes can determine or narrows down what to log.
for example when developers decide to log anexception the contents to be recorded become much morespecific including the exception message stack trace etc.besides a recent study has built an logenhancer tool that can enrich the recorded contents by automatically identifyingand inserting critical variable values into the existing loggingstatements.
as part of our future work this tool can be furtherintegrated into our learning to log framework to facilitatelog automation where logadvisor determines where to log and logenhancer determines what to log.
potential improvements towards learning to log we still have a number of potential directions that deserve furtherexploration for improvements other factors on logging decision.
the logging behaviours of developers can be quitecomplex and vary among developers.
also the logging state ments can be dynamically updated such as deletion andmodification.
thus additional consideration of factors such as icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.
code owner check in time and execution frequency of code may further enhance the performance of logging prediction.
interdependence of logging statements.
our approach identifieseach logging point sequentially and in isolation.
in somecases logging at one point may impact another.
for example atry catch block may be enclosed in another catch block and the exception may be thrown to the upper one to log.or sometimes logging statements at critical points are usedtogether to record the execution path.
further exploration of ajoint inference model e.g.
graphical models markov chains may help in this case.
runtime logging.
current logging statements are mostly statically inserted into the code.
thereis a new proposal for runtime logging in which whether to logor not can be determined at runtime.
for example logs maybe recorded by adaptive sampling or only be recordedwhen encountering some problems e.g.
a failed request or a long response .
although such sophisticated runtimelogging mechanism is not supported by our studied systems it is a promising direction for exploration to balance utilityand overhead of logging.
vii.
r ela ted work log analysis logs contain a wealth of information that are useful in aiding software system maintenance and thusbecome an important data source for postmortem analysis .for instance logs have been widely analyzed for various tasks such as anomaly detection problem diagnosis program verification security monitoring usageanalysis etc.
in addition to the usage of logs shanget al.
studied how to automatically enrich the producedlog messages with development knowledge e.g.
source code commits issue reports and further assist users in log under standing.
instead our work aims to improve the underlyinglogging practice thus can potentially benefit these tasks onlog analysis and log understanding.
logging practices current research has mostly focused on the usage of logs but little on logging itself.
two em pirical studies have recently been conducted tocharacterize the logging practices.
y uan et al.
reportedthe characteristics of logging modifications by investigatingthe revision histories of open source software systems.
ourprevious work focused on studying where developer logthrough both code analysis and developer survey at microsoft and summarized five typical categories of logging strategies.additionally shang et al.
studied the relationship betweenlogging characteristics and the code quality of platform soft ware.
all these studies provide comprehensive logging char acteristics that shed insights into our design of logadvisor.
improving logging towards improving the logging quality y uan et al.
have recently pioneered two prior studies logenhancer and errlog .
logenhancer aims toenhance the recorded contents in existing logging statementsby automatically identifying and inserting critical variablevalues into them.
errlog summarizes a set of genericexception patterns e.g.
exceptions function return errors thatpotentially cause system failures and then suggests conser vative logging to automatically log all of them e.g.
log all exceptions .
their work takes the first step towards automaticlogging and provides promising results in reducing diagnosistime of system failures.
our work instead makes an initialattempt to help developers make informed logging decisions.furthermore we argue that logging too much can causeunintended problems and aim to draw a good balance via learning to log .
mining software repositories some technical insights in the design of logadvisor are also inspired from the existing work on mining software repositories especially fromsoftware defect prediction .
the defect predictionmethods extract features from the defective and non defectivemodules and then construct a classification model to pre dict the defect proneness of a new module.
kim et al.
proposed the clni method to address the data quality issue data noise in defect prediction.
zimmermann et al.
evaluated cross project defect predictions among real worldapplications and highlighted the critical challenges in cross project learning.
our work applies a similar machine learningapproach and also considers issues such as data quality andcross project learning.
exception handling exception handling mechanisms have been widely studied to improve the reliability and main tainability of software systems.
cacho et al.
evaluatedhow changes in exceptional code can impact system robust ness.
thummalapenta et al.
leveraged association rules tomine some specific exception handling patterns.
in our work we focus on logging in two types of code snippets with regardto exceptions as well as function return errors.
viii.
c onclusion strategic logging is important yet difficult for software development.
however current logging practices are not welldocumented and cannot provide strong guidance on deve lopers logging decisions.
to fill this gap we propose a learn ing to log framework which aims to automatically learn thecommon logging practices from existing code repositories.as a proof of concept we implement an automatic loggingsuggestion tool logadvisor which can help developers make informed logging decisions on where to log and potentiallyreduce their effort on logging.
evaluation results on four large scale software systems as well as a controlled user study demonstrate the feasibility and effectiveness of logadvisor.
we believe it is an important step towards automatic logging.
a cknowledgment the work described in this paper was substantially supported by the national basic research program of china 973project no.
2011cb302603 the national natural sciencefoundation of china project no.
andthe research grants council of the hong kong special ad ministrative region china no.
cuhk of the generalresearch fund .
icse florence italy authorized licensed use limited to chinese university of hong kong.
downloaded on december at utc from ieee xplore.
restrictions apply.