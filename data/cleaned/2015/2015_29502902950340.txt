proteus computing disjunctive loop summary via path dependency analysis xiaofei xie1bihuan chen2y ang liu2wei le3xiaohong li1 1tianjin key laboratory of advanced networking tianjin university china xiexiaofei xiaohongli tju.edu.cn 2nanyang t echnological university singapore bhchen yangliu ntu.edu.sg 3iowa state university usa weile iastate.edu abstract loops are challenging structures for program analysis especially when loops contain multiple paths with complex interleavingexecutions among these paths.
in this paper we first propose a classification of multi path loops to understand the complexity of the loop execution which is based on the variable updates on the loop conditions and the execution order of the loop paths.
secondly we propose a loop analysis framework named proteus whichtakes a loop program and a set of variables of interest as inputs and summarizes path sensitive loop effects on the variables.
the key contribution is to use a path dependency automaton pda to capture the execution dependency between the paths.
a dfs based algorithm is proposed to traverse the pda to summarize the effect for all feasible executions in the loop.
the experimental results show that proteus is effective in three applications proteus can compute a more precise bound than the existing loop bound analysistechniques significantly outperform state of the art tools for loop verification and generate test cases for deep loops within one second while klee and pex either need much more time or fail.
ccs concepts theory of computation program verification program analysis software and its engineering software verification automated static analysis software testing and debugging keywords loop summarization disjunctive summary .
introduction analyzing loops is very important for successful program optimizations bug findings and test input generation.
however loop analysis is one of the most challenging tasks in program analysis.
itis described as the achilles heel of program verification and a key bottleneck for scaling symbolic execution .
xiaohong li is the corresponding author school of computer science and technology tianjin university.generally there are three kinds of techniques for analysing loops namely loop unwinding loop invariant inference and loop summarization .
the most intuitive method is loop unwinding where we unroll the loop with a fixed number of iterations a.k.a.
the bound .
this technique is unsound and cannot reason about the program behaviors beyond the loop bound.
loop invariant is a property that holds before and after each loop iteration.
it is mostly used to verify the correctness of a loop.
the limitation is that typically only strong invariants are useful to prove the property while commonly used fixpoint based invariant inferencing is iterative and sometimes time consuming.
it may fail to generate strong invariants especially for complex loops.
in addition loop invariants often cannot suffi ciently describe the effect after the loop and hence are limited to check the property after the loop.
compared with loop invariants loop summarization provides a more accurate and complete comprehension for loops .
it summarizes the relationship between the inputs and outputs of a loop as a set of symbolic constraints.
we therefore can replace the loop fragments with such symbolic transformers during program analysis.
this leads to a wider range of applications.
for example we can use loop summarization to verify program properties after a loop and we can use it to better direct test input generation in symbolic execution.
detailed discussion about invariant and summarization can be found in section .
the loop summarization techniques mainly handle singlepath loops the simplest type of loops where no branches are present .
the recent advances of loop analysis are to perform loop summarization for multi path loops the loops that contain branches .
however the techniques cannot summarize the interleaving effect among the multiple paths in a loop.
the goal of this paper is to reason about the interleaving of multiple paths in the loop and generate a disjunctive loop summary dls for such multi path loops.
as an example the while loop in fig.
a contains an ifbranch which makes it a multi path loop.
in addition the computation in the ifandelse branches can impact the outcome of the ifcondition leading to interleaving of the two paths in the loop.
it is the initial values of the variables x zand nthat determine the different possibilities of interleaving between the ifandelse branches.
for some of the multi path loops we can determine what types of interleaving potentially exist and what are the loop summaries for the determined types.
consider fig.
a let x zand x prime z primebe the values before and after loop execution respectively.
when the initial values satisfy x n the loop effect is x prime x z prime z. when x n z the loop effect is x prime n z prime z. when the loop starts with x n z n the loop effect is x prime z prime n. hence a precise summary of the loop effect should be a disjunction that includes all possible loop executions due to different initial values of x zand n. thus the dispermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
fse november seattle wa usa c acm.
... .
junctive loop summary for fig.
a is x n x prime x z prime z x n z x prime n z prime z x n z n x prime z prime n .
comparing with the loop summarization in dls computes the effect of each possible pattern of the loop execution and it is more specific and fine grained.
this paper accomplishes two tasks to advance the state of the art loop analysis.
first we proposed a classification for multi path single loops non nested loops based on a deep analysis on challenging loops found in real world software.
the classification defines what types of multi path loops we can handle precisely what types of multi path loops we can handle with approximation and what types of multi path loops we cannot handle.
the classification is based on two aspects the update patterns of variables that direct the path conditions and the interleaving patterns among the paths in the loop.
second we developed a loop analysis framework named proteus1 to summarize the effect of the loops for each type.
proteus takes a loop code fragment and a set of variables of interest as inputs to compute the dls.
the dls represents a disjunction of a set of path sensitive loop effects on the variables of interest.
basically proteus generates a fine grained loop summary in three steps.
the first step applies a program slicing on the loop according to the variables of interest so that irrelevant statements are removed to reduce irrelevant paths in the loop.
in the first step we also construct the loop flowgraph based on the control flow graph cfg of the sliced loop.
the second step is a novel technique where we construct a path dependency automaton pda from the flowgraph to model the path interleaving.
each state in the pda corresponds to a path in the flowgraph and transitions of the pda capturethe execution dependency of the paths.
the last step performs a depth first traversal on the pda to summarize the effect of each feasible trace in the pda which corresponds to an execution in the original loop .
the final result is a disjunction of the summaries for all feasible traces.
for the challenging loop types that cannot be directly handled we transform them to the simpler ones with approximation techniques before summarizing them.
we have implemented proteus and experimentally evaluated the usefulness of summary by applying it to loop bound analysis program verification and test case generation.
we collected single loops in total from several open source projects to understand the distributions of loop types and the complexity of loops in real world programs.
we computed the loop bound for the loops in these projects.
the result shows that proteus can compute a more precise loop bound than the previous techniques .
we performed program verification using the benchmark sv comp .
the result indicates that our approach can summarize .
of the total programs among these summarized programs proteus can help correctly verify .
of the programs.
compared to proteus smack corral that achieved the highest correct rate in sv comp can only correctly verify .
of loops.
in addition proteus only took seconds while smack corral took more than hours.
we also evaluated test case generation by compar ing the two configurations of the symbolic execution tools klee and pex with proteus.
our result shows that with proteus it only took less than one second to generate the test cases for all the loops while klee either times out or needs much more time and pex often throws an exception.
to the best of our knowledge this is the first work to compute dls for multi path loops.
the main contributions of this paper are .we propose a classification for multi path loops of four types to understand the complexity of the loop execution 1a greek god who can foretell the future.bx n cz x x a edz x z x n f abce abde af a flowgraph x z true x x z x n n z x z n x z z z n n n x z n x n z z n n n 2 x n z x z x 1 x n z x x 3 x n s1 s2 s3 b path dependency automaton pda figure the flowgraph and pda for the loop in figure a .we propose a path dependency automaton to capture the execution dependency and effects of the paths in multi path loops .we propose an algorithm to compute dls based on the path dependency automaton and .we conduct an experimental study to classify the loops in realworld projects as well as to evaluate the usefulness of dls in three important software applications.
.
overview in this section we first formally introduce the concepts of flowgraph and loop paths which are needed to understand the rest of the paper.
we then present a classification of multi path loops we identified and also provide an overview of proteus that computes thedls for the identified types.
note that the loops in the scope are multi path single loops that do not contain other loops inside.
.
preliminaries definition .given a loop the flowgraph of the loop is a tuple g v e vs vt ve where vis a set of vertices e v vis a set of edges that connect the vertices vs vt vare two virtual nodes that capture the start and end points of each loop iteration veis a virtual node that represents the exit of the loop and is a function assigning every edge e ean instruction e .
a node is a branch node if its out degree is and the instruction on the edge that starts from the branch node is a boolean condition.
for example fig.
a shows the flowgraph of the loop in fig.
a .
nodes aand especify the start and end of the loop iteration respectively and node fis the exit node.
node bis a branch node the instructions on the edges b c and b d are conditions.
intuitively given a loop flowgraph g each iteration in the loop from node vstovtis an execution path.
we introduce the concept of theloop path to better discuss how we model the effect of each loop iteration to compute the summaries of the loop.
definition .given a loop flowgraph g v e vs vt ve a loop path we call it path here after for simplicity ingis a finite sequence of nodes angbracketleftv1v2...vk angbracketright where k vi vi e i k v1 vs and vk vt ve .
a path is called an iterative path ifvk vt o ra n exit path ifvk ve.
we use to denote the path condition of path which is a conjunction of the branch conditions along the edges of path .
given a loop flowgraph g we use gto denote the set of all paths in g. in fig.
a the flowgraph has two iterative paths 1 angbracketleftabce angbracketright and 2 angbracketleftabde angbracketright and one exit path 3 angbracketleftaf angbracketright.
for path 1 the path condition 1isx n z x.
62int n int x int z while x n if z x x else z assert x z a while i if a a else a if j j else j i b while i l i n t int j nondet assume j assume j lint i i j k c while x1 x2 x3 if c x x else if c x x else x3 x3 c1 nondet c2 nondet assert x1 x2 x3 d while i a j b if a b i j else i i j j e int s x x while nondet if s x1 else if s x2 s if s s if s x1 !
x2 error f figure motivating loop programs from the recent work and the sv comp benchmark .
loop classification to summarize a multi path loop we need three critical pieces of information value changes in each iteration of one path the number of iterations of each path and the execution order of the paths.
since a loop path consists of a finite sequence of nodes we can perform symbolic analysis to derive value changes at the end of the path.
the number of iterations of each path depends on the path condition.
if the variables in path condition are induction variables we usually can reason about the number of iterations.
the execution order of loop paths depends on the input of a loop.
we found there are patterns that we can summarize to describe the path interleaving.
based on the above analysis the difficulties of summarizing a multi path loop are determined by the patterns of value changes in path conditions i.e.
whether the variables are induction ornoninduction and the patterns of path interleaving which we defined the three types sequential periodic and irregular .
in the following we provide a detailed explanation for the two patterns and also present the classification of a multi path loop based on the two.
the classification represents how difficult a multi path loop can be summarized .
patterns of value changes in path conditions .
given variable xand path we write i xto denote the value change of xbetween the i thand ithiterations of .
we define the induction variable as follows according to their value change during the execution.
definition .given a loop flowgraph g a variable xis an induction variable if g for any ithand jthiterations of i x j x. otherwise xis a non induction variable .
for an induction variable x the value change of xis constant in each iteration of and we write it as x. for example in fig.
a xis an induction variable as the change of xover each iteration of the loop path 1 2or 3is constant and we have 1x 2x 0and 3x .
similarly zand nare also induction variables.
note that it is undecidable to determine induction variables.
in our implementation we perform a conservative static analysis and report one variable as induction variable only when we statically identify that the symbolic change of the variable is constant in each iteration of a path.
each condition in a path can be transformed to the form of e where eis an expression and .
for the operator negationslash we transform it to e e .
we use eas a variable for the ease of presentation.
we classify each condition into two types iv condition .
a condition is an iv condition if eis an induction variable.
for example the condition x nin fig.
a is an iv condition since 1e 1and 2e 3e where e x n. niv condition .
a condition is a niv condition if eis a noninduction variable.
for example the condition i ain fig.
e is a niv condition since v i ais non induction variable.
in some niv conditions the value change of eis solely dependent on the input or context before the loop but not the statements in the loop.
for example the condition in the loop that traverses atable a classification of single loops iv condition niv condition sequentialtype type 3periodic irregular type type data structure is often dependent on the content of the data structure and a non deterministic function as a condition cannot determine the value change patterns over the iterations.
we call such niv conditions input dependent niv conditions .
in fig.
e the condition a b is an input dependent niv condition since the value change of a b depends on the element contents of aand b. the conditions c1and c2in fig.
d are also input dependent niv conditions as they depend on the non deterministic function nondet .
patterns of path interleaving .
we use the concept of loop execution to define the patterns of path interleaving in the loop.
the precondition of the loop specifies the conditions of the variables before entering the loop.
note that with different preconditions the loop may have different executions.
definition .given a loop flowgraph gwith a precondition a loop execution gis a sequence of paths angbracketleft 1 2 ... i .
.
.
angbracketright where i gfor all i .
we use i jto represent a subsequence from ito jin g. if i negationslash j i j iis a subsequence of g then gcontains a cycle.
the cycle is periodic if its execution has the pattern angbracketleft ki i .
.
.
kj j .
.
.
angbracketright its period is angbracketleft ki i .
.
.
kj j .
.
.
angbracketright where ki and kjare constant values that represent the execution times of i and jrespectively.
for example in fig a the flowgraph contains cycle 1 2 1 whose execution is angbracketleft angbracketleft 1 1 angbracketright angbracketleft 1 1 angbracketright .
.
.
angbracketright.
thus this cycle is periodic and its period is angbracketleft 1 1 angbracketright.
given a loop flowgraph gwith a precondition we classify a loop execution ginto three types sequential execution .i f gdoes not contain any cycle it is a sequential execution.
periodic execution .
if all cycles in gare periodic it is a periodic execution.
irregular execution .
if a loop execution is neither sequential nor periodic we call it an irregular execution.
in this case the loop execution contains cycles however the path interleaving pattern for the loop execution cannot be statically determined.
therefore we cannot easily compute the number of iterations for each path.
loop classification .
in table we show a loop classification we defined based on the above two patterns.
the first row indicates that we classify a multi path loop based on whether all the conditions in the loop are iv conditions see type and or there exists a condition that can be the niv condition see type and .
the first column displays the criteria of path interleaving patterns i.e.
whether all the feasible executions of the loop are sequential or 636olflqj dqg orzjudsk rqvwuxfwlrq rrs 3urjudp 9duldeohv ri qwhuhvw ssur lpdwlrq 3dwk hshqghqf qdo vlv lvmxqfwlyh rrs 6xppdul dwlrq7 sh ru hv1r orzjudsk sh ru rrs 6xppdu figure an overview of our framework proteus periodic see type and or there exists one loop execution that can be irregular see type and .
typically the loops related to integer arithmetics e.g.
fo r i n i often belong to type .
the loops that traverse a data structure often belong to type and as the loop iteration depends on the content of the data structure.
intuitively loops with niv conditions such as the ones related to complex data structures tend to have no path interleaving patterns i.e.
irregular execution .
as examples the loop in fig.
a is type as it only contains iv conditions and has a periodic execution.
the loop in fig.
b belongs to type .
although theoretically type loops should exist in practice we did not find any type loops in real world programs details are given in the evaluation section .
the loop in fig.
c contains an niv condition and its execution is sequential the loop in fig.
f contains niv conditions and has a periodic execution.
thus both of them belong to type .
the loops in figs.
d and e belong to type because they contain input dependent niv conditions that can lead to an irregular execution.
.
loop analysis framework fig.
shows the workflow of proteus.
it takes a loop program and a set of variables of interest as input and it reports a loop summary for the variables of interest.
the variables of interest are given by the client analysis who uses the loop summary.
for example if the goal is to determine the loop bound the variables in the conditions that may jump out of a loop are of interest and if we use the loop summary for program verification we will need to summarize the variables relevant to the properties to be verified.
in this way proteus performs a problem driven summarization for the loop program.
guided by the variables of interest proteus can further simplify the loop to generate the summary more efficiently.
if the variables of interest are not specified proteus can also generate a summary for all the induction variables in the loop.
proteus mainly consists of four steps to summarize a loop.
step performs a program slicing using the variables of interest as slicing criteria and constructs the flowgraph for the sliced loop program.
the loop slicing removes the irrelevant statements which can help reduce irrelevant paths in the constructed flowgraph and make our summarization more efficient.
we implement the loop slicing based on the program dependence graph pdg which combines the control flow graph cfg and data dependencies and the details can be found in .
then the flowgraph is constructed based on the cfg by adding the virtual start node end node and exit node.
from the flowgraph we can directly determine the type of the loop from the loop conditions.
if all the conditions in a loop are iv conditions the loop belongs to type or type otherwise the loop belongs to type or type .
summarizing the non induction variables is very challenging because of the uncertain value changes we provide some approximation techniques step to transform some of the loops of type and type to type or type .
this approximation may cause imprecise summaries but may still be useful and effective in specific applications.
we cannot handle type and type loops that cannot be approximated.in step proteus extracts the path condition and value changes of the variables from the flowgraph and analyzes the dependency between any two paths.
we propose a path dependency automaton pda to capture the execution order and path interleaving patterns of the paths.
note that we can construct the pda for type and type loops.
in step we perform a depth first search on the pda to check the feasibility of each trace in the pda and summarize the loop effect if it is feasible.
the loop summary is a disjunction of the summaries for all loop executions i.e.
all feasible traces in the loop .
the last two steps are our main contributions in this paper which will be elaborated in section and respectively.
.
path dependency analysis this section presents the definition of path dependency automaton pda and the algorithm to construct a pda from a flowgraph.
.
path dependency automaton definition .given a flowgraph gwith a set of induction variables x the path dependency automaton pda is a tuple m s init accept arrowhookleft where sis a finite set of states each of which corresponds to a path in g. each state s sis a tuple s s sx where s g is the corresponding path sis the path condition of s a n d sxrepresents the set of the value changes for all the induction variables after one execution of s. init sis a set of initial states.
accept sis a set of accepting states which have no successors.
an accepting state is called an exit state if it corresponds to an exit path and a terminal state if it corresponds to an iterative path.
arrowhookleft s sis a finite set of transitions.
we use si arrowhookleft sjto represent the transition si sj arrowhookleft and introduce a variable kij as the state counter to indicate that sican transit to sjafter kijexecutions ofsi.
each transition si arrowhookleft sjis annotated with a tuple transition predicates ij ij uij .
ijis a constraint about kij.
ijis the guard condition satisfying which si arrowhookleft sjwill be triggered.
note that ijand ijare conditions on the variables before entering into si.uijis a function computing x prime which are the values of variables xafter kijexecutions of si.
that is x prime uij x kij .
note that a terminal state indicates that once the execution enters a terminal state it never transits to other paths i.e.
the loop will execute infinitely on the path.
for example there are two states corresponding to the two paths of the loop while i i .
the state corresponding to the iterative path i i 0is a terminal state leading to an infinite execution of the loop.
for a pda m a trace inmis a sequence of transitions s1 arrowhookleft ... arrowhookleft si where s1 initand si accept .
a trace represents a possible loop execution.
note that not all traces in pda are feasible and the existence of transitions si arrowhookleft skand sk arrowhookleft sjcannot guarantee si arrowhookleft sk arrowhookleft sjis feasible.
we use emto denote the set of all feasible traces in m and x to represent the symbolic values of the variables xafter the execution of the trace .
example.
fig.
b shows the pda of the loop in fig.
a .
its flowgraph is given in fig.
a .
in the pda s s1 s2 s3 corresponds to the three paths of the loop init s1 s2 s3 represents the initial states marked as red and accept s3 corresponds to the exit path in the loop.
for state s1 it corresponds to path 1 whose path condition s1isx n z x. the value changes along 1are s1 x z n here we omit the variables that do not change over the loop iterations .
the table above the transition represents the transition predicates.
for the transition s1 arrowhookleft s2 i t indicates that after executing s1fork12number of times the loop 64algorithm constructpda input g flowgraph precond the precondition of the loop output m p d a 1construct states sfrom paths g 2let xbe the induction variables in the flowgraph g 3foreach s sdo ifsolve precond s sat then init init uniontext s 6foreach si sj s i negationslash jdo let kij be the state counter for si arrowhookleft sj let x prime kij 1be the variables after kij executions of state si let x prime kijbe the variables after kijexecutions of state si cond si x prime kij x sj x prime kij x ifsolve cond sat then ij simplify cond ij eliminate cond ij arrowhookleft arrowhookleft uniontext si sj annotate ij ij uij x kij with the transition si arrowhookleft sj 16accept is the set of states which have no successors 17return m s init accept arrowhookleft leads to s2.
the first row in the table specifies the constraint for k12 k12 k12 z x i.e.
12 .
the second row is the guard condition 12 z n indicating that when the condition z nis satisfied s1is transited to s2after k12number of iterations.
the function u12 the third row is x prime z prime n prime z z n suggesting that after executing s1fork12times the symbolic values of x zand n become z zand n. note that the variables x n zon each table are not the initial values before the loop but the values before executing the source state of the corresponding transition.
.
construction of pda algorithm presents the procedure to construct a pda from the flowgraph.
the input of the algorithm includes the loop flowgraph gand the precondition of the loop precond .
the output is the constructed pda.
at line we first construct the states sof pda from g. for each state s s we solve the constraint precond sby using the smt solver z3 .
if the result is sat i.e.
the constraint is satisfied the state sis added into init line .
then we compute the transition between any two states si sjin the pda line .
first we introduce the state counter kij 1for the transition si arrowhookleft sj and we also specify the value of variables after kij 1and kijtimes of execution of siasx prime kij 1and x prime kij line .
the key observation here is that if a transition between sitosjis feasible sishould be satisfied with variables x prime kij 1and sjshould be satisfied with variables x prime kij.
we use to represent xare substituted with x primein the condition .
at line we get the guard condition for si arrowhookleft sjby the conjunction of the substituted siand sj.
this computation is effective for type and type loops that only contain iv conditions discussed in section .
.
in this case the change of the variables is linear along the path i.e.
x prime kij 1and x prime kijhave a linear relation with x. finally we use the smt solver z3 to solve the generated guard condition at line .
if the result is sat the transition si arrowhookleft sjis feasible unsat means there is no transition from sitosj .
we simplify the linear inequalities in the guard condition based on an extended z3 tactics and compute the predicate for kij line .
at line we aim to eliminate the variable kijincond if possible and simplify the guard condition ijto use only loop variables.
in particular if siimplies cond ijcan be simplified to true whichalgorithm summarizetype1loop input m p d a precond precondition output sm loop summary of mon precondition precond 1let xbe the induction variables in mand recbe a summary map 2foreach si initdo summarizetrace si precond si x rec 4return sm algorithm summarizetrace input si current state tc current trace condition x prime updated variables rec a map 1ifsi recthen summarize cycle by checking the period 3else if si accept then ifsiis exit state then sm sm uniontext tc six prime .
else sm sm uniontext tc six prime 8else foreach sj sm si arrowhookleft sm arrowhookleft do let ij ij uij be the predicates on transition si arrowhookleft sj ifsolve tc ij sat then nrec clone rec nrec tc ij uij x prime kij summarizetrace sj tc ij uij x prime kij nrec means once entering into si sican always transit to sj.
note that if it cannot be eliminated it just keeps the original cond and does not affect our approach.
we add the transition into the set arrowhookleft line and update the variables in xusing the state counter kij.
the result uij x kij is used with ij ijto annotate the transition line .
example.
using the previous example in fig.
b we explain how the transitions are computed.
consider the transition s1 arrowhookleft s2in fig.
b .
the table on top of s1 arrowhookleft s2in fig.
b shows the tuple transition predicates.
let k12be the state counter.
the updates of the variables after k12 1and k12times of executions of path 1are x prime k12 x prime x k12 n prime n z prime z and x prime k12 x prime x k12 n prime n z prime z respectively.
we then can compute the conjunction of the two path conditions s1and s2by substituting the variables xwith x prime k12and x prime k12 1respectively and obtain cond as x k12 n z x k12 x k12 n z x k12 .
after the simplification of the inequalities we can get ijasz x k12 z x i.e.
k12 z x. using this information we can further simplify cond to be z n i.e.
12 .
the update function u12is x prime n prime z prime x k12 n k12 z k12 z n z .
similarly we can also compute 21 x nfor transition s2 arrowhookleft s1.
however 21can be simplified as true since s2implies x n .
disjunctive loop summarization in this section we elaborate the algorithm for computing dls which is formally defined below.
definition .given a pda mgenerated from a loop flowgraph g and a set of induction variables x the summary of a trace mis denoted as a tuple tc x where tc is the condition needed to meet when trace is feasible and x is the value of the variables after executing the trace.
the loop summary of m denoted as sm i s uniontext em tc x i.e.
the union of all trace summaries in the loop.
65s1 s2s3 a circlessl kl sj kj sn...... si ki b cyclesl kl ... sj kjsi kisl kl sj k kjsn...... si ki c cycle execution figure examples of cycle .
summarization for type loops algorithm shows the detailed procedure for summarizing type loops.
it takes as inputs the pda of a loop m the precondition before the loop precond and returns the loop summary sm.
let xbe the set of the induction variables which contain the variables of interest and recbe a map to record the summary for the current trace i.e.
from the initial state to the current state line .
algorithm traverses each initial state to summarize the feasible traces starting from it by calling algorithm line .
algorithm performs a depth first search dfs on the pda to summarize each transition of the trace until it reaches an accepting state.
its inputs are the current state si the current trace condition tcfor the prefix trace during dfs the values of variables x primeafter the previous transition summarization and the summary map rec.
specifically if the current state siis contained in rec a cycle is found and we summarized the cycle by its period which will be introduced later line .
if siis an accepting state the summarization for one trace is finished line .
in particular if the accepting state is an exit state tcis the satisfied condition of the trace the variables x primeare updated to six primein the exit path line .
if siis a terminal state the trace corresponds to an infinite execution.
thus the current variables x primeare updated to six prime where means the infinite update of six prime.
in the implementation we use a symbolic infinite value to represent this infinite update.
on the other hand if siis not an accepting state the algorithm continues to summarize the transitions from sito its successors line .
for each successor sj let ij ij uij be the transition predicates line .
the guard condition ijis updated by substituting its variables xwith x prime.
the constraint tc ij is solved by the smt solver to check whether the current trace can transit to sj line .
if feasible the algorithm clones a new map nrec for the new branch line updates the current trace condition to tc ij updates the variables to uij x prime kij and stores the current trace summary into nrec line .
then it continues the summarization from state sj line .
example.
for the pda in fig.
b the precondition is true.
starting with the initial state s3 algorithm reaches an exit state.
thus the trace condition is x n the variables do not change and the summary for the trace s3is x n x prime x z prime z n prime n .
starting with the initial state s1which has two successors the initial trace condition is x n z x. consider the transition s1 arrowhookleft s3 the execution reaches an exit state after this transition.
the trace condition is updated to x n z x z n simplified as x n z. the variables are updated to x prime n z prime z n prime n .
thus the summary for trace s1 arrowhookleft s3is x n z k13 n x x prime n z prime z n prime n .
cycle summarization .
summarizing a cycle is challenging since the execution number of each state is uncertain during the executions of the cycle.
multiple connected cycles are challenging due to the interleaving of the cycles.
for example fig.
a shows the interleaving of three cycles which represents the dependencies among the three paths in fig.
d .
the execution order of such connected cycles are often undecidable.
hence the loops that contain multiple connected cycles are regarded as irregular execution.
in our n x true x n z z n x n n z x z n x z z z n n 1 x n z x x 0 x n z x z n z x s1 3 x n s0s3 figure the substitution of a cycle table the summarization process for s1 arrowhookleft s2 arrowhookleft s1 arrowhookleft s2 trace tc x prime sss111 arrowhookleft s2 x n k12 z x z x z n x prime z z prime z n prime n s1 arrowhookleft sss222 arrowhookleft s1 x n z x k12 z x k21 z n true x prime z z prime z n prime n s1 arrowhookleft s2 arrowhookleft sss111 arrowhookleft s2 x n z x k12 z x k21 z n z n x prime z z prime z n prime n experiments we found the cycles that connected are all aperiodic and there is no loop containing connected periodic cycles.
however if the cycle is periodic each execution of the cycle has the same pattern i.e.
the period see section .
then we can compute the effect of each period and abstract the cycle as a new state since the execution of the cycle is periodic.
each execution of the new state represents a full execution of the cycle i.e.
the period and the state counter of the new state represents the execution number of the cycle.
for example fig.
b is a periodic cycle its period is angbracketleftskl l ... skj j ski i angbracketright and it has one successor sn.
fig.
c shows the specific execution pattern of fig.
b .
the executionconsists of two parts k executions of the complete cycle the red part and one execution of the remaining chain a partial cycle sl arrowhookleft ... arrowhookleft sj arrowhookleft sn the blue part .
the red part is abstracted as a new state each of whose execution represents kl ... kj ki executions of the states sl ... sj sirespectively.
example.
table shows the summarization for s1 arrowhookleft s2 arrowhookleft s1 arrowhookleft s2in fig.
b .
in the third row since s1is already in rec a cycle c s2 arrowhookleft s1 arrowhookleft s2is detected.
we can learn from k12 k21 that cis periodic and the period is angbracketlefts1 s1 angbracketright.
fig.
shows the pda after substituting the cycle as new state s0.
the path condition s0 isx n z x true z prime n prime where z prime z n prime n and the variables xand zincrease by one in each iteration of the cycle.
then we compute the path dependency for s0 arrowhookleft s3.
finally the trace of the loop execution acyclic is s1 arrowhookleft s2 arrowhookleft s1 arrowhookleft s32 and its summary is x z n k12 z x k03 n z x prime n z prime n n prime n .
similarly we can also compute the summary for another trace s2 arrowhookleft s1 arrowhookleft s2 arrowhookleft s1 arrowhookleft s3as z x n k21 x z k01 n x k13 x prime n n prime n z prime n .
.
summarization for types and loops it is non trivial to summarize type and loops precisely as they contain niv conditions irregular executions or both.
we introduce several approximation techniques to proteus to facilitate the summarization which are still effective for specific applications.
niv condition.
niv conditions are difficult to be summarized because of the unpredictable value change for non induction variables.
we use different strategies for three kinds of niv conditions.
if the variables in a condition are monotonically increased or decreased and we only care about the path dependencies e.g.
in loop bound analysis and termination analysis we approximate the 2this trace is a simplification of s1 arrowhookleft s2 arrowhookleft s1 arrowhookleft s2 arrowhookleft s1 arrowhookleft s3 as the chain after the cycle is also one complete cyclic execution.
66change of the value as increased by one or decreased by one .
this approximation makes the variable becomes an iv .
the summary can still be used to get a safe result for some applications.
example.
the variable iin the loop in fig.
c is a non induction variable but it is always increased.
if we want to compute a bound for the loop we approximate that iis increased by one in each iteration and we compute the loop bound as lint which is a safe bound.
some niv conditions are from the data structure traversal e.g.
list which are difficult to summarize.
in bound analysis we perform a pattern based approach to capture some of them and the string loops can also be summarized with our technique in .
example.
we use the attribute size li to describe the loop iterations for the data structure traversal loop like fo r li!
null li li next then the loop can be converted to fo r li size li li .
similarly length str can be used to describe for the string traversal loop like fo r char p str p!
p .
for input dependent niv conditions they can always be satisfied in any iteration since their values are dependent on the input or context but not the loop execution.
thus we abstract them as true.
example.
the loop assume i while i v key i contains one iterative path and two exit paths.
the condition v keyis an input dependent niv condition.
after abstracting it as true we get 1 i true i 2 i true and 3 i .
then we can summarize it as the trace summary for 1 arrowhookleft 2is i k12 i i prime i k12 and the trace summary for 1 arrowhookleft 3is i k13 i i prime .
note that this loop summary is also precise.
imprecision can be caused when the content of data structures are updated before or in the loop.
we will discuss the imprecision in section .
irregular execution.
for loops with irregular path executions the interleaving pattern can be arbitrary and thus cannot be deter mined.
hence we do not consider the interleaving order between any two paths but consider the total effect of each path during the whole loop execution by introducing a path counter kifor each path i. each path counter kican be used to compute the values of the induction variables after kiexecutions of the loop.
intuitively loops with irregular execution satisfies the following condition assume ican transit to the exit path then j negationslash i after kjiterations of jand ki 1iterations of i it will satisfy the exit condition of the loop and after kjiterations of jand kiiterations of i it will violate the exit condition.
example.
the loop in fig.
d has irregular executions with three paths.
we introduce path counters k1 k2and k3to represent their total execution count.
the variables after the loop can be x prime x1 k1 x prime x2 k2 x prime x3 k3.
for the path 1which can transit to the exit path the variables after k1 1iterations of 1satisfy the exit condition and the variables after the k1iterations of 1violate the exit condition which implies the constraints x1 k1 x prime x prime x prime x prime x prime .
by simplifying the constraints we can get x prime x prime x prime .
similarly if the last iteration is path 2or path 3 we can compute x prime 0orx prime .
the summary can be used to verify the property after the loop successfully.
.
discussion precision.
our summarization for type loop is precise with respect to the following aspects.
first we perform an equivalent translation from a loop program to its pda.
second with the induction variables and state counters the summarization is an accumulation of the variable updates in the execution of the trace and there is no approximation involved when producing dls from pda in algorithm .
third dls is disjunctive and thus fine grained we consider all of the possible loop execution patterns under different preconditions of the loop.
types loop summarization may intro duce imprecision because approximation is used on non induction variables.
however it can still be useful and precise in certain applications.
limitation.
in this paper we mainly focus on the systematic summarization for type loops.
summarization for non induction variables and nested loops is still an area of open interest.
nested loops are challenging when changes in inner loops make the variables become non induction variables in outer loops.
the problem is then equivalent to summarizing non induction variables inunnested loops.
we will leave the systematic summarization for non induction variables and nested loops in the future work.
.
ev aluation the goals of our experiments are to study the distributions of loop classification in real world programs and to demonstrate the usefulness and accuracies of proteus in practical applications.
we have implemented proteus using llvm .
and smt solver z3 .
we planned the following experiments to achieve our evaluation goals.
in the first experiment we selected five open source projects of different categories including coreutils .
a basic module in the gnu operating system containing the core utilities gmp .
.
an arithmetic library pcre2 .
the library that implements regular expression pattern matching libxml2 .
.
.tar the xml c parser and toolkit developed for the gnome project and httpd .
.
the apache http server project.
we studied the loop classifications for these programs.
the results help understand the capabilities of proteus in solving loops in real world programs.
in the next set of experiments we applied proteus for loop bound analysis program verification and test input generation.
the experimental results are discussed in the following sections.
.
classification of real world loops in table the programs under study are listed in the first column.
under total nest we list a total number of loops discovered which includes both single loops and nested loops the number of nested loops is listed in the parenthesis .
for the nested loops we classify only their inner loops.
under type1 type3 and type4 w e list the total number of type loops found for each of the benchmarks.
there is no column for type as we have not found any type loops in the five benchmarks.
the type loop shown in fig.
b is an constructed example.
theoretically type loops do exist however we believe that such loop is difficult to understand and maintain and the developers typically do not write such code.
the last row of the table summaries the results for all the benchmarks and the programs can be classified in less than five minutes.
we show that for the five projects under study we found that .
of the loops belong to type .
is type and .
belong to type .
type loops are most common loops and they are mainly caused by the usage of data structures and arrays in the loop.
type loops are the second most common category.
for example gmp is an arithmetic library and many of its loops are type .
proteus is able to handle such category precisely.
with the techniques of demand driven analysis and approximation proteus is also able to handle some of the type and loops.
by furtherinvestigating these loops we found that the dominance of type and type loops makes sense when a multi path loop contains niv conditions the loop execution is often irregular type loops and when a loop s conditions are only iv conditions the loopexecution is either sequential or periodic type loops .
there is often a correlation between niv condition and irregular execution.
in summary our loop classification can provide a better understanding of real world loops with respect to the four loops types.
it 67table results of loop classification projects total nest type1 type3 type4 coreutils .
.
.
gmp .
.
.
pcre2 .
.
.
libxml .
.
.
httpd .
.
.
total .
.
.
also guides the design decision in proteus to primarily focus on type loops and to use approximation to handle other loop types.
.
application on loop bound analysis to compute the loop bound using proteus we are interested in knowing when the exit conditions are met.
thus we use the exit conditions as the slicing criteria to simplify the loops as the first step.
we perform summarization on the simplified loop and addup the state counters for each state along feasible traces as a loop bound.
in our experiment we found that slicing is an effective technique to improve the capability of the loop summarization for a given problem.
for example we found that of the loops in coreutils is simplified as a result of slicing and .
of the paths that are irrelevant to bound analysis are pruned.
based on these sliced loop programs we can compute the bounds for .
loops in the projects.
table provided detailed results for each benchmark.under type1 type3 and type4 we list the percentage of the loops of type type and type where we successfully compute the loop bounds.
under total we show the percentage of all the loops where we can compute the loop bounds.
we found that all these loops are summarized in less than minutes totally.
we investigated the cases where we are not able to compute the loop bounds.
we found the following reasons niv conditions .
the loops has non induction variables whose value changes are not always increased or decreased in all loop paths e.g.
for conditions that contain function calls.
note that many of the loops we can handle also contain function calls but they do not affect loop conditions and can be removed via slicing.
irregular executions .
the loops have irregular interleaving of the loop paths and the execution order of the paths affects the bounds.
for example in the loop while i n if a i else i the value change of idepends on the execution order of the paths and thus the bound is non deterministic.
we also tried to compare our loop bound analysis results with the current techniques .
however their tools are currently not publicly available.
instead we compared our approach with these techniques based on the examples used in their work.
generally our approach has three advantages when the value change of the variables in some paths is not exactly one we can compute a more precise bound than them since we summarize the change.
for example in the loop while i n i suppose i 0and n the technique in computes the bound as nwhile we compute the bound as n .
our approach can compute a fine grained bound for each possible loop execution trace with the disjunctive summary.
our approach not only computes the bound for the loop but also computes the bound for each path.
this is very crucial and usefulin some applications.
for example for worst case execution time wcet analysis it is easy to compute the whole execution time based on the path bounds given the estimated execution time for each path .
differently the techniques in can compute bounds for some nested loops while we only consider single loops.table results of loop bound analysis projects type1 type3 type4 total coreutils .
.
.
gmp .
.
.
pcre2 .
.
.
libxml .
.
.
httpd .
.
.
total .
.
.
assume m n 2i j while i n nondet if j m j else j i a int size a j a while j size a !
j assert j s i z e b figure loop examples for evaluation we also found one imprecise loop bound computed by i.e.
example in fig.
in .
that loop is shown in fig.
a which contains interleaving among its multiple paths.
assume that path 1takes the ifstatements the true branch 2takes the elsestatements the false branch and 3is the exit path.
the loop has only one execution trace 1 arrowhookleft 2 arrowhookleft 1 arrowhookleft 2 arrowhookleft 3 whose summary is i j m n k12 m k02 n k23 j prime i prime n m prime m n prime n .
its periodic execution executes 1formtimes and 2for once.
thus the bound is m m n n m n. however the result in is n m. in summary using dls we can compute a more precise and finegrained loop bound than the existing loop bound analysis techniques.
.
application on program verification in this experiment we apply dls to program verification.
we used the benchmark loops in competition on software verification sv comp which has loop categories.
this benchmark contains small but non trivial loops.
note that the loop invcategory contains many assertions that are not relevant to loops and thus we used the other four categories.
we compared our verification results with several tools which represent the state of the art.
cbmc is the basic bmc based verification tool and cbmcacc is the latest work to improve the capability of cbmc on loops with a trace automata.
smack corral cpachecker lpi and seahorn are the top tools with respect to correct rate in sv comp16 cpacheckerlpi achieved the best score in sv comp16 for loops .
note that we select the tools based on correct rate rather than the score in sv comp16 since we compare the number of correctly verified loop programs.
we also select the cpachekcer based on predicate analysis and cpachecker kinduction based on k induction .
we configured cbmc as in smack corral cpacheckerlpi and seahorn as in the competition and cpachecker as in .
all of them were configured with a timeout of minutes.
since cbmcacc is currently not publicly available we only used the experimental results from to do the comparison.
table shows the verification results of those techniques together with the loop summarization statistics.
column bench shows the involved loop categories.
columns nv arand nlrespectively list the number of loops that cannot be summarized because of non induction variables array variables and nested loops.
column smlists the number of loops that can be summarized.
column tt reports the total programs each program contains one loop in each loop category.
columns creport the number of programs that can 68table verification results of cbmc cbmc acc cpachecker seahorn and proteus bench nv ar nl sm ttproteuscbmc cbmcacc cpachecker smack corralseahornb predicate k induction lpi c t s c t s acc c c t s c t s c t s c t s c t s loops loopacc looplit loopnew total be correctly verified by the techniques while columns tlist their time overhead.
column accgives the number of loops that can be accelerated by the cbmcacc tool.
here we only compared the programs whose loops can be summarized because our goal is to show the loop summary is complement to these tools to improve their capability on loops.
we compared the verification results with the loops that can be summarized by proteus.
when the bound is set to cbmc can correctly verify .
loops in seconds.
a large number of loops cannot be verified correctly since the bound is not large enough.
we also set the bound to it can correctly verify .
loops but takes seconds we omit this from the table for the space limitation .
on the other hand with dls proteus can correctly verify .
loops within seconds.
note that in table the time reported for proteus includes both the time for computing dls and the time for proving properties with dls.
the average time for computing dls for each loop is .
seconds.
the results indicate that bmc are often less effective and our technique can correctly verify more loop programs with less time overhead.
to compare with cbmcacc we only show the results for loop categories loops and loop accsince they only used these two categories in their paper .
in their experiments the bound was set to if the loop could be accelerated otherwise the loop was verified by cbmc with the bound being .
from their experimental results we know it can accelerate of the loops in category loops and .
loops can be verified correctly while our technique can verify .
loops.
the loops they fail to accelerate are mostly multi path loops containing complex interleaving.
the loops in category loop acchave deep iterations but one single path.
thus cbmc acc can accelerate and verify all of them.
our technique can verify loops the incorrect one is caused by the imprecision in approximation of input dependent niv condition.
the results indicate that our technique can handle complex interleaving based on the pda while cbmcacc often fails.
compared with other tools .
loops can be correctly verified in seconds for predicate analysis in cpachecker .
loops in seconds for k induction and .
loops in seconds for lpi.
seahorn takes seconds to correctly verify .
loops.
smack corral can correctly verify .
loops in seconds.
note that the time overhead of cpachecker smack corral and seahorn is very large because some programs time out.
the results indicate that our technique slightly outperforms these top tools on effectiveness and significantly outperforms them on performance.
the incorrect verification results of our techniques are caused by the potentially imprecise summaries with approximation.
for example the program in fig.
b taken from category loops has a inputdependent niv condition.
our technique approximates the condition a !
3astrue and thus finds a counterexample j size .
actually the content of array ais changed at line which makes the property j size always true.
in summary using dls we can correctly verify more programs with less time overhead than existing tools for those loops that wetable test case generation results of klee pex and proteus toolfunctio phases overfl multiv simple simple ns false false ow true ar false false1 false2 klee min t o t o .
s min .
s pex f f f f f .
s proteus .
s .
s .
s .
s .
s .
s can summarize.
therefore our loop summary can be en effective complementary to existing tools.
.
application on test case generation in this experiment we apply dls to test case generation.
we did not compare with other summarization techniques since their tools are not available and the comparison of the approaches are discussed in the related work.
we compared the performance of our technique with the symbolic execution tools klee and pex using the loops in loop acc which contain deep loops with large loop iterations .
a test case is generated for the assertion after the loop to be true by using klee pex and our technique.
our goal is not to compare the tools but to show dls can be potentially used to scale symbolic execution.
table shows the results for six programs.
for the other programs five of them are the corresponding patched versions of the selected programs and the results are similar and of them do not have very deep iterations about iterations and the results using the three tools are all less than one second.
in the table t orepresents that klee cannot generate a test case within minutes and times out and fmeans that pex fails to generate a test case and throws an out of memory exception for the large branches.
among the six programs the program phases false has a multipath loop and the other five programs contain simple loops each of them only contains one statement.
the results show that even for the simple loops klee timed out for two programs and took much more time for three programs.
pex failed to generate test cases for five programs.
this is because symbolic execution consumes much time to keep unfolding the loop.
on the contrary proteus generated test cases for all the programs in less than one second.
in summary the state of the art symbolic execution tools klee and pex can take much time or throw exceptions when a loop has many iterations.
in such cases dls can be helpful to improve the performance of these tool by utilizing the summary during symbolic execution.
we leave it as our future work to integrate disjunctive loop summarization into symbolic execution.
.
related work loop invariant is a property hold at the beginning or at the end of each loop iteration including the exit of the loop .
on the other hand loop summarization focuses on capturing the relations of variables at the entry of the loop and at the exit of the loop which can also generate symbolic constraints at the exit of the loop.
comparing to loop invariants loop summaries are more precise and more rich.
hence computing summary is more challenge than invariant.
69in the following we present the related work on the two areas and discuss loop analysis in different applications.
.
loop summarization several techniques have been proposed to summarize the loop effect .
lese introduces a symbolic variable trip count as the number of times a loop executes and uses it to infer the loop effect.
the technique in detects loops and induction variables on the fly and infers the simple partial loop invariants and generates pre and post conditions as loop summaries.
these techniques only focus on single path loops.
apc introduces path counter for each path to describe the overall effect of variable changes in the loop.
it summarizes a loop by computing the necessary condition on loop conditions.
s looper summarizes multi path string loops using path counters.
it extracts the string pattern from each path and then generates the string constraints.
both apc and s looper cannot handle loops with complex path interleaving e.g.
the loop in fig.
a .
proteus aims to model path interleaving of a multi path loop and we compute fine grained dls which none of the existing techniques have done.
in they compute the may and must summary compositionally and use them for program verification.
however they do not compute the loop summary and loops are handled with invariants.
.
loop invariant detection a number of advances have been made on loop invariant inference .
most of them arebased on abstract interpretation which iterates the loop until a fixpoint is reached.
to ensure the termination they often use the widening operator which can lead to imprecision.
techniques are proposed to accelerate the iteration and reduce imprecision.
these approaches mainly focus on conjunctive invariants which cannot represent disjunctive program properties.
several attempts have also been made to infer disjunctive invariants.
the techniques in are based on octagons and polyhedra and it cannot compute complete disjunctive invariants.
the tech nique in decomposes a multi path loop into several single loops which is difficult to handle complex interleaving.
the technique in uses dynamic analysis to generate disjunctive invariants over program trace points but it is often hard to compute effective tracepoints for each invariant.
the template based technique needs user provided templates and thus is not fully automatic.
the techniques in synthesize invariants using templates and learning techniques which are not sufficient and precise for some properties.
compared with loop summary loop invariant has several limitations.
first it cannot guarantee to provide the required invariants strong and precise enough .
our summarization computes stronger constraints and can also be used to infer invariants .
second invariant is more suitable for checking properties inside the loop.
it cannot describe the loop effect i.e.
postcondition .
proteus can compute symbolic values for variables after a loop and thus can be used in symbolic execution.
finally most techniques focus on conjunctive invariant which cannot represent disjunctive properties.
.
loop analysis for different applications loop analysis can be applied to various domains.
here we focus our discussion on loop bound analysis and program verification.
the existing symbolic execution tools mainly handle loops by unrolling the loop and thus are omitted here.
loop bound analysis .
lokuciejewski et al.
compute the loop iteration counts based on abstract interpretation .
their polytopebased approach assumes that the variable in the loop exit condition must increase in each loop iteration and cannot handle the loops infig.
d and e .
gulawani et al.
compute bounds for multipath loop based on user annotations.
gulwani et al.
use counter instrumentation strategies and a linear arithmetic invariant generation tool to compute the bound.
however it is limited for multi pathloops when disjunctive invariants are needed.
it also fails to compute the bound for the loop in fig.
a .
gulwani et al.
use control flow refinement and progress invariants to estimate loop bounds.
control flow refinement is similar to pda but pda contains more information and is more specificthan control flow refinement.
its bound computation relies on thestandard invariant generator and the result is usually inequalities.
gulwani et al.
also propose a two step solution computing disjunctive invariants and a proof rule based technique to compute the bound.
however if the variables are not increased or decreased by one in each iteration their result is an upper bound and not precise.
differently proteus can compute a precise bound with the disjunctive summarization on the pda.
program verification .
bound model checking bmc is a technique to check the properties with bounded iterations of loops .
it is mainly used to find property violations based on sat solvers but it can not prove safety properties soundly.
kroening et al.
overcome this problem by introducing trace automata to eliminate redundant executions after performing loop acceleration which is limited for multi path loops whose accelerated paths interleave with each other.
the technique in combines predicate analysis with counterexample guided abstraction refinement.
however it depends on the discovered predicates which are often difficult to control.
several techniques propose to handle loops by combining bmc with k induction.
scratch supports combined case kinduction but needs to set kmanually.
however split case k induction can change kiteratively.
ecbmc assigns non deterministic values to loop termination condition variables making induction hypothesis too weak and unsound.
pkind cpachecker and kiki strengthen the induction hypothesis with auxiliary invariants.
however their effectiveness and performance depend on the inferred invariants.
k induction technique may consume much more time to get a better k. proteus can help verify programs with the loop summary effectively as shown in our experimental results.
.
conclusions in this paper we propose a classification for multi path loops to understand the complexity of loops.
based on the classification we propose a path dependency automaton to describe the executions of the paths in a loop as well as a loop analysis framework proteus toperform disjunctive summarization for different types of loops.
to the best of our knowledge this is the first work that can identify different execution patterns of a loop and compute disjunctive loop summary for multi path loops with complex path interleaving.
in the future we plan to extend proteus to support nested loops summarize type and loops with abstraction approaches and apply it to more applications such as detection of loop related performance bugs and analysis of the worst case execution time .
.