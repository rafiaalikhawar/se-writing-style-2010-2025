targeted example generation for compilation errors umair z. ahmed iit kanpur umair cse.iitk.ac.inrenuka sindhgatta queensland university of technology renuka.sr qut.edu.aunisheeth srivastava iit kanpur nsrivast cse.iitk.ac.inamey karkare iit kanpur karkare cse.iitk.ac.in abstract we present tegcer an automated feedback tool for novice programmers.
tegcer uses supervised classification to match compilation errors in new code submissions with relevant pre existing errors submitted by other students before.
the dense neural network used to perform this classification task is trained on error repair code examples.
the proposed model yields a test set classification pred accuracy of .
across error category labels.
using this model as its base tegcer presents students with the closest relevant examples of solutions for their specific error on demand.
a large scale n usability study shows that students who use tegcer are able to resolve errors more than faster on average than students being assisted by human tutors.
index t erms intelligent tutoring systems introductory programming compilation error example generation neural networks i. i ntroduction cs1 the introduction to programming course is one of the most popular college courses with class sizes reaching students in some universities and up to hundreds of thousands on massive open online courses moocs .
programming assignments are used as an important learning tool to help acquire and practice programming skills.
presently cs instruction is struggling to cope with the challenge of effectively imparting such programming lessons at scale .
in this paper we present a potential solution to a part of this challenge providing personalized feedback to correct programming errors.
while attempting programming assignments students run into compilation errors and logical errors.
compilation errors typically occur when a program does not obey the syntax or grammar of a language and are flagged by a compiler.
however the associated errors messages are often cryptic and unclear to novice programmers especially those undertaking their first programming course.
in order to help students enhancements to compiler messages have been proposed which involves manually analyzing the topfrequent error messages by experts and listing possible solutions raising scalability concerns.
a large number of repair tools have been proposed to automatically detect and repair errors in programs enumerated in the survey paper by monperrus .
the current state ofart compilation error repair tools are able to achieve up to repair accuracy .
these repair tools typically take part of this work was carried out by the author at ibm research.as input the incorrect solution by a student also referred to as erroneous or buggy code and generate the correct repaired code as their final output.
while revealing these correct solution could be invaluable as a feedback in certain situations to help student proceed further it is unclear if providing it during the programming exercise could aid in effective learning.
it is plausible for the student to simply copy the answer without understanding the error causation or its fix.
novice programmers consider example programs as the most useful type of material for learning .
the notion of learning by example has been widely studied in education research .
while there is no precise definition an example aims to convey how another similar problem can be solved.
in this paper we propose a new feedback tool called tegcer targeted example generation for compilation errors .
the goal of tegcer is to provide an alternative feedback to students who encounter compilation errors in their program while maintaining the scalability offered by automated repair tools.
this feedback is in the form of examples of fixes performed by other students albeit on a different program when faced with similar error previously.
such an approach is a departure from most of the recent work in literature which instead tend to focus on producing the desired repair solution help improve the descriptive error message or vary the error message s structure and placement .
figure presents an erroneous code attempt by student on our custom ide prutor with tegcer feedback tool integrated.
the students code written in the top right editor pane suffers from compilation errors in separate lines.
in line 5and the student forgot to use an asterisk operator and comma separator respectively.
while in line the student mistakenly uses comma separator instead of the semi colon separator required in for statement specifier.
the error messages returned by clang a popular compiler for c language are then shown in the bottom right console pane.
the error messages for line 5and line are cryptic with the compiler treating them as an incorrect function invocation and misplaced bracket respectively.
this can be even more confusing for novice students learning their first programming language usually requiring human tutor assistance to understand the error and then fix it.
tegcer s example feedback is shown in the left side tutor pane for each individual erroneous line.
these automatically generated examples are highly relevant to both the mistake 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
user interface of tegcer feedback tool.
the erroneous student code is written in top right editor pane and the compilation errors are displayed in bottom right console pane.
tegcer s example feedback is shown in the left tutor pane.
made by student and its desired repair.
the students can request for multiple examples of repaired code from which they can be expected to learn the general cause of a particular compilation error and its potential fixes after which they can proceed to transfer the acquired knowledge on their own code and repair it.
there have been extensive studies in literature on how providing relevant worked examples can help students learn effectively in a pedagogical setting .
this idea of using code examples from other students as compilation error feedback is not new.
the closest related work to ours is helpmeout where students can query a central repository to fetch example erroneous repaired code pairs of other students that suffer from compilation errors similar to their own code.
this repository of errors is created and maintained manually by students and relies on user provided explanation and ratings for suggesting relevant examples.
in contrast tegcer passively learns from mistakes made by students of previous offerings and provides feedback for students in new future offerings of course.
our contributions our main contribution is the theory and implementation of tegcer1 a tool to automatically suggest relevant programming examples as feedback to students without requiring any human assistance.
to the best of our knowledge tegcer is the first automated tool of this kind.
in the extremely challenging task of predicting a single correct label for buggy program from unique error repair classes tegcer achieves very high accuracy of on its first prediction pred .
from a dataset of buggy programs we identified unique compilation error groups egs made by novice students and different class of error repairs cs performed by them to fix the errors.
this dataset is released in public domain to help further research1.
we also report results from a large scale empirical evaluation of our system comparing its ability to assist students with that of human teaching assistants across errors of greatly varying complexity.
ii.
tegcer s ystem overview in this section we present tegcer in its entirety.
figures 2a and 2b give an overview of the training and live deployment phases respectively.
from a course offering of cs1 at iit kanpur a large public university we obtained a dataset of erroneous student programs which fail to compile along with their corresponding repaired code.
during the training phase we train an error repair classifier on this dataset to predict the type of error repair class it belongs to.
as mentioned in figure 2a this classifier involves a four phased methodology as follows.
a. error localization given an erroneous code tegcer locates the line s where repair must be performed by relying on the exact line number reported by the compiler.
this is a departure from existing repair tools such as tracer and deepfix which employ a search repair test strategy to achieve localization accuracy of .
such a strategy is not applicable for example generation due to its very nature of being subjective.
tegcer achieves localization accuracy of on the same dataset by focusing on only compiler reported lines.
b. code abstraction as a second step tegcer abstracts the compiler reported lines by replacing program specific tokens such as variable names function names literals etc with their generic types.
these types are inferred using llvm a standard static analysis tool.
this abstraction module is largely motivated by the one employed in tracer .
this stage greatly reduces the load on neural network classifier described in section ii d and helps it generalize better by performing implicit vocabulary compression.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
student code repository error repair classpair repaired codeerroneous codeerror repair classi fier error localization code abstraction dense neural networkencoding predicted class compare a training phase example suggestionerror repair classi fierlive erroneous code student code repository pair b live deployment phase fig.
tegcer system workflow.
the error repair classifier is trained on previous student code repository during the training phase.
in live deployment phase the trained classifier is used to predict and fetch relevant examples for live erroneous codes.
c. encoding the abstract tokens are then encoded into a binary representation with few additional features added before passingthem to our neural network.
this technique is further elabo rated in section iv a. d. dense neural network finally we train a dense neural network classifier which takes the encoded erroneous line and learns to predict the error repair class that it belongs to.
the error repair classcaptures the type of mistake made by student and its desiredrepair.
the concept of error repair class and our neural networksetup are explained in sections iii d and iv respectively.
live deployment figure 2b shows the workflow during live deployment phase.
given a new erroneous code encountered in the live setting the previously trained classifier is used to predict the error repair class for each erroneous line.
the old student coderepository is then queried to fetch all examples that belong tothe exact same predicted class.
the repaired code pair of theseexamples is then suggested back to student as feedback in thedecreasing order of their frequency of occurrence.
iii.
s tudent code repository the student code repository consists of code attempts made by students during the fall semester courseoffering of introductory to c programming cs1 at iitkanpur a large public university.
this course has been creditedby400 first year undergraduate students who attempted different programming assignments as part of course requirement.
these assignments were completed on a customweb browser based ide which records all intermediate code1void main int i if i i compiler message 3e10expression is not assignable a erroneous program1void main int i if i i repair tokens b repaired program fig.
erroneous repaired code pair e attempts.
this dataset has previously been used by multiple state of the art repair tools in literature .
from the logs for the entire semester we found a total of23 program pairs such that i the student program failed to compile and ii the same student edited a single line in the buggy program to repair it.
we use only thesesingle line edit programs during our training phase.
during thelive deployment phase programs with errors on multiple linesare treated as multiple instances of single line errors.
thatis during the live deployment phase tegcer can handleprograms with errors on multiple lines by suggesting examplesfor each compiler reported erroneous line.
a. error types the erroneous code attempts trigger unique kinds of compilation error messages.
table i lists the top frequent error messages returned by clang compiler apopular compiler for c programming language.
the messages are generalized by replacing any program specific tokens demarked by clang within single double quotes with .
one example substitution for each is also provided in the table.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
error id message e1 expected e2 expected 1after expression e3 use of undeclared identifier sum e4 expected expression e5 expected identifier or e6 extraneous closing brace e7 expected 1in 2statement for e8 expected 1at end of decl.
e9 invalid operands to binary int int expression 1and e10 expression is not assignable table i the top frequent individual compilation errors es listed in the decreasing order of frequency.
error group eg1 eg2 eg3 eg4 eg5 error e3 e4 e1 e2 e35 error group eg6 eg7 eg8 eg9 eg10 error e3 e4 e5 e6 e9 e1 e4 e5 table ii top frequent compilation error groups eg .
fig.
frequency distribution of compilation error groups egs .
the plot depicts the program y axis in log10scale attempts by students that failed to compile due to presence of eg x axis .
figure 3a presents an erroneous code example that suffers from compilation error e10 expression is not assignable due to incorrect usage of assignment operator in place of equality operator .
b. error groups a buggy program can contain one or more compilation errors a collection of which is called compilation error group abbreviated as eg .
in the dataset of the course offering the unique individual compilation errors ei combine to form unique error groups egs .
this grouping is performed since the bug in the program and hence its fix is better characterized by the set of errors occurring together as opposed to each individual error considered independently.
for example error group eg e5 e6 typically occurs due to mismatched braces whose repair involves inserting deleting o r .
where as the error group eg 10containing single error e5typically occurs when the program contains a spurious comma operator .
for example the line int i j suffers from eg e5 error group type.
table ii lists the top frequently observed egs.eg resp eg is the top frequent resp 10thfrequent compilationclass id error repair class programs c1 e2 c2 e3 int invalid c3 e1 c4 e1 c5 e5 e6 c6 e8 c7 e1 c8 e10 c9 e1 c10 e7 ... c211 e47 int c212 e1 e5 e47 all table iii top frequent error repair classes cs from singleline edit dataset.
the class is a combination of error types es and repair tokens rs .
a total of classes contain 10or more buggy programs.
error group encountered by close to resp programs compiled by students.
as observed in fig.
the frequency plot of the set of errors egs novice programmers make in our course offering follows a heavy tailed distribution.
in other words there is a sharp decrease in the number of programs affected by an error group egs as we proceed through a list of egs sorted by their frequency count.
similar observation has been made by others on their student error datasets .
in the entire course offering where students made failure code attempts the top frequent egs accounted for more than of all the student programs failing to compile.
out of the different egs only the top 240ones repeat in 10or more different programs for the entire run of the course offering.
c. repair tokens for every erroneous code in the dataset we have a corresponding repaired code pair.
this repair is performed by the same student by inserting and deleting program tokens until all compilation errors are resolved.
we treat replacements as a combination of insertion and deletion.
after performing error localization and code abstraction on erroneous repaired code pairs the difference between these two abstract lines form the set of repair tokens rs .
the top repair tokens inserted deleted by students are invalid and int .
the invalid abstract token represents an undeclared variable function and int refers to integer datatype variables.
the repaired code example in figure 3b deletes assignment operator and inserts an equality operator .
hence its set of repair tokens are .
d. error repair class given a buggy source program that suffers from compilation errors es which require a set of repair tokens rs to fix its error repair class c is defined as the merged set of errors and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
eg cs c error repair class c programs eg124c2 e3 int invalid c11 e3 array invalid c16 e3 literal int invalid eg238c15 e4 int c17 e4 literal int c18 e4 eg328c3 e1 c4 e1 c7 e1 eg4 5c1 e2 c58 e2 if c79 e2 eg7 2c5 e5 e6 c78 e5 e6 eg10 3c22 e5 c205 e5 c206 e5 int table iv top repair classes cs for few of the frequent error group egs .
the second column cs denotes the total number of different repairs possible for a given eg with the third and fourth column listing the top frequent class id cid and repair class c respectively.
finally the number of buggy programs programs belonging to each cis provided in the last column.
repairs esrs .
for example the erroneous repaired code pair in figure belongs to c8 e10 the 8thmost frequently occurring error repair class.
we determine the error repair class of the 275erroneousrepaired code pairs in our dataset.
table iii lists the errorrepair classes cs sorted in decreasing order of frequency along with the number of buggy programs belonging to each class.
a total of 212classes were found containing 10or more buggy programs and total of 579programs belong to one of these 212classes.
only these 579buggy programs and their classes then form the training dataset for our deep classifier.
while the remaining classes are unused due to lack of sufficient training examples.
as seen from table iii c1 e2 is the top most frequent error repair class containing 888buggy programs which encounter compilation error e2 expected 1after expression and require one or more insertion of semi colon to fix it.
while c212 e1 e5 e47 is one of the least frequent class containing 10buggy programs which encounter compilation errors e1 e5 e47and require one or more deletion of semi colon to fix it.
additional examples of error repair classes are presented later in section v. table iv presents a different arrangement of error repair classes grouped based on the error group eg .
as seen from this table a wide variety of repairs were undertaken by our students for the same set of compiler reported error messages es .
consider the last row of table iv for error group eg which consists of single compiler error e5 expected identifier or .
students in our course offerring typically resolved this error in unique ways either by deleting commaserroneous repaired line b xyz b a abstraction int invalid int int repair int invalid table v example erroneous repaired line pair requiring replacement of invalid token with int token.
the compiler reports error e3 use of undeclared identifier .
deleting semi colons or by deleting the keyword int.
the choice of repair is dictated by program context which our error repair class attempts to capture.
maintaining a trivial list of programs per compilation error which can then be retrieved and suggested as examples would not capture the relevant repair.
iv .
e rror repair classifier in this section we present our deep neural network setup which given an erroneous abstract line predicts the relevant error repair class that it belongs to.
a. data encoding the labelled dataset of 579erroneous programs is split in the ratio of for training validation and testing purpose respectively.
before the abstracted erroneous line is supplied to neural network for learning we pre process it to help the deep network generalize better.
input tokens for each erroneous abstract line the input to neural network consists of unigram tokens bigram tokens and compilation errors es .
for example consider the erroneous line shown in table v. the sequence of input tokens passed to deep network are err e3 uni int invalid bi int invalid invalid eos .
in our dataset of 579source lines the input vocabulary size is observed to be .
that is a total of 756unique input tokens combination of unigrams bigrams and es exist in our dataset.
input encoding each input token is then vectorized using tokenizer2 a text pre processor provided by the keras deep learning library .
in this encoding the input tokens are represented using one hot encoding a binary representation indicating presence or absence of token.
more involved encoding techniques such as frequency or tfidf gave poor results due to the extreme paucity of data for most classes more than of the 212classes have just 10erroneous examples to train and test from.
output encoding similar to the input encoding output error repair class labels need to be encoded as well before neural network learns to predict them.
the error repair class labels are represented with one hot binary encoding using the tocategorical3utility provided by keras .
tokenizer tocategorical authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
input layer tokens hidden layer units dropout layer softmax output units fig.
dense neural network of 512hidden units with dropout used to classify input tokens with errorrepair class labels.
b. dense neural network allamanis et al.
present an extensive survey of existing deep network setups used in literature to represent computer programs for various tasks.
for our error repair classification task we experimented with some of the popular complex deep networks such as long short term memory lstm models with embeddings and convoluted neural network cnn models with max pooling .
these complex models need to train a large number of parameters in the order of millions of different weights capturing patterns in the entire sequence of input tokens for which massive amounts of training data is required typically in the order of thousands per class.
however in our labelled dataset of programs tagged with labels only the largest class has more than 000programs.
on the other hand 67of these classes of total have just 10examples each for both training and testing the classifier.
due to which complex neural networks fail to generalize on our dataset of student errors recording prediction accuracy in the range of .
neural network layers to overcome the difficulties mentioned above we turn towards simpler deep network model for our class predictions.
in particular we found that a dense neural network with single hidden layer is best suited for our task.
a dense network is a fully connected network where each neuron is connected to all the neurons of previous layer.
figure describes the network arrangement of our dense classifier.
the first layer is an input layer which consists of binary encoded input source tokens.
the second layer is the single hidden layer of units densely connected with the previous input layer.
this is followed by a dropout layer which randomly drops of the input neurons to0during the training stage to avoid overfitting the model on training dataset.
finally our last layer is an output layer containing 212units one for each class .
this output layer is densely connected with the previous hidden layer as well.classifier pred 1p r e d 3p r e d dense neural network .
.
.
table vi pred kaccuracy for dense neural network classifier parameters keras framework was used to build our dense neural network classifier with tensorflow backend.
the following parameters including the hidden layer size were selected based on performance of classifier on the validation set.
we used rectified linear unit relu a non linear activation function between the hidden layers.
while a softmax activation function is used in the last output layer to predict the probabilities of all 212classes given the set of input tokens.
stochastic gradient descent algorithm was used to learn the weights between layers by minimizing a categorical crossentropy loss function over the training data set.
also adam an adaptive moment estimator function was chosen to optimize the learning process leading to faster and stable convergence.
the peak accuracy of our model on the validation data set was obtained after training for a short number of 6epochs.
beyond this the model begins to heavily overfit on training dataset due to the small number of examples available for most classes.
the training phase typically lasts minutes while predicting a class during the testing phase requires few milliseconds.
c. accuracy we report on the overall accuracy of the classifier as well as precision recall scores of individual classes on our held out test dataset.
the latter analysis is necessitated due to the highly skewed distribution of classes in our dataset where the top classes out of the 212unique ones account for of the total test cases.
overall accuracy we measure the overall performance using a pred kmetric which denotes the percentage of testcases where the top kclass predictions contains the actual class.
the classifier returns a probability score for each class on being given a buggy line pr y cj x .
which can be sorted in descending order to select the top kresults as predicted classes.
table vi reports on the accuracy of dense network in predicting classes on held out test set of buggy source lines for various values of k. when we consider only the top prediction pred by the dense classifier the predicted class is exactly same as the actual class in .
of the cases.
if we are to sample the top predictions instead then the actual class is present in one of these three predictions for97.
of the cases.
in other words for majority of the test cases out of dense neural network predicts the correct class in its top .
top frequent classes table vii lists the precision and recall scores of our dense neural network for the top frequent classes cs .
the classifier enjoys high precision recall scores authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
cid error repair class c train test precision recall top incorrect prediction incorrect class test c1 e2 .
.
e2 if c2 e3 int invalid .
.
e3 literal int invalid c3 e1 .
.
e1 c4 e1 .
.
e1 c5 e5 e6 .
.
c6 e8 .
.
e8 c7 e1 .
.
e1 c8 e10 .
.
e10 c9 e1 .
.
e1 c10 e7 .
.
e7 ... c211 e47 int .
.
c212 e1 e5 e47 .
.
table vii precision and recall scores of dense neural network on top frequent classes.
the columns train and test indicates the total number of source lines used for training validation and testing of the classifier respectively.
for each actual class c top incorrect prediction column lists the top incorrectly predicted class along with the number of test cases in which this mis classification occurred.
of more than .
across most of the listed classes.
further even on the extremely rare classes of c211andc212 that offer just8buggy examples to train and validate from the neural network is able to generalize successfully and achieve precision recall score.
two of the listed classes c2andc4 suffer from relatively weaker recall scores of .79and0.
respectively.
in other words out of the resp.
test cases having label c2 resp.
c4 the classifier is able to correctly predict resp.
of them.
the last column which lists the top most incorrect prediction made by classifier are both valid classes.
from table vii the class c2 e3 int invalid is most confused with e3 literal int invalid .
this is intuitive since in c programming language a variable is often interchangeable with a literal of the same type.
similarly the class c4 e1 is incorrectly predicted as class e1 10different times since the repair for incorrectly balanced parenthesis could be to either add more closing parenthesis or remove few of the existing open ones.
while choice of the repair is dictated by logical correctness either of these two can be used to fix the compilation error.
this suggests a larger issue where an erroneous line can belong to multiple classes since it can be repaired in multiple different ways.
since our erroneous repaired dataset captures only one form of repair performed by actual student we are forced to treat the problem as multi class instead of multilabel.
this limitation accounts for the lower precision recall scores observed in some of the classes.
individual classes in figure we analyze the recall scores across all 212classes.
from figure 6a it is seen that our dense neural classifier achieves high accuracy across majority of the classes.
the recall score is .5on80 of classes and .9for more than 100classes.
figure 6b then presents the recall scores of all 212classes plotted against their training sample size.
while the classifier achieves recall score on classes across multiple training sizes including those with just 8training examples the recall a histogram of classes recall scores b effect of classes training size on recall scores fig.
dense neural network recall scores for 212classes scores drop to .
resp.
.
only when the training size is below resp.
.
in other words having more training examples for small sized classes could help improve their prediction scores.
d. unseen errors the design of our error repair class is flexible in accommodating new mistakes that students would make unobserved in our training dataset.
to further elaborate consider an unlikely buggy line printf d xyz!
where the student has made different mistakes.
namely a comma separator is missing between both expressions the inequality operator !
is incorrectly written as !
and xyz is an undeclared variable of type invalid .
the compiler reports just a single error e1 expected on this particular line.
our neural network classifier has never come across this combination of errors during its entire learning phase.
nonetheless it is able to capture the errors better than a standard compiler and predict relevant repair classes for all mistakes individually.
the top repair classes predicted by tegcer are c148 e1 !
!
c2 e3 int invalid c35 e12 int invalid and c7 e1 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
erroneous line and predicted tegcer s top example relevant repaired line class erroneous and repaired 1d x x1 x x1 c32 e15 amount p t r d x x1 x x1 amount p t r 2if a !
c148 e1 !
!
while n !
if a !
while n !
3for j j j c10 e7 for i i n i for j j j for i i n i 4printf c210 e62 sort printf d a sort rsum n 5printf d a c40 e19 printf f f x y printf d a printf f f x y 6b xyz c2 e3 int invalid scanf d a b a scanf d n 7p a p c8 e10 if a b p p a if a b table viii sample erroneous repaired lines and the top erroneous repaired code example suggested by tegcer.
the third column lists the top error repair class predicted by tegcer.
the last column indicates whether the feedback is relevant to the student s error repair.
.
hence tegcer can be used to successfully generate relevant feedback on unseen errors by sampling multiple topn classes.
notice that tegcer does not restrict itself to the cryptic compiler reported error e1 and this freedom allows it to match buggy program with relevant repair by borrowing repairs observed in different errors e3ande12.
v. e xample suggestions given an erroneous program tegcer suggests relevant example erroneous repaired pairs of another student.
either the erroneous code or the repaired code or both the code pairs can be provided to the student depending on the instructor s preference.
tegcer s implementation is made publicly available4.
table viii lists few sample erroneous lines by students and the top example feedback generated by tegcer.
in the first example listed in row 1of table viii the student fails to realize that that an asterisk operator is required between the two integer expressions.
while in rows 2and the student has misunderstood the syntax of inequality operator !
and for loop statement specifier respectively.
the suggested examples by tegcer reflects the same confusion and desired repair as the original student s erroneous code.
the compiler reports cryptic error messages e15 called object type int is not a function and e1 expected for rows 1and respectively.
hence providing tegcer s examples as feedback to novice students could be more useful over these compiler messages in understanding the error and its repair.
rows 4and 5deal with bracketing issues in printf function calls where a student has incorrectly used square brackets and added a spurious closing parenthesis tegcer s example of correct parenthesis usage inprintf and a user defined function call is highly relevant.
row 6lists an example of undeclared variable where tegcer suggests replacing it with a previously declared integer variable based on the erroneous line s local context.
row 7demonstrates the limitation of our dense neural network which relies on unigrams bigrams and compilation error messages to predict the repair class.
in this case the erroneous line is p a p and the student is confused between the lvalue left and rvalue right of assignment operator.
the input tokens passed to the neural network are err e10 uni char literal char char bi char literal char literal char char char eos .
as we can see there is very little indication from these unigram and bigram tokens that the issue is due to presence of multiple tokens in lvalue of assignment.
in fact examples belonging to a frequently occurring class c8 contain very similar unigram bigram tokens where the confusion is between usage of assignment and equality operator.
hence the classifier incorrectly predicts the repair class c8 e10 for row 7source line suggesting replacement of with .
this issue could be resolved by using more complex neural networks which capture the entire sequence information.
however these would typically require larger training sample size for each individual class.
vi.
u serstudy in order to measure the pedagogical benefit of providing example based feedback we deployed tegcer during the ii fall semester offering of introduction to c programming cs1 course at iit kanpur.
this course was credited by more than first year undergraduate students.a authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
semester feedback students human success failure time taken sec attempt type tutors compile compile a vg std dev a vg std dev i manual .
.
ii example .
.
table ix success and failure of compilation requests made by students during the week labs across various offerings major component of the course was weekly programming assignments termed labs which were attempted under the guidance of post graduate teaching assistants tas over a period of 14weeks.
our analysis focuses on the first weeks of the course while tegcer was deployed to guide these students instead of the tas.
every week the students were given hours to complete assignments of varying difficulty.
the theme of assignments covered during these weeks was input output conditionals iterations nestediterations functions arrays and matrices.
all intermediate code attempts were recorded on prutor a custom ide developed for teaching cs1.
during this hour hours x weeks period tegcer was deployed to provide live feedback to students in addition to the error messages reported by compiler.
fig demonstrates the user interface of tegcer integrated with the prutor ide and fig 2a provides the backend system overview.
whenever a student in this course offering encountered a compilation error we first ran our neural network classifier to predict the error repair class that it belongs to.
then we searched our student code repository of ii semester for code attempts that belong to the same error repair class.
finally the repaired line of these previous code attempts is extracted and presented to student as feedback sequentially in decreasing order of the lines frequency in our corpus.
initially only the top frequent repaired example is shown.
the student could request for additional examples using a more?
button upto a maximum of 10per line and master the programming syntax from multiple correct examples.
for instance in fig the student has requested two additional examples for line by utilizing the more?
option.
human tutors were asked to not help students resolve compilation errors unless they were unable to resolve them with automated feedback for more than minutes.
a. baseline comparison the previous semester i course offering of the same cs1 course at the same university iit kanpur attended by a different set of students was used as a comparative baseline.
notably the division of the first year student into groups that would attend cs1 in the fall and spring semester respectively was made administratively and randomly using no student input.
thus the two student populations could be treated as substantially identical.
also both these course offerings followed the same syllabus and weekly lab settings.
however different sets of lab assignments were framed for both offerings.
these students used the same browser based ide to complete their programming tasks but without access to any feedback tool.
they relied on the compiler errormessages and manual help by human tutors to resolve their compilation errors.
b. overall results we compared student performance on two different metrics namely attempts and time taken .time taken is defined as the time elapsed from the first occurrence of a compilation error to the next successful compilation attempt made by student.
attempts is defined as the number of unsuccessful compilation requests made by the student before finally resolving the error.
for both the tegcer and the baseline group we filtered out instances where students took more than minutes time to resolve their compilation error to discount intrusions such as being away from the desk or something else.
table ix shows the results of 453students from the first weeks of the baseline semester and 238students from the first weeks of the semester with access to tegcer.
students in our control group took 103seconds on an average to resolve any compilation error with manual help provided by tas when they get stuck.
significantly lower 78seconds on average were required by our experimental group even accounting for delayed manual help by tas on getting stuck on a compilation error.
a welch s t test for testing statistical significance of variance in average time taken log transformed returned t .
p .
.
the test is robust for unequal sample sizes as it is in our case.
similarly the average attempts of1.99required by experimental group is significantly lower compared to the .20required by the baseline group welch s t test t .
p .
.
c. tegcer helps more when problems are harder due to the heavily imbalanced distribution in compilation error types the most frequent ones tend to dominate the overall average result.
hence we also compare time taken across individual error groups eg .
a total of unique egs were encountered common to both semesters.
in .
of these error groups the experimental group with access to tegcer resolved their errors faster compared to .
cases where the baseline group has a lower average time.
figure plots the potential hardness of each eg measured in terms of average time taken by baseline students time b t o resolve programs belonging to a particular error type eg against the potential performance improvement offered by tegcer measured as the normalized difference between the time taken by both cohorts time b time e time b for the same error type.
note that each point in the figure represents oneeg encountered in both semesters.
from this figure it is evident that while errors that are easier to resolve may or may not benefit from tegcer it is predominantly more authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
potential hardness x axis of resolving an error group plotted against potential performance improvement y axis offered by our example generation tool.
1void main int i compiler message 5e6extraneous closing brace example feedback delete this line a eg e6 1void main 2int i j 3for j j j i compiler message 3e7expected in for statement example feedback 3for i i n i 3for i i n i b eg e7 fig.
sample programs and top example suggestions for a eg 25where students with access to tegcer perform poorly b eg 19where examples seems to work better.
helpful than human tas for more difficult errors.
this is a crucial observation as it brings out the value of deploying a comprehensive tool like tegcer as opposed to using simpler solutions such as explaining compiler error messages better.
d. interesting error groups from our earlier analysis it is apparent that automated example based feedback generated by tegcer does help students resolve compilation errors faster on average.
in this section we highlight two particular cases wherein tegcer s feedback helped the most or least compared to our baseline.
students with access to tegcer feedback seem to perform worse than baseline group of students when tegcer produces an irrelevant feedback.
consider the error group eg consisting of e6 which is typically encountered when students inadvertently add extra closing brace .
fig 8a shows a simple code which triggers this errors along with the compiler message and tegcer s feedback.
since tegcer relies oncompiler for error localization it focuses its feedback on line .
hence tegcer incorrectly suggests deleting the brace on line to successfully resolve the compilation error instead of suggesting the more relevant fix of deleting spurious on line .
this seems to adversely affect students with access to tegcer who take seconds on average to resolve e6 errors compared to our baseline group of students who require seconds on average.
in contrast for eg tegcer assistance shows much faster error resolution seconds on average than the baseline students seconds on average .
a simple example code belonging to this error group is shown in fig 8b where the student is confused with for loop syntax.
while the compiler message correctly suggests the replacement of comma with a semi colon after loop initialization tegcer suggests the same through examples.
its top examples demonstrate the to n and to n loop iteration.
on requesting further examples tegcer s examples suggests different ways of writing for loops with empty initialization empty condition or empty increment mode which is perhaps helping students master the for loop syntax better.
vii.
r elated work compiler error messages are the quickest form of feedback provided to a novice programmer.
a novice programmer can be expected to learn better if error messages are augmented with the information to fix them.
improving the compiler error messages and repairing them has been active areas of research over last several decades.
we highlight some recent related work targeting introductory programmers in this section.
a. compilation error repair skp uses sequence to sequence seq2seq network to generate a statement repair based on other statements observed around it local context .
deepfix trains a recurrent neural network rnn on artificially generated correct programs to jointly perform error localization and correction on entire buggy program.
tracer improves upon deepfix by abstracting variables with their types and training a seq2seq on erroneous repaired pairs of abstract program lines.
rlassist treats the entire buggy program as a 2d game and trains a reinforcement learning algorithm which utilizes movement and edit based actions to improve upon deepfix.
these compilation error repair tools typically use some form of generative deep networks.
they achieve low repair accuracy in the range of since the tools have to predict not only the set of repair tokens to add remove but also their exact arrangement for the program to compile.
in contrast tegcer achieves high pred 1accuracy of by utilizing a dense classifier of error repair tokens instead of generative model.
b. compilation error message enhancement denny et al.
and parihar et al.
enhance the compiler generated error messages to make it easy to comprehend for novices.
whenever a submission triggers compilation error authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
these system show the enhanced error message corresponding to the error possibly accompanied by an explanation and an example of correct code.
however in these work the enhancements and the example are created statically unlike tegcer where the examples are mined from old submissions.
becker et al.
have recently showed that enhanced error messages are effective in error repair by novice programmers.
in contrast other studies have found that additional information does not help students significantly and that placement and structuring of the message is more crucial .
this confusion in the literature suggests that further research is clearly needed to establish the optimal methods for presenting error messages to students.
our large sample study s observations should be helpful in this regard.
barik et al.
have developed a large number of guidelines about how the error messages should be presented to developers .
most of these guidelines could be applicable to novice programmers as well for example the recommendation that the error message which appears in the editor must be close to the source of error.
c. compilation error feedback generation the closest related work to ours is helpmeout which relies on manual contribution by students to record code examples and explanations.
helpmeout ranks the relevant examples based on the error similarity and user provided ratings while tegcer ranks the examples based on the similarity of error and predicted repair desired by student.
other related work that use machine learning include the work by wu et al.
and santos et al.
.
the technique by wu et al.
is similar to ours wherein they apply machine learning techniques on a large corpus of erroneous student programs albeit focusing on type related errors.
this learnt model is used to generate high quality error message and repair suggestions at the expression level.
santos et al.
differ from tegcer as they use correct programs by experienced programmers from github5instead of prior student submissions.
thiselton et al.
propose pycee an ide plugin that queries stack overflow6automatically whenever a programmer encounters a python error message.
the stack overflow answers are summarized and presented as enhanced error message within the ide.
they report on the usefulness of compiler error message enchancements encountered during a user study of programmers using pycee.
viii.
t hreats to validity in this section we describe some threats to the validity of our study.
external validity threats relate to the generalizability of the results.
in this study we had over students from two semesters for a period of weeks.
we have conducted the study on a sample size that represents an educational setting with novice programmers.
internal validity threat relates to the environment under which experiments were carried out.
baseline participants where students had access to teaching assistants only were selected from a different semester i compared to our control group participants with access to tegcer ii .
while it is desirable to randomize students from the same semester our choice of study design was ethically constrained by the prospect of one group receiving unfair advantage over the other in the live graded course offering.
during the measurement interval issues such as mortality students withdrawing from the lab during data collection and maturation students changing their characteristics by parameters outside of the study did not arise.
construct validity relates to measurement of variables used during the study.
we have used standard dependent variables such as time taken to resolve compiler error s attempts .
our metric of time taken to resolve errors does not take into account time spent away from the task or spent resolving logical errors.
to partially account for time away from task problems we discounted instances of errors persisting for longer than minutes.
since we are unable to remove all possible sources of variation from our variable it is appropriate to consider the possibility that our quantitative predictions may have less than ideal veridicality while remaining directionally correct.
ix.
c onclusion we presented tegcer an automated example generation tool.
it is based on the realization that while students make multiple types of compilation errors on various programming assignments the kind of repairs performed by them is limited to addition deletion of few abstract program tokens.
to this end we first collated and labeled a large dataset of aligned erroneous repaired student program pairs with unique error repair classes c .
these classes capture the combination of errors es made by students and the repairs rs attempted by them.
we aim to release this labelled dataset into the public domain to aid further research.
this novel labelling data pre processing steps of error localization and abstraction enabled a simple dense neural network with a single hidden layer achieve pred 3of97.
on a challenging task of predicting a correct label from different ones.
we conducted a large scale empirical evaluation comparing error repair times for a cohort of about students programming with the aid of tegcer in a controlled lab environment with those for a similar cohort of about students programming in the same environment with human assistance.
we found that example based feedback from tegcer helped resolve errors faster on average.
further tegcer was consistently more useful for fixing harder errors.
the large scale and controlled nature of our empirical evaluation allows us to assert with high confidence that assistance by tegcer is comparable to if not better than the assistance provided by human teaching assistants in lab settings.