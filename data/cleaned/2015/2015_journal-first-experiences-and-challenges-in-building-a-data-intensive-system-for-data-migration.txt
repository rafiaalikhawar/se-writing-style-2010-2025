experiences and challenges in building a data intensive system for data migration marco scavuzzo elisabetta di nitto danilo ardagna politecnico di milano dipartimento di elettronica informazione e bioingegneria milano italy name.lastname polimi.it recentanalyses reportthatmanysectorsofoureconomy and society are more and more guided by data driven decision processes e.g.
healthcare publicadministrations etc.
.assuch data intensive di applications arebecomingmoreandmoreimportant and critical.
they must be fault tolerant they should scale with the amount of data and be able to elastically leverage additional resources as and when these last ones are provided .
moreover they should be able to avoid data drops introduced in case of sudden overloads and should offer some quality of service qos guarantees.
ensuringallthesepropertiesis perse achallenge butitbecomes evenmoredifficultfordiapplications giventhelargeamountof datatobemanagedandthesignificantlevelofparallelismrequired foritscomponents.eveniftodaysometechnologicalframeworks areavailableforthedevelopmentofsuchapplications forinstance think of spark storm flink we still lack solid software engineering approachesto support theirdevelopment and inparticular to ensurethattheyoffertherequiredpropertiesintermsofavailability throughput dataloss etc.infact atthetimeofwriting identifying therightsolutioncanrequireseveralroundsofexperimentsand the adoption of many different technologies.
this implies the need forhighlyskilledpersonsandtheexecutionofexperimentswith large data sets and a large number of resources and consequently a significant amount of time and budget.
to experiment with currently available approaches we performed an action research experiment focusing on developingtesting reengineeringaspecificdiapplication hegira4cloud h4c thatmigratesdata betweenwidelyusednosqldatabases including so called database as a service daas as well as on premise databases.
this is a representative di system because it has to handlelargevolumesofdatawithdifferentstructuresandhasto guarantee that some important characteristics in terms of datatypes and transactional properties are preserved.
also it poses stringentrequirementsintermsofcorrectness highperformance fault tolerance and fast and effective recovery.
journalfirstpresentationofthepaper scavuzzo m. dinitto e. ardagna d.empir software eng .
permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage.copyrightsforthird partycomponentsofthisworkmustbehonored.
for all other uses contact the owner author s .
icse may june gothenburg sweden copyright held by the owner author s .
acm isbn .
our action research we discovered that the literature offered some high level design guidelines for di applications and some toolstosupportmodellingandqosanalysis simulationofcomplex architectures.
ho wever the available tools were not yet suitable to support di systems.
moreover we realized that the available big dataframeworkswecouldhaveusedwerenotflexibleenoughto cope with all possible application specific aspects of our system.
hence toachievethedesiredlevelofperformance faulttolerance and recovery we had to adopt a time consuming experimentbased approach which in our case consisted of three iterations the design and implementation of a mediation data modelcapableofmanagingdataextractedfromdifferentdatabases together with a first monholitical prototype of h4c the improvementofperformanceofourprototypewhenmanagingand transferring huge amounts of data the introduction of faulttolerantdataextraction andmanagementmechanisms whichare independent from the targeted databases.
among the others an important issue that has forced us to reiterateinthedevelopmentofh4cconcernedthedaasweinterfaced with.inparticularthesedaas whicharewell knownserviceswith alargenumberofusers weremissingdetailedinformationregarding the behaviour of their apis did not offer a predictable service were suffering of random downtimes not correlated with the datasets we were experimenting with.
in this journal first presentation we describe our experience and the issues we encountered that led to some important decisions during the software design and engineering process.
also weanalysethestateoftheartofsoftwaredesignandverification tools and approaches in the light of our experience and identify weaknesses alternative design approaches and open challenges thatcouldgeneratenewresearchintheseareas.moredetailscan be found in the journal publication.