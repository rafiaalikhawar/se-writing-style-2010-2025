a system identification based oracle for control cps software fault localization zhijian he1 yao chen1 enyan huang1 qixin wang1 y up e i1 haidong yuan2 1department of computing the hong kong polytechnic university hong kong sar china 2dept.
of mechanical and automation engineering the chinese univ.
of hong kong hong kong sar china corresponding authors.
email csqwang csypei comp.polyu.edu.hk abstract control cps software fault localization sfl aka bug localization is of critical importance as bugs may cause major failures even injuries deaths.
to locate the bugs in control cpss sfl tools often demand many labeled correct incorrect source code execution traces as inputs.
to label the correctness of these traces we must judge the corresponding control cps physical trajectories correctness.
however unlike discrete outputs the boundaries between correct and incorrect physical trajectories are often vague.
the mechanism aka oracle to judge the physical trajectories correctness thus becomes a major challenge.
so far the ad hoc practice of human oracles is still widely used whose qualities heavily depend on the human experts expertise and availability.
this paper proposes an oracle based on the well adopted autoregressive system identification ar si .
with proven success for controlling black box physical systems ar si is adapted by us to identify the buggy controlcps as a black box.
we use this identification result as an oracle to judge the control cps s behaviors and propose a methodology to prepare traces for control cps debugging.
comprehensive evaluations on classic control cpss with injected real life and artificial bugs show that our proposed approach significantly outperforms the human oracle approach in sfl accuracy recall and latency and in oracle false positive negative rates.
our approach also helps discover a new real life bug in a consumergrade control cps.
keywords oracle cyber physical system debug testing.
i. i ntroduction control cyber physical systems cpss aka control cpss are growing rapidly due to the inevitable convergence of computer i.e.
cyber and physical systems .
typical control cpss include avionics vehicles robotics etc.
many control cpss are life mission critical hence faults can cause major failures even injuries deaths .
over the years faults caused by physical subsystems noises inaccuracies are well taken care of by modern control theories .
on the other hand modern control cpss cyber subsystems scale up rapidly.
they no longer just involve numerical computations of core control laws but also middleware libraries e.g.
for computer vision etc.
and can total millions of lines of source code.
how to help removing software faults aka bugs from these cyber subsystems is becoming a bigger challenge and is the focus of this paper.
a critical step for removing bugs aka debugging is to locate bugs in the source code aka software fault localization sfl .
as software complexity scales up manual sfl no longer suffices.
over the years many automatic sfl toolsare developed.
according to a recent survey there are over papers on sfl.
the corresponding tools can be categorized into families respectively based on program spectrum statistics machine learning data mining program slice program state model and others.
particularly with the recent rise of big data technology many modern mainstream sfl tools and over of all the tools surveyed particularly those of the program spectrum statistics and machine learning tool families need a large number of labeled as correct or incorrect source code execution traces aka code traces as input.
manually labeling so many code traces is no longer practical.
this leads to a compelling need for an automatic judgement mechanism aka oracle to do the labeling.
however how to design an oracle and the corresponding code trace preparation methodology is a well known hard problem i.e.
the so called oracle problem .
solutions to the oracle problem are highly application domain dependent .
for some application domains the oracle problem is still open .
control cps is one such domain where the oracle problem faces unique challenges.
unlike the clean cut discrete output of pure cyber systems control cps outputs are continuous physical trajectories .
at the first look multiple physical trajectories in an envelope can seem correct see fig.
.
to exactly decide which one s is are correct an ideal blackbox oracle approach would need a known a priori bug free physical trajectory i.e.
the expected physical trajectory .t o predict the expected physical trajectory however the approach needs an emulation of the control cps upon a bug free cyber subsystem and a correctly simulated physical subsystem1.
this contradicts the fact that our cyber subsystem is to be debugged.
a is are arc a bo rc d correct?
b is are the dotted or the dashed curve correct?
fig.
control cps oracle problem is hard e.g.
in quadcopter autopilot how to tell which physical trajectories are correct?
replacing the prerequisite of the bug free cyber subsys1usually the physical subsystem model is available and simple enough.
hence we assume that the physical subsystems can be correctly simulated.
ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
tem with a substitute cyber subsystem implementation e.g.
those generated by matlab simulink cannot solve the problem.
this is because a simplified substitute implementation e.g.
a matlab simulink implementation of the core control laws would not catch all the subtleties those caused by the large additional software modules such as middleware and libraries besides the core control law computation needed by debugging while a comprehensive substitute implementation costs too much human effort hence contradicts our goal of sfl automation and may itself needs debugging.
therefore the ideal black box oracle approach is unlikely to work.
meanwhile specifications inferred by program analysis can neither be used as oracles.
this is because the specifications inferred must comply with existing source code and program behaviors including the buggy source code and behaviors.
thus specifications found before debugging will regard buggy behaviors as normal hence fail as oracles.
due to the above reality human oracles are still widely used in control cps sfl .
typically a group of human experts are convened to discuss and manually design a set of assertions to judge physical trajectory correctness with best effort.
these assertions are the so called human oracles .
apparently the human oracle approach is fundamentally ad hoc it heavily depends on the human experts expertise and availability.
to improve this paper aims to find another approach to deterministically and automatically generate better oracles for a large category of control cpss sfl.
to achieve this we notice a key domain feature when noises are under control e.g.
in simulated physical subsystems many control cpss are designed to move smoothly see more rigorous definitions in section iii a .
for example if an airplane bumps when there is no turbulence nor passenger cargo movement something might be wrong.
a mature tool that checks man made control systems smoothness is the autoregressive system identification ar si .
its validity is well evidenced by the great success of model predictive control mpc which is a widely adopted online control technology .
mainstream mpcs often use ar si to identify the math models of concerned control systems as black boxes assuming smoothness and use the identified models to predict future and make control decisions.
if a control system s physical trajectory is smooth the ar si prediction shall succeed otherwise the prediction shall fail.
in other words we can use ar si to check if a control cps s physical trajectory is smooth which in turn indicates if the trajectory is buggy.
inspired by the above we propose the following solution heuristics.
to prepare the many code traces for sfl we emulate the control cps with the real cyber subsystem and the simulated physical subsystem using the accurate physical subsystem model and put noises under control .
during the emulation we use ar si to identify the control cps as a black box and predict the physical trajectory in the near emulation future.
we speculate that when all the easy to findbugs are removed i.e.
when automatic sfl tools are needed physical trajectories shall usually be smooth.
a segment of a physical trajectory that is not smooth can be detected by ar si and shall indicate a possibly buggy behavior.
that is we can use the ar si prediction as an oracle to label the smoothness hence correctness of physical trajectories and then label the corresponding code traces.
guided by the above heuristics this paper makes the following contributions.
we propose an ar si based oracle for control cps sfl.
we propose a corresponding code trace preparation methodology which runs deterministically and automatically.
we compare the performance of our proposed approach with the mainstream practice of human oracle approach.
comprehensive evaluations on classic control cpss with injected real life and artificial bugs show that our proposed approach significantly outperforms the human oracle approach in sfl accuracy recall and latency and in oracle false positive negative rates.
our proposed approach also helps to discover a new real life bug in a consumer grade control cps while the human oracle approach does not .
the rest of the paper is organized as follows.
section ii gives the background and assumptions.
section iii proposes our oracle and corresponding code trace preparation methodology.
section iv evaluates our proposal.
section v discusses related work.
section vi concludes the paper.
ii.
s ystem architecture and assumptions fig.
illustrates a typical control cps architecture.
in this architecture the control cps consists of a cyber subsystem and a physical subsystem see the gray area in fig.
.
user input at time t to the control cps is u t rq.
depending on the cyber subsystem design u t can be an actuation signal an intended target output etc.u t is sampled before it enters the cyber subsystem.
the hth h sample happens at th ht wheretis the user input sampling period .
correspondingly we denote uhdef u th .
the cyber subsystem zero order holds the sample uhfor the duration ht h t .
that is during ht h t the cyber subsystem takes constant uhas the user input.
u t is the user input to the control cps.
x t andy t are respectively the state and the output of the physical plant.
in case of emulation the physical subsystem is replaced by its simulator and the human user is often replaced by a mimicking program aka monkey .
fig.
a typical control cps architecture inside of the physical subsystem lies the physical object aka plant being controlled.
the state and the output of the plant at timet are respectively denoted as x t rnand authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
y t rm.
as a closed loop system y t is also sampled by the cyber subsystem periodically.
the ith i sample happens at ti i where is the plant sampling period and t n wheren z 1is a preconfigured constant.
correspondingly we denote yidef y ti .
the cyber subsystem also zero order holds the sample yifor the duration i i .
in this paper we only focus on control cpss complying with the following assumptions assumption y t is continuous and differentiable with a frequency component upper bound fmax hz .
control cpss complying assumption are common e.g.
when the last stage of the physical subsystem is a low pass filter with maximal passing frequency of fmax.
indeed this is why airplane trajectories temperature trajectories etc.
are usually continuous and differentiable and cannot be a step function over time which contains hz frequency component .
corresponding to assumption control cps design has the following empirical rule on how to set assumption lessorequalslant1 20fmax .
intuitively this means the cyber subsystem must sample fast enough so that the physical subsystem can regard it as if a continuous signal processor.
this is an empirical prerequisite for reusing continuous domain control theories .
the above said to generate the many labeled code traces for sfl the user shall run the control cps many times.
usually the human user is replaced by an automatic humanuser mimicking program aka monkey and the physical subsystem is replaced by its simulator see footnote .
the cyber subsystem is still the buggy real implementation.
thus the monkey the buggy real cyber subsystem and the trustworthy physical subsystem simulator form an emulation platform see fig.
.
we can run the emulated control cps millions of times without fatiguing any human user or real physical hardware and we can run the emulations on parallel computers in a much faster pace than in real time.
each run of the emulated or real control cps generates a code trace and a corresponding physical trajectory.
to label the correctness of the code trace we need to judge the correctness of the physical trajectory.
this leads to the control cps oracle problem discussed in section i. iii.
s olution a. mathematical background and heuristics section i proposes using ar si as an oracle for control cps sfl.
the following gives the math details of ar si.
ar si regards a control system as a black box and identifies the relationship between the control system s sampled input and output online.
the identification result is called the identified model .
specifically if we regard the the gray area of fig.
as a black box whose input is uh rq and output is yi rm then ar si typically models therelationship between uhandyi i p p a s yi p summationdisplay j 1ajyi j bu h i whereh i t i n p ... n is a preset constant to be discussed later a1 a2 ap rm mand b rm qare the model parameters to be identified and i rmis the si error .
as mentioned in section ii during runtime in each user input sampling period the user input sample uhholds constant throughout ht h t .
in such a user input sampling period once i p lessorequalslanti n consecutive plant states without loss of generality denote them as y0 ... yi p ... yi yi become available ar si optimizes the values ofa1 a2 ... apandbin exp.
so that the runtime accumulated si error energy is minimized see the seminal textbooks of for details .
suppose the optimal a1 a2 ... ap andbvalues are a i a i ... a i p andb i then ar si predicts yi 1with yi yi 1def p summationdisplay j 1a i jyi j b i uh.
whenyi 1becomes available we know the ar si prediction error ei 1def yi yi .
heuristics when the actual maximal frequency component of the continuous control cps output y t isfactual max hz it is well known in control theory that the y t in a small enough moving time window specifically p lessorequalslant 20factual max sec can be regarded as linearizable .
that is the ar si prediction error magnitude when p lessorequalslant 20factual max should be small a magnitude outlier indicates something unusual i.e.
likely buggy is happening.
in this sense we can use the ar si prediction error as an oracle.
now let us discuss the setting of p. we have the following heuristics.
when noise is under control usually a control cps is designed so that the normal behavior of y t should not reach its frequency component upper bound fmax.
indeed the actual maximal frequency component factual max of a normal y t is usually order s of magnitude below fmax.
that is heuristics normally a control cps output should have factual max lessorequalslantfmax or equivalently10 fmax lessorequalslant1 factual max.
for example though an engine can shake at 100hz maximal a normal design shall not let it shake at such extreme under controlled noises .
the design shall limit the shaking below 10hz.
with heuristics and assumption w eh a v ei f p thenp lessorequalslant10 20fmax lessorequalslant1 20factual max .
thus the prerequisite for heuristics holds.
hence by setting pto10 w e can use heuristics as the oracle2for control cps sfl.
this ar si based oracle has three advantages.
2a breach of heuristics or other faults may cause big ar si prediction error.
if the error is big enough to be identified as an outlier heuristics flags the output y t .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
first the method procedure is deterministic and is readily implementable as an automatic program.
second both the method procedure and the identified model are simple and are independent of the internal complexity of the control cps.
hence it is easy to implement and use.
third though the method is simple it can effectively catch subtleties of control cps physical trajectories due to assumption heuristic and the setting of pto10.
b. proposed solution based on the heuristics of section iii a we propose the oracle and code trace preparation methodology referred to as our proposed approach in the following as fig.
.
step1 sample a valid initial state x0of the plant.
step2 task1 emulate the control cps using the emulation platform of fig.
starting from x x0.
log the physical trajectory yi user input trace uh and code trace .
task2 run ar si in parallel with the controlcps emulation.
for each new physical trajectory sampleyi 1from the emulation calculate the arsi prediction error ei 1via exp.
and log it.
step3 when the emulation ends check if the ar si prediction error trace ei contains outlier s a.i f so label as incorrect otherwise label as correct .
step4 if enough code traces are collected terminate otherwise go to step1 .
anote in statistics currently there is no consensus on the strict definition of an outlier .
in this paper unless otherwise noted we regard a data point outside of mean 6std as an outlier.
see section iv g .
for more discussions.
fig.
our proposed oracle and methodology to prepare code traces this oracle and methodology are referred to as our proposed approach .
compared to our proposed approach the other approach is the so called human oracle approach depicted by fig.
.
step1 same as fig.
step1 .
step2 same as fig.
step2 task1 .
step3 use human oracle to judge the correctness of physical trajectory yi and label the corresponding code trace .
step4 same as fig.
step4 .
fig.
human oracle and methodology to prepare code traces this oracle and methodology are referred to as the human oracle approach .
iv .
e v aluation next we shall evaluate our proposed approach see fig.
.a.
evaluation metrics and research questions our proposed approach see fig.
mainly serve three mainstream families of sfl tools program spectrum statistics and machine learning.
an sfl tool of these families takes in a large number of labeled code traces and outputs a suspect list.
this list lists suspected buggy source code entities such as statements methods and classes in descending order of suspiciousness.
we have three metrics to measure the quality of the suspect list.
suppose the suspect list is s s1 s2 sl wheresi i l i st h eith suspected s1is the most suspected source code entity.
suppose bis the set of truly buggy source code entities.
then accuracy refers to si si b l i.e.
coverage of true bugs by s recall refers to si si b b i.e.
coverage of true bugs in b latency refers to min i si b i.e.
starting from s1 the index of the first suspect in s that is truly buggy.
in case none of the items in sbelong tob we define latency as the length of suspect list s i.e.
l as the programmer needs to investigate all litems in the suspect list before s he stops.
note when land b are given recall is just a linear scale up of accuracy.
in this context accuracy implies recall.
therefore to save space we omit the corresponding recall evaluations in the following.
as the suspect list is the sfl result the above suspect list quality metrics are hence also the sfl quality metrics.
our evaluation intends to answer the following research question.
q1 how does our proposed approach impact sfl quality measured by accuracy recall and latency ?
in addition to sfl we are also interested in the raw quality of the oracle itself.
specifically suppose we have collected a set of code traces letpdef is labeled by the oracle as buggy i.e.
incorrect ptdef truly includes buggy entity of the source code ndef p and ntdef p t we can then define the false positive rate rfp and the false negative rate rfnof the oracle as rfpdef p n t n t andrfndef n p t p t .
we intend to answer the following research question.
q2 how does our proposed approach impact raw oracle quality measured by rfp rfn ?
in the following we shall carry out evaluations on two control cps test beds with various bugs from real life and or artificial injection to answer the above research questions.
b. control cps test beds the first test bed is ardupilot .
ardupilot is a stateof the art open platform to build consumer grade unmanned aerial vehicles ua vs .
the cyber subsystem of ardupilot is mostly written in c .
it consists of over .
million lines of source code from more than files with a total size of over 380mb.
to debug the entirety of ardupilot is too much work for one paper.
in this paper we focus on debugging the application layer of ardupilot which already authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
consists of lines of source code from files with a total size of over .06mb.
ardupilot also features a physical subsystem simulator the software in the loop sitl simulator.
as the ua v physical subsystem model is simple and well established the sitl simulator is relatively simple only consists of about thousand lines of source code .
also the sitl simulator is already widely used by the community even for the development of consumer products .
based on these we reasonably regard the sitl simulator as bug free.
by connecting a possibly buggy ardupilot cyber subsystem with the sitl physical subsystem simulator we build the control cps emulation platform required by our proposed approach and the human oracle approach see fig.
fig.
step2 and fig.
step2 .
the monkey see fig.
we adopt is a program that steers the ardupilot ua v from randomly sampled initial states.
the initial x y z location and pitch roll yaw of the ua v are sampled3from range respectively.
each emulation spans an emulated time duration of seconds.
in the emulated time the plant sampling period ms and the user input sampling period t 2s.
the second control cps test bed is one that combines inverted pendulum and computer vision ip cv .
the physical subsystem is an inverted pendulum ip which is a classic robotic test bed for control theories .
an ip consists of a cart moving along the x axis and a metal rod i.e.
the pendulum with one end hinged on the cart.
the other end of the metal rod is free to rotate.
the cyber subsystem has two parts an on ip module and an off ip module.
the on ip module runs inner loop control i.e.
the core control law that moves the ip cart back and forth along the x axis to keep the metal rod standing up right still.
the off ip module runs outer loop control i.e.
the complex computer logic involving video monitoring and computer vision cv to decide the target locations i.e.
reference points on the x axis for the ip to stabilize around.
to build the emulation platform of fig.
for the ip cv test bed we need a physical subsystem simulator which is realized by the virtual reality software of unity .
due to interfacing constraints the cyber subsystem s on ip module and the off ip module s video camera sub module also run upon the unity server.
the total source codes running on the unity server consist of lines.
due to the small scale these source codes can be manually thoroughly debugged.
we therefore regard them as bug free.
the remaining of the cyber subsystem mainly the cv part of the off ip module runs outside of the unity server and has lines of source code from files with a total size of .9kb.
3note fig.
step1 leaves the sampling strategy open.
indepth discussion on the optimal strategy is way beyond this paper s coverage.
instead we adopt a mixed clustered uniform sampling strategy.
specifically we start with uniform sampling.
once we have an initial sample set we quadruple the number of samples by adding disturbances to the initial sample set.
so the final set of samples are clustered samples per cluster and the clusters are uniformly distributed.by connecting a possibly buggy ip cv cyber subsystem with the physical subsystem simulator we can build the control cps emulation platform required by our proposed approach and the human oracle approach see fig.
fig.
3step2 and fig.
step2 .
the monkey see fig.
we adopt is a program that steers the ip from randomly sampled initial states.
the initial x axis location of the ip cart is sampled see footnote for the sampling strategy details from range m .
each emulation trial spans an emulated time duration of seconds.
in the emulated time the plant sampling period ms and the user input sampling periodt 8s.
c. evaluations with injected real life bugs ardupilot archives its release history in github .
from it we can find real life bugs appeared in earlier released versions.
of these bugs belong to the application layer source code that we focus on.
we inject these bugs back into our ardupilot test bed as described by table i. table i real life bugs to be injected into ardupilot file function line bug description mode steering.cpp update wrong stop throttle calculation mode steering.cpp update 6wrong navigation throttle calculation when reversing mode auto.cpp update 56wrong acceleration calculation when reversing mode auto.cpp enter wrong initialization in auto mode mode rtl.cpp enter wrong initialization in rtl mode mode guided.cpp update wrong mavlink signal message mode guided.cpp enter wrong initialization in guided mode mode.cpp calc throttle wrong braking throttle value calculation guided by table i we create versions of buggy ardupilot cyber subsystems each called a subject .
eight of the subjects are respectively injected with one of the candidate real life bugs in table i. the other subjects are respectively injected with candidate real life bugs selected from table i. for each buggy ardupilot cyber subsystem subject our emulation platform runs trials.
in each trial the emulation platform generates code traces and the corresponding physical trajectories by repeating fig.
step1 tostep2 task1 times4.
these code traces are then labeled by our ar si oracle as per fig.
step2 task2 and step3 .
the labeled code traces are then sent to three different sfl tools to find bugs tarantula ta crosstab cr and bp neural network nn .
these three tools are respectively the widely recognized representatives from the program spectrum statistics and machine learning sfl tool families .
as mentioned before such tools respectively output a suspect list of litems i.e.
lpossibly buggy source code entities in descending order of suspiciousness.
we assume a human programmer s effort is limited and can only investigate the top suspect list items.
hence we set l .
in comparison we also carry out the human oracle approach see fig.
.
in the human oracle approach evaluation each 4in fact as per our sampling strategy see footnote initial states are sampled but only the first samples are used.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
buggy ardupilot subject is again given trials.
in each trial the emulation platform generates code traces and the corresponding physical trajectories .
these code traces are then labeled by the human oracle and then sent to ta cr and nn for sfl.
specifically the human oracle for ardupilot runs as follows.
a code trace is labeled correct iff its corresponding physical trajectory obeys all the rules h1.
h1.
listed below and labeled incorrect otherwise.
h1.
the ua v velocity shall never exceed 20m s. h1.
the ua v velocity component along longitude latitude and altitude shall never exceed .5m s .16m s 30m s respectively.
h1.
the ua v angular velocity along pitch and roll shall never exceed .5rad s and .6rad s respectively.
h1.
h1.
are given by a panel of five domain experts via thorough discussions6.
three of the domain experts have phd degrees and to years of experiences on control systems and cps research and development r d .
two experts hold professorship in control theory including one from a leading mechanical engineering department in the world.
three experts have over years of ardupilot r d experiences.
the evaluation results are plotted in fig.
and will be discussed in section iv e. ideally we would also like to carry out injected real life bug evaluation on the ip cv control cps test bed.
unfortunately this test bed is a legacy of our lab.
its debugging history is not well documented.
meanwhile its smaller size compared to ardupilot and long usage history make it unlikely to contain more bugs.
therefore we do not include the ip cv test bed in the injected real life bug evaluation.
d. evaluations with injected artificial bugs besides the real life bugs mentioned in section iv c there are other commonly seen bugs.
natella et al.
conducted a comprehensive survey and publish a list of commonly seen bugs in the field as shown in table ii .
in our evaluation we also inject such bugs referred to as artificial bugs i n the following into our test beds and evaluate our proposed approach in the corresponding sfl.
we run evaluations on both test beds.
for the ardupilot test bed guided by table ii we inject various artificial bugs into the cyber subsystem source code.
these candidate artificial bugs and injection locations are listed in table iii.
we create versions i.e.
subjects of buggy ardupilot cyber subsystems.
of the subjects respectively contain one of the candidate artificial bugs in 5note for both our proposed approach and the human oracle approach the emulation methods are the same see fig.
step1 tostep2 task1 fig.
4step1 tostep2 .
therefore the unlabeled code traces and the corresponding physical trajectories generated for our proposed approach evaluation are reused.
such reuse also applies to all other comparison evaluations between our proposed approach and the human oracle approach in the paper.
6note lyapunov stability region is not listed as an oracle because the ardupilot ua v controller uses model less pid control whose lyapunov stability region is impractical to derive.accuracy the higher the better a bug subjects trials b bug subjects trials c all subjects trials latency the shorter the better d bug subjects trials e bug subjects trials f all subjects trials oracle false positive rate rfp and false negative rate rfn g bug subjects trials h bug subjects trials i all subjects trials x axis for a f oracle approach sfl tool.
x axis for g i oracle approach.
pa our proposed approach ha human oracle approach.
ta tarantula cr crosstab nn bp neural network.
fp oracle false positive rate fn oracle false negative rate.
y axis for a f statistics of per trial sfl quality metrics.
y axis for g i statistics of per trial oracle false positive negative rates.
in each boxplot the thick bar in each box is the median of the data the box bottom top are the 1st and 3rd quartile of the data see for some subtle details on their definitions .
in a f the s outside the boxes are data outside of the 1st and 3rd quartiles as they have relatively discrete values we plot them individually instead of using whiskers so as to provide more information .
for each given oracle approach and sfl tool there are one bug subject trials and five bug subject trials hence a total of trials.
each trial corresponds to code traces.
fig.
evaluation results ardupilot with real life bugs table ii common bugs in the field quoted from type description wpfv wrong variable used in parameter of function call wv a v wrong value assigned to variable mv ae missing variable assignment using expression mfc missing function call mia missing if construct around statements mviv missing variable initialization using a value mv a v missing variable assignment using a value mifs missing if construct plus statements mieb missing if construct plus statements plus else before statements mlc missing a logic clause in branch condition mlpa missing small and localized part of the algorithm w aep wrong arithmetic expression in parameter of function call table iii.
the other subjects each contains candidate artificial bugs selected from table iii.
for each buggy ardupilot cyber subsystem subject our emulation platform runs trials.
each trial generates code traces and the corresponding physical trajectories .
these code traces are then labeled by our ar si oracle as per fig.
3step2 task2 and step3 .
the labeled code traces are then sent to the ta cr authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii artificial bugs to be injected into ardupilot type function line bug description wv a v pos torate xy mistake multiply by divide mv a v calc leash length an assignment deleted wv a v pos torate z assigned value negated mv ae pos torate z an assignment deleted mv ae pos torate xy an assignment deleted wpfv pos torate z swapped parameter x y mlpa getstopping point z wrong expression used mlpa getstopping point z wrong expression used mv a vadvance wp target along track 610an assignment deleted mv a vcalculate wp leash length 794an assignment deleted mfcsetwporigin and destination 487immediate function return mvivcalc slow down distance 1232initialization deleted mieb pos toaccel z 410missing if construct plus statements plus else before !
flags.freeze ffz mia pos torate xy missing if construct mifs calc leash length 1000missing if construct plus leash length statements w aep getstopping point z wrong arithmetic expression mlcsetalttarget from climb rate ff 211a logic clause in branch condition deleted and nn sfl tools to find bugs.
same as section iv c the sfl tools respectively output an l item suspect list.
in comparison we also carry out the human oracle approach see fig.
.
simply put in the human oracle approach evaluation each buggy ardupilot subject is also given trials.
in each trial the emulation platform generates code traces and the corresponding physical trajectories .
these code traces are then labeled by the human oracle see section iv c h1.
h1.
and then sent to ta cr and nn for sfl.
the evaluation results are plotted in fig.
and will be discussed in section iv e. for the ip cv test bed we do the same thing.
guided by table ii we inject various artificial bugs into the cyber subsystem source code.
these candidate artificial bugs and injection locations are listed in table iv.
we create versions i.e.
subjects of buggy ip cv cyber subsystems.
of the subjects respectively contain one of the candidate artificial bugs in table iv.
the other subjects each contain candidate artificial bugs selected from table iv.
table iv artificial bugs to be injected into ip cv type function line bug description wv a v cvfindchessboardcorners assigned value negated mv ae cvfindchessboardcorners an assignment deleted wv a v cvcreatematheader assigned value negated mviv cvcreatematheader initialization deleted wv a v cvinitimageheader mistake by w aep cvinitimageheader wrong arithmetic operation for each buggy ip cv cyber subsystem subject our emulation platform runs trials.
each trial generates code traces and the corresponding physical trajectories .
these code traces are then labeled by our ar si oracle as per fig.
3step2 task2 and step3 .
the labeled code traces are thenaccuracy the higher the better a bug subjects trials b bug subjects trials c all subjects trials latency the shorter the better d bug subjects trials e bug subjects trials f all subjects trials oracle false positive rate rfp and false negative rate rfn g bug subjects trials h bug subjects trials i all subjects trials see fig.
annotations for the meanings of x axis labels y axis labels and legends in boxplots.
for each given oracle approach and sfl tool there are one bug subject trials and five bug subjects trials hence a total of trials.
each trial corresponds to code traces.
fig.
evaluation results ardupilot with artificial bugs sent to the ta cr and nn sfl tools to find bugs.
same as section iv c the sfl tools respectively output an l item suspect list.
in comparison we also carry out the human oracle approach see fig.
.
simply put in the human oracle approach evaluation each buggy ip cv subject is also given trials.
in each trial the emulation platform generates code traces and the corresponding physical trajectories .
these code traces are then labeled by the human oracle and then sent to ta cr and nn for sfl.
specifically the human oracle for ip cv runs as follows.
a code trace is labeled correct iff its corresponding physical trajectory obeys all the rules h2.
h2.
listed below and labeled incorrect otherwise.
h2.
when the ip velocity is within .
m s the ip angular velocity shall never exceed .
rad s. h2.
the ip angular displacement shall never exceed .09rad.
h2.
the ip velocity shall never exceed .
m s. h2.
h2.
are given by a panel of five domain experts via thorough discussions7.
three of the five domain experts have phd degrees and to years of experiences on control systems including ip and cps r d. two experts hold professorship in control theory including one from a leading 7note lyapunov stability region is not listed as an oracle because it focuses on the core control law implementation in the inner control loop which is quite simple for the ip cv and is thoroughly debugged.
as mentioned in section i this paper focuses on the additional modules e.g.
cv libraries in the outer control loop of the cyber subsystem not the core control law implementations.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
mechanical engineering department in the world.
two experts have over years of cv r d experiences.
the evaluation results are plotted in fig.
and will be discussed in section iv e. accuracy the higher the better a bug subjects trials b bug subjects trials c all subjects trials latency the shorter the better d bug subjects trials e bug subjects trials f all subjects trials oracle false positive rate rfp and false negative rate rfn g bug subjects trials h bug subjects trials i all subjects trials see fig.
annotations for the meanings of x axis labels y axis labels and legends in boxplots.
for each given oracle approach and sfl tool there are one bug subject trials and five bug subject trials hence a total of trials.
each trial corresponds to code traces.
fig.
evaluation results ip cv with artificial bugs e. discussions on injected bug evaluation results now we discuss the above evaluation results aiming to answer the research questions q1and q2 see section iv a .
corresponding to q1 fig.
a f fig.
a f and fig.
a f all show our proposed approach outperforms the human oracle approach in accuracy recall and latency in the ta and cr sfl.
the significance and magnitude of the improvement are respectively quantified by the pvalues and effect size es values in table v. note p values estimate the probabilities that the comparison differences are only by chance hence the smaller the more significant are the comparison differences.
es values measure the magnitudes of the differences.
our es values are quantified by cohen s d an absolute value of over .
indicates the difference magnitude is at least medium.
as shown in table v for accuracy recall and latency comparisons related to the ta and cr sfl the p values are mostly except for a few light gray cells with slightly over p values below hence the improvement of our proposed approach over the human oracle approach is statistically significant.
the corresponding es absolute values are mostly above .
except for a few light gray cells with slightly less than .
values and often exceed .
implying the magnitude of the improvement is medium to large.table v quality of fig.
and statistics fig.
pa vs ha comparisons on ardupilot with real life bugs metric1 bug sbj bug sbj all sbj p value es p value es p value es accuracyta .
.
.
.
.
.
cr .
.
.
.
nn .
.
.
latencyta .
.
.
.
.
.
cr .
.
.
.
.
.
nn .
.
.
rfp .
.
.
rfn .
.
.
fig.
pa vs ha comparisons on ardupilot with artificial bugs metric1 bug sbj bug sbj all sbj p value es p value es p value es accuracyta .
.
.
.
cr .
.
.
.
nn .
.
.
latencyta .
.
.
.
cr .
.
.
.
nn .
.
.
rfp .
.
.
rfn .
.
.
fig.
pa vs ha comparisons on ip cv with artificial bugs metric1 bug sbj bug sbj all sbj p value es p value es p value es accuracyta .
.
.
.
.
.
cr .
.
.
.
.
.
nn .
.
.
latencyta .
.
.
.
.
cr .
.
.
.
nn .
.
.
rfp .
.
.
rfn .
.
.
for the nn sfl neither our proposed approach nor the human oracle approach works well.
this is possibly because as a neural network solution nn needs really big data to work.
that is millions to trillions of items in the training set.
the hundred or thousands of labeled code traces that we generate for each trial are probably still insufficient.
correspondingly for nn the lack of difference between our proposed approach and the human oracle approach is reflected in the p values in table v see the dark gray cells .
for accuracy and latency comparisons related to the nn sfl the p values are big.
this also means that it is meaningless to evaluate the magnitude of improvement i.e.
the corresponding es values which are hence omitted in the table .
corresponding to q2 fig.
g i fig.
g i and fig.
g i all show our proposed approach outperforms the human oracle approach in rfpandrfn.
the significance and magnitude of the improvement are respectively quantified by the p values and es values in table v. as shown in table v for rfpandrfncomparisons the pvalues are all much smaller than hence the improvement of our proposed approach over the human oracle approach is statistically significant.
the corresponding es absolute values are all over .
indicating large improvement magnitudes.
in summary our evaluations imply the following answers.
answer to q1 compared to the human oracle approach our proposed approach significantly improves the quality of ta authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
and cr sfl in terms of accuracy recall and latency .
the magnitude of improvement is medium to large.
answer to q2 compared to the human oracle approach our proposed approach significantly improves the raw quality of the oracle in terms of false positive negative rates .
the magnitude of improvement is large.
f .
discovery of new real life bugs in ardupilot besides the injected bug evaluations we also apply our approach to discover new real life bugs.
for the current version of ardupilot github version hash a7fd353 we run an extensive emulation trial generating code traces and the corresponding physical trajectories by repeating fig.
3step1 tostep2 task1 times.
these code traces are then labeled8by our ar si oracle as described by fig.
step2 task2 and step3 .
the labeled code traces are then sent to ta for sfl.
we checked the top suspected source code blocks outputted by ta sfl and the 7th is confirmed by the ardupilot core developers as a bug .
correspondingly we also carried out the human oracle approach for comparison but none of the found suspects is confirmed.
particularly the new real life bug discovered by our proposed approach is not in the suspect list found by the human oracle approach.
g. threats to v alidity .
construct validity threats .
human oracle v alidity.
in a human oracle design panel an expert can be biased due to his her knowledge and skill set differences.
to mitigate the bias introduced by individuals each panel has at least five experts with high qualifications e.g.
three experts hold phds and over to years of r d experiences on cps two experts hold professorship in control theory including one from a leading mechanical engineering department of the world across various domains embedded systems cv control theory mechanical engineering to design the human oracles via thorough discussions.
though our panels can always be improved their qualities are reasonably good compared to real world practices.
.
golden oracle v alidity.
to judge the raw correctness of oracles in the oracle false positive negative rates evaluations we need a golden oracle that tells if the control cps behavior is truly buggy or not.
unfortunately for controlcpss what shall be the golden oracle is indeed also an open problem.
as shown by fig.
b a so called correct physical trajectory may not be unique.
we cannot for example use the behavior of a specific implementation e.g.
ardupilot without bug injection as the golden oracle and deny the correctness of other behavioral possibilities.
given this we adopt a quasi golden oracle.
we conservatively classify a code trace as truly buggy as long as it covers a buggy source code entity.
such approximation is acceptable considering that our ultimate goal is to locate the buggy source code entity instead of detecting buggy behavior.
for this ultimate goal it makes sense that a code trace covering 8note instead of 6std we used 7std as thresholds for outliers.buggy entities is always reported to sfl tools even if it may indeed cause no buggy behaviors.
also note the golden oracle is not used to label code traces for sfl in our evaluations.
those code traces are labeled by our ar si oracle and or human oracle.
hence the golden oracle has nothing to do with ta cr and nn sfl evaluations.
.
sfl tool representativeness.
to reduce this threat we used three widely recognized representatives from different families of sfl tools and compared their performance in terms of accuracy recall and latency in the same evaluation settings.
we also plan to conduct extensive evaluations on more sfl tools.
.
other si methods.
we choose ar si of exp.
because it is deterministic automatic simple and empirically well tested by broad adoption in practice .
however there are many other si methods .
nevertheless to our best knowledge we are the first to use si for control cps sfl oracle.
whether there exists an even better si oracle is still an open problem for now.
in this paper we show ar si oracle alone already outperforms the mainstream human oracle approach significantly.
next we will conduct comprehensive survey of other si methods and the optimal si oracle to be found shall only outperform the human oracle even more.
.
internal validity threats .
evaluation platform implementation correctness.
there might be bugs in the implementation of our proposed approach and the human oracle approach and in the reimplementation of existing sfl tools.
to address the threat we review our code to ensure their correctness before conducting the evaluations.
.
setting of p.we set the ar model order p see exp.
to10due to assumption and heuristics .
in case the constants in assumption and or heuristics change this setting shall change accordingly.
.
setting of outlier bounds.
we set the outlier bounds see fig.
remark a to mean 6std .
this is an empirical setting advised by domain experts.
how to optimize this settings is still an open problem.
fortunately our evaluations show that even without optimization our proposed approach already outperforms the human oracle approach note the latter approach does not use this outlier bound .
with optimization our proposed approach shall outperform even more.
.
bug injection locations and combinations.
the locations of injected real life bugs are determined by the public archives see the file function line column of table i .
while the locations of injected artificial bugs are randomly selected see the function line columns of table iii iv .
due to combinatorial explosion and feasibility constraints we cannot try every possible injection location combination.
but we are trying our best to randomize these selections.
.
external validity threats .
v ariety of test beds and injected bugs.
the limited types of control cpss and injected bugs used in our evaluations may threaten the external validity.
this is also a well known authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
problem facing control cps research.
control cps naturally involves other domains for which there lacks an open source movement.
this results in much less open control cps platforms for academia to explore compared to the pure computer science community.
to mitigate the problem we deploy two widely used control cpss as test beds and deploy real life as well as artificial bugs reflecting commonly seen bugs in field.
such test beds and bugs however may still under represent all control cpss and bugs.
as future work we plan to carry out more evaluations on other test beds and types of bugs.
v. r elated work this paper focuses on cross domain control cpss.
hence the topic is orthogonal to general purpose oracle or sfl design for pure cyber systems .
si methods that identify hybrid automata models from control cps behaviors may also provide control cps oracles.
but these si methods still have open issues.
for example focuses on converging behaviors which are not always the case for generic control cps behaviors.
needs known domain knowledge of the control cps e.g.
semantics of feature vectors hence is not entirely blackbox.
choi et al.
explored si based oracles on detecting malicious attacks to control cpss.
in comparison this paper focuses on evaluating oracle performance over typical bugs unintentionally left by the programmers.
si is closely related to specification inference.
various approaches including static analysis and dynamic analysis techniques have emerged to infer specifications in the form of behavioral models and or invariants between variables .
the inferred specifications however comply with the existing programs and or training behaviors including the incorrect ones.
hence they are unfit for oracles though they can help programmers understand existing programs better.
there are works on exploiting static analysis to find the most relevant oracle variables .
but these works are not about specifications inferred by static analysis and how to apply these works to control cps is still an open problem.
alippi et al.
designed an oracle for control cps fault detection.
but their focus is on sensor faults instead of software faults.
metamorphic testing exploits necessary conditions governing outputs interrelationships as imperfect oracles .
chen et al.
propose a metamorphic testing oracle for control cps with pid controller software.
modern control cpss however are often more complex than pid control.
recently goebel et al.
propose a set of hybrid systems stability theories for control cpss.
the stability rules can be used as metamorphic testing oracles.
however goebel et al.
s theories require the definition of a lyapunov function for the concerned hybrid system.
for a given generic control cps the existence of a lyapunov function is not guaranteed neither is there a generic routine to decide its existence.
even if the lyapunov function exists there is no generic mechanical routine to find it.
thereforegoebel et al.
s hybrid systems stability theories are mainly for designing new control cpss instead of for designing imperfect oracles for existing and or generic control cpss.
nonetheless the above endeavors inspire us to propose this paper s ar si based oracle which is indeed an imperfect oracle in a general sense.
there are other efforts to solve the oracle problem.
several modeling programming languages are developed to formally describe oracles in addition assertions and contracts are forms to describe oracles.
but they do not answer the oracle problem itself what oracles to describe.
we can use n version or previous versions to generate trajectories for comparisons but such methods are orthogonal to the oracle problem solutions for debugging a single version of a control cps.
there are a few works on test case generation for controlcpss .
test case generation however is orthogonal to this paper s topic.
meanwhile a good oracle can always benefit testing especially by spotting bugs whose triggering mechanisms are not well known.
liu et al.
propose a sfl tool specialized for control cps whose cyber and physical models are known accurately.
however this paper focuses on control cpss whose accurate cyber model is unavailable.
deshmukh et al.
propose using sfl to tune control parameters this is not related to oracle designing.
the content of this paper is included in the first author s phd thesis.
vi.
c onclusion in this paper we proposed an ar si based oracle and corresponding code trace preparation methodology for control cps sfl.
our proposed approach can run deterministically and automatically.
we evaluated our proposal on classic controlcps test beds with sfl of injected real life and artificial bugs.
the evaluation results show that our proposed approach significantly outperforms the human oracle approach achieving medium to large improvements on sfl accuracy recall and latency as well as oracle false positive negative rates.
using our approach we also discovered a new real life bug in a consumer grade control cps.
acknowledgment we thank mr. ming jin for the unity program development and thank anonymous reviewers for their comments.
yao chen is currently with the dept.
of computer science southwestern univ.
of finance and economics chengdu china.
the research related to this paper is supported in part by hong kong rgc grf polyu 18e polyu 14e polyu 16e rgc ecs polyu 12e rgc germany hk joint research scheme g polyu503 the hong kong polytechnic univ.
fund g ybmw g ybxw g yn37 g ua7l bbwc zzhd zvj1 g ybxu.