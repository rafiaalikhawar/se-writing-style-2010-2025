aggreplay efficient record and replay of multi threaded programs ernest pobee department of computer science city university of hong kong kowloon tong hong kong ernestpob gmail.comw.
k. chan department of computer science city university of hong kong kowloon tong hong kong wkchan cityu.edu.hk abstract deterministic replay presents challenges and often results in high memory and runtime overheads.
previous studies deterministically reproduce program outputs often only after several replay iterations or may produce a non deterministic sequence of output to external sources.
in this paper we propose aggreplay a deterministic replay technique which is based on recording read write interleavings leveraging thread local determinism and summarized read values.
during the record phase aggreplay records a read count vector clock for each thread on each memory location.
each thread checks the logged vector clock against the current read count in the replay phase before a write event.
we present an experiment and analyze the results using the splash2x benchmark suite as well as two realworld applications.
the experimental results show that on average aggreplay experiences a better reduction in compressed log size and better runtime slowdown during the record phase as well as a .
higher probability in the replay phase than existing work.
ccs concepts software and its engineering synchronization software verification dynamic analysis .
keywords concurrency deterministic replay multi threading.
acm reference format ernest pobee and w. k. chan.
.
aggreplay efficient record and replay of multi threaded programs.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
this research is supported in part by the grf of hksar research grants council project nos.
and the hksar itf projectno.
its and the cityu mf ext project no.
.
correspondence author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn .
.
.
.
introduction deterministic replay is a process of recording data from a program s execution and guiding a subsequent execution towards a specific program state and or program output .
it can be used in for example software debugging and software testing .
deterministic replay consists of two phases namely record phase and replay phase.
in the record phase such a technique logs data from an execution of a multithreaded program.
logged data includes thread access interleavings to shared memory locations and synchronization objects access orders.
the replay phase is an execution of the program guided with an execution schedule generated based on the data output from the record phase.
some techniques further include an offline phase in between the record and replay phases to resolve some data missed from the record phase.
we categorize deterministic replay techniques into hardware based and software based for brevity.
hardware based techniques may require specialized hardware which may not be available on commodity systems .
we focus on software based deterministic replay techniques in this work due to their ease of deployment compared to hardware based techniques.
software based replay techniques need to tackle data races1 .
as such replay techniques record thread access interleavings on shared memory locations and synchronization objects during the record phase to generate an execution schedule which produces the required interleavings in the replay phase.
there are three types of interleavings recorded on shared memory locations read write write read andwrite write .
however logging all the interleavings in an execution incurs high memory and runtime overheads.
as such some techniques record subsets of interleavings .
we refer to the proportion of interleavings recorded as the degree of recording fidelity .
we further categorize software based deterministic replay techniques hereafter referred to as replay techniques into order based and search based replay techniques for brevity.
order based technique s these techniques record the order of thread accesses to shared memory locations as well as synchronization objects.
they may record all sets of thread access interleavings read write write read andwrite write or subsets of them.
in the simplest form order based techniques protect instrumentation events with some lock object ensuring that the 1a data race occurs when two or more threads accessing a shared memory location without proper synchronization and at least one of the access operations is a write operation.
567esec fse august tallinn estonia ernest pobee and w. k. chan a trace 1 w1 x r1 x w2 x the interleaving r1 x w2 x is not recorded.
b replay trace sr1 w1 x r1 x data race race 1is missed by light.
figure illustration of thread interleavings recorded by existing replay techniques.
correct thread interleaving order is preserved.
thus they exhibit high recording fidelity.
however logging all thread interleavings is costly due to the frequent use of locks during the record phase.
moreover excessive event matching in the replay phase reduces concurrency and increases the execution overhead.
replay techniques such as leap use more than one lock object to protect read and write accesses by to different shared memory locations increasing parallelism.
however leap incurs high memory and runtime overheads as all events both read and write executed on each shared memory location are recorded in a serialized manner.
search based techniques these techniques like stride and odr sacrifice recording fidelity in exchange for a speedup in record time and low memory usage.
stride records the values read by threads and couples each read value with a previous write access to some shared memory location.
whilst search based techniques may sometimes reproduce the output of a program the process often requires several iterations and may reduce the efficiency of such techniques.
another downside is that low record fidelity means search based techniques may generate new data races or fail to reproduce data races during the replay phase.
stride achieves up to .5x in slowdown reduction on average compared to order based technique leap.
however a search based strategy does not imply low overheads.
for example the order based technique light achieves up to 4x in memory overhead reduction in comparison to stride.
an example is shown in figure 1a where the execution trace is given as 1 w1 x r1 x w2 x .
there are two data races race and race 2on the interleaving r1 x w1 x and r1 x w2 x respectively.
assuming both writes are protected by a lock light records the write read dependency from the trace 1as w1 x r1 x .
light will reproduce race 2but will miss the dependency r1 x w2 x and transitively race .
according to the replay strategy of light the event w2 x may not execute to reproduce race .
as such light will never reproduce race .
also supposing the events w1 x andw2 x were writes to output devices light cannot guarantee the two events will be outputted in a deterministic order.
therefore light s strategy is not output determinisitc .
we propose our solution with the following insight a list of read events on a shared memory location by each thread are strictly ordered and can be summarized and recorded before the next immediate write and write write interleavings are globallyordered .
as such summarized reads by different threads could be ordered before some write to that shared memory location.
in this paper we present aggreplay a novel deterministic replay technique which exploits the advantages of strictly ordered threadlocal operations.
aggreplay keeps a thread local read count vector clock for each shared memory location.
such a read count vector clock is updated in two different ways during the record phase.
when a thread reads a value on each shared memory location the index for the thread in its read count vector clock is updated.
prior to a thread s write on a shared memory location the thread s read vector is updated with read values from all other threads read count vector clock.
the executing thread s read vector is constructed before the current write event in the log.
this enables us to keep track of read write interleavings.
during the replay phase each thread maintains a read vector similar to the record phase.
on a write to each shared memory location the read vector for the executing thread is updated with read values from all other threads read vectors.
the thread s read vector is matched with the corresponding read vector from the record log.
the thread executes the write operation if the read vectors are matched successfully.
to evaluate the performance of aggreplay we design our experiments to answer the following research questions rq can aggreplay achieve smaller log sizes and runtime slowdown compared to existing state of the art in the record phase?
our experimental results show an average of 6x reduction in log sizes as well as average slowdown compared to stride.
light however achieves .75x on average of aggreplay log sizes.
rq how much do the various space optimization techniques employed by the replay strategies affect record?
data recorded for write read interleavings are compressed for better storage efficiency and all techniques employ different space optimization approaches.
our experimental results show that aggreplay achieves a .6x compression for write read logs compared to stride.
aggreplay is more efficient than stride on out of benchmarks.
light achieves a .3x write compression on average over aggreplay.
rq is aggreplay able to replay applications in high probability?
aggreplay reproduces all the interleavings and the output with .
probability across all benchmarks higher than stride by .
.
aggreplay also incurred .85x slowdown compared to .54x of stride during replay.
568aggreplay efficient record and replay of multi threaded programs esec fse august tallinn estonia preliminaries this section details preliminary information used in this paper.
table preliminary information operation opbw x r x acq m rel m fork u join u x memory location m lock u thread event eb t op t thread op operation execution trace b e1 e2 e3 .
.
.
en ei event .
execution trace an execution trace e1 e2 .
.
.
en is a sequence of operations observed from the execution of a software program.
an operation erepresents one of the following t.r x a read instruction executed by thread ton memory location x. t.w x a write instruction executed by thread ton memory location x. t.acq m a lock acquisition instruction executed by thread t on lock m. t.rel m a lock release instruction by thread ton lock m. t.fork u thread tforks another thread u. t.join u thread tjoins another thread u. other synchronization primitives such as wait signal and barrier are also considered by our algorithm and follow procedures similar to the synchronization primitives above.
we omit them for brevity.
.
read count vector clocks we track read write interleavings with the aim of enforcing these interleavings in the replay phase using read count vector clocks.
a read count rc vector clock a variation of lamport s vector clock is a tuple of values where each value which tracks the number of read events of the corresponding thread in an execution trace.
an rc vector clock maintains a count of a thread s read events to a shared memory location in the form of rct where trepresents the current thread.
running example we present a running example to motivate our work.
figure illustrates an execution of a multithreaded program with three threads t1 t2andt3 as well as operations which are write and read labeled e1through to e9.
in figure t1executes a write on location x. thread t2then executes a write e2ony.thread t3then executes a write e3onxandt2executes a read e4onx.t3then writes ony.t2then writes on z.t3executes e7which is a read on z. thread t2executes a read on z.finally t1executes e9 which is a write on z. the trace 2 e1 e2 e3 e4 e5 e6 e7 e8 e9 is produced.
the set e1 e3 e3 e4 e2 e5 e6 e7 e6 e8 e8 e9 e7 e9 is produced as thread interleavings.
to capture the trace 2 a simple strategy is to log all the events.
for figure nine locks events will be inserted during the instrumentation for correctness.
however this recording strategy figure running example an execution trace of a multithreaded program t1t2 t3.
dashed arrows represent the global trace 2 reduces parallelism and increases runtime slowdown for the record phase.
the existing state of the art light records only flow dependencies write read interleavings .
synchronization events are also encoded as read and write events.
for trace 2 light records the write read interleavings e3 e4 e6 e7 e6 e8 then passes the set of interleavings to a constraint solver as constraints.
light further includes constraints over the set of constraints per shared memory location.
the constraint solver constructs a feasible trace for subsequent replay.
during the replay phase light attempts to replay the execution using a member trace of the trace set generated by the constraint solver.
the events e1 e2 e5ande9are not executed by light since they are considered blind writes by light.
blind writes are write events not involved in any write read dependence .as such light is not able to reproduce the program state by design .the main drawback is light is unable to guarantee a deterministic order of output for any set of serialized write events which may include blind writes.
light is also limited by the capacity of constraint solvers to generate traces.
stride is a search based replay technique which reduces recording overhead by maintaining a write version counter for all writes on a shared memory location.
to record data on write read interleavings it pairs the read value value e of each read operation with a possible matching write version version e .
for trace 2 stride records the write write interleavings e1 e3 and e6 e9.
the candidate write read pairs value e4 version e3 value e7 version e6 and value e8 version e6 are recorded.
during a write operation in the replay phase the write read pairs are used to infer possible interleaving candidates with the version ebeing the upper and the value ebeing the matching criterion.
for the trace 3in figure t2executes two writes eiand ek after t3executes e7.
suppose that e5andekwrite the value but eiwrites the value .
in this case stride may record the pair value e7 version ek because write read interleavings are not ordered in the record phase.
during the replay phase the interleaving e6 e7will be missed by stride because the 569esec fse august tallinn estonia ernest pobee and w. k. chan figure modified running example with trace 3. double compound arrow represents the recorded pairing value e7 version ek .
interleaving ek e7matches stride s search criterion for the pairing value e7 version ek .
note that stride can correctly infer e6 e7if there is no write operation after e6which writes to the same memory location having the same value as e6.
in the case of light let us consider the events e2and e .e2will be correctly ordered by light when outputting to external devices only because of the write read interleaving e3 e4.however the events e1and e3are not explicitly ordered by light and may be incorrectly ordered.
aggreplay records write write andwrite read interleavings with optimizations as well as read write interleavings in a novel strategy.
as such it can keep track of all events in both traces 2and 3. we present our aggreplay algorithm in the next section.
aggreplay algorithm in this section we present aggreplay.
the following notations are used in our algorithms wx the write access list for shared object x. repw x the write access list for shared object xduring the replay phase.
lm the lock acquisition list for lock m. ext the thread local read write access list for thread t. wr x the write read access list for shared object x. tid e the executing thread of operation e. lock e the lock object acquired in operation e. var e the shared object being accessed by operation e. rct.x the rc vector clock for thread tfor shared memory location x. init rc t.x this function instantiates all the elements of rct to .
inc rc t.x this function increments the read count value of the thread t inrctby for shared memory location x. last write var e the last write event to the shared memory location in event e. lwx last write event to a shared memory location x. execute e event eis executed.
t.yield the executing thread t waits for other threads to advance without blocking.
top input reads data from the first index of input .
input wx lm ex wr x .
pop input removes data from first index position of input .
.
aggreplay record phase the record phase of aggreplay is presented in algorithm .
lines instantiate the rc vector clock for each thread for each shared memory location in the program execution to rc where every element in the vector clock rcis zero.
lines detail the onwrite function.
on a write to a shared memory location aggreplay first checks the read accesses to that memory location by the other threads.
line invokes the updatereadvectors function.
this function enables us to keep track of read write interleavings.
our insight is that due to read events on all shared memory locations being ordered by that thread and all write events on each shared memory location are globally ordered we need not track read write interleavings at the shared memory level.
rather we track the total number of reads for each shared memory location for each thread prior to a write event.
the write event is executed at line .
the write event is added to the write access list of the shared memory location line .
algorithm the aggreplay recording algorithm input execution trace b e1 e2 e3 .
.
.
en e event output extid e wvar e wr var e llock e for each t e thread event init rc t.var e write access performed by event e onwrite event e do sync updatereadvectors e execute e the write instruction is executed wvar e bwvar e e end onwrite read access returned by event e onread event e do tbtid e rct.var e binc rc t.var e synch lw last write var e execute e the read instruction is executed wr var e bwr var e lw e end onread updatereadvectors event e for each t thread and rct .var e do rctid e .var e brct .var e end for extid e bextid e rct id e e end updatereadvectors onlockacquire event e execute e llock e bllock e t id e end onlockacquire for lines on every read to a shared memory the executing thread and shared memory location are obtained.
then the index 570aggreplay efficient record and replay of multi threaded programs esec fse august tallinn estonia figure aggreplay record phase for running example.
for the current thread in its rc vector clock is incremented by at line .
the last write to the shared memory location for the current read operation is retrieved at line .
the read event is executed at line and is ordered before the current read in the write read access list of the shared memory location at line .
the updatereadvectors lines function is invoked at line of the onwrite function.
this function retrieves the read count values for every other thread in the set of threads with a read count value greater than zero.
the updated read count for the current thread is then paired with the write event and added to the threadlocal read write access list.
lines details the lock acquisition function.
the lock acquisition event is executed at line .
the executing thread is appended to the lock s access order list at line .
figure illustrates the rc vector clock values for the trace 2 in the running example.
on events e1 e2and e3 the write access lists for shared memory locations xandyare updated by t1 t2and t3 respectively.
on event e4 the read value for t2inrct2.x is incremented by .
the write read dependency e3 e4is also recorded by aggreplay events e5and e6also result in the write access lists foryandzbeing updated by t3andt2 respectively.
on event e7 the read value in rct3.z is incremented by .
the write read dependency e6 e7is also recorded.
then rct2.z is incremented by on handling e8.
on e9 the rc vector clock for t1is updated with the read count values from t2and t3.
then rc t1.z is constructed before event e8and saved in the record.
the record output for the trace is shown in figure .
.
aggreplay replay phase the agrreplay replay phase is shown in algorithm .
the output from the record phase ex w var e wr tid e llock e are used as input in the replay phase.
t1.z e9 wx e1 e3 wrx e3 e4 wy e2 e5 wrz e6 e7 wz e6 e9 figure aggreplay output data for trace 2in figure 2the repw var e is the access list for the shared memory location var e in the replay phase.
line instantiates the rc vector clocks for each thread in the program execution to rc where every element in the vector clock rcis zero.
lines detail the onwrite function during a write event anupdatereadvectors function is invoked.
this function updates the currently executing thread s rc vector clock with read count values from all other threads.
next the write event is matched with the first element in the write input list wvar e for that shared memory location var e at line .
if the two events match then the checkreadvector function is invoked to ensure that all necessary reads have been executed prior to the write event.
if checkreadvector returns true the write event is executed the repw var e is updated with the write event.
the first element is removed from the wvar e input list lines .
otherwise if checkreadvector returns false the thread yields the processor at line .
lines show the onread function.
during a read event the last write event for the shared memory location in the replay phase is matched to the first element in the wr var e input list line .
if the two elements match the read event is executed line .
the read count vector clock for the current thread is incremented then the first element in the wr var e input list is removed lines .
otherwise if the condition at line is evaluated to false the thread yields at line .
this way each thread can individually replay the correct sequence of read events without synchronization with other threads.
lines detail the onlockacquire function.
if the currently executing thread does not match the first element of the input list llock e then the thread yields lines .
otherwise the lock acquisition event is executed and the first element of the input list llock e is removed lines .
the updatereadvectors function at lines updates the rc vector clock of the currently executing thread with read count values from the rc vector clocks of threads other than the currently executing thread with read count values greater than zero .this function is invoked in the onwrite function at line .
the checkreads function is detailed at lines .
this function is invoked at line in the onwrite function.
during the record phase we record a null line instead of the original write read interleaving which is removed by o1.lines show the implementation for handling such null lines in the replay phase.
if the first element of extis a null line then the first element is removed and checkreads returns a truevalue .the thread is allowed to execute as there are no preceding read s or the preceding read s are ordered by the executing thread.
lines match the read count value for all threads other than the current thread tin the read count vector clock of the current thread against the first element of the extinput list line .
if the condition at line evaluates to false the function returns false.
if the condition at line is evaluated to true the algorithm at line removes the first element of the ext input list.
the function then returns trueat line .
aggreplay replays the execution in figure as follows t3 attempts to execute e3but the match between e3and the first element in the write access list wxevaluates to false.
t3yields the underlying thread scheduler.
t1then attempts to execute e1.
as no reads have been executed prior to e1 the checkreads function evaluates to true.
e1is then matched with the first element in the write access list for wx.t1proceeds to execute e1which is then 571esec fse august tallinn estonia ernest pobee and w. k. chan added to repw xand the matched element is removed from wx.t2 is scheduled to execute e2.
the matched element of wyis removed.
when t2tries to executes e3 the last write event on x e3 is retrieved from repw xand matched with the first element in wr x. since the two events do not match t2yields the scheduler.
t3 then executes e3and the matched element is removed from wx.
t2 then executes e4 then increments rct2.x by .
the matched element is removed from wr x.t2executes e6as no reads have been executed on zprior to e6.next t3then executes e5and the matched element is removed from wy.
t3executes e7and updates rct3.z by1.
t2executes e8and updates rct2.z by1.finally t1 tries to execute e9.the updatereadvectors function updates rct1.z with the read count values from rct2.zand rct3.z.
t1executes e9 when e9is matched with the first element in wzand the checkreads function returns true.
evaluation .
execution environment our hardware setup consisted of a dell poweredge r930 running the dell customized image esxi .
.
update a01.
our experiments were conducted on a bit virtual machine running the guest os ubuntu .
linux with intel xeon r cpu e7 v3 .20ghz processors as well as 16gb of ram.
we implemented aggreplay light and stride using intel pin version .
.
to be specific for each tool we implemented two separate pintools one each for the record and replay phases respectively.
in the case of light we followed the implementation in the paper using a solver for the integer difference logic theory inz3 see appendix2 .
the original implementation of light is made available without the constraint solver and replay phases.
both can only handle java applications.
we also implemented stride by following the paper despite the unavailability of implementation by the authors.
a precaution taken was to test the correctness of our implementations of stride and light on different variants of a small benchmark we developed that includes different threadinterleaving code patterns.we also used code inspection on our implementations.
.
benchmarks we evaluated our implementation using the splash2x extension of the parsec .
benchmark suite specifically barnes ocean cp radiosity raytrace volrend water spatial fmm water nsquared water spatial as well as kernel applications cholesky fft lu cb lu ncb radix.
we selected the splash2x extension of parsec for its focus on concurrent computation on parallel machines.
we also include real world applications simulations including mysql .
.
database server and apache .
.
webserver.
we further include an implementation of blockchain3to test the robustness of our tool for emerging software technology.
2github link 3github link the aggreplay replay algorithm input ex w var e wr tid e llock e output from record phase output program output valued outputted by subject program for each t thread do init rc t init ex t end for write access performed by event e onwrite event e do updatereadvectors e if e top w var e checkread s tid e then execute e repw var e brepw var e e pop w var e else tid e .yield end if end onwrite read access returned by operation e onread e match write event from wr input list if last write var e top wr var e .lw then execute e t tid e rct inc rc t pop wr var e else tid e .yield end if end onread onlockacquire e if tid e top l lock e then tid e .yield else execute e pop l lock e end onlockacquire updatereadvectors e for each t thread and rc t do rctid e rc t end for end updatereadvectors checkreads thread t iftop ex t then pop ex t return true end if for each t thread do if rct top ex t.rc then return false end if end for pop ext return true end checkreads 572aggreplay efficient record and replay of multi threaded programs esec fse august tallinn estonia table execution metadata for benchmarks used in our experiment.
all benchmarks were configured with worker threads except apache mysql and test chain which were configured with threads.
benchmarks of events write read locks cholesky .
x .
x fft .
x .
x fmm .
x .
x .
x lu cb .
x .
x lu ncb .
x .
x ocean cp .
x .
x ocean ncp .
x .
x raytrace .
x .
x radiosity .
x .
x radix .
x .
x volrend .
x .
x water nsquared .
x .
x water spatial .
x .
x barnes .
x .
x .
x mysql .
x .
x apache .
x .
x test chain .
x .
x .
methodology to carry out our experiment we first conducted a dry run on each benchmark using a pintool with no instrumentation functions.
we recorded the execution time as the base time for each benchmark in the dry run.
in the record phase each splash2x benchmark program was configured with worker threads with the gcc pthreads option and the simlarge workload.
the inputs for apache and mysql are apache bug and mysql bug respectively.
this configuration provided each program adequate concurrency and input.
the blockchain implementation was set to mine blocks append two transactions to a block chain.
.
thread abstraction and matching to ensure that any pintool matched threads between record and replay runs we abstracted each thread as a pair of unsigned integers abst a b where arepresents the child count value assigned to the thread by its parent thread and brepresents the index value for the parent thread.
we assumed that the main thread usually thread always begins first in each run and as such we did not abstract and record it.
during thread creation we mapped each thread s index to the thread s uniquely assigned system id.
e.g.
all threads created by the main thread had a pairing abst a where a was the child count value under the main thread and is main thread s index value .
the abstraction pair was then outputted to a log file.
on thread creation during replay the frequency of encountering a particular thread as a parent index was matched against the first item in the logged pair of values i.e.
freq parent id abs.a .
.
record and replay setup during the record phase each thread kept a thread local counter one each for read and write events to shared memory locations and synchronization objects respectively.
each thread also kept a thread local data structure to maintain the thread s rc vector for each shared memory location.
the write file was accessed by all the threads and we used a lock in moderating accesses to it.
aggreplay maintained internal data structures for writes reads and synchronization events which were indexed by the shared memory locations and locks in the case of synchronization events .
aggreplay stored all recorded data in memory and wrote to the log file when the benchmark terminated with the exception of read write data which was written to file intermittently.
with the exception of thread local data structures accesses to all remaining data structures was controlled by locks.
for stride we used locks to protect write events and synchronization events being recorded to the log file.
apart from write events thread local read events and their associated read values were not protected by locks based on the algorithm of stride.
we recorded time spent total processor time spent on each execution using the clock function4.
the slowdown factor was computed as the time spent divided by the base time .
for aggreplay each thread kept a local counter for all events.
the record log format for synchronization events was a list of pairs in the form of a b where arepresents the thread id andbrefers to the value for th isthread local counter .the write logs also feature a similar format to the synchronization logs.
each read write interleaving is recorded during a write event by some thread on some shared memory location.
as such the read write log was recorded as a pair rc write where rcrefers to the read count vector clock of the current thread and write refers to the write event.
for stride the write and read event pairs which made up write read interleaving candidates were recorded separately.
we also implemented the last one value predictor for the write read candidate interleavings as described in the paper .
we have made our aggreplay implementation available online for data reproduction5 .
record phase results table shows our experimental results.
the first and second columns show the names of the benchmarks and their application domains.
the third fourth and fifth columns show the log sizes in mb for aggreplay light and stride respectively after compression with gzip.
the sixth column shows the base execution time for each benchmark with no instrumentation or analysis.
the seventh eighth and ninth columns show the slowdown factor for aggreplay light and stride with respect to the base time.
the last two columns show the ratio of slowdown factor for light and light over aggreplay.
from table aggreplay resulted in an average of .
mb which was a fold improvement on average compared to stride.
out of benchmarks aggreplay recorded a smaller log size for of these subject programs whereas stride experienced about 5github link 573esec fse august tallinn estonia ernest pobee and w. k. chan table experimental results on aggreplay ap light li and stride st .
the column bt represents the base runtime slowdown presented in seconds.
columns a b and c represent the slowdown runtime slowdown factors for stride aggreplay and light respectively.
benchmark application domainlog size mb btslowdown factor aggreplay light stride a b c b a c a cholesky hpc .
.
.
.
.
.
.
.
fft signal processing .
.
.
.
.
.
.
.
.
fmm hpc .
.
.
.
.
.
.
.
.
lu cb hpc .
.
.
.
.
.
.
.
.
lu ncb hpc .
.
.
.
.
.
.
.
.
ocean cp hpc .
.
.
.
.
.
.
.
.
ocean ncp hpc .
.
.
.
.
.
.
.
.
raytrace graphics .
.
.
.
.
.
.
.
.
radiosity graphics .
.
.
.
.
.
.
.
.
radix general .
.
.
.
.
.
.
.
.
volrend graphics .
.
.
.
.
.
.
.
.
water nsquared hpc .
.
.
.
.
.
.
.
.
water spatial hpc .
.
.
.
.
.
.
.
.
barnes hpc .
.
.
.
.
.
.
.
.
mysql database .
.
.
.
.
.
.
.
.
apache webserver .
.
.
.
.
.
.
.
.
test chain blockchain simulation .
.
.
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
.
reduction in log size for over aggreplay for two benchmarks lu cb and lu ncb two kernel based applications .a contributing factor to this result is the optimization of stride s last one value predictor for write read candidate pairs which enabled stride to compress a number of read events if they returned the same value.
aggreplay maintained read count vector clocks for each thread and outputs read write events to logs.
stride did not log read write relations it had some advantage in generating smaller log sizes over aggreplay.
light generated a lower log size on average compared to aggreplay.
light achieved smaller log sizes by recording only write write dependencies.
the seventh eighth and ninth columns show the runtime slowdown results.
aggreplay had better slowdown on out of benchmarks.
on average aggreplay incurred a improvement in slowdown over stride.
in the recording phase light also achieved only a .2x speedup over aggreplay.
this is because aggreplay monitored more events than light did.
.
thread interleaving results during the replay phase we followed in reading log files as input.
aggreplay retrieves read write interleavings by comparing the read count vc values of the executing thread against the logged read vector values line of algorithm .
the complexity of determining a read write interleaving is o n where nrepresents the number of threads in the subject program.
table shows the comparison on write read pairs between all replay techniques.
recall that aggreplay logged write read interleavings as well as other interleaving data as stated in algorithm .
during this process aggreplay achieved small logs by applying threeoptimization functions see section .
.stride records write read interleaving candidate pairs and read values to infer write read interleavings during each replay execution.
this strategy can increase parallelism in the record phase.
despite the space optimization used by stride aggreplay achieved similar write write event numbers.
aggreplay achieved relatively small read write logs due to the read count vector clock strategy.
also aggreplay is the only technique among the three to record read write events.
.
replay phase results table presents the experimental results on replay phases for aggreplay light and stride.
a successful replay run for aggreplay in our experiment was the reproduction of interleavings observed in the record phase.
each subject program is run times.
aggreplay outperforms stride in successfully reproducing thread interleavings in all benchmarks with an average probability of .
compared to .
for stride.
however stride does not guarantee to reproduce all interleavings.
recall that light employs a constraint solver in generating possible schedules for replay.
the constraint solver iteratively and progressively searches for candidate schedules which satisfy the given constraints.
however in our experiment we found the constraint solver to be incapable of generating candidate schedules mainly due to the high number of constraints generated for our benchmarks.
with the exception of mysql possible traces and apache traces the constraint solver did not return any output even after several hours of constraint solving.
for mysql and 574aggreplay efficient record and replay of multi threaded programs esec fse august tallinn estonia table comparison on thread interleaving sets recorded by aggreplay ap light li and stride st .
table replay results on aggreplay ap light li and stride st .the second column coe correct output executions represents number of executions with successfully reproduced output.
the third and fourth columns cie correct interleaving executions show the number of successfully reproduced interleavings.
represents no results for the benchmark under that column.
represents worse performing runtimes for aggreplay.
benchmark coe cie mean slowdown factor st ap li st ap li st cholesky .
.
fft .
.
fmm .
.
lu cb .
.
lu ncb .
.
ocean cp .
.
ocean ncp .
.
raytrace .
.
radiosity .
.
radix .
.
volrend .
.
water nsquared .
.
water spatial .
.
barnes .
.
mysql .
.
apache .
.
.
test chain .
.
mean .
.
.
.
.
.
apache light succeeded in reproducing correct interleavings of the time .
the second column in table shows the number of executions with successfully reproduced outputs by stride.
stride produced output of benchmarks with an average probability of .
.
in the case of stride unexpected program halts due to its replay strategycounted as unsuccessful runs.
the mean slowdown factor for each technique on all the benchmarks is shown in the last two columns of table .
for mysql and apache aggreplay reproduced all interleavings with an average probability of compared to for stride.
aggreplay incurs the least amount of slowdown among the three techniques except for fmm.
575esec fse august tallinn estonia ernest pobee and w. k. chan .
aggreplay optimization functions to reduce the number of entries in the record log the implementation of aggreplay includes three optimization functions in the record phase as follows o1 if the read count vector clock for the current thread remains unmodified during the updatereadvector function the event is not recorded .
o2 if there is a change in the read count vector clock for the current thread and the only modified value is that of the current executing thread the event is not recorded .
o3 if more than one thread has the same read count value the values are recorded in the format c dwhere crefers to the read count value and drefers to its frequency in the read vecto r. foro1ando2 we modify line of algorithm with as follows if a condition rc changed evaluates to true when a thread s rc vector clock is modified and evaluates to false otherwise evaluates to true then extid e bextid e rct id e e .
ifrc changed evaluates to false then a null line is appended to extid e as extid e bextid e in algorithm lines show how the records missed by o1 ando2are recovered.
if the first element of extmatches a null line it means the last read event to the shared memory location prior to the current write was executed by the currently executing thread.
as such the first element of extis removed and the checkreads function returns true.
for o3in algorithm the init ext function recovers all c d pairs recorded and resolves each pair to a rct object.
.
limitations our implementations of all replay techniques suffer the constraints of any tool created using pin which serializes the instrumented events from the subject program to a pintool regardless of support for multi threading.
aggreplay may not deterministically reproduce interleavings which involve worker threads spawned non deterministically by long running applications like apache or mysqlas the workload increases during the replay phase.
related work some replay techniques aim to reproduce a target output including particular program state only.
odr takes a core dump as input extracts some program state values from the latter and generates a trace to reproduce these values at target code locations through a search process.
bbr needs a predefined set of location checkpoints to reduce log sizes and uses a search process with symbolic execution in constructing feasible traces passing through these checkpoints.
aggreplay does not rely on symbolic executions to construct target traces.
rather aggreplay records the counts on the numbers of thread local read accesses at the execution point of handling the write instructions.
aggreplay can be further augmented with a technique that records the non deterministic inputs in the record phase and compares the corresponding values in the replay run against these logged inputs.
recording write read interleavings has been explored by existing work.
light records inter thread and intra thread write read interleavings and uses a constraint solving approach tofind thread schedules having these interleavings whilst constructing replay traces.
aggreplay also records write read interleavings explicitly but uses no constraint solver.
keeping thread local data for efficient recording has also been explored by existing work such as clap .
clap relies on constraint solving in an offline phase to symbolically analyze expression values which is proven by our experiment with light to be unscalable and has limitations in handling complex arithmetic computations in practice.
care maintains thread local caches for shared memory locations records cache missed write read interleavings but does not record write read interleavings if the interleaving results in a cache hit.
maintaining such caches incur high memory overheads.
care keeps each read write interleaving in the record phase.
aggreplay does not need constraint solving nor have an offline phase and records a read count vector for read write dependencies.
some techniques combines record and replay into one phase.
doubletake divides an exaction into epochs by the locations of irrevocable system calls.
it iteratively logs the system state right before the epoch executes the instructions in the epoch analyzes the program state for derivations and replays that fragment if derivations are found otherwise it proceeds to reply the next epoch.
doubletake requires special hardware to support.
unlike mobiplay aggreplay does not need to modify the underlying framework to support its replay.
checkpointing is frequently used in replay techniques.
ireplayer stores the system state in memory and allows users to specify checkpointing rules.
it monitors data races in its replay phase and iteratively executes an epoch in a sense similar to doubletake if the replay schedule for the involving interleavings differs from the required thread interleavings.
aggreplay does not use checkpointing.
processor oblivious record and replay has been proposed for data race free systems such as cilk programs.
this replay strategy focuses on recording the synchronization order for programs which employ task parallelism.
such programs do not have any notion of threads or data.
however current mainstream software supports multi threaded parallelism.
aggreplay can be applied to most mainstream software.
conclusion we have presented aggreplay a deterministic replay technique which is based on recording read write interleavings leveraging thread local determinism and summarized read values.
during the record phase aggreplay records a read count vector clock for each read on each shared memory location.
in the replay phase each thread matches the logged read count against each executing read event to ensure a target number of read events prior to the next write.
we have presented an experiment and analyzed the results of our experiment using the splash2x benchmark suite apache and mysql and a blockchain implementation.
the experimental results indicated that on average aggreplay experiences better reduction in compressed log size and better runtime slowdown during the record phase as well as a .
higher probability in the replay phase than an existing technique.
576aggreplay efficient record and replay of multi threaded programs esec fse august tallinn estonia