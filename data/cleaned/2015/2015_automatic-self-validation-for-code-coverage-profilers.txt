automatic self validation for code coverage profilers yibiao yang yanyan jiang zhiqiang zuo yang wang hao sun hongmin lu yuming zhou and baowen xu state key laboratory for novel software technology nanjing university nanjing china school of cyber science and engineering huazhong university of science and technology wuhan china yangyibiao jyy zqzuo nju.edu cn dz1933028 smail.nju.edu.cn shqking gmail.com hmlu zhouyuming bwxu nju.edu.cn abstract code coverage as the primitive dynamic program behavior information is widely adopted to facilitate a rich spectrum of software engineering tasks such as testing fuzzing debugging fault detection reverse engineering and program understanding.
thanks to the widespread applications it is crucial to ensure the reliability of the code coverage profilers.
unfortunately due to the lack of research attention and the existence of testing oracle problem coverage profilers are far away from being tested sufficiently.
bugs are still regularly seen in the widely deployed profilers like gcov and llvm cov along with gcc and llvm respectively.
this paper proposes cod an automated self validator for effectively uncovering bugs in the coverage profilers.
starting from a test program either from a compiler s test suite or generated randomly cod detects profiler bugs with zero false positive using a metamorphic relation in which the coverage statistics of that program and a mutated variant are bridged.
we evaluated cod over two of the most well known code coverage profilers namely gcov and llvm cov.
within a fourmonth testing period a total of potential bugs for gcov for llvm cov are found among which are confirmed by the developers.
index terms code coverage metamorphic testing coverage profilers bug detection.
i. i ntroduction profiling code coverage data e.g.
executed branches paths functions etc.
of the instrumented subject programs is the cornerstone of a rich spectrum of software engineering practices such as testing fuzzing debugging specification mining fault detection reverse engineering and program understanding .
incorrect coverage information would severely mislead developers in their software engineering practices.
unfortunately coverage profilers themselves e.g.
gcov and llvm cov are prone to errors.
even a simple randomized differential testing technique exposed more than bugs in coverage profilers .
the reasons are two fold.
firstly neither the application end developers nor academic researchers paid sufficient attention to the testing of code coverage profilers.
secondly automatic testing of coverage profilers is still challenging due to the lack of test oracles.
during the code coverage testing the oracle is supposed to constitute the rich execution information e.g.
the execution frequency of each code statement in the program under a given particular test case.
different from the functional oracle which usually can be obtained via the given specification achieving the complete code coverage oracles turns out to be extremely challenging.even though the programming experts can specify the oracle precisely it requires enormous human intervention making it impractical.
a simple differential testing approach c2v tried to uncover coverage bugs by comparing the coverage profiling results of the same input program over two different profiler implementations e.g.
gcov and llvm cov .
for instance if gcov and llvm cov provide different coverage information for the same statement of the profiled program a bug is reported.
due to the inconsistency of coverage semantics defined by different profiler implementations it is rather common that independently implemented coverage profilers exhibit different opinions on the code line based statistics e.g.
the case in figure this essentially contradicts the fundamental assumption of differential testing that distinct coverage profilers should output identical coverage statistics for the same input program.
approach to tackle the flaws of the existing approach this paper presents cod a fully automated self validator of coverage profilers based on the metamorphic testing formulation .
instead of comparing outputs from two independent profilers cod takes a single profiler and a program p either from a compiler s test suite or generated randomly as input and uncovers the bugs by identifying the inconsistency of coverage results from pand its equivalent mutated variants whose coverage statistics are expected to be identical .
the equivalent program variants are generated based on the assumption that modifying unexecuted code blocks should not affect the coverage statistics of executed blocks under the identical profiler which should generally hold in a non optimized setting1.
this idea originates from emi a metamorphic testing approach which is targeted at compiler optimization bugs.
specifically assuming that the compiler is correct2and given a deterministic program punder profiling either from a compiler s test suite or generated randomly and fixate its input cod obtains a reference program p primeby removing the unexecuted statements in p.p primeshould strictly follow the same execution path as long as the coverage profiling data of p is correct.
therefore cod asserts that the coverage statistics should be exactly the same over all unchanged statements 1according to the developers coverage statistics are only stable under zero optimization level.
2we assume this because mis compilations are rare.
34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
inpandp prime.
however consider a line of code sinpand p prime for which the same profiler reported different coverage results i.e.
cp s negationslash cp prime s wherecp s refers to the profiled runtime execution count of statement sin program p. the execution count cp s is usually a nonnegative number except for a special value 1indicating the unknown coverage information.
this could happen when the coverage profiler failed to obtain the coverage information of statement sdue to the information loss caused by the abstraction gap between the source code and the intermediate code transformed during compilation.
given cp s negationslash cp prime s either of the two cases applies strong inconsistency cp s cp prime s meaning that the coverage profiler reports the inconsistent coverage information.
definitely there is a bug in the profiler because p primeshould follow exactly the same execution path as passuming that the coverage statistics of program pare correct.
weak inconsistency cp s cp prime s indicating an inaccurate statistics because that a noninstrumented line is actually executed in its equivalent.
this is also for sure a bug because non optimized coverage statistics should faithfully reflect the program s execution path.
the self validator cod fully exploits the inconsistencies between path equivalent programs with zero false positive.
cod addresses the limitation of c2v in section ii c and handles weak inconsistencies whereas c2v has to ignore all weak inconsistencies between independent profiler implementations to avoid being flooded by false positives.
it is worth noting that such a technique of obtaining path equivalent programs firstly known as emi was proposed to validate the correctness of compiler optimizations .
we found that this idea is also powerful in the validation of coverage profilers.
nevertheless cod differs from emi as we proposed the specialized mutation strategies to acquire the program variants and adopted the results verification criterion in particular for testing coverage profilers.
we defer to section vfor the comparison details.
results we implemented cod as a prototype and evaluated it on two popular coverage profilers namely gcov and llvm cov integrated with the compiler gcc and llvm respectively.
as of the submission deadline a total of potential bugs for gcov for llvm cov are uncovered within months among which bugs have already been confirmed by the developers.
promisingly all the detected bugs are new bugs according to the developers feedback.
outline the rest of the paper is organized as follows.
we introduce the necessary background and a brief motivation in section ii.
section iiielaborates on the detailed approach followed by the evaluation in section iv.
we discuss related work in section vand conclude the paper in section vi.ii.
b ackground and motiv ation a. coverage profilers code coverage profiling data each line of code s execution count in a program execution is the foundation of a broad spectrum of software engineering practices.
code coverage is the most widely adopted criteria for measuring testing thoroughness and is also widely used in the automation of software engineering tasks.
for example test input generation techniques leverage code coverage to guide search iterations fault localization techniques use code coverage to isolate potentially faulty branches .
to obtain code coverage statistics a code coverage profiler maintains each source code line an execution counter and updates them along with the program execution.
specifically given a program p a coverage profiler runs pand outputs each line of code s p a number cp s n indicating that swas executed ntimes.
a special value n 1indicates that the profiler provides no coverage information for this line.
where should a profiler report a coverage statistics for a line of codes i.e.
whether cp s is not well defined.
code transformations e.g.
expansion of macros or compilation from source code to intermediate code and optimizations may lead to cp s 1for a line and different profilers generally have different opinions upon which lines would have cp s .
later we see that this is a major limitation of existing techniques for validating coverage profilers.
b. v alidating coverage profilers validating the correctness a coverage profiler is challenging because it is labor intensive to obtain the ground truth of coverage statistics.
though we have large number of test inputs any program used to test a compiler also works in testing a profiler lacking of a test oracle became the problem.
the only known technique to uncover coverage profiler bugs isc2v which is based on differential testing .
given a programpunder profiling c2v profiles it using two independently implemented profilers to obtain for each statement sthe coverage statistics cp s andc prime p s .
whencp s negationslash c prime p s an inconsistency is found.
when cp s c prime p s a strong inconsistency c2v reports it as a bug candidate and uses clustering to filter out potential false positives and duplicates.
c. limitations of differential testing though being effective in uncovering coverage profiler bugs differential testing also has the following major limitations first differential testing cannot be applied when there is only a single coverage profiler .
this is the case for many mainstream programming languages e.g python and perl .
second differential testing requires heavy human efforts on analyzing the reports because it is hard to determine which one is faulty when two profilers disagree on the statistics of a line of code.
third differential testing miss many potential bugs on weak inconsistencies .
two profilers can have inconsistent but both authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
check1 intmain switch case8 check1 break default abort break check1 return0 intmain check1 check1 switch check1 check1 case8 check1 break check1 default abort check1 break check1 check1 return0 check1 intmain check1 check1 switch check1 check1 case8 check1 break check1 default abort break check1 check1 return0 check1 a cp gcov b cp llvm cov c cp s8 s prime llvm cov fig.
.
the bug case of llvm .
llvm cov incorrectly reported that the break in line is executed.
this bug cannot be detected by differential testing because gcov does not provide coverage statistics for line .
visual conventions of coverage statistics for a line of code s gcov and llvm cov output coverage statistics cp s in the first and second column respectively.
a 1denotes that the profiler does not provide coverage information of s.a check mark or cross mark followed by a number ndenotes that cp s n. correct interpretations over the coverage statistics.
section iv reveal that .
of inconsistencies found by differential testing are weak i.e.
cp s negationslash c prime p s withcp s c prime p s .
our motivating example in figures a b showed that for lines exactly one of gcov or llvm cov provides no coverage information.
unfortunately c2v has to ignore allof such weak consistencies i.e.
not report any of them as a bug because the vast majority of them are attributed to the feature of independently implemented profilers.
finally differential testing reports false positive even when two profilers report strongly inconsistent coverage statistics because two profilers may disagree over the definition of the execution count of a line e.g.
whether the initialization code of afor loop counts for one time of execution.
d. motivation the key observation leading to automatic self validation of a single profiler is that changing unexecuted statements in a program should not affect the coverage statistics .
take the program in figure a b as an example.
suppose that we comment out the function call in line of pand obtain p prime p s8 s prime as shown in figure c we assert that unchanged statements should have identical coverage statistics i.e.
s p p prime.cp s cp prime s reasonably assuming that pis deterministic contains no undefined behavior and does not depend on external environment the coverage statistics is correct and the executions of pandp primeare consistent with their semantics.
since we only remove unexecuted statements reported by a coverage profiler pandp primeshould be semantically equivalent.
furthermore a profiler particularly under minimal optimization should be self consistent in terms of which statement should have a coverage statistics.
therefore if there is an inconsistency cp s negationslash cp prime s no matter whether it is a strong or weak inconsistency either of the above assumptions is violated.
it turns out that we should blamebug reportnocoverage report ccoverage report c consistent?
equal?noprogram p program p program pruner coverage profilercoverage profiler output o output o fig.
.
the framework of cod the profiler because we have full control over p thus easily to guarantee it is deterministic and there is little chance that the compiler hardware is defective.
in the motivating example cp s9 negationslash cp prime s9 revealed a previously unknown profiler bug in which llvm cov incorrectly reported an unexecuted break as being executed once.
this bug case is missed by differential testing particularly c2v because all inconsistencies between cp gcov and cp llvmcov are weak lines and .
generally weak inconsistencies between different compiler implementations indicate different compilation strategies thus do not indicate a profiler bug and should not be reported by c2v.
iii.
a pproach a. metamorphic testing a test oracle is a mechanism for determining whether a test has passed or failed.
under certain circumstances however the oracle is not available or too expensive to achieve.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
this is known as the oracle problem .
for example in compiler testing it is not easy to verify whether the generated executable code by a compiler is functionally equivalent to the given source code.
even if the oracle is available manually checking the oracle results is tedious and error prone .
as a matter of fact the oracle problem has been one of the most difficult tasks in software testing .
metamorphic testing mt was coined by t.y .
chen in which can be exploited to alleviate the oracle problem.
based on the existing successful test cases that have not revealed any failure such as running too long or returning abnormal values mt generates follow up test cases by making reference to metamorphic relations mr which are the necessary properties of the target function or algorithm in terms of multiple inputs and their expected outputs.
let us consider a program pimplementing function fon domain d. lettbe an initial successful test case i.e.
t d and the execution output p t equals to the expected value f t .
mt can be applied to generate a follow up test case t prime d base ontand a pre defined mr i.e.
metamorphic relation .
for program p a mr is a property of its target function f. for instance suppose f x sin x then the property sin x sin x is a typical mr with respect to f. hence given a successful test case say t .
mt generates its follow up test case t prime .
and then runs the program overt prime.
finally two outputs i.e.
p t andp t prime are checked to see if they satisfy the expected relation p t p t prime .i f the identity does not hold a failure manifests.
in our work we apply mt to the validation of code coverage profilers.
each program becomes a test case fed to the profilers.
given a program pand the code coverage profiler under testing running pwith an input iwould produce the execution outputoand a coverage report cfrom the coverage profiler the coverage report crecords which lines of code are executed or unexecuted and how many times are executed exactly.
note that this program pis the initial test case according to the notions of mt.
a follow up test program p primecan be generated based on the following mr given a program the unexecuted code can be eliminated since these code has no impact with the execution output or the coverage report specifically for the executed part.
in other words by taking advantage of the coverage informationc we generate p prime a functionally equivalent variant of pby removing the un executed code statements of p. we run p primeon the same input iand obtain the output o primeand coverage resultsc prime accordingly.
a bug can then be discovered if the execution output ois not equal to the new one o prime or there exists inconsistency between the coverage information for executed code inside candc prime.
figure 2shows our framework for the self validation of code coverage profilers.
b. our algorithm based on our formulation we implemented a tool cod for detecting bugs in c code coverage profilers.
cod consists of three main steps extracting output and coverage informa algorithm cod s process for coverage tool validation data the profiler tunder test the program p the input i result reported bugs 1begin step extract output and coverage information 2pexe compile p 3o getoutput execute pexe i 4c t .extractcoverage execute pexe i step generate variants via transformation 5p prime genvariant p c 6p prime exe compile p prime 7o prime getoutput execute p prime exe i 8c prime t .extractcoverage execute p prime exe i step compare outputs and reports first stage ifo negationslash o primethen reportbug second stage else ifinconsistent c c prime then reportbug generate a variant for program punder coverage c 13functiongenvariant program p coverage c 14p prime p foreach s getstmts p cp s do p prime.delete s ifiscompiable p prime then returnp prime else genvariant p c check whether coverages is inconsistent 21functioninconsistent coverage c coverage c prime foreach s c s c primedo ifcp s negationslash c prime p prime s then return true return false tion of a given test program generating equivalent variants based on code coverage report and comparing the outputs and coverage results to uncover bugs.
algorithm 1is the main process of cod.
at the first place cod compiles the program pand profiles the execution information with input ito collect the output o which may correspond to a return value or an exit code and the code coverage information c lines .
it then generates the variant p primewith respect to program p line and collects the respective output o primeand code coverage c prime lines .
finally it compares the outputs together with the code coverage reports to validate the coverage profiler.
a potential bug intis reported if any of them is inconsistent lines .
we discuss each step in details as follows.
extracting coverage information for each test program p we first compile it with particular options to generate the executable binary pexe.
the options enables the compiler authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
to integrate the necessary instrumentation code into the executable.
while executing pexewith input i we obtain the outputoof the program.
meanwhile the code coverage report ccan also be readily extracted by the coverage profiler t. each code coverage report contains the lines of code executed and unexecuted in the test program punder the input i. those statements marked as unexecuted will be randomly pruned for the purpose of generating p s equivalent variants which will be discussed shortly.
cod implemented the supports for both gcov and llvm cov.
take gcov as an example cod extracts coverage information by compiling the program pwith the flag o0 coverage under gcc.
it tells the compiler to instrument additional code in the object files for generating the extra profiling information at runtime.
cod then runs the executable binary under input ito produce coverage report for the program p. generating v ariants via transformation based on the coverage report cfor the original program p its variants are generated line .cod produces the variants by stochastically removing unexecuted program statements from the original program p. specifically for each of these removable lines of code we made a random choice.
as such we obtain a number of variants p primethat should be equivalent to the original program.
the function genvariant lines describe cod s process for generating equivalence mutants via transformation.
note that stochastically removing unexecuted program statements would lead to many uncompilable mutants.
only the compilable ones are returned by genvariant line .
comparing the outputs and coverage reports having the outputs and the coverage reports for the orginal program pand its variants p prime we detect bugs in the code coverage tool tby checking the existence of inconsistency.
more specifically we first compare the outputs of pandp prime.
if they are not identical a potential bug would be reported in the code coverage tool.
otherwise the code coverage reports are further compared to seeking for inconsistencies.
note that only the code coverage of the common lines of code between the programs pandp prime i.e.
those lines of code left in the variant program will be considered for comparison.
if the code coverage reports is not consistent over the common lines a potential bug is reported as well lines .
c. illustrative examples in the following we take our reported three concrete bug examples to illustrate how cod works.
three bugs are newly discovered by cod and confirmed by the gcc developers.
bug example exposed by different outputs figure 3shows a real bug example exposed via different outputs of two equivalent programs in gcov a c code coverage tool integrated in gcc .
figure a and b are the code coverage reports produced by gcov for the original program pand its equivalent program p prime by removing an unexecuted line respectively.
note that all the test programs are reformatted for presentation.
as can be seen a code coverage report is an annotated version of the source code augmentedwith the execution frequency of each line.
the first and second column list the execution frequency and the line number.
the frequency number in the first column indicates that the coverage information is unknown.
in this example we first utilize gcc to compile the program pand then execute it to produce the output and coverage report shown as figure a .
note that the output in this case is .
according to the original code coverage report of p cod decides to remove the 6th statement from the original program resulting in an equivalent program p primeshown as figure b .
next we compile and execute p primeto get the new output and coverage report.
here the output turns to be .
since the outputs of these two program are not equal p andp primeare somehow not equivalent meaning that we actually deleted some executed code.
the code coverage tool wrongly marked some executed statements as not executed.
a potential bug is identified.
we reported this bug to bugzilla.
the gcov developers quickly confirmed and fixed it.
bug example exposed by strongly inconsistent coverage figure 4illustrates another real bug example uncovered by strongly inconsistent code coverage reports between the program and its equivalence variant.
figure a shows the coverage report for p. we can read from it that line is not executed at all i.e.
the execution count is .
cod prunes line to generate the equivalent program p prime.
after compiling and executing p prime another coverage report shown as figure a is produced.
as can be seen there exists an strong inconsistency in term of the execution frequency of line indicating a potential bug.
this bug is submitted and confirmed already by gcov developers.
bug example exposed by weakly inconsistent coverage figure 5presents another confirmed real bug example found via the weakly inconsistent code coverage reports between the program and its equivalent variant.
in figure a line in pis not executed i.e.
the execution count is .
cod gets rid of line to generate the equivalent program p prime.
upon compiling and executing p prime another coverage report shown as figure a is generated.
apparently the weakly inconsistency with respect to the execution frequency of line appears indicating a potential bug.
iv .
e v aluation this section presents our evaluation of cod.
we evaluated cod using the most popular practical code coverage profilers gcov and llvm cov and a set of testing programs for testing compilers and compared the results with existing differential techniquec2v .
a. evaluation setup profilers for v alidation we evaluated cod using the latest versions of gcov and llvm cov the most popular two code coverage profilers of c programs as our experimental subjects.
both profilers are popular in the software engineering community authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
include stdio.h int p a b check1 int foo check1 int r int while r int a p 1 check1 if a b returnr returnr check1 voidmain check1 int r f o o check1 printf d n r check1 include stdio.h int p a b check1 int foo check1 int r int while r int a p 1 check1 if a b returnr returnr check1 voidmain check1 int r f o o check1 printf d n r check1 a cp gcov output b cp s6 s prime gcov output fig.
.
a real bug example exposed by cod via different outputs.
this is bug of gcov .
.
.
in a line is marked as not executed b is the equivalent program by deleting line from the original program in a .
the outputs of these two equivalent programs are not identical indicating a bug in gcov .
.
.
check1 intfoo check1 inth f k check1 inty x y check1 if y!
k x check1 h y ?
check2 if f check1 h else h check1 returnh check1 voidmain foo check1 intfoo check1 inth f k check1 inty x y check1 if y!
k x check1 h y ?
check1 if f check1 h else h check1 returnh check1 voidmain foo a cp gcov b cp s10 s prime gcov fig.
.
a real bug example discovered by cod with confirmed bug id of gcov .
.
.
when the unexecuted line is pruned from the original program in a the code coverage of line is inconsistent between that of the original program and the new program in b which indicates a bug.
a star after a number in line denotes that this number may be inaccurate.
check1 voidfoo intx unsigned u check1 if 1u x !
check1 x !
u x check1 !
builtin abort check1 check1 intmain check1 foo 128u check1 return0 check1 voidfoo intx unsigned u check1 if 1u x !
check1 x !
u x !
builtin abort check1 check1 intmain check1 foo 128u check1 return0 a cp gcov b cp s5 s prime gcov fig.
.
a real bug example discovered by cod with confirmed bug id of gcov .
.
when the unexecuted line is pruned from the original program in a the code coverage of line is weakly inconsistent between that of the original program and the new program in b .
integrated in the most widely used production compilers i.e.
gcc and clang extensive validated by existing research both for the compilers and the profilers.
following the existing research we use the default complier flags to obtain coverage report for gcov and llvm cov under zero level optimization.
given a piece of source code test.c the following commands are used to produce the coverage report test.c.gcov gcc o0 coverage o test test.c .
testgcov test.c for llvm cov we use the following commands to produce the coverage report test.c.lcov clang o0 fcoverage mapping fprofile instr generate o test test.c .
test llvm profdata merge default.profraw o test.pd llvm cov show test instr profile test.pd test.c test.c.lcov evaluation steps to run either differential testing or cod w e obtain code coverage statistics for the test programs authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i statistics of bug triggering testprograms .
profilers different outputsinconsistent reports strong weak gcov llvm cov in the test suite shipped with the latest gcc release .
.
and random programs generated by csmith .
all evaluated programs contain neither external environmental dependency nor undefined behavior.
we run cod over all the test programs and collect all reported inconsistencies for a manual inspection.
we also compare these results with the state of the art differential testing technique c2v .
testing environment we evaluated gcov shipped with the latest version of gcov until gcc .
.
and llvmcov until llvm .
.
svn358899 during our experiments.
all experiments were conducted on a hexa core intel r core tm cpu .20ghz virtual machine with 10gib of ram running ubuntu linux .
.
b. experimental results inconsistent reports for each of the test cases in our testbed only one variant was generated by using cod for the validation.
the only variant is generated by removing all the unexecuted statements reported by coverage profilers from the original test cases.
it is obvious that generating more variants for each test program may trigger more inconsistencies over the test programs and probably detect more bugs in those coverage profilers.
table ishows the statistics of bug triggering test programs over two code coverage profilers under test i.e.
gcov and llvm cov.
column refers to the total number of the pairs of test program with its variant which can lead to different execution outputs and column shows the total number that can impose inconsistent coverage reports.
the single case in which the variant outputs a different value figure is due to the incorrect coverage statistics causing cod to create functionally different equivalent mutated variants.
others inconsistencies also due to profiler bugs which are discussed as follows.
bugs found we manually inspected all cases and found that allreported strong and weak inconsistencies revealed defects in the profiler.
by far we reported a total of bugs to the developers of gcov and llvm cov.
the manual classification and reporting of profiler bugs is still on going.
we believe that more bugs will be reported in the future.
bugs are confirmed3by the developers as listed in table ii.
one of the remaining three is still in the pending 3consistent with c. sun et al s and v .
le et al s studies due to the bug management process of llvm is not as organized as that of gcc if a llvm cov bug report has been cced by clang developers and there is no objection in the comments we label the bug as confirmed.
in addition as stated by developers if someone does not close the reported bug as invalid then the bug is real in llvm bugzilla.table ii list of confirmed or fixed bugs.p n denotes a normal priority .
difftest denotes whether the bug can be found by a differential testing .
id profiler bugzilla id priority status type difftest gcov p3 fixed wrong freq.
check gcov p3 fixed wrong freq.
check gcov p5 new wrong freq.
check gcov p3 fixed wrong freq.
check gcov p3 fixed missing gcov p3 fixed wrong freq.
check gcov p5 new wrong freq.
gcov p5 new wrong freq.
check gcov p5 new wrong freq.
check gcov p5 new spurious gcov p5 new spurious gcov p3 fixed missing gcov p5 new spurious gcov p3 fixed missing check gcov p3 fixed wrong freq.
check gcov p5 new wrong freq.
gcov p3 new wrong freq.
check gcov p3 new wrong freq.
gcov p5 new wrong freq.
gcov p3 new missing llvm cov pn new wrong freq.
check llvm cov pn new spurious llvm cov pn new missing confirmation state one was marked as duplicate and only one was rejected by the developer gcov .
this rejected case is controversial because gcc is performing optimization even under the zero optimization levels as shown in figure which may mislead a developer or an automated tool that are based on the branch information in the coverage statistics.
following the notions from c2v code coverage bugs inside coverage profilers can categorized as spurious marking missing marking and wrong frequency .
as shown in column of table ii we can find that cod is able to detect all three types of bugs in coverage profilers.
bugs belong to wrong frequency bugs belong to missing marking and the rest bugs is spurious .
besides most of bugs are wrong frequency bugs i.e.
the execution frequencies is wrongly reported.
among all these bugs nearly half cannot be manifested by differential testing.
considering that differential testing leverages the coverage statistics of an independent profiler implementation which produces correct coverage information in all these cases and thus differential testing is essentially comparing with a golden version while cod is merely selfvalidation we are expecting cod to be effective and useful in finding code coverage profiler bugs.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
check1 intf inti intres check1 switch i case5 r e s i i break check1 default check1 r e s i check1 break check1 returnres check1 intmain void check1 f check1 return0 check1 intf inti intres switch i case5 res i i break default check1 r e s i check1 break check1 returnres check1 intmain void check1 f check1 return0 a p gcov b p prime p s5 s6 s prime s prime gcov fig.
.
in the case of gcov gcov refuses to report coverage information for the case statement after removing lines but reports the execution of its default branch which may mislead a developer or an automated tool.
note that though line is not covered it is not removed otherwise will result in a compilation error.
table iii summary of the test programs with inconsistent coverage reports by codon the consistent test programs by c2v.
weakly consistent under c2v inconsistent in terms of cod gcov llvm cov strong weak strong weak c. discussions statistics of inconsistencies table iiisummarizes the test programs in which inconsistencies are identified by cod but unable to be identified by c2v.
all these inconsistencies are true positives one is either a bug or may mislead a developer or automatic tool.
while using these test programs to test gcov by cod w e respectively identified weak and strong inconsistencies from these test programs.
for llvm cov weak and strong inconsistencies are identified.
this indicates that cod has its unique ability to identify many inconsistencies that c2v unable to given the same test programs.
we thus believe that cod is more powerful and useful than c2v.
weak inconsistencies between independently implemented coverage profilers as aforementioned independently implemented code coverage profilers might have different interpretations for the same code.
this is the major source of weak inconsistencies thatc2v cannot recognize as a bug.
to further understand weak inconsistencies among profilers we collect the common instrumentation sites between gcov .
.
and llvm cov .
for the test programs using programs in gcc testsuites .
.
.
a code line sis a common instrumentation site s cifcg p s negationslash cl p s negationslash where cg p s andcl p s refer to the profiled runtime execution count of code line sin program prespectively by gcov and llvmcov.
when cg p s negationslash cl p s cg p s cl p s sis an non common instrumentation site s c.table iv summarization of the common and non common instrumentation sites between gcov and llvm cov for the test programs in gcc testsuites .
.
.
c c number of common non common instrumentation sites .
cc total avg.
total avg.
.
.
.
.
only test programs in gcc testsuites .
.
can be successfully compiled and further processed by both gcov and llvm cov.
table ivsummarizes the total number and total percentage of common instrumentation sites and non common instrumentation sites.
the second and the forth columns respectively show the total number percentage candc.
the third and the last columns respectively shows the average c andc.
from table iv we can found that about code lines arecand each test program has about code lines are c. table vsummarizes the statistics of the proportion of cfor the test programs in gcc testsuite .
.
.
we calculate the proportion as p c c c for each test program.
then we can obtain how many test programs falls into different intervals as listed in the second row of table v. from table v we can find that about code lines in most test programs are in c. this indicates that most code lines of each program is instrumented by only one of the two coverage profilers.
besides we also found that only .
test programs have exactly the same instrumentation sites under the two profilers.
overall our core observation is that different coverage profilers indeed have quite different interpretations on a same piece of code.
reliability of code coverage profilers under compiler optimizations finally even though coverage profilers provide only faithful statistics under the zero optimization level we authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table v distribution of the percentage of non common instrumentation sites .
p c c c the proportion of non common instrumentation sites .
p .
.
.
.
.
.
.
.
.
.
.
table vi summary of inconsistent reports with different optimization levels .
optimization levelinconsistent lines gcov llvm cov strongly weakly strongly weakly o0 o1 o2 o3 os ofast still wonder whether inconsistencies reported by cod for optimized binaries may reveal bugs in a profiler.
therefore we conducted our experiments under optimized compiler settings and the results are summarized in table vi.
after the manual inspection of a few cases we found that gcov generally does notprovide comprehensive coverage statistics for optimized code sometimes even obviously wrong however llvm cov is much more reliable coverage statistics barely change across optimization levels.
we attempted to report such an obviously incorrect coverage statistics of gcov to the developers as shown in figure gcov under o3 optimization level .
line cannot be executed for times in any circumstance however the developer rejected this bug report and argued that it s the nature of any optimizing compiler.
if you want to have the best results then don t use o3 or any other optimization level.
this case is also controversial however revealed that providing guarantee of coverage statistics under compiler optimizations would be a worthwhile future direction.
v. r elated work this section surveys some related work on coverage profiler testing metamorphic testing testing via equivalence module inputs and techniques relied on code coverage.
a. code coverage profiler testing to the best of our knowledge c2v is the first and also the state of the art work for hunting bugs in code coverage profilers.
it feeds a randomly generated program to both gcov and llvm cov and then reports a bug if there exist inconsistencies between the produced coverage reports.
within noncontinuous four months of testing c2v uncovered bugs among which and bugs are confirmed fixed by gcov and llvm cov respectively.
in essence c2v is a randomized differential testing approach.
as stated in section ii c c2v suffers from a bunch of drawbacks.
the work presented in this paper attempts to fill the gap.
b. metamorphic testing as a simple but effective approach to alleviating the oracle problem metamorphic testing mt exploits the metamorphic relation mr among multiple inputs and their expected outputs to generated follow up test cases from existing ones and verifies the corresponding outputs against the mr. since its first publication in mt has been successful applied in a variety of domains including bioinformatics web services embedded systems components databases machine learning classifiers online search functions and search engines and security .
several representative work are listed below.
chan et al.
presented a metamorphic testing methodology for service oriented applications soa .
their method relies on so called metamorphic services to encapsulate the services under test executes the seed test and the followup test cases and finally check their results.
zhou et al.
employed metamorphic testing to detect inconsistencies in online web search applications.
several metamorphic relations are proposed and utilized in a number of experiments with the web search engines like google yahoo!
and live search.
jiang et al.
presented several metamorphic relations for fault detection in central processing unit cpu scheduling algorithms.
two real bugs are found in one of the simulators under test.
beydeda proposed a selftesting method for commercial offtheshelf components via metamorphic testing.
zhou et al.
applied metamorphic testing to self driving cars and detected fatal software bugs in the lidar obstacleperception module.
chen et al.
presented several metamorphic relations for the detection of faults in two opensource bioinformatics programs for gene regulatory networks simulations and short sequence mapping.
in this paper we applied mt to a new domain i.e.
validating the correctness of coverage profilers.
c. testing via equivalence modulo inputs testing via equivalence modulo inputs emi is a new testing technique proposed in recent years being targeted at discovering the compiler optimization bugs.
the basic idea of emi is to modify a program to generate variants authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
intfunc int p check11 intx for inti i i check10 x p check1 returnx check1 intmain check1 inta check11 for inti i i check10 a check11 if func a !
return1 return0 intfunc int p check1 intx for inti i i x p check1 returnx check1 intmain check1 inta check1 for inti i i a check1 if func a !
return check1 return0 a p gcov b p prime p s12 s prime gcov fig.
.
the bug case of gcc .
gcov incorrectly reported that the if func a !
in line was executed times.
deleting line revealed this bug.
with the same outputs as the original program.
initially le et al.
proposed to generate equivalent versions of the program by profiling program s execution and pruning unexecuted code inside.
once a program and its equivalent variant are constructed both are fed to the compiler under test and the inconsistencies of the outputs are checked.
following this work athena and hermes are developed subsequently.
athena generates emi by randomly inserting code into and removing statements from dead code regions.
hermes complements mutation strategies by operating on live code regions which overcomes the limitations of mutating dead code regions.
incod we followed the similar way to generate program variants as emi did but focused on validating the correctness of coverage profilers instead of optimization bugs in compilers.
as such during the results verification cod not only checked the inconsistencies in terms of the outputs but more importantly the coverage reports.
through our evaluations it is also shown that only few bugs among confirmed bugs can be discovered by looking at only the outputs.
moreover different from emi performing a random modification cod mutates the original program by aggressive statement pruning thus triggering different coverage behaviors as much as possible.
d. techniques relied on code coverage code coverage is widely adopted in practice and extensively used to facilitate many software engineering tasks such as coverage based regression testing coverage based compiler testing and coverage based debugging.
in the context of regression testing test case prioritization and test suite augmentation are the two widely used techniques .
the former aims to improve the ability of test cases in finding faults by scheduling test cases in a specific order .
to achieve a high code coverage as fast as possible is a common practice .
the latter is to generate new test cases to strengthen the ability of a test suite in finding faults .
in practice it is often to generate new test cases to cover the source code affected by code changes.
recent years have seen an increasing interest in compiler testing which aims to validate the correctness of compilers.one of the most attractive compiler testing techniques is based on the code coverage of a program s execution to generate equivalence modulo inputs by stochastically pruning its unexecuted code .
with the equivalence modulo inputs we can differentially test compilers.
it is obvious that the correctness of equivalance relies on the reliability of code coverage.
debugging is a common activity in software development which aims to locating the root cause of a fault.
spectrum based fault localization sbfl is one of the most extensively studied debugging techniques which is heavily based on code coverage .
under a specific test suite sbfl leverages the code coverage and the corresponding failed passed information to statistically infer which code is the root cause of a fault.
as we can see the correct code coverage information is one of the prerequisites for the techniques above indicating the importance of our work.
vi.
c onclusion this paper presents cod an automated self validator for code coverage profilers based on metamorphic testing.
cod addressed the limitation of the state of the art differential testing approach and encouragingly found many previously unknown bugs which cannot be revealed by existing approaches.
acknowledgment we thank the anonymous reviewers for their constructive comments.
we also thank the gcc and llvm developers especially martin li ska for analyzing and fixing our reported bugs.
this work is supported by the national key r d program of china 2018yfb1003901 the national natural science foundation of china the natural science foundation of jiangsu province bk20191247 bk20170652 the china postdoctoral science foundation 2018t110481 the fundamental research funds for the central universities .
we would also like to thank the support from the collaborative innovation center of novel software technology and industrialization jiangsu china.
yuming zhou and baowen xu are the corresponding authors.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.