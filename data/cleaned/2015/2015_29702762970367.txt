multi objective test report prioritization using image understanding y ang fengy james a. jonesy zhenyu chen chunrong fang ydepartment of informatics university of california irvine usa state key laboratory for novel software technology nanjing university nanjing china yang.feng jajones uci.edu zychen nju.edu.cn abstract in crowdsourced software testing inspecting the large number of test reports is an overwhelming but inevitable software maintenance task.
in recent years to alleviate this task many text based test report classi cation and prioritization techniques have been proposed.
however in the mobile testing domain test reports often consist of more screenshots and shorter descriptive text and thus text based techniques may be ine ective or inapplicable.
the shortage and ambiguity of natural language text information and the well de ned screenshots of activity views within mobile applications motivate our novel technique based on using image understanding for multi objective test report prioritization.
in this paper by taking the similarity of screenshots into consideration we present a multi objective optimization based prioritization technique to assist inspections of crowdsourced test reports.
in our technique we employ the spatial pyramid matching spm technique to measure the similarity of the screenshots and apply the natural language processing technique to measure the distance between the text of test reports.
furthermore to validate our technique an experiment with more than test reports and images is conducted.
the experimental results show that imageunderstanding techniques can provide bene t to test report prioritization for most applications.
ccs concepts software and its engineering !maintaining software keywords crowdsourced testing test report prioritization image understanding multi objective optimization .
introduction crowdsourced techniques have recently gained wide popularity in the software engineering research domain .
oneof the key advantages of crowdsourced techniques is that they can provide engineers with information and operations of real users and those users provide data from tasks performed on real diverse software and hardware platforms.
for example crowdsourced testing e.g.
beta testing provides validation data for a large population of varying users hardware and operating systems and versions.
such bene ts are particularly ideal for mobile application testing which often needs rapid development and deployment iterations and support many mobile platforms.
in addition crowdsourced mobile testing can provide developers with real users feedback new feature requests and user experience information which can be di cult to obtain through conventional software testing practices.
for these reasons several successful crowdsourcing mobile testing platforms such as utest 1testin 1and appstori1 have emerged in the past ve years .
typically crowdsourced workers provide information for developers in the form of test reports which may consist of screenshots and textual content.
due to the inherent nature of crowdsourced testing which usually involves a large number of users the number of test reports can be great and the resulting task of inspecting those test reports can be quite time consuming and expensive.
as such it is natural for developers to seek methods to assist in identifying and prioritizing new and useful information.
in the past decades to alleviate tedious test report inspection researchers have proposed many full or semi automatic methods in which they mainly focused on the problems of duplicate report identi cation report classi cation and report prioritization.
to reduce the costs of inspecting duplicate test reports techniques have been proposed and widely used such as bugzilla1and mantis.1similarly report classi cation techniques have been proposed to group similar reports so that ideally an expert would only need to sample some reports from each group to gain a su cient understanding of the bugs that they represent .
finally prioritization techniques have gained wide attention in the software testing domain.
feng et al.
rst proposed the concept of prioritization of crowdsourced testing reports.
instead of attempting to reduce the time cost of inspecting the basic assumption of prioritization techniques is the earlier a bug is detected the cheaper it is to remedy which implies that all of the reports will be eventually inspected.
in almost all such techniques the test reports are captured and analyzed based on their textual similarity e.g.
1utest.com itestin.com appstori.com bugzilla.org mantisbt.org permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
or based on their execution traces e.g.
.
for software designed for a desktop computer such techniques are likely su cient.
however for mobile software writing long and descriptive test reports may be more challenging on a mobile device keyboard.
in fact test reports written from mobile devices tend to be shorter and less descriptive but also to include more screenshots primarily due to the ease of taking such screenshots on mobile platforms .
due to this paucity of textual information for test reports and also due to the ambiguity of natural language and prevalence of badly written reports utilizing the screenshots to assist with such mobile crowdsourced testing techniques is appealing.
moreover the activity views of typical mobile applications often provide distinguishable aspects of the software interface and feature set and provide more motivation for utilizing such screenshots.
in this paper we proposed an approach to test report prioritization that utilizes a hybrid analysis technique which is both text based and image based.
this approach is a fully automatic diversity based prioritization technique to assist the inspection of crowdsourced mobile application test reports.
to facilitate this we capture textual and image information and measure the similarity among these artifacts.
for the image analyses we employed the spatial pyramid matching spm technique to measure the similarity of screenshots.
for the textual analyses we used naturallanguage textual analysis techniques to measure the similarity of textual descriptions within test reports.
finally we combine these similarity results using a multi objective optimization algorithm to produce a hybrid distance matrix among all test reports.
based on these results we prioritize the test reports for inspection using a diversity based approach with the goal of assisting developers of nding as many unique bugs as possible as quickly as possible.
to evaluate this proposed hybrid test report prioritization technique we implemented the technique and conducted an experiment.
the experiment was conducted with three companies and more than students who simulated the crowdsourcing of testing of ve widely used mobile applications.
in all we received and analyzed crowdsourced test reports from the crowd workers.
we assessed e ectiveness of our technique using the average percentage of faults detected apfd metric and the fault detection rate.
to serve as our baseline e ectiveness results we calculated the results of two strategies an ideal strategy which is a bestcase ordering to nd all bugs in the shortest order possible and a random strategy which is a random ordering.
the results of our empirical study shows that screenshots are critical in the test report of mobile application which could signi cantly improve the e ectiveness of the prioritization technique and the e ciency of test report inspection for certain classes of mobile applications our multiobjective optimized prioritization technique can outperform the single image based optimized technique the text based optimized technique as well as the random technique.
the main contributions of this paper are as follows to the best of our knowledge this is the rst work to take the image information as well as the text information of test reports into consideration to assist the inspection procedure.
a novel multi objective optimization based technique is proposed to combine the image similarity and textsimilarity which improves the e ectiveness and e ciency of test report maintenance.
five mobile applications with more than screenshots are used to evaluate our test prioritization techniques.
based on the experimental results and our experiences we provide some practical guidance for crowdsourced mobile test report prioritization.
.
background test and bug report resolution.
software maintenance activities are known to be generally expensive and challenging.
one of the most important maintenance tasks is bugreport resolution.
however current bug tracking systems such as bugzilla mantis the google code issue tracker the github issue tracker and commercial solutions such as jira rely mostly on unstructured natural language bug descriptions.
these descriptions can be augmented with les uploaded by the reporters e.g.
screenshots .
although test descriptions and execution traces are currently used to characterize and analyze test reports how to involve screenshots remains unsolved.
speci cally for mobile crowdsourced testing the reporters often prefer to provide only short text descriptions along with necessary screenshots.
in this situation how to combine short text processing with image processing is important for test report prioritization.
arti cial intelligence and computer vision researchers created a class of analyses classi ed as image understanding which extracts features from images and uses them for analysis.
within the software engineering research domain imageunderstanding techniques have been used in cross browser issues for web applications.
cai et al.
propose the vips algorithm which segments a web page s screenshot into visual blocks to infer the hierarchy from the visual layout rather than from the dom.
choudhary et al.
proposed a tool called webdiff to automatically identify cross browser issues in web applications.
given a page to be analyzed the comparison is performed by combining a structural analysis of the information in the page s dom and a visual analysis of the page s appearance obtained through screen captures.
however to date there has been no work that addresses the use of screenshot images for use with test reports particularly for mobile test reports produced by crowd workers in crowdsourced testing.
unfortunately the crowd workers tend to describe bugs with a direct screenshot and short descriptions rather than verbose and complex text descriptions.
at the same time the developers are also interested in screenshots rather than inspecting the workers long natural language descriptions.
but due the complexity of image understanding there is a paucity of study on automated processing of screenshots in crowdsourcing testing.
in this paper we overcome the di culties in understanding the screenshots by applying advanced image matching techniques.
image understanding.
image matching is an important problem in the area of computer vision.
matching images of real world objects is particularly challenging as a matching algorithm must account for factors such as scaling lighting and rotation.
fortunately the images that we compare in this work are screen captures of application views rendered by di erent devices by di erent workers for di erent apps.
in 203report screenshots text description keyword vector nlp feature histogram spm balance formula chi square screenshot distance matrix word set distance matrix balanced distance identify the similar ones jaccard screenshot set distance matrix jaccard extract verbs and nouns figure test report processing framework this context the above issues are ameliorated and the main problems are for instance the shifting of gui elements or the fact that some elements are not displayed at all.
a basic technique for comparing two images is to compare their histograms where an image histogram represents the distribution of the value of a particular feature in the image .
in particular a color histogram of an image represents the distribution of colors in that image i.e.
the number of pixels in the image whose color belongs in each of a xed list of color ranges or bins .
obviously if two images are the same their color distributions will also match.
although the converse is not true and two di erent images can have the same histogram this issue is again not particularly relevant in our problem domain.
.
technique framework this section elaborates the details of our method.
we assume the test reports only consist of two parts text description and screenshots which we will handle separately and nally generate the balanced distance.
figure shows the framework of calculating the distance between the test reports which mainly contains three steps screenshotset distance calculation test description distance calculation and distance balancing.
after we compute the distance matrix from the test report set we apply various strategies to prioritize test reports.
.
preliminary even though in practice there could be other multimedia information that exists in the mobile test reports such as the short operation videos and voice messages our experience indicates that text descriptions and screenshots are the most widely used types of information.
in this paper we focus on the processing of mobile screenshots to assist the test report prioritization procedure.
we assume each of the test reports only consists of two parts a text description and a set of screenshots i.e.
the test report set r r fr si ti ji ng in which sdenotes the screenshots i.e.
images containing the views that may capture symptoms of the bug being reported and tdenotes the text describing the buggy behavior.
.
test description processing the processing of text consists of two steps keywords set building and distance calculation.
because naturallanguage processing nlp techniques have been widely used to assist various software engineering tasks e.g.
we focus our description below on the distinguishing features and implementation choices of our approach.keywords set building.
in order to extract the keywords from the natural language description we rst need to segment the text.
fortunately word segmentation is a basic nlp task and as such many e cient tools for word segmentation for di erent natural languages have been implemented .
in our method we adopted the language technology platform ltp which is the most widely used chinese nlp cloud platform to process the chinese text descriptions.
ltp segments the text parts of test reports and marks each word with its part of speech pos for its context.
in this procedure ltp used the conditional random fields crf model to segment chinese words and adopted the support vector machine svm approach for tagging the pos.
after we compute the segmentation results with the pos tags we lter out relatively meaningless words that could negatively impact the distance calculation.
according to prior works e.g.
verbs and nouns can reveal the main information of a document.
so to simplify the technique we extract only the nouns and verbs to build the keywords sets.
it is worth noting that our technique should not be limited to only the chinese language.
by applying other nlp tools such as the stanford nlp toolkit 3similar text models can be built for text descriptions written in other languages such as english french or german.
however di erent natural languages have di erent characteristics and may need special accommodations.
for example languages with relatively more prevalent polysemy i.e.
many possible meanings for a word or phrase and synonyms may require special processing such as synonym detection and replacement to avoid negative impacts on analyses.
distance calculation.
our method focuses on processing mobile test reports.
compared with the test reports of desktop or web applications one characteristic of typical mobile test reports and based on our experience is that their text descriptions are shorter and contain more screenshots.
as such we treat all of the words in the text description equally and we adopted the jaccard distance to measure the di erence between the text descriptions tiin the test report set r r .
the de nition of jaccard distance used in our technique is presented in the following equation in which ki denotes the keyword set of test report ti anddt ri rj denotes the distance between the text portion of the test reportsriand report rj.
dt ri rj jki kjj jki kjj a playing b playing c lyrics d lyrics figure four example screenshots from the test reports of the cloudmusic application.
a and b are screenshots of the playing view and c and d are screenshots of the lyrics view of two di erent songs.
.
screenshot processing compared with nlp techniques image understanding techniques are relatively less studied and used in the softwareengineering domain.
one of our motivations of conducting this research is to proposed a method to extract the information from images to assist software engineering tasks.
the work ow of processing screenshots sis presented in the top branch of figure.
.
the process is composed of three key steps to build up the distance between screenshot sets building feature histograms calculating distance between individual screenshots and computing the distance between screenshot sets.
feature histogram building.
in order to compute the di erence between the screenshots we convert the screenshots into feature vectors.
bug screenshots provide not only views of buggy symptoms but also app speci c visual appearances.
we hope to automatically identify application behaviors based on their visual appearance in the screenshots.
however the screenshots often have variable resolution and complex backgrounds.
therefore modeling the similarity between the screenshots merely based on rgb is not an approach that is well suited for our task.
to address the challenges we apply the spatial pyramid matching spm to build a global representation of screenshots.
since the details of spm are beyond this paper s topic we only brie y introduce it here.
given an image spm partitions it into sub regions in a pyramid fashion.
at each pyramid level it computes an orderless histogram of low level features in each subregion.
after decomposition it concatenates statistics of local features over sub regions from all levels.
after building the spatial pyramid representation we apply kernelbased pyramid matching scheme to compute feature correspondence in two images.
figure presents four original and actual screenshots from four test reports of a popular chinese music playing app cloudmusic.
figures 2a and 2b show the music playing view of the application and figures 2c and 2d show the lyrics view.
note that in each screenshot the details of the view di er e.g.
di erent music is playing di erent background images appear di erent lyrics are shown and even the screen size is di erent for the last image.
the layout of screenshots and background colors di er and provide challenges for correct matching although figures 2a and 2b have the same view layout figures 2b and 2d share a similar background color.
if we were to directly calculate distance based on the rgb histograms we would incorrectly .
.
.
.
.
featurevalue a playing .
.
.
.
.
featurevalue b playing .
.
.
.
.
featurevalue c lyric .
.
.
.
.
featurevalue d lyric figure the corresponding feature histograms of the screenshots in figure .
table distance between screenshots of figure playing playing lyrics lyrics playing .
.
.
playing .
.
.
lyrics .
.
.
lyrics .
.
.
get a closer distance between figures 2b and 2d.
nevertheless the image understanding technique should be able to capture the similarities of the the similar views.
intuitively figures 2a and 2b should be identi ed as similar views and figures 2c and 2d should be identi ed as similar views.
based on the four images spm rst builds the histograms of features for each of image.
the resulting histograms for these images are shown in figure .
screenshot distance calculation.
using the screenshot feature histograms a distance is computed for each pair of images.
to compute such distances between feature histograms we adopt the chi square distance metric .
the chi square metric is generally used to compute the distance between two normalized histogram vectors i.e.
their elements sum to .
also both of the pairwise histograms being compared should contain the same number of bins i.e.
the vectors should have the same number of dimensions .
we usehi x1 x2 x n to denote the feature histogram of screenshot si andhi xk to denote the value of kth feature ofsi.
the formula used to calculate chi square distance ds si sj between screenshot siandsjis de ned as follows ds si sj hi hj 2dx k hi xk hj xk hi xk hj xk based on equation we obtain the distance matrix shown in table from the feature histograms of figure .
these results show that the calculated distance between the same views playing and playing and lyrics and lyrics have relatively shorter i.e.
smaller distances .
between playing screenshots and .
between lyrics screenshots than the across view distances.
screenshot sets distance calculation.
the previous step uses the chi square distance metric to compute distances between pairs of screenshots.
however in practice 205each test report may contain more than one screenshot.
so in this step we compute the distance between screenshot sets.
to account for the diversity of display resolutions of mobile devices and user content e.g.
songs backgrounds we set a threshold to assess screenshots that match.
the threshold is rst used to nd representative members from within the same screenshot set i.e.
from the same test report .
screenshot subsets whose histograms produce chisquare distances that are below the distance threshold i.e.
assessed as representing the same situation are rst represented as an aggregated summary histogram which is computed as the mean of the feature histograms from the constituent members.
once the representative set of screenshots are selected from each test report the chi squared metric with the metric is again used to compute the across test report screenshot similarity between the representative screenshots.
again for screenshots i.e.
their representative histograms whose distance is less than they are assessed as representing the same view and as such the similar and non similar screenshots from each test report can be used to calculate the intertest report screenshot set distance for a pair of reports.
for this calculation we use the jaccard distance metric.
for the test reports riandrjand their respective screenshot sets si andsj the distance metric is de ned as ds ri rj jsi sjj jsi sjj note that in the special case where both siandsjare the empty set i.e.
no screenshots were included for either test report we assess dsto be zero.
.
balanced formula based on above distance computations for both the textual descriptions and the screenshot sets we combine these distances to produce a hybrid distance.
we present equation to combine these di ering distance values.
equation is a step wise formula where the rst condition holds for when the textual descriptions are assessed to be identical by way of the text distance formula dt.
in this case we assess the balanced distance metric to be similarly identical.
in the next step where ds where typically no screenshots were included for either test report the textual di erence is used and scaled to make them more similar and thus less diverse.
this diversity adjustment will make these less descriptive test reports less likely to be highly prioritized in the next prioritization step.
in the nal step which holds in all other cases the harmonic mean is calculated between the textual distance dtand screenshot set distance ds.
the resulting balanced distance bdis used to represent the pairwise distance of the corresponding test reports.
bd ri rj ifdt ri rj dt ri rj ifds ri rj ds ri rj dt ri rj 2ds ri rj dt ri rj otherwise .
diversity based prioritization using the computed balanced distance measures for all test reports we can prioritize the test reports for inspection by developers.
the guiding principle of our prioritization approach is to promote diversity of test reports that getinspected.
in other words when a developer inspects one test report the next test reports that she inspects should be as di erent as possible to allow her to witness as many diverse behaviors and bugs as possible in the shortest order.
this diversity based prioritization strategy has been used by other software engineering researchers for test prioritization e.g.
.
the goal is for software engineers to nd as many bugs as possible in a limited time budget.
givenqdenotes the result queue the distance between a test report randq denoted byd r q is de ned by the minimal distance between rand eachriinq i.e.
d r q min ri2qfd r ri g. the algorithm of bddiv is shown in algorithm .
in the beginning qis empty we rst initialize the algorithm by randomly choosing one report from rand append it to q. the second step is to calculate the distance between each test report ri2randq.
as soon as we get the distance values we choose the largest one to append to q. the whole procedure completes when jrj .
algorithm bddiv bd r q ?
randomly choose a test report rkfromr appendrctoq r r frkg whilejrj6 0do maxdis rc null for allri2rdo mindis for allrj2qdo ifbd ri rj mindis then mindis bd ri rj end if end for ifmindis maxdis then maxdis mindis rc ri16 end if end for appendrctoq r r frcg end while returnq .
experiment in our experiment we propose the following three research questions rq1 can test report prioritization substantially improve test report inspection to nd more unique buggy reports earlier?
rq2 to what extent can the image based approaches improve the e ectiveness of the text only based approach?
rq3 how much improvement is further possible compared to a best case ideal prioritization?
if the software engineers have no test report prioritization technique they may randomly inspect test reports in a non systematic order.
rq1 is designed to inform whether prioritization of test reports is in fact advantageous.
to address the rq1 we conduct the experiment to evaluate the e ectiveness of our prioritization techniques alongside arandom based strategy.
rq2 is designed to investigate whether image understanding techniques can assist the inspection procedure compared with the text only based technique.rq3 is designed to investigate the gap between the performance of our techniques and the theoretical ideal prioritization technique which could be helpful to engineers in 206table experimental software subjects name versionjrjjfjjsjjrsjjrfj se .
.
cloudmusic .
.
ubook .
.
ishopping .
.
justforfun .
.
totals selecting proper techniques in practice and inform the future research in this eld.
.
software subject programs from november to january we collaborated with three companies and more than students to simulate a crowdsourced testing process.
the ve applications on which we simulated crowdsourced testing are as follows justforfun a picture editing and sharing application produced by dynamic digit.
ishopping a shopping application for taobao produced by alibaba.
cloudmusic an application for free sharing music as well as a music player produced by netease.
se a monitoring application for a power supply company produced by panneng.
ubook an application for online education produced by new oriental.
testing for all of these applications was crowdsourced to workers on kikbug.net.
for these ve apps more than students were involved.
to perform crowdsourced testing each student installed a kikbug android app chose testing tasks and completed testing tasks on their own phone.
during the testing process workers performed testing tasks according to some guidelines speci ed by the app developers.
during task performance the workers could take screenshots if necessary such as experiencing some unexpected behavior.
after the testing task was completed the worker could provide a brief description on bug phenomenon on his own phone.
finally the student submitted a test report including the short descriptions and possible screenshots.
then all the test reports are submitted to app developers and the developers can inspect the reports and begin the debugging process.
with the help of the developers inspection kikbug obtained ground truth assessments for the students reports.
the detailed information of the applications is shown in table in which the jrjdenotes the number of reports jfjdenotes the number of faults revealed in the test reports jsjdenotes the number of screenshots contained in the test reports jrsjdenotes the number of test reports containing at least one screenshot and jrfjdenotes the number of test reports that revealed faults.
.
prioritization strategies technique ideal.
the best result in theory to inspect test reports in such a way as to demonstrate the most unique bugs as early as possible.
represented as ideal .
technique textdiv.
the prioritization strategy based only on the distance between test reports text descriptions i.e.
in this strategy dtwill replace bd the rst parameter of algorithm .
represented as textdiv .
technique imagediv.
the prioritization strategy based only on the distance between test reports screenshots i.e.
in this strategy dswill replace bdas the rst parameter of algorithm .
represented as imagediv .
technique random.
the random prioritization strategy which is used to simulate the situation without any prioritization technique.
represented as random .
technique text imagediv.
our prioritization strategy that balances the distance of screenshot sets and text descriptions.
represented as text imagediv .
.
evaluation metrics we employed the apfd average percentage of fault detected metric which is the most widely used evaluation metric for test case prioritization techniques to measure the e ectiveness of our techniques.
for each fault apfd marks the index of the rst test report revealing it.
we present the formula to compute the afpd value in equation in which ndenotes the number of test reports mdenotes the total number of faults revealed by all test reports tfiis the index of the rst test report that reveals fault i. apfd tf1 tf2 tfm n m n in our experiment a higher apfd value implies a better prioritization result.
that is it can reveal more faults earlier than the other methods do.
although the apfd values re ect the global performance of prioritization techniques in practice developers often cannot inspect all reports in a limited time budget.
thus we also provide a metric to reveal the percentage of bugs that would be found at certain milestones of inspection.
for this we use linear interpolation to evaluate the partial performance of each prioritization technique.
we de ne linear interpolation as following qp m p which is the number of faults corresponding to a percentage p. letint q andfrac q be the integer part and fractional part of q respectively.
if frac q the linear interpolation is needed.
i jare the indexes of reports that reveal at least q and q faults respectively.
the linear interpolation valuevpis calculated as vp i j i frac q in our experiment we set the p2f25 g. .
experimental setup in order to ensure the correctness of the implementation of spm we directly used the matlab code provided by the inventors of spm.
there are some key parameters a ecting the performance of spm which are the size of the descriptor dictionarydictsize number of levels of the pyramid l and number of images to be used to create the histogram bins histbin .
in our experiment as the recommended values of the spm inventor we set dictsize l and histbin .
for the nlp technique because all of test reports in our experiment are in chinese we employed the ltp platform to assist the text description analysis.
moreover the size of screenshots i.e.
image resolution submitted by the crowd workers was not xed in fact they varied widely.
in order to apply the spm technique we resize all screenshots to pixels.
given the way 207that the spm technique focuses on detecting features within images resizing the images should not produce a substantial impact to the distance calculation.
in this experiment we implemented all of the strategies presented in section .
.
particularly for the text imagediv strategy we set the threshold of determining the identity of screenshots to .
the factor that is used to weaken the weight of test reports without any screenshots to .
and the parameter used to balanced the text based distance and screenshot set distance to which means we weigh the two kinds of distance equally.
.
results analysis and discussion in this section we present the results of our experiment then interpret those results to attempt answers to our research questions and nally discuss the overall results.
in order to reduce the bias that was introduced by the random initialization of the algorithm and the tie breaking we conducted the experiment times and present the result in figure .
figures a c e g and i show the boxplots of the apfd results for the ve projects respectively each aggregated over the experimental runs.
figures b d f h and j show the average fault detection rate curves.
the exact mean value of apfd is shown in table which also includes the result of one way anova tests of all strategies the improved extent over random and the gap between our strategies and ideal .
furthermore we present the mean linear interpolation value over the experiment runs in table to demonstrate the performance of our techniques in limited time budgets.
.
answering research question rq1 rq1 can test report prioritization substantially improve test report inspection to nd more unique bugs earlier?
based on the results shown in figure a c e g i and in the third column of table we nd to di erent extents all of the three diversity based prioritization strategies outperform random .
furthermore in table all f values are relatively large and the p values which means the apfd values of the four strategies are signi cantly di erent.
compared with the random strategy the percentage of improvement of text imagediv ranges .
.
.
summary all of the diversity based prioritization methods can improve the e ectiveness of test report inspection overrandom and thus test report prioritization can substantially and signi cantly nd more unique buggy reports earlier in the prioritized order.
.
answering research question rq2 to what extent can the image based approaches improve the e ectiveness of the text only based approach?
figure reveals that except on the justforfun project thetext imagediv outperforms the textdiv imagediv andrandom strategies which means the image understanding technique improves the performance of the textonly based technique.
we did a deeper investigation on this problem and found what we speculate to be the reason for the di erent result for the justforfun project.
justforfun is an image editing and sharing application and as such the inherent functionality is to process various userprovided photos.
the screenshots for this app largely consist of user content with relatively few app speci c features in those screenshot images.
thus the various screenshotsof justforfun make the screenshot sets distance calculating procedure generate large distances even between the same activity views which leads to a negative impact on the image based strategies.
in contrast based on table text imagediv outperformed the single text based prioritization techniques on inspecting di erent percentage of test report of se cloudmusic and ubook.
summary generally compared with the text only based prioritization strategy the image understanding technique is able to improve the performance of prioritizing test reports both globally i.e.
apfd and partially i.e.
linear interpolation at many level .
however we found that some classes of apps are naturally less suited for image understanding techniques namely apps where the bulk of the views are composed of user contect.
.
answering research question rq3 how much improvement is further possible compared to a best case ideal prioritization?
the fourth column of table shows the gap between our strategies and the theoretical ideal .
we found the gap between text imagediv andideal vary from .
to .
.
for more details we can observe the growth curves in figure .
the curve of ideal grows at a fast rate.
the best situation reached top while the text imagediv only stayed around .
summary we nd that our prioritization methods can provide a reasonable small gaps for the theoretical ideal result particularly for some subjects.
however there is room for future work to continue to improve the prioritization ordering of test reports.
.
discussion method selection.
re ecting on all of our experimental results we nd that image understanding techniques can provide bene ts to test report prioritization and that the area of such hybrid text and image approaches demonstrates promise.
that said we also observed that di erent techniques may be more or less applicable for di erent types of applications.
speci cally we observed that the image editor app produced the worst results for the image based and hybrid techniques compared to text only.
in such cases where the screenshots mainly represent user content image based techniques may be less applicable.
however in applications in which little user or external content is displayed imagebased or hybrid techniques may be more applicable.
one noteworthy point is that both the textdiv and text imagediv are full automated which we believe are more applicable in practice than the semi automated divrisk and risk techniques that require the users to input the inspection result to prioritize the crowdsourced test reports dynamically.
mobile application testing.
all of our experimentation was conducted on mobile applications and thus we cannot state with certainty that such results would hold for other types of gui software such as desktop or web applications.
however we speculate that while there will likely be new and unique challenges in these domains the basic concepts would likely hold at least for the class of applications with relatively less user content.
desktop and web applications have the potential for even more di ering screen and window sizes as well as multiple windows and pop up dialog windows and each of these unique aspects would likely need 208table one way anova tests method apfd improvement gap meansx random randombest x x se f p value ideal .
.
text imagediv .
.
.
textdiv .
.
.
imagediv .
.
.
random .
.
cloudmusic f p value ideal .
.
text imagediv .
.
.
textdiv .
.
.
imagediv .
.
.
random .
.
ubook f p value ideal .
.
text imagediv .
.
.
textdiv .
.
.
imagediv .
.
.
random .
.
ishopping f p value ideal .
.
text imagediv .
.
.
textdiv .
.
.
imagediv .
.
.
random .
.
justforfun f p value ideal .
.
text imagediv .
.
.
textdiv .
.
.
imagediv .
.
.
random .
.
table linear interpolation average number of inspected test reports program strategy ideal .
.
.
.
text image .
.
.
.
se textdiv .
.
.
.
imagediv .
.
.
.
random .
.
.
.
ideal .
.
.
.
text image .
.
.
.
cloud textdiv .
.
.
.
music imagediv .
.
.
.
random .
.
.
.
ideal .
.
.
.
text image .
.
.
.
ubook textdiv .
.
.
.
imagediv .
.
.
.
random .
.
.
.
ideal .
.
.
.
text image .
.
.
.
ishop textdiv .
.
.
.
ping imagediv .
.
.
.
random .
.
.
.
ideal .
.
.
.
text image .
.
.
.
just textdiv .
.
.
.
forfun imagediv .
.
.
.
random .
.
.
.
to be addressed.
overall we speculate that the success of such image understanding assisted test report prioritization techniques would likely depend on the visual complexity of the application views.
.
threats to validity there are some general threats to validity in our experimental results.
for example we need more projects and different parameter values combinations to reduce the threat to external validity and to better generalize our results.
crowd workers.
due to a monetary limitation we simu lated the crowdsourced mobile testing procedure to validate our techniques in which we invited the students to work as crowd workers.
such a choice means that our population of workers may be less diverse than the population of crowdsourced workers from the general populace.
theoretically crowdsourcing requires workers come from a large pool of individuals that one has no direct relationship with the others which implies that our result may be di erent if the crowd workers were from the internet with open calls.
however according to the study of salman et al.
if a technique or task is new to both students and professionals similar performance can be expected to be observed.
based on this study we believe this threat may not be the key problem for our validation procedure.
subject program selection.
the cost of conducting this kind of experiment is quite expensive involved more than people the monetary budget is limited so we conducted the experiment on only ve applications.
however these ve applications are widely used and publicly accessible.
the functionalities of our subject applications vary widely including music player video player picture editor power monitor and online shopping assistant.
thus we believe these applications can be used to validate the our methods at least to give initial indications of e ectiveness and applicability.
natural language selection.
admittedly in our experiment all of the test reports were written in chinese which could threaten the generalizability to other natural languages.
however the nlp techniques and text based prioritization technique are not the focus of this work.
even though we used text based techniques as one of our baselines what matters to the performance of these technique is the distance built from keywords set but not the languages.
as for the keyword extraction technique di erent languages have their own inherent characteristics and thus nlp researchers have proposed keywords extraction techniques for di erent languages.
in future research we will validate our technique with test reports written in english.
moreover the focus of this work is to study the potential for image understanding techniques to augment text only based techniques.
.
related work bug report triage.
as a large number of bug reports will be submitted in the software testing phase manually triaging each of these reports will become an e ort consuming task.
bug report triage is a process that includes prioritizing bug reports ltering out duplicate reports and assigning reports to the proper bug xer.
among the various bug report triaging techniques we address two highly relevant research areas bug report prioritization and duplicate identi cation techniques.
yuet al.
used neural networks to predict the priority of bug reports.
their technique also employs the reused data set from similar systems to accelerate the evolutionary training phase.
kanwal et al.
used svm and naive bayes classi ers to assist bug priority recommendation.
tian et al.
predicted the priority of bug reports by presenting a machine learning framework that takes multiple factors including temporal textual author related report severity and product into consideration.
by analyzing the textual description from bug reports and using text mining algorithms lamkan et al.
conducted case studies on three large scale open source projects and based on the result .
.
.
.
.
.
text image text image randomapfdideal a apfd on se .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
percentage of inspected reportspercentage of found faults ideal text image text image random b average fault detection rates on se .
.
.
.
.
.
text image text image randomapfdideal c apfd on cloudmusic .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
percentage of inspected reportspercentage of found faults ideal text image text image random d average fault detection rates on cloudmusic .
.
.
.
.
.
text image text image randomapfdideal e apfd on ubook .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
percentage of inspected reportspercentage of found faults ideal text image text image random f average fault detection rates on ubook .
.
.
.
.
.
text image text image randomapfdideal g apfd on ishopping .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
percentage of inspected reportspercentage of found faults ideal text image text image random h average fault detection rates on ishopping .
.
.
.
.
.
text image text image randomapfdideal i apfd on justforfun .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
percentage of inspected reportspercentage of found faults ideal text image text image random j average fault detection rates on justforfun figure experiment results averaged over runs 210concluded that the technique is able to predict the severity with a reasonable accuracy.
by applying natural language processing techniques runesonet al.
took more textual features including software versions tester information and submission date into consideration to detect duplicate bug reports.
they validated this technique by conducting a large scale experiment on industrial projects.
jalbert et al.
used the surface features textual semantics and graph clustering to identify the duplicate status.
besides duplicate detection their technique is also able to rank the existing reports that are more similar with the new one.
by measuring the textual semantic similarity between the test reports nyugen et al.
applied the topic model to detect duplicate bug reports.
podgurski et al.
proposed the rst approach to categorizing software failure reports by applying the undirected clustering on execution traces.
feng and xin et al.
adopted the multi label classi cation technique to assign the bug reports into more than one classes based on the execution traces.
to assist test report prioritization in crowdsourced software testing feng et al.
proposed two strategies div and risk.
both of the two strategies are text based.
div is a fully automated technique which aims at assisting the developers inspect a wide variety of test reports and to avoid duplicates and wasted e ort on falsely classi ed faulty behavior.
in this paper we denote div technique as textdiv and treat it as a baseline.
risk is designed to assist developers to identify test reports that may be more likely to be fault revealing based on past observations.
because risk requires the users to input the inspection result i.e.
it is a semi automated technique and not fully automatic it is a distinct category of technique and thus we did not employ it as a baseline for evaluation.
crowdsourced software testing.
mao et al.
conducted a comprehensive survey on the crowdsourced software engineering in which they de ned the crowdsourced software engineering as the act of undertaking any external software engineering tasks by an unde ned potentially large group of online workers in an open call format.
in fact crowdsourced techniques have been widely used in industrial software testing and gained popularity in usability testing localization testing gui testing user experience testing and stress performance testing.
however it is a fairly new research topic in the software engineering research community.
liu et al.
investigated both methodological di erences and empirical contrasts of the crowdsourced usability testing and traditional face to face usability testing.
to solve the oracle problem pastore et al.
applied the crowdsourcing technique to generating test inputs depending on a test oracle that requires human input in one form or another.
dolstra et al.
used virtual machines to run the system under test and enable the crowd workers to accomplish expensive and semi automatic gui testing tasks.
by introducing crowdsourced testing nebeling et al.
conducted an experiment to evaluate the usability of web sites and web based services the result of which showed that crowdsourcing testing is an e ective method to validate the web interfaces.
application of image understanding on testing.
in michail et al.
proposed a static approach guisearch to guide search and browsing of its source code by using the gui of an application.
they further proposed a dynamic ap proach to obtain an explicit mapping from high level actions to low level implementation by identifying execution triggered by user actions and visually describing actions from a fragment of the application displayed .
kurlander et al.
introduced the notion of an editable graphical history that can allow the user to review and modify the actions performed with a graphical interface.
similarly michail and xie used before after screenshots to visually describe application state at a very high level of abstraction to help users avoid bugs in gui applications.
however images in these work are provided to developers or users directly without machine understanding.
image understanding techniques have been used in crossbrowser issues for web applications.
cai et al.
propose the vips algorithm which segments a web page s screenshot into visual blocks to infer the hierarchy from the visual layout rather than from the dom.
choudhary et al.
proposed a tool called webdiff to automatically identify cross browser issues in web applications.
given a page to be analyzed the comparison is performed by combining a structural analysis of the information in the page s dom and a visual analysis of the page s appearance obtained through screen captures.
.
conclusion in this work we proposed a novel technique to prioritize test reports for inspection by software developers by using image understanding techniques to assist traditional text based techniques particularly in the domain of crowdsourced testing of mobile applications.
we proposed approaches for prioritizing based on text descriptions based on screenshot images and based on a hybrid of both sources of information.
to our knowledge this is the rst work to propose using image understanding techniques to assist in test report prioritization.
in order to evaluate the promise of using image understanding of screenshots to augment textbased prioritization we implemented our hybrid approach as well as a text only and image only based approaches and two baselines an ideal best case and a random average case baseline.
we found that prioritization in almost all cases is advantageous as compared to test report inspection based on an unordered process.
we also found that for most software applications that we studied there was a bene t to using the screenshot images to assist prioritization.
however we also found that there exist a class of applications for which image understanding may not be as applicable and found room for improvement to narrow the gap to the hypothetical best case ideal result.
as such in future work we will investigate ways to help prioritize for those classes of applications and also identify application classes that are best suited for each type of technique.
finally in future work we will extend the set of software systems that we use and the natural language used to write the test reports.
.