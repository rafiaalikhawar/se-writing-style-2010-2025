a comparison of sampling algorithms for configurable systems fl vio medeiros fed.
univ.
of campina grande para ba brazilchristian k stner carnegie mellon university pittsburgh pennsylvania usam rcio ribeiro federal university of alagoas macei alagoas brazil rohit gheyi fed.
univ.
of campina grande para ba brazilsven apel universit t passau passau germany abstract almosteverysoftwaresystemprovidesconfigurationoptions to tailor the system to the target platform and application scenario.
often this configurability renders the analysisof every individual system configuration infeasible.
to ad dress this problem researchers have proposed a diverse setof sampling algorithms.
we present a comparative study of state of the art sampling algorithms regarding their fault detection capability and size of sample sets.
the for mer is important to improve software quality and the lat ter to reduce the time of analysis.
in a nutshell we found that sampling algorithms with larger sample sets are able to detect higher numbers of faults but simple algorithmswith small sample sets such as most enabled disabled a r e the most efficient in most contexts.
furthermore we ob served that the limiting assumptions made in previous work i n fl u e n c et h en u m b e ro fd e t e c t e df a u l t s t h es i z eo fs a m p l e sets and the ranking of algorithms.
finally we have iden tified a number of technical challenges when trying to avoidthe limiting assumptions which questions the practicality of certain sampling algorithms.
.
introduction manysoftwaresystemscanbeconfiguredtodifferenthardware platforms operating systems and requirements .
however the variability that is inherent to configurable systems challenges quality assurance .
developers need to consider multiple configurations when they executetests or perform static analyses to find faults and vulner abilities.
as the configuration space often explodes exponentially with the number of configuration options analyzing every individual system configuration becomes infeasiblein real world projects for example the linux kernel has more than thousand compile time configuration options.configuration related faults that occur only in a subset of all configurations are especially tricky to find .
as such it is not surprising that many configuration related faults have permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full cita tion on the first page.
copyrights for components of this work owned by others thanacm must be honored.
abstracting with credit is permitted.
to copy otherwise or re publish to post on servers or to redistribute to lists requires prior specific permissionand or a fee.
request permissions from permissions acm.org.
c circlecopyrt2016 acm.
isbn .
.
.
.
found in highly configurable systems such as the linux kernel gcc busybox a n d apache .
although researchers have proposed approaches to analyze complete configuration spaces in a sound fashion for some classes of defects the vast majorityofmaturequality assurancetechniquesconsideronlyasingleconfiguration at a time.
for example static analysis tools operate typically on c code after the c preprocessor has resolved configuration options implemented through condi tional compilation e.g.
using ifdefdirectives .
to reuse state of the arttools suchas gcc fordetectingconfigurationrelated faults sampling is a viable alternative .
that is instead of analyzing all configurations one se lects asubsetof configurations to analyze individually.
the effectiveness of sampling for detecting configuration relatedfaults depends significantly on how samples are selected though.
several sampling algorithms have been proposed in the literature suchas t wise statement coverage andone disabled .
to select a suitable sampling algorithm one needs to understand the tradeoffs especially withregardtoeffort i.e.
howlargearethesamplesets andfaultdetection capabilities i.e.
how many faults can be found inthe sampled configurations .
unfortunately acomparison ofsampling algorithms for finding configuration related faults is not available.
more importantly many proposed sampling algorithms make severe assumptions that may not berealistic for practical applications and that are not alwaysclearly communicated.
for instance they perform analy ses per file instead of globally and they ignore constraints among configuration options header files and build system information .
applying sampling algorithmsunder different assumptions may introduce significant addi tional effort or reduce coverage as we will discuss.
a lack of understanding of the tradeoffs and assumptions of sampling algorithms can lead to both undetected faults which de crease software quality and time consuming code analysis which increases costs.
weconductedacomparativestudytoanalyze10sampling algorithms in detail to fill that gap.
we compared the se lected sample sizes and the fault detection capabilities of thesampling algorithms in a study of known configuration related faults in open source c systems each configurable with conditional compilation.
specifically we analyzed a set of sampling algorithms proposed in the research literature variations of t wise statement coverage random one disabled one enabled a n dmost enabledicse may austin tx usa ieee acm 38th ieee international conference on software engineering disabled.
in summary we analyzed sampling algorithms and combinations of algorithms in two studies.
in the first study we compared sample sizes and fault detection capabilities of the different sampling algorithms and theircombinations on a large set of open source systems underfavorable assumptions e.g.
ignoring constraints and headerfiles .
in the second study we explored the influence of considering constraints header files build system information and global analysis which are often neglected in the litera ture and practice .
our results show that all algorithms select configurations with more than of the configuration related faults inour corpus.
almost of all faults are detected by en abling or disabling one or two configuration options butthere are also faults that require developers to enable ordisable up to sevenoptions.
as expected we found that the algorithms with the largest sample sizes detected themost faults.
however simple algorithms with small samplesets such as most enabled disabled a r et h em o s te ffi c i e n t in many scenarios.
more interestingly we identified several novel combinations of algorithms that provide a useful bal ance between sample size and fault detection capabilities.
as a further result we found that considering constraints among configuration options global analysis header files and build system information influence the performance of most sampling algorithms substantially up to the point that several algorithms are no longer feasible in practice.
consid ering constraints increases the time of analysis significantly whichprohibitsustousesomealgorithms suchas three wise andfour wise at all.
including build system information increases the size of sample sets slightly whereas global anal ysis and analyses that include configuration options fromheader files turn the analysis to be practically infeasible formost algorithms.
in summary our main contributions are a comparative study of sampling algorithms and35 combinations of algorithms regarding their fault detection capability and size of sample sets a study on the influence of considering header files constraints build systeminformation andglobalanal ysis on the performance of sampling algorithms a discussion of results showing that some sampling al gorithms become infeasible under realistic settings for example when incorporating header files and applying global analysis a report of significant changes of the efficiency rank ing of sampling algorithms when considering different pieces of information such as build system and constraint information results supporting sampling algorithms with an effi cient balance between sample size and fault detectioncapabilities under different assumptions such as the most enabled disabled algorithm.
all data used in this study are available on our website.
.
configuration related faults conditional compilation is used in many real world systemstomakethesourcecodeconfigurable .
forinstance figure depicts a code snippet of libpng2related to splitting images into segments.
the splitting feature is optionaland is included only when configuration option spltis en1 spg sampling thiscodesnippetalsocontainsaconfigurationoptionthat checks for pointer index support controlled by configuration option pointer.
using the c preprocessor we can generate four different configurations from this code snippet both configuration options enabled only pointer enabled only spltenabled and both configuration options disabled.
.
other definitions.. .
ifdef splt .void png handle splt .
ifdef pointer .
png splt entryp p .
endif .
lines of code.. .
ifdef pointer .
p palette i .
p red start .
else12.
p new palette .
p .red start .
endif15.
.
endif .
more definitions.. define splt define pointerconfiguration undef splt define pointerconfiguration define splt undef pointerconfiguration undef splt undef pointerconfiguration compilation succeed compilation error figure a fault in libpng that occurs when splt is enabled and pointer is disabled.
mostanalysistoolsforccode suchas gcc operateonpreprocessed code one configuration at a time.
by compiling the code snippet of figure with spltenabled and pointer disabled we get a compilation error at line .
this lineuses variable p which is not declared before line when we disable pointer.
because common analysis tools check only one configuration at a time they do not show warningor error messages when one compiles the code depicted infigure considering other configurations.
this is an example of a configuration related fault that can only be exposed in some combinations of configuration options .unfortunately the space of possible combinations is expo nential in the worst case and it is usually too large toexplore exhaustively.
for instance the linux kernel offers more than 12k configuration options which give rise tomore configurations than there are atoms in the universe.
to analyze real world configurable systems developers often use sampling algorithms that select only a few configurations for analysis.
for instance one can check the code snippet presented in figure using the most enabled disabled sampling algorithm.
it considers two configurations allconfiguration options enabled and all options disabled.however it is not possible to detect the fault presented in figure using the most enabled disabled algorithm as the fault requires enabling one configuration option while disabling another.
by using other sampling algorithms onecan detect this specific fault in libpng but other faults possibly not.
for instance one can use one disabled which disables one configuration option at a time or statementcoverage which enables each block of optional code at least once.
previous work has studied configuration related faults similar to the one we discuss here and proposed manysamplingalgorithms .
however researchersmakeassumptions that may not be realistic in practice.
for in stance they perform per file instead of global analysis and theyignoreconstraintsbetweenconfigurationoptions header files and build system information.
in this paper we reporton a comparative study of sampling algorithms initially ac cepting those assumptions section but explicitly evalu ate the influence of including different types of information in a second study section .
.
study design and sampling algorithms ouroverallgoalistocomparestate of the artsamplingalgorithms regarding their capability to detect configurationrelated faults and the size of their sample sets.
furthermore we study four assumptions of previous work which often does not consider constraints global analysis build system information and header files.
we performour studies in the context of the c programming languageand configuration options implemented with the c preprocessor i.e.
ifdef as illustrated in the previous section.
we aim at answering the following research questions rq1.what is the number of configuration related faults detected by each sampling algorithm?
rq2.what is the size of the sample set selected by each sampling algorithm?
rq3.which combinations of sampling algorithms maximize the number of faults detected and minimize the number of configurations selected?
rq4.whatistheinfluenceofthefourassumptionson thefeasibilitytoperformtheanalysisforeachsamplingalgorithm?
rq5.what is the influence of the four assumptions on the number of faults detected by each sampling al gorithm?
rq6.what is the influence of the four assumptions o nt h es i z eo ft h es a m p l es e ts e l e c t e db ye a c hs a m p l i n galgorithm?
.
overall study design at first glance a study comparing sampling algorithms rq1 seems straightforward.
we use a number of differ ent sampling algorithms independent variable to measurehow many of the faults we can find with them in differentsoftware systems and how big the sample set is dependent variables .
however there are several challenges to overc o m ei nt h ed e s i g no fs u c ha ne x p e r i m e n t .
sampling the configuration space needs to be combined with a technique to detect faults in the respective selectedconfigurations suchasinspection unrealisticallylaborious executing existing test suites if available automated testcase generation looking for crashing defects or static anal ysis prone to false positives .
if not conducted carefully wemight be evaluating the fault detection technique instead of the sampling algorithm.
we address this potential bias by taking the fault detection technique out of the loop andby using a corpus of previously found configuration relatedfaults.
for each known fault we check whether the samplingalgorithms select configurations in which the fault could have been found assuming a suitable fault detection technique.
that is by using a corpus of confirmed configuration related faults we eliminate the fault detection technique asa confounding factor from our study setup.
however we actually do not know if the sampling algorithms actually discovered more or different faults.
we discuss this threatand an alternative study design in section .
a second design challenge is how to evaluate the influence of the four assumptions regarding global analysis header files constraints andbuild systeminformation behindmany sampling algorithms.
as we will show lifting these assump tions can make it infeasible to apply some of the algorithmsto real world software systems.
therefore we decided to proceed in two steps first we study tradeoffs among sam pling algorithms rq1 under favorable conditions i.e.
fulfilling all assumptions .
subsequently we investigate theinfluence of the assumptions rq4 on a smaller set ofsubject systems in a second study.
the four assumptionsare constraints constraints between configuration options may exclude certain configurations e.g.
optionx may only be selected if option y is selected from the set of valid configurations.
a sample set may contain configurations that violate constraints.
un fortunately configuration constraints are rarely docu mented explicitly the linux kernel is an exception and has been studied therefore extensively .
in the presence of constraints samplesetsareoften larger to achieve the same coverage and highly optimizedcovering array tables 3cannot be used.
as we do not know configuration constraints for most of our subject systems we exclude contraints entirely from the sam pling process in our first study.
global analysis we can sample configurations per fi l eo rg l o b a l l yf o rt h ee n t i r es y s t e m .e v e ni ns y s t e m s with many configuration options individual files are usuallyaffectedonlybyfewoptions.
samplingoverthe global configuration space may detect inter file faults e.g.
linker issues but this often creates huge samplesets which hardly affect individual files.
thus in the first study we assume a per file analysis.
header files in c code a significant amount of variability arises from header files.
however detecting all configuration options from header files in a sound wayis a difficult and expensive task which requires some form of variability aware analysis .
it is necessary to resolve includes and macro expansions but to keep the conditional directives i.e.
partial pre processing .
we therefore analyze only configuration options inside source files in our first study.
build system the build system may induce a significant amount of variability such that certain files are not compiled in all configurations .
since buildsystems are inherently difficult to analyze we do not use build system information in the first study.
.
sampling algorithms in both studies we will analyze the same set of sampling algorithms proposed in prior work as well as their combinations.
we explain each samplingalgorithm using the example code snippet of figure .
ifdef a code endif ifdef b code else code endif ifdef c code endifone disabled most enabled disabledpair wise config config config config !a !a a a!b b !b bc !c!c c statement coverage config config aab !bc cone enabled config config config a !a !a!b b !b!c!c cconfig config config !a aab !b bcc !c config config a !ab !bc !c figure comparing the sampling algorithms by example.
3a covering array is a mathematical object used for software testing which ensures specific coverage criteria.
for example a pair wise covering array ensures that all pairs of configuration options are considered by the array .
645the t wisealgorithm covers all combinations of tconfiguration options pair wise checks all pairs of configuration options pt 2q and it selects four configurations of the example of figure .
considering options aandb we can see that there is a configuration where both options are disabled config two other configurat i o n sw i t ho n l yo n eo ft h e me n a b l e d config andconfig and another configuration where both configuration optionsare enabled config .
the same situation occurs for configuration options aandcand options bandc.h o w e v e r tcan take integer values to check different combinations of options such as three wise pt 3q four wise pt 4q a n d five wise pt 5q.
as we increase t the sizes of the sample sets also increase.
figure presents the sample set distri butions of three wise four wise five wise a n dsix wise.a s we can see three wise andfour wise create small sample sets five wise andsix wise create much larger sample sets.
we selected samples based on precomputed and optimalcovering array tables 4that select a minimal set of configurat i o n st h a tc o v e r sa l lt combinations of configuration options.
these tables do not consider constraints between configuration options.
there are tools that implement t wiseconsidering constraints such as splcatool casa and acts .
however these tools do not necessarily select a minimal sample set or even guarantee t wisecoverage as discussed in section .
number of configuration optionssize of sample setthree wise four wisefive wisesix wise figure sample sets of t wise sampling considering a file with a number of configuration options ranging from zero to eighty.
thestatement coverage algorithm selects a set of configurations in which each block of optional code is enabled at least once .
we used statement coverage as implemented in theundertaker tool suite.5notice that we are not usingundertaker to detect dead code but to select configurations with the statement coverage algorithm.
as presented in figure by enabling configuration options a b andc the algorithm ensures that the optional code blocks code code 2andcode 4are enabled at least once.
however it needs another configuration e.g.
aandcenabled andbdisabled to enable code .
including each block of optional code at least once does not guarantee that all pos sible combinations of individual blocks of optional code areconsidered though.
themost enabled disabled algorithm checks two samples independently of the number of configuration options.when there are no constraints among configuration options it enables all options config and then it disables all configurationoptions config .one disabled isanalgorithm suggested by abal et al.
based on faults found in thelinux kernel.
it disables one configuration option at a time.we can also see in figure that it disables configuration 4the precomputed and optimal covering arrays used in our study are available at 5despite the existence of an algorithm to compute an optimal solution for the coverage problem which is np hard w eu s e da na l g o r i t h m that computes the sample set much faster but may produce a sample set that is possibly larger than optimal.optionainconfig option binconfig and option cin config .
in contrast one enabled enables one configuration option at a time.
finally we implemented a random sampling algorithm.
random sampling receives as input the maximum number of configurations n to check per file.
then it creates n distinct configurations with all configuration options of the file and randomly assigns trueorfalsefor every option of each configuration.
for files which a brute force algorithm requires fewer configurations than the maximum number of configurations n per file random sampling selects all configurations.
we ran random sampling considering differentnumbers of configurations per file ranging from to .
foreach number we ran the analysis ten times and computedthe average number of detected faults and the confi dence interval.
.
detecting faults in this first study we compared the fault detection capabilities and the sample sizes of the sampling algorithms using a corpus of known faults of open source systems to answer questions rq1 .
as explained in section we performed the first study under favorable assumptions that is without constraints global analysis build systeminformation and header files.
we proceeded in three steps as illustrated in figure .
instep w es e l e c te a c hs o u r c efi l eo ft h eg i v e ns u b j e c t system.
step 2applies each sampling algorithm to select the samples for every file.
step 3determines the number of configuration related faults detected rq1 and measuresthe size of the sample set rq2 for each algorithm.
thesize of the sample set is the sum of the numbers of sampledconfigurations for every source file.
to identify the sam pling algorithms that detect a fault we consider its presence condition which is a subset of system configurations in which the fault can be found assuming a suitable fault detection technique.
we checked whether we could find atleast one configuration of this subset in the sampled configurations for each algorithm.
finally we repeat the process for combinations of sampling algorithms rq3 .
ifdef endif endif ifdef source file configurations samples sampling algorithms10what is the number of faults detected by the algorithm?
does the algorithm select the configuration with fault?
figure strategy used to compare the sampling algorithms.
.
corpus of faults using a corpus of configuration related faults in a study raises the question of how to acquire a proper corpus and whether it is a representative corpus of configuration related faults in real systems.
faults identified with existing sam pling algorithms will obviously bias results toward these spe cific algorithms.
instead we assembled a corpus of faults inwhich all faults have been identified in one of two ways variability awareanalysistoolsareabletoidentifycer tain kinds of faults mostly syntax and type errors by 646covering the entire configuration space without sampling.
difficulties in setting up these tools and narrow classes of detectable faults limit their applicability at this point and their prototype status leads tofalse positives.
we collected only configuration relatedfaults that have been reported by such tools reportedto the original developers and confirmed or fixed by the developers .
weuseconfiguration relatedfaultsthathavebeenmanually identified and fixed by developers.
faults re ported by users and fixed in the repository by the system s developers may be slightly biased toward more popular configurations but are not systematically bi ased toward specific sampling algorithms.
they repre sent configuration related faults that are routinely de tected and fixed in real software systems.
we started with abal s corpus of faults of the linux kernel and complemented it with faults found in other studies andourowninvestigationofsoftwarerepos itories see table .
overall the corpus of faults used in our study includes configuration related faults from subject systems ofvarious sizes and from different domains over differ ent files with distinct numbers of configuration options seefigure .
our corpus contains faults of different kinds including syntax errors memory leaks nullpointer dereferences uninitialized variables undeclaredvariablesandfunctions resourceleaks array and buffer overflows arithmetic faults and type errors .
table presents a characterization of the subject systems we use in the first study listing theproject name application domain lines of code number offiles number of configuration options and number of knownfaults considered in our study.
table shows the presence conditions of the faults and the number of configuration options that we need to en able or disable to detect the configuration related faults weconsider in the first study for faults we need to enable some options for faults we need to disable some configuration options and for another faults we need to enable some options and disable others.the majority of faults are related to one or two con figuration options while less than related to more than four configuration options.
notice that we discarded seven faults of the linux kernel from our corpus that span multiple files because we performed a per file analysis in our first study.
we considered faults that require inter procedural analysis as long as all procedures are defined in the same file.
number of configuration optionsfrequency figure number of distinct configuration options in files with configuration related faults.
.
results and discussion for each sampling algorithm we answered the research questions rq1 .
figure presents the number of faults detected and the corresponding size of the sample set for each algorithm.
note that detecting more faults does notmean more efficiency because there is a tradeoff between thenumber of faults detected and the size of the sample set.
we consider the efficiency of the sampling algorithms in terms of efficiency e sizeofsampleset numberoffaults.
this ratio represents the number of configurations that one needsto check per fault to be detected.
furthermore we analyzed35 combinations of sampling algorithms to answer research question rq3 as illustrated in figure .
we discuss the results in terms of the three research questions next.
rq1.what is the number of configuration related faults detected by each sampling algorithm?
overall we found that all algorithms detected more than of all faults of our corpus.
statement coverage detected thelo w estn um beroffaults whilesix wise detectedthehighest number.
the majority of faults in our corpus can be detected by enabling or disabling fewer than six configura tion options.
this way six wise is able to detect all these faults.statement coverage missed faults because they require developers to enable some configuration options anddisable others i.e.
require specific combinations of multipleblocks of codes whereas statement coverage is only concerned with including each block of code at least once in asystem configuration.
allt wisesampling algorithms detected more than of the configuration related faults.
six wise andfive wise detected all faults.
most enabled disabled one enabled a n d one disabled detected all between to of the faults.
furthermore we present the average values of random sam pling with a confidence interval gray area in figure .we ran random sampling with the maximum number of con figurations per file n ranging from to ten times for each value of n. 6we report the mean of all runs it detected configuration related faults.
configuration related faultssamples per file pair wisestmt coveragerandom four wisefive wisesix wise three wisemost enabled disabledone enabled one disabled sampling algorithm faults samples file statement coverage .
most enabled disabled .
one enabled .
one disabled .
random .
pair wise .
three wise .
four wise .
five wise .
six wise .
figure number of configuration related faults and samples per file for each sampling algorithm.
rq2.what is the size of the sample set selected by each sampling algorithm?
thesizesofthesamplesetsrangefrom1.3to10configurations per file.
the algorithm most enabled disabled selected t h es m a l l e s ts a m p l es e t six wise required the largest sample set with more than 500k sampled configurations across all projects .
the number of configurations to check influences the time of analysis.
so it is not feasible to use algorithms with large sample sets in all situations as we will discuss 6random selects .
samples per file on average.
647table configuration related faults considered in our first study.
source faults kind strategy subject system number of faults memory type and arithmetic repository mining linux syntax typechef busybox include and arithmetic repository mining gcc firefox type repository mining gnome keyring gnome vfs and totem syntax typechef apache bash dia gnuplot libpng and libssh memory type and arithmetic our repository mining apache bison cherokee cvs dia fvwm gnuplot irssi libpng lua libssh linux libxml lighttpd vim xfig and xterm total135 faults collected from previous studies and detected in our additional repository analysis.
in section .
based on our efficiency measure we rank the algorithms starting from the most efficient most enableddisabled pair wise stmt coverage one disabled one enabled three wise random four wise five wise a n dsix wise .
rq3.which combinations of sampling algorithms maximize the number of faults detected and minimize the number of configurations selected?
inadditiontotheindividualalgorithms weanalyzedcombinations that is the union of the sample sets produced by the respective sampling algorithms of two and three sampling algorithms excluding random five wise a n dsixwisealgorithms.
we excluded random because it detects different numbers of faults in different runs and we excludedfive wise andsix wise because they already detected all faults.
furthermore we excluded combinations withmore than three algorithms because they resulted in ineffi cient combinations according to our efficiency function.
figure relates the number of faults and the size of sample sets for all combinations of sampling algorithms.
based on the results we determined the pareto front to illustrate t r a d e o ff sb e t w e e nn u m b e ro fd e t e c t e df a u l t sa n ds i z eo ft h e sample sets.
figure also presents the combinations of sam pling algorithms on the pareto front starting from the most efficient c1 c3 c2 a n dc4.
summary all sampling algorithms are able to detect at least ofthe configuration related faults most enabled disabled pair wise and statement coverage are the most efficientalgorithms some combinations provide a useful balance between sample size and fault detection capabilities.
.
effects of assumptions in the first study we made many simplifying assumptions also made in related studies on sampling .
we ignored constraints header files and build system informa tion and we did a per file analysis only.
in more realisticconditions these assumptions often do not hold for example constraints often exist and ignoring them may lead to false positives but constraints are rarely documented sys tematically and therefore easily ignored.
similarly informa tion from build systems may increase precision but build systems are inherently difficult to analyze .
while the simplifying assumptions allow researchers and practitionersto apply sampling algorithms quickly to a large set of sys tems as we did in our first study their influence on practi cability and effectiveness is not well understood.
therefore in a second study we explore the effect of each assumption on the efficiency of the sampling algorithms.
configuration related faultssamples per filec4 c3c2 c1combination individual pareto front sampling algorithm c1 pair wise and one disabled c2 one enabled one disabled and statement coverage c3 one enabled one disabled and most enabled disabled c4 one enabled one disabled and pair wise faults samples file faults samples file c1 .
c2 .
c3 .
c4 .
figure number of configuration related faults and samples perfile for the combination of algorithms on the pareto front.
basically we replicate the first study for a subset of the corpus investigating how the assumptions affect each sampling algorithm rq4 .
to increase internal validity weconsideredeachassumptionseparatelyasanindependent variable that we manipulate to understand the influence ofeach assumption on sampling.
we limit the second study to faults of the linux kernel andbusybox faults from the first study because these subject systems are the only ones for which we have build system and constraint informationfrom the lvatandtypechef projects .
for the linux kernel we consider additionally seven known faults that cross files which we excluded from our original corpus as we discussed in section .
table summarizes the number of configuration related faults detected sizes of sample sets and the ranking of sampling algorithms per lifted assumption.
.
constraints constraints exclude certain combinations of configuration options e.g.
option x must be selected if option y is selected from the set of valid configurations.
faults identified ininvalidconfigurationsareconsideredfalsepositives which did not occur in the first study because we consider only acorpus of true positives hence sampling invalid configura tions adds no value.
the analyzed version of the linux kernelhas constraint clauses among its configuration options busybox has .
in the original sample sets of the first study many sampled configurations are actually invalid in these highly con strained configuration spaces.
for instance random selects of valid configurations and the percentage goes up to43 when picking most enabled disabled.
sampling within 648table project characterization and the total number of known faults used in the first study.
project application domain loc files configuration options faults apache webserver bash language interpreter bison parser generator busybox unix utilities cherokee webserver cvs version control system dia diagramming software firefox webbrowser fvwm windows manager gcc c c compiler gnome keyring daemon application gnome vfs file system library gnuplot plotting tool irssi irc client libpng png library libssh ssh library libxml xml library lighttpd webserver linux operating system lua language interpreter totem movie player vim text editor xfig vector graphics editor xterm terminal emulator total such constrained spaces is more challenging for all sampling algorithms as solvers or search based strategies are needed.we incorporate constraints as follows most enabled disabled we cannot simply enable all options if some of them are mutually exclusive.
in stead we use a solver to find two valid configurationswith the maximum number of configuration optionsenabled and disabled.
if there are multiple optimal solutions we pick the first offered by the solver.
one enabled disabled similarly for each option we use a solver to identify the valid configuration that disables enables the most other options.
random sampling we randomly assigned trueorfalse for every configuration option inside a file and discardinvalid assignments until we find the desired number ofconfigurations.
truly random sampling in large con strained spaces with many options is still a research problem though with recent progress in theory and recent pragmatic search heuristics .
statement coverage to select a minimal set of covering configurations we need to consider constraints.
conceptually we can use the original implementation ofstatement coverage a sp a r to f undertaker but the tool is not flexible to handle other projects thanlinux.
thus we use an alternative implementationthat we created in previous work .
t wise sampling the covering array tables used in the first study are precomputed often optimal solu tions that however assume independence of all op tions.
recent research investigated strategies to generatet wisecovering arrays for constrained configuration spaces such as splcatool casa and acts .
all tools use heuristics and may produce larger than optimal sampling sets and sampling sets that do not actually achieve full t wise coverage.
togeneratethe pair wise coveringarray weused splcatool.
we failed to generate three wise or even higher covering arrays for the linux kernel even with gb ram we ran out of memory a developer from casaestimated that that the generation could take months and would require a .
tb array to track the covered options.
overall we could not find an alter native to implement the three wise four wise five wise andsix wise algorithms considering constraints existing approaches are intractable for the size and com plexity of the linux kernel.
the changes in sampling algorithms to incorporate constraints changed the efficiency of the algorithms as summar i z e di nt a b l e4 .m o s ta ff e c t e dw e r et w i s es t r a t e g i e s pairwiserequired a larger sample set and detected fewer faults including faults that pair wise should have guarantee to find from the linux kernel because the used heuristics are unsound and do not cover all valid pairs of options.
threewisesampling and beyond was not tractable at all.
the time to compute sample sets increases significantly when adding constraints.
our use of a sat solver required significant additional time and memory to generate the sample sets.
on average we created sample sets for each file in .
seconds without constraints the first study while theanalysis with constraints took .
seconds per file on av erage.
this time represents an increase from minutes toover hours for the linux kernel .
regarding the ranking of algorithms most enabled disabled andstatement coverage remain at top positions see table the t wisealgorithms dropp ed significantly or were not feasible at all.
summary when considering constraints we substantially reducefalse positives but there are high costs for generatingsample sets which are often not optimal.
649table presence conditions of the configuration related faults.
some configuration options enabled a a b a b c a b c d e some configuration options disabled !a !a !b !a !b !c !a !b !c !d !a !b !c !d !e !f !g some options enabled and some disabled !a b a !b a b !c !a !b c a b !c !d a b c !d a b c d !e !a !b !c !d e a !b !c !d !e !f a b !c !d !e !f 124321faultsconfiguration options20406080 .
global analysis to perform global analysis we created a single sample set across all files instead of a distinct set per file.
such global set allows us to perform cross file analysis to find faults that cannot be identified on a per file basis such aslinking problems.
however for global analysis a samplingalgorithm needs to consider all options in the system notjust the subset of options used in each file.
we were not able to generate global sample sets with anyt wisealgorithm at the scale of our subject systems.
the largest precomputed tables we found covered up to 2koptions pair wise or options six wise .
we are not aware of any tool that has the capability to generate covering arrays for such a large number of configuration options even without constraints.
statement coverage also turns intractable asitrequirestosolvethecoverageproblemconsid ering all source files of the project i.e.
equivalent to concatenating all source code into a single file and finding a set of configurations that enabled all optional code blocksat least once .
one enabled andone disabled require substantially larger sample sets as more options are considered from1.7toalmost8k .
random requireslargersamplesets on average because previously we could use smaller sample sets when the file had only few options.
most enableddisabled is the only algorithm for which the size of sample sets was not influenced because it is not sensitive to the number of options and it always selects exactly two configurations.
to explore the ability of global analysis to identify crossfile faults we opportunistically analyzed known faults of thelinux kernel that span multiple files which we had to exclude from our first study.
we detected all seven faults by applying one enabled andone disabled with global analysis.most enabled disabled detected five out of the seven faults and random detected four faults.
the other algorithms are not feasible with global analysis.summary using a global analysis we can potentially detect faultsthat span multiple files it causes an explosion in thenumber of configuration options that leads to large sample sets too large for t wise and statement coverage.
.
header files in c source code variability may be introduced by header files because macros used in ifdefs can have non local effect.
if sampling is applied only to variability in the main c source file faults stemming from variability in header filesmay not be detected.
for example a function may not bedeclared in all configurations of the header a type name may be defined as either intorlongdepending on configuration decisions in the header or a macro may be defined in the header only in some configurations.
precisely analyzingheader variability is challenging though due to the interaction of include directives with conditional compilation and macros.
precise analyses exist but are challenging and time consuming to use because one needs to set upthe environment with all header files used by the project.
incorporating header files increases the number of configuration options per file significantly.
for instance whereas the files of the linux kernel contain on average distinct configuration options when ignoring variability from header files headers add another distinct configuration options on average.
this increases the size of the sample set for all algorithms except for most enabled disabled.f o r statementcoverage five wise a n dsix wise our subject systems reach configuration spaces for which these algorithms become in tractable.
since our corpus does not include faults caused by misconfigurations from header files most algorithms detect thesamefaults.
the one enabled algorithmdetectedmorefaults becauseincludingconfigurationoptionsfromheadersallowed it to disable more options while enabling one at a time.
summary when incorporating header files there is a potential to detect additional faults from header files but the setup isdifficult and the sample sets are much larger if feasibleat all which lead to ranking changes.
.
build system information the build system controls which files are compiled and included.
files may be included only when specific configura tion options are selected or may be compiled with additionalparameters.
this is equivalent to wrapping an additional ifdefaround each source file or define additional macros in the beginning of a file.
like ignoring constraints ignoring build system information can lead to false positives wherefaults are reported in configurations that are prevented in practice by the build system.
build systems often have a strong influence on the configurability of a system for instance in the linux kernel of source files are compiled only in certain configurations inbusybox.
still extracting configuration knowledge from build systems is very difficult.
while linuxandbusyboxhave been analyzed with specialized parsers that recognize common patterns and more modern build sys tems use a more declarative style which is easier to analyze analyzing make files in general is an open research problem with only few initial solutions .
650table number of faults size of sample sets and ranking considering the faults of the second study.
algorithms constraints global analysis header files build system faults configs rank faults configs rank faults configs rank faults configs rank pair wise .
three wise .
four wise .
five wise .
six wise most enabled disabled .
.
.
.
one enabled .
.
one disabled .
.
random .
.
.
stmt coverage .
.
some algorithms do not scale indicated using dashes .
we use and to represent small changes in the number of faults and size of sample set as compared to our first study and we use and to represent larger changes.
considering build system information the presence conditions of faults become more complex because we include the condition when the file is compiled whereas withoutbuild system information of all faults of our corpus canbe found by enabling or disabling a single option only can be found the same way with build system information.
by requiring more options to pinpoint faults incorporat ing build system information decreases the efficiency of al gorithms.
pair wise three wise most enabled disabled a n d one enabled detected fewer faults than in the first study.
t h es i z e so ft h es a m p l es e t sa r es l i g h t l yi n c r e a s e di na l l sampling algorithms except most enabled disabled as we consider additional configuration options used in the buildsystem.
time required to compute sample sets is increased only by a few milliseconds.
summary including build system information requires to consider more configuration options in most files but does notsignificantly affect any sampling algorithm or their effi ciency.
.
threats to v alidity regarding external validity we studied only systems that implement variability with conditional compilation and cannot generalize to systems that use other mechanisms to implement variability.
regarding internal validity the corpus of faults is critical for our research strategy.
creating a representative corpus is difficult primarily because we have no means of knowing all faults in the system.
we address this threat with twostrategies we avoided biasing our corpus to any specific samplingalgorithm.
as the corpus has been partially mined from software repositories it might be biased towards more popular system configurations.
still our cor pus is the most comprehensive corpus of configuration related faults we are aware of.
we conducted a complimentary experiment using anautomated bug finding technique instead of a corpusof known faults.
this experiment yielded comparableresults and complements and confirms the first studyon our corpus.
in a nutshell we measured with which sampling algorithm the bug finding technique static analysis with cppcheck would expose the most warnings per sampled configuration.
the experiment intro duces a different threat to internal validity in terms of false positives but triangulating the results across both setups with orthogonal threats increases confi dence in our findings.
we omit details for space reasons and refer the interested reader elsewhere .
.
guidance for practitioners ourstudyprovidesempiricalevidenceabouttheefficiency and typical sample sizes for analyzing configurable c code with various sampling algorithms both under ideal and real world conditions.
there is not a single sampling algorithm thatisoptimalforallsystemsandinallconditions butpractitioners can use our results to identify plausible candidatesfor their purposes.
for instance during initial phases of a project when developers are changing the source code frequently they may prefer sampling algorithms with small sample sets to run the analysis fast.
at some point such as before a release developers might want to use algorithms with larger sam ple sets to minimize the number of configuration related faults.
under favorable conditions that is without considering constraints global analysis header files and build system information all algorithms scale in practice we rec ommend t wisesampling with a high tfor rigorous testing and simpler sampling algorithms such as most enableddisabled pair wise statement coverage and combinations of these for quicker early runs.
combining many and expen sive sampling strategies does bring only marginal benefitsbut requires very large sample sets we do not recommend them.
whenconsideringheaderfiles constraints andglobalanalysis we recommend to go for simple algorithms such as most enabled disabled because many other algorithms be come intractable in practice as presented in table .
again while no algorithm fits all contexts we hope that ourdatawillhelppractitionerstoidentifysuitablecandidatesampling algorithms for their specific scenario.
.
related work several researchers have studied the way developers use the c preprocessor.
they performed empirical studies with open source systems written in c that are statically configurable with the c preprocessor .
liebig et al.
found that almost of the preprocessor usage is undisci plined according to an empirical study of c software sys tems.
in a previous study we interviewed developers and performed a survey with developers to understand whythecpreprocessorisstillwidelyusedinpracticedespitethe strong criticism the preprocessor receives in academia.according to our results developers check only a few configurations of the source code.
all these studies discussed the 651c preprocessor and its problems such as faults inconsistencies code quality and incomplete testing.
these studies motivated us to analyze sampling algorithms to support developers in finding configuration related faults.
other studies have analyzed software repositories by considering faults already fixed by developers to understand thecharacteristics of configuration related faults .
in particular researchers analyzed configuration related faults in dynamic configurable systems .
they concluded thatthe majority of configuration related faults involve a fewconfiguration options a result similar to ours.
abal et al.
analyzed the linux kernel software repository to study configuration related faults.
tartler et al.
also performed studies to find configuration related faults in the linux kernel.
in our study we considered some configuration related faults reported by these previous studies.
in addition there are several studies proposing tools to find faults such as undertaker tracker and splint .
researchers have proposed various strategies to deal with configuration related faults.
they considered combinatorial interaction testing to check different combinations of config uration options and prioritize test cases .
nie et al.
performed a survey with combinatorial test ing approaches but without considering the complexities ofc such as header files and build system information.
most studies on sampling make assumptions that might not be realistic in practice such as ignoring constraints among con figuration options.
including constraints build system in formation and header files is a non trivial task.
several researchers used the t wisesampling algorithm to cover all t configuration option combinations many studies without considering constraints .
otherresearchers proposed the statement coverage sampling algorithm and applied a per file analysis.
abal et al.
suggested the one disabled algorithm.
s anchez et al.
studied realistic settings and studied the use of non functional data for test case prioritization.
other researchers appliedt wisealgorithms with constraints and grindal et al.
studied different constraint handling methods.
how ever a comparative study to understand the fault detectioncapability and effort size of sample set of sampling algo rithms and the influence of limiting assumptions on sam pling was not covered in previous studies.
k astner et al.
developed a variability aware parser that analyzes all possible configurations of a c program simultaneously.
it also performs type checking and data flow analysis .
gazzillo and grimm developed a similar parser.
in our work we considered faults detected by typechef and reported in previous studies .
difficulties in setting up these tools and narrow classes of detectablefaults limit their applicability and lead to false positives.in addition variability aware tools work at the preprocessor level which hinders the reuse of existing bug checkers of traditional c tools including gccandclang.
somestudieshavecomparedsample basedandvariabilityaware strategies.
apel et al.
developed a model checking tool for product lines and used it to compare sample based and variability aware strategies with regard to verificationperformance and the ability to find defects.
liebig et al.
performed studies to detect the strengths and weaknesses ofvariability aware and sampling based analyses.
they considered two analysis implementations type checking and liveness analysis and applied them to a number of sub ject systems such as busybox and the linux kernel .i n our study we performed complimentary analyses regardingsampling algorithms and filled a gap by comparing samplingalgorithms considering the influence of assumptions made in previous studies.
.
concluding remarks we compared sampling algorithms.
our study makes a step toward understanding the tradeoffs between effort i.e.
how large are the sample sets and fault detection capabilities i.e.
how many faults can be found in the selected configurations .
in a first study we used a corpus of configurationrelated faults from popular c projects reported in pre vious studies.
we initially ran the comparison accepting some assumptions and we ignored configuration constraints header files and build system information and we applieda per file analysis.
the results reveal that all sampling al gorithms selected configurations that include at least of the faults reported in previous work.
as expected the algorithms with the largest sample sizes detected themost faults.
more interestingly we identified several combi nations of algorithms that provide a useful balance betweensample size and fault detection capabilities.
subsequently we performed a complementary study to measuretheinfluenceofconsideringconstraints globalanal ysis header files and build system information on sampling.we found that when considering constraints we can reduce false positives but it increases the costs for generating sample sets which are often not optimal.
using a global analy sis we can potentially detect non modular faults that spanmultiple files but it causes an explosion in the number ofconsidered configuration options that leads to large sample sets.
when incorporating header files there is a potential todetect additional faults but the setup is difficult and the algorithms produce much larger sample sets.
when includingbuild system information we face a difficult analysis a few more configuration options to consider but no significant changes.
overall we found that global analysis and analy ses that include configuration options from header files turnthe analysis to be practically infeasible for most algorithms.
our study fills a gap as a comparison of sampling algorithms for finding configuration related faults was not avail able.
ourfindingsaremeanttosupportdevelopersinunder standing the tradeoffs regarding effort and fault detectioncapabilities of sampling algorithms aiding developers in selecting an algorithm and deciding what kind of information they include in the analysis.
a lack of understanding thetradeoffs and assumptions of sampling algorithms can leadto both undetected faults which decreases software quality and time consuming code analysis which increases costs.