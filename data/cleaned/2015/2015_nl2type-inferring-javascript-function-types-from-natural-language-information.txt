nl2type inferring javascript function types from natural language information rabee sohail malik tu darmstadt germany sohail.rabee gmail.comjibesh patra tu darmstadt germany jibesh.patra gmail.commichael pradel tu darmstadt germany michael binaervarianz.de abstract javascript is dynamically typed and hence lacks the type safety of statically typed languages leading to suboptimal ide support difficult to understand apis and unexpected run time behavior.
several gradual type systems have been proposed e.g.
flow and typescript but they rely on developers to annotatecode with types.
this paper presents nl2type a learning basedapproach for predicting likely type signatures of javascriptfunctions.
the key idea is to exploit natural language informationin source code such as comments function names and parameternames a rich source of knowledge that is typically ignoredby type inference algorithms.
we formulate the problem ofpredicting types as a classification problem and train a recurrent lstm based neural model that after learning from an annotatedcode base predicts function types for unannotated code.
weevaluate the approach with a corpus of javascriptfiles from real world projects.
nl2type predicts types with aprecision of .
and a recall of .
when considering onlythe top most suggestion and with a precision of .
and arecall of .
when considering the top suggestions.
theapproach outperforms both jsnice a state of the art approachthat analyzes implementations of functions instead of naturallanguage information and deeptyper a recent type predictionapproach that is also based on deep learning.
beyond predictingtypes nl2type serves as a consistency checker for existingtype annotations.
we show that it discovers inconsistenciesthat deserve developer attention from a manual analysis of 50warnings most of which are due to incorrect type annotations.
index t erms javascript deep learning type inference comments identifiers i. i ntroduction javascript has become one of the most popular programming languages.
it is widely used not only for client side web applications but e.g.
also for server side applications runningon node.js desktop applications running on electron and mobile applications running in a web view.
however unlike many other popular languages such as java and c javascript is dynamically typed and does not require develop ers to specify types in their code.
while the lack of type annotations allows for fast prototyping it has significant drawbacks once a project grows andmatures.
one drawback is that modern ides for other lan guages heavily rely on types to make helpful suggestions forcompleting partial code.
for example when accessing the fieldof an object in a java ide code completion suggests suitablefield names based on the object s type.
in contrast javascript calculates the area of a rectangle.
param number length the length of the rectangle.
param number breadth the breadth of the rectangle.
returns number the area of the rectangle in meters.
may also be used for squares.
getarea function length breadth return length breadth fig.
function with jsdoc annotations.
the annotationsinclude comments parameter types and the return type.
ides often fail to make accurate suggestions because the types of the code elements are unknown.
another drawback is thatapis become unnecessarily hard to understand sometimesforcing developers to guess what types of values a functionexpects or returns.
finally type errors that would be detectedat compile time in other languages may remain unnoticed injavascript which causes unexpected runtime behavior.
to mitigate the lack of types in javascript several solutions have been proposed.
in particular gradual type systems suchas flow developed by facebook and typescript devel oped by microsoft use a combination of developer providedtype annotations and type inference to statically detect typeerrors.
a popular format to express types in javascript arejsdoc annotations.
figure shows an example of such anno tations for a simple javascript function.
the main bottleneckof these existing solutions is that they rely on developers toprovide type annotations which remains a manual and time consuming task.
previous work has addressed the type inference problem through static analyses of code .
unfortunately thehighly dynamic nature of languages like javascript preventthese approaches from being accurate enough in practice.
inparticular analyses that aim for sound type inference yieldvarious spurious warnings.
this paper addresses the type inference problem from a new angle by exploiting a valuable source of knowledge thatis often overlooked by program analyses the natural languageinformation embedded in source code.
we present nl2type a learning based approach that uses the names of functionsand formal parameters as well as comments associated withthem to predict a likely type signature of a function.
typesignature here means the types of function parameters and the ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
return type of the function e.g.
expressed via param and return in figure .
we formulate the type inference task as a classification problem and show how to use an lstmbased recurrent neural network to address it effectively and efficiently.
the approach trains the machine learning model based on a corpus of type annotated functions and then predicts types for previously unseen code.
there are four reasons why nl2type works well in practice.
first developers use identifier names and comments to communicate the semantics of code.
as a result most humanwritten code contains meaningful natural language elements which provide a rich source of knowledge.
second source code has been found to be repetitive and predictable even across different developers and projects .
third probabilistic models such as the deep learning model used by nl2type are a great fit to handle the inherently fuzzy natural language information .
finally our work benefits from the fact that some developers annotate their javascript code with types giving nl2type sufficient data to learn from.
we are aware of two existing approaches jsnice and deeptyper that also use machine learning to predict types in javascript.
jsnice analyzes the structure of code in particular relationships between program elements to infer types.
instead we consider natural language information which allows nl2type to make predictions even for functions with very little code.
moreover our approach is languageindependent as it does not depend on a language specific analysis to extract relations between program elements.
deeptyper uses a sequence to sequence neural network to predict a sequence of types from a sequence of tokens.
similar to us they also consider some natural language elements of the code.
however their approach considers only identifier names not comments missing a valuable source of type hints and they frame the problem as sequence to sequence translation while we frame it as a classification problem.
we envision nl2type to be valuable in several usage scenarios.
for code that does not yet have formal type annotations the approach serves as an assistance tool that suggests types to reduce the manual annotation effort.
for code that already has type annotations nl2type checks for inconsistencies between these annotations and natural language information which exposes incorrect annotations misleading identifier names and confusing comments.
another usage scenario is improving type related ide features such as code completion or refactoring for code that does not have any type annotations.
we evaluate nl2type with javascript files from open source projects.
after learning from a subset of these files the approach predicts types in the remaining files with a precision of .
and a recall of .
giving an f1score of .
.
when considering the top suggested types precision and recall even increase to .
and .
respectively.
comparing our approach to jsnice and deeptyper we find that nl2type significantly outperforms both approaches.
when combining nl2type with jsnice we find that .
of all correctly predicted types are found exclusively by nl2type showing that our approach not onlydata extraction preprocessing data representation neural network learning nl2type modelcorpus of annotated functions new functionlikely type signaturenl information and types canonicalized nl and types vector prepresentations fig.
overview of the approach.
improves upon but also complements existing work.
beyond predicting likely types for code where annotations are missing we use nl2type to check for inconsistencies in existing type annotations.
we rank the reported inconsistency warnings by the confidence of the prediction and manually inspect the top .
out of warnings are valuable in the sense that developers should fix an incorrect type annotation or improve a misleading natural language element in the code.
finally the approach is efficient enough for practical use.
training takes minutes in total and predicting types for a function takes 72ms on average.
in summary this paper contributes the following the insight that natural language information is a valuable yet currently underused source of information for inferring types in a dynamically typed language.
a neural network based machine learning model that exploits this insight to predict type annotations for javascript functions.
empirical evidence that the approach is highly effective at suggesting types and that it clearly outperforms state ofthe art approaches.
empirical evidence that the approach is effective at finding inconsistencies between type annotations and natural language elements a problem not considered before.
ii.
l earning a model to predict types this section describes nl2type our learning based approach for predicting the type signatures of functions from natural language information embedded in code.
figure gives an overview of the approach which consists of two phases alearning phase shown in blue in the top part of the figure which learns a neural model from a corpus of code with type annotations and a prediction phase shown in gray in the bottom part of the figure which uses the learned model to predict types for previously unseen code.
to prepare the given code for learning a lightweight static analysis extracts natural language and type data section ii a and preprocesses these data using natural language processing techniques section ii b .
section ii c describes how nl2type transforms the data into a representation that captures the semantic relations between words which is then fed into a neural network that authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
extracted function data nf cf cr tr getarea calculates the area of a rectangle.the area of the rectangle in meters.
may also be used for squares.number preprocessed function data nf cf cr tr get area calculate area rectanglearea rectangle meter may also use squarenumber fig.
example of data extraction and preprocessing.
learns to predict type signatures section ii d .
once the model is trained querying it with natural language information extracted from a previously unseen function yields a likely type signature for the function section ii e .
a. data extraction the goal of the data extraction step is to gather natural language information and type signatures associated with functions.
to this end a lightweight static analysis visits each function in the given corpus of code.
we focus on functions with jsdoc annotations an annotation format that is widely used to specify comments and types.
for each javascript function the analysis extracts the following definition function data for a given function f the extracted function data is a tuple nf cf cr tr p where nf name of the function f cf comment associated with f cr comment associated with return type of f tr return type of f p sequence of parameter data the sequence pof parameter data is a sequence of tuples np cp tp where np name of the formal parameter p cp comment associated with p tp type of p for example the upper table in figure shows the function data extracted from the javascript code in figure .
we omit the parameter data for space reasons.
b. preprocessing to prepare the natural language information extracted in the previous step for effective learning nl2type automatically preprocesses the function data using natural language processing techniques.
the goal of this step is to canonicalize natural language words and to remove uninformative words.
at first we tokenize all natural language data into words.
the approach tokenizes the extracted comments cf cr and cp on the space character.
for the extracted names of functions and parameters nfandnp we tokenize each name based on the camel case convention which is the recommended naming convention in javascript.
for example the name getrectanglearea is tokenized into three words get rectangle and area .
beyond camel case other tokenization techniques for identifier names could be plugged into nl2type.
after tokenization the approach removes all punctuation except for periods and converts all characters to lowercase.
by converting to lowercase we reduce the vocabulary size without losing much semantic information.
the approach also removes stopwords i.e.
words that appear in various contexts and therefore do not add much information such as the and a .
finally the approach lemmatizes all words i.e.
it reduces the inflicted forms of a word e.g.
running runs ran to its base form e.g.
run .
for our running example in figure the lower table in figure shows the function data after preprocessing.
c. data representation to feed the extracted data into a machine learning model we need to represent it as vectors.
the following describes our vector representations of natural language words and of types.
representing natural language information to enable nl2type to reason about the meaning of natural language words we build upon word embeddings a popular technique to map words into a continuous vector space.
the key property of embeddings is to preserve semantic similarities by mapping words that have a similar meaning to similar vectors.
for example assuming we map words into a dimensional space then nation and country may have vectors and .
in practice embeddings map words into larger spaces we use vectors of length for our evaluation.
more formally a word embedding is a map e v rk that assigns to each word w vin the vocabulary a kdimensional vector of real numbers.
to learn word embeddings nl2type builds upon word2vec which takes a set sof sentences composed of words in vand learns the embedding of a word wfrom the contexts in which w occurs.
context here means the words preceding and following w where the number of context words to consider is a configurable parameter ten in our evaluation .
nl2type learns two word embeddings an embedding ec for words that occur in comments and an embeddings enfor words that occur in identifier names.
the rationale for having two instead of just one embedding is that identifier names tend to contain more source code specific jargon and abbreviations than comments.
to learn ec the set of sentences sconsists of all sequences of words in the preprocessed comments cf cr and cp.
for example for the word rectangle in the lower table in figure the comments cfandcrgive two sequences of words in which rectangle occurs.
for a larger corpus of code many more such sequences are available.
similarly to learn en the set of sentences sconsists of the sequences of words in the preprocessed identifier names nfandnp.f o r both embeddings we consider only words that occur at least five times in the training data to prevent the embedding from overfitting to few contexts.
a possible alternative to learning word embeddings from data extracted from a code corpus would be to use publicly available pre trained embeddings e.g.
the google news word authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
embeddings.1however such pre trained embeddings are typically trained on sentences that use a different vocabulary than that found in real world javascript code or on sentences where some words have a different meaning than in source code.
for example words like push or float may have a different meaning in a programming context than in common usage while other words e.g.
int occur often in a programming context but not at all in common usage.
representing types in addition to the natural language information which is the input to nl2type we must also represent the to be predicted types as vectors.
given the set tallof all types that occur either as a function return type tf or as a parameter type tpin the training corpus the approach focuses on a subset t tallof frequently occurring types.
the reason for bounding the size of tis that types have a longtail distribution i.e.
a few types occur very frequently while many other types occur only rarely section iv f .
predicting more frequent types covers a large percentage of all type occurrences whereas predicting less frequent types is more difficult as there is less data to learn from.
for a specific size t we select the t 1most frequent types from tall and add an artificial type other that represent all other types and that indicates that nl2type cannot predict the type.
the size of tis a configuration parameter and we evaluate its influence in section iv f. for the evaluation we consider the most common types including the built in types of the javascript language e.g.
boolean andnumber and custom types e.g.
graphics andpoint3d .
given the set t we represent a type t tusing a one hot vector i.e.
a vector of length t where all elements are zero except for one specific element set to one for each word.
for example the type boolean may be represented by a vector that consists of zeros and a single one.
d. training the model based on the vector representations of natural language information and types nl2type learns to predict the latter from the former.
we use a neural network based machine learning model for this purpose because neural networks have been shown to be highly effective at reasoning about natural language information.
specifically we adopt a recurrent neural network based on long short term memory lstm units.
recurrent neural networks are well suited for ordered input data such as sequences of natural language words.
lstms are effective for data with both long term and short term dependencies.
they have been successfully applied to a number of problems in natural language processing that are similar to our classification problem such as sentiment analysis which classifies texts into different categories .
the following describes the data points used for training the model and the architecture of the neural network.
data points we transform the extracted and preprocessed function data into a set of data points.
each data point represents a single type and the natural language information with it.
we distinguish two kinds of data points one for return types and another for parameter types.
definition data points a data point is a pair n t of natural language information nand a type t. given the function data nf cf cr tr p of a function where pis a sequence p n1 p c1 p t1 p .. n p p c p p t p p of parameter data we have two kinds of data points one data point for the return type with n nf cf cr n1 p .. n p p andt tr.
p data points for the parameter types with n ni p ci p andt ti p. for example for the function in figure there are three data points for the return type n area calculate area rectangle area rectangle meter may also use square length breadth t number for the first parameter n length length rectangle t number for the second parameter n breadth breadth rectangle t number given a set of data points n t the task solved by the neural network is to predict tfrom n. we train a single model for both return types and parameter types because both tasks are similar and it enables the model to learn from all available data.
to feed data points into the neural network we transform each data point into a sequence of input vectors and an output vector using the vector representations from section ii c. intuitively the input is the sequence of embeddings of words in the natural language information n and the output vector is the vector representation of the type t. to formally define the input vectors consider a helper function e w1 .. w l rl kthat takes a sequence of lwords maps each word to a vector representation using the embedding function e w rk and then yields the sequence of these vectors.
the embedding erefers to en andecfor names and comments respectively as described in section ii c. to ensure that all input vectors have the same length l k no matter how many natural language words the static analysis could extract from the source code the helper function e truncates word sequences to a maximum length and pads word sequences that are too short with zeros.
we discuss and evaluate the length limits in section iv f. based on this helper function the input for a data point that represents a return type is the following sequence of vectors where chains vectors into a sequence kret e cf e n1 p ... e n p p e nf e cr likewise the input for a data point that represents a parameter type is the following sequence of vectors kparam e cp z ... z e np e cr the vectors kretandkparam are special marker vectors that indicate to the network what kind of type to predict i.e.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
e w1 e w n hidden layer softmax layer lstm t1 t1 t2 tntn 1tn e w2 lstm lstm lstm lstm lstm fig.
architecture of neural network used in nl2type.
whether the type is a return type or a parameter type.
making the kind of type explicit enables the network to distinguish between both kinds if necessary.
the zvectors are padding vectors of zeros that we use to ensure that the input sequences of return types and parameter types have the same length.
in addition to concatenating vectors each also inserts a vector of ones into the sequence as a delimiter between the different natural language elements which helps the network understand the structure of the data.
for instance recall the three examples of data points given above.
the natural language part nof each of them is transformed into a sequence of real valued vectors based on the embeddings of the natural language words in n. due to the padding all three sequences have the same length.
neural network architecture given the data points described above nl2type learns a function m rx k mapsto r t where xis the total number of word embeddings in an input sequence and t is the number of types we are trying to predict.
using the length limits as set in our evaluation the network maps a sequence of x vectors of length k to a vector of length t .
to learn the function m we use a bi directional lstmbased recurrent neural network as illustrated in figure .
the network takes a sequence of rkvectors at each step consumes one vector and updates its internal state represented by the lstm nodes .
after consuming all the vectors for a single data point the network feeds the internal state through a hidden layer to the output layer.
the output layer uses the softmax function which yields a vector of real valued numbers in so that the sum of all numbers is equal to one.
that is the output can be interpreted as a probability distribution.
during training the backpropagation algorithm adapts the weights of the network to minimize the error between the predicted and the expected type.
e. prediction once the model is sufficiently trained it can predict the types of previously unseen functions.
to query the model with a new function we extract and preprocess all natural language information associated with the function and create one sequence of input vectors for each type associated with the function i.e.
one sequence for the return type and one sequence for each parameter type .
then each such input sequence is given to the network which yields a type vectorinr t .
the type vector can be interpreted as a probability distribution over the types in t. for example suppose that t number boolean function other and that the predicted type vector is .
we interpret this prediction as a probability that the type is number that the type is boolean that the type is function and that the type is any other type.
if the most likely type is other the network essentially says that it cannot predict a suitable type for the given natural language information.
iii.
a pplications the previous section describes a general model to predict the return type and the parameter types of functions from natural language information.
this model has several applications which we present in the following.
all these applications query nl2type as described in section ii e. a. suggesting type annotations the perhaps most obvious application of nl2type is to support developers in the process of annotating code with types by suggesting type annotations.
adding type annotations to functions enables an effective use of type systems for javascript such as flow and typescript and it provides useful api documentation.
for the large number of functions in legacy javascript code without type annotations nl2type can suggest types during the annotation process.
to this end the developer queries the model for each type and uses the predicted type vector as a ranked list of type suggestions.
b. improving type based ide features ides use type information for making suggestions to developers such as how to complete partial code.
for example consider a developer that implements the body of a function and wants to access a property of a parameter of this function.
without type information the ide cannot make any accurate suggestions about the property name.
for example the popular webstorm ide will simply suggest an alphabetically ordered list of all identifier names used in the current file.
nl2type can improve these suggestions by probabilistically predicting the parameter type of the function which the ide can then use to prioritize the suggested property names.
c. detecting inconsistencies in addition to predicting types for functions that are not yet type annotated nl2type can check existing type annotations for inconsistencies.
in this scenario the approach checks whether the natural language information associated with a type matches the annotated type.
finding mismatches is useful for fixing broken type annotations for changing misleading identifier names and for improving confusing comments.
given an annotated function type we query the nl2type model with the natural language information associated with the type and compare the type predicted as the most likely with the actual type.
to avoid overwhelming developers with spurious inconsistencies the approach ranks all inconsistencies by how certain the model is in its prediction.
one possible authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ranking approach would be to consider the predicted type vectors and to rank inconsistencies by the highest probability in each vector.
for example suppose the type vector is but the type represented by the first element does not match the annotated type.
based on the type vector the model appears to be very certain of its prediction and we would rank this inconsistency high.
unfortunately this naive ranking approach does not work well in practice because neural networks tend to be too confident in their predictions.
the underlying reason as shown by guo et al.
is that for a softmax function over more than two classes the output of the softmax function is not a true probability distribution.
instead of ranking inconsistencies by the highest value in the type vector we compute a more reliable estimate of the network s confidence .
the key idea is to use dropout i.e.
to purposefully deactivate some neurons during prediction and to measure how much it influences the outcome of the prediction.
for every sequence of input vectors we query the model multiple times each time deactivating some probabilistically selected neurons and record the predicted type vectors.
we then measure the variance of the type vectors and consider a prediction with lower variance to be more confident.
finally we rank all potential inconsistencies by their confidence and report the ranked list to the developer.
iv .
e v aluation our evaluation on real world javascript code focuses on the following research questions rq1 how effective is nl2type at predicting function type signatures from natural language information?
rq2 how does the approach compare to existing type prediction techniques ?
rq3 how useful is nl2type for detecting inconsistencies in existing type annotations?
rq4 what is the influence of hyperparameters such as the number t of considered types on the effectiveness of nl2type?
rq5 is nl2type efficient enough to be applied in practice?
our implementation and data to reproduce our results are available at a. implementation we implement nl2type in python based on several existing tools and libraries.
for the data extraction the implementation parses every javascript file using the jsdoc tool which extracts the comments the function name and the parameter names of a function.
the preprocessing including removing stopwords and lemmatization is implemented based on the python nltk library .
to convert natural language words into embeddings we use gensim s word2vec module .
the neural network that predicts types from a sequence of embeddings is implemented on top of keras a high level deep learning library using tensorflow as a backend .table i precision recall and f1 score as percentages of nl2type with and without considering comments and of a naive baseline.
approach top top top prec.
rec.
f1 prec.
rec.
f1 prec.
rec.
f1 nl2type .
.
.
.
.
.
.
.
.
nl2type w o comments .
.
.
.
.
.
.
.
.
naive baseline .
.
.
.
.
.
.
.
.
b. experimental setup we evaluate nl2type on a corpus of javascript files composed of a corpus from prior work and popular javascript libraries downloaded from a content delivery service .
following common practice in large scale machine learning including on software we divide these files into disjoint sets of training files and testing files .
a fixed split into training data and validation data instead of k fold cross validation reduces computational cost yet gives accurate results due to the large amount of available data.
for all files we extract data points as described in section ii which gives a total of data points.
.
and .
of them are for function return types and parameter types respectively.
not all data points contain all pieces of natural language information.
in particular .
of all data points do not contain a comment cforcp.
given the data extracted from the training files we train the embeddings and our model and then use the data extracted from the testing files to evaluate the trained model.
all experiments are run on an ubuntu .
computer with an intel xeon e5 processor with cores 64gb of memory and an nvidia tesla p100 gpu with 16gb of memory.
c. rq1 effectiveness at predicting types metrics to evaluate the effectiveness of nl2type in predicting types we measure precision recall and f1 score.
intuitively precision is the percentage of correct predictions among all predictions and recall is the percentage of correct predictions among all data points.
the f1 score is the harmonic mean of precision and recall.
similar to previous work we report these evaluation metrics for the top k predicted types assuming that a user of nl2type inspects up to ksuggested types.
we also report the top 1results which means that the user considers only the single most likely predicted type.
we define top kprecision as precision pred corr pred allwhere pred corr is the number of predictions where the actual type is in the top kandpred allis the number of data points for which the model makes a prediction at all.
if the model suggests other as the most likely type it indicates that it cannot make a good prediction and we count it neither in pred allnor in pred corr.
the top krecall is defined as recall pred corr dps where dpsis the number of all data points.
results table i shows the precision recall and f1score of the type predictions.
the first row shows the default approach as described in section ii.
when considering the first authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
get the appropriate anchor and focus node offset pairs for ie.
param domelement node return object function getieoffsets node ... fig.
function with correctly predicted type signature.
fig.
relation between f1 score and amount of data available for a type.
suggested type only the approach achieves .
precision with a recall of .
.
when considering the top suggested types the precision and recall increase to .
and .
respectively.
the results for parameter types and for return types are similar to each other showing that nl2type is effective for both kinds of types.
for example figure shows a function for which nl2type correctly predicts the parameter type and the return type.
note that the parameter type domelement is not a built in javascript type but nevertheless predicted correctly presumably from the words node and ie .
overall these results show that the approach is highly effective at making accurate type suggestions for the majority of javascript functions.
to better understand whether the effectiveness depends on the amount of training data figure shows for the ten most common types the f1 score along with the number of data points for the type.
we find little correlation between the amount of available data and the prediction s f1 score suggesting that the data we train nl2type on is sufficient for commonly used types in javascript.
interestingly the f1 scores differ between types presumably because some types are more likely than others to have a comment or name that reveals the type.
for example functions with return type boolean often have a name that begins with is or has while for object inferring the type is less straightforward.
because not all functions come with comments but all functions and their parameters have a name we also evaluate a variant of nl2type that does not consider any comments.
instead the input given to the neural network consist only of the function name and parameter names.
the second row in table i shows the results for this variant of the approach.
as expected the precision recall and f1 score are lower than for the full approach because some valuable parts of the input are omitted.
however the approach still makesaccurate suggestions that are likely to be useful in practice.
we conclude from these results that using comments as part of the input considered by nl2type is beneficial but that comments are not essential to the effectiveness of the approach.
we also compare nl2type to a naive baseline that simply predicts the kmost common types every time it is queried.
in particular when asked for the top type suggestion the baseline always suggests string because this is the most common type.
the third row in table i shows the effectiveness of this baseline.
nl2type is clearly better than the baseline e.g.
improving the f1 score for the top suggestion by a factor of .5x.
d. rq2 comparison with prior work the two closest existing approaches are jsnice and deeptyper .
both use the implementation of a function to infer the function s type signature whereas our approach ignores the function implementation and instead focuses on natural language information associated with the function.
jsnice uses structured prediction on a graph of dependencies that express structural code properties such as what kind of statement a variable occurs in.
similar to our work they train their model with existing type annotated javascript code.
deeptyper is similar to our work in the sense that they also use a neural network model.
however they train the model with an aligned code corpus i.e.
pairs of typescript and javascript programs which are generated from existing typescript code.
comparison with jsnice to compare with jsnice we download their publicly available artifact and train a model with the same training data as for nl2type using the command line arguments given in the artifact s readme file.
we run the tool with a time limit of two minutes per file and remove any files that exceed that limit from the training corpus of both jsnice and nl2type.
in total files are removed for this reason.
once trained we evaluate jsnice on our testing set.
because jsnice tries to predict types only for minified files we minify the testing files using a script provided in the jsnice artifact.
all results reported for jsnice are for the top suggestion only because the jsnice artifact reports only the most likely type suggestion.
beside types jsnice also predicts other code properties e.g.
identifier names we consider only the predicted parameter types and return types for our comparison.
the precision achieved by jsnice is .
with a recall of .
which gives an f1 score of .
.2comparing these results to those in table i shows that nl2type clearly outperforms the state of the art approach.
in particular the f1 score of nl2type is .
higher than that of jsnice which is a significant improvement.
one reason why nl2type outperforms jsnice is that it successfully predicts types for functions independent of the amount of code in the function body whereas jsnice relies on type hints provided by the function body.
to evaluate to what extent nl2type and jsnice 2note that our definition of recall is different from the one used in which defines recall as the percentage of data points for which any prediction is made either correct or incorrect.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
venn diagram showing the overlap of data points correctly predicted by nl2type and jsnice.
utility function to ensure that object properties are copied by value and not by reference private param object target target object to copy properties into param object source source object for the proporties to copy param string propertyobj object containing properties names we want to loop over function deepcopyproperties target source propertyobj ... fig.
incorrect type annotation found by nl2type our model correctly predicts the third parameter to be object .
complement each other figure shows how many of the correctly predicted types overlap.
the figure considers the top predictions only.
of all data points that are predicted correctly by either nl2type or jsnice .
are predicted only by nl2type while .
are predicted only by jsnice.
overall these results show that our approach of considering natural language information complements and improves upon prior work that focuses on the implementation of a function.
comparison with deeptyper we compare with deeptyper based on their publicly available artifact .
as we do for jsnice we compare the top predictions of deeptyper and compute our precision and recall metrics.
for a fair comparison we implement a typescript frontend for nl2type and then use the typescript data set used in .
nl2type achieves a precision of .
and a recall of .
compared to .
precision and .
recall by .3that is when using the same data set for both approaches our model significantly improves precision while slightly improving recall.
the results of nl2type are less strong than when applying it to the javascript data set because the typescript data set is smaller and because its types have a longer tail distribution.
e. rq3 usefulness for detecting inconsistencies an application of nl2type that goes beyond predicting types in code without type annotations is as a tool to detect inconsistencies in existing type annotations.
to evaluate the usefulness of nl2type for this task we get a ranked list of 3the results differ from those reported in for two reasons i we use a different definition of recall pred corr dpsand notpred all dps .
ii we do not apply any confidence threshold when using deeptyper whereas their best precision recall results are with a threshold optimized after the fact.
tests to see if a point x y is within a range of current point param numeric x the x coordinate of tested point param numeric y the x coordinate of tested point param numeric radius the radius of the vicinity near function x y radius var distance math .sqrt math .pow this .
x x math .pow this .y y return distance radius fig.
non standard type annotation detected by nl2type our model predicts the parameters to have type number b u t the code annotates them as numeric which is not a legal javascript type.
calculate the average of two 3d points param point3d a param point3d b return point3d the average a b point3d.avg function a b return new point3d a.x b.x a.y b.y a.z b.z fig.
misclassification nl2type predicts a number return value but the code indeed returns an object of type point3d .
potential inconsistencies as described in section iii c and manually inspect the top of this list.
we classify each potential inconsistency into one of three categories.
inconsistency .
we classify a warning as an inconsistency if the source code the comments and the type annotations are inconsistent with each other because at least two of these three are contradictory.
developers should fix these inconsistencies by adapting either the type annotations the comments or the code.
figure shows an example of an inconsistency due to an incorrect type annotation.
our model correctly predicts that the type of the propertyobj should be object but the code instead annotates it as string .
non standard type annotation .
we classify a warning as non standard type annotation if the type annotation refers to a type that is not a legal javascript type but may nevertheless convey the intended type to a human developer.
for example figure shows a function where the parameters are annotated asnumeric .
however this type is not a legal javascript type and the developer intended the types to be number which nl2type correctly predicts.
because nl2type learns conventions from a large corpus of code it tends to predict the standard type instead of the non standard type.
to benefit from one of the type checkers built on top of javascript and from improved ide support developers should replace non standard types with the corresponding standard type.
misclassification .
we call a warning a misclassification if the type predicted by nl2type is incorrect and the code need not be changed in any way.
for example the function in figure returns an object that represents a point in the dimensional space as specified in the return annotation.
however the function name and the comment of the function mislead nl2type to predict number .
misclassifications can result because nl2type has not seen enough data similar to the given natural language information during training or authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii classification of potential inconsistencies reported by nl2type.
category total percentage all inspected warnings inconsistencies non standard type annotations misclassifications table iii length limits for inputs processed by the neural network.
avg.
in maximum fully covered data set considered data points words in function or parameter name1.
.
words in function comment .
.
words in parameter or return comment0.
.
number of parameters .
.
because the code comments or identifier names are unusual w.r.t.
the training corpus.
table ii shows how the manually inspected warnings reported by nl2type distribute across the above categories.
most warnings point to code that deserves action by the developer fixing a type annotation improving a comment or changing the code.
the percentage of actionable warnings is .
we conclude that nl2type provides a useful tool for checking type annotations for inconsistencies.
to the best of our knowledge our work is the first to show probabilistic type inference to be effective for this task.
f .
rq4 parameter selection parameters for input representation as discussed in section ii d each part of the input sequence has a fixed length and data that are too short or too long are padded with zeros or truncated respectively.
table iii shows the length limits we use and how many of all data points these limits cover without any truncation.
for example we consider up to six words as part of a function or parameter name which covers .
of all names in our data set.
the parameters are selected to cover the large majority of the available natural language data.
parameters for output representation the output of the neural network is a type vector of length t which determines how many different types the model can predict.
the set tallof all types in our data set contains types.
because classification problems become harder when the number of classes increases and because the frequency of types follows a long tail distribution we focus on a subset t tall.
table iv shows how the size of t influences the percentage of all data points covered by the considered types.
for example t 000covers .
of all data points.
the trade off in choosing t is between precision and recall.
choosing a larger t has the potential to increase recall because the model can predict the types of more data points.
however this potential increase of recall comes at the cost of lower precision because the model must choose from more possible types and because the amount of training data quicklytable iv impact of the number of considered types on the number of covered unique types and data points.
number of types unique types covered data points covered .
.
.
.
.
.
.
.
.
.
.
.
fig.
effectiveness of nl2type depending on the number t of types.
decreases for less frequent types.
to pick t we train and evaluate models for t 000and measure precision recall and f1 score for the top prediction.
the results in figure show the tradeoff between precision and recall.
the approach reaches the maximum f1 score at t which is the value we select for the evaluation.
parameters for learning table v summarizes the values of parameters related to the learning parts of nl2type.
the hyperparameters of the neural networks are selected based on values suggested by previous work and by our initial experiments.
we stop training after twelve epochs because it is sufficient to saturate the accuracy.
g. rq5 efficiency the total time taken by nl2type is the sum of the time for five subtasks.
first data extraction takes 44ms per function on average most of which is spent in the jsdoc tool while parsing javascript code.
second data pre processing takes 23ms per function on average.
third learning both the word embeddings takes about minutes in total.
fourth the onetime effort of training the model takes about minutes.
this time is relatively little compared to some other neural networks because of the small number of units in the hidden layer.
finally predicting types for a new function takes the time to extract and pre process data from the function plus 5ms per function on average to query the model.
we conclude that nl2type is efficient enough to apply to real world javascript code and to quickly give feedback to developers.
v. r elated work a type inference through program analysis static type inference addresses the lack of type annotations in dynamically authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table v parameters and their default values.
parameter value neural network to predict word embeddings word embedding size context size minimum occurrences of a word neural network to predict types hidden layer size batch size number of epochs used for training dropout of model loss function for model categorical cross entropy optimizer adam typed languages which can help detecting otherwise missed bugs .
hackett et al.
use type inference in a jit compiler to type specialize the emitted machine code .
typedevil observes types at runtime and reports type inconsistencies as potential bugs .
because none of these approaches can guarantee to infer correct types for all values lots of real world javascript code still lacks type information.
our work addresses the problem by analyzing natural language elements instead of code.
b probabilistic type inference besides nl2type we are aware of two other probabilistic type inference approaches for javascript jsnice and deeptyper .
section iv d discusses and compares with both approaches showing that nl2type outperforms both of them.
c analysis of comments prior work on analyzing comments focuses on finding inconsistencies between comments and code on inferring executable specifications for a method on identifying comments that have textual