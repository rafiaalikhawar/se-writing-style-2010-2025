performance influence models for highly configurable systems norbert siegmundy alexander grebhahny sven apely christian k stnerz yuniversity of passau germanyzcarnegie mellon university usa abstract almost every complex software system today is con gurable.
while con gurability has many bene ts it challenges performance prediction optimization and debugging.
often the in uences of individual con guration options on performance are unknown.
worse con guration options may interact giving rise to a con guration space of possibly exponential size.
addressing this challenge we propose an approach that derives a performance in uence model for a given con gurable system describing all relevant in uences of con guration options and their interactions.
our approach combines machine learning and sampling heuristics in a novel way.
it improves over standard techniques in that it represents in uences of options and their interactions explicitly which eases debugging smoothly integrates binary and numeric con guration options for the rst time incorporates domain knowledge if available which eases learning and increases accuracy considers complex constraints among options and systematically reduces the solution space to a tractable size.
a series of experiments demonstrates the feasibility of our approach in terms of the accuracy of the models learned as well as the accuracy of the performance predictions one can make with them.
categories and subject descriptors c. measurement techniques d. .
domain engineering keywords performance in uence models sampling machine learning .
introduction end users developers and administrators are often overwhelmed with the possibilities to con gure a software system.
in most systems today including databases web servers video encoders and compilers hundreds of con guration options can be combined each potentially with distinct functionality and di erent e ects on quality attributes.
the sheer size of the con guration space and complex constraints permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august september bergamo italy copyright acm ... .
.
con guration options make it di cult to nd a conguration that performs as desired with the consequence that many users stick to default con gurations or only try changing an option here or there.
this way the signi cant optimization potential already built in many of our modern software systems remains untapped.
even domain experts and the developers themselves often do not fully understand the performance in uences of all con guration options and their combined in uence when they interact.
our goal is to build performance in uence models and models of other measurable quality attributes such as energy consumption that describe how con guration options and their interactions in uence the performance of a system e.g.
throughput or execution time of a benchmark .
performance in uence models are meant to ease understanding debugging and optimization of highly con gurable software systems.
for example an end user may use an optimizer to identify the best performing con guration under certain constraints e.g.
encryption needs to be enabled from the model a database administrator may use it to determine the in uence of certain con guration options and how they interact and a developer may compare an inferred performance in uence model with her own mental model to check whether the system behaves as expected.
our approach is to infer a performance in uence model for a given con gurable system in a black box manner from a series of measurements of a set of sample con gurations using machine learning .
that is we benchmark a given system multiple times in di erent con gurations and learn the in uence of individual con guration options and their interactions from the di erences among the measurements.
our approach addresses several challenges we are facing huge con guration spaces that explode with the number of con guration options.
at the same time we can sample and measure only a relatively small number of con gurations several hundred or thousand measurements so we better select our sample purposefully.
often con guration spaces are highly constrained such that already random sampling is challenging because most random samples do not satisfy the constraints.
binary and numeric options in con gurable systems typically have di erent characteristics that require dedicated sampling and learning strategies.
of course binary and numeric options can interact too .
if available domain knowledge should be exploited for sampling and learning.
for example if we know that performance likely decreases quadratically with a certain nu meric option we would like to incorporate that knowledge for creating better models with fewer measurements.
to address these challenges we propose a novel approach of sampling and learning that takes the characteristics of binary and numeric con guration options and their interactions into account.
speci cally we propose a hybrid sampling strategy that uses di erent experimental designs for numeric options and sampling heuristics tailored for binary options grounded in their respective characteristics in practical systems.
furthermore we use a learning mechanism that can cope with both and that additionally incorporates domain knowledge about an option s in uence if available.
our approach di ers from prior work on performance optimization in highly con gurable systems in that it supports both binary and numeric options it relies on sampling heuristics that respect constraints among con guration options and it learns models that can explain performance behavior in terms of individual in uences of individual options and their interactions allowing applications beyond mere local or global optimization.
our approach is able to build reasonably accurate performance models of con guration spaces of real world systems including compilers multi grid solvers and video encoders.
in a series of experiments with con gurable systems with up to 1031con gurations we demonstrate that few measurements are su cient to build fairly accurate models prediction error on average .
the performance in uence models learned by our approach can explain the performance variation among con gurations with a few dozen terms describing the in uence of individual options and another dozen terms describing interactions.
finally while accuracy is important simple models are important too.
views on a performance in uence model can be used to isolate in uences of individual options and their interactions.
this way we found two performance bugs in the polly extension of thellvm compiler framework.
in summary our contributions are the following we introduce a novel kind of performance in uence models describing the in uence of binary and numeric con guration options and their interactions on performance.
we propose a learning algorithm based on stepwise feature selection that learns performance models focusing on the most important factors in uencing performance.
we develop a sampling approach that smoothly integrates binary sampling using heuristics and numeric sampling using experimental designs.
we demonstrate practicality and feasibility of our approach with several synthetic benchmarks as well as an empirical evaluation on six real world systems.
we make an implementation of our approach on top of the toolspl conqueror as well as all measurement results and con guration models available online including data of several months of performance measurements supporting others in replicating our experiments and evaluating related approaches .
.
performance influence models a performance in uence model consists of several terms that describe the performance of a con guration based on the values of con guration options.
individual terms may refer to a single option describing the in uence of that option to multiple options describing an interaction.
before we explain how in uence models are obtained by sampling and learning in section let us outline the underlying concepts and how we unify binary and numeric options.
assumeois the set of all con guration options including numeric and binary options and cthe set of all congurations.
we model a con guration c2cas a function c o!rassigning a user selected value to every option.
for a binary option o c o if the corresponding option is selected and c o otherwise.
for a numeric option o c o returns a number in the value range of that option.
without loss of generality we normalize the value range of all numeric con guration options to the interval as common in machine learning.
conceptually a performance in uence model is simply a function from con gurations to a performance measure c!r where performance can be any measurable property that produces interval scaled data.
the model is described as a sum of terms over con guration values.
individual terms of the performance model can have di erent shapes includingn c x n c x orn p c x c y .
for illustration consider a con gurable database management system with the options encryption e compression c statistics s page size p and db size d and a corresponding performance in uence model c ez c e cz c c sz c s pz c p dz c d c e c c z e c c e c p z e p c e c c c d z e c d in general we distinguish between terms that refer to a single optiono denoted as o and terms that refer to multiple optionsi j denoted as i j. the former describes the performance in uence of an option e.g.
e c e denotes the in uence of encryption the latter describes the in uence of a performance interaction among multiple options e.g.
e c c e c c denotes the in uence of the interaction between encryption and compression .
all performance in uence models are of the following form c x i2o i c i x i j2o i j c i c j 0represents a minimum constant base performance shared by all con gurations as determined during learning p i2o i c i represents the sum of the in uences of all individual options p i j2o i j c i c j is the sum of the in uences of all interactions among all options.
this structure allows us to easily see the in uence of an individual option from the model.
in our example we can see that encryption e if enabled slows down our example system by seconds and that encryption interacts with compression i.e.
their combined slowdown is less severe than expected from their individual e ects since compressed data are quicker to encrypt which illustrates that performance interactions are not necessarily bad .
combining binary and numeric options.
our approach is exible enough to incorporate both binary and numeric options but still allows us to handle them separately.
although we could discretize the values of a numeric option into a number of mutually exclusive auxiliary binary options this way we would loose the relation between the binary op tions that make up the corresponding numeric option such that we cannot t a function and interpolate.
by contrast converting a binary option into a numeric option we would interpret a categorical variable as an interval variable assigning a possibly wrong meaning to the range between and and invalidating the mathematical methods we use in our approach.
next we explain how to obtain the and terms of equation by means of learning and sampling.
.
learning influence models although performance in uence models are simple in their structure it is challenging to actually determine the relevant in uencing factors i.e.
terms with a reasonable number of measurements.
the key problem is that we cannot learn the whole in uence model in a single step since it contains a potentially exponential number of terms.
as a solution we incrementally select only the strongest in uences regarding prediction accuracy in each iteration of the learning process.
a key contribution of our work is thus not to develop a new learning technique but to select a suitable one and adapt it to the requirements and speci cs of con gurable systems.
.
overview we use stepwise linear regression to learn the function of a performance in uence model from a sample set of measured con gurations.
to reduce the dimensionality problem of handling a very large number of options and interactions we use forward and backward feature selection to incrementally learn the model.
we use linear regression because it ts the requirements of the domain of con gurable software systems and the practicality requirements for end users.
in contrast to many alternative approaches including classi cation and regression trees neuronal nets and support vector machines linear regression allows us to learn a formula that can be understood by humans.
it also makes it easy to incorporate domain knowledge on the in uence of certain options if available which can be an e ective means to avoid over tting and under tting .
finally we do not need any internal information about the system but can apply the learning approach in a black box fashion onto sampled benchmark results.
linear regression is a common approach to learn how a dependent variable ydepends on a number of independent variablesxiin the form y 1x1 2x2 nxn given a learning set of observations for y x1 xn linear regression ts the regression coe cients isuch that the overall error is reduced this way learning a function that explains the observations.
we use the measured performance of a con guration as dependent variable yand the con guration values c i as the independent variables thus learning performance models of the form 1c o1 nc on a performance model of basic terms without any interactions or nonlinear behavior.
linear regression can also be used to learn linear coe cients for more complex terms i.e.
to learn non linear functions by using computed values as independent variables.
for example we can use c p c q as independent variable to 2note that the term feature selection used here is a machine learning term and must not be confused by the process of selecting features in product line engineering.algorithm stepwise feature selection data measurements o result model 1featureset error 2repeat lasterror error bestcandidate ?
candidates generatecandidates featureset o foreach feature incandidates do model learnfunction featureset ffeatureg measurements modelerror computeerror model measurements ifmodelerror error then error modelerror bestcandidate candidate end end ifbestcandidate6 ?then featureset featureset ffeatureg end 17until lasterror error margin error threshold 18featureset backwardstep featureset measurements 19return learnfunction featureset measurements learn interactions between pandq orc o 2to learn coe cient for a quadratic function.
that is if we know which single option terms interaction terms or function terms might appear in the performance in uence model we can learn linear coe cients for all of them yielding performancein uence functions as in our initial example in section .
the key challenge of using linear regression is hence to identify the relevant terms to be used as independent variables.
next tojojbasic option terms x c o there is an exponential number of basic interaction terms x c o1 c on and an in nite number of additional function terms over one or multiple options e.g.
polynomials .
the problem of too many possible independent variables is known as the curse of dimensionality .
given a set of measurements selected by a speci c sampling heuristics see section our learning process proceeds iteratively in a process known as forward feature selection learning one term at a time until further improvement minimizing the error term becomes negligible.
in each iterative step we try a number of candidate terms and select the term that provides the biggest improvement for the model.
we select candidate terms based on heuristics and domain knowledge if available as we will explain in section .
.
.
incremental learning algorithm in algorithm we sketch the learning algorithm that computes the function representing the performance influence model from a set of measurements representing selected con gurations and corresponding measurement results .
conceptually we incrementally compute the relevant feature set in which each feature represents a term over one or multiple con guration values c o .
throughout the learning process the feature set holds the features that have been identi ed to improve the error rate of the learned model with regard to the measured learning set.
for our example model in section the feature set would eventually include c e c d c e c c and so forth.
starting with an empty feature set the algorithm selects one feature in each iteration until improvements of model accuracy become marginal or a threshold for expected accuracy is reached repeat loop line .
the feature to be added stems from a number of candidate features theirselection is described in section .
.
using linear regression to compute a model with every candidate line we select the candidate that reduces the error rate most.
the algorithm concludes with a backward learning step backward feature selection not shown for brevity in which every feature in the feature set is tested for whether its removal would decrease model accuracy.
this can happen if initially a single feature is selected because it best explains the measurements but it becomes obsolete by other features e.g.
representing interactions later in the learning process.
.
selecting candidate features a nal critical step is to select candidate features that are explored during the learning process.
much like it is infeasible to learn a model with all features at once it is infeasible to try all features in each iteration it is typically not even possible to enumerate all features due to their sheer number.
hence we have to apply heuristics to select these candidates that are likely to in uence performance.
a key innovation of our approach is the procedure of determining which candidates we select for learning.
we use separate heuristics for the two main factors that result in the huge number of candidate features interaction and function terms.
hierarchical interactions.
conceptually any combination of options may cause a distinct performance interaction which would render any learning approach useless as there is no common pattern.
in practice however performance behavior is usually more tractable in that only few interactions contribute substantially to the overall performance.
in our previous work we found that relevant interactions do not emerge randomly among con guration options but form a hierarchy .
that is three way interactions i.e.
interactions among three options build on corresponding two way interactions among the same set of options.
furthermore we found at most ve way interactions and the most common interactions were two way.
thus based on our experience and following standard practices of machine learning we perform our learning hierarchically we rst start adding only the individual option in uences and then add interactions as candidates containing options that have been found already to contribute to performance.
function learning.
for numeric options we learn functions over their data ranges.
if we know the kind of the function or the polynomial degree then we generate the corresponding candidates.
for example if we know that the performance in uence of a numeric option ois logarithmically we generate only the feature o log c o rather than a set of polynomial candidates.
without domain knowledge we use an array of standard functions linear quadratic logarithmic that can be activated by the user of our approach.
again our approach can incrementally increase the complexity of these functions by building new functions from combinations of already learned ones.
.
sampling configuration spaces sampling heuristics must satisfy two requirements first they have to produce a reasonable number of measurements heuristics requiring millions of measurements are certainly infeasible.
second a heuristic must select the con gurations that incorporate most of the relevant interactions.
that is we want to nd a sweet spot between prediction accuracy and measurement e ort.
there are several invariants that need to be considered when constructing the learning set random sampling choosing con gurations randomly from the con guration space is still an open problem for highly con gurable systems.
the presence of constraints prohibit o the shelf solutions such as experimental designs or random selection and ltering .
using sat solving to nd valid con gurations usually produces only locally clustered solutions in the con guration space although recent attempts try to mitigate that problem .
binary and numeric options binary and numeric options have substantially di erent value ranges resulting in huge di erences in the number of measurement points we should select for them.
for instance a numeric option might have a quadratic performance in uence when varying its value which certainly requires more measurements than the constant in uence of a binary option when switched on and o .
we address these problems by dividing the con guration space along the two types of con guration options and by applying dedicated sampling heuristics to them.
.
binary option sampling for binary option sampling we use heuristics that we developed in previous work .
the goal of these heuristics is to pick con gurations to learn the basic in uence of each individual binary option and subsequently to pick con gurations that exhibit two way interactions.
option wise sampling ow .
option wise sampling selects con gurations such that it purposefully avoids interactions.
we use a constraint satisfaction problem csp solver to nd for each option o a con guration with as many options disabled as possible under the constraint c o and the given constraints among the options.
the process is repeated until all options have been included in the learning set which requires a number of measurements that is linear in the number of binary options.
negative option wise sampling now .
instead of minimizing the number of options negative option wise sampling aims at maximizing the number of options in a conguration to maximize the number of possible interactions.
that is for each option o we search a con guration with as many options enabled as possible under the constraints c o and the constraints between the options.
much like ow now requires a linear number of measurements.
pair wise sampling pw .
for pair wise sampling we construct a learning set that includes a minimal set of con gurations in which all two way interactions are present and not confounded with other interactions.
that is for each pair of options qandp we determine a con guration with as many options disabled as possible under the constraints c q c p and the constraints between the options.
without constraints pw requires a number of measurements that is quadratic in the number of binary options.
.
numeric option sampling the science of choosing an appropriate learning set in the presence of numeric options has a long history and many approaches have been proposed under the umbrella of thedesign of experiments orexperimental designs .
the goal of an experimental design is to generate an experimental plan by assigning values to independent variables numeric con guration options in our case such that a given hypothesis can be properly tested.
as a preparation for this work we surveyed eight standard experimental designs and sorted out those that do not meet our requirements.3for example the d optimal design requires to enumerate all possible combinations or other designs such as the full factorial and the 2k 1design require a number of measurements that is infeasible in practice.
after this preselection we selected the following experimental designs for our empirical evaluation box behnken plackett burman central composite and randomization with seed .
due to space constraints we report only on the best performing designs plackett burman and random the complete set of evaluation results are available on our supplementary web site.
plackett burman design.
in plackett and burman proposed an experimental design that aims at determining the main e ects of an experiment .
it minimizes the variance of the estimates of the independent variables while using a limited number of measurements.
wang and wu extended it to incorporate two way interactions .
o1o2o3o4o5o6o7o8 c101120221 c210112022 c321011202 c422101120 c502210112 c620221011 c712022101 c811202210 c900000000 figure plackettburman design de ning experiments for numeric options using the minimum maximum and midpoint as levels .a plackett burman design is a speci c type of fractional factorial design which are often used for combinatorial testing .
the design speci es seeds depending on the number of experiments to be conducted and the number of levels of the input variables.
the level speci es the number of distinct values of an independent variable and the seed de nes the pattern at which the di erent values are varied which a ects also the number of measurements.
since numeric conguration options can have a large number of values we sample the value range uniformly depending on the chosen level.
for a three level design we take the minimum maximum and center point of the value range.
next we have to determine the number of measurements to be performed.
when we are interested only in the main factors i.e.
only we need n measurements for nnumeric con guration options.
if domain knowledge is available and we know that there might be interactions between con guration options we chose the seed such that more con gurations are measured.
in table we show a plackett burman design for a seed n l de ning experiments for independent variables with levels.
the rst row represents the seed and each row below is computed by a right shift of the row above except for the last row which sets all numeric options to .
3central composite 2k d optimal plackett burman box behnken one factor at a time full factorial hyper sampling form of gridding random design.
unlike binary option sampling we can easily determine random values from numeric options because we know the minimum and maximum value as well as the step size as these must be given to obtain a meaningful con guration.
furthermore constraints among numeric options appear rarely in con gurable systems.
it is very unusual that numeric options have value ranges with undened or invalid holes or that setting a numeric option s value prohibits certain value ranges of other options.
to ensure reproducibility of our experiments we use random values with seeds available on the supplementary web site .
.
combining binary and numeric sampling so far we have explained how we sample the con guration space regarding binary and numeric options individually.
the remaining task is to combine the two.
in a rst step we determine con gurations using binary option sampling resulting in a set of partial con gurations .
in a second step for each partial con guration we determine a set of complete con gurations based on numeric option sampling.
the rationale behind this ordering is that the majority of domain constraints are usually between binary options so this part of the con guration space is more challenging for nding valid con gurations.
furthermore in real world applications such as database and web servers compilers and enterprise applications it is often the case that a binary option activates a piece of functionality and numeric options adjust existing functionality e.g.
by setting input bounds specifying the workload or controlling the output quality .
as a consequence numeric options often depend on binary options.
overall this combined approach yields a learning set comprising n rmeasurements where nis the number of binary partial con gurations and ris the number of numeric partial con gurations.
.
evaluation a key question is whether our approach can learn accurate performance in uence models for highly con gurable realworld systems with a reasonably small number of measurements.
more speci cally we aim at answering the following three research questions rq1 what is the range of prediction errors per sampling heuristics we get with our approach?
rq2 which combinations of binary and numeric sampling technique give rise to pareto optimal solutions with respect to measurement e ort and prediction accuracy?
rq3 is our learning approach accurate in the sense that we learn actually existing in uences and interactions?
for the purpose of our evaluation we operationalize accuracy as follows given a sample set we compute a performance in uence model which we subsequently use to predict the performance of a large number of con gurations in an evaluation set.
as said previously the actual performance metric may vary and depends on the subject systems.
we then measure the con gurations of the evaluation set and calculate the error rate byjmeasured predicted j measured averaged over all con gurations.
ideally we would use the whole con guration space of a system as evaluation set but the measurement e ort would be prohibitively high for most real world systems.
therefore we perform the evaluation in two separate experiments with di erent goals.
in a rst experiment we use synthetic performance models.
we start with a known realistic formula of a perfor mance in uence model as ground truth and derive the measurements for both sample set and evaluation set from this formula.
since there are no measurement costs and no measurement bias we can perform accurate and large scale experiments with high internal validity using the entire con guration space as evaluation set.
we use this rst experiment primarily as a sanity check to determine whether we can accurately learn a performance in uence model rq1 and and as means to explore the tradeo s of di erent sampling strategies rq2 .
in a second experiment we assess the feasibility of our approach by building performance in uence models for six real world software systems from a number of di erent domains rq1 .
that is we execute their actual benchmarks and measure execution time over a large number of con gurations in both sample and evaluation sets.
.
experiment correctness and accuracy standard learning approaches are typically sensitive to even slight variations in the learning set.
this is undesired because we cannot trust the resulting performance in uence model when analyzing the system although it might give reasonable performance estimates.
thus we aim at checking whether our approach learns the actually existing in uences answering rq3.
for this purpose we create measurements from a number of ground truth models from which we learn performance in uence models and compare them against the ground truth to check whether the learned in uences and interactions are similar to the given ones.
a second goal of this experiment is to lter out infeasible sampling heuristics regarding prediction accuracy and measurement e ort because evaluating all combinations of sampling heuristics on real world systems is computationally infeasible.
setup.
overall we compare three sampling heuristics for binary options option wise ow negative option wise now and pair wise pw their combinations and several experimental designs from which we report here only the plackettburman and random design with randomly selected numeric con gurations and ve seeds.
as ground truth performance models we use formulas along the lines of our motivating example in section .
but instead of creating random models we create models that represent performance variations in real software systems by deriving them from actual performance models extracted in prior work using a di erent approach see section .
.
since the original models contained only binary options we enhance them with numeric options as follows a we add one to four numeric options with different value ranges to b we vary the number of numeric option interactions to and their kinds i.e.
binary numeric and numeric numeric and c we use different shapes of functions linear quadratic linear combined with quadratic .
this way we consider a wide range of different in uence functions and interactions.
to get an impression of how our given models look we refer the reader to section .
.
to distinguish the ground truth models we name them after the con gurable systems from which we obtained the binary options.
table .
shows all ground truth models including their con guration spaces the application domain of the original performance models and the number of constraints among options.
we provide all models as well astable overview of the ground truth performancein uence models.
model domain bin num const jcj ajstats analysis tool apache apache web server bdb c berkeley db c bdb j berkeley db java clasp answer set solver llvm compiler infrastructure lrzip compression library bin number of binary options num number of numeric options const number of constraints jcj number of con g. the intermediate models of the learning process on the supplementary web site.
mean error rate number of measurements terms of the influence model term with high divergenceundetected influenceterm equal to ground truth to characterize the accuracy of a learned model for a speci c sampling strategy we use a compact visual representation as depicted to the right covering several aspects mean error rate over predictions of all con gurations the standard deviation of the error when repeating sampling and learning for random sampling the number of measurements required by the sampling heuristic and a compact representation of all terms in the model lower part boxes denote individual terms weighted in size by their e ect strength coe cients accuracy per term is color coded from green for the same value to red for a relative di erence larger than and black for terms that are missing in the learned model .
results.
figure summarizes our experimental results for all binary option samplings and plackett burman and random design.
again we show only the best combinations of sampling heuristics and refer the interested reader to our supplementary web site for all results.
overall we observe a good degree of similarity between the learned models and the ground truth models indicated by the green rectangles.
only when binary option interactions exist and no pair wise sampling was used we observe some undetected in uences black bars .
there are also models such as for the synthetic clasp model for which we obtain a prediction error of on average but we miss to in uence functions row pw pbd .
this observation suggests that missing a single term likely a ects only a small fraction of the con guration space such that the overall prediction error remains small.
these results suggest that we indeed learn the actual existing in uences in most cases which is useful for performance debugging and interactive con guration tools .
to analyze the tradeo among prediction accuracy and measurement e ort rq2 we plot the pareto front dashed line of the combination of binary option and numeric option sampling heuristics in figure .
the plackett burman design n l outperforms all designs no matter which binary sampling heuristics is used which applies also to combinations not shown.
for binary option sampling pair wise sampling has the highest accuracy in combination with plackett burman .
on average even better in combination with option wise and negative option wise sampling .
on average .
however it comes at the cost of an increased number of measurements compared to the pureow pbd ajstats ow rd now pbd now rd pw pbd 1k pw rd 8k ow pw pbd 1k ow pw rd 8k now pw pbd 1k now pw rd 9kapache 2k 2k 2k 2k 2k 3kbdb c 1k 1k 1k 1k 2k 2kbdb j 2k 3k 2k 2k 2k 2k 4k 5kclasp 12k 12k 5k 6k 5k 6k 17k 18kllvm 3k 3k 3k 3k 3k 3klrzip 9k 9k 5k 5k 5k 5k 14k 15kfigure comparison of learned and ground truth models in terms of mean prediction error number of measurements and existence and similarity of model terms.
option wise approach which in turn has a mean prediction error of about .
random sampling is not competitive at sample sizes comparable to the plackett burman design and we observed a strong uctuation in the error rate when repeating learning with a fresh random sample.
.
experiment effort and accuracy in our second experiment we evaluate whether our learning and sampling approach is feasible in practice.
although partly parallelized we invested more than two months for measuring con gurations of six subject systems to obtain a huge data basis including learning and evaluation sets .
however using our approach in practice would require much less measurements as most measurements were meant to evaluate and analyze our approach.
setup.
with a focus on external validity we selected six highly con gurable systems from di erent domains written in di erent programming languages with varying numbers of binary and numeric options.
some systems support conguration at compile time others at load time.
we purposefully selected some systems for which we can perform a whole population analysis dune mgs hipacc hsmgp being able to reliably quantify prediction accuracy as well as systems that are highly con gurable to evaluate the scalability of our approach see table for an overview .
dune mgs is a geometric multi grid solver based on the dune framework .
the framework provides algorithms for smoothing and solving poisson equations on structured grids.
binary options include several smoother and solver mean prediction error in mean number of measurements ow pbd ow rd now pbd now rd pw pbd pw rd ow now pbd ow now rd ow pw pbd ow pw rd now pw pbd now pw rd ow now pw pbd ow now pw rd figure pareto front dashed line of combinations of sampling heuristics.
algorithms.
numeric options include di erent grid sizes and pre and post smoothing steps.
we measured the time to solve poisson s equation on a dell optiplex with an intel i5 quad code and gb ram ubuntu .
.
hipaccis an image processing acceleration framework which generates e cient low level code from a high level speci cation.
binary options are among others the kind of memory to be used e.g.
texture vs. local .
the number of pixels calculated per thread is an example of a numeric option.
we measured the time needed for solving a test set of partial di erential equations on an nvidia tesla k20 card with 5gb ram and cores ubuntu .
.
hsmgp is a highly scalable multi grid solver for largescale data sets.
binary options include in place conjugate gradient and in place algebraic multi grid solvers.
numeric options include the number of smoothing steps and the number of nodes used for computing the solution.
as a benchmark we performed a multi grid iteration of solving poisson s equation.
we executed the benchmark runs on juqueen a blue gene q system located at the j ulich supercomputing center germany.
javagc is the java garbage collector version with several options for adaptive garbage collection boundary and size policies.
for measurement we executed the dacapo benchmark suite on a computing cluster consisting of nodes each equipped with an intel xeon e5 ivy bridge having cores and gb ram ubuntu .
.
sac is a variant of c for high performance computing based on stateless arrays.
the sac compiler implements a large number of high level and low level optimizations to tune high level programs for e cient parallel executions.
the compiler is highly con gurable allowing users to select various optimizations and to customize the optimization e ort e.g.
optimization cycles and loop unrolling threshold .
as benchmark we compile and execute an n body simulation shipped with the compiler measuring the execution time of the simulation at di erent optimization levels.
we executed all benchmarks on an core intel i7 2720qm machine with gb ram ubuntu .
.
x264 is a video encoder that encodes raw videos into the h. compressed format.
con guration options con gure output quality encoder types and encoding heuristics.
as benchmark we measured the time needed to encode the sintel trailer mb using on an intel core2 q6600 with 4gb ram ubuntu .
.table overview of the real world subject systems.
system domain bin num const jcj dune mgs multi grid solver hipaccimage processing hsmgp stencil grid solver javagc runtime env.
sac compiler x264 video encoder bin number of binary options num number of numeric options const number of constraints jcj number of con g. we started our experiments by determining sample sets to following the plackett burman and random sampling as they performed best in our rst experiment see sec.
.
as well as our binary sampling heuristics ow pw .
we do not report on the results for now because our rst experiment sec.
.
showed that it increases measurement e ort considerably for only a limited gain in accuracy.
as evaluation set we selected either the whole population dune mgs hsmgp hipacc or a large random set of con gurations more than randomly selected con gurations .
results.
in table we present the results for the six subject systems.
as expected the error rate is larger than for the synthetic models since we cannot fully control for confounding factors such as measurement bias which made up to of deviations within multiple repetitions of measuring the same con guration.
putting this into perspective we observe still a comparatively high prediction accuracy for most of the systems.
we yield for every subject system a performance in uence model whose error rate is below .
forsac the pw heuristic requires more than measurements which is infeasible.
surprisingly the ow heuristic performs often equally well as the pw heuristic for dune mgs hipacc hsmgp sac x264 although requiring a substantially lower number of measurements.
for numeric option sampling we see similar results as in our rst experiment the plackettburman design is often superior to the random design.
the measurement e ort for plackett burman is higher with constrained con guration spaces e.g.
dune mgs orhipacc .
for systems with few constraints and many options plackettburman requires less measurements.
learning a model required to hours depending on the size of the learning set and the size of the models.
remarkably the resulting models are compact with only few terms explaining most of the performance variations particularly we observe usually a larger number of in uences from individual options i.e.
i and only a low number of interactions i.e.
i j considering that there is potentially an exponential number of interactions.
furthermore we see an increase in the number of interactions when pw sampling is used compared to ow sampling and also plackett burman results in larger numbers of identi ed interactions compared to random design.
in section .
we discuss these and other results and put them into perspective.
4we use an active learning approach in which we rst evaluated the performance in uence model produced with the ow heuristic to determine which binary options have an in uence at all.
then we applied the pw heuristic to these options.
the corresponding results are marked with in table .
we discuss this solution more in section .4table results for the six subject systems and combinations of option wise ow and pair wise pw sampling.
we consider terms with an absolute coe cient of 01only.
ow pw e jcj ij i j e jcj ij i j dune mgs rd 5j0 8j8 pbd 6j24 j18 pbd 8j16 8j20 hipacc rd 16j13 11j16 pbd 18j8 12j19 pbd 18j9 12j19 hsmgp rd 11j14 9j13 pbd 9j13 10j13 pbd 11j13 11j14 javagc rd 4j0 5j7 pbd 5j0 9j14 pbd 3j0 5j21 sac rd 14j5 7j9 pbd j11 8j13 pbd 14j5 6j19 x264 rd 4j3 3j7 pbd 5j4 6j9 pbd 4j1 j6 pbd plackett burman design rd random design e mean prediction error jcj size of sample set i number of terms representing the in uence of individual options i j number of terms representing the in uence of interactions .
threats to validity internal validity.
to rule out conceptual and implementation errors of our approach we conducted a high internal validity experiment in which we used ground truth models and aimed at learning these models using di erent sampling heuristics.
note that the ground truth models have been learned in prior work with linear programming which is important as it would be invalid to compare models that have been created with the same learning technique.
furthermore we do not only computationally compared the models but manually reviewed them to avoid errors in the evaluation.
this way we mitigate the threat that we learn models with similar prediction accuracy but with di erent in uences and detected interactions which might be a result of over tting.
in the second experiment we repeated all measurements several times and used averages to control measurement bias.
although we parallelized the measurement on equal machines they might slightly di er in their performance but these e ects are usually small and due to repeated measurements likely cancel each other out.
external validity.
as highly con gurable systems exist in a broad range of application domains with di erent con guration spaces we selected six real world subject systems in our second experiment.
these systems have varying numbers of options and are from di erent application domains which increases external validity.
naturally we cannot guarantee that our approach works for all possibly con gurable software systems but we invested several months of measurement to gather and analyze a substantial evaluation set.
.
discussion research questions.
our results show that building performance in uence models is a computationally tractable a few hours of learning and measurement b our approach nds actual in uences and represents them directly and c we attain a reasonable prediction accuracy.
regarding rq1 prediction accuracy in the rst experiment we almost always learned performance in uence models with nearly perfect prediction accuracy.
for the realworld systems we observe average error rates of to which are only a slightly higher than the measurement bias.
for some subject systems and sampling heuristics we observe larger prediction errors.
a possible explanation is that these subject systems contain three way or more complex interactions which cannot be detected by ow and pw sampling.
another possible reason is that many weak in uences may sum up to larger prediction errors.
we purposefully do not search for weak in uences as they complicate the model to an extent that is impracticable for performance debugging or comprehension.
regarding rq2 tradeo between measurement e ort and prediction accuracy we found that more con gurations do not necessarily lead to more accurate predictions.
it depends on which con gurations are selected and how they are distributed in the con guration space to cover the relevant interactions.
for both experiments plackett burman designs yield the best tradeo .
although random sampling is very e ective in learning accurate models with comparable sampling sizes it incurs substantial uctuations such that an additional design should be applied that acts as a base layer to cover all numeric options and their respective data ranges.
for binary option sampling we observe a mixed picture.
we found that the pw heuristic is superior to ow and now for the ground truth models in which the binary option part originates from real world performance models whereas without ow sampling we miss some inuences leading to higher error rates for some real world systems.
hence also in this case a combination of the ow and pw heuristic might be a better solution.
rq3 aimed at determining whether we learned the actual relevant options and interactions.
the results of the rst experiment provide us the clear picture that we indeed nd most of the original terms of a given performancein uence model.
moreover when considering the size of the learned performance in uence models of the real world systems number of terms we conclude that we learn simple models at the cost of some prediction accuracy with both individual options and interactions.
the ratio ofj ij jojover all subject systems for ow with plackett burman sampling is .
indicating that one third of the options signi cantly contribute to the performance of a system.
when considering interactions j i jj jojis only .
such that the number of determined interactions is similar the the number of relevant in uences of individual options.comprehension and debugging.
an issue not addressed by our evaluation is to what extent performance in uence models help developers in their everyday development and debugging tasks.
while we strive for simple models that contain only the most important factors for performance they still may get considerably large.
nevertheless based on such models we are able to provide views such that isolated in uences of con guration options or interactions become immediately apparent.
let us consider again the excerpt of the performance in uence model of berkeley db c pagesize cachesize hash statistics crypto hash hash verify statistics crypto hash replication cachesize crypto if we are interested in understanding the in uence of cryptography on the overall execution time we can project out all other in uences yielding the following simpler formula crypto hash crypto hash replication cachesize this view suggests that the cryptography feature should not be used in combination with the hash search index because it degrades performance when used in combination with replication the degradation is even worse but increasing the cache size limits the negative in uence of cryptography on the execution time.
actually using our approach we found an unexpected slowdown in the polly extension of the llvm compiler framework trmm.c .
by incident this was observed around the same time by others.5moreover for the con guration options ignore aliasing andno runtime alias checks we found di ering performance in uences for which a developer ofpolly expected that both should have a similar e ect.
we already propagated some performance in uence models back to domain experts e.g.
the hpc domain to guide and improve the development and con guration which goes beyond performance tuning of highly con gurable software systems.
while these examples nicely illustrate the power of views on performance in uence models for program comprehension and debugging it will be imperative to conduct a comprehensive user study in further work.
limitations.
our approach rests on several assumptions.
first we use regression analysis to learn in uence functions.
if a con guration option has an unsteady performance behavior or has a very complex nearly chaotic behavior we cannot learn but only approximate its performance in uence.
furthermore we need the con gurable system to have a deterministic performance behavior.
if two equal runs of the same program lead to largely di erent performances we cannot reliably learn in uences and hardly predict performance.
finally our approach has its limits regarding the number of options and the size of the learning set.
although we already tried to minimize the learning set and there is room for further improvement it is still an infeasible problem to support systems with thousands of options in terms of constrainedness and performance variability .
still our evaluation demonstrated that our solution scales to problems with up to 1031con gurations making it feasible for a su cient number of real world systems.
beside various facets of performance performance in uence models may be bene cial to reason about other non functional properties and quality attributes most notably energy consumption.
moreover we can supply the models we learned to other performance modeling and optimization tools such as clafer and epoal .
technically our approach could be extended to support active learning.
that is we could evaluate the performancein uence models in an intermediate step to decide whether additional measurements should be applied.
we found that forsac applying ow sampling with a plackett burman design resulted in a performance in uence model in which only of binary options have a relevant in uence.
based on this result it is advisable to use the pw heuristic only for the binary options which would reduce the required measurements from to or from to when combined with random numeric option samples .
in general our notion of performance in uence models is conceptually independent of the concrete learning technique.
that is the concrete technique is hidden behind the is and i jterms of the model.
thus our approach is complementary to existing approaches of performance modeling.
we made a number of decisions to support program comprehension and debugging performance of con gurable systems.
however when prediction accuracy or optimization is the single most important aspect then other techniques such as support vector machines could be used.
.
related work learning.
our approach aims at determining the individual in uences of con guration options and their interactions which has several use cases such as performance bug detection or con guration optimization.
there are many successful approaches that aim at nding optimal con gurations without pinpointing the in uence of con guration options explicitly .
more closely related to our work are standard machine learning techniques such as supportvector machines bayesian nets and evolutionary algorithms.
these approaches trade simplicity and understandability of the learned models for predictive power.
software con guration however usually involves humans in the reasoning process since not a single but a number of objectives need to be satis ed.
hence we need to understand how individual options in uence performance and which interact.
there are a number of approaches that use pro ling data to create performance models .
for instance jovic and others analyze samplings of call stacks of deployed versions of a program to nd performance bugs .
grechanik and others propose to learn rules for the generation of workloads that reveal program paths with suboptimal performance .
however these approaches concentrate on workload variability rather than software system con gurability.
sampling.
although a proper sampling heuristic is a critical success factor for determining the in uence of con guration options and nding optimal con gurations there is only little work done so far.
important sampling approaches have been developed in statistics in which experimental designs have been developed to ensure certain statistical properties.
we used these designs such as central composite box behnken and plackett burman to determine con g urations of numeric options .
one simple approach is gridding which computes a grid over the space of the input parameters.
it was used for sampling con gurations of berkeley db .
however due to its exponential complexity sullivan and others could consider only four options in a reasonable amount of time .
for binary option sampling several approaches tackle the problem of nding valid con gurations .
especially evolutionary algorithms have been proposed for this task .
pohl and others found that determining a valid con guration based on a variability model increases response time exponentially with respect to the number of features .
the sampling heuristics and experimental designs we use to identify interactions are related to the heuristics used in combinatorial testing .
the di erence is that we do not focus on functional correctness but on performance which allows us to learn performance in uence models using linear regression.
this would be considerably harder when applying it to defect prediction as defects are much more singular events in a program s execution than the observable performance pro le.
.
conclusion today most contemporary systems are con gurable which makes performance prediction optimization and debugging di cult.
we address this challenge by proposing an approach that derives a performance in uence model for a given con gurable system describing all relevant in uences of individual con guration options and their interactions.
to this end we select and adapt a suitable machine learning technique and combine it with sampling heuristics for binary and numeric con guration options in a novel way.
our approach rests on an algorithm that iteratively learns a performance in uence model using a small set of candidate features representing relevant performance in uences.
to derive learning sets of tractable sizes we combine heuristics for binary option sampling with experimental designs for numeric option sampling.
by means of a rst experiment on partially synthetic ground truth models we could show that our hierarchical learning strategy nds the actually relevant in uencing options and interactions and yields a mean prediction error of .
in a second experiment we applied our approach to six real world software systems in which we measured performance in terms of the execution time of a given benchmark.
our results con rm the rst experiment for both accuracy and measurement e ort.
a major insight is that the plackett burman design is superior to all other numericoption sampling heuristics regarding the tradeo between measurement e ort and prediction accuracy with an average prediction error below which is only slightly above the measurement bias.
furthermore we found that our approach is feasible for nding performance bugs in real world systems which is a promising avenue of further research.
.