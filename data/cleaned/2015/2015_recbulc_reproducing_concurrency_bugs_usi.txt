recbulc reproducing concurrency bugs using local clocks xiang yuan1 chenggang wu1 zhenjiang wang1 jianjun li1 pen chung yew4 jeff huang5 xiaobing feng1 yanyan lan2 yunji chen1and yong guan6 1state key laboratory of computer architecture 2cas key laboratory of network data science and technology institute of computing technology chinese academy of sciences beijing china yuanxiang wucg wangzhenjiang lijianjun fxb lanyanyan cyj ict.ac.cn 3university of chinese academy of sciences beijing china 4department of computer science and engineering university of minnesota at twin cities minneapolis usa.
yew cs.umn.edu 5department of computer science and engineering texas a m university texas usa.
jeff cse.tamu.edu 6college of information engineering capital normal university beijing china.
guanyong mail.cnu.edu.cn abstract multi threaded programs play an increasingly important role in current multi core environments.
exposing concurrency bugs and debugging such multi threaded programs have become quite challenging due to their inherent non determinism.
in order to eliminate such non determinism many approaches such as record and replay and other similar bug reproducing systems have been proposed.
however those approaches often suffer significant performance degradation because they require a large amount of recorded information and or long analysis and replay time.
in this paper we propose an effective approach recbulc to take advantage of the hardware clocks available on modern processors.
the key idea is to reduce the recording overhead and analyzing events global order by using time stamps recorded in each thread.
those timestamps are used to determine the global orders of shared accesses.
to avoid the large overhead incurred in accessing system wide global clock we opt to use local per core clocks that incur much less access overhead.
we then propose techniques to resolve differences among local clocks and obtain an accurate global event order.
by using per core clocks state of the art bug reproducing systems such as pres and clap can reduce the recording overheads by and the analysis time by .
.
respectively.
index terms concurrency bug reproducing local clock i. i ntroduction parallel programming is essential to fully utilize the compute power of multi core processors.
however debugging such programs has become a major challenge for software developers because of the non deterministic nature of parallel programs .
a survey showed that it took about days to fix a concurrency bug .
these bugs can have serious consequences.
well known incidents include the therac medical accident and the north american blackout .
such bugs need to be fixed as quickly as possible.
one of the main debugging techniques is record replay rr .
it faithfully records the execution interleaving and deterministically replays the same interleaving to reproduce bugs .
the main challenge in rr techniques is the need to reduce the significant performance penalty incurred at runtime to record the interleaving information.
some rr to whom correspondence should be addressedtechniques could incur 10x 100x slowdown.
furthermore the perturbation caused by the instrumented code and the recording overhead may alter the interleaving sequence of the program execution which can obscure some bugs especially on systems with weak memory models .
to address those limitations several schemes have been proposed to improve rr techniques by recording only minimally needed interleaving information and then reproduces the buggy interleaving with offline analysis and guided exploration.
because significantly less information is recorded the runtime overhead can also be substantially lower.
many systems adopt this idea .
although the interleaving reproduced by these schemes may not be exactly the same as the original one they are useful in practice as the same failure can be reproduced.
for example pres records the global orders of some special events such as synchronizations system calls function calls basic blocks and memory instructions.
when a bug turns up it tries to analyze the unordered shared accesses.
at the function call level it can reproduce bugs in tries mostly and experiences only slowdown .
similar to other rr techniques pres needs to explicitly record the global order of shared resource accesses among threads.
they use synchronization operations to serialize the logging to a shared buffer or incrementing a global event counter which are the root cause of execution slowdown .
to avoid such expensive synchronizations an effective mechanism called clap has been proposed.
each thread in clap only records its local information.
during the offline analysis clap generates constraints by symbolic execution and searches for buggy interleavings using a satisfiability modulo theories smt solver such as yices and z3 .
thus its slowdown is only about .
however it cannot get the buggy interleavings directly.
instead it relies on an smt solver which is hard to scale because such constraint solving is np hard.
these systems trade off between less time in the record phase and more time in the analysis and replay phase.
it ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee icse florence italyis thus very desirable to find a scheme that requires each thread to log only its own local information while allowing a quick offline analysis to get the order of shared accesses among threads during the replay.
such a scheme could greatly greatly improve the efficiency of program debugging for multithreaded programs.
the key insight here is to take the advantage of the available hardware per core local clocks to reduce both the recording overhead and the bug reproduction time.
most commercial processors today such as intel amd x86 ibm power mips and sun sparc provide such clocks.
each core can access its own local clock without any need for synchronization with other cores.
the order of shared accesses can then be inferred accordingly.
however these local clocks are core private.
and the hardware don t guarantee them to be consistent i.e.
they may have different skews among themselves.
it is quite difficult to get the precise skews among these local clocks unless there is a global clock as assumed in .
the main challenge here is thus to find an effective way to resolve these local timestamps and determine a global order among them.
in this paper we proposes a new mechanism recbulc to reconstruct the order of shared memory accesses among threads using local timestamps.
this scheme can thus be used to reproduce concurrency bugs more efficient.
as a demonstration we apply recbulc to two recent systems and show that it can significantly improved their performance.
our contributions are as follows we propose to use hardware per core clocks available on commercial processors to determine the global order of shared accesses among threads that allows concurrency bugs to be recorded and reproduced with substantially reduced overheads.
we present a methodology to obtain a range of the skews among per core clocks.
we then use a statistical scheme to narrow down the range of clock skews to less than ticks cycles with a high confidence.
recbulc is applied to two recent systems and shows that it can improve their efficiency significantly.
following section ii gives a motivation.
section iii presents two schemes to calculate the skews among local clocks.
section iv applies recbulc to pres and clap.
section v discusses our experimental results.
section vi covers the related work and section vii concludes this paper.
ii.
m otivation almost all mainstream commercial processors provide local per core clocks and applications can access them for needed timing information.
for example intel amd x86 processors provide a bit time stamp counter tsc since pentium family.
the tsc is incremented at a constant rate with respect to the wall clock time.
it is not affected by the frequency of processors so as to avoid the impact of dynamical frequency scaling .
similar mechanisms exist on other processors.
on ibm power processors every core has a bit time base register while its counting frequency can be changed by software.
if we record the change of counting frequency and the frequencies before and after the change we can convert fig.
happen before determined by local clock the value of time base register to the real wall clock time .
mips processors also have a similar count register but its size is only bit.
sparc processors have a bit tick register to keep the clock cycles.
ideal local clocks should have the same value at the same time across all different cores like a global clock .
each thread can then locally record their own clock values when accessing shared resources.
the recorded time values in different threads can then be compared directly to determine their global order.
they will need neither synchronization when being recorded nor constraints solving when being reproduced so the overall efficiency is improved.
an example is shown in fig.
.
t1 and t2 are two threads bound to different cores.
rdtc is the instruction that reads the per core clock.
suppose in an execution the time stamps read from the local clocks are ts1 andts2 respectively and ts2 is smaller than ts1.
it means that s6happens before s2 i.e.
s6 s2 we can infer that s5 s3.
however although hardware local clocks have existed for a long while no systems has used them to record and reproduce bugs.
an important reason might be that these clocks are not ideal .
hardware does not ensure that the values read from local clocks on different cores are identical at the same time.
lreplay expects that future processors will provide a global clock with a fast access time which would dramatically reduce the runtime overhead and log size as it only needs to record orders that cannot be inferred from the global clock.
unfortunately most commercial processors provide only local core private clocks that can be accessed in user mode.
it usually requires system calls to access the global clock with a substantially higher overhead.
for example on intel xeon phi the overhead to access its global clock is in the order of cycles while it only takes cycles to access local per core clock.
however there are some significant challenges that need to be resolved in order to use the low overhead per core local clocks to determine the global order of shared accesses we need to deal with the differences among different per core local clocks.
in fig.
such differences are needed to infer whether ts2 is earlier than ts1.
unfortunately it is very difficult to get the differences among different per core clocks.
therefore to accurately measure these time differences and use them to order shared accesses are the first challenge.
icse florence italy we need to determine the precise clock value when each thread accesses shared resources.
clocks are read by specific instructions e.g.
rdtsc on x86.
they can be recorded before or after an instruction accessing a shared resource.
however in neither case does the clock value stand for precisely when the shared resource is actually accessed.
furthermore there is no data dependency between rdtc and the target shared resource access instruction.
hence they can be scheduled dynamically in any order on processors that support out of order execution.
this means in fig.
s6may happen before s5 and s3may happen before s2.
for this reason we cannot naively use the results of rdtc instructions to order shared accesses directly.
we need to handle possible overflow of the clocks.
clocks on mips processors has only bits so overflows can occur every few seconds.
even a bit clock can still overflow depending on when we start taking the clock values.
for cores on the same chip their local clocks are triggered by the same clock signal.
they count at the same frequency and the differences among them will be the same after processor reset.
to different processors if they are of the same type and use the same crystal oscillator the difference of their local clocks is highly likely to be consistent.
in such cases with the difference among these local clocks we can use their values to determine the orders of shared memory accesses.
the rest of this paper is based on such cases.
iii.
d etermining the order by local clocks in this section we propose our solutions for the challenges mentioned in section ii.
to use the local clocks challenge must be solved first.
we thus begin with this challenge.
a. out of order execution exclusion most modern processors execute instructions out of order for higher performance.
although instructions are retired in order rdtc reads per core clock before its retirement and thus could be out of the desired order.
an intuitive solution is to insert fence instructions before and after each rdtc which is shown in fig.
a .
this may seem to work but on multi core platforms things are much more complicated.
in modern multi core processors the completion of a write operation can be divided into two phases local complete lc i.e.
the written data is held in the local write buffer but still not seen by other cores yet.
globally visible gv i.e.
the written data reaches the cache memory and is visible to all other cores guaranteed by the cache coherence protocol.
figure b shows the example of a wrong inference.
a local fence only guarantees that w1 lc rdtc1 but cannot control w1 gv .
from the value of the local clock we would infer that w1 r2 which is not the case.
therefore the selected fence instruction must be able to ensure that rdtc is not issued until all previous write instructions become gv .
fortunately modern processors do provide instructions to ensure such orders among memory instructions or to flush the pipeline.
for example on x86 mfence will hold the following loads and stores until preceding loads and stores become globally visible lfence holds the following fig.
tc order fig.
determine orders by local clock instructions until preceding instructions are locally complete.
a correct implementation on x86 is thus shown in fig.
c store means a memory store instruction which is used by mfence .
in thread t1 mfence andlfence guarantee w1 gv rdtc1 while lfence guarantees rdtc1 r1.
b. handling the time difference among per core clocks although per core clock values among cores could be different at any instance of time we can still make use of them if we know their differences called d .
an example is shown in fig.
here.
assume that the values of the two local clocks aretscore1 and tscore2 at a certain time respectively.
then d is tscore2 tscore1 .ts2 ts1 d means s6 s2 i.e.
rdtc2 rdtc1 .
we can infer that s5 s3.
however it is very difficult to get the precise value of d because of those mentioned in section ii.
fortunately it turns out that if we can get a range of possible values on d we still can determine the order of shared accesses among threads.
taking fig.
as an example assume d .
if ts2d1 ts1 we have ts2 d ts2 d1 ts1 and this means s6 s2.
we can thus infer s5 s3.
similarly if ts1 d2 ts2 we can infer s1 s7.
in other cases these operations cannot be ordered.
although the range of d is not as good as a precise d it is still possible to determine the order of most shared accesses if the range is small enough.
for commercial processors that cannot provide the value of d precisely we propose two schemes to get a range of d scheme use test programs to obtain an range of d. icse florence italyfig.
local clock difference tester scheme use statistical means to obtain a smaller range of d with high confidence scheme use test programs we designed a small test program shown in fig.
for this scheme.
the order of rdtc and other instructions is guaranteed and the fence instructions are not included for clarity.
threads t1 and t2 are bound to two cores for which d is measured.
each thread writes a different value to the variable x. both threads read the local clock before and after the write operation and they get ts1 ts2 ts3andts4 respectively.
the final value of xis checked after both t1 and t2 exits.
ifxis s7 in t2 must be later than s2 in t1 so we can infer s1 s2 s7 s8.
at the time that s1reads the value ts1 from core1 s local clock the value of core s local clock ists1 d. therefore we have ts1 d ts4 that is d ts4 ts1 ifread xis2 similarly if the value of xread by thread t0 is .
we can infer that s6 s7 s2 s3 and ts3 ts2 d d ts3 ts2 ifread xis1 we can repeat the above process so as to collect many cases satisfying either equation or and obtain many pairs of ts4i ts1i or ts3i ts2i .
according to the above inference the value of d is less than any ts4i ts1i and greater than any ts3i ts2i.
that is max i ts3i ts2i d min i ts4i ts1i as mentioned in section iii a in order to ensure the execution order of the above instructions we have to add some fence or similar instructions in the testing program.
we designed four implementations for x86 platforms.
in fig.
a we use the instructions sequence introduced in fig.
c while in fig.
b we use the serializing instruction cpuid instead.
serializing instructions force the processor to complete all previous instructions and flush all buffered writes to memory before next instruction is fetched .
in fig.
c we make use of atomic instruction xchg .
this fig.
difference tester implementation fig.
statistic tester implementation does not guarantee that the gv of writing xhappen before rdtsc so we need to check whether it does.
fig.
d is similar to that in fig.
c but it uses cmpxchg instead.
fig.
c and fig.
d may generate a smaller range for d for the expensive mfence orcpuid is replaced.
the efficacy of these versions depends on the hardware implementation but we can always run all of them many times to obtain a minimum range of d. scheme statistical testing although the range obtained by scheme can be used to identify the order of most shared accesses we would still like to have a smaller one.
in scheme when the operations x and x are executed close to the same time we may get a smaller range of d. however even in such cases the range cannot be shrunk to .
the reasons include the time needed by rdtc and fence instructions.
the overhead brought by the write buffer flushing.
the overhead brought by the cache coherence protocol.
in order to reduce their impact we propose another scheme based on statistics.
fig.
shows our statistic tester.
it has two worker threads t1 t2 and a trigger thread t0 which are bound to different cores.
the initial value of flag is so t1 and t2 will spin on flag.
after thread t0 writes to flag t1 and t2 finish the while loop and read the local clock hopefully about the same time.
the difference of their results ts2 ts1 is the d we want.
icse florence italyhowever in practice the rdtc s in t1 and t2 are unlikely to be executed at the same time for the following factors factor the while loop contains at least instructions load compare andbranch .
when t0 sets to flag t1 and t2 may not execute the same instruction and they will not exit thewhile loop at the same time.
factor the cache coherence protocol will delay one of the worker threads.
in most modern processors each core has private l1 and l2 caches and the processor uses a coherence protocol e.g.
mesif on intel x86 to maintain data coherence among cores.
when two cores simultaneously read one cache line absent in their private cache they obtain the data serially .
therefore one of the cores will suffer a delay.
besides according to the thread core mapping strategy data transfer distance between t1 t2 and t0 may be different.
when t0 set to flag t1 and t2 may not know it at the same time.
factor scheduling and interruption may occur between thewhile loop and rdtc.
factor when t1 and t2 exit the while loop icache miss or page fault may occur.
for the test program in fig.
the effect of the above factors needs to be reduced.
putting the codes of while loop and rdtc in the same cache line can eliminate the factor .
for factor a kernel module will be helpful.
it will prevent the kernel to schedule other threads to the cores that t1 or t2 is bound to.
if an interruption occurs during the execution of the test program it can notify the test program that its result is invalid.
on most modern processors x86 power sparc and mips etc.
each processor has several cores.
suppose in fig.
t0 and t2 are bound to the same processor and t1 is bound to a different processor.
t2 will get the new value of flagfaster than t1.
this is the effect from thread core mapping strategy.
we then use such a thread core mapping if we want to calculate the dof two cores on the same processor t1 and t2 are bound to cores in one processor or t1 and t2 are bound to two different processors and in each run t0 is randomly bound to either of the two processors that t1 and t2 are bound to.
we use and i to represent the effects of factors and and run the test program repeatedly.
assume ts1i ts2i is the timestamp pair of the i th run then ts2i ts1i d i iii that is d i iii ts2i ts1i in equation if t1 obtains the new value of flagfirst the value of iis otherwise the value of iis .
we have braceleftbiggd i ii ts2i ts1i ith t2gets data first d j ij ts2j ts1j jth t1gets data first when the test program is run numerous times we have d r2r2 summationdisplay l 1 il r2r2 summationdisplay l 1iil r2r2 summationdisplay l ts2il ts1il d r1r1 summationdisplay s 1 js r1r1 summationdisplay s 1ijs r1r1 summationdisplay s ts2js ts1js fig.
a distribution of tsd assume in r2runs i1 i2 ir2 t2 obtains data first while in the r1runs j1 j2 jr1 t1 obtains data first.
when t0 set flagto the instructions that t1 and t2 are executing are random.
the effect of factor on t1 and t2 are the same implying that the expectation value of is .
if the test program runs numerous times we can assume that the average of is that is1 r2 summationtextr2 l 1 il r1 summationtextr1 s 1 js .
according to our thread core mapping strategy if the number of runs is large enough the delay caused by factor is the same for both t1 and t2 that is1 r2 summationtextr2 l 1iil r1 summationtextr1 s 1ijs.
therefore equation is converted to d r2r2 summationdisplay l ts2il ts1il r1r1 summationdisplay s ts2js ts1js by wiener khintchines law for large numbers when the number of test increases to a very large number the value of d in equation will approach a constant.
therefore we can use the test program in fig.
.
to estimate the difference of the local clocks on the cores to which t1 and t2 are bound.
to use the above equations we need to know the thread in fig.
that obtains the new value of flagfirst.
we run the test program in fig.
million times.
a distribution of tsd ts2 ts1is shown in fig.
.
there are two spikes in fig.
.
in the i th run tsdi ts2i ts1i d i iii.
the value of d is fixed.
and the value of iis affected by instructions which take less than cycles.
in fig.
the distance of the two spikes is more than cycles.
therefore the two spikes are generated by i. we regard the center line of the two spikes in fig.
.
as the boundary.
if the value of tsd is on the left side of this boundary it implies that t1 obtains data first and the value of iis .
otherwise the value of iis .
using the above equations we get an approximation of d marked as d .
however it is still not precise enough.
we need to calculate the confidence interval of d. according to the central limit theorem the value of d approximately has a normal distribution that is d n 2 .
the expectation value of this distribution is the approximated difference of the local clocks on different cores.
assume d1 d2 dnare n samples and dands2are the sample average and variance respectively.
to a given significance level we expect to find an interval that contains the expectation with a probability .
because the variance 2of this distribution is unknown we use sample variance instead of the real variance icse florence italyp d s nt n d s nt n assume the sample size is n the expectation i.e.
the difference value d has a confidence interval with confidence coefficient d s nt n d s nt n local clock overflow as mentioned earlier the size of the clock in most processors expect sparc and mips is bit which takes more than ten years to overflow with the current clock frequency.
the bit sparc clock also takes several years.
it is enough for most applications.
but for a bit mips clock overflows can occur every a few seconds.
therefore overflow must be considered and handled.
assume the overflow cycle of a clock is p we must ensure that the interval between two adjacent records is less than p. in such a case we only need to compare the value of two adjacent recordstscn 1andtscn iftscn tscn the clock overflowed if tscn tscn it did not.
we scan all the records during the offline analysis.
when we found the clock overflows an overflow counter is increased by .
when we order shared accesses among threads both the clock and the overflow counter are taken into consideration.
however since the mips clock overflows every few seconds an interrupt or task rescheduling may make the interval between two records larger than p. in practice the time used to handle an interrupt is short in most cases in milliseconds but task rescheduling will affect the accuracy if dozens of threads are bound to one core.
we did not find two adjacent records whose interval is more than second.
furthermore using a kernel module to record the wall clock time of the scheduling and interruption could solve this problem thoroughly.
iv.
r eproducing bugs using local clocks in this section we select two well known bug reproducing systems pres and clap and show how to apply our approach to them.
the reasons to select them are as mentioned in section i pres relies on an expensive scheme to record the global order of some special events.
clap depends on offline analysis to compute the buggy interleaving with very low recording overhead.
they represent the two key problems .large recording overhead .long analysis and replay time.
to apply our approach to pres and clap first we need to bind each thread to a different core.
we then use our technique described in section iii.b to calculate the range of dof these cores in advance.
for pres its bottleneck is the recording phase.
we record the value of local clock instead of the global order and infer the orders of such special points as described in section iii.
our experiments show that without globally recording the overhead can be reduced by up to .
.
for clap our goal is to shorten the constraint solving time.
besides recording the execution paths we select some fig.
constraints reduction key points to record their local timestamps and infer their orders by an efficient offline analysis.
these key points can be selected at function calls or loops.
we then combine the inferred orders and the original constraints as new input to the smt solver.
our experiments show that for most benchmarks more than of shared accesses order can be ordered.
for the remaining unordered shared accesses we can also reduce the solving complexity with the help of local timestamps.
assume the memory operations in fig.
access the same shared variable.
in fig.
a for r11in thread t1 clap needs to infer the order between r11and all the writes w21 w2m in thread t2.
however in fig.
b if we could know rdtc3 rdtc1 andrdtc2 rdtc4 by local timestamps we only need to infer the order of r11 w21 andw22.
on the other hand for every shared access clap assigns an integer as its global order number.
with the help of local timestamps we can restrict the range of these global order numbers and shorten the solving time.
in fig.
c the global order numbers of the five shared accesses are all within the interval .
if by the value of local clock we know rdtc1 rdtc2 rdtc3 rdtc4 rdtc5 rdtc6 rdtc7 we can infer that w1 w2 r1 w3 r2.
this can reduce the range of the global order numbers of these shared accesses to and respectively.
v. e xperiments two systems pres impl and clap impl are implemented according to the schemes described in pres and clap .
we then apply recbulc to these two systems called pres tc and clap tc respectively.
in order to use the local clocks each thread of them is bound to a different core.
in this section we will evaluate their performance and table i shows the platform.
we select several bugs in real multi threaded programs table ii as benchmarks.
they include widely used servers desktop applications and scientific programs.
the types of bugs cover common concurrency bugs such as atomicity violation a v and order violation ov .
in this section we compare pres tc clap tc with presimpl clap impl and evaluate our approach.
in the experiments the performance of apache and cherokee is measured by their throughputs and the others are by the execution time.
icse florence italytable iii r eproducing tries .
adduo means the additional unordered accesses benchmarkssync func bb rw pres impl pres tc s pres tc p impl tcs tc p impl tcs tc p impl tcs tc p tries add uo tries tries add uo tries tries add uo tries tries add uo tries apache .
.
.
.
.
.
.
.
cherokee .
.
.
.
.
.
.
.
pbzip2 .
.
.
.
.
.
.
.
pfscan .
.
.
.
.
.
.
.
aget .
.
.
.
.
.
.
.
barnes .
.
.
.
.
.
.
.
lu .
.
.
.
.
.
.
.
radiosity .
.
.
.
.
.
.
.
fig.
normalized exec.
time of pres impl pres tc table i p latform details cpu intel xeon e7 cores .87ghz processors level cache i d 24k 24k level cache 256k level cache 18m memory 16g os linux .
.
compiler gcc .
.
smt solver z3 table ii b enchmarks type benchmarks description bug types serverapache httpd web server a v cherokee web server a v desktop applicationpbzip2 compressor ov pfscan file scanner a v aget http ftp downloadera v scientific application splash barnes barnes n body algorithmov lu lu matrix multiplicationov radiosity graphics renderingov system library routines rarely access shared variables and their accesses can be inferred from their arguments easily so we do not consider them.a.
evaluating pres impl and pres tc pres impl records the global order of certain operations while pres tc records their local timestamps instead.
it reduces the recording overhead significantly.
fig.
shows the normalized execution time of presimpl to pres tc instrumented at the synchronization sync function func basic block bb and memory operation rw level.
the baseline is the native execution time.
pres can reproduce all of the bugs at the func level within tries.
at the bb level pres reproduces all of the bugs within tries.
taking recording overhead and the number of reproducing tries into consideration instrumentation at these two levels seems reasonably good for pres impl.
prestc reduces the recording overhead from .
in pres impl to .
at the func level on average.
at the bb level the recording overhead is reduced from .
to .
.
the main reason for the improvement is that pres tc avoids the synchronizations and allows each thread to record local timestamps concurrently.
take lu as an example .
and .
of the recordings in pres tc are done concurrently at func and bb levels respectively and thus .
and .
of the recording overheads are reduced.
at sync level the overheads of the two systems are similar.
this is because the number of synchronization operations is very small and the recording overhead is hidden by the time consuming synchronization operations.
during the execution of lu with default inputs it has more than million function calls but only synchronization operations.
for pbzip2 and aget their overheads in both schemes are nearly the same.
the reason is that the main workload of pbzip2 and aget is compressing and downloading data icse florence italyfig.
scalability of pres impl pres tc.
the y axis is normalized exec.
time and in the lower sub graphs are logarithmic.
fig.
normalized solving time of clap impl clap tc.
each benchmark is evaluated with inputs.
using system library routines but we do not instrument those routines as mentioned earlier.
pres tc determines the order of shared memory accesses by a range of d. compared with pres impl it will bring a small amount of additional unordered shared memory accesses.
table iii shows the percent of them to the total shared memory accesses and the number of tries in both presimpl and pres tc.
pres tc p and pres tc s use the ranges of d calculated by the two schemes described in section iii respectively.
we can see from these data that the percent of additional unordered accesses is less than at bb func and sync levels which is a small percentage of all shared memory accesses.
we also see that pres tc needs no more tries than pres impl.
this is because the goal of pres is to reproduce bugs and for most concurrency bugs the root cause is only related to a handful of shared accesses .
for lu at rw level although there are .
.
unordered shared accesses the bug can still be reproduced in one try.
that is because the bug in lu is caused by invalid synchronization operations and the order of accesses determined by local timestamps is enough to reproduce this bug.
figure shows the recording overhead of pres impl and pres tc with different numbers of threads.
when the number of threads increases the overhead of pres impl increasesmore quickly in most cases because the lock is more frequently accessed.
for pres tc the thread private recording benefits its scalability.
for lu at the func level .
.
and .
of the recordings are done concurrently when there are and threads respectively.
if there are more threads a higher percentage of the recording time will be done concurrently.
b. evaluating clap impl and clap tc clap uses an smt solver to reproduce the buggy interleavings but the floating point operations supported by smt solvers are limited.
the bugs in barnes lu and radiosity are related to floating point operations.
clap does not use them as benchmarks.
therefore in clap impl we use these three benchmarks to measure the recording slowdown only.
furthermore clap uses a well designed test case racey that contains massive data races and is very likely to produce a different result when the interleaving is different.
clap uses it to show its capability.
we also use racey to evaluate clap tc.
for better performance the range ofdused by clap tc is calculated using statistics testing .
figure shows the recording overhead of clap impl and clap tc at different instrumentation levels.
func records the local timestamps at the entries and exits of functions icse florence italyfig.
recording overhead of clap impl clap tc.
loop records at the entries exits and back edges of loops funcloop is a combination of func and loop.
in fig.
we can see that the recording slowdown of clap tc is of clap impl and mostly less than .
figure shows the solving time of clap impl and claptc at different instrumentation levels.
from small to large each benchmark is tested with different inputs.
during bug reproducing for the input constraints we can get the results from the smt solver first and combine the results with the original input as a new input.
the time the solver takes to solve the new input is approximated to the minimum solving time and we call it near optimal solving time nost .
in fig.
we show the ratios of clap impl and clap tc to nost.
clap tc records the local timestamps at three different levels.
figure shows that compared to clap impl clap tc reduces solving time by .
.
.
this is because the orders of most shared memory accesses are determined by local timestamps.
in pbzip2 at the funcloop level the local timestamps determine more than of the orders.
this reduces the solving time substantially.
furthermore with larger inputs the solving time of clap impl increases much more quickly than that of clap tc.
in pbzip2 the solving time of clap impl with the largest input is about 1000x to the smallest input while the ratio of clap tc is only 4x.
on the other hand for most benchmarks the solving time of clap tc is less than 10x of nost.
especially the solving time of aget is nearly the same as nost.
in our experiments nost of all benchmarks is at most several seconds.
in studying fig.
and we can see that the lower the instrumentation level is the less solving time but the more overhead is introduced.
at the func and loop levels the loop bodies may contain complicated function calls and a function body may contain many loops.
this makes their solving time much longer than that at the funcloop level.
the recording overhead at the funcloop level is a bit more than that at the func and loop level.
altogether we believe funcloop is a suitable level for instrumentation.
on the other hand clap tc is less effective for racey.
in racey most addresses of write operations are calculated by shared variables.
in such cases if a read happens before a write it is difficult to infer whether the read and the write access the same shared variable or not.
thus a few redundant constraints remain in the input for the smt solver.
even fig.
stability of equation .
table iv p rogram testing results testing program1sttest 2ndtest min max min max fig.
a fig.
b fig.
c fig.
d result so the solving time of clap impl is about 5x 100x longer compared to clap tc in our experiments which also shows the effectiveness of using local time stamps.
c. value differences of local clocks among cores this subsection shows the results of our two schemes to calculate the range of d. program testing scheme we designs four programs to test the ranges of d. table iv shows two test results for these programs on the same cores.
in each test every program executes 10k times.
the test platform and the number of test runs could affect the results in table iv.
more test runs could generate a smaller range.
on our test platform the test program in fig.
b gets a larger range than other programs in fig.
.
this is because the implementation of the serializing instructions on this processor is more time consuming than others.
the results of the other programs are more or less the same.
in table iv the range of d is about cycles.
using is to order shared access will not bring false positives or false negatives.
statistics scheme our proposed statistical scheme uses the statistical tester and equation to calculate the range of d. for equation we need to know the value of i and the test procedure is as follows bind the worker and trigger threads in fig.
according to section iii b2.
run the test program n times and get n results by using equation deltai d i iii ts2i ts1i build the distribution of deltaiaccording to section iii b2 and infer the value of iin each execution.
calculate the value of d by equation .
stability .
if the number of test runs of the statistical tester is large enough the result of equation will be stable.
we ran this program continuously for more than days collected around million results that are shown in fig.
.
icse florence italytable v c onfidence intervals .
the first column is the con fidence coefficient .
the first row is the value of n and the second row is the value of m in this figure we calculate d every hour using about runs of the statistical tester.
stability means the d is calculated by the data collected in each hour while acc stability means the d calculated by the data from the beginning.
from these data we can see that over a long time period more than days the calculated d in each hour are all in the interval and their sample variance is .
.
this means that the calculated d is very stable.
confidence interval .
now we calculate an approximation of d. we calculate its confidence interval under different confidence coefficients using equation .
the confidence interval requires many samples of d. we calculates d using the method described in section iii b2 many times and get d1 d2 d3 dm.
eachdiis the result of n runs of the program in fig.
.
finally we get the data shown in table v by equation using these di.
in table v the higher the confidence coefficient is the larger the range is.
when the confidence coefficient is fixed the values of n and m vary inversely with the confidence intervals.
in practice we could calculate confidence intervals with different confidence coefficients according to the target program.
table v shows that when the confidence coefficient is .
the n is and the m is .
the range of the confidence interval is about which is still smaller than the range obtained by program testing.
vi.
r elated work for most record and replay or other bug reproducing systems the focus has been on reducing the recording overhead.
however this is often traded with high offline analysis cost.
our approach takes advantage of the local clock and can reduce both recording overhead and the bug reproducing time.
pres does not record all the global order during recording and tries to reproduce bugs by offline analysis.
it only records the global order of some special events such as synchronizations system calls function calls basic blocks and memory instructions.
during offline analysis it searches for the buggy interleaving by exploration.
some systems reduce the recording slowdown by record other information that imply the global order of shared accesses.
smp revirt and scribe make use of the page protection mechanism.
they record the ownership transfer of pages among threads to infer the order of shared accesses.for programs with little false sharing scribe has good performance.
however for programs with significant false sharing its recording overhead could be very large.
doubleplay divides the program into many epochs by time intervals.
besides concurrent execution doubleplay forks new processes to run epochs serially at the beginning of every epoch.
it only needs to record the order of epochs hence dramatically reduce recording overhead.
if the results of concurrent and serial execution are different a rollback is needed.
for programs with many races the rollback overhead can be large.
besides these systems affect the behavior of multi threaded programs and some bugs may never be exposed.
there are also systems that record mostly local information to avoid global synchronization.
clap makes each thread record its own execution paths and searches for buggy interleavings by a smt solver.
odr reproduces concurrency bugs by ensuring the same output as recording execution.
it only records the global order of synchronization operations during execution.
in reproducing similar to clap it generates many interleavings and verifies their outputs by an smt solver.
coredump makes use of the core dump when a program crashes.
it records the number of iterations in loops at run time and incurs little overhead.
depending on the error point it searches for a similar point to generate a right core dump.
comparing the core dumps of these two points it tries to explore the buggy interleaving.
lreplay uses global timestamps.
it expects future processors to provide a global clock with a fast access time.
with such a global clock lreplay only needs to record orders that cannot be inferred from the global time.
vii.
c onclusion in order to reproduce the concurrency bugs in multithreaded programs more efficiently this paper proposes recbulc which takes advantage of the local per core clocks on modern processors.
during the recording phase each thread records its own data and local timestamps to avoid expensive synchronization operations among threads.
the local clocks are used to determine the global order of shared resource accesses.
we have proposed two effective schemes to calculate the time difference among local clocks.
our experiments show that after applying recbulc to pres and clap two wellknown record and replay schemes the recording overheads and solving time can be reduced by and .
.
respectively.
acknowledgement we would like to thank the anonymous reviewers for their useful feedback.
this research is supported by the national high technology research and development program of china under grant 2012aa010901 the national natural science foundation of china nsfc under grants and the innovation research group of nsfc under grant .
icse florence italyreferences shan lu soyeon park eunsoo seo yuanyuan zhou.
learning from mistakes a comprehensive study of real world concurrency bug characteristics.
in asplos .
nancy leveson clark s. turner.
an investigation of the therac accidents.
computer 18c41 .
securityfocus.
software bug contributed to blackout.
jeff huang charles zhang and julian dolby.
clap recording local executions to reproduce concurrency failures.
in pldi .
intel and ia architectures software developers manual.
september .
mips architecture for programmers.
revision .
.
april .
power isa version .
.
may .
oracle sparc architecture .
july .
j.r. goodman and h.h.j.
hum.
mesif a two hop cache coherence protocol for point to point interconnects .
thomas.
j. leblanc and john.
m. mellor crummey.
debugging parallel programs with instant replay.
ieee trans.
comput.
.
satish narayanasamy cristiano pereira harish patil robert cohn brad calder.
automatic logging of operating system effects to guide application level architecture simulation.
in sigmetrics .
george w. dunlap dominic g. lucchetti michael a. fetterman peter m. chen.
execution replay of multiprocessor virtual machines.
in vee .
soren laadan nicolas viennot and jason nieh.
transparent lightweight application execution replay on commodity multiprocessor operating systems.
in sigmetrics .
soyeon park yuanyuan zhou weiwei xiong zuoning yin rini kaushik kyu h. lee and shan lu.
pres probabilistic replay with execution sketching on multiprocessors.
in sosp .
yunji chen weiwu hu tianshi chen and ruiyang wu.
lreplay a pending period based deterministic replay scheme.
in isca .
dongyoon lee benjamin wester kaushik veeraraghavan satish narayanasamy peter m. chen jason flinn.
respec efficient online multiprocessor replay via speculation and external determinism.
in asplos .
gautam altekar ion stoica.
odr output deterministic replay for multicore debugging.
in sosp .
pablo montesinos luis ceze and josep torrellas.
delorean recording and deterministically replaying shared memory multi processor execution efficiently.
in isca .
dasarath weeratunge xiangyu zhang and suresh jagannathan.
analyzing multicore dumps to facilitate concurrency bug reproduction.
in asplos .
min xu rastislav bodik and mark hill.
a flight data recorder for full system multiprocessor deterministic replay.
in isca .
kaushik veeraraghavan dongyoon lee benjamin wester jessica ouyang peter m. chen jason flinn and satish narayanasamy.
doubleplay parallelizing sequential logging and replay.
in asplos .
derek hower and mark hill.
rerun exploiting episodes for lightweight memory race recording.
in isca .
jeff huang peng liu and charles zhang.
leap lightweight deterministic multi processor replay of concurrent java programs.
in fse .
leonardo de moura and nikolaj bjorner.
z3 an efficient smt solver.
in tacas .
steven cameron woo moriyoshi ohara evan torrie jaswinder pal singh anoop gupta.
the splash programs characterization and methodological considerations.
in isca .
apache httpd.
cherokee web server.
dongyoon lee peter m. chen jason flinn and satish narayanasamy.
chimera hybrid program analysis for determinism.
in pldi .
bruno dutertre and leonardo de moura.
the yices smt solver.
technical report .
j. gray .
why do computers stop and what can be done about it?
in buroautomation pp.
.
icse florence italy