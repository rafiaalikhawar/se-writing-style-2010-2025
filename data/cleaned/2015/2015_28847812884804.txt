automatically learning semantic features for defect prediction song wang taiyue liu and lin tan electrical and computer engineering university of waterloo canada song.wang t67liu lintan uwaterloo.ca abstract software defect prediction which predicts defective code regions can help developers nd bugs and prioritize their testing e orts.
to build accurate prediction models previous studies focus on manually designing features that encode the characteristics of programs and exploring di erent machine learning algorithms.
existing traditional features often fail to capture the semantic di erences of programs and such a capability is needed for building accurate prediction models.
to bridge the gap between programs semantics and defect prediction features this paper proposes to leverage a powerful representation learning algorithm deep learning to learn semantic representation of programs automatically from source code.
speci cally we leverage deep belief network dbn to automatically learn semantic features from token vectors extracted from programs abstract syntax trees asts .
our evaluation on ten open source projects shows that our automatically learned semantic features signi cantly improve both within project defect prediction wpdp and cross project defect prediction cpdp compared to traditional features.
our semantic features improve wpdp on average by .
in precision .
in recall and .
in f1.
for cpdp our semantic features based approach outperforms the state of the art technique tca with traditional features by .
in f1.
.
introduction software defect prediction techniques have been proposed to detect defects and reduce software development costs.
defect prediction techniques build models from software data and use the models to predict whether new instances of code regions e.g.
les changes and methods contain defects.
e orts of previous studies towards building accurate prediction models fall into two main directions one is manually designing new features or new combinations of features to represent defects more e ectively the other is using new and improved permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
learning algorithms.
researchers have manually designed many features to distinguish defective les from non defective les e.g.
halstead features based on operator and operand counts mccabe features based on dependencies ck features based on function and inheritance counts etc.
mood features based on polymorphism factor coupling factor etc.
code change features include number of lines of code added removed etc.
and other object oriented features .
meanwhile many machine learning algorithms have been adopted for software defect prediction including support vector machine svm naive bayes nb decision tree dt neural network nn and dictionary learning .
programs have well de ned syntax which can be represented by abstract syntax trees asts and have been successfully used to capture programming patterns .
in addition programs have semantics which is hidden deeply in source code .
it has been shown that programs semantic information is useful for tasks such as code completion and bug detection .
such semantic information should also be useful for characterizing defects for improving defect prediction.
speci cally in order to make accurate predictions the features need to be discriminative capable of distinguishing one instance of code region from another.
however existing traditional features cannot distinguish code regions of di erent semantics.
program les with di erent semantics can have traditional features with the same values.
for example figure shows two java les file1.java and file2.java both of which contain an if statement a forstatement and two function calls.
using traditional features to represent these two les their feature vectors are identical because these two les have the same source code characteristics in terms of lines of code function calls raw programming tokens etc.
however the semantic information is di erent.
features that can distinguish such semantic di erences should enable the building of more accurate prediction models.
to bridge the gap between programs semantic information and features used for defect prediction this paper proposes to leverage a powerful representation learning algorithm namely deep learning to learn semantic representation of programs automatically and use the representation to improve defect prediction.
speci cally we use deep belief network dbn to automatically learn features from token vectors extracted from programs asts and then utilize these features to train a defect prediction model.
ieee acm 38th ieee international conference on software engineering int i if i foo for i i i bar file1.java1 int i foo for i i i if i bar file2.java figure a motivating example dbn is a generative graphical model which learns a representation that can reconstruct training data with a high probability.
it automatically learns high level representation of data by constructing a deep architecture .
we have seen successful applications of dbn in many elds including speech recognition image classi cation natural language understanding and semantic search .
to use a dbn to learn features from code snippets we convert the code snippets into vectors of tokens with structural and contextual information preserved and use these vectors as input to the dbn.
for the two code snippets in figure the input vectors will be ... if foo for bar ... and respectively.
since the vectors of these two les are di erent dbn will automatically learn features to distinguish these two code snippets details are in figure and section .
.
this paper makes the following contributions we propose to leverage a powerful representationlearning algorithm namely deep learning to learn semantic features from token vectors extracted from programs asts automatically.
we leverage the semantic features learned automatically by dbn to improve both within project defect prediction wpdp and cross project defect prediction cpdp .
our evaluation results on ten open source java projects show that the automatically generated semantic features improve both wpdp and cpdp.
for wpdp our semantic features achieve an average improvement of precision by .
recall by .
and f1 by .
compared to traditional features.
for cpdp our semantic feature based approach outperforms the stateof the art technique tca built on traditional features by .
in f1.
the rest of this paper is summarized as follows.
section provides backgrounds on defect prediction and dbn.
section describes our proposed approach to learn semantic features from source code automatically and leverage these learned features to predict defects.
section shows the experimental setup.
section evaluates the performance of learned semantic features.
section and section present threats to our work and related work respectively.
we conclude this paper in section .
.
background this section provides the backgrounds of le level defect prediction and deep belief network.
figure defect prediction process .
defect prediction figure presents a typical le level defect prediction process that is adopted by existing studies .
the rst step is to label data as buggy or clean based on post release defects for each le.
a le is buggy if the le contains bugs.
otherwise the le is clean .
the second step is to collect corresponding traditional features of these les.
instances with features and labels are used to train machine learning classi ers.
finally trained models are used to predict new instances as buggy or clean.
we refer to the set of instances used for building models as thetraining set whereas the set of instances used to evaluate the trained models as the test set.
as shown in figure when performing within project defect prediction following existing work we call this wpdp the training and test sets are from the same project a. when performing crossproject defect prediction following existing work we call this cpdp prediction models are trained by training set from a project a source and test set is from a di erent project b target .
in this study we examine the performance of learned semantic features on both wpdp and cpdp.
.
deep belief network a deep belief network is a generative graphical model that uses a multi level neural network to learn a representation from training data that could reconstruct the semantic and content of input data with a high probability .
dbn contains one input layer and several hidden layers and the top layer is the output layer that used as features to represent input data as shown in figure .
each layer consists of several stochastic nodes.
the number of hidden layers and the number of nodes in each layer vary depending on users demand.
in this study the size of learned semantic features is the number of nodes in the top layer.
the idea of dbn is to enable the network to reconstruct the input data using generated features by adjusting weights between nodes in di erent layers.
dbn models the joint distribution between input layer and the hidden layers as follows p x h1 hl p xjh1 ly k 1p hkjhk wherexis the data vector from input layer lis the number of hidden layers and hkis the data vector of kthlayer k l .p hkjhk is a conditional distribution for the adjacentkandk layer.
298to calculate p hkjhk each pair of two adjacent layers in dbn are trained as a restricted boltzmann machines rbm .
a rbm is a two layer undirected bipartite graphical model where the rst layer consists of observed data variables referred to as visible nodes and the second layer consists of latent variables referred to as hidden nodes .
p hkjhk can be e ciently calculated as p hkjhk nky j 1p hk jjhk p hk j 1jhk sigm bk j nk 1x a 1wk ajhk a wherenkis the number of node in layer k sigm c e c bis a bias matrix bk jis the bias for node jof layerk and wkis the weight matrix between layer kandk .
dbn automatically learns wandbmatrices using an iteration process.
wandbare updated via log likelihood stochastic gradient descent wij t wij t log p vjh w ij bo k t bo k t log p vjh bo k wheretis thetthiteration is the learning rate p vjh is the probability of the visible layer of a rbm given the hidden layer iandjare two nodes in di erent layers of the rbm wijis the weight between the two nodes and bo kis the bias on the node oin layerk.
to train the network one rst initializes all wmatrices between two layers via rbm and sets the biases bto0.
they can be well tuned with respect to a speci c criterion e.g.
the number of training iterations error rate between reconstructed input data and original input data.
in this study we use the number of training iterations as the criterion for tuningwandb.
the well tuned wandbare used to set up a dbn for generating semantic features for both training and test data.
also we discuss how these parameters a ect the performance of learned semantic features in section .
.
.
approach in this work we use dbn to generate semantic features automatically from source code and leverage these features to improve defect prediction.
figure illustrates the workow of our approach according to the motivating example in figure .
our approach takes tokens from the source code of the training and test sets as input and generates semantic features from them which are then used to build and evaluate the models for predicting defects.
speci cally our approach rst extracts a vector of tokens from the source code of each le in both the training and test sets.
since dbn requires input data in the form of integer vectors we build a mapping between integers and tokens and convert the token vectors to integer vectors.
to generate semantic features we rst use the integer vectors of the training set to build a dbn.
then we use the dbn to automatically generate semantic features from the integer vectors of the figure deep belief network architecture and input instances of file1.java and file2.java.
although the token sets of these two les are identical the di erent structural and contextual information between tokens enables dbn to generate di erent features to distinguish these two les.
training and test sets.
finally based on the generated semantic features we build defect prediction models from the training set and evaluate their performance on the test set.
our approach consists of four major steps parsing source code into tokens mapping tokens to integer identi ers which are the expected inputs of dbn leveraging dbn to automatically generate semantic features and building defect prediction models and predicting defects using the learned semantic features of the training data and the test data.
.
parsing source code for our study we need to extract syntactic information from source code for dbn to learn semantic features.
we utilize java abstract syntax tree ast to extract syntactic information from source code.
three types of ast nodes are extracted as tokens nodes of method invocations and class instance creations e.g.
in figure method foo and bar are recorded as their method names declaration nodes i.e.
method declarations type declarations and enum declarations and controlow nodes such aswhile statements catch clauses ifstatements throw statements etc.
controlow nodes are recorded as their statement types e.g.
an ifstatement is simply recorded as if.
in summary for each le we obtain a vector of tokens of the three categories.
we exclude ast nodes that are not one of these three categories such as assignment and intrinsic type declaration because they are often method speci c or class speci c which may not be generalizable to the whole project.
adding them may dilute the importance of other nodes.
since the names of methods classes and types are typically project speci c methods of an identical name in different projects are either rare or of di erent functionalities.
thus for cross project defect prediction we extract all three categories of ast nodes but for the ast nodes in categories and instead of using their names we use their ast node types such as method declarations and method invocations .
take project xerces as an example.
as an xml parser it consists of many methods named getxxx and 299figure overview of our proposed dbn based feature generation and defect prediction setxxx where xxxrefers to xml speci c keywords includingcharset type and href.
each of these methods contains only one method invocation statement which is in form of either getattribute xxx orsetattribute xxx .
methodsgetxxx and setxxx do not exist in other projects while getattribute xxx and setattribute xxx have di erent meanings in other projects so using their names getattribute xxx orsetattribute xxx is not helpful.
but it is useful to know that there exist method declaration nodes and only one method invocation node is under each of these method declaration nodes since it might be unlikely for a method with only one method invocation inside to be buggy.
in this case compared with using the method names using the ast node types method declaration and method invocation is more useful since they can still provide partial semantic information.
.
handling noise and mapping tokens .
.
handling noise defect data are often noisy and su er from the mislabeling problem.
studies have shown that such noises could signi cantly erode the performance of defect prediction .
to prune noisy data kim et al.
proposed an e ective mislabeling data detection approach named closest list noise identi cation clni .
it identi es the k nearest neighbors for each instance and examines the labels of its neighbors.
if a certain number of neighbors have opposite labels the examined instance will be agged as noise.
however such approach cannot be directly applied to our data because their approach is based on the euclidean distance of traditional numerical features.
since our features are semantic tokens.
the di erence between the values of two features only indicates that these two features are of di erent tokens.
to detect and eliminate mislabeling data and help dbn learn common knowledge between the semantic information of buggy and clean les we adopt the edit distance similarity computation algorithm to de ne the distances between instances.
the edit distances are sensitive to both the tokens and order among the tokens.
given two token sequences a andb the edit distance d a b is the minimum weight series of edit operations that transform atob.
the smaller d a b is the more similar aandbare.
based on edit distance similarity we deploy clni to eliminate data with potential incorrect labels.
in this study since our purpose is not to nd the best training or test set we do not spend too much e ort on well tuning the parameters of clni.
we use the recommended parameters and nd themwork well.
in our benchmark experiments with traditional features we also perform clni to remove the incorrectly labeled data.
additionally we lter out infrequent ast nodes which might be designed for a speci c le and be hardly generalized to other les.
for a project if the total number of occurrences of a token is less than three we lter the token out.
we encode only the tokens that occur three or more times which is a common practice in the nlp research eld .
.
.
mapping tokens dbn takes only numerical vectors as inputs and the lengths of the input vectors must be the same.
to use dbn to generate semantic features by using dbn we rst build a mapping between integers and tokens and encode token vectors to integer vectors.
each token has a unique integer identi er while di erent method names and class names will be treated as di erent tokens.
since our integer vectors may have di erent lengths we append to the integer vectors to make all the lengths consistent and equal to the length of the longest vector.
adding zeros does not a ect the results and it is simply a representation transformation to make the vectors acceptable by dbn.
taking code snippets in figure as an example if we consider only file1 and file2 the token vectors for file1 and file2 would be mapped to and respectively.
through this encoding process method invocation information and inter class information are represented as integer vectors.
in addition some program structure information is preserved since the order of tokens remains unchanged.
.
training dbn and generating features .
.
training dbn to generate semantic features for distinguishing buggy and clean les we need to rst train dbn by using the training data.
as discussed in section to train an e ective dbn for learning semantic features we need to tune three parameters which are the number of hidden layers the number of nodes in each hidden layer and the number of training iterations .
existing work that leveraged dbn to generate features for nlp and image recognition reported that the performance of dbn generated features is sensitive to these parameters.
we show how we tune these parameters in section .
.
to simplify our model we set the number of nodes to be the same in each layer.
through these hidden layers and nodes dbn obtains characteristics that are di cult 300to be observed but are capable of capturing semantic di erences.
for each node dbn learns probabilities of traversing from this node to the nodes of its top level.
through backpropagation validation dbn reconstructs the input data using generated features by adjusting weights between nodes in di erent layers.
dbn requires the values of input data ranging from to while data in our input vectors can have any integer values due to our mapping approach.
to satisfy the input range requirement we normalize the values in the data vectors of the training and test sets by using min max normalization .
in our mapping process integer values for di erent tokens are just identi ers.
one token with a mapping value of and one token with a mapping value of only means these two nodes are di erent and independent.
thus the normalized values can still be used as token identi ers since the same identi ers still keep the same normalized values.
.
.
generating features after we train a dbn both the weights wand the biases b details are in section are xed.
we input the normalized integer vectors of the training data and the test data into the dbn respectively and then obtain semantic features for the training and test data from the output layer of the dbn.
.
building models and performing defect prediction after we obtain the generated semantic features for each le in both the training data and the test data we build and train defect prediction models by following the standard defect prediction process described in section and then we use the test data to evaluate the performance of the built defect prediction models.
.
experimental setup we conduct several experiments to study the performance of the proposed semantic features and compare them with existing traditional features.
we run experiments on a .5ghz i5 3210m machine with 4gb ram.
.
evaluation metrics to measure defect prediction results we use three metrics precision recall andf1.
these three metrics are widely adopted to evaluate defect prediction techniques .
here is a brief introduction precision true positive true positive false positive recall true positive true positive false negative f1 precision recall precision recall precision and recall are composed of three numbers in terms oftrue positive false positive and false negative.
true positive is the number of predicted defective les that are truly defective while false positive is the number of predicted defective les that are actually not defective.
false negative records the number of predicted non defective les that are actually defective.
a higher precision makes the manual inspection on a certain amount of predicted defective les nd more defects while an increase in recall can reveal moredefects given a project.
f1 takes consideration of both precision and recall.
.
evaluated projects and data sets to facilitate the replication and veri cation of our experiments we use publicly available data from the promise data repository.
we select all java open source projects from promise1whose version numbers are provided.
we need the version numbers of each project because we need to extract token vectors from asts of source code to feed our dbn based feature generation approach.
in total java projects are collected.
table shows the versions the average number of les and the average buggy rate of each project.
the numbers of les of the projects range from to and the buggy rates of the projects have a minimum value of .
and a maximum value of .
.
.
two baselines of traditional features to evaluate the performance of semantic features in defect prediction we compare semantic features with traditional features.
our rst baseline of traditional features consists of traditional features including lines of code operand and operator counts number of methods in a class the position of a class in inheritance tree and mccabe complexity measures etc.
the traditional features are available for promise data and the work from he et al.
contains the full list of the features which are well described in their table ii.
these features and data have been widely used in previous work .
we choose the widely used promise data so that we can directly compare our work with previous studies.
note that for a fair comparison we also perform the noise removal approach described in section .
.
on the promise data.
the traditional features from promise do not contain ast nodes which were used by our dbn models.
for a fair comparison our second baseline of traditional features is the ast nodes that were given to our dbn models i.e.
the ast nodes in all les after xing noise section .
.
.
each instance is represented as a vector of term frequencies of the ast nodes.
.
parameter settings for training a dbn model many dbn applications report that an e ective dbn needs well tuned parameters i.e.
the number of hidden layers the number of nodes in each hidden layer and the number of iterations .
in this study since we leverage dbn to generate semantic features we need to consider the impact of the three parameters.
we tune the three parameters by conducting experiments with di erent values of the parameters on ant .
.
camel .
.
jedit .
.
lucene .
.
and poi .
.
respectively.
each experiment has speci c values of the three parameters and runs on the ve projects individually.
given an experiment for each project we use the older version of this project to train a dbn with respect to the speci c values of the three parameters.
then we use the trained dbn to generate semantic features for both the older and newer versions.
after that we use the older version to build a defect prediction model and apply it to the newer version.
lastly we evaluate the speci c values of the parameters by the average f1 score of the ve projects in defect prediction.
301table evaluated projects project description releases avg files avg buggy rate ant java based build tool .
.
.
.
camel enterprise integration framework .
.
.
.
jedit text editor designed for programmers .
.
.
.
log4j logging library for java .
.
.
lucene text search engine library .
.
.
.
xalan a library for transforming xml les .
.
.
xerces xml parser .
.
.
ivy dependency management library .
.
.
synapse data transport adapters .
.
.
.
poi java library to access microsoft format les .
.
.
.
figure defect prediction performance with di erent parameters .
.
setting the number of hidden layers and the number of nodes in each layer since the number of hidden layers and the number of nodes in each hidden layer interact with each other we tune these two parameters together.
for the number of hidden layers we experiment with discrete values include and .
for the number of nodes in each hidden layer we experiment with eight discrete values include and .
when we evaluate these two parameters we set the number of iterations to and keep it constant.
figure illustrates the average f1 scores for tuning the number of hidden layers and the number of nodes in each hidden layer together.
when the number of nodes in each layer is xed with increasing number of hidden layers all the average f1 scores are convex curves.
most curves peak at the point where the number of hidden layers is equal to .
if the number of hidden layers remains unchanged the best f1 score happens when the number of nodes in each layer is the top line in figure .
as a result we choose the number of hidden layers as and the number of nodes in each hidden layer as .
thus the number of dbn based features for each project is .
.
.
setting the number of iterations the number of iterations is another important parameter for building an e ective dbn.
during the training process dbn adjusts weights to narrow down error rate between reconstructed input data and original input data in each iteration.
in general the bigger the number of iterations the figure average error rate and time cost for di erent numbers of iterations lower the error rate.
however there is a trade o between the number of iterations and the time cost.
to balance the number of iterations and the time cost we choose the same ve projects to conduct experiments with ten discrete values for the number of iterations.
the values range from to .
we use error rate to evaluate this parameter.
figure demonstrates that as the number of iterations increasing the error rate decreases slowly with the corresponding time cost increases exponentially.
in this study we set the number of iterations to with which the average error rate is about .
and the time cost is about seconds.
.
within project defect prediction to examine the performance of our semantic features in within project defect prediction we build defect prediction models using three machine learning classi ers including adtree naive bayes and logistic regression which have been adopted in previous work .
to obtain the training and test data we use two consecutive versions of each project listed in table .
we use the source code of an older version to train dbn and generate the training data.
then we use the trained dbn to generate features for a newer version which are the test data.
we compare our semantic features with the traditional features as described in section .
.
for a fair comparison we use the same classi ers on these traditional features.
defect data are often imbalanced which might a ect the accuracy of defect prediction.
table shows that most of our examined projects have buggy rates less than and so are imbalanced.
to obtain optimal defect prediction 302models we perform the re sampling technique used in existing work i.e.
smote on our training data for both semantic features and traditional features.
.
cross project defect prediction due to the lack of defect data it is often di cult to build accurate prediction models for new projects.
to overcome this problem cross project defect prediction techniques train prediction models by using data from mature projects or called source projects and use the trained models to predict defects for new projects or called target projects .
however since the features of source projects and target projects often have di erent distributions making an accurate and precise cross project defect prediction is still challenging .
we believe that our proposed semantic features can capture the common characteristics of defects which implies that the semantic features trained from a project can be used to predict a di erent project and so applicable in cross project defect prediction.
to measure the performance of the semantic features in cross project defect prediction we propose a technique called dbn c ross project defect prediction dbn cp .
given a source project and a target project dbn cp rst trains a dbn by using the source project and generates semantic features for both the two projects.
then dbn cp trains an adtree based defect prediction model using data from the source project and then use the built model to perform defect prediction on the target project.
we choose tca as our baseline.
to compare with tca we randomly pick or versions from each project in total we have target projects and for each target project we randomly select source projects that are di erent from the target projects.
thus test pairs are collected.
the reason why we compare with tca is that tca is the state of the art technique that reports the best performance in cross project defect prediction.
since tca is not publicly available we have reimplemented our own version of it.
in our reproduction we follow the processes described in we rst implement all their proposed ve normalization methods and assign them with the same conditions as given in tca paper.
we then perform transfer component analysis on source projects and target projects together and map them onto the same subspace while minimizing data di erence and maximizing data variance.
finally we use the source projects and target projects with the new features to build and evaluate adtree based prediction models.
.
results this section presents our experimental results.
we focus on the performance of our proposed semantic features and answer the following research questions rq rq1 do semantic features outperform traditional features for within project defect prediction?
to answer this question we use di erent features to build within project defect prediction models to compare the impact of three sets of features semantic features that are automatically learned by dbn promise features and ast features.
the latter two are the two baselines of traditional features.
we conduct sets of within project defect prediction experiments each of which uses two versions of thetable comparison between semantic features and two baselines of traditional features promise features and ast features using adtree.
tr denotes the training set version and t denotes the test set version.
p r and f1 denote precision recall and f1 score respectively and are measured in percentage.
the best f1 scores are highlighted in bold.
pro jectv ersions s emantic pr omise a st tr t p r f1 p r f1 p r f1 a nt1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
c amel1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
jed it3 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
lo g4j .
.
.
.
.
.
.
.
.
.
.
lu cene2 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
xa lan .
.
.
.
.
.
.
.
.
.
.
xe rces .
.
.
.
.
.
.
.
.
.
.
iv y .
.
.
.
.
.
.
.
.
.
.
sy napse1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
p oi1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
a verage .
.
.
.
.
.
.
.
.
same project listed in table .
the older version is used to train prediction models and the newer version is used as the test set to evaluate the trained models.
table shows the precision recall and f1 of the withinproject defect prediction experiments.
the highest f1 of the three sets of features are shown in bold.
for example by using ant .
as the training set and ant .
as the test set the f1 of using semantic features is .
while the f1 is only .
with the rst baseline of traditional features from promise and the f1 is .
with the second baseline of traditional features based on ast nodes .
for this comparison the only di erence is the three sets of features meaning that the same classi cation algorithm namely adtree the same parameters and the same training and test sets are used.
on average semantic features achieve a f1 of .
while the promise features achieve a f1 of .
and the ast features achieve a f1 of .
.
the results demonstrate that by using the semantic features automatically learned by dbn instead of the promise features we can improve the defect prediction f1 by .
on average on data sets.
the average improvement in the precision and recall is .
and .
respectively.
since the dbn algorithm has randomness the generated features vary between di erent runs.
therefore we run our dbn based feature generation approach ve times for each experiment.
among the runs the di erence in the generated features is at the level of .
e which is too small to propagate to precision recall and f1.
in other words the precision recall and f1 of all ve runs are identical.
the proposed dbn based approach is e ective in automatically learning semantic features which improves the performance of within project defect prediction.
rq1a do semantic features outperform traditional features with other classi cation algorithms?
we use semantic features and promise features separately to build defect prediction models by using two alternative 303table comparison of f1 scores between semantic features and promise features using naive bayes and logistic regression.
tr denotes the training set version and t denotes the test set version.
f1 scores are measured in percentage.
the best f1 scores are highlighted in bold.
pro jectv ersion n aive bayes lo gistic regression tr t s emantic pr omise s emantic pr omise a nt1 .
.
.
.
.
.
.
.
.
.
.
.
c amel1 .
.
.
.
.
.
.
.
.
.
.
.
jed it3 .
.
.
.
.
.
.
.
.
.
.
.
l og4j .
.
.
.
.
.
l ucene2 .
.
.
.
.
.
.
.
.
.
.
.
xa lan .
.
.
.
.
.
xe rces .
.
.
.
.
.
i vy .
.
.
.
.
.
sy napse1 .
.
.
.
.
.
.
.
.
.
.
.
p oi1 .
.
.
.
.
.
.
.
.
.
.
.
a verage .
.
.
.
classi cation algorithms naive bayes and logistic regression.
we conduct sets of within project defect prediction where the training sets and the test sets are exactly same as those in rq1.
table shows the f1 scores of running naive bayes and logistic regression on semantic features and promise features.
we compare the performance of semantic features and promise features under di erent classi cation algorithms.
the better f1 scores are in bold.
take antas an example when the model is built on naive bayes by choosing version .5as the training set and .6as the test set semantic features produce a f1 of .
which is .
higher than using promise features.
for the same example with logistic regression as the classi cation algorithm semantic features achieve a f1 of .
while using promise features produces a f1 of .
only.
among the experiments with either naive bayes or logistic regression as the classi cation algorithm semantic features outperform promise features in out of the times.
on average naive bayes based defect prediction model with semantic features achieves a f1 of .
which is a .
improvement over naive bayes with promise features.
similarly the average f1 of using semantic features with logistic regression is .
which is a .
improvement over logistic regression with promise features.
the semantic features automatically learned from dbn improve within project defect prediction and the improvement is not tied to a particular classi cation algorithm.
rq2 do semantic features outperform traditional features for cross project defect prediction?
in order to answer this question we compare our proposed cross project defect prediction technique dbn cp with tca .
dbn cp runs on the semantic features that are automatically generated by dbn while tca uses promise features.
for a fair comparison we also provide a benchmark of within project defect prediction.
we conduct sets of cross project defect prediction experiments.
each experiment takes two versions separately fromtable f1 scores of cross project defect prediction.
f1 scores are measured in percentage.
the best f1 scores between dbn cp and tca are highlighted in bold.
s ource t argetcro ss project wi thin project dbn cp tc a s emantic features a nt1.
c amel1.
.
.
.5jed it4.
c amel1.
.
.
c amel1.
a nt1.
.
.
.4p oi3.
a nt1.
.
.
c amel1.
jed it4.
.
.
.5lo g4j1.
jed it4.
.
.
jed it4.
l og4j1.
.
.
.1lu cene2.
l og4j1.
.
.
lu cene2.
xa lan2.
.
.
.5xe rces1.
xa lan2.
.
.
xa lan2.
l ucene2.
.
.
.1lo g4j1.
l ucene2.
.
.
xa lan2.
xe rces1.
.
.
.1iv y2.
xe rces1.
.
.
xe rces1.
i vy2.
.
.
.0sy napse1.
i vy2.
.
.
iv y1.
sy napse1.
.
.
.4p oi2.
sy napse1.
.
.
iv y2.
sy napse1.
.
.
.3p oi3.
sy napse1.
.
.
sy napse1.
p oi3.
.
.
.3a nt1.
p oi3.
.
.
a verage .
.
.
two di erent projects while one is as the training set and the other one is as the test set.
di erent from dbn cp and tca the benchmark of within project defect prediction uses the data from an older version of the target project as the training set.
table contains the f1 scores of dbn cp tca and the benchmark within project defect prediction.
the better f1 scores between dbn cp and tca are in bold.
take an example of the experiment where the source project training set is from camel .
and the target project test set is from ant .
.
running dbn cp with camel .
as the training set and ant .
as the test set produces a f1 of .
while running tca on the same sets produces a f1 of .
.
the within project defect prediction for this experiment uses semantic features with ant .
as the training set and ant .
as the test set which are the same sets with the experiment that uses ant .
as the test set in table .
in this experiment running dbn cp achieves a f1 score of .
which is even higher than the f1 score of within project defect prediction with a value of .
.
from the point of average f1 dbn cp achieves .
which is .
higher than the .
of tca .
compared with within project defect prediction dbn cp makes progress for cross project defect prediction by reducing the gap to only .
.
ou r proposed dbn cp improves the performance of cross project defect prediction.
the semantic features learned by dbn are e ective and able to capture the common characteristics of defects across projects.
r q3 what is the time and space cost of the proposed dbn based feature generation process?
while we conduct the sets of within project defect prediction experiments for rq1 we keep track of the time cost and memory space cost for our proposed dbn based feature generation process refer to section .
in which dbn 304table time and space cost of generating semantic features s second projectgenerating features time s memory mb ant .
.
camel .
.
jedit .
.
log4j .
.
lucene .
.
xalan .
.
xerces .
.
ivy .
.
synapse .
.
poi .
.
generates semantic features automatically by using noisehandled data.
for the other processes including parsing source code handling noise mapping tokens building models and predicting defects they are all common procedures so we do not analyze their costs.
table shows the time cost and the memory space cost for generating semantic features.
give an example of ant table shows that anthas two sets of within project defect prediction experiments which are ant .
.
and ant .
.
.
on average it takes the two experiments .
seconds and .8mb memory for dbn to generate semantic features for both the training data and the test data.
among all the projects the time cost of automatically generating semantic features varies from .
seconds ivy to .
seconds camel .
as for the memory space cost it takes less than .5mb for all the examined projects.
u sing our proposed dbn based approach to automatically learn semantic features is applicable in practice.
.
threats to validity implementation of tca .
for the comparative analysis we compare our proposed cpdp approach with tca which is the state of theart cpdp technique.
since the original implementation is not released we have reimplemented our own version of tca .
although we strictly followed the procedures described in their work our new implementation may not reect all the implementation details of the original tca .
we test our implementation using data provided by their work since our implementation could generate the same results we are con dent that our implementation re ects the original tca .
in this work we did not evaluate our dbn based feature generation approach on projects used for evaluating tca .
there are two reasons.
first our dbn based feature generation approach to within project defect prediction works on data of two di erent versions from the same project while datasets used in only provided one version of defect data for each of their eight projects which are unsuitable for evaluating our approach to within project defect prediction.
second some of their examined projects are c c projects.
the current implementation of our dbn based feature generation approach focuses on java projects and all of the ten evaluated projects in this workare java projects.
despite the threats our comparison should be fair since we apply tca and our approach on the same projects which are publicly available data from promise and are biased toward neither tca nor our approach.
project selection.
the examined projects in this work have a large variance in average buggy rates.
we have tried our best to make our dataset general and representative.
however it is still possible that these ten projects are not generalizable enough to represent all software projects.
given projects that are not included in the ten projects our proposed approach might generate better or worse results.
our proposed semantic features generation approach is only evaluated on open source java projects.
its performance on closed source software and projects written in other languages is unknown.
.
related work .
software defect prediction there are many software defect prediction techniques .
most defect prediction techniques leverage features that are manually extracted from labeled historical defect data to train machine learning based classi ers .
commonly used features can be divided into static code features and process features .
code features include halstead features mccabe features ck features and mood features which are widely examined and used for defect prediction.
recently process features have been proposed and used for defect prediction.
moser et al.
used the number of revisions authors past xes and ages of les as features to predict defects.
nagappan et al.
proposed code churn features and shown that these features were e ective for defect prediction.
hassan et al.
used entropy of change features to predict defects.
lee et al.
proposed micro interaction metrics to improve defect prediction.
other process features including developer individual characteristics and collaboration between developers were also useful for defect prediction.
based on these features many machine learning models are built for two di erent defect prediction tasks withinproject defect prediction and cross project defect prediction.
.
.
within project defect prediction within project defect prediction wpdp uses training data and test data that are from the same project.
many machine learning algorithms have been adopted for wpdp including support vector machine svm bayesian belief network naive bayes nb decision tree dt and dictionary learning .
elish et al.
evaluated the capability of svm in predicting defect prone software modules and they compared svm against eight statistical and machine learning models on four nasa datasets.
amasaki et al.
proposed an approach to predict the nal quality of a software product by using the bayesian belief network.
tao et al.
proposed a naive bayes based defect prediction model they evaluated the proposed approach on datasets from the promise defect data repository.
wang et al.
and khoshgoftaar et al.
examined the performance of tree based machine learning 305algorithms on defect prediction their results suggested that tree based algorithms could help defect prediction.
jing et al.
introduced the dictionary learning technique to defect prediction.
they proposed a cost sensitive dictionary learning based approach to improve defect prediction.
.
.
cross project defect prediction due to the lack of data it is often di cult to build accurate models for new projects.
to address this issue crossproject defect prediction cpdp models are trained by using data from other projects.
watanabe et al.
proposed an approach for cpdp by transforming the target dataset to the source dataset by using the average feature values.
turhan et al.
proposed to use a nearest neighbor lter to improve cpdp.
nam et al.
proposed tca which adopted a state of the art technique called transfer component analysis tca and optimized tca s normalization process to improve cpdp.
they evaluated tca on eight open source projects results shown tca signi cantly improved cpdp.
nam et al.
and jing et al.
used di erent approaches to address the heterogeneous data problem in cross project defect prediction.
the main di erences between our approach and existing approaches for within project defect prediction and crossproject defect prediction are as follows.
first existing approaches to defect prediction are based on manually encoded traditional features which are not sensitive to programs semantic information while our approach automatically learns semantic features using dbn and uses these features to perform defect prediction tasks.
second since our approach requires only the source code of the training and test projects it is suitable for both within project defect prediction and cross project defect prediction.
.
deep learning and semantic feature generation in software engineering recently deep learning algorithms have been adopted to improve research tasks in software engineering.
yang et al.
proposed an approach that leveraged deep learning to generate features from existing features and then used these new features to predict whether a commit is buggy or not.
this work was motivated by the weaknesses of logistic regression lr that lr can not combine features to generate new features.
they used dbn to generate features from traditional change level features the number of modi ed subsystems modi ed directories modi ed les code added code deleted line of code before after the change les before after the change and several developer experience related features .
our work di ers from the above study mainly in three aspects.
first we use dbn to learn semantic features directly from source code while features generated from their approach are relations among existing features.
since the existing features used cannot distinguish many semantic code di erences the combination of these features would still fail to distinguish the semantic di erences.
for example if two changes add the same line at di erent locations in the same le the traditional features used cannot distinguish the two changes.
thus the generated new features which are combinations of the traditional features would also fail to distinguish the two changes.
second we evaluate the e ectiveness of our generated features using di erent classi ers and for both within project and cross project defect prediction while they use lr only for within project defect prediction.
third we focus on le level defect prediction while they work on change level defect prediction.
other studies leverage deep learning to address other problems in software engineering.
lam et al.
combined deep learning algorithms and information retrieval techniques to improve fault localization.
raychev et al.
reduced the code completion problem to a natural language processing problem and used deep learning to predict the probabilities of next tokens.
white et al.
leveraged deep learning to model program languages for code suggestion.
similarly mou et al.
used deep learning to model programs and showed that deep learning can capture programs structural information.
in addition deep learning has also been used for malware classi cation acoustic recognition etc.
many studies used topic model to extract semantic features for di erent tasks in software engineering .
nguyen et al.
leveraged topic model to generate features from source code for within project defect prediction.
however their topic model handled each source le as one unordered token sequence.
thus its generated features cannot capture structural information in a source le.
chen et al.
used topic model to generate features for source les to help explain their defect proneness.
liu et al.
proposed to use topic model to generate features from comments and identi ers in source code.
then they further used these features to model class cohesion.
in this work we leverage dbn to automatically learn semantic features from token vectors extracted from programs asts for both wpdp and cpdp.
.
conclusions and future work this paper proposes to leverage a representation learning algorithm deep learning to learn semantic representation directly from source code for defect prediction.
speci cally we deploy deep belief network to learn semantic features from token vectors extracted from programs asts automatically and leverage the learned semantic features to build machine learning models for predicting defects.
our evaluation on ten open source projects shows that the automatically learned semantic features could signi cantly improve both within project and cross project defect prediction compared to traditional features.
our semantic features improve the within project defect prediction on average by .
in precision .
in recall and .
in f1 comparing with traditional features.
for cross project defect prediction our semantic features based approach improves the state of the art technique tca built on traditional features by .
in f1.
in the future we would like to extend our automatically semantic feature generation approach to c c projects for defect prediction.
in addition it would be promising to leverage our approach to automatically generate features for predicting defects at other levels such as change level module level and package level.