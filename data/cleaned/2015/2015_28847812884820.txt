inteq recognizing benign integer overflows via equivalence checking across multiple precisions hao sun xiangyu zhang yunhui zheng and qingkai zeng state key laboratory for novel software technology nanjing university nanjing china department of computer science and technology nanjing university nanjing china department of computer science purdue university west lafayette usa ibm t.j. watson research center yorktown heights usa shqking gmail.com xyzhang purdue.edu zhengyu us.ibm.com zqk nju.edu.cn abstract integer over ow io vulnerabilities can be exploited by attackers to compromise computer systems.
in the mean time ios can be used intentionally by programmers for benign purposes such as hashing and random number generation.
hence di erentiating exploitable and harmful ios from intentional and benign ones is an important challenge.
it allows reducing the number of false positives produced by io vulnerability detection techniques helping developers or security analysts to focus on xing critical ios without inspecting the numerous false alarms.
the di culty of recognizing benign ios mainly lies in inferring the intent of programmers from source code.
in this paper we present a novel technique to recognize benign ios via equivalence checking across multiple precisions .
we determine if an io is benign by comparing the e ects of an over owed integer arithmetic operation in the actual world with limited precision and the same operation in the ideal world with su cient precision to evade the io .
speci cally we rst extract the data ow path from the over owed integer arithmetic operation to a securityrelated program point i.e.
sink and then create a new version of the path using more precise types with su cient bits to represent integers so that the io can be avoided.
using theorem proving we check whether these two versions are equivalent that is if they yield the same values at the sink under all possible inputs.
if so the io is benign.
we implement a prototype named inteq based on the gcc compiler and the z3 solver and evaluate it using harmful io vulnerabilities from real world programs and benign ios from specint specint and real world applications.
the experimental results show that inteq does not misclassify any harmful io bugs no false negatives and recognizes out of about .
benign ios whereas the state of the art can only recognize benign ios.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c 2016 acm.
isbn .
.
.
.
concepts security and privacy software security engineering keywords integer over ow benign equivalence checking precision .
introduction in c c programming languages integer arithmetic operations such as addition subtraction multiplication and left shift operations might cause the results to go beyond the limited range that the integer type can represent causing integer over ow io .
as the direct consequence of an io is just to produce an erroneous value the erroneous value has to be further used in some security related program points orsinks to perform various attacks on the subject programs such as code injection and denial of service dos attacks .
following the notions in rich and soupint such security related program points include memory related routines e.g.
malloc memcpy ifstatement while statement and array indexing statement.
for instance listing shows a typical io bug in cups .
when a malicious image le with large width and height is provided e.g.
img xsize as and img ysize as x40000004 an io occurs at line with bufsize over owed to x10 not the expected 0x .
the miscomputed bufsize is nally used at the memory allocation site at line leading to less space allocated than expected.
as a result bu er over ow would occur if out ofbound reads or writes are performed later.
a study in about the common vulnerabilities and exposures cve reports suggests that handling integer over ows is the number for os vendor advisories whereas bu er over ows rank number one.
integer over ows are listed among the most dangerous software bugs according to a study in .
due to its importance researchers have developed various techniques to address this problem.
for instance rich ioc air ra intpatch and inttracker instrument integer arithmetic operations to monitor over ows at runtime smartfuzz intscope and kint leverage symbolic execution to generate test cases which can trigger over ows safeint cert s integerlib and ranged integer use safe library functions to wrap integer arithmetic operations.
despite the signi cant advances in detecting and protecting against ios how to distinguish exploitable and harmful ieee acm 38th ieee international conference on software engineering read a png image f i l e .
2int cupsimagereadpng cups image t img file fp .
.
.
png uint width height png structp pp p n g i n i t i o pp fp get the image dimensions png getihdr pp info width height .
.
.
9img x s i z e width img y s i z e height s i z e t bufsize s i z e b u f s i z e img x s i z e img y s i z e s i z e b u f s i z e in malloc s i z e .
.
.
listing a harmful io in cups cve .
ios from the benign ones still remains an open problem.
in practice programmers might leverage ios intentionally to implement speci c functionalities such as hash value computation and random number generation or to achieve conciseness in coding .
as shown in listing .gcc in specint utilizes a signed io at line to compute a hash value.
this over ow is benign because the bit and operation at line and the modulo operation at line ensure that the over owed value i.e.
hi has a constant and legitimate range before owing into the array indexing statement at line .
as we will show in section the majority of ios are benign in practice.
unfortunately most existing io detection tools cannot distinguish them from harmful ios.
the main di culty of recognizing benign ios is to infer the intent of programmers from source code.
intflow leverages information ow tracking to identify benign overows if both the operands originate from trusted sources.
the main intuition behind this technique is that the ios in uenced only by benign inputs are considered less likely to be used in exploitation attempts.
instead they are likely developer intended and benign.
however in practice there also exist a large number of benign ios whose operands come from external inputs.
take the benign io in listing as an example.
array text is actually from user inputs.
unfortunately intflow still undesirably treats such ios as harmful.
in this paper we present a novel technique to recognize benign ios via equivalence checking across multiple precisions .
as we show in section .
our technique is based on two core insights.
first the root cause of ios is the limited number of bits used to represent an integer.
if we supply su cient bits the data can be represented more accurately so that the integer operation no longer over ows.
second one key prerequisite for an io to become harmful is being used at a sink site.
this provides an interface for an adversary to conduct malicious operations.
based on the two observations our idea is as follows.
given a path from an over owed integer arithmetic operation to a sink we create a new version of the path with more precise types that have su cient bits to represent integer values.
as such the over ow no longer occurs in the new version.
if both the low precision version with the io and the high precision version without the io produce the same value at the sink the io in the low precision version is benign as it has no di erent e ect compared to the ideal case.
otherwise the io is considered harmful.
the essence of inteq is to use1 define hashbits define max hash table return an identifier node whose name i s text 5t r e e g e t i d e n t i f i e r char text int hi i .
.
.
compute hash code hi hash len unsigned text for i i hash len i hi hi unsigned text hi hashbits hi max hash table search t a b l e for i d e n t i f i e r for idp hash table idp idp .
.
.
.
.
.
listing a benign io for hashing in .gcc.
the high precision version to model the behavior intended by the programmer such that the equivalence between the two versions determines if the io is benign.
our contributions are highlighted as follows.
we propose the novel idea of determining if an io is benign by checking equivalence between two versions of code which have di erent levels of representation precision.
we propose and implement a static integer over ow classi er inteq based on the gcc compiler and the z3 solver aiming to improve the accuracy of integer over ow detection.
given an io report generated by a third party tool our tool rst leverages a static data ow analysis to extract the data ow path from the over owed integer arithmetic operation to a sink and then creates a new version of the path with higher representation precision using types with su cient bits.
at last inteq leverages a constraint solver z3 to reason about the equivalence of the two versions with all possible inputs.
if equivalent we report this io as benign.
we apply inteq to harmful cve io vulnerabilities from real world programs and benign ios from specint specint and real world applications.
the experimental results show that inteq correctly recognizes all the cve ios as harmful and hence no false negatives .
more importantly it correctly identi es out of the total benign ios i.e.
.
whereas the state of theart can only recognize of them.
outline.
the rest of this paper is organized as follows.
section presents an overview of our approach.
section describes the design and implementation in detail.
section evaluates our tool.
related work and conclusion are discussed in section and section respectively.
.
overview in this section we discuss the characteristics of benign ios including their typical use cases and the importance and di culty of recognizing them.
we also present an overview of our approach which is mainly motivated by two core insights.
.
characteristics of ios and existing solutions io vulnerabilities are quite di erent from other types of software vulnerabilities e.g.
bu er over ow null pointer dereference and sql injection vulnerabilities .
while bu er over ows and null pointer dereferences are always harmful ios are benign in many cases.
benign ios are often used intentionally by programmers to implement speci c functionalities or even just to achieve conciseness in coding .
such speci c functionalities mainly include hash value computation as shown in listing random number generation coding and decoding.
most existing techniques such as rich ioc air ra and cannot distinguish benign ios from the harmful ones producing a large number of false positives and substantially degrading the usability of those tools.
according to our manual analysis on the io reports by ioc on specint and benchmarks together with real world applications only of them .
are harmful.
this implies the developers and security analysts have to manually lter out the numerous benign ios before they can x the harmful ones.
hence distinguishing benign ios from the critical ones is an open challenge of great importance.
the key di culty of recognizing benign ios lies in inferring the intent of programmers from source code.
given a program it is hard to automatically reason about the programmer s intent without any hints annotations from the programmer.
take the code snippets in listing and listing as an example.
in these two code snippets the usages of the two integer multiplications i.e.
line in listing and line in listing are quite similar both originating from external inputs going through several operations and nally propagating to the sink point i.e.
malloc at line in listing and the array indexing statement at line in listing .
as such we can hardly tell the developer intended and hence benign io from the harmful one.
inferring the intent of programmers in io detection is known as a hard challenge.
in the following we present some related quotes from other researchers in the area.
like all over ows the c source code contains no indication from programmer that this over ow is intentional.
rich programmers may intentionally use unsafe integer behavior.
it is impossible for an automated tool to unambiguously understand the intent of a programmer.
the intention of a developer however cannot be formally de ned or automatically derived as the code patterns used in a piece of code are deeply related to the author s knowledge preference and programming style.
intflow instead of inferring the intent of programmers intflow proposes to determine if an io is benign by checking where the operands originate from.
the intuition is that the ios with their operands from trusted sources cannot be controlled or exploited by adversaries.
therefore such ios are considered benign.
unfortunately many ios from untrusted sources are also benign.
.
our approach we propose to determine whether an io is benign from the view of its e ect on sinks.
our approach is motivated by two core insights.
first the root cause of ios is the limited number of bits used to represent integers in c c languages.
this might cause the results of integer arithmetic operations to go beyond the limited range.
hence if we use su cient bits to represent integers the arithmetic operations will not over ow any more.
take listing as an example.
an io occurs at line if we set img xsize as and img ysize as 0x respectively.
the over owed variable bufsize holds the value of 0x which is erroneous.
if we use bits i.e.
unsigned long long type to represent the integers the multiplication at line does not over ow and the variable bufsize has the ideal and expected value 0x .
second one key prerequisite for an io to become harmful is that the over owed value may be eventually propagated to some critical places or sinks such as the size argument of a memory allocation function .
this is mainly because ios cannot directly over write memory and thus adversaries have to manipulate sinks through the over owed values to conduct malicious attacks.
speci cally adversaries might exploit over owed data at memory related routines to cause bu er over ows e.g.
the case in listing or dos if statement to bypass security checks while statement to trigger in nite loops and array indexing statement to induce out of bound reads writes .
therefore we consider an io benign if the over owed data has no harmful e ect on sinks.
to evaluate the e ect of an io on sinks we present a novel technique based on equivalence checking across multiple precisions .
speci cally we rst utilize static data ow analysis to extract all possible data ow paths from the over owed integer arithmetic operation to all sinks.
for each path we then create a new version where integers are represented by higher precision types with su cient bits such that the integer operations no longer over ow.
finally we verify whether these two versions with di erent precisions are semantically equivalent using theorem proving.
equivalence refers to that the two versions always yield the same value s at the sinks for all possible inputs.
if for all paths of the over owed integer arithmetic operation the two versions with di erent precision levels are always semantically equivalent this io is benign.
consider the example in listing .
given the aforementioned over ow inducing inputs the two precisions yield di erent values at the sink point line .
the io is hence harmful.
in contrast for the example in listing although variable hihas di erent values with the two precisions the lower bits of the two values are always the same due to the characteristics of the arithmetic operations.
as such after the bit and operation at line and the modulo operation at line the two values always become identical.
the io is hence benign.
it implies that the programmer had considered possible ios when writing the program and they have put in sanitization operations to suppress the undesirable consequences of ios.
.
design and implementation the architecture of inteq is shown in figure .
the inputs are the source code of the subject c c program 1053c c source codefront end path extractionpath encodingtheorem prover io bug reportsat unsat benignoriginal precisionhigh precision harmfulfigure arichtecture of inteq.
and a set of io vulnerabilities reported by a third party tool.
the tool can be dynamic or static analysis based.
in this paper we use ioc which is a state of the art dynamic analysis based io detection tool.
the front end converts the subject program to its static single assignment ssa form and builds control ow graphs and call graphs.
for each io report the path extraction component extracts all the data ow paths from the over owed integer operation to some sink.
the sinks are a set of statements of prede ned and con gurable types.
the path encoding component generates two versions of symbolic encoding of the path one with the original precision and the other with high precision i.e.
using more bits to represent integers .
the encodings are bit vector based.
finally the equivalence of the two versions is determined by a theorem prover.
if for all paths of an over owed integer operation the two versions are always equivalent i.e.
unsat when we assert one version is not equal to the other we consider the over ow benign otherwise harmful.
.
path extraction given an io bug report all the paths from the over owed integer arithmetic operation to the potential sinks are rst extracted.
this process works on the intermediate representation provided by the front end.
the key idea of our path extraction is traversing the control ow graph to obtain the relevant statements which the over owed integer operation may a ect with the help of def use chains provided by ssa.
in ssa a unique variable name is assigned to each de nition and phi operators are used at join points to multiplex the di erent values along di erent branches.
using def use chains the uses of the value de ned by an integer operation can be easily located.
our analysis starts from the over owed integer operation and traverses along the def use edges originating from the operation in a depth rst fashion until some sink is reached.
it is context sensitive path sensitive and inter procedural based on function summaries .
next we focus on discussing how we handle loops and pointers.
the other pieces such as handling function summaries are standard and hence elided.
handling pointers .
handling pointers is a prominent challenge for static analysis.
the problem lies in that a de nition and the corresponding use may de reference di erent pointer variables that are aliases.
for instance given a de nition de referencing pand a use de referencing q it is challenging in general to determine if the use gets its value from the de nition which requires alias analysis.
although there are many advanced points to analysis that can determine the set of memory locations that a pointer may point to due to the inherent limitations of static analysis they usually produce over approximated results.
in our scenario they may report a large number of bogus defuse relations that fail our equivalence check.in inteq we treat a write through a pointer dereference as a sink.
in other words if there is a write through a pointer dereference along the extracted path we aim to establish the equivalent relationship on the value that is being written across the two versions .
the intuition is that the path we acquire is essentially a sub path of the true data ow path that ends at a real sink.
if we can prove equivalence for the sub path the io must make no di erence to the remaining computation in the true path including the sink and is hence benign.
we call it the path reduction theorem whose formal de nition is as follows.
theorem path reduction .
given a data ow path p nint n1 n2 ni nsink where nintis an overowed integer arithmetic operation niis in the form of var op x1 x2 and nsink is a real sink and a sub path p nint n1 n2 ni which is a pre x of p if the two versions of p with low and high precisions are equivalent regarding var then this over owed integer arithmetic operation n int has no harmful e ect on the sink nsink i.e.
this over ow is benign for path p. proving the theorem is straightforward.
because if the pre x computes the same varvalue at niwith two precisions the continuation of the pre x is using the same value to conduct its computation such that the over owed data has no further harmful e ect on the continuation including the sink.
however it is possible that inteq cannot prove equivalence for the sub path whereas the equivalence for the full path can be proved assuming an ideal points to analysis.
in other words inteq may misclassify a benign io as harmful.
fortunately we observe in practice the over owed value does not propagate far before it gets sanitized.
in other words it usually gets sanitized before being written through a pointer dereference.
moreover applying path reduction would not lead to misclassi cation of a harmful io as benign which is unacceptable.
example listing shows a code snippet from .gap that simulates multiplication of large numbers by multiplying the individual digits in the two large multiplicands.
at lines both land rare of bit unsigned short integer type so that the product may likely exceed the range of unsigned short causing an io.
the third party io detection tool ioc we use detects this io.
however this is a benign io.
in particular the compiler always extends multiplicands to integers of bits before carrying out the multiplication.
as such despite the over ow the 32bit product is correctly produced and stored in c which is further casted to a bit short through p c .
note that the carry on from the multiplication of the previous digits is also added.
for example the c at line adds the carry on generated at line .
for the over ow at line inteq extracts a number of paths all starting with the multiplication l r ending with the pointer based write p c at lines and 10541typedef unsigned short typdigit 3typhandle prodint typhandle hdl typhandle hdr register unsigned spec int32 t c register typdigit l r p register typhandle hdp .
.
.
l typdigit i i f l !
r typdigit ptr hdr p typdigit ptr hdp c multiply the r i g h t with t h i s d i g i t and store in the product for k size hdr sizeof typdigit k !
k c l r c p c c l r c p c c l r c p c c l r c p c p c .
.
.
listing benign ios for digit wise operations in .gap.
respectively.
one can easily tell that for all these paths the low and high precisions are equivalent due to the type cast at the sink.
handling loops .
equivalence checking involving loops is a hard problem in software veri cation.
it requires getting the right loop invariants which often entails substantial manual e orts.
we have tried the approach of unrolling the loop once and treating any de nition that has loopcarry dependencies as a sink.
intuitively if we can prove equivalence for one iteration the io does not have harmful e ect on the other iterations due to the path reduction theorem.
unfortunately we nd out the applicability of this method is limited in practice.
this is because the sanitization often occurs outside the loop.
listing shows a typical example.
observe that the sanitization is at line and outside the loop.
therefore we choose to follow a standard solution in bounded model checking unrolling the loop for a xed number of times.
in inteq we unroll once.
as a result the soundness of inteq is limited by the unroll bound.
more discussion can be found in section .
.
.
path encoding and equivalence checking given a data ow path from an over owed integer operation to a sink the next step is to encode the path into two versions of constraints with di erent precisions and then to correlate the two sets of constraints to check equivalence.
in inteq we leverage the bit vector logic to encode paths.
bit vectors can precisely model the semantics of unsigned and of signed two complement s arithmetics.
more importantly the logic supports bit vectors with arbitrary size.
hence we can easily extend the original version s precision by simply using longer bit vectors.
.
.
high precision estimation given a path with the original low precision our technique rst estimates the needed precision i.e.
the number of bits to represent an integer so that ios in the original low precision can be completely evaded along the path.
the basic idea is to over approximate the number of bits needed for each integer operation in the path in order to avoid ios.algorithm precision estimation.
input data ow path p original precision n output high precision m m n initialization foreach operation node in path pdo ifnode is mul then m n else if node is add or sub then m else if node is shl c a b then ifbis a constant then m val b else m n end if else continue end if end for note that the number of needed bits monotonically grows along the path as the result of an operation is further used in another operation.
however since our path is nite the number of bits needed is bounded.
at the end we use the inferred number of bits to denote integers such that ios are completely avoided.
algorithm shows the process of precision estimation.
it takes as input a data ow path pand the original low precision n which is the number of bits to represent an integer and produces the high precision m. initially the high precision mis initialized as the original precision line .
it is later updated according to the di erent types of arithmetic operations along path p lines to .
we consider mul add sub and shl operations because only these operations might over ow.
with the original precision n mul and shl might over ow by nbits at most and add and sub might over ow by onebit at most.
note that val b denotes the concrete value of this constant operand b. it is worth mentioning that the high precision mwill not be too large as the paths are usually not long as shown in section .
.
.
.
path encoding the next step is to encode the path to bit vector constraints in precisions nand mrespectively.
algorithm describes the process.
it takes as input a data ow path p the original precision nand the high precision m and produces a set of bit vector logic constraints denoted as cs.
lines to encode a statement on the path to constraint s .
at the end line adds the satis ability check.
lines encode an assignment with a binary operation.
lines declare the symbolic variables for the destination program variable c with corgandcextfor the original precision and high precision respectively.
lines declare symbolic variables for the source operands if they were not declared meaning that these operands are not de ned along the path.
lines encode the operation.
the encoding of other operations e.g.
unary operations follows a similar procedure and is hence elided.
if the statement is the sink the algorithm asserts the equivalence of the involved symbolic variables lines .
note that the symbolic variable with the lower precision needs to be extended to the high precision before checking equivalence.
we will explain precision extension later in the section.
variable declaration.
function declare var var size bufsize img xsize img ysize size bufsize in malloc size declare fun xsize org bitvec declare fun ysize org bitvec declare fun bufsize org bitvec assert bufsize org bvmul xsize org ysize org declare fun size org bitvec assert size org bvmul bufsize org x00000003 declare fun size org ext bitvec assert size org ext concat x000 size org assert not size org ext size ext check sat path original precision high precision declare fun xsize ext bitvec declare fun ysize ext bitvec assert xsize ext concat x000... xsize org assert ysize ext concat x000... ysize org declare fun bufsize ext bitvec assert bufsize ext bvmul xsize ext ysize ext declare fun size ext bitvec assert size ext bvmul bufsize ext x00... figure path and bit vector constraints for the harmful io in listing .
algorithm path encoding.
input data ow path p original precision n and high precision m output constraint set cs foreach statement node in path pdo ifnode is a binary operation c a op b then declare the destination operand declare var corg n declare var cext m declare the unde ned source operands ifais not a declared variable then declare var aorg n declare var aext m extend var aext a org m n end if ifbis not a declared variable then ... end if encode the operation into bit vector operation encode operation corg a org b org opcode encode operation cext a ext b ext opcode else if node is a unary operation c op a then ... else if node is the sink such as malloc c and if c then add assertion extend var corgext c org m n cext else ... end if end for add check sat into cs nally.
declares a bit vector symbolic variable with the name var and the length size.
we declare bit vectors for both the destination and source program variables.
declaration for a source variable is only needed when it is not de ned in the path by a preceding assignment statement.
in this case the declared bit vector is a free variable denoting an input to the path.
intuitively our tool reasons about equivalence for all possible values of these free variables.
precision extension.
to check equivalence we provide the same inputs to the two versions and then compare the values of the two versions at the sink.
in order to enforce the same inputs we assert that the high precisioninput be derived by extending the corresponding original low precision input.
precision extension is provided by function extend var ext org num .
the logic is shown as follows.
note that organd extdenote the inputs for the original and high precision versions respectively.
function zero extend num org conducts zero extension on bit vector org i.e.
extending orgwith num zero upper bits before org while function sign extend num org conducts sign extension on org i.e.
extending orgwith num upper bits that equal to the sign bit of org.
for an unsigned variable ext zero extend num org for a signed variable ext sign extend num org the same extension is conducted at the sink point before checking equivalence line .
note that comparing bitvectors of di erent lengths is meaningless and not allowed.
operation encoding.
most commonly used integer operations are directly supported in the bit vector logic for example bit wise operations are supported by bvand and bvxor etc.
simple arithmetic operations by bvadd bvmul bvsub etc.
comparative operations by bvult bvsgt etc.
and bit propagation operations by concat andextract etc.
hence the encoding for these operations is standard .
example the left column of figure shows the data ow path of the io in listing .
according to algorithm the high precision needed is m which is computed bym at line and m at line .
then we apply algorithm .
the encoded constraints are shown in the right column of figure .
an expression op x y in the constraint means x op y .
the constraints in bold are for precision extension.
as variables xsize and ysize are of unsigned type their extended versions i.e.
xsize ext andysize ext are represented by appending i.e.
m n zero bits to the beginning of xsize org and ysize org .
note that the multiplications are encoded with the corresponding bit vector operations i.e.
bvmul .
at last the theorem prover takes as input all these constraints and tries to produce an assignment of inputs which can satisfy the assertions.
for this case the result is sat which indicates that these constraints are satis able.
hence the over ow is harmful.
.
soundness the soundness of our technique means that a harmful io should not be misclassi ed as a benign io.
here we follow the de nition that a benign io has equivalent e ects on all reachable sinks in the actual world with limited precision and the ideal world with su cient precision .
it is important to guarantee soundness because any misclassi cations of harmful ios cause the vulnerabilities to be omitted by developers or security analysts.
like most bounded model checking techniques the soundness of our technique is limited by the loop unroll bound.
we say our technique is sound with regard to the loop unroll bound for the following reasons.
the process of path extraction is complete.
here complete means that for each over owed integer operation all potential paths are extracted.
to overcome the challenge caused by aliasing we treat pointer de