global optimization of numerical programs via prioritized stochastic algebraic transformations xie wang1huaijin wang1zhendong su2 3enyi tang1 xin chen1 weijun shen1zhenyu chen1linzhang wang1xianpei zhang1xuandong li1 1state key laboratory of novel software technology software institute of nanjing university nanjing china 2department of computer science swiss federal institute of technology eth z urich switzerland 3department of computer science university of california davis usa corresponding author eytang nju.edu.cn abstract numerical code is often applied in the safety critical but resource limited areas.
hence it is crucial for it to be correct and efficient both of which are difficult to ensure.
onone hand accumulated rounding errors in numerical programscan cause system failures.
on the other hand arbitrary infinite precision arithmetic although accurate is infeasible in practiceand especially in resource limited scenarios because it performsthousands of times slower than floating point arithmetic.
thus it has been a significant challenge to obtain high precision easyto maintain and efficient numerical code.
this paper introduces a novel global optimization framework to tackle this challenge.
using our framework a developer simply writes the infiniteprecision numerical program directly following the problem smathematical requirement specification.
the resulting code is cor rect and easy to maintain but inefficient.
our framework thenoptimizes the program in a global fashion i.e.
considering the whole program rather than individual expressions or statements as in prior work the key technical difficulty this work solves.
to this end it analyzes the program s numerical value flows across different statements through a symbolic trace extractionalgorithm and generates optimized traces via stochastic algebraictransformations guided by effective rule selection.
we first evalu ate our technique on numerical benchmarks from the literature results show that our global optimization achieves significantlyhigher worst case accuracy than the state of the art numericaloptimization tool.
second we show that our framework is alsoeffective on benchmarks having complicated program structures which are challenging for numerical optimization.
finally we apply our framework on real world code to successfully detectnumerical bugs that have been confirmed by developers.
i. i ntroduction numerical programs are often key components of safetycritical systems so it is crucial for them to get correct.
as many of such systems are restricted with limited resources such as a very limited energy budget for an on board satellite system it is also important for numerical programs to be efficient.
however both the correctness and the efficiency of numerical programs are difficult to ensure.
on one hand accumulated rounding errors in numerical programs can cause system failures.
on the other hand numerical software with arbitraryprecision arithmetic performs thousands of times slower than the traditional fixed precision floating point programs which makes it infeasible in the resource limited scenario.
hence experts need to elaborately design stable numerical programs to make sure of their correctness and efficiency.unfortunately the elaborately designed numerical programs are difficult to maintain.
numerical experts often introducecomplicated tricks in them.
for example a lot of numerical algorithms are not as intuitive as its original mathematical requirement specification because numerical experts use different ways of calculation to make sure that the representation and rounding errors are accumulated as less as possible.
furthermore experts also introduce precision specific operations that are difficult to understand by developers who do not familiar with numerical programming.
our goal is to address such maintenance problems.
in this paper we propose a global optimization framework shown in figure that transforms numerical programs directly following the mathematical requirement specification to theefficient fixed precision programs with numerically stablealgorithms.
using our framework a developer just needs to simply write a numerical program following the mathematical specification from the software requirements.
when the input program is easy to maintain we call it a direct numerical program written in infinite precision arithmetic.
then our framework changes the calculation of the direct program and generates an efficient equivalent program in fixed precision floating point arithmetic with stable numerical algorithms.
the framework decouples the knowledge of numerical calculation from the software development.
in other words developers do not need to focus on the details in numericalprogramming but just thinking in terms of the real number which makes their programs intuitive and easy to maintain.
our optimization framework considers its floating point approximation on computers by the optimization rules from numerical experts who focus on the numerical analysis techniques and make our framework incrementally powerful.
our optimization is global.
it not only rewrites individual expressions or statements but optimizes the unstable calculationflows of the whole program.
the global optimization frameworkbrings two major challenges different from a local numerical expression a numerical program often contains multiplebranches with complicated constraints.
a global numerical optimization needs not only to rewrite the numerical operations with high local error in a program but also reduce the cumulative floating point errors with constraints.
a global ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
global numerical optimization frameworkz3 z1 z2 z1 z2 mathematical speci fication from the software requirements icomplex midarc icomplex z1 icomplex z2 if abs z1 !
abs z2 !
throw preconditionexception real r real z1 real z2 real i imag z1 imag z2 icomplex sum r i icomplex z3 sum abs sum return z3 direct numerical program written in in finite precision arithmetic easy to maintain however may be unstable in finite precision arithmetic optimized numerical program in fixed precision floating point arithmetic with numerically stable algorithms software developers may not be familiar with numerical analysis just program directly following the mathematical requirement speci fication optimization rules wherez1 z2 z3 c z1 z2 1fcomplex midarc fcomplex z1 fcomplex z2 if abs z1 epsi abs z2 epsi throw preconditionexception double r real z1 real z2 double i imag z1 imag z2 fcomplex sum r i fcomplex z3 if abs sum epsi double theta1 arg real z1 imag z1 double theta2 arg real z2 imag z2 double theta3 theta1 theta2 if abs theta1 theta2 pi z3 fcomplex cos theta3 sin theta3 else z3 fcomplex cos theta3 sin theta3 else z3 sum abs sum return z3 fig.
illustration of the optimization framework for globally rewriting numerical programs numerical flow is often much longer than a local numerical expression.
that is more potential numerical rewrites consist in a global flow which leads to vaster search space than just rewriting local numerical expressions.
to overcome the first challenge we propose a symbolic trace extraction algorithm inspired by the symbolic execution technique .
the algorithm connects the numerical operations in different statements together and transforms the input numerical program to an intermediate representation ir that records the numerical traces with their corresponding path constraints.
to overcome the second challenge we present a stochastic algebraic transformation guided by an effective rule selection strategy.
the strategy characterizes the floating point domain knowledge as prioritized preconditions of transformation rules and prioritizes the transformation in consideration of both its precondition and success rate.
state of the art numerical verification and analysis are extensively studied topics .
most of these researches provide techniques that compute error bounds detect numerical instabilities or elaborately design stable numerical programs manually.
herbie is a state ofthe art transformation tool that rewrites a local expression to improve its accuracy.
but it can not handle a numerical program with path constraints and program structures.
to the best of our knowledge none of the previous work has considered a global optimization framework that automatically rewrites the whole program to a stable one.
the main contributions of this paper are as follows we propose a global optimization framework that transforms infinite precision numerical programs to the stable and efficient fixed precision implementations.
it is the first framework that automatically takes global numerical errors into consideration to our knowledge.
we carefully design the framework with a symbolic trace extraction algorithm a numerical intermediate representation ir and a stochastic algebraic transformation.
with these techniques our framework overcomes the major challenges in the global numerical optimization.
we first evaluate our optimization on groups of numerical benchmarks from the literature.
results show that our global optimization achieves significantly higher worstcase accuracy than the state of the art numerical optimization tool which is also effective on benchmarks having complicated program structures.
furthermore we apply our framework on real world projects of an open source graphics library and a driving tool for 3d printers and successfully detect numerical bugs that have been confirmed by developers.
ii.
f loa ting point background n umerical errors according to ieee each floating point number represents a numerical value in the form of s m 2e wheresis the sign bit zero or one mis the significand also called the mantissa eis the exponent.
the floating point standard also defines a variety of precisions double precision floats are defined with a bit significand and an bit exponent while single precision floats are are defined with a bit significand and an bit exponent.
when the floating point format bounds the number of bits in its representation the precision limitations are the root cause of the numerical errors .
our framework uses infinite precision arithmetic to evaluate the errors that are introduced by a fixed precision floating point program.
the infinite precision arithmetic expands the precision automatically on an arbitraryprecision floating point format such as gnu mpfr .
it increases the working precision until the observed bits of the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
significand such as the first bits of the computed answer for evaluating a double precision program does not change any more.
as the infinite precision arithmetic achieves a sufficiently large working precision we treat the output as the exact result in its observed bits of the significand.
metrics are necessary to evaluate the errors between the floating point outputs and the exact results.
the absolute and relative error functions are natural measures but they will suffer from ill suited cases in evaluating floating point values .
following a few recent practices i n floating point evaluation we also use the base logarithm of the number of floating point values between the exact result xand approximate result xas the error metric e which we call error in bits in this paper e x x l o g2 vextendsingle vextendsingle vextendsingle vextendsingle n n fp min x x n max x x vextendsingle vextendsingle vextendsingle vextendsingle error in bits erepresents uniformly the entire range of floatingpoint values including the inf andnan values.
intuitively it measures the number of most significant bits that xand x agree on.
note that the significand 0x00ff and0x0100 just have bit error not bits.
the metric eis still available if x and xhave a different sign bit or exponent bits.
so the range of error in bits for double precision values is and for single precision values.
iii.
m otiv a ting example in figure we have presented a midarc example from guo et al.
which calculates the midpoint z3of an arc z1 z2 in the complex plane.
asz1 z2 z3are complex numbers and z1 z2 the arc z1 z2 is a segment of the unit circle in the complex plane shown in figure .
z3is the midpoint of the arc z1 z2 and can be calculated according to the equation z2z1 z3 reim fig.
the argand diagram of our example that calculates the midpoint z3of the arc z1 z2 z3 z1 z2 z1 z2 following equation and the basic arithmetic rules of complex numbers software developers can implement the midarc program directly as the code snippet in figure .
the code in figure is intuitive and easy to maintain however it is not an efficient and stable numerical implementation.
first state of the art implementations of infinite precision arithmetic perform thousands times slower than fixed precision floating point programs.
so we need the efficient fixed precision implementation.
second a fixed precision floating point program can be unstable if it follows the direct algorithm in figure .
the instability occurs1icomplex midarc icomplex z1 icomplex z2 if abs z1 !
abs z2 !
throw preconditionexception real r real z1 real z2 real i imag z1 imag z2 icomplex sum r i sum z1 z2 icomplex z3 sum abs sum return z3 fig.
the direct numerical program for calculating the midpoint z3 in infinite precision arithmetic 1fcomplex midarc fcomplex z1 fcomplex z2 if abs z1 epsi abs z2 epsi throw preconditionexception double r real z1 real z2 double i imag z1 imag z2 fcomplex sum r i fcomplex z3 if abs sum epsi double theta1 arg real z1 imag z1 double theta2 arg real z2 imag z2 double theta3 theta1 theta2 if abs theta1 theta2 pi z3 fcomplex cos theta3 sin theta3 else z3 fcomplex cos theta3 sin theta3 else z3 sum abs sum return z3 fig.
the optimized fixed precision numerical program for calculating the midpoint z3 when z1 z2 where is a positive real value close to .
when z1 z2 is very small both the addition at line and line in figure cause serious massive cancellations if we calculate it in finite precision arithmetic.
the error is further enlarged by the division at line because the divisor is also very small which is equal to z1 z2 .
hence when we run the program with double precision floating point arithmetic on an apple macbook pro with intel core i7 .9ghz where the inputz1 ei z2 z1 e i and it outputs z3 .
.8321iwith about bits error in both the real part and the imaginary part.
it is obviously wrong since the correct z3 .
.7071i.
when every local expression in figure such as imag z1 imag z2 sum abs sum does not have a rewriting form to make the program numerically stable existing local optimization techniques are not effective in this problem.
our framework optimizes the code globally.
it extracts a numerical ir that connects the numerical calculation flows together with a symbolic trace extraction algorithm.
inspired by symbolic execution the symbolic trace extraction algorithm propagates symbolic states through every execution path and records constraints between numerical variables.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i transformation rules that match the path v ariable constraints in equation no.
rule a b squigglerightb a a b squigglerighta2 2ab b2 3r1 r2 squiggleright radicalbig r1 r2 i1 i2 2cos 1 arg m1 m2cos 2 1 m2sin 2 1 wherem1 radicalbig r2 i2 m2 radicalbig r2 i2 1 arg r1 i1 2 arg r2 i2 4if r2 i2 r2 i2 arg r1 i1 arg r2 i2 r1 r2 r1 r2 squiggleright radicalbig r1 r2 i1 i2 2cos arg r1 i1 arg r2 i2 5if r2 i2 r2 i2 arg r1 i1 arg r2 i2 r1 r2 r1 r2 squiggleright radicalbig r1 r2 i1 i2 2cos arg r1 i1 arg r2 i2 ... ... ... when the algorithm unfolds the subfunction such as abs the collected global trace is if radicalbig z1.re2 z1.im2 logicalanddisplay radicalbig z2.re2 z2.im2 z3.re z1.re z2.re radicalbig z1.re z2.re z1.im z2.im z3.im z1.im z2.im radicalbig z1.re z2.re z1.im z2.im where z1.re refers to the memory object returned by real z1 that stores the real component of the complex value z1 whereas z2.re z3.re z1.im z2.im andz3.im refer to the corresponding memory objects.
after comparing the outputs between the infinite precision program and the corresponding fixed precision program with a heuristic sampling strategy our framework locates the input regions that trigger the numerical instabilities.
the framework focuses the optimization on these unstable input regions and yields a new optimized branch with the path constraint derived from these regions in the output program.
in our example the path constraint of the new optimized branch isabs sum epsi where epsi is a small value close to .
the insight of our optimization is to find the numerically stable forms for the calculations under the unstable regions of the input program.
our framework substitutes these optimized forms in the new branch of the output program.
unfortunately if the framework cannot find them it will keep the infiniteprecision calculations in the new optimized branch to make sure the correctness of the output program.
meanwhile the output program is still efficient in other stable input regions since the calculations under these regions are transformed to the fixed precision floating point arithmetic directly.
our framework searches the numerically stable forms for optimization with a stochastic algebraic transformation which rewrites the global calculations in a rule based manner.
specifically it rewrites the global constraint in the numerical irwith a database of transformation rules from numerical experts.
as a global numerical constraint is often more complicated than a local expression our framework records the optimization success count for every rule in the database and applies it as a gauge of the probability for selecting the rule in future.
furthermore we refine the optimization rules with prioritized preconditions to further introduce the floating point domain knowledge in the transformation.
these transformation strategies significantly increase the chance of finding the effective stable forms in the large search space for the global numerical optimization.
table i depicts some of the rules that can be applied in our example.
we define sub procedures for complicate rules such as rule the polar form conversion rule for the realpart addition .
rule and rule are special cases of rule with preconditions.
some of the preconditions such as r2 i2 r2 i2 2guarantee the correctness of the rule.
so we call them the correctness preconditions .
other preconditions boxed in table i are prioritized preconditions that significantly increase the chance to apply the corresponding rule if any of them is satisfied.
the insight of a prioritized precondition is the prior knowledge numerical experts already know that a transformation should be effective under such condition.
this information is fundamental in the rule based transformation and effectively reduces the search space of rule selection in our framework.
when the constraints restrict the application of rule and rule they have a high success rate when applied in the optimization.
as the derived target path constraint in our example matches the prioritized preconditions in rule and rule our stochastic transformation applies them in equation .
with the same procedure of the imaginary part addition and a few post procedures such as simplification and code generation our framework optimizes the code to a stable fixed precision program shown in figure .
when we run it in double precision with the same input z1 ei z2 z1 e i and we get the correct output z3 .
.7071i.
iv .
g lobal numerical optimiza tion this section presents the technical details of our global numerical optimization framework.
figure depicts its main workflow consists of stages the symbolic trace extraction stage transforms the input program to the numerical ir that globally connects numerical operations in different statements together.
the instability analysis stage generates the unstable input regions that need to be optimized.
the stochastic algebraic transformation stage generates the optimized traces from the unstable traces in the numerical ir.
with a code generation stage the verified optimized traces are merged together and finally translated to the optimized program.
the rest of this section further describes the procedures in every stage separately.
a. numerical ir symbolic trace extraction our numerical ir provides a global view of the input numerical program.
it denotes every execution path with authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
direct numerical program symbolic trace extraction instability analysisnumerical ir unstable input regionsstochastic algebraic transformation verified optimized tracesoptimized numerical programcode generation verification of optimized tracesa b c d fig.
main workflow of the global numerical optimization framework numerical calculations in the input program by a numerical tracet so syntactically the numerical ir is a set of traces.
every trace consists of a path constraint t.c and a set of variable constraints t.v.
a variable constraint is in the form ofv e whereeis often a long expression that records all the numerical updates of the output numerical variable valong the corresponding execution path.
for example the numerical ir of figure should have two numerical traces when the code contains two execution paths.
but for one of the paths with the path constraint abs z1 !
abs z2 !
does not contain any numerical calculation our numerical ir just records the trace of the other path.
equation depicts the information in the trace with the path constraint z1.re2 z1.im2 logicalandtext z2.re2 z2.im2 and two variable constraints that updates z3.re andz3.im separately.
inspired by the symbolic execution technique we present a symbolic trace extraction algorithm to generate the numerical ir.
it replaces each input numerical value of the program with a symbol that initially represents anything denoted by latticetop .
then it executes the program step by step collects operations on the symbols and generates constraints for the numerical ir.
algorithm depicts the symbolic trace extraction technique.
at the entry of the program p our algorithm initializes an execution state esthat holds all the input symbols line .
for the code in figure z1.re z1.im z2.re and z2.im are initialized as symbols when the code accepts complex numbers.
for further propagating the execution state every stateesrecords fields ins sym out c where es.ins records the instruction that esis currently propagated in the input program es.sym refers to a map that collects the corresponding variable constraints of all the symbols at the current step such as z1.re latticetop z1.im latticetop ... when esis just initialized es.out records the output symbols such as z3.re z3.im and es.c holds the current path constraint such as abs z1 !
abs z2 !
when esis propagated to line of figure .
algorithm maintains a set of execution states es line and processes it with a loop lines .
in each iteration it propagates a step forward of a randomly selected execution statees line by processing its current instruction es.insalgorithm symbolic trace extraction input p input numerical program output ir syntactically a set of numerical traces es initialstate p ir es es es is a state set whilees negationslash do es selectrandom es esis the current state es.ins.forward switches.ins.type casev exp v fp an update of v e symsubstitute exp es.sym es.sym .update v e case fork such as the if statement es1 es2 forkexecution es es es es es1 es2 case output v v fp such as printf v es.out es.out v casep.exit new trace t es.c initialize a new trace for allv es.out do t.v t.v v es.sym v end for ir ir t es es es default same as default symbolic execution es.execinstruction es.ins end switch end while lines .
when the current instruction updates a numerical variable vwith an expression exp line it substitutes the variable constraint in es.sym for every symbol in the exp line and writes the substituted expression back to es.sym as a new variable constraint of v line .
this operation connects multiple numerical updates in different statements together.
for example when the algorithm propagates an execution state esto line of figure and unfolds the assignment of the complex number it encounters a real part update of z3.
in this case es.ins isz3.re sum.re abs sum.re sum.im .
wheneshas already been propagated through lines of figure es.sym sum .re i s z1.re z2.re andes.sym sum .im i sz1.im z2.im .
so the algorithm substitutes the variable constraints in es.sym for the expression in es.ins and further maps z3.re to z1.re z2.re abs z1.re z2.re z1.im z2.im .
after unfolding the subfunction abs the expression will further be transformed to the form in equation .
we fork the execution states line of algorithm to collect variable constraints in multiple execution paths because every state just holds the constraints for one path.
when es encounters a branch condition b or a fork instruction it generates new execution states es1andes2following both thetrue andfalse directions separately.
es1andes2are the same as esexcept their path constraints where es1.cis updated to es.c b andes2.cis updated to es.c b. authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
lines of algorithm collect the output variables and lines extract information from the execution state to build a trace in ir when the current execution state is propagated to an exit of the program.
by default the trace extraction algorithm executes the current instruction as the same way of symbolic execution which unfolds subprocedures in the program automatically lines .
b. instability analysis in heuristic it is not necessary to optimize the program at the inputs that already make the program stable in fixed precision arithmetic.
so our framework integrates an instability analysis to distinguish the unstable input regions from its input space.
meanwhile our framework also uses it to verify if an optimized transformation improves the accuracy of the program.
with a few trials on different instability analysis approaches we integrate a sampling based heuristic technique in our framework for the practicality.
because the framework keeps the infinite precision calculations at the unknown input regions our optimization is still sound even if the sampling based technique misses some unstable inputs.
our sampling based instability analysis starts from random samples uniformly from the floating point bit patterns.
it separately samples the sign bit exponent bits significand bits and then combines them together.
this sampling strategy generates very small values very large values and values of normal size with both positive and negative signs.
when some inputs are empirically easy to trigger instabilities in numerical software we also integrate an additional group of sample points with the following guided strategy let andi e e i i w e uniformly select sample points in the range of i i including i. these sample points will be further refined with the feedback of program evaluation which strongly improves the robustness of the instability analysis.
for every sample input we evaluate the accuracy by executing it in both the fixed precision and infinite precision arithmetic described in section ii and mark it as a stable input if the accuracy is acceptable.
otherwise it is marked as a unstable input.
then our framework tries to build input regions by refining the sampling process.
it resamples more points around the marked inputs to seek the boundary between the stable and unstable regions and derives the constraint of regions heuristically in a template matching way.
in this paper we represent the constraint of unstable input regions bycu the constraint of stable input regions by cs and other unknown input regions by cuk.
for example when our framework performs instability analysis on figure it obtains a series of unstable inputs that matches a linear template a x bx c wherea b c x1 z1.re x2 z2.re as well as x1 z1.im x2 z2.im .
our framework follows the template to generate cu z1.re z2.re z1.im z2.im which is equivalent to the path constraint of the new optimized branch in section iii.
if the inputs does not match any template thealgorithm main optimization procedure input irin input ir output iropt optimized ir iropt ts initialized as the stable input trace for every t irin logicalandtext t.c cu negationslash false do for every v e t.v do e e build an equivalent set do e selectrandom e angbracketlefte prime c prime rule angbracketright stochastictransform e t.c cu ifstablev erification e prime c prime then new trace t prime c prime v e prime optimized trace rule .succ increase the success count else e e e prime end if whilet prime nil !time out iropt iropt t prime update optimized traces irin irin t t.c c prime t.v end for end for algorithm stochastic algebraic transformation input e c output angbracketlefte prime c prime rule angbracketright r rule e0 subexp e e0.match rule.i logicalandtext rule.cp c negationslash false a rule candidate set for every r rdo ifr.pp c negationslash false then update the priority prior r r.succ pfactor else prior r r.succ end if end for rule prioritizedrandom r prior select the rule return angbracketleftsimplify rule .apply e rule.cp c rule angbracketright input regions i i1 i2 i prime i prime can also build a constraint by themselves such as i1 i i i prime i i prime .
the stable input regions create a optimized trace tsnatively wherets.ciscs ts.v is the original updates in the input program with the fixed precision arithmetic.
c. stochastic algebraic transformation our framework transforms the global variable constraints in the numerical ir with a rule based manner.
a rule in our framework is specified as a tuple cp pp i o succ wherecprepresents a correctness precondition pprepresents a prioritized precondition idenotes its input pattern odenotes its output pattern and succ is the success count of finding stable optimizations when applying the current rule which is initialized by .
if a subexpression e0of the global constraint expression ematches the input pattern of a rule rule.i line of algorithm our framework applies the rule on e line of algorithm by substituting the corresponding output pattern rule.o fore0in the constraint expression.
for example the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
rulea b squigglerightb aperforms commutative law of addition whenaandbmatches any subexpressions.
some complicated transformations are only valid under conditions which is defined by the correctness preconditions.
for example rule in table i is only valid when r2 i2 r2 i2 2istrue .
so we disjunct it rule.cp with the input path condition c line of algorithm to generate the optimized path constraint when applying the corresponding rule.
the insight of a prioritized precondition ppin a rule is a floating point domain knowledge that the rule should be especially effective under such condition.
for example a b c squigglerighta b c is always correct in real arithmetic but it will improve the accuracy of floating point arithmetic only when a b a c .
hence we put it as a prioritized precondition of the rule and significantly increase the chance of choosing the rule by multiply its priority with a factor pfactor line of algorithm when the precondition is satisfied.
the default value of pfactor is .
the default priority of selecting a rule in our framework is its success count rule .succ .
when it is initialized as every rule has a chance to be selected in the transformation.
higher success count means the rule is empirically more useful in the transformation which leads to more chances to be selected.
when a number of rules r1 r2 r3...rnare prepared for being applied on the current global constraint expression the probability of selecting a rule ri line of algorithm is prior ri summationtextn x 1prior rx .
our framework integrates an extensible rule database which contains rules in the current version.
the database includes both the simple transformations such as the commutative associative distributive laws and several complicated rules such as the complex number transformations and the facts of trigonometry exponents logarithms and gamma functions.
the database can be extended with more rules to support other types of floating point transformation.
with the help of prioritized preconditions numerical experts are easy to express the domain knowledge of floating point arithmetic in the database.
algorithm depicts the main optimization process that transfers the input numerical ir to the optimized ir while algorithm defines the function stochastictransform that is called at line of algorithm to perform a stochastic transformation on a global constraint expression.
algorithm initializes the optimized ir with the native stable trace ts line and tries to optimize every trace in the input ir.
for every global variable constraint in the trace it builds an set of expressions ethat are equivalent to the original expression e in real arithmetic line and seeks the stable optimization of eby stochastically transforming a form in e line .
when the transformed expression e primeis verified to be stable under its optimized path constraint c primewith infinite precision arithmetic line it creates an verified optimized trace t primeand adds it into the optimized ir line .
it also removes the corresponding optimized trace from the input ir for further optimizing other traces line .d.
code generation post analysis the final stage of our framework generates the output program from the optimized ir.
it translates every trace t in the optimized ir as a branch in the output program with fixed precision arithmetic which sets the branch condition ast.cand updates every target variable with the optimized procedure in the trace.
furthermore our framework also keeps the unoptimized traces in irinat the end of the output program with infinite precision arithmetic which ensures the soundness of the optimized program.
our framework also integrates a post analysis to reduce code clones in the output program.
it merges traces with the same path constraint or variable constraints.
if parts of variable constraints are the same with another trace the post analysis pushes down the branch condition to make the output program short and easy to read.
with the post analysis our framework generates clean outputs such as the code in figure .
since the post analysis does not affect the soundness and efficiency of the output program it is an optional module in the optimization framework.
v. e v alua tion and results we implement our optimization framework1in a loosely coupled manner with a front end that converts the direct numerical program to the numerical intermediate representation ir and a back end that performs the stochastic algebraic transformation and generates the optimized program.
in our front end we analyze the structures of the input program with the rose compiler and implement our symbolic trace extraction module based on klee .
we implement our back end with the python language based on the sympy library.
we parse the syntax of every rule with antlr4 and evaluate the infinite precision program with the latest version of irram library.
we conduct several experiments to evaluate our optimization framework and intend to answer the following key research questions rq1 does our optimization achieve higher floating point accuracy when compared with the state of the art numerical optimization tool?
rq2 can our framework globally optimize numerical software with complicated program structures such as loops ?
rq3 is our optimization framework helpful for real world software?
we get several observations in our evaluation for rq1 our optimization significantly improves the worst case floatingpoint accuracy of numerical expressions when compared with the state of the art numerical optimization tool.
for rq2 our framework is effective in optimizing numerical software with complicated program structures which are challenging for numerical optimization.
for rq3 our framework detects and provides fixing advices of numerical bugs in real world 1the framework is available at authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
3frac2atan2frac2isqrt2log2cbrt2sqrtexp2expaxlogsinvcottanhfsintancos2quad2pquadpquad2m2nthrtquadm2tan2sinexpq2expm1sqrtexp2cosexpq3logqqlog a double precision3frac2atan2frac2isqrt2log2cbrt2sqrtexp2expaxlogsinvcottanhfsintancos2quad2pquadpquad2m2nthrtquadm2tan2sinexpq2expm1sqrtexp2cosexpq3logqqlog b single precision fig.
observed worst case bits corrected by herbie longer arrow to the right is better every row shows the improvement in bit error achieved by herbie on the worst input of random input points for a single benchmark.
the thick arrow points from the accuracy of the fixed precision input program to the accuracy of herbie s output.
accuracy is measured by the number of correct bits when comparing the value to infinite precision arithmetic.
3frac2atan2frac2isqrt2log2cbrt2sqrtexp2expaxlogsinvcottanhfsintancos2quad2pquadpquad2m2nthrtquadm2tan2sinexpq2expm1sqrtexp2cosexpq3logqqlog a double precision3frac2atan2frac2isqrt2log2cbrt2sqrtexp2expaxlogsinvcottanhfsintancos2quad2pquadpquad2m2nthrtquadm2tan2sinexpq2expm1sqrtexp2cosexpq3logqqlog b single precision fig.
observed worst case bits corrected by our optimization framework longer arrow to the right is better every row shows the improvement in bit error achieved by our optimization on the worst input of random input points for a single benchmark.
the thick arrow begins at the same accuracy of the input program as figure and ends at the accuracy of the output of our optimization.
software which has been confirmed by developers of open source projects.
the rest of this section depicts more details in every experiment.
a. rq1 accuracy improvement on local optimization herbie2is the state of the art numerical transformation tool.
since it mainly aims to optimize local numerical expressions authors of herbie have evaluated it on classic benchmarks from hamming s numerical methods for scientists and engineers .
the results show that herbie is good at improving average accuracy for various numerical expressions.
to avoid a bias in our experiment we also conduct our evaluation on these the same experiment parameters except the following setups instead of using average accuracy we make our evaluation more rigorous.
that is we evaluate our optimization with the worst accuracy of all the output values for a numerical program.
if a system has a high worst case accuracy it must also have a high average accuracy but the reverse is not true.
as we can only get a random subset of the numerical outputs we callour measurement the observed worst case accuracy.i no u r point of view the worst case accuracy is important because it 3when our optimization framework accepts input programs instead of numerical expressions we capsulate every numerical expression in the benchmark with a main function.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii specification of the infinite precision benchmark programs for our global optimization program specification analytic evaluate with a simple iterative algorithm e example calculate euler s number e .
... with !
float ext evaluate 100 gamma generate the euler mascheroni constant .
... with stirling s approximation harmonic evaluate the sum of the first 5e terms of the harmonic series itsyst iteratively evaluate .75 with different inputs and calculation orders.
jmmuler iteratively evaluate xi x i x i with different inputs and calculation orders.
lambov calculate the remainder of taylor series is very dangerous for a safety critical numerical software to have only a small number of inaccurate outputs which will still cause system failures and serious consequences.
since both herbie s and our optimization are based on probabilistic mechanism we repeat times of both the tools for every benchmark and show the result of the worst optimization in figure and figure .
hence the results in these figures describe the worst situation for users when they use the optimizations.
from the results our optimization framework has a significant advantage in improving the worstcase accuracy.
such observation is for several reasons our transformation strategies for global optimization also fits in finding better transformation rules for the local optimization.
different from herbie that often infers inaccurate path constraints with a regime algorithm on optimized expressions our framework derives the constraints directly from the input program and further refines the constraints by the rich context in our optimization rule.
b. rq2 effectiveness on global optimization the irram library attaches a group of infinite precision test programs.
after omitting the trivial example programs such as the one just transferring string inputs to the infinite precision values we collect of these infinite precision programs that contain complicated program structures as our benchmark to evaluate our global optimization.
all these programs contain at least a loop to calculate the numerical results some of them introduce complicated iterative refinement algorithms such as stirling s approximation.
table ii specifies these benchmarks that involve various aspects of numerical calculations.
our framework optimizes the benchmarks to doubleprecision programs.
figure depicts the observed worst case accuracy improvement from the direct double precision programs with the original algorithms to our optimized programs.
the experiment setup is the same as figure .
when analytic ande example are stable in their original algorithms our framework cannot further improve their accuracies.
inlambovjmmuleritsystharmonicgammafloat exte exampleanalytic fig.
observed worst case bits corrected by our global optimization longer arrow to the right is better .7e .3e .3e .7e .5e .5e .4e .1e .5e .5e .1e .0e .4e .7e .7e .8e .7e .3e .3e .7e .5e .5e .4e .1e .5e .5e .1e .0e .4e .7e .7e .8e analyti ce example float extgamma harmonicitsystjmmuller lambov0.
.0x1054.0x1055.0x1065.2x1065.4x1065.6x106average execution time s input program left column optimized program right column fig.
average execution time of the input benchmark programs and the corresponding optimized programs fact our framework rewrites e example from summationtextn i i!to summationtext0 i n1 i!in order to alleviate the annihilation of adding a big number to small numbers.
but the accuracy is not improved in the optimized program because the factorial result i!grows too fast that make summationtexti prime i n1 i!still very small.
for other cases our framework yields useful transformations that obviously improve the accuracies of the optimized programs.
figure shows the average execution time of the input programs and their corresponding optimized programs.
when we optimize the benchmark from the infinite precision arithmetic to the double precision arithmetic most cases have a significant speed up.
the benchmark lambov just has a small speed up from milliseconds to milliseconds because the optimized program still relies on some calculations in the infinite precision arithmetic of this case.
c. rq3 case study on real world programs we make a prospect that numerical developers just need to write easy maintained infinite precision programs and implement the framework to generate the corresponding fixedprecision optimizations.
however many current real world programs are still written directly in fixed precision floatingpoint arithmetic with numerical instabilities.
our framework can also help these programs to detect and fix the numerical bugs.
this section describes two cases that our framework authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
improves the accuracy for an open source graphics library clipper and a driving tool slic3r for three dimensional 3d printers.
for every real world project we replace the float and double types in its source code with the real type in the irram library and introduce a pre defined header to make the project look like an infinite precision program.
then we input the project into our framework at the function level and check if the optimization fixes numerical bugs.
our framework detects and provides fixing advices of two numerical bugs in the clipper library.
one of them is caused by the cumulative errors when the library calculates the area of a polygon and the other bug is caused by a massive cancellation when the library computes the distance from a point to a line.
we report both of the bugs4and get the confirmation email from its developer.
our framework also detects a numerical instability in slic3r when it tries to lift the extruder of a 3d printer and the bug is also reported5and get confirmed.
vi.
r ela ted work improving the correctness and efficiency for numerical software is a popular topic with a long research history.
numerical experts have proposed a great number of theoretical approaches and technical tricks to help developers write stable programs .
in this section we mainly survey some closely related recent work on numerical optimization and analysis.
numerical accuracy improvement a few recent researches focus on improving the accuracy of floating point expressions by rewriting them to the forms with smaller rounding errors.
martel presents an abstract semantics which defines a numerical transformation on a set of abstract operations.
it does not support large database of rules in numerical rewriting because the technique is bound to a brute force search which limits the program transformations that can be found.
tang et al.
propose expression perturbation which rewrites numerical expressions in a program with commutative associative and distributive laws for finding a form with higher accuracy.
panchekha et al.
present herbie a state of the art numerical transformation tool that rewrites input expressions with a database of transformation rules and a heuristic estimation that localizes rounding errors in the expression with dynamic sampling.
sanchez stern et al.
further combines herbie with v algrind named herbgrind which dynamically detects and reduces numerical error at a significant part which is called the root cause part in their paper in the program.
speedup of floating point programs schkufza et al.
implement an aggressive optimization of floating point computations as an extension to stoke which generates reduced precision implementations of numerical binaries with a markov chain monte carlo mcmc sampling.
lam et al.
present a framework that builds mixed precision configurations of 4bugs and at double precision binaries with identification of code regions that can use lower precision.
rubio gonz alez et al.
present precimonious a dynamic program analysis tool that decreases the precision of intermediate numerical values precision tuning to speed up floating point calculations.
they further improve the efficiency of precision tuning with blame analysis and a scalable hierarchical search that exploits the community structure of floating point variables .
none of these techniques concern about transforming the numerical program to a form with higher accuracy.
numerical v erification and error detection v erification of a numerical program is difficult when it does not always adhere to the ieee standard .
darulova and kuncak tracks the guaranteed range of floating point values in a program.
franco et.
al conduct an empirical study of numerical bugs from widely used numerical libraries .
goubault et al.
track the error of floating point operations algorithms and computations with abstract interpretation.
barr et al.
detect floating point overflows and underflows with an smt solver.
then darulova et al.
also use an smt solver to prove error bounds in numerical computation.
benz et al.
present fpdebug which find numerical accuracy problems with a dynamic testing in higher precision.
chiang et al.
develop a heuristic search algorithm to generate test inputs that cause significant floating point inaccuracies.
zou et al.
further propose a genetic algorithm to find the inaccurate inputs.
bao et al.
propose a technique to detect the floating point error inflation that causes different execution paths.
later they integrate the technique in raive a vectorized executor.
tang et al.
present a framework to detect and diagnose numerical instabilities automatically in software.
none of the above techniques optimize floating point computations in a program.
vii.
c onclusion this paper presents a global optimization framework that helps numerical developers to obtain high precision easyto maintain and efficient numerical software.
using our framework a developer simply writes the infinite precision numerical program directly following the problem s mathematical requirement specification.
our framework then optimizes the input program in a global fashion which analyzes the program s numerical value flows across different statements through a symbolic trace extraction algorithm and generates optimized traces via stochastic algebraic transformations guided by effective rule selection.
acknowledgment this research is supported by national key r d program of china grant no.
2017yfb1001801 and national natural science foundation of china grant no.
and .
zhendong su was supported in part by united states national science foundation grants and .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.