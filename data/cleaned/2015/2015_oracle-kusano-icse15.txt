dynamic generation of likely invariants for multithreaded programs markus kusano arijit chattopadhyay chao wang department of ece virginia tech blacksburg virginia usa abstract weproposeanewmethodfordynamicallygeneratinglikelyinvariantsfrommultithreadedprograms.whilee xisting invariantgenerationtoolsworkwellonsequentialprogram s we foundtheyareineffectiveatreasoningaboutmultithreade dprogramsbothintermsofthenumberofrealinvariantsgenerate d and in terms of their usefulness in helping programmers.
we address this issue by developing a new dynamic invariant gen eratorconsistingofanllvmbasedcodeinstrumentationfro nt end asystematicthreadinterleavingexplorer andacusto mized invariant inference engine.
we show that efficient interlea ving exploration strategies can be used to generate a diversified set of executions with little runtime overhead.
furthermore w e show that focusing on a small subset of thread local transit ion invariantsisoftensufficientforreasoningabouttheconcu rrency behavior of programs.
we have evaluated our new method on a set of open source multithreaded c c benchmarks.
our experimentsshowthatourmethodcangenerateinvariantsth at aresignificantlyhigherinqualitythanthepreviousstate of theart.
i. i ntroduction methods for dynamically generating likely invariants from sequential software have been used in many applications including program understanding maintenance testing v erification and error diagnosis.
however effective tools for generating such invariants for concurrent software are sti ll lacking.
for example daikon is a highly successful invariant generation tool for sequential programs written in languages such as java c c and perl.
however as we will show in section ii for multithreaded programs daikon often produces many confusing and incorrect results.
one problem of existing methods such as daikon is that they depend heavily on the set of execution traces fed to the invariant inference engine.
in general increasing the amo unt of program behavior exercised in the set of execution traces increases the likelihood that the generated invariants are true.
however generating a sufficiently diversified set of execution traces is difficult for a multithreaded program since th e program s behavior depends not only on the program s input but also on the thread s schedules.
thread scheduling in a typicalexecutionenvironment isdeterminedbytheunderl ying operating system and the threading library naively execut ing the program many times does not necessarily increase the diversity of the thread schedules.
another problem of existing methods is that they tend to report too many invariants.
even if many of these reported invariants are real invariants they are unlikely to be equa lly useful.
it is impractical to assume that the user will have ti me to sift through all of them individually.multithreaded c c code executable llvm based instrumentation block size likely invariants exploration of interleavings strategy trace logs test oracle based trace classifier daikon based invariant gen. good traces bad traces figure .
our new dynamic invariant generation tool named udon .
multithreaded programs due to the subtle interactions amongstthreadsand potentially large numberof interleavi ngs pose challenges both in their design and analysis.
typicall y whenthefocusofananalysisisonconcurrentnondeterminis m one assumes the sequential part of the computation is correc t instead the problem comes from rare and complex thread interactions.
in such cases we argue that the focus should be put on a small subset of thread local invariants called t he transition invariants that capture the relations among shared variables directly related to concurrencycontrol.
for exa mple a certain code block should be kept atomic or instances of certain operations should be made mutually exclusive.
tothisend we proposea newdynamicinvariantgeneration method for multithreaded programs.
by leveraging systemat ic thread interleaving exploration algorithms to generate di versified execution traces our method significantly improves the quality of generated invariants over existing methods.
the overall flow of our method is shown in figure .
our method takes a multithreaded c c program as input and returns likely invariants as output.
first we instrument t he code using a new llvm based front end to add monitoring capabilities for dynamic analysis.
then we execute the pro gram under the control of a systematic interleaving explore r. the generated traces are fed to a classifier which separates the passing traces from the failing traces.
finally we feed a subsetofthetracestoacustomized daikon invariantinference engine which returns the likely invariants as output.
anothercontributionofourworkisinvestigatingtheimpac t of differentinterleavingexplorationstrategiesonthe pr ecision andperformanceofinvariantgeneration.intheory allpos sible thread interleavings of a concurrent program should be give n to the invariant inference engine to obtain the most precise invariants.
however due to the well known interleaving ex thread 1p a 2if p!
null ... 4p x ... 7thread 6p null ... ... ... ... ... figure .
two threads sharing a pointer.
in thread the if statement and the subsequent write to pis intended to be atomic.
plosion problem the number of thread interleavings can be exponential with respect to the number of concurrent operations.
therefore we propose the use of selective exploration strategies as opposed to exhaustive exploration to reduc e runtime overhead.
our experimental evaluation shows that selectiveexplorationoftenleadstoinvariantsofsimilar quality to sound reduction methods such as dynamic partial order reduction but with an order of magnitude faster run ti me.
athirdcontributionof ourworkis a focusongeneratinginvariants that are most relevant to concurrencyrelated prog ram behaviors.
in general the invariantsgenerated by an infer ence engine fall into two categories state invariants and trans ition invariants.
for example consider the program in figure where a.x isinitializedtozero.thepredicate a.x at line is a state invariant it holds at a thread local progra m location and is expressed in terms of the program variables visible at that location.
a transition invariant in contra st is a predicate that may hold at the entry and exit points of an arbitrarycode block and is expressed in terms of two version s ofaprogramvariableattheentryandexitpoints.forexampl e in figure the predicate a.x orig a.x is a transition invariantover the code block from line to line where orig a.x is the value of variable a.x at line the original value and a.x is the value of variable a.x at line .
forreasoningaboutconcurrencyrelatedprogrambehaviors we argue that it is often sufficient to focus on these transiti on invariants.
the reason is that they capture the no threadinterference properties i.e.
whether the associated code block is atomic or whetherit should be made atomic .by atomic we mean that the execution of the code block is not affected by the execution of other instructions from concurrently runn ing threads.
considertheprograminfigure2.abugcanoccurifthread sets the value of pto null when thread is executing lines .
if we generate invariants only from the non buggy runs wewillobservethetransitioninvariant p orig p for the code block from line to line .
examining the buggy runs we will see that this invariant no longer holds.
the differencein the invariantsgeneratedbetweenthe pass ing and failing runs shows the root cause of the bug pis not constant.
throughout this paper we will show how discrepancies betweentheinvariantsgeneratedfrompassingandfailingr uns like this example can be leveragedto understandthe softwa re code and diagnose concurrency bugs.
we have implemented our new methods and conducted experiments on a set of open source multithreaded c c programs.
our results show that the invariants generated by our new method are often significantly higher in quality than the previousstate of the art daikon .overall this papermakes the following contributions we show through experiments that existing dynamic invariant generation tools such as daikon do not work well on multithreaded programs both in terms of the number of true invariants generated and in terms of the usefulness of these invariants.
we propose a new method for improving the quality of dynamic invariantgeneration for multithreadedprograms byleveragingselectiveinterleavingexplorationstrateg ies.
we show that transition invariants are the most relevant invariants to help in reasoning about concurrency related behaviors.theyareusefulinprogramcomprehensionand diagnosing concurrency errors.
we implement the proposed method and demonstrate its efficiency and effectivenessthrough experimentson a set of multithreaded c c benchmarks.
the remainder of this paper is organized as follows.
we present examples to illustrate our new methods in section ii .
we establish notation in section iii and then present our new invariant generation algorithm in section iv.
we present bo th runtimeoptimizationsandmethodstoclarifyoutputtotheu ser in section v. this is followed by our experimentalevaluatio n in section vi.
we review related work in section vii and finally give our conclusions in section viii.
ii.
m otivating examples in this section we present examples to illustrate the problemsinexistingmethods highlightourmaincontributions and demonstrate some potential use cases for our new method.
first consider the program in figure which has a global variable named balance being accessed by functions getbalance and setbalance .
the third function withdraw invokes the previous two functions to deduct a certain amount from balance .
since the global variable balance is protected by a lock and unlock pair everytimeitisaccessedthereisnodata race.however there can be atomicity violations.
the function withdraw is meant to be executed atomically without other threads interleav ed betweenthecallsto getbalance and setbalance but the atomicity is not enforced.
for example starting wit h balance if two concurrentthreads run withdraw at the same time the result may be either or .
existing invariant generation tools do not work well in this case.
for example if we run the program with daikon s c frontend mostlikely we will get a false invariant.the reas on is thatdaikon relies on the native execution environment to determine the program s thread schedule at run time and in this example since the code in each thread is small significantly smaller than what can be executed in the linux kernel s time slice all threads will have ample time to run t o completion before encountering a context switch.
if the erroneous interleaving never occurs during its analysis daikon would report the following false transition invariant for the withdraw function balance orig balance where orig balance denotes the original value of balance at the entry point of 1int getbalance 2int bal 3lock 4bal balance 5unlock 6return bal 8void setbalance int bal 9lock balance bal unlock void withdraw int bal getbalance bal bal setbalance bal figure .
concurrent bank account example.
withdraw and balance denotes the value of balance at the exit point.
this is not a true invariant and reporting it to the user may do more harm than good.that is it can make the developer believe that withdraw is atomic thereby masking the concurrency bug.
our new method in contrast controls the thread scheduling of the program in order to create a diverse and representative set of execution traces.
consequently the invariant inference engine would produce the following correct invariant for the withdraw function balance orig balance .
this is the correct result and is the best onecaninferfromtheexecutionsofthisprogram twothread s running withdraw concurrently .
that is the balance always decreases but not necessarily by .
another problem with existing tools is that they often report too many invariants.
for example running daikon on the benchmark fibbench which has lines of code would generate likely invariants.
among them are true invariants therestarefalse butonlythreeofthemarere lated to the concurrency behaviors of the threads.
the others are either specific to the particular program input used in the test runs or the sequential part of the computation.
since ou r goal is to reason about concurrency related behaviors our new method allows the user to focus only on the concurrency related invariants known as transition invariants .
therecanbemanyapplicationsfortransitioninvariantssu ch as balance orig balance and balance orig balance .
here we give two examples to help diagnose concurrency bugs and to infer atomic code regions.
during software testing it is reasonable to expect the user to provide a test oracle which separates failing test runs fr om passing test runs.
we allow users of our new tool to specify correctness conditions using r assert which from the user s perspective is identical to the standard c assert function.forourrunningexample assumetheuserassertst hat balance must hold at the end of the execution.
this is illustrated in figure .
for the buggy program in figure if the function withdraw is executed atomically by both threads the assertion would pass but if the function is no t executed atomically the assertion would fail.
if we run our new invariant generation method on the passing traces only it would report the transition invaria nt balance orig balance .
in contrast if we int main void thread create t1 withdraw thread create t2 withdraw thread join t1 thread join t1 r assert balance test oracle figure .
the main function for the example in figure .
void withdraw lock int bal getbalance bal bal setbalance bal unlock figure .
enforcing atomicity in the withdraw function in figure .
run our new invariant generation method on the failing trace s only it would report the transition invariant balance orig balance .
the discrepancy between these two sets of results from passing and failing runs will help the user diagnose the root cause of the concurrency failure.
regarding atomic region inference consider the same example in figure .
the transition invariant generated from the passing runs for the code block spanning lines is balance orig balance whichis consistent with the thread localtransition relation of this code block when it is executed without interference from other threads .
in other words the programmer s design intent as revealed by all the passing test runs is that withdraw should be executed atomically.
this suggests that to fix the bug in withdraw we need to enforce atomicity around the calls to getbalance and setbalance as illustrated in figure .
1typedef struct int a b c data 2data a 3data p a 4void thr1 5data tmp p 6if tmp !
null 7p a 8p b 9p c r assert tmp a tmp b tmp c void thr2 p a figure .
concurrent program where one thread updates the fie lds of a structure while the other modifies a global pointer.
another limitation with daikon due to the location of code instrumentation is that invariants are only generate d at function entry and exit points.
although this design choice is suitable for sequential code it is not suitable for concurr ent programsbecauseconcurrencyconstructs suchasatomicco de regions rarely coincide with the procedural boundaries.
o ur method in contrast has the capabilityof generatinginvar iants ..main.c 3 9 enter p !
null ..main.c 3 9 exit p orig p ..main.c 5 9 enter p !
null ..main.c 5 9 exit p orig p figure .
portion of the output generated by our tool for the e xample in figure .
at the boundaryof code blocks of arbitrary size the user can set the block size as input to our tool as shown in figure .
we illustrate this feature using the following example.
consider the program in figure .
within thr1 the three fields are intended to be updated atomically similar t o the previous example the programmer asserts the correctne ss condition using r assert .
to infer the intended atomic region that spans from line to line the capability of generating invariants for arbitrary code blocks is crucial .
figure shows a section of our tool s output regarding the transition invariant generated from passing runs.
it first s tarts with a code block size of two and then iteratively expands the block size.
a block size of two means that our tool will attemptto generateinvariantsoverany code regioncontain ing two consecutive accesses to a shared object.
the partitioni ng of the source code into code regions was performed by our llvm based instrumentation front end as shown in figure .
in figure ..main.c 6 12 means that we consider the block from line to line in figure whereas ..main.c 8 12 means that we consider the block from line to line .
with a block spanning lines we cover all the shared memory accesses in thr1 .
in both cases when analyzing the passing runs we can generate the invariantp orig p whichindicatesthatthe valueof pis neverchanged.amongstallthefailingruns thisinvariant does not hold.
again the discrepancies in the invariants genera ted by the passing and failing runscorrectlysuggeststhat in or der forthetestrunstopass thecodeblockfromline6toline12 must be kept atomic.
iii.
p reliminaries in this section we present a formal model for concurrent programs and introduce the basics of the dynamic invariant generation process.
a. concurrent programs a multithreaded program consists of a set of shared variables and a set of threads t1 ... t n where nis the number of threads in the program.
each thread is a sequential program with a set of thread local variables.
let st be an instruction.
an execution instance of st is called an event denoted e a bracketle ttid l st l a bracketri ht where tid isthethreadid and land l are the thread program locations before and after executing st .
an event is said to be visible if it accesses a shared variable or a thread synchronization object mutex lock or conditionvariable .
otherwise the event accesses only th readlocal variables and it is said to be invisible .
during systematic interleaving exploration and execution trace logging inv isible events will be ignored.
we model each thread tias a state transition system mi.
the transition system of the program denoted m m1 m2 ... mn is constructed using interleaving composition.
letm a bracketle ts r s a bracketri ht where sis the set of global states r is the set of transitions and s0is the initial state.
each state s sis a n tuple of thread program states.
each transition e ris an event from one of the nthreads.
an execution trace of mis a sequence s0e0 s1... en sn where s0e0 s1correspondstoexecutingevent e1instate s0leading to state s1.
we use the special event haltto denote normal program termination and the special event abortto denote faulty programtermination whichcorrespondstoafailed r assert statement.
an event from thread timay have the following types halt which denotes the normal program termination abort which denotes the faulty program termination fork j for creating child thread tj where j e atio slash i join j for joining back thread tj where j e atio slash i. lock lk for acquiring lock lk unlock lk for releasing lock lk signal cv for setting signal on condition variable cv wait cv for receiving signal on condition variable cv read v for reading of shared variable v write v for writing to shared variable v mentry m for entering a function call mexit m for returning from a function call bentry blk for starting a code block bexit blk for ending a code block.
here mentry and mexit are also supported by existing invariant generation tools such as daikon whereas bentry and bexit are the new additions in our method.
we model thread synchronization events in our method in order to controlthe executionorder during thread interlea ving exploration.
using this model at each moment during a program s execution we know which threads are blocked disabled and which threads are executing enabled an enabled thread becomes disabled if i it attempts to execute lock lk while lk is held by another thread ii it attemptsto execute wait cv while the signalon cv hasnotyet been set or iii it attempts to execute join j while the child thread tjisstillrunning.similarly adisabledthreadbecomes enabled if i another thread releases the lock lk by executing unlock lk ii anotherthread sets the conditionvariable cv by executing signal cv or iii thechildthread tjterminates.an accurate model of the sets of enabled and disabled threads at runtimeisrequiredsinceattemptstoscheduledisabledthr eads while postponing the execution of enabled threads may lead to artificial deadlocks.
at runtime our scheduler selects a given event from the set of enabled events.
which event to select is determined by the exploration strategy used by the scheduler.
similarl y the scheduler repeatedly executes the program systematic ally exploring new interleavings until the search strategy s i nter leaving coverage criteria is satisfied.
we defer discussion s of exploration strategies until section iv.
for an in depth discussion on systematic concurrent program testing refer to .
b. dynamic invariant generation dynamically generated invariants are predicates that hold over the execution traces produced by test runs.
as such the y are not guaranteed to hold for all possible executions of the program.
furthermore the invariant inference engine ofte n uses a statistical analysis and in theory is neither sound nor complete.
however in practice dynamic invariant generat ion tools such as daikon have shown to be useful in a wide range of applications.
in general the number of invariants that c an be generated as well as the likelihood of them being true invariants depends on the test suite.
daikon is a highly successful invariant discovery tool that supports programming languages such as c c c eiffel f java lisp and visual basic.
for each of these languages daikon provides a front end tool for code instrumentationtoaddloggingcapabilitytothetargetpro gram.
the frontend tools preparethe programto generate trace log s in a commonformat which are then fed to the same back end invariant inference engine.
we have developed a new instrumentation tool based on the popular llvm compiler platform to replace daikon s previousfrontend.the main advantageof ournewinstrumentation tool is to leverage the large number of static program analysis procedures implemented in llvm as well as to reduce the runtime overhead caused by instrumentation.
we will show through experiments section vi that our llvm based instrumentation tool can indeed lead to faster dynami c analysis compared to the default front end in daikon due to its significantly lower instrumentation overhead.
since daikon cannot diversify the thread schedules it may generate many bogus invariants for a multithreaded program .
furthermore daikon iseffectiveingeneratinglinearinvariants of the form ax by c but weak in generating more complex invariants such as polynomialinvariants c0 c1x1 c2x2 ... andarrayinvariants.forthelatestdevelopment along this line please refer to the recent work by nguyen et al.
.
however our focus is not on improving the expressiveness of the generated invariants but on improvi ng their quality with respect to concurrency.the vast majorit y of invariants generated by existing tools such as daikon capture the sequentialprogrambehavior.
our new method in contras t focuses on invariants that capture the concurrency behavio rs.
iv.
u don o ur new dynamic invariant generation tool in this section we present the three components of our new method an llvm based code instrumentation tool a systematic interleaving exploration tool and a customize d inference engine for daikon .
the overall flow of our tool called udon is illustrated in algorithm which takes the source code of a multithreaded c c program as input and returns a set of likely invariants as output.algorithm1 high level algorithm for udon inst output inspect pass src code inst output daikon pass inst output inst output spacer pass inst output spacer size trace file gen traces inst output thrd mod traces trace classifier trace file invariants inv inference thrd mod traces a. llvm based code instrumentation we developed an llvm based front end for instrumenting multithreaded c c code.
as shown in algorithm it consists of three code transformation passes.
the first pass inspect pass takes c c code as inputandreturnsaninstrumentedversionofthecodeasoutp ut.
inside this pass we first identify all the programpoints whe re a thread s schedule needs to be controlled.
these program pointsincludethecallstothreadsynchronizationroutine s and the read and write operations on shared memory locations discussed in section iii.
at each program point we inject new code before these visible operations to allow the control of the thread at run time by the scheduler.
we leverage the conservative static analysis techniques implemented in ll vm to identify these visible operations.
the second pass daikon pass takes the previously instrumented code as input and returns another instrumente d version of the code as output.
inside this pass we inject new code to add event trace generation capabilities to the program.
the event trace generated by the program conforms to the common file format as required by the back end invariant inference engine in daikon .
by default this pass instrumentsthecode onlyatthe functionentryandexitpoin ts whichiscomparabletotheoriginalc frontendfor daikon .
the third pass spacer pass takes the previously instrumentedcode as inputand returns the final version of th e code as output.
inside this pass we also inject new code to add logging capabilities not just at the procedural boundar ies but also at the boundary of arbitrary code blocks.
this is accomplishedbyinsertinghookfunctioncallsto the entrya nd exit points of these code blocks which in turn take care of the trace generation at run time.
note that the events logged as a result of the second and third passes are kept in the same format.
from the standpoint of the back end invariant inference engine ther e is no distinction between a pair of entry and exit points for a function and a pair of entry and exit points for an arbitrary code block.
therefore the back end inference engine does not have to be drastically altered in order to infer invarian tsat the boundary of arbitrary code blocks.
by varying the size of the instrumented code blocks we can dynamically change the locations where state and transition invariants are genera ted.
this will help us to detect likely atomic regions in the code.
b. systematic interleaving exploration the gen traces function in algorithm involves an exploration of the concurrent state space of the program.
due to the well known interleaving explosion in general we cannot afford to naively enumerate all possible thread schedules while diversifying the execution traces for the b ack end inference engine.
in this work we build off a set of interleaving exploration strategies to produce a represen tative subset of thread interleavings.
thebaselinesearchstrategyreliesonthetheoryofpartial orderreduction por .itgroupsthepossibleinterleavin gsof aconcurrentprogramintoequivalenceclasses andthensel ects one representative interleaving from each equivalence cla ss to explore.
equivalence classes are defined using mazurkiewic z traces .
two sequences of events are said to be in the same equivalence class if we can create one sequence from the other by successively permuting adjacent and independent events.twoeventsare dependent iftheyarefromtwodifferent threads access the same memory location and at least one of them is a write or modifyoperation otherwise the two event s are independent .
it has been shown that in the context of verifying concurrent systems exploring one representa tive interleaving from each equivalence class is sufficient to ca tch all deadlocks and assertion violations.
one benefit of por based methods is that they are a sound reduction.thereducedset ofinterleavingsstill cancaptu reall possiblebehaviorsoftheconcurrentprogram.therefore u sing theexploredinterleavingsasinputforthesubsequentinva riant inference will lead to the best possible result the explore d interleavings form a maximally diversified set of execution traces.
thecurrentstate of the artporbasedalgorithmisdynami c partial order reduction dpor .
dpor computes the dependency relation among events dynamically at run as opposed to statically at compile time.
as a result dpor proved to be a practical step forward for por algorithms.
it allowed for realistic programs written in full fledged programming languages such as c c to be verified.
however due to its exhaustive exploration of the search space even dpor may incur a large runtime overhead.
as a result there is a large body of work dedicated to the development of more efficient yet unsound exploration strategi es.
two methods along these lines are preemptive context bounding pcb andhistory awarepredecessorsets hapset .
in practice even though they are unsound i.e.
they do not guaranteeto findallconcurrencybugs empiricalstudiesh ave shown that they still providedecentbug coveragein program s far too complex for dpor to handle.
with respect to invariant generation we will address performance concerns in section v. we will show that replacing the ideal yet slow exhaustive search of dpor with faster selective exploration strategies such as pcb and hapset we can still maintain the quality of generated invariants whil e significantly reducing the execution time.
c. customized invariant generation the final two steps in algorithm denoted by trace classifier and inv inference respectively solvetwo issues in previousinvariantinferenceen gines.
first the inference engine may produce confusing results when the event trace from both passing and failing execution s are simultaneously used as input.
to solve this problem we developed a trace classification module that separates the executiontracesintotwogroupsbasedonatestoracle.spec ifically udon providesafunctioncalled r assert through which the programmers can assert correctness conditions fo r the program.
during dynamic analysis if the assertion fail s the corresponding execution trace will be classified as fail ing.
otherwise the trace is passing.
this behavior from the use r perspective isidenticaltothestandardc assert function.
while inferring likely invariants the engine may choose to consider only the bad traces only the good traces or all traces.
as a result we can compareand contrastthe invarian ts generated in these three scenarios.
second we customized the invariant generation engine in daikon to focus on two types of invariants in a multithreaded program the state invariants and the transition invariant s. both transition and state invariants are expressed in terms of shared variables variablesaccessedbymultiplethreadsinthe execution traces.
a state invariant is a predicate expresse d in terms of the value of variablesat a single programlocation.
a transitioninvariantisapredicateexpressedintermsofva riable values at two different program locations of the same thread .
in essence a transition invariant is capable of capturing t he non interference impact of executing an arbitrary code block.
moreformally weconsideraprogram pasastatetransition system p a bracketle ts r i a bracketri ht where sis the set of states i sis thesetofpossibleinitialstates and r s sisthetransition relation.ingeneral atransitioninvariant denoted t isan over approximation r ofthetransitiveclosureof rrestricted to the reachable state space i.e.
r r i r i t. intuitively a transition invariant summarizes the relat ion between the pre and post conditions of a consecutive set of instructions transitions executed by a thread.
transition invariants are particularly useful in software verification.
to verify the concurrent behavior of a program one typically assumes the sequential computation is correc t but the thread interaction is potentially buggy.
in this cas e transition invariants would conform to the transition rela tion ofasequentialcodeblockintheabsenceofunexpectedthrea d interference but would deviate from the transition relati on in the presence of thread interference.
therefore observing that a sequential transition invariant differs from the concurr ent transition invariantfor the same code block is often indica tive of a bug caused by thread interference.
for example consider a shared counter that is incremented by multiple threads.
the sequential or correct invariant for the increment operation would be that the counter increases its value by one at a time counter orig counter .
however if the programmer fails to enforce atomicity in the increment operation this invariant would no longer hold for all possible executions of the program.
clearly th e discrepancybetweenthesequential orcorrect andconcur rent orincorrect transitioninvariantshintsatthe rootcaus e ofthe aforementioned bug.
due to the help of both systematic interleaving exploration techniques and customized invariant inference engines udon can more robustly generate high quality invariants for mul tithreaded applications than existing methods.
v. o ptimizations the method presented in the previous section addresses the problem of dynamically generating high quality invari ants from multithreaded programs.
however using dpor may cause a performancebottleneck due to the exponentialgrowt h in the number of interleavings with respect to program size.
another problem of the new method is that the number of reported invariants can still be very large.
despite that ma ny of them are indeed invariants reporting all of them without filtering can overwhelm the user.
in this section we present our solutions to these problems.
a. exploring interleavings selectively we address the performance problem by replacing the exhaustive dpor exploration strategy with efficient but un sound selective search strategies.
in this context our go al is to drastically reduce the runtime overhead while maintaini ng the diversity of the generated interleavings.
dpor is a soun d reduction in that it can prune away redundant interleavings withoutmissinganyconcurrencyrelatedprogrambehavior.
to thisend it groupsallpossiblethreadinterleavingsintoe quivalence classes and then tries to explore only one representat ive interleaving from each equivalence class.
however due to t he limited amount of program information available at run time dpor still may create many redundant equivalence classes for the purpose of generating invariants.
consider the busy waiting example in figure which has two threads t1 t 2communicating via the variable x x initially .
under dpor the systematic exploration wouldgenerateinfinitelymanyinterleavings.eachinterle aving corresponds to a different execution of the loop by the first thread.
each of these interleavings belongs to a separate equivalenceclass sincedependentmemorylocationsarebe ing updated soeachmustbetested.noticethat exceptforthefi rst two interleavings denoted c ab and ab c ab respectively none of the other interleavings of the form ab kc ab where k ... can offer new concurrency scenarios.
in this paper we propose to avoid generating an excessive number of execution traces during interleaving exploratio n by using a selective search as opposed to an exhaustive search .
the aim of a selective search is to cover a small subset of high risk concurrency scenarios while avoiding the redundant ones as shown in the example in figure .
the rationale is that in practice programmersoften make impl icit assumptionsregardingtheconcurrencycontrolofthreads e.g.
certain code blocks should be mutually exclusive certain code blocks should be atomic and a certain operation order should be obeyed.
concurrency bugs are frequently the resul t of these implicit assumptions being broken leading to data races atomicity violations and orderviolations.
the goa lof a selective search is to maximize the coverageof such scenari os while reducing the runtime overhead.
one popular selective search strategy proposed in the context of software testing is preemptive context bounding pcb .
pcb explores interleavings with only a bounded number of involuntary context switches.
the strategy can be effective in concurrency testing because in practice man y concurrency bugs can be exposed using a small number of context switches.
we note that although pcb is effective in practice the number of explored interleavings remains exponential with respect to the number of concurrent thread s. furthermore it is not effective on the example in figure where all interleavings have exactly one context switch.thread t1 do a tmp x b while tmp thread t2 cx execution a1 r x c w x a2 r x figure .
using hapset reduction to prune interleavings x initially .
another popular and more scalable selective search strat egy is the history aware predecessor set hapset based reduction.itcanbeviewedasanimprovementoverpcbsince the number of explored interleavings is no longer exponenti al withrespecttothe numberofconcurrentoperationsorthrea ds.
this is accomplished by focusing on covering only the ordering combinationsof read write instructions in the program as opposed to the many instances of these instructions.
formally a program statement st is defined as a tuple file line thr ctx where file is thefile name line istheline number thr is the thread id and ctx is the bounded calling context.
given a set t 1 ... n of interleavings and a statement st stmt thataccessesasharedobject thehistoryaware predecessor set or hapset is defined as the set st ... st k of statements such that for all i i k an eventeproduced by st is immediately dependent upon an eventeiproduced by st iin some interleaving t .
consider again the example in figure .
after exploring the first two interleavings denoted c ab and ab c ab respectively the hapsets computed over these interleavings are as follows hapset c and hapset a .
since a and care the only two conflicting program statements in the program all possible hapset combinations have already bee n covered.therefore the interleavingexplorationstops si nce no other interleaving can lead to new hapset scenarios.
we shallshowthroughexperimentsinsectionvithatfaster interleaving exploration algorithms such as pcb and hapset areoftenasgoodasdporintermsofgeneratinghigh quality invariants.
at the same time these algorithms can be orders of magnitude faster which makes udon practically useful.
b. focusing on transition invariants by default the number of invariants generated by our method as well as other similar tools such as daikon can be large.
however not all of these invariants are useful for reasoning about the concurrency related program behaviors .
for example among the likely invariants generated for fibbench by daikon onlythree are related to concurrency whereas the others are specific to the sequential part of the computation.
therefore in this work we propose to focus on only the transition invariants over shared variables.
in the remainder of this section we show why transition invariant s are useful in helping the user understand the software code and diagnose concurrency bugs.
let us assume that a multithreaded program has some assertions that would be satisfied in most cases but may fail in some rare interleavings.
furthermore regarding th e concurrency control there is no formal documentation othe r than the source code that describes the programmer s intent .
in this case we classify the execution traces of the program into two groups the passing traces and the failing traces.
t o1void thread 2sum sum 4int main create run and join num threads... 6r assert sum num figure .
concurrent program with multiple threads updatin g a counter.
help the user understand the root cause of the concurrency error manifested in the failing traces we leveragethe two s ets of invariants generated by udon from the set of passing and failing traces and identify the discrepancy between them.
formally let ipand ifbe the likely invariants generated from the passing and failing traces respectively.
as a resu lt id ip ifconsists of all the invariants satisfied by the passing but not the failing traces.
our conjecture is that th e discrepancyoftenprovidesinformationtohelpunderstand why the error occurs.
in the following example we show that id can indeed help a programmer understand the root cause.
considerfigure9 whereaparameterizednumberofthreads share a global counter sum initialized to zero.
num is the number of threads that execute the function thread concurrently.
these threads are created run and joined insid e main before it checks the value of sum .
the test oracle providedby the programmeris shown on line which states that the expected result is sum num .
the assertion passes in runs where each thread executes the function thread atomically but fails in runs where the threads interfere wi th each other.
specifically depending on how they interfere wi th each other the value for sum ranges from 1to num .
when given the passing traces udon will generate the transition invariant sum orig sum for the inc function.
however when given the bad traces udon will generate the transition invariant sum orig sum which covers cases in which sum is increased by ... num.
by comparing the two sets of transition invariants we can see the difference in behavior of the passing and failing runs.
i n the passing runs sum is always incremented whereas in the failing runs it is not.
another possible application of transition invariants is t o help the user identify atomic regions.
when the transition relationofacoderegionisconsistentwiththetransitioni nvariant generated for the same code region we say that section has been executed atomically.
furthermore if the transiti on invariant is generated from passing traces only and they ar e not satisfied by the bad traces we can assume that the code region is intended to be atomic .
for example the function thread in figure and the function withdraw in figure are intended to be atomic whereas only the fixed version of withdraw in figure is atomic.
the atomic coderegionsinferredinthiswaycanhelptheusercomprehen d the software code and diagnose failed execution traces.
vi.
e xperiments we have implemented the proposed method in a software tool called udon .udon can handle unmodified c c code written using posix threads to automatically generate dynamic invariants.
we used llvm to create a new front end for daikon and a modified version of inspect for systematic concurrent program exploration.
we evaluated udon on open source programs.
the first set of programs come from the software verification competition .
these programs while small in terms of lines of code implement complex low level synchronizatio n algorithmssuchaspeterson s anddekker s soluti ons to the mutual exclusion problem.
the second set of programs are real world applications pfscan is a parallel directory scanner and nbds is a c implementation of several nonblocking concurrent data structures.
all tests were run on a machine with a .
ghz intel core i5 3230m cpu and gb of ram running a bit linux os.
our experimental evaluation was designed to answer the following research questions can the previous state of the art method daikon generate correct invariants for concurrent programs?
can our new method udon robustly generate highquality invariants for concurrent programs?
can udon scale to programs of realistic size and complexity?
a. results table i shows the results of an experiment comparing the performance of udon againstdaikon .
for each test program both daikon and udon were used to generate invariants.
bydesign udon needstore runtheprogrammultipletimesin ordertoexploretheconcurrentbehaviorofaprogram where as daikon runs the program only once.
in order to create a fair comparison we also allowed daikon to run each test program the same number of times as udon .
we refer to the multirun daikon strategy as daikon and the single run strategy as daikon in table i. columns of table i show the program name lines of code loc number of program program points and number of monitoredsharedvariables for each test.
columns5 an d show the total number and the number of incorrect invariantsgeneratedby daikon daikon and udon respectively.
for experiment purposes only we manually inspected the resultsto verifyifthe invariantsweretrue.finally column s11 13and14 16showthenumberofrunsandruntimeinseconds for each method.
first theresultsshowthat daikon generatesincorrectinvariants for every test program.
the cause of this is clear since daikon onlyexercisesa smallportionofthe concurrentbehavior of a program even if it runsthe programmultiple times it fails to observe many different states of the program and asaresult deducesincorrectinvariants.comparingcolum ns8 and of table i shows that running daikon multiple times on thesameprogramhaslittletonoeffectatreducingthenumbe r of incorrect invariants.
the likely cause of this is that sim ply re running a concurrent program repeatedly explores only a small portion of the entire interleaving space.
second columns and show that udon is capable of generating a large number of correct invariants for each test program.
on average udon produces only one incorrect invariant per test.
compared to daikon and daikon udon produces on average over an order of magnitudefewer incor rectinvariants.theincorrectinvariantsgeneratedby udon are table i. comparison of the invariants generated by daikon baseline daikon multi run and udon new .
for the same set of program points.
number of invariants incorrect invariants number of runs ru n time s name loc prog.
points shared vars.
daikon daikon udon daiko n daikon udon daikon daikon udon daikon daikon udon sync01 safe .
.
.
fibbenchsafe .
.
.
lazy01safe .
.
.
stateful01 safe .
.
.
dekkersafe .
.
.
lamportsafe .
.
.
petersonsafe .
.
.
timevarmutex .
.
.
szymanski .
.
.
inctrue .
.
.
inccas .
.
.
incdec .
.
.
incdeccas .
.
.
reorder .
.
.
accountbad .
.
.
pfscan .
.
.
nbds hashtable .
.
.
nbds skiplist01 .
.
.
nbds listidx01 .
.
.
average .
.
.
table ii.
breakdown of the invariants generated by udon .
name regular invs transition invs total invs trans.
invs sync01 safe .
fibbenchsafe .
lazy01safe .
stateful01 safe .
dekkersafe .
lamportsafe .
petersonsafe .
timevarmutex .
szymanski .
inctrue .
inccas .
incdec .
incdeccas .
reorder .
accountbad .
pfscan .
nbds hashtable .
nbds skiplist01 .
nbds listidx01 .
duetothefactthathapset thedefaultconcurrentcover age metricusedby udon canskipcertaininterleavingswherenew values of memory could have been explored.
as a result the invariants are generated based on an incomplete exploratio n of the program.
finally we examine the scalability of our method.
columns and of table i show that on average using ournewllvmbasedfrontendforinstrumentationresultsina five times speedup over the previous daikon front end.
the reason is that daikon s front end for c c called kvasir uses valgrind to dynamically instrument the executabl e everytime itrunstheprogram.whereas udon instrumentsthe program only once at the compile time.
as a result using our newfrontend should providea speed up when analyzingboth sequential and multithreaded c c programs.
table ii shows a breakdown of the invariants generated by udon .
we classified each invariant into one of two categories transition invariants over shared variables and a ll other regular invariants.transition invariantswere ge nerated with respect to the entry and exit of each function.
table ii shows that by considering only transition invariants we can present the user with a more manageable output compared to considering all invariants.
as shown in the previous sectio ns these transition invariants present a concise summary of th e concurrency behavior of a program.figure compares the scalability of three interleaving explorationstrategies implementedin udon .hapset is the default strategy dpor is theoretically the ideal strat egy since it will lead to the most precise results and pcb which is a widely used strategy in the testing literature we used a context bound of two .
in this experiment we ran udon on the indexer benchmark from svcomp varying thenumberofthreadsintheprogram.here the x axisdenotes the number of threads and the y axis denotes the number of interleavings explored by each strategy.
the result shows t hat the number of interleavings quickly explodes under dpor.
under pcb the increase in the number of interleavings is slower since only the interleavings with a bounded number of preemptive context switches are explored nevertheless the growth is still predictably exponential with respect to t he number of threads.
in contrast the increase in the number of interleavings is the smallest under hapset.
to quantify the effect of different interleaving explorati on strategies on the quality of the generated invariants we ra n udon on the benchmarks using hapset pcb and dpor respectively.
for pcb we used a context bound of two.
the results are summarized in table iii.
here we compare the number of runs time and number of incorrect invariants.
an in a column indicates the test took longer thantwohours.column1showsthenameofthetestprogram columns and show the number of runs and time of hapset pcb anddpor respectively.finally columns8 showthenumberofincorrectinvariantsfoundbyeachmethod .
first since dpor provides a sound guarantee to explore all relevant thread schedules it produces no incorrect inv ariants.
however dpor suffers from an exponential increase in run time relative to the length and number of threads in a program.
as a result dpor failed to finish analyzing nbds hashtable while both hapset and pcb were able to finish in a reasonable time.
however if a user desires high invariant accuracy at the cost of longer run time udon is capable of using dpor instead of hapset.
since both hapset and pcb skip interleavings where new memory values could be encountered they both suffer from incorrect invariants being generated.
however on average hapset performs significantly better than pcb in terms of thread count number of iterations ha pset pcb dpor figure .
comparing thethread interleaving exploration s trategies in udon .
tableiii.
detailed comparisonofinterleaving exploratio n strategies in udon .
number of runs run time s incorrect invariants name hapset pcb dpor hapset pcb dpor hapset pcb dpor sync01 safe .
.
.
fibbenchsafe 17k .
.
.
lazy01safe .
.
.
stateful01 safe .
.
.
dekkersafe .
.
.
lamportsafe .
.
.
petersonsafe .
.
.
timevarmutex .
.
.
szymanski .
.
.
inctrue .
.
.
inccas .
.
.
incdec .
.
.
incdeccas .
.
.
reorder 19k .
.
.
accountbad .
.
.
pfscan 56k .
.
nbds hashtable .
.
nbds skiplist01 10k .
.
.
nbds listidx01 .
.
.
average .
.
.
the number of correct invariants created the number of runs explored and time.
for these reasons we selected hapset as thedefaultsearchstrategyin udon itprovidesa goodbalance between precision and scalability.
vii.
r elated work static techniques.
there is a large body of work on using static analysis for invariant generation whose main advantage is that the reported invariants are true for every reachable state of the program.
typically invariants gene rated by these techniques are predicates expressed in some linear abstract domains such as difference logic octagon al or polyhedral.
there are also methods based on constraint solving which can generate more complex invariantssuchaspolynomialandnon linearinvariants.r ecent development along this line includes the work by furia et al.
on generating loop invariants from post conditions and invariants related to integer arrays .
h owever due to the inherent limitations of static analysis th ese methods tend to lack either in precision or in scalability.
o ur method in contrast relies on dynamic analysis.
dynamic techniques.
there is also a large body of work on dynamic invariant generation including tools such as daikon which havebeen highlysuccessful in practice.
the main advantage of dynamic invariant generation is scala bility they have been applied to realistic applications wh ere static techniques fail to scale.
other dynamic invariant ge neration tools include diduce dysy agitator and iodine .
however existing dynamic generation tool sdo not work well on multithreaded programs due to the nondeterminismin thread scheduling.
our contribution udon fills the gap by solving the issue of nondeterminism with respect to dynamic invariant generation.
hybrid techniques.
there are also hybrid techniques for invariant generation which leverage both static analysis an d dynamicanalysisto improveperformance.for example nguyen et al.
proposed a method for generating invariants expressed as polynomials and linear relations over a limite d number array variables.
such invariants have been difficult to generatebyexistingmethods.therearealsohybridtechniq ues basedonrandomtesting andguess and check whic h first generate a set of candidate invariants from concrete execution data and then verify them using smt solvers.
interleaving exploration.
there is a large body of work on using selective interleaving exploration techniques for t esting concurrent programs including contest chess ctrigger calfuzzer penelope and maple and property guided pruning techniques implementedininspect.recentempir ical evaluationsofsuchtechniquescanbefoundin .
however the focusof this paper is not on improvingsoftware testing butonleveragingthe relatedtechniquesforgener ating high quality invariants.
in this sense our work is orthogo nal to these existing methods.
atomicity inference.
various methods have been proposed for inferring atomicity and detecting concurrency bugs.
th ey may rely on static analysis dynamic analysis or symbolic analysis techniques.
however their focus is primar ily on discovering the intended order of conflicting events from different threads.
the thread local transition invariant s generated by our new method is similar to the likely deterministic specifications generated by the determin tool which has its own construct for specification of invariants.
the main difference is that determin relies on a given set of thread schedules whereasin our work differentschedules are generated automatically.
viii.
c onclusions we presented a new method for dynamically generating invariants from multithreaded programs.
we used selective interleaving exploration to simultaneously improve invar iant quality while keeping runtime overhead low.
we also proposed the use of thread local transition invariants to help the user understand the code and diagnose concurrency errors.
we implemented our method and evaluated it on a set of multithreaded c c programs.
our experiments show that whencomparedtothestate of the art suchas daikon ournew method produces better invariants while remaining scalabl e. ix.
a cknowledgments this research was primarily supported by the onr under grant n00014 .partial support was provided by th e nsf under grants ccf ccf and ccf1500024.
any opinions findings and conclusions expressed in this material are those of the authorsand do not necessari ly reflect the views of the funding agencies.