black box fairness testing of machine learning models aniya aggarwal aniyaagg in.ibm.com ibm research ai indiapranay lohia plohia07 in.ibm.com ibm research ai indiaseema nagar senagar3 in.ibm.com ibm research ai indiakuntal dey kuntadey in.ibm.com ibm research ai indiadiptikalyan saha diptsaha in.ibm.com ibm research ai india abstract any given ai system cannot be accepted unless its trustworthiness is proven.
an important characteristic of a trustworthy ai system is the absence of algorithmic bias.
individual discrimination exists when a given individual different from another only in protected attributes e.g.
age gender race etc.
receives a different decision outcome from a given machine learning ml model as compared to the other individual.
the current work addresses the problem of detecting the presence of individual discrimination in given ml models.
detection of individual discrimination is test intensive in a black box setting which is not feasible for non trivial systems.
we propose a methodology for auto generation of test inputs for the task of detecting individual discrimination.
our approach combines two well established techniques symbolic execution and local explainability for effective test case generation.
we empirically show that our approach to generate test cases is very effective as compared to the best known benchmark systems that we examine.
ccs concepts software and its engineering software testing and debugging .
keywords individual discrimination fairness testing symbolic execution local explainability acm reference format aniya aggarwal pranay lohia seema nagar kuntal dey and diptikalyan saha.
.
black box fairness testing of machine learning models.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
introduction model bias.
this decade marks the resurgence of artificial intelligence ai where ai models have started taking crucial decisions in a lot of systems from hiring decisions approving loans etc.
to design driver less cars.
therefore dependability of ai models is of utmost importance to ensure wide acceptance of the ai systems.
one of the important aspects of a trusted ai system is to ensure that permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn .
.
.
.
decisions are fair.
bias may be inherent in a decision making system in multiple ways.
it can exist in the form of group discrimination where two different groups e.g.
based on protected attributes such as gender race get a varied decision or through individual discrimination which discriminates between two samples.
note that discrimination aware systems need to be trained to avoid discriminating against sensitive characteristic features that are termed as protected attributes.
protected attributes are application specific.
features such as age gender ethnicity etc.are a few frequent examples of what many applications practically treat as protected attributes .
individual discrimination.
in this paper we address the problem of detecting individual discrimination in machine learning models.
the definition of individual fairness bias that we use in this paper is a simplified and non probabilistic form of counterfactual fairness which also fits into dwork s framework of individual fairness .
as stated in this work a system is said to be fair if for any two valid inputs which differ only in the protected attribute are always assigned the same class and bias is said to exist if for some pair of valid inputs it yields different classification .
such cases of bias have been previously noticed in models such as and caused derogatory consequences to the model generator.
therefore detection of such cases is of utmost importance.
note that removal of such bias cannot be done by removing the protected attributes from the training data as the individual discrimination may still exist due to the possible co relations between protected and non protected attributes just like the case of race protected and zip code non protected in adult census income dataset.
this is an instance of indirect discrimination for which individual discrimination testing is still required for co related non protected attributes.
the challenge is therefore to evaluate and find that for which all values of non protected and protected attributes the model demonstrates such an individual discrimination behavior.
existing techniques and their drawbacks.
measuring individual discrimination requires an exhaustive testing which is infeasible for a non trivial system.
the existing techniques such as themis aequitas generate a test suite to determine if and how much individual discrimination is present in the model.
themis selects random values from the domain for all attributes to determine if the system discriminates amongst the individuals.
the aequitas generates test cases in two phases.
the first phase generates test cases by performing random sampling on the input space.
the second phase starts by taking every discriminatory input generated in the first phase as an input and perturbing it to generate further more test cases.
both techniques aim to generate more discriminatory inputs.
even though these two aforementioned techniques are applicable to any black box system our experiments demonstrate that they miss many such combinations of non protected attribute esec fse august tallinn estonia aniya aggarwal pranay lohia seema nagar kuntal dey and diptikalyan saha values for which the individual discrimination may exist.
we also look to cover more diverse paths of the model to generate more test inputs.
our approach.
our aim is to perform systematic searching of feature space to cover more space without much redundancy.
there exist symbolic evaluation based techniques to automatically generate test inputs by systematically exploring different execution paths in the program.
such methods avoid generation of multiple inputs which tend to explore the same program path.
such techniques are essentially white box and leverage the capabilities of constraint solvers to create test inputs automatically.
symbolic execution starts with a random input and analyzes the path to generate a set of path constraints i.e.
conditions on the input attributes and iteratively toggles or negates the constraints in the path to generate a set of new path constraints.
it then solves the resultant path constraints using a constraint solver to generate a new input which can possibly take the control to the new path as explained using an example in section .
our idea is to use such dynamic symbolic execution to generate test inputs which can potentially lead to uncovering individual discrimination in ml models.
however existing such techniques have been used to generate inputs for procedural programs which are interpretable.
our main challenge is to apply such technique for non interpretable models which cannot be executed symbolically.
note that similar to themis our goal is to build a scalable black box solution which can be applied efficiently on varied models.
black box analysis will enable ai testing service where a third party machine learning model in the form of an access api can be given as an input along with some payload training data.
challenges.
there exist a few works which try to use symbolic evaluation based techniques for non interpretable models such as deep neural networks although they do not address the problem of finding individual discrimination that may exist in the model.
such techniques are essentially white box and try to approximate the functions relu sigmoid that exist in the network.
therefore they are catered towards a specific kind of networks and are not generalized.
other test case generation techniques use coverage criteria like neuron coverage sign coverage etc.
which are structure dependent and hence such techniques suffer from scalability.
solution overview.
in this paper our key idea is to use the local interpretable model as the path in the symbolic execution.
a local explainer such as lime can produce a decision tree path corresponding to an input in a model agnostic way.
the decisions in the decision tree path are then toggled to generate a new set of constraints.
next we list several advantages and salient features of our approach.
constraints.
it is possible to use an off the shelf local explainer to generate a linear approximation to the path.
the linear constraints obtained from one such explainer can be used for symbolic evaluation which won t require any specialized constraint solver .
data driven.
our algorithm can take advantage of the presence of data which can be used as the seed data to start the search.
global and local search.
once an individual discrimination is found we perform a local search to uncover many input combinations which can uncover more discrimination.
otherwise we perform a global search using symbolic execution to cover different paths in the model.
optimizations.
the local explainer presents confidence associated with the predicates.
our algorithm performs the selection of constraints for toggling based on their confidence scores.
scalability.
our algorithm systematically traverses paths in the feature space by toggling feature related constraints.
this makes it scalable unlike other techniques which consider structurebased coverage criteria.
contributions.
our contributions are as listed next.
we present a novel technique to find individual discrimination in the model.
we develop a novel combination of dynamic symbolic execution and local explanation to generate test cases for non interpretable models.
we believe that the use of local explainer will open up many avenues for path based analysis of black box ai models.
we demonstrate the effectiveness of our technique on several open source classification models having known biases.
we empirically compare our technique with the existing algorithms i.e.
themis aequitas and demonstrate the performance improvement delivered by our approach over these prior works.
outline.
section presents the required background on dynamic symbolic execution and local explainability.
in section we present our solution while concentrating on the various challenges that we have faced to successfully combine the idea of symbolic execution with the local explanation.
further in section we present our experimental setup and the results.
next we discuss the related prior work in section while section mentions a brief summary along with the possible future extensions of this work.
background .
notation and individual discrimination let us consider a dataset dwith the set of attributes defined as a a1 a2 .
.
.
an where p adenotes its set of protected attributes.
we use x x to represent two data instances where x x d. each data instance is an n tuple x xi .
.
.
xn where xidenotes the value for aiin data instance x. the domain of attribute aiis denoted as dom ai .
say a model mis trained on the training data t d then m x denotes the output of this model on an input x. formally an individual bias instance is a pair x x of input samples such that xi x ifor all ai pand j xj x j where aj pandm x m x .
note that we use a strict notion of equality for all non protected attributes which does not consider various issues such as equality in case of continuous attributes possible co relation between attributes etc.
however the focus of the paper is to perform systematic test case generation with respect to a definition of individual fairness and therefore handling the above issues are considered as possible future extensions.
.
dynamic symbolic execution dynamic symbolic execution dse performs automated test generation by instrumenting and running a program while collecting execution path constraints for different inputs.
it systematically toggles the predicates present in a set of path constraints 626black box fairness testing of machine learning models esec fse august tallinn estonia algorithm generalized dynamic symbolic execution 1count 2inputs seed test inputs 3priorityq q empty q.enqueueall inputs 4while count limit !q.isempty do t q.dequeue check for error condition t path p getpath t prefix pred true foreach predicate cin order from top of path do path constraint prefix pred toggle c if!visited path.contains path predicate then visited path.add path predicate input solve path constraint r rank path constraint q.enqueue input r end prefix pred prefix pred c end count 20end to generate a new set of path constraints whose solution generates new inputs to further explore a new path.
note that this technique caters for path coverage and hence does not generate any redundant input.
the path coverage criteria states that the test cases are executed in such a way that every possible path is executed at least once.
it is further to be noted that the path coverage criteria are stronger than branch decision coverage and statement coverage.
next we formally present a generalized version of the above algorithm in algorithm which can be used as a framework to generate test cases for ai models.
we further discuss the changes in this generalized version as compared to the algorithm for dynamic symbolic execution used in dart .
the first change relates to the inputs the algorithm starts with.
instead of starting from a random input the algorithm finds one or more seed inputs to start with line .
seeds can also be generated at random.
the second change lines is related to the abstraction of the ranking strategy of selecting which test inputs to execute next.
please note that the rank function now determines which input should be processed next.
the third change is an addition of the check to detect if a path is already traversed or not line .
such checks are not required in symbolic execution for programs as the selection of predicates for toggling ensures that an already traversed path will not be traversed again.
however in an environment where path generation does not guarantee preservation of predicates in the path this is a necessary check to avoid generating redundant inputs.
the generation of constraints lines corresponding to the generalized algorithm is illustrated in figure .
note that the other variables not present in the constraint can take any value from its possible domain.
.
local explainability local interpretable model agnostic explanations lime consists of explanation techniques that explain any prediction of any classifier or regressor in an interpretable and faithful manner.
it is able to do that by approximating it as an interpretable model locally around the prediction.
it generates explanation in the form of interpretable models such as linear models decision trees or falling rule lists which can be easily comprehended by the user with visual ortextual artifacts.
given an input data instance and its output as generated by the classifier lime generates data points in the vicinity of the instance by perturbation of the input data point and generates the output.
using such input and output it learns an interpretable model by maximizing local fidelity and interpretability.
we use lime to explain a prediction instance for a model and generate a decision tree as interpretable model for a prediction.
algorithm in this section we discuss our overall solution approach spread across the subsequent three subsections.
the first sub section discusses the goals of our test case generation technique under different conditions.
we divide our algorithm into two different kinds of search algorithms called global search and local search.
the next two sub sections devout on these respective searches.
.
problem formulation below are the two optimization criteria that we want to achieve through the devised test case generation technique.
effective test case generation given a model m a set of domain constraints cand protected attribute set p the aim is to generate test cases to maximize the ratio of succ gen where gen is the set of non protected attribute value combinations generated by the algorithm and succ gen that leads to discrimination i.e.
each instance in succ yields at least one different decision for different combinations of protected attribute values.
here are a few salient points about this criteria.
test case each test case is not considered as the collection of the values of all the attributes but only non protected attributes.
this ensures that multiple discriminatory test cases are not counted for the same combination of non protected attribute values.
domain constraints we assume that applying domain constraints cwill filter out unreal test cases.
order of generation and discrimination test the optimization criteria does not specify if all the test cases are generated at once or whether check for discrimination and generation can go handin hand.
this way the test case generation can be dependent on discrimination checking as well.
in the software testing domain there exists a number of predefined coverage criteria.
many such coverage criteria have also been defined in recent works on machine learning .
next we define the path coverage criteria such that it is applicable for varied types of models.
coverage criteria note that defining path coverage criteria for anyblack box model is not straightforward.
it is possible to define figure generation of path constraints 627esec fse august tallinn estonia aniya aggarwal pranay lohia seema nagar kuntal dey and diptikalyan saha algorithm individual discrimination checker 1function generate test cases seed model cluster count limit rank rank rank count priorityq q seed test input seed cluster count limit rank while count limit !q.isempty do t q.dequeue found check for error condition t path p get path model t iffound then local search foreach predicate cin order from top to bottom of pdo path constraint p.constraint ifcis of protected attribute then continue path constraint.remove c path constraint.add not c if!visited path.contains path constraint then visited path.add path constraint input solve path constraint t r average confidence path constraints q.enqueue input rank2 r end end end global search prefix pred true foreach predicate cin order from top to bottom of pdo ifcis a protected attribute then continue ifc.conf idence t1then break path constraint prefix pred not c if!visited path.contains path constraint then visited path.add path constraint input solve path constraint r average confidence path constraints q.enqueue input rank3 r end prefix pred prefix pred c end count end return 39function get path model input set in out inout lime localexpl model input return gendecisiontree inout 42function seed test input data cluster count limit rank i priorityq q empty clusters kmeans data cluster count while i max size clusters do ifq.size limit then break end foreach cluster clusters do ifi size cluster then continue end row cluster.get i q.enqueue row rank1 end i end return q 60function check for error condition t class m t foreach val0 .
.
.
valn ai p vali dom ai do try combination of protected attribute values tnew replace value of aiintwithvali class1 m tnew ifclass1 !
class then return individual discrimination found end end return individual discrimination not found path for different types of models based on their operational characteristics.
for instance it is possible to define a path in a neural network based on the activation of neurons similar to the branchcoverage defined in and decision paths in a decision tree classifier.
we define the coverage criteria as follows.
given a classification model mand a set of test cases t we define the coverage of tas the number of decision regions of mexecuted by t. in this paper we use a decision tree classifier to approximate the behavior of the model m. we generate highly accurate decision tree model to approximate the decision regions of m. the aim of our test case generation technique is to maximize both the path coverage and the individual discrimination detection.
in practice there is always a limit to the automatic test case generation process within which maximizing both the objectives needs to be done.
in our case we consider two such possible limits the number of generated test cases and the time taken to generate.
in the subsequent subsections we present our algorithm that intends to maximize path coverage and effectively detects discrimination and the way to combine them both.
.
maximizing path coverage path coverage maximization is carried out by leveraging the capabilities of symbolic execution algorithm which is catered towards the systematic exploration of different execution paths.
in this subsection we describe the various functions that are kept undefined in algorithm .
the final algorithm is presented in algorithm .
maximizing the path coverage is done in the global search module as mentioned in our final algorithm presented in algorithm .
path creation.
let us start with the get path method.
as mentioned in section our key idea is to use the set of input output as generated from a local explainer lime.
our algorithm learns the decision tree using the input and output instead of the linear regression classifier as in the original implementation of lime refer line in algorithm .
with above definition of get path method the algorithm works in the same way as the symbolic execution algorithm which can negate the conditions present in the decision tree path to generate new set of constraints that can then be solved using a constraints solver to generate further new inputs that can traverse other paths.
there are three major challenges associated with the straightforward application of the idea of symbolic execution and local model approximating a path.
the first two arise due to the inherent approximation present in the local model while symbolic execution is the reason for the third one.
approximation the decision tree path approximates the actual execution path in terms of interpretable features.
because of such an approximation duplicates of the actual program path can be generated.
confidence decision tree path has a confidence score associated with all its comprising predicates which was not the case for a program path .
therefore the challenge lies in devising a way to use this confidence score for better exploration of the paths.
symbolic execution in program testing suffers from path explosion problem especially in the depth first search way.
it can keep on exploring paths in the depth of the program tree without exploring paths in other parts of the program.
researchers have explored various techniques to address 628black box fairness testing of machine learning models esec fse august tallinn estonia this problem applying demand driven or directed technique which generates test cases towards a particular location in the program and compositional techniques which try to analyze various functional modules separately before combining them to generate longer paths in the whole program.
all these techniques exploit the structure of the program under test.
addressing path explosion.
to resolve the path explosion problem such that the path generation does not concentrate only on a few localized portion of the entire space we exploit the distribution present in the data training or testing if available.
each data instance can be a good starting point of the symbolic search.
therefore we add the data as the seed test data as shown in method at line given in algorithm .
however the order of data instances become important when a search limit is imposed due to which execution of all the data instances is not possible.
therefore to increase the diversity in search we cluster the data and process seed inputs from each cluster in a round robin fashion.
addressing local model approximation.
we use an off the shelf local explainer lime to fetch the interpretable local model.
the perturbation used in such an explainer is outside the scope of the present algorithm therefore it is not possible to reduce the error caused by the local approximation.
note that the approximation can lead to production of test inputs which do not uncover any new path in the model.
however by introducing the data instances in the seed our algorithm addresses the above issue.
our algorithm further ensures that the seed inputs get more priority than the inputs generated by the constraint solver during symbolic execution.
this ensures high degree of varied path coverage.
ranking based on confidence.
automated test case generation procedure typically runs within a limit.
it is therefore important to generate non redundant test inputs and cover as much as path covered by the generated test inputs within the limit.
for the test cases generated by the constraint solver we use a ranking scheme based on the confidence of predicates in the decision tree to select which test input to execute next.
the confidence of a path is determined by taking an average of the confidence of all its comprising predicates line algorithm .
therefore when the algorithm selects a predicate cfor negating it considers the rank as the average confidence of the predicates in the prefix of the path leading to and including c. confidence threshold.
the lesser the confidence of a predicate in the decision tree path the lesser is the chance of generating varied inputs.
therefore to remove unnecessary generation of inputs through symbolic evaluation our algorithm employs a threshold on the confidence of the predicate for selection line algorithm .
the value of the threshold is obtained through experimentation.
.
maximizing effectiveness of discrimination detection in this subsection we discuss a few more changes that we have employed on the generic algorithm in order to maximize the detection of individual discrimination.checking individual discrimination to start with let us consider the case of checking individual discrimination which is carried out in the method check for error condition as presented in algorithm .
the algorithm performs the check as per the definition of individual discrimination.
a test case is said to be individually discriminatory if keeping the values of its set of non protected attributes same but changing the values of its protected attributes set by trying every possible combination yields different class labels.
local search the symbolic execution as discussed in earlier sections tries to find test inputs to maximize the path coverage.
we call such a symbolic search strategy the global search .
some of the test inputs generated through seed data or symbolic execution will be discriminatory in nature.
to increase the likelihood of discriminatory test cases we exploit the fact that we can execute test cases and check whether they are discriminatory and then depending on that generate more test cases.
once a discriminatory test case say tis found we try to generate further more test inputs which may lead to individual discrimination.
the key idea is to negate the non protected attribute constraints oft s decision tree to generate more test inputs.
by toggling one constraint related to non protected attribute and generating an input solving the resultant constraint the algorithm tries to explore the neighborhood of discriminatory path p. this form of symbolic execution is what we call as local search as it tends to search the locality of discriminatory test cases.
the reason why this works is due to the inherent adversarial robustness property of a machine learning model which demonstrates that a small perturbation of an input can result in changing the classifier decision .
sticky solutions.
the aim of the local and the global search is to traverse as many paths as possible.
the local search concentrates on exploring the paths in the vicinity of the discriminatory paths i.e.
the paths that are generated from discriminatory inputs.
therefore we only get one solution for the constraint.
however to cater to the possible approximation caused by the local linear model we use the constraint solver s solution that is close to the solution of the previous constraint related to discriminatory input .
we call such a solution as a sticky solution .
because of the stickiness if we negate one predicate then for the remaining predicate it tends to take the same values as in its previous solution.
in section we demonstrate that sticky solution provides a huge performance improvement over the existing works.
the algorithm for test case generation to detect individual discrimination is presented in method generate test cases given at line algorithm .
lines describe the local search whereas lines describe the global search.
there are two major differences between the implementations of the local and global search.
the first difference is that no threshold based constraint selection is done in local search.
in contrast during global search only the high confidence constraints are chosen for toggling.
the reason behind this strategy is to increase the chances of diverse coverage of paths.
the second difference is that in global search no constraint exists for suffix of the path whereas in local search all constraints except the selected low confidence one to toggle remain as it is.
629esec fse august tallinn estonia aniya aggarwal pranay lohia seema nagar kuntal dey and diptikalyan saha ordering local and global search.
in the consolidated algorithm three reference ranks namely rank rank 2andrank 3are presented one each for seed input local search and global search respectively.
these ranks are set in such a way that the highest priority is given to local search followed by the seed input which is further followed by the global search based on their ability to uncover discrimination causing inputs see lines of algorithm .
in the next section we experimentally show the effectiveness of various optimizations described in this section along with comparisons with the existing works.
experimental evaluation .
setup .
.
benchmark characteristics.
we have conducted our experiments on eight open source fairness benchmarks from various sources as listed in table .
.
.
configurations.
our code is written in python and executed in python .
.
.
all the experiments are performed in a machine running ubuntu .
having 16gb ram .4ghz cpu running intel core i5.
we have used lime for local explainability.
we have used k means with cluster size 4to cluster the input seed data.
since our use case requires generation of more test cases in lesser time k means being one of the simplest and fastest clustering algorithms proves to be a reasonable choice.
the fact that the data sets used to run our experiments have either two or four true class labels drives the logical assumption to set the cluster count as .
this was further validated using a scatter plot shown in figure which clearly depicts four different clusters in the seed data.
for each benchmark we have generated a model using logistic regression with its default configuration as provided in scikit learn .
the model is configured similar to the one used in themis in order to ensure fair comparison.
the models are highly precise accuracy to avoid overfitting.
the threshold t1 proposed earlier in algorithm is set to t1 .
.
the justification for choosing this value of threshold has been experimentally validated later in this section.
.
experiment goals by conducting our set of experiments we broadly try to achieve two goals as mentioned below.
table benchmark characteristics benchmark size features count domain size german credit data11000 .
adult census income232561 .
bank marketing345211 .
us executions41437 .
fraud detection51100 .
raw car rentals6486 .
credit data1 modified .
census data2 modified .
with the existing works the intention is to gauge how well does our algorithm perform as compared to the existing works in the field of test case generation to find individual discrimination in models.
we compare our approach with two existing systems a themis which checks the individual discrimination by random test case generation and b aequitas which performs both random global search and perturbation based local search.
we have used success score i.e.
succ gen as an appropriate metric for evaluation where succ denotes the subset of the generated test cases i.e.
gen which results in individual discrimination.
please note that the same metric as ours has also been used in other related works such as themis and aequitas.
furthermore precision and recall as evaluation metrics are more appropriate when we have fixed gold standard data.
a detailed theoretic comparison with both the approaches is presented in the forthcoming section .
in this paper we refer our algorithm as sg which stands for symbolic generation in all our subsequent discussions.
effect of algorithmic features the motive is to find out how well does each algorithmic feature such as symbolic execution in local and global search presence of data etc.
contribute towards finding individual discrimination.
figure scatter plot for clustered seed data and discriminatory inputs black for german age data .
comparison with related work .
.
comparison with themis.
we have fetched themis code from their github repository.2on carefully analyzing their code we figured out an unintended behavior in the open sourced code.
themis actually generates duplicate test cases and their reported experimental statistics also contains these duplicates.
this is one of the problems posed by random test case generation as it can produce duplicate test cases.
we have changed themis s code to remove duplicates for our experimental evaluations.
table depicts the results of the comparison with themis.
it can be inferred from the results that our algorithm performs better than themis except in the case of one benchmark i.e.
fraud detection.
themis has an average success score succ gen of .
but for our algorithm it is .
.
it is evident that across benchmarks our algorithm generates times more successful i.e.
the ones that resulted in discrimination test cases than themis.
it is further to be noted that the maximum percentage of discriminatory test 630black box fairness testing of machine learning models esec fse august tallinn estonia table comparison of sg with themis bench.
prot.
attr.
themis sg gen succ gen succ german credit gender german credit age adult income race adult income sex fraud detection age car rentals gender credit i gender census h race census i sex bank marketing age us executions race us executions sex table contribution of different features bench.
data local symb.
global symbolic gen succ gen succ gen succ german credit gender german credit age adult income race adult income sex fraud detection car rentals credit census race census sex bank marketing us executions race us executions sex cases as generated by sg is which is also very high as compared to themis s .
in table we report the contribution of different test case generation features such as seed data global symbolic search and local symbolic search towards the aforementioned success.
the data refers to the case where test instance itself is the data point available in the input seed data.
global and local symbolic search refer to the cases where test cases are generated by employing symbolic execution in the global search and local search respectively.
please note that the contribution of each of these searches is dependent on the previously executed search.
table does not aim to compare the effectiveness of these individual searches but records whether a test case is generated in the data local global symbolic search phase thus drilling down on results of table .
the results show the effect of our relative ranking strategy which specifies the order of preferences for local symbolic seed data and global symbolic in the decreasing order.
please note that on an average the success percentage for data and local symbolic execution are .
and .
respectively.
we have performed an another experiment where we try to make the same comparison with themis but by varying the time limit instead of considering a fixed limit of test cases to be generated.
essentially we conducted this test to check that within a given time limit whether sg performs better than themis or not.
considering that our algorithm requires local model generation and running constraint solver this experiment also takes into account the time taken by such components in our algorithm.
this result also depicts the time required for test case generation by our algorithm.
we experimented with german credit dataset with age as its protected attribute and run both themis and sg for 000secs.
interestingly at any given instant the number of test case generated by sg is moretable time limit wise comparison between themis and sg for german credit dataset duration themis sg secs gen succ gen succ table number of discriminatory test cases generated through global search for adult dataset with limit model type aequitas sg decision tree random forest multi layer perceptron than that of themis.
the reason is that random sample generation takes a lot of time as it still conforms to the constraints of the domain whereas sg takes very little time to generate samples from seed and lime constraint solver based local and global test case generation is also quite fast.
most importantly within the same limit the number of discriminatory test cases for themis is much lower as compared to sg which is well evident by the results in table .
.
.
comparison with aequitas.
the aequitas algorithm operates in two search phases global and local.
the global phase considers a limit on the count of test cases and generates them by random sampling of the input space.
out of all these generated test cases a few of them are discriminatory in nature.
the local phase then starts by taking each of the discriminatory inputs identified in the global search phase as an input and perturbs it to generate further more test cases.
this phase just like the previous global search considers a limit on the number of test cases to be generated.
they have applied three different types of perturbation resulting in three different variations of the algorithm.
as we have similar phases in our algorithm too therefore we perform phase by phase comparison with aequitas by considering the same limit.
we have fetched the code for aequitas from their github3repository and run it for comparison.
global search comparison.
table presents a comparison of sg with aequitas in context of their global search strategy.
our global search method uses clustered seed data and symbolic execution whereas their strategy uses random sampling of the input space.
it is evident from the statistics that in general our algorithm generates more discriminatory inputs othan aequitas.
local search comparison.
aequitas perturbs the available discriminatory test input to find even more discriminatory inputs.
in contrast sg s local search is still symbolic which helps to discover more execution paths near the discriminatory paths.
to accurately compare both the local searches we have run them considering thesame set of discriminatory inputs and the same models for the adult dataset.
please note that aequitas open source code has 631esec fse august tallinn estonia aniya aggarwal pranay lohia seema nagar kuntal dey and diptikalyan saha table number of discriminatory test cases generated through local search for adult dataset with limit model type aequitas sg decision tree random forest multi layer perceptron hard coding for the adult dataset and therefore we could only perform the comparison experiments on that dataset but for all the three different model types.
table presents the comparison of the number of discriminatory inputs generated by both the approaches within the limit of test cases.
in two out of three cases sg s local search performs better than that of aequitas s. in case of multi layer perceptron sg s poor performance is attributed to the error in local model approximation by lime.
.
path coverage we perform an experiment to compare the path coverage of our global search and random data based search.
the random data based search has been applied for both themis and aequitas.
therefore this experiment presents the comparison with the existing related works.
to perform the path coverage we learn a decision tree model with a precision of measured using fold cross validation for each benchmark and map each generated test input to a path of the decision tree model.
the results in table show that on average over all the benchmarks sg has .
times more path coverage than random data.
this result demonstrates that on the path coverage metric we are superior to other algorithms.
therefore our algorithm will be able to find discriminatory inputs at various different places in the model.
this is important as at one shot we can de bias multiple parts of the model if we use the test cases for retraining.
.
importance of seed data we conducted two experiments for determining the importance of seed data and related features.
in both the experiments we compare the training data with random data as seed data.
in the first experiment shown in table we switch off the global and local symbolic execution so that all the test cases are generated from the seed data i.e.
the training data.
in the second experiment we keep both the symbolic searches.
both the experiments are performed with a limit on the number of test cases generated.
the third experiment compares the path coverage of training data vs. the random data.
limited number of test cases the results from the first experiments in table demonstrates the importance of the seed data.
the results show that for all benchmarks the number of discriminatory test cases generated from seed training data is more than that of table path coverage of sg global search vs random benchmark limit random sg global adult census credit german age 187random data.
we see that just by applying training data without any symbolic search we get an average improvement of to in comparison with random data.
this implies that in global search more discriminatory examples can be obtained with training data.
this result also demonstrates why our global search method is superior to themis and aequitas to find discriminatory inputs.
the second experiment in table shows the effectiveness of symbolic evaluation even if we start with the random input.
for example in the credit data we see that random data got successful test cases and is less effective than training data which has got successful test cases.
importance of clustering of seed data.
figure shows the distribution of the seed data and the discriminatory inputs found.
it also demonstrates that the discriminatory inputs are scattered across the input space a proof why random exploration of the input space is not effective in finding discriminatory inputs.
figure shows the use of diverse seed data ordering got getting individual discrimination.
when the number of test cases is limited then we expect that diverse ordering round robin will fetch more discrimination than iterative ordering.
it is evident from the figure that for most number of test cases the number of discrimination found is higher for round robin selection from clusters is more effective than iterative selection.
for example in the execution of test cases round robin selection found discriminatory inputs compared to found by iterative selection.
note that even on using random data as seed our global symbolic search performs well as discussed in the next subsection.
table training vs random seed data no symbolic execution bench.
training data random gen succ gen succ credit german age census sex car table random seed data with symbolic succ gen bench.
random total seed local symbolic global symbolic credit german age census sex car figure importance of clustering german age 632black box fairness testing of machine learning models esec fse august tallinn estonia table global symbolic search w o local with random seed data succ gen bench.
total seed local global total random credit german age census sex car .
importance of global symbolic search to determine the effectiveness of global symbolic search we performed an experiment where we removed the local symbolic search to emphasis on the global search part and we assigned the higher priority to the global symbolic search than the seed data.
since the seed data selection may also affects the symbolic search we used random data as seed data.
the result of the experiment is shown in table .
we see that in case of credit effectiveness is little lower vs as symbolic search could not find any discriminatory cases generated in the generated test cases.
in all the other three cases global symbolic search alone is able to generate more discriminatory test cases than random search.
importance of threshold in the global symbolic search we experimented with the global search threshold for benchmarks and the result is shown in figure .
the result shows that in most cases the lower threshold causes decrease in the ratio of discriminatory inputs.
therefore we have chosen the threshold to be .
which balances the number of test case generated and the effectiveness of generation.
.
importance of local symbolic search based on the previous experiments we notice that local symbolic search has a high percentage .
of effectiveness.
we conduct another experiment to see how we local symbolic search affects the overall execution of the algorithm given a limit on the number of test cases .
the results by switching off the local symbolic search feature is presented in table .
we should compare this result with the results in table for the benchmarks.
we see that the average effectiveness drops from .
to .
for these benchmarks by removing the local symbolic search feature.
this shows the importance of the local symbolic search technique.
overall our experiments demonstrate that local symbolic search uncovers many bias instances after finding the discriminatory input.
figure importance of thresholdtable without local symbolic search succ gen bench.
total seed local global credit german age census sex car for initial fault finding seed data works better than the global symbolic search.
.
threats to validity nature of data inputs.
our approach works well on the data sets containing both numeric and categorical attributes or a mix of them.
however it doesn t handle very high dimensional data such as image sound or video in its current state due to a limitation posed by our local explainer lime.
note that our algorithm is generic to any local explainer.
so lime can be replaced by any sophisticated explainer such as grad cam in the image domain to make it work for the high dimensional data.
relevance of benchmarks and models used.
the benchmarks used to evaluate this work are well known in the field of fairness and are used in the related works such as themis and aequitas as well.
further we have picked the same models to conduct our experiments as the ones used in these works.
protected attributes.
we consider only one protected attribute at a time per benchmark for our experiments.
however considering multiple protected attributes will not hamper the coverage or effectiveness offered by our novel search technique but will certainly lead to an increase in execution time.
this increase is attributed towards the fact that the algorithm in such a case needs to consider all the possible combinations of their unique values.
related work this section discusses the existing works spread across two related spheres model testing and individual discrimination detection.
ai model testing.
first we present the works which are capable to perform symbolic or concolic based test case generation for ai models.
deepcheck uses a white box technique which performs symbolic execution on deep neural networks with the target of generating adversarial images.
another related work performs concolic execution concrete and symbolic on deep neural networks.
their technique is also white box with the goal of ensuring coverage of deep neural network by systematic test case generation.
they model the network using linear constraints and use a specialized solver to generate test cases.
wicker et al.
aim to cover the input space by exhaustive mutation testing that has theoretical guarantees while in gradient based search algorithms are applied to solve optimization problems.
in addition sun et al.
leverage the capabilities of linear programming.
all above techniques are white box as compared to our blackbox solution approach.
we use an off the shelf solver to generate test cases.
the aforementioned approaches try to consider test generation to create adversarial input in the image space while our technique addresses a new problem domain trust and ethics .
633esec fse august tallinn estonia aniya aggarwal pranay lohia seema nagar kuntal dey and diptikalyan saha individual discrimination detection.
themis uses the notion of causality to define individual discrimination.
even though they use a black box technique their technique employs random test case generation approach instead of a systematic one.
however they envision the use of systematic test case generation techniques in their paper as future work.
aequitas randomly samples the input space to discover the presence of discriminatory inputs.
then it searches the neighborhood of these inputs to generate further more inputs.
therefore their global search technique is based on random search while the local search is performed by perturbing discriminatory inputs.
however their approach still differs from ours in the context of global search and local search techniques.
for global search they perform random sampling on the input space while we use clustered seed data and symbolic execution to systematically uncover the first set of discriminatory inputs.
the effectiveness of their technique completely depends on where the discriminatory inputs are placed.
as we have already demonstrated in section our global search performs better than random sampling because of the combination of clustered seed data and symbolic execution used in our technique.
in the context of local search the two techniques differ in the way that they perturb.
aequitas perturbs the input by a factor of .
to start with and selects attributes with a probability p which is set as uniform across non protected attribute at the start .
the probability of selection and is further updated depending on their three different strategies namely random semi directed and fully directed.
in contrast our selection of attributes is based on the confidence of the predicates associated with the attributes and the change or perturbation is performed based on the constraints found in the approximated decision tree path.
aequitas tends to generate test data points in the vicinity of the discriminatory test cases which may or may not explore new paths but our algorithm makes use of symbolic execution which results in exploration of new paths near the discriminatory ones.
furthermore our perturbation scheme does not consider any pre determined offset like the one used in aequitas.
fairtest uses manually written tests to measure four types of discrimination scores.
their idea is to leverage indirect co relation behavior existing between attributes e.g.
salary is related to age to generate test cases.
fairml uses an iterative procedure based on an orthogonal projection of input attributes to enable interpretability of black box predictive models.
through such an iterative technique one can quantify the relative dependence of a black box model on its input attributes.
the relative significance of the inputs with respect to a predictive model can then be used to assess the fairness or discriminatory extent of such a model.
despite being black box techniques none of these existing individual discrimination techniques uses systematic test case generation.
to the best of our knowledge we are the first ones to present a black box solution approach capable of generating test cases systematically with the intention of detecting individual discrimination in ai models.
conclusion and future work in this paper we present a test case generation algorithm to identify individual discrimination in machine learning models.
ourapproach combines the notion of symbolic evaluation which systematically generates test inputs for any program with local explanation that approximates the execution path in the model using a linear and interpretable model.
our technique offers an additional advantage by being black box in nature.
our search strategy majorly spans across two approaches namely global and local search.
global search caters for path coverage and helps to discover an initial set of discriminatory inputs.
in order to achieve that we use seed data along with symbolic execution while considering approximation existing in the local model and intelligently using the confidence associated with the path constraints fetched from the local model.
further local search aims at finding more and more discriminatory inputs.
it starts with the initial set of available discriminatory paths and generates other inputs belonging to the nearby execution paths thereby systematically performing local explanation while banking on the adversarial robustness property.
our experimental evaluations clearly show that our approach performs better than all the existing tools.
symbolic testing of machine learning models is bound to pave way for a number of efforts in future some of them are listed below.
a generic framework for testing.
our global search method is a generic way of testing any black box ml model and not just a method towards solving individual discrimination.
for a different problem there may be a need to change the implementation of only check for error condition function especially if the modality remains the same.
local model generation.
in this paper we are very much dependent on lime which is a local model generator.
the approximation caused by the local model does have a role to play as far as the effectiveness of systematic exploration is concerned.
in future we want to investigate how we can generate a more effective and efficient local model for better exploration.
model path definition.
for testing neural networks we can use neuron activation to precisely define path.
global approximation.
we have used a local approximation as a way to get an interpretable portion of the model.
intuitively that decision goes with the on demand exploration strategy which does not require re engineering of all the parts of a model.
also local model generation does not require any training data.
in future we also wish to investigate the global approximation algorithm like trepan in order to create decision tree models and perform symbolic execution on such a decision tree in case of availability of training data.
adversarial robustness.
there exists many white box approaches addressing the problem of finding adversaries.
in future we may investigate if such techniques can be applied in case of black box testing to detect individual discrimination.
hybrid search strategy.
our algorithm gives preference to local search over the global one and seed data over global search.
finding an interleaved strategy can be another direction to pursue in future.
explaining source of individual discrimination and de biasing.
once an individual discrimination is detected in a model we would like to uncover its root cause especially by mapping it to the training data.
we envision the use of influence function to achieve this.
once we figure out the training data instance and their attributes responsible for bias it is then possible to de bias the model by either removing or appropriately perturbing the training data instances.
634black box fairness testing of machine learning models esec fse august tallinn estonia