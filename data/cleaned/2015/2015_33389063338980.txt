preference wise testing for android applications yifei lu minxue pan juan zhai lyf smail.nju.edu.cn mxp nju.edu.cn zhaijuan nju.edu.cn state key laboratory for novel software technology software institute nanjing university nanjing chinatian zhang xuandong li ztluck nju.edu.cn lxd nju.edu.cn state key laboratory for novel software technology department of computer science and technology nanjing university nanjing china abstract preferences the setting options provided by android are an essential part of android apps.
preferences allow users to change app features and behaviors dynamically and therefore need to be thoroughly tested.
unfortunately the specific preferences used in test cases are typically not explicitly specified forcing testers to manually set options or blindly try different option combinations.
to effectively test the impacts of different preference options this paper presents prefest as a preference wise enhanced automatic testing approach for android apps.
given a set of test cases prefest can locate the preferences that may affect the test cases with a static and dynamic combined analysis on the app under test and execute these test cases only under necessary option combinations.
the evaluation shows that prefest can improve .
code coverage and .
branch coverage and find five more real bugs compared to testing with the original test cases.
the test cost is reduced by for both the number of test cases and the testing time compared to testing under pairwise combination of options.
ccs concepts software and its engineering software testing and debugging .
keywords android apps android testing preference wise testing acm reference format yifei lu minxue pan juan zhai tian zhang and xuandong li.
.
preference wise testing for android applications.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
https corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn .
.
.
.
introduction the last decade has witnessed a rapid growth in android apps drawing attention from both academia and industry.
to cope with the ever changing market demands android app developers have to work in fast development cycles causing a growing need for costeffective testing approaches.
automatic generation of test inputs aiming at the fully automatic testing of android apps as an example has been prosperous since then.
for mobile apps on all platforms it is often the case that there are some setting options designed to allow users to change app features and behaviors and in android it is the preference .
by using preference users can switch among different gui styles change the behaviors of certain functions and enable or disable services etc.
while preference offers users the ability of customization unfortunately for developers the resulting diverse gui displays and app behaviors require more testing under different preference options.
indeed an app may work well in one setting of preference options while crash in another.
to properly test an app s behavior under different preference options which we call the preference wise testing can be challenging.
the specific preferences used in one test case is typically not explicitly specified and existing tools have not considered the impacts of preferences on app behaviors during testing.
black box testing captures app status from guis.
since changing preference options usually causes just slight or even no changes in guis preferences are mostly ignored.
as for while box testing since a key value mechanism is used for preference access where the keys are typically dynamically generated techniques such as symbolic execution are required for the accurate prediction of keys.
however symbolic execution is predominantly known to be suffering from scalability issues which is even worse for android apps due to the event driven nature and the application development framework adf .
therefore despite of the recent progresses in mobile testing testers are still forced to manually set preference options or try different option combinations for the same test case if they want to perform preference wise testing.
in this paper we propose the problem of preference wise testing for android apps and present the prefest approach.
prefest is built on two key observations.
our first observation is that a test case typically interacts with just a few preferences defined in the app.
so for each test case prefest analyzes the preferences that may impact the app behavior which we call test case relevant preferences and executes test cases only under relevant preference option combinations.
specifically given an android app prefest first leverages esec fse august tallinn estonia yifei lu minxue pan juan zhai tian zhang and xuandong li a static analysis to identify the preference structure that contains all the preferences defined in the app.
then in a dynamic analysis it executes the test cases and logs the execution flows to pinpoint the relevant preferences to each test case.
finally it re executes test cases only under relevant preference option combinations to reach previously uncovered code.
to further reduce the test cost we exploit our second observation that android apps often share app states globally using the keyvalue mechanism.
so under one preference option combination a piece of code executed in different test cases often produces the same app behavior and therefore does not require re executions.
we equip prefest with a reduction strategy named target mode which splits the app code into blocks and performs a further analysis of the relevance between the preferences and the code blocks.
for one code block referred as target prefest will execute it only if it has not been executed by previous test cases.
prefest can enhance the performance of existing automated testing tools.
in addition it can be a useful complement to manual testing.
in practice developers and testers are often not the same group of people.
identifying relevant preferences for test cases and testing apps under adequate preference options can be a costly or even tough job for testers.
this is where prefest can be handy since it is all automated and the manual effort can be saved.
the main contributions can be summarized as a novel problem of preference wise testing and also a fully automated solution prefest to improve the efficacy of existing testing approaches by considering the effects of preferences multiple techniques employed in analyzing the impacts of preferences to android testing including the loading patterns for preference identification the analysis for relevant preferences acquisition and the target mode for test cost reduction a prototype also named prefest and an empirical study on real world apps showing that prefest achieves .
and .
improvement in code and branch coverages respectively and detects five more real bugs.
the paper is organized as follows.
sec.
introduces the background and motivation of our work.
sec.
provides the overview and the details of the prefest approach.
sec.
presents the experimental evaluation.
related work is discussed in sec.
and conclusion is drawn in sec.
.
background motivation .
background in android gui pages containing preferences are called setting screens .
to use setting screens in an app a programmer needs to define resource files in xml format to describe the preferences in each setting screen invocations of preference related apis in source code to specify the loading location of each setting screen and the accesses of preferences in source code.
listing shows a simplified resource file for a setting screen.
the top level tag preferencescreen defines the container for a setting screen.
each contained element represents a preference of different types such as listpreference andcheckboxpreference in listing .
to perform preference wise testing we need to obtain the essential details for each preference including key the uniquename to refer to the preference in source code title the text displayed in the setting screen defaultvalue the initial value of the preference and entryvalues the possible options can be set to the preference.
as listing shows these details are coded in the resource files which can be retrieved by static analysis.
preferencescreen checkboxpreference key widget update location pref key title update location defaultvalue false ... listpreference key widget theme pref key title widget theme entryvalues dark light ... ... preferencescreen listing sample resource file for preferences for an app to load a setting screen defined in the resource file the most common way is to call the api method addpreferencesfromresource with the resource file as its parameter upon the creation of an activity or a fragment i.e.
within their lifecycle methods oncreate .
a special setting screen named preferenceheaderscreen which shows a list of navigation texts to switch among different setting screens is officially recommended to load with another api method loadheadersfromresource see sec.
.
.
the accesses of preferences values are particularly complex.
android provides the sharedpreferences mechanism for activities and applications to manage preference data in the form of key value pairs of primitive data types in the android file system.
the precise values of keys are critical to analyzing which preferences are relevant to a test case.
however they are difficult to acquire through static analysis since very often they are generated dynamically.
to address this problem we employ a dynamic approach to analyze which preferences are loaded and used for the given test cases.
more details will be discussed in sec.
.
.
.
motivation in this section we use a simple app called goodweather to show how preferences affect app behaviors.
goodweather is an app that allows users to select the location by gps or text search and displays the weather condition for the selected location.
it also has a feature called widget that decks out the phone screen with the up to date weather condition.
users are offered with customization options manifested in preferences as shown in figure 1a.
some of the preferences can change the widget s functions for example update location can determine whether or not to start a service to runtime synchronize the location in the widget with the one set in the app.
others can be used to customize the styles of look such as widget theme .
the setting of such preferences can affect either the app behavior or the gui display and in some cases cause bugs.
for example by default update location is set to disabled under which users are able to change the location.
however if update location is enabled when users try to change the location a crash would occur as shown in figure 1b.
clearly to reveal this 269preference wise testing for android applications esec fse august tallinn estonia a the setting screen for widget settings b a crash when selecting a location figure a preference related crash in goodweather bug testers need to set this specific preference option first and then change the location in the app.
however there is no explicit connection between a preference setting for the widget and a failure in the main app and thus this bug is very likely to be untested.
from the goodweather example it is obvious that a systematic and thorough preference wise testing is needed to improve app quality.
however preference wise testing can be challenging since the impacts of preferences are tangled with app functions.
as illustrated by the example only enabling preference update location or selecting the current location will not trigger the crash.
very often testing tools or even human testers have no knowledge about what preferences would affect the functions under test.
therefore to intentionally reveal instead of randomly triggering the preference related bugs they may have to perform exhaustive combinations of test cases and preference settings which can lead to an explosion in testing space.
hence there is an urgent need for the study of cost effective preference wise testing approach.
preference wise testing .
approach overview figure depicts the overview of prefest .
given an apk file of the app under test aut and a set of test cases for the aut prefest identifies the relevant preferences that may affect the app behavior and runs the test cases under relevant preference option combinations to have a more thorough test of the aut.
the test cases can be written manually or generated from automated testing approaches like androidripper a3e or stoat .prefest consists of two major analyses preference identification which identifies and locates all the preferences denoted as pi defined in aut and preference guided test case analysis which reveals the relevance between preferences and test cases through a data flow analysis and only tries the combinations of relevant preference options for each test case denoted as ps .
an additional analysis mode called target mode is also proposed in which prefest splits the code into code blocks and identifies the untested blocks and their relevant aut file test cases preference identification preference guided test cases analysis stubbed targeted testing normal testingpspi data flow analysis dynamic execution pi pi ntestcase testcase n pi pi nblock block nblock block ntestcase testcase nblock partitioningexecution flow pbtarget mode targeted testin g nnnnnaalysis pi pi n block k block n k k block k block n k k testcase testcase n block p artition ing pb target mod e preference recording preference locatingfigure overview of prefest preferences denoted as pb .
it only executes the test cases that can reach untested code blocks and therefore is more efficient.
.
preference identification to conduct preference wise testing it is necessary to first identify the collection of preferences defined in the aut .prefest achieves so by reversing preference resource files from the aut with jadx and recording preferences by their key title type and entryvalues .
currently it supports four types of preferences which areswitchpreference checkboxpreference listpreference andedittextpreference .
the decision is based on the investigation of apps containing preferences from a popular open source android app list on github .
it shows on average each app contains preferences of which preferences are of the aforementioned four types.
the other are of the other types or customized preferences by developers which we plan to support in the future.
then prefest uses soot to statically analyze the source code for the activities and fragments in which the preferences are located.
it first collects all the direct method calls denoted as mcaller mcallee inaut .
the method callbacks are not considered here since methods responsible for loading setting screens are mostly directly called during the initialization of the activities or fragments.
each method mis assigned an attribute declass representing its declaration class.
a call trace defined as m1 m2 ... mt mt represents that through methods m2 m3 .
.
.
mt m1eventually invokes mt and tis the set of all call traces.
prefest conducts analysis on the call traces to identify where the setting screens are loaded.
by studying ways of implementing the setting screen loading we summarized three loading patterns from the android official documents as shown in table .
pattern lpa represents that the loading of a setting screen is performed by an activity where the loading api addpreferencesfromresource is eventually called by the oncreate method of an 270esec fse august tallinn estonia yifei lu minxue pan juan zhai tian zhang and xuandong li table patterns for loading setting screens pattern definition lpa moc ... madd p moc.declass activities lpf p moc ... madd m lifecycle ... m init moc.declass m init.declass fragments m lifecycle.declass activities lph p moc ... madd m oc ... m load moc.declass fragments referred m load m oc.declass activities moc lifecycle method oncreate mlifecycle any lifecycle method madd api method addpreferencesfromresource mload api method loadheadersfromresource minit the constructor of a class.
activity through .
the setting screen is shown when the activity is launched.
pattern lpf represents that the loading of a setting screen is performed by a fragment which itself is initialized by an activity.
loading api addpreferencesfromresource is eventually called by method oncreate declared in a fragment and an activity instantiates this fragment in one of its lifecycle methods through .
for pattern lpf the setting screen is shown when the activity is launched initializing the fragment to load the setting screen.
pattern lph represents that a preference header responsible for loading multiple setting screens is loaded by an activity.
through call trace loading api addpreferencesfromresource is eventually called by method oncreate declared in a fragment.
different from pattern lpf the fragment is not initialized explicitly but instead referred to in a preference header resource file.
when an activity eventually calls method loadheadersfromresource in itsoncreate method through and loads the preference header all fragments referred to in its resource file represented by fragments referred m load are initialized by the android system.
for pattern lph when the activity is launched a preference header is shown containing a list of selections for users to switch among different setting screens.
to analyze which pattern is adopted prefest starts from each maddandmload and performs a backwards search for any match of the pattern lpa lpf or lph.
after the analysis it obtains necessary information for each preference denoted as pi key title type entryvalues location .
we define pias the set of all the pi.
with pi prefest is able to set any concerned preference option combinations automatically with off the shelf android gui test frameworks.
.
preference guided test case analysis to reduce the number of preference option combinations for test cases we need to analyze for each test case which preferences are relevant.
we define the relevant preferences to a test case are those whose values are acquired passed and used in branch conditions during the execution of the test case since preferences used in branch conditions can dynamically modify the function behaviors.these branches ignored by existing approaches are usually blind spots in android testing.
however it is difficult to conduct a precise analysis statically as android apps are not stand alone applications but plugins into the android framework .
even worse the sharedpreferences mechanism used in preferences acquisition makes that the same line of code may point to a different preference since the key of the preference can be changed.
techniques such as symbolic execution is required however they suffer from scalability issues due to the event driven nature and the application development framework of android.
we propose a dynamic analysis to address this problem.
for the aut prefest instruments loggers with soot at the beginning and the end of each method and also at each branching point.
for efficiency loggers are not instrumented in android sdk and the other external libraries.
we simply record the invocations of api methods in these libraries.
when running a test case the logs are automatically collected from which an execution flow comprised of a linear sequence of statements is generated.
then prefest analyzes the execution flow statement by statement and collects variable manipulations and branch conditions.
expression e n pi v op e mi e e variable v v1 v2 ... vm v condition label l label statements s v e i f elsielse s j switch elcase n i si case n j sj .
.
.
execution f low f s1 s2 s3 .
.
.
sn the syntax of an execution flow is shown above.
here vande represent the sets of variables and expressions respectively.
each e ecan be a constant n including constants of boolean integer float string a variable v or an expression constructed with a java operator op a method invocation mior a symbolic variable pi representing a preference.
recall that all necessary information for manipulating a preference is in pi sec.
.
so it is natural to use pias the symbolic representation for preferences.
in an execution flow loops are unfolded during the dynamic execution.
branch conditions of conditional statements are all labelled.
additionally for invocations of methods that are instrumented the parameter passing and method returns are also considered as assignments and the execution of method bodies are included in the execution flow.
finally an execution flow fis represented as a series of statements.
symbolicvariable state v symbolic conditional state c execution state s v c our data flow analysis is performed along the execution flow statement by statement.
to deal with aliasing an andersen s style analysis is implemented.
the execution state sat statement sis defined above.
for s we use vand cto define the mapping relation that maps a variable vor a branch condition labeled with l to its symbolic expression e. 271preference wise testing for android applications esec fse august tallinn estonia by applying von the variables representing keys expressions about keys can be obtained.
in most cases keys are represented with constants or string operations over several constants and therefore prefest can calculate the concrete values of such keys.
then it retrieves the preferences having been accessed during testing from sharedpreferences by interpreting the seven preference acquisition methods defined in the android official documents including getboolean getfloat getstring getint getlong getstringset and getall with the calculated concrete values of keys.
... s1 r1 widget ... s2 r2 r1 update location pref key ... s3 r3 sharedpreferences.getdefaultsharedpreferences s4 z0 r3.getboolean r2 ... s5 z1 !
z0 s6 if z1 l6 ... listing a slice of execution flow of goodweather take the preference update location of goodweather in sec.
.
for example.
listing shows a slice of the execution flow consisting of four inconsecutive sequences of statements which acquires and uses preference update location .
statements s1ands2generate the key of preference update location by string concatenation.
s3 obtains sharedpreferences which stores all preferences.
s4invokes a preference acquisition method getboolean with variable r2as the key and assigns the acquired preference option value to z0.s5 assigns the reverse of z0to z1 which contributes to the branch condition in s6.prefest calculates the concrete value of the key variable r2used in s4 which is widget update location pref key .
it then interprets getboolean ins4with the value of r2 to get the specific preference update location represented by the symbolic variable piupdate location .
with c a relevant preference can be revealed from whether its pi is directly or can affect by assignments other variables contained in the symbolic value of any branch condition.
for instance in the cof the execution state at s6of listing we have l6 piupdate location for the branch condition in s6.
so preference update location isrelevant to this branch condition and by setting it to different values trueorfalse the execution can reach different branches.
now prefest can test different app behaviors by trying different option value combinations of the relevant preferences instead of all the preferences in the app.
the valid values for a preference i.e.
entryvalues are already known as discussed in sec.
.
.
specifically switchpreferences and checkboxpreferences can be set to trueor false listpreferences can be set to a finite set of options in the form of strings predefined by developers for edittextpreferences which accept user text inputs as their values prefest uses boundary values as its entryvalues such as null or a random string intmax are tested when only number input is allowed since it focuses on bug detection.
we define a preference option combination to be tried for a test case testcase as a ps where ps pi value testcase andeach pi value represents the setting for a single preference.
a testcase can have multiple psrepresenting different option combinations.
note that the number of psfor a test case depends on the combinatorial strategy of preferences.
for example a pairwise combinatorial strategy can result in a smaller number of psthan a full combinatorial strategy.
psrepresents all preference option combinations to be tested on all test cases in our preference wise testing.
given a ps ps prefest generates a script and executes it to set preference option values before executing the test case ps.testcase .
in the script for each pi value ofps the pi.title and pi.location help locate the preference in the screen while pi.type andvalue are used to generate operations that set the correct option value for the preference.
after all the relevant preference are set the original test case ps.testcase is executed.
.
test cost reduction with target mode by focusing on relevant preferences prefest only needs to try option combinations for the relevant preferences.
however we empirically found out that pscan still be of a large size in some cases.
for instance in app suntimes two option trueandfalse preferences are used in branch conditions upon its initialization where option combinations can be too many.
a further reduction of test cost is required and we propose the target mode .
in target mode prefest splits the app code into blocks straightline code sequences with no branches in except to the entry and no branches out except at the exit.
since prefest aims at testing the preference related branches we select blocks in preferencerelated branches as our targets.
noticing that third party libraries can also be affected by preferences through parameter passing to demonstrate different behaviors blocks containing invocations of third party methods with preference related variables as their parameters are also considered as targets.
by splitting the execution flows into blocks prefest analyzes the relevant preferences to targets similar to the analysis in sec.
.
.
like the psfor a test case we define a preference option combination to be tested for a target aspb pi value block .
as discussed earlier targets only need to be executed once during testing.
to accelerate the testing process prefest adopts the greedy strategy that the test case which can potentially execute most targets under a certain preference option combination is selected to be executed first.
the key to the strategy is that we need to know which blocks can be reached by a test case under different option combinations and which option combinations can help to reach the previously unreached blocks.
by analyzing the execution flow of a test case combined with code we can locate the branching points that the test case can reach and all branches belong to these branching points can be reached potentially.
to test the unreached blocks we need the concrete values of variables including preferences to manipulate the values of the branch condition.
thanks to the symbolic representation of the branch conditions most concrete values can be calculated.
thus given a target block prefest can produce its pb which is used to set the values of preferences.
algorithm shows the details of the target mode.
it takes ps the set of test cases with different preference option combinations as input and outputs pbtotal the set of the reached blocks with the option combination settings when it finishes.
in the beginning is a 272esec fse august tallinn estonia yifei lu minxue pan juan zhai tian zhang and xuandong li algorithm target mode of prefest .
input ps pi value testcase output pbtotal the total set of pbof reached blocks 1foreach ps psdo pbsbgettargetblocks ps pbtarget .put pbs 4end 5pbtarget .remove pborigin 6pbtotalb 7while ps pbtarget do psmaxbgetmostblocks ps pbreachbexecute psmax pbtotalbpbtotal pbreach pbtarget .remove pbreach ps.remove ps 13end loop lines that iterates each ps psto get the blocks that can be potentially reached by ps.testcase which form the set of targets pbtarget .
then in line pborigin the already reached blocks when executing the original test cases are removed from pbtarget .
next a greedy algorithm which is also a loop starts from line .
it aims at reaching as many unreached blocks as possible each turn until all unreached blocks are reached or there is no test cases left to be executed.
in the loop prefest will search psforpsmax that can test most unreached blocks execute psmaxand record all the reached blocks with option combination settings pbreach add them to pbtotaland remove them from pbtarget lines remove psfrom ps line .
the target mode uses just one option combination for a block instead of exhausting combinations of relevant preferences.
this is particular effective when there are more than one preferences in a branch condition.
as the experiment in sec.
.
shows target mode can reduce a significant portion of the test cost while still being effective in code coverage and bug detection.
.
system preference analysis in this paper we mainly focus on user preferences which are designed for users to change app behaviors and features.
similarly environment configurations of the android system can also make apps behave differently.
they are like the preferences on the system level.
prefest also supports the testing under different environment configurations.
currently prefest supports six kinds of environment configurations that are often used which are wifi bluetooth mobile data gps locating network locating andmusic playing .
by interpreting api methods for acquiring the status of the six environment configurations similar to the interpreting the preference acquisition methods but no keys required the environment configurations can be treated the same as user preferences.
evaluation we implemented our approach into a tool also name prefest .
the tool and the experimental data are available online1.
evaluate prefest we conducted a series of experiments to answer the following questions rq1 how effective is prefest in terms of the code branch coverages and the bug detection ability?
rq2 how efficient is prefest in terms of the number of test runs and the test time?
rq3 how does prefest compare against alternative approaches for preference option combinations in terms of effectiveness and efficiency?
rq4 how does target mode perform?
specifically does it strike a good balance between test cost and test effectiveness?
.
experiment setup we selected stoat one of the state of the art automated android testing tools to generate test cases as inputs for prefest .
the subject apps are chosen from both previous researches and a popular open source android app list on github with the following criteria the app should contain at least five preferences in its setting the app should be able to run standalone instead of as a library and should be compatible with android api which is the recommended environment for stoat the app should achieve a code coverage of over and not easily crash when tested with stoat .
eventually apps from previous researches and apps from the github list satisfying the criteria were selected.
together with our motivating example goodweather totally apps were chosen as our subjects.
we also analyzed the apps sizes by lines of bytecode i.e.
lines of instructions calculated by jacoco and numbers of preferences.
the results show that the complexity of these apps has enough diversity for ranging from 5k instructions with preferences to over 200k instructions with preferences.
to answer the rqs we first applied prefest with target mode denoted as prefest t on all apps.
then we compared prefest t with another two combination approaches for preference options which are nondefault from sec.
.
we know that each preference has a default value under which the original test case is executed.
in this strategy each preference is set to a value other than its default value random value is used if there are multiple valid values .
pairwise the most common type of t way combinatorial testing that is for any two preferences among all preferences all possible pairs of their option values are tested for each test case.
for listpreference and edittextpreference which may have multiple values only two values the default one and a randomly selected one is used to restrict the combination number in pairwise .
we also compared prefest against an implementation without the target mode denoted as prefest n in the comparative study.
prefest n uses pairwise technique to construct the set psto be executed.
in other words compared with pairwise prefest n adapts the pairwise testing for not all preferences but only relevant ones.
the comparative study was only conducted on goodweather and the seven apps from previous researches since it was extremely time consuming and virtually impossible to conduct the study on all apps.
273preference wise testing for android applications esec fse august tallinn estonia table the performance of prefest on apps subject inst.
pref.default prefest t default prefest t inst.
branch inst.
branch time min run time min run goodweather .
.
.
.
.
.
a2dpvolume .
.
.
.
.
.
alwayson .
.
.
.
.
.
suntimes .
.
.
.
.
.
opensudoku .
.
.
.
.
.
radiobeacon .
.
.
.
.
.
notepad .
.
.
.
.
.
wikipedia .
.
.
.
.
.
fillup .
.
.
.
.
.
tintbrowser .
.
.
.
.
.
signal .
.
.
.
.
.
anki android .
.
.
.
.
.
runnerup .
.
.
.
.
.
amme .
.
.
.
.
.
nanoconverter .
.
.
.
.
.
aphotomanager .
.
.
.
.
.
timber .
.
.
.
.
.
antennapod .
.
.
.
.
.
vanilla .
.
.
.
.
.
materialistic .
.
.
.
.
.
redreader .
.
.
.
.
.
commons .
.
.
.
.
.
hacker news .
.
.
.
.
.
kiss .
.
.
.
.
.
uhabit .
.
.
.
.
.
omni notes .
.
.
.
.
.
amazefilemanager .
.
.
.
.
.
connectbot .
.
.
.
.
.
forecast .
.
.
.
.
.
openbikesharing .
.
.
.
.
.
average .
.
.
.
.
.
the experimental environment was a physical machine with 8gb ram and .0ghz quad core processor.
the android emulator to run tests was configured with 2gb ram and the x86 abi image sdk .
.
api level .
the running of stoat was on ubuntu .
configured as 1h for gui exploring 1h for mcmc sampling steps as the longest steps in sampling one case and cases generated at one iteration of sampling.
for comparison we retrieved the test cases from stoat s records of mcmc sampling and run the tests on windows under the above four strategies.
for all the experiments we use jacoco to calculate the coverage of instructions and branches.
.
rq1 effectiveness on coverage and bugs table lists the apps their sizes measured by number of instructions and preferences the instruction and branch coverages achieved by the original test default and prefest t respectively.
as we can see with a preference wise testing the coverages of all subjects have been improved by percentages ranging from .
.
for instruction coverage and .
.
for branch coverage.the average improvement is .
and .
for instruction and branch coverages respectively.
as an enhanced testing for an already state of the art tool this improvement is significant.
we can see that prefest t achieved large improvement in some apps among apps instruction coverage improvement over is seen in apps and branch coverage improvement over is seen in apps and small improvement less than improvement in instruction and branch coverages in apps commons connectbotanduhabit .
we studied these apps and their original test cases and found out that the apps having more improvement were better tested by stoat compared with the apps with less improvement.
this is reasonable since prefest is a complement to existing testing approaches and relies on the execution flows to analyze the relevant preferences.
therefore the preference wise testing and the other testing approaches can form a mutual boost relationship in performance.
it is worth mentioning that for apps signal anikandroid and wikipedia although the improvement of .
.
and .
.
.
and .
in instruction branch coverage is not 274esec fse august tallinn estonia yifei lu minxue pan juan zhai tian zhang and xuandong li goodweather a2dpvolumn alwayson suntimes opensudoku radiobeacon notepad wikipedia0 stoat monkey prefest t prefest n figure preference related branch coverage achieved by stoat monkey prefest t and prefest n significant considering that these apps have more than 100k instructions the more tested instructions and branches in absolute terms can be over instructions and branches.
we are particularly interested in branch coverage since branches can cause different app behaviors with the same movements on the guis and are common in complex apps.
we conducted experiments to evaluate how well the branches can be tested with prefest and whether it is possible to use existing approaches to obtain similar or better results.
we chose default stoat prefest n prefest t and an additional testing tool monkey a clear winner among current test input generation tools to conduct experiments on the example of goodweather and the seven apps from existing researches.
we configured monkey as suggested and the test time was also set to hour the time for mcmc sampling in stoat.
the results are shown in figure .
for all the branches in the apps that can be affected by preferences prefest t and prefest n covered and branches on average.
although prefest t tries less preference option combinations than prefest n in some apps it can achieve higher branch coverage since prefest t can select the exact options for listpreferences to cover preferencerelated branches via the concrete value calculation whereas for the pairwise combination strategy of prefest n a random selection of the listpreferences value is used for the non default value.
stoat andmonkey achieved and branch coverages on average respectively.
considering that all preferences have default values even forbidding the setting of preferences stoat andmonkey should be able to achieve a branch coverage ranging from to from our observation.
so from this point of view we can say that it is difficult to achieve a high coverage for these preference related branches even with the two of the most effective testing tools.
however with prefest the branch coverage can be easily improved to around .
prefest detected additional five bugs as shown in table .
these bugs are all preference related which can only be found by testing specific functions under specific preference settings and are not detected by stoat .
the reason is that stoat usually missed sometable bugs detected by prefest app github issue url goodweathergithub.com qqq3 goodweather issues radiobeacongithub.com openbmap radiocellsscanner android issues kiss github.com neamar kiss issues vanillagithub.com vanillamusic vanilla issues amazefilemanagergithub.com teamamaze amazefilemanager issues specific values of specific preferences or sometimes even missed the setting screens due to its random nature.
the first bug causes data leaks while the others cause app crashes which were logged as error messages by android system.
all bugs have been reproduced.
only the bug in vanilla is two preference relevant while the rests are one preference relevant.
particularly the first four bugs were revealed for the first time and we posted issues on github.
the last bug has been reported by others.
so far bugs in kiss vanilla and amazefilemanager have been confirmed and fixed by developers.
especially the bug revealed in vanilla was an old one introduced over one year ago and developers were happy to know the root cause and be able to fix it.
there is no response for the other two bug issues and we noticed that these two projects are no longer maintained.
nevertheless since they cause app crashes or data leaks we are confident that they are real bugs.
.
rq2 efficiency to answer rq2 we recorded the test time and the numbers of test runs of default and prefest t on the apps in table .
time consumed by prefest t consists of the preference analysis time and the test execution time and table shows the total time with the analysis time in parentheses.
compared to minutes and test runs took by default on average prefest t only took minutes and test runs contributing .
and .
to those of default .
the reason is that prefest t aims at only the unreached blocks and thus just needs to execute part of the test cases.
meanwhile as discussed prefest t has a good performance on code coverage and bug detection showing the value of our proposed enhanced testing .
the results also show the efficiency of our static and dynamic combined analyses.
for out of all apps apps took just about minute to conduct the analyses and the other apps took no more than minutes.
only app signal took minutes due to its large app size and long execution flow.
however the time cost is still acceptable compared with the original test time and more time spent on complex apps we believe is worthwhile.
.
rq3 rq4 comparative study to answer rq3 and rq4 we run experiments on the example of goodweather and the seven apps from existing researches with default prefest t prefest n nondefault andpairwise and recorded the results in in table and table .
275preference wise testing for android applications esec fse august tallinn estonia table comparison of the instruction and branch coverages of different strategies subjectdefault prefest t prefest n nondefault pairwise inst.
branch inst.
branch inst.
branch inst.
branch inst.
branch goodweather .
.
.
.
.
.
.
.
.
.
a2dpvolume .
.
.
.
.
.
.
.
.
.
alwayson .
.
.
.
.
.
.
.
.
.
suntimes .
.
.
.
.
.
.
.
.
.
opensudoku .
.
.
.
.
.
.
.
.
.
radiobeacon .
.
.
.
.
.
.
.
.
.
notepad .
.
.
.
.
.
.
.
.
.
wikipedia .
.
.
.
.
.
.
.
.
.
average improvement .
.
.
.
.
.
.
.
table comparison of test run numbers and test time of different strategies subjectdefault prefest t prefest n nondefault pairwise run time min run time min run time min run time min run time min goodweather a2dpvolume alwayson suntimes opensudoku radiobeacon notepad wikipedia average percentage .
.
table lists the instruction and branch coverages and table lists the test time and the number of test runs.
in general we have pairwise prefest n prefest t nondefault in the improvement of coverages and pairwise prefest n nondefault default prefest t in the test time and the number of test runs.
being the simplest way to conduct perfence wise testing nondefault showed the poorest performance in improving code coverage and took more time than prefest t .
this demonstrates that a more sophisticated approach for preference wise testing is needed.
from table we can see that pairwise and prefest n have the best and similar performance in improving instruction and branch coverages which are .
and over improvement for instruction and branch coverages respectively.
the marginally lower branch coverage of prefest n than pairwise is because prefest n missed some relevant preferences due to the short circuit evaluation in the compiling stage.
as soot works on java bytecode these short circuit preferences were not analyzed.
however such cases are extremely rare and thus we can consider the effectiveness of prefest n and pairwise as equivalent.
prefest t comes next in effectiveness with .
and .
improvement for instruction and branch coverages respectively.
a main reason for more coverage ofpairwise and prefest n compared with prefest t lies in that for few blocks their behaviors can vary under different preference option combinations.
for example some blocks responsible for displaying guis can present different preferences on setting screens depending on the value of a certain preference e.g.
a switch deciding to display or hide a sub menu of preferences.
these casescannot be handled by prefest t but with a more exhaustive trying of different preferences prefest n is able to process most of them.
nevertheless prefest t still retained and improvement in instruction and branch coverages of those of prefest n andpairwise.
considering its time cost we still consider prefest t as the best approach for its balance on effectiveness and cost.
as table shows the pairwise approach was extremely time consuming by taking over times of the original time cost.
in fact the comparative study on just these apps took about days and we estimated that over four months would be needed to scale the study to all the apps.
the fact that days were used in applying pairwise on the apps indicates the necessity of our prefest .
by removing irrelevant preferences in combinations prefest n reduces the time by about two third of the time cost of pairwise but still needed more than times of the original test time.
in contrast prefest t only took about half an hour to perform the tests accounting to just one fifth of the original test time.
nowadays fast developing cycle is the key to the success of android app development due to the fast changing mobile markets and developers typically can only spare a little time for testing.
the target mode which tries to keep a good balance between test efficiency and effectiveness is more likely to be attractive to developers.
if app quality is critical and time recourse allows developers can still choose prefest n for its best effectiveness in coverage but much less time cost than pairwise .
however as the experiments show the effectiveness in bug detection for prefest n 276esec fse august tallinn estonia yifei lu minxue pan juan zhai tian zhang and xuandong li andprefest t is the same all bugs found by prefest n andpairwise were found by prefest t .
.
threats to validity .
.
internal threats.
the major threat comes from that the original test cases may include some operations of setting preference options which will change some option values set by prefest and result in executing different code parts than planned.
to mitigate this threat prefest takes into account the effects of some simple preference setting methods such as setboolean setstring when calculating the values of preference options.
another threat comes from soot which we use to perform the analysis.
soot works on java bytecode so the short circuit evaluation in the compilation phase would lead to the missing of relevance between preferences and test cases.
an alternative analysis framework based on original source code can solve the problem which we plan to study in the future.
the third threat comes from that the current implementation of prefest takes stoat s way of focusing on error messages produced by the android system and does not consider test assertions.
if one needs assertions in the test cases since prefest generates new tests with different preference settings new assertions will be needed.
.
.
external threats.
the main external threat is that our evaluation results may not be generalized on other android applications.
our experiments were performed only on thirty apps since the experiments were time consuming.
it is possible that the effectiveness may vary for other apps.
however this problem is alleviated since the complexity of the thirty apps has enough diversity for ranging from 5k to over 200k instructions and several apps are also widely used in real world such as wikipedia and signal.
asprefest has only worked with stoat another threat arises from whether prefest can work with other test input generation approaches.
we mitigate this threat by implementing prefest into an independent tool which takes test cases as the direct input.
in this case prefest can easily cooperate with other tools as test cases can be easily obtained from these tools log files.
certainly manually written test cases are also welcome to prefest .
related work in this section we will discuss relevant researches from android testing and combinatorial testing.
.
android testing nowadays frameworks and tools that automate the execution of tests are widely spread in industry such as robotium monkeyrunner and appium .
to further improve the automation many research approaches are proposed for the automated generation of test inputs based on fuzzing testing techniques model based testing techniques and search based techniques .
several researches also apply symbolic execution or concolic execution to android testing mirzaei et al.
present sigdroid which combines model based testing with symbolic execution to systematically generate test inputs for android apps anand et al.
illustrate the technique acteve which treats touch on screen as user inputs and generates sequences of events automatically and systematically with concolic execution to alleviate thepath explosion problem.
these approaches are similar to prefest asprefest also performs a dynamic analysis similar to concolic execution.
however prefest only focuses on preferences and analyzes the execution of given test cases so it consumes much less test cost and is less affected by app size.
also most preferences options are enumerable in which case the exact option values to reach the targets can be obtained by enumeration while for sigdroid and acteve a constraint solver is needed for specific values which can be more time consuming.
most importantly the application scenarios and purposes are different prefest works based on existing tests to enhance their performance in terms of preferences while both sigdroid andacteve try to generate new tests for given apps.
.
combinatorial testing combinatorial testing has been an active field of researches in the last twenty years .
one of the major trends in this area has been towards minimizing the size of test sets for a given combinatorial criteria with greedy and heuristic algorithms genetic algorithm or even artificial intelligence .
recent years these combinatorial optimization techniques are also adapted in android testing.
two studies are closely related to this paper one is trimdroid an approach that statically extracts dependencies among widgets to reduce the number of combinations in gui testing and the other one is patdroid which performs a hybrid program analysis that excludes irrelevant permissions to reduce unnecessary permission combinations for test cases.
compared with trimdroid prefest uses both static and dynamic analyses on the aut and the existing test cases to perform the preference wise testing under certain preference option combinations while trimdroid employs static analysis over the aut to automatically generate test cases.
compared with patdroid prefest targets at preferences which are more difficult to analyze as their values are passed through execution flows.
in addition patdroid uses manual written test cases while prefest uses test cases generated from automatic testing tools which are usually of huge size bringing more difficulty for reduction.
in summary we propose the target mode in prefest that can reduce the test cost to a plausible level.
conclusion we present prefest a preference wise enhanced testing approach for android applications.
with a static and dynamic combined analysis prefest gives an automated solution to test apps only under necessary preference option combinations with existing tests in which a target mode is proposed for further reduction in test cost.
our experiment results show that within test cost compared to tests under pairwise combinations of preferences prefest achieves a .
and .
improvement in code and branch coverages.
moreover we also found five additional preference related bugs in real world apps using prefest .