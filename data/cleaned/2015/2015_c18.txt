development emails content analyzer intention mining in developer discussions andrea di sorbo sebastiano panichella corrado a. visaggio massimiliano di penta gerardo canfora and harald c. gall university of sannio benevento italy university of zurich switzerland disorbo unisannio.it panichella ifi.uzh.ch visaggio dipenta canfora unisannio.it gall ifi.uzh.ch abstract written development communication e.g.
mailing lists issue trackers constitutes a precious source of information to build recommenders for software engineers for example aimed at suggesting experts or at redocumenting existing source code.
in this paper we propose a novel semi supervised approach named deca development emails content analyzer that uses natural language parsing to classify the content of development emails according to their purpose e.g.
feature request opinion asking problem discovery solution proposal information giving etc identifying email elements that can be used for specific tasks.
a study based on data from qt and ubuntu highlights a high precision and recall of deca in classifying email content outperforming traditional machine learning strategies.
moreover we successfully used deca for re documenting source code of eclipse and lucene improving the recall while keeping high precision of a previous approach based on ad hoc heuristics.
keywords unstructured data mining natural language processing empirical study i. i ntroduction in many open sources and industrial projects developers make an intense usage of written communication channels such as mailing lists issue trackers and chats .
although voice communication still remains something unavoidable such channels ease the communication of developers spread around the world and working around the clock and allows for keeping track of discussions and of decisions taken .
from a completely different perspective information contained in such a recorded communication has been exploited by researchers to build recommender systems for example aimed at perform bug triaging suggest mentors or providing a description of an existing undocumented software artifact .
however profitably using information available in development communication is challenging because of its noisiness and heterogeneity.
firstly a development email or a post on issue tracker contains a mix of different kinds of structured semi structured and unstructured information.
for example they may contain source code fragments logs stack traces or natural language paragraphs mixed with some source code snippets e.g.
method signatures.
in order to work effectively recommenders must separate such elements and this has been achieved by approaches combining machine learning techniques with island parsers or by using other statistical techniques such as hidden markov models .the second issue is that communication posted on issue trackers mailing lists or forums may have different purposes.
for example an issue report may relate to a feature request a bug or just to a project management discussion.
for example herzig et al.
and antoniol et al.
found that over of all issue reports are misclassified i.e.
rather than referring to a code fix they resulted in a new feature an update of documentation or an internal refactoring .
hence relying on such data to build fault prediction or localization approaches might result in incorrect results.
kochhar et al.
shed light on the need for additional cleaning steps to be performed on issue reports for improving bug localization tasks.
this for example may involve a re classification of issue reports.
on a different side certain recommender may require to mine specific portions of a written communication for example to identify questions being asked by developers or to mine descriptions about certain methods .
also sometimes an email or a discussion is too long and this does not help a developer who get lost in unnecessary details.
to cope with this issue previous literature proposed approaches aimed at generating summaries of emails and bug reports .
however none of the aforementioned approaches is able to classify paragraphs contained in developers communication according to the developers intent in order to only focus on paragraphs useful for a specific purposes e.g.
fixing bugs add new features improve existing features etc.
.
paper contribution.
this paper proposes an approach named deca development email content analyzer that uses natural language parsing to capture linguistic patterns and classify emails content according to developers intentions such as asking providing helps proposing a new feature or reporting discussing a bug.
the use of natural language parsing is motivated by the need to better capture the intent of a sentence in a discussion a task for which techniques based on lexicon analysis such as vector space models latent semantic indexing or latent dirichlet allocation lda would not be sufficient.
for example considering the following two sentences we could use a leaky bucket algorithm to limit the bandwidth.
the leaky bucket algorithm fails in limiting the bandwidth.a topic analysis will reveal that these two sentences are likely to discuss the same topics leaky bucket algorithm and bandwidth .
however these two sentences have completely different intentions in sentence the writer proposes a solution for a specific problem while in sentence the writer points out a problem.
thus they could be useful in different contexts.
this example highlights that understanding the intentions in developers communication could add valuable information for guiding developers in detecting text content useful to accomplish different and specific maintenance and evolution tasks.
for this reason we devised six categories of sentences describing the intent of a developer more details about the methodology used for the definition of the categories are in section ii a feature request opinion asking problem discovery solution proposal information seeking and information giving .
section ii b discusses how deca detects in accordance with these categories of sentences developers intentions behind the communication occurring during development relying on natural language parsing.
the main contributions of this paper are a taxonomy of high level categories of sentences obtained by manually classifying development emails using grounded theory along with a manually labeled and available for replication purposes dataset of development emails from the qt open source project and the linux ubuntu distribution.
deca a novel automated approach to classify development emails content according to developers intentions.
a prototype implementation of the proposed approach available online.
results of an empirical comparison of deca with machine learning classifiers.
last but not least as a practical application of deca we show how it can be used to mine method descriptions from developers communication and how deca can overcome the limitations of a previously proposed approach .
the taxonomy proposed in this paper defines a conceptual framework for indexing discussions of different nature as the inferred categories reflect some of the actual developers needs in searching information across different channels.
in this context deca could be very useful for classifying and indexing content of developers discussions occurring over several communication channels i.e.
issue trackers irc chats on line forums etc.
.
the results of our empirical study on data from qt and ubuntu highlight a high precision and recall of deca in classifying email content.
moreover the proposed approach can be used for a wider application domain such as the preprocessing phase of various summarization tasks.
for example deca could be used as a preprocessing support to discard irrelevant sentences within emails or bug report summarization approaches .
we successfully used deca for re documenting source code of eclipse and lucene improving the recall while keeping high precision of a previous approach based on ad hoc heuristics.
paper structure .
section ii presents the approach we defined to address the problem of email content classification.
section iii reports the research questions of our empirical evaluation the data we collected and the study design.
section iv discusses the results of this empirical study.
section v reports an evaluation of our approach in a real life application.
section vi presents the threats that could affect the validity of our work.
section vii provides a discussion about the related literature and section viii concludes the paper outlining future research directions.
ii.
a napproach to classify emails according to intentions in this section we describe the approach we applied for the automatic classification of development emails content.
in particular we defined a taxonomy of sentences categories in order to catch useful contents for developers see section ii a .
we extracted a set of linguistic patterns for each category.
for each linguistic pattern we defined an heuristic responsible for the recognition of the specific pattern.
we also developed a java tool that implements the defined heuristics with the aim of enabling the automatic recognition of content fragments in development emails see section ii b .
a. categories definitions of development sentences we have defined six categories of sentences describing the intent of the writer feature request opinion asking problem discovery solution proposal information seeking and information giving .
table i provides a description of each category.
these categories are designed to capture the aim of a given email and consequently recognizing the kind of information generally contained in messages regarding the development concerns.
table i sentence categories definition the categories were identified by a manual inspection of a sample of emails taken from the qt project development mailing list.
during this task we manually grouped all the extracted emails according to the categories defined by guzzi et al.
which are implementation technical infrastructure project status social interactions usage anddiscarded .w e obtained groups of emails one for each category with theexception of discarded .
the aim of the taxonomy presented in was to assign topics to discussions threads.
thus this classification is useful to assign the scope to the entire mail message but not the intent related to relevant sentences in the email content which is our purpose.
indeed we believe a single message may contain relevant sentences of different nature e.g.
an identification of a bug and a subsequent solution proposal to fix it .
thus for each group of emails we manually selected and extracted significant sentences that evoke or suggest the intent of the writer e.g.
is the writer saying that there is something to be implemented?
is the writer saying that she he discovered a bug?
with the aim of defining a complete set of categories we relied on a further taxonomy proposed by guzzi et al.
.
this second taxonomy classifies the reasons why developers need to communicate about source code.
this taxonomy includes three categories i coordination ii seeking information and iii courtesy .
this second classification is close to the aim of our work but it is not enough detailed.
through a manual inspection of the extracted sentences we extended and refined the set of categories of guzzi et al.
with a new set of categories detailed in table i which better fits the content of development mailing list messages.
we discarded the sentences that do not belong to any of the defined categories because they have negligible information and or are too generic to help during a development task.
the categories we defined are intended to capture the intent of each sentence requesting new features describing a problem or proposing a solution and consequently allow developers to better manage the information contained in emails.
table ii sentence types by guzzi et al.
left side and ours right side table ii compares our classification to the one proposed by guzzi et al.
highlighting that our classification is more suitable for the software development domain as it is more detailed and specific.
as an example let s consider three different kinds of sentences i discuss a change e.g.
a computer icon is required i would like to see a chat included in this release ii file a bug e.g.
the serverdoesn t start i found a problem during the installation process and iii propose a solution e.g.
you may have to enable the package what you need to do is to re install the application .
while in the classification of guzzi et al.
all of them fall in the same category coordination in our model each of them is associated to a different category feature request problem discovery a n d solution proposal respectively.
we neglected some forms of courtesy e.g.
ask a permission adding the information giving category to model cases in which the developers intent is to provide useful information to other participants in the discussion e.g.
i have provided some extra information in the bug report plan is to make available a new release for this month .
we finally introduced the opinion asking class for capturing explicit opinion requests e.g.
what do you think about creating a single webpage for all the services?
.
the sentences belonging to the opinion asking class may emphasize discussion elements which could be useful for developers activities thus it appears reasonable to distinguish them from more general information requests mapped with the information seeking category .
b. natural language parsing of linguistic patterns we assume that when developers write about existing bugs problem discovery or suggest solutions to solve these bugs solution proposal within discussions about development issues they tend to use some recurrent linguistic patterns.
for instance let s consider again the example sentences introduced in section i. observing the syntax of the sentence we could use a leaky bucket algorithm to limit the bandwidth we can notice that the sentence presents a well defined predicateargument structure the verb to use constitutes the principal predicate of the sentence could is the auxiliary of principal predicate.
we represents the subject of the sentence a leaky bucket algorithm represents the direct object of the principal predicate to limit is a non finite clausal complement depending on the principal predicate the bandwidth is the direct object of the clausal complement by exploiting this information most of the sentences that present similar predicate argument structure would indicate a solution proposal .
thus we define a heuristic to detect this particular predicate argument structure.
the formalization of a heuristic requires three steps i discovering the relevant details that make the particular syntactic structure of the sentence recognizable e.g.
the verb to use as principal predicate of the sentence and the auxiliary could ii generalizing some kinds of information e.g.
subject doesn t necessarily be we and direct object doesn t necessarily be leaky bucket algorithm iii ignoring useless information e.g.
the clausal complement and its direct object don t provide any useful information for the structure identification .
so we define a general pattern could use the wordsin square brackets are placeholders indicating generic subjects and generic direct objects and associate it with the solution proposal class.
on the contrary if we consider the sentence the leaky bucket algorithm fails in limiting the bandwidth we can notice that this second sentence has a totally different structure.
indeed the verb to fail constitutes the principal predicate of the sentence and this would rather suggest the description of problem.
we used the stanford typed dependencies sd representation in order to describe a set of heuristics able to recognize similar recurrent linguistic patterns used by developers in an automated way.
each category is then associated to a group of heuristics.
thus each heuristic is leveraged for the recognition of a specific linguistic pattern.
the typed dependency parser represents dependencies between individual words contained in sentences and labels each of them with specific grammatical relation such as subject or indirect objects .
the sd representation was successfully used in a range of tasks including textual entailments and bionlp and in recent years sd structures have also become a de facto standard for parser evaluation in english .
figure through an example shows the process we applied to define each heuristic.
more precisely in figure we can see how previously discussed concepts on sentences predicateargument structures can be implemented through the stanford typed dependencies.
firstly we analyze a sentence containing one of the recurrent linguistic patterns e.g.
we should add a new button to access to personal contents in figure and build its sd representation.
fig.
natural language parse tree from a feature request table iii defined heuristics for each sentence category in figure the main predicate add jointly to the auxiliary verb should is a clue for a feature request .
obviously this predicate has to be connected to a generic subject that indicates who makes the request and one or more generic direct object that along with the predicate indicates the request object .
at this point we can define the related heuristic should add and associate it with the feature request class.
once we have defined the heuristic a sentence having a similar structure add or synonyms in the role of principal predicate should or synonyms in the role of auxiliary verb and one or more direct objects that indicates the things a user would add can be recognized as belonging to the class of feature request .
through the process described above we defined a set of heuristics1for each of the defined categories.
table iii shows the number of heuristics implemented for each class.
we implemented a java tool for evaluating the recognition capability of the proposed approach.
by exploiting the defined heuristics and working on the sd representation of the emails sentences the tool highlights the recognized sentences with different colors.
we make the tool2and a replication package3 available to help other researchers to easily replicate our study.
iii.
e va l uat i o n study definition the goal of this study is to analyze development emails contents with the purpose of investigating the effectiveness of the approach in identifying discussions relevant for developers for specific maintenance task.the perspective is of researchers interested in identifying relevant recurring linguistic patterns in the software engineering domain useful for performing several software engineering tasks.
a. research questions the study aims at investigating the following research questions rq1 is the proposed approach effective in classifying writers intentions in development emails?
this research question represents the core part of our study aimed at developing and evaluating a novel approach for classifying messages able to help retrieving meaningful information from message content.
rq2 is the proposed approach more effective than existing ml in classifying development emails content?
this research question aims at comparing results achieved by deca with the results obtained by a set of existing ml techniques previously used in the literature for classifying bug reports.
thus this research question is aimed at quantifying the benefits obtained by the use of natural language parsing with respect to existing ml techniques.
deca implemented heuristics.pdf replicationpackagedeca.zipb.
context selection and data extraction the context of the study consists of mailing lists belonging to two open source projects whose characteristics are summarized in table iv.
specifically for each project table iv provides i name ii home page iii period of time considered to collect the emails and iv total number of analyzed emails.
the qt project is a cross platform application and ui framework used to develop application software that can run on various software and hardware platforms.
the development of qt framework started in while nokia founded the qt project on october with the aim of easing online communication among qt developers and community members through public forums mailing lists and wikis.
ubuntu is a debian based linux operating system.
table iv analyzed projects table v development mailing lists samples both projects have large development communities and this ensures high messages density more than messages per month .
in order to have as many message types as possible in our study we selected emails in specific time windows for the two projects.
for the qt project we selected emails in a period related to a very advanced development stage the development of qt framework started in in which we expected to find more messages related to information requests and solution proposals.
for ubuntu we selected emails in a period related to a very early development stage the first release of ubuntu was issued in october in which we expected to find more messages related to new bugs discovered and or feature requests.
table v summarizes the samples of emails we randomly selected for our study reporting for each sample the i name of the project the ii amount of messages considered in the sample for that project and the iii period of time in which the messages of the sample have been exchanged.
in this dataset we anonymized the messages and applied a pruningof email metadata removing for example names of sender and receiver that were not relevant for our goals.
starting from sentences categories defined in section ii a two phd students one of them not involved in this research work separately analyzed all the messages in the dataset and manually extracted significant sentences assigning each of them to one of the defined categories.
we involved an external evaluator to avoid any bias related to the subjectivity of the classification.
specifically the classifications performed by the two evaluators coincide for the most part in about of the cases they assigned a sentence to the same category .
we considered only the sentences that both evaluators assigned to the same category.
table vi shows the samples size of the classified sentences for the two projects considered in our study.
it is important to stress that the proportion of table vi samples size of classified sentences the categories of sentences varies depending on the projects.
however in both projects opinion asking andinformation seeking are respectively the categories having the lowest and the highest percentages of occurrences if compared to each other class of sentences.
c. analysis method to answer rq1 we defined a sequence of train and test sets pairs for a progressive assessment of the results.
thus we scheduled experiments.
experiment i a. we randomly selected as training set emails among the messages sent in june related to qt project development mailing list.
as explained in section iii b two humans performed the manual classification of the sentences contained in such email messages according to the defined category in section ii a. thus we manually detected the recurring linguistic patterns found in this set of messages according to the defined categories in section ii a. through the process explained in section ii b figure we defined and implemented heuristics for automatically classifying recognition of patterns the sentences contained in training set.
b. we randomly selected as test set emails sent in may regarding the qt project.
also in this case two people performed a manual classification of the contents of these messages according to the defined category.
specifically only senteces evaluated as belonging to the same category were selected.
c. relying on the defined heuristics we used our tool to automatically classify sentences of the emails in the test set.
we compared tool outputs with the human generated oracleand computed i true positives tp as the number of sentences correctly classified by the tool ii false positives fp as the number of sentences incorrectly labeled as belonging to a given class and iii false negatives fn as the number of items which were not assigned to any sentence category but were belonging to one of them.
thus we evaluated the tool performances relying on the widely adopted metrics of information retrieval precision recall and f measure.
experiment ii a. to improve the effectiveness of the deca s classification we used the set of sentences classified as false negatives in the experiment i as a gold set for defining new heuristics able to capture such sentences.
specifically new heuristics were identified formalized and implemented in order to detect the sentences not identified in experiment i. thus our heuristics set increased from to .
b. we prepared a new test set to verify if the augmented heuristics set allowed us to get better results.
emails were randomly selected between messages sent in the months of march april july august september of the year related to qt project.
following the same approach previously discussed two human judges contributed to constitute the oracle for this experiment.
c. we executed deca on emails sentences of this new test set and we compared the data with the human generated oracle.
experiment iii a. to further improve the effectiveness of the classification performed by deca we used again false negatives found in the experiment ii as new set for identifying new recurrent patterns.
in this way new heuristics were implemented giving a total number of .
b. to evaluate the potential usefulness of the new set of heuristics we created a third test set randomly selecting emails sent from september to january in the ubuntu distribution.
two human judges created the oracle table relatively to this test set according to the previously explained process.
c. we executed deca on the emails messages of this new test set and compared the results with the human generated oracle.
it is worth nothing that the two evaluators are the same in all the three experiments.
d. an approach based on ml for email content classification this section discusses the methodology we used to train machine learning techniques to classify the email content rq2 .
specifically the work by antoniol et al.
exploited conventional text mining and machine learning techniques to automatically classify bug reports.
they used terms contained in bug reports as features fields of machine learning models to discern bugs from other issues.
the work by zhou et al.
extended the work of antoniol et al.
building the mltechniques considering as additional features structural information improving ml prediction accuracy.
we implemented an approach similar to the one used by antoniol et al.
to classify sentences contained in mailing lists data using as features the terms contained in the sentences themselves.
formally given a training set of mailing list sentences t1 and a test set of mailing list sentences t2 we automatically classify the email content contained in t2 by performing the following steps .text features the first step uses all sentences contained in t1andt2as base information to build a textual corpus indexing the text .
in particular we preprocessed the textual content applying stop word removal and stemming similarly to the work of zhou et al.
to reduce the number of features for the ml techniques.
the output of this phase is a term by documents matrix mwhere each column represents a sentence and each row represents a term contained in the given sentence.
thus each entry m of the matrix represents the weight or importance of the i th term contained in the j th sentence.
similarly to the work of antoniol et al.
we weighted words using the the tf term frequency which weights each words iin a document jas tfi j rfi j summationtextm k 1rfk j where rfi jis the raw frequency number of occurrences of word iin document j. we used the tf term frequency instead of tf idf indexing because the use of the inverse document frequency idf penalizes too much terms appearing in too many documents .
in our work we are not interested in penalizing such terms e.g.
fix problem or feature that actually appear in many documents because they may constitute interesting features that guide ml techniques in classifying development sentences.
.split training and test features the second step splits the matrix m the output of the previous step in two submatrices mtraining andmtest.
specifically mtraining and mtestrepresent the matrix that contains the sentences i.e.
the corresponding columns in m oft1and the matrix that contains the sentences i.e.
the corresponding columns in m t2respectively.
.oracle building this step aims at building the oracle to allow ml techniques to learn from mtraining and predict onmtest.
thus in this stage we manually classified the sentences in t1andt2assigning each of them to one of the categories defined in section ii a as described in section iii c two human evaluators performed this classification .
we added the value of the classification as further columns in both mtraining andmtest.
the machine learning techniques during the training phase use the column c of the classification for learning the model.
.classification this step aims at automatically classifying sentences relying on the output data obtained from the previous step mtraining and mtestwith classified sentences .
the automatic classification of sentences isperformed using the weka tool experimenting with eight different machine learning techniques namely the standard probabilistic naive bayes classifier the logistic regression simple logistic j48 the alternating decision tree adtree random forest ft ninge.
the choice of these techniques is not random.
we selected them since they were successfully used for bug reports classification i.e.
adtree logistic regression and for defect prediction in many previous works thus allowing to increase the generalisability of our findings.
in the replication package3 we make available the data we used for training and test the ml techniques.
it is important to specify that the generic training set t1and the generic test sett2 correspond to training and test set pairs discussed in section iii c. iv.
a nalysis of results a. rq1 is the proposed approach effective in classifying writers intentions in development emails?
table vii results for experiment i table viii results for experiment ii table ix results for experiment iii tables vii viii and ix report the results achieved by deca in classifying development emails content.
in particular these tables show the amounts of i true positives ii false negatives iii false positives iv precision v recall and vi f measure achieved for each defined class for the three experiments respectively .
in general the results of the classification performed by deca are rather positive and the addition of new heuristics improves the effectiveness of the approach along the various experiments.
specifically while the precision is always very high ranges between and and stable for all the experiments the recall increases with the addition of new heuristics from to i.e.
around two times .
this is also reflected by the increment of the f measure in the three experiments it varies from an initial value of experiment i to experiment iii .
furthermore data shows that deca works well for all the categories of sentences and all the experiments.
the only exception is in the experiment i for the opinion asking category where recall and precision are equal to zero.
however in general for the experiment i precision ranges from .
obtained for solution proposal to achieved in feature request whereas recall ranges from .
for information seeking category to achieved for problem discovery .
in the experiment ii precision ranges from obtained for solution proposal to achieved in information seeking andopinion asking categories whereas recall ranges from .
obtained for solution proposal to .
achieved in problem discovery .
in the experiment iii precision ranges from .
obtained for solution proposal to achieved inopinion asking category whereas recall ranges from obtained for solution proposals to .
achieved in feature request .
it is important to note that we achieved the best results in terms of recall classifying problem discoveries in the experiments i and ii.
this indicates that developers very often rely on common recurrent patterns successfully detected by deca when their intent is to communicate a bug or a problem.
on the other hand we achieved the worst results in detecting solution proposals for all the three experiments with a precision that has gradually and relatively deteriorated from .
in experiment i to .
in experiment iii and a recall that has gradually increased but never exceeded the .
this suggests that there are many different ways developers use when proposing solutions making it hard to identify common patterns to detect them.
summary rq1 the automatic classification performed by deca achieves very good results in terms of both precision recall and f measure over all the experiments .
the results tend to improve when adding new heuristics.
deca achieved the best values of f measure for problem discovery sentences and the worst f measure results for solution proposal sentences.
b. rq2 is the proposed approach more effective than existing ml in classifying development emails content?
as discussed in section iii d this research question aims at comparing performances of deca with the performances of a set of machine learning techniques.
for the lack of space we report in this paper only the results of the ml models that obtained the best performances in classifying development content.
specifically in order to get a more complete picture we selected a set of techniques belonging to different ml categories regression functions i.e.
logistic regression simple logistic decision trees i.e.
j48 ft random forest and rules models i.e.
ninge .
the comparison of results for the experiment i highlights that deca achieves the best global results in terms of both precision see figure andfig.
compared precision for experiment i fig.
compared recall for experiment i fig.
compared precision for experiment iii fig.
compared recall for experiment iiirecall see figure .
the precision of deca was only worse than j48 technique when identifying solution proposal for deca with respect to for j48 .
however for the solution proposal category deca achieved a recall of .
while j48 reached a recall of only .
see figure .
focusing the attention on recall our approach was worse than the randomforest technique in detecting feature request .
versus see figure on the other side for feature request class deca achieved a precision of while randomforest obtained a precision of only see figure .
furthermore the recall of our approach was better only than randomforest technique in identifying information seeking sentences.
however deca results are much better than all the other techniques in terms of precision around as showed in figure .
finally in the experiment i the recall achieved by deca in detecting information giving sentences was comparable to the randomforest technique .
versus .
.
also in this case deca achieved a better precision .
versus of randomforest .
in both the experiment ii and the experiment iii deca achieved the best global results in terms of both precision and recall.
we discuss in details the results of the comparison in experiment iii figure and figure .
specifically in the experiment iii deca outperforms in terms of recall precision and f measure the results of all the ml techniques.
what is interesting to highlight is that our approach was the only technique able to recognize opinion asking sentences in the experiment iii the same happened in experiment ii with a substantially high precision and recall precision and a recall of .
deca obtained the best f measure values for all the defined sentences categories in all the three experiments.
to evaluate the performances of the proposed approach we repeated the run of each experiments times.
the results of the ml classifiers and deca were pretty stable and statistically equal to the results showed in the study.
in experiment i deca achieved an average f measure of that is better than the f measure that can be achieved relying on all other considered techniques.
while in experiment iii deca obtained an average f measure of for experiment ii also in this case higher than the f measure of all ml techniques.
moreover while the results of deca improve in experiment ii and experiment iii this does not happen for all the considered ml techniques.
indeed their performances are quite stable along all the experiments even if the training set grows up with the number of experiments with a precision and recall never exceeding the threshold of .
and respectively.
summary rq2 deca outperforms traditional ml techniques in terms of recall precision and f measure when classifying e mail content.
moreover while the results of deca improve in experiment ii and experiment iii this does not happen for all the considered ml techniques.v.
deca in a real life application code re documentation in this section we show how deca can be used for a specific application namely mining source code documentation from developers communication.
specifically a previous work by panichella et al.
proposed an approach based on vector space models and ad hoc heuristics able to automatically extract with high precision up to method descriptions from developers communications bug tracking systems and mailing lists of two open source systems namely lucene and eclipse.
the limit of such approach is that it tends to discard a high number of potentially useful method descriptions.
indeed the approach discarded around and useful paragraphs for lucene and eclipse respectively.
however the authors pointed out that several are the discourse patterns that characterize false negative method descriptions .
we argue that deca can be successfully used to overcome such limitations capturing some of the discourse patterns contained in false negative method descriptions .
thus we experimented our intention based approach on all the paragraphs for each project validated in to provide a preliminary evaluation of how many useful paragraphs i.e.
false negatives could be recovered by using our approach.
specifically we considered as valid method descriptions the paragraphs containing for deca sentences belonging to feature request problem discovery information seeking or information giving categories in according to the taxonomy defined in section ii a because are more likely to contain information about the behaviour of a java method.
table x reports for each project i the number of analyzed paragraphs ii the number of paragraphs previously labeled as false negatives fn iii the number of fn recovered by deca and iv the number of false positives fp generated by deca.
for eclipse deca was able to recover about of paragraphs previously labeled as false negatives while for the apache lucene deca recovered about of them.
moreover deca generates a reduced set of false positives for both projects achieving a precision of for eclipse and for lucene.
these results demonstrate how deca can improve significantly the recall of the previous approach even if we obtain a slight degradation of the performance in terms of precision.
table xi shows some examples of paragraphs correctly detected by deca that were marked as false negatives in the previous work by panichella et al.
.
this happens because the previous approach assigned a score to paragraphs to be candidate method documentation if they contain some keywords such as return override invoke etc.
however there can be valid method descriptions not containing anyone of such keywords.
as a consequence these paragraphs were discarded by the approach of panichella et al.
.
instead as it can be noticed from the examples reported in table xi deca is able to identify at least of them.
for example in the case of eclipse the paragraph referring to the build method from the javabuilder class contains the sentence javabuilder.build triggers a pde model change... .
decasuccessfully recovers such paragraph and correctly assign this method description to the information giving category.
a similar situation occurs for the others recovered paragraphs.
thus intention mining performed by deca could improve the recall and precision of a previous approach that mine source code documentation from developers communication means.
specifically this result shows that deca really overcomes limitations of traditional lexicon approaches e.g.
as lda that are not able to capturing capturing discourse patterns contained in paragraphs useful for code redocumentation.
table x number of paragraphs recognized by deca table xi examples of paragraphs recognized by deca vi.
t hreats to validity threats to internal validity concern any confounding factor that could influence our results.
this kind of threats can be due to a possible level of subjectivity caused by the manual classification of entities.
to reduce this kind of threats we attempt to avoid any bias in the building of oracles by keeping one of the human judges who contributed to define our oracle tables unaware of all defined and implemented patterns.
moreover we built the oracle tables on the basis of predictions that two human judges separately made.
only predictions which both judges agreed upon formed our oracles for the experiments.
another threat to internal validity could regard the particular ml classification algorithm used as baseline for estimating our results as the results could be dependent on the specific technique employed.
for mitigating this threat we used different ml algorithms and compared the results achieved through our approach with the results obtained through each of them.
threats to external validity concern the generalization of our findings.
in our experiments we used a subset of messages in the original mailing lists.
this factor may be a threat to the external validity as the experimental results may be applicable only on the selected messages but not to the entiremailing lists.
to reduce this threat we tried to use as many messages as possible in our experiments.
for the same reason we prepared different test sets in which we tried to select both messages related to different periods of the same year and messages related to different development stages.
messages posted in the same month often belong to the same discussion threads and often include quotations of messages to which they reply.
to avoid analyzing more times the same sentences for the experiments ii and iii we randomly selected test sets containing messages posted in time windows of five months.
another threat to the external validity is represented by the mailing lists used in our experiments.
it is possible that some particular characteristics of mailing lists we selected lead to our experimental results.
to reduce this threat we used two different existing development mailing lists as we discussed in section iii b .
moreover we further experimented our approach with text fragments belonging to mailing lists of two others open source projects eclipse and lucene .
however in the future our aim is to assess our approach on mailing lists of more projects of different nature both industrial and open source asking developers to validate the sentences according to the categories defined in this paper.
vii.
r elated work in the last years several research works proposed various approaches based on nlp analysis as tools to derive important information aimed at supporting program comprehension and maintenance activities .
recent studies used natural language parsing to classify the content of natural language text in according to pre defined categories.
shihab et al.
showed that mailing list discussions are closely related to source code activities and the types of mailing list discussions are good indicators of the types of source code changes code additions and code modifications being carried out on the project.
in the literature several techniques have been presented to speed up and facilitate managing emails.
the work by corston oliver et al.
presented an approach to provide task oriented summary of email messages by identifying task related sentences in development messages.
mining of intention in developers discussions provides a higher level of abstraction.
koet al.
in presented a study that observed how noun verbs adverbs and adjectives are used to describe software problems to what extent these parts of speech can be used to detect software problems.
we share with this work the idea of using natural language parsing to detect recurrent patterns in descriptions reported by developers in our case in mailing list data allows to automatically classify the content written in natural language text relevant for development tasks.
cohen et al.
in presented an approach that relying on machine learning methods classifies emails according to the intent of the sender.
differently from these previous works we focus our attention in classifying emails sentences written by developers during development discussions in mailing listsdata .
thus we analyzed syntactic and semantic information to discover significant recurrent patterns useful to recognize relevant sentences within messages.
it is important to highlight that sentence classification has been used in several practical application domains including analysis of biomedical data generation of scientific summaries based on textual analysis legal judgment product reviews customer complaints in help desks .
viii.
c onclusions and future work in this paper we presented deca development email content analyzer an approach based on natural language parsing to automatically classify the content of development communication e.g.
emails according to likely developer intentions such as asking providing helps proposing a new feature or reporting discussing a bug.
the approach builds on top of an english natural language parser and applies a set of heuristics that have been defined on a training set.
to evaluate deca we have carried out an empirical study on emails from the qt project and emails from the ubuntu linux distribution.
results for the study indicates that deca achieves high levels of precision and recall about outperforming a classification performed with six different machine learning techniques.
also performances of deca improve along three experiments in which we improved the heuristics by exploiting false positives and false negatives of the previous experiments which a rate of improvement varying between and .
we also showed that our approach can be used to mine source code documentation from developers communication means see section v and that it improves the recall of a previously preposed approach based on vector space models and heuristics.
thus as a first direction for future work we plan to implement specific heuristics to detect paragraphs useful to re document java methods classes performing a larger study on data from different communications means such as mailing lists issue trackers and irc chats.
the proposed approach can be used for a wider application domain such as the preprocessing phase of various summarization tasks.
for example deca could be used as a preprocessing support to discard irrelevant sentences within emails or bug report summarization approaches .
furthermore we plan to use deca in combination with topic models for retrieving contents presenting the same intentions and treating the same topics from developers discussions.
for example such a combination could enable the possibility for a developer to retrieve all feature requests related to a given topic from different communication means in order to plan a set of change activities.
acknowledgment sebastiano panichella gratefully acknowledges the swiss national science foundation s support for the project essentials snf project no.
.
we also thank the reviewers of this paper for the very insightful comments useful to improve our research work.