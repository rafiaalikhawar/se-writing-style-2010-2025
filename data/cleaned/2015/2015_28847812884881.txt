automatic model generation from documentation for java a pi functions juan zhai jianjun huang shiqing ma xiangyu zhang lin tan jianhua zhao feng qin the state key laboratory for novel software technology at nanjing university purdue university university of waterloo ohio state university zhaijuan seg.nju.edu.cn huang427 ma229 xyzhang cs.purdue.edu lintan uwaterloo.ca zhaojh nju.edu.cn qin cse.ohio state.edu abstract modern software systems are becoming increasingly complex relying on a lot of third party library support.
library behaviors are hence an integral part of software behaviors.
analyzing them is as important as analyzing the software itself.
however analyzing libraries is highly challenging due to the lack of source code implementation in different languages and complex optimizations.
we observe thatmanyjavalibrary functionsprovideexcellentdocumentation which concisely describes the functionalities of the functions.
we develop a novel technique that can construct models for java api functions by analyzing the documentation.
these models are simpler implementations in java compared to the original ones and hence easier to analyze.
more importantly they provide the same functionalities as the original functions.
our technique successfully models functions from widely used java classes.
we also use these models in static taint analysis on android apps and dynamic slicing for java programs demonstrating the effectiveness and efficiency of our models.
.
introduction libraries are widely used in modern programming to encapsulate modular functionalities and hide platform specific details from developers.
they substantially improve programmers productivity.
but on the other hand they make software analysis very challenging.
the reason is that library behavior is an integral part of software behavior such that software analysis cannot avoid analyzing library behaviors.
unfortunately the source code of libraries may not be available.
many libraries are mixed with many languages sometimes even in assembly code.
library implementations are usually highly optimized and full of sophisticated engineeringtricksthatare difficultforanalysisenginestohandle.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c circlecopyrt2016 copyright held by the owner author s .
publication rights licensed to acm.
isbn .
.
.
.
an important but very challenging problem modeling library functions has been studied by many previous works .
however most of them require manually constructing models.
this puts a lot of burden on the analysis developers.
it can hardly scale to large projects that usually make use of a large number of library functions.
uses dynamic dependence summaries to improve analysis.
however the technique does not model the functionalities of library functions but rather their dependencies.
the summary may not be accurate when conditional statements are involved and the training set is not of high quality.
tries to automatically generate models for library system functions using satisfiability modulo theories smt solver.
the technique requires substantial manual efforts and does not scale well due to the very large search space.
according to our observation api documentation like javadoc and .net documentation usually contains wealthy information about the library functions such as the behaviors ofafunctionandtheexceptionsthefunctionmaythrow.
thus it is feasible to generate models for library functions from such api documentation.
however it is still challenging to do so since accurate linguistic analysis is needed to analyze api documentation.
this paper proposes a novel approach to generate models from javadocs in natural languages.
these models are code snippets that have the same functionalities as the original implementations but are much simpler in complexity.
they can replace the original library functions during software analysis.
our contributions are highlighted as follows.
we propose a novel and practical technique to generate substantially simplified java code that models libraries.
it allows software analysis to reason about library behaviors without suffering from problems such as lack of source code and library implementations being too complex to analyze.
we identify technical challenges of applying nlp techniques in modeling libraries and propose solutions to these problems.
we implement a prototype which automatically models functions in commonly used java container classes.
the application of these models in android appstatictaintanalysisandjavadynamicslicingshows that these models precisely represent the library function behaviors and improve the efficiency andeffectiveness of the analysis.
ieee acm 38th ieee international conference on software engineering 1public void add intindex e element 2rangecheckforadd index 3ensurecapacityinternal size 4system.arraycopy elementdata index elementdata index size index 5elementdata element 6size figure the method a dd in the class arraylist .
background and motiv ation .
models in software analysis many program analyses require proper reasoning about libraries as their behaviors are an integral part of the software behavior.
for example program slicing taint analysis and information flow tracking need to know the dependenciesbetweeninputandoutputvariablesofalibrary function.
symbolicexecutionengineslike requireprecise models of libraries to construct correct symbolic constraints and model checkers like java pathfinder need appropriate models of libraries to combat the state space explosion problem.
unfortunately it is usually difficult and timeconsuming to obtain either this kind of dependencies or the models due to the following reasons.
first the source code of library functions is often beyond reach.
even if the source code is available it is still very challenging to analyze the code owningtothefactthatthesourcecodetendstobeprohibitively large mix multiple programming languages and contain substantial optimizations and engineering tricks.
it is often the case that a single invocation to an api function may lead to a large number of invocations to functions internal to the library substantially adding the complexity and cost of software analysis.
furthermore many libraries have inherent cross platform support making analysis even harder.
take the java standard library as an example.
the java development kit jdk contains the java standard library source code version .
the size of which is .7mb.
there are more than classes and methods.
to achieve thebinarylevelcompatibilityofnativelibrarymethodsacross all java virtual machine jvm implementations on a given platform jdk libraries invoke native methods through the java native interface jni framework.
these native methods are implemented in other languages such as c and assembly andtheirsourcecodeisunavailableingeneral.
besides there are multiple implementations for such a method on different architectures and jvms.
fig.
shows a simple library function add int index e element in thearraylistclass.
there are three function calls including system.arraycopy in five effective lines of code eloc .
the implementation of the function system.arraycopy is unavailable in the source code folder.
it is implemented in native code using jni.
from this we can see that analyzing jdk functions is challenging.
due to these reasons library function models are usually constructed and provided to replace the original implementation during analysis.
these models are code snippets that have the same functionality as the original library functions but are much simpler.
they can be used in place of the original functions during software analysis.
note that even though they are not as efficient or sophisticated as the original functions they are much easier to analyze.
currently the majority of models used are manually constructed which represents a substantial burden for the analysis developers due to the large number of library functions and their rapid evolution.
furthermore library functions are often optimized to achieve high performance.
the details of these optimizations are usually not the essential part of the functional models.
for example as shown in fig the model of the add function can be represented by simple array operations guarded bya range checkpredicate.
the low leveldetailsof system.arraycopy andrangecheckforadd are not needed in the model.
all these factors motivate us to develop an approach toautomatically generate models for library functions.
.
approach overview it is a common practice for library developers to provide behavior description of library functions in natural language in the application programming interface api documents.
j2se s javadoc is a typical example of such api documentation which offers wealthy information such as class interface hierarchies and method description.
our idea is hence to construct models from api documentation.
in recent years natural language processing nlp techniqueshave madetremendous progress andhavebeen shown tobefairlyaccurateinidentifyingthegrammatical structure ofanaturallanguagesentence .
this enablesus to leverage nlp techniques including word tagging partof speech pos tagging phrase and clause parsing chunking and syntactic parsing to acquire semantics of sentences in api documentation.
basic idea given the documentation of a java api function we leverage an nlp tool to generate the parse trees of the individual sentences.
for each sentence we match its parse tree with the tree patterns of a set of predefined primitives which are small code snippets implementingverybasic functionalities.
in particular we try to identify a subset of primitives whose tree patterns can cover the entire parse tree when they are put together.
the parameters in the primitives are also instantiated by the corresponding nodes in the parse tree.
the same procedure is repeated until the parse trees ofall sentencesare completely covered.
the composition of the code snippets corresponding to the identified primitives produces a model candidate.
since there are multiple possible parse trees for a sentence and many ways to cover a tree multiple candidates are generated.
the invalid ones are filtered out by testing if a candidate behaves differently from the original library function.
example.
fig.
a gives part of the documentation of the library function add int index e element in fig.
.
the textcan be dividedintofour parts the declaration of the function including explanations of the parameters shown as box4 circlecopyrtin the figure the functionality of the method boxes2 circlecopyrtand3 circlecopyrt the exception handling logic box circlecopyrt .
we take box circlecopyrtas an example to demonstrate our idea.
the parse tree generated by an off the shelf nlp tool is shown in fig.
b .
we perform further processing on the tree including transforming the tree structure to accommodate ambiguity and recognizing parameters to produce a treelikeintermediate representation ir as shown in fig.
c .
we then try to use the primitive tree patterns to create a tilingof their.inthis case thetree template ofthe insert primitive as shown in fig.
d alone can cover the whole ir tree.
as such the model code for the sentence is gener381insert o1 at o2 tag this elements o1 d insert primitiveinsert element atindex tag this c ir for insert sentencenp npppnppp npvps np list this in position specified the at element specified the insertsvbz dt vbn nn in dt vbn nn in dt nn b syntactic parse tree of the insert sentence box in subgraph a method specific informationprimitive provides code templatepublic void add int index e element inserts the specified element at the specified position in this list.
shifts the element curr ently at that position if any and any subsequent elements to the right adds one to their indices .
parameters index index at which the specified element is to be inserted element element to be inserted throws indexoutofboundsexception if the index is out of range index index size a the partial comments of the method add of the class arraylist1 elements element size size for int i size i index i elements elements if index index size throw new indexoutofboundsexception public void add int index e element f generated model elements element e model for insert sentence figure motivation example.
a ted as in circlecopyrt.
note that the parse tree nodes that denote the variable names i.e.
element and index allow us to instantiate the parameters o1ando2in the primitive.
the code for the other sentence and the exception handling description is similarly generated.
note that boxes circlecopyrtand9 circlecopyrt have a different order than that in the text.
our technique generates multiple candidates including those with different orders and use testing to prune out the invalid ones.
.
design fig.
gives the overarching design of our approach.
the whole system takes a javadoc as input and uses the javadoc parser pre processor text analysis engine tree transformer intermediate representation ir generator model generator and model validator to generate models.
in particular the javadoc parser takes the javadoc in a structured html format as input and extracts contents from both class and method description.
the pre processor performs some synonym analysis and enhances the extracted sentences.
then a tree structure is generated for each sentence by the text analysis engine which leverages stanford parser and domain specific tags to perform the natural language processing nlp .
after that the tree transformer automatically generates variants for some of those tree structures.
these variants represent the different interpretations of the sentence in the context of java programming.
the variants as well as the original tree structure are processed by the ir generator which identifies and marks function parameters in each tree structure.
the model generator searches for tilings of the irs using the tree patterns of the pre defined primitives and eventually generates multiple model candidates for each function.
these candidates are passed to the model validator to filter out candidates that behave differently from the original function.
the model validator makes use of randoop to automatically generate test cases.
the first candidate that passes all the test cases is the resulting class model.
.
pre processor the pre processor accepts the descriptions extracted by the javadoc parser and performs three kinds of analysis.javadocjavadoc pa rsertext analysis en gine tree node t ransformermodel g eneratormodel v alidatorclass mo delpre processor ir g enerator figure overview of our solution t able the documentation of the method indexof of class arraylist public int indexof objecto r eturns the index of the first occurrence of the specified element in this list or if this list does not contain the element.
more formally returns the lowest index isuch that o null ?
get i null o.equals get i or if there is no such index.
specified by indexof in interface list e o verrides indexof in classabstractlist e p arameters o element to search for returns the index of the first occurrence of the specified element in this list or if this list does not contain the element.
equivalence analysis.
o ur pre processor classifies words into pre defined semantic classes based on domain dictionaries.
for example the words adds and inserts are semantically equivalent in method description.
classifying them into one category can relieve the effort of identifying mappings for each word in the generated irs.
redundant information elimination.
we attempt to remove sentences that are used to elaborate other sentences.
just to name a few sentences starting with in other words namely more formally and that is to say are explanations of other sentences and they will be eliminated in our system to prevent redundancy in analysis.
sentence augmentation.
the sentences in return descriptions and exception descriptions in javadocs tend to be incomplete which makes it difficult for the stanford parser to analyze.
our sentence augmentation component aims to enhance those sentences for easy parsing.
for return descriptions the verb return is often omit382ted.
for example t rue if this list contained the specified element is the return description for the remove object o method in the arraylist class.
in this case our approach checks whether the sentence is under the tag return in thecorrespondingjavadoc.
ifso theverb returns is added to the sentence.
for exception descriptions the throw behavior and the exception thrown are typically omitted.
for example if this vector is empty is the exception description for thelastelement method in the vectorclass.
the verb throwand the exception nosuchelementexception are missing.
in this case our approach checks whether the sentenceisunderthetag throw inthecorrespondingjavadoc.
if so the phrase throws nosuchelementexception is added to the sentence to augment the original sentence.
note that the exception name can be easily extracted and used in the augmentation e.g.
in fig.
a .
.
text analysis engine the text analysis engine generates a grammatical tree structure for each pre processed sentence through natural language processing.
to do this we leverage the state ofthe art stanford parser with domain specific tags.
the stanford parser parses a sentence and determines postagsassociatedwithdifferentwordsandphrases.
these tags are essential to the generation of the syntactic tree structure for the sentence.
there are some words that represent nouns in programming while representing adjectives in general linguistics.
for instance in the sentence returns true if this list contains the specified element.
true should be regarded as a noun in programming rather than an adjective.
but the stanford parser would identify it as an adjective.
in addition the stanford parser may incorrectly identify some words as nouns while in fact they should be marked as verbs.
for example returns in the mentioned description is a verb but it is incorrectly identified as a noun by the stanford parser.
therefore a pos restricting component is added to the stanford parser to force it to use our pre defined tags for some programming specific words.
some pre defined tags are as follows noun true false null verb returns sets maps copies adjective reverse next more empty .
tree transformer the tree transformer transforms the original tree structure generated by the stanford parser to produce variants.
each variant corresponds to a different interpretation of the sentence.
we need to generate multiple interpretations of a sentence due to ambiguities in natural languages and consequently we will generate multiple model candidates which are passed to the model validator discussed in section .
to filter out incorrect models.
text analysis engines like the stanford parser are able to generate multiple trees with different semantics.
unfortunately these parsers cannot understand the real semantic of a sentence especially when domain knowledge is involved.
the stanford parser can generatekparse trees for a sentence with kgiven by the user.
however thereis noway for the parser toguarantee thatthe tree with the expected meaning is generated for a sentence even with a large k.returns the head of this deque or null if this deque is emptyif this deque is empty returns the head of this deque or null.
returns the head of this deque null if this deque is emptyreturns the head of this deque or returns the head of null if this deque is empty .
or figure syntactic trees with unexpected meanings t ake the method description returns the head of this deque or null if this deque is empty as an example and we set the value of kas .
none of the parse trees generated by the stanford parser gives the exact meaning conveyed by this sentence in the context of programming which should be returns the head of this deque or returns null if this deque is empty .
two of the trees with unexpected meanings are shown in fig.
.
some subtrees are summarized to be one tree node to save space.
for example the left tree expresses if this deque is empty returns the head of this deque or null while the right tree conveys returns the head of this deque or returns the head of null if this deque is empty .
if the value of kis large a lot of computation will be wastedingeneratingandanalyzingtreeswithincorrectmeanings.
through an analysis of the generated trees we found that in most cases the stanford parser is good at recognizing individual phrases of a sentence in the context of programming and the places where ambiguity arises are those phrases starting with or and and .
we also discovered that by lifting up or pushing down the node or or and and its right siblings for only a few number of times in the tree produced by the stanford parser1 we can get the tree which conveys the expected meaning of the sentences.
thus we propose algorithm to transform the parse tree from the stanford parser to produce a set of variants by repositioning only the conjunctive nodes.
this algorithm takes the root of the tree generated by the stanford parser as an input and produces a set of tree variants represented byvariantset .
first variantset is initialized to contain only the original treeroot lines .
then the main loop is executed to generate variants lines .
in each iteration lines make a transformation of each tree in variantset to get variants and add them back to variantset .
the transformation process is the function transform shown in fig.
.
when the set does not change any more line a fix point is reached meaning all possible variants have been identified and the process terminates.
as can be seen in fig.
for each tree node n if it is a node representing and its right sibling node represents or or and the function transforms the tree by lifting up and pushing down the node nand all its right siblings.
the 1the parser by default returns a single tree that it considers havingthe highest probability of denotingthe real semantics of the sentence.
383transform r n c children n uniondisplay ctransform r c braceleftbiggliftup r n pushdown r n a node followed by a or or and node otherwise figure function transformation algorithm t ransforming one tree node function transformtree input r oot root of the original tree node output v ariantset a set of variants of the original tree node v ariantset variantset variantset root whiletruedo oldset variantset for all tree variantset do variantset variantset transform tree tree end for ifvariantset oldsetthen break end if end while return variantset r or a nd!p c1r or a nd p c1 c2 c2 a lifting up.r or a nd p1 c1p2r or a nd!p1 c1 p2 b pushing down.
f igure lifting up and pushing down nodes.
the shaded nodes are repositioned.
lifting up operation is shown in fig.
a while the pushing down operation is shown in fig.
b .
in other cases the tree keeps unchanged.
consider the documentation in table .
the left tree in fig.
is generated by the stanford parser for the sentence returns the index of the first occurrence of the specified element in this list or if this list does not contain the element .
from this tree we get the semantics returns the index of the first occurrence of the specified element in this list or returns the index of the first occurrence of if this list does not contain the element .
which is not the expected meaning of this comment sentence.
by lifting up the nodes or and if this list does not contain the element on the seventh layer of the left tree five times we get the tree on the right which conveys the exact meaning of this comment.
note that since our tool does not know which variant represents the intended meaning it generates all of them and then selects the right one through testing.
from fig.
we can see that the number of variants generated by lifting up the left tree is five which is acceptable.
.
intermediate representation generator ourintermediaterepresentationgeneratormanipulatestrees generated by the tree transformer to constructs irs by substituting subtrees identifying parameters and adding labels based on programming domain knowledge.
we cannot directly translate a generated tree to code unless we associate tree nodes with code artifacts.
to achieve this our ir generator performs two major tasks parameter recognition which identifies parameters loop and conditional structure recognition.
parameter recognition this component recognizes pa returns the index of the first occurrencereturns the index of the first occurrence of the specified element in this list or returns the index of the first occurrence of if this list does not contain the element.
of of the specified element in this list if this list does not contain the element returns the index of the first occurrencereturns the index of the first occurrence of the specified element in this list or returns if this list does not contain the element.
of ofor or if this list does not contain the element the specified element in this list figure lifting up nodes example.
r ameters in method descriptions.
javadocs refer to parameters using several different descriptions which are summarized as patterns shown in column pattern in table .
however due to the complexity and ambiguity of natural languages these patterns may not always imply parameters.
in some cases even the occurrences of the same word as the parameter name do not indicate the corresponding parameter.
for example the description of the method set int index e element in the class arraylist is replaces the element at the specified position in this list with the specified element .
the phase the element does not refer to the parameter element but the specified element does.
our solution is again to generate all possibilities and let the model validator to determine the right mappings of parse tree nodes to parameters .
algorithm describes the process of recognizing placeholders of parameters in method description.
it takes three arguments i.e.
all theparameters ofthe methodbeingmodeledparams the root of the parse tree root and a predefined list of synonyms synonyms .
the output of this algorithm is represented as irset which is a set of irs generated by recognizing parameters of the tree.
the algorithm works as follows.
the first step is to initialize irsetto contain the original tree root lines .
next the main loop is executed to recognize parameters in root lines .
the algorithm recognizes the parameters one by one with each iteration responsible for recognizingone parameter on thetree s .
since there are multiple possible places that indicate a parameter multiple trees may be generated by associating the parameter with different tree nodes.
each iteration in the loop handles one tree irfrom the previous round.
the resulting trees are stored in newset.
recognizing a variable on a tree is done through a recursive function traverse shown in fig.
which tries to match the parameter with each tree node.
since the parameter can match multiple nodes corresponding to that there are multiple words that seem to mean the parameter the function may produce multiple trees each representing one possible match.
at the end each tree in irsetis a tree with recognized parameters and each tree node represents at most one parameter.
384algorithm i dentifying parameters in one tree function identifyparams input p arams all the parameters of the method being modeled root root of the original tree node synonyms the predefined list of synonyms output i rset a set of irs after recognizing parameters i rset irset irset root for all param params do newset for all ir irsetdo newset newset traverse ir param end for irset newset end for return irset traverse t p c children t uniondisplay ctraverse c p recparam t p figure the function traverse function recparam in fig.
is to recognize a parameter by pattern matching.
the patterns are described in table .
particularly if a subtree rooted at tmatches a tree pattern in the first column and satisfies the condition in the second column tis replaced with a node representing the parameter.
the third column shows some examples.
for example the rule in the first row means that if a subtree denoting a phase the w 1w2 is observed and the concatenation of w1 andw2is a synonym of the parameter name.
the subtree is replaced with a node representing the parameter.
other rules are similarly defined.
it is worthy mentioning that we take special care of the word this as it often has special meanings in our context.
in particular for every occurrence of phrase this word with word being the class name or its abbreviation we label the corresponding tree node with a special tag this indicating the code to be generated operates on the receiver object.
for example this list is used to represent the receiverarraylist object in thedocumentationof arraylist .
take the right tree in fig.
as an example.
according to the second rule our approach substitutes the subtree representing the specified element with a node representing variable o which is further tagged with this due to the phrase in this list .
structure recognition this component recognizes programmingstructuresindicatedinmethoddescriptions.
documentation descriptions use some special words to specify how the behavior is carried out such as the condition under which the behavior will execute and how many times the behavior should execute.
these restrictions are projected to programming structures like loops and conditionals which are vital for generating models.
our approach recognizes these structures by recognizing subtrees containing the special words and substituting subtrees as well as adding tags.
loop structure.
plurals and singular nouns modified by each tend to imply that the behavior should be executed for multiple times which indicates a loop structure.
for example the phrase all of the elements in the sentence inserts all of the elements in the specified collection into this list starting at the specified position of the method addall int index collection ?
extends e c inarraylist indicates thatthe insert operation should execute multiple times.
thus the model for this behavior must have a loop structure.
in this case our approach adds a looptag to the ir and substitutes the subtree representing all of the elements with a node representing elements .
some phrases in natural language do not explicitly indicate a loop structure.
instead they can imply the iteration order.
for example the subtree representing the first occurrence of in fig.
a implies that if there is a loop structure for this behavior it should iterate from left to right.
in this case our approach adds a ltrtag to the ir and trims the subtree representing the first occurrence of .
conditional structure.
words like if and when in natural languages indicate a conditional statement in programming while words like otherwise indicate an else branch.
our approach adds tags ifandelseto the subtree that is modified by these words.
for example in fig.
a an if tag is added to the subtree representing .
in addition our technique recognizes whether the description is affirmative or negative to determine the condition of the ifstatement.
for example the behavior contain in fig.
a is modified by does not .
it means that the condition of theifstatement should be the negation of the result of the contains behavior.
in such cases our approach trims the subtree representing does not and adds a flag to the node representing contain .
for instance we get the ir in fig.
b by recognizing structures of the ir in fig.
a .
.
model generator in this section we introduce our method of generating models based on irs.
for each ir a tiling by the tree patterns of primitives is identified.
the corresponding code snippets of the primitives are assembled to constitute the model of the ir.
the code snippets for all the irs in a methoddescriptionarefurtherintegratedtogainthemethod model.
the class model is eventually generated based on the individual method models and the class information collected earlier.
since one sentence can have multiple irs multiple method class model candidates are generated.
for all the java container classes e.g.
lists queues and stacks weobservethatitissufficienttouseaone dimensional array to model them.
as such many of our primitives are essentially operations manipulating the underlying onedimensional array.
using primitives avoids generating models from simple and low level expressions and statements which requires exploring a very large search space for the proper combination.
table 3presents partof the pre defined primitives.
each primitive has a tree pattern and a piece of code template on the underlying one dimensional array .
the tree pattern describes the syntactic structure of the description of the primitive.
it is used to cover part of an ir tree to create a tiling.
each cell in the table includes the name of the primitive the description and the tree pattern.
the corresponding code templates are elided.
each primitive has a set of parameters which are also denoted in the tree pattern.
the primitive insert o1 o2 represents thefunctionalityof inserting an object o1too2.
the corresponding code template implements this functionality on the one dimensional array.
its tree pattern essentially describes how such functionality is expressed in a natural language and hence can be used for ir tree tiling.
we also have other primitives such as copy andapply.
we have a total of primitives.
385table patterns for labeling a parameter n. symbols w w1andw2denote words.
pattern condition example the w1 w2w1 w2a nd nare synonymous setsize int newsize instringbuffer throws arrayindexoutofboundsexception if the new size is negative .
the specified wwa ndnare synonymous get intindex inarraylist returns the element at the specified position in this list .
the w specifiedwa ndnare synonymous add int index attribute object inattributelist inserts the attribute specified as an element at the position specified .
the specified ww the type of n add attribute object inattributelist addsthe attribute specifiedas the last element of the list .
the w specifiedw the type of n append stringbuffer sb instringbuffer appends the specified stringbuffer to this sequence .
the w argumentw the type of n append charc instringbuffer appends the string representation of the char argument to this sequence .
the argumentremoveelement object obj i nvector removes the first lowest indexed occurrence of the argument from this vector .
the wwa ndnare synonymous set int index e element inarraylist replaces the element at the specified position in this list with the specified element .
return the index contain!
or the element o o tag thisif this list does notof the first occurr ence of a irs after parameter recognitionreturn the index tag ltr contain tag tag if!or the element o o tag thisofthis list b irs after structure recognitionint index1 if o null for int i i size i if elements null index1 i break else for int i i size i if o.equals elements index1 i break int index2 if o null for int i i size i if elements null index2 i break else for int i i size i if o.equals elements index2 i break if index2 return else r eturn index1 c model f igure irs and model.
the tiling algorithm is very similar to that used in compiler code generation .
it is a greedy algorithm that tries to cover an ir tree from the root to the leaves.
particularly it first tries to cover a subtree starting from the root of the original tree .
it then tries to cover the remaining parts of the tree until a tiling is found.
example.
consider the ir tree in fig.
b .
the algorithm first covers the top part of the tree with the pattern of the primitive return which returns different values depending on a condition.
it then covers the left sub tree with the indexof primitive and the right sub tree with the contain primitive.
the tiling is shown in fig.
.
the resulting code is shown in fig.
with the order of circlecopyrt circlecopyrt and then circlecopyrt.
observe that the code generation is bottom up boxes circlecopyrt and2 circlecopyrtfor theindexof andcontainprimitives respectively andthenbox circlecopyrtisforreturn.
alsoobservethatalthoughthe generated model functions correctly it is a bit redundant as the code templates for the first two primitives are essentially the same.
this redundancy is easily precluded through a post processing step.
we will assemble code snippets of each ir to form the method model during which procedure our technique also explores the different orders of the code snippets.
.
model validator as pointed outbefore our approach can generate multiple model candidates due to the ambiguity of natural languages and the limitation of current nlp tools.
but most of them have inconsistent behaviors with the original library whichreturn the index tag ltr ofo tag thiscontain tag this tag if!or ol l c1 indexof o this ltr r c2 contain this o t c3 return c1 c2 t r figure tiling an intermediate representation.
m akes it necessary to filter out the inconsistent model candidates.
our model validator accepts multiple model candidates and excludes the candidates that behave differently from the original method.
we leverage the existing work randoop which can automatically generate test suites for java classes to help us check whether the generated models preserve the behavior of the original method s .
for each class we generate test cases on average.
.
ev aluation we have implemented a prototype and conducted a set of experiments to evaluate the prototype.
in our evaluation we focus on two aspects .
the effectiveness of the model generation technique.
.
using the generated models in other analyses.
386table primitives copy o1 o2 copy the content specified by o1into the destinationo2.
copyo1intoo2return o1 o2 o3 return o2if condition o3holds o1otherwise.
return o1 or o2o3throw o throw an exception specified by o. throw oremove o remove objectofrom the container.
remove o tag this insert o1 o2 insert object o1at a location specified by o2.
insert o1 at to o2 tag this isempty o check whether ois not an empty container.
o ?is emptyshift o left right shift an objecto.
shift o1 to left rightset o1 o2 set a field o1of the receiver object to o2.
set o1 tag this with o2 apply o1 o2 appy a primitive operation o1to an object o2.
apply o1 to for o2contain o1 o2 check whether the container o1 does not contains the object o2.
o1 ?contain o2indexof o1 o2 t get the index ofo1ino2by searching elements contained in o2.
the index tag t of o1 t ag o2 elementat i get the element at the position specified by indexi.
the element at i table overall result class t m c gt vt cn arraylist .
.
v ector .
.
s tack .
.
a rraydeque .
.
l inkedlist .
.
h ashmap .
.
l inkedhashmap .
.
h ashset .
.
l inkedhashset .
.
attributelist .
.
rolelist .
.
r oleunresolvedlist .
.
stringbuffer .
.
s tringbuilder .
.
summary .
if not specified in the following sections the evaluation w as conducted on a machine with intel r coretmi7 cpu .
ghz and 8gb main memory.
the operating system is ubuntu .
and the jdk version is .
.
effectiveness in model generation to evaluate the effectiveness of our model generation we applied it to java container like classes.
table shows the results.
column class lists the names of the modeled classes which are grouped by different packages.
the packages from top to bottom are respectively java.util javax.management javax.management.relation and java.lang .
for each class column t lists the total numberofmethodsoftheoriginal jdkclass.
column m lists the number of methods that our tool can successfully model.
here the models are functionally equivalent to the original methods.
column lists the ratio of modeled methods to total methods.
column c lists the number of model candidates for each class.
column gt lists the time used to generate class model candidates in seconds.
column vt lists the time used to validate class models using randoop in seconds.
column cn lists the average number of test cases generated by randoop.
row summary lists the total numbers for columns t and m and gives the average of column .
from the results in table we have the following observations.
first we can generate models for most methods in these classes which indicates the effectiveness of our approach.
for the last five classes the percentage is relatively low.
the low ratios ofthe classes attributelist rolelist and roleunresolvedlist result from the incompleteness of their documentations.
for example the method add int index object element inattributelist should throw an exception java.lang.indexoutofboundsexception whenindexis less than or greater than the length of this list.
but no sentences describe this behavior which makes it impossible for our tool to generate the corresponding code.
our approach handles each sentence separately while descriptions of some methods use several sentences todepictone primitive behavior.
this leads to the low ratios of the classes stringbuffer andstringbuilder .
take the method insert int index char str int offset int len ofstringbuffer as an example.
the insertion operation is described using the following three sentences inserts the string representation of a subarray of the str array argument into this sequence.
the subarray begins at the specified offset and extends len chars.
the characters of the subarray are inserted into this sequence at the position indicated by index .
currently our approach cannot handle such cases.
we plan to correlate multiple sentences in the future.
second both the time used to generate models and the time used to verify models are acceptable.
the time used to generate models for stringbufferandstringbuilder are much longer than that of the otherclasses whichresults from thefact thatthereare much more sentences to be analyzed in these two classes.
much of the time used to verify models is spent in generating test cases by randoop.
the average time used to generate a series of test cases for one class model is seconds.
third the validation time and the number of the candidates has linear relationship.
the pie charts in fig show more statistics.
fig.
a gives the distribution of the tree variants derived from a tree due to the lift up and push down transformations.
each tree corresponds to one sentence.
fig.
b presents the distribution of the number of irs derived from a tree after parameter recognition.
fig.
c shows the distribution of the numbers of models generated for a sentence.
from these three pie charts we can see that the number of generated models of each sentence is not simply the product of the number of tree variants and the number of irs of each tree variant.
the reason is that we cannot generate models for some irs which cannot be tiled with our proposed primitives.
fig.
d shows the distribution of the number of model candidates generated for each method.
only one model is generated for a method in the majority .
.
.
.
.
a tree varia nts97.
.
.
b irs .
.
.
c models of e ach sentence88.
.
.
d models of e ach method figure distributions .
.
.
.
.
.
.
figure line of code comparison with jdk c ases .
and the maximum number of models for a method is with a percentage of .
which is acceptable for the validation step.
fig.
shows the comparison of the line of code between our models and the original jdk.
we counted the line of code for all functions including its dependencies and divided the line of code of the original jdk by ours.
from the chart we can see that for normal cases the original jdk is to times larger than our models.
there are some cases that our models are larger because some jdk methods calls jni functions like system.arraycopy while our models are completely implemented in java.
and there are some extremal cases that the code size is large such as the model for hashmap.clone which needs to check boundaries and clone all objects inside it.
fig.
shows the distribution of the appearances of the primitives in documentation.
we observe that add remove andshifttake a large portion because our models focus on container classes.
the primitive throwtakes a large portion as well because java api document clearly defines this behavior for many functions.
fig.
shows the numberof primitives used tomodel each method.
most methods can be constructed by only a few primitives.
.
our models in static taint analysis to evaluate the effectiveness and efficiency of our models in static analysis we conduct a taint analysis on android that detects the undesirable disclosures of user inputs to .
.
.
.
.
.
.
.
.
.
.
.
figure distribution of primitives in documents25.
.
.
.
.
figure of primitives per method model apps figure efficiency improvement distribution p ublic channels on apps that were previously known to have user input disclosures.
we limit the sinks to internet access and log writing and set a minutes timeout for each app in our experiment.
we first run the analysis with the original jdk source code and then replace part of the jdk with our models and then compare the number of information leak warnings reported and the performance.
among the apps app does not have any use of the modeled methods and is hence excluded other apps are also eliminated because they time out or run out of memory using both our models and the jdk implementation.
the results of the remaining apps are summarized as follows.
effectiveness.
the analysis reports the same set of information leak warnings for both versions for almost all apps except app com.yes123.mobile which is reported to have paths using our models and paths using jdk.
we manually inspect the differences and find that the two paths contain invocations of arraylist.toarray object .
the jdk implementation calls a jni method system.arraycopy to copy data from the 1st argument to the 3rd argument.
our model provides an implementation of the functionality such that static analysis is not blocked by the absence of java code.
we have also found of the apps have similar jni calls such that the static analysis cannot handle those calls properly.
however since those calls are not on any leak path from the source to the sink they do not induce differences in the bug report.
efficiency.
fig.
shows the performance comparison by presenting the distribution of the improvement.
the performance improves more than for apps by using our model.
the maximum improvement is and the average is even with a small portion of the jdk library replaced by our models.
.
our models in dynamic slicing in addition to the static taint analysis on android applications discussed in section .
we also evaluate our models in dynamic program analysis techniques namely java dynamic slicing.
we utilize javaslicer and benchmark programs including specjbb funkyjfilter listappend batik in dacapo and some unit tests with jtreg .
javaslicer is a dynamic slicing tool.
we first run the program with javaslicer and inputs.
during runtime javaslicer collects traces of the execution of this program.
then for each benchmark program we choose one variable as the input and javaslicer reports the number of unique java bytecode instructions and all the detailed instructions in the dynamic slice for this given variable.
note that an instruction that gets executed multiple times is reported only once.
for all the benchmark programs we run them with parameters given as examples in their manuals and choose the generated result valueas the starting pointof the slicing.
388table dynamic slicing results naive approach our model slice size time slice size time specjbb .
.
funkyjfilter .
.
listappend .
.
batik .
.
unit tests .
.
all experiments are conducted successfully.
t o demonstrate the results we compare our models with a naive approach that considers any output of a method depends on all the inputs.
the results are shown in table .
the first column lists the names of the benchmark programs.
for each program we show the size of the slice and the running time of using the naive approach column and respectively and using our models column and respectively .
as shown in the table for all the programs javaslicer produces slices of smaller size with our models than the naive approach.
due to the characters of these different benchmarks we get different results.
on average the slice size is32timessmaller duetothehigherprecisionofour models.
for the same reason it takes less time to produce slices using our models than using the naive approach.
.
limitations ourtechniqueheavilydependson thequalityof documentation.
if the documentation is incomplete or uses strange syntax or wordings our tool may not generate the correct models.
this is a general limitation for many nlp based techniques .
our technique relies on a set of syntactic patterns to recognize parameters and primitive operations.
these patterns are mainly derived from javedocs.
they may not be generally applicable.
however we argue that our technique is general in principle and it is a valuable step towards automated model generation which is a hard problem in general.
we envision the writing style of documentation may not change as frequently as the library implementation.
as a result our technique can serve as an automated approach to quickly generate models for a large number of library functions as demonstrated by our results.
in the future it may be a beneficial practice to enforce a fixed documentation style.
furthermore ourcurrentstudylargelyfocuses oncontainerlike libraries as they are the most widely used category.
it is very difficult to model the precise functionalities of some special purpose libraries such as math libraries.
however we also observe that having the precise models for those libraries are unnecessary in many applications.
for example the input output dependencies of most math library functions are very simple despite their complex computation.
it is also possible that the test cases used in model validation are not sufficient so that we admit some incorrect models.
even though we have not encountered such problems in our experience it would be interesting to use more rigorous validation techniquessuchas equivalencechecking.
.
related work our approach is related to previous works closely on two areas documentation analysis and environment modeling.
documentation analysis.
previous researchers analyze natural language documents for many purposes.
proposes methods to infer method specifications from api de scriptions.
try to detect code document inconsistencies by leveraging nlp and program analysis.
gives programmers suggestions for usage of apis based on mining the usage patterns.
analyze bug reports to remove duplicates.
tries to help generate use cases in real world development by inspecting language documents.
use commentswithothertechniquestodetectinconsistenciesbetween comments and code.
in contrast to these approaches our approach aims to help program analysis by constructing models forlibraries.
weonlyusejavadocs buttheapproach can be easily expanded to other types of natural language documents e.g.
comments bug reports.
environment modeling.
to reduce manual efforts for environment models various approaches have been proposed.
derivesenvironmentmodelsfromuser provided environment assumptions which capture ordering relationships among program actions.
ocsegen is an environment generation tool for open components and systems which generates both drivers and environment stubs by analyzing java byte code.
modgen makes uses of program slicing to generate an abstract model of a class and it focuses on optimization of library classes by reducing their complexity.
discusses these two mentioned tools on how they can be applied to generate android environment models.
acquires the input output specification by sampling given binary implementations of the methods being modeled and uses smt solver to construct models which satisfy the specification.
unlike previous approaches we automatically construct environment models by analyzing javadocs which give abundant information about the behaviors of each library method.
.
conclusion based on the idea of applying natural language processing techniques and program analysis techniques to model libraries we identify and overcome the challenges of applying nlp techniques on real code generation and build a prototype of a modeling tool that can automatically generate simplified code for java container like libraries from javadocs.
on average the size of the generated model is only one third of that of the original code base.
we also apply our technique to help other program analysis that needs reasoning software runtime environment.
the results show that our models can help both static and dynamic analysis.
.
acknowledgement we thank the anonymous reviewers for their constructive comments.
this research was partially supported by nsf grants ccf ccf ccf and ccf and the cas safea international partnership program for creative research teams nserc and an ontario early researcher award national key basic research program of china no.2014cb340703 national science foundation of china no.
no.
no.
no.
and no.
.
any opinions findings and conclusions in this paper are those of the authors only and do not necessarily reflect the views of our sponsors.
.