locus locating bugs from software changes ming wen rongxin wu shing chi cheung department of computer science and engineering the hong kong university of science and technology hong kong china mwenaa wurongxin scc cse.ust.hk abstract various information retrieval ir based techniques have been proposed recently to locate bugs automatically at the le level.
however their usefulness is often compromised by the coarse granularity of les and the lack of contextual information.
to address this we propose to locate bugs using software changes which o er ner granularity than les and provide important contextual clues for bug xing.
we observe that bug inducing changes can facilitate the bug xing process.
for example it helps triage the bug xing task to the developers who committed the bug inducing changes or enables developers to x bugs by reverting these changes.
our study further identi es that change logs and the naturally small granularity of changes can help boost the performance of ir based bug localization.
motivated by these observations we propose an ir based approach locus to locate bugs from software changes and evaluate it on six large open source projects.
the results show that locus outperforms existing techniques at the source le level localization signi cantly.
map and mrr in particular have been improved on average by and20 respectively.
locus is also capable of locating the inducing changes within top for of the bugs.
the results show that locus can signi cantly reduce the number of lines needing to be scanned to locate the bug compared with existing techniques.
ccs concepts software and its engineering !software testing and debugging software evolution information systems!retrieval models and ranking keywords bug localization software changes information retrieval software analytics .
introduction bug localization using information retrieval ir based techniques has been shown to be e ective.
it enjoys the advantage of not requiring program traces whichmay not be obtainable in real life systems.
the intuition is that bug reports and the corresponding buggy source les share similar tokens and thus bug locations can be retrieved from bug reports based on the token similarities calculated by various retrieval models .
although the general e ectiveness of ir based techniques has been demonstrated recent studies have identi ed two major issues that can greatly hinder the practical usefulness of these techniques.
wang et al.
pointed out that existing works produce results at the source le level which is coarse grained and still leaves developers with a large amount of code to examine before they successfully nd the buggy code.
parnin et al.
pointed out that locating buggy modules in isolation may not provide adequate information for developers to understand the bugs and more contextual clues are desired.
to address these issues we propose to locate bugs in terms of software changes rather than source les.
our idea is inspired by the observation that bug inducing changes i.e.
the changes which introduce a bug are one of important clues for developers to understand and x a bug.
we nd that bug inducing changes can bring about the following three bene ts.
first since a bug inducing change records the developer who committed it it can help activities like bug triaging.
our empirical study shows that around to80 of bugs are xed by the developer who introduced the bug.
second reverting a bug inducing change is a common way to x bugs as pointed by existing work .
third it has been shown that the granularity of software changes is ne grained and debugging at the change level can signi cantly save e orts as compared with that at the source le level .
since bug inducing changes are useful for debugging we then investigated the feasibility of applying ir based techniques to locate bugs at the change level.
while locating bug inducing changes is challenging due to the massive number of changes and the limited information in bug reports we observe that software changes can indeed facilitate ir based bug localizations.
first change logs describing the intention or functionality of the changed code often contain substantial information.
common tokens are found between the log of a bug s inducing change and its bug report.
these common tokens can be leveraged by ir based techniques to locate bug inducing changes.
second change hunks i.e.
a group of contiguous lines that are changed along with contextual unchanged lines are intrinsically small in size.
bug related changes are associated with small size commits which indicates that using change hunks can be an alternative way to segment source les .
this can mitigate the noise problem identi ed by existing studies in locating bugs using large les.
lastly the performance of bug localization can be boosted by leveraging change histories.
bug xing permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
histories inferred from the changes have been widely used for defect prediction and bug localization .
based on these observations we propose an ir based bug localization approach called locus which can locate bugs at both the change and source le levels.
unlike existing techniques locus retrieves information from software changes instead of source les.
besides extracting natural language tokens from software changes as current techniques do locus also extracts the code entity names i.e.
package name class name method name .
the reason is that these entities modi ed in the changes may alter the behaviors of the system or even induce bugs.
therefore two corpora based on natural language tokens and code entity names are created.
locus separately indexes these two corpora and generates two rankings by applying the vector space model vsm which is explained in section .
apart from these two corpora locus also leverages the information of change histories to generate an additional ranking as follows.
for source le level localization a suspicious value for each le to contain faults is computed based on its xing histories.
for change level localization a boosting score for each change is calculated based on its committed time and the bug reporting time.
locus later combines these three rankings and generates the nal localization results.
we evaluated locus on six large open source projects.
for bug localization at the source le level the results show that it can successfully locate the buggy les and rank them within the top for of the bugs and within the top for74 .locus outperforms the current state of the art tools for all subjects.
the map and mrr are respectively improved by and20 on average.
to the best of our knowledge locus is the rst ir based technique to locate bug inducing changes based on bug reports without requiring any knowledge of the associated bug xing patches.
although there are some studies for collecting bug inducing changes all of them require the knowledge of bug xing patches which is unavailable before the bug is xed.
the experiments showed that locus can locate the inducing changes and rank them within the top for of the bugs.
our results further show that the number of lines which need to be scanned to locate the bug has been reduced signi cantly compared with existing approaches.
these results are promising and show the e ectiveness of locus .
in summary the main contributions of this paper are we conducted an empirical study to show the usefulness of bug inducing changes and the bene ts that ir based bug localization techniques can get from software changes.
we proposed locus a new ir based bug localization method that can e ectively locate bugs from software changes.
to the best of our knowledge we are the rst to create a text corpus from software change hunks in ir based bug localization techniques.
we evaluated locus on six open source projects.
the results indicate that locus can locate bugs with high accuracy and outperform the existing state of the art approaches at the source le level.
besides locus can also get promising results in locating bug inducing changes.
the rest of the paper is structured as follows.
section introduces the background and motivation.
we present our approach and its architecture in section .
the experiment setup follows in section which covers the datasets evaluation metrics and the four proposed research questions.section presents the experimental results in detail and answers the four research questions.
threats to validity are covered in section .
related work is introduced in section and section concludes this work.
.
background and motivation .
change hunks when software evolves changes are committed to x bugs introduce new features or refactor source codes.
a committed change could modify multiple les.
a le can be modi ed at one or more places and each of them is called a hunk or a delta .
a hunk is a group of contiguous lines that are changed along with contextual unchanged lines .
figure shows two hunk examples of source le wsservercontainer.java .
one introduces a bug and the other xes the bug.
we call those modi ed lines the changed lines which are highlighted in color in the example.
the contextual lines are those unchanged lines which are displayed in black in the example.
changes made by developers can induce new bugs .
as a system evolves the number of bugs induced by committed changes will outnumber those that are induced by the initial codes code introduced in the rst version of a source le .
figure shows the number of bugs caused by the initial source les and that by the subsequent software changes of a popular apache project tomcat.
we extracted all the changes starting from the release time of tomcat which is mar to aug .
fixing changes among all these changes were then identi ed by heuristic and the szz algorithm was then applied to identify the inducing changes based on these xes .
.
.
.
.
.
.
.
.
.
1number of bugs time normalized to initial code later changes .
.
.
.
.
figure comparison between the number of bugs induced by software changes and the initial source files of tomcat after obtaining the inducing changes we distinguished whether the bug is introduced by the initial code or the subsequent changes.
figure shows that the number of bugs caused by the initial code is larger than that induced by changes at the beginning after the release of tomcat.
however more bugs are soon induced by the subsequent committed changes and the gap between the number of the two types of bugs becomes larger and larger.
.
the uses of bug inducing changes locating buggy modules in isolation may not provide adequate information for developers to understand and x a bug .
we found that the information of bug inducing changes has the potential to address this issue.
first most of the bugs are introduced by changes as discussed in section .
.
second bug inducing changes contain important information for developers to understand and x a bug.
we found evidence of this in apache bug reports and eclipse bug 263reports that contain discussions about bug inducing changes.
the following are extracts of some of the discussions.
this regression was caused by bugzilla .
that patch was reverted and this is now xed.
ouch that s my fault.
.
.
.
we should revert revision asap.
to further understand developers perspective on the usefulness of bug inducing change we sent emails to developers from open source projects surveying whether bug inducing changes helped x their bugs and what actions they would take if bug inducing information was available.
the following shows some of the representative feedback.
it can be a eureka moment for the developer where they see the inducing change and say i know exactly why this is happening thus resulting in a x typically in a matter of days even hours.
it really is a critical piece of the puzzle.
the action taken is usually getting the responsible developer to either a back out the change or b code and land a follow up x as soon as possible.
here we summarize three aspects to show the bene ts of using bug inducing change information for bug xing.
first since a bug inducing change records the developer who committed it it facilitates triage the bug to the developer who is the most familiar with the buggy code.
to con rm the bene t we further investigated how many bugs are xed by the developer who introduced the buggy code.
we studied the ratio of those bugs for three open source projects swt jdt and tomcat.
table shows the detailed results.
on average of the bugs were xed by the committer of the corresponding introducing changes.
as bug inducing changes can facilitate triaging bugs automatically this can save developers manual e orts in this process.
to quantify the e orts saved we investigated how much time it requires to triage the bugs.
we only investigated the jdt and swt projects since they recorded the bug triage activities in detail.
we followed the existing approach to measure the bug triage time.
figure shows that the bug triage time is non trivial.
the median bug triage time in jdt and swt is and days respectively.
these manual e orts could be saved if bugs can be triaged automatically by leveraging the information of inducing changes.
table ratio of bug reports whose fixing developer is the same as the developer of the bug inducing change subject dev bugs same ratio swt .
.
jdt .
.
tomcat .
.
jdt meadian swt meadian figure bug triage time for jdt and swt days the second bene t is that reverting bug inducing changes is a common way to x bugs as pointed out by the existing work bug.cgi?id bug.cgi?id and this was also con rmed with developers feedbacks in our study.
another bene t is that debugging at the change level can signi cantly save e ort when compared with coarser grained debugging at source le level since changes and hunks are small in size .
we compared the size of hunks changes and source les in terms of lines code for project swt jdt and tomcat.
the median lines of code that a hunk contains is for all three projects.
for changes the median numbers of lines are and 28for swt jdt and tomcat respectively.
source les contain more lines of code with the median numbers and accordingly.
among these three code elements hunks o er the nest granularity while source les the coarsest ones.
.
motivations of using software changes in ir based bug localization the above ndings motivate us to locate the bugs at the change level.
in this subsection we investigate whether it is feasible to use software changes in ir based bug localization.
case studies are then conducted to show that ir based techniques can bene t from three aspects informative change logs change hunks ne granularity and the change histories.
.
.
informative change logs change logs often contain substantial information that helps infer the intention or the functionality of the changed code.
such information can be leveraged by ir based techniques.
for example figure shows the brief summary of bug from project tomcat.
the bug reports a problem unable to destroy websocket thread group when reloading webapp and the corresponding buggy le is wsservercontainer.java .
commit 2653cea modi ed wsservercontainer.java during the evolution of tomcat.
from the log message we know that the intention of this change is to refactor and add new features to the destroy method.
it is this change that induced bug and the bug was xed in change a027afd as shown in figure .
the log of the bug inducing change 2653cea shares many common tokens with the bug report such as destroy thread and group .
these common tokens are essential to e ective bug localization using ir based techniques.
to understand the correlation between bug reports and the information contained in change logs we computed the cosine similarities between bug reports and the corresponding buggy les as well as the change logs of the buggy les for all the bugs of the three subjects used in section .
.
for each bug only those changes committed before the bug report was led are considered.
we selected the highest cosine similarity when a bug relates multiple source les or change logs.
figure shows the results.
the median values of commit logs are and for swt jdt and tomcat respectively while the values are 288and for source les.
we conducted mann whitney u test to test if the cosine similarities computed from logs are signi cantly larger than that from source les.
the results shows that the di erences are signi cant for all three subjects p value .
.
these results suggest that change logs share substantial common tokens with bug reports.
.
.
fine granularity of change hunks the e ectiveness of ir based techniques can be improved by using change hunks due to their granularity being ner than program source les.
recently researches have found 264bug summary unable to destroy websocket threadgroupwhen reloading webapp...... generally there might be threads that are still running commit 2653cea inducing change author mark emlyndavid thomas markt apache.org date tueapr log refactor server container shutdown into the destroy method.
destroy the threadgroupon shutdown.
log a warning if the threadgroupcan t be destroyed public void addendpoint class ?
pojo shutdownexecutor super.destroy try threadgroup .destroy catch illegalthreadstateexception itse ... boolean areendpointsregistered return endpointsregistered commit a027afd fixing change author mark emlyndavid thomas markt apache.org date wedsep log fix public void addendpoint class ?
pojo int threadcount threadgroup .activecount boolean success false try threadgroup .destroy catch illegalthreadstateexception itse while true int oldthreadcount threadcount synchronized threadgroup ...figure bug report of tomcat and its fixing change and inducing change the bold texts are the common tokens shared between bug report commit logs and changes cosine similarity0.
.
.
.
.
pdejdttomcatsource codecommit logs figure text similarities between bug reports and the buggy les as well as the change logs that bugs are usually located in a small portion of the code and thus large source les are susceptible to noise due to the fuzziness arising from information retrieval .
take the case in figure as an example the buggy le wsservercontainer.java contains lines in total.
however only a small number of lines from line to relate to the bug.
figure shows the cosine similarities between the tokens extracted from the bug report and di erent lines of the source le wsservercontainer.java .
the gure shows that the text similarities between the bug report and the source le diverge a lot at di erent lines.
the lines relevant to the bug exhibit the highest similarity while most of the lines that are irrelevant to the bug achieve lower similarities.
therefore if we treat the whole source le as a unit for querying in the information retrieval model the noise introduced by the irrelevant lines may degrade the performance of bug localization.
to handle the noise problem di erent approaches have been proposed to use small pieces of codes to represent source les by segmentation.
wong et al.
proposed dividing a source le into equally sized segments and ye et al.
segmented source les into multiple methods .
both of .
.
.
.
.
.
.
.
500cosine similarity line numberfix pointfigure text similarities between bug report and di erent lines of its buggy file wsservercontainer.java of apache tomcat them use the most similar code segments compared with bug reports to represent the le.
their results have shown that the performance of bug localization can be boosted by segmentation.
however segmenting source les into equally sized segments could lose the characteristics of the source codes like code structures .
as for segmenting source les into methods they could still be large in size.
as a result better ways to put highly related code portions into small segments are desired.
change hunks are intrinsically small pieces of code whose content are highly correlated and most of the bugs are induced by them.
therefore using change hunks instead of source les can mitigate the noise problem existing in large les for ir based techniques.
for instance if we use the inducing change 2653cea we can obtain a high cosine similarity of 656compared to the bug report while only can be achieved by using the whole lewsservercontainer.java in the previous example.
.
.
change histories apart from the textual information software changes capture the histories of source les such as the alternatives of authorship of a source le the number of bugs a source le contained previously and the corresponding xing histories.
such information can indicate the proneness for source les to contain faults .
therefore information extracted from change histories has been widely leveraged in bug prediction models as well as bug localization model with promising performance.
it has also been deployed in large systems in industry such as google .
as a result the performance of ir based techniques can be boosted by leveraging change histories.
the empirical studies above showed the usefulness of bug inducing changes and the applicability of applying software changes in ir based localization techniques.
this motivates us to propose a new ir based bug localization approach.
.
approach .
vector space model like existing ir based bug localization techniques locus adopts vsm to retrieve bug related information.
in vsm both queries qand documents dare represented as vectors of weighted terms v fwtjt2tg tis the corpus of tokens created from all the queries and documents.
the similarity between a query qand a document dis computed as the cosine similarity between their term vectors simi q d cosine vq vd vqtvd kvqkkvdk the weight wtfor each term is computed based on the classical weighting scheme term frequency tf and inverse 265document frequency idf .
the intuition behind this is that the weight of a term normally increases with its appearance frequency in a document and normally decreases with its occurrence frequency in the other documents.
over the years many approaches for calculating tfand idfhave been proposed to improve the performance of vsm model.
locus follows the approach adopted by buglocator which was shown to o er better performance tf t d logftd idf t log n nt wtd logftd log n nt in equation ftdrepresents the number of appearance of termtin document d.nrefers to the total number of documents in the corpus while ntis the number of documents which contain term t. in existing models each bug report is treated as a query qand a source le is regarded as a document.
when a bug report is received source les are ranked based on their similarities compared to the bug report calculated by the vsm model.
however as mentioned in section the e ectiveness of the vsm model by regarding source les as single units can be easily a ected by the noises contained in large les .
in our approach we treat change hunks as single documents.
.
architecture of locus in this study we proposed a tool called locus which locats bugs from software change h unks.
to create token corpora existing approaches use a bug report and source les of the version where this bug occurred as the input while locus uses a bug report and all the changes committed before this bug was reported as the input .
however many change hunks extracted are unrelated to source les e.g.
modi cation in con guration les have no semantic meaning e.g.
adding deleting space or comments or do not alter the behaviors of a system e.g.
code reformatting .
a preprocessing step as shown in figure is introduced to lter out these irrelevant hunks .
since the entities modi ed by hunks are more likely to a ect the behaviors of the software system or even induce bugs the names of these changed entities are signi cant.
therefore locus extracts and indexes these code entity names separately besides the natural language tokens.
as a result from the selected hunks after ltering locus creates two corpora which are nl natural language corpus and ce code entity corpus.
each hunk including the content of changed lines contextual lines and the corresponding commit log are indexed as an independent document.
besides locus computes another boosting score from the software change repository.
at the source le level locus extracts the xing history for each source le and uses it as a feature indicating the suspiciousness of source les to contain faults.
at the change level locus leverages changes committed time and favors those that were committed near the occurrence of the bug.
based on the nlcorpus the cecorpus and the boosting score we design three ranking models respectively to rank suspicious faulty les or bug inducing changes.
when given a bug report locus constructs two queries anl query and a ce query .
these two queries allow all hunks to be ranked based on the vector space model.
the ranking results at the source le level or the change level can be later calculated based on the ranking of hunks and the boosting ranking model.
the output oflocus is a rank list software change repositoryextract all hunks bug report preprocess selected hunks corpus creation indexing nl index ce index combine retrieval ranking ranked entitiesquery construction nl query ce query fixing history change property nl model ce model boosting modelsource file level a.java change level aa45a74 a.javafigure architecture of locus nl stands for natural language ce for code entity fixing history is used in source file level prediction while change property is used in change level prediction of source les or changes.
note that when locating bugs at change level locus narrows down the code to be examined for each suspicious change and only outputs the modi cation content of the most suspicious le in each suspicious change.
for example the modi cation contents of a.java on change aa45a74 is presented in the suspicious rank.
.
ranking models .
.
nl model the nl corpus is composed of natural language tokens extracted from the selected hunks after preprocessing.
given a bug report we construct a query using the tokens extracted from the bug summary and description .
subsequent discussions from developers in the bug report which may include xing hints e.g.
patched code are not included as the input of our tool since our tool is designed to provide debugging hints.
this process is the same as general process of corpus creation and query construction.
we perform lexical analysis for each hunk and create a vector of lexical tokens.
english stop words e.g.
a the etc.
and programming language keywords e.g.
if for etc.
are removed.
the identi ers which are composed of multiple tokens e.g.
threadgroup are split into two individual tokens e.g.
thread andgroup .
finally the porter stemming algorithm3is applied to stem a word to its root.
after these steps all the hunks as well as bug reports can be indexed and term weighted vectors can be computed.
for a bug report band a hunk h the similarity is calculated as follows and simi is de ned by equation .
nl b h simi bnl hnl .
.
ce model let us explain how to construct the ce corpus based on the code entity names appeared in the code repository.
package names class names and method names are kept in our model and they are treated as individual tokens without splitting.
for example a class threadgroup is treated as an individual token in the ce corpus.
after creating the corpus we extracted the code entity names from hunks and bug reports.
however these two artifacts are mainly described by natural languages and thus extracting code entity names from them is di erent from that from source les.
to do so we rst use the heuristics proposed by meng et al.
to extract the code like terms from natural language.
then we compare each code like term with the tokens in the ce 266corpus and only the matched ones are kept.
we compute the term weighted vectors after indexing both the hunks and bug reports.
similar to that of the nl model for a source lesand bug report b the similarity is calculated as ce b h simi bce hce .
.
boosting model section has shown the usefulness of change histories.
at source le level localization for the sake of simplicity and e ectiveness we adopt the same algorithm used by google to calculate the boosting score.
for a source le s its suspiciousness score of being buggy is computed as fix s nx i e 12ti wherenis the number of bug xing commits for s andtiis the timestamp of the ith bug xing commit.
the timestamp used in the algorithm is normalized between and where is the release date of the code base and is the time when predicting which is the reporting time of the bug to be located in our case.
existing works have pointed out that changes committed recently contribute the most to fault potential .
therefore we favor those changes committed near the occurrence of the bug at change level localization.
for each source le s we extract all the changes cthat modi ed sbefore the bug is reported.
we then rank these changes based on their committed time from the oldest to the latest and denoted it asrank sc.
for a change c we compute the boosting score as follows where t c denotes the set of the source les that the change chas modi ed.
time c max s2t c rank sc .
integrating ranking models .
.
combining models at both source le level and change level localization locus leverages three models the nl and ce models serve as the basic units while the boosting model serves as a discriminative factor.
at the source le level the score for a source lesand a bug report bis determined by these three models integrated according to equation .
source le smay be altered by multiple hunks fh1 h2 h ng.
we follow the strategy adopted by existing approaches and select the hunk with the highest cosine similarity to represent the whole source le.
therefore the nal score is computed as follows score b s nmax i 1fnl b hi ce b hi g fix s like source les we choose the hunk with the highest cosine similarity to represent a change cif it comprises multiple hunksfh1 h2 h mg. as a result the score between a changecand a bug report bis computed as follows score b c mmax i 1fnl b hi ce b hi g time c here we use the hunk hpwith the highest suspiciousness to represent the change.
when we present the results at change level we do not present all the contents of source les modi ed by the change.
instead we only present the modi cations of the source le which hpbelongs to.
.
.
determining parameters three parameters are involved when combining di erent models.
the parameter adjusts the weight ofthe vsm score calculated from the ce corpus and thus the number of code entity names appeared in a bug report can be an important clue to determine .
bug reports vary a lot in their quality .
the more code entity names a bug report contains the more weight the ce model should deserve.
based on this intuition we use the ratio of the number of code entity names compared to the number of split tokens to determine individually for each bug report.
however the average ratio of code entity names appeared in bug reports is only for the subjects we studied.
since the bug report quality is an important factor we magnify the e ect of code entity names by multiplying with an ampli cation factor .
for a bug report if is greater than 1after ampli cation we will set it to .
our experiments show that works well between 3to7 and we set it to 5for all the subjects empirically for consistency.
codeentitynames splittokens the parameter captures the weight of the boosting score.
our experiments show that our proposed model performs the best when 1is between 05and0 15at source le level and 2between and at change level.
could also be set based on the target projects characteristics such as the number of changes the number of history bugs and so on.
we leave it to our future work.
in this study for the consistency and the general e ectiveness we set 1to0 1and 2to0 2empirically for all the subjects in our experiments.
.
experiment setup .
subjects to evaluate the performance of our proposed bug localization tool locus we selected six open source projects as shown in table .
all these projects have well maintained a bug tracking system and change histories.
half of them come from the benchmark datasets collected by zhou et al.
which are zxing aspectj and swt .
.
the code repository of the subject eclipse in the benchmark was previously maintained via cvs and the cvs repository is deprecated nowadays.
the repository of eclipse is now maintained by its sub project teams separately via git and thus we collected two projects from eclipse eclipse jdt core .
and eclipse pde ui .
.
we also collected another apache project tomcat .
.
all of these three subjects are popular and large open source projects.
we adopt the traditional heuristics to build the links between bug reports and bug xes.
jdt core .
contains xed bugs and of them are linked to source codes.
pde .
contains xed bugs in total and of them are linked.
tomcat .
contains xed bugs and of them are linked to source les.
we manually checked the links between bugs and the corresponding source les later and found out that some of the links may not be applicable to our evaluation oracle.
for example for the bug of subject aspectj one of its linked source le is modules tests bugs bug70619 precedence.java it is obvious that this source le is designed to test bug and is not the root cause for this bug.
this will inevitably cause bias to the evaluation results.
as such we removed those links from the six subjects whose linked source les are designed as test cases.
due to the removal of these links the number of bugs in the benchmark subject aspectj has been reduced to .
267table basic information of evaluation subjects subject bugs files k loc k changes zxing .
.
swt .
.
.
aspectj .
.
pde .
.
.
jdt .
.
.
tomcat .
.
.
.
evaluation metrics in order to evaluate the e ectiveness of our proposed bug localization model we adopt the following three metrics which are widely used to evaluate the performance of bug localization techniques .
top n this metric reports the percentage of bugs whose buggy entities source les inducing changes can be discovered by examining the top n n ... of the returned suspicious list of code entities.
the higher the value the less e orts required for developers to locate the bug and thus the better performance.
mrr mean reciprocal rank is the average of the reciprocal ranks of a set of queries.
the reciprocal rank of a query is the multiplicative inverse of the rank of the rst relevant answer found.
this metric is used to evaluate the ability to locate the rst relevant code element for a bug.
map mean average prevision is by far the most commonly used traditional ir metric.
it takes all the relevant answers into consideration with their ranks for a single query.
this metric is used to evaluate the ability of approaches to locate all the buggy entities of a bug.
.
research questions our experiments are designed to address the following four research questions rq1 are the tokens extracted from software changes better than those from source les in improving the performance of ir based bug localization?
section shows that software changes can bene t ir based techniques in several aspects.
however can the text tokens extracted from software changes e ectively locate bugs?
how is the e ectiveness compared with the tokens extracted from source les?
to answer these questions we compare the localization results using the text tokens extracted from software changes with those from source les.
note that given a bug report the bug localization is conducted on all the changes committed before this bug was reported as well as the source les without segmentation in the version where this bug occurred.
we conducted the experiments under three di erent settings keeping only the split and stemmed natural language nl tokens keeping only the code entity names ce and using both of them nl ce the heuristics to combine nl and ce together is the same as described in section .
.
we performed the experiment for all six subjects and compared the results of map and mrr.
rq2 how e ective is locus?
does it outperform other bug localization tools?
to answer this question we apply our approach to locate bugs for the collected six subjects and then use all the metrics de ned above to characterize the e ectiveness of the results.
buglocator proposed by zhou et al.
is one of the representative ir based bug localization techniques which can locate bugs at source le level.
brtracer is builton top of buglocator and can achieve better performance by segmenting large les into segments and leveraging stack traces .
saha et al.
proposed another technique called bluir which outperforms buglocator by using structured information retrieval.
the xing information of similar bugs has been shown to be useful in bug localization .
the underlying intuition is that similar bugs tend to x similar source les.
therefore amalgam combined this information with the structure information together to improve the performance.
we compare locus with these three state of the art ir based approaches brtracer bluir and amalgam.
as bluir is publicly available we directly use it in all the evaluation subjects.
for brtracer we carefully implemented it on top of buglocator as described in the paper.
for amalgam two of its key components similar bug component and structure components are provided by buglocator and bluir which are both publicly available.
we implemented amalgam by combining the components using the parameter as described in their papers.
rq3 what is the performance of locus to locate bugs at the change level?
locus is capable of locating bugs at change level.
to the best of our knowledge locus is the rst approach that targets at locating the inducing changes based on the descriptions of a bug report before it is xed.
this research question is designed to evaluate the e ectiveness of locus to locate bugs at this ner granularity.
in order for the evaluation the changes which induced the bugs need to be extracted.
szz algorithm proposed by sliwerski et al.
can identify the bug inducing changes based on the x locations and we adopt this algorithm to extract the oracles for our evaluation.
since multiple les can be modi ed in a change we also keep the information of which source le to be blamed for the bug in this change.
a successful localization for locus requires to locate not only the correct change but also the buggy source le in the change.
besides the evaluation metrics described in section .
we further estimate the debugging e ort required to locate bugs at the change level compared with that at the le level.
we referred to the existing e ort based evaluation method that measures the number of blocks to be inspected until the buggy block is located with a given rank of blocks.
similarly we measured the number of lines to be inspected until the buggy statement is located of the results generated by locus and compared with the state of the art approaches.
rq4 what is the contribution of each model?
in our approach we leveraged three di erent information extracted from change hunks and packaged them into three di erent models nl model ce model and boosting model.
can all these models contribute to our nal performance?
in this research question we aim to evaluate the e ectiveness of each model.
to evaluate the contributions of these three factors we conducted three experiments on the six subjects.
first we only used the nl model in locus to locate all the bugs and then we added the ce model and combined it with the nl model.
finally we added boosting model intolocus .
experiments are performed under these three settings and our purpose is to investigate if the performance can be improved by adding a new model.
.
experiment results in this section we answer the four proposed research questions through analyzing the experimental results.
268rq1 are the tokens extracted from software changes better than those from source les in improving the performance of ir based bug localization?
table shows the results of map and mrr by using source les or change hunks as the source of text tokens.
the results show that no matter using the split natural language tokens the code entity names or using both adopting the text tokens extracted from change hunks in ir based models achieves better results than that from source les for all six subjects.
for example for swt the improvements by using only nl are and for map and mrr.
if only using ce the improvements are and .
the improvements are65 and64 for map and mrr respectively by combing nl and ce.
we later conducted one tailed statistics test of the results to see if the improvements are signi cant.
the mann whitney u test shows that for most of the subjects the bold text in table the performance of hunks are signi cantly better than that of source les p value .
.
these results prove that the advantages of the software changes discussed in section .
including the information in change logs and the small granularity do help locate bugs for ir based techniques.
table comparisons of the results between using source files and changes hunks the bold text means the outperformance is signi cant subjects nl ce nl ce text source hunk source hunk source hunk zxingmap .
.
.
.
.
.
mrr .
.
.
.
.
.
swtmap .
.
.
.
.
.
mrr .
.
.
.
.
.
aspectjmap .
.
.
.
.
.
mrr .
.
.
.
.
.
pdemap .
.
.
.
.
.
mrr .
.
.
.
.
.
jdtmap .
.
.
.
.
.
mrr .
.
.
.
.
.
tomcatmap .
.
.
.
.
.
mrr .
.
.
.
.
.
rq2 how e ective is locus?
does it outperform other bug localization tools?
table shows the results of our approach for all evaluated subjects.
it shows that our approach can locate the buggy les and rank them as top among all the source les for and53 of the bugs for zxing swt aspectj pde jdt and tomcat respectively.
on average locus locates the buggy les and ranks them at the top for of all the bug reports and within top .
for of the bug reports locus locates the correct buggy les within the top .
the results also indicate the locus can outperform the three existing works brtracer bluir and amalgam for ve subjects swt aspectj pde jdt and tomcat under all the metrics.
for zxing locus achieves the same result as brtracer under metric top for other metrics locus outperforms all the other approaches.
speci cally compared with brtracer the improvement of map varies from to and the weighted average improvement is .
the average improvement of mrr is32 varing from to46 for di erent subjects.
compared to bluir the improvement of map varies from to32 and the weighted average improvement is .
the average improvement of mrr is whichvaries from to35 for di erent subjects.
compared to amalgam map and mrr are improved by and respectively on average.
table comparisons of the results at the source file level with the state of the art approaches subjects methods map mrr top top top zxinglocus .
.
.
.
.
brtracer .
.
.
.
.
bluir .
.
.
.
.
amalgam .
.
.
.
.
swtlocus .
.
.
.
.
brtracer .
.
.
.
.
bluir .
.
.
.
.
amalgam .
.
.
.
.
aspectjlocus .
.
.
.
.
brtracer .
.
.
.
.
bluir .
.
.
.
.
amalgam .
.
.
.
.
pdelocus .
.
.
.
.
brtracer .
.
.
.
.
bluir .
.
.
.
.
amalgam .
.
.
.
.
jdtlocus .
.
.
.
.
brtracer .
.
.
.
.
bluir .
.
.
.
.
amalgam .
.
.
.
.
tomcatlocus .
.
.
.
.
brtracer .
.
.
.
.
bluir .
.
.
.
.
amalgam .
.
.
.
.
to combine the ce model with the nl model we set to in the above experiments.
figure shows the performance measured in terms of map and mrr of the six subjects with di erent values.
we nd that the bug localization performance increases with the increasing of when is small.
this shows that magnifying the e ect of the ce model helps improve the performance of bug localization.
locus achieves the optimum performance for the six subjects when is between 3to7.
the improvement slows down or is even decreased when is set to 7or larger.
however the decrease is subtle since we set an upper bound 1for and it guarantees that the ce model shares at most the same weight with the nl model.
these results are consistent with our intuition that code entities names are important as discussed in section .
.
.
.
.
.
.
.
.
.
.
10swt tomcat zxing pde jdt aspectj .
.
.
.
.
.
.
.
.
.
.
10swt tomcat zxing pde jdt aspectj 0. .
.
.
.
.
.
.
.
.
.
swt tomcat zxing pde jdt aspectj map mrr figure the e ect of parameter in summary these results show that locus is e ective in locating bugs at the le level.
locus can outperform the existing state of the art ir based bug localization approaches.
rq3 what is the performance of locus to locate bugs at the change level?
to the best of our knowledge we are the rst one to locate bugs at the change level using ir based techniques.
table shows the results of map mrr and top n for 269all the subjects.
the map and mrr are 205and0 respectively on average.
besides locus can locate the inducing changes and rank them within the top for of bugs.
for of the bugs the inducing changes can be ranked within the top .
table results of map mrr and top n at the change level subject map mrr top top top top zxing .
.
.
.
.
.
swt .
.
.
.
.
.
aspectj .
.
.
.
.
.
pde .
.
.
.
.
.
jdt .
.
.
.
.
.
tomcat .
.
.
.
.
.
figure shows the results produced by locus at the change level and results by amalgam at source le level in terms of the lines of codes need to be inspected in natural logarithm .
note that amalgam performs better than other approaches at the le level so we only show the comparison between locus and amalgam.
the results indicate that debugging e orts can be saved signi cantly by using locus .
when using locus the median number of lines needing to be inspected has been reduced by an order of magnitude compared with that using amalgam.
for example for all the bugs in tomcat the median number of lines is 193using locus while the median number is over using amalgam.
to further understand the di erences between the results generated by locus and amalgam we take bug in tomcat .
as an example.
both locus and amalgam will rank the relevant element in the top .
however the result generated by locus isjspcservletcontext.java in the change 05c84ff which includes only lines of code.
the result generated by amalgam is jspcservletcontext.java which includes lines of code.
however this is only an estimation of the e orts required to locate bugs.
developers may not investigate suspicious source les line by line when debugging in practice and debugging habits are developerspeci c. therefore to evaluate the e orts saved precisely requires user studies involving real developers and we leave it as our future work.
number of lines needs to be scanned ln zxingswtaspectjpdejdttomcatlocusamalgam figure comparison between locus and amalgam in terms of the e ort based evaluation.
locating bugs at the change level is worth exploring and the results shown in table and figure are promising overall.
however the massive number of change hunks and the prevalent similar changes make it a challenge task to locate the exact inducing change hunks.
we plan to leverage more properties of software changes such as change patterns authorship and their proneness to contain faults .
this information can be integrated into our localization model to improve the results.
besides we can excavate deep relations between software changes and bug reports by leveraging the information of stack traces if found inbug reports.
we leave the study of such additional software change properties to our future work.
rq4 what is the contribution of each model?
figure shows the results under the three settings as described in the experiment setup.
using only the natural language information at the source le level the average map and mrr are 348and respectively.
the results can be improved by and23 on average when incorporating our proposed ce model.
this demonstrates the usefulness of the ce model.
by adding the information of xing history the results of map and mrr can be further improved by and5 respectively on average.
at the change level the average map and mrr are respectively and when using only the nl model.
the results can be improved by and18 after combining the ce model.
the information of change time can improve the results by and2 on average in a further step.
in summary the results show that each model has contributed to the performance of bug localization.
.
.
.
.
.
.
.6zxingswtaspectjpdejdttomcat map source level nl nl ce nl ce boosting .
.
.
.
.
.
.
.
.8zxingswtaspectjpdejdttomcat mrr source level nl nl ce nl ce boosting .
.
.
.
.
.
.30zxingswtaspectjpdejdttomcat map change level nl nl ce nl ce boosting .
.
.
.
.40zxingswtaspectjpdejdttomcat mrr change level nl nl ce nl ce boosting figure contribution of each model .
threats to validity our experiments are subject to several threats to validity.
subject selection bias six popular open source projects are used in our study and evaluation.
similar results were found among these projects suggesting that our ndings are generalizable.
however locus performs the worst on subject jdt and aspectj map .
as shown by table while these subjects contain the largest number of source les.
this raises the concern that our ndings may not generalize to very large subjects.
therefore evaluation on more subjects are desired to increase the con dence for our ndings.
besides the nature of open source projects may di er from that of commercial projects.
to validate if our ndings are generalizable to commercial projects experiments on these projects are required.
we leave this as our future work.
data quality the quality of bug reports collected may vary a lot for di erent subjects and some subjects may contain more reports submitted by developers than end users.
the e ect of bug reports quality on our nal results should be investigated in a further step.
however it s hard to di erentiate between bug reports submitted by developers and that by users in practice.
another threat is that the links between bug reports and software artifacts in the datasets may not be well maintained .
to mitigate this threat we adopted the benchmark dataset including the bug reports and the linked source les from buglocator for three of our studied subjects.
the dataset is widely evaluated 270by existing studies .
for the other three subjects collected by ourselves the heuristics adopted to recover the links are widely used by existing works .
empirical evaluation we designed several experiments in this study to evaluate the e ectiveness of locus .
however the practical usefulness of locus should be validated by developers through their debugging tasks.
the carrying out of a user study is left as an important future work.
.
related work .
ir based bug localization lots of approaches have been proposed to locate bugs automatically using ir based techniques .
zhou et al.
proposed buglocator that combines similar bugs with a revised vsm model which considers the length of source les to rank relevant source les for a bug report .
wong et al.
found that large source les may contain noises and thus they segmented source les into equal sized segments and chose the segments with the highest similarity to represent the whole source le .
they also considered the information of stack traces which may be found in bug reports.
moreno et al.
also found that using the information of stack traces can boost the performance of ir based techniques .
saha et al.
proposed a tool named bluir which considers the structure information of source les .
similar to our approach they considered code entity names in their ranking model.
however our approach is di erent from them in the following aspects rst they only extract the identi ers from the stack traces or code snippets in bug reports while we adopted the heuristics that can extract code entity names from general artifacts written in natural languages like bug reports or commit logs.
second they indexed full identi ers as well as split tokens together while we treated split natural language tokens and code entity names as two corpora and indexed them individually the vsm scores were calculated separately and were then combined together.
the approaches discussed above are based on vsm model.
there are other ir based techniques using di erent models.
lukins et al.
found that latent dirichlet allocation can successfully be applied to source code retrieval for the purpose of bug localization .
lda was also extended in bugscout to narrow down the search space of buggy les given a bug report.
information retrieval models have also been combined with other techniques to improve the performance of bug localization.
the combination with learning to rank was proposed by ye et al .
they extracted six features from the given bug reports and source les with domain knowledge such as lexical similarity bug xing recency and so on.
a learning model was trained on historical xed bugs and was then used to locate relevant les for newly received bug reports.
the combination with deep learning was proposed by lam et al.
.
they leveraged deep neural network to relate the terms in bug reports to potentially di erent code tokens and terms in source les.
these approaches require training a model from historical data while locus does not.
the combination with spectrum based localization was proposed by le et al.
.
they found that by considering program spectra which are traces of program elements executed under di erent test cases the performance of bug localization can be improved.
however this technique requires the availability of test cases and execution traces of subjects.
.
debugging at software change level our empirical study shows that many bugs are induced by software changes and thus assuring the quality of software changes is important.
change impact analysis has been well studied aiming to select a subset of regression test suite that might be a ected given a change and then identify program edits that induced the test failures.
delta debugging was proposed to locate a subset of the history that may contributes to a test failure.
combining test spectra passed or failed test traces and change impact analysis faulttracer was able to locate the failure inducing program edits .
di erent from these works locus does not require any regression test suites or test spectra it is designed to locate the inducing changes based on the descriptions of bug reports and change properties.
thomas et al.
studied the properties of bug inducing changes in large open source projects including mozilla and eclipse .
they found that bug xing changes as well as those changes committed on fridays have higher chances to induce new bugs.
kim et al.
proposed an approach to automatically predict whether a change is buggy or clean using machine learning classi cation algorithms .
they extracted features from source codes change logs and change metadata and trained learning models using historical data.
newly committed changes can be classi ed into either clean or buggy by the model.
kamei et al.
conducted an empirical study of just in time quality assurance which concerns defect prediction at the change level.
they pointed out that the ne granularity of prediction at the change level can save large e orts over coarser grained predictions at the source le level.
.
conclusion and future work the practical usefulness of existing ir based bug localization techniques is greatly compromised by the coarse granularity of les and the lack of contextual information.
we observed that bug inducing changes can help developers in debugging and software changes can bene t ir based bug localization techniques.
inspired by our observation we proposed an approach locus which locates bugs in terms of software changes instead of source les.
it creates two individual corpora composed of natural language tokens and code entity tokens respectively.
it leverages the information of change histories.
experimental evaluation on six popular open source projects shows that locus can locate the relevant les within top for of the bugs and within top on average.
our approach outperforms three state of the art approaches.
locus can also locate the bug inducing changes within top for of the bugs which is very promising.
in the future we plan to investigate if software changes can also improve the performance of bug localization based on other ir models besides vsm.
we also plan to incorporate more properties of software changes such as change patterns authorship and their proneness to contain faults intolocus to lter out uninteresting changes and hence to more accurately locate bug inducing changes.
.