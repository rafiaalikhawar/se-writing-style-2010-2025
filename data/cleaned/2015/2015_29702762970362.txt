quickar automatic query reformulation for concept location using crowdsourced knowledge mohammad masudur rahman chanchal k. roy department of computer science university of saskatchewan canada masud.rahman chanchal.roy usask.ca abstract during maintenance software developers deal with numerous change requests made by the users of a software system.
studies show that the developers nd it challenging to select appropriate search terms from a change request during concept location.
in this paper we propose a novel technique quickar that automatically suggests helpful reformulations for a given query by leveraging the crowdsourced knowledge from stack over ow.
it determines semantic similarity or relevance between any two terms by analyzing their adjacent word lists from the programming questions of stack over ow and then suggests semantically relevant queries for concept location.
experiments using queries from two software systems suggest that our technique can improve or preserve the quality of of the initial queries on average which is promising.
comparison with one baseline technique validates our preliminary ndings and also demonstrates the potential of our technique.
ccs concepts software and its engineering !software maintenance tools requirements analysis traceability maintaining software keywords query reformulation crowdsourced knowledge semantic relevance word co occurrence adjacency list stack over ow .
introduction studies show that about of the total e ort is spent in software maintenance and evolution .
during maintenance software developers deal with numerous change requests made by the users of a software system.
although the users might be familiar with the application domain of the software they generally lack the idea of how a particular software feature is implemented in the sourcecode.
hence the requests from them generally involve domain related concepts e.g.
application features and they are written in an unstructured fashion using natural language texts.
the developers need to prepare appropriate search query from those concepts and then identify the relevant location s in the code to implement the requested change s .
unfortunately preparing such a query is highly challenging and error prone for the developers .
based on a user study kevic and fritz report that developers were able to suggest good quality search terms for only .
of the change tasks.
furnas et al.
suggest that there is a little chance i.e.
that developers guess the exact words used in the source code.
one way to assist the developers in this regard is to automatically suggest helpful reformulations for the initially executed query.
existing studies use relevance feedback from developers or information retrieval techniques query quality and the context of query terms within the source code in suggesting reformulated queries.
gay et al.
make use of explicit feedback on document relevance from the software developers and then suggest reformulated queries using rocchio s expansion.
haiduc et al.
and colleagues take quality of the query into consideration and suggest the best reformulation strategy for a given query using machine learning.
howard et al.
analyze leading comments and method signatures from the source code for mining semantically similar word pairs and then suggest reformulated query using those word pairs.
while these above techniques are reported to be novel or e ective they are also limited in certain aspects.
first collecting explicit feedback from the developers could be highly expensive and such study could also be hard to replicate.
second machine learning model of haiduc et al.
is reported to be performing well in the case of within project training and only queries are considered from each of the ve projects for training and testing .
given such small dataset the reported performance possibly could not be generalized for large systems.
third howard et al.
require the source code to be well documented for the mining of word pairs and hence might not perform well if the code is poorly documented .
thus we need a technique that is neither subject to the training data nor the availability of comments in the source code.
one way to possibly overcome those concerns is to apply crowd generated knowledge in the reformulation of queries for concept location.
in this paper we propose a novel technique quickar that automatically identi es semantically similar words to an initial query not only from project source code but also permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
from crowdsourced content of stack over ow q a site and then suggests a reformulated query.
the technique collects adjacent word lists from the programming questions of stack over ow for any two terms and determines their semantic similarity by comparing their corresponding adjacency lists .
in short quickar not only follows the essence of a nearest neighbour classi er in the context of natural language texts but also harnesses the technical corpus developed by a large crowd over the years in estimating semantic similarity orrelevance .
such simple but intuitive estimation of semantic relationship could be highly useful for suggesting an alternative version of a given query.
quickar also addresses the overarching vocabulary mismatch problem .
first stack over ow is curated by a large crowd of four million technical users and the millions of questions and answers posted by them are a great source for technical vocabulary e.g.
api names .
thus quickar mines semantically similar words not only from a larger corpus i.e.
compared to a single project but also from a more appropriate vocabulary i.e.
compared to wordnet .
second rahman et al.
reported a signi cant overlap i.e.
between the vocabulary of real life code search queries and that of question titles from stack over ow.
quickar mines 500k programming related questions from stack over ow carefully and reaps the bene t through meaningful vocabulary extension.
to the best of our knowledge no existing studies apply crowdsourced knowledge yet in the reformulation of queries for concept location which makes our technique novel.
experiments using concept location queries from two subject systems ecfand eclipse.pde.ui suggest that our technique can improve or preserve the quality of i.e.
improves and preserves of the initial queries through reformulation which is promising according to relevant literature .
comparison with one baseline technique rocchio s expansion validates our preliminary ndings and also demonstrates the potential of our technique for query reformulation.
while the preliminary ndings are promising they must be validated using further experiments.
in this paper we make the following contributions construction of a word adjacency list database by mining 500k questions from stack over ow for the estimation of semantic similarity or relevance between words.
a novel technique that suggests helpful reformulations for a given query for concept location by leveraging crowdsourced knowledge from stack over ow.
.
motivating example software change requests and project source code are often written by di erent people and they use di erent vocabularies to describe the same technical concept.
concept location community has termed it as vocabulary mismatch problem .
table shows three di erent questions from stack over ow that are marked as duplicates orlinked by the users of the site.
these questions use three di erent verbs create cause and track to describe the same programming issue locating memory leaks and this can be considered as a real life parallel for vocabulary mismatch issue.
although these verbs have di erent semantics in english literature they share the same or almost similar semantic in this technical literature programming questions .
more interestingly their semantic similarities can also be approximated from their adjacent word lists.
in graphtable duplicate questions from stack over ow id title of question creating a memory leak with java easiest way to cause memory leak in java?
tracking down a memory leak garbage collection issue in java theory two nodes are considered to be connected if they share the same neighbour nodes .
we adapt that idea for natural language texts and apply to the estimation of semantic connectivity between words.
the co occurred word lists i.e.
sentence as a context unit of create cause and track fmemory leak java g feasiest way memory leak javagandfdown memory leak garbage collection issues javag respectively share multiple words among themselves.
thus comparison between any two such lists can potentially approximate the semantic similarity or relevance of their corresponding words .
in this research we apply the above methodology in semantic similarity estimation and then use the similar terms for the reformulation of an initial query.
.
quickar query reformulation using crowdsourced knowledge programming questions and answers from stack over ow were previously mined for api elements q a dynamics or post suggestions .
in this research we make a novel use of such questions in query reformulation for concept location.
since these questions contain unstructured information relevant items i.e.
potential alternative query term should be carefully extracted and then applied to query reformulation.
we rst construct a database containing adjacent word list for each of the individual words taken from the title of the questions and then leverage that information in suggesting reformulated queries.
fig.
shows the schematic diagram of our proposed technique quickar for query reformulation.
thus our technique can be divided into two major parts a construction of an adjacency list database from stack over ow questions and b reformulation of an initial query as follows .
construction of adjacency list database word co occurrence is often considered as a proxy for semantic relevance between words in natural language texts .
yuan et al.
rst propose to use contextual words i.e.
word co occurrence from the programming questions and answers of stack over ow in identifying semantically similar software speci c word pairs.
while they introduce the idea we adapt that idea for a speci c software maintenance task search query reformulation for concept location.
given the signi cant overlap i.e.
between real life code search queries and titles of stack over ow questions we collect the titles of 500k java related questions from stack over ow using stack exchange data explorer1.
we check for java tag in the tag list for identifying the java related questions.
we perform standard natural language preprocessing i.e.
word splitting stop word removal and turn each of those titles into a sequence of words step fig.
a .
we decompose each camel case word e.g.
genericcontainerinstantiator into separate tokens e.g.
generic container instantiator and apply a standard list2for stop word removal.
it should be noted that we avoid stemming to ensure a meaningful refor1 ow 221figure proposed technique for query reformulation a construction of word adjacency list database from stack over ow questions and b reformulation of an initial query for concept location mulation of the query.
after preprocessing step we found a large set of individual words i.e.
words in total from our collected titles.
given that source code of a software project is often authored by a small group of developers such a large set could possibly extend the vocabulary of the code.
we then use a sliding window ofwindow size to capture co occurred words from the titles and construct an adjacency list for each of the individual words.
for example based on table the adjacency list for the word memory would be fcreating leak cause down g. we collect adjacency list for each of the words where each list contains co occurred words on average step fig.
a .
these lists comprise our database which is later accessed frequently for query reformulation.
.
reformulation of an initial query fig.
b shows the schematic diagram and algorithm shows the pseudo code for our query reformulation technique quickar.
we collect semantically similar words i.e.
with initial query from two di erent but relevant sources project source code and stack over ow questions and then reformulate a given query for concept location.
we discuss di erent intermediate steps involved in such reformulation as follows collection of candidate terms existing literature mostly relies on the source code of a software system or wordnet for reformulated query suggestion.
unfortunately source code often might not contain a rich vocabulary and wordnet might also not be appropriate for technical words .
we thus collect candidate terms for possible query expansion not only from the source code but also from another technical literature programming questions of stack over ow line line algorithm .
in the case of project source we perform code search using the reduced keywords k from the initial query q .
we useapache lucene a popular implementation of vector space model vsm for code search and then collect the top i.e.
cut o retrieved documents as the source for candidate terms.
the cut o value is chosen based on iterative experiments.
we perform standard natural language preprocessing on those documents and extract each of the terms as the reformulation candidates tp step fig.
b .
relevant literature also follows the same procedure for candidate term selection.
in the case of questions from stack over ow we collect such words as candidates tso that frequently co occurred in those questions with the keywords from the initial query.
the underlying idea is that if two words frequently co occur in various technical contexts they share their semantics and thus are possibly semantically relevant .
we use our adjacency list database section .
for identifying the second set of candidates.
estimation of semantic similarity or relevance since we target to reformulate a query using meaningful al algorithm query reformulation using crowd knowledge procedure quickar q .
q initial search query q0 fg .reformulated search query .collecting keywords from the initial search query k collectkeywords q k reducekeywords k .collecting candidate terms tp getcandidatetermsfromproject k tso getcandidatetermsfromso k .estimating semantic similarity of the candidates forcandidate ti2tpdo adjti getadjacencylistfromdb ti forkeyword kj2kdo adjkj getadjacencylistfromdb kj .contextual similarity between words scos getcosinesimilarity adjti adj kj rp score rp score scos end for end for forcandidate ti2tsodo forkeyword kj2kdo .co occurrence between words scof getco occurrencefreq ti kj rso score rso score scof end for end for .ranking and selection of candidates srtopp selecttopk sortbyscore rp srtopso selecttopk sortbyscore rso r selectivecombine srtopp sr topso .reformulate the initial query q0 selectivereformulate q k r return q0 end procedure ternatives we need to choose such terms from the candidates that are either semantically similar or highly relevant to the initial query.
yuan et al.
use contextual words i.e.
based on co occurrence from stack over ow for automatically identifying similar software speci c words.
in the context of query reformulation for software maintenance we similarly apply adjacency list to the estimation of semantic relevance between two terms.
we collect adjacency list i.e.
from the adjacency list database for each of the candidate terms and the keywords of the initial query and estimate their similarities using cosine similarity measure scos .
cosine similarity is frequently used in information retrieval for determining textual similarity between two given documents.
it returns a value between zero i.e.
completely dissimilar and one i.e.
completely similar .
thus a candidate term achieves score only if it shares its context i.e.
adjacent word list adjti with that i.e.
adjkj of the keywords across various questions from stack over ow.
quickar iterates this 222table experimental dataset subject system release id files methods queries ecf eclipse.pde.ui i20151110 total process for each of the candidates tp and accumulates their similarity scores against the keywords line line algorithm step fig.
b .
we also determine cooccurrence frequency scof between each candidate term and each keyword in the titles of stack over ow questions and derive another set of scores for the candidates tso line line algorithm step fig.
b .
finally we end up with two sets of candidates i.e.
collected from two di erent sources and quickar determined their relevance to the initial query in terms of their context or direct co occurrences in the stack over ow questions.
candidate term ranking top k selection once relevance estimates for both candidate sets rpandrso are collected they are ranked based on their estimates.
we then collect the top k candidates from each ranked list selectively choose the top candidates r from both lists and then treat them as similar or relevant to the initial query q line line algorithm .
in particular the nominal terms i.e.
nouns from both lists are chosen .
thus we select such terms for reformulation that co occur with the initial query keywords not only in the project source but also in the titles of the questions from stack over ow.
query reduction expansion we apply both reformulation strategies reduction and expansion to the initial query .
in the case of reduction we apply a conservative strategy as was also applied by haiduc et al.. we discard the keywords from initial query that either are non nominal or occurred in more than of the documents of the project corpus.
such keywords are not speci c enough and thus are not useful for document retrieval .
in the case ofexpansion we apply the semantically similar or relevant terms r returned by quickar to the query.
if there existmterms after the reduction step i.e.
line we append m relevant terms from rto the query and prepare an alternative query q0 line line algorithm step fig.
b .
we also decompose each camel case term into separate tokens and preserve both the separate and the camel case terms into the reformulated query .
it should be noted that if our reduction step already improves the initial query we conveniently avoid its expansion.
working example let us consider a change request id from ecfproject.
we select title of the request restclientservice ignores content encoding as the initial search query for the request as was also used by the existing literature .
the query returns the rst relevant document i.e.
java class at 44thposition when tested using apache lucene .
on the other hand quickar returns the reformulated query rest client service restclientservice content web java executor webservice http that returns the same relevant document at 1stposition in the search result.
please note that our technique expands the initial query using several relevant terms such as webservice executor and http and also discards some terms such as encoding or ignore which improved the query.
we also expand the query simply using terms from project source restclientservice ignores content encoding call container service http test that returns the document at 11thposition.
this clearly demonstrates that candidates from the sourcecode of a project might always not be su cient and crowd generated vocabulary from stack over ow can complement them and thus can assist in e ective query reformulation.
.
experiment one of the most e ective ways to evaluate a query reformulation technique is to check whether the reformulated query improves the search results or not.
we de ne improvement of search results as the bubbling up of the rst relevant document to the top positions of the result list .
that is a good reformulation of query provides a better rank than a baseline query for the rst relevant document.
we conduct experiments using change requests from two java subject systems of eclipse ecfandeclipse.pde.ui and a well known search engine apache lucene .
we also compare with a baseline technique for query reformulation to validate our ndings.
in particular we attempt to answer the following research questions using our experiments rq how does quickar perform in the reformulation of a query for concept location?
rq can crowdsourced knowledge from stack overow improve a given query signi cantly?
rq how does quickar perform compared to the baseline technique for query reformulation?
.
experimental dataset corpus dataset collection table shows details of our selected subject systems.
we rst collect the resolved change requests i.e.
bug reports from bugzilla for each of the selected systems.
then we identify such commits that implemented those requests in their corresponding github repositories.
we consider a commit as eligible only if its title contains a speci c request identi er e.g.
bug .
this practice is common for relevant literature for evaluation .
the step provides and requests from ecf and eclipse.pde.ui respectively.
we also collect change setfrom each of the identi ed commits which are later used as the solutions for the corresponding change requests.
we then consider title of each request as the baseline query and identify such queries that return their rst relevant results with poor rank i.e.
rank .
that is the baseline query needs reformulation for returning a better rank.
this ltration step left us with and baseline queries from ecf and eclipse.pde.ui respectively for the experiments.
corpus preparation unlike an unstructured natural language document a source code document contains items beyond regular texts such as classes interfaces methods and constructors .
one should consider such structures for e ective retrieval of the source documents from a project.
we thus decompose each java document into methods and consider each of those methods as a single document of the corpus.
this step provides and java methods from ecfandeclipse.pde.ui respectively.
we collect these methods using javaparser3 and apply natural language preprocessing to them.
in particular we remove all punctuation marks java programming keywords and english stop words from the body and signature of the method and also decompose each camel case token into individual tokens.
.
evaluation of quickar we execute each of our reformulated queries and baseline queries from each subject system with apache lucene 223table performance of quickar system queriesimprovement worsening preserving improved mean q1 q2 q3 min.
max.
worsened mean q1 q2 q3 min.
max.
preserved ecf .
.
.
pde.ui .
.
.
total avg .
avg .
avg .
pde.ui eclipse.pde.ui mean mean rank of rst relevant document in the search result qi rank value for ithquartile of all result ranks table role of crowdsourced knowledge from so technique improved worsened preserved baseline query preprocessed .
.
.
quickar p .
.
.
quickar so .
.
.
quickar red .
.
.
quickar all .
.
.
and compare their topmost ranks for evaluation.
we identify the queries that were improved worsened or preserved based on those ranks.
table reports the outcome of our preliminary investigation.
on average quickar was able to improve of the baseline queries while preserving the quality of which are highly promising according to relevant literature .
we see that quickar can return the top results within the 10thposition for of requests from ecfsystem.
it also performs similarly foreclipse.pde.ui and returns the top results within the 17thposition.
one might argue about the verbatim use of the title of a change request as the baseline query.
however we also experimented with preprocessed version i.e.
stop word removal camel case decomposition of the title.
we found that the preprocessing step discarded important information and did not provide much improvement in the query quality which possibly justi es our choice about baseline query.
thus to answer rq our proposed technique for query reformulation quickar improves or preserves of the baseline queries which is promising.
we investigate how di erent reformulation decisions inuence the end performance of our technique and table reports our ndings.
we rst experimented using a preprocessed version of the baseline queries and found that the preprocessing step did not improve the queries much i.e.
only improvement .
since candidate terms for reformulation are extracted from both project source code and stack over ow questions we need to examine their impact in the reformulated queries.
when we rely solely on source code quickar pcan improve of the queries but degrades the quality of .
although the candidate terms from stack over ow questions alone might not be su cient i.e.
quickar soimproves and degrades they de nitely can complement the candidate terms from the project source which leads to overall query quality improvement i.e.
quickar all improves .
we also performed mann whitney u mwu test on the provided ranks by quickar pand quickar all and found that quickar all returns the results at signi cantly higher ranks i.e.
p values .
.
and .
.
for ecfand eclipse.pde.ui respectively table in the result list.
the negative mean rank di erence mrd in table suggests that quickar all returns the results at relatively closer to the top of the list than the counterpart i.e.
extent of result rank improvement .
thus to answer rq crowdsourced knowledge from stack over ow questions can signi cantly improve the quality of a baseline query during reformulation.
since quickar involves two steps during query reformulation reduction andexpansion an investigation is war table comparison with baseline technique technique system improved worsened preserved rocchio s ecf .
.
.
expansion pde.ui .
.
.
quickar pecf .
.
.
pde.ui .
.
.
quickar allecf .
.
.
pde.ui .
.
.
pde.ui eclipse.pde.ui table result of mann whitney u tests technique pairecf eclipse.pde.ui p value mrd p value mrd quickar all vs. quickar p .
.
.
quickar all vs. quickar so .
.
.
quickar all vs. rocchio .
.
mrd meanrankdi erence ranted on how these two steps impact the end performance.
according to our preliminary investigation the reduction step i.e.
quickar red dominates over expansion step especially with ecfsystem.
one possible explanation could be that we used a smaller version of the adjacency list database constructed from i.e.
questions from the dataset.
since accessing a large database is time consuming we made this feasible choice during experiment.
however further investigation and experiments are essential to mitigate such concern which we consider as a future work.
in short the potential of crowdsourced knowledge is yet to be explored.
.
comparison with baseline technique although the conducted evaluation demonstrates the potential of our proposed technique quickar we still investigate to at least partially validate our performance.
we compare with a baseline technique rocchio s expansion that is reported to be e ective for query reformulation.
rocchio s method rst collects candidate terms from the top k i.e.
k source code documents returned by a baseline query.
then it selects the most important candidate terms t for reformulation by calculating their tf idf in each of those top k documents d as follows rocchio t x d2rtfidf t d we implemented rocchio s method in our working environment experimented on the same corpus and applied similar natural language preprocessing.
table reports the comparative analysis between our technique and rocchio s method.
we see that our technique can improve of the baseline queries from each of the subject systems whereas such measure for rocchio s method is close to .
more importantly quickar degrades less number of queries compared to its counterpart.
while rocchio s method worsened the quality of of the baseline queries during reformulation such measure for quickar is between to .
we also performed mann whitney u test on the returned result ranks from both techniques and found that quickar provides signi cantly better ranks i.e.
p values .
and .
for ecfand eclipse.pde.ui respectively table than rocchio s expansion.
we also compared using a equiv224alent variant of our technique quickar p and found that the variant still performed better than rocchio s method for both subject systems.
all these above preliminary ndings clearly demonstrate the potential of our proposed technique.
thus to answer rq our technique quickar performs signi cantly better than the baseline technique in query reformulation for concept location.
.
related work existing studies from the literature use relevance feedback from developers or information retrieval techniques query quality or the context of a query in the source code for suggesting query reformulations.
gay et al.
capture explicit feedback on document relevance from the software developers and then suggest reformulated queries using rocchio s expansion.
although their adopted methodology is meaningful capturing feedback from the developers could be expensive and such study is often di cult to replicate.
haiduc et al.
and colleagues analyze quality of the query and suggest the best reformulation strategy for any given query using machine learning.
although their reported performance is signi cantly higher such performance might not be generalized for large systems given their use of small dataset i.e.
only queries from each system .
howard et al.
analyze leading comments and method signatures from the source code and suggest reformulated queries by extracting semantically similar word pairs.
however their technique requires the source code to be well documented and thus might not perform well with poorly documented code.
on the other hand our technique quickar complements the source code vocabulary by capturing appropriate candidate terms from the programming questions of stack over ow.
carpineto and romano conduct a survey on the automatic query expansion aqe mechanisms applied to information retrieval.
rocchio s expansion is one of such mechanisms which was adapted by earlier studies in the context of software engineering.
we consider this mechanism as the baseline reformulation technique and compared with it using experiments section .
.
yuan et al.
rst apply contextual words from stack over ow questions and answers for identifying semantically similar software speci c words.
while they introduce the idea we successfully adapt that idea for a software maintenance task i.e.
query reformulation for concept location.
from a technical point of view we collect candidate query terms opportunistically not only from project source code but also from questions of stack overow and determine their relevance to the initial query using crowdsourced knowledge i.e.
adjacency list database .
we then apply the most relevant terms from both source code and stack over ow to query reformulation and such methodology was not applied yet by any existing studies.
.
conclusion and future work studies show that software developers face di culties in preparing an appropriate search query from a change request during concept location.
in this paper we propose a novel technique quickar that automatically suggests e ective reformulations for an initial query by leveraging the crowd generated knowledge from stack over ow.
the technique collects candidate query terms from both project source and questions of stack over ow and then determines their ap plicability for the reformulated query by applying the crowdsourced knowledge.
experiments using change requests from two software systems suggest that our technique can improve or preserve the quality of of the baseline queries which is promising.
comparison with one baseline technique also validates our preliminary ndings.
while the preliminary ndings are promising further experiments and investigations are warranted.