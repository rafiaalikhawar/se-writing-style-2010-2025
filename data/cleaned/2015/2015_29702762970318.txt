symbolic execution of stored procedures in database management systems muhammad suleman mahmood maryam abdul ghafoor junaid haroon siddiqui department of computer science lums school of science and engineering lahore pakistan junaid.siddiqui lums.edu.pk abstract stored procedures in database management systems are often used to implement complex business logic.
correctness of these procedures is critical for correct working of the system.
however testing them remains di cult due to many possible states of data and database constraints.
this leads to mostly manual testing.
newer tools o er automated execution for unit testing of stored procedures but the test cases are still written manually.
in this paper we propose a novel approach of using dynamic symbolic execution to automatically generate test cases and corresponding database states for stored procedures.
we treat values in database tables as symbolic model the constraints on data imposed by the schema and by the sql statements executed by the stored procedure.
we use an smt solver to nd values that will drive the stored procedure on a particular execution path.
we instrument the internal execution plans generated by postgresql database management system to extract constraints and use the z3 smt solver to generate test cases consisting of table data and procedure inputs.
our evaluation using stored procedures from a large business application shows that this technique can uncover bugs that lead to schema constraint violations and user de ned exceptions.
ccs concepts software and its engineering !software veri cation and validation software testing and debugging keywords symbolic execution stored procedures sql .
introduction symbolic execution is a powerful program analysis technique based on systematic exploration of bounded program paths which was developed over three decades ago .a key idea in symbolic execution is to build path conditions given a path a path condition represents a constraint on the input variables which is a conjunction of the branching conditions on the path.
thus a solution to a feasible path condition is an input that executes the corresponding path.
a common application of symbolic execution is indeed to generate test inputs say to increase code coverage.
automation of symbolic execution requires constraint solvers or decision procedures that can handle the classes of constraints in the ensuing path conditions.
a lot of progress has been made during the last decade in constraint solving technology in particular sat and smt solving.
these technological advances have fuelled the research interest in symbolic execution which today not only handles constructs of modern programming languages and enables traditional analyses such as test input generation but also has non conventional applications for example in checking program equivalence in repairing data structures for error recovery and in estimating power consumption .
despite the progress applying symbolic execution in new domains remains a challenging problem.
one such domain is stored procedures in relational database management systems.
relational databases are widely used for storing and managing data for applications.
many applications using databases interact with multiple users simultaneously.
in order to process user requests the applications mostly need information from database tables relations often requiring access to multiple database tables and sometimes involving decisions in the form of conditional statements as well.
if database server and application server are on separate machines then the network overhead can be signi cant due to multiple requests to the database server.
in order to avoid this overhead and to place business logic close to data for integrity purpose application programmers often move business logic for common tasks from the application server to the database server in stored procedures.
correctness of stored procedures is crucial for correct working of the application as well as for maintaining data integrity.
however testing them is a di cult task.
any test case written for stored procedures needs to provide data for database tables in addition to the usual program inputs in order to have reproducible results.
symbolic execution has been used with database driven applications .
however the techniques for testing applications are not directly applicable to testing stored procedures because they run inside a database server.
furthermore the techniques are limited in permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
nature due to the challenges posed by multi lingual nature of these application sql and some imperative language and because of considering the database as an external system.
often a very limited sql grammar has been supported for these applications for automated test generation.
this paper presents a novel technique to adapt symbolic execution for automated testing of stored procedures.
our key insight is that instrumenting the internal query nodes of the database query processing engine enables us to gather internal database constraints while being more precise and e cient in producing non redundant test cases.
we adapted symbolic execution technique for stored procedures written in the pl pgsql language for postgresql1.
pl pgsql runs directly on the database so it is not an external system.
a major advantage of our technique of instrumenting query nodes for pl pgsql is that it has the same type system as the database tables.
this makes it simpler to establish a relation between program variables and data stored in the database.
this is a simpli cation that is not available to logic written in other languages.
because of these simpli cation we are able to support a larger subset of the sql grammar.
in contrast to dynamic symbolic execution of simple programs where program conditions are the only source of constraints we identi ed three sources of constraints in symbolic execution of stored procedures.
these constraints imposed on program variables are gathered during execution of the program through instrumentation of postgresql.
these sources of constraints include i language constructs e.g.
if statement are rst source of constraints imposed on program variable.
ii sql constructs are the second source of constraints that are indirectly imposed by sql statements.
based on a key insight we used the query plans generated for execution of the sql statements to extract such constraints.
the important di erence between language and sql construct is that the number of paths choices depends on the number of rows being processed at the sql node e.g.
a sequential scan plan node has four choices when the table being scanned has two rows and eight choices with three rows in a table and iii database integrity constraints are imposed on the database tables to ensure that the data always satis es certain properties.these constraints may be violated in some cases during the execution of the application causing exceptions in the procedures.
a typical example would be a primary key constraint violation that occurs when the user requests insertion of a record which already exists in the system.
we make the following contributions symbolic execution of stored procedures we demonstrate an end to end technique for symbolic execution of stored procedures in postgresql.
instrumentation at query node level our instrumentation at the level of query nodes allows more precision and e ciency than was possible using any technique at the abstraction of a high level query language like sql.
constraint collection from query nodes we identi ed and collected constraints from three sources using query node instrumentation i.e.
conditions on program variables indirect constraints due to sql statements and database integrity constraints.
we implemented symbolic execution of stored procedures on postgresql an opensource database with support for stored procedures and using the z3 smt solver .
the algorithms are adaptable to other database systems but the implementation is speci c for the query node types and processing in postgresql.
evaluation we evaluated our technique on procedures that are part of an open source accounting and crm erp postbooks2.
our symbolic executor has generated around cases that trigger constraint violations or hit user de ned exceptions showing the e ectiveness of our technique and the limitations of writing manual test cases for stored procedures.
.
background symbolic execution is a technique for executing a program on symbolic values .
there are two fundamental aspects of symbolic execution de ning semantics of operations that are originally de ned for concrete values and maintaining a path condition for the current program path being executed a path condition speci es necessary constraints on input variables that must be satis ed to execute the corresponding path.
as an example consider the following program that returns the absolute value of its input static int abs int x int result if x result x else result x return result to symbolically execute this program we consider its behavior on integer inputs say x. we make no assumptions about the value of x except what can be deduced from the type declaration .
so when we encounter a conditional statement we consider both possible outcomes of the condition.
to perform operations on symbols we treat them simply as variables e.g.
the statement on l4 updates the value of result to be x. of course a tool for symbolic execution needs to modify the type of result to note updates involving symbols and to provide support for manipulating expressions such as x. we perform operations on symbols algebraically.
symbolic execution of the program absexplores two paths path l2 l3 l4 l7 path l2 l3 l6 l7 note that for each path that is explored there is a corresponding path condition shown in square brackets .
while execution on a concrete input would have followed exactly one of these two paths symbolic execution explores both.
5201create or replace function updateempsalary id integer 2returns integer as body 4declare sal integer experience integer 7begin select a.salary a.experience into sal experience from emp a where empno id if not found then return end if if experience then sal sal else sal sal endif update emp set salary sal where empno id return end body figure example code of stored procedure for test case generation through symbolic execution.
random input stored procedure execution a trace analysis b analyze construct c new table?model table d update table g gather and solve constraints e generate test case and table data f new test case sql language constructyes no choicesettable data figure flow of symbolic execution of stored procedure .
illustrative example in order to explain symbolic execution of stored procedure consider procedure updateempsalary given in figure .
our database schema for this example is a single table empwith table structure given in table which contains records of the employees of the company.
we have primary key and not null constraints on the empno and salary columns respectively.
before initiation of symbolic execution of updateempsalary our program connects to the database to extract signature of1t result targetlist target entry functioncall argument start argument end as updateempsalary 2start function 3plpgsql stmt execsql 4t seqscan targetlist target entry col salary as salary target entry col experience as experience conditions col empno param into sal experience 6plpgsql stmt execsql end 7plpgsql stmt if not param found 8plpgsql stmt if end 9plpgsql stmt if param experience ... figure trace log for example code table emp table structure no attributes constraints type empno primary key integer name string salary not null integer 4experiance integer the procedure i.e.
number of input parameters along with their data types.
we generate rst test case with random value e.g.
id .
symbolic execution with concrete input is also called concolic execution .
flow of execution of stored procedure is given in figure .
a stored procedure execution we execute stored procedure with rst test case.
as procedure runs on the database we record its execution through instrumentation of query nodes in postgresql in trace log which includes every step that database performs as shown in figure .
it also lists conditions enforced at a particular point during execution of the procedure.
b trace analysis we analyze collected trace line by line to extract conditions imposed on variables and tables and to store information in a corresponding state.
for example in case of a variable declaration in a procedure we create symbolic object and add constraints to it.
for language constructs e.g.
if statement we add constraint to the respective symbolic objects.
for sql constructs we model tables.
here in this example line in trace log corresponds to procedure call.
line corresponds to sequential scan due to occurrence of sql construct in stored procedure on line of figure .
c analyse constructs in this step we check if we already have model for the table we move directly to step e otherwise we identify new table and prepare model for it in step d .
line in trace log tells that sequential scan is done on the table empwhere output of scan is given as targetlist which comprises of salary and experience .
condition speci es constraint in sql construct and is given in preorder notation i.e operatorid rstoperand secondoperand.
here condition is empid param where param is rst input argument of the procedure.
for language constructs as given on line of example code given in figure line in trace log given in figure is recorded.
it tells us about if condition.on encountering such constructs we move to step e .
521table symbolic rows for table emp empno name salary experience r11 r12 r13 r14 r21 r22 r23 r24 empid param1 r11!
param1 r21!
param1r11 param1 r21!
param1r11!
param1 r21 param1r11 param1 r21 param1 figure possible cases for sequential scan table data set against condition for case1 input value for procedure id empno name salary experience ali amna d model table we model table based on sql constructs analyzed above.
we query database to extract structure and integrity constraints on the table.
we add two symbolic rows to our table empas shown in table .
e gather constraints for sql constructs we de ne and gather already de ned constraints imposed on a table.
adding integrity constraints ensures that data generated for tables will not violate constraints imposed on the structure of the table.
we consider three cases for processing of sequential scan.
i none of the rows match ii only one row matches and iii all rows match scan condition.
case i and iii corresponds to one condition whereas case ii corresponds to two conditions.
all four conditions in figure are constructed and added to structure choiceset as choices shown in figure .
in addition to the conditions we also generate and store corresponding result which satisfy conditions.
this result set is a representation of output of sql statement e.g.
for case it is empty and for case it returns both rows of table empas shown in figure .
for language constructs we add constraints imposed by these constructs to choiceset .
choicesets are generated lazily i.e.
choices are only available for the path under exploration at any point in time.
in our example when we reach line of trace log we de ne symbolic variable for experience and add to the choiceset .
f generate test case and table data in order to generate test data for table emp our symbolic executor does not know which of the possible four paths shown in figure is taken by the procedure during execution.
but we now know that value of input argument id can satisfy or dissatisfy the condition in where clause.
we append this constraint to each of the choices in our choiceset .
we pick each choice one by one from choiceset and append integrity constraints of the table as well.
we use z3 to solve these constraints to generate value of id and four di erent datasets for table empwhere each dataset corresponds to one choice.
in our example dataset for case and case are given in table and table respectively.
while executing line of trace log for each of the path generated by sql construct we append1choiceset condition not r param1 not r param1 result condition r param1 not r param1 result condition not r param1 r param1 result condition r param1 r param1 result figure choiceset for sequnential scan table data set against condition for case2 input value for procedure id empno name salary experience ali amna constraints of language construct to lead the execution of store procedure to within if statement.
g update table we setup our tables with data generated in previous step and re execute stored procedure with new set of inputs generated as test cases in previous step.
for above example we populate emptable and move to step a for the execution of stored procedure with new test case.
we explore remaining choices in depth rst search manner by repeating steps described above until test cases for testing complete procedure are generated.
.
technique our technique for modeling of database tables is described in section .
instrumentation and processing of query plan nodes is in section .
and symbolic execution of the collected trace is in section .
.
handling of data types and query nodes is discussed in section in detail.
.
modeling of database tables tables in database are two dimensional objects.
each table can have multiple columns with di erent data types.
however the number of columns in a table is xed whereas the number of rows is varied which makes it di cult to properly initialize the table model.
our model for the tables is a d array of symbolic variables with number of rows as a con gurable constant in initial model.
due to exponential increase in number of cases with increase in rows of the table we setup initial table with two rows only.
this in our experience covers most of the cases that can arise in execution of stored procedures.
insertions and deletions in the tables are modeled and they can change the number of symbolic rows in the table as procedure executes.
when a table is modeled we also have to consider the constraints imposed on table by the schema.
the constraints can be primary key foreign key unique and check constraints.
the primary key constraint can be decomposed into a unique and a set of not null check constraints.
we have basic underlying models for unique foreign key and check constraints in the system.
the modeling of a foreign key constraint requires addition of another table model.
the foreign key constraint 522sql plan nodespl pgsql language nodes expression evaluation subsystem figure structure of postgresql can be recursive for such cases we model chains of foreign key relations.
we disable foreign key relations only if we detect a cyclic relation during the processing of foreign key constraints.
we generate data by solving these constraints applied to all rows in a table model using z3 smt solver and populate tables during setup for procedure execution.
.
processing of sql execution of pl pgsql procedure can be divided into execution of pl pgsql language constructs and sql statements.
because of same type system both rely on the same expression processing subsystem as shown in figure to process conditions and expressions.
expressions can also contain function calls allowing recursive procedure calls.
everytime pl pgsql encounters an sql statement it calls the sql processing system to get the results.
postgresql prepares multiple possible execution plans with estimate of cost of executing each plan.
an optimal plan represented as tree is selected for execution.
for example select from table1 t1 table2 t2 table3 t3 where t1.col1 t3.col1 and t1.col2 t2.num1 and t2.num2 2joins three tables and places extra conditions on column of table2 .
the plan for this query is shown in figure .
during execution system scans table1 and table3 discarding the rows that don t meet condition.
results of the two scans are joined using a nested loop based join.
latter these results are joined with output of scan of table2 .
we treat the nodes in the plan tree as basic building blocks of the program and modeled their execution in our symbolic executor.
when a sequential scan executes we extract the table identi er the columns that appear in the output and condition s .
extracted conditions decide the results of the scan.
in the absence of condition all rows are selected as result.
whereas in presence of where clause we impose the conditions on the table model such that each row in a table can either satisfy or dissatisfy the scan condition.
here we draw inspiration from numerous works on symbolic execution that treat a simple if condition as a choice point where system can take any of the two paths depending on whether the condition or its negation is true.
here we have a larger number of conditions that are not related to each other by a simple negation.
each of the conditions if true has a corresponding result model containing the rows selected by that condition.
therefore we de ne choice as a set of conditions with corresponding result model.
choiceset is the set of all choices at the node.
during exploration of paths at each node we select a choice from choiceset one by one append table integrity constraints as well as conditions from already processed nodes along this path.
we then solve it to generate corresponding result.
however if solver gives no solution for the condition it means that figure plan for join query choice corresponding to condition is not possible.
this is a possible limitation but in our evaluation we did not encounter any case where solver timed out.
if solver times out we consider path to be unreachable.
when we reach a node which needs the results of the earlier node we can easily provide symbolic models of the results processed earlier.
in example above second nestedloop requires results from the rst nestedloop and a sequential scan.
since output model of rst nestedloop is compatible with general result model plan can be symbolically modeled.
this means our grammar coverage of sql is not based on syntax rather it is based on the underlying execution plan of sql.
.
symbolic execution we have instrumented postgresql to record execution of pl pgsql sql and expression processing in a le trace log .
in our symbolic executor state object is used to keep track of the explored and unexplored paths and it tells us about execution of the program.
the algorithm for generating test cases is outlined in algorithm .
this algorithm explores states in a depth rst search manner.
the trace log is processed line by line.
information extracted from each trace line from trace log is stored in our data structure called stackframe.
each state maintains its stackframe which allows processing of nested queries functions.
when a trace line comes in for processing the state object can tell if it has already processed that line before.
if the trace line is not processed then a new stack frame is prepared in state to store information about the current trace line.
the function processtraceline models all kinds of operations and generate choicesets and add them in state.
if trace line generates only one choice which means only one path out of state then we are certain about program ow.
at this point we simply add condition to the solver and get new traceline for processing.
if the choiceset of state has more than one condition then we are not certain about the path taken by the current trace so we stop analyzing trace and solve constraints to generate test cases.
on line a new condition is fetched from the state.
this tells us if the state has advanced moved to next state since the last call to nextchoice.
if stateadvanced is true then we have a new stack frame in state and condition should be added to solver stack.
otherwise we will pick next condition from stack frame.
we explore all conditions in the stack frame before advancing to next state.
this happens when solver says that the condition is not satis able.
we check if we are still on same trace line then it means that state has 5231solver create new solver object contains the path condition stack 3state create new state object keeps a stack of choicesets for trace 5t create a test case with random values main symbolic execution code 7while t is not null execute test case t on database for line in executiontrace if line is already processed continue with next loop iteration state.advance prepare new stack frame choiceset processtraceline line state.addchoiceset choiceset if choiceset.size add the condition from the only choice in solver continue with next loop iteration break while true condition stateadvanced state.nextchoice if condition null terminate backtrack if terminate t null break else continue with next iteration else if stateadvanced add condition in solver stack else replace condition at solver top of stack solve the path condition stack in solver if path condition is satisfied t make test case from solver result break algorithm test case generation algorithm not advanced.in such case nextchoice function will return the second condition from the same choiceset.
as the new condition comes from the same choiceset we need to replace the condition in the solver stack instead of adding a new frame.
the nextchoice function returns a null if all choices are explored.
this means that end of path is reached and we need to move back.
function backtrack removes the stackframe from top of stack for both state and solver objects and continues with next loop iteration.
the next iteration then gets a choice from the new stack top leading to exploration of another path.
whenever backtracking ends up emptying the state stack then we know that the complete tree has been explored.
backtrack function returns true for terminating the search.
from the algorithm it is clear that we are progressing towards a full path condition by generating many cases that are based on incomplete paths through the program.
we skip the processing of the trace lines already processed based on the assumption that the execution of those statements will be exactly the same.
this is a reasonable assumption for pl pgsql language nodes but it is not completely true for sql.
sql being a declarative language leaves it for the database to decide how to execute the statement through a planner instead of simply executing programmer instructions.
hence it is possible for the sql statement to join two tables using nestedloop algorithm in one execution and use sortingtable data type models data typesolver typemodel summary integer integer direct mapping numeric real direct mapping boolean boolean direct mapping character integerinteger represents ascii value restricted to a z a z text integerinteger is dictionary lookup value date integer integer is o set from base date with mergejoin algorithm in the next execution.
we refer to this problem as plan instability for sql statements.
both the plans would give the same nal output but it will throw o our symbolic executor which was expecting the exact same trace till the last processed trace line.
we addressed this issue by turning o the use of many algorithms that planner can use to optimize the queries such as bitmapscan hashagg hashjoin indexscan indexonlyscan and mergejoin.
this just deactivates possible planner optimizations without restricting language grammar in any case.
.
implementation details .
data type models data elements in the tables and variables have speci c data types.
we represented these data elements as symbolic variables.
most data types don t translate directly to z3 solver data types.
only three database types integer numeric and boolean map directly to corresponding solver types.
we provided added support for character text and date types by modeling them as integers because these are some of the most common data types in databases.
characters naturally translate to integers through their ascii values.
in order to ensure that the solver does not assign invalid values to integers representing characters a constraint is added to restrict the value of the such integers between a and z or a and z or and .
this restricts special characters but using special characters in character type columns is not a common practice.
strings are mapped to integers.
this allows for exact string matches but does not support partial matches with like operation in sql.
in order to model date as an integer we have maintained a reference date in the symbolic executor.
the integer modeling of the date is an o set from this reference date.
the timestamp data types are compatible with date type and we use the same model for them.
any data element in the database can be initialized to null.
so null is modeled as a special integer with value as it is not a common hard coded value.
data type models are summarized in table .
.
expression processing models while processing constraints we come across a variety of expressions.
the expressions that we have modeled include binary operators boolean operators testing for null values coalesce expressions and functions calls.
the arguments for these operators can be table columns variables constants or expressions.
postgresql represents expressions as a tree before processing it which is printed out as a pre order traversal in trace log .
the results of processing each type of expression is shown in the table .
for many cases in the 524table expressions and table constraint models expression type expression model boolean operator and result and arg1 arg2 boolean operator or result or arg1 arg2 boolean operator not result not arg nulltest result arg null or arg !
null conditional binary operator opresult arg1 op arg2 condition and arg1 !
null arg2 !
null arithmetic binary operator opresult exprresult condition or and arg1 !
null arg2 !
null exprresult arg1 op arg2 and or arg1 null arg2 null exprresult null coalesce expressionresult exprresult condition or and arg1 !
null exprresult arg1 and arg1 null arg2 !
null exprresult arg2 ... and all args null exprresult null pl pgsql function callresult functionresult condition on function start and param1 arg1 param2 arg2 ... condition on function end functionresult actualreturnexpresion non pl pgsql function call result functionresultfrommodel functionid argumentlist constraint type constraint model unique constraint assuming rows in table composite constraint condition and not and row1.col1 row2.col1 row1.col2 row2.col2 not and row1.col1 row3.col1 row1.col2 row3.col2 not and row2.col1 row3.col1 row2.col2 row3.col2 foreign key constraint assuming table1 row table2 rows table1.col2 referencing table2.col1 condition or table1.row1.col2 table2.row1.col1 table1.row1.col2 table2.row2.col1 table1.row1.col2 null table we have speci ed processing result expression with a condition.
result is the expression that is sent back to the main trace processor.
main trace processor use the result according to its needs e.g if condition trace line processing would use it as the decision condition and generate two choices from it the condition itself and its negation.
whereas an assignment operation trace line processing will use it to assert that the target variable is equal to this expression value.
the condition expression represents the conditions that are automatically added with every choice by the trace processor using the result expression.
.
.
boolean operators binary operations and coalesce expression all three boolean operations and binary conditional operators map directly to the z3 solver api.
we have two types of nulltests.
isnull and isnotnull test.
both return true when the value is null and not null respectively.
result expressions for isnull and isnotnull as in table are returned.
in binary arithmetic operators for null arguments result of the expression is also null.
for the arithmetic operation a new symbolic variable is created and returned as a result.
conditions are imposed on the new symbolic variable.
we have two conditions inside the or function.
both the conditions are mutually exclusive because of the null checks in each condition i.e.
if both arguments are not null then the or condition inside the second and can never be true.
therefore the solver has to impose exprresult arg1 op arg2 in order to get a satisfying assignment.
similarly if any of the arguments is null then the or condition will be true but the rst and can never be true so in order to get a satisfying assignment exprresult null must be imposed.
a coalesce expres sion takes multiple inputs and returns its rst not null result.
like arithmetic operators the result is a new symbolic variable whose value comes from a set of mutually exclusive constraints.
.
.
function calls we classify the function calls according to the function language.
execution of functions written in pl pgsql is printed in our trace and we can follow the path through these functions.
for function calls appearing in an expression we simply return a new symbolic variable representing its result value with no condition imposed on it.
we also generate a condition that assigns the values to the function input variables.
we call this condition call condition for the function and it links the variables in the current function with the variables in the new context.
reaching trace line of the expression containing function calls we get the trace lines for execution of the functions listed in that expression.
call condition is loaded into solver when we get trace for the start of the function.
at the end of the function the value returned by the function is stored in result variable created earlier.
implementing this functionality requires tracking the call stack in the symbolic executor.
the maximum depth of the call stack for the symbolic executor is a con gurable constant.
.
.
special functions and sequences functions not written in pl pgsql don t show execution details in the trace.
these functions includes sql built in functions like the nextval for sequences date and time and type conversion.
model for the nextval function relies on our model for sequences to output a symbolic expression.
we model the sequence object as symbolic variable of type integer with starting value as .
we return the expression 525start value integer whenever nextval function is called for this object.
the model for current date and time function simply returns .
that means we are treating the base date of our symbolic executor as current date.
another function that we have modeled takes in the sequence name and returns the sequence id in database.
to model this function we query database for the relevant information and return it as model output.
.
constraint models we model check unique foreign key and primary key not null check and unique constraints.
check constraints are translated into pre order traversed tree expressions and processed in same way to get conditions.
the conditions are added to the solver for each row in the table s .
the models for foreign key constraints and unique constraints are shown in table .
for unique constraint in table the condition is generated for a composite constraint on col1 and col2.
composite constraint means that value of both columns taken together must be unique.
in general the condition needs to be asserted for all row combinations.
table also shows foreign key constraint model.
column value has to be one of the values in the referenced column or it needs to be null.
.
sql plan node processing we support sequentialscan nestedloop resultnode and modifytable nodes.
in previous section we discussed rst two types of nodes.
resultnode is used to generate a single row of results.
the values in the row being generated can be variables constants or any expression containing variables and constants.we treat results of the expressions as symbolic element in a new symbolic row that resultnode is supposed to produce.
the conditions from processing of multiple expressions are appended to generate a single condition.
the row produced by the expression results by solving conditions is the result for this node.
modifytable is top plan node and supports inserts updates and deletes.
thus it relies on its child node to provide the data it needs to perform its job.
for delete operation this node needs a list of row identi ers of the rows that need to be deleted.
for update operation it need the new rows along with the row identi ers of the rows which the new rows are supposed to replace.
for insert operations the new row must be the output of the child plan.
the simple case where we specify the list of values to be inserted is covered by the resultnode which makes the row out of the values.
in more complicated cases where we are inserting the result of a query into a table we simply have the whole query plan as the child plan for modifytable.
in all three cases we check that the table modi cations do not violate the table constraints by creating constraint conditions on the modeled table and adding the result as a choice.
we get our second choice as negation of the rst choice which is responsible for generating cases which violate constraints.
.
pl pgsql construct processing the pl pgsql language constructs such as if condition for loops over sql query results assignment statement variable initialization from sql results function start function return statement are supported.
if statement can be a simple expression or it can have a complicated condition with an sql statement embedded in it.
for the simple case thetable exception cases total exception cases no data found in select over exceptions due to sequence reset constraint violation due to unchecked inputs user de ned exceptions on input validation condition for the choice can be obtained from the expression processor where as in later case the result comes from the sql processing.
consequently generating cases for the sql is the way to explore the possible directions the code can take from the if condition.
assignment statements usually generate only one choice i.e target variable expression result .
another kind of assignment occurs with the result of the sql queries.
the keyword into allows the sql statements in pl pgsql procedures to directly assign their result values to variables.
this is handled similarly except for the fact that multiple variables can be simultaneously assigned new values.
in both cases these nodes have choicesets of size .
function start and function return statements are part of the support for the pl pgsql function calls.
the choicesets for these are described in table .
we have also added support for for loop over select statements.
the statement at the start of the for loop acts like an assignment statement and assigns a row from the for loop select query results to the variables on which the loop runs.
for loop works with currently modeled data types.
.
evaluation we evaluated our technique on an open source accounting and enterprise resource planning erp system postbooks which has a signi cant amount of its business logic written in functions in the database.
it has a schema consisting of tables.
functionality of procedures is fully supported by our models.
manual inspection of some of these procedures indicated that branch coverage was achieved.
the symbolic execution was con gured with the stack depth of result size of excluding unconditional scans and cross joins and an initial table size of rows each.
all experiments were performed on a .9ghz dell i7 machine.
many of the procedures in postbooks have user de ned exceptions to give a user friendly response to the client.
during exploration of the procedures we automatically generate cases that drive the procedure execution towards such exceptions e.g.
schema constraint violations.
we found test cases that trigger user de ned exceptions or constraints violations.
the scalability of our technique is shown by the number of modeled tables for many stored procedures.
postbooks uses a very large number of constraints to ensure data integrity.
in particular the schema has over foreign key constraints.
this means that long chains of tables related by foreign keys are common.
even if a procedure directly uses a few tables we had to model the tables it