graph based statistical language model for code anh tuan nguyen iowa state university usa email anhnt iastate.edutien n. nguyen iowa state university usa email tien iastate.edu abstract n gram statistical language model has been successfully applied to capture programming patterns to support code completion and suggestion.
however the approaches using ngram face challenges in capturing the patterns at higher levels of abstraction due to the mismatch between the sequence nature inn grams and the structure nature of syntax and semantics in source code.
this paper presents gralan a graph based statistical language model and its application in code suggestion.
gralan can learn from a source code corpus and compute the appearance probabilities of any graphs given the observed sub graphs.
we use gralan to develop an api suggestion engine and an ast based language model astlan.
astlan supports the suggestion of the next valid syntactic template and the detection of common syntactic templates.
our empirical evaluation on a large corpus of open source projects has shown that our engine is more accurate in api code suggestion than the state of the art approaches and in of the cases it can correctly suggest the api with only five candidates.
astlan also has high accuracy in suggesting the next syntactic template and is able to detect many useful and common syntactic templates.
i. i ntroduction source code is repetitive .
the programming patterns detected from code have been shown to be useful in many software engineering se applications including integrated development environment ide supports e.g.
code completion suggestion code search documentation framework adaptation program repair language migration etc.
recognizing their importance many approaches have been proposed to detect code patterns in various forms.
they can generally be classified into two categories.
the first one is based on deterministic pattern mining algorithms e.g.
mining frequent item sets frequent subsequences frequent graphs associate rules etc.
instances occurring at least a number of times are reported as patterns.
the second category is based on statistical language models.
a statistical language model lis a generative model defined via three components a vocabulary vof basic units a generative process g and a likelihood function p jl .p sjl is the probability that a sequence sof the elements in vis generated by the language model lfollowing the process g. recent research in se has shown that ngram language model is useful in capturing fine grained code patterns to support code suggestion code suggestion is the suggestion of a complete code element given a code portion .
n gram model is a statistical language model with two assumptions.
first it assumes that a sequence is generated from left to right.
second the generating probability of a word in that sequence is dependent only on its local context i.e.
awindow of previously ngenerated words.
n gram is popularly used for text analysis in natural language processing nlp .
however source code in a program has well defined syntax and semantics according to the programming languages.
the syntax and many levels of semantics can be represented by tree based data structures e.g.
abstract syntax tree ast or graph based data structures e.g.
control flow graph and program dependency graph .
the programming patterns at those levels have been shown to be useful in several se applications as listed above.
however using n gram creates a mismatch to those structured data representations thus making it not well suited and less accurate in detecting patterns at those levels.
for example using n gram model to capture api usage patterns faces the following issues.
first in a usage pattern it is not always that there is a required order between two api method calls e.g.
between the instantiations of two objects scanner and filewriter in a pattern of reading data from a file with scanner and writing to another file with filewriter in jdk.
however to model that pattern n gram requires a total order among api calls.
thus it might consider two instances of that pattern with different orders as not related.
second the code of a pattern often interleaves with the code for project specific logic e.g.
a usage for reading from a file is used together with project specific processing for the texts in the file.
an n gram could incorrectly include the nearby tokens of the project specific usage into the pattern.
thus the model could potentially miss the correct pattern and incorrectly suggest the next api call.
third in many cases the prior napi calls do not sufficiently provide the context for code suggestion since the api calls in the same usage pattern could be far apart and cannot be captured within nelements.
extending nto a large value does not solve the problem since more irrelevant api elements would be included.
similarly using n gram to capture syntactic templates is not well suited since the structural and containment relations among ast nodes are not considered.
in this work we introduce gralan a graph based statistical language model that can learn from a corpus of graphs produced from training data of source code to compute the probability that a graph bwould appear given a set of context graphsctxt .ctxt includes a subgraph aofbin whichaor subgraphs of awere observed.
we further consider the cases wherebhas exactly one more node than aand the inducing edges.ais called the parent graph of b. during training we identify the sub graphs with parent child relations in the corpus and compute such probabilities by using thebayesian formula on the graphs in ctxt and by counting the occurrences of sub graphs and co occurrences among them.
to demonstrate the applications of gralan we used it to build a code suggestion engine for the next api element.
api elements are api method calls and field accesses and related control units e.g.
if while for used in an api usage.
the next api element is the one that is requested to be filled in at the current editing position l which is not necessarily at the end of the current code .
first the current code is parsed to build a groum a graph representing api usages.
for suggestion we consider as the context the api usages surrounding l represented by subgraphs and use gralan to suggest a list of api candidates ranked by their probabilities.
we also developed astlan an ast based language model that was adapted from gralan to support the suggestion of the next valid syntactic template and the detection of common syntactic templates.
ides could provide developers such commonly used syntactic templates during editing.
we have conducted an empirical evaluation on gralan s and astlan s code suggestion capability.
with a single suggestion in one out of three cases gralan is able to correctly suggest the api element.
in one of two cases the correct api element is from two suggestions.
in out cases the correct api element is within the top suggested apis.
we also compared gralan s accuracy with that of two stateof the art approaches used in bruch et al.
and raychev et al.
.
while bruch et al.
is based on sets of api elements in the methods of a corpus raychev et al.
is based on n grams on such api elements .
our results showed that gralan s top5 accuracy is .
.
and .
.
higher than those of the set based and n gram based approaches respectively.
astlan is able to achieve high accuracy as well.
in of the cases the correct next template is in astlan s top list of candidates.
importantly astlan is able to mine several correct syntactic templates.
our key contributions include .
gralan and astlan the graph based and tree based statistical language models for object oriented source code .
their applications in api and syntactic template suggestion engines and in syntactic template detection and .
an empirical evaluation on the performance of the models to show their accuracy in code suggestion.
ii.
a m otivating example let us start with an example that explains the challenges when using n gram model for code suggestion and motivates gralan.
figure shows the code in which the book data is read from a text file via the classes fileand scanner and then stored into another text file via fileand filewriter of the jdk library.
after the metadata is read lines a while loop lines is used to iterate over all the lines in the first text file to retrieve the authors data and write to the second file.
from the example we see that to achieve a programming task developers use the application programming interface elements api elements apis for short which are the classes methods and fields provided by a framework orlibrary .
the api elements are used in some order with specific data1file bookfile new file books.txt 2scanner booksc new scanner bookfile 4file authorfile new file authors.txt 5filewriter authorfw new filewriter authorfile 7bookmetadata metadata getmetadata bookmetadata.txt 8metadata.printdata 10while booksc.hasnextline f string bookinfo booksc.nextline if isnotvalid bookinfo continue string authorinfo getauthorinfo bookinfo authorfw.append authorinfo system.lineseperator 15g 17authorfw.close 18booksc.close fig.
.
an api usage example and or control flow dependencies and control structures i.e.
condition repetition according the api specification.
a usage of api elements is used to achieve a programming task and is called an api usage .
an example of a usage is for reading data from a file involving file.new scanner.new scanner.hasnextline scanner.nextline scanner.close and the control unit while.
usingn gram to capture common usages called patterns and give code suggestion would face the following challenges .
total order.
the api elements in a usage do not always have a specific required order e.g.
the instantiations of the scanner and filewriter objects.
however n gram requires a total order among apis.
thus it would not consider two sequences filewriter.new scanner.new and scanner.new filewriter.new as two instances of the same pattern.
using a graph model could help to represent the partial order among apis.
.
interleaving between the code of patterns and projectspecific code.
the code for the pattern reading from a file and writing to another is interleaved with the code for the project specific logic e.g.
reading metadata lines checking information validity line or retrieving authors information line .
an n gram could incorrectly include the nearby tokens of the project specific usage e.g.
getauthorinfo orisnotvalid into a pattern leading to incorrect suggestion.
.
api elements of the same pattern could be far apart in the code.
for example reading from a file involves file.new scanner.new lines the while loop with scanner.hasnextline line scanner.nextline line and scanner.close line .
such patterns can not be captured well with n grams with limited lengths.
however considering dependency graphs among api elements can help to connect them together.
.
non sequential order of editing.
for example a developer could write the body of the while loop line before writing its condition.
if s he requests for code suggestion at the condition n gram will use the code prior to line for suggestion.
however the code after that such as booksc.nextline could suggest the use of booksc.hasnextline at the condition of thewhile loop since they often go together.
this also suggests us to expand the context for code suggestion to include the code after the requested location.iii.
g raph based statistical language model to address those issues we propose gralan a graph based statistical language model.
let us present it in the context of its application of api code suggestion where it is applied to the graphs representing api usages.
however gralan is general for any graphs extracted from code.
for the concepts specifically applicable to api suggestion we will explicitly state so.
a. api usage representation definition api usage an api usage is a set of related api elements i.e.
classes method calls field accesses and operators in use in the client code together with control units i.e.
condition and repetition in a specific order and with the control and data flow dependencies among api elements .
in our prior work we developed a graph based representation model called groum to represent api usages.
definition groum a groum is a graph in which the nodes represent actions i.e.
method calls overloaded operators and field accesses and control points i.e.
branching points of control units if while for etc.
.
the edges represent the control and data flow dependencies between nodes.
the nodes labels are from the names of classes methods or control units.
our prior work shows that an api usage can be represented by a connected sub graph in a groum.
in figure p2 g illustrates the pattern on filewriter as a groum.
the action nodes such as file.new filewriter.new etc.
represent api calls field accesses or operators.
the nodes labels have fully qualified names and an action node for a method call also has its parameters types not shown .
an edge connects two action nodes if there exist control and data flow dependencies between them.
for example filewriter.new must be executed before filewriter.append and the object created by the former is used in the latter call thus there is an edge from the former to the latter.
if a usage involves a while loop e.g.
in figure a control node named while is created after the node for the condition and is connected to the first node in the body of while.
if a method call is an argument of another call e.g.
m n the node for the call in the argument will be created before the node for the outside method call i.e.
the node for ncomes before that of m .
the rationale is that nis evaluated before m. b. generation process a graph can be constructed from one of its subgraphs by adding nodes and edges.
thus the graph generation process can be modeled by the addition of nodes and edges to alreadyconstructed subgraphs.
thus we define the following concept definition parent and children graphs a connected graphp g is a parent graph of a graph gif adding a new nodenand inducing edges from ntop g will createg.gis a child graph of p g .
a child graph of gis denoted as c g .
a graph can have multiple parents and multiple children.
this relation is general for any graph.
however let us illustrate it via figure for api usage graphs groums .
the graphp1 g is a parent graph of gbecause adding the node file.new and the edge file.new filewriter.new top1 g will create g.galso has its children c1 g andc2 g .
the suggestion of file.new g 1c g filewriter.
f l ushfilewriter.
f lush 2c g list.addfile.newfilewriter.new filewriter.append filewriter.closelist.get 1p g 2p g filewriter.new filewriter.appendlist.get filewriter.closefile.new filewriter.new filewriter.append filewriter.closelist.get file.new filewriter.new filewriter.appendlist.get filewriter.closefile.new filewriter.new filewriter.appendlist.get filewriter.closelist.addfig.
.
parent and children graphs a new api given an already observed groum gcan be done by considering all of its children c g 0s.
we extend the concept of parents to ancestors and that of children to descendants.
definition context the context of a generation process of a new graph c g from a graph gis a set of graphs includinggthat are used to generate c g .
we usepr c g jctxt pr g n e jctxt to denote such generation probability.
n is the additional node and e is the list of additional edges connecting gandn to build c g .
all the graphs in ctxt includinggaffects the generation ofc g .
for the api suggestion application the context contains the subgraphs g1 gn of the groum gbuilt from the code that surround the current editing location.
those subgraphs represent the potential usages that are useful in the prediction.
for each child graph generated from a subgraph gi the corresponding additional nodes nj s will be collected and ranked.
each new node will be added to gto produce a candidate graph g0as a suggestion see details in section iv .
c. computation based on bayesian statistical inference let us explain how we calculate the generation probability of a new graph with bayesian statistical inference.
we have pr c g jctxt pr g n e jctxt we want to compute the generation probability for the additional node and edges to g. that probability is learned from a training set via statistical learning.
to do that we start with pr c g jctxt pr c g jg1 gn wherepr represents a probability that a child graph c g is generated from its parent g andg1 gnis the set of graphs includinggmaking up the context for generating c g .
the bayesian model is based on the bayes theorem to estimate the posterior probability given the prior probability pr a b pr ajb pr b pr bja pr a pr bja pr ajb pr b pr a wherepr bja is the probability of a hidden variable b having a state given the observed state of the variable a. pr ajb is the learned knowledge on the impact relation via conditional probability between banda.pr a andpr b are the prior probabilities that aandbhave their respective states.
in gralan the hidden variable brepresents the graph c g to appear i.e.
to be generated and the known variables as include the given graph gand the rest of the graphs in the contextctxt having been observed.
thus the formula for the generation probability of c g becomes pr c g jg1 gn pr c g g1 gn pr g1 gn pr c g g1 gn pr g1 gnjc g pr c g pr c g g1 gn is the probability that all the graphs g1 gnandc g co appear.
pr c g is the probability that the child graph c g appears.
it can be estimated by pr c g methods c g methods where methods is the number of all methods in a training dataset and methods c g is the number of all the methods containing c g .
pr g1 gnjc g is the probability that the graphs g1 gnappears given that c g has been observed.
similar to the n gram model where the subsequences ngrams are assumed to be conditionally independent we assume g1 ... gnto be conditionally independent given c g .
thus pr g1 gnjc g pr g1jc g pr gijc g pr gnjc g pr gjjc g j n is the probability that the graph gj appears given c g and is estimated by the bayes formula pr gjjc g pr gj c g pr c g methods gj c g method c g methods where methods gj c g is the number of all methods having bothgjandc g .
a smoothing constant is used to avoid zero value when there is no method having both gjandc g .
sincegbelongs to the context let g gi.
the pairg andc g co appears at least in one method and they have parent child relation hence we give that pair a probability pr c g jg methods g c g method g .
thus pr c g jctxt pr g n e jctxt pr c g jg1 gn pr g1jc g pr gi 1jc g pr gjc g pr gi 1jc g pr gnjc g pr c g pr g1jc g pr gi 1jc g pr gjc g pr c g pr gnj pr g1jc g pr gi 1jc g pr c g jg pr g pr gnjc g methods g1 c g method c g methods methods g c g methods g methods g methods methods gn c g method c g methods the calculation of the product of probabilities which are within is not resilient due to floating underflow.
thus we calculate the logarithmic values of and use them to compare the additional nodes corresponding to different c gj s. log pr c g jg1 gn p j nlog methods gj c g log methods gj c g n log method c g methods log methods g file.new scanner.new file.new filewriter.new bookmetadata.new bookmetadata.printdatamain.getmetadata while scanner.closescanner.nextline1 file bookfile new file books.txt scanner booksc new scanner bookfile file authorfile new file authors.txt filewriter authorfw new filewriter6 authorfile bookmetadata metadata getmetadata bookmetadata.txt metadata.printdata while booksc.nextline booksc.close a. b.fig.
.
an api suggestion example and api usage graph 1function apisuggestion code c location l graphdatabase gd 2g buildgroum c 3ctxt getcontextgraphs g l 4nl a ranked list of recommended nodes 5foreachg2ctxt 6fc g g getchildrengraphs g gd foreachc g fc g g 8score log pr c g jctxt 9nm getaddednode c g 10nl updaterankednodelist nl nm score returnnl 12end fig.
.
api suggestion algorithm iv.
g ralan in api e lement suggestion this section explains how we use gralan to build an engine for suggesting the next api element for the current code.
the suggestion task for api elements is to recommend an api element upon request at a location in the current code under editing not necessarily at the end .
an example of partially edited code is shown in figure 3a.
a developer requests the engine to suggest an api call at the while loop line .
a. algorithm overview.
the key idea of the api suggestion algorithm is to extract from the currently edited code the usage subgraphs groums surrounding the current location and use them as the context.
then the algorithm utilizes gralan to compute the probabilities of the children graphs given those usage subgraphs as the context.
each child graph has a corresponding additional node which is collected and ranked as a candidate of api element for suggestion.
those probabilities are used to compute the scores for ranking the candidates.
detailed algorithm.
figure shows the pseudo code of our algorithm.
the input includes the current code c the current locationl and the trained model with graph database gd see section iv b for building gd .
first we use eclipse s java parser to create the ast for the current code.
if the incomplete code under editing is not parsable by the parser we run the ppa tool on it.
the ppa tool accepts a portion of code and returns an ast with all available type binding information.one node two nodes three nodes ...while bookmetadata.
printdata scanner.nextlinescanner.new while filewriter.new while bookmetadata.new while bookmetadata.new scanner.nextline scanner.closescanner.new while scanner.nextline while scanner.nextline scanner.close ... ...... four nodes scanner.new while scanner.nextline scanner.closebookmetadata.
printdata ...scanner.closefig.
.
context subgraphs however in some cases there might exist some unresolved nodes for example their syntactic or data types are undetermined.
thus they are assigned with an unknown type.
then we build the groum from the ast using the groum building algorithm line .
due to the possible incompleteness of the current code the unresolved nodes in the ast if any are considered as single node graphs.
their labels are the lexemes.
the groum of the code in figure 3a is shown in figure 3b.
next apisuggestion determines the list of context graphs from the groum gand the current location l line .
we use the graphs that contain the apis surrounding las the context.
one or more of those context graphs are potentially the graphs that generate the child graphs in which the corresponding additional nodes are the candidates to be filled in at l. they represent the usages with high impact on the selection of the api to be filled.
details on context graphs are in section iv c. figure shows the context graphs for the code in figure .
then for each graph gin the context we search in the graph databasegd of gralan to determine all feasible children graphsc g s line .
we compute the score that each child graphc g would be generated line with the equation .
the respective additional nodes for those children graphs are collected line and ranked based on the computed probabilities as the candidate apis for suggestion line .
table i shows a few examples of the context graphs and their corresponding children graphs for our example in figure .
in the interest of space we show the graphs as a sequence of the nodes labels.
the respective additional nodes of the children graphs are written in bold e.g.
scanner.hasnextline is from the child graph in table i. moreover an additional node n from a child graph c g will assume the location lin the code.
the relative order between n and other nodes in c g must be consistent with their corresponding order in the graphg.
for example the api scanner.nextline is after both the current location land while .
thus the children graphs c g s with scanner.nextline appearing before n or before while are not considered.
any graph c g with its additionaltable i context graphs and their children graphs gi c gi score while .scanner.hasnext while .
.stringtokenizer.hasmoreelements while .
... scanner.new while .
scanner.new scanner.hasnext while .
.
scanner.new scanner.hasnextline while .
.
scanner.new scanner.hasnextchar while .
... bookmetadata.new while null i.e.
no child graph in gd project specific .
while scanner.nextline .scanner.hasnextline while .
scanner.nextline .scanner.hasnext while scanner.nextline .
.scanner.hasnextchar while scanner.nextline .
table ii ranked candidate nodes node scores highest score scanner.hasnextline .
.
.
scanner.hasnext .
.
.
.
scanner.hasnextchar .
.
.
stringtokenizer.hasmoreelements .
.
noden violating that condition will not be used.
the graphs in table i conform to that condition.
such checking is part ofupdaterankednodelist in line of figure .
note that in a groum the node for the condition of a while loop appears before the while node.
in table i the children graphs c g s withn in bold connecting to while are still valid.
the probability that a node is added to gis estimated by the probability that the respective child graph is generated given its context.
table ii shows the examples of candidate apis.
each candidate might be generated by more than one parent graphs.
thus its highest score is used for ranking.
for example the additional node scanner.hasnextline appears in the two children graphs and .
finally the node with highest score could be used to be filled in the requested location l. the additional edgese s are determined from the corresponding c g s but we do not need them for this api suggestion application.
a user just uses the suggested api with their chosen arguments.
b. building database gd of parent and children graphs we use grouminer to build groums for the code in any given code corpus.
to identify parent and child sub groums we traverse a groum in a depth first order and expand from a smaller parent graph by adding a new node and inducing edges to get a child graph.
we repeat until all nodes edges are visited.
c. determining context subgraphs to determine the context graphs at the current location l we collect the surrounding api calls.
a threshold is used to limit the number of such calls.
the closer to lan api call is in the code the higher priority it has.
in figure 3a if the surrounding api elements are metadata.printdata while booksc.nextline and booksc.close .
thus we collect into a set s the nodes bookmetadata.printdata while scanner.nextline and scanner.close .
from those nodes we expand them to all the subgraphs in gthat satisfy the following containing at least one api ins and having the sizes smaller than a threshold .
is also used to limit the number of context graphs which can increase exponentially.
for example given the set sof bookmetadata.printdata while scanner.nextline scanner.close and the context graphs are partially listed in figure .
v. ast based language model we have adapted and extended gralan into astlan an ast based language model to support the suggestion of a syntactic template at the current editing location and to support the detection of popular syntactic templates.
an example of such suggestion is shown in figure .
a developer wrote a while loop with a declaration of the string variable bookinfo .
the cursor is at the end of bookinfo .
the engine built with astlan could suggest to him her the addition of a new ifsyntactic unit with a continue since it has often encountered such common structure where a checking is performed within a while loop.
such common syntactic structure e.g.
a while loop with an ifcontinue is called syntactic template .
our engine can suggest such templates as part of its code completion.
unlike existing ides which give pre defined templates our engine can suggest syntactic templates that most likely occur at the current location taking into account the current code .
astlan also has three key components generation process the context and the computation of generation probabilities.
a. generative process similar to gralan the foundation of the generative process is the parent child relation between asts.
we want to model the generation from a smaller ast to a larger one.
definition parent and children asts an astcis a child of another ast p pis a parent of c if cis formed by adding a minimal ast sub tree tto a node in p and bothpandcare syntactically correct.
aminimaltmeans that there is no way that we can delete one or multiple nodes in tand still make csyntactically correct.
this first condition ensures that the newly added tforc is the one with the minimum number of nodes among all other sub trees that can be added to pat the same location with the same syntactic type.
for example the asts in figures fa bg satisfy this since we cannot add to the blockstatement any other smaller fragment of the type ifstatement to create a valid ast.
all three nodes ifstatement cond and continuestatement are needed.
the rationale for this condition is that we want to suggest the smallest template of certain syntactic type.
for example the following suggested code does not satisfy that while booksc.hasnextline f string bookinfo if cond continue string authorinfo getauthorinfo bookinfo g because it is larger and contains the ast in figure 6b.
the rationale for the second condition on syntactic correctness let us call it valid for short is that we want to suggest a valid syntactic template for the current code.
if one wants to build a suggestion engine for templates without concerning syntactic correctness the validity condition is not needed.
in figure 6b the suggested template is an ifstatement with a condition and continue .
the corresponding subtree with ifstatement ... while booksc.hasnextline string bookinfo whilestatement methodinvocation variable hasnext line booksc blockstatement variabledeclaration type variable string bookinfo ... while booksc.hasnextline string bookinfo if condexpr continue if statement continuestatement condexpr blockstatement ......a. b. newly addedastfig.
.
an example of suggesting a valid syntactic template cond and continuestatement is valid.
however if we add only ifstatement !cond the resulting tree will be syntactically invalid.
finally as in gralan a parent can have multiple children asts and a child ast can have many parent asts.
b. normalization on ast the concrete values in ast nodes are specific in different locations.
for example the variable name booksc in figure is project specific and might not be matched to other variables in other projects.
to detect syntactic templates and enhance astlan s suggestion capability we perform a normalizing procedure on the ast s subtrees.
an ast subtree is normalized by re labeling the nodes for local variables and literals.
for a local variable node in a subtree or a label in a switch statement its new label is the name of that variable label via alpha renaming within the subtree concatenated with its type.
for instance in figure 6a booksc becomes var1 scanner and bookinfo becomes var2 string .
a literal s label is lit concatenated with its data type.
we abstract the special values such as empty string zero and nullwith special labels.
such values are often used for special meaning e.g.
successful execution nullity checking etc.
c. building database of parent and children asts an important task in astlan is to mine all the parent and child asts from a corpus of syntactically correct programs.
given a method we parse it to build its ast.
we traverse the ast from the top and identify the parent and children asts.
the first phase is to find one or more valid ast fragments and use them as initial parent asts.
we examine the first childcof the blockstatement of the method s body.
depending on the ast node type of c we consider its children nodes that form withca syntactically correct tree.
for example if cis an ifnode we expand from cto its children in either one of the two following possibilities depending on its concrete children connecting ifto both eand s1 or connecting ifto all three nodes e s1 and s2 table iii .
note that connecting if to only eand s2creates an invalid ast fragment since the truebranch is always needed.
table iii shows the examples of such expansion rules.
next we connect blockstatement toc table iii examples of expanding rules syntax valid expansion if ife s1 s2 if!e if!e s1 if!e s1 s2 while while e stmt while!e while!e stmt for forinit e update stmt for!init e update for!init e update stmt switch switch e case def switch !e switch !e f with f 2all case combinations switch !e def switch !e f def with f 2all case combinations case case e stmt case!e case!e stmt infixop e1 op e2 infixop !e1 e2 try tryblockfcatches try!block all combinations of catches jfinallyg try!block finally try!block all comb.
of catches finally and toc s children nodes according to either one of those two possibilities.
for each possibility we apply the same expansion rules on each of the children of cand repeat the expansion until seeing a leaf node.
then the next possibility is explored.
at each step for a possibility after traversing to c s children if the resulting ast fragment formed by the tree expanding toc citself andc s children is valid we will consider it as an initial parent ast s p. in figure 6a after this phase we have two initial parent asts the left subtree at while p1 and left subtree at while and the node blockstatement p2 .
in the second phase for each of parent asts p we consider the edges coming out of pin the method s ast.
for each edge let us use nito denote the corresponding node.
for example for p1 niisblockstatement .
forp2 niisvariabledeclaration .
we want to find the children asts of that parent tree p by attempting to expand from ptoniand toni s children.
to do that we use the same expansion rules in table iii.
we then collectniand each of the valid combinations of its children nodes to form different possible subtree s t. the subtree s twith the minimum number of nodes is used to connect to pto form its child ast c s .
the ones with higher numbers of nodes will be used as the children or descendent asts for thosecs depending on their numbers of nodes.
for example the tree with all sub components of ifwill be used for the child ast of the one with if e and s1.
the process repeats as those resulting children asts cand their descendants will be used as the parent asts for further traversal.
for example after this phase we have p1is a parent ast of p2 which in turn is a parent ast of the entire subtree at while in figure 6a.
to find other parent ast s for a child ast c we take each parent ast of pand connect to the corresponding tof c tis the newly added subtree .
if the resulting tree is valid and connected to the parent ast of pin the method s ast it will be noted as another parent ast of cas well.
d. context trees first to determine the context trees in the ast we find the smallest valid subtree whose corresponding source code contains the current location l. let us call the root of thattable iv data collection total projects total classes total methods total slocs total usage graphs involving jdk apis total distinctive graphs total distinctive api elements total valid ast s fragments total distinctive fragments total distinctive ast nodes subtreenl.
then we collect all valid trees tis that satisfy two conditions ticontainsnl and tihas a height not greater than a threshold .
as in gralan those nearby nodes provide a context to generate the next child ast s .
in figure 6a nlis the blockstatement .
if the trees rooted at whilestatement and blockstatement whose heights are smaller than are in the context.
e. valid ast suggestion with bayesian statistical inference with the parent child relation on asts and context trees we can apply the same process with bayesian statistical inference to calculate the generation probability of a new valid ast c t given the context including t e.g.
t ti section iii c pr c t jctxt pr t n e jt1 tn methods t1 c t method c t methods methods t i c t method c t methods methods t c t methods t methods t methods methods tn c t method c t methods that probability is used in our algorithm to suggest the next valid syntactic template in the similar procedure as in the api suggestion algorithm in figure .
let us explain the differences between two algorithms.
first ppa is used to build the ast from the current code.
second instead of collecting context graphs we collect context trees in the ast considering the current location.
third for each context tree t the tree database is used to find children asts.
the formula for the probability pr c t jctxt is computed for each context treetj.
finally the corresponding additional ast s subtrees are computed and ranked using those probabilities.
vi.
e mpirical evaluation we conducted several experiments to study gralan s and astlan s code suggestion accuracy with different data sizes and parameters and to compare gralan to the state of the art approaches.
they were run on a computer with intel xeon e5 .1ghz configured with thread and 32gb ram .
we collected a large corpus of java projects from sourceforge.net table iv .
to get higher quality code for mining we filtered out the projects that is not parsable and might be experimental or toy programs based on the number of revisions in the history.
we only kept projects with at least revisions.
we downloaded the last snapshots of each project.
we eliminated from the snapshot of a project the duplicated code from different branches.
for each project we used eclipse s java parser to parse the code and built the asts andtable v accuracy with different numbers of closest nodes top .
.
.
.
.
.
.
.
.
.
top .
.
.
.
.
.
.
.
.
.
top .
.
.
.
.
.
.
.
.
.
time ms .
.
.
.
.
.
.
.
.
.
the usage graphs groums for all methods.
in experiments for apis we focus only on java development kit jdk .
we built databases for groums and asts section v c .
in total we built almost 800m graphs involving jdk apis with 55m distinctive ones and .
billion asts both jdk non jdk .
a. api recommendation accuracy our first study aims to evaluate gralan s accuracy in api suggestion.
we chose a project in sf named spring framework that does not belong to the above corpus.
it has a long history and methods.
we kept methods using jdk apis.
procedure and setting.
for each body of those methods m we conducted the following.
we collected into a list all the api elements and the control units in m i.e.
if for while etc.
and sorted them in the appearance order for sequential suggestion.
let us call both of them apis for short.
we traverse that list sequentially from the second api to the last one we did not start from the first since we want to have previous code as the context .
at a position i we use gralan to compute the top k most likely apis a1 a2 akfor that position based on the code prior to and not including it.
we predicted only for jdk apis because our database table iv is built for jdk only.
to do that since the previous code might be incomplete we first used ppa tool to perform partial parsing and semantic analysis for the code from the starting of the method to the current position in order to build the ast and then the groum g. the unresolved nodes in the ast if any are considered as single node graphs.
next we chose previous apis including jdk and non jdk apis closest to the position i. from those apis we find in graph gthe context subgraphs g1 g2 gp that contain one or more of those apis.
then we used gralan to suggest the top ranked apis.
if the actual api at position i is amongksuggested apis we count this as a hit.
the top k suggestion accuracy is the ratio of the total hits over the total number of suggestions.
in total for all methods gralan made suggestions.
we also measured suggestion time in ms. accuracy sensitivity analysis impact of parameters let us explain our experiments to study the impact of three parameters on gralan s api suggestion accuracy.
our first experiment was to study the impact of the number of apis closest to the position under question on accuracy.
table v shows accuracy with different values of for this study the maximum size of groums in the context is set to .
as seen when is increased accuracy also increases.
thus more related apis should be added to the context.
however when is or higher accuracy does not change much.
our next experiment aims to study the impact of the maximum size of the context graphs gon accuracy.
this is atable vi accuracy with different maximum context graphs sizes top .
.
.
.
.
.
.
.
.
top .
.
.
.
.
.
.
.
.
top .
.
.
.
.
.
.
.
.
time ms .
.
.
.
.
.
.
.
.
table vii accuracy with different datasets datasets top1 top2 top3 top4 top5 top6 top7 top8 top9 top10 s100 .
.
.
.
.
.
.
.
.
.
s300 .
.
.
.
.
.
.
.
.
.
s1000 .
.
.
.
.
.
.
.
.
.
second threshold used to limit the number of context graphs section iv .b .
we set for this study.
as seen in table vi when the size limit of graphs increases to i.e.
more context graphs being used accuracy also reaches higher values.
we also want to analyze the impact of the size of the training dataset on accuracy.
for this study we set and based on the two previous experiments.
first we randomly chose projects in our original dataset of projects.
then among those projects we randomly selected projects.
we built databases for datasets and ran gralan for each case.
as seen in table vii accuracy increases when more data is used for model training.
thus the larger the training dataset the more likely the correct api usages are observed thus the less noise impacts the suggestion quality.
as seen in the last row table vii gralan achieves high accuracy.
with a single suggestion in one out of three cases it can correctly suggest the api element.
in one of two cases the correct api element is from two suggestions.
in out cases the correct api element is within the top suggested apis.
moreover as seen in tables v and vi when and are increased suggestion time increases more context graphs are used .
however it is acceptable for interactive use in ides.
accuracy comparison our next experiment aims to compare gralan to two state of the art approaches for api suggestions the set based andn gram based approaches which were used in the existing work by bruch et al.
and raychev et al.
respectively.
we used the dataset in table iv to build two databases for the sets of apis and for the ngrams of apis.
for comparison we also used as the limit for the number of previous apis in a n gram and the limit for that in a set.
we have our own implementations of api suggestion engines using the set based and n gram based approaches.
we chose projects that do not belong to the training data.
we processed each of their methods in the same manner except the following.
at the position i we did not build groum.
we took at most prior apis in the code prior to ithat have data and control flow dependencies.
for the set based approach we built all subsets of those apis.
for the n gram approach we builtn grams from those apis for the sizes from .
we used the subsets and the n grams as the respective inputs for the two suggestion engines to compute the appearing probabilities of apis and rank the candidates.
top kaccuracy is measured.table viii api s uggestion accuracy comparison system model top1 top2 top3 top4 top5 top6 top7 top8 top9 top10 spring gralan .
.
.
.
.
.
.
.
.
.
set .
.
.
.
.
.
.
.
.
.
n gram .
.
.
.
.
.
.
.
.
.
ant gralan .
.
.
.
.
.
.
.
.
.
set .
.
.
.
.
.
.
.
.
.
n gram .
.
.
.
.
.
.
.
.
.
lucene gralan .
.
.
.
.
.
.
.
.
.
set .
.
.
.
.
.
.
.
.
.
n gram .
.
.
.
.
.
.
.
.
.
log4j gralan .
.
.
.
.
.
.
.
.
.
set .
.
.
.
.
.
.
.
.
.
n gram .
.
.
.
.
.
.
.
.
.
xerces gralan .
.
.
.
.
.
.
.
.
.
set .
.
.
.
.
.
.
.
.
.
n gram .
.
.
.
.
.
.
.
.
.
table viii shows accuracy comparison for each project with the total suggestions in parentheses.
as seen at top accuracy gralan achieves better accuracy than the set based and ngram approaches from .
.
.
at top accuracy it improves over the set based approach from .
.
and over then gram approach from .
.
.
the improvements at top accuracy are .
.
and31.
.
respectively.
we investigated the reasons for such accuracy among the approaches.
via observing the results we found that the n gram model tends to collect apis including project specific ones noises due to the strict order of n grams.
thus its suggestion accuracy is affected more by noises.
for example let a filereader.new b filereader.hasnext c book.check filereader d filereader.next .
assume that we currently have a b and c and want to suggest d. n gram would use the sequences a!b!c b!c or c. however they do not commonly occur in the database since c is project specific thus d might not be ranked high enough.
in contrast both gralan and set based approach do not require strict order among apis.
they can have the contexts relevant in suggesting d. for example the set based engine and gralan could use the subset a b and the subgraph a !b respectively for the suggestion of d. we observed many cases where gralan performs better than the set based approach.
that approach tends to include many irrelevant subsets of apis as the context since it does not keep the partial order among apis and control units as in gralan.
b. ast recommendation accuracy accuracy sensitivity analysis this section presents our experiments to evaluate astlan s accuracy.
for each body of the methods mof the projects in our dataset we built the ast formand traversed it from the top.
initially we started from the first valid subtree in the ast e.g.
a statement .
we set the current location lin the code corresponding to the right most leaf node of that subtree.
we then collected the context trees for l section v .d .
we keep only the context trees that have the code tokens of their leaf nodes appearing prior tol.
next we used astlan to suggest the top kvalid syntactic templates.
let us call a suggested tree t0.
then we compare t0against the actual next valid ast after we normalized it.
if they matches we count it as a hit.
otherwise table ix accuracy with different maximum heights of context trees top .
.
.
.
top .
.
.
.
top .
.
.
.
time ms .
.
.
.
table x accuracy ofastl an with different datasets datasets top1 top2 top3 top4 top5 top6 top7 top8 top9 top10 s100 .
.
.
.
.
.
.
.
.
.
s300 .
.
.
.
.
.
.
.
.
.
s1000 .
.
.
.
.
.
.
.
.
.
it is a miss.
the process is repeated to the end of the method.
top kaccuracy is measured in the same way.
our first experiment with astlan is to study the impact of the parameter the maximum height of context trees on suggestion accuracy.
we varied different values for up to and measured accuracy.
as seen in table ix when is increased accuracy increases due to more context trees.
second we built different databases for the datasets with and projects and ran astlan to suggest for spring framework .
we set .
as seen in table x the same behavior as in gralan was observed.
more training data more chances that astlan observes various syntactic templates.
as seen in the last row table x astlan achieves good accuracy.
with a single suggestion in of the cases it can suggest the next correct syntactic template.
in of the cases it correctly suggests with five candidates.
note that the n gram model is sequence based and cannot always guarantee to suggest a syntactically correct code template.
thus we did not compare astlan with n gram model.
common syntactic template mining we also used the database of astlan to mine the frequently used syntactic templates.
we are interested in mining templates involving if for while do and switch .
for each syntactic type we collected the top most frequently used valid syntactic templates with the heights from .
we manually verified templates to see if they truly correspond to common editing ones.
we found correct ones.
in addition we mined common templates with additional abstractions for the condition expressions in the above syntactic units and the init update and expr infor.
all results are listed in our website .
here is two examples for init expr update f if expr f return expr g gwhile !var1 shell.isdisposed f if !var2 display.readanddispatch f var2 display.sleep g g the left template a loop with checking and return is a popular template that is ranked 3rdamong all templates with for.
the right one is a template in swt library for initializing a display.
c. graph and tree databases and suggestion time we also studied our databases built for our models and the suggestion time.
tables xi and xii show the statistics on the graphs and asts.
as seen the number of distinctive graphstable xi statistics on graph database train distinctive nodes edges sug.time training storage set graphs min avg mean max min avg mean max ms time gb s100 .
.
.
hrs .
s300 .
.
.
.
hrs .
s1000 .
.
.
hrs .
table xii statistics on tree database train distinctive nodes edges sug.time training storage set trees min avg mean max min avg mean max ms time gb s100 .
.
.
hrs .
s300 .
.
.
.
hrs .
s1000 .
.
.
hrs .
is high.
the average mean number of edges of graphs is small since most graphs are sparse.
moreover searching isomorphic graphs over such sparse graphs is time efficient.
the average time for suggestion in ms is acceptable for interactive use.
for sparse graphs we have applied highly efficient algorithms for storing searching thus suggestion time is fast.
however we limit astlan s suggestion to syntactic templates with the height of since the number of all syntactically correct asts in a corpus with the height of or less can be trillions.
similar issues would occur for other graphs such as cfgs pdgs.
we will explore algorithms from vldb for handling ultralarge numbers of trees graphs and for graph matching .
currently with more data suggestion time and storage size increase reasonably.
in practice one can load different databases for different libraries as needed for api suggestion.
threats to validity.
the subject projects might not be representative.
for comparison we ran all approaches on the same dataset.
we do not use the state of the art tools since they are not available.
however our implementations follow their ideas of using sets and n grams of apis for suggestion.
in the n gram engine we used multi object n grams instead of perobjectn grams as in raychev et al.
.
we built the database only for jdk.
for other libraries the results might be different.
limitations.
the first issue of gralan is with ultra large numbers of trees graphs.
second our result is affected by the quality of client code.
third gralan is limited by static analysis for type binding of the tools it uses.
fourth we currently do not apply any heuristics in selecting children graphs.
we consider them all leading to too many candidates.
finally it cannot suggest for an api that did not occur at all in the training data.
however to suggest a node from a graph h it does not need to see entire hbefore.
it still can work if it has seen subgraph s gjofhsince it will include gjin the context.
other potential applications.
to use gralan on cfgs or pdgs one could expect to detect common control flows or dependencies.
one could use the common graphs in cfgs pdgs to improve language constructs or ide services one could use gralan to predict synthesize code or api usage examples one could rate the quality of an api example based on the likelihood of its graph one could detect subgraphs in cfgs pdgs that least likely occur as potential code smells.vii.
r elated work thestatisticaln gram language model has been used in capturing patterns in source code .
hindle et al.
usen gram model on lexical tokens to suggest the next token.
in slamc we enhanced n gram by associating code tokens with roles data types and topics.
tu et al.
improve n gram with caching for recently seen tokens to improve next token suggestion accuracy.
raychev et al.
capture common sequences of api calls with per object n grams to predict next call.
we do not compare gralan to slamc tuet al.
and other code completion methods because gralan works at the api level rather than the lexical level.
allamanis and sutton present a token based probabilistic language model for source code.
hidden markov model is used to learn from a corpus to expand abbreviations .
deterministic pattern detection.
many approaches use such data structures as pairs sets trees and graphs to model various abstractions in code.
deterministic pattern mining methods are used e.g.
mining frequent pairs subsequences item sets subgraphs associate rules .
code completion based on mined patterns.
bruch et al.
s best matching neighbor approach uses as features the setof api calls of the current variable vand the names of the methods using v. the set features in the current code is matched against those in the codebase for api suggestion.
freqccs suggests the most frequent call and arccs mines associate rules on api calls.
grapacc mines patterns as graphs and matches them against the current code.
in comparison grapacc uses deterministic subgraph pattern mining.
statistic based gralan considers all subgraphs thus requires higher computation storage.
while trying to complete a largest pattern as possible grapacc cannot suggest smaller subpattern.
gralan potentially can by using its subgraphs as explained.
there exist deterministic approaches to improve code completion suggestion and code search by using recent editing history cloned code developers editing history api usages examples and documentation structural context parameter filling interactive code generation specifications on constraints between input and output etc.
viii.
c onclusion we present gralan a graph based statistical language model that learns from a source code corpus and computes the appearance probabilities of usage graphs given the observed sub graphs.
we use gralan to develop an api suggestion engine and an ast based language model astlan to support the suggestion of the next valid syntactic template.
our empirical evaluation on a large corpus showed that our engine is more accurate in api suggestion than existing approaches.
astlan also has high accuracy in suggesting common templates.
acknowledgment this project is funded in part by us national science foundation grants ccf cns ccf ccf and ccf .