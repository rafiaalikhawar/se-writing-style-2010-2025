shadow of a doubt testing for divergences between software versions hristina palikareva tomasz kuchta cristian cadar department of computing imperial college london uk h.palikareva t.kuchta c.cadar imperial.ac.uk abstract while developers are aware of the importance of comprehensively testing patches the large e ort involved in coming up with relevant test cases means that such testing rarely happens in practice.
furthermore even when test cases are written to cover the patch they often exercise the same behaviour in the old and the new version of the code.
in this paper we present a symbolic execution based technique that is designed to generate test inputs that cover the new program behaviours introduced by a patch.
the technique works by executing both the old and the new version in the same symbolic execution instance with the old version shadowing the new one.
during this combined shadow execution whenever a branch point is reached where the old and the new version diverge we generate a test case exercising the divergence and comprehensively test the new behaviours of the new version.
we evaluate our technique on the coreutils patches from thecorebench suite of regression bugs and show that it is able to generate test inputs that exercise newly added behaviours and expose some of the regression bugs.
ccs concepts software and its engineering !software testing and debugging keywords symbolic patch testing regression bugs cross version checks .
introduction the malleability of software is both a blessing and a curse.
on the one hand one can easily change software to x incorrect behaviour or add new functionality.
on the other hand software changes are often responsible for introducing the rst two authors contributed equally to this paper.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa copyright held by the owner author s .
publication rights licensed to acm.
isbn .
.
.
.
and security vulnerabilities making users think twice about whether or not to update to the latest version.
ideally software changes typically referred to as patches should be comprehensively tested.
at the very minimum each line of code a ected by the patch should be covered by at least one test case.
while this level of testing is still far from being achieved in practice automatic techniques for enabling high coverage patch testing are becoming more and more successful .
many of these techniques are based on dynamic symbolic execution a program analysis technique that provides the ability to generate inputs that form high coverage test suites.
however achieving full statement or even full branch coverage for the patch code is clearly insu cient.
in fact one can achieve full statement and branch coverage without testingat all the new behaviour introduced by the patch!
to give a simple example consider a patch that only changes the statement if x toif x with this statement executed only once by a deterministic program.
suppose that the developer adds two test cases x and x to test the patch.
a super cial reasoning might conclude that the change is comprehensively tested as we have inputs covering each side of the branch.
however the execution of these inputs is completely una ected by the patch as the program will behave identically for these inputs before and after the patch is applied.
careful analysis shows that the program behaviour is changed only when x is between and inclusive causing the two versions to take di erent sides of the branch so one of these values should be used to test the patch.
in this paper we present a technique based on dynamic symbolic execution that can generate test inputs that cover the new program behaviours introduced by a patch.
the technique works by executing both the old unpatched version and new patched version in the same symbolic execution instance with the old version shadowing the new one.
this form of analysis which we refer to as shadow symbolic execution makes it possible to precisely determine when the two versions exhibit divergent behaviour and keep execution time and memory consumption low.
both of these features are key for e ective testing of software patches and are di cult to achieve without running both versions in the same symbolic execution instance.
the main contributions of this paper are shadow symbolic execution a technique for generating inputs that trigger new behaviours introduced by a patch.
the technique e ectively prunes a large number of irrelevant execution paths and reduces the program search space.
ieee acm 38th ieee international conference on software engineering 1char arr 3int foo int x 4int y x 5if y int z x if z arr a return return figure a toy example illustrating symbolic execution.
a way to unify the two program versions and represent them as a single annotated program equivalent to executing both versions in lockstep which lets us run the analysis in a single symbolic execution instance.
the uni ed program could be useful in other dynamic analysis techniques.
a tool called shadow that implements shadow symbolic execution and the experience of applying it to the coreutils patches in corebench a collection of highlycomplex real world patches.
the rest of the paper is organised as follows.
we introduce shadow symbolic execution in x2 and then present it in detail inx3.
we then give a brief overview of our prototype tool shadow inx4 and describe our experience applying it to test a suite of complex patches in x5.
we nally discuss related work inx6 and conclude in x7.
.
overview in our approach we assume that we already have a test input that touches the patch i.e.
executes at least one patch statement if such an input does not exist in the program s test suite it could be generated using previous techniques such as katch .
given such an input our technique is designed to automatically generate new inputs that exercise the new behaviours added by the patch.
these inputs can then be analysed by developers to either uncover bugs if the new behaviour is unexpected or create test cases that witness and validate the new behaviour if it is expected .
our technique is based on dynamic symbolic execution a popular program analysis technique that runs the program on symbolic rather than concrete inputs with classes of program paths with the same branching behaviour being encoded as sets of constraints over those symbolic inputs.
at any point on a path the symbolic state maintains the current program location a symbolic store mapping program variables to expressions computed over the symbolic input re ecting dynamic runtime information for the nonsymbolic inputs and a path condition pc characterising the inputs that exercise the path.
the pc takes the form of a conjunction of constraints obtained from the symbolic branch conditions encountered along the path.
as an example consider the toy program in figure and assume that we want to run function fooon symbolic input x. when symbolic execution starts the symbolic store is fx!xg meaning that variable xmaps to symbolic input x and the pc is true.
after line is executed the symbolic store becomesfx!x y!x 1g.
when execution reaches branch y we discover that under the current pc bothif old dothen else doelse !if new dothen else doelse if old new new new do else diffdo else samedo then diffdo then sameold old old old figure four way forking in shadow symbolic execution to capture divergent executions the ones shaded in grey .
sides of the branch are feasible so we fork execution following each path separately.
on the then branch we add to the pc the constraint x while on the else branch its negation x .
the latter path immediately terminates by executing return but the former continues by executing the assignment z x which adds the mapping z!x to the symbolic store.
then when execution reaches branch z we discover that under the current pc both branches are feasible and we fork execution again adding the constraint x on the then side and the constraint x on the else side.
the latter path terminates immediately by executing return while the former executes arr a .
prior to this array indexing instruction symbolic execution inserts an implicit check asking if the array index is guaranteed to be in bounds.
on this path the pc is x x which can be used to establish that z!x cannot be out of bounds.
in shadow symbolic execution our goal is to generate inputs that trigger the new behaviours introduced by a patch.
while various de nitions of behaviour are possible especially if higher level semantic information about the program is available in this paper we use a generally applicable definition of behaviour at the code level the behaviour of the program on a certain input is represented by the sequence of edges in the controlow graph of the program traversed during execution.
we say that two versions diverge on an input if their code level behaviours are di erent for that input.
note that a code level divergence may or may not result in an observable output di erence .
to nd inputs exposing di erent behaviour across versions we start by executing both the old and the new version of the program on an input that exercises the patch and gather constraints on the side as in the dynamic symbolic execution variant called concolic execution .
until the patch is reached assuming deterministic code both the symbolic stores and the path conditions are identical for the two versions by de nition since they have yet to execute a different instruction .
however once the patch is reached the two versions might update their symbolic stores and path conditions di erently.
in our approach we let each version update its symbolic store as required sharing the two stores e ciently seex3.
.
11821char arr 3int foo int x 4int y change x x y x y x 5if y int z x if z arr a return return figure a toy example showing a simple patch that modi es an ifstatement.
when a branch condition is reached we evaluate it under the symbolic stores of each version and we explore the entire branch cross product.
figure illustrates the general case where we reach a branch condition that evaluates to semantically di erent expressions in the two versions say oldin the old version and new in the new version.
instead of forking execution into two paths if possible based on the execution of the new version one adding the condition new and the other new we fork into up to four ways.
on two of these cases the two versions behave identically denoted bysame in the gure both versions take either the then new old or the else new old branch.
on the other two the executions of the two versions diverge denoted by di in the gure either the new version takes the then branch and the old version the else branch new old or the new version takes the else branch and the old version thethen branch new old .
there are two scenarios of interest whenever the initial input reaches such a branch concrete executions diverge.
that is the input makes the two program versions follow di erent sides at this branch.
this means that developers have already done a good job exploring at least part of the new behaviour introduced by the patch.
however this one input might not be su cient to explore all the new behaviours for example the new version might go on and execute a lot of new code introduced by the patch.
to better test the patch at this point we enable a bounded symbolic execution run on the new version i.e.
we start symbolic execution in a breadthrst search mode for a xed time budget.
this also lets us generate other divergent inputs exhibiting the same branching behaviour up to that point but di erent afterwards .
concrete executions are identical but divergences are possible.
that is the input makes the two programs take the same side of the branch but at least one of the di paths in figure is feasible.
in this case we also explore those paths.
for each feasible di path we rst generate an input that exercises the divergent behaviour and then continue bounded symbolic execution in the new version in order to systematically and comprehensively explore additional divergent behaviours.
as long as the concrete executions do not diverge we continue running both versions until the end of the program exploring any additional possible divergences along the way.
toy example.
as an illustrative example consider again the code in figure and assume that the developers have written a patch that changes y x toy x .we repeat for convenience the code in figure where the changed code is marked using the annotation change .
furthermore suppose that the developers have written three test cases to exercise the patch x x andx .
these tests achieve full branch coverage in both versions but fail to exercise the new behaviour introduced by the patch and miss a bu er under ow bug introduced for x .
shadow symbolic execution provides a systematic way of testing the new behaviours introduced by a patch.
its effectiveness and performance depend on the starting input that touches the patch but in our example it can nd the bug starting from any of the three inputs with similar amount of e ort.
we illustrate how it works starting from input x .
when function foo is entered both symbolic stores are fx!xgand the pc is true.
after the patched code on line is executed the symbolic stores becomefx!x y!x 1gin the old version and fx!x y!x 1g in the new version.
as a result when line is reached the condition y evaluates to x in the old version and to x in the new version.
at this four way fork our input x follows one of the same cases illustrated in figure .
however both di cases are also feasible at this point so shadow symbolic execution rst generates an input that triggers the divergent behaviour in each case and then starts from that point a bounded symbolic execution run on the new version.
one di case when at line the old version takes the else side while the new version takes the then side generates the condition x x .
at this point the constraint solver may return x which exposes the bu er under ow bug but it could also return x which does not.
in both cases we start bounded symbolic execution on the new version which nds the bug thanks to the implicit index in bounds check injected by the symbolic execution engine before each array access.
note that the bounded symbolic execution phase is started only on the divergent path in our case when the new version takes the then side on line and with the path condition that triggers the divergence in this case x x .
this signi cantly constrains the search space making symbolic execution explore only paths that expose new behaviours introduced by the patch .
while not relevant for our bu er under ow bug note that the patch also introduces a divergence which causes the old version to take the then side and the new version theelse side at line resulting in a divergence condition x x .
this divergence is less obvious because it only occurs when there is an arithmetic under ow on line .
for example when xis ybecomes in the old version 1and in the new version causing the unexpected divergence.
the subtle point is that x does not imply x for xedwidth machine arithmetic which illustrates the di culty of manually reasoning about the new behaviours introduced by software patches and the need for automatic techniques to help in the process.
.
shadow symbolic execution figure presents an overview of the process of testing software patches with shadow symbolic execution.
the inputs to our technique are i the old and the new version of the 1ingcc .
.
signed over ow is unde ned in c. 1183figure a high level overview of shadow symbolic execution.
program under test alternatively the old version and the patch and ii the program s test suite.
the output is a set of inputs that expose divergent behaviour between versions triggering either regression bugs or expected divergences.
we further divide these divergent behaviours into four subcategories.
first divergences that lead to generic errors e.g.
memory errors only in the new version are clear regression bugs that should be xed.
second divergences that lead to generic errors only in the old version are expected divergences that witness the x of that error.
third divergences that propagate to the output are of interest to developers because they can be used to quickly assess whether they are intended changes or regression errors.
finally divergences that do not lead to any noticeable di erences could still be of interest to developers who could add the corresponding inputs to the application s test suite.
in the rst step of our approach we annotate the patches as illustrated in figure in order to unify the old and the new version into a single program that incorporates them both x3.
.
next we select from the test suite those test cases that touch the patch.
we then perform shadow symbolic execution and generate inputs that expose divergent behaviour x .
.
finally we run both versions natively on all divergent inputs using enhanced cross version checks and identify those that trigger errors or output di erences x3.
.
.
unifying versions via patch annotations our approach to executing both the old and the new version of the program in the same symbolic execution instance is to enforce them to proceed in lockstep until they diverge in control ow.
this is done by creating a single uni ed program in which the two versions are merged via change annotations as we have shown on line in figure .
mapping program elements across versions is a di cult task as in the extreme the two versions could be arbitrarily different programs.
however in practice the process can be made su ciently precise and furthermore automated using various heuristics as shown by recent work .
we currently add these annotations manually following the annotation patterns discussed below however we believe many patterns could be applied automatically although we leave this for future work.
our annotations use the macro change which resembles a function call with two arguments the rst argument represents the code expression from the old version and the second argument the corresponding expression from the new version.
one key property is the ability to run the old version by replacing change with its rst argument and the new version by replacing it with its second argument.
writing these annotations was easier than we initially expected we started by targeting very small patches 2lines of code but ended up annotating large patches of up to several hundred lines of code.
below we discuss the main annotation patterns that we follow in the order in which we typically apply them.
.modifying an rvalue expression.
when an expression e1 is changed to e2 the annotation is simply change e1 e2 .
as a general principle we always push the change annotations as deep inside the expression as possible.
this strategy optimises the sharing between the symbolic stores of the two versions and it also allows for various optimisations such as constant folding to be performed by the symbolic execution engine.
examples include a changing the right hand side of an assignment x y change e1 e2 b changing an argument in a function call f ... change e1 e2 len s ... c changing a conditional expression if change e1 e2 ... code ... in the patches we examined we observed that developers often change the control ow in the program by strengthening or weakening existing conditional expressions i.e.
by adding or removing boolean clauses.
for instance d weakening a condition from a to a jjb if a change false b ... code ... e strengthening a condition from a to a b if a change true b ... code ... we choose a di erent style of annotations for strengthening of a condition from a jjb to b and for weakening a condition from a b to b f strengthening a condition from a jjb to b if change a b b ... code ... g weakening a condition from a b to b if change a b b ... code ... the reason for using this di erent style is to avoid the introduction of spurious divergences.
for example if we annotated a strengthening of a condition from a jjb to b as if change a false b then if a is true and b is also true a divergence would be reported even though the two versions would take the same then side of the branch.
while this annotation might be preferable when a stronger coverage criterion such as mc dc is desired in our experiments we prioritise divergences that propagate to the output.
11841x change a b 2y x 3z y ... 5if z ... code ... figure a change in an assignment propagating through the rest of the code.
.adding removing extra assignments or conditionals.
essentially we view all changes of this type as modi cations of existing constructs by adding dummy statements at appropriate points in the program .
e.g.
a adding an extra assignment x e x change x e b removing an assignment x e x change e x c adding code conditional on an expression.
that is if the code added in the new version has the form if c ... code ... the annotation is if change false c ... code ... d removing code conditional on c if change c false ... code ... .adding removing straightline code fragments.
in general we rst try to annotate any code modi cations using rules and .
however if the changed code has side e ects e.g.
it writes to a le or the previous rules are too di cult to apply we use the following rules a removing straightline code if change true false ... code ... b adding straightline code if change false true ... code ... we note that this is the most conservative way of annotating a change in our framework the execution of a branch instruction conditional on a change true false expression immediately triggers the generation of a divergent test input terminates shadow execution and proceeds by running the new version only losing the ability to use the old version as an oracle.
.adding removing variable declarations.
if a variable declaration is added or removed we keep it in the merged program no annotations are necessary.
uses of that variable are treated using rules to above.
.modifying variable declarations.
when the type of a variable is changed to include more or fewer values we keep the larger type.
due to arithmetic over ow issues we reason manually whether this is safe to do however in our benchmarks type changes were a rare occurrence and quite straightforward e.g.
changing char buf tochar buf or changing a bool to an enum.
sha dow a b12z y x figure a shared expression tree for the expressions corresponding to the variables x yandzin figure .
expressions containing shadow subexpressions are kept in the symbolic store and lazily evaluated at symbolic branch points e.g.
in theifcondition on line in order to extract the new and old counterparts.
.
symbolic execution phase for each input that touches the patch shadow symbolic execution operates in two phases .concolic phase.
we start by executing the uni ed program on that input and gather constraints on the side as in concolic execution .
as the program executes a if at a branch point the input exposes a divergence we stop shadow execution and add this divergence point to a queue to be processed in phase .
b if at a branch point the input follows the same path in both versions but divergences are also possible we generate a test case exposing each possible divergence and then add these divergence points to the queue to be processed in phase .
we then continue the concolic execution of the uni ed program.
.bounded symbolic execution bse phase.
for each divergence point placed in the queue we initiate a bse run in the new version starting from that divergence point to search for additional divergent behaviours.
the concolic phase is computationally cheaper nevertheless the bse phase is essential as it is able to propagate the divergent behaviour down the execution tree and explore systematically the impact of the divergence.
e ciently sharing state using shadow expressions.
as in other instances when di erent software variants or versions are run together shadow symbolic execution can substantially increase memory consumption.
as a result it is important to maximise sharing between the symbolic state of the two versions.
since the patch typically a ects a relatively small number of symbolic expressions everything else can be shared.
furthermore it is possible to share those parts of symbolic expressions that are identical between versions.
to enable sharing whenever we encounter a change annotation instead of constructing and maintaining separate symbolic expressions for the old and the new version we create a shadow expression .
a shadow expression contains two subexpressions one corresponding to the old version and one to the new.
shadow expressions can be used as any other expressions without the need to duplicate for each version entire expression trees that contain modi ed subexpression 1185nodes.
to illustrate consider the example in figure in which the code is changed to assign into xvalue binstead ofa.
furthermore assume that after this change xis used multiple times in the program directly or indirectly e.g.
to derive variables yand zon lines and .
without sharing both yand zwould have to point to di erent symbolic expressions in the two versions.
however the use of shadow expressions uni es the expressions for the two versions and maximises sharing.
in our example as illustrated in figure xwill point to a shadow expression with children a and b. then when yis created its left child is assigned to this shadow expression but node yitself remains the same in both the old and the new versions.
similarly when zis created its children become simply yand .
this scheme has the advantage that sharing is maximised propagation of changes is implicit and the creation of expressions can still be performed in constant time.
in addition the dynamic nature of symbolic execution provides opportunities for identifying refactorings on a perpath basis at run time which allows for further optimisations.
in particular if the two candidate children eoldand enewof a shadow expression are equivalent under the current pc then the syntactic changes do not introduce semantic di erences and we skip the creation of a shadow expression.
.
enhanced cross version checks in order to determine whether an input that exposes a code level divergence results in an externally observable regression bug or expected behavioural change we use a series of enhanced cross version checks.
these checks run the two versions natively on each input which exposes a divergence and compare their outputs including exit codes.
they also check for generic errors in particular crashes and memory errors that do not trigger a crash the latter detectable by compiling the code with address sanitization .
if the outputs of the two versions di er it is up to developers to decide whether the di erence is expected or a regression bug.
even though in our evaluation we determined this automatically because we also knew the patches that xed the introduced bugs we validated the classi cation manually and often found making this judgement easy to do by reading the commit message describing the intention of each patch.
we also had cases in which it was not immediately obvious whether the change in behaviour was expected these are exactly the kind of inputs that developers should pay attention to as they could point to bugs or lack of proper documentation.
we apply these checks both on the inputs in the regression test suite and on those generated by our technique.
.
implementation we implemented our approach in a tool called shadow which is built on top of the klee symbolic execution engine and uses the concolic execution functionality from the zesti extension .
our code is based on klee revision 02fa9e4d llvm .
and stp revision .
to select the test cases in the regression suite that touch the patch we run the regression suite on the new version of the program compiled with coverage instrumentation gcov2 .
to run the concolic phase we replace the program under test with a wrapper script that passes the original invocation to shadow .
note that a test case may invoke a given program multiple times.
to test the nthinvocation the script runs the rst n invocations natively and forwards the nthtoshadow .
the concolic phase runs each test case touching the patch and generates a test input every time it nds a divergence.
the bse phase repeats the concolic phase for ease of implementation and stores all divergence points in a queue.
then shadow performs bounded symbolic execution starting at each divergence point in this queue in a breadth rst search manner.
we generate an input for each path explored during bse.
as these paths originate from divergent points by de nition all generated inputs expose divergences.
in the concolic phase a single invocation is allowed to run for a maximum of 600s.
the same budget is given for the bse phase which as discussed above also repeats the concolic phase for ease of implementation.
the actual symbolic exploration phase is given 570s divided equally among all the divergence points placed in the queue.
for each phase we set a global timeout of 3600s for running an entire test case potentially consisting of multiple invocations .
also for each phase we set a global timeout of 7200s for running all the test cases that touch the patch.
in order to rerun the generated inputs natively shadow provides a replay functionality that implements the enhanced checks described in x3.
.
this functionality also uses a wrapper script that calls the native versions of the application and substitutes the original parameters with the ones synthesised for the generated test cases.
shadow runs each test input twice once with the old version and once with the new one.
the outputs and exit codes are then compared in order to discover divergences that propagate to the program output.
for each phase the replay is bounded by a per invocation timeout of 5s a per test case timeout of 60s and a global timeout of 7200s.
due to some non determinism in our replay infrastructure we retry each replay experiment once if the rst attempt is unsuccessful.
.
ev aluation we evaluate shadow on the software patches from the gnu coreutils application suite3included in the corebench suite of regression bugs.4coreutils is a collection of utility programs for le text and shell manipulation.
it is a mature well maintained and widely used project included in virtually all linux distributions.
together the programs form a code base of over kloc.
the corebench patches represent a tough challenge for test input generation as the corebench authors discuss the complexity of these regression errors and associated xes is signi cantly higher than those in popular evaluation suites such as the sir and siemens benchmarks.
corebench provides pairs of fbug introducing bug xingg patches for coreutils.
however some patches introduce multiple bugs so we are left with unique bug introducing patches which are shown in table .
the rst column of this table shows the corebench id for the patch.
if the patch is responsible for multiple bugs we show all relevant ids e.g.
means that the bug introducing patch with id is 5measured with the cloc tool 1186table coreutils patches from corebench.
we report the patch size which takes into account source code only the number of test les that touch the patch and the number ofchange annotations that we used for each patch.
id tool patch size test files touchingannotationslo c hunks files mv rm od cut tail tail cut seq seq seq cp cut cut ls ls du seq cut expr the same as the one with id .
the loc hunks andfiles columns provide information about the size of each patch in terms of added modi ed lines of code loc hunks and les.
the number of loc is measured by the diff tool.
the hunks forming a patch are essentially the di erent areas of code a ected by a patch.
more formally a hunk groups together all the lines added or modi ed in a patch which are at a distance smaller than the context size.
we used the uni ed di format with a context size of zero when computing the hunks.
as can be seen the size of a patch varies between only loc and a single hunk and up to loc and hunks.
most patches change a single le with two exceptions where and respectively di erent les are a ected.
finally the column test files touching gives the number of test les in the regression test suite that touch the patch which are used as starting points by shadow .
due to technical problems related to running old revisions we could not run the test suites coming with patches and .
therefore we exclude those two patches from our evaluation although we do report the annotation e ort involved for these patches too.
.
annotations column annotations in table shows the number of change annotations that we added for each patch.
in general the number of annotations does not depend on the number of loc in the patch.
for example patch adds a call to a new function consisting of over loc which in turn calls other new code.
however while a lot of code has been added we need a single change annotation to enable it as discussed in x3.
.
instead the number of hunks can give a rough estimate of the number of required annotations.
nonetheless there are exceptions for example many hunks do not require any annotations.
e.g.
patch discussed earlier includes a variable renaming from nfiles ton files which results in many hunks that do not require any annotations.
hunks that only change comments are another example.
table provides a rough overview of the distribution of annotation patterns as classi ed in x3.
.
the classi cationtable distribution of annotation patterns across the corebench patches.
the last two columns refer to changes that require no explicit annotations despite taking some e ort to reason about.
variables that are added or removed in a scope accessible only to a single version e.g.
in a newlyadded function do not contribute toward column .
id modi ed extra straightline a dded removed modi ed rvalues assign cond code v ariables types x x x x x x x x x x x x x x t otal x x is approximate for example a transformation of a variable bool neg intoint sign can be interpreted as both a change of type and an addition and a removal of a variable.
in general there is often more than one way to annotate a patch.
furthermore our manual e ort is error prone although we are con dent that the annotations are correct.
we make our annotations publicly available 7hoping they will prove valuable in other di erential testing projects too.
.
experimental details environment.
we conducted our experiments on a server running ubuntu .
equipped with two intel r xeon r e5 v2 at .
ghz cpus cores and 192gib of ram.
the tests were usually run in parallel for all the tested revisions.
memory limit.
we use klee s default memory limit of mib per invocation which was never exceeded.
changes to code and test suites.
since some of the tested coreutils revisions are several years old they do not compile out of the box and we had to apply several patches provided by the corebench authors.
furthermore we had to make other minor modi cations for compatibility with klee and our infrastructure.
to consistently compare the program outputs across versions we also applied a series of changes to the coreutils test suite related to making tests run more deterministically.
one example is the creation of temporary les which by default have di erent names across runs.
.
overall results we conduct three sets of experiments corresponding to running the regression test suite the concolic phase ofshadow and the bse phase of shadow .
we run all three sets of experiments with our enhanced cross version checks ofx3.
.
note that for running the regression test suite with the enhanced checks we use the same uni ed programs employed by the concolic and bse phases of shadow .
we take a conservative approach and assume that all invocations 1187table experimental results for the coreutils patches in corebench showing the number of code level divergences detected the percentage of these replayed and the number of observed output di erences divided into expected changes and regression bugs.
the inputs created by shadow for patch marked with also expose an additional bug an abort which is di erent from the one detected by the regression suite wrong exit code .
idr egression suite concolic phase bse phase total d ivergences di erences divergences di erences divergences di erences divergences di erences t otal replayed expected bug total replayed expected bug total replayed expected bug total expected bug in the regression suite which execute the change annotations with arguments of di erent value are divergent.
note that this is an over approximation as the two versions might still have the same branching behaviour.
regarding run times for the di erent phases of shadow we observed median values of 020s for running the regression suite 962s for running the concolic phase and 213s for running the bse phase all including our enhanced checks.
note that these values are only meant to give a rough estimate of the time needed by shadow they are in uenced by the di erent numbers of test cases that touch the patch and also by the load on our machine which we have not tried to control.
table gives an overview of our experimental results.
for each phase we provide the number of test inputs exposing code level divergences divergences total and the percentage of those inputs that we manage to replay in the allotted time frame divergences replayed .
due to a small degree of non determinism in our replay infrastructure a few of these divergences might be duplicates.
the gures under total divergences total are an over approximation as they re ect our conservative approach of assuming that all invocations in the regression suite that touch change annotations with di erent value arguments are divergent.
table also presents how many of the divergent inputs that we replayed led to output di erences.
these di erences are further classi ed into expected di erences and bugs.
there are two types of bugs generic bugs such as memory errors and semantic bugs that lead to incorrect results.
for generic bugs if the old version does not trigger the error and the new one does then we report the input as exposing a regression error.
if it is the other way around we report it as exposing an expected di erence.
as discussed inx3.
by reading the commit message associated with the patch we can often reason manually whether an input that leads to di erent outputs across versions exposes a regression bug or an intended change in behaviour.
we expect this would be even easier for the authors of those patches.
however in our evaluation we make use of the fact that the corebench regression suite provides the revisions xing the introduced bugs.
more precisely we run the input on two additional versions the version just before the x and the version in which the x was applied.
if these two versions behave the same on this input or the xed version behaves the same as the new version we classify the change in behaviour as expected.
otherwise we classify it as a regression bug.
for patches introducing multiple bugs we run each x in turn.
this approach is automatic but is not guaranteed to correctly classify changes in behaviour due to non determinism and because the patch xing the bug may introduce other changes too.
hence we also perform a brief manual sanity check of the automatic classi cation.
.
successful examples table gives several examples of actual inputs generated byshadow .
for each input we show side by side the behaviours of the old and the new version.
for instance the rst example shows an expected di erence in tail while the second example shows a regression bug that triggers a bu er over ow in the new version of cut.
we discuss in more detail two patches in which we managed to nd the introduced regression bug and or the intended change in behaviour.
corebench patch .
this is a patch in cut a tool whose purpose is to delete portions of text ranges of bytes characters or elds from each line of a le.
to do so the user can specify both closed ranges e.g.
meaning all the bytes or characters or elds from the third to the fth byte from the beginning of the line as well as open ranges e.g.
5and to refer to all the bytes or characters or elds from the beginning of the line up to the fth byte and from the ninth byte until the end of the line respectively.
the aim of the patch is to prevent unnecessary memory allocation when only open ranges are speci ed.
the annotated patch is presented in figure .
we added three annotations one when an ifstatement is removed line one when an ifstatement is added line and one when an extra conjunct is added to the condition of an ifstatement line .
1188table sample inputs generated by shadow exposing regression bugs and expected di erences.
id generated inputbehaviourclassi cation old new 4tail retry s x01 x00g x00tail warning retry is useful mainly tail warning retry ignored retryexpectedwhen following by name.
.
.
is useful only when following.
.
.
cut c1 output d hfileiabc abc bu er over ow bug le contains abcdefg cut c1 output d hfileiabcdefg abcdefg bu er over ow bug le contains abcdefg cut b0 output d hfileiabc signal abort bug le contains abc cut s d f0 hfilei nn nnnn expected le contains nn cut d f1 hfileia b c a expected le contains a b c 1if change max range endpoint eol range start false max range endpoint eol range start ... 4if change true max range endpoint printable field xzalloc max range endpoint char bit ... 7if output delimiter specified !complement eol range start change true max range endpoint !is printable field eol range start mark range start eol range start figure corebench bug .
prior to the patch memory was allocated unconditionally line but the patch strengthened the condition guarding the allocation based on the value of max range endpoint which represents the maximum end value of an index in a closed range and is when the user speci es only open ranges.
the patch introduces a bu er over ow on line when both closed and open ranges are speci ed and the value of max range endpoint is greater than but smaller than the minimum start value of an index in an open range eol range start .
in such cases max range endpoint in the new version is not set to the value of eol range start line and on line the printable field array is allocated to size max range endpoint .
finally on line function is printable field accesses the printable field array at index eol range start which results in an index out of bounds error in the new version.
table shows a test input generated by shadow that exposes this bug.
the input was found in the bse phase.
corebench patch .
this patch intends to make cut emit an error message when invalid ranges such as 0are speci ed.
our annotated patch is given in figure .
we added six annotations three of them when an rvalue expression is changed lines and one which adds a new ifstatement line one which removes an ifstatement line and one which modi es an ifstatement line .
the test cases in the regression suite already detect expected output di erences exposing the same behaviour in which the new version prints out one of the two error messages on lines and .
however shadow generated fur set fields const char fieldstr ... initial change value lhs specified ?
value value change value true ?
value 6else if fieldstr isblank fieldstr fieldstr ... dash found false if change false !lhs specified !rhs specified fatal error invalid range with no endpoint ... if change value !rhs specified ... if value initial fatal error change invalid byte or field list invalid decreasing range ... else if change value !
true ... figure corebench bug .
ther inputs for which the output di erences do not involve error messages.
the last two rows of table show two such inputs.
using the bug xing revision we classi ed these changes as expected and we think the generated inputs are good candidates for being added to the regression suite.
shadow also found unexplored divergences just o the paths executed by the test suite which revealed an abort failure.
a sample such input generated by shadow during the concolic phase is b0 output d file.
in the bse phase shadow detected a bu er over ow bug similar to the one discussed in patch .
note that these are separate bugs from the one recorded in corebench.
.
unsuccessful executions for several patches shadow failed to synthesise inputs that trigger either expected divergences or bugs.
regarding expected divergences we note that several patches seem to be refactorings so it would be impossible to trigger an expected output di erence any di erence would be a bug .
in terms of the missed regression bugs as mentioned before the corebench patches are very challenging and signi cantly more complex than those typically considered by prior research studies see the corebench paper for details .
to get a feel for the challenges involved in analysing these patches consider the following bugs missed by shadow nding 1189bug requires reasoning about le access rights bug requires oating point support bug requires support for symbolic directories and the bug report for is not reproducible on our recent distribution of linux.
finally our relatively short timeout values may have prevented us from successfully detecting some of the bugs and expected divergences we chose these values to keep the turnaround time for running all experiments within a nightly run.
more generally some of these patches require a precise environmental model klee s model is incomplete e.g.
lacks the ability to handle symbolic directories and at least one requires support for symbolic oating point values which klee does not provide .
we also depend on the quality of the inputs in the test suites from which we start exploration.
our mechanism for detecting changes is also limited focusing solely on output di erences.
however some patches change non functional properties such as improving memory consumption in or performance in .
finally note that with one exception we always have inputs that expose divergences at the code level which could prove useful to developers to reason about their patches.
however in many cases the number of divergent inputs is simply too large and in future work we plan to investigate clustering and ranking techniques to help developers sift through these divergences.
.
reflections on regression testing process our experience with the corebench patches revealed several insights into the regression testing process.
first we believe that cross version checks could be easily incorporated into existing regression test suites.
we envision a process in which developers would examine divergent inputs and conrm whether the change in behaviour is expected or not.
such a lightweight process would have detected some of the complex regression bugs in corebench.
second generating inputs that trigger externally visible di erences is valuable both for the possibility of nding regression bugs as well as for documentation regarding the latter we found that such inputs are often the best explanation of the patch.
.
related work we introduced the high level idea behind shadow symbolic execution in a short idea paper but without any implementation or evaluation.
recent years have seen a lot of work on automatic techniques for testing software patches with many of these techniques based on symbolic execution .
however most research e orts have looked at the problem of generating test inputs that cover a patch.
by contrast input generation targeting behavioural changes introduced by a patch has received much less attention.
di erential symbolic execution is a general framework that can reason about program di erences but its reliance on summaries raises signi cant scalability issues.
directed incremental symbolic execution combines symbolic execution with static program slicing to determine the statements a ected by the patch.
while this can lead to signi cant savings static analysis of the program di erences is often imprecise and can miss important pruning and prioritisation opportunities particularly those which exploit dynamic value information.
partition based veri cation prv uses random testing and concolic execution to infer di erential partitions i.e.input partitions that propagate the same di erential state to the output.
prv separately runs both program versions using concolic execution and uses static and dynamic slicing to infer di erential partitions.
in contrast to prv by running the two versions in a synchronised fashion shadow symbolic execution does not need to re execute potentially expensive path pre xes and can provide opportunities to prune and prioritise paths early in the execution as well as to simplify constraints.
the techniques discussed above were evaluated on patches signi cantly less complex than the coreutils patches we considered.
however our technique is not fully automatic while most of the annotations that we added could be automated manual assistance might still be needed.
nevertheless research on automating this step is promising furthermore note that even an imprecise automatic annotation system might be enough to help our technique generate inputs exposing behavioural changes.
overall while shadow symbolic execution o ers new opportunities it is unlikely to subsume any of the techniques cited above.
testing evolving software is a di cult problem which is unlikely to be tamed by any single technique.
running the two program versions in the same symbolic execution instance is similar in spirit to running multiple versions in parallel which has been employed in several other contexts including online validation model checking product line testing and software updating .
research on test suite augmentation requirements has used the di erences between two program versions to derive requirements that test suites have to meet in order to ensure proper patch testing our analysis could potentially provide further information to guide these techniques.
.
conclusion in this paper we have presented shadow symbolic execution a novel technique for generating inputs that trigger the new behaviours introduced by software patches.
the key idea behind shadow symbolic execution is to run both versions in the same symbolic execution instance and systematically test any encountered code level divergences.
the technique uni es the two program versions via change annotations maximises sharing between the symbolic stores of the two versions and focuses exactly on those paths that trigger divergences.
we implemented this technique in a tool called shadow which we used to generate inputs exposing several bugs and intended changes in complex coreutils patches.
we make our experimental data available via the project webpage at .