predicting field reliability pete rotella cisco systems inc. kit creek road res.
triangle pk.
nc usa protella cisco.com sunita chulani cisco systems inc. w. tasman drive san jose ca usa schulani cisco.com devesh goyal cisco systems inc. w. tasman drive san jose ca usa devgoyal cisco.com abstract the objective of the work described is to accurately predict as early as possible in the software lifecycle how rel iably a new software release will behave in the field.
the initiative is based on a set of innovative mathematical models that have consistent ly shown a high correlation between key in process metrics and our primary customer experience metric swdpmh software defects per million hours per month .
we have focused on the three primary dimensions of testing incoming fixed and backlog bugs.
all of the key predictive metrics described here are empirically derived and in specific quantitative terms have not previously been documen ted in the software engineering quality literature.
a key part of this work is the empirical determination of the precision of the measurements of the primary predictive variables and the determination of the prediction outcome error.
these error values enable teams to accurately gauge bug finding and fixing progress week by week during the primary test period.
categories and subject descriptors i. .
model development modeling methodologies.
general terms algorithms measurement reliability experimentation theo ry.
keywords software release reliability prediction modeling testing error analysis customer experience.
.
introduction for several years software defects per million hours swdpmh has been the primary customer experience metric used at cisco.
this metri c is goaled for product teams on a yearly basis and this includes product families in .
swdpmh is considered to be a reasonable measure of customer pain since we count e ach time a bug is found by the customers.
the metric a key reason swdpmh is considered to be of critical importance is that we see a high correlation between swdpmh and software customer satisfaction sw csat as measured by our yearly customer survey over a wide range of products and featu re releases.
therefore it is important to anticipate swdpmh before the software is released to customers for several reasons early warning that a feature release is likely to experience substantial field quality problems may al low for remediation during or prior to function and system testing on the integration branch .
the integration branch is the software branch that results from the collapse of the development branches in the case of a waterfall project or the subsequent function and system testing on an agile development branch.
prediction of swdpmh enables better planning for rollout strategies and for maintenance releases.
if we anticipate that swdpmh will be too high d istribution of the release can be restricted until rebuilds can improve the reliability.
calculating the tradeoffs between swdpmh and feature volume c an provide guidance concerning acceptable feature content test effort release cycle timing and other key parameters affecting future feature releases.
our recent efforts have focused on enhancing our ability to predict swdpmh in the field.
toward this end we and many others have developed several predictive models have tested the models with major feature releases for strategic products and have provided guidance to developme nt test and release teams on how to improve the chances of achiev ing best inclass levels of swdpmh and sw csat .
.
modeling release quality predicting field swdpmh future experience is of paramount importance to the development test and technical support organizations.
if the predictions can be made early enough in the development test phases steps can be taken to improve the release steps such as adding testers pulling out n on essential features more time testing push out the re lease date etc.
.
model general characteristics our recent work has concentrated on models targeting the function and system test phases as typically con ducted in our environment for waterfall and hybrid waterfall agile development programs .
results for waterfall and hybrid waterfall agile are consistently good.
r esults for pure agile projects are encouraging but more testing is needed to check the mino r adaptations needed for a pure agile environment.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august september bergamo italy c acm.
... .
the initial experiments focusing on the effect of test practices and processes on swdpmh were done using three major software trains that are resident on product families and include major feature releases.
the dependent variables used were swdpmh at and months after release to the field.
swdpmh s numerator is the number of software incidents encountered in the field which is the number of times a field bug is seen by any customer.
for example one bug seen by customers would contribute a value of to the numerator of swdpmh.
these bug incidents are referred to here as bugsrs.
a total of independent variables were included in the initial modeling ex ercise these include basic un normalized variables and about normalized variables for each of the primary testing dimensions namely incoming disposal and backlog variables .
our aim was to find a highly predictive variable in each of these primary dimensions if possible since our organization normally measures many characteristics of these dimensions and therefore additional data collection would n ot be needed .
also incoming disposal backlog me trics are highly interrelated and likely to be more fully characteristic of the testing and disposal functions .
disposal means that the bug has reached a terminal state including resolution but also closed i.e.
a bug that is left unresolved junk ed duplicate and unreproducible bugs.
using jmp and excel we reduce d the size of the independ ent variable array and id entified predictive and useable models .
we found the most highly predictive variables are incoming variables followed by several disposal variables.
all the backlog variables produce high i.e.
.
p values and low levels of correlation i.e.
with the dependent variables.
table is a summary of t he best modeling results table linear regression best modeling results var.
coeff.
s x t p fadj.
r2 s y inter.
x1 .
.
.
x2 .
.
.
.
y .
.
.
.
independent variable x1 we call incoming defect level idl .
it is the percentage of total bug content as estimated using the asymptote of the goel okumoto shaped gos software cumulative incoming growth curve .
in other words idl is the actual percent of the total cumulative bug content of the release estimated as the asymptote of the gos s shaped curv e. independent variable x2 we call fix rate reduction frr .
it is the percentage decline in the weekly bug disposal rate from the maximum level .
dependent variable y is the swdpmh value for the platform release in question taken at months after rele ase to the field.
similar results are seen for swdpmh observed at months after release .
.
model results to date analyses have been done for platforms hosting feature releases and large maintenance releases.
these platforms include router switch ing and datacenter hardware products plus software only applications and tools such as security collaboration and network management .
correlations between the full model equation scal ar value and swdpmh have been consistently high.
for example the adjusted r2 for product a shown in the case study below is at the high end of the range seen with the products examined so far.
the average correlation seen is range of .
error analysis a key requirement for any model used in a development test environment is that the measurement and prediction errors be published and avai lable to the users.
u sers need to know if the target and actual idl and fr r curves are statistically distinct at each point in time during testing and fixing.
if the target idl curve is statistically higher than the actual curve for example the team will be asked to take action such as adding resources extending the testing timeline reducing feature content or taking another remediation step.
therefore the error d eterminations for these curves constitute s an important practical step.
the idl measurement error determination method is straightforward the idl measuremen t error is the standard error of the predictive variable idl for the fleet of releases.
in this analysis we use the group of releases and the method used is we calculate an empirically determined measurement error referred to here as residuals for decile clusters of idl from to .
these residuals are calculated using the delta between the observed intermediate idl values and the idl value for each release derived using the end point idl asymptote value and its weekly cumulative values .
only releases that achieved an idl level of or higher were used in this analysis since the standard error of the idl variable in the model equation is added to the residuals determined error and the standard error of the idl variable has only been determined above .
in other words we use the final week s idl to determine the most accurate asymptote then derive actuals for all previous weeks from that asymptote val ue.
the residuals are rank ordered and the forward looking idl calculation s week by week are then compared to the actuals and the delta between the two is calculated.
on each side of the actuals curve we find the point at which of the residuals are found and this point is the one standard deviation error bar point.
in excess of of the residual volume from the s curve is beyond one standard deviation therefore this distance constitutes the one standard deviation error bar for the measurement precision.
the error bars upper and lower are depicted in figure below for the residual and actual values for the releas es studied.
therefore the blue lines correspond to the confidence intervals for the releases studied.
the x axis shows one unit tick for each of the readings.
in addition to the err or determination derived from using the end points of the each of the goel okumoto shaped cumulative growth curves we need to add in the standard error .
of the idl variable derived from the general model equation since all the residual c omparisons assume no figure residua ls v. actuals for r eleases error in the final testing week measurement.
the average size of these releases is about thousand lines of new plus modified source code.
specific f indings of this exercise using the approach described we find that the residual based idl measurement error is .
within the primary region of interest idl for the releases studied to this we need to add .
for the model s standard idl error for a total of .
.
the residual based idl measurement error is .
within the idl region from idl for the releases studied so the total error is .
in this region.
the idl measurement error is .
in the idl region from idl for the releases studied so the total error is .
in this region.
below are several examples of t he product specific variants of the error bar calculations described above.
by product specific we mean that an individual regression graph is constructed for the sequence of his torical releases applicable to the specific product family and product specific error bars are constructed using the independent and dependent variable standard errors applicable to the releases used.
.
case study heat maps and regression graphs have been genera ted for the recent historical releases that are resident on the prod uct b platform.
the heat map in table shows idl frr swdpmh and ancillary metrics for releases that have been available to customers for about the past three years.
the idl frr column shows the scalar quantity derived from the combination of the tw o predictive independent variables weighted according to the coefficients of the variables in the general model equation developed with the product a and product d data.
the goal for this linear combination of idl and frr is the minimum value neede d to enable the successor release sequence to achieve best in class swdpmh levels within three years whichever type feature or large maintenance release we examine.
table idl frr swdpmh heat map product a figure shows the relationship between the swdpmh for the product a historical releases and the percent idl achieved at throttle pull i.e.
the time most testing is complete figure swdpmh idl regression g raph for product a historical r eleases the y axis error bar for this specific population is .
relative and the x axis error bar is .
absolute .
.
summary for all releases studied all case studies have yielded similar idl error analysis results results similar to those shown in the case study of product.
here is a summary a total of releases were studied with a total of n data points observed .
the y axis error bar is .
relative mean y axis value is .
and x axis value is .
product a idl frr need idl need frr need swdpmh fcs bugsrs rel.
.
rel.
.
rel.
.
rel.
.
rel.
.
rel.
.
rel.
.
r2 .
100swdpmh idl percentage figure shows the absolute percent error in idl for various deciles of idl value figure absolute error in idl m easurement for decile idl clusters the idl measurement error calculation should include the full error this error is a function of the average variance of individual incoming rates vis a vis the actual growth curve values specifically the variance of the regression residuals that are centered around the actuals plus the er ror of the actual readings .
.
conclusions following are the c onclusions from error analysis addressing releases also see table .
the idl measurem ent error is .
within the primary region of inter est idl for releases studied this includes .
residual based measurement error and .
standard error of the idl variable.
.
in idl reg ion of idl includes .
residual error plus .
standard error.
.
within the idl region of idl for releases studied includes .
residual based error plus .
standard error.
idl swdpmh predict ion error is .
from the region of idl for the releases .
table summary idl swdpmh prediction errors idl residual based measurement error model standard error total measurement error .
.
.
.
.
.
.
.
.
.
summary the findings of this study are so far the combination of a n incoming bug metric incoming defect level and a bug disposal metric fix rate reduction have been shown to be highly predictive of swdpmh for release sequences the average spearman correlation is and the standard error of swdpmh the response variable is only .
.
the model is applicable over a wide range of releases and has the poten tial to be a broadly generalizable model.
high correlations are seen for all systems studied so far including router switc h and datacenter releases and releases for software only applications error analysis for one i.e.
idl of the two primary customer experience i.e.
swdpmh predictors has been completed.
the measurement error for idl varies between and from idl to idl.
this completes the key step in ascertaining whether or not teams are on track to achieving weekly bug incoming and fix rates which in turn enables reaching best in class swdpmh goals.
.