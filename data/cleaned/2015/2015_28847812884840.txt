code review quality how developers see it oleksii kononenko school of computer science university of waterloo waterloo on canada okononen uwaterloo.caolga baysal school of computer science carleton university ottawa on canada olga.baysal carleton.camichael w. godfrey school of computer science university of waterloo waterloo on canada migod uwaterloo.ca abstract in a large long lived project an e ective code review process is key to ensuring the long term quality of the code base.
in this work we study code review practices of a large open source project and we investigate how the developers themselves perceive code review quality.
we present a qualitative study that summarizes the results from a survey of mozilla core developers.
the results provide developer insights into how they de ne review quality what factors contribute to how they evaluate submitted code and what challenges they face when performing review tasks.
we found that the review quality is primarily associated with the thoroughness of the feedback the reviewer s familiarity with the code and the perceived quality of the code itself.
also we found that while di erent factors are perceived to contribute to the review quality reviewers often nd it di cult to keep their technical skills up to date manage personal priorities and mitigate context switching.
ccs concepts software and its engineering !maintaining software collaboration in software development keywords code review review quality survey developer perception .
introduction in a large long lived project an e ective code review process is key to ensuring the long term quality of the code base.
code review is considered to be one of the most e ective qa practices in software development.
while it is relatively expensive in terms of time and e ort it delivers bene ts of identifying defects in code modi cations before they are committed into the project s code base .
reviewers play a vital role in the code review process not only by shaping and evaluating individual contributions but also by ensuring the high quality of the project s master code repository.
code review explicitly addresses the quality of contributions before they are integrated into project s code base.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
to volume of submitted contributions and the need to handle them in a timely manner many code review processes have become more lightweight and less formal in nature .
this evolution of review process increases the risks of letting bugs slip into the version control repository as reviewers are unable to detect all of the bugs.
in our recent study we explored the topic of code review quality by conducting a quantitative investigation of what factors may in uence the quality of evaluating code contributions.
the study was of quantitative nature as it employed data mining and analysis of project s repositories.
while we found that both technical and personal attributes are associated with the review quality many other factors such as organization its culture and structure development cycles time pressures etc.
can potentially in uence how reviewers assess code changes.
since these hidden factors are di cult to take into account in a quantitative analysis because such data is not available easily accessible or extractable from the available artifacts we decided to employ qualitative research methods to ll the gap in the knowledge we had about the developer perception and attitude towards the code review quality.
our qualitative study is organized around an exploratory survey that we design based on the state of the art qualitative research and our own observations of the mozilla code review process and interactions with mozilla developers during our previous research project .
we conducted an exploratory survey with mozilla core developers.
our qualitative analysis of the survey data aims at addressing the following research questions rq1 how do mozilla developers conduct code review?
existing literature o ers several case studies of how code review processes are employed by various software development projects and organizations .
rq2 what factors do developers consider to be in uential to review time and decision?
code review is a complex process that involves people their skills and social dynamics as well as development artifacts and environments thus it can be a ected by both technical and non technical factors .
rq3 what factors do developers use to assess code review quality?
while the quality assessment of code contributions is an active research area the topic of code review quality remains largely unexplored.
to better understand ieee acm 38th ieee international conference on software engineering developer perception and attitudes towards the quality of the process that evaluates code changes we further re ne this research question into the following subquestions rq3.
how do reviewers assess the quality of a patch?
rq3.
how do developers de ne a well done code review?
rq3.
what factors are perceived to contribute to the review quality?
rq4 what challenges do developers face when performing review tasks?
we believe that it is important to understand what ongoing problems developers deal with to provide them with better tools to support their daily tasks and activities.
our main ndings reveal that the review quality is primarily associated with the thoroughness of the feedback the reviewer s familiarity with the code and the perceived quality of the code itself.
as expected we found that di erent factors including technical personal and social signals are perceived to contribute to the review quality.
also we found that reviewers often nd it di cult to keep their technical skills up to date manage personal priorities and mitigate context switching.
the paper makes the following contributions a qualitative study with the professional oss developers who participated in our survey on the topic of code review quality.
a thorough survey analysis that o ers insights into the developer perception of the code review quality and factors a ecting it as well as identi es of the main challenges developers face when conducting review tasks.
a publicly available dataset of anonymized survey responses.
the rest of the paper organized as follows.
section summarizes prior related work.
section describes our methodology including the survey design participants and data analysis.
section presents the results of the qualitative study.
section discusses implications of our work and suggests possible future research directions.
section addresses limitations of our work.
finally section concludes the paper.
.
related work a large body of work has attempted to assess modern code review as practised in the development of large software systems.
mockus et al.
were among the pioneer researchers who studied open source development.
by analyzing the mozilla and apache projects they identi ed the main characteristics of open source communities such as the dependency on the contributions from outside developers and developers being free to choose tasks to work on.
rigby and german presented an investigation of code review processes as practised within four open source projects gcc linux mozilla and apache.
they identi ed the existence of several review patterns as well as quantitatively studied the execution of the review process inside the apache project.
later rigby and storey investigated the mechanisms employed by developers of ve open source projects to identify code changes they are competent to review.
they ex plored the way stakeholders interact with one another during the code review process.
their ndings provided insights to developers about how to e ectively manage large quantities of reviews.
additionally their investigation reveals that the identi cation of defects is not the sole motivation for modern code review.
resolving non technical issues such as scope or process issues was among other motivations of code review.
baysal et al.
empirically studied the webkit project and showed that review positivity i.e.
the proportion of accepted patches is also a ected by non technical factors.
the authors found that factors from both personal and organizational dimensions a ect code review response time and the outcome of a review.
jiang et al.
studied through an analysis of the linux kernel the relation between patch characteristics and the probability of patch acceptance as well as the time taken for patches to be integrated into the code base.
the results of their study indicated that developer experience and patch maturity impact the patch acceptance while the number of suggested reviewers a ected subsystems developer experience and the time of submission a ect the duration of a review.
bacchelli and bird examined the motivations challenges and outcomes of toolbased code reviews.
they found that while the identi cation of defects is the main purpose of code review other motivations such as team awareness and knowledge sharing exist as well.
kemerer et al.
investigated the e ect of review rate i.e.
lines of code reviewed per hour on the e ectiveness of defect removal and the quality of software products.
their study showed that allowing su cient preparation time for reviews and inspections can improve their quality.
hatton found that defect detection capabilities di er among code reviewers the worst reviewer was ten times less e ective than the best reviewer.
moreover he found almost improvement in defects detection between settings where the source code is inspected by two developers together of faults found and where the source code is inspected by two developers separately of faults found .
pull based development is a new model for distributed software development in this model proposed changes submitted as pull requests.
in a quantitative study gousios et al.
explored what factors a ect the decision to accept a pull request as well as the time needed to make such a decision.
they found that decision is dominated by the number of recent changes to the les being modi ed by the pull request the number of such les and the size of a project while the time is mainly a ected by the developer s track record and the test coverage of a project.
tsay et al.
analyzed the in uence of social and technical factors on acceptance of pull requests.
their study showed that while many di erent factors a ect pull request acceptance the social distance and collaborator status are the most in uential ones.
although modern code review has received a signi cant attention recently there is little empirical evidence on what factors contribute to code review quality .
a recent qualitative study by gousios et al.
explored the practices of pull based development model.
they conducted a tworound survey with and github integrators on what factors they consider in their decision making process to accept or reject a pull request.
they found that integrators are most concerned with quality and prioritization.
1029in our recent empirical study we quantitatively investigated the relationships between the reviewers code inspections and a set of factors both personal and social in nature that might a ect the review quality.
we found that of the reviewed changes introduced bugs in the code we also found that personal metrics such as reviewer workload and experience and participation metrics such as the number of involved developers are associated with the quality of the code review process.
while we identi ed which of these factors are more likely to contribute to the review quality our approach was mainly quantitative we were limited by the number of metrics whose values we could extract from the code review data stored in the issue tracking system.
to improve the understanding of how developers perceive the quality of their reviews and the factors they consider to be important in preserving the quality of the code assessment we extend our previous work here by presenting a qualitative study of developer perception and attitudes.
.
methodology we conducted an exploratory qualitative study that involved data collection through a survey with professional developers.
this section describes the survey design the participants and the analysis of the responses in detail.
.
survey design the survey consisted of three main parts nine questions about the developer s demographic background and work practices three likert scale questions related to di erent aspects of code review and seven follow on open ended questions to allow developers to elaborate on issues raised by the multiple choice questions.
participants were asked to spend minutes to complete the survey.
the main goal of conducting the survey was to solicit developer feedback on the perceived quality of code reviews and factors a ecting review time decision and quality.
we also wished to identify key problem areas within the existing review process.
.
participants we decided to continue our work within the mozilla project developer community for several reasons much of our previous work has studied this project and we have good intuition about the system and its development practices we have made good contacts within the project who are supportive of our research goals and because mozilla is a well known very large and long lived open source project.
to identify potential participants for our study we looked at the month history from may to may of all contributions to the mozilla project as they are recorded in bugzilla issue tracking system.
because of the bugzilla s limitations on the search results we directly queried mozilla s elastic search cluster that contains the upto date copy of bugzilla data .
by processing the queried data we extracted unique email addresses bugzilla uses an email address as a unique user identi er .
after that we queried the cluster for each email address to get the information about developer s activity number of contributions submitted for review and the number of patches that were reviewed by the developer during the studied period.
finally we used bugzilla s rest api to extract developers real names.
we decided to limit our survey to experienced developers who were not new to the project.
we computed an experi ence value as the sum of submitted and reviewed patches.
we set a threshold for the experience value at meaning that anyone with a combined experience of at least patches will pass the lter which reduced the list of potential participants to people.
to lter out developers who were new to the mozilla project regardless of their experience level we de ned familiarity as having contributions submitted and or reviewed patches at least months prior to the beginning of the studied period.
this lter further reduced the list of experienced developers to people.
once we selected developers whom we wanted to survey we sent out personalized emails.
each email contained the number of contributions submitted or reviewed during the months period and an invitation to participate in the survey.
the survey was open for weeks from may to june and received responses response rate .
the beginning of the survey consisted of background related questions.
by analyzing the responses we found that we had successfully targeted highly experienced developers about of respondents said that they have more than years of software development experience while another of them have between and years of experience.
most of the respondents have been performing code review for more than years .
.
survey data analysis we applied a grounded theory methodology to analyze the survey data as we had no prede ned groups or categories we used an open coding approach.
as we analyzed the quotes themes and categories emerged and evolved during the open coding process .
author kononenko created all of the cards splitting survey responses into individual quotes these generally corresponded to individual cohesive statements.
in further analysis authors kononenko and baysal acted as coders to group cards into themes merging themes into categories.
for each open ended question we proceeded with this analysis in three steps .
the two coders independently performed card sorts on the of the cards extracted from the survey responses to identify initial card groups.
the coders then met to compare and discuss their identi ed groups.
.
the two coders performed another independent round sorting another of the quotes into the groups that were agreed upon in the previous step.
we then calculated and report the coder reliability to ensure the integrity of the card sort.
we selected two of the most popular reliability coe cients for nominal data percent agreement and cohen s kappa.
coder reliability is a measure of agreement among multiple coders for how they apply codes to text data.
to calculate agreement we counted the number of cards for each emerged group for both coders and used recal2 for calculations.
the coders achieved a substantial degree of agreement on average two coders agreed on the coding of the content in of the time the average percent agreement varies across the questions and is within the range of .
.
while the average cohen s kappa score is .
.
.
the rest of the card sort for each open ended question of the quotes was performed by both coders together.
.
results during the open coding process main including irrelevant categories emerged.
table presents these categories in detail reporting the number of quotes the number of respondents the question numbers the totals and the average percent agreement for each question.
.
rq1 how do mozilla developers conduct code review?
first we wanted to understand the current practices of performing code review tasks at mozilla.
we asked developers several multiple choice questions with an option of providing their own detailed response.
the rst pair of questions focused on the workload that developers face the average number of patches they write and the average number of reviews they perform each week.
while the answers to these two questions are skewed towards smaller workloads fewer than patches per week submitted or reviewed and respectively we received many more responses for the heavier review workload than for the patch workload.
about of the respondents reported that they review to patches each week while another said that they review more than patches each week.
the analysis of a contingency table for these two variables shows that developers with high workloads i.e.
over patches reviews per week tend to concentrate their e orts on a single task type i.e.
either writing patches or reviewing them.
the need for dedicated reviewers is pursued to bring their unique knowledge and expertise e.g.
overall architecture or domain knowledge to the project to ensure the correctness and t of code contributions.
this nding mirrors mozilla s notion of super reviewers a small set of developers enlisted by mozilla who provide an additional review for certain kinds of changes .
the remaining two questions focused on where developers perform code review i.e.
within what environment and where they discuss patches under review.
while all reviewrelated information is stored in bugzilla there is no requirement in the mozilla s code review policies on where a review should be performed.
surprisingly although mozilla provides their developers with a code review platform called mozreview only of the respondents said that they are using it.
the majority of the respondents conduct their code review tasks inside bugzilla itself while another copy a patch locally into their ide.
as for the locations of patch discussions developers were allowed to select multiple of the proposed answers and or their own answer.
the two overwhelmingly popular answers were bugzilla and irc channel and respectively while voip email and face to face discussions received a similar number of responses around each .
while this wide adoption of irc might be in uenced by mozilla itself it also might be explained by the fact that irc allows them to have realtime less formal discussions with ability to bring in more people into a conversation as needed.
rq1 while most of developers write patches as well as review them a dedicated group of developers is responsible for reviewing code changes.
the majority of reviewers conduct code review in bugzilla despite having access to a custom built code review tool and use various communication channels for discussing code modi cations.
the following factors influence code review time percentpriority of a bugse verity of a bug of people in the discussionreview queuemodulethe length of the discussionnumber of resubmitspatch writer experiencecode chunksnumber of modified filesreviewer experiencepatch size loc strongly disagree disagree agree strongly agreefigure factors in uencing code review time.
.
rq2 what factors do developers consider to be influential to review time and decision?
we asked developers about the factors that they believe are most likely to a ect the length of time needed to review a patch as well as the decision of the review i.e.
accept or reject .
for each aspect review time and decision we solicit developers opinions via a point likert scale question and probe more in depth information via an optional follow on open ended question.
the proposed answers to likert scale questions were compiled from the factors that were previously reported in the literature to have an impact on time and outcome.
the open ended questions provided developers an opportunity to specify any other factors not covered by the likert scale question.
time.
the analysis of the likert scale question figure shows that size related factors patch size the number of modi ed les and the number of code chunks are the ones the developers feel are most important and of positive responses respectively .
this nding is consistent with several previous quantitative studies that demonstrate the correlation between the size of the code change and the review time i.e.
smaller patches are more likely to receive faster responses .
the second most positive group is experience reviewer experience and patch writer experience .
again this also mirrors previous research that found that the increase in experience leads to faster reviews.
while all other proposed factors received more than of positive responses the two factors with the biggest numbers of negative responses stand out bug priority and severity received and of negative responses respectively.
such high values speak against the very idea of bug triage.
it may be because mozilla developers use the priority and severity elds inconsistently or because these elds are not used as intended for example in our previous study we found that over of all patches in webkit project are assigned the same priority value .
the manual coding analysis of the open ended question revealed several categories that developers believe have an impact on code review time.
the biggest theme identi ed in the responses is code quality which includes code quality and change complexity categories.
as explained by r67 the amount of in code comments describing what the patch 1031table the list of categories that emerged during open coding.
categoryq11 q13 q14 q15 q17 q18 q r q r q r q r q r q r code quality testing time constraints change scope rationale understanding code change base human factors tools communication change complexity relationship trust usefulness workload submitter related architecture design reviewer related discussion conformance to project goals bug type selecting correct reviewer performance integration into code base security memory management familiarity with the author thorough feedback catching bugs organizational factors documentation context switch irrelevant total average percent agreement .
.
.
.
.
.
notes q the number of quotes r the number of respondents q11 factors a ecting decision q13 factors a ecting time q14 patch quality q15 characteristics of code review quality q17 other factors a ecting review quality q18 challenges.
does.
readability variable naming a ecting how hard it is to understand any particular hunk of the patch on its own.
when reviewing patches the developers stated that patches dependency r39 and changes to the api surface between modules r32 a ect the review time.
perhaps surprisingly developers identi ed that the bug type category also plays a role during the review of a patch and a ects its time.
according to respondent r76 when the cause of the bug is obscure it takes time to review while r74 said nature of the bug some bugs require timeconsuming manual testing .
another category that emerged from the responses is patch scope and rationale .
here the scope also includes granularity whether the patch is broken up into self contained pieces or whether it s one big patch touching lots of di erent areas individual patches are much faster to review in total than one big merged patch of those pieces r19 .
developers believe that the clarity of explanation of what is being changed and why a ects the review time clearly identi ed goal for the patch r11 and what is patch trying to do and should we even be that?
r55 .
understanding the code base category goes along with the scope of a patch.
several developers stated that amount of knowledge that a reviewer has about the code being changed a ects the review time.
several of the emerged categories can be combined into a social theme.
one of the categories here is selecting the cor rect reviewer.
there are di erent characteristics that identify the suitability of a reviewer.
for r87 it is the personality of a reviewer while for r52 it is presence of personal backlog of work and personal priorities .
moreover sometimes the reviewers themselves question their suitability for reviewing a patch am i the best person to be reviewing this patch?
r55 .
developers also identi ed the importance of previous relationship with an author of a patch if someone has a good track record i won t think about the code in quite as much detail compared to someone with a track record of breaking things often r13 .
the other categories in this theme are about submitter type e.g.
newcomer or not and the ease of communication between a patch writer and a reviewer.
decision.
contrary to the answers to the likert scale question about the review time we found no agreement between developers i.e.
strong prevalence of either positive or negative answers for the majority of factors in the case of the review decision figure .
similarly to the previous question both patch writer experience and reviewer experience are the factors with the most positive answers and .
at the same time the size related factors patch size the number of modi ed les and the number of code chunks no longer have the overwhelming number of positive answers instead the respondents are more likely to disagree with the statement that these factors a ect review decisions.
surprisingly bug severity and priority are now the 1032the following factors influence code review decisions percentreview queuenumber of modified filescode chunksnumber of resubmitsthe length of the discussionmodulep atch size loc of people in the discussionpriority of a bugseverity of a bugreviewer experiencepatch writer experience strongly disagree disagree agree strongly agreefigure factors in uencing code review decision.
third and the fourth the most agreed factors.
another interesting nding is related to reviewer workload about of respondents disagree that workload a ects the decision in any way.
this demonstrates that developers think of reviewers as highly capable of carefully analyzing every patch regardless of the time pressure they might face.
while such attitude describes the project s culture this result contradicts our previous nding that suggest that reviewers with shorter review queues are more likely to reject a patch .
several categories emerged during the analysis of the openended question related to review decision.
the highest impact on the review decision is perceived to be code quality of a submitted patch.
while developers associate di erent meanings with the term code quality they can be grouped into several sub categories.
the rst one is adherence to the code style r57 the quality of the code and whether it adheres to accepted style and practices as well as spelling r38 attention to details such as spelling grammar and code formatting .
other two sub categories are readability and simplicity of a patch r34 ease of understanding of code changes i.e.
simplicity of code and presence and quality of design or architectural changes.
finally developers associate the code correctness and its maintainability with code quality.
the second biggest category identi ed from the answers istesting.
when developers submit a patch they can include the results of running existing tests as well as include the tests they wrote speci cally for that patch.
the two subcategories that we identi ed re ect the option patch writers have.
the rst sub category is focused on the presence of automated tests in a patch ... changes that are accompanied by tests are much more likely to be accepted r20 .
moreover developers identi ed that the actual completeness of tests is also important thoroughness of tests included in patch r37 .
the other sub category represents the presence of test results for a patch including test results as a message on the bug tracker can either give the reviewer more con dence to accept the patch if the tests pass or likewise lead them to reject the patch if the tests fail r38 .
change scope and rationale is believed to be an of in uential factor for reviewers making their decisions.
reviewers rst look for the actual appropriateness of change to be incorporated into the code base does the feature t in with the product for patches submitted out of the blue r29 .as r10 explains ... not all xes or improvements are a good idea to actually land even if they re correct .
also reviewers expect a clear explanation of the reasoning behind the proposed change how it solves a problem and why an author chose a particular way of it.
according to r38 including such information can have a signi cant impact on some reviewers con dence to accept the patch .
similarly to the previous question we have a theme of social categories.
the reviews are done by humans so the process is likely to be in uenced by their personalities.
indeed we identi ed reviewer related factors.
several developers report that with some reviewers it is more di cult to get a patch accepted than with others a new reviewer might feel inclined to nd a fault to prove that they done due duty in reviewing the patch r38 and the perfectionist syndrome can you try ... ?
r49 .
in addition to that individual quirks preferences of the reviewer r20 play a role as well.
relationship trust between reviewer and patch writer is found to play a critical role in decision making.
several respondents stated that interpersonal relationship is important for the review outcome.
as explained by r36 if it s someone you trust you don t have to check things as rigorously .
and nally contributor type i.e.
whether he is new mentored or experienced contributor can in uence reviewers decisions if the patch writer is a new or rsttime contributor the reviewer may be inclined to encourage them by accepting their patch more readily after identifying any obvious problems that need xing r38 .
rq2 developers believe that factors such as the experience of developers the choice of a reviewer size of a patch its quality and rationale a ect the time needed for review while bug severity code quality and its rationale presence and quality of tests and developer personality impact review decisions.
.
rq3 what factors do developers use to assess code review quality?
quality is one of the key attributes of ensuring high standards of both code and project development.
with this research question we explore how developers perceive the quality of a patch and what characteristics they believe to be essential in contributing to a well done code review.
to answer this question we analyzed two mandatory and one optional open ended questions as well as one multiple choice question of the survey.
perception of a patch quality.
one of the top attributes for developers when evaluating patch quality is code quality .
code quality has many interpretations.
for some developers it is associated with coding style such as the names of things need to be descriptive readability compactness maintainability lack of redundant or duplicated code strong and unveri ed coupling consistent indentation and style and elegance and lack of hacks .
while for others code quality is about the presence of meaningful comments comments should tell why not what documentation and clear and helpful commit messages i m looking for a thoughtful summary that instructs me reviewer what is going on and what to expect r28 .
some developers nd that adherence to project module standards was equally important to ensure the changes are consistent and conformant to the mozilla coding standards.
1033change rationale is the second top property that reviewers look for.
patches are assessed for their correctness does actually implements what it intends to do?
r19 associated risk and possible alternative solutions are there easier less risky ways to achieve the same thing?
r35 functionality and errors e.g.
correct handling of exceptional cases r33 are all cases handled?
r56 .
reviewers examine whether the patch author understands the source of the problem and the problem domain without introducing any other bugs r62 or ambiguity.
reviewers often think of their own solution to the x before reviewing it and then compare it with the submitted patch.
they also try to understand how much time the author spent on the patch and how well the solution has been thought through does it needlessly reinvent the wheel does it rewrite everything from scratch even though a spot x would have been better ... does it use clever tricks that others will struggle to understand r64 .
in a nutshell a high quality patch usually provides a robust solution for the problem r42 .
change complexity is also perceived as an important property of the patch quality.
developers often look for simple solutions simpler is better r20 simplicity of code makes a big di erence.
code that is complicated often is the result of not being able to distill the problem down to its core.
also reducing the cognitive load required to understand the code means it s easier to maintain and less likely to have bugs in it r34 .
if a patch is trying to resolve more than one issue it is expected that submitter split it into multiple patches if the patch is addressing or di erent things it is lower quality than or separate patches for the individual issues r13 .
many developers agree that size of the change is correlated to the bug proneness small focused changes are easier to assess than large ones.
if bug rate is proportional to lines of code quality is inversely proportional to patch size.
so small patches preferred r28 .
testing is also a key indicator of quality for developers when they evaluate patches.
reviewers expect code changes to come with a corresponding test change.
the lack of such tests is a good sign that test coverage is lacking and we re taking a risk accepting the patch r28 .
the presence of tests in the patch also boosts developers con dence that the patch actually xes the problem.
many developers run and test patches locally or when testing is not practical they perform manual testing as well.
as a part of manual testing developers often perform an operational proof such as code walks through i walk through the changes executing it as i imagine the machine would with as much variety of inputs and states as i can imagine.
i look for edge cases.
i try to consider what is not in the patch things that are being a ected by the patch but are not directly changed by the patch r21 .
reviewers pay careful attention on how the patch ts into the existing code base.
integration into the code base can be examined by checking how the patch melds with the existing code or how it replaces the existing code r23 how much change there is and how far spread the change is r12 or whether the patch breaks web compatibility r4 .
submitters are often expected to be able to anticipate the upcoming surrounding changes and have an overall understanding of the impact of the change on other areas of the code.
to support code maintainability submitters are expected to conduct refactoring tasks if they see the need for it.
reviewerscan request to perform necessary refactoring if they nd that the patch is contributing to code rot r38 .
when reviewing patches developers often examine whether software architecture and design meet expectations.
for example whether a code change meets other design considerations e.g.
pep8 for python code r67 .
it is expected that submitted changes keep the architecture of the code base intact to facilitate code comprehension and maintenance does it continue the architecture of the existing code or diverge in a way that makes future maintenance di cult?
r81 i look for architectural impact to see if it is making the code cleaner or messier r87 .
if the code changes rely on apis reviewers check whether they are used appropriately could the new apis be misused?
r65 .
among other characteristics that developers consider when assessing changes are memory management such as no leaks no unsafe memory usage r4 no accesses to dead objects r9 security such as security related checks and return types performance that relates to the order of algorithms used r38 the right trade o s between simplicity of code and performance r24 e ciency and speed.
social factors such as familiarity with the author play an important role in evaluating patches.
previous relationships with the submitters their experience and reputation within the project can determine the fate of their patches i set a baseline based on any previous relationship with the submitter and the area of code concerned.
if i know the submitter i have both some idea of what to check and a better idea if they ll be around later to x subsequent issues r56 past experience of patch author is a big factor r43 .
characteristics of a well done code review.
this research question investigates developer perception of the key characteristics contributing to a well done code review.
through an open ended question we asked developers opinion on what a high quality review means to them.
the majority of the developers responded that clear and thorough feedback is the key attribute of a well done review.
reviewers are expected to provide feedback that is clear to understand is not only about code formatting and style r6 provides constructive advice e.g.
points out major correctness issues rst and points our minor issues that can be clearly xed without another round of review r24 highlighting potential problems ... and how to x them r42 saying this is the worst code i ve ever seen is not constructive r81 is done by the correct reviewer who has the domain knowledge to properly evaluate the change r55 is delivered via proper communication good code reviews are dialogues between the reviewer and patch author r50 and provides mentoring and training for patch authors providing detailed mentoring to help them improve faster r56 to help the author of the patch become a better programmer in the long term r35 .
developers expect reviewers to have understanding of the code in particular to know the code that s being changed and what other pieces of code interact with it and what their assumptions are what else could break?
... r19 knowledge of the code is paramount because otherwise reviews are super cial r30 .
submitters want reviewers to know the outcome the impact and the side e ects of the modi ed code r49 as well as to ensure that the logic of the patch makes sense.
reviewers are also expected to have an overall understanding of the project s code base enough domain knowledge is always the rst criteria for a well done code 1034review r61 and familiarity with utilities in other parts of the repository that could be re used r38 .
we found that human factors play a crucial role for developers when receiving feedback.
developers associate good reviews with the reviewers who possess personal attributes such as being supportive yet strict r9 patient and stable r61 punctual and tactful r28 helpful and encouraging especially when rejecting a patch r55 expressing appreciation for contributions r38 especially if contributions come from the newcomers to the oss community and inter personal qualities such as being able to establish clear and open minded communication r73 trust the programmer to be competent enough to x the problems r64 provide positive and constructive feedback with the comments written in such a way that the patch author does not take them personally r9 delivered in a constructive tone that respects acknowledges the e orts of the patch writer r21 .
from the developer perspective code review relies on the participation of everyone on the project and an ideal review process is described as the one that allows the author and the reviewer to work together to produce better code than either could on their own maintain quality standards and build familiarity with the code base r56 .
code quality once again is found to be a vital part of the review process.
the review quality is associated with patch writers taking into consideration coding style and formatting preserving code maintainability embracing current best practice within the project r38 .
while reviewers are responsible for not allowing messy code in just because of time r23 ensuring the patch achieves what it was intended to achieve r31 and the code adheres to community standards r82 .
quick turnaround time is also important for the responses as they report that both parties reviewers and submitters are expected be done in a timely manner the value of the review feedback is in the proportion to the cost in terms of delays and time spend r87 .
however reviewers are to avoid shipping their feedback under stress or when there s a deadline r7 as this introduces risks of missing problems.
some developers noted that mozilla code review suffers from non responsive reviewers due to overload or too few reviewers available.
as a result the speed of reviews might overweight the risks depending on what module a faster yet less thorough review is probably going to be ok and worth the risk r34 .
testing is seen as a feature that helps to accomplish the review process.
during the review developers are expected to apply the patch locally and test it to make sure it causes no regression.
thorough and careful testing of the patch ensures it is what is is supposed to and not introducing regressions r42 .
among other factors contributing to a well done review are design and code pattern considerations providing architectural recommendations e.g.
interaction wit other subsystems use of correct apis and catching the bugs left in the patch.
factors a ecting code review quality.
through a mandatory multiple choice question and an optional open ended question we asked participants to express their opinion on the factors they nd to in uence code review quality.
the results of the relevant likert scale survey question are summarized in figure .
the vast majority of the developers agrees that factors such as reviewer experience and technical properties of the patch patch size the following factors influence code review quality percentpriority of a bugse verity of a bugthe length of the discussionreview response timenumber of resubmits of people in the discussionmodulereview queuepatch writer experiencenumber of modified filescode chunkspatch size loc reviewer experience strongly disagree disagree agree strongly agreefigure factors in uencing code review quality.
code chunks number of modi ed les are strong indicators of code review quality.
most developers also consider that personal factors such as patch writer experience reviewer workloads developer participation in the discussion of code changes module and number of resubmitted patches are more likely to a ect the quality of reviews.
while developers have mixed feelings about whether severity and priority of a bug review response time and the length of the discussion have an a ect on code review and its quality.
from the open ended question we found a number of additional factors that respondents think are in uencing the review quality but were not present in our multiple choice question .
as we have seen from previous ndings developers consider understanding of the code base as an important property that characterizes the review quality domain expertise of both the author and reviewer r35 and experience of the reviewer and familiarity with the code or domain are pretty important r85 .
human factors such as reviewer mood personality experience communication skills and style style of making reviews and productivity stress level are seen as ones of the highest determining factors in the quality of the review.
time related factors such as the time of the day the reviewer gets to do a review time pressure and deadlines release schedules release management and priorities of other tasks are also among the factors that in uence reviewer ability to deliver e cient reviews.
code quality and patch complexity presence of tests tool support organizational overhead are mentioned as other potential factors a ecting the review quality.
developer perception of the factors a ecting code review quality matches the insights we obtained in our qualitative analysis of the data from the project s repositories .
reviewer experience and their work loads number of previous patches discussion around issues as well as technical characteristics of a code change such as its size and the number of les it spreads across are found to be strong indicators of the code review quality.
rq3 developer perception of code review quality is shaped by their experience and de ned as a function of clear and thorough feedback provided in a timely manner by a peer with a supreme knowledge of the code base strong personal and inter personal qualities.
.
rq4 what challenges do developers face when performing review tasks?
this research question identi es key challenges developers face when conducting code review tasks.
we identi ed two categories of challenges technical challenges a ect reviewers ability to execute e ective reviews while personal challenges relate to their self management and context switching.
we also report the responses to an optional open ended question about the desired tool support that could help developers with their code review activities.
technical challenges the biggest challenge for developers is gaining familiarity with the code .
since reviewers are often asked to review the code they do not own understanding the unfamiliar code that the patch is modifying can be challenging our module boundaries are broad so patches often touch areas that i m not up to date on r37 .
developers also nd that decision making of whether the change is good can be di cult it s really important that i understand what the patch does r62 .
related to this reviewers often have to assess whether they are capable of reviewing a particular patch or whether they should delegate it to a di erent reviewer deciding whether i am the most appropriate reviewer or if my knowledge of the area of code is good enough to be an e ective reviewer r57 .
reviewers are also expected to fully understand the problem which can be a time consuming process in particular if they review code in diverse areas of the code base.
reviewers have to not only understand the change but also understand its interactions with the existing code and being able to determine what code has to be co changed as well as spot now redundant code r74 .
another category of the technical challenges is related to code complexity .
reviewers are often required to evaluate large patches.
the size of the patch is correlated with the quality of the reviews.
large patches are di cult to review because it can be di cult for developers to see the big picture long patches are hard to review attention wanes quality of the review goes r21 .
r12 mentions that if large patches are broken up it can still be di cult to understand the bigger picture .
the complexity of the pre existing code can add up to this problem.
nevertheless being able to see the big picture can be troublesome yet very critical for reviewers.
finally many reviewers complained about the current tool support available to perform review tasks.
some of them mentioned that reviewing in bugzilla is di cult while others refer to bugzilla as a pretty good tool r62 .
since running automated tests is a part of the review developers nd applying the patch locally and testing it time consuming.
reviewers mention that existing tools are good at visualizing line by line change di tools but fall short in providing a summary of what a patch is changing not on the le level .
personal challenges reviewers often nd themselves struggling with time management skills such as setting personal priorities and beating procrastination convincing yourself that reviews should have higher priority than whatever other work you re r19 how to get reviewing on a rst priority and still getting your own things done r40 .
all reviewers have other non review tasks to conduct such as writing patches participating in discussions attending meetings in person orremotely engaging and recruiting other members to the community or educating and training the new generation of hackers.
thus balancing time to perform reviews as well as all other daily activities can be a struggle.
as r38 says i try to respond within hours but sometimes a review for patches can just show up out of the blue requiring a full day to review.
that throws all other plans out of schedule .
on a personal level reviewers often feel the pressure of keeping up the personal technical skill level i need to constantly improve so i can help others too r52 .
while reviewers understand the importance of providing guidance and support to new contributors they admit that this can be very time consuming and carry risks of landing bug prone patches to the code repository.
as r54 explains reviewing patches by new contributors where hand holding is needed... it becomes tempting to simply land the patch to end the hassle for both the contributor and the reviewer.
this frequently results in buggy code landing in the tree .
several reviewers nd it di cult to work on multiple tasks simultaneously.
working on multiple tasks such as performing reviews and xing a bug is common for developers.
context switching from one problem space to another appears to be challenging.
more importantly when the patch undergoes several revisions reviewers have to keep the context between revisions of the patch to make sure all their concerns with the proposed changes are addressed by the submitter.
from the submitter s point of view keeping track of the comments from the reviewer or other peers can be di cult.
this becomes a challenge when a patch writer is working on a large bug or feature that involves a substantial discussion on the best way to resolve or implement it.
rq4 the key challenges are twofold.
technical challenges are associated with gaining familiarity with the code coping with the code complexity and having suitable tool support.
while personal challenges are related to time management technical skills and context switching.
tools the majority of respondents perform code review tasks inside bugzilla that provides a very basic and limited set of code review related features it allows side by side viewing of the patch and code as well as adding comments to the patch diff.
the most commonly requested feature is a builtinlint like tool that should provide automatic static analysis automatic format and style checking and automatic spell checking.
moreover many developers stated that such a tool should not only automatically check the code but also automatically x it where it is possible .
such a feature would allow them to focus on a bigger picture rather spending time on small problems i should be paying more attention to the architecture and the problem solving mechanics of the patch rather than whether or not the braces are in the right position r21 .
developers also expressed interests in having better development environment that o ers the ability to easily get the patch from the issue tracking system into the local editor for analysis.
another feature is autolanding i.e.
incorporation into the code base of patches once they are reviewed.
finally the developers expressed a desire for direct access to the indexed source code from inside the issue tracker to better understand how the code that being changed is used as well as for the ability to get the change history of that code.
1036almost every code review involves before after comparison of the code.
therefore it is not surprising that developers want improved support for di tools .
the most desired features here are the ability to see the di in the context of the entire le r57 and compare the di erence between the original code and code with multiple consecutive patches applied.
.
discussion we now discuss several research directions that have emerged from this work and can help researchers and practitioners to plan their next research projects.
reviewer recommender system .
mozilla developers need to control an overwhelming ow of information including bug reports review requests updates on their patches etc.
.
one way to help developers manage the increasing ow of information is to provide them with tools that can assist them with speci c tasks.
for example for code review tasks a reviewer recommender system could be able to help both reviewers and patch writers determine the right person to review a code change at hand considering reviewer code module expertise his or her current review loads and availability schedule .
for example r8 asks for a tool to be able to automatically identify potential reviewers based on similar types of code change perhaps in other modules .
while there is a large body of research that addresses this problem of expertise recommendation and o ers a variety of techniques most existing solutions are research tools that do not scale well or would otherwise be impractical to deploy within an industrial environment.
next generation code review tool.
many reviewers expressed concerns with current support for tasks related to code review.
code review is an essential part of the development process at mozilla yet respondents complained about the lack of a good code review tool.
we found that developers expressed interests in having an online code review tool that supports automatic static analysis automatic format and style checker as well as automatic spell checker.
these features can help developers with their time management by allowing them to focus on the code change and how they t into the bigger picture rather than paying attention to the formatting and style nits.
the next generation review tool should also support code indexing and navigation for reviewers to be able to better understand code modi cations and their interactions with other areas of the code base.
another desired feature is related to developing better diff tools to enable the comparison of di erent versions of the code or tracking of individual code changes.
reviewers also commented on the importance of having the ability to compare code on le by le rather then line by line level and to determine the di erences between multiple consecutive patches.
reshaping oss.
while we only attracted and surveyed mozilla developers the results of our study can be applied to other oss projects such as linux apache red hat etc.
most recent studies were either conducted at microsoft or focused on the pull based development model .
while pull based development e.g.
via github is gaining popularity among distributed software development community the need to continue studying and supporting the evolution of large long lived oss projects remains as important as ever.
we noticed that some developers are interested in borrowing emerging technologies e.g.
github and bring ing them to their own working environments.
oss projects are constantly reshaping themselves and researchers can facilitate their growth by helping them address their practical needs and overcome the obstacles they face.
having said that our study adds to the existing body of knowledge on code review.
.
threats and limitations the rst limitation lies in the validity of our ndings from the qualitative study.
while we carefully designed our survey questions to ensure their clarity as with all exploratory studies there is a chance we may have introduced the researcher bias when applying coding to the open ended questions.
we tried to minimize this by coding the of the card sorts extracted from each question independently measuring the coder reliability on the next and reporting these values in the paper see table .
as with any survey method to control for sampling bias can be challenging.
we targeted the core developers of the mozilla community who actively participate in code review tasks either by evaluating patches of their peer developers or submitting their own code changes to reviewers for quality assessment.
we only survey developers from one large open source community yet we targeted mozilla s core developers who are full time employees.
while our ndings might not generalize outside of mozilla we believe any medium and large open source project employ similar code review practices.
nevertheless further research studies are needed to be able to provide greater insight into code review quality and develop an empirical body of knowledge on this topic.
to encourage replication of our study we documented our survey questions and card sort results in a technical report that is made available online .
we also made anonymized survey responses publicly available1.
.
conclusion code review is a vital element of any long lived software development project.
a high quality execution of this process is essential to ensuring the ongoing quality of project s code base.
this work explores the code review practices of a large open source project and aims to understand the developers perception of code review quality.
to accomplish this we surveyed core contributors to the mozilla project.
the qualitative analysis of the survey responses provides insights into the factors that a ect the time and decision of a review the perceived review quality and the challenges developers face when conducting code review tasks.
our ndings suggest that the review quality is mainly associated with the thoroughness of the feedback the reviewer s familiarity with the code and the perceived quality of the code itself.
we also found that developers often struggle with managing their personal priorities maintaining their technical skill set and mitigating context switching.
.