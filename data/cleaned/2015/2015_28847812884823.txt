feature model interfaces the highway to compositional analyses of highly configurable systems reimar schr ter 1sebastian krieter 1thomas th m 2fabian benduhn 1and gunter saake1 1university of magdeburg germany 2tu braunschweig germany abstract today s software systems are often customizable by means of load time or compile time con guration options.
these options are typically not independent and their dependencies can be speci ed by means of feature models.
as many industrial systems contain thousands of options the maintenance and utilization of feature models is a challenge for all stakeholders.
in the last two decades numerous approaches have been presented to support stakeholders in analyzing feature models.
such analyses are commonly reduced to satis ability problems which su er from the growing number of options.
while rst attempts have been made to decompose feature models into smaller parts they still require to compose all parts for analysis.
we propose the concept of a feature model interface that only consists of a subset of features typically selected by experts and hides all other features and dependencies.
based on a formalization of feature model interfaces we prove compositionality properties.
we evaluate feature model interfaces using a three month history of an industrial feature model from the automotive domain with features.
our results indicate performance bene ts especially under evolution as often only parts of the feature model need to be analyzed again.
ccs concepts software and its engineering !software product lines formal software veri cation feature interaction abstraction modeling and modularity keywords con gurable software software product line variability modeling feature model modularity compositionality .
introduction there is a growing need to customize software.
this demand is often based on con icting functional and nonfunctional requirements of each customer.
systematic reuse permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
customized software systems can be achieved by means of load time or compile time variability .
common and variable artifacts of such con gurable software are speci ed in terms of features each representing a unit of functionality.
however not all features are compatible with one another and some features force the existence of others.
feature models are typically used to describe all valid combinations of features and can be represented as a hierarchical model or as a propositional formula .
as feature models specify valid combinations of features they in uence all phases of the development process for congurable software from requirements engineering to veri cation.
in particular all software analyses such as type checking e.g.
or model checking e.g.
have to incorporate feature models to produce sound and complete results .
hence we are interested in all defects for valid feature combinations while defects for invalid combinations are not of interest.
besides such lifting of existing analyses also numerous new analyses devoted to feature models have been presented .
for instance it is intended that all features occur in at least one valid combination .
all these analyses have in common that they are reduced to one or more satis ability problems by translating the feature model into a propositional formula .
hence when the feature model evolves usually the complete analysis has to be executed again even if the feature model changes only slightly.
this work is motivated by recent experiences in applying our feature modeling tool featureide to real feature models of our industrial partner.
dozens of stakeholders maintain a feature model from the automotive domain with features and they face scalability problems for analyses especially as they need to analyze the complete model again after every change.
in addition they expect that the feature model grows even further which is also known from other industrial models and from the linux kernel with thousands of features .
we studied existing approaches to compose feature models from smaller parts but none of them considers compositional reasoning.
that is even if only a single part changes we still have to compose all parts and perform all analyses again.
we propose to use feature model composition with feature model interfaces to enable compositional analyses.
a feature model interface is a feature model with a subset of all features that are selected and intended to be used by domain experts in a speci c composition scenario.
similar to interfaces of programming languages feature model interfaces hide information i.e.
features and can be used instead of the original feature model.
as result the feature model in2016 ieee acm 38th ieee international conference on software engineering terfaces can be considered as placeholder and reduce the complexity of the composed model.
in contrast to programming interfaces the consumer de nes the interface and not the provider.
in this paper we prove compositionality properties for feature model interfaces.
in addition we illustrate their bene ts by applying a time consuming feature model analysis to our industrial feature model.
in particular we make the following contributions we formally de ne and illustrate feature model composition and feature model interfaces.
we prove compositionality between the analysis results of compositions with and without feature model interfaces.
we evaluate the potential of feature model interfaces for the three month evolution of a real world feature model.
.
feature models and analyses in this section we introduce feature models formalize them and present challenges regarding their correctness.
based on this we also formalize common analyses that we investigate in the remainder of this paper.
.
feature models a feature model describes a set of features and their valid combinations.
typically feature diagrams are used to represent feature models graphically by arranging the features in a tree structure with additional cross tree constraints to describe their dependencies .
in figure we illustrate di erent types of feature dependencies by using the example of feature model index which represents a set of index structures to optimally support direct access of data items in a database.
an index can only support one data type at a time.
thus the features int double and float are arranged in an alternative group.
furthermore the developer can choose one or both of the search algorithms k nearest neighbor knn and range .
since the query algorithms are independent of each other they are represented by an or group.
in addition it is optional to force unique keys in an index structure for which we include an optional feature uniquekeys .
since it is only possible to support unique keys for integer values the model includes the additional crosstree constraint uniquekeys intas propositional formula.
besides feature diagrams some other representations of feature models exist such as propositional formulas textual representations or an enumeration of all valid con gurations.
to simplify our proofs we formalize feature models as the set of all valid con gurations de nition .
a feature modelmxis a tuple fx px where a fxis a set of features and b pxis a set of products with px 2fx.
in figure we exemplify this de nition using feature modelindex .
however this representation does not scale well in an actual implementation of any analysis and thus we rely on a conventional feature model representation i.e.
a propositional formula for our evaluation.
.
feature model analyses in industry feature models may consist of thousands of features .
thus automated consistency checks for largescale feature models are important.
benavides et al.
present an overview of automated analyses and consider them as an information extraction process that is executed in two steps .
first an analysis tool translates the feature mofigure feature model mindex f index pindex highlighted characters of the feature diagram are used to represent findex andpindex .
del into a speci c representation e.g.
a propositional formula .
second a speci c algorithm uses a corresponding solver to perform the analysis.
in the following we de ne several analyses based on our feature model formalization and illustrate their usage with feature model mindex.
de nition .
letmx f x px be a feature model and mthe set of all feature models of the universe then void fm x2mjp x g .
core m x p2pxp .
dead m x fxn p2pxp .
pconf m x f f s fd j 9p2p x fs p f d f xnpg .
aset m x fp2asub m x j 8q2asub m x p6 qg .
asub m x fqjq6 px6 8p2p x q p q f xnpg .
a feature model is void if and only if it represents no products .
the analysis is particularly helpful for huge feature models with thousands of features to check the feature model correctness .
using our formalization see void in eq.
.
we get the result that feature modelmindex is not void because it is not contained in the set of all void feature models i.e.
mindex62void .
acore feature is a feature that is included in all products of a non void product line .
the analysis can be used to determine feature priorities as it may be useful to develop core features rst .
using our formalization see core m x in eq.
.
with feature model mindex we obtain the setfindex queries typesg.
a feature of a feature model is a dead feature if and only if it is not part of any valid product of a non void product line .
the analysis is particularly useful to identify contradictions in feature models .
furthermore it avoids implementing features that are not part of any product.
for feature modelmindex the application of function dead see dead m x in eq.
.
results in an empty set and thus the feature model does not contain any dead features.
apartial con guration is a tuple consisting of a set of selected featuresfsand a set of deselected features fdwith the restrictionfs f d f xandfs f d .
if the union offsandfdis equal tofxthe tuple represents a full conguration which describes exactly one product .
hence a full con guration is included in our de nition as a special case.
the analysis of partial con gurations investigates 668whether a partial con guration ful lls all the dependencies of the corresponding feature model .
using our formalization see pconf m x in eq.
.
for feature model mindex the con guration fi q t k ng fu r d fg is part of the resulting con gurations of function pconf and thus a valid con guration.
by contrast the partial con guration fi u dg is invalid because it does not conform to the cross tree constraint and alternative group.
anatomic set is a non empty set of features which is either completely included or completely absent in each product.
the analysis is used to reduce the size of a feature model as input for further analyses .
however most implementations only consider a mandatory feature and its parent as atomic set .
by contrast similar to dur an et al.
we formally de ne the function aset atomic set which uses a feature model mxas input and returns the set of all atomic sets see aset m x in eq.
.
.
to ease the de nition of atomic sets with function aset we use a second function asub atomic subset that determines allatomic subsets i.e.
all subsets of features that are either completely included or completely absent in each product.
however function aset is used to nd all super sets in asub s result i.e.
the function removes all subsets that are completely contained in other sets.
hence the set of atomic sets is always a subset of the set of atomic subsets i.e.
aset m x asub m x .
as an example we use function aset to determine all atomic sets of feature model mindex.
besides the atomic sets with one feature there is one atomic set containing all core features.
.
problem statement as seen in the linux kernel in the application scenario of our industrial partner and in other case studies the complexity of feature models can be challenging for humans and machines.
in the following we explain some of the most important problems.
manual construction and maintenance of a feature model with thousands of features is almost impossible because the size is overwhelming and blurs important feature dependencies.
furthermore feature diagrams do not scale for this feature model size.
therefore decomposition is used to handle large feature models .
using this strategy di erent groups of domain experts can work on smaller feature models which are easier to understand and to visualize.
if we use feature model composition to reuse existing feature models in another one it is possible that only some features are needed to describe or understand the featuremodel dependencies.
a complete feature model reuse can a ect the comprehension of the composition and again blur the important dependencies.
decomposition of a large feature model into smaller fragments is one state of the art strategy to ease human comprehensibility and maintainability.
however to use the previously described analyses for a large decomposed feature model it is necessary to combine its fragments into a representation that is analyzable using existing techniques .
the result is again a large feature model for which not all analyses scale.
thus the scalability problem of complex analyses in the context of large feature models is not solved yet.
a compositional procedure in which we can reuse the results of analyses in smaller feature models for the computation in a feature model composition is desirable.the previous problems are by themselves hard to solve but if we take evolution of decomposed feature models into account the situation gets even worse.
in this scenario we consider changes in feature model fragments where we need to re execute all desired analyses.
in particular it is challenging to reuse existing analysis results of the previous feature model version and thus it is necessary to re compute the complete analysis.
however evolutionary changes are not unusual e.g.
within three months the feature model of our industrial partner was extended by more than features.
therefore it is desirable to reduce the amount of complete re computations when feature model fragments change.
.
compositionality basics as we aim to reduce the mentioned problems we propose to use a combination of feature model composition and feature model interfaces.
based on their formalization we prove compositionality properties in the remaining paper.
.
feature model composition multiple mechanisms exist that allow us to combine feature models .
in this paper we consider the composition through aggregation i.e.
by inclusion of one feature model as an instance in another feature model .
in our running example we want to create an instance of feature modelmindex by connecting it to the feature access in the database feature model mdbms .
to further specify their relationship we add two additional cross tree constraints to the resulting feature model.
we depict the composition result on the left side of figure feature model mcis used to describe the dependencies of the models .
we de ne semantics of the composition as follows de nition .
letmx fx px my fy py and mc f c pc be feature models with fc f x f y. we de ne the function composition usingmx my andmc with in x notation mcbased on the join function and functionrto achieve the composed feature model mx y mx y m x my mc mx mcmy m x r m y m c .
r m y r f y py f y py f g .
mx m y fx px fy py fx f y fp qjp2p x q2p y p f y q f xg .
the de nition of the composition function is based on the functions join and r remove core property .
function rtakes one feature model as input and converts it to a new feature model in which the empty product is a valid product.
thus the feature set is identical to the input feature model and the set of products is extended by the empty set.
ris used in function to ensure thatmy s core features are not necessarily core in the composed feature model.
the join function takes two feature models as input and returns a new combined feature model which is a merge of all input information i.e.
features and products .
in detail the resulting feature model consists of all features from the input feature models.
to combine the product sets of both input models we use an operation that is similar to a join as known from relational algebra .
like the join we only combine two products if the additional condition 669figure composition of the feature models mdbms andmindexusing the feature model mc which describes dependencies between both feature models.
p f y q f xis ful lled.
consequently the function s result is a feature model that conforms to our de nition .
in particular if both feature sets are disjoint the condition p f y q f x is always true.
hence our function behaves similar to a cross product from relational algebra and creates all combinations between both product sets.
the composition function based on the functions r and uses three feature models as input to create a new one.
the second feature model myis instantiated in the rst feature modelmx.
the third feature model mcdescribes a parent child relationship and other inter model constraints betweenmxandmyin order to connect both models.
while function allows us to combine arbitrary feature models our proofs cf.
section are based on the assumption thatfxandfydo not share features i.e.
fx f y .
in figure we exemplify all three functions using mdbms andmindex.
to instantiate feature model mindex in feature modelmdbms we have to transform feature model mindex using our function rand create all product combinations using our join function i.e.
mdbms r m index .
this results in additional product combinations that are not part of the nal feature model mdbms index due to the absence of feature modelmc.
we depict the intermediate result in figure .
finally we eliminate all unintended products using the join function with the intermediate result and the feature modelmc which contains the desired parent child dependency and the two cross tree constraints.
the highlighted products of feature model mdbms index represent the nal result of our composition function .
.
feature model interfaces we now formally de ne feature model interfaces and prove algebraic properties of feature model interfaces that we need for our compositionality proofs.
.
.
formalization of feature model interfaces we de ne a feature model interface as follows de nition .
a feature modelmint fint pint is an interface of feature model mx f x px denoted asmint mx if and only if a fint f xand b pint fp f intjp2p xg.
if two feature models mxandmintdo not ful ll this de nition i.e.
mint6 m x we callmintincompatible tomx.
from de nition we can infer that for each pair mxand fintthere exists exactly one feature model interface.
a vital characteristic of a feature model interface is that it is a feature model itself.
therefore we are able to use an interface instead of a feature model for composition.
in detail the feature model interface minthas a possibly reduced set of features compared to feature model mx.
furthermore each product ofmintis a subset of a product of mx including only features from fint.
moreover each product of mxis a super set of one or more products of mint.
corollary .
8p2p int9q2p x p q f int 8q2p x9p2p int p q f int for our theoretical investigation of feature model interfaces we de ne a function s slice similar to the slice operator proposed by acher et al.
that allows us to generate a feature model interface by removing a given set of features which are of no interest for a speci c target domain.
de nition .
we de ne a function s that takes a feature modelmx f x px and a set of features fras input and returns a feature model mintwithmint m x. mint s m x fr f xnfr fpnfrjp2p xg for our running example we want to reuse mindex as enhancement ofmdbms .
however some features are not of our interest and thus we apply function sonmindex with the set of features frto be removed fr frange unique keys floatg cf.
figure .
in practice frdepends on the speci c reuse scenario in agreement with the stakeholders.
.
.
algebraic properties of interfaces next we take a look at certain properties of function s which we will use in our proofs for compositionality.
in detail we investigate its right identity for certain feature sets and the distributivity with the functions and r. right identity.
a feature setfris a right identity element tosiffxdoes not contain any feature from fr.
as result the application of shas no e ect on a feature model that does not contain a feature of the feature set fr.
lemma .
letmx f x px be a feature model and fr a set of features with fx f r then s m x fr mx.
670proof.
as the intersection of fxandfris the empty set there will be no feature that is removed from the set fx.
the result is the identical feature set fx.
similarly the intersection between each product and the set of features fris also empty and thus each product will be the same as before.
s fx px fr f xnfr fpnfrjp2p xg .
fx px mx distributivity of and s.the order in which we apply the functions and sis not relevant for the result.
lemma .
letmx f x px my f y py be feature models andfra set of features then s m x m y fr s m x fr s m y fr proof.
in general we separate the application of the function s on each part of the composed feature model so that we can apply function later on.
s fx px fy py fr .
fz pz .
fx f y nfr pz .
fxnfr fynfr pz .
next without loss of generality we introduce the sets r and s to represent the results of function s which are then used as input for function .
fz f p q nfrj p2p x q2p y p f y q f xg .
f z f pnfr qnfr j p2p x q2p y p f y q f xg .
de nition f z fr sjr2fpnfrjp2p xg s2fqnfrjq2p yg r f y s f xg .
de nition s m x fr s m y fr distributivity of rand s.finally we prove that the order in which we apply the functions rand sis not relevant.
lemma .
letmx f x px be a feature model and fr a set of features then s r m x fr r s m x fr .
proof.
function r adds the empty set to the set of products.
to prove the interaction of r with s it is necessary to extract this empty set from the input feature model of s. s r m x fr f xnfr fpnfrjp2 px f g g .
fxnfr fpnfrjp2p xg f gg .
r fxnfr fpnfrjp2p xg .
r s m x fr .
compositionality in theory first we present the general idea of compositionality that is based on feature model composition and feature model interfaces.
second we show the potential of this combination using the presented feature model analyses of section .
.
compositionality principle to introduce our general concept of feature model compositionality we assume that two feature models mxandmy figure application of function son feature model mindex.
the highlighted products are part of the resulting feature model interface mint.
are composed to mx y mx mcmy.
typically not all features of feature model myare of interest for the composition with feature model mx.
given the knowledge about those features it is possible to create a feature model interfacemintbased onmy i.e.
mint m y with all features of interest.
now it is possible to use feature model mint instead of feature model myfor feature model composition withmx i.e.
mx int mx mcmint and subsequently usemx intfor automated analyses.
however analysis results formx intmight di er from the results for mx y due to the reduced feature set of mint.
therefore we identify and prove speci c relations between analysis results based onmx intandmx yfor each analysis of section .
for instance the analysis result of dead features for mx intis a subset of the result for mx y. however the main pro t of this dependency exists in an evolution scenario.
if a new version ofmyexists that still conforms to the interface the results formx intare identical.
for our proofs regarding the analysis result relations of feature modelmx intandmx y we have to consider an additional property.
in detail we prove that a feature model composition based on a feature model interface mintis itself a feature model interface in relation to a composition based onmy i.e.
mx int m x y .
this property is based on the assumption that we only remove features from the set fywhereas the feature sets fxandfcremain unchanged.
lemma .
letmx y mx mcmy mx int mx mc mintbe composed feature models based on the models mx fx px my fy py mc fc pc mint s m y fr withfr f x fr f c then mx int m x y. proof.
given the algebraic properties of the function s and the de nition of our composition function mc the following relations hold mx y s m x y fr .
s m x mcmy fr .
eq.
.
s m x r m y m c fr .
lemma s m x fr s r m y fr s m c fr .
lemma m x s r m y fr m c .
lemma mx r s m y fr m c .
de nition mx r m int m c .
eq.
.
mx mcmint .
mx int as a result of this proof we can consider feature model mx intas an ordinary feature model interface of mx y in which the knowledge about the initial composition is not relevant.
thus it is su cient to prove the analysis result relations between feature model mintandmybecause the same dependency holds for feature model mx intandmx y. .
compositionality of existing analyses in this section we investigate the compositionality of the analyses of void feature model core features dead features valid partial con gurations and atomic sets .
for each analysis we rst examine the analysis result relation between feature modelmyandmintfollowed by an investigation of the composed feature models using the following two premises premise .
letmy f y py be a feature model and mint s m y fr f int pint its feature model interface i.e.
mint m y .
premise .
letmx y mx mcmy mx int mx mc mintbe composed feature models based on the feature models mx f x px my f y py mc f c pc mint s m y fr withfr f x fr f c .
.
.
void feature model with respect to premise mintis void if and only if my is void.
theorem .my2void m int2void proof.
with corollary the following equivalences hold my2void p y .
corollary p int .
m int2void based on this knowledge and premise we deduce that a feature modelmx intis void if and only if mx yis void.
theorem .mx y2void m x int2void.
proof.
from lemma and theorem we infer that the same analysis result relation is also valid for mx int and mx y. .
.
core features with respect to premise a feature f2f intis a core feature ofmintif and only if fis a core feature of my.
theorem .
core m y f int core m int proof.
with de nition the following equation holds core m int p2pintp .
de nition p02py p0 f int .
p02pyp0 f int .
core m y f inttherefore we can conclude that if a feature fis a core feature ofmint it is also a core feature of my.
in addition if we determine core features of mythat are also part of mint these are also core features of feature model mint.
f2core m int f2core m y f2core m y f int f2core m int using theorem and premise for composed feature models we can deduce that a feature f2f x intis a core feature ofmx intif and only if fis a core feature in mx y. theorem .
core m x y f x int core m x int proof.
analogous to theorem .
.
.
dead features in compliance with premise a feature f2f intis a dead feature ofmintif and only if fis a dead feature of my.
theorem .
dead m y f int dead m int proof.
based on de nition the following equations hold dead m int fintn p2pintp .
de nition fy f int n p02py p0 f int .
fy f int n p02pyp0 f int .
fyn p02pyp0 f int .
dead m y f int therefore if a feature fis a dead feature in mint it is also a dead feature in my.
furthermore if a feature fis a dead feature in feature model myandfis also part ofmint it is also a dead feature in feature model interface mint.
f2dead m int f2dead m y f2dead m y fint f2dead m int again we take a look into the relations of analysis results regarding feature model compositions.
using premise a feature f2f x intis a dead feature of feature model mx int if and only if fis a dead feature of mx y. theorem .
dead m x y f x int dead m x int proof.
analogous to theorem .
.
.
valid partial configurations regarding premise a con guration c f s fd with fs f int fd f intis a valid partial con guration of mintif and only if cis a valid partial con guration of my.
theorem .
pconf m int f f s f int fd f int j fs fd 2pconf m y g proof.
with de nition the following equation holds pconf m int de nition f f s fd j9p2p int fs p f d f intnpg .
corollary f f s fd j9q2p y fs q f int fd f intn q f int g .
fint f y f f s fd j9q2p y fs q f int fd fy f int n q f int g .
f f s fd j9q2p y fs q f int fd fynq f intg .
f f s f int fd f int j9q2p y fs q f d f ynqg .
de nition f f s f int fd f int j fs fd 2pconf m y g as result we know that each valid partial con guration ofmintis also a valid partial con guration of myand valid partial con gurations of myare also valid partial con gurations ofmintiffsandfdare intersected with fint.
fs fd 2pconf mint fs fd 2pconf my fs fd 2pconf my fs fint fd fint 2pconf mint based on theorem and premise we consider the relationship of analysis results of composed feature models.
hence a partial con guration with fs fx int andfd fx int is a valid partial con guration of mx intif and only if f s fd is a valid partial con guration of mx y. theorem .
pconf m x int f f s f x int fd f x int j fs fd 2pconf m x y g proof.
analogous to theorem .
.
.
atomic sets with respect to premise a feature set awith a f y is an atomic subset with a f intof feature model mintif and only if ais an atomic subset of feature model my.
we prove this relation using function asub .
theorem .
asub m int fq f intjq2asub m y q f int6 g proof.
asub m int de nition fqjq6 pint6 8p2p int q p q f intnp g .
corollary fqjpy6 q6 8p2p y q p f int q fynp f int g .
fq f intjpy6 q6 q f int6 8p2p y q p q f ynp g .
de nition fq f intjq2asub m y q f int6 g thus we know that each atomic subset aofmintis also an atomic subset of my.
in addition an atomic subset aof myintersected withfintis also an atomic subset of mint.
a2asub m int a2asub m y a2asub m y a fint 2asub m int using theorem and the premise we investigate the relation of atomic sets in composed feature models.
in detail a set awith a f x int is an atomic subset of mx intif and only if ais an atomic subset of mx y.theorem .
asub m x int fq f x intjq2asub m x y q f x int6 g proof.
analogous to theorem .
.
discussion to exemplify the obtained properties of compositionality with feature model interfaces we reconsider the identi ed problems of section and use our running example with the analysis of atomic sets as illustration.
of course the approach is also applicable for other analyses.
first we considered the problem of feature model scalability for humans.
compared to the composed feature model mdbms index mdbms int withmint m index is slightly smaller and thus it might be easier for humans to identify all relevant features of the feature model composition.
this bene t increases even more if more than one feature model is used for the feature model composition see section .
second we took the scalability problem with feature model analyses into account.
here we focus on a scenario where we are interested in the analysis of atomic sets for the feature modelmdbms int.
if we use state of the art implementations of this analysis we perform the analysis for feature modelmdbms index and nally lter the results to receive atomic sets that only contain features of interest i.e.
fdbms int .
by contrast applying our concept of featuremodel interfaces we can use the feature model mdbms int for the analysis of atomic sets.
thus we achieve the same results as in the state of the art approach but with performance bene ts due to the reduced propositional formula of feature modelmdbms intcompared tomdbms index .
third we identi ed the support of feature model evolution as one of our main challenges.
usually an evolutionary change of feature model mindex implies a complete re computation of atomic sets for mdbms int.
by contrast if we use feature model interfaces we only have to re compute the analysis if the feature model interface mintis no longer compatible with the evolved feature model mindex i.e.
mint m index .
to check this compatibility we only need to compute the interface of the evolved feature model mindex and to compare it to the previous interface version.
.
compositionality in the wild next we explore feature model interfaces in practice with thousands of features as given in industrial cases .
we investigate the typical size of interfaces and their potential to support humans and machines during evolution.
furthermore we examine how often feature model interfaces become incompatible to their corresponding evolved feature models.
in detail we investigate the research questions rq1 how small can feature model interfaces get compared to their corresponding feature models?
rq2 how often does a feature model interface become incompatible to an evolved feature model?
additionally using the analysis of atomic sets as it is the most computationally intensive analysis of our considerations with exponential complexity we give an outlook on potential performance bene ts of compositional analysis.
therefore we investigate the following question rq3 is it possible to achieve performance bene ts using compositional analysis for atomic sets compared to an analysis of the complete feature model?
.
experimental design and subject in our experiment we investigate four monthly snapshots of one real world feature model from the automotive domain which includes features of hardware and software.
we received it from our industrial partner in an obfuscated way i.e.
feature names are replaced by unique ids .
in snapshot v1 the feature model consists of features with constraints whereas snapshot v4 has features with constraints the feature models are available in theexample wizard of featureide .
the complete feature model of a snapshot originally contained more than smaller feature model instances.
for our evaluation we need the original feature model instances because we want to investigate the relations to their featuremodel interfaces.
fortunately we are able to decompose the complete model into one root model and depending featuremodel instances since we know the position of each instance in the complete feature model i.e.
the id of its root feature .
regarding cross tree constraints of the complete feature model we distinguish between intra model constraints which describe dependencies within an instantiated feature model and inter model constraints which describe dependencies between di erent models.
we insert intra model constraints in the corresponding feature model whereas we save inter model constraints for later usage.
for the evaluation we use each instantiated feature model as input for our interface generation algorithm and search for a strategy to select relevant features.
due to the lack of speci c domain knowledge we declared each feature that is included in an inter model constraint as relevant most notably the root feature due to its parent child relationship to the root model .
we call the resulting interfaces minimal because they only consist of features that are relevant for the composition i.e.
they can di er from interfaces designed by domain experts .
afterwards we reconstruct a reduced feature model of the speci c snapshot by recomposing the minimal feature model interfaces and the root feature model.
we perform this procedure for each snapshot and use the results to answer rq1 and rq2.
in order to use feature model interfaces for this evaluation we need a scalable generation algorithm.
although an algorithm of our previous work is suitable for the elimination of features in propositional formulas the algorithm does not scale for the generation of feature model interfaces.
therefore we designed a new algorithm that is based on multiple satis ability tests and logical resolution.
however the algorithm itself is out of our scope and discussed elsewhere in detail .
we refer interested readers to our opensource implementation in featureide v3.
.
to exemplify the compositionality properties of featuremodel interfaces and to answer rq3 we investigate the analysis of atomic sets and the results for the reduced feature model of snapshot v1.
contrary to the proposed atomic set algorithm that only combines features with their mandatory children we use our de nition of atomic sets which may also combine features of di erent sub trees.
for the computation of atomic sets for the reduced feature model we consider two ways using the complete model with a subsequent ltering on the features of interest and using our recomposed feature model from the minimal interfaces.
afterwards we compare the individual computation times.
.
results and discussion we divide this section according to our research questions.
rq1.
in figure we depict the results of our investigation for research question rq1 using boxplots please ignore the bars for now .
each boxplot illustrates one snapshot of the automotive feature model and presents the percentage of features given in the interface relative to the features in the corresponding feature model.
to further improve the illustration we removed feature models with only one feature.
for instance in snapshot v1 there exists an instantiated feature model with exactly features whereas the corresponding interface only consists of the root feature.
the median of boxplot v1 and v2 is less than whereas the boxplots of snapshot v3 and v4 have a median less than .
thus half of all existing feature model interfaces only consist of less than of features relative to the corresponding feature models.
furthermore of all feature model interfaces consist of less than of the features.
in summary the di erence between the number of features in a feature model interface and its corresponding feature model is signi cant.
in most cases the resulting featuremodel interface consists of less than of the features.
rq2.
for research question rq2 we investigate the bene t of feature model interfaces for an evolutionary scenario.
in detail we check how often adaptations of a feature model interface are necessary due to evolution of its corresponding feature model.
in figure we depict the result of this investigation using bar charts that present the percentage of incompatible feature model interfaces between all snapshots.
for instance the rst bar i.e.
v1 !v2 presents whether the feature model interfaces of snapshot v1 are still compatible with the feature models of snapshot v2 mintv1 m v2 .
the results can be divided into three categories a the feature model interface is still compatible green b the interface is incompatible red and c the desired minimal interface changed yellow .
in the last case the new feature model is incompatible to its interfaces because the interface has a changed feature set due to new inter model constraints.
however the dependencies within the feature model did not change and all features that are necessary to describe the inter model constraints are available in the previous snapshot.
thus they could be used to create the same interface as given in the current snapshot.
therefore if a domain engineer creates ideal interfaces i.e.
using the knowledge of all future dependencies instead of the minimal ones the result would be a compatible featuremodel interface for both snapshots.
in the bar v1!v2 we present all cases in which the feature model has been changed.
here more than of all feature model interfaces are equal in both snapshots less than are not equal and more than are not equal because of minimality.
in the other bars only and feature models have been changed.
as result bar v2 !v3 presents more than not equal feature model interfaces whereas the bar v3 !v4 again presents less than .
the equality of the new feature model interface was decreased from in bar v1 !v2 over in v2 !v3 to in bar v3!v4.
by contrast the results from category c increase from to and thus the success of interfaces depends on the choice of removed features.
for research question rq2 we investigated the interface dependency of evolved feature models to the interfaces of the 674features in v114 v1 v219 features in v217 v2 v314 features in v318 v3 v413 features in v418 616figure percentage of features in the minimal feature model interface compared to their feature models and percentage of compatible interfaces incompatible interface because of minimality and incompatible interfaces .
previous version.
we get the result that in more than half of all cases in which the feature model has been changed the interface dependency holds.
for all positive cases it is not necessary to change anything in the composed feature model and thus we need no further computations.
rq3.
using the analysis atomic sets we evaluate the potential of feature model interfaces for compositional analyses.
as described in our experimental design we use the feature model of snapshot v1 as input and are interested in the atomic sets of the corresponding reduced feature model.
the analysis based on the complete feature model takes more than hours for the computation of all atomic sets while the subsequent ltering is negligible.
by contrast in the composed analysis we need in total less than seconds for the generation of feature model interfaces reconstruction of the feature model and computation of all atomic sets.
indeed it is also possible to optimize the internals of the atomic sets algorithm to only consider relevant features.
however these optimizations are out of scope of this paper.
hence we considered the algorithm as black box and used the described evaluation strategy.
in summary using the analysis of atomic sets we illustrated that it is possible to reduce computational time using our concept of compositional analyses.
.
threats to validity external validity.
the results of our study strongly depend on the analyzed feature model of the automotive domain the distribution of the root features of the instantiated models and on the features of interest fint that we declared based on inter model constraints due to the lack of domain knowledge.
we plan to investigate whether the results can be generalized to other snapshots feature models or domains.
nevertheless we had no in uence on the selection of snapshots and root features we received from our industrial partner.
the snapshots of the automotive feature model seems to be extracted from an early state of the development process i.e.
snapshot v1 with features and v4 with features .
it is possible that a more stable version leads to di erent results regarding necessary interface changes.
however we plan to investigate more snapshots and other case studies to get more insights.
furthermore we automatically generated minimal interfaces.
in practice developers will be able to incorporate domain knowledge to create interfaces.
however we receivedthe feature model in an obfuscated way which does not allow us to use domain knowledge for the interface generation.
internal validity.
we used a prototypical implementation of our optimized algorithm to compute feature model interfaces in a scalable manner.
to reduce the probability of errors we used unit tests in which the results of this algorithm were compared to the state of the art algorithm for abstract features .
because of scalability problems it was not possible to compare the results of both algorithms with huge feature models but we used smaller feature models for the comparison with di erent sets of relevant features.
with refactorings it is possible to further reduce our minimal feature model interfaces.
for instance let us consider the constraint a b cas inter model constraint in which the features a and b are features of the same instantiated feature model and c is part of another feature model.
here we include both features in the corresponding feature model interface.
however it is possible to refactor this constraint into two new constraints a bas intra model constraint anda cas inter model constraint.
as result it is sufcient to only include a into the feature model interface instead of a and b. this approach could lead to even better results but may harm readability.
.
related work here we present several works in the domains of interfaces in product lines feature model composition the analysis of feature models and further analyses based on interfaces.
interfaces and views for product lines .as stated above the de nition of the slice operator presented by acher et al.
is similar to our de nition of feature model interfaces .
thus the slice operator uses a feature model as input to create a new one that only consists of a subset of features with unchanged feature dependencies.
however acher et al.
use the slice operator to focus on the property of feature model decomposition.
in subsequent work acher et al.
use the slice operator in combination with a merge operator to consider evolutionary changes of extracted variability models in a real world plugin system .
for the extraction process the authors used feature model aggregation and slicing and compare the di erent models of each system s version.
whereas we aim to support evolution using a stable feature model interface so that we prevent a re evaluation of the system acher et al.
aim to detect differences of the feature model versions during evolution.
furthermore dhungana et al.
present an interface that is mainly used for information hiding to other parts of the feature model called fragments and to support evolution .
in detail the authors save a merge history of fragments at one point in time give feedback to the single fragments to ease their maintenance and use the history to re merge the fragments in the future.
however the approach does not consider automated analyses.
a further concept related to feature model interfaces are feature model views .
views also present a subset of relevant features based on a master feature model and are generally used to ease the con guration of large scale feature models.
thus di erent views regarding one master feature model are combined to get a valid con guration based on the view s partial con gurations.
by contrast a feature model interface can be an interface of a set of di erent feature models and is not bound to a speci c one.
675automated analyses of feature models.
there exists a wide range of research for automated analyses.
benavides et al.
present a survey about existing analyses of feature models with information regarding the analysis concept tool support and