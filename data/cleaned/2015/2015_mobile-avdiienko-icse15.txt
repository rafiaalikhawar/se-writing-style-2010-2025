mining apps for abnormal usage of sensitive data vitalii avdiienko konstantin kuznetsov alessandra gorla andreas zeller steven arzty siegfried rasthofery and eric boddenyz saarland university imdea software instituteytu darmstadtzfraunhofer sit saarbr ucken germany madrid spain darmstadt germany darmstadt germany abstract what is it that makes an app malicious?
one important factor is that malicious apps treat sensitive data differently from benign apps.
to capture such differences we mined benign android applications for their data flow from sensitive sources and compare these flows against those found in malicious apps.
we find that a for every sensitive source the data ends up in a small number of typical sinks b these sinks differ considerably between benign and malicious apps c these differences can be used to flag malicious apps due to their abnormal data flow and d malicious apps can be identified by their abnormal data flow alone without requiring known malware samples.
in our evaluation our mudflow prototype correctly identified .
of all novel malware and .
of novel malware leaking sensitive data.
i. i ntroduction most existing malware detectors work retrospectively checking an unknown app against features and patterns known to be malicious.
such patterns can either be given explicitly text messages must only be sent after user s consent or induced implicitly from samples of known malware this app contains code known to be part of the tdss trojan.
.
if a novel app is sufficiently different from known malware though this retrospective detection can fail.
in this work we thus conversely investigate the idea that given access to a sufficiently large set of benign apps one might be able to detect novel malware not by its similarity with respect to existing malware but rather through its dissimilarity with respect to those benign applications.
checking for dissimilarity is different from checking for similarity though because in terms of functionality or code fragments we already have lots of dissimilarity across benign applications themselves.
as a measure for establishing similarity or dissimilarity with respect to the norm we thus explore the usage of sensitive data in an app.
specifically we apply static taint analysis on the most popular android apps from the google play store to determine for every sensitive data source the sensitive apis to which this data flows.
we consider these flows to constitute the normal usage of sensitive data as we assume the most popular google play store apps to be benign these flows also resemble benign usage.
as an example of such flows consider the well known android twitter app.
table i shows its extracted data flows.
we can see that while the twitter app accesses sensitive account information it uses this information only to manage synchronization across multiple devices.
network information is being accessed as part of the main functionality of the app saved in logs and passed on to other components.table i flows in android twitter app accountmanager.get contentresolver.setsyncautomatically accountmanager.get accountmanager.addonaccountsul accountmanager.get activity.setresult accountmanager.get log.w accountmanager.getaccountsbytype contentresolver.setsyncautomatically accountmanager.getaccountsbytype activity.setresult accountmanager.getaccountsbytype log.w uri.getqueryparameter activity.startactivity uri.getqueryparameter activity.setresult uri.getqueryparameter activity.startactivityforresult uri.getqueryparameter log.w sqlitedatabase.query log.d sqliteopenhelper.getreadabledatabase log.d sqliteopenhelper.getwritabledatabase log.d table ii flows in com .keji.danti malware telephonymanager.getsubscriberid url.openconnection telephonymanager.getdeviceid url.openconnection in contrast consider the com.keji.danti604 malware from the virusshare database .
table ii shows the two flows in that application they leak the subscriber and device id to a web server.
both these flows are very uncommon for benign applications furthermore danti604 does not contain any of the flows that would normally come with apps that use the telephonymanager for legitimate reasons.
thus danti604 is an anomaly not only because it may be similar to known malware but in particular because its data flows are dissimilar to flows found in benignware such as twitter.
we have built a tool called mudflow1which leverages the flowdroid static analysis tool to determine such flows for all sensitive android sources.
mudflow implements multiple classifiers trained on the data flow of benign apps to automatically flag apps with suspicious features.
to the best of our knowledge mudflow is the first approach to massively mine application collections for patterns of normal data flow and to use these mined patterns to detect malicious behavior.
the remainder of this paper is organized as follows.
after introducing data flow and taint analysis in section ii this paper presents the following contributions we present mudflow an approach to mine compare and classify the data flow in large sets of android applications section iii .
we apply mudflow to the most popular apps collected from the google play store section iv .
for each significant sensitive data source we summarize 1mudflow mining unusual data flowthetypical usage of this source across these apps and contrast it against the usage found in a collection of malware apps.
we use the data flow differences to automatically identify malware based on its flow of sensitive data section v .
in particular we train a model using data flows of benign apps only and use it to detect novel malware even if no earlier malware samples are known.
our experiments show that dissimilarity with benign apps determined through data flow from sensitive sources can be a significant factor in characterizing malware.
in our experiment on a set of malicious apps leaking sensitive data mudflow recognized .
of the malware as such with a false positive rate of .
which is remarkable given that mudflow is not trained on malware samples.
after discussing threats to validity section vi and relating to existing work section vii we close with conclusion and future work section viii .
ii.
d ata flow and taint analysis in android when installing an android application a user only sees a textual description of the alleged behavior of the app and a list of required permissions that the app needs in order to work.
an app may for instance require access to the list of contacts on the mobile device but unless clearly stated in the description it is vague how the app is using this data.
a benign messaging application may need to access the contact list to send messages while a malicious application may collect the list of contacts and send them to a third party server that gathers them for spamming.
to detect this kind of behavior one can use taint analysis which is a particular instance of data flow analysis .
in essence given a source of information e.g.
the sqlite database containing the list of contacts and a sink e.g.
an http connection to a third party server taint analysis can tell whether that information can flow to the undesired sink.
information flow can be analyzed statically i.e.
the analysis would report whether there exist some paths in the program that may lead to this information flow or dynamically i.e.
by reporting information flows that actually occur during a specific execution.
in the first case the analysis might report false positives i.e.
information flows that are not feasible in practice.
in the second case the analysis would likely miss information flows namely if those flows occur in part of the behavior that was not observed.
both static and dynamic data and information flow analysis techniques have been used to analyze android applications since several malicious applications use this platform to collect sensitive information of users.
in fact compared to the list of requested permissions information flows can better describe the behavior of an android application as they can show how the application is using a specific piece of information.
data and information flow analysis has been used to detect typical spyware behavior such as collecting sensitive information and sending it to third party servers.
however flows of sensitive data are quite present in benign applications aswell.
the sole fact that an app has specific flows does not necessarily mean that the app is malicious.
a. static taint analysis with flowdroid internally mudflow uses the static taint tracking tool flowdroid to identify data flows in android applications.
we chose flowdroid because of its precise analysis and because it accurately models the lifecycle of android applications and their interactions with the operating system.
unlike normal java programs android apps are tightly coupled with their execution framework which can for instance pause and resume them at any time.
callbacks notify the application of system events such as a low battery level or an incoming text message.
flowdroid first analyzes the apps for all registered event handlers and components and then creates dummy code that simulates these interactions with the operating system causing the static analysis to take this possible runtime behavior correctly into account.
flowdroid provides a highly precise taint analysis that is fully object flow and contextsensitive.
high precision is required to reduce false positives during data flow analysis it also reduces the amount of noise within the input data on which the machine learning approach ofmudflow is later trained.
listing shows an example of how an android application can obtain leaked data.
the example reads the phone s unique identifier and sends it to the example telephone number using an sms message.
in real world applications the path between source the call to getdeviceid and sink the call to sendtextmessage can be substantially longer and may include field and array accesses polymorphic library method calls conditionals etc.
flowdroid uses an instantiation of the ifds framework by reps and horwitz .
ifds reduces data flow problems to reachability in a graph whose nodes represent combinations of possible facts about the program e.g.
variable devid is tainted at line xin filef .
if one fact can be derived from another the respective nodes are connected with an edge causing the latter to be reachable from the former.
if a certain fact at a sink is reachable from the node modeling a source the analysis has discovered a leak from this source to this sink.
in the example in listing the node for variable devid at line forms the root of the graph.
it is connected to the node that models ais tainted at line due to normal void oncreate f telephonymanager mgr telephonymanager this.getsystemservice telephony service string devid mgr.getdeviceid string a devid string str prefix a smsmanager sms smsmanager.getdefault sms.sendtextmessage null str null null 9g string prefix string s f return deviceid s g listing .
android data leak exampleforward propagation.
when processing a method invocation the algorithm creates an edge into the callee in the example causing the node representing sis tainted in line to become reachable.
on method returns the return values are mapped back into the caller creating an edge to stris tainted in line .
the analysis then recognizes this line as a sink.
the fact that parameter stris tainted is transitively reachable from the source means that there exists a leak of the device id.
the context sensitivity of flowdroid makes it possible to distinguish different calls to the prefix method with different parameter values.
a context insensitive analysis would act conservatively marking as tainted all program variables capturing the return value of prefix even at those call sites that call prefix with benign values.
flowdroid uses special hand written summaries for calls to library methods for which no source code is available.
numerous optimizations make sure that the taint analysis scales to large apps such as the popular social network applications in the google play store.
space limitations preclude us from explaining these optimizations further.
we kindly point the interested reader to the original flowdroid paper .
b. sensitive sources mudflow leverages static taint analysis with flowdroid tocharacterize the behavior of individual apps with respect to their usage of sensitive data.
the key idea is to identify data flows that originate from sensitive sources.
we first describe our concept of a sensitive source followed by how we characterize the originating flows.
in android all sensitive data can be accessed through specific apis for instance the android method getlastknownlocation returns the user s current location.
by tracing where this data flows to it is possible to characterize the app s behavior.
for this though we need to identify the apis that access sensitive data.
this is less easy than it might seem because several android apis are not or hardly documented furthermore lists crafted by researchers get outdated with every new android version.
we therefore leverage the susi technique by rasthofer et al.
which automatically classifies all methods in the whole android apias a source sink or neither using a small hand annotated fraction of an android apito train a classifier.
beside providing a list of apis that access sensitive sources susi also provides a categorization of these apis listed in table iii.
the method getlastknownlocation for instance falls into the location information category.
in addition to the originally published susi categories we created three new categories to further break down the behavior of android apps marked with in table iii.
sensitive resources.
during our investigation we found that android apps also access sensitive resources through content providers external components that resolve appropriate resource identifiers a calendarcontract provider for instance can access calendar data.
all these flows start from the android.content.contentresolver api which gets the desired resource identifier as an argument.table iii susi api categories of sensitive sources and sinks sources hardware info unique identifier location information network information account information email information file information bluetooth information voip information database information phone information content resolver no sensitive source new category see textsinks phone connection voip phone state email bluetooth account settings video synchronization data network email settings file log intent no sensitive sink shared audio sms mms contact information calendar information system settings image browser information nfc susi assigns the contentresolver apitono category because the same apican be used to access all sorts of resources sensitive or non sensitive.
in however au et al.
published a list of sensitive resource schemes as used in android.
we therefore conducted an additional step of static analysis using soot we extracted android.net.uri usages from all android applications and assigned them to the appropriate susi source categories.
any resource usage not in the list would be classified into thecontent resolver sensitive source category.
intents.
we found that several flows end in communication between multiple app components intent in android parlance .
as of now the precise identification of activities launched by intents as well as identification of flows across intents is out of scope for this paper our main objective namely classification of malware is still fulfilled despite this imprecision.
to mark flows into intents we introduced a special category intent for this kind of potentially sensitive sink.
non sensitive sources and sinks.
almost all applications in the google play store access sensitive sources.
however the data accessed does not necessarily end up in a sensitive sink wallpaper apps for instance access the user s images as sensitive sources but the user s display is not a sensitive sink.
to leverage these accesses every source used that does not flow into a sensitive sink is modeled as a flow from that source to the special category no sensitive sink.
similarly we modeled flow that does not start from sensitive source and ends up in a sensitive sink from the special category no sensitive source .
iii.
m ining and classifying flows a. extracting flows applied on a single app mudflow uses flowdroid to extract all data flows from all sensitive data sources toall sensitive data sinks.
the result is a set of pairs that characterizes the sensitive flows in the application and thus the application itself flows app source sink source sink where each source iand sink iis a sensitive android api method.
again sensitive means that it falls into one of the susi categories listed in table iii .
as examples of such flows consider table i and table ii discussed in section i.table iv flows in android twitter app bysusi category account information synchronization data account information account settings account information intent account information log network information intent network information log database information log b. flow granularity by default each source and sink contains the full method name and signature.
for the sake of obtaining a coarser granularity this information can be shortened allowing for multiple sources and sinks to be aggregated.
mudflow supports the following three granularity levels from finest to most coarse method.
this is the full method signature for instance locationmanager.requestlocationupdates .
.
.
.
class.
considering only the class name locationmanager allows to express flows between classes rather than methods.
this treats all methods of a class uniformly.
category.
considering only the susi category of the api location information allows to express flows between categories.
this is the coarsest way of expressing flows yet one that could be made accessible to end users.
table iv shows the flows in the android twitter app at the category level.
here it is indeed easy to spot how the sensitive data is being used.
c. automatic classification as shown above the flow within malicious apps may differ significantly from the flow within benign apps.
mudflow leverages such differences to automatically classify novel apps whether they are malicious or not.
while most malware detection is retrospective in nature checking apps against patterns found in known malware mudflow is able to compare a new app against benignware only and check whether it contains abnormal flows with respect to this set.
this allows mudflow to detect malware as abnormal even if the specific attack is the first of its kind.
the mudflow malware classification takes a set sof benign apps say all apps from an app store and then works in three steps detailed below.
outlier detection in category in its first step illustrated in figure mudflow identifies which apps have unusual flows within each category using sas a ground set.
specifically for a category c mudflow takes all apps in sthat use at least one apifromc extracts all flows within these apps that is flows originating from sources in cas well as flows originating from other sources .
to compute the flows in this step mudflow uses the apimethods classified as sources and sinks assigns .
as a weight to all flows that lead to log since these flows are highly prevalent in apps but are less harmful since starting from android .
log filescan only be accessed by diagnostic and administrative tools.
finally it determines outlierness score of apps considering these flows as features by using orca method with sas a reference set.
the resulting model can then be used to assess a novel potentially malicious app awhich also uses at least one api fromc.
for this purpose mudflow extracts the flows from a and computes the distance betweenaand itsk nearest neighbors from the set s. for this step mudflow resorts to the orca outlier detector and considers by default the nearest neighbors of a sample a. to measure the dissimilarity between samples mudflow uses the weighted jaccard distance metric since it is more suitable for data with a huge number of features as in this case.
the resulting distance serves as an outlier score the higher a s distance the less normal are its features resulting according to our hypothesis in a higher likelihood of being malicious.
aggregating scores in its second step mudflow applies the above outlier detection on all susi source categories resulting in a single outlier detector for each sensitive source.
we can now take an app aand determine its scores for each category.
as illustrated in figure we thus obtain a vector of distances telling for each sensitive category how much a deviates from the norm.
if an application does not use the apis of the appropriate source its outlierness score is set to zero.
we have dubbed this vector a maliciogram as it may guide investigators towards potential issues or inform end users about potential risks allowing them to focus on the categories they care about most.
however the quality of susi categories depends on how similar the benign applications are within the particular category.
to take this fact into account mudflow assigns a app1 log1id4app2 app?
id4 id4?
sms2...... log2id2 app1 app3outlier detectiontrainingd .76outlier detector fig.
.
per category outlier detection.
for each susi category such as unique identifier shortened to id mudflow selects apps that use apis of that category as source and uses their flows as features.
it then takes a new unknown app and determines its outlierness score with respect to the normal apps.
the higher the score the less normal the app behaves inside a particular susi category.weight to each category emphasizing its importance.
when the mean value of scores within a category is high it means that all benign apps considerably differ from each other.
as a consequence of this induced noise we have less confidence that an outlier would be malicious.
for this reason we give a lower weight to such categories if in contrast the mean of score values is low the category will have higher weight.
more precisely we use exp mean as the formula to weigh categories.
overall classification in the third and last step mudflow leverages one class classification to determine whether an appaoverall would be considered malicious or not.
this decision would be based on the individual scores in each category as determined in the past two steps.
the process is illustrated in figure mudflow constructs a training set based on benign applications.
their score vectors maliciograms across the susi source categories are used as features.
it trains a svm one class classifier which is commonly used for novelty detection purposes.
after training it uses the svm forclassification of a novel appa based on its score vector into either likely benign or likely malicious .
the result is a fully automatic warning flag for any novel app which when raised would trigger further investigation such as additional analysis or testing.
this investigation would be guided by the individual category scores as reported by mudflow how does this app deviate from the norm?
as well as the individual flows detected within the app which flows in this app are abnormal?
.
d. advertisement frameworks many android apps generate revenue through advertisements which are delivered through specific advertising frameworks.
these frameworks access sensitive sources such as account data to deliver personalized advertisements however these flows are separate from the actual app code.
as advertising frameworks are frequently used their flows thus become normal and make malicious flows harder to detect.
furthermore malicious software may use an advertisement framework to motivate and mask its malicious flows.
assuming that advertisement frameworks are to be trusted mudflow therefore ignores all sensitive flows taking place within advertisement frameworks only allowing it to focus on the actual app code.
table v shows the list of frequently used frameworks whose flows are excluded in mudflow .
currently app??
d .76d .62d .30d .08d .
fig.
.
aggregating probabilities across apiusage.
given an app for each susi category we use the approach from figure to determine the distance of the app with respect to the benign training set.
the resulting vector of scores maliciogram tells how abnormal the app is in each category.
app1 app2 app??......
app1 app3classifyingtraining classifier app fig.
.
classifying apps across multiple categories.
for each benign app in the google play store we determine its vector of probabilities of being an outlier in each susi category figure .
a one class classifier trained from these vectors can label an unknown app as likely benign if it is normal across all categories or likely malicious instead.
table v ad frameworks whose flows are excluded com.admob.android com.adsdk.sdk com.adsmogo com.aduwant.ads com.applift.playads com.google.ads com.inneractive.api.ads com.mopub.mobileads com.revmob.ads com.smartadserver.android com.swelen.ads de.selfadservice mudflow is unable to detect such advertisement frameworks in presence of code obfuscation.
this problem is in the scope of our future work and will be discussed in section viii.
iv.
a pps and their flow to evaluate mudflow we used two sets of benign and malicious apps for training and classifying.
let us describe these datasets as well as their characteristic flows.
a. apps mined benign apps.
as source for benign apps we used the google play store the most popular app store for android.
for each of the app categories in the store we downloaded the top most popular free applications as of march .
as not all categories had such entries this gave us a total of apps as our initial benign dataset.
malicious apps.
we used two sources for malicious apps malware apps from the genome project .
this is the dataset already used in the chabada project .
the full set of malicious applications from the virusshare database as of march .
our initial malicious set thus contained a total of apps.
b. analysis settings running a precise static taint analysis on real world applications is not without challenges.
in favor of a faster analysisor the ability to analyze a larger application which would otherwise not fit in memory we used the following flowdroid settings no flow across intents.
android apps use special components called intents to implement messaging between components in particular to start activities or provide services in the background.
we do not track flows across intents when sensitive data is sent to an intent the flow is marked with the intent category as a sink explicit flow only.
our static taint analysis settings do not consider conditionals controlling specific flows nor the flows leading to these conditionals.
this is in contrast to information flow analysis which also takes such implicit flow into account flow insensitive alias search .
making the alias search flow insensitive may generate false positives but greatly reduces runtime for large applications maximum access path length of again possibly reducing precision with respect to the default setting of no layout mode ignoring android guicomponents such as input fields as data flow sources no static fields ignoring the tracking of static fields.
all these choices sacrifice some amount of precision for speed and memory.
as a result the list of flows determined by mudflow can have false positives flows that are infeasible during executions as well as false negatives missing flows that actually might be possible but still flowdroid is much more precise than a basic object or context insensitive data flow analysis.
as ever when applying precise static analysis on real world programs with finite time and resources striking a good balance between false positives and false negatives is an important challenge.
let us remind at this point that our goal isto detect anomalies not to prove the presence or absence of flows and thus we can tolerate imprecision as long as the overall results are fine.
still let us state what finite time and resources mean in our setting and why compromises are badly needed.
the main machine we used to run mudflow was a compute server with gb of ram and intel xeon cpu cores far exceeding the standard memory sizes of today s personal computers.
even with all the compromises listed above the server sometimes used all its memory running on all cores for more than hours to analyze one single android app as shown in figure .
overall we had this machine run for two months without interruption to extract data flows from android applications.
c. analysis results a small proportion of downloaded apps proved to be a challenge for precise taint analysis.
of the benign apps were not analyzable apps exceeded the ram limit of gb or the 24hour timeout and apps caused a soot exception while transforming dex bytecode to jimple representation.
of the malicious apps were not analyzable because of corrupted or incomplete apks most frequently the required callgraph size as of edges log scale time in seconds log scale fig.
.
analysis time of benign applications with respect to their call graph sizes.
all times obtained on an intel core machine with gb ram .
android manifest was missing.
we also removed all such nonanalyzable apps from our dataset.
this resulted in final datasets of benign apps and malicious apps.
d. data flow in benign apps table vi summarizes the data flows detected in our set of benign apps.
most interesting .
of all accesses to sensitive data do not end in a sensitive sink.
across the sensitive sinks we detected different data flows i.e.
distinct pairs of code locations accessing a sensitive source apiand a sensitive sink api linked by data flow between them.
the most important source is database information followed by calendar information network information and location information .
this reflects what most android apps are interacting with external services using information maintained in their own databases.
as it comes to the least frequently used sources we find results that reflect programming practices in android.
the source email shows no flows at all which might be surprising considering the number of apps that handle phone calls or e mails.
this is because most e mail accesses take place via imap and pop protocols and thus belong to the network information source category.
the sources system settings and browser information rarely ever end in sensitive sinks.
the most important sinks are log andintent which make up more than of all sinks in sensitive flows.
as discussed in section iv b the intent category means that the data was used by another activity in the app a flow we currently cannot analyze log however is a true sink but it is less harmful as starting from android .
log files can only be accessed by diagnostic and administrative tools.
the data set coming with this paper contains detailed information on all flows showing the exact flows between apis for all of the benign applications.
in benign apps of all sensitive data flows are to logging and inter process communications i.e.
intents .
e. data flow in malicious apps table vii summarizes the data flows detected in our set of malicious apps showing similarities but also importanttable vi data flows in benign applications bysusi categories sourcelogintentnetworkfilesystem settingsaccount settingssms mmsaudionfcsynchronization datacalendar informationlocation informationbluetoothno sensitive sinktotaldatabase information6643617412798108430610003018046313039 calendar information35297199244305189170121507430252083679510 network information47741529122705337852400000278093450310 location information37581242372212001520028014187193035 content resolver1769823742422251240210357263101 unique identifier796514171231500000181931580 account information477264182626602080000103221470 contact information3909200050000000215080 file information25013641450020000092113320 nfc531297600007300001654330 bluetooth information15323001002000006097880 sms mms4200000810000001562790 synchronization data1900000000100001371660 image1500000000000058730 browser information5300000000000190 system settings500000000000026310 no sensitive source14793645028409226263553961123514922262020147259 total1706146315647423168753412233137095139986129376733861050 table vii data flows in our set of malicious applications bysusi categories sourcelogintentnetworkfilesystem settingsaccount settingssms mmsaudionfcsynchronization datacalendar informationlocation informationbluetoothno sensitive sinktotaldatabase information210062536340233232410821200000719061193658 calendar information5649359994746104660000062683722304 network information2993032935174373733118021160000026173931250320 location information2254818311242600681400060801521058677 content resolver989733128597929036890000010176244771 unique identifier109811179660824010579170000049279688844 account information86114502870206000124615480 contact information4122760111058113000002913230 file information7062550012003200000179127960 nfc367200040110000951550 bluetooth information792221060002100001196823070 sms mms331800001170000001853530 synchronization data310000000000030340 image0000000000000000 browser information1512000000000001732000 system settings030000000000038410 no sensitive source50558422232025897232931251603314362013703131078252352 total60696526180540293244043462541363049441114303192541490149460640 differences to the benign apps from table vi.
the most important source here is network information almost twice as prevalent as in benign apps.
calendar information is accessed far less frequently as a sensitive source as is to our surprise account information .
in sinks we also see important differences.
most striking is the sms mms sink more than times as prevalent as in our benign apps.
this reflects the common attack of stealthily sending sms messages to premium numbers allowing the owner of these numbers to earn money from the victim.
as the flows to sms mms indicate the malicious apps also include sensitive data such as unique identifier and contact information in their messages as well as network information such as network mac addresses or simcard information.
given that of our malicious apps use sms as a sink whereas this is the case for only of the benign apps a simple check for the ability to send sms messages would easily weed out of malicious apps with a precision of .
note however that several of such simple checks may bring conflicting classifications also while our benign set is representative in that it encompasses the most popular apps our malicious set is in no way representative for malware actually prevalent in the wild or the types of attacks actually conducted.
in that sense table vii serves as descriptive statistics of the dataset we use for the evaluation of mudflow .
our set of malicious apps differs from the benign apps in terms of sources sinks and flows.
v. e valuation with our datasets of benign and malicious apps available we are now able to evaluate the classifiers in mudflow .
this section reports our results.
a. detecting overall outliers in our first experiment we evaluated the full mudflow classifier as described in section iii c. using fold crossvalidation we repeated the following ten times we trained the classifier on the score vectors from a random of the benign dataset.
the remaining form the testing dataset as well as the whole malicious dataset.
the average results with the svm configured as are as follows true positives malware recognized as such .
true negatives benignware recognized as such .
accuracy apps correctly classified .
mudflow recognizes .
of malware as such with a false positive rate of .
.
as we are most interested in apps that access and send sensitive data we ran a second evaluation on the subset of malicious apps that have at least one flow from a sensitive source to a sensitive sink i.e.
malware leaking sensitive data .
for this sensitive subset we get the following results true positives malware recognized as such .
true negatives benignware recognized as such .
accuracy apps correctly classified .
mudflow recognizes .
of malware leaking sensitive data as such with a false positive rate of .
.
again all these numbers come from one class classification that is no existing malware is used for training.
b. repackaged apps we have seen that mudflow shows good classification results on our malicious samples because they are apparently sufficiently different from the benign apps used for training.
but what happens if we take benign apps and repackage them to include malicious behavior on top of their regular functionality?
these would include all the behavior and flows of the originals plus additional flows and sources from the added malware components.
to this end in our genome set we identified the repackaged apps which in essence are those apps that come with package names matching existing apps from the google play store but include malicious payloads.
this gave us distinct apps which we verified manually to be easily confounded with original benign apps.
of these apps mudflow classified correctly as malicious and three falsely as benign.
in a sample of repackaged apps benign apps with added malicious behavior mudflow identified .
correctly as malicious.
as expected the repackaged apps included flows that would be unusual for benign apps.
the repackaged version of es file manager for instance would include flows from device id or subscriber id to the web as these flows would normally only occur in advertisement libraries section iii d their presence outside of these libraries would immediately flag the application as an anomaly.
c. alternate features an important question regarding mudflow is whether the individual features in our approach are all necessary and whether the expensive static analysis could be replaced by something simpler.
for this purpose we repeated the evaluation of section v a using different features.
notably we checked the classification results using source methods alonetable viii effectiveness of mudflow using different features .
malicious true true features set positives negatives accuracy source methods all .
.
.
sink methods all .
.
.
flow between classes all .
.
.
sensitive .
.
.
flow between methods all .
.
.
sensitive .
.
.
as features as these would not require complex static analysis.
as summarized in table viii data flow between methods as implemented in mudflow and evaluated in section v a shows the best performance across all metrics.
if one wants to save analysis time source methods alone may produce sufficient performance as shown in table viii this results in a true positive rate of .
rather than .
with flows for all apps still showing a low false positive rate.
a classification using source methods alone though is easy to fool as an attacker could repackage an existing app reuse existing sources and divert the flow to other sinks.
yet in our experiment on repackaged apps mudflow performed particularly well section v b .
data flow from sensitive sources as used in mudflow show the best classification results.
d. per category outlier detection as described in section iii c1 the overall mudflow classifier depends on individual per category outlier detectors computing outlier scores for each category.
in this section let us assess the accuracy of these detectors.
for this purpose we computed the area under the roc curve for each outlier detector this value is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.
an area of .
thus represents a perfect test an area of .
represents a worthless test.
table ix shows the size of the categories as well as the area under roccurve numbers.
we see that across all categories the individual classifiers perform very well.
the highest accuracy .
is achieved for apps that use contact information where all malicious apps are higher ranked than benign apps a result partially explained by the imbalance between benign and malicious apps.
for bluetooth information and other categories the outlier detectors work well for balanced sets.
outlier scores in individual categories are good predictors of malicious behavior.
despite their accuracy keep in mind that the individual classifiers only work for applications that also use the appropriate category as a source.
furthermore a single app may get a low benign score in some categories but a high malicious score in others.
this is why mudflow aggregates these scores to provide an overall classification.
e. learning from malware in our final experiment we changed the setting in section iii c1 from the one class svm to a two class svm table ix performance of per category outlier detectors benign malicious area under category apps apps roc curve network information .
database information .
calendar information .
location information .
unique identifier .
file information .
content resolver .
account information .
bluetooth information .
synchronization data .
nfc .
contact information .
browser information .
system settings too few samples sms mms too few samples image too few samples which would be trained with both benign and malicious apps thus exploiting the existence of known malware and their respective flows.
again we used ten fold cross validation each time training the svm with the malicious apps not used in the testing set.
this setting increases the classification accuracy to for sensitive malware that is an even larger fraction of the benign apps and malicious apps would be correctly classified.
by also learning flows from known malware mudflow accuracy increases to for all malware and to for malware leaking sensitive data.
this higher detection rate however is due to our malware set being self similar i.e.
incorporating the same attack schemes again and again.
these attack schemes result in recurring data flows which can be exploited by mudflow in practice though malware not only shares similar attack schemes but even shares code implementing these attacks.
hence to determine similarity with known malware we see data flow as only one feature besides established effective techniques such as code signatures apis used and others all of which could show similar or better detection rates.
as a dissimilarity measure comparing against benignware though our results make data flow a promising feature to detect unusual behavior.
normal and abnormal data flow can be an important factor in malware detection.
vi.
t hreats to validity the main threat to validity in our work is external validity asking how our results generalize to alternate settings.
while our set of benign apps represents the most popular google play store apps across all categories our set of malicious apps stems from collections of malware where each app at some point has been found and identified as malicious but we do not know whether it has ever caused damage before being detected.
we also do not know which android malware is currently in circulation and we do not know its main attack vectors its code features and its possible obfuscationfeatures.
our detection results should thus be seen as a result on a publicly available benchmark and may not necessarily generalize.
a second threat to external validity are deficiencies of our static analysis as discussed in section iv b our analysis may report flows that are infeasible as well as miss flows that are feasible notably implicit flow and flow across components or storages .
this impacts our summaries as shown in table vi and table vii.
our classification mechanisms though would be expected to include misclassifications and thus would be impaired but not threatened by such noise.
vii.
r elated work mudflow mines the usage of sensitive data in android apps and uses this information to detect malicious applications.
mudflow is thus related to the many existing techniques that leverage taint analysis to detect information leaks to android malware detection techniques and to the empirical studies on android stores.
a. information flow analysis for android as mobile devices are a particularly rich store of sensitive data it is not a surprise that much of the mobile security research work has developed taint analysis techniques to detect information leaks.
among the research works that leverage dynamic taint analysis to detect information leaks taintdroid is the de facto state of the art tool for android applications .
thanks to an efficient instrumentation of the android execution environment taintdroid can report without any false positives information leaks in apps even when they involve native code.
dynamic taint analysis has the obvious limitation of reporting only on what has been observed during a limited set of executions.
at the opposite side static taint tracking tools report any information leak that may occur at runtime.
the flowdroid tool described in section ii employs a highly precise static control and data flow analysis of android apps to report both explicit and implicit information flows .
other static taint tracking tools work in a similar fashion but miss several possible information flows since they implement less precise data flow analyses .
other techniques focus on detecting information flows involving inter applications communication and can thus detect when multiple applications can act together to leak sensitive information .
mudflow is orthogonal to all these techniques.
in fact while all these techniques can detect whether there is any information flow in android applications they cannot tell whether such behavior is likely to be malicious or not.
on the other hand mudflow has no ability to detect information flows on its own and therefore needs tools such as flowdroid to collect information regarding the behavior of apps.
b. android malware detection as for any other software platform malware detection received a lot of attention in android.
several techniquesfocus on detecting whether the claimed behavior matches the actual behavior of the application.
some of these techniques use the textual description to understand what an application should do while others analyze the text associated to gui elements .
mudflow instead only requires the binary of the application and therefore can easily be adopted to classify also applications that come without textual descriptions.
moreover all the aforementioned techniques either look at the declared permission in the manifest file or at apicalls to critical functionalities of the android framework.
mudflow instead uses sensitive data flows as features to describe the behavior of an application.
thus instead of knowing whether an application accesses the contact list it knows what the application does with the contact list.
thanks to more precise features mudflow can consequently provide better malware detection abilities.
mudflow is not the first work that uses machine learning techniques to detect malicious android applications.
on the other hand it is the only one together with chabada to train the model only on benign applications .
other techniques such as mast and drebin instead train the classifier only on samples of malware and can therefore be very effective at detecting other samples of similar malware .
differently from mudflow though they are quite ineffective at detecting new types of malware.
similarly techniques that implement static or dynamic analyses to detect known malware features are complementary to mudflow as they are designed to detect known malware .
c. mining of android apps on markets together with a malware classifier for android this paper presents a novel study of the typical information flows of android applications that are popular on the google play market.
other researchers used android markets for empirical studies.
harman et al.
mined the blackberry app store to identify correlations between user rating and ranking of applications .
stevens et al.
analyzed free apps from popular android markets and found a significant correlation between the popularity of a permission and the number of times it is misused .
ruiz et al.
instead study the prevalence of multiple ad libraries in android apps and nagappan et al.
analyze the software reuse in the android mobile app market .
more related to mudflow are the empirical studies of allix et al.
and zhou et al.
on android malware .
shen et al.
employ a static data flow analysis technique to enrich the android permission mechanism with information regarding detected information flows.
to the best of our knowledge their work is the only other work that compares the information flows between benign and malicious applications.
their final goal though is radically different from ours.
viii.
c onclusion and future work mudflow learns normal flows of sensitive data from trusted applications to detect abnormal flows in possiblymalicious applications.
the approach is effective in detecting novel attacks learning from benignware only as well as recognizing known attacks learning from benign as well as malicious samples.
despite data flow analysis being expensive for real world apps we see the flow of sensitive data as a useful abstraction not only for automatic classification but also for end users to understand what an app does with sensitive data.
despite these successes there still are lots of opportunities for improvement.
our own future work will focus on the following topics to fool mudflow malware writers could use reflection native code self decrypting code or other features that challenge static analysis.
usage of such techniques in combination with sensitive data however would be unusual for benign apps.
we are investigating analysis techniques that would detect such obfuscation techniques as anomalies.
while static taint analysis across components and intermediate data storages is difficult it is not fundamentally impossible.
we want to design analysis techniques specifically tailored to app wide and system wide data flows as found in android.
incorporating our earlier chabada work we want to associate flows with app descriptions detecting anomalies within specific application domains such as travel wallpapers and likewise.
where static analysis is challenged combinations of automated test generation and dynamic flow analysis may prove to be helpful alternatives.
we are investigating such combinations in conjunction with static analysis to combine the strengths of both static and dynamic flow analysis.
to support further research in app mining as well as replication and extension of the results in this paper all our mined data as well as the scripts for our statistical analysis are available for download.
for details see our project page acknowledgment.
this work was funded by the german federal ministry of education and research bmbf under grant no.
01ic12s01 as well as by an european research council erc advanced grant specmate specification mining and testing .
the work was also supported by the bmbf within ec spride by the hessian loewe excellence initiative within cased by the dfg s priority program reliably secure software systems and the project dfg runsecure .
florian gross provided the script for downloading the benign apps.
marcel b ohme ulfar erlingsson florian gross matthias h oschele clemens hammacher and kevin streit provided useful feedback on earlier revisions of this paper.