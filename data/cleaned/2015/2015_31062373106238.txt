using bad learners to find good configurations vivek nair north carolina state university raleigh north carolina usatim menzies north carolina state university raleigh north carolina usa norbert siegmund bauhaus university weimar germanysven apel university of passau passau germany abstract finding the optimally performing configuration of a software system for a given setting is often challenging.
recent approaches address this challenge by learning performance models based on a sample set of configurations.
however building an accurate performance model can be very expensive and is often infeasible in practice .
the central insight of this paper is that exact performance values e.g.
the response time of a software system are not required to rank configurations and to identify the optimal one.
as shown by our experiments performance models that are cheap to learn but inaccurate with respect to the difference between actual and predicted performance can still be used rank configurations and hence find the optimal configuration.
this novel rank based approach allows us to significantly reduce the cost in terms of number of measurements of sample configuration as well as the time required to build performance models.
we evaluate our approach with scenarios based on software systems and demonstrate that our approach is beneficial in scenarios for the remaining scenarios an accurate model can be built by using very few samples anyway without the need for a rank based approach.
ccs concepts computing methodologies ranking classification and regression trees software and its engineering model driven software engineering feature interaction software performance keywords performance prediction sbse sampling rank based method acm reference format vivek nair tim menzies norbert siegmund and sven apel.
.
using bad learners to find good configurations.
in proceedings of esec fse paderborn germany september pages.
introduction this paper proposes an improvement of recent papers presented at icse ase and ase which predict system performance permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse september paderborn germany copyright held by the owner author s .
publication rights licensed to association for computing machinery.
acm isbn .
.
.
.
on learning influences of individual configuration options and combinations of thereof .
the idea is to measure a few configurations of a configurable software system and to make statements about the performance of its other configurations.
thereby the goal is to predict the performance of a given configuration as accurate as possible.
we show that if we slightly relax the question we ask we can build useful predictors using very small sample sets.
specifically instead of asking how long will this configuration run?
we ask instead will this configuration run faster than that configuration?
or which is the fastest configuration?
.
this is an important area of research since understanding system configurations has become a major problem in modern software systems.
in their recent paper xu et al.
documented the difficulties developers face with understanding the configuration spaces of their systems .
as a result developers tend to ignore over of configuration options which leaves considerable optimization potential untapped and induces major economic cost .
with many configurations available for today s software systems it is challenging to optimize for functional and non functional properties.
for functional properties chen et.
al and sayyad et.
al developed fast techniques to find near optimal configurations by solving a five goal optimization problem.
henard et.
al used a sat solver along with multi objective evolutionary algorithms to repair invalid mutants found during the search process.
for non functional properties researchers have also developed a number of approaches.
for example it has been shown that the runtime of a configuration can be predicted with high accuracy by sampling and learning performance models .
state of theart techniques rely on configuration data from which it is possible to build very accurate models.
for example prior work has used sub sampling to build predictors for configuration runtimes using predictors with error rates less than quantified in terms ofresidual based measures such as mean magnitude of relative error or mmre pn i ai pi ai nwhere ai piare the actual and predicted values .
figure shows in green a number of realworld systems whose performance behavior can be modelled with high accuracy using state of the art techniques.
recently we have come across software systems whose configuration spaces are far more complicated and hard to model.
for example when the state of the art technique of guo at al.
is applied to these software systems the error rates of the generated predictor is up to see the yellow and redsystems of figure .
the existence of these harder to model systems raises a serious validity question for all prior research in this area was prior research merely solving easy problems?
esec fse september paderborn germany vivek nair tim menzies norbert siegmund and sven apel ss1 ss2 ss3 ss4 ss5 ss6 ss7 ss8 ss9 ss10 ss11 ss12 ss13 ss14 ss15 ss16 ss17 ss18 ss19 ss20 ss21 ss22 software systems10 1100101102mmre mmre figure errors of the predictions made by using cart a machine learning technique refer to section to model different software systems.
due to the results of figure we use of the valid configurations chosen randomly to train test the model.
can we learn predictors for non functional properties of more complex systems?
one pragmatic issue that complicates answering these two questions is the minimal sampling problem .
it can be prohibitively expensive to run and test all configurations of modern software systems since their configuration spaces are very large.
for example to obtain the data used in our experiments we required over a month of cpu time for measuring and much longer if we also count the time required for compiling the code prior to execution .
other researchers have commented that in real world scenarios the cost of acquiring the optimal configuration is overly expensive and time consuming .
hence the goal of this paper must be find predictors for non functional properties for the hardto model systems of figure where learning accurate performance models is expensive.
use as few sample configurations as possible.
the key result of this paper is that even when residual based performance models are inaccurate ranking performance models can still be very useful for configuration optimization.
note that predictive models return a value for a configuration ranking models rank nconfigurations from best to worst .
there are two very practical cases where such ranking models would suffice developers want to know the fastest configuration developers are debating alternate configurations and want to know which might run faster.
in this paper we explore two research questions about constructing ranking models.
rq1 can inaccurate predictive models still accurately rank configurations?
we show below that even if a model has overall a low predictive accuracy i.e.
a high mmre the predictions can still be used to effectively rank configurations.
the rankings are heuristic in nature and hence may be slightly inaccurate w.r.t the actual performance value .
that said overall our rankings are surprisingly accurate.
figure the relationship between the accuracy in terms of mmre and the number of samples used to train the performance model of the apache web server.
note that the accuracy does not improve substantially after sample configurations.
for example when exploring the configuration space of sqlite our rankings are usually wrong only by less than neighboring configurations which is a very small number considering that sqlite has almost million configurations.
rq2 how expensive is a rank based approach in terms of how many configurations must be executed ?
to answer this question we studied the configurations of scenarios based on open source systems.
we measure the benefit of our rank based approach as the percentage of required measurements needed by state of the art techniques in this field see sarkar et al.
presented at ase .
those percentages were as follows note that lower values are better and values under denote an improvement over the state of the art from figure that is the novel rank based approach described in this paper is rarely worse than the state of the art and often far better.
for example as shown later in figure for one of the scenarios of apache storm ss11 the rank based approach uses only of the measurements used by a residual based approach.
the rest of this paper is structured as follows we first formally describe the prediction problem.
then we describe the state of theart approach proposed by sarkar et al.
henceforth referred to as residual based approach followed by the description of our rank based approach.
then the subject systems used in the paper are described followed by our evaluation.
the paper ends with a discussion on why a rank based approach works finally we conclude.
to assist other researchers a reproduction package with all our scripts and data are available on github.
problem formalization a configurable software system has a set xof configurations x x. letxiindicate the ithconfiguration option of configuration x which takes the values from a finite domain dom xi .
in general xiindicates either an i integer variable or a ii boolean variable.
the configuration space is thus dom x1 dom x2 ... dom xn which is the cartesian product of the domains where n x is the number of configuration options of the system.
each configuration 258using bad learners to find good configurations esec fse september paderborn germany progressive sampling def progressive training testing lives for stopping criterion last score independent vals list dependent vals list forcount in range len training add one configuration to the training set independent vals training measure the performance value for the newly added configuration dependent vals measure training set build model model build model independent vals dependent vals test model perf score test model model testing measure testing if current accuracy score is not better than the previous accuracy score then loose life ifperf score last score lives last score perf score if all lives are lost exit loop iflives break return model figure pseudocode of progressive sampling.
x has a corresponding performance measure y yassociated with it.
the performance measure is also referred to as dependent variable.
we denote the performance measure associated with a given configuration by y f x .
we consider the problem of ranking configurations x that such that f x is less than other configurations in the configuration space of xwith few measurements.
f x f x x x x our goal is to find the near optimal configuration of a system where it is not possible to build an accurate performance model as prescribed in earlier work.
residual based approaches in this section we discuss the residual based approaches for building performance models for configurable software systems.
for further details we refer to sarkar et.
al .
.
progressive sampling when the cost of collecting data is higher than the cost of building a performance model it is imperative to minimize the number of measurements required for model building.
a learning curve shows the relationship between the size of the training set and the accuracy of the model.
in figure the horizontal axis represents the number of samples used to create the performance model whereas the vertical axis represents the accuracy measured in terms of mmre of the model learned.
learning curves typically have a steep sloping portion early in the curve followed by a plateau late in the curve.
the plateau occurs when adding data does not improve the accuracy of the model.
as engineers we would like to stop sampling as soon as the learning curve starts to flatten.
projective sampling def projective training testing thres freq collector list independent vals list dependent vals list forcount in range len training add one configuration to the training set independent vals training measure the performance value for the newly added configuration dependent vals measure training set update feature frequency table t update frequency table training build model model build model independent vals dependent vals test model perf score test model model testing measure testing collect the the pair of training set and performance score collector minimum values of the feature frequency table if min t thresh freq break return model figure pseudocode of projective sampling.
figure is a generic algorithm that defines the process of progressive sampling.
progressive sampling starts by clearly defining the data used in the training set called training pool from which the samples would be selected randomly in this case and then tested against the testing set.
at each iteration a set of data instance s of the training pool is added to the training set line .
once the data instances are selected from the training pool they are evaluated which in our setting means measuring the performance of the selected configuration line .
the configurations and the associated performance scores are used to build the model line .
the model is validated using the testing set2 then the accuracy is then computed.
the accuracy can be quantified by any measure such as mmre mbre absolute error etc.
in our setting we assume that the measure is accuracy higher is better .
once the accuracy score is calculated it is compared with the accuracy score obtained before adding the new set of configurations to the training set.
if the accuracy of the model with more data does not improve the accuracy when compared to the previous iteration lesser data then a life is lost.
this termination criterion is widely used in the field of multi objective optimization to determine degree of convergence .
.
projective sampling one of the shortcomings of progressive sampling is that the resulting performance model achieves an acceptable accuracy only after a large number of iterations which implies high modelling cost.
there is no way to actually determine the cost of modelling until the performance model is already built which defeats its purpose as there is a risk of over shooting the modelling budget and still not obtain an accurate model.
projective sampling addresses this 2the testing data consist of the configurations as well as the corresponding performance scores.
259esec fse september paderborn germany vivek nair tim menzies norbert siegmund and sven apel problem by approximating the learning curve using a minimal set of initial sampling points configurations thus providing the stakeholders with an estimate of the modelling cost.
sarkar et.
al used projective sampling to predict the number of samples required to build a performance model.
the initial data points are selected by randomly adding a constant number of samples configurations to the training set from the training pool.
in each iteration the model is built and the accuracy of the model is calculated using the testing data.
a feature frequency heuristic is used as the termination criterion.
the feature frequency heuristic counts the number of times a feature has been selected and deselected.
sampling stops when the counts of features selected and deselected is at least at a predefined threshold thresh freq .
figure provides a generic algorithm for projective sampling.
similar to progressive sampling projective sampling starts with selecting samples from the training pool and adding them to the training set line .
once the samples are selected the corresponding configurations are evaluated line .
the feature frequency table t is then updated by calculating the number of features that are selected and deselected in independent vals line .
the configurations and the associated performance values are then used to build a performance model and the accuracy is calculated lines .
the number of configurations and the accuracy score are stored in the collector since our objective is to estimate the learning curve.
min t holds the minimum value of the feature selection and deselection frequencies in t. once the value of min t is greater than thresh freq the sampled points are used to estimate the learning curve.
these points are used to search for a best fit function that can be used to extrapolate the learning curve there are several available including logarithmic weiss and tian power law and exponential .
once the best fit function is found it is used to determine the point of convergence.
rank based approach typically performance models are evaluated based on the accuracy or error.
the error can be computed using3 mmre predicted actual actual the key idea in this paper is to use ranking as an approach for building regression models.
there are a number of advantages of using a rank based approach for the use cases listed in the introduction ranking is the ultimate goal .
a user may just want to identify the topranked configurations rather than to rank the whole space of configurations.
for example a practitioner trying to optimize an apache web server is searching for a set of configurations that can handle maximum load and is not interested in the whole configuration space.
ranking is extremely robust since it is only mildly affected by errors or outliers .
even though measures such as mean absolute error are robust in the configuration setting a practitioner is often more interested in knowing the rank rather than the predicted performance scores.
3aside there has been a lot of criticism regarding mmre which shows that mmre along with other accuracy statistics such as mmre mbre has been shown to cause conclusion instability .
rank based approach def rank based training testing lives last score independent vals list dependent vals list forcount in range len training add one configuration to the training set independent vals training measure the performance value for the newly added configuration dependent vals measure training set build model model build model independent vals dependent vals predicted performance values predicted performance model testing compare the ranks of the actual performance scores to ranks of predicted performance scores actual ranks ranks measure testing predicted ranks ranks predicted performance mean rd rd actual ranks predicted ranks if current rank difference is not better than the previous rank difference then loose life ifmean rank difference last rank difference lives last rank difference mean rd if all lives are lost exit loop iflives break return model figure psuedocode of rank based approach.
ranking reduces the number of training samples required to train a model .
we will demonstrate that the number of training samples required to find the optimal configuration using a rank based approach is reduced considerably compared to residual based approaches which use mmre.
it is important to note that we aim at building a performance model similar to the accurate performance model building process used by prior work as described in section .
but instead of using residual measures of errors as described in equation which depend on residuals r y f x 4we use a rank based measure.
while training the performance model f x the configuration space is iteratively sampled from the training pool to train the performance model.
once the model is trained the accuracy of the model is measured by sorting the values of y f x from small to large that is f x1 f x2 f x3 ... f xn .
the predicted rank order is then compared to the actual rank order.
the accuracy is calculated using the mean rank difference accuracy n nx i rank yi rank f xi this measure simply counts how many of the pairs in the test data were ordered incorrectly by the performance model f x and measures the average of magnitude of the ranking difference.
in figure we list a generic algorithm for our rank based approach.
sampling starts by selecting samples randomly from the 4refer to section for definitions.
260using bad learners to find good configurations esec fse september paderborn germany training pool and by adding them to the training set line .
the collected sample configurations are then evaluated line .
the configurations and the associated performance measure are used to build a performance model line .
the generated model cart in our case is used to predict the performance measure of the configurations in the testing pool line .
since the performance value of the testing pool is already measured hence known the ranks of the actual performance measures and predicted performance measure are calculated.
lines .
the actual and predicted performance measure is then used to calculate the rank difference using equation .
if the rank difference of the model with more data does not decrease when compared to the previous generation lesser data then a life is lost lines .
when all lives are expired sampling terminates line .
the motivation behind using the parameter lives is to detect convergence of the model building process.
if adding more data does not improve the accuracy of the model for example in figure the accuracy of the model generated does not improve after samples configuration the sampling process should terminate to avoid resource wastage see also section .
.
subject systems to compare residual based approaches with our rank based approach we evaluate it using test cases collected in open source software systems5.
ss1x264 is a video encoding library that encodes video streams to h. mpeg avc format.
we consider features which results in valid configurations.
ss2berkeley db c is an embedded key value based database library that provides scalable high performance database management services to applications.
we consider features resulting in valid configurations.
ss3sqlite is the most popular lightweight relational database management system.
it is used by several browsers and operating systems as an embedded database.
in our experiments we consider features that give rise to more than million valid configurations.
ss4wget is a software package for retrieving files using http https and ftp.
it is a non interactive command line tool.
in our experiments we consider features which result in valid configurations.
ss5lrzip or long range zip is a compression program optimized for large files consisting mainly of an extended rzip step for long distance redundant reduction and a normal compressor step.
we consider features which results in valid configurations.
ss6dune or the distributed and unified numerics environment is a modular c library for solving partial differential equations using grid based methods.
we consider feature resulting in valid configurations.
ss7hsmgp or highly scalable mg prototype is a prototype code for benchmarking hierarchical hybrid grids data structures algorithms and concepts.
it was designed to run on super computers.
we consider features resulting in valid configurations.
5for more details on the subject systems and configurations options refer to http server is a web server we consider features resulting in valid configurations.
in addition to these subject systems we also consider apache storm a distributed system in several scenarios.
the datasets were obtained from the paper by jamshidi et al.
.
the experiment considers three benchmarks namely wordcount wc counts the number of occurences of the words in a text file.
rollingsort rs implements a common pattern in real time analysis that performs rolling counts of messages.
sol sol is a network intensive topology where the message is routed through an inter worker network.
the experiments were conducted with all the above mentioned benchmarks on cloud clusters.
the experiments also contain measurement variabilities the wcexperiments were also carried out on multi tenant cluster which were shared with other jobs.
for example wc rsmeans wcwas deployed in a multi tenant cluster with rsrunning on the same cluster.
as a result not only latency increased but also variability became greater.
the environments considered in our experiments are ss9wc 6d throughput is an environment configuration where wcis executed by varying features resulting in configurations throughput is calculated.
ss10 rs 6d throughput is an environment configuration where rsis run by varying features which results in configurations the throughput is measured.
ss11 wc 6d latency is an environment configuration where wcis executed by varying features resulting in configurations latency is calculated.
ss12 rs 6d latency is an environment configuration where rsis executed by varying features which results in configurations latency is measured.
ss13 wc rs 3d throughput is an environment configuration where wcis run in a multi tenant cluster along with rs.wcis executed by varying features resulting in configurations throughput is measured.
ss14 wc sol 3d throughput is an environment configuration where wcis run in a multi tenant cluster along with sol.wcis executed by varying features resulting in configurations throughput is measured.
ss15 wc wc 3d throughput is an environment configuration where wcis run in a multi tenant cluster along with wc.wcis executed by varying features resulting in configurations throughput is measured.
ss16 sol 6d throughput is an environment configuration where solis executed by varying features resulting in configurations throughput is measured.
ss17 wc wc 3d throughput is an environment configuration where wcis executed by varying features resulting in configurations throughput is calculated.
ss18 wc sol 3d latency is an environment configuration where wcis run in a multi tenant cluster along with sol.
thewcis executed by varying features resulting in configurations latency is measured.
ss19 wc wc 3d latency is an environment configuration where wcis run in a multi tenant cluster along with wc.
261esec fse september paderborn germany vivek nair tim menzies norbert siegmund and sven apel thewcis executed by varying features resulting in configurations latency is measured.
ss20 sol 6d latency is an environment configuration where solis executed by varying features resulting in configuration setting latency is measured.
ss21 wc rs 3d latency is an environment configuration where wcis run in a multi tenant cluster along with rs.
wcis executed by varying features resulting in configurations latency is measured.
evaluation .
research questions in the past configuration ranking required an accurate model of the configuration space since an inaccurate model implicitly indicates that the model has missed the trends of the configuration space.
such accurate models require the evaluation measurement of hundreds of configuration options for training .
there are also cases where building an accurate model is not possible as shown in figure right side .
our research questions are geared towards finding optimal configurations when building an accurate model of a given software system is not possible.
as our approach relies on ranking our hypothesis is that we would be able to find the near optimal configuration using our rank based approach while using fewer measurements as compared to an accurate model learnt using residual based approaches6.
our proposal is to embrace rank preservation but with inaccurate models and to use these models to guide configuration rankings.
therefore to assess the feasibility and usefulness of the inaccurate model in configuration rankings we consider the following accurate rankings found by inaccurate models using a rank based approach and the effort number of measurements required to build an inaccurate model.
the above considerations lead to two research questions rq1 can inaccurate models accurately rank configurations?
here the optimal configurations found using an inaccurate model are compared to the more accurate models generated using residualbased approaches.
the accuracy of the models is calculated using mmre from equation .
rq2 how expensive is a rank based approach in terms of how many configurations must be executed ?
it is expensive to build accurate models and our goal is to minimize the number of measurements.
it is important to demonstrate that we can find optimal configurations of a system using inaccurate models as well as reducing the number of measurements.
.
experimental rig for each subject system we build a table of data one row per valid configuration.
we then run all configurations of all systems and record the performance scores i.e.
that are invoked by a benchmark .
the exception is sqlite for which we measure only 6aside it is worth keeping in mind that the approximation error in a model does not always harm.
a model capable to smoothing the complex landscape of a problem can be beneficial for the search process.
this sentiment has been echoed in the evolutionary algorithm literature as well .configurations corresponding to feature wise and pair wise sampling and additionally random configurations.
this is because sqlite has possible configurations which is an impractically large number of configurations to test.
to this table we added a column showing the performance score obtained from the actual measurements for each configuration.
note that while answering the research questions we ensure that we never test any prediction model on the data that we used to learn the model.
next we repeat the following procedure times.
to answer the research questions we split the datasets into training pool testing pool and validation pool .
the experiment is conducted in the following way randomize the order of rows in the training data do select one configuration by sampling with replacement and add it to the training set determine the performance scores associated with the configuration.
this corresponds to a table look up but would entail compiling or configuring and executing a system configuration in a practical setting.
using the training set and the accuracy build a performance model using cart.
using the data from the testing pool assess the accuracy either using mmre as described in equation or the rank difference as described in equation .
while the accuracy is greater or equal to the threshold determined by the practitioner rank difference in the case of our rank based approach and mmre in the case of the residual based approaches .
once the model has been iteratively trained it is used on the data in the validation pool.
please note the learner has not been trained on the validation pool.
rq1 relates the results found by the inaccurate performance models rank based to more accurate models residual based .
we use the absolute difference between the ranks of the configurations predicted to be the optimal configuration and the actual optimal configuration.
we call this measure rank difference rd .
rd rank actual optimal rank predicted optimal ranks are calculated by sorting the configurations based on their performance scores.
the configuration with the least performance score rank actual optimal is ranked and the one with highest score is ranked as n where nis the number of configurations.
results .
rq1 can inaccurate models accurately rank configurations?
figure shows the rdof the predictions built using the rank based approach and residual based approaches7by learning from of the training set and iteratively adding data to the training set from the training pool while testing against the testing set .
the model is then used to find the optimal configuration among the configurations in the validation dataset .
the horizontal axis 7the mmre scores for the models 262using bad learners to find good configurations esec fse september paderborn germany figure the rank difference of the prediction made by the model built using residual based and rank based approaches.
note that the yaxis of this chart rises to some very large values e.g.
ss3 has over three million possible configurations.
hence the above charts could be summarised as follows the rank based approach is surprisingly accurate since the rank difference is usually close to of the total number of possible configurations .
in this figure and represent the subject systems using the technique mentioned at the top of the figure in which we could build a prediction model where accuracy is mmre and respectively.
this is based on figure .
rank treatment median iqr median and iqr chart ss1 projective .
.0s progressive .
.0s rank based .
.0s ss2 projective .
.0s rank based .
.0s progressive .
.0s ss3 progressive .
.0s projective .
.0s rank based .
.
s ss11 progressive .
.0s rank based .
.0s projective .
.0s ss20 projective .
.0s progressive .
.0s rank based .
.0s figure median rank difference of repeats.
median ranks is the rank difference as described in equation and iqr the difference between 75th percentile and 25th percentile found during multiple repeats.
lines with a dot in the middle s show the median as a round dot within the iqr.
all the results are sorted by the median rank difference a lower median value is better.
the left hand column rank ranks the various techniques for example when comparing various techniques for ss1 a rank based approach has a different rank since their median rank difference is statistically different.
shows subject systems.
the vertical axis shows the rank difference rd from equation .
in this figure the perfect performance model would be able to find the optimal configuration.
hence the ideal result of this figure would be if all the points lie on the y 0or the horizontal axis.
that is the model was able to find the optimal configuration for all the subject systems rd .
the markers and represent the software systems where a model with a certain accuracy can be built measured in mmre is mmre and respectively.
overall in figure we find that the represents software systems where the performance models are inaccurate mmre and still can be used for ranking configurations since the rank difference of these systems is always less than .
hence even an inaccurate performance model can rank configurations.
all three models built using both rank based and residualbased approaches are able to find near optimal configurations.
for example progressive sampling for sqlite predicted the configuration whose performance score is ranked 9th in the testing set.
this is good enough since progressive sampling is able to find the 9th most performant configuration among configurations8.
the mean rank difference of the predictedoptimal is .
.
and .939for the rank based approach progressive sampling and projective sampling respectively.
thus a performance model can be used to rank configurations.
we claim that the rank of the optimal configuration found by the residual and rank based approaches is the same.
to verify that the similarity is statistically significant we further studied the results using non parametric tests which were used by arcuri and briand at icse .
for testing statistical significance we used a non parametric bootstrap test with confidence followed by an a12 test to check that any observed differences were not trivially small effects that is given two lists xandy count how often there are larger numbers in the former list and if there are ties add a half mark a x x y y x y .
x y x y as per vargha we say that a small effect has a .
.
lastly to generate succinct reports we use the scott knott test to recursively divide our approaches.
this recursion used a12 and bootstrapping 8since we test only on of the possible configuration space of .
9the median rank difference is for all the approaches.
263esec fse september paderborn germany vivek nair tim menzies norbert siegmund and sven apel figure number of measurements required to train models by different approaches.
the software systems are ordered based on the accuracy scores of figure .
to group together subsets that are a not significantly different and are b not just a small effect different to each other.
this use of the scott knott test is endorsed by mittas and angelis and by hassan et al.
.
in figure the table shows the scott knott ranks for the three approaches.
the quartile charts are the scott knott results for our subject systems where the rank based approach did not do as well as the residual based approaches10.
for example the statistic test for ss1 shows that the ranks of the optimal configuration by the rank based approach was statistically different from the ones found by the residual based approaches.
we think this is reasonably close since the median rank found by the rank based approach is out of configurations whereas residual based approaches find the optimal configurations with a median rank of .
as our motivation was to find optimal configurations for software systems for which performance models were difficult or infeasible to build we look at ss20.
if we look at the skott knott chart for ss20 the median rank found by the rank based approach is whereas the residual based approaches could find the optimal configurations very consistently iqr .
but as engineers we feel that this is close because we are able to find the 5th best configuration using measurements compared to and measurements used for progressive and projective sampling respectively.
overall our results indicate that a rank preserving probably inaccurate model can be useful in finding near optimal configurations of a software system using a rank based approach.
.
rq2 how expensive is a rank based approach?
to answer the question of whether we can recommend the rankbased approach as a cheap method for finding the optimal configuration it is important to demonstrate that rank based models are indeed cheap to build.
in our setting the cost of a model is determined by the number of measurements required to train the model.
figure demonstrates this relationship.
the vertical axis 10for complete skott knott charts refer to the number of measurements in log scale and horizontal axis represents the subject systems.
in the systems ss1 ss4 green band the number of measurements required by the rank based approach is less than for projective sampling and more than for progressive sampling.
this is because the subject systems are easy to model.
for the systems ss4 ss13 yellow band the number of measurements required to build models using the rank based approach is less than residual based approaches with the exception of ss8.
note that as building accurate models becomes difficult the difference between the number of measurements required by the rank based approach and residualbased approaches increases.
for the systems ss14 ss21 red band the number of measurements required by the rank based approach to build a model is always less than for residual based approaches with significant gains for ss19 ss21.
in figure the ratio of the measurements of different approaches are represented as the percentage of number of measurements required by projective sampling since it uses the most measurements in of the subject systems.
for example in ss5 the number of measurements used by progressive sampling is twice as much as used by projective sampling whereas the rank based approach uses half of the total number of measurements used by projective sampling.
we observe that the number of measurements required by the rank based approach is much lower than for the residual based approaches with the only exceptions of ss4 and ss8.
we argue that such outliers are not of a big concern since the motivation of rank based approach is to find optimal configurations for software systems where an accurate model is infeasible.
to summarize the number of samples required by the rankbased approach is much smaller than for residual based approaches.
there are4 21cases where residual based approaches progressive sampling use fewer measurements.
the subject systems where residual based approaches use fewer measurements are systems where accurate models are easier to build green and yellow band models built using the rank based approach require fewer measurements than residual based approaches.
in8 21of the 264using bad learners to find good configurations esec fse september paderborn germany figure the percentage of measurement used for training models with respect to the number of measurements used by projective sampling dashed line .
the rank based approach uses almost times less measurements than the residual based approaches.
the subject systems are ordered based on the accuracy scores of figure .
figure the correlation between actual and predicted performance values not ranks increases as the training set increases.
this is evidence that the model does learn as training progresses.
cases the number of measurements is an order of magnitude smaller than residual based approaches.
discussion .
how is rank difference useful in configuration optimization?
the objective of the modelling task considered here is to assist practitioners to find optimal configuration s. we use a performance model like traditional approaches to solve this problem but rather than using a residual based accuracy measure we use rank difference.
rank difference can also be thought as a correlation based metric since rank difference essentially tries to preserve the ordering of performance scores.
in our rank based approach we do not train the model to predict the dependent values of the testing set.
but rather we attempt to train the model to predict the dependent value that is correlated tothe actual values of the testing set.
so during iterative sampling based on the rank based approach we should see an increase in the correlation coefficient as the training progresses.
figure shows how the correlation between actual and the predicted values increases as the size of the training set grows.
from the combination of figure and figure we see that even an inaccurate model can be used to find an optimal configuration.
.
can inaccurate models be built using residual based approaches?
we have already shown that a rank preserving probably inaccurate model is sufficient to find the optimal configuration of a given system.
mmre can be used as a stopping criterion but as we have seen with residual based approaches they require a larger training set and hence are not cost effective.
this is because with residualbased approaches unlike our rank based approach it is not possible to know when to terminate sampling.
it may be noted that rank difference can be easily replaced with a correlation based approach such as pearson s or spearman s correlation.
.
can we predict the complexity of a system to determine which approach to use?
from our results we observe that a rank based approach is not as effective as the residual based approaches for software systems that can be modelled accurately green band .
hence it is important to distinguish between software systems where the rank based approach is suitable and software systems where residual based approaches are suitable.
this is relatively straight forward since both rank based and residual based approaches use random sampling to select the samples.
the primary difference between the approaches is the termination criterion.
the rank based approach uses rank difference as the termination criterion whereas residual based approaches use criterion based on mmre etc.
hence it is possible to use both techniques simultaneously.
if a practitioner observes 11this also shows how a correlation based measure can be used as a stopping criterion.
265esec fse september paderborn germany vivek nair tim menzies norbert siegmund and sven apel figure the trade off between the number of measurements or size of the training set and the number of lives.
that the accuracy of the model during the building process is high as in case of ss2 residual based approaches would be preferred.
conversely if the accuracy of the model is low as in the case of ss21 the rank based approach would be preferred.
.
what is the trade off between the number of lives and the number of measurements?
our rank based approach requires that the practitioner defines a termination criterion lives in our setting before the sampling process commences which is a similar to progressive sampling.
the termination criterion preempts the process of model building based on an accuracy measure.
the rank based approach uses rank difference as the termination criterion whereas residual based approaches use residual based measures.
in our experiments the number of measurements or the size of the training set depends on the termination criterion lives .
an early termination of the sampling process would lead to a sub optimal configuration while late termination would result in resource wastage.
hence it is important to discuss the trade off between the number of lives and the number of measurements.
in figure we show the tradeoff between the median minimum ranks found and the number of measurements size of training set .
the markers of the figure are annotated with the values of lives.
the trade off characterizes the relationship between two conflicting objectives for example point lives requires very few measurements but the minimum rank found is the highest whereas point lives requires a large number of measurements but is able to find the best performing configuration.
note this curve is an aggregate of the trade off curves of all the software systems discussed in this paper12.
since our objective is to minimize the number of measurements while reducing rank difference we assign the value of 3tolives for the purposes of our experiments.
reliability and validity reliability refers to the consistency of the results obtained from the research.
for example how well can independent researchers reproduce the study?
to increase external reliability we took care 12complete trade off curves can be found at or either clearly define our algorithms or use implementations from the public domain scikit learn .
also all data and code used in this work are available on line.
validity refers to the extent to which a piece of research actually investigates what the researcher purports to investigate .internal validity is concerned with whether the differences found in the treatments can be ascribed to the treatments under study.
for sqlite we cannot measure all possible configurations in reasonable time.
hence we sampled only configurations to compare prediction and actual values.
we are aware that this evaluation leaves room for outliers and that measurement bias can cause false interpretations .
since we limit our attention to predicting performance for a given workload we did not vary benchmarks.
we aimed at increasing external validity by choosing subject systems from different domains with different configuration mechanisms.
furthermore our subject systems are deployed and used in the real world.
conclusion configurable systems are widely used in practice but it requires careful tuning to adapt them to a particular setting.
state of the art approaches use a residual based technique to guide the search for optimal configurations.
the model building process involves iterative sampling used along with a residual based accuracy measure to determine the termination point.
these approaches require too many measurements and hence are expensive.
to overcome the requirement of a highly accurate model we propose a rank based approach which requires a lesser number of measurements and finds the optimal configuration just by using the ranks of configurations as an evaluation criterion.
our key findings are the following.
first a highly accurate model is not required for configuration optimization of a software system.
we demonstrated how a rank preserving possibly even inaccurate model can still be useful for ranking configurations whereas a model with accuracy as low as can be useful for configuration ranking.
second we introduce a new rank based approach that can be used to decide when to stop iterative sampling.
we show how a rank based approach is not trained to predict the raw performance score but rather learns the model so that the predicted values are correlated to actual performance scores.
to compare the rank based approach to the state of the art residual based approaches projective and progressive sampling we conducted a number of experiments on real world configurable systems to demonstrate the effectiveness of our approach.
we observed that the rank based approach is effective to find the optimal configurations for most subject systems while using fewer measurements than residual based approaches.
the only exceptions are subject systems for which building an accurate model is easy anyway.
acknowledgement the work is partially funded by an nsf award .
siegmund s work is supported by the dfg under the contract si .
apel s work is supported by the dfg under the contract ap and ap .
266using bad learners to find good configurations esec fse september paderborn germany