city univ ersity of new y ork cun y city univ ersity of new y ork cun y cun y academic w orks cun y academic w orks publications and resear ch hunter college going big a lar ge scale study on what big data de velopers ask going big a lar ge scale study on what big data de velopers ask mehdi bagherzadeh oakland univ ersity raffi t .
khatchadourian cun y hunter college how does access t o this work benefit y ou?
let us know!
more information about this work at https academicworks.cuny .edu hc pubs disco ver additional works at https academicworks.cuny .edu this work is made publicly a vailable b y the city univ ersity of new y ork cun y .
contact academicw orks cuny .edu going big a large scale study on what big data developers ask mehdi bagherzadeh oakland university usa mbagherzadeh oakland.eduraffi khatchadourian hunter college city university of new york usa raffi.khatchadourian hunter.cuny.edu abstract software developers are increasingly required to write big data code.
however they find big data software development challenging.
to help these developers it is necessary to understand big data topics that they are interested in and the difficulty of finding answers for questions in these topics.
in this work we conduct a large scale study on stackoverflow to understand the interest and difficulties of big data developers.
to conduct the study we develop a set of big data tags to extract big data posts from stackoverflow use topic modeling to group these posts into big data topics group similar topics into categories to construct a topic hierarchy analyze popularity and difficulty of topics and their correlations and discuss implications of our findings for practice research and education of big data software development and investigate their coincidence with the findings of previous work.
ccs concepts general and reference empirical studies theory of computation concurrency .
keywords big data topics big data topic hierarchy big data topic difficulty big data topic popularity stackoverflow acm reference format mehdi bagherzadeh and raffi khatchadourian.
.
going big a largescale study on what big data developers ask.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
.
introduction big data computing is coming to us all fisher et al.
software developers are increasingly required to write big data code to process and analyze the data that is now abundantly available in a variety of disciplines ranging from science to commerce to national security .
for example a big data software is required to analyze behaviors of large populations of amazon s users when interacting permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn .
.
.
.
different shopping cart interfaces on its website .
such analysis convinced amazon to add a feature to its shopping cart that shows personalized recommendations using items in the cart and increase its revenue by worth hundreds of millions of dollars .
similarly big data software is required to analyze behaviors of large populations of zynga s users when playing online games to allow zynga for immediate update of their games to create and sell game extras such as a translucent anglerfish .
however developers find big data software development challenging .
to help developers with writing big data software it is necessary to understand the topics that they are interested in and their difficulty in finding answers to questions in these topics.
this understanding not only can help these developers and their practice but also the research and education of big data software development by allowing these communities to better decide when and where to focus their efforts.
without such understanding practitioners may not prepare for similar difficulties researchers may make incorrect assumptions and educators may teach the wrong topics.
with more than million developer participants and million of their questions and answers stack overflow has become a great source to learn about topics that real world developers are interested in and their difficulties in finding answers to questions in these topics .
in this work we conduct a large scale study on stackoverflow to understand the interest and difficulties of big data developers by answering the following research questions rq1.
big data topics what big data topics do developers ask questions about?
rq2.
big data topic hierarchy can these topics be organized into a hierarchy of topics?
rq3.
big data topic popularity what topics are more and less popular among big data developers?
rq4.
big data topic difficulty what topics are more and less difficult to find answers to their questions?
rq5.
correlation of topic popularity difficulty how do popularity and difficulty of big data topics correlate?
to answer these questions we first develop a set of big data tags to extract big data questions and answers from stackoverflow.
second we use topic modeling and open card sort to group these questions and answers into big data topics.
third using the open card sort we group similar topics into categories to construct a topic hierarchy.
fourth we measure the popularity and difficulty of these topics using several well known metrics from previous work and analyze their correlations.
finally weesec fse august tallinn estonia mehdi bagherzadeh and raffi khatchadourian discuss the implications of our findings for the practice research and education of big data software development.
we also investigate the coincidence of our findings with the findings of previous work.
a few findings of our study are big data topics big data developers ask questions about a broad spectrum of topics including mapreduce model debugging basic concepts performance andstream processing .
developers find even the basics of big data software development challenging.
developers ask more about debugging than performance .
big data topic hierarchy big data questions can be grouped into a hierarchy with higher level categories programming storage configuration analysis debugging basic concepts performance stream processing andlogging .
big data topic popularity file management andlogging are among the most and least popular big data topics.
big data topic difficulty connection management anddataframe are among the most and least difficult big data topics.
correlation of topic popularity difficulty there is no statistically significant correlation between the popularity and difficulty of big data topics.
coincidence of findings with previous work some of our findings agree with findings of previous work while others are new.
our dataset is available at methodology figure shows an overview of the methodology of our study.
determine popularity difficulty correlationsdownload stackoverflow dataset preprocess big data questions answers determine big data topic popularity rq3 determine big data topic difficultymallet ldause1 87rq1 rq5 9identify big data questions answers model label topics rq4construct big data topic hierarchy rq2 develop big data tag set figure an overview of the methodology of our study.
step download stackoverflow dataset in this step of our analysis we download the stackoverflow dataset s .
the dataset sincludes stackoverflow question and answer posts and their metadata.
the metadata of a post includes its identifier its question or answer type title body tags creation date view and favorite counts score and the identifier of the accepted answer for the post if the post is a question.
an answer to a question is an accepted answer if the developer who posted the question marks it as accepted.
a question can have to tags.
our dataset sincludes questions and answers posted over years during august to december by developer participants of stackoverflow.
among these posts .
are questions and are answers and among these answers .
are marked as accepted answers.
step develop big data tag set in this step of our analysis we develop a set of big data tags tto identify and extract big data questions in stackoverflow.
first we start with a tag set tinitthat includes our initial big data tags.
second we extract questions pfrom our dataset swhose tags match a tag in tinit.
third we construct a set of candidate tags tby extracting tags of questions inp.
finally we refine tby keeping tags that are significantly relevant to big data and exclude others.
we use two heuristics and from previous work to measure the significance and relevance of a tag tin the big data tag set t. significance of questions with tag t in p of questions with tag t in s relevance of questions with tag t in p of questions in p a tag tis significantly relevant to big data if its and are higher than specific thresholds.
our experiments with a broad range of threshold values .
.
.
.
.
.
and .
.
.
.
.
.
show that .2and .005allow for a significantly relevant set of big data tags.
these threshold value are inline with values used in previous work .
we use tinit hadoop to construct the tag set thadoop for tags related to hadoop and services in its ecosystem using the above tag development approach.
similarly we use tinit apache spark to construct tspark for tags related to spark and its ecosystem.
our final big data tag set tis the union of thadoop andtspark .
thadoop amazon emr ambari apache pig bigdata cloudera cloudera cdh elastic map reduce emr flume hadoop hadoop partitioning hadoop streaming hadoop2 hbase hdfs hdinsight hive hiveql hue impala mahout hortonworks data platform mapreduce oozie sqoop yarn tspark amazon emr apache spark apache spark .
apache spark dataset apache spark ml apache spark mllib apache spark sql apache zeppelin emr databricks parquet pyspark pyspark sql rdd spark cassandra connector spark dataframe spark graphx spark streaming sparklyr spark structured streaming spark submit sparkr yarn t thadoop tspark we choose hadoop andapache spark tags as our initial tags because hadoop and spark are industry s standard ecosystems for big data software development to date used by companies such as amazon ebay twitter linkedin ibm adobe and nasa jpl.
also hadoop and spark are large ecosystems each containing several services for big data software development.
our big data tag set tis very broad and covers a large spectrum of services in hadoop and spark ecosystems used in big data software development.
a few of these services are ambari for cluster management flume for log analysis mahout andapache spark ml for machine learning oozie for workflow management spark streaming for stream processing and yarn for resource management.
our tag set talso includes generic tags such as bigdata .going big a large scale study on what big data developers ask esec fse august tallinn estonia there tags in t. table shows tag sets for select significance and relevance values.
step extract big data posts in this step we use our big data tag set tto extract our set bof big data questions and answers from stackoverflow.
a stackoverflow question is a big data question if it has a tag that belongs to t. the preliminary set of our big data posts includes question and answers among these answers .
are accepted answers.
to construct b we select questions and their accepted answers from this preliminary set.
to reduce noise following previous work we do not include unaccepted answers in b. the final set of big data b includes stackoverflow questions and answers of which .
are questions and .
are accepted answers.
step preprocess big data post set in this step we preprocess the set of big data posts bto reduce the noise for the next step of the analysis.
first we remove code snippets marked with code code html tags such as paragraph and url tags p p and a a stop words such as a the and is numbers punctuation marks and non alphabetical characters.
we use mallet s list of stop words .
second we use porter stemmer to reduce words to their stemmed representations.
for example configuration configure and configured all reduce to configr .
step model and label big data topics in this step we use mallet with latent dirichlet allocation lda topic modeling to group our big data posts binto topics.
in our topic model a big data post is a probabilistic distribution of several topics with different proportions.
a topic is a set of frequently co occurring words that approximates a real world concept.
mallet groups posts into ktopics after igrouping iterations and returns a set of topics and their proportions for each post and a set of words for each topic.
a post has a dominant topic that covers the biggest proportion of the post.
our experiments with a broad range of values k andi show that k 30andi 000allow for sufficiently granular topics for our big data posts b. these values are inline with values used by previous work .
smaller values of kallow for undesirable combination of multiple unrelated topics into a single topic and large values of kallow for breaking down of a single topic into multiple similar topics.
for example with k 10mallet undesirably combines two unrelated memory management andstream processingtopics into a larger topic and with k 40it breaks down the dependency management topic into two smaller topics.
mallet uses hyperparameters and to control the distribution of words in topics and distributions of topics in posts.
we use standard values kand0.01for these hyperparameters following previous work because bigger et al.
show that and have little influence on the accuracy of the lda .
mallet groups big data posts in binto topics tthat are a set of words but cannot decide about the meaning of a topic and label the topic with a name useful for humans.
to illustrate the word set w model spark vector mahout train featur data matrix algorithm user mllib predict recommend cluster item set dataset label similar code represents a topic in mallet.
following previous work we use an open card sort to label topics.
in open card sort there is no predefined topics and topics are developed during the labeling process.
to label atopic we manually inspect the top words in the set of words for the topic and read through random posts for that topic to come up with a label that best explains words and posts of the topic.
to illustrate we label the word set wwith machine learning topic.
number of topic words and random posts are inline with previous work .
table shows our big data topics their names and top stemmed words.
we merge topics and into debugging and topics and into mapreduce model due to similarities between their words and questions.
our final set of big data topics includes topics.
step answers the research question rq1 .
during the card sort process the authors individually assign labels to topics and reiterate and refine labels until they agree on topic labels.
a third non author collaborator reviews topic labels provides suggestions and approves the labels after integration of his suggestions.
the first author is a software engineer and programming languages professor with extensive expertise in concurrent systems of which big data systems are an instance of.
the second author is a software engineer professor with extensive expertise in streaming and parallel systems.
the authors also have several years of industrial experience working as software engineers.
the nonauthor collaborator is a ph.d. senior software engineer at google with extensive research and programming expertise in concurrent and big data systems especially flumejava.
step construct big data topic hierarchy in this step we use a similar card sort process to construct a hierarchy of big data topics by repeated grouping of similar topics into lower and higher level categories.
to illustrate dataframe andrdd are grouped into the lower level category dataset .
lower level category dataset itself is grouped with primitive category into datatype which itself is grouped with mapreduce model languages and general programming into the higher level category programming .
table and figure show the hierarchy of big data topics textually and graphically.
step answers the research question rq2 .
step determine big data topic popularity we use wellknown metrics used by previous work to measure the popularity of a big data topic.
the first metric is the average number of views for all the questions of a topic .
the number of views includes both registered users and visitors of stackoverflow.
the inclusion of views by visitors is important because in stackoverflow there are many more visitors than registered users .
the second metric is the average number of questions of a topic that are marked by users as a favorite question .
the third metric is the average score of questions of a topic .
intuitively a topic with higher number of views and favorites and a higher score is more popular.
table shows the popularity of our big data topics.
step answers the research question rq3 .
step determine topic difficulty we use well known metrics used by previous work to measure the difficulty of a big data topic.
the first metric is the percentage of questions of a topic that have no accepted answers .
the second metric is the average median time needed for questions of a topic to receive accepted answers .
intuitively a topic with less accepted answers received in longer amount of time is more difficult.
table shows the difficulty of our big data topics.
step answers the research question rq4 .
step determine correlation of topic popularity difficulty in this step we use kendall correlation to identify if there isesec fse august tallinn estonia mehdi bagherzadeh and raffi khatchadourian table thadoop andtspark tag sets for select relevance and significance threshold values.
final tag sets are in gray.
thadoop set of tags for hadoop no.
.
.
apache pig bigdata cloudera hadoop hadoop streaming hadoop2 hbase hdfs hive hiveql hortonworks data platform mapreduce oozie sqoop yarn15 .
.
apache pig bigdata cloudera cloudera cdh flume hadoop hadoop streaming hadoop2 hbase hdfs hive hiveql hortonworks data platform mahout mapreduce oozie sqoop yarn18 .
.
amazon emr ambari apache pig bigdata cloudera cloudera cdh elastic map reduce emr flume hadoop hadoop partitioning hadoopstreaming hadoop2 hbase hdfs hdinsight hive hiveql hortonworks data platform hue impala mahout mapreduce oozie sqoop yarn26 tspark set of tags for spark no.
.
.
apache spark apache spark mllib apache spark sql pyspark pyspark sql rdd spark dataframe spark streaming yarn .
.
apache spark apache spark dataset apache spark ml apache spark mllib apache spark sql parquet pyspark pyspark sql rdd sparkcassandra connector spark dataframe spark streaming spark structured streaming yarn14 .
.
amazon emr apache spark apache spark .
apache spark dataset apache spark ml apache spark mllib apache spark sql apache zeppelin databricks emr parquet pyspark pyspark sql rdd spark cassandra connector spark dataframe spark graphx spark streaming sparkstructured streaming spark submit sparklyr sparkr yarn23 a statically significant correlation between popularity and difficulty of our big data topics.
we use kendall because it is less sensitive to outliers and therefore relatively more stable.
in total we investigate correlations between popularity metrics and difficulty metrics for big data topics.
step answers the research question rq5 .
results in this section we discuss the results of our study for research questions rq1 rq5 .
we also investigate the coincidence of our findings with the findings of previous work.
.
rq1 big data topics table shows the big data topics that developers ask questions about on stackoverflow determined in step of our study.
according to table developers ask questions about a broad spectrum of big data topics including mapreduce model debugging basic concepts performance andstream processing .
the meaning of a big data topic is best understood by looking at questions that belong to the topic.
to illustrate the following is a question with stackoverflow identifier in mapreduce model topic in which the developer is asking about chaining mapreduce jobs where the output of the reduce phase in a preceding job in the chain is the input of the mapper phase in the following job.
this question has been viewed times more than times the average number of views for a stackoverflow question.
the average number of views for a stackoverflow question is .
q. chaining multiple mapreduce jobs in hadoop in many real life situations where you apply mapreduce the final algorithms end up being several mapreduce steps.
i.e.
map1 reduce1 map2 reduce2 .. .
so you have the output from the last reduce that is needed as the input for the next map.
what is the recommended way of that in hadoop?
mapreduce is a programming model for parallel processing of big data in a cluster of distributed machines.
in mapreduce a program is divided into map and reduce functions that map data into a collection of key and value pairs and reduce these pairs by their keys.
mapreduce is the programming model for hadoop and spark.
similarly the following is a question with views in machine learning topic in which the developer is asking about automatic validation of a classifier built using random forest.
random forst is a learning and classification technique that constructs a setof decision trees during its training and outputs the class that is the mode of the classes output by these trees.
q. how to cross validate randomforest model?
i want to evaluate a random forest being trained on some data.
is there any utility in apache spark to do the same or do i have to perform cross validation manually?
finally the following is a question with views in logging topic in which the developer is asking about batching up and moving seconds worth of logging information into a file in hadoop distributed filesystem hdfs using flume ng.
hdfs is the hadoop file system for distributed storage and retrieval of big data files in a cluster of machines.
flume ng is a service for efficient collection aggregation and moving of log data.
q. using an hdfs sink and rollinterval in flume ng to batch up seconds of log information i am trying to use flume ng to grab seconds of log information and put it into a file in hdfs.
i have flume working to look at the log file .. however it is creating a file every seconds instead of .. every seconds.
finding developers ask questions about a broad spectrum of big data topics including mapreduce model debugging basic concepts performance andstream processing .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mapreduce model dataframe debugging hive job management dependency management basic concepts connection mgmt dataset load export rdd file management performance general programming machine learning file distribution string file format stream processing memory management pyspark date time pig database import export data organization text search hbase scala spark loggingaverage bigdata topicsnum of questions in thousands figure big data topics and number of their questions.
figure shows the numbers of questions that developers ask about our big data topics.
according to figure the number ofgoing big a large scale study on what big data developers ask esec fse august tallinn estonia table topic labels categories separated by and top stemmed words of our big data topics.
no.
topic name category topic words memory management configuration memori executor task job spark run core node yarn set pig analysis pig script oozi job workflow action run error shell apach connection management configuration connect hadoop server instal cloudera configur user cluster run error dataset load store storage transfer file data spark read json csv parquet load schema write data organization datatype dataset partit join data number case oper kei set shuffl order scala spark programming languages scala spark org apach java sql appli anonfun rdd iwc pyspark programming languages python pyspark spark zeppelin error run notebook instal packag azur dataframe datatype dataset column datafram row spark pyspark data valu function join creat file distribution storage file system node hadoop cluster namenod hdf datanod start run master slave general programming programming class function method object call code type pass work creat debugging debugging error code run work problem issu except fail spark log hbase storage hbase tabl row region zookeep client scan phoenix data server job management configuration spark run cluster job applic submit yarn master emr mode file format storage file system file line read input split text block size data process file management storage file system file hdf directori path hadoop folder local command creat copi string datatype primitive string type field arrai null column valu convert charact data database import export storage transfer sqoop cassandra import tabl data connect jdbc mysql databas connector stream processing stream processing stream spark kafka data messag batch process topic consum read basic concepts basic concepts data hadoop store process question system databas solut support work date time datatype primitive date time timestamp dai data month year format event record logging logging info flume log java org channel apach sink agent sourc performance performance data time perform memori process larg size take run million text search analysis index document mongodb queri collect user elasticsearch search mongo result dependency management configuration jar hadoop version spark java error run depend file build debugging debugging java org apach hadoop lang run mapr util main reflect machine learning analysis model spark vector mahout train featur data matrix algorithm user hive analysis hive tabl queri creat data sql select insert partit column mapreduce model programming kei group count valu list result word sort output function mapreduce model programming reduc job map hadoop mapreduc mapper output run input task rdd datatype dataset rdd spark transform code function scala map creat datafram oper questions that developers ask for big data topics are not uniform.
developers ask the most number of questions .
about mapreduce model and the least number of questions .
about logging .
the average number of questions for a big data topic is about .
finding developers ask the most questions about mapreduce model and the least about logging topic.
mapreduce model according to figure developers ask the most questions about mapreduce model .
this may show that big data developers find mapreduce programming challenging.
mapreduce makes big data programming easier by abstracting away details about fault tolerant distribution of both computation and data over a cluster of machines.
however developers still need to understand how to divide and combine computations using mappers and reducers and compose mappers and reducers into complex computational logics over key and value pairs.
mapreduce is the dominant programming model for big data programming.
inmapreduce model topic developers ask questions like what is the purpose of shuffling and sorting phase in the reducer in map reduce programming?
and simple explanation of mapreduce?
.
debugging in figure debugging is the third topic in the number of questions that developers ask.
this may show that developers find debugging of big data software rather challenging.
this observation coincides with observations of several previous work and may partly explain the recent focus of previous work on makingdebugging of big data software easier.
fisher et al.
interview data analyst at microsoft and observe that a cloud based computing solution will often be far more difficult to debug.
kim et al.
interview data scientist at microsoft and observe that some of their participants work on fault localization and root cause analysis in debugging.
gulzar et al.
propose bigdebug for interactive debugging of big data software written in spark.
similarly gulzar et al.
propose bigsift for automatic identification of the root cause of a debugging error.
more details about these previous works can be found in section .
indebugging developers ask questions like spark job running on yarn cluster java.io.filenotfoundexception file does not exits even though the file exits on the master node and hive failed semanticexception line table not found field .
yarn is a resource manager and hive allows for sql like queries.
basic concepts according to figure developers also ask more than average number of questions about basic concepts .
this may show that developers find even the basics of big data software development challenging.
this observation is not specific to big data software and coincides with observations of several previous work for other software.
ahmed and bagherzadeh study concurrency questions on stackoverflow and observe that developers ask the most about basic concepts of concurrent software development .
similarly pinto et al.
study most popular concurrency questions on stackoverflow.
and observe that most of them are related to basic concepts .esec fse august tallinn estonia mehdi bagherzadeh and raffi khatchadourian inbasic concepts developers ask questions like what is the actual difference between data warehouse big data?
.
finding developers ask more than average number of questions about basic concepts which may show that they find even the basics of big data software development challenging.
performance developers ask more than average number of questions about performance .
this observation is not specific to big data software and coincides with observations of several previous work about other software and may also partly explain the focus of some previous work on improving performance.
fisher et al.
observe that choosing architecture based on cost and performance is a challenge.
kim et al.
observe that some of data scientist at microsoft work on performance regression .
li et al.
propose a tool for automatic configuration of hadoop software to optimize performance.
garbervetsky et al.
propose a static analysis for performance optimization of big data queries written in scope language.
however developers ask less questions about performance than topics such as mapreduce debugging and basic concepts .
this observation coincides with the observation of the work of ahmed and bagherzadeh that observes that developers ask more about correctness of their concurrent programs than performance.
.
finding developers ask more questions about mapreduce model debugging andbasic concepts than performance .
stream processing and string the emergence of stream processing topic may be a sign of an increased interest in real time processing of stream data in addition to original batch data processing in big data software development.
this observation may partly explain the recent focus on services for efficient and unified processing of batch and stream data such as apache storm and flink .
similarly the emergence of string topic may show that data that big data developers are still mostly concerned about processing of textual data and not other forms of data such as images.
.
big data topic hierarchy figure shows the hierarchy of big data topics constructed using step of our study.
the figure shows big data topics in gray and their categories in white and percentages of their questions.
the hierarchy expands outwards from higher level categories to lower level categories and topics.
according to figure questions that big data developers ask can be grouped into a hierarchy with high level categories programming storage configuration analysis debugging basic concepts performance stream processing andlogging .
more than one third of questions that developers ask are about programming one sixth are about storage andconfiguration and the least are about logging .
finding questions that big data developers ask can be grouped into a topic hierarchy with high level categories programming storage configuration analysis debugging basic concepts performance stream processing andlogging .
figure hierarchy of big data topics in gray their categories in white and percentages of their questions.
finding developers ask the most number of questions about programming category and the least about logging .
in the following we discuss each big data higher level category its lower categories and topics using sample questions.
.
.
programming category.
more than in big data questions belong to programming category.
programming is concerned about programming models languages and datatypes that developers use to write big data software.
programming has lower level categories datatype mapreduce model languages andgeneral programming .
more than half of programming questions are about datatype a quarter are about mapreduce model and the least are about general programming .
the datatype category is concerned about composite datasets such as dataframes and resilient distributed datasets rdd as well as primitive datatypes such as string and date time.
an rdd is an in memory distributed dataset that can be operated on in parallel by different machines in a cluster.
an rdd is immutable and fault tolerant and allows for data organization through partitioning and join.
a dataframe is similar except that its data is organized into named columns similar to a table in a relational database.
rdds and dataframes are the main datasets in spark.
dataset category includes questions with titles like dataframe how to change column types in spark sql s dataframe?
rdd why do we need to call cache or persist on a rdd and data organization how to define partitioning of dataframe?
.primitive category includesgoing big a large scale study on what big data developers ask esec fse august tallinn estonia questions like string filter spark dataframe on string contains and date time convert timestamp to date in spark dataframe .
the topic of a question above is included inside parentheses.
mapreduce model is the programming model that developers ask about in programming category.
this is inline with the general understanding that mapreduce is the dominant model for programming big data software.
in languages category developers ask about popular programming languages for programming big data software including python scala and java that scala translates to.
languages includes questions like pyspark how do i get python libraries in pyspark?
and scala spark how to write case with when condition in spark sql using scala .
finally the general programming category includes general programming questions like how to store custom objects in dataset?
and how to escape forward slash in java so that to use it in path .
finding of big data questions are about programming .
finding of programming questions are about mapreduce model inline with the general understanding that mapreduce is the dominant model for programming big data software.
.
.
storage category.
more than in big data questions belong tostorage category.
storage is concerned about distributed storage of data random and real time read and write access and transfer of data.
storage has lower level categories file system transfer and hbase .
more than half of questions in storage are about file system one third are about transfer and the least are about hbase .
the file system category is about management distribution and format of files on hadoop distributed file system hdfs used by both hadoop and spark services.
file system includes questions like file management how to copy file from hdfs to the local file system file distribution hadoop datanodes cannot find namenode and file format store images videos into hadoop hdfs .file system is mainly about hdfs.
in hdfs a file is partitioned and stored in a distributed cluster of nodes for sequential and batch access.
a master datanode stores the metadata of the file and worker datanodes store the actual data partitions.
transfer category is concerned about transferring data between filesystem datatypes and relational databases.
transfer includes questions like dataset load store how to export a table dataframe in pyspark to csv and database import export how to import tables from sql server through sqoop to hdfs .hbase category is concerned about random and real time access and querying the filesystem and includes questions like hbase in hbase is there a way for me to get the middle key of a region?
.
hbase is a nosql database that stores its data in hdfs and adds random and real time read and write access to hdfs.
an hbase table divides its rows into regions.
finding of big data questions are about storage .
.
.
configuration.
more than in big data questions belong toconfiguration category.
configuration is about the configuration of constituent components of a big data software including memory connections between services in a cluster dependencies and jobs.
configuration has lower level categories job management dependency management connection management and memory management .
one third of configuration questions are about job management andmemory management a quarter are about connection management and the least is about memory management .
configuration includes questions like job management how to allocate more executors per worker in standalone cluster mode?
dependency management hadoop unable to load native hadoop library for your platform warning connection management hadoop connecting to resourcemanager failed and memory management how to avoid spark executor from getting lost and yarn container killing it due to memory limit?
.
the observation that out of big data questions are about configuration may partly explain the focus of some recent previous work on making configuration of big data software easier.
li et al.
propose a tool for adaptive and automatic configuration of big data programs written in hadoop to optimize performance.
finding of big data questions are about configuration .
.
.
analysis.
more than in big data questions belong to analysiscategory.
analysis is about analyzing big data using higher level query and scripting languages and functionalities like full text search and machine learning.
this is unlike programming category in which big data is processed using lower level programming languages such as python scala and java.
analysis has lower level categories hive machine learning pigand search .
near half of analysis questions are about hive less than a quarter about machine learning and the least are about text search .
analysis includes questions like hive compare two tables of data in hive machine learning how can i create a tf idf term frequency inverse document frequency for text classification using spark?
pig pig string extraction using regex and text search generate solr indice using customized mapper in mapreduce .
hive is a database with a sql like query language hiveql to analyze data stored in hdfs.
pig is an analysis platform with a scripting language pig latin.
a high level pig latin analysis translates to a lower level mapreduce program to execute.
solr is a service with indexing and full text search capabilities.
tf idf is a numerical statistics used as a weighting factor to denote the importance of a word in a document and in the text search.
our machine learning topic coincides with observations of some previous work.
kandel et al.
interview business data analyst and observe that machine learning and especially its feature selection and scale are challenging for data analysts.
kim et al.
interview data scientist at microsoft and categorize data scientists into groups including insight provider modeling specialist platform builder polymath and team leaders.
their modeling specialist is a data scientist with strong background in machine learning their main task is to build predictive models .
.
.
debugging.
the debugging category is about finding and fixing bugs that manifest during the development and execution of big data software.
debugging includes questions like what is the meaning of eof exceptions in hadoop namenode connections from hbase filesystem?
and how can i debug hadoop map reduce?
.
.
.
basic concepts.
the basic concepts category is about fundamental concepts underlying big data software development andesec fse august tallinn estonia mehdi bagherzadeh and raffi khatchadourian table popularity of big data topics.
topic avg.
views avg.
favorites avg.
score file management .
.
.
file distribution .
.
.
hive .
.
.
dependency management .
.
.
dataframe .
.
.
string .
.
.
rdd .
.
.
hbase .
.
.
dataset load store .
.
.
data organization .
.
.
file format .
.
.
connection management .
.
.
mapreduce model .
.
.
debugging .
.
.
basic concepts .
.
.
pyspark .
.
.
memory management .
.
.
job management .
.
.
general programming .
.
.
pig .
.
.
date time .
.
.
text search .
.
.
scala spark .
.
.
database import export .
.
.
performance .
.
.
logging .
.
.
machine learning .
.
.
stream processing .
.
.
big data average .
.
.
its ecosystems and includes questions like what is the difference between big data and data mining?
difference between hadoop and nosql?
and difference between hbase and hadoop hdfs?
.
.
performance.
the performance category is about run time of big data software and its speedup and includes questions like spark performance for scala vs python and getting the count of records in a data frame quickly .
.
stream processing.
the stream processing category is about real time processing of stream data and includes questions like how to convert spark streaming data into spark dataframe and spark processing multiple kafka topic in parallel .
kafka is a streaming platform with publish and subscribe capabilities for streams of records stored in topics.
.
.
logging.
the logging category is about generation and processing of execution logs and includes questions like filtering log files in flume using interceptors and controlling logging functionality in hadoop .
shang et al.
analyze execution logs to assist with deployment of big data hadoop software from a test environment to the real world environment.
.
rq3 popularity of big data topics table shows the popularity of big data topics measured using three metrics average number of views favorites and score as described in step of our study.
table is sorted by average number of views for topics.
a topic with higher number of views favorites and score is more popular.table difficulty of big data topics.
topic w o acc.
answer hrs to acc.
answer stream processing .
.
database import export .
.
memory management .
.
connection management .
.
pyspark .
.
logging .
.
hive .
.
job management .
.
scala spark .
.
debugging .
.
dependency management .
.
performance .
.
dataset load store .
.
hbase .
.
file distribution .
.
pig .
.
file management .
.
file format .
.
machine learning .
.
basic concepts .
.
data organization .
.
text search .
.
date time .
.
general programming .
.
string .
.
mapreduce model .
.
rdd .
.
dataframe .
.
big data average .
.
according to table file management topic has the highest views fourth highest favorites and sixth highest score whereas logging has the third lowest views and second lowest favorites and score.
topic popularity measures can be used by practitioners researchers and educators to tradeoff one topic against another as discussed in section .
finding file management topic in storage category and logging are among the most and least popular big data topics.
.
rq4 difficulty of big data topics table shows the difficulty of big data topics measured using two metrics percentage of questions with no accepted answers and average median time to get an accepted answer as described in step of our study.
table is sorted by percentage of questions with no accepted answers.
a topic with higher percentage of questions with no accepted answers and higher median time to receive accepted answers is more difficult.
according to table connection management topic has the fourth highest percentage of questions with no accepted answers and third highest time to accepted answer whereas dataframe has the lowest percentage of questions with no accepted answers and third lowest time to accepted answer.
topic difficulty measures can be used by practitioners researchers and educators to tradeoff one topic against another as discussed in section .going big a large scale study on what big data developers ask esec fse august tallinn estonia table correlations of big data topics popularity difficulty.
coefficient p value avg.
views avg.
favorites avg.
score w o acc.
answer .
.
.
.
.
.
hrs to acc.
answer .
.
.
.
.
.
file management file distributionhive dependency managementdataframe stringrdd hbase dataset load storedata organization 69popularity avg.
views difficulty w o acc.
answer figure tradeoff big data topics by popularity difficulty.
finding connection management topic in configuration category and dataframe inprogramming are among the most and least difficult big data topics.
.
rq5 popularity difficulty correlation according to tables and a topic such as logging is not only less popular but also more difficult.
such anecdotal evidence could suggest an intuition that there may be a negative correlation between the popularity and difficulty of big data topics where a more difficult topic is less popular.
to investigate we calculate correlations between popularity and difficulty metrics of big data topics as discussed in step of our study.
table shows the coefficients and p values for these correlations.
according to table although there is a negative correlation between popularity and difficulty measures of big data topics but the correlation is not statically significant at significance level.
finding there is no statically significant correlation between popularity and difficulty of big data topics.
implications the results of our study can not only help big data developers and their practice but also the research and education of big data software development to better decide where to focus their efforts.
members of these communities could use tradeoffs between big data topics as one of several factors they use in their decision making process.
one way to tradeoff a big data topic against another is using popularity and difficulty of these topics.
to illustrate figure shows the popularity and difficulty of our top popular big data topics in tables and .
for simplicity we use the average number of views and the percentage of questions without accepted answers as measures for popularity and difficulty of topics.
in figure a topic is represented by a circle where the size of the circle is proportional to the number of questions in the topic as shown in figure .
practice according to figure a developer with interest in big data software development may decide to start their learning onthe more popular and less difficult dataframe andrdd topics in datatype category before the less popular and more difficult hbase and dataset load store topics in storage category.
similarly a manager of a big data development team may decide to assign a less difficult task related to dataframe to a less experienced developer and a more difficult task related to hbase to a more experienced developer.
finally the manager may allocate more time to the more difficult hbase task when assigning the task to a developer and review their work performance than a less difficult dataframe task.
research according to figure an experienced big data researcher may decide to focus their research on the more difficult and less popular dependency management inconfiguration category compared to the less difficult and more popular file management instorage category in the hope of making more contributions in a less crowded area.
this decision is further supported by observations that there are more than average number of questions about dependency management and in big data questions are about configuration .
conversely a research looking to transition anew to the big data research may decide to start their research on the more popular and less difficult dataframe inprogramming category.
education according to figure a big data educator may decide to teach the material for the less difficult and more popular dataframe andrdd topics before the more difficult and less popular hbase anddataset load store if there are no dependencies between these topics.
the educator may also decide to prepare more material and spend more time in both the class and lab on the more difficult topic hbase than the less difficult topic dataframe .
obviously there are many factors that go into tradeoffs that practitioners educators and researchers make to decide where to focus their efforts.
however we believe our findings can contribute to inform and improve these decisions.
threats to validity some of our decisions during this study could be a threat to its validity.
using tags in general and big data tags in particular to identify and extract big data questions and answers from stackoverflow is a threat.
this is because big data tags may not identify a complete set of big data questions and answers.
to minimize this threat we use well known techniques along with extensive experiments to develop a set of big data tags that are significantly relevant to big data software development.
using stackoverflow as a single dataset to study interests and difficulties of big data developers is another threat.
this is because stackoverflow questions and answers may not be a representative set for questions that developers ask and answers that they provide and receive.
however the large number of stackoverflow questions and answers and participant developers could help mitigate this threat.
manual labeling of topic word sets is another threat.
to minimize this threat we use well known techniques to label topics using not only their top words but also a set of random questions.
deciding an optimal value for numbers of topics k iterations iand hyperparameters and is another threat.
to minimize this threat we use well known techniques and default values in addition to extensive experiments to find reasonable values for these variables.
values we have used are all inline with values used by previous works.
it is known that determining an optimal value for kis difficult .
metrics usedesec fse august tallinn estonia mehdi bagherzadeh and raffi khatchadourian to measure popularity and difficulty of big data topics could be another threat.
to minimize this threat we use well known metrics to measure popularity and difficulty .
related big data gulzar et al.
propose bigdebug for interactive debugging of big data spark software.
bigdebug supports interactive debugging through simulated breakpoints and on demand watchpoints to allow for inspection of a program without pausing its entire computation and retrieval of select intermediate data.
gulzar et al.
propose bigsift for automatic identification of the root cause of an error.
bigsift uses delta debugging and data provenance to identify the root cause of an error in a spark program.
li et al.
propose a tool for automatic configuration of hadoop programs to optimize performance by learning the relationship between the performance and configuration.
garbervetsky et al.
propose a static analysis for performance optimization of big data scope queries that use user defined functions.
the analysis identifies the columns of an input table that are unused or unmodified by the query and optimizes the query by pruning away the unused columns and copy unmodified columns directly from input to output.
shang et al.
propose an approach to assist with deployment of hadoop software from a test environment to the real world environment.
they assist by detecting anomalies between executions of the software in the test and real world environments through abstraction and analysis of execution logs.
zhou et al.
conduct an empirical study on service quality issues of a big data platform at microsoft to understand their common symptoms causes and mitigations.
they identify hardware faults system and customer side effects as major causes of quality issues.
data science data science is about transformation of data into insight using both big or small amounts of data.
fisher et al.
interview data analyst at microsoft to characterize big data analytics and its challenges.
they identify challenges in categories including acquiring data selection of computation platform based on cost and performance shaping data into computation platform formats and iterative writing and debugging of code.
kandel et al.
interview business data analyst in industry including healthcare retail marketing and finance to characterize industrial data analysis and its challenges.
they identify challenges in data discovery shaping profiling modeling and reporting data.
harris et al.
interview more than data science practitioner to understand how they view their skills careers and experiences with prospective employers.
they group their practitioners into categories data businesspeople data creatives data developers and data researchers.
begel and zimmerman survey and software engineers to identify questions that software engineers would like data scientists to investigate.
they identify and rate questions in categories ranging from bug measurements to development best practices to software development life cycle.
kim et al.
interview data scientist at microsoft to understand the role of data scientists in software engineering including their background problems they work on and working style.
they group data scientists into categories insight provider modeling specialist platform builder polymath and team leaders.
their data scientist work on problems ranging from performance regressionto fault localization to customer understanding.
kim et al.
extend their previous work and survey data scientist at microsoft to understand their background problems they work on and working style challenges and best practices and tools.
their data scientist work on problems ranging from user engagement to software productivity and quality to domain specific problems and business intelligence.
their challenges are data challenges for quality availability and preparation analysis challenges for scale and machine learning and people challenges.
they categorize data scientist into categories polymath data preparer shaper and analyzer platform builder data evangelist insight actor and moonlighter.
topic modeling ahmed and bagherzadeh use topic modeling to infer concurrency topics on stackoverflow and study their popularity and difficulty and correlations.
they group their topics into a hierarchy with categories.
yang et al.
use topic modeling tuned with a genetic algorithm to infer security topics on stackoverflow and study their popularity and difficulty.
they group their topics into categories.
rosen and shihab use topic modeling to infer mobile development topics on stackoverflow and study their popularity and difficulty.
they categorize questions that developers ask based on platforms for mobile development and the type of questions into why what and how questions.
bajaj et al.
use topic modeling to infer client side web development topics on stackoverflow and study interests of developers in these topics and challenges they face when working with these topics.
barua et al.
use topic modeling to infer general topics on stackoverflow.
they study relations of questions and answers of their topics and evolution of interests of developers in these topics.
gy ngyi et al.
and adamic et al.
study yahoo!answers questions and answers to determine interests of developers in a set of predefined and fixed categories.
hindle et al.
use topic modeling to infer topics related to development tasks from commit messages of a software project and study the evolution of interests in these topics.
treude et al.
and allamanis and sutton study stackoverflow questions and answers to infer types of questions that developers ask and determine their difficulties.
in contrast in this work we extract topic model and categorize big data questions and answers on stackoverflow to understand big data topics that developers are interested in the hierarchy of these topics their popularity difficulty and their correlations and implications of such understanding for practice research and education of big data software development.
conclusion and future work in this work we conduct a large scale study on stackoverflow to understand interest and difficulties of big data developers.
we infer big data topics that developers ask questions about organize them into a hierarchy of topics and measure their popularity and difficulty and correlations.
we show the coincidence of findings of our study with findings of previous work.
we also show how our findings can help practice research and education of big data software development.
one avenue of future work is to conduct similar large scale studies using commit logs and bug reports to triangulate with our results.