scalable thread sharing analysis jeff huang parasol laboratory texas a m university je cse.tamu.edu abstract we present two scalable algorithms for identifying program locations that access thread shared data in concurrent programs.
the static algorithm though simple and without performing the expensive whole program information ow analysis is much more e cient less memory demanding and even more precise than the classical escape analysis algorithm.
the dynamic algorithm powered by a locationbased approach achieves signi cant runtime speedups over a precise dynamic escape analysis.
our evaluation on a set of large real world complex multithreaded systems such as apache derby and eclipse shows that our algorithms achieve unprecedented scalability.
used by client applications our algorithms reduce the recording overhead of a record replay system by 9x on average as much as 16x and increase the runtime logging speed of a data race detector by on average as much as .
.
introduction a major di culty of concurrent programming lies in the complex interaction among threads on shared data.
distinguishing shared data accesses from those thread local is vital to virtually all concurrency related problems from program comprehension compiler optimization to testing debugging and veri cation.
as examples if an access is not to shared data synchronizations surrounding it can be safely eliminated a race detection technique can ignore it as it cannot be involved in any race condition and a replay technique does not need to track it because it cannot introduce non determinism .
problem.
we shall call the problem of localizing shared data accesses i.e.
determining if a program statement can read or write thread shared data as thread sharing analysis tsa .
unfortunately sound and complete tsa is generally undecidable.
a classical approach to this problem is escape analysis which approximately determines if an allocated object may escape from the method or thread creating it.
escape analysis has attracted more than a decade permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa acm.
isbn .
.
.
.
active research and has been proven valuable in practice.
for instance it has been used in oracle jvm for performance optimization if an object does not escape a method it will be allocated on the method s stack frame and if an object does not escape a thread the synchronization associated with it will be eliminated.
limitations of escape analysis .
we argue that escape analysis does not suite the tsa problem well the focus of which di ers in several aspects.
first a thread escaped object may not be accessed by multiple threads .
for example static variables are often considered as escaped and any object that is reachable from static variables is classied as thread escaped.
however a static variable may only be accessed by a single thread.
second an object is threadescaped does not mean all data associated with the object are shared .
in object oriented programs di erent threads may access di erent elds or only part of the elds is shared.
third standard escape analysis algorithms do not directly work for array accesses .
because escape analysis has no information about array aliases it cannot determine if an access a is to shared data or not even though amay refer to an escaped array object.
fourth a thread escaped object may be immutable that it is only read after initialization.
more importantly escape analysis is expensive in both time and space that it is di cult to scale to large programs.
the classical algorithm needs to construct an interprocedural information flow graph ifg for the whole program and propagates the shared nodes in the graph initially all static variables and runnable objects are shared nodes .
this process is slow as the propagation continues until reaching a x point and is highly memory demanding as it needs to create a summary ifgfor every reachable method.
for instance tloa a state of the art escape analysis implemented in soot cannot even nish analyzing a toy program in minutes in our experiment.
our solution.
in this paper we present two tsa algorithms a static and a dynamic for object oriented programs exempli ed by java that scale to real world large multithreaded systems.
the static algorithm is much faster less memory demanding and even more precise than the classical escape analysis .
it is sound object sensitive eld sensitive and works for array objects but does not distinguish between individual array elements .
the algorithm leverages two key insights.
first a eld sensitive analysis can signi cantly improve precision.
rather than reporting which objects escape a thread and thus might be concurrently accessed it reports which mutable elds of those objects might be accessed by multiple threads.
sec2016 ieee acm 38th ieee international conference on software engineering ond building an ifgis unnecessary for tsa instead the call graph and points to analysis which are commonly available in compiler frameworks and are also required by escape analysis can be directly leveraged to perform tsa.
this seems counter intuitive because existing points to analyses e.g.
spark often sacri ce precision for e ciency by applying ow insensitive context insensitive algorithms.
however as we will show empirically section with extensive evaluation even built upon context insensitive points to analysis and the simple cha call graph our algorithm signi cantly outperforms escape analysis with interprocedural informationow analysis for the reasons mentioned earlier.
the limitation of static tsa as for any static analysis is that when certain code is not known statically e.g.
in the presence of re ection or dynamic code generation it may produce unsound results because the call graph is incomplete.
the dynamic tsa algorithm is proposed to complement static tsa by tracking shared data accesses dynamically.
the key insight is to represent dynamic memory locations in a eld sensitive but object insensitive way such that for any program location it su ces to analyze at most two memory accesses performed at that location and if a program location is marked as shared analysis of future memory accesses performed at that location can be skipped.
powered by a location based approach our algorithm improves the e ciency of a precise dynamic escape analysis algorithm by an order of magnitude but still achieving close precision within di erence on average .
highlights of results .
we demonstrate the e ciency and e ectiveness of our algorithms with extensive evaluation on a wide range of real world large complex multithreaded programs.
by comparing with a state of the art static escape analysis tloa and a precise dynamic escape analysis dea we show that our static tsa algorithm is able to analyze these large programs in a few minutes whereas tloa runs either out of memory or timeout in an hour.
and our dynamic algorithm is .6x 14x faster than dea while maintaining good precision whereas dea cannot even nish by running out of memory on some programs.
we have also applied our algorithms in two client applications a deterministic record replay system leap and a dynamic race detector rvpredict .
our algorithms reduce the recording overhead of leap by 9x on average as much as 16x speed up the runtime logging of rvpredict by on average as much as and enable rvpredict to detect more data races in these large programs.
our implementations are open source and are publicly available at contributions .
to sum up our contributions are threefold we present a scalable static thread sharing analysis that signi cantly improves classical escape analysis.
we present a scalable dynamic thread sharing analysis that signi cantly improves precise dynamic escape analysis while maintaining good precision.
we demonstrate the practicality and scalability of our algorithms with extensive evaluation on real world large systems as well as two client applications.
roadmap .
the rest of the paper is organized as follows section presents a motivating example to illustratethe tsa problem and to identify the limitations of escape analysis section presents our static and dynamic tsa algorithms section describes our implementations of the two algorithms.
section presents a case study of our static tsa algorithm and section reports our detailed experimental results.
section discusses further improvements of our algorithms.
section reviews the related research and section concludes the paper.
.
motivating example figure shows a simple example illustrating the tsa problem.
the program contains three threads accessing a shared object s with two instance elds xand y a static eld z and an array reference a. there are in total nine reads writes to these eld array variables marked with numbers from to3 .
the goal of tsa is to nd out which of these nine accesses are to thread shared data.
we shall call such an access as shared access point sap in this paper.
this information is useful in many applications for example when all saps in a program are known a dynamic race detector can eliminate the instrumentations on those non saps which improves the runtime performance.
note that here the identi cation of saps is context insensitive if an access has multiple runtime instances as long as any one of them reads or writes thread shared data this access is classi ed as a sap.
although context sensitive identi cation may produce more precise results it is also more expensive and harder to scale which is not the focus of this paper.
since all these nine accesses are to the shared object s an escape analysis will conclude that they are all saps because sescapes its creating thread t1.
however only 11 are true saps.
read y is not a sap because yis immutable not modi ed after initialization .
o write z is not a sap because though zis static it is only accessed by thread t1.
and1 both read a are not saps because ais immutable only read by threads t1and t3after initialization .
another major problem with escape analysis is that it relies on interprocedural information ow analysis which is expensive to compute.
for example for this program the state of the art escape analysis implementation tloa in soot runs out of memory in minutes on a .60ghz machine with jdk and 4gb heap.
in practice to use tloa jdk libraries are typically excluded from the analysis.
however this is unsound in general see more detailed discussion in section .
for instance when jdk libraries are excluded tloa can nish in a second for this program but it will classify as non saps which is wrong.
the reason is that without analyzing java hashset in this example one cannot determine if there is an information ow from stoo and hence would miss the call to the hashcode method on sbyt2.
furthermore escape analysis does not directly handle array accesses.
it can only determine if an array object can escape or not but not for array indexing operations.
as a result escape analysis may miss shared array accesses.
for instance tloa identi es the sap1 b as thread local even though baliases aand1 4con icts with a .
.
thread sharing analysis in this section we present our static and dynamic tsa algorithms and discuss their usages and characteristics.
1098t2 for object o set print o.hashcode s.a t3 1 read y 4 write x5 write z6 read a7 write b 8 read a 2 read x 3 write x 9 write a 8 9 class shared int x int y static int z int a new int override public int hashcode return y x 1 2 3 1. .
.
.
.
.
.shared s new shared set set new hashset set.add s new t2 set .start new t3 s .start s.x s.z int b s.a b t1 4 5 6 7 8. .
.
.
.
.
.
.
.
.
.
.figure all eld and array accesses are numbered.
accesses to shared data are in red.
algorithm staticsharinganalysis input cg program call graph global state pointsto points to analysis.
global state threads findstaticthreads fort2threads do m t entrymethod visitmethod t m .
static algorithm algorithm outlines our static tsa algorithm.
from a high level view it leverages the call graph and points to analysis pta of the program and traverses the eld and array access statements reachable from each static thread to identify saps.
it consists of two steps identifying threadshared data and answering the sap queries.
to correctly classify those accesses to thread shared but immutable data our algorithm also distinguishes between reads and writes.
speci cally we rst nd all the static threads in the program that may be executed once or multiple times line .
this is a standard step also employed by escape analysis such as tloa .
finding static threads is not di cult in practice because threads are almost always explicitly dened either at the language level or through common apis such as pthreads and openmp.
in cases where threads are not explicit such as customized user level threads developers might still be able to provide annotations for the analysis since customized threads are likely to be an important aspect in the target program.
we then traverse the statements of each static thread starting from its entry method i.e.
the main method or therunmethod of a runnable class .
in java there are four kinds of statements that are relevant to tsa instance eld access static eld access array access and method invocation because only these statements may access or in uence thread shared data.
we next describe how they are handled in the procedure visitmethod algorithm to identify thread shared data.
instance eld access o.f lines .
we query pta to nd all the possible abstract objects that the base reference omay point to.
depending on the context sensitivity of pta the abstract objects may be represented in di erent ways for example it is represented by the object allocation site in the default context insensitive pta provided inalgorithm visitmethod t m visitedmethods visitedmethods add m fors2m statements do switch s case o f read write instance eld objects findpointstoobjects o foro02objects do checksharing t o0 f read write break case f read write static eld checksharing t null f read write break case a read write array objects findpointstoobjects a foro02objects do checksharing t o0 null read write break case m args call a new method methods findcalleemethods cg m args form2methods do if!visitedmethods.
contains m then visitmethod t m visitedmethods default break end switch soot.
nevertheless our algorithm is oblivious to the speci c representation.
for each such abstract object o we call the procedure checksharing t o f iswrite algorithm to check if the eld fofo is shared or not.
in checksharing we maintain for each object eld o.fa set of write threads and a set of read threads retrieved by getreadthreads andgetwritethreads respectively.
if a eld fof an object ois accessed by more than one static thread or by only one static thread that may run more than once1 and with at least one of them is a write we mark o.fas shared via the procedure markobjectfieldshared o f .
static eld access f lines .
static eld accesses are handled in a similar way as to that for instance eld accesses except that we set the object otonull.
note that fis represented by its full signature including the class name such that each static eld is unique.
1in our implementation we use a simple multirunstatementsfinder in soot based on the cha call graph to compute runmorethanonce .
1099array access a lines .
for array accesses we do not distinguish between di erent array indexes unless all array accesses in the program have a constant index value .
although there exists a large body of work we will discuss in section that can infer the content of arrays in general the value of iis undecidable statically.
hence for practicality we abstract every array with a single eld represented simply by null and consider all array accesses as to that single eld.
we then handle array accesses similar to that of instance eld accesses.
method invocation m args lines .
for method invoke statement the receiver object is also included in the arguments args we rst use the call graph to get the possible target methods and then traverse the statements of each of them following the same procedure visitmethod.
after all thread shared data is identi ed the analysis result can then be easily queried by client analyses to answer if a statement contains a sap or not.
algorithm shows our algorithm querysap which takes a statement s and a set of shared object and eld data d and returns if scontains asap.
it checks for three kinds of memory accesses that s may contain instance eld access o.f it rst nds all the possible abstract objects that omay reference using points to analysis.
for each such object o it checks if o .f has been marked as shared o0 f2d .
if any of o .f is shared it returns true.
static eld access f similar to instance eld access o.fexcepts that ois set to null.
array access a similar to instance eld access a.f excepts that fis set to null.
ifscontains none of the above accesses it simply returns false.
discussion.
our static tsa algorithm presented above is mostly straightforward.
however we were not able to nd it presented in previous literature or implemented in popular compiler frameworks partly because that the key focus of tsa is di erent from classical escape analysis.
more importantly being practical and at the same time sound i.e.
no sap will be mis classi ed our algorithm features in the following ways it does not need to perform the expensive information ow analysis.
it works at the granularity of eld rather than object.
it handles array accesses as well i.e.
it will not miss any sap to array object but does not distinguish different array indexes .
it does not assume that static eld accesses are saps by default but handles them in the same way as instance eld accesses.
note that our algorithm assumes that the call graph and points to analysis of the whole program are constructed beforehand.
for static analysis this is a reasonable assumption and actually adds to the practical aspect of thread sharing analysis since call graph and points to analysis serve as the basis for most whole program analyses and optimizationalgorithm checksharing t o f iswrite input t current static thread o accessed object nullmeans static eld access f accessed eld nullmeans array access iswrite true means write and false means read.
ifiswrite then ift.runmorethanonce then markobjectfieldshared o f else wthreads getwritethreads o f ifwthreads6 !wthreads .contains t then markobjectfieldshared o f else rthreads getreadthreads o f ifrthreads6 !rthreads.
contains t then markobjectfieldshared o f else wthreads .add t else wthreads getwritethreads o f ifwthreads6 !wthreads.
contains t then markobjectfieldshared o f else rthreads getreadthreads o f rthreads .add t algorithm querysap s d input s a program statement d a set of thread shared object and eld data.
output true scontains a sap.
switch s case o f access instance eld objects findpointstoobjects o foro02objects do ifo0.f2dthen return true break case f access static eld iff2dthen return true break case a access array objects findpointstoobjects a foro02objects do ifo02dthen return true break default return false end switch return false including escape analysis and are available in standard compilers such as soot2 wala3 and llvm4.
moreover as we will show empirically in section building call graph and points to analysis is much less expensive i.e.
faster and consumes less memory than information ow analysis which is required by escape analysis.
.
dynamic algorithm when call graph and points to analysis are not available or their quality is impaired e.g.
by the increasing use of re ection in libraries and frameworks dynamic tsa could be more favorable in some client applications.
for example for dynamic concurrency bug detection a lightweight dynamic tsa can be run rst to identify saps for a given program input and then those saps are used in a second run with the same input to nd races or atomicity violations.
though the program needs to be run twice because those non saps are not tracked the overall performance can often be improved .
however dynamic analysis in general faces two challenges.
besides the well known unsoundness due to input sensitivity a complete dynamic analysis often incurs prohibitive runtime overhead both time and space .
dynamic tsa is no exception.
although it seems obvious to perform tsa when all thread memory access information is available at runtime precisely tracking every memory access to determine if it accesses thread shared data is expensive and does not scale to large real world programs.
for instance in our experiments the precise dynamic escape analysis can slow down the program by as much as 82x and even run out of memory for some programs e.g.
h2and sun ow after a few minutes.
our dynamic tsa algorithm addresses the runtime overhead problem by making the following observations although a statement may be executed multiple times at runtime as long as one of its execution instances accesses threadshared data the statement contains a sap and should be instrumented e.g.
by a dynamic race detector or atomicity violation checker .
hence our algorithm remembers the program location of each memory access and uses this information to lter out most redundant checks on accesses to the same program location.
this enables two optimizations.
first if a program location is marked as shared we can skip checking any future memory access performed at that location.
second we orchestrate all objects by their type and ignore di erent array indexes and only analyze for each program location one or two memory accesses performed at that location.
after the orchestration it is su cient to track memory accesses performed at each program location at most twice.
the reason is that the type and eld of memory accesses performed at a program location are invariant.
since determining if a program location accesses shared data can involve at most two memory accesses performed at that location it is hence su cient to analyze the rst two and skip any future memory accesses performed at the location.
as we will show empirically in section this optimization signi cantly improves the e ciency of tsa in practice while still achieving good precision.
algorithm shows our dynamic tsa algorithm.
it runs on every dynamic heap access.
for each program location we only track twice to check the eld or array it accesses regardless of the runtime object of the eld and index of the array.
if the same eld or array object is accessed by two di erent threads from two di erent program locations or twice from the same program location with at least one write the eld or array is marked as shared.
for each shared eld or array object all statements accessing it are classi ed as saps.
we use a common interface dynamicsharinganalysis t loc o f iswrite to track both eld and array accesses at runtime on o.fby thread tat loca algorithm dynamicsharinganalysis run on every heap access input t current thread loc accessed program location o accessed array object nullmeans eld access f accessed eld nullmeans array access iswrite true means write and false means read.
ifloc.accessedlessthantwice then if!isobjectfieldshared o f then wthreads getwritethreads o f ifwthreads6 !wthreads .contains t then markobjectfieldshared o f marksaps o f return rthreads getreadthreads o f ifiswrite then ifrthreads6 !rthreads.
contains t then markobjectfieldshared o f marksaps o f else wthreads .add t else rthreads.
add t tionloc.
for eld accesses ois set to null as we do not distinguish between di erent object instances.
for array accesses ois the accessed array object and fis set to null as we do not distinguish di erent array indexes.
if o.fis determined shared we mark all statements that have accessed o.fassaps via the procedure marksaps o f .
for client analyses to use our dynamic tsa result we can simply save the saps into a le upon the termination of the program execution.
discussion.
it is worthing noting that in our algorithm each program location is tracked at most twice for all eld and array accesses.
because the eld fis unique to each location if the array reference oat a program location is also insensitive i.e.
always