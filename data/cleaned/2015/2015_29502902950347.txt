perfguard binary centric application performance monitoring in production environments chung hwan kimyjunghwan rheezkyu hyung lee xiangyu zhangydongyan xuy ypurdue universityznec laboratories america university of georgia west lafayette in usa princeton nj usa athens ga usa chungkim xyzhang dxu cs.purdue.edurhee nec labs.com kyuhlee cs.uga.edu abstract diagnosis of performance problems is an essential part of software development and maintenance.
this is in particular a challenging problem to be solved in the production environment where only program binaries are available with limited or zero knowledge of the source code.
this problem is compounded by the integration with a signi cant number of third party software in most large scale applications.
existing approaches either require source code to embed manually constructed logic to identify performance problems or support a limited scope of applications with prior manual analysis.
this paper proposes an automated approach to analyze application binaries and instrument the binary code transparently to inject and apply performance assertions on application transactions.
our evaluation with a set of largescale application binaries without access to source code discovered publicly known real world performance bugs automatically and shows that perfguard introduces very low overhead less than on apache and mysql server to production systems.
ccs concepts software and its engineering !software performance software testing and debugging software post development issues keywords performance diagnosis post development testing .
introduction diagnosis and troubleshooting of performance problems is an essential part of software development and maintenance.
traditionally various performance tools have been extensively used by developers during the development and testing stages in order to identify ine cient code and prevent performance problems.
however unlikeother software issues preventing performance problems before software distribution is challenging for the following reasons.
first modern software has complex dependency on many components developed by multiple parties.
for example an application may have dependency on third party libraries as well as the system libraries to use the underlying operating system.
therefore nding the root causes of performance problems requires investigation of the whole software stack of various software component layers .
second it is very challenging to identify performance issues during the development because software vendors have limited time and environments to test various complex usage scenarios.
consequently there have been e orts to diagnose performance problems during production deployment long after the development stage .
production run performance diagnosis has been performed generally in two major ways which complement each other and often are used together.
first software vendors maintain bug reporting systems .
these systems are used for reporting software issues such as performance and failures issues.
users can voluntarily report the details of their performance issues for instance how to reproduce the symptom the speci cations of their system etc.
second some software vendors embed code logic to detect unexpected performance delay and to report the incident to the vendors automatically .
speci cally such logic monitors the performance of semantically individual operations of a program1and raises an alarm if their latency exceeds predetermined thresholds.
however the cost of human e orts to support such logic and thresholds is high due to requirements to perform in depth analysis on possible application behaviors and to determine the range of its reasonable execution time.
in addition the location to insert the logic needs to be manually determined considering its functionality and run time impact.
such manual e orts may involve human errors due to the misunderstanding of complex program behaviors particularly when dealing with large scale software.
although automating the process could save signi cant efforts in performance debugging and testing such feature is not implemented by many software vendors in practice.
furthermore software users at the deployment stage require performance diagnostics for production software without source code or deep knowledge of the target application.
for instance service providers use open source programs 1such operations are also known as application transactions user transactions units or business transactions .
we will use application transactions herein.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
fse november seattle wa usa c acm.
... .
or 3rd party software as part of their large infrastructure.
monitoring their performance in the production stage is important due to their impact on the overall quality of the service.
however the lack of source code and code knowledge for instrumentation make the monitoring challenging.
there are application performance management apm services available in the market but those services require developers to modify the application code for inserting the monitoring api provided by the service or support a limited range of known applications and platforms with prior analysis.
table lists the apm services and existing techniques for application performance diagnosis in comparison.
among the compared approaches only perfguard automatically identi es application transactions and monitors their performance with no code knowledge using only binaries.
to provide a generally applicable binary centric framework for performance monitoring we designed and implemented perfguard which automatically transforms the binaries of an application without its source code or prior code knowledge to monitor its performance at the production run.
perfguard performs dynamic analysis of a target application and generates a performance pro le which is a summary of the application performance behavior.
it is used as a hint to create a set of monitoring code in the binary format called performance guards to be inserted into the binaries of the application to diagnose its performance in the production environment.
during the production run the inserted performance guards automatically monitor the performance of speci c application transactions that are automatically determined by our analysis.
an unexpected performance delay triggers a performance assertion set by the performance guard and invokes a performance diagnosis to help developers and users resolve the issue.
perfguard utilizes program execution partitioning a.k.a.
units to automate the recognition of application transactions.
each unit is a segment of the execution of a process that handles a speci c workload.
during the pro ling of the application the units of the identical or similar control ow are clustered into the same unit type .
perfguard determines the time threshold for each unit type during the pro ling.
a set of performance guards are generated based on these units and embedded into the application binaries.
during run time the type of each unit is inferred by utilizing the unit s distinct control ow and the run time stack depth.
the performance of each unit execution is examined using the time threshold determined for that unit type.
perfguard does not rely on speci c types of performance bugs.
instead it focuses on nding time delays caused by various hardware software issues and collecting useful footprints for troubleshooting them at the production run.
to show the e ectiveness of perfguard we have analyzed the binaries of popular applications and accurately detected publicly known real world performance problems without source code or code knowledge.
the performance impact of perfguard in these applications is less than x7 .
the contributions of this paper are summarized as follows.
automated analysis of application behaviors and their performance pro le from only binaries based on program execution partitioning.
enabling a lightweight and transparent insertion of performance monitoring and diagnostic logic without source code or code knowledge for the production stage.
unit and performance guard identification pre distribution instrumenting application with performance guards app metadata unit performance monitoring unit performance inspection feedback deploy trigger production run figure perfguard architecture.
implementation and evaluation of a prototype with various applications in the microsoft windows platform showing its practicality discovering performance bugs automatically in the real world software.
x2 presents the design overview of perfguard.
the key idea of unit based performance analysis is presented in x3.x4 shows how to identify units and performance guards.
instrumentation of applications with performance guards is presented inx5.
implementation and evaluation of perfguard are presented in x6 andx7.x8 andx9 respectively show related work and discussions.
x10 concludes this paper.
.
design overview the overall architecture of perfguard is presented in figure .
perfguard takes the binaries of a target application as an input and automatically discovers application transactions from a set of training runs to produce a performance pro le incrementally.
the preciseness of the performance pro le increases as more training runs are performed.
by analyzing the performance pro le perfguard generates a set of binary code snippets called performance guards that are injected into the binaries on the discovered application transactions to monitor application performance.
while the instrumented application is in the production stage the performance guards detect potential performance anomalies and inspect the application s state to nd their root causes.
to discover application transactions perfguard leverages the fact that a majority of large scale applications are eventdriven and incorporate a small number of loops in each event handler .
for instance many server applications run listener and worker loops to receive and handle client requests.
also the applications with a graphical user interface gui are based on loops to respond to user actions.
based on this perfguard partitions the application s execution into units with each unit corresponding to one iteration of such a loop.
intuitively each unit represents an individual task that the application accomplishes at an event.
perfguard performs pro ling on the application to nd the code locations to be instrumented for unit performance monitoring.
for the classi cation of units during a production run perfguard clusters units with di erent calling contexts based on their control ow using a hierarchical clustering algorithm.
the distinct calling contexts of each unit type allow perfguard to automatically identify which type of unit the application is executing at run time without code knowledge.
the pro ling also runs a statistical training to estimate reasonable execution time from which we determine the performance threshold of each unit type.
the inserted performance guards monitor the execution time of units while the application is in the production stage.
if the execution time of a unit exceeds the pre determined threshold of the corresponding unit type perfguard automatically detects it as a potential performance anomaly and triggers an inspection of the unit s execution.
596table the comparison of the approaches for performance diagnosis of native applications.
the app transaction performance aware column represents whether the approach is aware of the performance of application transactions.
the no code knowledge required and no source code required columns respectively show whether the approach requires code knowledge and the source code.
the events at which a program state is collected is shown in the monitored events column.
the selection of app transactions column shows whether an application transaction is determined automatically or manually.
category nameapp transaction no code know no sourcemonitored eventsselection of performance aware ledge required code required app transactions tracer kernel ftrace x x system events lttng kernel tracer x x system events introperf x x system events n a pro lerperf x x system events periodic sampling opro le x x periodic sampling these approaches gperftools x periodic sampling are not aware of gprof x all functions app transactions.
valgrind callgrind x x all functions tracer user lttng userspace tracer manually selected functions embedded perfor perftrack x app transactions manualmance diagnosis application appdynamics x app transactions manual performance new relic x app transactions manual management apm dynatrace x app transactions manual apm perfguard x x x app transactions units automatic we do not consider the known applications and platforms that these apm services support with prior analysis.
uithread ... ...while ... e getevent ... dispatchevent e callback end while... end uithreadmouseleftdownmouseleftupmouseleftclickbuttonclickidleredrawtime...loop units a type i gui applications with ui threads.
getevent is an example of a wait system call.
listenerthread ... ...while ... job accept ... signal e end while... end listenerthreadworkerthread ... ...while ... wait e process job end while... end workerthreadrequest brequest aidle time...idlerequest bunitsloops b type ii server programs with listener and worker threads.
signal and wait are an example of a signal wait relationship.
figure event processing loops and unit execution.
.
unit based performance analysis perfguard achieves performance pro ling and monitoring at the granularity of a unit which is a segment of a program s execution that represents a semantically independent operation of the program.
previous work discovered that a wide range of applications are dominated by event processing loops regardless of the platform and the language used.
the execution of such an application can be partitioned into units by identifying the event processing loops one iteration of an event processing loop indicates a unit.
perfguard leverages unit based performance monitoring and analysis to automatically generate performance guards and help the diagnosis of application performance issues.
unlike previous work that identi es units based on the functional aspects of event processing loops only our unit identi cation considers their performance related aspects.
figure illustrates the event processing loops of applications in two broad categories gui and server applications.
a gui application typically uses an event processing loop in a thread that is the ui thread that responds to the user s actions as illustrated in figure 2a.
at each iteration of the event processing loop the thread is blocked by a system callthat waits for a user action e.g.
a button click .
commodity operating systems and gui libraries provide such a wait system call getevent in figure 2a so applications can take user actions as events e.g.
the getmessage windows api .
when the user performs an action the loop dispatches the event dispatchevent to the corresponding callback function to handle the event.
after the event is handled that is after the execution of the unit the loop steps to the next iteration and the ui thread waits for another user action.
server programs such as apache http server and mysql server employ multiple event processing loops across di erent threads to handle client requests.
in figure 2b a listener thread and a worker thread are presented as two while loops which have a signal wait relationship .
the listener thread receives a client request and sends a signal to a worker thread for dispatching.
the worker thread then handles the received request.
once the request is processed the worker thread is blocked and waits for a new signal from the listener thread.
this model is commonly supported by commodity operating systems with signal and wait system calls e.g.
setevent andwaitforsingleobject for windows and kill and wait for the variants of unix .
we note that the waiting time of an event driven program either a gui or a server application for a user action or a client request should not be considered as part of the unit execution time as such idle time can be arbitrarily long regardless of performance issues.
in addition once a unit starts execution any latencies e.g.
thread blocking and context switch time should be included in the unit execution time since such latencies a ect the wall clock time that the user perceives.
speci cally perfguard detects the start and the end of each unit execution by instrumenting the wait system calls in the two models.
a return from a wait system call in an event processing loop indicates the start of a unit and an invocation of the wait system call represents its end.
.
identification of units and performance guards in this section we present how units are automatically identi ed and binaries are instrumented for unit performance monitoring and diagnosis.
.
unit identification in order to identify units perfguard nds event processing loops through dynamic binary analysis on the training workload of the application.
we use dynamic analysis since performance is inherently a property of run time program behavior and our analysis is based on system call invocation.
perfguard rst identi es all the loops executed by the training .
next we leverage the event processing models aforementioned in x3 to identify the event processing loops among all the loops previously found.
to be determined as an event processing loop a loop must either .
invoke a wait system call that receives an external event or .
have a signal wait relationship with another loop using a certain system call pair.
the entries of the event processing loops and the wait system calls are then instrumented to identify the unit boundaries during pro ling and production runs.
we use the parameters of the signal and wait system calls as hints to map which thread sends a signal to which waiting thread.
if multiple event loops are nested we use the top level event processing loops taking the largest granularity to cover all nested loops.
.
unit classification based on control flow an event processing loop receives di erent types of events as it iterates.
the execution of a unit depends on the type of the event that it handles.
for example a gui application may receive multiple button click events over time.
depending on which key or button is clicked the handling unit will have a distinct execution.
to monitor applications while distinguishing such di erences without prior knowledge perfguard classi es units based on their control ows with the granularity of a function call and analyzing the calling contexts.
the units with the same calling context are classi ed as the same unit type.
figure presents the examples of the unit calling contexts of a gui application and a server application zip file manager figure 3a and apache http server figure 3b respectively.
during the program s execution some calling contexts are shared by units of di erent unit types illustrated as ovals with no ll .
perfguard maintains a list ofcandidate unit types of the current context.
for example when the program runs onnotifylist in figure 3a the candidate list contains two unit types key press event on file list and redraw event on file list .
we discuss the details of how unit types are recognized at run time using the list of candidate unit types in x4.
.
.
unit clustering in general program pro ling through dynamic analysis could be incomplete.
this can cause a unit with an undiscovered calling context to appear during a production run.
perfguard addresses this issue by mapping a new unit to the closest known unit using a hierarchical clustering of their calling contexts.
by grouping units with similar control ows together a newly observed unit is handled the same as the group with its closest siblings i.e.
most similar control ow and by extension time threshold .
unit distance calculation.
given a pair of units xand y we rst derive a set of call paths pxandpyfrom the call tree of each unit px fp1 p mgandpy fq1 q ng1 function getpathset treet return getpath t root function getpath nodev p0 p ifv children then p p fp0 vg else forvi2v children do p p getpath vi p0 v returnp function pathdistance pi qj lcs pi qj .longest common subsequence b max jpij jqjj return b j j b function unitdistance unit a unit b pa getpathset unit a calltree pb getpathset unit b calltree sum forpi2pado forqj2pbdo sum sum pathdistance pi qj returnsum jpaj jpbj algorithm unit distance calculation.
where a call path pk fv1 v kgis a sequence of function nodes from the root node v1to a leaf node vk.
the distance between a call path piinpxand a call path pjinpyis calculated based on the longest common subsequence lcs of the two paths.
the distance d pi qj is de ned as d pi qj max jpij jpjj jlcs pi pj j max jpij jpjj we use the lengths of the lcs and the longer call path betweenpiandqjto normalize the distance value.
then based on the calculated call path distances the unit distance d x y is de ned as d px py p pi2pxp qi2pyd pi qj jpxj jpyj algorithm presents the pseudo code that computes the distance between two units unit aandunit b. once the distance between every pair of units is calculated a hierarchical clustering is performed on the distance matrix similar units are grouped into the same cluster and the units in the same group are classi ed as the same unit type.
perfguard then identi es the common calling contexts across all units in each cluster to use the distinctness of the calling contexts to represent the unit type.
the calling contexts of uncovered units can later be marked and examined by analyzing the call stack at run time if a performance delay is detected.
.
run time unit type inference perfguard inserts performance guards into a set of functions that can monitor distinct units based on calling contexts.
however identifying the type of a unit at an arbitrary point of production run without program semantics is challenging due to the following reasons.
first the current practice for identifying calling context at run time is examining the full call stack of a process a.k.a.
stack walking .
however this may incur high performance overhead if it is performed frequently at run time.
second given a current context the type of the current unit cannot be known a priori .
perfguard uses two techniques to handle these challenges with high accuracy.
run time calling context identi cation.
if many performance guards are used at run time perfguard can598 key press event on file list redraw event on file list redraw event on rebarunique calling contexttranslateacceleratorwgetmessagewtranslatemessagedispatchmessagewwinmain 1d8...defproconnotifyonnotifylistonkeydownsetitemtexteh prologonnotifyrebar a calling contexts of three unit types of zip file manager.
ap process connectiondav handlercgi handlerdav method propfindworker main ...strcmpdav get resourceapr file openap discard request bodydefault handlerap run create connectionap create sb handlewinnt get connectiondav fs get resourcegetqueuedcompletionstatus webdav file request html file requestunique calling context b calling contexts of two unit types of apache http server.
figure example unit calling contexts observed by perfguard.
in both graphs the left most node represents an event processing loop.
the rectangle nodes are wait system calls.
other nodes indicate function calls along with the edges showing the control ows of the units.
the nodes in lled ovals are unique calling contexts of the units of distinct unit types.
the graphs are simpli ed for readability.
abecfabecdgabedhabedhx 12333y 12344z 12345unit type inference x y z x y z x y z y z z unit type xunit type yunit type zexample unit type z execution time1234231451234 unit type x unit type y unit type zlegendsabecdfgh x y z x y z x y z x y y z x y z unit typecandidates figure illustration of unit type inference at production run.
the unit types with the largest number of occurrences are chosen to be the most likely types of the unit.
not rely on stack walking to understand the current calling context due to high run time overhead.
instead perfguard infers the calling context by using the stack frame pointer register that commodity processors support e.g.
the ebp register in the x86 architecture to identify the current context e ciently.
the function call conventions of modern architectures make sure that the frame pointer register holds the start address of the stack memory region that the current function is using.
at the entry of the event processing loop the stack frame pointer is recorded.
later when an inserted performance guard is executed perfguard reads the stack frame pointer again.
the di erence between the two stack pointers approximates the current calling context.
we call the stack pointer di erence the stack depth .
our evaluation inx7 shows that this approach can identify calling contexts with negligible overhead and has su cient accuracy to support perfguard compared to stack walking.
unit type inference from context.
after identifying the current calling context perfguard must determine the type of the current unit in order to use the corresponding time threshold for detection of performance anomaly.
finding the correct unit type at run time however is not straightforward because the unit type is not conclusive when the calling context is shared by units of di erent unit types.
in order to determine the most probable unit type at runtime perfguard identi es the potential unit types for each calling context and assign them as unit type candidates during pro ling.
at a production run perfguard tracks the occurrences of unit type candidates as the functions are executed in real time.
the most likely unit type is inferred using the number of accumulated occurrences.figure illustrates how perfguard infers the unit type as the program executes.
in this example there are three unit types x y and z composed of eight function calls a h .
each unit type has di erent calling context.
for example the unit type z has the call sequence a b e d h. the columns of the table show the distinct function calls that the unit executes over time a in the leftmost column is executed rst and h is executed last .
each row except the bottom most one tracks the number of the occurrences of the unit types that perfguard has observed.
the bottommost row shows the top unit types in the ranking based on the number of occurrences marked.
the unit types with the largest number of occurrences are selected.
if more than one unit types become candidates due to the tie of their numbers perfguard chooses the one with the smallest time threshold assigned.
this allows perfguard to detect performance anomalies conservatively.
as the execution proceeds the number of the selected unit types reduces and becomes nally one in the last column after the function h is executed.
we have observed that in the execution of real programs the number of unit type candidates often becomes one at the early stage of unit execution since modern applications typically have many contexts with large depths including library functions which make the unit types unique.
memory overhead is not a signi cant issue since perfguard only has to keep the most recent occurrence numbers the right most column of the table in memory with a xed number of unit types.
in our experiments the memory overhead was less than mb.
our unit type inference along with the unit clustering mitigates the incompleteness of dynamic analysis by limiting the impact of newly observed units in production environments.
x7.
shows that our context inference has signi cantly better scalability with high accuracy in comparison with stack walking.
.
estimating unit time threshold during the pro ling of training runs perfguard records the execution time of each unit and estimates the time threshold of the unit based on time samples.
the threshold a of a unit type ais calculated based on the series of the time records ra fr1 r ngwhere ra is the arithmetic mean ra is the standard deviation of the time records and kis a constant a ra k ra 599p address of intercepted code f stack frame pointer s thread local storage i input performance pro le function onloopentry p f s loop i. ndloop p .set current loop s loop f f .
remember stack frame pointer function onunitstart .wait system call return ifs loop6 then initialize s unit s unit types s unit t start gettimestamp function onunitcontext p f ifs unit6 then tend gettimestamp d js loop f fj .stack depth id p d .context id c s loop .
ndcontext id forui2c unittypes do s unit types hits u0 forui2s unit types do ifui hits max s unit types hits then u0.append ui .top unit type candidates u0 foruj2u0do ifuj tthreshold min u0 tthreshold then u0 uj telapsed tend s tstart iftelapsed u0 tthreshold then.performance check assert ... .inspection tcheck gettimestamp tend s tstart s tstart tcheck algorithm performance guards.
kis determined depending on the amount of performance variance that the developer would like to allow at the production.
during production runs the performance of the units are checked using the thresholds in the performance guards.
.
performance guard generation after the performance pro ling perfguard generates a set of performance guards which are procedure calls to our shared library functions.
algorithm presents the three library functions for the performance guards.
one of the functions is chosen for each performance guard based on the code where the performance guard will be inserted into.
onloopentry is called on the entry of an event processing loop.
when a program starts and a thread enters an event processing loop this function records the stack frame pointer in the thread s local storage.
perfguard begins to monitor the performance of the unit when the thread nishes waiting for an event.
onunitstart intercepts the return from a wait system call.
it records the time when a wait system call returns.
onunitcontext is invoked at the interception of the calling contexts instrumented for performance checks.
it infers the type of the current unit x4.
and performs an inspection the assert if it violates the prede ned threshold.
the inspection algorithm can be determined by the administrators or developers depending on their needs e.g.
a memory dump .
in our evaluation we examine the thread s call stack as one case to demonstrate the e ectiveness of perfguard.
call stack traces provide a wealth of information for troubleshooting performance issues since they provide not only the function executed at the anomaly but also the sequence of caller functions leading to the function.
pg for x target stackframe save registers set target and stackframe save error number do performance check restore error number restore registers return foo a b ... call pg for xinstruction x... figure code instrumentation for a performance guard abstract code .
a performance guard and the patch applied to the program code are tagged with and respectively.
.
instrumentation of applications with performance guards this section presents how performance guards are inserted into a program.
inserting new code into a binary program is in general not trivial due to the constraints in the binary structure such as the dependencies across instructions.
perfguard has following requirements in functionalities.
instrumenting arbitrary instructions.
first instrumenting arbitrary instructions is important to support any type of application code.
in order to provide this characteristic perfguard should be able to insert performance guards in any position of code.
our technique is based on detours which replaces target instructions with a jump instruction and executes the original instructions after the inserted code i.e.
trampoline .
however detours assumes the replaced instruction block is a subset of a basic block thus it does not allow the program to jump into the middle of the instruction block.
to solve this challenge we use nopinsertion and a binary stretching technique .
perfguard inserts nopinstructions before every instruction instrumented in the binary and replaces each nopinstruction block with acall instruction when the program is loaded.
perfguard generates performance guards in the form of a shared library and modi es the import table of the main executable so it can be loaded by the os s loader.
low run time overhead.
second keeping low overhead is required so that perfguard can be deployed in production environments.
the overhead depends on the number of functions that are instrumented and how frequently the instrumented functions are executed.
to keep the overhead minimal perfguard instruments a subset of the functions that are e ective for unit based performance diagnosis.
in our prototype implementation we instrument the functions that are shared by the least number of units of distinct types.
this is the key mechanism that enables perfguard to minimize the number of functions to instrument while maintaining high accuracy in the unit type inference.
later in x7 we show that perfguard achieves very low overhead.
side e ect free.
lastly performance guards should not interfere with the original application code.
therefore any code in performance guards should execute so that it can record and recover the original program state respectively before and after performance guard s execution.
perfguard preserves the application s original state by saving the execution state in memory before a performance check and restoring it after the execution of a performance guard as illustrated in figure .
perfguard also preserves the stack memory layout for compatibility since it can be used during performance inspection.
.
implementation the design of perfguard is general to be applied to any os such as windows unix linux and mac os.
for our evaluation we implemented perfguard on microsoft windows due to its popularity in enterprise environments and a wide variety of closed source software that perfguard can be applied due to its binary centric design.
the identi cation of units requires the ne grained inspection of code execution to monitor run time instructions.
we used the pin dynamic instrumentation platform for this feature.
also we instrumented the windows apis in table that represent signal and wait system calls to identify units.
our evaluation shows that these cover all the applications we have tested.
table windows apis instrumented for unit identi cation.
wait signal wait getmessage postqueuedcompletionstatus getqueuedcompletionstatus readconsole setevent waitforsingleobject accept resetevent waitforsingleobject recv pulseevent waitforsingleobject in order to retrieve high resolution time stamps for performance checks we used cpu performance counters via thequeryperformancecounter windows api which is provided in windows xp and later.
when calculating the time threshold of a unit type we use k for our experiments based on the three sigma rule .
withk a value falls within the range of the standard deviation with the probability of .
so the false alarm rate is .
statistically.
existing work also leverages a similar approach with k .
for the insertion of performance guards into programs we used an extended version of detours which we signi cantly improved to support instrumentation of arbitrary instructions.
bistro is used to stretch the application binaries and insert nops before instrumentation.
to inspect the call stack on a performance anomaly we used the capturestackbacktrace windows api .
.
ev aluation in this section we evaluate several aspects of perfguard experimentally.
all experiments are performed on a machine with an intel core i5 .
ghz cpu and gb ram running windows server r2.
we focus on answering the following key questions in our evaluation how successfully can perfguard diagnose real world performance problems?
how e ective is unit clustering based on control ow in performance monitoring?
how robust and accurate is the run time context inference?
what is the performance overhead of perfguard?
.
diagnosing real world performance bugs perfguard enables e cient performance bug diagnosis in production environments.
once the performance guards are inserted into a program perfguard monitors the units of the program at run time.
if any unit type has longer execution time than its threshold it is reported along with its call stack.
we chose popular windows applications to evaluate perfguard on various event based programs servers apache http server and mysql server text based clients mysql client and gui programs zip file manager notepad and processhacker .
after studying over bug reports for those applications we collected performance bugs caused by diverse root causes incorrect use of apis unexpectedly large inputs and poor design.
table shows the performance bugs detected by perfguard.
the rst two columns show the program name and the identi cation of this bug.
the following ve columns describe the characteristics of the unit type where the performance bug is detected.
jucj jpj andjfjrespectively show the number of distinct call trees the average number of call paths and the average number of functions in the unit type.
jpgjis the number of performance guards inserted into the program to detect the bug.
tis the time threshold in milliseconds for the unit type.
figure shows the example traces that perfguard generates at the detection of increased latencies caused by three performance bugs apache mysql and 7zip s3 in table .
when a performance bug is detected perfguard takes a snapshot of the call stack.
note that the call stack at the time of root cause and the call stack at the time of bug detection share part of the call stacks in common but there may be minor di erences because the program could have called or returned from several functions since the problematic logic was executed.
the gap between the time of bug located manually and the time of perfguard s detection is calculated as the di erence between their respective call stacks shown as din table and figure .
essentially this number may represent the developer s manual e ort to nd a root cause from the detection point and we aim to nd a balance between minimizing d and adding too many performance guards which will increase the run time overhead.
the two columns root cause binary and root cause function show the root cause of performance bugs which are manually determined from their bug reports and resolutions maintained in the software s bug repositories.
we note that this information is collected only for the evaluation purposes as the ground truth and perfguard does not need nor have access to such information.
in all cases the performance bugs are correctly detected along with the speci c details on the buggy unit types.
the comparison between the stack on detection and the root cause shows that the call stack distance d was i.e.
only to functions away .
after examining just a few functions in the call stack provided by perfguard developers will be able to easily identify the bug s root cause.
in addition to the applications that are open source we successfully analyzed and found units from a set of proprietary software shown in table .
table unit identi cation of proprietary software.
program name unit loop binary acrobat reader acrord32.dll internal library visual studio msenv.dll internal library windows live mail msmail.dll internal library evernote evernote.exe main binary calculator calc.exe main binary wordpad mfc42u.dll external library paint mfc42u.dll external library the unit loop binary column shows the binary where the unit loop is detected.
we do not use these applications in the evaluation due to the lack of ground truth and space constraints.
601table evaluation of perfguard on the root cause contexts of real world performance bugs.
program bug unit type characteristics perfguard evaluation name idjucjjpjjfjjpgjtdroot cause binary root cause function apache 4libapr .dll internal library apr stat mysql client 8mysql.exe main binary my strcasecmp mb mysql server 3mysqld.exe main binary item func sha val str zip fm s1 37zfm.exe main binary refreshlistctrl zip fm s2 17zfm.exe main binary refreshlistctrl zip fm s3 27zfm.exe main binary refresh statusbar zip fm s4 37zfm.exe main binary refreshlistctrl notepad 6notepad .exe main binary scintillaeditview runmarkers processhacker 4processhacker.exe main binary phallocateformemorysearch processhacker 5toolstatus.dll plug in processtreefiltercallback unitcall stacktlibapr .dll!convert protlibapr .dll!more finfolibapr .dll!apr file info getlibapr .dll!resolve identrlibapr .dll!apr stat mod dav fs.so!dav fs walker mod dav fs.so!dav fs internal walk mod dav fs.so!dav fs walk ... libhttpd.dll!ap run process connection libhttpd.dll!ap process connection libhttpd.dll!worker mainunit threshold violation in httpd.exe performance bug apache 45464unitcall stacktmysqld.exe!get int argmysqld.exe!
outputmysqld.exe!sprintfrmysqld.exe!item func sha val str mysqld.exe!item save in field mysqld.exe!fill record ... mysqld.exe!dispatch command mysqld.exe!handle one connectionunit threshold violation in mysqld.exe performance bug mysql 49491unit looplocationd 4unitcall stackt7zfm.exe!nwindows ncom mypropvariantclear7zfm.exe!getitemsizer7zfm.exe!refresh statusbar 7zfm.exe!onmessage ... user32.dll!dispatchmessageworker user32.dll!dispatchmessagew 7zfm.exe!winmainunit threshold violation in 7zfm.exe performance bug zip s3d 3d unit looplocationunit looplocation threshold violating function root cause function common context of andlegends rttr figure sample traces automatically generated by perfguard for three performance bugs in table .
table performance of top costly unit types.
is the mean in second.cis the performance variance in percentage where c 100and is the standard deviation.
a apache http server.
rank c .
.
.
.
.
.
.
.
.
.
avg.
.
b zip file manager.
rank c .
.
.
.
.
.
.
.
.
.
avg.
.
.
performance distribution of clustered units perfguard monitors application performance by recognizing units which are clustered into unit types based on control ow automatically.
in this section we evaluate the effectiveness of our unit clustering.
we assume that the same type of units have a consistent execution behavior and thus have similar execution time.
to show that our assumption is valid in real world applications we measured the means and variances of unit execution time in apache http server and zip file manager which represent server programs and gui applications respectively.
a set of performance guards were created and inserted into each application binary in order to record the unit time during the program execution.
table shows this data for the applications.
each row represents the performance statistics of one unit type which is a group of units clustered by the similarity of control ow.
relative standard deviation in percentage c is used to show the performance variance.
to generate realistic workloads for apache http server we used the web pages provided by bootstrap .
these pages have various sizes and contents.
apachebench ab is used to request each of the bootstrap examples times with the concurrency of threads.
this yielded a much larger number of units but due to the sim ilarity among them e.g.
similar page fetches these units were clustered into only unit types.
for zip file manager we performed the standard set of ui actions that users would take.
speci cally we navigated through various directories using the le manager created and deleted les compressed and uncompressed les and clicked on the menu and tool bar items.
units were recognized and they were categorized into unit types.
in both cases the performance deviation of the top most costly unit types is about percent .
for apache http server and .
for zip file manager .
note that the variation is quite low since performance bugs typically incur with more than percent of latency di erence.
this result shows that the automated clustering based on control ow accurately captures similar behaviors exhibiting similar run time latencies.
we nd that the performance deviation of each unit type is relatively small despite the varying input workload because the variation in workload both in size and content likely alters the program s control ow.
we observed that those performance deviations also come from other factors such as underlying libraries and system calls that contribute to the variation of unit performance.
.
run time context inference overhead of run time context inference.
in this experiment we measure the overhead of our run time context inference the key mechanism used in unit type inference.
figure 7a shows the overhead of windows apis capturestackbacktrace versus our approach using di erent call stack sizes.
traditional stack walk approaches cause non negligible overhead due to traversing all stack frames to infer the unit type.
moreover the overhead signi cantly increases as the call stack grows.
in contrast our mechanism is much faster and is not a ected by the size of the call stack.
such scalability is achieved because our context inference only has to read a hardware register regardless of the depth of the call stack.
in our experiments an average call stack size at the instrumented functions is .
and figure 7a shows that our approach .
sec is times .
100latency sec call stack depthcapturestackbacktrace w hash capturestackbacktrace perfguard context inference a overhead of run time context inference log scale windows api capturestackbacktrace and perfguard.
100response time ms request with perfguard without perfguard b performance of apache http server with and without perfguard.
512transactions per second threadswith perfguard without perfguard c performance of mysql server with and without perfguard.
figure performance evaluation of perfguard.
faster than windows stack walking .
sec with hashing and .
sec without hashing .
accuracy of run time context inference.
in this experiment we study the accuracy of run time context inference technique.
we choose one server apache http server and one client application mysql client .
we execute each application with a set of training inputs and record a calling context and a stack depth for each function call.
for a given function and stack depth if there exists only one calling context we can correctly infer that context at run time.
however if there exists more than one calling context for the stack depth we cannot uniquely indicate the calling context.
our approach was able to correctly identify the calling context from .
of function calls in apache and .
of function calls in mysql.
in other words the stack depth uniquely indicates the call stack .
of the time in apache and .
in mysql.
note that even though we fail to uniquely infer the calling context for a few cases it does not mean that perfguard will fail to identify the corresponding unit type.
our unit type inference technique discussed in x4.
still may identify the correct unit types as the program executes the following functions.
the result in this experiment shows our technique is signi cantly faster than traditional stack walk based technique while we can accurately infer the calling context at run time.
.
performance overhead of perfguard perfguard is designed to be used in the production stage so its run time overhead is a critical evaluation metric.
we present this data in the following two sub categories.
microbenchmarks on performance guards.
a major source of performance overhead of perfguard is performance guard components.
thus it is important to keep the overhead of performance guards as low as possible.
table shows the latency of the individual performance guard functions.
table latency of performance guards.
performance guard latency seconds onloopentry .
onunitstart .
onunitcontext .
the latency is measured from executions of a performance guard component and the table shows the aggregated time.
in all three cases the latency of a single performance guard execution is less than .
nanosecond.
overall impact on application performance.
figure 7b and figure 7c show the performance impact of perfguard on apache http server and mysql server respectively.the two server programs are selected due to the availability of their benchmarking tools.
in figure 7b the x axis is the number of requests sent in percentage and the y axis is the response time.
we used apachebench ab to generate web requests.
figure 7c shows the number of completed transactions per second by mysql server with an increasing number of threads .
sysbench is used for the benchmarking to query a table with rows concurrently.
functions of apache http server and functions of mysql server are instrumented by perfguard as described inx5 to show the overhead.
the results show the overhead by perfguard on two applications is less than .
.
related work execution partitioning.
beep derives the units of program execution using loop iterations.
we leverage the approach of beep in the windows platform to identify application execution units.
unlike beep which is designed to detect the inter dependency of units for security analysis perfguard identi es units based on temporal loop relationship and focuses on the classi cation of units with similar control ow for performance diagnosis.
performance debugging in production.
perftrack provides a performance debugging feature used in microsoft s software.
this system manually inserts hooks into the key functions of applications to measure their run time performance and report any incident when their execution time surpasses internal thresholds.
this approach is e ective due to developers domain knowledge regarding which code represents the key functions and how long their execution should be.
its downside is that it requires the source code and the application knowledge which may not be readily available and the manual e orts for the threshold determination and source instrumentation.
in this paper we aim to enable a general functionality similar to perftrack applicable to any software without source code or domain knowledge.
several approaches use call stacks to investigate performance problems.
introperf infers the performance of individual functions in the call stacks captured by a system event tracer e.g.
etw .
perfguard determines the key application workload using unit type identi cation and the observation of its run time performance is done by instrumented code.
therefore it achieves a more e cient and focused monitoring compared to sampling based introperf.
there exist techniques that use information from os reports for performance and or reliability issues.
in particular microsoft has a system called windows error reporting wer which collects call stacks from numerous windows machines.
stackmine models cpu consumption bugs and wait bugs based on clustered call stack patterns from call stack mining which allows to identify common root causes from diverse call stacks in di erent con gurations and deployments.
bartz et al.
proposed a machine learning based scheme to compute call stack edit distance from failure reports providing a probabilistic similarity metric for failure parts.
as shown in these approaches in order to understand the relevance of code to the root cause of a bug call stack is a key structure to determine its context becoming the index of code execution.
a general utility function e.g.
malloc can be used by multiple functions and depending on its caller its execution may show corresponding behavior.
to recognize this distinction perfguard uses call stack both in unit identi cation and at run time.
after unit identi cation we derive a performance threshold for an unit context which is recognized at run time and its threshold is veri ed.
log2 is a cost aware logging mechanism that controls the overhead of logging while keeping its performance diagnosis capability.
this approach is useful in practice but they have di erent focus from our work a cost aware run time logging.
performance pro lers.
performance analysis tools such as are popular in the development stage to determine the bottleneck of software functions.
these tools constantly and blindly sample cpu usages of target program some of which rely on pro ling code embedded into the program which requires a compilation option.
the accuracy of performance diagnosis highly depends on the frequency of sampling and higher frequency causes higher performance overhead.
therefore they are not commonly used in the production stages.
advanced techniques such as genetic algorithm symbolic execution and guided testing are used to automatically generate the test inputs to trigger performance bugs.
perfguard can complement these approaches by providing better accuracy in unit threshold determination and run time detection of threshold violation.
xiao et al.
proposed a technique to use di erent workloads to identify workload dependent performance bottlenecks in gui applications.
our technique may potentially complement their approach by providing the unit type classi cation and supporting the run time violation detection.
in future work we also plan to leverage their technique to accurately identify workload dependent unit thresholds in training runs.
caramel proposed a static analysis technique to automatically nd and x performance bugs that break out of the loop wasting computation from c and java code.
toddler nds repetitive memory accesses in loops for debugging java program performance.
in comparison perfguard focuses on nding time delays caused by various reasons memory accesses can be one of them for native programs.
mobile app performance.
there are approaches that monitor mobile application binaries to identify the critical paths of user transactions and provides detailed performance breakdowns on the detection of performance issues.
compared to that our approach utilizes a more general concept of workload units based on the execution partitioning and unit clustering to target a wider scope of applications.
.
discussion target applications of perfguard.
perfguard automatically recognizes application units and detects performance bugs associated with their latency.
therefore the main target of perfguard is the set of applications with the concept of workload units also known as app transactions and bounds of expected response time.
most server programs interactive software and gui applications belong to this category.
the performance of server programs are typically de ned by service level agreements sla which are standardized service contracts regarding quality and responsibilities on violations agreed between the service provider and the service user.
given a request from a client the server should respond within a bounded response time.
another set of programs with workload units is the programs with the graphical user interface gui because people have limited tolerance on the response in practice.
related approaches in human interface show the acceptable response delay for a user interface is around ms. user interactive applications can take bene ts of perfguard due to their workload units and corresponding performance.
training and variance of workload.
perfguard requires a training stage to generate a pro le of software workload.
it is theoretically incomplete and there is a chance that inexperienced workloads can appear during production runs.
to address this issue perfguard uses the unit type inference which allows a variation of unit control ow.
our evaluation shows that perfguard is su ciently e ective in monitoring the performance of popular applications.
table and figure show that perfguard e ectively detects real world performance bugs with negligible run time overhead.
also existing techniques can be leveraged to improve our training coverage.
we envision future integration of perfguard and these techniques.
.
conclusion we present perfguard a novel system to enable performance monitoring and diagnosis without source code and code knowledge for a general scope of software.
perfguard automatically identi es loop based units and determines their performance thresholds.
binary only software is transparently instrumented to include performance guards which monitor application performance e ciently and report detailed call stacks on the detection of performance anomalies.
in the evaluation of six large scale open source software with ten real world performance bugs perfguard successfully detected all of them with the run time overhead under showing an e cient solution for troubleshooting performance problems in production environments.
.