towards automating precision studies of clone detectors v aibhav saini farima farmahinifarahani y adong lu d iy a n g pedro martins hitesh sajnani pierre baldi and cristina v .
lopes university of california irvine usa email vpsaini farimaf yadongl1 diy4 pfbaldi lopes uci.edu pedromartins4 gmail.com microsoft usa email hitsaj microsoft.com abstract current research in clone detection suffers from poor ecosystems for evaluating precision of clone detection tools.
corpora of labeled clones are scarce and incomplete makingevaluation labor intensive and idiosyncratic and limiting inter tool comparison.
precision assessment tools are simply lacking.
we present a semiautomated approach to facilitate precision studies of clone detection tools.
the approach merges automaticmechanisms of clone classification with manual validation of clonepairs.
we demonstrate that the proposed automatic approach hasa very high precision and it significantly reduces the numberof clone pairs that need human validation during precisionexperiments.
moreover we aggregate the individual effort ofmultiple teams into a single evolving dataset of labeled clonepairs creating an important asset for software clone research.
index t erms precision evaluation clone detection machine learning open source labeled datasets i. i ntroduction source code clone detection is the task of finding similar software pieces according to a certain concept of similarity.
these pieces can be statements blocks of code functions classes or even complete source files and their similarity can be syntactic semantic or both.
cloning in software source code is as ubiquitous as software itself which gives clone detection tools many applications plagiarism and copyrights enforcement detection of errors faults bugs code optimization and refactoring analysis of programmers behaviors or program understanding are some examples.
in a systematic literature review rattan et al.
found at least clone detection tools and techniques .
clone detectors differ substantially in the underlying techniques and scopeof application.
in terms of technical approach used onecan find techniques that are learning based token based tree based graph based or text based .
with respect to the scope one can find tools that are language specific and language agnostic with varying degrees of specialization.
while there are many tools and techniques published to detect clones not much effort is spent on streamlining the evaluation of these tools and techniques.
the effectiveness of clone detection tools is usually evaluated in terms of precision and recall.
precision is the percentage oftrue positives clone pairs within a set of code pieces identifiedby the tool as clones.
recall is the percentage of true positivesthat are retrieved by the tool within the complete set of knownclones.
the measurement of precision and recall in general relies on the existence of labeled datasets.
a good labeleddataset provides realistic data and credible labels on all the constituents that should be detected by the analysis tool in the case of clone detection all clone pairs are labeled as such.
a labeled dataset for clones allows one to measure how many of the clones identified by a certain tool are indeed clones or not precision and how many of the true clone pairs are detected by the tool recall .
publicly available labeled datasets also known as benchmarks allow direct inter tool comparisons without the uncertainty that exists when two tools are compared with different datasets.
in the field of code clone detection building labeled datasets is particularly challenging and requires software expertise.methods can exist inside methods or they can vary wildly in size scope semantics and nature.
in addition to manually validate all the possible clones would require quadratic comparisons a combinatorial problem that becomes infeasible with growing codebases.
for this reason most datasets used in code clone studies are either small or synthetically created or are labeled only for a subset of pairs.
the dataset by bellon et al.
the dataset by murakami et al.
soco or bigclonebench have one of the above mentioned limitations.
there has been good progress in measuring recall systematically of clone detection tools.
based on bigclonebench dataset bigcloneeval estimates recall automatically by measuring how many of the labeled clone pairs are includedin the output of a clone detector.
however bigcloneeval stops short of estimating precision because bigclonebench does not contain labels for all possible clone pairs in it.
if a clone detector identifies a clone pair that is not marked as such only manual inspection can tell whether the pair is a false positive or a true positive.
since manual inspection is a difficult labor intensive and time consuming task most clone detection approaches estimate their precision by sampling a number of their reported clone pairs and then manually inspecting thesampled set .
so while clone detectors report recall using bigcloneeval the determination of their precisionis still a subjective and a manual process leading to difficulties in comparing with other tools.
the lack of an established labeled dataset for precision creates a number of problems ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
i precision estimation can suffer from sampling bias when sample set is small and not representative of the population ii large manual effort is required to conduct precision studies.
as each pair in the sample needs to be evaluated often by multiple judges the total manual effort required to complete a precision study is substantial and iii the efforts put into the manual inspection of clone pairs are not reused.
each time authors want to estimate their tool s precision they typically start from scratch.
to address these problems we present inspectorclone an approach designed to facilitate precision studies for code clone detectors.
inspectorclone helps in evaluating precision of clone detectors and in the process creates a dataset of well known source code clones.
inspectorclone automatically resolves as many clone pairs as possible identifying a subset of pairs where manual inspection is most needed.
our experiments demonstrate that inspectorclone reduces the number of clone pairs that need manual inspection by on an average.
at the end the results automatic and manual are aggregated to report the precision of the clone detector.
moreover the human judgments are stored to create a manually labeled dataset of clones.
this dataset is beneficial in inter tool comparison and also for the exploration of machine learning and artificial intelligence techniques in clone detection.
inspectorclone can be accessed at the main contributions of this work are the following i a semiautomated high precision approach for classification of clones that reduces the manual effort of precision studies significantly ii a publicly available web application that enables clone detection researchers to conduct precision experiments of clone detection tools and techniques and iii an evolving dataset of manually validated clone pairs that is publicly available.
with time as inspectorclone is used the number of humanly validated clone pairs will increase in the dataset.
this work is organized as follows.
in section ii we present inspectorclone the tool implementation of our approach.
the automatic mechanisms of clone pair resolution and related concepts are elaborated in section iii and then it is evaluated in section iv.
section v presents related work and threats to validity are explained in section vi.
finally we present the conclusions and future work in section vii.
ii.
i nspector clone measuring the precision of a clone detector is not a trivial process.
to measure the precision one can choose to manually validate all the clone pairs reported by a clone detector.
this process however is extremely time consuming and impractical as the number of clone pairs reported by a tool on a standard dataset like bigclonebench is in millions.
a more practical process is to estimate the precision by humanly validating a random and statistically significant sample of clone pairs.
this is what researchers do to estimate the precision of clone detectors .
in this process after running a clone detector on a dataset and getting the clone pairs a random and statistically significant sample set of these clone pairs isassigned to multiple judges for manual inspection.
the judges examine each pair to decide if it is a true clone and or what type of clone it is.
when all sampled pairs have been validated by all judges researchers aggregate the judges decisions usually by taking the majority vote and report precision.
the above process though more practical than humanly validating every clone pair still takes a non trivial amount of time and effort.
moreover the effort put into one study cannot be reused in future studies.
to address these issues we present a web based tool named inspectorclone that helps clone researchers in expediting the precision estimation process.
inspectorclone helps by mimicking this whole process and also by automatically validating a subset of sampled clone pairs thereby reducing the number of clone pairs shown to human judges.
moreover by storing human judgments in a centralized database this tool turns humans manual effort to a long lasting resource that can be reused in future studies.
inspectorclone conducts precision studies on the dataset curated by svajlenko et al.
for facilitating recall studies .
svajlenko et al.
curated this dataset using ijadataset .
to conduct recall study using bigcloneeval.
the dataset is available for download on inspectorclone s website.
inspectorclone does not run the clone detection tool instead it expects users to upload the clone pairs reported by their tool to the website.
the work flow is as follows.
a user john registers himself and his tool into inspectorclone.
after registration john can download the dataset of source code and run it on his clone detector.
john then uploads the clone pairs to inspectorclone where inspectorclone filters out the methods that are less than tokens a standard filter used in precision studies .
john now creates an experiment to estimate the precision of his tool.
he then invites multiple judges to evaluate the pairs.
once the judges are invited inspectorclone selects a random and statistically significant sample of clone pairs.
from this sample inspectorclone tries to automatically validate as many pairs as it can.
all of the remaining pairs of the sample which inspectorclone did not resolve are then shown to the judges.
when a judge alice starts an experiment assigned to her she is shown a web page as shown in figure .
all unresolved pairs will be shown to her.
this page is composed by a split screen with two columns showing both members of a pair.
the code is syntax highlighted to increase the readability.
alice must then decide if this pair does indeed represent a clone or not if it is a true or a false positive .
there are two optional form elements one to select the clone type and another to leave a comment.
when all of the unresolved pairs have been validated by all judges inspectorclone aggregates their decisions by taking the majority vote and creates a precision report.
in case there are even number of judges inspectorclone treats a pair as a true positive only when more than of the judges vote for it to be a clone pair.
inspectorclone stores the human judgments in a centralized database.
with time we expect the number of humanly judged pairs to increase in this database thereby creating a valuable asset for the community.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
v alidation of clone candidates on inspectorclone.
iii.
a utoma tic classifica tion of clones as explained in the previous section to estimate the precision of a clone detection tool inspectorclone needs to validate only a random and statistically significant sample set of the clone pairs reported by the tool.
the number of these pairs in such a sample set is small and therefore inspectorclone can use techniques which are very precise without caring much about the scalability aspects of the techniques.
also an automatic approach must be able to resolve pairs with very high precision otherwise researchers will fall back to the completely manual process.
with this in mind we designed a semiautomated approach to conduct precision studies using inspectorclone.
the automatic mechanism of inspectorclone has a very high precision but it compromises on recall as it only resolves those pairs on which it has high confidence.
the unresolved pairs are then shown to human judges for manual inspection.
we note that clone detection tools operate at various granularities like statements block of code methods files et cetera.
also clone detection can be carried out for software written in various languages like java c c and python among others.
in this work we narrow down our focus to facilitate precision studies for method level clone detectors which find clones in software systems written in java.
a. definitions in this section we elaborate on the terms and definitions that are pivotal to discussing inspectorclone s mechanisms.
clone pair a pair of code fragments that are similar specified by the triple f1 f2 including the similar code fragments f1 and f2 and their clone type .
clone types based on the literature our work uses the following four types of source code clones the first threebeing similar on the textual and syntactic level and the fourth type defining similarity on the functional semantic level type i identical code fragments except for differences in white space layout and comments.
type ii identical code fragments except for differences in identifier names and literal values as well as type i differences.
type iii syntactically similar code fragments that differ at the statement level.
the fragments have statements added modified and or removed with respect to each other in addition to type i and type ii clone differences type iv syntactically dissimilar code fragments that implement the same functionality.
the definition to classify clones as type iii does not specify what should be the minimum syntactical similarity between the methods of a clone pair to be classified as type iii.
also the lack of consensus in the community of clone researchers about this similarity makes it difficult to separate type iv and type iii clones.
to address this issue the popular clone benchmark bigclonebench has divided the zone between type iii and type iv into four subcategories based on syntactical similarity values v ery strongly type iii vst3 with similarity in range of .
.
strongly type iii st3 with similarity being in .
.
moderately type iii mt3 with similarity in range of .
.
and weakly type iii wt3 having similarity in the range of .
.
.
more details about these subcategories can be found elsewhere .
action token action tokens of a method are the tokens corresponding to the methods called and class fields accessed by that method .
additionally the array accesses made by a method are also special action tokens namely arrayaccess and arrayaccessbinary where array access of kind arr is an arrayaccess action token and arr is an arrayaccessbinary authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
listing example action tokens 1public enumeration children enumeration allchildren super .
children v ector filtered new v ector diligentnode node while allchildren .
hasmoreelements node diligentnode allchildren .
nextelement if !
node.
isfiltered true filtered .
addelement node return filtered .
elements type i?
type ii?
type iii?method method 2resolved yes noyes noyes noshow to judge automatic resolution fig.
the pipeline for clone validation.
action token.
in the code provided in listing action tokens are children hasmoreelements nextelement isfiltered addelement and elements .
action filter a filter which ensures a minimum amount of similarity between the action tokens of two methods .
we use overlap similarity calculated as sim a1 a2 a1 a2 to measure the similarity between the action tokens of two methods.
here a1anda2are sets of action tokens in methodsm1andm2 respectively.
each element in these sets is defined as t fr e q wheretis the action token and freq is the number of appearances of this token in the method.
m1andm2satisfy the action filter ifsim a1 a2 max a1 a2 where is action filter threshold such that .
b. overview of the approach the methodology for clone resolution follows the pipeline presented in figure .
the two methods in a candidate pair1 go through a series of steps in which they are checked against a certain clone type.
if at any step a pair is evaluated as a true clone pair it is marked as a true positive and the system proceeds to the next candidate pair.
otherwise if all of the steps are failed to evaluate a pair as a true positive the pair is presented to the human judge for manual inspection.
these steps are ordered by computational complexity for system performance and also by increasing clone type complexity and are individually described in the next sections.
c. automatic resolution of type i clones as described in section iii a two pairs are type i clones if they are exact replicas when neglecting source code comments 1a candidate pair consists of two piece of code reported as clone pair by a clone detection tool.
our approach validates these pairs and only when they are resolved as true positives they are called clone pairs.t able i method level software metrics from name description name description xmet external methods called heff halstead effort to implement vref variables referenced hdif halstead difficulty to implement vdec variables declared exct exceptions thrown nos statements excr exceptions referenced nopr operators cref classes referenced noa arguments comp mccabes cyclomatic complexity nexp expressions cast class casts nand operands nbl trl boolean literals mdn maximum depth of nesting ncl trl character literals loop loops for while nsl trl string literals lmet local methods called nnl trl numerical literals hvoc halstead vocabulary nnull trl null literals and layout2.
this makes the validation of type i candidates similar to a simple string comparison after removing certain elements.
we use algorithm to check if a candidate pair is a type i clone.
starting with a candidate pair the algorithm first removes all source code comments from both method bodies lines and then removes white spaces and newlines from them lines and and finally computes and compares the hash sha of both method bodies line .
algorithm automatic type i resolution input m1andm2are strings representing the method bodies including method signature of two methods for which we want to know if they are type i clones.
output boolean function istype one m1 m2 m1 r emove comments m1 m2 r emove comments m2 m1 r emove whitesp aces andnewlines m1 m2 r emove whitesp aces andnewlines m2 return hash m1 h ash m2 end function d. automatic resolution of type ii clones to resolve type ii pairs automatically we use two heuristics as described below action heuristic action tokens of a method form a more stable semantic signature for the method than the identifiers or types chosen by the developer.
this is because identifiers and types often change in duplicating methods while action tokens tend to remain the same.
the reason is that methods and class attributes represented by action tokens bring pre implemented functionalities which reduce the burden of coding and hence are not probable to be removed or modified after cloning.
metric heuristic software metrics measuring different characteristics of source code can capture structural information of a method.
these measurements are resilient to changes in identifier names and literals a useful property in the detection of type ii clones.
hence we use method level software metrics shown in table i for type ii resolution.
the details of these metrics can be found elsewhere .
a detailed explanation about the application of action tokens and software metrics in clone detection can be found in .
we use algorithm to check if a candidate pair is a type ii clone.
first we get a list of action tokens for both methods line 2the syntax of java is not dependent on layout so we can ease the definition of type i clones.
for layout dependent syntaxes like the ones found in python or haskell this approach would require a more careful deliberation authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
and .
then we compare if these lists are identical line that is the contents along with their order of appearance in these lists match.
if the lists are identical we get a list of metrics for both methods line and and then return true if these lists are identical line else return false.
this algorithm ensures that a candidate pair is resolved as type ii only when there is a match in both the metrics and the action tokens.
the rational is that type ii clones differ in identifier names and literal values while their structure captured by metrics and their method calls and accessed class fields captured using action tokens remain the same.
algorithm automatic type ii resolution input m1andm2are strings representing the method bodies including method signature of two methods for which we want to know if they are type ii clones.
output boolean function istype two m1 m2 listat ofm g etaction tokens m1 listat ofm g etaction tokens m2 ifisidentical listat ofm listat ofm then listmetm g etmetrics m1 listmetm g etmetrics m2 return isidentical listmetm listmetm end if return fa l s e end function e. automatic resolution of type iii clones typically syntactic clone detectors detect clones in st3 and vst3 categories.
this is because there is a high probability that code snippets with less than syntactical similarity are coincidentally similar.
moreover to detect clones between similarity range detectors may need to capture the semantic similarity a harder problem in clone detection.
therefore achieving very high precision in the automatic resolution of all of these subcategories is considered hard.
as we want to make sure whatever candidate pair our approach resolves as a clone pair is indeed a true clone pair we focus on the first two subcategories namely vst3 and st3.
to resolve type iii candidates automatically we first make the candidate pairs go through an action filter and the ones that survive this filter are fed to a deep learning classifier that predicts whether they are true clone pairs.
placing action filter before the classifier ensures that candidate pairs whose methods do not share a specific amount of functionalities are filtered out early and shown to judges instead of being resolved automatically hence increasing precision.
in the following subsections we first explain the training set used in training the deep learning model and next we describe the details of the trained model.
finally we provide the results of a sensitivity analysis we did for selecting the proper action filter threshold to resolve type iii clones with high precision.
dataset curation since the machine learning classifier is supposed to resolve type iii candidates we need a training set with clone pairs from this category.
also to resolve clone pairs with very high precision we want our dataset to contain true clone pairs which are very similar in terms of both their semantics and structure.
to generate such dataset t able ii dataset creation process statistics rowid dataset number of pairs sourcerercc pairs cloneworks pairs sourcerercc cloneworks intersection intersection after removal clone pairs non clone pairs at action filter union of pairs by sourcerercc cloneworks nicad non clones after removing union pairs non clones after random sampling total rows in final dataset we use two token based state of the art clone detectors cloneworks aggressive mode and sourcerercc .
the configurations of these tools are shown in table vi.
these clone detectors detect type iii clone pairs up to st3 category where the methods in each clone pair have high structural similarity.
on the other hand we ensure high semantic similarity in the methods of each clone pair in our dataset by using action filter with threshold set to .
the starting dataset used to generate our training dataset is bigclonebench.
the numbers related to dataset creation process are reported in table ii.
the training set includes equal number of both assumed positives clones and assumed negatives non clones .
to get the set of assumed positives we took an intersection of the clone pairs detected by the two tools rowid in table ii .
we then removed all type i and type ii pairs from this intersection and selected the pairs which satisfy our action filter rowid .
to ensure that these pairs are true clone pairs we randomly sampled pairs a statistically significant sample with confidence level and confidence interval and validated them manually.
two judges who are also the authors of this paper independently went through these clone pairs and unanimously found all pairs to be true clone pairs.
listing shows an example of true clone pair vst3 found by the judges.
both methods in this example seem to have a very similar aim first they fill a linkedlist line and and then they iterate over the linkedlist to remove its contents lines to and lines to .
the methods not only share many action tokens their structures also look very similar.
moreover the line and token similarity between the methods are high making this pair a good example of a true positive.
the training set needs not only positive samples of clones but also negative ones.
getting these pairs is considerably more difficult while there is an enormous amount of code pairs that are not clones of each other for machine learning purposes it is not useful to include pairs that have no similarities whatsoever.
ideally we would like to include pairs that we know with high certainty are not clones but that are sufficiently similar that they could be confused as clones.
to get such assumed negative pairs we modified oreo a clone detector designed to detect type iii clones even in harder clone categories to predict non clones such that they have at least similarity in their action tokens rowid .
the original source code of oreo is available at .
then we took a union of the clone pairs reported by three state of the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
listing example vst3 clone pair 1private boolean dopurgestudy dirwriter w dirrecord parent int counter throws ioexception boolean matchall true linkedlist toremove new linkedlist for dirrecord rec parent .
getfirstchild true rec !
null rec rec .
getnextsibling true if dopurgeseries w rec counter toremove.add rec else matchall false if matchall return true for iterator it toremove.
iterator it .
hasnext counter w.remove dirrecord it .
next return false private boolean dopurgeinstances dirwriter w dirrecord parent int counter throws ioexception boolean matchall true linkedlist toremove new linkedlist for dirrecord rec parent .
getfirstchild true rec !
null rec rec .
getnextsibling true file file w. getreffile rec .
getreffileids if !
file .
exists toremove.add rec else matchall false if matchall return true for iterator it toremove.
iterator it .
hasnext counter w.remove dirrecord it .
next return false art clone detectors cloneworks sourcerercc and nicad rowid .
nicad s configurations are shown in table vi.
to ensure high confidence in the non clone pairs we removed any non clone pair which is present in the union set rowid .
finally we did a manual analysis similar to what we did for true positives to gain more assurance about the non clone pairs.
the same two judges independently as before went through a random sample of pairs.
they found many examples which were definitely non clones and also found some examples of mt3 and wt3 clones where the pairs shared high semantic similarity but the structural similarity was weak.
this is useful in increasing the precision of the machine learning model since it learns to classify these harder pairs which are closer to the threshold boundary as non clones.
this is a desirable behavior as these harder cases are then left for human judgment.
listing shows an example of an mt3 pair found by the judges.
both methods in this pair are semantically similar as they both intend to copy the contents from an inputstream to anoutputstream .
the structural and token similarity between the two methods however is low making it harder to detect as a clone pair by many token based clone detectors.
similarly listing shows another pair that semantically are performing the same task but the structural similarity between the two methods is very low.
such methods are good candidates thatlisting example mt3 clone pair 1public static void copy inputstream i int buf outputstream o throws ioexception byte b new byte for int g i .
read b if g break o. write b g public static void copyto inputstream in outputstream out throws ioexception byte buffer new byte int n while n in .
read buffer !
out .
write buffer n out .
flush listing example wt3 clone pair 1protected void copy inputstream in outputstream out throws ioexception byte buf new byte int len while len in .
read buf out .
write buf len 7public static long copy inputstream is outputstream os throws ioexception byte buffer new byte int readed long length while readed is .
read buffer !
if readed length readed os .
write buffer readed else timerhelper.notsafesleep return length should be left for human judgment.
we then took a random sample of pairs rowid from the above obtained pairs rowid to have the number of non clone pairs matched with the number of true clone pairs rowid .
finally we aggregated the pairs from rowid and rowid to create a dataset rowid which we used for training and validating the machine learning model.
each row of this finalized dataset contains a method pair represented as a vector of metrics metrics of table i for each method and a label denoting whether this pair is clone or not.
deep learning model to classify type iii clones we are using siamese architecture to train a deep neural networks dnn model.
siamese models are well suited for problems where two things need to be compared against each other for example comparing fingerprints .
also in a recent work on clone detection saini et al.
compared different architectures of deep neural networks dnn and found siamese dnn to outperform the other dnn architectures .
we also carried out model comparison analyses on the train dataset at hand and found siamese model to outperform other models.
model comparison results are explained later in this section.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
featuresinput features128 units128 units128 units128 units units units units16 unitsclassification unittwo identical subnetworks comparator layer layer layer layer 4layer layer layer layer fig.
siamese architecture t able iii precision and recall on the test set for the siamese neural network model using different thresholds.
threshold precision recall .
.
.
.
.
.
.
.
.
.
.
.
figure shows the architecture of the siamese model we trained for our approach.
it consists of three components i two identical subnetworks ii a comparator unit and iii a classification unit.
the input to the model are the feature vectors of each method metrics in the candidate pair.
these feature vectors are then transformed and processed by the two subnetworks and the comparator.
finally the classification unit outputs a number between and representing the probability of a pair being a clone.
a more detailed explanation of this architecture and its components can be found elsewhere .
to perform the model selection experiments the train dataset of code pairs is randomly divided into for training and for testing.
furthermore pairs from the training set are set aside for validation purposes i.e.
for hyperparameter tuning.
first we explored the hyper parameter tuning for the siamese model.
the best performing model is the one shown in figure .
each of the two subnetwork layers in this model has layers each with neurons and the comparator has four fully connected layers of sizes .
the output of the comparator is then fed into a single classification neuron with sigmoidal logistic activation function.
the output of this neuron is a value between and .
normally the values more than .
are assigned label and values less than .
are assigned label .
however since our goal in this problem is to achieve almost perfect precision so that the number of false positives tends to zero during production testing we set the threshold to announce a pair a true clone pair to be .
.
the code pairs which have prediction values between to .
are sent to human judges for further inspection.
table iii shows the precision and recall values on the test set at different thresholds.
as it is observed using this deep learning approach with a threshold of .
yields almost perfect precision .
.
we also compared the siamese dnn to other models with different architectures including a plain fully connectedt able iv precision and recall values on test set threshold .
precision recall logistic regression .
.
shallow nn .
.
plain dnn .
.
siamese dnn .
.
t able v sensitivity analysis statistics threshold auto auto manual type iii type iii fp neural network plain dnn with similar number and sizes of hidden layers as the siamese one a shallow neural network shallow nn with one hidden layer and similar number of parameters and a logistic regression model.
since our final goal is to achieve a high precision all the comparisons are done when the thresholds for all models are set to be .
.
we first compared their performance during the training stage.
figure shows that the siamese dnn outperforms the other models in terms of accuracy on the validation set.
the accuracy of the siamese dnn converges to .
while the accuracy for plain dnn and shallow nn converges only to .
.
figure shows that for the validation loss also the siamese structure is superior to the other models.
the average loss value for the siamese dnn converges to .
as apposed to plain dnn .
shallow nn .
logistic regression model .
.
thus in short the siamese dnn better fits the training data.
next the model performance is compared at the testing stage.
table iv shows that the siamese network has the highest precision equal to .
.
in short this shows that the siamese network has better generalization performance than the other models used in the comparison.
sensitivity analysis we did a sensitivity analysis to find the optimum threshold of action filter with the goal of not having any false positives and maximizing the number of pairs resolved automatically.
methodology .
we used the clone pairs reported by sourcerercc on the bigclonebench dataset.
we ran inspectorclone with four different threshold values of action filter and .
one author manually inspected the clone pairs that are automatically resolved by inspectorclone to figure out the number of false positives in them.
results of this analysis are denoted in table v. the first column of this table shows the examined thresholds and the next three columns respectively denote the number of automatically resolved type i type ii and type iii clone pairs.
the next three columns show the number of false positives observed at each clone category and the last column depicts the number of clone pairs that need the manual validation by humans.
at and thresholds we observed some false positives whereas at and thresholds no false positives were observed.
the number of automatically resolved clone pairs at threshold is greater than this number at threshold .
consequently threshold was selected to be used in action filter.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
v alidation accuracy fig.
v alidation loss iv .
e v alua tion as discussed earlier the main goal of our approach is to automatically resolve as much as clone pairs as possible with high precision.
hence to evaluate it we designed an experiment using inspectorclone and seven clone detectors.
the goal of this experiment is twofold i to understand the impact of our approach on the reduction of manual effort and ii to measure the precision of the automatic clone resolution approach.
we include sourcerercc iclones nicad cloneworks simcad as popular examples of modern clone detectors that support type iii clone detection.
cloneworks comes in two different modes aggressive and conservative we tested inspectorclone on both of these modes.
we also include two recent tools oreo and ccaligner .
while all these tools detect clones in type i type ii and early categories of type iii vst3 and st3 oreo and ccaligner are capable of detecting clones beyond st3 categories such as mt3.
we also wanted to include deckard and cpd however they both detect clones beyond method boundaries.
at this time wecannot reliably conduct a meaningful experiment with themon inspectorclone which only supports method level clone detectors as of now.
also both of these tools report their resultsas clone classes and not as clone pairs.
when we ran processes to generate clone pairs from these clone classes they both produced large amount of clone pairs.
we killed the processes after generating more than 175g of clone pairs for each of them as these are very big files for inspectorclone to process.
we ran all tools on the recall dataset of bigclonebench and obtained the clone pairs reported by each tool.
we then uploaded the clones reported by each tool to inspectorclone and calculated the number of clone pairs automatically resolved in each category and the number of pairs left for manual validation.
we configured inspectorclone to consider only those pairs that have methods with at least language tokens a standard size filter used in precision studies .
to gain high confidence in our experiment results we conducted rounds of experiments for each tool a totalof experiments with tools and cloneworks being executed in two modes .
in each round inspectorclone sampled random candidate pairs from the output of each tool.
inspectorclone then automatically resolved some clone pairst able vi reduction of manual effort tool automatically manual fp tool configuration resolved inspection t1 t2 t3 out of ccaligner18 mil e q cloneworks a mit mode aggressive cloneworks c mit mode conservative iclones254 mit min block nicad99 mil bin true ia true oreo0 mit sourcerercc155 mit simcad15 gt true us true mil as assumed positives leaving the rest for manual validation.
to measure the precision of the automatic resolution part five judges who are also authors of this paper independently went through the whole set of automatically resolved clone pairs to look for possible false positives.
the judges were also asked to report the time they took to complete each round of experiment.
in total it took around 58person hours to complete all experiments rounds per each judge .
the results of this experiment are shown in table vi.
the first column shows the name of the tool.
the next three columns denote respectively the number of type i type ii and type iii candidate pairs that were automatically resolved by inspectorclone.
the fifth column shows the number of candidate pairs that could not be automatically classified and needed manual validation by humans out of the sample of .
the sixth column fp contains the number of false positives after considering majority vote observed by human judges in the automatically resolved pairs.
and finally the seventh column shows the configurations which were used to run the tools.
these configurations are based on our discussions with their developers and also the configurations suggested in .
in the table mit stands for minimum tokens mil authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
listing example candidate pair from oreo 1public static t t readstreamasobject inputstream inputstream class t type throws classnotfoundexception ioexception objectinputstream objectinputstream null try objectinputstream new objectinputstream inputstream return type .
cast objectinputstream .
readobject finally utility .
close objectinputstream public static t extends serializable t deserialise class t class1 file out throws classnotfoundexception try fileinputstream fis new fileinputstream out objectinputstream in new objectinputstream fis object output in .
readobject in .
close return class1 .
cast output catch ioexception ex ex.
printstacktrace return null stands for minimum number of lines bin and ia respectively stand for blind identifier normalization and literal abstraction used in nicad.
stands for similarity threshold for nicad it is difference threshold and for oreo it is action filter threshold is the threshold for input partition used in oreo.
in ccaligner s configurations estands for edit distance and qis the window size .gt and and us stand for greedy transformation and unicode support used in simcad.
as the table shows inspectorclone reduced the number of pairs that need manual analysis for all tools except for oreo.
on an average there is a reduction in the number of clone pairs that are left for human judges.
most reduction is observed for iclones and nicad while for simcad and oreo we observed little to no reductions.
the reduction for rest of the tools ranges from to .
to understand why inspectorclone did not help in reducing the number of pairs for oreo and simcad two judges went through the samples of one of the two experiments conducted for both tools.
for simcad the judges reported out of pairs as false positives of the simcad tool itself .
precision .
the presence of large number of false positives in the pairs of simcad explains why inspectorclone did not help much in resolving its pairs.
for oreo the judges reported a much higher precision of where they reported out of pairs as false positives of the tool.
almost all of the clone pairs in the sample of oreo were found to be in harder to detect type iii categories mt3 and wt3 .
an example of such a pair is shown in listing .
both methods in this example are reading an object from an input stream and then they cast this object into the type they received in their arguments.
though they are performing similar tasks and hence are semantically similar they differ significantly in their structural properties.
this qualifies such pairs to fall in harder to detect mt3 wt3 categories making them good candidates for human inspection.
if we remove oreo and simcad which are two special cases from the analysis on an average inspectorclone resolves of the clone pairs.
the results demonstrate that inspectorclone can have a key role in reducing the burden of manual effort needed by users in precision studies.
apart from the reduction in manual effort the precision of the automatic classification is of a great importance.
out of type i and type ii clone pairs resolved by inspectorclone judges found no false positives giving inspectorclone perfect precision scores in these categories.
the judges reported some false positives in the type iii pairs.
we report the precision for inspectorclone with following two strategies i strategy a when majority vote is considered numbers in column of table vi are based on this strategy and ii strategy b when a pair is considered false positive if any of the judges report it as a false positive.
in strategy a one false positive was found out of type iii pairs giving inspectorclone a precision score of .
.
with this strategy the precision of inspectorclone for all types of pairs combined pairs is .
.
the methods in this false positive pair are big in size nos .
both of these methods make around calls to add method of a list object which results into a high match in their action tokens.
also the arguments to these add method calls in both of these methods are string literals thereby increasing the match count in the nsltrl metric which in turn contributes to a high structural match making inspectorclone resolve the pair as a type iii clone.
however the string literals are very different and there exists a loop in one of the methods which led the judges to mark this pair as a false positive.
in strategy b false positives were found giving inspectorclone a precision score of .
in type iii pairs.
if pairs of all types are combined this strategy gives a precision score of .
.
in their judgments of pairs the judges were unanimously in agreement on pairs giving a conservative estimate of inter rater reliability as .
.
when asked about these false positives all judges mentioned that except for two or three pairs all of these pairs are borderline cases.
for instance one judge noted i am on the fence about this pair .
and for a different pair another judge noted i hesitate if it is a clone or not .
this shows that identification of clones is a subjective task which involves cases that are hard to judge even by humans.
we note that the judges are well aware of the clone definition and clone types and all of them have previously contributed to the research involving software clones or clone detectors.
the results show that the strict thresholds used for automatic clone validation are appropriate if not prefect and that we can rely on the automatically resolved pairs with high confidence.
v. r ela ted work measuring the detection capabilities of clone detection tools is an important part of source code cloning research.
this demands the existence of labeled and standardized datasets that can assist with this measurement.
therefore development of such datasets have been the focus of research throughout the years.
unlike the vast majority of areas for which the tasks for producing labeled datasets are accessible to a large number of people without any special expertise being required authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
developing labeled datasets related to source code cloning requires significant expertise in a narrow topic programming.
for example image or speech recognition can be done by everyone some examples of platforms that assist people with these tasks are amazon mechanical turk or the population of college students.
however such platforms cannot be used in preparation of source code cloning datasets due to the need for the related knowledge.
for this reason researchers have tried to build such labeled datasets in other ways.
most of these works have been successful in estimating the recall since recall estimation does not require the comprehensive labeling of all pairs which is needed in measuring the precision.
here we briefly discuss a set of these efforts.
bigclonebench bcb dataset is probably the most related work to ours.
we have also used it in the evaluation of our approach with inspectorclone.
the underlying corpus of java source code used by bcb is ijadataset .
.
this dataset represents a large inter project java repository containing open source projects with .
million source files and 365m lines of code .
bcb contains a subset of ijadataset curated by human judgment and it contains over million known clone pairs within ijadataset.
it is the result of using ijadataset selecting a series of known algorithms sorting algorithms is one example and tracking possible implementations of these across the dataset.
hence not all possible clone pairs are tagged in this dataset and there exists many pairs that are not tagged.
as a result this dataset cannot be used to measure the precision of clone detectors but it has been used by bigcloneeval bce to estimate the recall of clone detector tools automatically.
another dataset is created by bellon et al.
.
to prepare this dataset bellon manually validated of the clones reported by then year contemporary clone detectors for eight software systems.
svajlenko et al.
found that this benchmark is not suitable for accurate evaluation of modern clone detection tools.
they attributed many of the problems in the dataset to it being built using tools that are now outdated.
it has also been found to have other problems as we see next.
murakami et al.
s dataset is an improvement on the bellon et al.
s dataset.
murakami et al.
found out that since bellon dataset does not contain locational information of gaped lines i.e.
lines that are present in a pair but missing in the other it has not evaluated some type iii clones correctly.
hence they added this information and improved the dataset with this respect.
another effort has been made in soco .
soco was a challenge defined for detection of source code pairs that are reused.
the task was carried out at document level and in c c and java.
two datasets were provided train and test.
train dataset was labeled and used to train an algorithm that can find source code pairs in which one pair is developed reusing the other one.
the test dataset was used to evaluate the accuracy of the developed algorithm with respect to recall 3available at march .precision and f14.
soco contains only java files and c files and these examples do not represent realistic software projects the origin of the source code is unclear .
vi.
t hrea ts to validity and limit a tions the measurement accuracy of our approach and its reduction in manual effort was performed manually and independently by five expert judges over a large sample of clone pairs detected by seven different clone detection tools.
however these five judges were also authors of this work and more importantly like any work that relies on human action practical limitations related to bias and cognition could have affected our analysis.
we mitigated this issue by strictly adhering to the definition of the clone types during manual classification and also by sharing the data for researchers to verify.
the tools used to generate clone pairs and validate our approach can have an impact on the validation of our approach.
for example if a tool has a tendency to detect large clones then the validation will be performed on the large clones too.
to compensate for this bias and to gain more confident in our approach we evaluated it with seven different clone detectors.
another important consideration is that our approach focuses on java methods and is evaluated for methods with tokens on more.
it is possible to apply this methodology to other granularities of source code and to methods smaller than tokens but so would require modifying the existing components of our approach specifically the software metrics.
we measure manual effort involved in precision studies as the number of clone pairs that need manual inspection.
the effort however to inspect clone pairs of different types and sizes varies significantly and therefore may not be linear to the number of pairs.
vii.
c onclusions and future work we have presented a semiautomated approach and a tool inspectorclone that facilitate precision studies.
we evaluated the precision of the automatic clone resolution part of this approach on seven different clone detectors.
our experiments show that the precision of inspectorclone is very high .
making it suitable for conducting precision studies.
further we demonstrated that the number of clone pairs resolved by inspectorclone is significant.
inspectorclone is available to the community and it provides a beneficial framework to access community efforts and to contribute back to them.
as future work we are looking at the implementation of this approach in different programming languages different granularities classes or files instead of methods for example and different scales clone with less than tokens .