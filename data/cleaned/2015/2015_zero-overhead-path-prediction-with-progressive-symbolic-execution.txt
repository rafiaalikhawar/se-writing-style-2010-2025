zero overhead path prediction with progressive symbolic execution richard rutledge sunjae park haider khan alessandro orso milos prvulovic and alenka zajic georgia institute of technology atlanta usa frrutledge sunjae.park khang gatech.edu forso milosg cc.gatech.edu falenka.zajicg ece.gatech.edu abstract in previous work we introduced zero overhead profiling zop a technique that leverages the electromagnetic emissions generated by the computer hardware to profile a program without instrumenting it.
although effective zop has several shortcomings it requires test inputs that achieve extensive code coverage for its training phase it predicts path profiles instead of complete execution traces and its predictions can suffer unrecoverable accuracy losses.
in this paper we present zero overhead path prediction zop an approach that extends zop and addresses its limitations.
first zop achieves high coverage during training through progressive symbolic execution pse symbolic execution of increasingly small program fragments.
second zop predicts complete execution traces rather than path profiles.
finally zop mitigates the problem of path mispredictions by using a stateless approach that can recover from prediction errors.
we evaluated our approach on a set of benchmarks with promising results for the cases considered zop achieved over path prediction accuracy and pse covered feasible paths missed by traditional symbolic execution thus boosting zop s accuracy.
index terms symbolic execution path profiling tracing i. i ntroduction program tracing consists of logging selected events during program execution.
such trace logs are then used for various tasks such as computer forensics debugging performance analysis and user profiling.
typically program tracing is implemented through instrumentation that is by adding probes to a program that log events as they occur.
albeit effective instrumentation can cause issues due to its intrusive nature.
in particular instrumentation adds runtime overheads that can be problematic in many scenarios including real time systems embedded software and deployed applications.
to address these issues while still being able to collect accurate partial program traces in previous work we developed zero overhead profiling zop a technique that can profile a program without instrumenting it by leveraging the electromagnetic em emissions generated by the processing hardware during execution.
zop although effective has three main limitations.
first it requires extensive code coverage and therefore a thorough set of test inputs during its training phase to achieve good accuracy.
basically in zop each relevant subpath must be executed so that its em signal can be recorded and later matched.
unfortunately in realworld programs the test cases are frequently few of poor quality and often completely absent.
second zop predicts acyclic path profiles rather than complete execution traces.these path profiles count executions of unique acyclic paths within the program.
although useful for some tasks path profiles summarize away the exact sequence of events that would instead be logged in a complete path trace.
third zop can fail to recover from a misprediction.
zop attempts to match em signals by following the control flow graph of the program being profiled.
when a misprediction occurs zop backtracks until it can find a path that better matches the signal.
although this approach can avoid mispredictions that result in infeasible paths the predicted and actual control flows can diverge beyond recovery when the em signals collected during training do not closely match the signals observed during profiling for more than a short time.
in this paper we propose zero overhead path prediction zop a novel approach that extends zop and addresses its shortcomings.
first to support the training phase even in the absence of an extensive set of inputs we developed a new input generation technique based on symbolic execution progressive symbolic execution pse .
pse overcomes some of the limitations of traditional symbolic execution by taking advantage of the fact that program subpaths need not be observed in the context of a complete execution.
more precisely initially pse executes the whole program with symbolic inputs as done in classic symbolic execution.
if this fails to achieve sufficient coverage for zop training it proceeds to execute functions with symbolic inputs and unconstrained global state similar to uc klee .
pse then continues by substituting called functions with symbolic stubs and increasingly unconstrained local state until a given coverage objective is achieved.
although this approach can result in infeasible paths this is not problematic when the execution of such paths is used in training in most if not all cases the oversampled em emissions will simply never match a signal produced during profiling.
second we modified the zop profiling phase to predict complete execution traces instead of acyclic path profiles.
in this way we made the approach considerably more generable and applicable in a broader range of scenarios.
finally we developed a new signal matching algorithm that divides the em signals into sampling windows and matches them in a stateless fashion i.e.
without following paths in the control flow graph of the program being profiled .
although this state less prediction approach can increase the occurrence of mispredictions of individual basic blocks these ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
mispredictions do not impact future prediction accuracy which means that zop can easily recover from prediction errors.
to evaluate zop we applied it to the three original zop benchmarks and to a new larger benchmark.
our results show that zop is a promising approach.
in particular they show that zop does produce accurate path predictions with an accuracy over for the cases considered.
they also show that pse is an effective technique in that it was able to cover feasible paths missed by traditional symbolic execution which contributed to increasing zop s accuracy.
the main contributions of this paper are zop a zero overhead whole program tracing approach.
pse an input generation technique that targets increasingly smaller code fragments until it achieves a given coverage goal.
an implementation of pse which is publicly available as a docker image and in archival format .
an empirical evaluation that demonstrates the effectiveness and potential usefulness of zop .
ii.
b ackground in this section we provide some necessary background information on zop our previous technique for zero overhead acyclic paths profiling and on symbolic execution.
we also define some terms that we use in the rest of the paper.
a. zero overhead profiling zero overhead profiling zop computes acyclic path profiles for a program p by observing the electromagnetic em emanations produced by a computing system during execution of an unmodified version of p. zop consists of two main phases training and profiling.
in the training phase zop runs p against a set of inputs to collect waveforms for the em emanations generated by the computing system running p. in the profiling phase zop runs p uninstrumented and unmodified against inputs whose executions need to be profiled records the em emissions produced by the program and matches these emissions with those collected during training to predict which acyclic paths were exercised and how often.
in an evaluation performed on several benchmarks zop was able to predict acyclic path profiling information with an accuracy greater than on average.
despite these positive results however zop has some shortcomings that limit its usefulness and general applicability.
first of all as we discussed in the introduction zop requires an extensive set of inputs in order to build good models in the training phase.
in fact the empirical results we described above were obtained by using test suites that achieved complete branch coverage which are rarely available in practice.
in addition acyclic path profiles provide useful information but they summarize events into histograms and discard information about the full sequence of events.
they therefore cannot be used for the many tasks for which information about complete traces is needed.
finally due to the way zop matches signals the predictions it computes can suffer unrecoverable accuracy losses.b.
symbolic execution symbolic execution se is a technique that executes a program using symbolic instead of concrete inputs.
at any point in the program s symbolic execution se keeps track of the symbolic state expressed as a function of the inputs and the path condition pc a set of constraints in conjunctive form that consists of the conditions on the inputs under which the execution reaches that point.
the symbolic state and the pc are built incrementally during se.
when se executes a statement sthat modifies the value of a memory location m it computes the new symbolic value of m according to s s semantics and suitably updates the symbolic state.
when se executes a conditional branching statement c it forks the execution follows both branches and updates the pc along each branch by adding an additional conjunct that represents c s predicate.
when successful se can compute an input that would cause a given point in the program to be reached.
to do so the pc for that point would be fed to an smt satisfiability modulo theories solver which would try to find an assignment to the free variables in pc i.e.
the inputs that satisfies the pc.
c. terminology acontrol flow graph cfg for a function fis a directed graph g hn e en exi where nis a set of nodes that represent statements in f e n nis a set of edges that represent the flow of control between nodes and en2nand ex2nare the unique entry and exit points for the cfg.
abasic block in a cfg is a contiguous sequence of nodes i.e.
instructions with no incoming branches except for the first node in the block and no outgoing branches except for the last node in the block.
acall graph cg is a directed graph g m e where mis the set of functions in the program and an edge fa fb 2eimplies that function famay call function fb.
iii.
o urapproach zero overhead path prediction figure shows an overview of zop our technique for zero overhead path prediction.
please note that to avoid clutter some elements in the figure are repeated.
as the figure shows zop consists of two main phases training and prediction.
the training phase takes as input the source code of aprogram p whose complete paths we want to be able to predict and generates the eme model a model of the electromagnetic em emissions generated by the program.
two modules of zop take part in this phase the input generation and replay module and the eme model generator.
given p the goal of the input generation and replay module is twofold.
the first goal is to generate replay cases inputs forp or fragments thereof that achieve a given coverage goal typically expressed in terms of program subpaths.
the second goal is to replay the generated inputs against the program or against a program fragment so that the eme model generator can record the em emissions generated during authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
input generationand replaytargetdeviceeme modelgeneratorpathpredictortargetdevicetraining phaseprediction phase ememodelreplaycasesprogrampathpredictionsprograminputsprogramfig.
overview of our zop approach.
the replay and generate the eme model which links such emissions to the part of the program that generated them.
the prediction phase takes as input the eme model program p and a set of program inputs forp and generates a set of path predictions one for each provided program input.
the path predictions consist of complete execution traces for pand are computed by the path predictor module which observes the em emanations produced by the target device as it runs pagainst the provided inputs and matches the observed emanations with those in the eme model .
in the rest of this section we describe the four modules of zop in detail.
a. input generation and replay the training phase of zop requires the recording of sample em emissions collected from the target device i.e.
the device that runs the program whose traces we want to collect .
moreover for the training to be effective zop needs to collect a comprehensive set of samples.
ideally the technique would need to collect one sample for every possible path in the program which is clearly impractical.
because zop s signal matching divides the em emissions for an execution into smaller sampling windows however having samples of subpaths whose length is comparable to that of the sampling window is typically enough.
the goal of the input generation and replay module is therefore to generate inputs that adequately cover a suitably identified set of subpaths within the program.
the first step performed by this module is a preprocessing of the source code that performs a set of semanticspreserving transformations aimed to facilitate later source code manipulation.
specifically the preprocessing expands macros refactors short circuiting boolean expressions encloses single statement blocks in braces and rewrites each return statement that involves a complex value as an assignment to a temporary variable followed by a simple return of that variable.
next the module instruments the source code by inserting markers i.e.
special probes at selected program points.
these markers partition an execution trace into segments which we refer to as m2m paths marker to marker paths .
these m2m paths are the subpaths within the program functions that we want the inputs to cover that is they are the coverage requirements for the input generation.
the level of granularity of the inserted markers is critical to the effectiveness of theapproach.
subpaths that are too short would be easy to cover but would result in em signals that are hard to recognize and match.
conversely subpaths that are too long would generate em signals that are easy to recognize and match but would be difficult to cover.
based on our past experience preliminary experimentation the way zop performs signal matching and our domain knowledge we selected the following points for inserting markers entry nodes of functions exit nodes of functions loop heads and target nodes of goto statements.
furthermore because these markers can occasionally result in excessively long m2m paths our techniques splits m2m paths longer than a selected threshold by suitably inserting additional markers.
we selected these marking criterion so that m2m paths are intra procedural and do not contain cycles any program trace can be represented as a sequence of contiguous m2m paths and the length of the signals generated by the m2m paths is comparable to that of the sampling window used by the path predictor module see section iii c .
given a complete set of m2m paths our technique tries to generate inputs that cover all such paths using an approach based on symbolic execution.
in principle traditional symbolic execution can generate inputs for all feasible paths in a program.
however its effectiveness and scalability are limited in practice by several issues and in particular by the path explosion problem the fact that the number of feasible paths is usually exponential in the number of code branches .
in fact traditional symbolic execution has problems covering even individual statements let alone m2m paths that are located deep in the call graph or hidden behind complex looping control flow.
to address this problem and be able to generate inputs that cover most m2m paths we defined a new technique that extends classical symbolic execution and that we call progressive symbolic execution pse .
progressive symbolic execution pse the key insight behind pse is that a given m2m path mpin program pneed not be observed along a complete path that is a path that starts from p s entry and follows a complete actual execution.
if pse cannot generate an input that executes mp it therefore derives a related program p0that contains an equivalent subpath for which it can find an input.
to generate p0 pse operates along two dimensions it considers increasingly smallers fragments of the program and replaces calls to other functions or libraries with symbolic stubs.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
i n t p char p f mark m1 i n t x complex p while x f mark m2 some code g some code mark m3 g listing original code.
i n t p0 char p f mark m1 i n t x s y m b o l i c i n t while x f mark m2 some code g some code mark m3 g listing modified code.
we illustrate this second dimension with the example shown in listing .
assume that we are interested in covering m2m pathh5 9i between markers m2andm3 and that the symbolic execution of function complex either results in a timeout or cannot be performed because the code of the function involves theories not supported by the underlying solver.
in such a case no input covering the path of interest would be produced.
however it would be straightforward to generate an input that covers the analogous subpathh5 9iin the derived program p in listing where the integer value returned by complex has been replaced with a symbolic integer.
pse produces a set of inputs encoded as replay cases where each replay case is an ordered pair that consists of a program fragment and inputs for that fragment.
it also constructs for each replay case the scaffolding necessary to run the corresponding code fragment against its input.
the next two sections discuss how pse generates inputs that aim to cover all m2m paths identified in a program pand runs por fractions thereof against the generated inputs to support zop s training phase.
pse input generation to try to reach all the m2m paths in a program pse progressively unconstrains program state in four phases or strategies.
the phases are progressive in that the symbolic state in each phase is a superset of the symbolic state in the prior phase.
uinp symbolic input state execution of the whole program with symbolic inputs.
this is equivalent to traditional symbolic execution performed from the entry point of the program.
uext symbolic external state execution of each function with symbolic input parameters and symbolic global state.
intuitively this strategy corresponds to executing a function as if it could be reached with every possible state and is equivalent to under constrained symbolic execution .
ustub symbolic stubs execution of each function with symbolic input parameters symbolic global state and all callees replaced by symbolic stubs see example in listings and .
symbolic stubs return an unconstrained value and unconstrain global state and values passed as output parameters.
intuitively in addition to executing a function as if it could be reached with every possible state this strategy also assumes that callees can modify the state in every possible way.
uint symbolic internal state executions of fragments of a function with symbolic local and global state.
intuitively this strategy corresponds to unconstraining the state reachable bya code fragment so that the code fragment can be executed as if it could be reached with every possible state.
the specifics of pse s input generation are described in algorithm .
the algorithm takes as input a program a set of entry points for the program and three tuning timeout parameters and produces as output a set of pairs of program fragments and corresponding inputs.
although in most cases programs have a single entry point supporting multiple entry points allows for applying the same approach to libraries.
the timeout values specify maximum time budgets for the progressive unconstraining strategies t0applies to uinp t1applies to uext and t2applies to both ustub and uint.
the output of the algorithm consists of all the replay cases generated by all progressive phases which are stored in the container initialized in line .
the algorithm starts by performing the uinp strategy on each of the program entry points lines .
the uext strategy iterates over each program function as discovered in a breadth first traversal of the program call graph and maintained in a worklist lines .
we selected this traversal order to lengthen the average replay trace as entry from functions closer to program entry should produce longer traces.
lines ensure that the algorithm only executes uext if a remaining m2m path is reachable from the current function in the call graph traversal.
in that case the algorithm invokes pse on the function with the uext strategy adds the resulting replay cases to set cases and updates the set of remaining m2m paths lines .
note that for clarity we treat the utility function m2mpaths as polymorphic that is the function always returns a set of intra procedural m2m paths contained within its single argument.
if the argument is a function it simply returns the set of m2m paths in the function.
conversely if the argument is a program or a set of functions it returns the union of the m2m paths in each function.
finally if the argument is a basic block it returns the set of m2m paths reachable from the block and within the function containing the block.
if there are remaining m2m paths within the current function the algorithm aggressively unconstrains additional program state by substituting symbolic stubs for all callees within the function ustub strategy .
this strategy allows the algorithm to skip over complex callees that may be problematic for symbolic execution.
since each function entry and exit is marked m2m paths within the callee can be covered separately from the current function context.
each replay case produced in this phase must be considered for retention lines .
these includes replay cases that result in a memory fault due to the increased amount of symbolic state.
we retain these faulting replay cases anyway in case they end up being the only cases covering a specific m2m path.
when symbolic stubs fail to expose a remaining m2m path the algorithm proceeds to the uint phase which unconstrains also the program state at specific points within a function lines .
this portion of the algorithm is analogous to the ustub strategy except that it traverses the basic blocks authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm input generation input program program to analyze entry points program entry points t0 classic symbolic execution timeout t1 pse native callees timeout t2 pse stubbed callees timeout output result f frag input g 1begin 2cases 3remaining m2mpaths program foreach fn2entry points do cases cases execpse program fn uinp t0 6remaining remainingncoverage cases 7visited 8fnworklist entry points foreach fn2fnworklist do visited visited ffng newfns callees fn nvisited append fnworklist new fns reachable fns reaching fn ifremaining m2mpaths reachable fns then newcases execpse program fn uext t1 cases cases newcases remaining remainingncoverage new cases ifremaining m2mpaths fn then faulting newcases execpse program fn ustub t2 foreach case2newcases do ifremaining coverage case then iffaulted case then faulting faulting fcaseg else if completed case then cases cases fcaseg remaining remainingncoverage case ifremaining m2mpaths fn then bbworklist fbbjbb2cfg fn sorted by bfsg foreach bb2bbworklist do ifremaining m2mpaths bb then newcases execpse program bb uint t2 foreach case2newcases do ifremaining coverage case then iffaulted case then faulting faulting fcaseg else if completed case then cases cases fcaseg remaining remainingncoverage case foreach case2faulting do ifremaining coverage case then cases cases fcaseg remaining remainingncoverage case 44result 45remaining m2mpaths program 46csworklist fcasejcase2cases sorted by trace length g foreach case2csworklist do ifremaining coverage case then result result fcaseg remaining remainingncoverage case return result within a functions s cfg instead of the functions within the call graph of the program.
also in this case some replay cases may result in a memory fault and are retained in case they cover m2m path not otherwise covered.
before advancing to the next function in the call graph traversal the faulting replay cases are examined for coverage of this function s remaining m2m paths to decide which ones to keep lines .
because faulting replay cases contain a record of the faulting basic block and the number of times thatblock occurs in the replay trace before faulting pse s replay can use these replay cases if needed and terminate them prior to the execution of the faulty statement.
in its final part the algorithm returns a set of replay cases selected from all the potential replay cases generated.
longer replay traces preserve more of the processor context and thus can generate more authentic em emissions during training.
therefore given a set of replay cases covering a given m2m path the algorithm favors the case with the longest trace.
it does so by sorting the candidate replay cases by trace length and greedily selecting cases to achieve maximum m2m path coverage lines .
algorithm relies on function execpse to perform the different phases of its progressive symbolic execution.
we provide the details of execpse in algorithm .
the inputs of the execpse algorithm are the program to symbolically execute the program point to be used as the starting point for the symbolic execution the strategy to be used and the timeout to be enforced.
the algorithm first sets sto the initial symbolic state sets the first instruction to the first instruction in the start basic block and initializes the set of active states with the single element s lines .
it then unconstrains the formal parameters to the function containing the start basic block lines .
the algorithm continues to unconstrain program state according to the specified strategy lines .
the instruction processing loop lines is the same used in traditional symbolic execution except for the way it handles call instructions lines .
if either the callee fis an external function or the unconstraining strategy is ustub or uint the algorithm creates a new symbolic variable for each formal output parameter of fand assigns this symbolic variable to the corresponding actual argument at the call site.
additionally the algorithm creates new symbolic values and assignments for each global variable referenced by fand for f s return value if present.
pse optimizations to make pse more scalable we have incorporated in our technique several optimizations.
lazy initialization pse uses lazy initialization to construct pointer inputs for execution at an arbitrary program point.
specifically accessing an unconstrained pointer value causes pse to explore potential program paths in which the pointer a is null b points to a newly allocated memory object of the targeted type or c points to an existing memory object of the targeted type.
to prevent lazily initialized pointers to lazily initialized pointers from unrolling infinitely pse tracks the depth of lazy memory objects.
when the depth exceeds a configurable threshold only states for cases a and c above are considered.
pointer type casting type casting between pointer types is a common practice in c programs.
for example a pointer may be declared as a char accessed and later cast to struct foo .
in these cases the lazily initialized memory behind the pointer may no longer be large enough to store memory objects of the new type.
to address this authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm execpse simplified input program program to symbolically execute start program point to begin pse strategy uinpjuextjustubjuint timeout maximum time to perform pse output result f frag input g 1begin 2s initial state 3fn containingfn start 4active states fsg foreach arg2formalargs fn do unconstrain s arg ifstrategy2fuext ustub uint gthen foreach var2globalvariables do unconstrain s var ifstrategy uint then foreach var2localvars fn do unconstrain s var 13stop now timeout while active states6 now stop do s selectstate active states inst nextinstruction s switch inst do case call do f targetfunction inst ifstrategy2fustub uintg f 2program then foreach arg2actualargs inst do ifisoutputpointer arg then unconstrain s value arg value foreach var2globalvariables do ifisreferenced f var then unconstrain var value arg var ifreturntype f void then unconstrain s value setreturn s inst value else executecall s f issue lazily initialized symbolic objects have an immutable maximum physical size and a flexible visible size.
a lazy object s initial visible size depends on the size of the allocated type.
a subsequent cast to a larger type can increase the visible size up to its physical size whereas a cast to a smaller type does not decrease it.
the visible size is used when reporting symbolic solutions and when enforcing the inbounds pointer assumption which we discuss next.
inbounds pointer assumption since out of bound pointer accesses can result in non deterministic behavior lazy initialization ensures that unconstrained pointers either point to allocated memory or are null .
however there are other ways to have a potentially out of bounds pointer such as through array indexing and pointer arithmetic.
in pse an indexed operation automatically inserts a path constraint requiring the resulting pointer to be within the target allocation block.
this approach reduces the path search space while only eliminating undesirable paths.
faulting or non deterministic paths have in fact low utility when used to generate training samples.
path explosion mitigation rather than mitigating path explosion using search strategies pse tries to eliminate undesirable states early using multiple heuristics.
the inbounds pointer assumption discussed above for instance eliminatesmany abnormally terminating paths.
loops are also a significant cause of path explosion as symbolic conditions within a loop body can create at each iteration a number of new paths exponential in the number of branches.
to mitigate this issue pse periodically samples the number of active path states in each loop body.
if the number of states in a single loop body grows across the sample interval by more than a configurable threshold those paths are randomly reduced by .
pse input replay the replay cases i.e.
inputs generated by pse for a program pusing its uinp strategy can be run directly on p. this is not true however for the replay cases generated by pse using its uext ustub and uint strategies for which pse must create suitable scaffolding.
the reason is that these replay cases are generated by unconstraining program state considering fragments of the program and replacing called function with symbolic stubs.
pse generates the needed replay scaffolding in the same language as p and the scaffolding consists of four major parts replay bodies replay stubs input data and replay harnesses.
the replay bodies contain the source statements that comprise the m2m paths recorded for zop training.
bodies for replay cases generated using the uext strategy simply consist of the original function and corresponding callees.
bodies for replay cases generated using the ustub strategy also consist of the original source function but they are linked against newly created replay stubs that return the right values and suitably set output parameters and global variables.
in addition to this bodies for replay cases generated using the uint strategy must also be able to start executing from an internal basic block bb initialize the local and visible global state at bb and exit at the right point in the execution i.e.
after visiting a termination basic block a specific number of times .
to do so pse first creates a copy of the original function containing the fragment of interest and identifies the statement stmt from which to start the execution.
it then inserts a goto instruction at the beginning of the current body so as to cause the execution to jump to the stmt .
finally it inserts a call to a function that suitably initializes local and global state.
the replay stubs correspond to symbolic stubs and provide suitable values for returns output parameters and global variables.
furthermore because each called function can be invoked multiple times pse creates ordered sets of values so as to be able to produce the right values for the different invocations.
when executing a replay case with symbolic stubs pse substitutes these replay stubs to the original called functions in the corresponding replay body.
the input data consist of static initialized data structure arrays in the original source language produced from the generated input values in the replay cases.
note that the data input set for a replay case may not contain complete values for all the required input variables.
for instance a function may read the value of an input pointer but only write to the pointed memory block.
in general since the values not contained in the input set do not affect the execution pse can safely initialize the missing data items with some default value.
among the input data pointer variables require special handling as the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
address space during input generation is different from the address space during replay.
to address this issue pse adds to the replay cases a map of the address space at the time the case was generated.
this map includes the address and size of each memory object the allocation type and a list of the cast operator types applied to the memory object.
pse needs the entire address space because pointer values that are not in the generated input set cannot be assigned a default value as pse does with fundamental types.
writing memory by dereferencing such a pointer would in fact likely result in an access violation if not in undefined behavior.
given this map if the pointer value resolves into a memory object in the address space of the replay case pse calculates its offset and emits the replay pointer value as an offset into the staticallyinitialized data structure for the target object.
otherwise it is given a default initializer based on its type.
finally the replay harnesses contain one harness for each replay body and fragment and a driver that invokes each replay fragment harness in turn.
the fragment harness iterates through each input data set for the fragment initializing global variables declaring and initializing fragment parameters and initializing substituted stubs.
b. eme model generator the goal of the eme em emissions model generator is to generate the eme model which relates em emissions to the code in the program that generated them.
to do so this module collects and analyzes em emissions while replaying the inputs i.e.
replay cases generated by pse.
because the control flow path induced by these inputs is known so is the sequence of markers executed while replaying the inputs.
moreover the marker probes log the processor clock cycle so our technique knows at which clock cycles each m2m path started and ended and can use the marker sequence and the corresponding timestamps to annotate the collected em emissions.
more precisely the eme model generator is able to mark the collected emissions so as to identify the starting and the ending point of each m2m path.
this information is stored in the eme model which is then used in the prediction phase to compute which complete paths are being traversed by unknown executions.
c. path predictor this module is a fundamental part of zop as it is the component that actually produces path predictions using the eme model generated during the training phase.
as unknown inputs are provided to the program pfor which zop built the eme model and pruns on the target device the path predictor collects the em emissions produced by the device which represent the test signal .
it then splits this test signal into small non overlapping and fixed length segments referred to as sampling windows .
similar to what happens for the length of the m2m paths the size of the sampling window can considerably affect the accuracy of the path prediction algorithm.
on the one hand if the window size is too small the signal matching has low eme model bestmatchsampling windowfig.
em emission matching approach.
reliability especially in the presence of measurement noise.
on the other hand if the size is too large a single window may contain multiple m2m paths and require more training samples to be effective.
because of these tradeoffs we performed preliminary experimentation to identify a good combination of lengths for m2m paths and window sizes.
once the test signal is split into sampling windows the path predictor searches for each sampling window the best match in the eme model based on the least euclidean distance as intuitively shown in figure .
our technique then uses the best matching sample in the eme model together with the annotations added by the eme model generator to predict which m2m path contains the sampling window.
a concatenation of all the so identified m2m paths is used to predict the entire control flow path corresponding to the observed unknown execution.
in comparison to our original zop algorithm which used a depth first search dfs through the program s cfg while matching signals this prediction mechanism matches each signal window independently i.e.
there is no state of the search .
this approach is preferable to a dfs because the latter is prone to error propagation any misprediction is often followed by a series of consecutive mispredictions which amplifies the initial error and may result in the algorithm getting lost .
furthermore mispredictions in the original zop can also result in an exponential growth in the amount of backtracking the algorithm needs to perform which can limit the scalability and applicability of the algorithm especially in the case of large applications.
because the stateless path prediction algorithm in zop matches and predicts each window independently it is free from error propagation.
moreover unlike zop zop s path prediction is embarrassingly parallel and could thus be easily distributed to increase its efficiency.
iv.
e mpirical evaluation to evaluate the effectiveness of our technique we implemented it in a prototype tool and performed an empirical authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i benchmark statistics.
benchmark loc basic blocks m2m paths replace schedule print tokens mdns evaluation on a set of benchmarks.
in our evaluation we addressed the following research questions rq1 does zop provide accurate path predictions?
rq2 how does zop compare to zop?
rq3 to what extent does state unconstraining help coverage?
a. implementation details we implemented the modules of zop discussed in section iii.
we used cil and clang to preprocess source code.
we used a combination of clang and networkx for control flow graph analysis.
we implemented pse by extending the klee symbolic execution engine.
we also relied on llvm and on the stp constraint solver our implementation of pse is publicly available as a self contained docker image .
we implemented our path predictor module in matlab 2018b .
b. evaluation setup to answer our research questions we selected four benchmarks.
the first three were used to evaluate zop in previous work .
the fourth benchmark a real world mdns server shows the scalability of our approach as it is two orders of magnitude larger than the other benchmarks.
table i provides size metrics for our benchmarks.
as the target device we used an altera cyclone ii fpga with a nios iie processor.
using an fpga lets us leverage various debugging features and i o pins to better understand program behavior at the individualcycle level.
unfortunately however it also considerably limits the size of the benchmarks we can consider.
using the timeout parameters described in section iii a2 we defined three variants of pse.
this allowed us together with the use of vanilla klee to evaluate the effects of different input generation techniques on zop s accuracy cs classic symbolic execution.
vanilla klee .
uc under constrained symbolic execution.
uc klee proxied by performing pse at the function level.
pg pse with all unconstraining strategies enabled.
fn pse without the uext strategy.
basically this parameterization skips under constrained symbolic execution by introducing symbolic stubs and considering sub function fragments right away which makes the analysis considerably faster at the cost of generating shorter paths.
c. rq1 prediction accuracy to answer rq1 we first generated replay cases i.e.
input sets for the four benchmarks and for the four input generation strategies considered cs uc fn and pg.
second we used zop to train eme models for each benchmark andtable ii mean path prediction accuracy .
benchmark cs uc fn pg replace .
.
.
.
schedule .
.
.
.
print tokens .
.
.
.
mdns .
.
.
.
input set.
then for replace schedule and print tokens we randonly selected inputs from the tests provided in the sir repository .
for mdns we used avahi to generate inputs i.e.
mdns queries that target different host addresses and ask for different services including incorrect queries.
we manually checked that the inputs exercise different aspects of the mdns protocol.
finally we used zop to perform path prediction using the generated eme models.
table ii reports the path prediction accuracy for the cases considered computed by measuring the edit distance between actual and predicted paths.
the prediction error is the edit distance divided by the length of the actual path and the prediction accuracy is minus the prediction error.
as the table shows for all four benchmarks the prediction accuracy tends to be generally fairly high.
the highest accuracy is achieved with either uc or pg in three of four cases with the fourth case schedule showing a very close result for fn and pg.
interestingly as we will show in section iv e pg achieves higher coverage but does not always result in higher prediction accuracy.
the reason for this is that the increased accuracy from a fully populated waveform model is offset by an increased possibility of a misprediction when the sampling window straddles the entry or exit of a symbolic stub.
approaches to match sub window em signals could address this issue and further improve the results for pg.
also interestingly zop achieves high prediction accuracy for mdns regardless of the input generation strategy involved.
further analysis of the results showed that this happens for different reasons with the main ones being that all the paths the program takes when receiving a valid mdns packet are similar because traces are largely dominated by loops with a large number of iterations and all the paths the program takes when receiving an invalid mdns packet are extremely short.
this skews the results considerably and makes it so that any input generation strategy that produces even just a few valid and invalid packets result in reliable eme models and thus high accuracy in the prediction.
to better understand how path prediction accuracy varies across inputs consider the box and whisker plot in figure which shows detailed results for pg.
the plot for uc is fairly similar.
for each benchmark x axis the figure shows the range of prediction accuracy y axis .
the boxes represent the 1stand 3rdquartiles with an interior band at the median.
the whisker ends represent the lowest and highest points within .
of the interquartile range.
dots signify outliers.
although figure shows consistently high path prediction accuracy it also shows that there is room for improvement.
for example accuracy above for the schedule benchmark is authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
detailed path prediction accuracy for pg.
an outlier.
in general some limitations of the prediction technique can affect the results e.g.
the one we mentioned earlier related to the use of a fixed sampling window .
furthermore we found that different m2m paths may sometime result in instruction sequences that are very similar to each other even if they execute different parts of the program and thus generate em emissions that are also very similar to each other .
for example two different m2m paths may have the exact same mix of store and alu operations.
for another example switch statements are commonly compiled into jump tables which leads to multiple paths generating em emissions that are difficult distinguish a case that happens often for print tokens and mdns and causes a drop in accuracy .
d. rq2 comparison with zop zop and zop produce to some extent apples and oranges as the path profiles computed by zop and the complete traces computed by zop are not directly comparable.
to generate complete traces with zop we would have to extend the approach and basically re invent zop .
we can however compare the path profile prediction accuracy of zop with that of zop by extracting acyclic path profiles from complete traces.
table iii shows these results computed for the traces generated using uc and pg and for the three benchmarks for which we have zop results.
as the table shows zop s accuracy is lower than but comparable to that of zop for replace and schedule less than one percentage point and slightly lower for print tokens around .
percentage points .
the main reason for this slight decrease in accuracy lies in the fact that zop used a stateful model that selects the best match from m2m paths reachable from the currently predicted marker.
this strategy reduces mispredictions but is problematic when a misprediction does occur as we discussed in section iii c .
conversely zop s stateless prediction suffers no additional penalty for mispredictions which makes it effective for predicting complete paths but can result in a larger number of individual sub paths being mispredicted.
e. rq3 coverage to answer rq3 we measured the m2m path coverage achieved on all the benchmarks by the four input generationtable iii acyclic path profiles prediction accuracy .
benchmark zop zop uc zop pg replace .
.
.
schedule .
.
.
print tokens .
.
.
techniques considered.
table iv shows the results together with the total number of m2m paths determined by static analysis.
the pg and fn replay cases produced identical coverage so their results are shown together.
as the table shows pg pn achieved higher m2m path coverage than uc which in turn achieved higher coverage than cs.
this result is not surprising as increasing symbolic state should necessarily lead to higher coverage.
a more interesting question is how many additional feasible m2m paths were covered by pg pn.
unfortunately we cannot compute this information automatically as it is an undecidable problem and it by hand would be extremely time consuming and error prone.
we can however compute a lower bound for this information by checking how many of the m2m paths covered by the evaluation inputs in our study i.e.
in the actual executions that we used to evaluate prediction accuracy were missed by the generated input sets used for training a decreasing number of uncovered m2m paths would necessarily indicate an increased number of feasible paths covered.
table v reports this information and clearly shows that pg fn i.e.
pse consistently covers additional feasible subpaths that uc does not cover and so does uc with respect to cs.
this result provides initial indication that it is worth pursuing more aggressive state unconstraining approaches when generating inputs.
however more research and experiments are needed to demonstrate that client techniques can indeed benefit from the additional coverage achieved.
v. t hreats to validity in this section we briefly discuss the main threats to the validity of our empirical evaluation and steps we took to mitigate them.
the main threat to internal validity is the potential for defects in our implementation.
in mitigation we based our implementation on klee a reliable and stable symbolic execution engine.
we also carefully tested our implementation of pse which is available for public inspection .
threats to external validity include the size and number of our benchmarks.
as discussed in section iv b the maximum size of a potential benchmark was unfortunately constrained by the limitations of the embedded processor used for our evaluation.
programs larger than mdns could not be loaded onto the fpga board.
similarly long signal recording measurement analysis and human checks limited the number of benchmarks.
other threats to external validity are the way we selected inputs especially for mdns and the possible lack of generalizability of our results to other devices.
we are cognizant of these threats and plan to address them in future work by performing additional experiments on additional platforms.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv coverage comparison among cs uc and pg fn.
m2m paths benchmark total cs uc pg fn replace .
.
.
schedule .
.
.
print tokens .
.
.
mdns .
.
.
vi.
r elated work prior approaches to program tracing required instrumentation of the monitored system or runtime support.
software instrumentation is unfortunately expensive e..g they can incur overhead for acyclic path profiling alone .
recent processor designs such as intel processor trace can reduce this overhead to as little as but they require a sophisticated processor still entail non zero overhead and consume considerable storage capacity and throughput.
the key concepts of classical symbolic execution as provided in have been implemented for input generation in many prior tools .
our input generation work builds on this rich body of research on symbolic execution and automated test generation.
our pse technique is closely related to uc klee which performs under constrained symbolic execution from an arbitrary function call.
this degree of under constraining has been shown to be effective for patch validation and defect detection .
however unlike pse uc klee misses some subpaths needed for complete zop training.
chopped symbolic execution shares with our work the goal of reaching code buried deep in the call graph but takes an orthogonal approach it employs program slicing to exclude uninteresting portions of the code from symbolic execution while maintaining soundness.
for zop training the only uninteresting code is dead code so this approach would not be applicable in our context.
since symbolic execution is susceptible to path explosion numerous approaches have been defined to address this issue.
guided path search heuristics select paths for exploration either randomly or based on the predicted likelihood of reaching a given coverage target .
other approaches reduce the number of paths to search by removing equivalent paths removing paths that cannot reach new code or merging state on selected paths .
pse could benefit from suitably adapted versions of these techniques.
lazy initialization is an important feature of generalized symbolic execution as it allows the handling of unconstrained pointers or