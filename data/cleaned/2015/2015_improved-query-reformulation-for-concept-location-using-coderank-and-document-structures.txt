improved query reformulation for concept location using coderank and document structures mohammad masudur rahman chanchal k. roy department of computer science university of saskatchewan canada fmasud.rahman chanchal.royg usask.ca abstract during software maintenance developers usually deal with a significant number of software change requests.
as a part of this they often formulate an initial query from the request texts and then attempt to map the concepts discussed in the request to relevant source code locations in the software system a.k.a.
concept location .
unfortunately studies suggest that they often perform poorly in choosing the right search terms for a change task.
in this paper we propose a novel technique acer that takes an initial query identifies appropriate search terms from the source code using a novel term weight coderank and then suggests effective reformulation to the initial query by exploiting the source document structures query quality analysis and machine learning.
experiments with baseline queries from eight subject systems report that our technique can improve of the baseline queries which is highly promising.
comparison with five closely related existing techniques in query reformulation not only validates our empirical findings but also demonstrates the superiority of our technique.
index terms query reformulation coderank term weighting query quality analysis concept location data resampling i. i ntroduction studies show that about of the total efforts is spent in software maintenance where developers deal with a significant number of software issues .
software issue reports a.k.a.
change requests discuss both unexpected or erroneous features such as bugs and expected but nonexistent features e.g.
new functionality .
for both bug resolution and new feature implementation a developer is required to map the concepts discussed in the issue report to appropriate source code within the project which is widely known as concept location .
developers generally choose one or more important keywords from the report texts and then use a search method e.g.
regular expression to locate the source code entities e.g.
classes methods that need to be changed.
unfortunately as the existing studies report developers regardless of their experience perform poorly in choosing appropriate search terms for software change tasks.
according to kevic and fritz only .
of the search terms chosen by the developers were able to locate relevant source code entities for the change tasks.
furnas et al.
also suggest that there is a little chance i.e.
that developers guess the exact words used in the source code.
one way to assist the developers in this regard is to automatically suggest helpful reformulations e.g.
complementary keywords to their initially chosen queries.
existing studies apply relevance feedback from developers pseudo relevance feedback from information retrieval methods and machine learning for such queryreformulation tasks.
they also make use of context of query terms from source code text retrieval configuration and quality of queries in suggesting the reformulated queries.
gay et al.
capture explicit feedback on document relevance from the developers and then suggest reformulated queries using rocchio s expansion .
haiduc et al.
and colleagues take quality of a given query i.e.
query difficulty into consideration and suggest the best reformulation strategy for the query using machine learning.
while all these above techniques are reported to be novel or effective most of them also share several limitations.
first source documents contain both structured items e.g.
method signatures formal parameters and unstructured items e.g.
code comments .
unfortunately many of the above reformulation approaches treat the source documents as simple plain text documents and ignore most of their structural aspects except structured tokens.
such inappropriate treatment might lead to suboptimal or poor queries.
in fact hill et al.
first consider document structures and suggest natural language phrases from method signatures and field signatures for local code search.
however since they apply only simple textual matching between initial queries and the signatures the suggested phrases are subject to the quality of not only the given queries and but also of the identifier names from those signatures.
second many of these approaches often directly apply traditional metrics of term importance e.g.
avgidf tf idf to source code which were originally targeted for unstructured regular texts e.g.
news article .
thus they might also fail to identify the appropriate terms from the structured source documents for query reformulation.
in this paper we propose a novel technique acer for automatic query reformulation for concept location in the context of software change tasks.
we first introduce a novel graph based term weight coderank for identifying important terms from the source code and then apply that term weight and source document structures e.g.
method signatures to our technique for automatic query reformulation.
coderank identifies important terms not only by analyzing salient structured entities e.g.
camel case tokens but also by exploiting the co occurrences among the terms across various entities.
our technique acer accepts a natural language query as input develops multiple candidate queries from two different important contexts method signatures and field signatures of the source documents independently using coderank and then suggests the best reformulation based .
c ieeease urbana champaign il usa technical research428 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
java project compute runtimepathclasspath property containerlaunch entryvariableresolveoutputlocations configuration provider classpathresolve launch fig.
.
an example term graph generated by coderank for source code of listing on query quality analysis and machine learning to the poorly performing initial query.
table i shows an example change request submitted for eclipse.jdt.debug system and it refers to debugger source lookup issue of eclipse ide.
let us assume that the developer chooses important keywords from the request title and formulates a generic initial query debugger source lookup.
unfortunately the query does not perform well and returns the first correct result at the 79thposition of the result list.
further extension debugger source lookup work variables also does not help and returns the result at the 77thposition.
the existing technique rsv extends the query as follows debugger source lookup work variables launch configuration jdt java debug where the new terms are collected from the project source using tf idf based term weight.
this query returns the correct result at the 30thposition which is also far from ideal unfortunately.
the query of sisman and kak debugger source lookup work variables test exception suite core code also returns the correct result at the 51stposition.
on the other hand our suggested query debugger source lookup work variables launch debug problem resolve required classpath returns the correct result at the 2ndposition which is highly promising.
we first collect structured tokens e.g.
resolveruntimeclasspathentry from method signatures and field signatures of the source code e.g.
listing and split them into simpler terms e.g.
resolve runtime classpath andentry .
the underlying idea is that such signatures often encode high level intents and important domain terms while the rest of the code focuses on more granular level implementation details and thus possibly contains more noise .
we develop individual term graph e.g.
fig.
based on term co occurrences from each signature type apply coderank term weighting and extract multiple candidate reformulations with the highly weighted terms e.g.
orange coloured fig.
.
then we analyze the quality of the candidates using their quality measures apply machine learning and suggest the best reformulation to the initial query.
thus our technique first captures salient terms from the source documents by analyzing their structural aspects i.e.
unlike bag of words approaches and an appropriate term weight coderank and then suggests the best query reformulation using document structures i.e.
multiple candidates derived from various signatures query quality analysis and machine learning .
experiments using baseline queries from eight opentable i anexample change request issue eclipse .jdt.debug field content title debb ugger source lookup does not work with variables description inthe debugger source lookup dialog i can also select variables for source lookup.
advanced... add variables .
iselected the variable which points to the archive containing thesource file for the type but the debugger still claims that hecannot find the source.
initialdebugger source lookup work variablessearch query public static iruntimeclasspathentry resolveruntime classpathentry iruntimeclasspathentry entry ijavaproject project throws coreexception switch entry.gettype case iruntimeclasspathentry.project if the project has multiple output locations they must be returned iresource resource entry.getresource if resource instanceof iproject ijavaproject jp javacore.create iproject resource if jp.exists jp.getproject .isopen iruntimeclasspathentry entries resolveoutputlocations jp break listing .
source code used for automatic query reformulation abridged from source subject systems show that our technique can improve and preserve of the baseline queries which are highly promising according to relevant literature .
our suggested queries return correct results for of the queries in the top results.
our findings report that coderank is a more effective term weighting method than the traditional methods e.g.
tf tf idf for search query reformulation in the context of source code.
our findings also suggest that structure of a source code document is an important paradigm for both term weighting and query reformulation.
comparison with five closely related existing approaches not only validates our empirical findings but also demonstrates the superiority of our technique.
thus the paper makes the following contributions a novel term weighting method coderank for source code that identifies the most important terms from a given code entity e.g.
class method .
a novel query reformulation technique that reformulates a given initial query using coderank source document structures query quality analysis and machine learning.
comprehensive evaluation using baseline queries from eight open source subject systems.
comparison with five closely related existing approaches from the literature.
ii.
acer automatic query reformulation using coderank and docum entstructures fig.
shows the schematic diagram of our proposed technique acer for automatic query reformulation.
we use a novel graph based metric of term importance coderank for source code and apply source document structures query authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
software change request initial query input preprocessing code search pseudo relevance feedback source token selection preprocessing source term graphs for method and field signatures coderank calculation search term ranking candidate reformulations quality metric data resampling select best reformulation query expansion reformulated query output fig.
.
schematic diagram of the proposed query reformulation technique acer quality analysis and machine learning for query reformulation for concept location.
we define coderank and discuss different steps of acer in the following sections.
a. pseudo relevance feedback in order to suggest meaningful reformulations to an initial query feedback on the query is required.
gay et al.
first reformulate queries based on explicit feedback from the developers.
although such feedback could be useful gathering them is often time consuming and sometimes infeasible.
hence a number of recent studies apply pseudorelevance feedback as a feasible alternative.
the top ranked results returned by the code search tool for an initial query are considered as the pseudo relevance feedback for the query.
we first refine an initial query by removing the punctuation marks numbers special symbols and stop words step fig.
.
then we collect the top k i.e.
k best performing heuristic according to our experiments search results returned by the query and use them as the source for our candidate terms for query reformulation steps fig.
.
b. source token selection for query reformulation global query contexts pseudo relevance feedback on an initial query provides a list of relevant source documents where one or more terms from the query generally occur.
sisman and kak choose such terms for query reformulation that frequently co occur with the initial query terms within a fixed window size in the feedback documents.
hill et al.
consider presence of the query terms in method signatures or field signatures as an indicator of their relevance and suggest natural language phrases from them as reformulated queries.
both reformulation approaches are highly subject to the quality of the initial query due to their imposed constraints co occurrences with query terms and textual similarity with query terms .
rocchio determines importance i.e.
tf idf of a candidate term across all the feedback documents and suggests the top ranked terms for query reformulation.
carmel et al.
suggest that a single natural language query might focus on multiple topics and different parts of the returned results might cover different topics.
that is the same candidate term is not supposed to be important across all the feedback documents.
in other words accumulating term weight across all the documents might not always return the most appropriate terms for query reformulation.
such sort of calculation might add unnecessary noise to the term weight from the unrelated topics.
hence we consider all the feedback documents as a single body of structured texts which acts as a global context for the query terms.
thus with the help of an appropriate term weighting method the terms representing the most dominant topic across the feedback documents i.e.
also in the initial query could simply stand out and could be chosen for reformulation.
candidate token mining developers often express their intent behind the code and encode domain related concepts in the identifier names and comments .
however code comments are often inadequate or outdated .
all identifier types also do not have the same level of importance.
for example while the signature of a method encodes the high level intent for the method its body focuses on granular level implementation details and thus possibly contains more noisy terms .
in fact hill et al.
first analyze method signatures and field signatures to suggest natural language phrases as queries for code search.
in the same vein we thus also consider method signatures msig and field signatures fsig as the source for our candidate reformulation terms.
we extract structured identifier names from these signatures using appropriate regular expressions step fig.
.
since different contexts of a source document might convey different types or levels of semantics i.e.
developers intent we develop a separate candidate token set ct sig for each of the two signature types sig fmsig fsigg from the feedback documents 8d 2drf as follows ctsig 8d2d rff9t2tsiggjstructured t tsig sig d heresig d extracts all tokens from method signatures or field signatures and structured t determines whether the token t2tsigis structured or not.
although we deal with java source code in this research where the developers generally use camel case tokens e.g.
messagetype or occasionally might use same case tokens e.g.
decimaltype our approach can be easily replicated for snake case tokens e.g.
reverse traversal as well.
c. source code preprocessing token splitting structured tokens often consist of multiple terms where the terms co occur i.e.
are concatenated due to their semantic or temporal relationships .
we first split each of the complex tokens based on punctuation marks e.g.
dot braces which returns the individual tokens step fig.
.
then each of these tokens is splitted using a state ofthe art token splitting tool samurai given that regular authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
expression based splitting might not be always sufficient enough.
samurai mines software repositories to identify the most frequent terms and then suggests the splits for a given token.
we implement samurai in our working environment where our subject systems section iii a are used for mining the frequent terms and the author s provided prefix and suffix lists are applied to the splitting task.
stop word and keyword removal since our structured tokens comprise of natural language terms we discard stop words from them as a common practice step fig.
.
we use a standard list hosted by google for stop word removal.
programming keywords can often be considered as the equivalence of stop words in the source code which are also discarded from our analysis.
since we deal with java source code the keywords of java are considered for this step.
as suggested by earlier study we also discard insignificant source terms i.e.
having word length from our analysis.
stemming it extracts the root e.g.
send out of a word e.g.
sending .
although existing studies suggest contradictory or conflicting evidences for stemming with the source code we investigate the impact of stemming with rq 4where snowball stemmer is used for stemming.
d. source term graph development once candidate tokens are extracted from method signatures and field signatures and are splitted into candidate terms we develop source term graphs e.g.
fig.
from them step fig.
.
developers often encode their intent behind the code and domain vocabulary into the carefully crafted identifier names where multiple terms are concatenated.
for example the method name getchatroombots looks like a natural language phrase get chat room bots when splitted properly.
please note that each of these three terms chat room and bots co occur with each other to convey an important concept a robotic technology and thus they are semantically connected.
on the other hand the remaining term get cooccurs with them due to a temporal relationship i.e.
develops a verbal phrase .
similar phrasal representations refined with lexical matching were directly returned by hill et al.
for query reformulation.
however their approach could be limited due to the added constraint e.g.
warrants query terms in signatures .
we thus perform further analysis on such phrases and exploit the co occurrences among the terms for our graph based term weighting.
in particular we encode the term co occurrences into connecting edges e in the term graph g v e where the individual terms v i are denoted as vertices v .
v 8t2ct sigfvi2splitted t jvalidterm v i g e 9vi vj2vf vi vj jvi vj2t ji jj 1g heresplitted t returns individual terms from the token t2ctsig andvalidterm v i determines whether the term is valid i.e.
not an insignificant or a stop word or not.
we consider a window size oftwo within each phrase for capturing co occurrences among the terms.
such window sizefor co occurrence was reported to perform well by the earlier studies .
thus the above method name can be represented as the following edges get !chat chat !room and room !bots in the term graph.
that is if a set of terms are frequently shared across multiple tokens from two signature types such occurrences are represented as the high connectivity in the term graph e.g.
classpath in fig.
.
e. coderank calculation coderank pagerank is one of the most popular algorithms for web link analysis which was later adapted by mihalcea and tarau for text documents as textrank.
in this research we adapt our term weighting method from textrank for source code and we call it coderank.
to date only traditional term weights e.g.
tf tfidf are applied to source code which were originally proposed for regular texts and are mostly based on isolated frequencies.
on the contrary coderank not only analyzes the connectivity i.e.
incoming links and outgoing links of each source term but also the relative weight of the connected terms from the graph recursively and calculates the term weight s vi as follows step fig.
s vi x j in v i s vj jout vj j here in vi out vj and denote the vertices to which vi is connected through incoming links the vertices to which vjis connected through outgoing links and the damping factor respectively.
as shown earlier using the example getchatroombots co occurred terms complement each other with their semantics which are represented as bidirectional edges in the term graph.
thus each v i of the vertices from the graph has equal number of incoming links and outgoing links i.e.
in degree v i out degree v i .
parameters and configurations brin and page consider damping factor as the probability of randomly choosing a web page in the context of web surfing by a random surfer.
that is is the probability of jumping off that page by the surfer.
they use a well tested value of .
for which was later adopted by mihalcea and tarau for text documents.
similarly we also use the same value of for coderank calculation.
each of the vertices is assigned to a default value i.e.
base term weight of .
as suggested by earlier studies with which coderank is calculated.
it should be noted that the base weight of a vertex does not determine its final weight when pagerank based algorithms are applied .
coderank adopts the underlying mechanism of recommendation or votes for term weighting.
that is each vertex feeds off from the scores of surrounding connected vertices from the graph in terms of recommendation i.e.
incoming edges .
pagerank generally has two modes of computation iterative version and random walk version.
we use the iterative version for coderank and the computation iterates until the weights of the terms converge below a certain threshold or they reach the maximum iteration limit i.e.
as suggested by blanco and lioma .
as applied authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
earlier we apply a heuristic threshold of .
for the convergence checking.
the algorithm captures importance of a source term not only by estimating its local impact but also by considering its global influence over other terms.
for example the term classpath fig.
occurs in multiple structured tokens listing complements the semantics of five other terms and thus is highly important within the term graph i.e.
fig.
.
once the iterative computation is over each of the terms from the graph is found with a numeric score.
we consider these scores as the relative weight or importance of the corresponding terms from the source code.
f .
suggestion of the best query reformulation candidate reformulation selection algorithms and show the pseudo code of our query reformulation technique acer for concept location.
we first collect pseudo relevance feedback for the initially provided query q where top k source documents are returned lines algorithm .
then we collect method signatures and field signatures from each of the documents 8d 2drf and extract structured tokens from them.
we prepare three token sets ct msig ctfsig and ctcomb from these signatures lines algorithm step fig.
where ctcomb combines tokens from both signatures.
then we perform limited natural language preprocessing on each token set where samurai algorithm is used for token splitting.
we develop separate term graph for each of these token sets where individual terms are represented as vertices and term co occurrences are encoded as connecting edges lines algorithm step fig.
.
we apply coderank term weighting to each of the graphs which provides a ranked list of terms based on their relative importance.
then we select top k e.g.
k important terms from each of the three graphs and prepare three reformulation candidates lines algorithm steps fig.
.
algorithm acer proposed query reformulation procedure acer q .
q initial search query l fg .list of best reformulation query terms .collecting pseudo relevance feedback for q qpp preprocess q drf getrelevancefeedback q pp .collecting candidate source tokens from signatures forsourcedocument d2drfdo ctmsig ctmsig getmethodsigtokens d ctfsig ctfsig getfieldsigtokens d end for ctcomb ctmsig ctfsig ctall fct msig ctfsig ctcombg fortokenlist ctsig2ctalldo qr getqrcandidate ct sig end for .suggesting the best reformulated query for q qd resample getqueryqualitymetrics qr qrbest getbestcandidateusingml qr q pp qd l combine q pp qr best return l end procedure selection of the best reformulation haiduc et al.
argue that the same type of reformulation i.e.
addition deletion or replacement of query terms might not be appropriatefor all given queries.
in the same vein we argue that query reformulations from different contexts of the source document e.g.
method signature field signature might have different level of effectiveness given that they embody different level of semantics and noise.
that means one or more of the reformulation candidates could improve the initial query but the best one should be chosen carefully for useful recommendation.
haiduc et al.
suggest that quality of a query with respect to the corpus could be determined using four of its statistical properties specificity coherency similarity and term relatedness that comprise of metrics .
they apply machine learning on these properties and separate high quality queries from low quality ones.
we thus also similarly apply machine learning on our reformulation candidates and their metrics and develop classifier model s where classification and regression tree cart is used as the learning algorithm .
since only the best of the four reformulation candidates i.e.
including baseline is of our interest the training data was inherently skewed.
we thus perform bootstrapping i.e.
random resampling on the data multiple times e.g.
with sample size and replacement step fig.
train multiple models using the sampled data and then record their output predictions.
then we average all the predictions for each test instance from all models and determine their average probability of being the best candidate reformulation.
thus we identify the best of the four candidates using our models and suggest the best reformulation to the initial query lines algorithm steps fig.
.
bassett and kraft suggest that repetition of certain query terms might improve retrieval performance of the query.
if none of the candidates is likely to improve the initial query according to the quality model i.e.
baseline itself is the best we repeat all the terms from the initial query as the reformulation.
algorithm getqrcandidate get a candidate reformulation procedure getqrc andidate ctsig .
ct sig extracted candidate tokens from the signatures sig qrsig fg .candidate query reformulation .extracting terms and their co occurrences stsig preprocess samurai ct sig cosig gettermco occurrences st sig ctsig .developing term graph from token set gsig developtermgraph st sig co sig .calculating coderank using the graph crsig normalize calculatecoderank g sig .getting candidate reformulated query qrsig gettopkterms sortbyvalue cr sig return qrsig end procedure working example let us consider the query fdebugger source lookup work variablesg from our running example in table ii.
our term weighting method coderank extracts three candidate reformulations from method signatures and field signatures.
we see that different candidates have different level of effectiveness i.e.
rank to rank and in this case the candidate from the method signatures qr msig is the most effective.
our technique acer not only prepares such candidate queries from various contexts using a novel authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii a w orking example bug eclipse .jdt.debug sour ce query t erms qe bug t itle debb ugger source lookup does not work with variables initialfdeb ugger source lookup work variablesg77 query q q0 msigqpp qrmsig flaunch deb ug resolve required classpathg q0 fsigqpp qrfsig flabel classpath system resolution launchg q0 combqpp qrcomb fjav a type launch classpath labelg qrbest getbestcandidateusingml qr msig qrfsig qrcomb qpp qd q0 ace rqpp qrbest qe query effectiveness rank of the first correct result returned by the query table iii experimental dataset system classes cr system classes cr eclipse.jdt.core .
.
ecf .
eclipse.jdt.debug .
.
log4j .
.
eclipse.jdt.ui .
.
sling .
eclipse.pde.ui .
.
tomcat70 .
.
cr change requests term weighting method but also suggests the best candidate qrbest for query reformulation.
the reformulated query fdebugger source lookup work variables launch debug resolve required classpathg returns the first correct result at the top position i.e.
rank of the result list which is highly promising.
such effective reformulations are likely to reduce a developer s effort during software change implementation.
iii.
e xperiment although pre retrieval methods e.g.
coherency specificity are lightweight and reported to be effective for query quality analysis post retrieval methods are more accurate and more reliable .
existing studies also adopt these methods widely for evaluation and validation.
we evaluate our term weighting method and query reformulation technique using baseline queries and three performance metrics.
we also compare our technique with five closely related existing techniques .
we thus answer five research questions using our experiments as follows rq1 does query reformulation of acer improve the baseline queries significantly in terms of query effectiveness and retrieval performance?
rq2 does coderank perform better than traditional term weighting methods e.g.
tf tf idf in identifying effective search terms from the source code?
rq3 does employment of document structure improve acer s suggestion on good quality search terms from the source code?
rq4 how stemming query length and relevance feedback size affect the performance of our technique?
rq5 can acer outperform the existing query reformulation techniques from the literature in terms of effectiveness and retrieval performance of the queries?
a. experimental dataset data collection we collect a total of bug reports from eight open source subject systems i.e.
five eclipse systems and three apache systems for our experiments.
table iii shows the experimental dataset.
we first extract resolved bug reports i.e.
marked as resolved from bugzilla andjira repositories and then collect corresponding bug fixing commits from github version control histories of these eight systems.
such approach was regularly adopted by the relevant literature and we also follow the same.
in order to ensure a fair evaluation or validation we discard the bug reports from our dataset for which no source code files e.g.
java classes were changed or no relevant source files exist in the system snapshot collected for our study.
we also discard such bug reports that contain stack traces using appropriate regular expressions .
they do not represent a typical change request i.e.
mostly containing natural language texts from the regular software users.
baseline query selection we select the title of a bug report as the baseline query for our experiments as was also selected by earlier studies .
however we discard such queries that i.e.
in verbatim titles already return their first correct results within the top positions i.e.
they possibly do not need query reformulation .
finally we ended up with a collection of baseline queries.
we perform the same preprocessing steps as were done on the source documents section ii c on the queries before using them for code search in our experiments.
goldset development developers often mention a bug id in the title of a commit when they fix the corresponding reported bug .
we collect the changeset i.e.
list of changed files from each of our selected bug fixing commits and develop individual solution set i.e.
goldset for each of the corresponding bug reports.
such solution sets are then used for the evaluation and validation of our suggested queries.
replication all experimental data and relevant materials are hosted online for replication or third party reuse.
b. corpus indexing source code search since we locate concept within project source each of the source files is considered as an individual document of the corpus .
we apply the same preprocessing steps on the corpus documents as were done for query reformulation i.e.
details in section ii c .
we remove punctuation marks and stop words from each document.
then we split the structured tokens and keep both the original and the splitted tokens in the preprocessed documents.
we then apply apache lucene avector space model vsm based popular search engine to index all the documents and to search for relevant documents from the corpus for any given query.
such approaches and tools were widely adopted by earlier studies .
c. performance metrics query effectiveness qe it approximates the effort required to find out the first correct result for a query.
in other words query effectiveness is defined as the rank of the first correct result returned by the query .
the lower the effectiveness score the better the query is.
mean reciprocal rank mrr reciprocal rank is defined as the multiplicative inverse of query effectiveness measure.
mean reciprocal rank averages such measures for all the queries.
the higher the mrr value the better the query is.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv effectiveness of acer q uery against baseline query system queriesimpr o vement worsening preser ving impro v ed mean q1 q2 q3 min.
max.
worsened mean q1 q2 q3 min.
max.
preserv ed ecf .
.
.
jdt.cor e .
.
.
jdt.deb ug .
.
.
jdt.ui .
.
.
pde.ui .
.
.
log4j .
.
.
sling .
.
.
tomcat70 .
.
.
total avg .
avg .
avg .
jdt.cor e eclipse.jdt.core jdt.debug eclipse.jdt.debug jdt.ui eclipse.jdt.ui pde.ui eclipse.pde.ui mean mean rank of first correct results returned by the queries qi ithquartile of all ranks considered top k accuracy it refers to the percentage of queries by which at least one correct result is returned within the top k results.
the higher the metric value the better the queries are.
d. evaluation of acer and coderank we evaluate our technique using baseline queries from eight subject systems and three performance metrics discussed above.
we determine effectiveness and retrieval performance of our suggested reformulated queries and then compare them with their baseline counterparts.
we also contrast our term weight with traditional term weights and calibrate our technique using various configurations.
answering rq effectiveness of acer queries table iv and v show the effectiveness of acer queries.
if our query returns the first correct result closer to the top position than the baseline query then we consider that as query improvement and the vice versa as query worsening.
if both queries return their first correct results at the same position we cosider that asquery preserving.
from table iv we see that acer can improve or preserve of the baseline queries i.e.
about improvement and about preserving while worsening the quality of only about of the queries.
all these statistics are highly promising according to the relevant literature i.e.
maximum improvement reported and they demonstrate the potential of our technique.
when individual systems are considered our technique provides improvement across eight systems.
according to the quantile analysis in table iv of our queries return their first correct results within the top positions for all the systems except two i.e.
top position for log4j and top position for tomcat70 .
please note that only of the baseline queries return their correct results within the top10 positions table vi .
on the contrary of our queries do so for six out of eight systems which demonstrates the potential of our technique.
while query improvement ratios are significantly higher than the worsening ratios i.e.
times higher it should be noted that our technique does not worsen any of the queries for two of the systems log4j andsling.
table v reports further effectiveness and the extent of actual rank improvements by our suggested queries.
we see that reformulations from the method signatures improve the baseline queries significantly.
for example they improve of the baseline queries while worsening of them.
reformulations from the field signatures are found relatively less effective.
however acer reduces the worsening ratio to astable v effectiveness of acer v ariants against baseline queries query p airs impro ved mrd worsened mrd p value preser ved acer msig vs. baseline .
.
.
.
acerf sigvs.
baseline .
.
.
.
acer comb vs. baseline .
.
.
.
acer vs. baseline .
.
.
.
statistically significant difference between improvement and worsening mrd mean rank difference between acer and baseline queries low as .
and increases the improvement ratio up to which are highly promising.
more importantly the mean rank differences mrd suggest that acer elevates first correct results in the ranked list by 81positions on average for at least of the queries while dropping them for only of the queries by positions.
such rank improvements are likely to reduce human efforts significantly during concept location.
retrieval performance of acer queries table vi reports the comparison of retrieval performance between our queries and baseline queries.
given that most of our selected queries are difficult i.e.
no correct results within the top positions the baseline queries retrieve at least one correct result within the top positions for of the cases.
however our reformulations improve this ratio to about and the improvement is statistically significant i.e.
paired t test p value .
.
cohen s d .
moderate .
similar scenarios are observed with mean reciprocal rank as well.
thus to answer rq1 the reformulation of acer improves the baseline queries significantly both in terms of query effectiveness and retrieval performance.
acer improves of the baseline queries with top retrieval accuracy.
answering rq coderank vs. traditional term weighting methods table vii shows the comparative analysis between coderank and two traditional term weights tf and tf idf which are widely used in the text retrieval contexts .
while tf estimates the importance of a term based on its occurrences within a document tf idf additionally captures the global occurrences of the term across all the documents of the corpus .
on the contrary coderank employs a graph based scoring mechanism that determines the importance of a term based on its co occurrences with other important terms within a certain context.
from table vii we see that coderank performs significantly better than both tf i.e.
paired t test p value .
.
and tf idf i.e.
p value .
in identifying important search terms from source code especially from the method signatures.
considering the whole source code rather than signatures improves the performance of both tf i.e.
query improvement and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table vi comparison of acer sretrieval performance with baseline queries query metric top top top top baselinetop k accuracy .
.
.
.
mrr k .
.
.
.
acermsigtop k accuracy .
.
.
.
mrr k .
.
.
.
acerf sigtop k accuracy .
.
.
.
mrr k .
.
.
.
acercombtop k accuracy .
.
.
.
mrr k .
.
.
.
acertop k accuracy .
.
.
.
mrr k .
.
.
.
statistically significant difference between acer and baseline table vii comparison between coderank and traditional term weights query p airs impr o ved worsened preser ved acer msig vs. tfmsig .
.
.
.
.
.
acer f sigvs.
tf fsig .
.
.
.
.
.
acercomb vs. tfcomb .
.
.
.
.
.
acer vs. tf all .
.
.
.
.
.
acer msig vs. .
.
.
.
.
.
tf idf msig acer f sigvs.
.
.
.
.
.
.
tf idf fsig acercomb vs. .
.
.
.
.
.
tf idf comb acer vs. .
.
.
.
.
.
tf idf all statistically significant difference between acer measures and their counterparts tf idf i.e.
query improvement .
however our term weight coderank is still better alone i.e.
and improves significantly higher i.e.
p value .717e fraction i.e.
of the baseline queries when employed with our proposed reformulation algorithm acer.
fig.
shows how coderank and traditional term weights perform in reformulating the baseline queries with their a top and b top terms.
we see that tf reaches its peak performance pretty quickly i.e.
k and then shows a stationary or irregular behaviour.
that means tf identifies frequent terms for query reformulation and few of them e.g.
top could be highly effective.
on the contrary our method coderank demonstrates a gradual improvement in the performance up to top terms i.e.
k fig.
b and crosses the performance peak of tf with a large margin i.e.
paired t test p value .
.
cohen s d .
.
large fork tok .
coderank emphasizes on the votes from other important terms i.e.
by leveraging co occurrences for determining weight of a term and as demonstrated in fig.
this weight is found to be more reliable than tf.
tf idf is found relatively less effective according to our investigation.
thus to answer rq2 coderank performs significantly better than traditional methods in identifying effective terms for query reformulation from the source code.
answering rq do document structures matter?
while most of the earlier reformulation techniques miss or ignore the structural aspect of a source document we consider such aspect as an important paradigm of our technique.
we consider a source document as a collection of structured entities e.g.
signatures methods fields rather than a regular text document.
thus we make use of method signatures and field signatures rather than the whole source code for query reformulation given that they are likely to contain more salient terms and less noise .
fig.
demonstrates how incorporafig.
.
comparison of query improvement between coderank and traditional term weights for a top and b top reformulated query terms fig.
.
improved queries by reformulation from method signatures and field signatures using a coderank cr and b term frequency tf .
c acer vs. tf all content table viii impact of stemming on query effectiveness sour ce query impr o ved mrd worsened mrd preser ved method acermsig stem .
.
.
signature acermsig .
.
.
field acerf sig stem .
.
.
signature acerf sig .
.
.
both acercomb stem .
.
.
signatures acercomb .
.
.
both acerstem .
.
.
signatures acer .
.
.
statistically significant difference between two measures from the same signature mrd mean rank difference between acer and baseline queries tion of document structures into a technique could be useful for query reformulations.
we see that reformulations using method signatures and field signatures improve two different sets of baseline queries and this happens with both term weighting methods a coderank and b tf.
while these sets share about half of the queries reformulations based on each signature type also improve a significant amount i.e.
of unique baseline queries.
in fig.
c when these signatures i.e.
along with acer are contrasted with the whole source code i.e.
along with tf we even found that the signature based reformulations outperform the whole code based reformulations by a large margin i.e.
.
.
more query improvement .
that is the use of the whole source code introduces additional noise and diminishes the strength or salience of the individual structures i.e.
signatures .
most of the existing methods suffer from this limitation.
on the contrary our technique acer exploits document structures i.e.
signatures and carefully chooses the best among all the candidate reformulations derived from such structures using query quality analysis and machine learning.
thus to answer rq3 document structures improve the suggestion of query reformulation terms from the source code.
answering rq impact of stemming query length and relevance feedback from table viii we see that stemming generally degrades the effectiveness of our reformulated queries.
similar findings were also reported by earlier studies .
fig.
shows how a top and b top reformulation terms improve the baseline queries.
we see that authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ix comparison of query effectiveness with existing techniques technique queriesimpr o vement worsening preser ving impro v ed mean q1 q2 q3 min.
max.
worsened mean q1 q2 q3 min.
max.
preserv ed hill et al.
.
.
.
rocchio .
.
.
rsv .
.
.
sisman and kak .
.
.
refoqus .
.
.
refoqussampled .
.
.
acermsig .
.
.
acercomb .
.
.
acer .
.
.
baseline acerext .
.
.
mean mean rank of first correct results returned by the queries qi ithquartile of all ranks considered statistically significant difference between acer measures and their counterparts fig.
.
effectiveness of acer queries for a top and b top reformulated terms our reformulations perform the best i.e.
about query improvement with top to search terms collected from each signature type.
however when query quality analysis is employed our technique acer can improve of the baseline queries with only top reformulation terms.
we also repeat the same investigation with top terms and achieved the same top performance i.e.
fig.
b .
thus our choice of returning top reformulation terms is justified.
we also investigate how the size of pseudo relevance feedback influences our performance and experimented with top documents.
we found that reformulations for acer reach the performance peak when top to feedback source documents i.e.
returned by the baseline queries are analyzed for candidate terms.
this possibly justifies our choice of top10 documents as the pseudo relevance feedback.
thus to answer rq4 stemming degrades the query effectiveness of acer.
reformulation size and relevance feedback size gradually improve the performance of acer as long as they are below a certain threshold i.e.
k .
e. comparison with existing approaches answering rq while the empirical evaluation in terms of performance metrics above clearly demonstrates the promising aspects of our query reformulation technique we still compare with five closely related existing approaches .
hill et al.
suggest relevant phrases from method signatures and field signatures as query reformulations.
while sisman and kak focus on term co occurrences with query keywords rocchio and rsv apply tf idf based term weights for choosing query reformulation terms.
refoqus is closely related to ours and is reported to perform better than rsv and other earlier approaches which probably makes it the state of the art for our research problem.
we replicate each of hill et al.
rocchio rsv sisman and kak and refoqus in our working environment by carefully following their algorithms equations and methodologies given fig.
.
comparison of a query effectiveness and b retrieval performance that their implementations are not publicly available.
in the case of refoqus we implement metrics pre retrieval and post retrieval that estimate query difficulty.
we develop a machine learning model using cart algorithm i.e.
as used by them and fold cross validation.
then we use the model to return the best reformulation out of four candidates of refoqus query reduction dice expansion rocchio s expansion andrsv expansion for each baseline query.
table ix and fig.
summarize our comparative analyses.
from table ix we see that rsv and refoqus perform better than the other existing approaches.
they improve about and about of the baseline queries respectively.
such ratios are also pretty close to the originally reported performances by haiduc et al.
on a different dataset which possibly validates the correctness of our implementation.
while query improvement is the maximum performance provided by any of the existing approaches our technique acer improves about of the baseline queries i.e.
difference between table v and table ix due to rounding error which is significantly higher i.e.
paired t test p value .663e .
cohen s d .
.
large .
refoqus adopts a similar methodology like ours.
unfortunately the approach is limited due to possibly the low performance of its candidate reformulations.
one might argue about the data resampling step i.e.
step fig.
of acer for the high performance.
however we also apply data resampling to refoqus using the same settings as ours for further investigation.
we see that refoqus sampled has a similar improvement ratio like ours but it still worsens a significant amount of queries compared to our .
.
thus our technique still performs better than refoqus in the equal settings.
our quantile measures and mean ranks are more promising than those from the baseline or competing methods as reported in table ix.
table vandrq1also suggest that our queries have high potential for reducing human efforts.
we also experiment with an extended dataset i.e.
8x10 containing very good queries.
as reported in table authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ix acer extmostly preserves the good quality queries rather than worsening which also demonstrates its high potential.
fig.
a shows the box plots of query improvement and query worsening ratios by all the techniques under study.
we see that acer outperforms the existing techniques including the state of the art by a large margin.
our median improvement ratio is about which is higher than even the maximum improvement ratios of the counterparts which demonstrates the promising aspect of acer.
fig.
b shows the top k accuracy of the query reformulation techniques.
we see that our accuracy is relatively higher than that of each of the existing approaches across various top k i.e.
values.
the best performing existing method is rsv .
however our performance is significantly higher than that of rsv for various k values according to statistical significance tests i.e.
paired t test p value .
.
cohen s d .
.
thus to answer rq5 our technique outperforms the stateof the art techniques in terms of reformulation query effectiveness and performs significantly better than each of the existing techniques in terms of document retrieval accuracy.
iv.
t hreats to validity threats to internal validity relate to experimental errors and biases .
although coderank and document structures play a major role the data resampling step section ii f step fig.
has a significant role behind the high performance of our technique.
unfortunately to the best of our knowledge refoqus does not have such a step.
thus the performance comparison might look like a bit unfair.
besides models based on data resampling are sometimes criticized for intrinsic biases .
however we apply data resampling to refoqus as well i.e.
refoqus sampled and demonstrate that our technique still performs better in terms of worsening ratio.
threats to external validity relate to the generalization of the obtained results .
all of our subject systems are javabased.
so there might be different results with systems from other programming languages.
however we experimented with eight different systems with promising performance and the comparison with the state of the art techniques demonstrates the superiority of our approach.
v. r elated work there exist a number of studies in the literature that reformulate a given query for concept location in the context of software change tasks.
existing studies apply relevance feedback from developers pseudo relevance feedback from ir tools partial phrasal matching and machine learning to query reformulation.
they also make use of context of query terms from source code text retrieval configuration and quality of queries in suggesting the reformulated queries.
hill et al.
consider the presence of query terms in the method or field signatures as an indicator of their relevance and suggest natural language phrases from them as reformulated queries.
sisman and kak choose such terms for query reformulation that frequently co occur with query terms withina fixed size of window in the code.
rocchio and rsv determine importance of a term using tf idf based metrics.
haiduc et al.
identify the best of four reformulation candidates for any given query using a machine learning model with metrics.
all these five studies are highly relevant to ours and we directly compare with them using experiments.
readers are referred to section iii e for comparison details.
other related studies explore graph based methods for term weighting.
rahman and roy simply use textrank on change request texts for suggesting initial queries for concept location.
yao et al.
build a term augmented tuple graph and use a random walk approach to reformulate queries for structured bibliographic dblp data i.e.
nonsource code .
ours is significantly different from these studies in the sense that we reformulate the initial queries not only by employing our term weighting method coderank for source code but also by applying source code document structures query quality analysis and machine learning.
besides their reported best performance i.e.
query improvement over baseline is quite lower than our performance i.e.
even with difficult queries .
given that reformulation is often performed on the initial queries our technique can potentially complement theirs.
howard et al.
map method signatures to associated comments for query reformulation and thus might not work well with source code without comments.
rahman and roy exploit crowd sourced knowledge for query reformulation and their method is also subject to the availability of a third party information source.
thus while earlier studies adopt various methodologies or information sources our technique not only employs a novel and promising term weight coderank but also exploits structures of the source documents for identifying the best reformulation to a given query for improved concept location.
vi.
c onclusion f uture work to summarize we propose a novel technique acer for improved query reformulation for concept location.
it takes an initial query as input identifies appropriate search terms from the source code using a novel term weight and then suggests the best reformulation to the initial query using document structures query quality analysis and machine learning.
experiments with baseline queries from eight systems report that our technique can improve of the baseline queries and preserve of them which are highly promising.
comparison with five closely related approaches including the state of the art not only validates our empirical findings but also demonstrates the high potential of our technique.
in future we plan to apply our term weighting method coderank to other se text retrieval tasks involving source code such as bug localization and traceability recovery.
acknowledgement this research work was supported in part by the natural sciences and engineering research council of canada nserc and the internal dean s scholarship of university of saskatchewan canada.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.