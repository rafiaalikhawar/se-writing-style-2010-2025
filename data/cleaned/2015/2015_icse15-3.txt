dase document assisted symbolic execution for improving automated software testing edmund wong lei zhang song wang taiyue liu and lin tan electrical and computer engineering university of waterloo canada fe32wong lei.zhang song.wang t67liu lintan g uwaterloo.ca abstract we propose and implement a new approach document assisted symbolic execution dase to improve automated test generation and bug detection.
dase leverages natural language processing techniques and heuristics to analyze program documentation to extract input constraints automatically.
dase then uses the input constraints to guide symbolic execution to focus on inputs that are semantically more important.
we evaluated dase on programs from mature real world software suites c oreutils findutils grep binutils and elftoolchain .
dase detected previously unknown bugs that symbolic execution without input constraints failed to detect of which have already been confirmed by the developers.
in addition dase increases line coverage branch coverage and call coverage by .
.
.
.
and .
.
respectively which are .
.
percentage points pp .
.
pp and .
.
pp increases.
the accuracies of input constraint extraction are .
.
i. i ntroduction software testing is an essential part of software development.
many automated test generation techniques are proposed and used to improve testing effectiveness and efficiency .
symbolic execution has been leveraged to automatically generate high code coverage test suites to detect bugs .
symbolic execution represents inputs as symbolic values instead of concrete values.
upon exploring a branch whose condition involves symbolic values two paths are created and the corresponding constraints are added to each path.
once the execution of a path terminates the collection of constraints along that execution path is used to generate concrete inputs to exercise the path.
symbolic execution suffers from the fundamental problem of path explosion.
in practice one needs to use search heuristics and other techniques to guide symbolic execution .
although symbolic execution has been successful in improving testing effectiveness existing techniques do not take full advantage of programs input constraints expressed in documents.
valid program inputs typically need to follow certain constraints.
for example rm version .
only accepts options including rand f and readelf requires its input files to follow executable and linkable format elf .
focusing on the valid and close to valid inputs can help test the core functionalities of the program which should improve testing coverage and effectiveness as shown by previous techniques .
it allows symbolic execution to devote more resources on testing code that implementsprogram s core functionalities as opposed to code for input sanity check and error handling.
fortunately information about input constraints commonly exists in software documents such as programs manual pages e.g.
the output of man rm and the comments of header files e.g.
elf.h .
thus we propose a general approach document assisted symbolic execution dase to enhance the effectiveness of symbolic execution for automatic test generation and bug detection.
dase automatically extracts input constraints from documents and uses these constraints as a filter to favor execution paths that execute the core functionalities of the program.
dase as a path pruning strategy can be used on top of existing search strategies to further improve symbolic execution vi shows that dase can find more bugs and improve testing coverage on top of different search strategies .
testing with invalid inputs can also be important e.g.
to check error handling code or find defects due to malformed inputs .
however this paper focuses on testing with valid inputs as it allows symbolic execution to exercise deeper into program logic rather than focus on input parsing.
if developers believe it is more important to test some programs with invalid inputs they can use the dase approach to focus on invalid inputs by negating the input constraints which we would like to evaluate in the future.
regardless of what inputs valid or invalid to focus on one cannot do so without knowing what inputs are valid and what are not.
dase enables this choice automatically by extracting input constraints from program documents automatically .
this automation is novel because existing symbolic execution techniques do not analyze documents automatically and require input constraints to be given.
previous work has shown that constraint extraction from documentation is important yet challenging.
since this automation can reduce manual effort dase could make it easier for practitioners to adopt these symbolic execution techniques and other techniques that require input constraints such as constraint verification.
dase considers two categories of input constraints the format of an input file e.g.
elf and tar and valid values of a command line option e.g.
rforrm .
these two types are sufficient for a wide spectrum of programs.
this paper makes the following contributions we propose a novel approach dase to improve automated test generation.
by leveraging input constraints automatically extracted from documents dase enables symbolic accepted for publication by ieee.
ieee.
personal use of this material is permitted.
permission from ieee must be obtained for all other uses in any current or future media including reprinting republishing this material for advertising or promotional purposes creating new collective works for resale or redistribution to servers or lists or reuse of any copyrighted component of this work in other works.execution to automatically distinguish the semantic importance of different execution paths to focus on programs core functionalities to find more bugs and test more code.
we propose a new technique that combines natural language processing nlp techniques i.e.
grammar relationships and heuristics to automatically extract input constraints from documents.
the technique is general and should be able to extract input constraints for purposes other than symbolic execution such as program comprehension and constraint verification.
we study two types of documents i.e.
manual pages and code comments and extract input constraints from both.
our evaluation shows that dase finds more bugs and has higher code coverage than klee a symbolic execution tool without input constraints from documents .
we evaluated dase on programs from widely used software suites gnu c oreutils gnu findutils gnu grep gnu b inutils and elftoolchain most of which have been thoroughly tested by many symbolic execution tools .
dase detected previously unknown bugs1that klee failed to detect of which have already been confirmed by the developers while the rest await confirmation.
compared to klee dase increases line coverage branch coverage and call coverage by .
.
.
.
and .
.
respectively which are .
.
percentage points pp .
.
pp and .
.
pp increases.
the input constraint extraction of three files formats elf tar and the common object file format coff has accuracies of .
.
ii.
o verview a real world program typically contains numerous or even infinite number of execution paths.
given limited time it is crucial for testing to prioritize the paths effectively.
researchers have proposed approaches to guide the path exploration of symbolic execution to find more bugs and improve code coverage.
path pruning which applies a filter to prune uninteresting paths before employing a search strategy can further address the path explosion problem.
path pruning significantly reduces the size of the search space for a search strategy.
we propose using input constraint s as a filter to aid search strategies to focus on both valid and close to valid inputs e.g.
boundary cases to explore deeper in a program s core functionality.
the core functionality of a program is typically related to processing valid inputs.
for example a c compiler s core functionality is parsing and compiling valid c programs.
valid c programs are only a small portion of all strings the input space of a c compiler .
randomly generated inputs can cover many invalid inputs but miss valid and close to valid ones.
while symbolic execution addresses this issue by exploring paths systematically it is unaware of which branch the then branch or the else 1we do not count bugs that are already reported in the klee paper.
those bugs which can also be found by dase are not counted as newly detected ones by dase either.
i n t c o u n t e r f o r i n t i i i f i f i n p u t a f c o u n t e r foo 6g 7g i f c o u n t e r f p r o c e s s b o u n d a r y c a s e s bug !
i f i n p u t b p r o c e s s v a l i d i n p u t bug !
12g fig.
motivating example branch leads to valid inputs upon a conditional statement .
input constraints that define valid inputs can guide symbolic execution to focus on paths corresponding to valid inputs.
the constraints can be slightly relaxed e.g.
relaxing a constraint x must be between to inclusive to x must be between and inclusive to exercise paths corresponding to close to valid inputs to test boundary cases.
these paths for valid and close to valid inputs can pass the trivial part of input sanity check to go deeper and are more likely to uncover bugs for two main reasons.
first keeping invalid inputs in the search space hurts the effectiveness of symbolic execution based test generation.
the reason is that exploring invalid inputs takes up time and memory which can be used for testing valid and close tovalid inputs instead.
second some constraints are solved or simplified e.g.
the ones related to the concrete valid option which reduces the computation time of the constraint solver.
next we illustrate why input constraints can help symbolic execution find more bugs and improve testing coverage and summarize how dase extracts these types of constraints automatically from two sources of documents.
why can input constraints help symbolic execution find more bugs and test more code?
we will use the code snippet in figure to answer this question while real code from binutils is shown later in figure to explain how the automatically extracted input constraints help dase detect previously unknown bugs and improve coverage.
the code snippet in figure has branches from line and one from lines and one from line indicating 232possible paths to explore.
without knowing which paths execute the core logic it is hard to expose the bug deep in line because only out of the 232paths leads to that line.
dase automatically extracts constraints from documents and find that the first characters of a valid input must be a and the next character must be b .
these constraints will guide the execution to line .
if the document is incomplete e.g.
only mentioning that the first characters of a valid input must be a we can still hit the bug in line that is triggered by close to valid inputs.
in addition it increases the chance to detect the bug in line 232to1 .
in either case dase can cover more code lines and possibly which is hard for standard symbolic execution to cover in addition to detecting more bugs.
number of supplied input constraintsruntime minutes fig.
the runtime to find the bug in line decreases exponentially as we supply more input constraints.
the runtime when no constraint is supplied is not depicted because the bug was not detected after hours when we stopped the execution.
we run klee on this example for hours and klee detects neither of the bugs.
in contrast dase detects both bugs in .
seconds.
in practice one may not have all constraints to define the entire input.
in order to understand the effect of the number of constraints we plot how the time to discover the bug in line changes as the number of given constraints changes in figure .
the runtime to find the bug decreases exponentially as we supply more input constraints suggesting that input constraints can dramatically improve the efficiency of finding bugs i.e.
finding more bugs given the same amount of time.
how to flatten symbolic execution to find more bugs and test more code?
command line options are a special type of input.
therefore we propose a new way to leverage their constraints to improve testing effectiveness.
command line options are used to invoke certain functionalities of programs or tune parameters.
for example the option rtellsrmto perform a recursive deletion.
a program typically uses nested if else statements or a switch case statement to check the input argument against all valid options until it finds a match and then invokes the corresponding functionality.
dase extracts valid options by analyzing programs documentation and use them as input constraints.
for example dase finds that among the 256mpossibilities2forrm mis the maximum number of characters allowed in an option only values are valid options.
with nvalid options n in the example above dase forks the execution state ntimes with each child execution state taking a valid option3.
in this way dase creates nexecution branches for a program with nvalid options one for each valid option .
the concretization moves all valid options at the same depth of the execution tree indicating that all valid options are treated equally figure 3b .
figure 3a illustrates the dynamic execution tree of symbolic execution without dase.
clouds are subtrees related to valid command line options.
if a program has valid options a o and ois the deepest valid option as shown in figure 3a the time spent on testing code related to option ocould be1 215of the total testing 2there are possibilities for a single bit character option.
3we have additional child execution states for an invalid option and a null option for completeness.
but the execution time for these two options should be less than the circles in figure 3a combined.bash program a b ... o ... ... o b a... a without dase a b... o... b with dase fig.
abstract view of execution trees for command line options.
clouds are execution subtrees related to valid command line options.
ovals are other execution subtrees.
deep options such as oare more likely to be tested with dase.
time without dase4.
the reason is there are branches from the nested if else or switch case statements one for each valid option.
such a small fraction often means option o would not be tested at all in practice.
with dase the time of testing option owould be much longer about1 15as in figure 3b.
this way a bug in the code that processes option owill be more likely to be exposed with dase.
on the other hand the probability of hitting a bug in a shallower option e.g.
b would be reduced from1 22to1 but the difference is much smaller and it is still highly likely that the option bwill be tested given that the probability is1 .
in addition to finding more bugs since each option has about1 chance to be explored more options are likely to be tested improving testing coverage vi b shows that dase covers more options than klee .
although this approach may appear to be similar to breadthfirst search bfs it is very different from bfs.
without dase bfs would explore paths in figure 3a which would still waste time on shallow paths and are less likely to explore deeper paths.
in fact our evaluation shows that dase outperforms klee even if bfs is used as the underlying search strategy vi b .
what documents to analyze and how to extract input constraints from them automatically?
many types of software documents are available manual pages code comments api documentation requirement documents etc.
this paper studies and analyzes two popular types for constraint extraction i.e.
manual pages and code comments since they describe whole program constraints as opposed to api documentation that describes method level constrains and they contain more code level constraints compared to requirement documents .
we conduct an informal qualitative study of manual pages from c oreutils and code comments of header files elf tar and coff .
manual pages man pages for short typically have higher english quality e.g.
grammatically correct full english sentences since they are meant to be read by more than just the developers.
on the other hand it is easier to link constraints from code comments to code artifacts since 4the actual time depends on the search strategy but the time spent on testing owould be much smaller than that of testing a.comments are embedded in the code e.g.
a comment typically describes the code segment right below it .
valid options are typically described in a well structured manner in man pages.
therefore we use simple regular expression matching to extract them iv c .
input file formats are described in both man pages and code comments.
we use regular expression matching to analyze the man pages.
since code comments are less structured we use nlp techniques i.e.
grammar relationships for extraction iv a .
grammar relationships can help identify relevant sentence structures for constraint extraction.
it can tolerate different word orders and paraphrases thus more general than hard coded heuristics.
iii.
klee b ackground klee is a symbolic execution engine based on llvm.
programs are compiled into llvm bytecode and then interpreted by klee.
klee models the programs running states.
it checks for dangerous operations e.g.
pointer dereferences and assertions that can cause the program to fail.
in addition klee maintains path constraints that drive the execution to the current state.
klee provides a function klee make symbolic to make the memory symbolic whose usages are tracked and constraints are collected.
klee can also intercept the startup of programs and insert logic to make them support options for symbolic execution by using function klee init env .
supported options include sym args min max n which expands to at least min and at most max symbolic arguments each with a maximum length of n and sym files num n which makes stdin and up to num files symbolic each with a maximum size of n. klee s default search strategy consists of two atom search strategies that are interleaved in round robin fashion to prevent one atom strategy from getting stuck.
the first atom strategy coverage optimized search uses heuristics to choose a state that is most likely to cover new code in the immediate future.
the second atom strategy random path selection randomly selects a branch to follow at a branch point which helps alleviate starvation.
iv.
d esign and implementation this section describes how dase extracts and utilizes input constraints for file formats iv a and iv b and options iv c and iv d .
a. extracting file format constraints dase automatically extracts input constraints regarding file formats from both code comments and man pages.
as discussed in ii code comments and man pages have different characteristics so different techniques are used to extract constraints from them nlp techniques for code comments and regular expressions for man pages.
the same techniques are used for all three file formats elf tar and coff.
we apply nlp techniques to analyze the comments and code in header files to extract constraints automatically.
the header file contains a large number of comments that describethe constraints for the struct data fields i.e.
each comment is followed by a list of macros representing the valid values .
one example is fields in the e ident array.
the ei macros are indices into the array.
the macros under each ei macro are the values the byte may have.
define ei mag0 define elfmag0 0x7f define ei mag1 define elfmag1 e dase automatically generates two constraints regarding array index value pairs from the comments and code assume elf32 ehdr e ident elfmag0 assume elf32 ehdr e ident elfmag1 where assume is a klee function for putting constraints onto the current path.
the rest of this section explains the nlp techniques to generate the constraints.
our technique extracts two types of value constraints array index value pairs and struct field values e.g.
assume elf32 shdr e type ... .
since comments are written in natural language developers can use different forms to express the same meaning.
for example they may use fields in the e ident array fields of the e ident array the e ident array s fields or the array e ident s fields to start the listing of fields.
these sentences use different sentence structures and words to express the same meaning which are difficult to analyze automatically.
simple regular expression matching will fail to accommodate all these and other variants.
we propose to use stanford typed dependency to analyze the dependencies and grammatical relations among words and phrases in a sentence to handle these variants.
our technique is different from prior work .
dase uses four grammar rules gr to identify relevant comments and extract constraints from them.
all four rules are used as main rules to identify relevant comments if a sentence contains the typed dependency defined by a gr it is considered relevant and remains for further analysis.
gr1 and gr2 can also act as a supporting rule for any main rule.
for example gr1 can help identify the parameters in a rule e.g.
array and field names.
the four grs are listed below gr1 noun or adjectival modifier main support rule noun or adjectival modifier is a noun or adjectival phrase that modifies a noun phrase .
for example in the comment fields in the e ident array the noun phrase eident modifies the noun array .
dase applies this grammar relationship to retrieve data structure names and index names.
gr2 prepositional modifier main support rule prepositional modifier is a prepositional phrase that modifies the meaning of a verb adjective noun or preposition .
for example in the comment legal values for sh type field of elf32 shdr the prepositional phrase for ... elf32 shdr modifies the noun values .
dase applies this grammar on modifiers i.e.
for of in and under to locate specific nouns i.e.
value and field or specific word in the prepositional phrase i.e.
field .
after locating the prepositional modifier the dependency tree links values to the content word field .
if the contentword is being modified by an adjectival modifier dase applies gr1 to resolve the properties.
in this example gr1 will return sh type as the property of field and gr2 will flag the macros as the legal values for that data field.
gr3 nominal subject main rule nominal subject is a noun phrase that is the syntactic subject of a clause .
for example in the comment the ei macros are indices into the array .
the noun macros is the subject of the clause indices into the array .
dase applies this grammar to locate specific clauses i.e.
indices ... and values ... .
after locating the nominal subject dase applies gr1 to resolve the properties.
in this example gr1 will return the regular expression ei as the property of macros and gr3 will flag the macros named under this regular expression as the indices of an array.
gr4 possession modifier main rule possession modifier holds the relation between the head of a noun phrase and its possessive determiner .
for example in the comment shtype field s legal values .
the head noun is field and the possessive determiner is values .
dase applies this grammar to locate specific possessive determiners i.e.
value .
after locating the possession modifier dase applies gr1 to resolve the properties of the head noun.
in this example gr1 will return the field name sh type as the property of field .
if a comment only specifies a partial field name dase will resolve the name into a fully qualified name.
for example the comment legal values for e type specifies a field name e type without the struct name.
dase maps this field name to structs that contain this field name and generates the fully qualified names elf32 ehdr!etype and elf64 ehdr!etype .
we use the example that is shown at the beginning of this section to illustrate how to extract one type of constraints index value pairs using the grammar rules on the three sentences s1 s2 and s3 .
s1 gr2 identifies a prepositional link in between fields and array and invokes gr1 to resolve array .
gr1 queries the noun modifier for array and returns e ident .
therefore it captures the array name as eident .
s2 gr2 identifies a prepositional link into between indices and array but it does not invoke gr1 because there is no noun modifier.
gr3 identifies indices as the subject of macros and invokes gr1 to resolve macros .
gr1 queries the noun modifier for macros and returns ei .
therefore macros with the name ei are treated as the indices of an array.
s3 gr3 is invoked before gr2 because of the structure of the dependency tree.
gr3 identifies values as the subject of macros but it does not invoke gr1 because there is no noun modifier.
gr2 identifies a prepositional link under between macros and macro and invokes gr1 to resolve macro .
gr1 queries the noun modifier for macro and sh sh sh sh sh elf header ph ...... null section section header string table symbol table dynamic section random sectionsection header table program header table sectionfig.
dase s elf layout.
sh is section header and ph is program header.
numbers in brackets are array indices.
returns ei .
therefore the macro below the macro name ei is treated as the value of an array.
dase aggregates the information from the three sentences.
it then attempts to resolve the array name e ident into a fully qualified name.
since there is enough information it deducts elf32 ehdr!eident as the fully qualified name and generates two constraints.
in addition dase extracts constraints from man pages using regular expressions.
man pages often show a struct declaration followed by the constraints if available for each field in the struct .
the valid values for each struct field can be identified based on the indentation of the man page.
based on this layout dase first locates the name of the struct and maps it to each of the constraints that are listed below it.
the output of this analysis is also a list of constraints that can be directly used by the symbolic execution part of dase.
b. adding file layout constraints elf files follow a certain layout which also defines valid elf files.
therefore in addition to extracting the file format constraints as described in iv a we add file layout constraints for elf by reading the elf specification .
our results show that both the file format and file layout constraints contribute to the improvement of dase.
an elf file always starts with an elf header followed by the two header tables section header table sht and theprogram header table pht .
sht contains an array of section header s pht contains an array of program header s and object files real data are in the section s. in order to reduce the workload of the constraint solver and focus on important parts of elf we adopt a rigid layout as shown in figure .
sht is set to have five section headers.
the first section at index is a null section followed by a string table symbol table dynamic section and random section.
the second and fifth section are set with a size of bytes and the third and fourth section are set with a size that is enough to hold two symbols.
pht is set to contain one random program header.
note that our elf layout is incomplete.
we retain this incompleteness to give dase the ability to explore closeto valid inputs to explore boundary cases.
in addition input constraints can be slightly relaxed to include more close tovalid inputs which remains as our future work.c.
extracting valid options we automatically extract valid options only from man pages because we find that code comments do not describe valid options.
since man pages list the valid options in a standardized format our parsers perform simple regular expression matching which is effective and accurate.
dase takes a man page as input and outputs a list of valid command line options.
it uses two regular expressions one for short options a single dash followed by a single letter and one for long options two dashes followed by multiple letters .
if a short option has a long option equivalent dase keeps only the short option.
d. using options to flatten symbolic execution dase takes the options extracted in iv c to trim and reorganize the dynamic symbolic execution tree as shown in figure .
specifically instead of having ssymbolic arguments dase runs the program with s 1symbolic arguments and a concrete valid option which forms one execution branch.
in this way dase creates nexecution branches for a program with nvalid options one for each valid option .
the aim is to balance the testing effort on each option and the corresponding functionality which should be of the similar semantic importance at least not as skewed as1 2versus1 2n as shown in section ii .
the generated branches are then prioritized by search strategies.
we can consider this technique as a partition of the execution tree.
thes 1arguments remain symbolic which can expand to any concrete options.
therefore it is possible to cover combinations of commandline options such as r f of rm in our approach .
to ensure the completeness of this partition we add a branch for an invalid option and a branch for a null option.
v. m ethod we use three coverage criteria reported by gcov i.e.
line branch and call coverage of executed function calls as our main coverage metrics.
the coverage criteria and gcov are widely used in literature .
a. evaluated programs we evaluate dase on the following programs from popular and mature fundamental software suites for unix like systems.
the sizes of these programs are at the same scale as the ones evaluated by previous work .
coreutils .
.
coreutils also evaluated by klee is a package of gnu programs that consists of basic file shell and text manipulation utilities.
for a fair comparison with klee our settings for dase and klee for c oreutils are identical we set the same environment for c oreutils as klee s authors and we choose the same version .
and follow their parameters for both klee and dase.
the total source lines of code loc 5of the stand alone programs6 5following previous work all loc counts in this paper are reported by cloc .
.
6yes is excluded because klee failed to terminate its execution.
ddis excluded because it uses a different option style.
chmod kill mv rm and rmdir are excluded because they continually cause dangerous test cases to be generated that destroy our experiment data.
in the future we can apply dase to these programs in a sandbox to address this issue.that we tested in c oreutils are with a linked library size of loc.
the program sizes range from loc.
here we show the program sizes and library sizes to give a better image of the scale of the programs.
following previous work coverage is measured against the programs excluding libraries as reported by gcov since a program typically use only part of libraries.
diff .
.diff compares files line by line and outputs the differences.
the program has loc with a library size of loc.
grep .
.grep searches files for given patterns.
the program has loc with a library size of loc.
objdump readelf b .
.
these two programs are from b inutils which is a set of gnu programs for processing binaries libraries object files etc.
objdump andreadelf are used for displaying the contents of elf files.
they have and loc respectively with a library size of loc.
since both b inutils and elftoolchain contain a readelf program we use readelf b to denote the readelf program in b inutils andreadelf e to denote the one in elftoolchain .
elfdump readelf e r2983 .
in order to test our elf model more thoroughly we select elftoolchain s counterparts for the above two programs.
elftoolchain provides similar tools as b inutils but favors well separated and well documented libraries.
they have and loc respectively with a library size of loc.
b. experimental setup all automatically extracted file format constraints and valid options without manual examination for zero manual effort are used as input constraints for all programs when applicable.
dase extracts file format constraints for elf and uses them for the elf processing programs objdump readelf b elfdump and readelf e for path pruning.
elf is a boardly used main standard for binaries in unix like systems.
one can use the elf model that we build to potentially improve test generation for all programs that read or write elf binaries on a unix like platform .
in addition dase extracts valid options for the rest of the programs automatically and uses them to guide the symbolic execution on them.
to show the generality of our techniques of automatically extracting file format constraints dase extracts file format constraints for two additional standard file formats tar from tar.h and the common object file format coff from coff internal.h .
we run klee and dase on each program until no new instructions are covered in a certain amount of time minutes for c oreutils programs and minutes for the rest due to their larger sizes.
this stop criterion allows both dase and klee to run until they cannot make progress in coverage in a fixed time period which is similar to that of the previous paper but different from that of klee in which each program is only allowed to run for one hour.
in our experiments the actual run time of each program varies from seconds to .
hours.
we have also conducted experimentsusing the stop criterion from the klee paper and dase still achieves a similar amount of improvement over klee .
the other parameters are set by following the instructions from klee s authors .
the key parameters are klee prog sym args sym args sym files sym stdout where prog is a program in c oreutils .
while for dase we keep all the parameters the same as for klee except for replacing a symbolic argument with a list of valid options.
for diff andgrep we set the symbolic file size to bytes because they are meant to process textual files.
for the elf processing programs we use the following parameters respectively for klee and dase klee sym args sym files klee sym args sym elfs where sym elfs holds our elf model described in iv b. we conduct our experiments on an intel core i5 .10ghz cpu machine running ubuntu .
.
klee is built from git revision a45df61 with llvm .
.
vi.
r esults this section shows that dase finds more previously unknown bugs improves code coverage on top of different search strategies complements developer tests and extracts input constraints automatically.
we also show that our results are statistically significant.
a. detected bugs using the constraints automatically inferred from documents without any manual verification dase finds more bugs than klee.
klee detects previously unknown bugs from the programs while dase can uncover previously unknown bugs klee failed to detect of them .
table i lists all of the detected previously unknown bugs.
dase found previously unknown bugs in c oreutils and in b inutils objdump readelf b both of which have already been thoroughly tested by many symbolic execution tools.
for example c oreutils has been tested by veritesting zesti and klee and b inutils has been tested by veritesting zesti and katch .
finding new bugs in those extensively tested suites demonstrates dase s ability in finding new bugs and improving symbolic execution.
we explain a few example bugs to demonstrate dase s bug finding capability.
all these example bugs together with others a total of have already been confirmed and fixed by the developers after we reported the bugs to them.
readelf b fails with segmentation fault when the input file contains malformed attribute sections of type sht arm attributes .
the bug exists in the functionprocess attributes which is shown in figure .
pointer pwalks through the whole section.
at line bytes are read and interpreted as the length section len of the subsequent data structure.
directly after that the program expects to read a string and assign its length to namelen .
however section len can be a number smaller than namelen table i new bugs detected by klee and dase.
x denotes a bug is found by a tool.
iu means integer underflow.
dbz is divide by zero.
il is infinite loop.
npd means null pointer dereference.
pob stands for pointer out of bounds.
me is memory exhausted.
no program location problem klee dase 1readelf b readelf.c iu x objdump elf attrs.c iu x objdump elf.c pob x 4readelf e readelf.c dbz x 5readelf e readlef.c dbz x 6readelf e readelf.c dbz x 7readelf e readelf.c iu x 8readelf e readelf.c il x 9readelf e readelf.c il x readelf e readelf.c npd x readelf e readelf.c pob x elfdump elfdump.c pob x x elfdump elf scn.c pob x head head.c me x split split.c me x s t a t i c i n t p r o c e s s f i l e h e a d e r void f i f e l f header .
e i d e n t !
elfmag0 3jje l f h e a d e r .
e i d e n t !
elfmag1 4jje l f h e a d e r .
e i d e n t !
elfmag2 5jje l f h e a d e r .
e i d e n t !
elfmag3 f e r r o r not anelf f i l e .
.
.
return 8g.
.
.
9g .
.
.
s t a t i c i n t p r o c e s s o b j e c t .
.
.
f. .
.
i f !p r o c e s s f i l e h e a d e r return .
.
.
p r o c e s s a r c h s p e c i f i c f i l e c a l l s p r o c e s s a t t r i b u t e s i n d i r e c t l y .
.
.
16g .
.
.
s t a t i c i n t p r o c e s s a t t r i b u t e s .
.
.
f. .
.
s e c t i o n l e n b y t e g e t p p .
.
.
namelen s t r l e n char p p namelen s e c t i o n l e n namelen while s e c t i o n l e n .
.
.
28g fig.
buggy code in readelf.c from b inutils .
which causes an integer underflow at line .
the variable section len which becomes an extremely big number after underflow is later used as the stop condition of a continuing reading of the following memory which eventually causes a segmentation fault.
five other functions are ahead of process attributes in the call stack namely main process file process object process arch specific and process arm specific .
each function reads and processes specific parts of the input elf file.
for example to correctly invoke process attributes the condition for the ifstatement at lines must evaluate to false.
the automatically extracted elf constraints guide dase to generate an elf file that satisfies all these constraints to reach process attributes and expose the bug.
this close to valid elf file helps dase detect this bug.
readelf e contains a similar bug.table ii coverage results with klee s default search strategy .
line br and call show the total number of executable lines of code eloc branches and calls for each program reported by gcov .
k stands for klee and d is dase.
is the improvement in percentage points of dase over klee.
program line k d br k d call k d pp pp pp coreutils .
.
.
.
.
.
.
.
.
diff .
.
.
.
.
.
.
.
.
grep .
.
.
.
.
.
.
.
.
objdump .
.
.
.
.
.
.
.
.
readelf b .
.
.
.
.
.
.
.
.
elfdump .
.
.
.
.
.
.
.
.
readelf e .
.
.
.
.
.
.
.
.
the head program fails with memory exhaustion when invoked with options c 1p which tells head to print all but the last 1pbytes of the input file.
since pis a large unit of head tries to allocate a large amount of memory which exceeds the total amount of available memory.
according to the comment head is not expected to fail out of memory when asked to elide a ridiculous amount .
for bigger units e.g.
zandy head exits with the correct error message number of bytes is so large that it is not representable .
neither developers hand written tests nor klee generated tests detect this bug.
two bugs can be found by klee but not by dase due to the following reason.
the elf file to trigger the bugs has a very large e shoff value sht s offset from the beginning of the efl file which is incompatible with our elf model.
as shown in iv b we manually fixed the offset to layout the sht.
missing these two bugs shows the tradeoff involved in designing the elf model.
dase focused on those more valid inputs to test the core logic.
our results clearly demonstrate the benefits of our design choice dase finds more bugs than klee.
one can relax the constraints to explore fewer valid inputs and potentially cover these two bugs.
running klee and dase together to gain benefits from both is also a good solution.
b. code coverage table ii shows the overall code coverage achieved by klee and dase.
dase outperforms klee on the programs it increases the line coverage branch coverage and call coverage by .
.
.
.
and .
.
respectively which are .
.
pp .
.
pp and .
.
pp increases.
for example the line coverage boost on grep is .
pp.
programs readelf b objdump readelf e and elfdump are difficult to test because their inputs involve the complex elf format.
despite the lower coverage dase detected new bugs in them that existing techniques did not detect as shown earlier.
figure shows the coverage improvement of dase over klee on readelf b over time.
it shows that the improvement increases as time proceeds.
the coverage percentages for c oreutils are different from those of the klee paper .
the difference is inevitable because the klee tool has evolved significantly since then including major code changes of klee e.g.
removals of special tweaks and an architecture change from bit to .
.
.
.
time seconds br.
coverage dase kleefig.
branch coverage on readelf b over time.
table iii number of instructions of generated test cases showing that dase explored deeper than klee.
k stands for klee and d stands for dase.
a vg i and max i is the a verage and maximum number of instructions for the generated test cases respectively .
since coreutils includes multiple programs a range the minimum and the maximum is shown.
program k a vg i d a vg i k max i d max i coreutils programs diff grep objdump readelf b elfdump readelf e bit.
we choose the latest version of klee at the time of the experiment because the original version used in the klee paper is not publicly available.
for a fair comparison the configurations for klee and dase are identical.
dase explored deeper than klee.
since dase filters out uninteresting paths we expect it to explore deeper.
we count the number of executed instructions for each test case generated by klee and dase to approximate the depth of the corresponding paths.
the average and maximum numbers are shown in table iii which shows that dase generates test cases with much more instructions executed indicating that dase goes much deeper into the execution tree than klee.
for the elf processing programs both the averages and maximums almost double their counterparts of klee.
the difference is expected because while klee is still exploring at the early stage of the elf sanity check dase has already penetrated through that part with the help of our elf model.
dase covered more functionalities and options than klee.
to investigate dase s coverage gain in detail we manually check the coverage difference of klee and dase ondiff .
klee explores only out of the distinct options7 which are the shallower options while dase covers options.
the result agrees with our analysis in figure .
we have similar observations for the elf processing programs.
we manually examine the coverage difference on readelf.c binutils .
for the three functions related to dynamic section dynamic section in which means get 32bit get 64bit orprocess klee fails to cover any of them while dase naturally tests them all because our elf model has a dynamic section.
in addition 7we count options that invoke the same code segment as one option.table iv coverage results with bfs program line k d br k d call k d pp pp pp coreutils .
.
.
.
.
.
.
.
.
diff .
.
.
.
.
.
.
.
.
grep .
.
.
.
.
.
.
.
.
objdump .
.
.
.
.
.
.
.
.
readelf b .
.
.
.
.
.
.
.
.
elfdump .
.
.
.
.
.
.
.
.
readelf e .
.
.
.
.
.
.
.
.
table v coverage of combining dase with developer test cases showing that dase complements developer tests.
v is developer tests.
d is dase combined with developer tests.
do note that readelf e has no developer test cases hence is missing.
program line v d br v d call v d pp pp pp coreutils .
.
.
.
.
.
.
.
.
diff .
.
.
.
.
.
.
.
.
grep .
.
.
.
.
.
.
.
.
objdump .
.
.
.
.
.
.
.
.
readelf b .
.
.
.
.
.
.
.
.
elfdump .
.
.
.
.
.
.
.
.
many other functions such as print symbol are missed by klee but covered by dase.
the improvement of dase generalizes to bfs.
to show that the coverage improvement of dase over klee is not tied to klee s default search strategy we change the underlying search strategies for both klee and dase to bfs and rerun our experiments in table ii.
because it is too timeconsuming approximately days to run all the programs we randomly sample programs from c oreutils .
table iv shows that when the search strategy is bfs dase still outperforms klee.
comparing table iv with table ii we can see that bfs achieves higher coverage than klee s default search strategy for c oreutils while bfs is less effective for b inutils .
the result shows that although input constraints can help it is still important to select an effective search strategy for the program under test.
nonetheless dase is consistently better than klee for the two search strategies and the programs evaluated.
c. dase complements developer tests since automated test generation aims to complement developer generated tests we evaluate whether dase finds bugs that developer tests cannot detect and improves code coverage on top of developer tests.
dase detected a total of bugs on the evaluated programs that developer generated tests fail to detect vi a .
table v shows the coverage comparison.
we can see that by adding dase generated tests the line coverage is improved by .
.
pp.
together with table ii we can see that for c oreutils anddiff dase alone can generate tests to achieve comparable code coverage as developer generated ones.
although the coverage improvement onobjdump readelf b and elfdump is relatively small the dase generated tests detected previously unknown bugs for all of them.
the results demonstrate that dase can be used by developers to find more bugs and further improve testing coverage even if manual tests exist.d.
constraint extraction results dase automatically extracted input constraints from man pages and comments for command line options and three file formats with accuracies of .
.
specifically for command line options dase automatically extracted valid options from man pages from the c oreutils programs from grep and from diff .
the accuracy is .
for elf processing programs we manually enforced constraints to form the layout of our elf model shown in figure .
by analyzing the elf header file and elf man page dase automatically extracts values for constraints regarding array index value pairs and values for constraints regarding valid field values.
for example the constraint assume elf32 shdr !e type elf32 shdr!e type is one constraint with two values and .
in the case where a constraint exists from both the header file and man page dase combines all the values within both documents and creates a single new constraint with all the merged values.
the elf header file constraints is a superset of the man page constraints except for two constraints which specify valid values for the ei version indices of the e ident arrays.
the accuracy of the extracted constraints is .
.
the breakdown of the constraints extracted from the header file and the man page is as follows.
from the man page dase automatically extracts values for constraints regarding array index value pairs and values for constraints regarding valid field values.
the accuracy is .
from the header file dase extracted values for constraints regarding array index value pairs and values for constraints regarding valid field values.
among the values for constraints regarding valid field values values are invalid which affect constraints.
the accuracy is .
.
the inaccuracy results from a special kind of macro num inelf.h .
this macro represents the total number of valid values which is not a valid value.
among all the constraints constraints consisting of values on special section types are not used because they are not applicable to our model.
we can incorporate them when we improve our elf model in the future.
dase also extracted constraints from tar and coff s header files.
it extracted values for constraints for the tar file format and values for constraints for the coff file format.
all of the extracted constraints are correct.
impact of incorrect constraints.
to understand the impact of incorrect constraints we ran dase with only the correct constraints our main evaluation applies all constraints to minimize manual effort .
the coverage and bug finding results are almost identical suggesting that dase is robust when a few incorrect constraints are provided.
potential effort savings.
automated constraint extraction is important yet challenging and much work has been proposed to infer constraints from source code and execution traces automatically .
the proposed automated con straint extraction technique takes seconds to run can save the effort of manually writing constraints.
it is beneficial to automate the constraint extraction process to keep the constraints up to date since elf tar and coff file formats all have many revisions since their standardization.
dase extracted almost all constraints in the header files and man pages.
this can be expanded by analyzing more comprehensive file specifications such as the elf specification .
in the future we would like to extend the proposed nlp techniques to analyze other formats e.g.
tcp ip packets and xml format.
e. statistical significance test since there is randomness in klee s symbolic execution due to search strategies and the constraint solver we conduct significance tests to check whether it is statistically significant that dase outperforms klee.
since it takes a long time to run all programs we randomly sample programs to perform the statistical significance tests c oreutils programs grep and elftoolchain elfdump .
we run each program time for klee and time for dase and perform mann whitney u test wilcoxon rank sum test on each of the programs.
the p values are all smaller than .
indicating statistical significance.
earlier results in table ii shows that dase has a better coverage than klee therefore it isstatistically significant that dase achieves higher coverage than klee on these programs .
vii.
t hreats to validity while the natural language processing techniques are effective on the three evaluated file formats the techniques may not generalize to other types of documentation.
new grammar rules may be needed to support new types of sentence structures.
in addition the accuracy and quality of the extracted constraints depend on the quality of the documentation.
viii.
r elated work symbolic execution.
symbolic execution alone or with concrete execution has been widely used for automated testing .
to alleviate the path explosion problem many strategies have been proposed .
veritesting leverages static symbolic execution to guide and improve dynamic symbolic execution.
cute and crest both use a bounded depth first search dfs strategy.
zesti uses developer generated tests as seeds and explore paths similar to the seeds paths.
zesti s performance is affected by existing tests while dase does not suffer from this problem.
dase complements zesti dase detected two previously unknown bugs in coreutils that were not detected by zesti the same version of coreutils was used by dase and zesti .
input space partitioning has been used to improve symbolic execution .
for example flowtest partitions the inputs into non interfering blocks by analyzing the dependency among inputs.
the previous techniques rely on information from the code logic to guide the path exploration process.
different fromthem dase automatically extracts input constraints from documents and uses the constraints to prune execution paths.
in addition dase focuses on valid and close to valid inputs while the above techniques have no knowledge about whether an execution path corresponds to valid or invalid input.
input constraints guided testing.
input constraints and specifications have been used for automated test generation .
these techniques require input constraints to be given manually whereas dase can automatically extract input constraints from documentation.
lei zhang developed the basis of this work as a master s thesis .
this paper extends the thesis in several ways including analyzing two additional file formats tar and coff analyzing both manual pages and code comments for the file formats when applicable and providing a clearer explanation of why dase works.
documentation analysis.
many techniques analyze documents such as man pages to check for undocumented error codes and code comments and api documentation for bug detection.
these techniques do not improve symbolic execution based testing.
in addition dase uses a new approach typed dependencies for document analysis and extracts different types of constraints.
testing effectiveness versus code coverage.
a recent study shows little correlation between code coverage and test suite effectiveness measured by the number of mutants killed .
however only simple mutants generated by pit are used which may not represent real bugs.
our results demonstrate that dase improves testing effectiveness i.e.
detecting more new bugs andcode coverage over klee.
ix.
c onclusions and future work this paper presents document assisted symbolic execution dase a novel and general approach to extract input constraints from documents automatically to improve symbolic execution for automated bug detection and test generation.
dase prunes and flattens paths based on their semantic importance to help search strategies prioritize execution paths more effectively.
dase detected previously unknown bugs that klee fails to detect of which have been confirmed by the developers on mature programs.
compared to klee dase increases line coverage branch coverage call coverage by .
.
pp .
.
pp .
.
pp respectively.
in the future it would be promising to negate the input constraints to focus on testing error handling code.
acknowledgment the authors thank the statistical counseling service provided by the university of waterloo and william marshall for help with the statistical analysis of the results.
the authors are grateful to darko marinov and shan lu for their feedback on the paper.
this research is supported by the natural sciences and engineering research council of canada a google faculty research award and ontario ministry of research and innovation.