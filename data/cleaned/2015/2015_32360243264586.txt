bigsift automated debugging of big data analytics in data intensive scalable computing muhammad ali gulzar university of california los angeles usa gulzar cs.ucla.edusiman wang hunan university china simanw ucla.edumiryung kim university of california los angeles usa miryung cs.ucla.edu abstract developing big data analytics often involves trial and error debugging due to the unclean nature of datasets or wrong assumptions made about data.
when errors e.g.
program crash outlier results etc.
arise developers are often interested in pinpointing the root cause of errors.
to address this problem bigsift takes an apache spark program a user defined test oracle function and a dataset as input and outputs a minimum set of input records that reproduces the same test failure by combining the insights from delta debugging with data provenance .
the technical contribution of bigsift is the design of systems optimizations that bring automated debugging closer to a reality for data intensive scalable computing.
bigsift exposes an interactive web interface where a user can monitor a big data analytics job running remotely on the cloud write a user defined test oracle function and then trigger the automated debugging process.
bigsift also provides a set of predefined test oracle functions which can be used for explaining common types of anomalies in big data analytics for example finding the origin of the output value that is more than kstandard deviations away from the median.
the demonstration video is available at ccs concepts software and its engineering software testing and debugging information systems data provenance keywords automated debugging fault localization data provenance dataintensive scalable computing disc big data and data cleaning acm reference format muhammad ali gulzar siman wang and miryung kim.
.
bigsift automated debugging of big data analytics in data intensive scalable computing.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
0work done by siman wang as an intern at university of california los angeles.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa association for computing machinery.
acm isbn .
.
.
.
test predicate pushdownprioritizing backward tracesbitmap based test memoizationinput a spark program atest function and input data output minimum fault inducing input records data provenance delta debuggingfigure bigsift overall architecture introduction data intensive scalable computing disc systems such as google s mapreduce apache spark and apache hadoop enable processing massive data sets.
similar to other software development platforms developers often deal with unclean data or make wrong or incomplete assumptions about the data.
it is therefore crucial to equip these developers with toolkits that can better pinpoint the root cause of an error.
unfortunately debugging big data analytics is currently an ad hoc time consuming process.
data scientists typically write code that implements a data processing pipeline and test it on their local development workstation with a small sample data downloaded from a tb scale data warehouse.
they cross fingers and hope that the program works in the expensive production cloud.
when a job fails or they get results that end up being suspicious data scientists must identify the source of the error often by digging through post mortem logs.
in such cases the programmer e.g.
data scientist may want to pinpoint the root cause of errors by investigating a subset of corresponding input records.
one possible approach is to track data provenance input output record mappings created in individual distributed worker nodes .
however according to our prior study backward tracing based on data provenance finds an input subset in the order of millions which is still too large for a developer to manually sift through.
delta debugging dd is a well known algorithm that re executes the same program with different subsets of input records .
applying the dd algorithm naively on big data analytics is not scalable because dd is a generic black box procedure that does not consider the key value mapping generated from individual dataflow operators.
therefore dd cannot prune irrelevant input records easily by considering the semantics of dataflow operators.
the technical contribution of bigsift is two folds.
first it combines delta debugging with data provenance .
second it implements three systems level optimizations test predicate pushdown backward trace prioritization and bitmap based memoization to be discussed in section in details to improve debugging performance.
figure shows the overall architecture of bigsift .
esec fse november lake buena vista fl usa muhammad ali gulzar siman wang and miryung kim a job completion time and output b user and pre defined test function selection c area plot reports the real time information of the debugging process figure bigsift s web based user interface our evaluations show that bigsift improves the accuracy of fault localizability by several orders of magnitude 103to107 compared to titian s data provenance only.
bigsift improves performance by up to compared to using delta debugging alone .
for each faulty output bigsift is able to localize faultinducing data in less than of the original job running time.
this tool demonstration paper builds on our prior work and focuses on the tool features and corresponding implementation details of bigsift .bigsift is fully integrated with the current apache spark s web based ui.
a user can directly inspect raw output records and write a test oracle function on the fly or select from pre defined test oracle functions.
bigsift streams real time debugging progress information from the remote cluster to the user through an interactive area plot and presents the current set of fault inducing input records in a table format.
our current implementation targets apache spark .
.
with programs written in scala and java .
technical approach the contribution of bigsift is to adapt delta debugging for big data analytics by designing new systems optimizations and by leveraging data provenance in tandem which provides backward and forward tracing capabilities for apache spark .
the overview of our approach is described in figure .
without such systems optimizations delta debugging could take hours if not days.
this is because the input dataset size is huge and thus an exhaustive binary search like algorithm such as delta debugging could take significant amount of time.
in our evaluation bigsift is up to times faster than dd.
below we summarize three systems optimizations at a high level and further details are described elsewhere .
.
test function push down in the map reduce programming paradigm a combiner performs partial aggregation for operators such as reducebykey on the map side before sending data to reducers in order to minimize network communication.
since delta debugging uses a user defined test function to check if each final record is faulty our insight is that during backward tracing we should isolate the exact partitions withfault inducing intermediate inputs to further reduce the backward tracing search scope.
in apache spark certain aggregation operators e.g.reducebykey require a user to provide an associative andcommutative function as an argument.
bigsift implements a new optimization by pushing down a user defined test function to partitions in the previous stage to test intermediate results.
this optimization is enabled when the program ends with an aggregation operator such as reducebykey that requires an associative function f1 f1 f2 is associative when f2is a test function and f1 f2is failuremonotone.
if this monotonicity property is not satisfied which can be verified by testing final output or none of the partitions fail the test function bigsift rolls back to the default case of backward tracing the final faulty record.
.
overlapping backward traces multiple faulty output records may be caused by the same input records due to operators such as flatmap orjoin where a single data record can produce multiple intermediate records leading to multiple faulty outputs.
therefore bigsift prioritizes the common input records leading to multiple outputs before applying dd.
to check the eligibility for this optimization bigsift explores a program dag to find at least one to many or many to many operator such as flatmap andjoin .
in order to explore all the possible overlapping traces bigsift overlaps the two smallest backward traces let s say t1and t2 to find the intersection t1 t2.
if the test function evaluated on t1 t2 finds any fault then dd is applied to t1 t2and the remaining potential failure inducing inputs t1 t2and t2 t1.
otherwise dd is executed over both initial traces t1and t2.
if any fault inducing inputs are found in the overlap there could be potential time saving from not processing the overlapped trace twice.
.
bitmap based memoization of test results dd is not capable of detecting redundant trials of the same input configuration and therefore may test the same input configuration multiple times.
to avoid waste of computational resources bigsift uses a test results memoization optimization.
a naive memoization 864automated debugging of big data analytics in data intensive ... esec fse november lake buena vista fl usa 1class bigsift sc sparkcontext logfile string def runwithbigsift sparkprogram rdd lineage rdd test t boolean unit ... figure bigsift s api strategy would require scanning of the content of an input configuration to check whether it was tested already such content based memoization would be time consuming and not scalable.
bigsift instead leverages bitmaps to compactly encode the offsets of the input dataset to refer to a sub configuration.
the universal splitting function for dd is thus instrumented to generate sub configurations along with their related bitmap descriptions.
bigsift maintains the list of already executed bitmaps each of which points to the test result of running a program on the input sub configuration.
before processing an input sub configuration bigsift uses its bitmap description to perform a look up in the list of bitmaps.
if the result is positive the test result for the target subconfiguration is directly reused by the look up.
otherwise bigsift tests the sub configuration and enrolls its bitmap and the corresponding test result in the list.
this technique avoids redundant testing of the same input sub configuration and reduces the total debugging time.
bigsift uses the compressed roaring bitmaps representation to describe large scale datasets .
.
implementation to enable automated debugging of big data analytics applications a user can instantiate bigsift class with sparkcontext and input file path as input arguments as shown in figure .
internally this class instantiates lineagecontext that enables titian s instrumentation for data provenance support.
more details on the usage of titian is described in our prior vldb paper .
a user can then call runwithbigsift method with a test oracle function and a sparkprogram a directly acyclic graph dag workflow that takes in an input resilient distributed dataset rdd i.e.
an abstraction of distributed collection and returns the final rdd.
bigsift is designed as an external java library jar and can be deployed by importing the jar file in a spark application running on a data provenance enabled spark distribution such as titian .
bigsift s interactive ui is available on port on the spark driver node.
figure shows the web based user interface.
once the job is completed a user can examine the job execution time raw output etc.
she can write her own custom test oracle function or select from pre defined test functions.
bigsift also displays a set of input records that reproduce the same test failure.
the area chart reports the real time debugging progress information.
a user can click on the graph to see the size and samples of failure inducing inputs.
demonstration scenario suppose alice is a data scientist and she writes a big data application in apache spark to analyze a large scale dataset that contains passenger transit information in the us.
since the data is in the scale of terabytes she takes a small sample of the dataset say mb and builds a data processing pipeline using spark in a local machine.
alice wants to find the total transit time for all passengers spending less than minutes while in transit for each airport in a key value output visualization b data provenance visualization figure bigsift s histogram visualization of key value based output records 1val countoftranist sc.textfile dataset .map s val tokens s.split val arrival hr tokens .split val diff getdiff tokens tokens val airport tokens airport arrival hr diff .filter v v. 2 .reducebykey .collect figure a spark program written in scala that finds the total layover time of all passengers spending less than minutes per airport at each hour.
the us for each hour.
a row in the dataset represents a passenger s transit information in the following format.
mnn the program in figure first loads the dataset line and scans each row to retrieve a key value pair.
a key consists of the airport code and arrival hour of a passenger and the value is the transit time spent in minutes departure time arrival time at the airport line .
line filters passengers with the transit time less than minutes.
finally the program sums up the transit times of all passengers per airport at each arrival hour line .
after writing this application alice submits the job to the production cloud which results in the following output sea lax mnn ..... she then realizes that some output records look suspicious.
for example the total transit time of mnn is when she expects the total transit time to be a positive value.
alice wants to investigate what are the exact input records responsible for producing a negative value.
this task is challenging because the large scale dataset is infeasible to inspect manually and there is no one to one mapping between input records and output records due to an aggregation step that applies user defined functions.
alice decides to use bigsift that takes her program input data set and a test oracle function as input and eventually returns the following culprit input record responsible for the suspicious negative output value.
mnn the following describes bigsift demonstration step by step.
865esec fse november lake buena vista fl usa muhammad ali gulzar siman wang and miryung kim step program output inspection.
figure shows the landing page of bigsift .
it shows the size of input dataset as the number of records the job processing time final output records in a text box.
see and in figure respectively.
to better visualize output records bigsift provides interactive and dynamic visualization of key value pairs using a histogram to make it easier for a user to identify anomalous records visually figure a .
for example alice can mark any negative value as incorrect using a histogram and note down this threshold to construct a test function.
step classifying suspicious or wrong output records by defining a test oracle function.
bigsift enables a user to write a test function a predicate to be applied to each final output record to distinguish correct outputs from incorrect or anomalous outputs.
bigsift also enables user to choose from a list of pre defined test predicate functions figure b to help explain the common types of anomalies in big data analytics for example explain how a minimum output value is created explain how a maximum output value is created explain how the output value greater than kstandard deviations from the median is created etc.
once the selection is made from the radio buttons a user can press the runbigsift button figure b .
internally bigsift selects the corresponding pre defined test function to initiate debugging.
step visualization of data provenance.
to help understand the propagation of fault inducing intermediate input records across transformation steps bigsift provides a pie chart based dag visualization of the workflow figure b .
each node in this graph is represented as a pie chart where a red segment shows the ratio of fault inducing intermediate records against the total number of records processed by that transformation.
by viewing data ratio at each transformation a user may get deeper insight.
step automated disc debugging.
when bigsift is invoked by the user a realtime area chart appears on the ui.
in figure c yaxis represents the number of fault inducing input records isolated bybigsift in log scale and x axis represents debugging time.
as the time passes bigsift streams debugging progress information from the cloud.
a user can click on any part of the chart to view sample fault inducing input records at the selected time.
a mouse hover over will show the number of fault inducing input records.
as soon as bigsift finds the minimum set of fault inducing input records bigsift reports the total debugging time through a push notification green container in figure c .
related work delta debugging dd is a well known technique for finding the minimal failure inducing input that requires multiple tests of the program which alone is not tractable for disc system workloads.
hdd tries to minimize dd tests by assuming that the input is in a well defined hierarchical structure which rarely holds .
ramp and newt add data provenance support to disc systems.
bigsift differs from these by leveraging dd and data provenance in tandem and by implementing unique systems optimizations to improve performance for disc workloads.
bigdebug is an interactive debugger for spark and it leaves to the developer to manually identify the root cause of errors.
data x ray extracts a set of features representing input data properties and summarizes the errors in a sql table but does not support automated debugging.
evaluation and summary we are in the early days of debugging big data analytics.
this tool demonstration paper showcases bigsift an automated debugging toolkit in the context of data intensive scalable computing disc .
finding failure inducing inputs is just the beginning.
we see further opportunities for automated debugging of disc applications such as automated data cleaning and faulty code localization.
in our prior work we evaluated bigsift on a node cluster with subject program where faults were injected in both input datasets or code.
the datasets used in the evaluation ranges from few gb to 80gb.
in comparison to using dd alone bigsift reduced the fault localization time as much as by pruning out input records that are not relevant to faulty outputs.
further our trace overlapping heuristic decreases the total debugging time by and our test memoization optimization provides up to decrease in debugging time.
indeed the total debugging time taken bybigsift is on average less than the original job running time per single faulty output.
acknowledgment we would like to thank tyson condie and matteo interlandi with their insights in the design of bigsift optimizations.
participants in this project are in part supported through afrl grant fa875015 nsf grants ccf ccf ccf ccf onr grant n00014 and gifts from google and huawei.