goal driven exploration for android applications duling lai electrical and computer engineering university of british columbia vancouver canada dlai ece.ubc.cajulia rubin electrical and computer engineering university of british columbia vancouver canada mjulia ece.ubc.ca abstract this paper proposes a solution for automated goaldriven exploration of android applications a scenario in which a user e.g.
a security auditor needs to dynamically trigger the functionality of interest in an application e.g.
to check whether user sensitive info is only sent to recognized third party servers.
as the auditor might need to check hundreds or even thousands of apps manually exploring each app to trigger the desired behavior is too time consuming to be feasible.
existing automated application exploration and testing techniques are of limited help in this scenario as well as their goal is mostly to identify faults by systematically exploring different app paths rather than swiftly navigating to the target functionality.
the goal driven application exploration approach proposed in this paper called g oal explorer automatically generates an executable test script that directly triggers the functionality of interest.
the core idea behind g oal explorer is to first statically model the application s ui screens and transitions between these screens producing a screen transition graph stg .
then goal explorer uses the stg to guide the dynamic exploration of the application to the particular target of interest an android activity api call or a program statement.
the results of our empirical evaluation on benchmark applications and the most popular googleplay applications show that the stg is substantially more accurate than other android ui models and that g oal explorer is able to trigger a target functionality much faster than existing application exploration techniques.
i. i ntroduction mobile applications apps have grown from a niche field to the forefront of modern technology.
as our daily life becomes more dependent on mobile apps various stakeholders including app developers store owners and security auditors require efficient techniques for validating the correctness performance and security of the apps.
dynamic execution is a popular technique used for auditing and validating mobile apps .
for example a security auditor often monitors the network traffic generated by an app to ensure that user sensitive info is sent encrypted over the network and that it is sent to recognized third party servers only .
it is common for the auditor to know which part of the app is responsible for the functionality of interest but dynamically triggering that functionality is still a challenging task.
consider for example a popular mobile personalization app zedge which provides access to a large collection of wallpapers ringtones etc.
and has more than a hundred million installs on google play .
a security auditor exploring this app can quickly determine that it uses the facebook sdk and allows the users to log in with their facebook accounts.
such determination can be done by simply browsing the app code the facebook login is triggered via a particular api from the facebook sdk .
now the auditor wishes to check what information is transmitted during the login process and what information is granted by facebook when the user logs in into their account .
to perform this investigation the auditor needs to generate a sequence of user gestures that navigate the app to the facebook login screen.
for zedge that entails a nontrivial sequence of steps shown in fig.
first scroll all the way down in the menu of all possible operations in figs.
a b to the 11th menu item then click the settings button in fig.
b to open the settings view then click zedge account in fig.
c and only then click on continue with facebook in fig.
d .
such a manual exploration especially when one needs to analyze hundreds or thousands of different apps is time consuming.
existing testing frameworks such as espresso uiautomator and robotium are not helpful in this scenario as they are designed to provide the user a way to manually script test cases and later repeatedly execute these test cases.
automated app exploration techniques that exercise the app by generating user gestures and system events are of limited help as well.
the goal of these techniques is to detect faults through a thorough exploration of different app behaviors .
however when there is a large number of feasible paths to explore these techniques will have difficulties to quickly navigate to the functionality of interest.
for the zedge example in fig.
both the most prominent automated app exploration and testing tools sapienz and stoat failed to reach the facebook login screen after two hours of execution even when configured to prioritize previously unexplored paths.
that is because these techniques lack knowledge of which of the unexplored paths is most likely to lead to the functionality of interest and thus end up exploring a large number of possible feasible paths.
in this paper we introduce a goal driven app exploration approach and the associated tool called g oalexplorer which directly triggers a particular functionality of interest.
goalexplorer combines a novel approach for modeling an app user interface ui as a screen transition graph stg with a dynamic stg driven app exploration technique.
given 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
d e f g h i fig.
example app.
a particular target of interest an android activity api call or a code statement it automatically builds an executable script that swiftly triggers the target.
the idea of building a static ui model of an android app is not new by itself.
to the best of our knowledge a3e was the first to build a static model of an android app gui which only focused on android activities.
gator further extended this model to capture information about the menu items and the widgets that facilitate transitions between the modeled ui components e.g.
activities and menus.
however the main building blocks of both these models are ui components rather than their composition into ui screens.
as such they do not accurately model the current android ui framework that allows composing screens from multiple components such as fragments menus drawers etc.
thus they will misrepresent transitions originating in fragments e.g.
the transitions between screens in figs.
b and c .
moreover they do not model states and transitions triggered by background tasks and events broadcast receivers in android terminology .
for example an app relying on the facebook login mechanism can use a broadcast receiver to deliver login information to the interested app components as done in zedge example in fig.
after the login is triggered in fig.
e the app broadcasts the login status and in the case of a successful login additional meta information such as the user email address to the controller activity in fig.
f .
without modeling broadcast receivers a goal driven exploration tool will fail to reach that screen.
our analysis shows that more than of the top free android apps on google play contain at least one fragment background task and broadcast receiver of the apps contain menus and drawers.
moreover of the apps have at least one screen transition originating from a fragment and from a background task or broadcast receiver.
modeling these behaviors is thus critical for the goal driven exploration task and we do so in our work.
moreover we introduce the concept of modeling ui screens as composition of ui components rather than individual ui components.
we empirically show that for our task such approach is superior to the existing concepts of modeling app ui.
when compared to state of the art dynamic exploration and testing techniques i.e.
sapienz and stoat g oal explorer is able to explore a similar portion of each app which attests to the accuracy of its statically built model of screens and transitions.
however g oalexplorer is able to reach the functionality of interest substantially faster than the dynamic exploration tools.
as such g oalexplorer provides an efficient solution to the goal driven exploration problem in mobile apps.
interestingly our analysis of network traffic associated with facebook login in zedge helped revealing a potential security vulnerability in this app after receiving the oauth authentication bearer token from facebook the app openly sends it to its server.
such behavior is discouraged by the internet engineering task force ietf because any party holding the token can use it to access the user private information without any further proof of possession.
according to ietf when sent over the network bearer tokens have to be secured using a digital signature or a message authentication code mac .
zedge is not following these guidelines thus a man in the middle can steal the token and access private information of users logged into the app.
contributions.
this paper makes the following contributions it defines the problem of goal driven exploration for mobile apps efficiently triggering a functionality specified by the user.
it shows that existing approaches are insufficient for performing goal driven exploration.
it presents a technique for constructing a static model of an app ui called screen transition graph stg and using stg to generate an executable script that triggers a specific functionality of interest defined by the user.
it implements the proposed technique in a tool named goalexplorer and empirically shows its effectiveness on the benchmark apps used in related work and top google play apps.
our implementation of the g oalexplorer and its experimental evaluation package are available online .
ii.
b ackground in this section we give the necessary background on app component structure lifecycle and ui.
we then discuss the static android ui models used in earlier work .
a. android applications app components.
android apps are built from four main types of components activities services broadcast authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
receivers and content providers.
activities are the main ui building blocks that facilitate the interactions between the user and the app.
services perform tasks that do not require a ui e.g.
prefetching files for faster access or playing music in the background after the user has switched to other activities.
broadcast receivers are components that respond to notifications.
a broadcast can originate from i the system e.g.
to announce that the battery is low ii another app e.g.
to notify that a file download is completed or iii from other app components e.g.
to notify that the login was completed successfully.
content providers manage access to data e.g.
for storing and retrieving contacts.
component lifecycle.
unlike java desktop programs an android app does not have a main method instead each app component implements its own lifecycle events.
the activity lifecycle is shown in fig.
.
pausedstopped runningstarteddestroyed createdandroid system onstartoncreate onresume onstopondestroy onresumeonpauseonrestart fig.
activity lifecycle events.once an activity is launched the system calls its oncreate method followed by onstart and onresume .
developers specify the behavior of these methods e.g.
the ui setup is typically done in oncreate .
the activity completes the initialization after onresume .i t then enters a running state and begins handling callbacks e.g.
those triggered by user inputs or by system changes.
the activity is paused when it loses focus and can eventually be stopped and destroyed by the operating system.
the lifecycle of services is similar to that of activities except additional methods that handle service bindings i.e.
cases when other app components maintain a persistent connection to a service.
broadcast receivers have only one lifecycle event onreceive to handle received events.
content providers do not expose any lifecycle events.
the transition between android components relies on intents which explicitly or implicitly specify the target component and the data to be passed to that component.
broadcast receivers are registered with intent filters which specify the types of events that the broadcast receiver handles.
app ui structure.
an application screen is represented by an activity decorated by additional ui components such as fragments menus dialogs and navigation drawers .
fig.
depicts such a modular composition of screens.
the solid box in fig.
a highlights the container activity its two hosted fragments are highlighted in fig.
b .
a fragment is a re usable ui component with its own lifecycle and event handling.
a fragment can be instantiated in multiple activities and must always be hosted by at least one activity.
its lifecycle is directly affected by the owner activity e.g.
when the owner activity is destroyed all of its hosted fragment instances are also destroyed.
fragment instances can be added replaced or removed from the host activities throughdavid david lisa a activity.david david lisa b fragments.david david lisasettings find share more... c menu.
fig.
application screens.
thefragmenttransaction apis forming different screens of the same activity.
multiple fragments can exist in a single screen as in fig.
b a screen can have any number of fragments or no fragments at all.
menus and navigation drawers are ui components used primarily to provide additional options to the user such as adjusting settings or launching new activities.
fig.
c shows the activity with a menu opened which allows the user to access system wide actions such as settings and search.
fig.
a shows a drawer that occupies most of the screen and contains buttons for navigating to other parts of the app.
dialogs are small windows that prompt the user to take an action before the app can proceed with its execution e.g.
to agree to granting access to the device location.
menus navigation drawers and dialogs must be hosted by either an activity or a fragment.
ui components are composed of widgets such as buttons andtextviews .viewgroups are invisible containers used for grouping the widgets and specifying their layout before placing them inside the ui components.
users mostly interact with ui widgets and are typically unaware of the app and ui components and their lifecycle.
b. existing android ui models we now describe existing approaches for modeling android ui.
activity transition graph atg introduced by azim and neamtiu in a3e captures app activities and transitions between these activities.
it does not model other app components and does not model actions that trigger the transitions i.e.
which user input triggers the transition between activities.
window transition graph wtg introduced by yang et al.
in gator extends atg by addressing some of these limitations it models the event handler for each transition and also incorporates menus and dialogs as distinct nodes in the model.
however it does not consider fragments drawers services and broadcast receivers.
due to these reasons for the zedge example in fig.
both atg and wtg will only include three nodes that correspond to the app activities controller which corresponds to the activity in figs.
a c and f authenticator for the activity in fig.
d and facebook for the activity in fig.
e which is implemented inside the facebook sdk.
atg and wtg models will include no transitions as all transitions in this app originate from fragments.
as such none of these models will contain the path that reaches the facebook activity.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
moreover the models do not account for broadcast receivers and thus no activity that follows the facebook login e.g.
the one in fig.
f is reachable.
an even more severe drawback of the existing ui models is that they treat ui components such as activities and menus as separate nodes.
these models do not accurately represent the composition of ui components into screens which hinders their applicability for the goal driven exploration scenario as the representations do not include enough details to extract an executable path.
in sect.
iii a we will discuss this limitation in more detail outline alternative ways to model android ui components and their relationships and then present our proposed solution screen transition graph.
iii.
g oal explorer the high level overview of g oalexplorer is presented in fig.
.
it obtains two inputs the apk file of the app and the target functionality of interest which can be provided as an app activity an api call or a code statement.
for example when monitoring the network traffic related to the facebook login scenario in zedge we set as target a facebook api call as discussed in sect.
i. in the first step g oalexplorer statically constructs the screen transition graph stg of the app the stg extractor component in fig.
.
it then maps the target s to possibly multiple nodes of the graph the target detector component .
finally it uses the graph to guide the dynamic exploration to a reachable target node starting with the one that has the shortest path from the initial screen the dynamic explorer component .
in what follows we first introduce the stg and discuss our design choices.
we then describe the stg extractor target detector and dynamic explorer components.
a. screen transition graph as discussed in sect.
ii both window transition graph wtg and its predecessor activity transition graph atg model ui components as distinct nodes in the graph .
moreover they do not model fragments drawers services and broadcast receivers.
as such for the example app in fig.
these graphs will only contain three activity nodes elements and presented with solid lines in fig.
.
our direct extension to this model which we refer to as wtg e introduces a number of additional elements presented with dotted lines in fig.
.
for conciseness of the discussion we include in this snippet only parts of the zedge app shown in fig.
assuming drawers are handled similar to menus as they correspond to similar ui concepts element in fig.
would represent the drawer in figs.
a b .
adding drawers would also lead to creating transitions labeled open drawer and close drawer between elements and .
the transition labeled settings from element to would be contributed by an analysis of the drawer behavior that launches a new activity.
the account manager broadcast receiver responsible for notifying other app components when facebook authenticationis completed would be represented by element and its corresponding incoming and outgoing transitions.
the fragments contributing to each activity could be represented by inner boxes inside elements and as only these two activities have fragments in this example.
representing the fragments would allow the model to capture transitions from element to and to as these transitions are triggered from fragments embedded in each corresponding activity.
however even the extended wtg e model is sub optimal for producing the execution scenario that leads to the facebook login screen in the zedge example.
that is because wtg e s main nodes are ui components rather than their composition to screens.
thus the model cannot represent the actual screens omitting important information used for exploration.
for example from the wtg e graph in fig.
one can conclude that the close drawer action for element that leads to element the controller activity can be followed by the zedge account action to reach element the authenticator activity.
such execution is not possible in practice as the zedge account action is only enabled when the controller activity is opened with the settings fragment.
however when the app execution starts the controller activity is rather opened with the browse fragment thus there is no option to press the zedge account button after closing the drawer.
without distinguishing between these different states of the controller activity element one cannot successfully explore the application.
the screen transition graph proposed in this work addresses this limitation.
it models application screens by representing the composition of the container activity hosted fragments menus navigation drawers and dialogs on each screen.
fig.
shows the stg representation of the zedge snippet in fig.
.
unlike in the wtg e model the controller activity here is represented by five different elements and .
these elements correspond to different compositions of fragments and drawers hosted by the activity.
this representation clarifies that the only possible path to the facebook login activity element in fig.
is to start from the controller activity element open the drawer arriving at element then press the settings option arriving at element .
only after that one can transition to elements and .
moreover after the facebook login is completed the execution arrives at element which is another instance of the controller activity but with the account fragment.
it is clear from this representation that the user cannot press zedge account again as can mistakenly be concluded from the wtg e representation in fig.
.
this example demonstrates that the stg representation is more accurate than the original wtg and even wtg e for producing execution scripts in the goal driven exploration scenario.
we empirically evaluate the differences between these representations in sect.
iv.
below we give a more formal definition of stg.
in stg the main nodes vsrepresent app screens and the supporting nodes vrandvbrepresent services and broadcast receivers respectively.
each screen node in vs vsconsists authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
wudfwru7dujhw 7rsrorj wudfwru qdplf soruhu qsxw hqhudwru fwxdwru fwlrq 3lfnhu6fuhhq xloghu hfxwdeoh 6fulsw qwhu rpsrqhqw qdo hu7dujhw hwhfwru qgurlg hylfh fig.
g oalexplorer overview.
authenticatorsettings zedge account account manager receiverbrowsedrawercontroller settingsfacebook accountcontinue w. facebook open drawerclose drawer activity fragment broadcast receiver drawer event transitionlogin action logged inauth fig.
wtg solid lines and wtg e all lines of zedge.
authenticatorsettings zedge account account manager receiverdrawercontroller browsecontroller browsecontroller settings controllerfacebook controller accountcontinue w. facebook open drawer close draweropen drawer close drawer1 activity fragment broadcast receiver drawer event transitiondrawer settingslogin action logged inauth fig.
stg of zedge.
of one container activity va s zero or more fragments vf s zero or one menu drawer vm s and zero or one dialog vd s. the collection of all screen nodes corresponds to possible screens allowed in the app.
intuitively an activity with nfragments and one drawer could correspond to 2ndifferent screens all combinations of fragments with and without a drawer .
of course not all combinations are possible in a particular app and we describe our screen extraction algorithm in sect.
iii b. supporting nodes are required as transitions between screens can pass through these elements.
the edges ein stg correspond to transitions between nodes v vs vr vb.
each edge e ehas a label e which represents the event that triggers the transition either a user action e.g.
pressing the zedge account button to move from element to or an intent that triggers the broadcast receiver event e.g.
the notification received by the system for transitioning from element to .
transitions that are triggered automatically e.g.
when a service opens a ui dialog without any notifications or clicks have no event triggers in the model e .
b. stg extractor we now describe our approach for constructing stg.
the stg extractor consists of three main components outlined in fig.
topology extractor screen builder and intercomponent analyzer .t opology extractor .topology extractor identifies the main app components i.e.
activities services and broadcast receivers and their call graphs.
it relies on flowdroid s implementation to extract the components from both the app source code and xml files and to associate each component with its entry points i.e.
lifecycle events and applicationspecific callback methods.
it uses flowdroid to also build call graphs of all component s entry points.
for example an activity may register callbacks that get invoked when a button is pressed or a location update is received the respective callback handler would then be linked to the activity s call graph and analyzed between the onresume and onpause lifecycle events of the activity.
app methods annotated with javascriptinterface can also be triggered by javascript enabled webviews .
as the invocation of these methods depends on the webview content delivered at runtime topology extractor conservatively extends the call graphs by assuming that any javascript enabled method in a component can be called by any javascriptenabled webview in the same component.
after the components and their call graphs are extracted nodes corresponding to services and broadcast receivers are added directly to stg in vrandvb respectively.
app screens invsare constructed next.
screen builder .a key insight of our approach is modeling the ui screens and the transitions between the screens.
to this end screen builder analyzes the call graph of each activity collecting the hosted fragments menus dialogs and navigation drawers.
fragments can be defined statically in the activity layout file or dynamically in code.
screen builder starts by extracting the layout files using axmlprinter and then identifies fragments they declare.
to collect fragment declarations in code screen builder scans the call graph of each activity identifying fragment transaction methods that add remove or replace fragments.
the full list of such methods collected from the android developer website is available in our online appendix .
the activity call graphs are scanned in multiple iterations.
first screen builder analyzes the activity lifecycle events triggered when an activity is initialized from oncreate to onresume .
for each event it identifies fragment transaction methods mthat add remove or replace fragments it then performs an inter procedural context and flow sensitive analysis on the calling path of mto identify the java type of the fragment s handled in m. once all fragments from the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
oncreate to onresume lifecycle events of an activity aare processed screen builder creates the base screen node vsin vsfor the activity a with vf scontaining a possibly empty list of the identified fragments.
this base screen node is displayed when the activity is started.
lifecycle methods issued when the activity is paused stopped or resumed can further add remove or replace fragments in the base screen.
screen builder thus analyzes possible lifecycle method invocation chains onpause onresume and onpause onstop onrestart onresume see sect.
ii to extract the fragments from each of these chains.
if the fragments in a chain differ from the fragments in the base screen node vs it adds a new screen node vs primefor the activity a which contains a union of fragments in vsand those identified in the chain.
it also adds a transition between vsandvs prime with an empty label as this transition is triggered automatically by the system.
fragments in callback methods are handled similarly.
since the order of callbacks cannot be predicted screen builder assumes the callbacks can occur in any order it thus creates a new screen vs prime prime if it does not exist yet for any possible order of callback methods which modify fragments of the base screen.
screen builder also creates transition edges between these screens and sets the transition label e to be the action triggering the corresponding callback.
finally screen builder analyzes each screen vsto identify its menus drawers and dialogs.
to this end it analyzes the call graphs of the screen s activity va sand all its collected fragments vf s to identify methods initializing menus drawers and dialogs.
when such a method is found screen builder copies the screen vsfor the activity aintov s adds the found menu drawer or dialog to v s adds v sto the set of all screen nodes vs and creates a transition edge between vsandv s. the transition label e is set to be the action that triggers the callback method.
inter component analyzer .after the previous step we have collected all screen nodes and the transitions between screen nodes of the same activity but with different fragments menus drawers and dialogs.
the inter component analyzer collects the inter component transitions between nodes corresponding to different android components e.g.
screens of different activities services and broadcast receivers.
these transitions are performed via inter component communication icc methods and we rely on flowdroid s integration with iccta to identify icc links between app components.
for each link where the source and target are services and or broadcast receivers inter component analyzer simply creates the corresponding transition edge ein stg if the target of the transition is a broadcast receiver the transition label e is set to be the broadcast which triggers the event as specified in the broadcast receiver intent filter.
if the target of the transition is a service e as this transition is triggered automatically without any user or system event.
activities are represented by a number of screens and thus require a more nuanced treatment.
if a source of an icc link is an activity a inter component analyzer identifies the activityentry point pfrom which the communication originates.
it then finds all screen nodes in stg that correspond to a which can be reached from the base screen node of avia transitions associated with the action that triggers p. it adds a transition from all these nodes to the nodes that represent the targets labeling them with the action that triggers p. when the target is an activity as well inter component analyzer finds only the base screen node of that activity and creates a transition to that node.
that is because when a new activity is launched it starts in the initial screen transitions between different screens of the target activity are already handled by screen builder .
c. target detector when the exploration target is specified in a form of an activity target detector simply traverses and marks all screen nodes that correspond to that activity.
reaching any of these nodes will be considered reaching the target.
for targets given as an api target detector scans the app call graph to find all statements that invoke the given api.
for targets given as a single statement target detector simply finds the statement in the app call graph.
next it maps the identified statements to stg nodes as follows if a statement is identified in a lifecycle event of a component it marks all nodes that correspond to that component as targets.
if a statement is in a callback method simply reaching the component is insufficient as one also needs to invoke the callback method itself.
therefore target detector identifies the stg transitions labeled by the action that triggers the callback and sets the destination of these transitions as the targets.
d. dynamic explorer given an stg of the app and a set of targets dynamic explorer performs goal driven exploration guided by the stg to trigger at least one of these targets.
it also records an executable script which navigates the app to the target the script can be replayed without consulting with the static model or performing any further analysis.
dynamic explorer has three main components outlined in fig.
action picker input generator and actuator executing in a loop until a target node is reached.
action picker .in each iteration action picker first evaluates all possible actions enabled from the current screen.
to this end it retrieves the current activity and fragments using an adb shell dumpsys command and reads the screen ui hierarchy using uiautomator .
this information is used to verify that the exploration arrived at the intended stg node or map the current screen to the corresponding node in stg.
ifaction picker is already locked on a particular target it performs a breadth first search to find all paths from the current screen node vsto that target and sorts the paths from the shortest to the longest.
it picks the next action from the shortest path that leads to the new screen node vs primeand checks if the action is available on the screen.
if so it proceeds to the next step input generator .
some actions only become enabled after interacting with a screen.
for example only after adding an item to the shopping authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
cart the checkout button will be enabled.
as stg does not model the correct order of user events i.e.
clicks scrolls etc.
on a screen action picker dynamically interacts with the screen in an attempt to change its state and activate the required action.
like other dynamic exploration tools it adopts a weighted ui exploration strategy which picks the next event for a particular widget based on the event type past execution frequency and the number of new widgets the event unrolls.
to this end we adopt the weights used by stoat and list them online .
ifvs primestill cannot be reached after a certain number of attempts currently set to iterations action picker backtracks and proceeds to the next path.
if no action is available on any of the paths reaching to the current target or if there is no working target set yet action picker performs a breadthfirst search to find the next available target and repeats the search for that target.
it returns unreachable if no action leading to any of the targets is found.
input generator .when an action is picked input generatorchecks whether specific textual inputs are necessary to successfully trigger the transition.
first as many google play apps require the user to log in for accessing some app features we equip g oalexplorer with the ability to handle logins assuming that login credentials are supplied as an optional input.
to this end input generator analyzes the ui hierarchy of the current screen to search for textual input fields such asedittext .
it further evaluates whether the textual inputs requires login credentials.
similar to prior work this is done by checking whether the widget id text hint label and content description match the regular expressions associated with login and password strings e.g.
username user id etc.
the exact list of expressions we used is online .
if a match is found input generator enters the credentials into the corresponding text fields.
otherwise it feeds random strings to all textual input fields on the current screen.
actuator .actuator fires the action selected by the action picker .
its implementation extends the navigation framework of stoat.
the original stoat only supports android api level android .
and we extend it to support newer android platforms.
actuator also records all successfully triggered actions producing an executable test scripts that contain all actions necessary for reaching the target.
the script can be replayed without any further analysis and without reliance on the static model.
iv .
e v aluation we now describe our experimental setup and discuss evaluation results.
our aim is to evaluate g oalexplorer both quantitatively and qualitatively answering the following research questions rq1 coverage what is the fraction of targets g oalexplorer can reach and how does that compare with the baseline approaches?
rq2 performance how fast can g oalexplorer reach the target and how does that compare with the baseline approaches?rq3 accuracy stg what is the fraction of stg false negative and false positive transitions i.e.
existing transitions that are absent in stg and stg transitions that do not exist in reality respectively?
what are the reasons for such cases?
rq4 accuracy dynamic what is the fraction of true positive transitions i.e.
stg transitions that exist in reality that g oalexplorer cannot trigger dynamically?
what are the reasons for such cases?
a. experimental setup subject apps.
to answer our research questions we use stoat s benchmark that consists of open source fdroid apps of these apps are from the survey of choudhary et al.
and de facto became a standard benchmark in analyzing automated testing tools the authors of sapienz used these apps for their evaluation as well .
the additional apps were introduced by the stoat authors to further extend that benchmark.
to extend our evaluation to real applications commonly used in practice we also downloaded the most popular free apps from the google play store as of july .
we excluded from our analysis five apps that failed to run on the emulator the decision to use emulators for the experiments is discussed in the environment sub section below arriving at the set of benchmark and google play apps.
a detailed description of these apps is available online .
exploration targets.
we experiment with two scenarios.
in the first one we set each activity of the subject apps as the target one at a time and repeat the experiment for all activities in an app.
that allows us to align our results with those commonly reported in related work.
then we experiment with setting a code statement as a target investigating a more nuanced goal driven exploration scenario which motivates our work.
to this end we pick the url.openconnection api that is used by many apps to send and receive data over the internet this api is also used by the zedge app in our motivating example to send the facebook authorization token.
we identify all occurrences of this api in the subject apps and set them as targets one at a time.
methodology and metrics.
for the quantitative evaluation inrq1 and rq2 we perform two main experiments.
first we compare the exploration that is based on stg with the exploration based on the wtg and wtg e models described in sect.
iii a. as the original wtg model introduced by gator is not compatible with the current android api level gator failed to run for most of the google play apps.
we thus re implemented the wtg extraction process for apps with api level .
we then extended wtg to handle fragments services broadcast receivers etc.
producing the wtg e representation as described in sect.
iii a. that is we compare stg with two static models wtg our reimplementation of gator s model to handle modern apps and wtg e our extension of wtg to handle fragments drawers services and broadcast receivers.
in a second line of experiments we compare g oalexplorer with the state of the art automated exploration tech121 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
niques sapienz and stoat .
as these tools cannot be configured to reach a particular target without dynamically exploring the app first we run the tools on each app and record times when the tools reach each new target.
we stop the execution when a tool does not discover any new targets for the period of one hour and proceed to the next app.
we do not restart the tools every time they reach a new target as we believe such a comparison is more favorable for these tools.
we use configuration parameters specified by the papers describing the tools and kept default values for parameters not described in the papers.
we also experimented with modifying the parameters to ensure the baseline is most favorable for the goal driven exploration task e.g.
by increasing the sequence length and population size for sapienz and prioritizing coverage over test diversity for stoat.
as these adjustments did not affect the results we kept the default configurations.
moreover we extended both tools to handle login screens as we did for g oalexplorer see sect.
iii d .
specifically we added the same login logic that we used for our tool to that of stoat.
as the relevant code of sapienz is not open sourced the motif part is only available as binary we implemented a login detection component which runs in parallel to sapienz and constantly checks if the execution arrived at the login screen.
when it does we pause sapienz and handle the login flow as we do for g oalexplorer and stoat.
the execution time of this operation is negligible and is comparable to the handling of logins in g oalexplorer and stoat.
to answer rq1 we measure the fraction of targets reachable by each tool per app.
then to answer rq2 we measure the time it takes to trigger each reachable target.
to ensure a fair comparison we report the average time to target only for targets that are reachable by all tools.
for rq3 and rq4 we manually establish the ground truth of all reachable url.openconnection statements for open source f droid apps.
to arrive at a representative and practically valuable subset of apps we picked all f droid apps from our benchmark which are also available on google play.
we focused on f droid apps as establishing ground truth manually is unrealistic for closed source google play apps because these apps are largely obfuscated and manually tracking reachability of statements would not be reliable.
for the selected apps the first author of this paper collected the set of all url.openconnection statements and manually identified those that are reachable by both running the app and inspecting its code this manually established ground truth was cross validated with another member of the research group.
we then analyze and classify the reasons preventing g oalexplorer from triggering reachable targets and cases when g oalexplorer encounters spurious stg paths that cannot be followed due to the over approximation made by our model construction.
the set of the analyzed apps and the constructed ground truth is available online .
environment.
we run all tools on a bit ubuntu .
.
physical machine with a core cpu intel xeon and 512gb of ram.
as we run each app for up to one hour per target for each of the compared tools the total evaluation time is in thethousands of hours only to answer rq1 and rq2.
therefore we run the experiments on six android emulators to allow running multiple executions in parallel.
we allocate 64gb of ram for each emulator.
b. results rq1 coverage fig.
a shows the box and whisker plots representing the minimum median mean and maximum fraction of activities reached by goal driven exploration under three different models wtg wtg e and stg goalexplorer .
it also shows the fraction of activities reachable by the state of the art dynamic exploration tools sapienz and stoat.
the results are plotted separately for the benchmark f droid apps and the google play apps.
for the benchmark apps g oalexplorer reaches .
of activities per app on average.
for comparison wtg and wtg e reach .
and .
of activities on average per app respectively.
the differences between the ui models is much more substantial for the google play apps.
wtg can only cover around of app activities.
wtg e increases the activity level coverage to .
on average as it is able to deal with fragments services and broadcast receivers.
finally goalexplorer reaches the highest activity level coverage of .
on average due to its accurate representation of app screens.
this result demonstrates that only extending existing static models with handling of fragments services and broadcast receivers as we did in wtg e is less beneficial than the full set of solutions g oalexplorer applies.
notably g oalexplorer achieves similar activity level coverage as the dynamic exploration tools for both benchmark and the google play apps for the benchmark apps sapienz and stoat cover .
and .
of activities per app on average respectively for the google play apps both tools reach around of activities on average while g oalexplorer covers .
.
that is an encouraging result for g oalexplorer showing that the stg model it builds statically is accurate and comparable with the models constructed during the dynamic exploration.
fig.
b shows similar data for the fraction of reachable url.openconnection statements in an app.
here g oalexplorer largely outperforms other static ui models triggering .
target api statements on benchmark apps compared with .
and .
for wtg and wtg e respectively.
with its .
coverage it also slightly outperforms the dynamic tools sapienz .
and stoat .
.
for googleplay apps g oalexplorer also substantially outperforms other ui models.
it performs comparable with dynamic tools and triggers .
of the target statements on average while sapienz triggers .
and stoat .
.
our inspection of the results shows that statement level coverage is substantially higher than activity level coverage because many of the url.openconnection statements are located inside libraries or utility classes and thus have many possible paths that can reach them.
as the target is triggered if any of the paths can reach it this task appears to be easier than triggering all activities.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
rdo 6wrdw hqfkpdun rdo 6wrdw rrjoh 3od a fraction of reachable activities in an app higher is better .
rdo 6wrdw hqfkpdun rdo 6wrdw rrjoh 3od b fraction of reachable openconnection statements in an app higher is better .
rdo 6wrdw hqfkpdun rdo 6wrdw rrjoh 3od c average time in seconds to reach an activity lower is better .
rdo 6wrdw hqfkpdun rdo 6wrdw rrjoh 3od d average time in seconds to reach an openconnection lower is better .
fig.
coverage and performance results for the benchmark and googleplay apps.
to answer rq1 our experiments show that using the stg model allows g oalexplorer to trigger substantially more targets than with other statically built android ui models namely wtg gator and wtg e. moreover g oalexplorer is as effective as the dynamical tools in the ability to reach a certain target.
rq2 performance to evaluate performance we measure the minimum median mean and maximum time in seconds it takes g oalexplorer to reach a target activity or statement.
we only present times for targets that are reachable by all of the compared tools.
figs.
c and d present the results of the comparison for a target activity and statement respectively.
the results are presented on a logarithmic scale and clearly show that goalexplorer can reach a target much faster than dynamic tools for activities it takes g oalexplorer seconds on average on the benchmark apps and .
seconds on the google play apps compared with .
and .
seconds for sapienz and .
and .
seconds for stoat respectively.
goalexplorer reaches target statements in .
seconds on average on the benchmark apps and .
seconds on the google play apps compared with .
and .
seconds for sapienz and .
and .
seconds for stoat respectively.
not surprisingly g oalexplorer performs comparable to other static models wtg and wtg e as we only consider targets that are reachable given the tools model.
our experiments also show that it takes g oalexplorer around seconds per app to build the stg which contains .
nodes and transitions on average.
even given this time it outperforms dynamic tools and reaches substantially more targets than other static tools.
to answer rq2 g oalexplorer can trigger exploration targets substantially faster than dynamic exploration tools and on par with other tools based on a static model.
rq3 accuracy stg to evaluate the stg accuracy we manually identified all paths leading to url.openconnection statement in apps.
the analyzed apps contain such statements in total .
per app .
out of those are reachable .
per app are in library methods that apps do not use which occurs in apps and the remaining are in unused app methods all in the same app .
below we classify the reasons for transitions that stg misses false negatives and stg transitions that do not exist in reality false positives .
we also list the implication of false negative transitions on the ability of g oalexplorer to reach the desired target.
stg false negatives.
when a correct transition does not exist in the model g oalexplorer cannot construct a complete path to the target and thus will not attempt to follow that path.
in our sample that happens in eight cases in total in five apps.
the reasons for missing a transition are reflection transitions in one app are missing due to the limitation in handling complex reflective calls.
g oalexplorer relies on call graph construction implemented by flowdroid which only handles reflective call targets for constant string objects.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
unmodeled component transitions in two apps are missing due to unmodeled components such as app widgets which are miniature app views that can be embedded in other apps e.g.
in the home screen.
g oalexplorer as well as all other tools does not model these components as they are placed outside of the main app.
intent resolution transitions in two apps are missing due to failures in resolving the targets of intents i.e.
which component is to be launched by the intent.
g oalexplorer relies on a constant propagation technique from ic3 to resolve the intents and identify the targets.
when the constant propagation fails the correct transitions are missing in stg.
goalexplorer finds alternative paths to avoid missing the targets for out of the missing transitions in stg the remaining ones lead to four missed targets two are due to reflection and two as the consequence of unmodeled components.
sapienz and stoat cannot trigger the latter two missed targets either.
stg false positives.
goalexplorer identifies spurious transitions in apps .
transitions per app that contain false positive transitions and .
transitions per app overall that do not exist in reality callback sequence in cases apps .
transitions per app incorrect transitions in stg are caused by overapproximation in modeling the sequence of the callbacks.
since the order of callbacks cannot be predicted statically goalexplorer assumes that the callbacks can happen in any order see screen builder in section iii b producing screens in stg that are not feasible in practice.
fragment properties in cases apps .
transitions per app incorrect transitions are because stg only models the set of fragments but does not track the properties of each fragment.
for example apps can hide the fragments by setting its visibility properties i.e.
changing the visibility level to view.gone .
our model thus over approximates the set of visible fragments on a screen.
while stg over approximates the set of possible transitions all these transitions are ignored by g oalexplorer during exploration by backtracking and selecting another path.
none of the transitions analyzed above impacted the goalexplorer s ability to triggering the targets.
however such spurious transitions as well as transitions that cannot be triggered rq4 prolong the exploration as it takes time to resolve the false positives dynamically.
our results demonstrate that the execution time of the tool is not substantially affected by that and g oalexplorer still able to reach the target substantially faster than dynamic tools.
to answer rq3 the main reasons for stg s false negative and false positive transitions are imprecisions of the underlying static analysis tools.
g oalexplorer succeeds to find alternative paths in four out of eight false negative cases.
rq4 accuracy dynamic goalexplorer encounters correct transitions in apps that it fails to trigger dynamically .
transitions per app that contain such transitions and .08transitions per app overall .
the main causes for such failures false positives of dynamic exploration are semantic inputs in cases apps .
transitions per app meaningful inputs other than login credentials are required to explore the path to the target.
for example a valid zip code is required to start the search in the mileage app and an mp3 file has to be selected for upload in anymemo.
neither goalexplorer nor the contemporary dynamic exploration techniques can generate such semantic inputs.
remote triggers in cases apps .
transitions per app the transitions can only be triggered given a certain response from the remote server.
for example in synctopix a target can only be triggered when the app receives a certain reply from the server to syncing data.
during our testing period such reply was never received and none of the tools were able to trigger these transitions.
event order in cases apps .
transitions per app a transition is only possible under a certain order of events in a screen.
for example in the bookcatalogue app the target can be reached only after the user marks certain electronic books as an anthology.
while dynamic explorer is able to resolve many cases that require such interactions cases got successfully resolved in our data set the correct resolution is not always guaranteed.
overall the transitions that g oalexplorer could not follow resulted in missing targets in apps g oalexplorer finds alternative paths to targets for the remaining transitions.
sapienz and stoat cannot trigger of the missing targets either.
to answer rq4 the main reasons g oalexplorer cannot trigger a valid transition are the lack of semantic inputs e.g.
files of a certain type triggered that are external to the app e.g.
certain response from the server and pre defined order of input events that cannot be determined statically or dynamically.
evaluation summary overall our experiments demonstrate that the combination of the static stg model and the runtime exploration techniques applied by g oalexplorer is effective for the goal driven exploration task.
by using these techniques g oalexplorer is able to reach substantially more targets than techniques based on other static ui models.
it is able to reach a comparable number of targets as the dynamic app exploration techniques only substantially faster.
c. limitations and threats to v alidity the external validity of our results might be affected by the selection of subject apps that we used and our results may not necessarily generalize beyond our subjects.
we attempted to mitigate this threat by using a standardized set of benchmark apps and by extending this set to include the top google play apps.
as we used most popular realworld apps of considerable size we believe our results will generalize for other apps.
for internal validity our static analysis relies on flowdroid to construct the callgraph and collect the callbacks.
the validity of our results thus directly depends on the accuracy of that tool.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the main limitation of our approach is the lack of knowledge of the correct combinations of ui events on a screen required to issue a transition.
also even though we extended our implementation to handle login screens g oalexplorer cannot handle screens that require other types of semantic inputs such as a zip code or a specific type of file.
this limitation is common to many other automated exploration approaches and we intend to look at it as part of future work.
moreover g oalexplorer inherits weaknesses of its underlying static analysis tools such as handling of reflection intercomponent communication and callback order resolution.
v. r elated work in this section we discuss existing static android ui models automated app exploration techniques that rely on building ui models dynamically and prior work on targeted app exploration.
static android ui models.
approaches that statically construct an android ui model such as a3e and gator are the closest to our work the models they build atg and wtg are extensively discussed in sects.
ii and iii a and compared with our approach in sect.
iv.
a number of approaches extend these models e.g.
by adding information about specific api invocations and using that to estimate the execution time and energy consumption of possible app execution paths.
similar to g oalexplorer storydroid enhances wtg with information about fragments and then proposes an approach to statically render the ui of each activity.
yet the resulting representation is similar to our wtg e model not the stg model used by goalexplorer .
that is all these approaches do not change the underlying representation of ui elements thus sharing all the discussed limitations of the atg and wtg models.
automated app exploration.
instead of relying on a static model some approaches build the model dynamically during app exploration.
for example stoat is based on a high level statically constructed model that captures the core application activities and input events.
the model is further refined during the dynamic analysis adding missing states and events.
sapienz seeks to maximize code coverage and minimize the length of the generated test sequences to reveal more faults in shorter time.
it uses pre defined patterns of lowerlevel events that capture complicated interactions with the application in order to achieve higher coverage.
ape which was published after our paper was submitted represents the dynamic model as a decision tree and continuously tunes using the feedback obtained during testing.
it constructs a finer grained model than that of sapienz and stoat by e.g.
including additional widget attributes that indicate whether a widget is clickable or not.
swifthand focuses on minimizing app restarts during testing while still achieving maximal possible coverage.
although the models used in these techniques are different the underlying idea is similar dynamically build a model of the app and mutate it so that the generated tests achievehigher coverage and fault detection.
since these tools focus on systematically executing the whole app to detect faults rather than swiftly navigating to a particular functionality of interest they are inefficient for goal driven exploration.
that is because without building an accurate static model and identifying the target upfront it is difficult to determine which part of the app to ignore explore first.
another line of work explores approaches for covering the full code and state space of an app .
such approaches build symbolic execution engines that either model the android framework or build a customized dalvik virtual machine so that the app can be exercised in a controlled environment.
they only work for a specific version of android and have to be rebuilt for each new version.
in contrast our approach does not require such modifications.
targeted app exploration.
symbolic and concolic execution is also used for generating semantically meaningful inputs for directing app exploration towards a particular usually malicious behavior.
for example jensen et al.
use concolic execution to generate input event sequences that force the execution towards the target line of code.
yet this approach only resolves the path constraints within one component and requires an ui model of the app to handle the transitions between components.
sch utte et al.
also use concolic execution to force app executing into a security sensitive api.
unlike g oalexplorer this approach relies on modifying the app to shortcut the path to the target.
similar smartdroid modifies the android framework to prevent the creation of activities that do not lead to the desired sensitive target.
finally wong and lie and rasthofer et al.
generate android execution environments to direct the app towards a given target.
instead our approach identifies a path to the target in the original unmodified version of the app which guarantees the existence and correctness of that path.
vi.
c onclusions this paper introduced g oalexplorer a tool for goaldriven exploration of android applications.
such a tool is useful for scenarios when an analyst needs to automatically trigger a functionality of interest in an app.
the main contributions of g oalexplorer are a the static technique for constructing stg a model that represents ui screens and transition between the screens and b an engine that uses stg to build an executable script that triggers the functionality of interest.
our empirical evaluation shows that the stg model introduced in g oalexplorer is more accurate than other existing static ui models of android applications and can reach the target substantially faster than the state of the art dynamic approaches.