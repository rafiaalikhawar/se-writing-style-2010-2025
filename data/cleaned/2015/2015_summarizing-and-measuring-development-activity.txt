singapor e management univ ersity singapor e management univ ersity institutional k nowledge at singapor e management univ ersity institutional k nowledge at singapor e management univ ersity resear ch collection school of computing and information systems school of computing and information systems summarizing and measuring de velopment activity summarizing and measuring de velopment activity christ oph treude singapor e management univ ersity ctreude smu.edu.sg fernando figueira filho uir kulesz a follow this and additional works at https ink.libr ary.smu.edu.sg sis r esear ch part of the softwar e engineering commons citation citation treude christ oph figueira filho fernando and kulesz a uir .
summarizing and measuring development activity .
.
esec fse pr oceedings of the 10th joint meeting on foundations of softwar e engineering ber gamo italy august september .
.
available at available at https ink.libr ary.smu.edu.sg sis r esear ch this conf erence pr oceeding ar ticle is br ought t o you for fr ee and open access b y the school of computing and information systems at institutional k nowledge at singapor e management univ ersity .
it has been accepted for inclusion in resear ch collection school of computing and information systems b y an authoriz ed administr ator of institutional k nowledge at singapor e management univ ersity .
for mor e information please email cher ylds smu.edu.sg .
summarizing and measuring development activity christoph treude fernando figueira filho uir kulesza departamento de inform tica e matem tica aplicada universidade federal do rio grande do norte natal rn brazil ctreude fernando uira dimap.ufrn.br abstract software developers pursue a wide range of activities as part of their work and making sense of what they did in a given time frame is far from trivial as evidenced by the large number of awareness and coordination tools that have been developed in recent years.
to inform tool design for making sense of the information available about a developer s activity we conducted an empirical study with github users to investigate what information they would expect in a summary of development activity how they would measure development activity and what factors in uence how such activity can be condensed into textual summaries or numbers.
we found that unexpected events are as important as expected events in summaries of what a developer did and that many developers do not believe in measuring development activity.
among the factors that in uence summarization and measurement of development activity we identi ed development experience and programming languages.
categories and subject descriptors d. .
management keywords summarization empirical study development activity .
introduction and motivation software developers produce a large number of artifacts in their day to day work ranging from source code and development issues to online discussions and documentation.
making sense of this plethora of data is becoming harder with every new artifact created.
despite many metrics software projects continue to be di cult to predict and risky to conduct and nding relevant information within the vast amount of information available is challenging .
the need to condense the activity taking place in a software project into a more consumable format has given rise to software analytics and many tools that o er awarenesssupport such as the dashboards in ibm s jazz or palant r s views for awareness in the large .
many of these tools attempt to condense development activity into numbers such as the number of issues closed by a developer or the number of open issues.
while the resulting peer pressure is often seen as a good thing the need to look like you are making progress is useful it is evident that numbers are insu cient to capture all aspects of development activity as we found in previous research just because one team has a lot more defects than another that doesn t necessarily mean that the quality of that component is any worse .
recently qualitative dashboards have been proposed to improve developers situation awareness .
even though many metrics have been introduced to measure a developer s activity such as the number of tasks per month the number of source code lines per hour or the number of logical source statements per month none of these metrics have found wide acceptance.
given recent advances in the automatic summarization of software artifacts such as bug reports classes methods or code snippets it is conceivable that summaries could be generated to capture the development activity of a developer or team in a given time frame.
in other words development activity cannot only be condensed into numbers but also into textual summaries.
potential advantages of such summaries would be the possibility of explaining rather than simply measuring the opportunity to include context where needed and reducing the cognitive e ort required for consuming interpreting and making sense of large amounts of data.
this combination of textual and numerical data to summarize development activity is the ultimate goal of this work.
as a rst step here we present the results of an empirical study with github users to identify what information such a summary should contain how development activity can be measured and what factors in uence how development activity can be condensed.
using analysis methods from grounded theory we found that unexpected events are as important as expected events when summarizing development activity and that many developers do not believe in the existence of any measure suitable for measuring development activity.
we also identify factors which in uence how development activity can be condensed including experience and programming languages.
.
related work work related to this research can be divided into work on productivity awareness and summarization.
this is the author s version of the work.
it is posted here for your personal use.
not for redistribution.
the definitive version was published in the following publication esec fse august september bergamo italy acm.
... .
measuring developer productivity previous work on developer productivity has attempted to measure developer activity in di erent ways.
looking at di erent conceptualizations of developer productivity in the literature meyer et al.
found a long list of de nitions the number of tasks function points lines of code modi cation requests or logical source statements in a given time frame or compared to spent e ort or alternatively the resolution time of a modi cation request or the ratio of editing events to selection and navigation events .
since there is no consensus on how to measure developer activity in this work we asked developers how they would design such a measure.
meyer et al.
conducted a study on software developers perceptions of their own productivity through a survey and an observational study.
they found that developers perceive their days as productive when they complete many or big tasks without signi cant interruptions or context switches.
in contrast to their work we focus on measuring developer activity.
in earlier work demarco and lister studied programmers in a one day implementation benchmarking exercise.
they found evidence that characteristics of the workplace and of the organization seemed to explain a signi cant part of the di erence in productivity between di erent programmers.
blackburn et al.
found team size to have a negative correlation with productivity.
boehm described various avenues for improving developer productivity including better management sta ng incentives work environments integrated development environments rework elimination and component reuse.
in contrast in this work we focus on summarizing and measuring development activity.
.
awareness in software development awareness is related to social transparency and dened as an understanding of the activities of others which provide context for your own activity .
awareness spans technical and social aspects as well as articulation work and it is indispensable in sustaining team cognition and in constructing mental models of a software project .
however who should be aware of whom is an open question .
since maintaining awareness is time consuming many tools have been developed to support awareness in software development.
seesoft is a visualization approach which maps each line of source code to a thin row and uses colours to indicate changes.
augur adds software development activities to a seesoft style visualization allowing developers to explore relationships between artifacts and activities.
palant r provides insight into workspaces of other developers focusing on artifact changes.
fastdash uses a representation of a shared code base to highlight current activities aggregated at the level of les and methods.
social health overview mines the history of development artifacts to reveal social and historical patterns in the development process.
wipdash is a large screen visualization for small co located teams designed to increase awareness of tasks and source code activity.
the dashboard component of ibm s jazz is intended to provide information at a glance and to allow easy navigation to more complete information.
the dashboards of the pco vision platform are intended to support and enhance project based learning.
our work is related to awareness since summaries of devel opment activity have the potential to support awareness in collaborative software development.
we asked software developers what information they expect to be kept aware of and what information they disseminate to others.
.
summarizing software artifacts our assumption that development activity can automatically be summarized is based on the large body of work that has introduced summarizers for software artifacts.
haiduc et al.
explored the suitability of various automatic summarization techniques for generating source code summaries and found that a combination of text summarization techniques is most appropriate for source code summarization.
moreno et al.
automatically summarized java classes focusing on the content and responsibilities of a class rather than its relationships with other classes.
sridhara et al.
presented a technique that summarizes a method s actions which requires the detection of code fragments implementing high level actions within methods .
mcburney and mcmillan proposed to include method context in summaries of java methods by analyzing how these methods are invoked.
rastkar et al.
introduced an automated approach that produces a natural language summary which describes cross cutting concerns and how they are implemented.
ying and robillard investigated the feasibility of summarizing code examples for better presenting such examples.
focusing on bug reports rastkar et al.
investigated whether it is possible to summarize them automatically and e ectively so that developers can consult summaries instead of entire bug reports.
czarnecki et al.
posed three hypotheses on what makes a sentence in a bug report relevant discussing frequently discussed topics being connected to other sentences and keeping focused on the bug report s title and description.
mani et al.
proposed to improve the quality of unsupervised bug report summarization techniques by automatically removing noise such as email dumps and chat transcripts.
all of these approaches suggest that it is indeed possible to automatically summarize software artifacts.
.
research method in this section we present our research questions and the methods used for data collection and analysis.
in addition we show demographic data about the study participants.
.
research questions our research is guided by the following research questions rq1 from a developer s perspective what information should be included in a summary of development activity?
rq2 how would software developers design a metric to measure the input output of a software developer?
rq3 what factors in uence how development activity can be condensed into textual summaries or numbers?
answers to these questions will shed light on the requirements for tool support that automatically condenses development activity into words i.e.
textual summaries or numbers i.e.
measures .
we make no distinction between individual developer activity and project activity in this study 626since our research questions do not assume a particular organizational structure for either project or team.
.
data collection to answer our research questions we designed a webbased survey which was sent to github users responses and we conducted follow up interviews with ten of the survey respondents to validate the ndings.
table shows the most important questions of the survey where each horizontal line represents a page break.
the complete survey is available at .
the rst three questions ask for demographic information from each participant.
in addition to the data collected through these questions we used the data available on github about each participant in the data analysis.
following fink s advice on survey design we used speci c time periods and a speci c scenario to make the question about expected content in a summary question as concrete as possible.
the answer options to question potential sources for summary items were not yet visible when answering the previous questions to minimize bias and avoid generic answers such as all these options sound good .
since the survey instrument was static it was not possible to use the answers to question as answer options in question .
to get participants to think about measuring development activity we asked them to compare their own development activity in the two months prior to the survey question before asking how they would design a metric to automate such a comparison question .
again speci c options that we asked about in question were not visible when answering the earlier questions.
the answer options to question were taken from de lima since his work also explores di erent ways of measuring development activity.
to distribute the survey we downloaded all github user data on december .
out of a total of users had published their email address.
we further limited the study population to users that had made at least one public contribution push pull or issue creation in the past twelve months resulting in users.
we randomly sampled of these users and asked them to complete the survey.
a draw for corporate gift cards was conducted to incentivize participation.
we received responses response rate .
.
after analyzing all responses we sent messages to survey respondents asking for a follow up interview ten of which resulted in an interview.
the interviews were semi structured clarifying survey responses and asking about themes that emerged in our analysis.
.
data analysis considering the exploratory nature of our research questions we used methods from grounded theory to analyze the collected data.
we designed our study from rst principles since to the best of our knowledge no tool that summarizes development activity has been widely adopted in practice.
in three coding sessions of about four hours each the rst two authors collaboratively performed open coding of the responses to open ended questions in the survey.
answers related to summarizing development activity and answers related to measuring development activity were coded separately.
collaborative open coding was done until saturation was reached.
in both cases this happened after coding approximately to survey responses.
the rst two authors then divided the remaining survey responses0 projectsparticipants figure number of projects across participants experience in years participants figure experience across participants and coded them separately consolidating additional codes in an additional collaborative session.
in the end we obtained codes for the summarization part of the study and an additional codes for the measurement part.
we used axial coding to nd higher level conceptual themes to answer our research questions.
in the last phase of the research core themes were formed into statements that we validated through the follow up interviews.
.
demographics in this section we present basic demographic information about the participants in our study.
figure shows the distribution of the number of active projects per participant as indicated by their survey responses.
by far most of the participants were active in more than one project.
figure shows the distribution of years of development experience per participant.
half of them had at least ve years of development experience and many indicated having ten or more years of experience.
for the majority of participants developing software was part of their job of the participants gave a positive response to the corresponding survey question compared to negative responses.
of the participants indicated that they currently develop software in a team compared to solo developers.
we calculated all correlations between the demographic data we collected using spearman s rho.
in addition to all github metrics being correlated with each other there is a moderate positive correlation between a participant s experience and the number of projects they are involved in.
all other correlations are weak following dancey and reidy s interpretation .2in the following sections we will correlate responses to the survey questions with this demographic data.
.
findings in this section we report our ndings on summarization section .
and measurement section .
of software de1note that the numbers for di erent survey questions do not necessarily add up to since most questions in the survey were optional.
2the complete data is available in our online appendix at .
627table survey questions excerpt in how many di erent software development projects are you currently an active participant?
drop down is developing software part of your job?
yes no for how long have you been developing software?
drop down assume it s monday morning and you have just returned from a week long vacation.
one of your colleagues is giving you an update on their development activities last week.
what information would you expect to be included in their summary?
text box in your opinion are any of the following items important in summaries of what a developer did last week?
names of methods added by the developer commit messages by the developer titles of issues closed by the developer titles of issues opened by the developer titles of issues commented on by the developer source code comments added by the developer point likert scale for each option what other information sources might be useful to consider for such a summary?
text box in terms of input output how would you compare your development activity in november to that in october?
i had more better development activity in october i had more better development activity in november october and november were similar in terms of development activity for me how would you design metrics to automatically measure the input output of a software developer in a given month?
why?
text box in your opinion are any of the following metrics suited to measure input output of a developer?
lines of code number of bugs xed complexity of code added or modi ed low number of bugs introduced point likert scale for each option what other aspects are important to consider when assessing input output of a developer?
text box do you currently develop software in a team?
yes no velopment activity.
for each code that emerged in the qualitative analysis we indicate how many participants mentioned the particular theme in superscript.
note that these numbers only indicate how much evidence the data analysis yielded for each theme they do not necessarily indicate the importance of a theme since we did not explicitly ask all participants about each theme speci cally.
.
summarizing development activity our ndings related to the summarization of development activity can be divided into ndings on primary artifacts expected and unexpected events coordination and secondary artifacts.
in addition we describe the factors that in uence what information should be included in a summary.
.
.
primary artifacts the importance of being updated on how di erent artifacts move through the development cycle was a recurrent theme among the participants.
in our analysis we observed a di erence between primary artifacts those that move through a development cycle and secondary artifacts .
we summarize our ndings regarding secondary artifacts in section .
.
.
among the primary artifacts projects play an important role as p83 s request of what should be in a summary shows any projects that were completed and started .
within these projects information on development tasks is essential as described by p141 task state transition history which tasks were taken which were done which were tested .
similarly p27 described the importance of features i would expect to include a description of the new feature how the new feature impacts the current work ow .
other primary artifacts that were mentioned included documentation modules and user stories as detailed by p20 i d like to know how many stories moved through the development cycle .
.
.
expected in this section we discuss in more detail the information that developers need about the process that thesetable high level codes that emerged for process expect.
unexpect.
coord.
status changes people planning bugs communic.
time di culties awareness goal blocked integration justi cation releases changes strategy responsib.
primary artifacts follow.
table shows the higher level themes that emerged for process in our study.
expected events describe status updates that are generally not surprising to the consumer of the summary i.e.
some primary artifact is following the development cycle as planned whereas unexpected events are unforeseen.
we rst focus on the expected updates where updates on the status play a central role as p40 explained i would report a status report of activities what was done what state in which branch which the purpose of the activity .
among the possible status updates participants mentioned nished in progress changed added planned deployed removed delivered and reviewed .
p142 gave an example of what such a summary would look like i nished story xxx.
when i was working on it i found y problem.
in order to x it i created and scheduled story z. in addition we had min of unscheduled downtime to a bad deploy .
while such summaries should contain some detail for example as expressed by p63 functionality changes with point form details with description and location of changes they should mostly be high level as this quote from p121 shows list of high level features and explanation of how much progress was made on any of them .
balancing these two ends of the spectrum is one of the challenges in summarizing development activity.
when deciding what information to include in a summary priority and severity were 628mentioned as criteria.
in addition the content of a summary depends on other communication channels that developers have already used as this example from p32 shows well rst of all i would know medium and low priority errors on production environment of the current projects if a high priority error occurs we call us via phone .
another crucial aspect when summarizing development activity is planning mostly for the time frame of a week or a day and often based on priorities as indicated by p10 what to focus on for the coming week based on business priorities .
long term planning often involves new projects or the project budget .
status updates usually involve a time aspect as this quote from p156 shows if we are on time and if we need more time to nish the job .
another example was given by p99 i m very oc when it comes to timelines deadlines so i think i would say everything is right on track .
this focus on deadlines or milestones was con rmed by p123 how far the development has come what milestones been reached and or set up .
time is imperative in terms of how much time has been spent and in terms of how much time is required as indicated by p144 can we keep the deadline with the current status?
.
other themes that emerged from the analysis include updates on goals in particular as they are related to business concerns .
these ndings are unsurprising given the ability of commercial tools such as rally or rational team concert to monitor how artifacts move through the development cycle and to send state changes to team members.
after describing the expected events that developers want to see in a summary of development activity in the next section we focus on the unexpected events that emerged from the data we collected.
.
.
unexpected developers need to know about unexpected events that happened in their projects.
for example this is the ideal summary envisioned by p49 work log what functionality been implemented tested.
what were the challenges.
anything out of the ordinary .
p57 s version is similar what we have to do what has been done while i was away is everything going as expected?
something strange happened i.e.
the client complains about something or we did a big mistake some critical decision has been chosen?
some architectural decisions had been chosen?
.
another example came from p111 i would expect a description of any drastic changes to the codebase what major tasks were completed if any responsibilities were re distributed if any short term goals were changed and in particular if anything that was once estimated as not di cult turned out to be more di cult than expected .
p60 also mentioned unexpected issues this is what i got done since you left.
this issue came up that we did not expect.
now it s going to take longer shorter and p121 talked about unusual problems description of the features they worked on and any unusual problems antipatterns they encountered .
in this section we explain in more detail what information about unexpected events software developers would like to see in a summary of software development activity.
many of the unexpected items that participants mentioned were unexpected changes .
for example changes to the requirements play an essential role as p78 explained i d expect them to start by going over any changesto the spec features completed and major bug closures and openings .
unexpected events can be related to version control in particular with regard to branches such as merging or unmerging as p133 described i would include in my summary the latest commits as well as what i have unmerged on my working branch .
in addition the themes of new active and closed branches emerged from our analysis.
other changes that play a crucial role are changes to an api as p61 explained api changes are key much more than documentation so comments commit messages and whatnot in my opinion .
new dependencies are another important item as described by p144 is there any new 3rd party dependency that is added or removed .
developers want to be informed about changes to the design as stated by p138 business level documents change logs.
if are tracked changes to requirements and design documents would be useful and architecture as described by p10 meetings attended and the outcomes of those meetings particularly when large architectural decisions have been made during those meetings .
changes to the environment emerged as a theme from the analysis in terms of the deployment environment such as version x has been deployed to server y as described by p10 and the development environment .
for example p5 described the relationship between task status and problems in the development environment in his example summary we had problems in development environment caused by a third party api.
this made me unable to complete the task i was working on .
the criticality of such changes is decisive as shown by this example from p71 i would give details about any critical event bugs major architecture changes task updates and changes to goals or business priorities are among the most critical as p53 described the biggest source of change and uncertainty in software development is the changing business environment.
at my place of work business priorities and expected features change frequently enough to make long term technical planning challenging.
i think this di cultly is widely shared in many which conduct software development .
related to that are conceptual changes or changes to estimates as indicated by p117 revised estimate of time to completion for outstanding goals projects .
bugs are by de nition unexpected and they play a crucial role when summarizing development activity as described by p83 i would want them to know if any serious bugs came up .
bug xing is an important activity to be included in a summary as shown in this example summary given by p70 we ve seen a new issue on one of our clusters xxxx ticket number .
turns out it was caused by yyyy.
i ve spent days to diagnose and x the issue code review .
apart from this i ve written a design document on component zzzz and started working on the prototype repository .
i ve also xed these three bugs aaaa bbbb cccc .
the root cause and solution used when xing bugs were also mentioned by participants.
in addition to bugs xed bugs found or newly introduced play an important role as shown in these two descriptions from p22 and p53 respectively i usually give status updates whenever i nish a major part of my end of the project.
weekly updates would include telling 629him what he needs to do to use my code any bugs that i ve found what my next steps are and a way to look at it working i would tell him the most signi cant changes we have done in development since he left.
also the problems i found and how i overcame those situations what i m in this moment and if i have any problem in this moment .
bugs can have been reported by a client as this example summary from p95 shows last week a client reported that retrospectively adding products to the database causes a fatal server crash.
after investigating the os server software and database it turned out that the source of the problem was invalid validation in the rails webapi.
this issue is now xed and clients have been informed.
however this x might impact our archiving plans as clients may now update the archive retrospectively .
downtime emerged as another theme from the analysis also related to bugs.
problems or di culties are an essential part of a summary on development activity as shown in this example from p76 i ve been working on this feature bug x and have completed this much while encountering these problems.
my next steps are... .
these problems can originate from mistakes and often lessons are learned when solving a problem as p16 described in what he would expect from a summary short description about what he did problem he solved what he learnt .
a common problem in collaborative software development is that one developer is blocked on another one as this hypothetical summary from p9 illustrates i am blocked on nate for app which requires a orm module to be completed before i am able to work on that ticket .
the work ow plays an necessary role in such a summary as underlined by p131 what i think is more important to do not to break the work ow joe must have the task x y z nished so i can use them or write tests .
a crucial di erence between expected events cf.
previous section and unexpected events is that unexpected events usually require some kind of justi cation .
for p22 unexpected events and their justi cation are the most critical part of a meeting we cut our developer status meetings way down and started stand up meetings focusing on problems and new ndings rather than dead boring status.
only important point is when something is not on track going faster than expected and why .
p144 s idea of a summary is as follows would give a list about the tasks i had to complete by and provide details about those which are not yet resolved with the reason why they are not .
the last theme that emerged from the analysis as part of the unexpected events pertains to interesting problems and interesting solutions .
this quote by p78 illustrates the importance of such problems and solutions i d like them to then describe any odd or novel obstacles they had to overcome while coding and whether the solutions to those obstacles could be used in a wider context in later development .
.
.
coordination coordination plays a crucial role in collaborative software development and it emerged as a core theme in the data analysis.
coordination is rst of all about people and participants mentioned developers as well as customers and users which may or may not be the same group of individuals .
p4 s example sum mary underlines the importance of customers i ve implemented stubbed these modules a b c ... and i found these problems.
called emailed regarding to and .
p61 talked about users in what he expects in a summary generally everything involving users or dummy users interacting with the product with relative feedback .
coordination needs communication which can come in many di erent forms.
again quoting p61 i would begin by summarizing the work and the status of progress in the various projects.
i d then proceed to report any important communications between me and the clients the bosses or other colleagues .
since communication often happens in meetings the information on these meetings is vital as well as p41 explained the minutes of any development meetings and a di le from between now and the previous week would be all i needed to get up to date .
feedback was mentioned by participants as well as requests for help or o ers of help as these examples from p106 and p151 show if they are having any problems that they need help with a brief view of the issues they believe i can help to solve quickly .
some issues should be mentioned in summaries because they require discussion as shown by p19 s quote for example last week i would have said that i have about projects ready to be upgraded i sent images screenshots of new ideas and restated issues that require discussion .
one signi cant aspect of coordination in software development is awareness as shown by what p42 expects in a summary any caveats in the design or implementation that others should be aware of .
developers want to be kept aware of refactorings as shown in this example summary by p145 i have completed a major refactoring of a wordpress plugin and the plugin is now being tested in a sandbox prior to rollout .
similar items that are necessary to communicate so that developers are aware of them include reusable components optimizations compatibility and workload .
coordination is paramount during integration as p22 explained i would ask what it will take to provide me with integration points i foresee i will be needing .
coordination is required about releases when changes are needed or when responsibilities are re distributed .
finally the themes of strategy and philosophy emerged as being important in summaries of development activity.
.
.
secondary artifacts summaries do not stand on their own but they are often supported by and related to secondary artifacts .
as opposed to the primary artifacts described earlier in this section secondary artifacts do not go through a development cycle and are either ne grained artifacts that do not change status such as a commit or they present a view on data available in a repository such as a burndown chart .
artifacts related to testing play a central role as secondary artifacts in summaries of development activity in particular related to coverage and outcomes .
commits are relevant as well as p71 described commit tree is very important when working with large teams .
however commits might not be high level enough to always be useful in a summary as p20 indicated i d also look at the git history for an overview of merged feature branches.
i wouldn t look through each commit but rather view the 630table rating of summary sources mean method names .
commit messages .
issues closed .
issues opened .
issues commented .
code comments .
merges to get an idea of time size of each feature .
other artifacts include comments code reviews emails pull requests and meeting notes .
p93 thought that summaries could improve meetings anything that ampli es signal noise ratio of daily standups .
what has been accomplished since the last meeting?
.
what will be done before the next meeting?
.
what obstacles are in the way?
.
secondary artifacts further include data from work ow management tools working examples screenshots burndown charts wikis blogs metrics and patches .
p98 detailed the role of patches if any patches were contributed by volunteers or non regular developers it is useful to know who worked on them .
finally cards were mentioned for example by p97 i want to know the ones he did the ones he didn t and i ll check if this makes him on or out his schedule .
.
.
factors influencing summary content after detailing the content that developers expect when they are presented with a summary of development activity in this section we investigate what factors in uence the content that should be considered.
we use the answers to question in the survey cf.
table as well as the followup interviews to explore this question.
table shows how the survey participants rated di erent potential summary sources.
the highest ratings on a point likert scale not important at all very important were given to issue titles of opened and closed issues.
at the other end of the spectrum code comments and the names of methods were rated the lowest.
several survey participants explained what their answers depended on.
for example p78 and p115 mentioned the quality of commit messages and comments as a factor looking through commit logs can also be extremely useful as long as the commit messages are actually descriptive if these are good commit messages they will provide a good overview of the progress made most comments would be redundant but some could be very important .
p52 pointed out that answers depend on the nature of the project my answers assume a ux project.
if we were building an api method names and source comments would go up in importance .
the management style of a project is in uential as indicated by p3 in the follow up interview theory this sort of automatic summarization could probably be applied to almost all of the projects i ve ever worked on especially at the beginning of my career many of my managers were very set in their ways and wary of new approaches .
in addition the stage at which a project is determines what information is signi cant when summarizing development activity as p52 explained in the follow up interview for example if we re in the early planning phases of a project i expect developer status to mostly be prototyping x technology or ramping on y framework or similar.
if i heard a developertable summary sources and experience source experience mean method names up to years .
or more years .
code comments up to years .
or more years .
table summary sources and prog.
languages summary source prog.
language mean code comments c .
no c .
say they were implementing a feature in that context that would stand out and i d want to know more.
on the other end of the project towards the end a status of ramping would be the stand out requiring more investigation .
table explores this further by showing the correlations between demographic data of the survey participants and their answers regarding potential summary sources spearman s rho .
none of the correlations are statistically signi cant after adjusting the p values using a bonferroni correction .3we explored the role of experience in more detail.
table shows the mean scores assigned to the importance of method names and code comments separately for participants with up to ve years development experience and participants with at least six years development experience.4the di erences between these groups are statistically signi cant mann whitney wilcoxon test p .
we hypothesize that these di erences can be explained by the diversity of activities that are performed by more experienced developers.
while junior developers might only work on well de ned tasks involving few artifacts the diversity of the work carried out by senior developers makes it more di cult to summarize their work by simply considering method names code comments or issue titles.
future work will have to be conducted to explore this hypothesis.
we also analyzed the di erences in answers as they relate to the programming languages that participants use on github for each of the nine most used programming languages among our participants javascript css shell java python ruby php c c .
for each participant we obtained the three languages that they used the most on github.
the only signi cant di erence is related to the role of code comments see table .
participants using c rated the importance of code comments signi cantly higher than participants who did not use c. we hypothesize that this might be related to the projects that developers undertake in di erent languages.
c might generally be used for more complex tasks which requires more meaningful code comments.
future work will have to be conducted to understand the reasons for this di erence.
we conclude that several factors in uence how software development activity can be summarized ranging from programming languages and development experience to the current stage of a project.
.
measuring development activity in this section we explore the themes that emerged from the analysis regarding the measuring of development activ3correlations between summary sources and the github metrics of the participants are available in our online appendix at .
4we chose six years as threshold for experienced since it best divides our participants into two groups of equal size.
631table correlations between demographic data and potential summary sources method names commit messages issues closed issues opened issues commented code comments projects .
.
.
.
.
.
part of job?
.
.
.
.
.
.
experience .
.
.
.
.
.
team?
.
.
.
.
.
.
ity namely a set of measures and the fact that many participants believed that development activity is impossible to measure.
we also investigate the factors that in uence how development activity can be measured.
.
.
measures several themes emerged from the analysis for our second research question how would software developers design a metric to measure the input output of a software developer?
the most prevalent theme is a number of measures that we divided into objective measures and subjective measures in the analysis.
while the distinction is sometimes blurry as a general rule we classi ed a measure as objective if we believed that tool support could automatically measure it e.g.
lines of code and we classi ed a measure as subjective if we believed that di erent individuals would rate the same development activity di erently with regard to that measure e.g.
impact on user experience .
table shows the themes that emerged from the analysis for objective and subjective measures of development activity along with the number of survey participants that mentioned each measure in the survey.
among the objective measures simple measures that count items such as tasks commits or story points are prevalent while the subjective measures are dominated by themes on code quality.
in previous work meyer et al.
asked software developers to rate di erent measures for development activity in their work conceptualized as productivity .
a crucial di erence between their work and ours is that we did not give participants a set of answer options and therefore the answers to our survey questions are not biased by the presence of several potential metrics.
instead our question was openended which led to the emergence of subjective measures as well as to many participants voicing their opinion that development activity is impossible to measure as we will show in the next section.
.
.
impossible to measure considering all the previous work on productivity metrics an important theme that emerged from our work is that development activity is impossible to measure .
for example p61 explained a tool capable of automatically the productivity of a developer should know the developer what he s working on be aware semantically of the codebase and the age of every part of it and every interaction between developers.
i believe that s pretty impossible for a xed program .
p19 elaborated further for me development is a craft.
sometimes when i am in the zone i can knock out or three projects.
sometimes when something is hard it will take me much longer to resolve.
so productivity cannot just be measured by a metric.
it needs something more organic .
without being prompted about this metric speci cally participants mentioned that development activity cannot be measured in lines of code as shown in this example from p10 it s di cult to measure output.
simple quantitativemeasures like lines of code don t convey the di culty of a code task.
changing the architecture or a conceptual refactoring may have signi cant impact but very little evidence on the code base.
other important contributions include interfacing with users e.g.
customer support even if those customers are just other people at our company who are using the software our team produces .
the focus on customers and the value created for them was con rmed by p32 well in my main role as analyst developer one important aspect the customer and co team devs relations it s not measurable but sometimes it s more important than metrics we do systems for people in rst place .
similarly the di culty of a task or conceptual work cannot be measured in lines of code.
another theme that emerged from the analysis is that there is a wide range of development activities which makes it impossible to measure what developers do with a simple measure.
for example the context of the work is essential as indicated by p41 i don t believe there are any simple metrics for this kind of thing.
anything objective like lines of code written hours logged tags completed bugs squashed none of them can be judged outside of the context of the work being done and deciphering the appropriate context is something that automated systems are not surprisingly not very good at .
in addition there is a wide range of di erent roles and work ows as p61 explained you should probably start o by dividing the roles and taking note of every developer s role s .
then you should start by tracking amount of commits per day amount of lines per commit related to the project and with that hopefully capturing the role one is acting in that speci c commit assuming the codebase is well structured amount of interaction on work ow control .
finally the development stage that a project is at matters as described by p133 measuring these metrics would change based on the stage of the project in its development cycle .
another problem is that measures can be gamed as p22 explained in the follow up interview a lot of indicators you want to measure would give a bonus to the employees when they meet the measures and then they are the wrong thing because they are trying to optimize their own bonus.
i think those kinds of bonus systems are problematic .
similarly p52 described automatic is pretty challenging here as developers are the most capable people on earth to game any system you create .
p120 added i wouldn t use automatic measurements.
they are too easy to game and don t re ect the range of useful activities of a good developer and p61 commented it s a method full of pitfalls though developers are smart people so you have to assume that if they want they could exploit the system pretty easily .
this applies in particular to simple measures such as number of issues and number of commits as p44 described a poor quality developer may be able to close more tickets than anyone else but a high quality developer often closes fewer tickets but of those few almost 632table rating of activity measures mean lines of code .
bugs xed .
complexity .
few bugs introduced .
table activity measures and experience measure experience mean lines of code up to years .
or more years .
bugs xed up to years .
or more years .
complexity up to years .
or more years .
none get reopened or result in regressions.
for these reasons metrics should seek to track quality as much as they track quantity .
other problems with automatic measures include di erent artifact sizes and the di erence between activity and output .
interestingly participants who talked about the di culty of measuring development activity generally felt positive about the idea of summarizing development activity.
for example p106 stated it s dangerous to measure some number have rankings.
because that can be easily gamed.
i think having summaries of what everyone did is helpful.
but ranking it assessing it is very di cult could encourage bad habits.
i think it s better to provide the information leave it up to the reader to interpret the level of output .
numbers might be used to complement text but not the other way around as explained by p3 in the follow up interview i think that s probably the better approach text rst and maybe add numbers.
i spend about minutes every friday reviewing git di s just to have a clearer picture in my mind of what happened over the week.
the automatic summary would make it harder to miss something and easier to digest .
.
.
factors influencing measurement to investigate the factors that in uence how software development activity can be measured we examined the answers to question in the survey cf.
table .
table shows how survey participants rated di erent potential measures.
the highest ratings on a point likert scale not well suited at all very well suited were given to low number of bugs introduced number of bugs xed and complexity of code added or modi ed.
unsurprisingly the rating for lines of code was much lower than that for the other measures.
we investigated the correlations between demographic data and the answers to this question.
table shows the results.
none of the correlations are statistically signi cant after adjusting the p values using a bonferroni correction.5as table shows we investigated the role of experience further.
the mean scores assigned to the suitability of three out of four of these measures di er signi cantly mann whitneywilcoxon test p between participants with up to ve years development experience and participants with at least six years development experience.
5correlations between activity measures and the github metrics of the participants are available in our online appendix at .table measures and prog.
languages measure prog.
language mean few bugs introduced javascript .
no javascript .
few bugs introduced css .
no css .
lines of code c .
no c .
complexity c .
no c .
table objective and subjective measures objective subjective artifact count code quality tasks issues documentation closed structure opened resilience complexity legibility reopened rate clarity commented e ciency priority style found design severity adaptability tests scalability coverage maintainability commits few bugs features few crashes story points few changes in review lines of code initiative methods discussions change loc ideas scrum metrics volunteering pull requests psychological factors stories customer relations comments in company releases outside company reviews customer experience plan ful lment mentoring estimate reality usefulness goals number of problems expectation reality number of solutions deadlines personal growth time spent impact on ux work hours demonstrable results when we investigated the relationship between participants programming languages and their ratings of the different measures we found four statistically signi cant differences as table shows participants using javascript and css assigned more importance to the measure of few bugs introduced than those who did not use javascript or css respectively.
lines of code and complexity were seen as more suitable measures for development activity by participants who used c compared to those who did not.
we hypothesize that it is particularly di cult to recover from bugs in web development javascript and css and that more complex programs are often written in c. future work will have to be conducted to explore these hypotheses.
.
discussion we brie y discuss two of the themes that emerged from our analysis the interest of developers to learn about unex633table correlations between demographic data and potential activity measures lines of code bugs xed complexity few bugs introduced projects .
.
.
.
part of job?
.
.
.
.
experience .
.
.
.
team?
.
.
.
.
pected events and the opinion that development activity is impossible to measure.
.
unexpected events when we validated the theme of unexpected events in follow up interviews with participants we asked them specifically about how such unexpected events could be detected.
participants referred to the commit history in particular.
for example p115 elaborated commits that take particularly long might be interesting.
if a developer hasn t committed anything in a while his rst commit after a long silence could be particularly interesting for example because it took him a long time to x a bug.
also important commits might have unusual commit messages for example including smileys lots of exclamation marks or something like that.
basically something indicating that the developer was emotional about that particular commit .
p3 added changes to les that haven t been changed in a long time or changes to a large number of les a large number of deletions etc.
.
while there is work on automatically detecting buggy commits e.g.
little work has been conducted on detecting the unusual or unexpected in a commit history.
visualization of the software process the commit history or speci c commits can help developers spot unexpected events but they have not been designed specifically for this purpose.
based on the ndings of this work we are investigating ways for automatically detecting unusual or unexpected events in commit histories and software repositories in general.
to do so we need to establish what is normal in a given context and then identify derivations from the expected.
as our participants pointed out the wide range of development activities project stages technologies team compositions and individual characteristics make it impossible to assume the same normal for all developers or projects.
approaches for the detection of unexpected events have to be aligned with the speci c situations in which they will be used.
we have recently published a rst prototype for the detection of unusual events in commit histories .
.
impossible to measure?
as many of our participants indicated development activity is impossible to measure and it might even be dangerous to measure it since measures could lead developers to game a system rather than work towards the goodness of the codebase as p10 described it.
one of the challenges is the prevalence of invisible work and articulation work in software development that cannot be measured in terms of lines of code number of commits or number of issues.
however our ndings suggest that summarizing software development activity is a promising approach to address some of these issues.
instead of condensing development activity into numbers which can easily be gamed the idea is to condense development activity into textual summaries that provide a richer source of information than numbers.
our work provides empirical data on the content that such sum maries should contain.
expanding on the idea of qualitative dashboards text can be used to complement numbers and vice versa.
.
limitations we chose methods from grounded theory to answer our research questions due to the exploratory nature of these questions.
while we achieved saturation when analyzing the survey responses and validated the core themes in follow up interviews we cannot claim that we recorded all possible perspectives on these questions among github users.
to distribute the survey we randomly sampled github users that had been active within the last year.
however all individuals who contributed to this study were self selected volunteers within this sample.
the general population on github might have di erent characteristics and opinions.
thus we cannot claim that our results generalize to all github users or to the entire population of developers.
as mentioned before while we report the amount of evidence for each theme yielded by the data analysis we cannot infer the strength or pervasiveness of a theme from these numbers since we did not explicitly ask all participants about each theme speci cally.
.
conclusions and future work in this paper we reported on an empirical study designed to investigate how software development activity can be condensed into textual summaries or numbers in the opinions of software developers.
we recruited github users to participate in a survey and follow up interviews and we analyzed the data using methods from grounded theory.
we found that unexpected events are as important as expected events in summaries of development activity and that many developers do not believe in the existence of any good measure for development activity.
in addition we identi ed factors that in uence summarization and measurement of development activity including development experience and programming languages.
in future work we plan to design and build the tool support that the participants in our study envisioned a development activity summarizer that re ects expected and unexpected events supported by numbers that are intended to augment the summaries instead of pitting developers against each other.