the impact of test case summaries on bug fixing performance an empirical investigation sebastiano panichella 1annibale panichella 2moritz beller andy zaidman 2harald c. gall1 1university of zurich switzerland 2delft university of technology the netherlands panichella ifi.uzh.ch a.panichella m.m.beller a.e.zaidman tudelft.nl gall ifi.uzh.ch abstract automated test generation tools have been widely investigated with the goal of reducing the cost of testing activities.
however generated tests have been shown not to help developers in detecting and nding more bugs even though they reach higher structural coverage compared to manual testing.
the main reason is that generated tests are di cult to understand and maintain.
our paper proposes an approach coined testdescriber which automatically generates test case summaries of the portion of code exercised by each individual test thereby improving understandability.
we argue that this approach can complement the current techniques around automated unit test generation or searchbased techniques designed to generate a possibly minimal set of test cases.
in evaluating our approach we found that developers nd twice as many bugs and test case summaries signi cantly improve the comprehensibility of test cases which is considered particularly useful by developers.
categories and subject descriptors d. .
testing and debugging code inspections and walk throughs testing tools d. .
distribution maintenance and enhancement documentation enhancement keywords software testing test case summarization empirical study .
introduction software testing is a key activity of software development and software quality assurance in particular.
however it is also expensive with overall testing consuming as much as of overall project e ort and programmers spending a quarter of their work time on developer testing .
several search based techniques and tools have been proposed to reduce the time developers need to spend on testing by automatically generating a possibly minimal set of test cases with respect to a speci c test coverage criterion .
these research e orts permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
important results automatic test case generation allows developers to i reduce the time and cost of the testing process to ii achieve higher code coverage when compared to the coverage obtained through manual testing to iii nd violations of automated oracles e.g.
undeclared exceptions .
despite these undisputed advances creating test cases manually is still prevalent in software development.
this is partially due to the fact that professional developers perceive generated test cases as hard to understand and di cult to maintain .
indeed a recent study reported that developers spend up to of their time in understanding and analyzing the output of automatic tools.
as a consequence automatically generated tests do not improve the ability of developers to detect faults when compared to manual testing .
recent research has challenged the assumption that structural coverage is the only goal to optimize showing that when systematically improving the readability of the code composing the generated tests developers tend to prefer the improved tests and were able to perform maintenance tasks in less time about and at the same level of accuracy .
however there is no empirical evidence that such readability improvements produce tangible results in terms of the number of bugs actually found by developers.
this paper builds on the nding that readability of test cases is a key factor to optimize in the context of automated test generation.
however we conjecture that the quality of the code composing the generated test cases e.g.
input parameters assertions etc.
is not the only factor a ecting their comprehensibility.
for example consider the unit test test01in figure which was automatically generated for the target class option2.
from a bird s eye view the code of the test is pretty short and simple it contains a constructor and two assertions calling getmethods.
however it is di cult to tell without reading the contents of the target class i what is the behavior under test ii whether the generated assertions are correct iii which if conditions are eventually traversed when executing the test coverage .
thus we need a solution that helps developers to quickly understand both tests and code covered.
paper contribution.
to handle this problem our paper proposes an approach coined testdescriber which is designed to automatically generate summaries of the portion of code exercised by each individual test case to pro1the test case has been generated using evosuite .
2the class option has been extracted from the apache commons library ieee acm 38th ieee international conference on software engineering public class testoption test public void test0 throws throwable option option0 new option 1w assertequals 1w option0.getdescription assertequals option0.getkey figure motivating example vide a dynamic view of the class under test cut .
we argue that applying summarization techniques to test cases does not only help developers to have a better understanding of the code under test but it can also be highly bene cial to support developers during bug xing tasks improving their bug xing performance.
this leads us to the rst research question rq1 how do test case summaries impact the number of bugs xed by developers?
automatically generated tests are not immediately consumable since the assertions might re ect an incorrect behavior if the target class is faulty.
hence developers should manually check the assertions for correctness and possibly add new tests if they think that some parts of the target classes are not tested.
this leads us to our second research question rq2 how do test case summaries impact developers to change test cases in terms of structural and mutation coverage?
the contributions of our paper are summarized as follows we introduced testdescriber a novel approach to automatically generate natural language summaries of junit test cases and the portion of the target classes they are going to test we conducted an empirical study involving human participants from both industry and academia to investigate the impact of test summaries on the number of bugs that can be xed by developers when assisted by automated test generation tools we make publicly available a replication package3with i material and working data sets of our study ii complete results of the survey and iii rawdata for replication purposes and to support future studies.
.
the testdescriber approach this section details the testdescriber approach.
.
approach overview figure depicts the proposed testdescriber approach which is designed to generate automatically summaries for test cases leveraging i structural coverage information and ii existing approaches on code summarization.
in particular testdescriber generates summaries for the portion of code exercised by each individual test case thus providing a dynamic view of the code under test.
we notice that unlike testdescriber existing approaches on code summarization generate static summaries of source code without taking into account which part of the code is exercised during test case execution.
our approach consists of four steps 1test case generation 2test coverage analysis 3summary generation and 4summary aggregation.
in the rst step namely test case generation we generate test cases using evosuite .
in the second step test coverage analysis testdescriber identi es the code exercised by each individual test case generated in the previous figure overview testdescriber step.
to detect the executed lines of code we rely on cobertura4a tool based on jcoverage5.
the goal of this step is to collect the information that will be summarized in the next steps such as the list of statements tested by each test case the used class attributes the used parameters and the covered conditional statements etc.
during the step summary generation testdescriber takes the collected information and generates a set of summaries at di erent levels of granularity i a global description of the class under test ii a global description of each test case iii a set of ne grained descriptions of each test case describing for example statements and or branch executed by the test case .
finally during the summary aggregation step the extracted information and or descriptions are added to the original test suite.
an example of tests summaries generated by testdescriber for the test case showed in figure which tests the java class option of the system apache commons cli6 can be found in figure .
the complete example of generated test suite for such class is available online7.
.
test suite generation researchers have proposed several methods capable of automatically generating test input based on the source code of the program under test based on di erent search strategies such as genetic algorithms symbolic execution etc.
among them we have selected evosuite a tool that automatically generates junit test cases with junit assertions for classes written in java code.
internally evosuite uses a genetic algorithm to evolve candidate test suites individuals according to the chosen coverage criterion where the search is guided by a tness function which considers all the test targets e.g.
branches statements etc.
at the same time.
in order to make the test cases produced more concise and understandable at the end of the search process the best test suite is post processed to reduce its size while preserving the maximum coverage achieved.
the nal step of this post processing consists of adding test assertions i.e.
statements that check the outcome of the test code.
these assertions are generated using a mutation based heuristic which adds all possible assertions and then selects the minimal subset of those able to reveal mutants injected in the code.
consequently the nal test suite serves .uzh.ch seal people panichella testoption.txt 548as starting point for a tester who has to manually revise the assertions.
it is important to note that the use of evosuite is not mandatory in this phase of the testdescriber indeed it is possible to rely on other existing tools such as randoop 8to generate test cases.
however we select evosuite since it generates minimal test cases with the minimal set of test assertions reaching high structural coverage and it reached top in last sbst tool competitions.
.
test coverage analysis once the test cases are generated testdescriber relies oncobertura to nd out which statements and branches are tested by each individual test case.
however with the aim at generating tests summaries for the covered information we need more ne grained information regarding the code elements composing each covered statement such as attributes method calls the conditions delimiting the traversed branches etc.
in the next step testdescriber extracts keywords from the identi er names of such code elements to build the main textual corpus required for generating the coverage summaries .
therefore on top of cobertura we built a parser based on javaparser9to collect the following information after the execution of each test case i the list of attributes and methods of the cut directly or indirectly invoked by the test case ii for each invoked method our parser collects all the statements executed the attributes variables used and calls to other methods of the cut iii the boolean values of branch decisions in the ifstatements to derive which conditions are veri ed when covering a speci c true false branch of the cut.
the output of this phase is represented by the list of ne grained code elements and the lines of code covered by each test case.
.
summary generation the goal of this step is to provide to the software developer a higher level view of which portion of the cut each test case is going to test.
to generate this view testdescriber extracts natural language phrases from the underlying covered statements by implementing the well known software word usage model swum proposed by hill et al.
.
the basic idea of swum is that actions themes and any secondary arguments can be derived from an arbitrary portion of code by making assumptions about di erent java naming conventions and using these assumptions to link linguistic information to programming language structure and semantics.
indeed method signatures including class name method name type and formal parameters and eld signatures including class name type and eld name usually contain verbs nouns and prepositional phrases that can be expanded in order to generate readable natural language sentences.
for example verbs in method names are considered by swum as the actions while the theme i.e.
subjects and objects can be found in the rest of the name the formal parameters and then the class name.
pre processing .
before identifying the linguistic elements composing the covered statements of the cut we split the identi er names into component terms using the java camel case convention which splits words based on capital letters underscores and numbers.
then we expand abbreviations in identi ers and type names using both i an external dictionary of common short forms for english and ii a more sophisticated technique called contextual based expansion that searches the most appropriate expansion for a given abbreviation contained in class and method identi ers .
part of speech tagging.
once the main terms are extracted from the identi er names testdescriber uses languagetool10 a part of speech pos tagger to derive which terms are verbs actions nouns themes and adjectives .
speci cally languagetool is an open source java library that provides a plethora of linguistic tools e.g.
spell checker pos tagger translator etc.
for more than di erent languages.
the output of the pos tagging is then used to determine whether the names of method or attribute should be treated as noun phrases np verb phrases vp and prepositional phrases pp .
according to the type of phrase we used a set of heuristics similar to the ones used by hill et al.
and sridhara et al.
to generate natural language sentences using the pre processed and pos tagged variables attributes and signature methods.
summary generation.
starting from the noun verb and prepositional phrases testdescriber applies a templatebased strategy to generate summaries.
this strategy consists of using pre de ned templates of natural language sentences that are lled with the output of swum i.e.
the pre processed and tagged source code elements in covered statements.
testdescriber creates three di erent types of summaries at di erent levels of abstractions i a general description of the cut which is generated during a speci c sub step of the summary generation called class level summarization ii a brief summary of the structural code coverage scores achieved by each individual junit test method iii a ne grained description of the statement composing each junit test method in order to describe the ow of operations performed to test the cut.
these negrained descriptions are generated during two di erent substeps of the summary generation the fine grained statements summarization and the branch covered summarization.
the rst sub step provides a summary for the statements in the junit test methods while the latter describes the if statements traversed in the executed path of the cut.
class level summarization .
the focus of this step is to give to a tester a quick idea of the responsibility of the class under test.
the generated summary is especially useful when the class under test is not well commented documented.
to this end we implemented an approach similar to the one proposed by moreno et al.
in for summarizing java classes.
speci cally moreno et al.
de ned a heuristics based approach for describing the class behavior based on the most relevant methods the superclass and class interfaces and the role of the class within the system.
di erently during theclass level summarization we focus on the single cut by considering only its interface and its attributes while a more detailed description of its methods and its behaviour is constructed later during the sub step fine grained statements summarization .
speci cally during this sub step are considered only the lines executed by each test case using the coverage information as base data to describe the cut behavior.
figure shows an example of summary in orange generated during the class level summarization phase for the class option.java .
with this summary the developer has the possibility to have a quick understanding of the cut the main class under test is option.
it describes a single option and maintains information regarding the option the long option the argument name the description of the option .a whether it has required whether it has optional argument the number of arguments the type the values and the separator of the option public class testoption overview the test case test0 covers around .
.b low percentage of statements in option test public void test0 throws throwable the test case instantiates an option with option .c equal to and description equal to 1w .
option option0 new option 1w then it tests whether the description of option0 is equal to .c 1w assertequals 1w option0.getdescription whether the key of option0 is equal to .c the execution of the method call used in the assertion .d implicitly covers the following conditions the condition option equal to null is false assertequals option0.getkey figure example of summary generated by testdescriber for a junit test method exercising the class options.java without reading all of its lines of code.
test method summarization.
this step is responsible for generating a general description of the statement coverage scores achieved by each junit test method.
this description is extracted by leveraging the coverage information provided by cobertura to ll a pre de ned template.
an example of summary generated by testdescriber for describing the coverage score is depicted in figure in yellow before each junit test method test0 in the example testdescriber adds a comment regarding the percentage of statements covered by the given test method independently from all the other test methods in testoption .
this type of description allows to identify the contribution of each test method to the nal structural coverage score.
in the future we plan to complement the statement coverage describing further coverage criteria e.g.
branch or mutation coverage .
fine grained statement summarization .
as described in section .
testdescriber extracts the ne grained list ofcode elements e.g.
methods attributes local variables composing each statement of the cut covered by each junit test method.
this information is provided as input to the fine grained statements summarization phase thus testdescriber performs the following three steps i parses all the instructions contained in a test method ii it uses the swum methodology for each instruction and determines which kind of operation the considered statement is performing e.g.
if it declares a variable it uses a constructor method of the class it uses speci c assertions etc.
and which part of the code is executed and iii it generates a set of customized natural language sentences depending on the selected kind of instructions.
to perform the rst two steps it assigns each statement to one of the following categories constructor of the class .
a constructor typically implies the instantiation of an object which is the implicit action verb with some properties parameters .
in this case our descriptor links the constructor call to its corresponding declaration in the cut to map formaland actual parameters.
therefore pre processing and pos tagger are performed to identify the verb noun phrase and adjectives from the constructor signature.
these linguistic elements are then used to ll speci c natural language templates for constructors.figure contains an example of a summary generated to describe the constructor option string string i.e.
the lines and highlighted in green .
method calls .
a method implements an operation and typically begins with a verb which de nes the main action while the method caller and the parameters determine theme and secondary arguments .
again the linguistic elements identi ed after pre processing and pos tagging are used to ll natural language templates speci c for method calls.
more precisely the summarizer is able to notice if the result of a method call is assigned as value to a local variable assignment statement thus it adapts the description depending on the speci c context.
for particular methods such as getters and setters it uses ad hoc templates that di er from the templates used for more general methods.
assertion statements .
this step de nes the test oracle and enables to test whether the cut behaves as intended.
in this case the name of an assertion method e.g.
assertequals assertfalse notequals etc de nes the type of test while the input parameters represent respectively i the expected and ii the actual behavior.
therefore the template for an assertion statement is de ned by the pre processed assertion name itself and the value s passed and veri ed as parameter s to the assertion.
figure reports two examples of descriptions generated for assertion methods where one of the input parameters is a method call e.g.
getkey the summary is reported in line and highlighted in green .
branch coverage summarization .
when a test method contains method constructor calls it is common that the test execution covers some if conditions branches in the body of the called method constructor.
thus testdescriber after the fine grained statements summarization step enriches the standard method call description with a summary describing the boolean expressions of the ifcondition.
therefore during the branch coverage summarization step testdescriber generates a natural language description for the tested ifcondition.
when an ifcondition is composed of multiple boolean expressions combined via boolean operators we generate natural language sentences for the individual expressions and combine them.
thus during the branch coverage summarization we adapt the descriptions when an if condition contains calls to other methods of the cut.
in the previous example reported in figure when executing the method call getkey line for the objectoption0 the test method test0 covers the false branch of the if condition if opt null i.e.
it veri es that option0 is not null.
in figure the lines and highlighted in red represent the summary generated during the branch coverage summarization for the method call getkey .
.
summary aggregation the information aggregator is in charge of enriching the original junit test class with all the natural language summaries and descriptions provided by the summary generator.
the summaries are presented as di erent block and inline comments i the general description of the cut is added as a block comment before the declaration of the test class ii the brief summaries of the statement coverage scores achieved by each individual junit test method is added as 550table java classes used as objects of our study pro ject class eloc methods branches co mmons primitives arrayintlist math4j rational block comments before the corresponding test method body iii the ne grained descriptions are inserted inside each test method as inline comments to the corresponding statements they are summarizing.
.
study design and planning .
study definition the goal of our study is to investigate to what extent the summaries generated by testdescriber improve the comprehensibility of automatically generated junit test cases and impact the ability of developers to x bugs.
we measure such an impact in the context of a testing scenario in which a java class has been developed and must be tested using generated test cases with the purpose of identifying and xing bugs if any in the code.
the quality focus concerns the understandability of automatically generated test cases when enriched with summaries compared to test cases without summaries.
the perspective is of researchers interested in evaluating the e ectiveness of automatic approaches for the test case summarization when applied in a practical testing and bug xing scenario.
we therefore designed our study to answer the following research questions rqs rq1 how do test case summaries impact the number of bugs xed by developers?
our rst objective is to verify whether developers are able to identify and xing more faults when relying on automatically test cases enriched with summaries.
rq2 how do test case summaries impact developers to change test cases in terms of structural and mutation coverage?
the aim is assessing whether developers are more prone to change test cases to improve their structural coverage when the summaries are available.
.
study context the context of our study consists of i objects i.e.
java classes extracted from two java open source projects and ii participants testing the selected objects i.e.
professional developers researchers and students from the university of zurich and the delft university of technology.
speci cally the object systems are apache commons primitives and math4j that have been used in previous studies on searchbased software testing .
from these projects we selected two java classes i rational that implements a rational number and ii arrayintlist which implements a list of primitive int values using an array.
table details characteristics of the classes used in the experiment.
eloc counts the e ective lines of source code i.e.
source lines without purely comments braces and blanks .
for each class we consider a faulty version with ve injected faults available from previous studies .
these faults were generated using a mutation analysis tool which selected the ve mutants faults more di cult to kill i.e.
the ones that can be detected by the lowest number of test cases .
these classes are non trivial yet feasible to test within an hour they do not require i to learn complex algorithms and ii to examine other classes in the same library .
to recruit participants we sent email invitations to our con table experience of participants pro gramming experience absolute frequency years .
years .
years .
years .
tacts from industrial partners as well as to students and researchers from the department of computer science at the university of zurich and at delft university of technology.
in total we sent out invitations developers and researchers .
in the end subjects performed the experiment and sent their data back see table .
of them were professional developers from industry and were students or senior researchers from the authors computer science departments.
all of the professional developers have more than seven years of programming experience in java one of them more than years .
among the subjects from our departments were bachelor s students were master s students phd students and senior researchers.
each participant had at least three years of prior experience with java and the junit testing framework.
.
experimental procedure the experiment was executed o ine i.e.
participants received the experimental material via an online survey platform11that we use to collect and to monitor time and activities.
an example of survey sent to the participants can be found online12.
each participant received an experiment package consisting of i a statement of consent ii a pretest questionnaire iii instructions and materials to perform the experiment and iv a post test questionnaire.
before the study we explained to participants what we expected them to do during the experiment they were asked to perform two testing sessions one for each faulty java class.
they could use the test suite i.e.
junit test cases generated by evosuite to test the given classes and to x the injected bugs.
each participant received two tasks i one task included one java class to test plus the corresponding generated junit test cases enriched with the summaries generated by testdescriber ii the second task consisted of a second java class to test together with the corresponding generated junit test cases without summaries.
the experimental material was prepared to avoid learning e ects each participant received two di erent java classes for the two testing tasks each participant received for the rst task test cases enriched with corresponding summaries while for the second task they received the cases without the summaries.
we assigned the tasks to the participants in order to have a balanced number of participants which test i the rst class with summaries followed by the second class without summaries and ii the rst class without summary followed by the second class with summaries.
since evosuite uses randomized search algorithms i.e.
each run generates a di erent set of test cases with di erent input parameters we provided to each participant di erent starting test cases.
before starting the experiment each participant was asked to ll in the pre study questionnaire reporting their programming and testing experience.
after lling in the questionnaire they could start the rst testing task by opening survey.pdf 551the provided workspace in the eclipse ide.
the stated goals were i to test the target class as much as possible and ii to x the bugs .
clearly we did not reveal to the participants where the bugs were injected nor the number of bugs injected in each class.
in the instructions we accurately explain that the generated junit test cases are green since evosuite as well as other modern test generation tools generate assertions that re ect the current behavior of the class .
consequently if the current behavior is faulty the assertions re ect the incorrect behavior and thus must be checked and eventually corrected .
therefore participants were asked to start reading the available test suite and to edit the test cases to eventually correct the assertions.
they were also instructed to add new tests if they think that some parts of the target classes are not tested as well as to delete tests they did not understand or like.
in each testing session participants were instructed to spend no more than minutes for completing each task and to nish earlier if and only if i they believe that their test cases cover all the code and ii the found and xed all the bugs.
following the experiment subjects were required to ll in an exit survey we used for qualitative analysis and to collect feedback.
in total the duration of the experiment was two hours including completing the two tasks and lling in the pre test and post test questionnaires.
we want to highlight that we did not reveal to the participants the real goal of our study which is to measure the impact of test case summaries on their ability to x bugs .
as well as we did not explain them that they received two different tasks one with and the other one without summaries.
even in the email invitations we use to recruit participants we did not provide any detail to our goal but we used a more general motivation which was to better understand the bug xing practice of developers during their testing activities when relying on generated test cases.
.
research method at the end of the experiment each participant produced two artifacts for each task i the test suite automatically generated by evosuite with possible xes or edits by the participants e.g.
adding assertions to reveal faults and ii the original xed target class i.e.
without some of the injected bugs.
we analyze the target classes provided by the participants in order to address rq1 for each class we inspect the modi cations applied by each participant in order to verify whether the modi cations are correct true bug xing or not.
thus we counted the exact number of seeded bugs xed by each participant to determine to what extent test summaries impact their bug xing ability.
forrq2 we computed several structural coverage metrics for each test suite produced when executed on the original classes i.e.
on the target classes without bugs .
speci cally we use cobertura to collect statement branch and method coverage scores achieved.
the mutation score was computed by executing the junit test suite using pit13 a popular command line tool that automatically seeds a java code generating mutants.
then it runs the available tests and computes the resulting mutation score i.e.
the percentage of mutants detected by the test suites.
as typical in mutation testing a mutant is killed covered if the tests fail otherwise if the tests pass then the mutation is not covered.
once we have collected all the data we used statistical arrayintlist rationaln.
fixed bugs with summaries without summariesfigure rq1 bugs xed with and without summaries.
tests to verify whether there is a statistical signi cant difference between the scores e.g.
the number of xed bugs achieved by participants when relying on tests with and without summaries.
we employed non parametric tests since the shapiro wilk test revealed that neither the number of detected bugs nor the coverage or mutation measures follow a normal distribution p .
hence we used the nonparametric wilcoxon rank sum test with a p value threshold of .
signi cant p values indicate that there is a statistical signi cant di erence between the scores e.g.
number of xed bugs achieved by the two groups i.e.
by participants using test cases with and without summaries.
in addition we computed the e ect size of the observed di erences using the vargha delaney a12 statistic .
the varghadelaney a12 statistic also classi es the obtained e ect size values into four di erent levels negligible small medium and large that are easier to interpret.
we also checked whether other co factors such as the programming experience interact with the main treatment test summaries on the dependent variable number of bugs xed .
this was done using a two way permutation test which is a nonparametric equivalent of the two way analysis of variance anova .
we set the number of iterations of the permutation test procedure to to ensure that results did not vary over multiple executions of the procedure .
parameter con guration.
there are several parameters that control the performance in terms of structural coverage for evosuite in addition there are di erent coverage criteria to optimize when generating test cases.
we adopted the default parameter settings used by evosuite since a previous empirical study demonstrated that the default values widely used in the literature give reasonably acceptable results.
for the coverage criterion we consider the default criterion which is branch coverage again similar to previous experiments .
the only parameter that we changed is the running time we run evosuite for ten minutes in order to achieve the maximum branch coverage.
.
results in the following we report results of our study with the aim of answering the research questions formulated in section .
.
rq1 bug fixing figure depicts the box plots of the number of bugs xed by the participants divided into the i target classes to x and ii the availability of testdescriber generated summaries.
the results indicate that for both tasks the number 552of bugs xed is substantially higher when to the participants had test summaries at their disposal.
speci cally from figure we can observe that for the class arrayintlist participants without testdescriber summaries were able to correctly identify and x out of bugs median value of injected bugs and no participant was able to x all the injected bugs.
vice versa when we provided to the participants the testdescriber summaries the median number of bugs xed is bugs and about of the the participants were able to x all the bugs.
this result represents an important improvement of bugs were xed by participants if we consider that in both the scenarios with and without summaries the amount of time given to the participants was the same.
similarly for rational when relying on test cases with summaries the median number of bugs xed is out of and of participants were able to x all the bugs.
vice versa using test cases without summaries the participants xed bugs median value .
hence when using the summaries the participants were able to x twice as many number of bugs with respect to the scenario in which they were provided test cases without comments.
the results of the wilcoxon test highlight that the use of testdescriber summaries signi cantly improved the bug xing performance of the participants in each target class achievingp values of and for arrayintlist and rational respectively which are smaller than the signi cance level of .
the vargha delaney a12statistic also reveals that the magnitude of the improvements is large for both target classes the e ect size is and for arrayintlist and rational respectively.
finally we used the two way permutation test to check whether the number of xed bugs between the two groups test cases with and without summaries depends on and interacts with the participants programming experience which can be a potential co factor.
the two way permutation test reveals that i the number of bugs xed is not signi cantly in uenced by the programming experience p values2f0 1372g and ii there is no signi cant interaction between the programming experience and the presence of test case summaries pvalues2f0 1351g .
this means that all participants bene t from using the testdescriber summaries independent of their programming experience.
this nding is particularly interesting if we consider that fraser et al.
reported that there is no statistical difference between the number of bugs detected by developers when performing manual testing or using automatically generated test cases to this aim.
speci cally in our study we included i two of the classes fraser et al.
used in their experiments arrayintlist and rational and for them we ii considered the same set of injected bugs and iii we generated the test cases using the same tool.
in this paper we show that the summaries generated by testdescriber can signi cantly help developers in detecting and xing bugs.
however a larger sample size i.e.
more participants would be needed to compare the performances of participants when performing manual testing i.e.
when they are not assisted by automatic tools like evosuite and testdescriber at all.
in summary we can conclude that rq1 using automatically generated test case summaries signi cantly helps developers to identify and x more bugs.table statistics for the test suites edited by the participants for arrayintlist v ariable factor min mean max p value a m ethod cov.
with .
.
.
.
without .
.
.
s tatement cov.
with .
.
.
.
without .
.
.
b ranch cov.
with .
.
.
.
without .
.
.
m utation score with .
.
.
.
without .
.
.
table statistics for the test suites edited by the participants for rational v ariable factor min mean max p value a m ethod cov.
with .
.
.
.
without .
.
.
s tatement cov.
with .
.
.
.
without .
.
.
b ranch cov.
with .
.
.
.
without .
.
.
m utation score with .
.
.
.
.
m without .
.
.
.
rq2 test case management to answer rq2 we verify whether there are other measurable features instead of the test case summaries the might have in uenced the results of rq1.
to this aim tables and summarise the structural coverage scores achieved by the test suite produced by human participants during the experiment.
as we can see from table there is no substantial di erence in terms of structural coverage achieved by the test suites produced by participants with and without test case summaries for arrayintlist .
speci cally method branch and statement coverage are almost identical.
similar results are achieved for rational as shown in table for method branch and statement coverage there is no di erence for the tests produced by participants with and without test summaries.
consequently for both the two classes the p values provided by the wilcoxon test are not statistically signi cant and the e ect size is always negligible.
we hypothesize that these results can be due to the fact that the original test suite generated by evosuite that were used by the participants as starting point to test the target classes already achieved a very high structural coverage in all the cases .
therefore even if the participants were asked to manage when needed the test cases to correct wrong assertions at the end of the experiment the nal coverage was only slightly impacted by these changes.
for the mutation analysis the mutation scores achieved with the tests produced by the participants seem to be slightly lower when using test summaries on average for array intlist .
however the wilcoxon test reveals that this di erence is not statistically signi cant and the varghadelaney a12measure is negligible.
for rational we can notice an improvements in terms of mutation score for the tests produced by participants who were provided with test summaries.
the wilcoxon test reveals a marginal statistical signi cant p value .
and the vargha delaney a12measures an e ect size medium and positive for our test summaries i.e.
participants provided test cases able to kill more mutants when using the test summaries.
a replication study with more participants would be need to further investigate whether the mutation score can be positively inuenced when using tests summaries.
rq2 test case summaries do not in uence how the developers manage the test cases in terms of structural coverage.
withwithout count very low low medium high very highfigure perceived test comprehensibility with and without testdescriber summaries.
.
discussion and lessons learnt in the following we provide additional qualitative insights to the quantitative study reported in section .
summaries and comprehension .
at the end of each task we asked each participant to evaluate the comprehensibility of the test cases either with or without summary using a likert scale intensity from very low to very high involving all the participants .
when posing this question we did not explicitly mention terms like test summaries but instead test comments to avoid biased answers by the participants.
figure compares the scores given by participants to the provided test cases i.e.
generated by evosuite according to whether the tests were enriched with or not without with summaries.
we can notice that when the test cases were commented with summaries with of participants labled the test cases as easy to understand high and very high comprehensibility with only of participants that considered the test cases as incomprehensible.
vice versa when the test cases were not enriched with summaries without only of participants judged the test cases as easy to understand while a substantial percentage of participants labeled the test case as di cult to understand.
the wilcoxon test also reveals that this di erence is statistical signi cant p value with a positive and medium e ect size .
according to the vargha delaney a12statistic.
therefore we can argue that test summaries statistically improve the comprehensibility of automatically generated test case according to human judgments.
post test questionnaire .
table reports the results to questions from the exit survey.
the results demonstrate that in most of the cases the participants considered the test summaries when available as the most important source of information to perform the tasks after the source code itself i.e.
the code of the target classes to x. indeed when answering q1 and q2 the most common opinion is that the source code is the primary source of information in q1 and of the opinions in q2 followed by the test summaries in q1 and in q2 .
in contrast participants deem the actual test cases generated by evosuite to be less important than i the test summaries and ii the test cases they created themselves during the experiment.
as con rmation of this nding we received positive feedback from both junior and more experienced participants such as the generated test cases with comments are quite useful and comments give me better and more clear table raw data for exit questionnaire sc source code tcs tc summaries tc test cases and mtc manually written tc .
q uestions sc tcs tc mtc other q what is the best source of information?
q can you rank the speci ed sources of information in order of importance from high to low ?
rank rank rank rank rank q uestionsdisagree agree f ully partial partially fully q adding or changing the tests leads to better tests?
q without comments tests are di cult to read and understand?
q adding assertions to tests with comments is prohibitively di cult?
q adding assertions to tests without comments is prohibitively di cult?
q i had enough time to nish my task q automatically generated unit tests exercise the easy parts of the program.
table raw data of the questionnaire concerning the evaluation of testdescriber summaries.
co ntent adequacy r esponse category p ercentage of ratings i s not missing any information.
m issing some information.
m issing some very important information.
co nciseness r esponse category p ercentage of ratings ha s no unnecessary information.
ha s some unnecessary information.
ha s a lot of unnecessary information.
ex pressiveness r esponse category p ercentage of ratings i s easy to read and understand.
i s somewhat readable and understandable.
i s hard to read and understand.
picture of the goal of a test.
from table we can also observe that participants mainly considered the tests generated by evosuite as a starting point to test the target classes.
indeed these tests must be updated e.g.
checking the assertions and enriched with further manually written tests q3 since in most of the cases they test the easier part of the program under tests according to of opinions for q8 .
automatically generated tests are in most of cases of participants considered di cult to read and understand q4 especially if not enriched with summaries describing what they are going to test q5 and q6 .
quality of the summaries .
finally we ask the participants to evaluate the overall quality of the provided test summaries similarly as done in traditional work on source code summarization .
we evaluate the quality according to three widely known dimensions content adequacy considering only the content of the comments of junit test cases is the important information about the class under test re ected in the summary?
conciseness considering only the content of the comments in the junit test cases is there extraneous or irrelevant information included in the comments?
expressiveness considering only the way the comments of junit test cases are presented how readable and understandable are the comments?
the analysis is summarized in table .
the results highlight that i of the participants consider the testdescriber comments adequate they do not miss very important information ii of them perceive the summaries su ciently concise as they contain no or only some unnecessary information iii of participants consider the comments easy to read and or somewhat readable.
in summary the majority of the participants consider the comments generated by testdescriber very concise and easy to understand.
feedback .
comments collected from the survey participants mentioned interesting feedback to improve testdescriber summaries redundant information from test to test developers of our study were concerned by the fact that for similar test cases testdescriber generates the same comments and as solution they suggested to generate for each assertion already tested in previous test methods a new inline comment which speci es that the assertion was already tested in a previous test method.
useless naming of test methods for several participants the name of the test does not give any hint about the method under test.
they suggest to i ...rename the method names to useful names... so that it is possible to see at a glance what is actually being tested by that test case or ii ...describe in the javadoc of a test method which methods of the class are tested.
.
lessons learnt .
as indicated in section .
test suites having high structural coverage are not necessarily more effective to help developers in detecting and xing more bugs.
most automatic testing tools consider structural coverage as the main goal to optimize for with the underlying assumption that higher coverage is strongly related to a test s effectiveness .
however our results seem to provide a clear evidence that this is not always true as also con rmed by the non parametric spearman correlation test the correlation between the number of bugs xed and the structural coverage metrics is always lower than for arrayintlist and for rational .
only the mutation score has a correlation coe cient larger than in both the two classes.
on the other hand the results of rq1 provide clear evidence that the summaries generated by testdescriber play a signi cant role even if they do not change the code and the structural coverage of the original test cases generated by evosuite.
therefore we can argue that comprehensibilityorreadability are two further dimensions that should be considered together with structural coverage when systematically evaluating automatic test generation tools.
.
threats to v alidity in this section we outline possible threats to the validity of our study and show how we mitigated them.
construct validity .
threats to construct validity concern the way in which we set up our study.
due to the fact that our study was performed in a remote setting in which participants could work on the tasks at their own discretion we could not oversee their behaviour.
the metadata sent to us could be a ected by imprecisions as the experiment wasconducted o ine.
however we share the experimental data with the participants using an online survey platform which forces the participants to perform tasks in the desired order and to ll in the questionnaires.
therefore participants only got access to the nal questionnaire after they had handed in their tasks as well as they could not perform the second task without nishing the rst one.
furthermore the online platform allows us to monitor the total time each participant spent on the experiment.
we also made sure participants were not aware of the actual aim of the study.
internal validity .
threats to internal validity concern factors which might a ect the causal relationship.
to avoid bias in the task assignment we randomly assigned the tasks to the participants in order to have the same number of data points for all classes treatments.
to ensure that a su cient number of data points are collected for statistical signi cance tests each participant performed two bug xing tasks one with test summaries and one without on di erent classes rather than one single task to produce data points in this study.
the two java classes used as objects for the two tasks have similar di culty and can easily be tested in minutes even for intermediate programmers .
another factor that can in uence our results is the order of assignments i.e.
rst with summaries and then without summaries or vice versa.
however the two way permutation test reveals that there is no signi cant interaction between the order of assignments and the two tasks on the nal outcome i.e.
the number of bugs xed p value .
external threats .
external threats concern the generalizability of our ndings.
we considered two java classes already used in two previous controlled experiments investigating the e ectiveness of automated test case generation tools compared to manual testing .
we also use the same set of bugs injected using a mutation analysis tool which is common practice to evaluate the e ectiveness of testing techniques in literature .
we plan to evaluate testdescriber with a bigger set of classes investigating its usefulness in the presence of more complex branches.
future work also needs to address which aspects of the generated summaries are useful.
is the coverage summary useful to developers and if so in what way?
another threat can be that the majority of our study participants have an academic background.
recent studies have shown that students perform similarly to industrial subjects so long as they are familiar with the task at hand .
all our student participants had at least years of experience with the technologies used in the study see section .
.
moreover our population included a substantial part of professional developers and the median programming experience of our participants is years.
nevertheless we plan to replicate this study with more participants in the future in order to increase the con dence in the generalizability of our results.
conclusion threats .
in our study we use testdescriber to generated tests summaries for junit test cases generated by evosuite.
it might be possible that using di erent automatic test generation tools may lead to di erent results in terms of test case comprehensibility.
however we notice that i coverage ii structure and iii size of test cases generated with evosuite are comparable to the output produced by other modern test generation tools such as randoop jcrasher etc.
we support our ndings by using appropriate statistical 555tests i.e.
the non parametric wilcoxon test and the two way permutation test to exclude that other co factors such as the programming experience can a ect our conclusion.
we also used the wilk shapiro normality test to verify whether the non parametric test could be applied to our data.
finally we used the vargha and delaney a12statistical test to measure the magnitude of the di erences between the di erent treatments.
.
related work in this section we discuss the related literature on source code summarization and readability of test cases.
source code summarization .
murphy s dissertation is the earliest work which proposes an approach to generate summaries by analysing structural information of the source code.
more recently sridhara et al.
suggested to use pre de ned templates of natural language sentences that are lled with linguistic elements verbs nouns etc.
extracted from important method signature .
other studies used the same strategy to summarize java methods parameters groups of statements java classes services of java packages or generating commit messages .
other reported applications are the generation of source code documentation summary by mining text data from other sources of information such as bug reports e mails forum posts and question and answer site q a discussions .
however binkley et al.
and jones et al.
pointed out that the evaluation of the generated summaries should not be done by just answering the general question is this a good summary?
but evaluated through the lens of a particular task .
stemming from these considerations in this paper we evaluated the impact of automatically generated test summaries in the context of two bug xing tasks.
in contrast most previous studies on source code summarization have been evaluated by simply surveying human participants about the quality of the provided summaries .
test comprehension.
the problem of improving test understandability is well known in literature especially in the case of test failures .
for example zhang et al.
focused on failing tests and proposed a technique based on static slicing to generate code comments describing the failure and its causes.
buse et al.
proposed a technique to generate human readable documentation for unexpected thrown exceptions .
however both these two approaches require that tests fail or throw unexpected java exceptions .
this never happens for automatically generated test cases since the automatically generated assertions re ect the current behaviour of the class .
consequently if the current behaviour is faulty the generated assertions do not fail because they re ect the incorrect behavior.
kamimura et al.
argued that developers might bene t from a consumable and understandable textual summary of a test case.
therefore they proposed an initial step towards generating such summaries based on static analysis of the code composing the test cases .
from an engineering point of view our work resumes this line of research however it is novel for two main reasons.
first of all our approach generates summaries combining three di erent levels of granularity i a summary of the main responsibilities of the class under test class level ii a ne grained de scription of each statement composing the test case as done in the past test level iii a description of the branch conditions traversed in the executed path of the class under test coverage level .
as such our approach combines code coverage and summarization to address the problem of describing the e ect of test case execution in terms of structural coverage.
finally we evaluate the impact of the generated tests summaries in a real scenario where developers were asked to test and x faulty classes.
understandability is also widely related with the test size and number of assertions .
for these reasons previous work on automatic test generation focused on i reducing the number of generated tests by applying a post process minimization and ii reducing the number of assertions by using mutation analysis or splitting tests with multiple assertions .
to improve the readability of the code composing the generated tests daka et al.
proposed a mutation based post processing technique that uses a domain speci c model for unit test readability based on human judgement.
afshan et al.
investigates the use of a linguistic model to generate more readable input strings.
our paper shows that summaries represent an important element for complementing and improving the readability of automatically generated test cases.
.
conclusion and future work recent research has challenged the assumption that structural coverage is the only goal to optimize suggesting that understandability of test cases is a key factor to optimize in the contest of automated test generation.
in this paper we handle the problem of usability of automatic generated test cases making the following main contributions we present testdescriber a novel approach to generate natural language summaries of junit tests.
testdescriber is designed to automatically generate summaries of the portion of code exercised by each individual test case to provide a dynamic view of the cut.
to evaluate testdescriber we have set up an empirical study involving human participants from both industry and academia.
speci cally we investigated the impact of the generated test summaries on the number of bugs actually xed by developers when assisted by automated test generation tools.
results of the study indicate that rq1 testdescriber substantially helps developers to nd more bugs twice as many reducing testing e ort and rq2 test case summaries do not in uence how developers manage test cases in terms of structural coverage.
additionally testdescriber could be used to automatically document tests improving their readability and understandability.
results of our post test questionnaire reveal that test summaries signi cantly improve the comprehensibility of test cases.
future work is directed towards di erent directions.
we plan to further improve testdescriber summaries by i considering the feedback received by the participants of our study ii combining our approach with recent work that improves the readability of the code composing the generated test iii complementing the generated summaries including further coverage criteria such as branch or mutation coverage.
also we aim to replicate the study involving additional developers.
556references s. afshan p. mcminn and m. stevenson.
evolving readable string test inputs using a natural language model to reduce human oracle cost.
in proceedings international conference on software testing veri cation and validation icst pages .
ieee .
a. arcuri and g. fraser.
parameter tuning or default values?
an empirical investigation in search based software engineering.
empirical software engineering .
d. athanasiou a. nugroho j. visser and a. zaidman.
test code quality and its relation to issue handling performance.
ieee trans.
software eng.
.
r. d. baker.
modern permutation test software.
in e. edgington editor randomization tests .
marcel decker .
l. baresi and m. miraz.
testful automatic unit test generation for java classes.
in proceedings of the international conference on software engineering volume icse pages .
acm .
m. beller g. gousios a. panichella and a. zaidman.
when how and why developers do not test in their ides.
in proceedings of the 10th joint meeting of the european software engineering conference and the acm sigsoft symposium on the foundations of software engineering esec fse .
acm .
to appear.
d. binkley d. lawrie e. hill j. burge i. harris r. hebig o. keszocze k. reed and j. slankas.
task driven software summarization.
in proceedings of the international conference on software maintenance icsm pages .
ieee .
f. p. j. brooks.
the mythical man month .
addisonwesley .
r. p. buse and w. r. weimer.
automatic documentation inference for exceptions.
in proceedings of the international symposium on software testing and analysis issta pages .
acm .
c. cadar v. ganesh p. m. pawlowski d. l. dill and d. r. engler.
exe automatically generating inputs of death.
in proceedings of the conference on computer and communications security ccs pages .
acm .
a. cavarra c. crichton j. davies a. hartman and l. mounier.
using uml for automatic test generation.
inproc.
of the international symposium on software testing and analysis issta .
springer verlag .
m. ceccato a. marchetto l. mariani c. d. nguyen and p. tonella.
do automatically generated test cases make debugging easier?
an experimental assessment of debugging e ectiveness and e ciency.
acm trans.
softw.
eng.
methodol.
.
s. chen h. miao and z. qian.
automatic generating test cases for testing web applications.
in proc.
of the international conference on computational intelligence and security workshops cisw pages .
b. cornelissen a. van deursen l. moonen and a. zaidman.
visualizing testsuites to aid in software understanding.
in proc.
european conference on software maintenance and reengineering csmr pages213 .
ieee .
l. f. cortes coy m. l. v asquez j. aponte and d. poshyvanyk.
on automatically generating commit messages via summarization of source code changes.
in proceedings of the international working conference on source code analysis and manipulation scam pages .
ieee .
c. csallner and y. smaragdakis.
jcrasher an automatic robustness tester for java.
softw.
pract.
exper.
.
b. dagenais and m. p. robillard.
recovering traceability links between an api and its learning resources.
inproceedings of the international conference on software engineering icse pages .
ieee .
e. daka j. campos g. fraser j. dorn and w. weimer.
modeling readability to improve unit tests.
inproceedings of the 10th joint meeting of the european software engineering conference and the acm sigsoft symposium on the foundations of software engineering esec fse .
acm .
to appear.
a. de lucia m. di penta r. oliveto a. panichella and s. panichella.
using ir methods for labeling source code artifacts is it worthwhile?
in ieee 20th international conference on program comprehension icpc passau germany june pages .
a. de lucia m. di penta r. oliveto a. panichella and s. panichella.
labeling source code with information retrieval methods an empirical study.
empirical software engineering .
g. fraser and a. arcuri.
whole test suite generation.
ieee trans.
software eng.
.
g. fraser and a. arcuri.
faults in projects automatically nding faults while achieving high coverage with evosuite.
empirical software engineering .
g. fraser m. staats p. mcminn a. arcuri and f. padberg.
does automated unit test generation really help software testers?
a controlled empirical study.
acm trans.
softw.
eng.
methodol .
to appear.
g. fraser m. staats p. mcminn a. arcuri and f. padberg.
does automated white box test generation really help software testers?
in proceedings of the international symposium on software testing and analysis issta pages .
acm .
g. fraser and a. zeller.
mutation driven generation of unit tests and oracles.
in proceedings of the international symposium on software testing and analysis issta pages .
acm .
s. haiduc j. aponte l. moreno and a. marcus.
on the use of automated text summarization techniques for summarizing source code.
in proceedings of the international working conference on reverse engineering wcre pages .
ieee .
m. hammad a. abuljadayel and m. khalaf.
automatic summarising the state of the art.
lecture notes on software engineering .
m. harman and p. mcminn.
a theoretical and empirical study of search based testing local global and hybrid search.
ieee trans.
softw.
eng.
.
e. hill z. p. fry h. boyd g. sridhara y. novikova l. pollock and k. vijay shanker.
amap automat557ically mining abbreviation expansions in programs to enhance software maintenance tools.
in proceedings of the international working conference on mining software repositories msr pages .
acm .
e. hill l. pollock and k. vijay shanker.
automatically capturing source code context of nl queries for software maintenance and reuse.
in proceedings of the international conference on software engineering icse pages .
ieee .
m. h ost b. regnell and c. wohlin.
using students as subjects comparative study ofstudents and professionals in lead time impact assessment.
empirical softw.
engg.
nov. .
m. kamimura and g. murphy.
towards generating human oriented summaries of unit test cases.
in proc.
of the international conference on program comprehension icpc pages .
ieee may .
s. macdonell.
reliance on correlation data for complexity metric use and validation.
acm sigplan notices .
p. w. mcburney and c. mcmillan.
automatic documentation generation via source code summarization of method context.
in proceedings of the international conference on program comprehension icpc pages .
acm .
b. meyer i. ciupa a. leitner and l. liu.
automatic testing of object oriented software.
in sofsem theory and practice of computer science volume oflecture notes in computer science pages .
springer berlin heidelberg .
l. moonen a. van deursen a. zaidman and m. bruntink.
on the interplay between software testing and evolution and its e ect on program comprehension.
insoftware evolution pages .
springer .
l. moreno j. aponte g. sridhara a. marcus l. pollock and k. vijay shanker.
automatic generation of natural language summaries for java classes.
in proceedings of the international conference on program comprehension icpc pages .
ieee may .
t. mortensen r. fisher and g. wines.
students as surrogates for practicing accountants further evidence.
in accounting forum volume pages .
elsevier .
g. c. murphy.
lightweight structural summarization as an aid to software evolution .
phd thesis .
aai9704521.
c. pacheco and m. d. ernst.
randoop feedbackdirected random testing for java.
in companion to the 22nd acm sigplan conference on object oriented programming systems and applications oopsla pages .
acm .
a. panichella f. kifetew and p. tonella.
reformulating branch coverage as a many objective optimization problem.
in proceedings of the international conference on software testing veri cation and validation icst pages .
ieee .
s. panichella j. aponte m. di penta a. marcus and g. canfora.
mining source code descriptions from developer communications.
in proceedings of the international conference on program comprehension icpc pages .
ieee .
f. ricca and p. tonella.
analysis and testing of web applications.
in proceedings of the international con ference on software engineering icse pages .
ieee .
j. m. rojas g. fraser and a. arcuri.
automated unit test generation during software development a controlled experiment and think aloud observations.
in proceedings of the international symposium on software testing and analysis issta pages .
acm .
p. runeson m. alexandersson and o. nyholm.
detection of duplicate defect reports using natural language processing.
in proc.
int l conference on software engineering icse pages .
ieee .
k. sp arck jones.
automatic summarising the state of the art.
inf.
process.
manage.
.
g. sridhara.
automatic generation of descriptive summary comments for methods in object oriented programs .
phd thesis newark de usa .
aai3499878.
g. sridhara e. hill d. muppaneni l. pollock and k. vijay shanker.
towards automatically generating summary comments for java methods.
in proceedings of the international conference on automated software engineering ase pages .
acm .
g. sridhara l. pollock and k. vijay shanker.
automatically detecting and describing high level actions within methods.
in proceedings of the international conference on software engineering icse pages .
ieee .
g. sridhara l. pollock and k. vijay shanker.
generating parameter comments and integrating with method summaries.
in proceedigs of the international conference on program comprehension icpc pages .
ieee .
p. tonella.
evolutionary testing of classes.
in proc.
of the international symposium on software testing and analysis issta pages .
acm .
a. vargha and h. d. delaney.
a critique and improvement of the cl common language e ect size statistics of mcgraw and wong.
journal of educational and behavioral statistics .
c. vassallo s. panichella m. di penta and g. canfora.
codes mining source code descriptions from developers discussions.
in proceedings of the international conference on program comprehension icpc pages .
acm .
c. wang f. pastore a. goknil l. briand and z. iqbal.
automatic generation of system test cases from use case speci cations.
in proceedings of the international symposium on software testing and analysis issta pages .
acm .
e. wong j. yang and l. tan.
autocomment mining question and answer sites for automatic comment generation.
in proceedings of the international conference on automated software engineering ase pages .
ieee .
j. xuan and m. monperrus.
test case puri cation for improving fault localization.
in proceedings of the international symposium on foundations of software engineering fse pages .
acm .
s. zhang c. zhang and m. ernst.
automated documentation inference to explain failed tests.
in proceedings of the international conference on automated software engineering ase pages .
ieee .