feedback directed instrumentation for deployed javascript applications magnus madsen university of waterloo waterloo ontario canada mmadsen uwaterloo.cafrank tip samsung research america mountain view ca usa ftip samsung.comesben andreasen aarhus university aarhus denmark esbena cs.au.dk koushik sen eecs department uc berkeley ca usa ksen cs.berkeley.eduanders m ller aarhus university aarhus denmark amoeller cs.au.dk abstract many bugs in javascript applications manifest themselves as objects that have incorrect property values when a failure occurs.
for this type of error stack traces and log les are often insu cient for diagnosing problems.
in such cases it is helpful for developers to know the control ow path from the creation of an object to a crashing statement.
such crash paths are useful for understanding where the object originated and whether any properties of the object were corrupted since its creation.
we present a feedback directed instrumentation technique for computing crash paths that allows the instrumentation overhead to be distributed over a crowd of users and to reduce it for users who do not encounter the crash.
we implemented our technique in a tool crowdie and evaluated it on real world issues for which error messages and stack traces are insu cient to isolate the problem.
our results show that feedback directed instrumentation requires to of the program to be instrumented that the same crash must be observed to times to discover the crash path and that feedback directed instrumentation typically slows down execution by a factor 2x 9x compared to 8x 90x for an approach where applications are fully instrumented.
.
introduction despite the best e orts of software engineers and testers software shipped to end users still contains bugs causing applications to crash or produce incorrect results.
failures that occur post deployment are often reported via on line error reporting facilities 1or in a bug reporting forum.
depending on the type of problem additional information may the work of these authors was carried out during internships at samsung research america.
1e.g.
windows error reporting or crashreporter .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa acm.
isbn .
.
.
.
available along with failure reports.
for example log les may exist that contain a summary of an application s execution behavior or a dump of an application s state at the time of a crash.
however such information is often of limited value because the amount of information can be overwhelming e.g.
log les may span many megabytes most of which is typically completely unrelated to the failure or is woefully incomplete e.g.
a stack trace or memory dump usually provides little insight into how an application arrived in an erroneous state .
many bugs that arise in javascript applications manifest themselves as objects that have incorrect property values when a failure occurs.
this includes situations where an object is created with incorrect or missing property values and where properties are corrupted after the object was created.
in such cases it is helpful for developers to know the controlow path from the creation of the object of interest to the crashing statement.
we will refer to such a path as a crash path.
in the case studies reported on in this paper we consider real life bugs where the error message and stack trace provided with a bug report are insu cient to nd and x the underlying cause of a bug.
in these case studies information contained in the crash path provided crucial hints to developers in a debugging scenario.
in principle crash paths could be obtained by instrumenting applications so that controlow is recorded as the program executes and exercising the application until the same failure is encountered.
unfortunately such a full instrumentation approach tends to incur prohibitive runtime overhead and is indiscriminate in that much of the instrumentation occurs in regions of the code unrelated to the failure.
furthermore in many cases developers do not need an entire execution history as much of it tends to be unrelated to the bug being pursued.
in this paper we present a feedback directed technique for computing crash paths in scenarios where the same failure can be observed repeatedly.
the technique relies on repeatedly deploying new versions of the application in which the amount of instrumentation is gradually increased to uncover successively longer su xes of the crash path.
this process continues until the complete crash path is found i.e.
the allocation site for the object of interest is found .
we believe that our technique is particularly well suited for a scenario where users collectively isolate crash paths associated with bugs in deployed software.
in the scenario we envision users ieee acm 38th ieee international conference on software engineering install applications from a central software repository e.g.
through an app store or a package manager .
when a crash is encountered by a user new versions of the application that contain additional instrumentation can be distributed to other users so that the e ort of isolating crash paths is distributed over a user population.
furthermore while our feedback directed instrumentation approach occurs signi cant overhead this tends to be up to an order of magnitude less than an approach where applications are fully instrumented.
similar crowdsourcing techniques for debugging were pioneered by liblit et al.
and by orso et al.
although they do not consider the speci c problem of computing crash paths.
we implemented the technique using jalangi and evaluated it on crashing executions of javascript applications available from github.
we report on instrumentation overhead and on the number of times that the same crash needs to be encountered to recover the complete crash path.
in summary the contributions are we propose the notion of a crash path as a supplement to error messages and stack traces.
a crash path records the path from the creation of an object of interest to a crashing statement.
we present a technique for computing crash paths based on feedback directed program instrumentation.
this technique identi es increasingly longer su xes of crash paths in successive executions of the application by gradually increasing the amount of instrumentation.
we implemented a prototype of our technique in a tool called crowdie and used it to debug real world issues previously reported on github.
our case study shows that error messages and stack traces are insu cient to debug these issues and that crash paths provide useful hints to developers debugging these issues.
our experimental evaluation shows that only to of the program is instrumented that the same crash must be observed between to times to recover complete crash paths and that the feedbackdirected instrumentation has a typical slowdown of 2x 9x compared to 8x 90x with full instrumentation.
furthermore we argue informally that our technique is well suited to a crowdsourcing scenario where the e ort of identifying crash paths is distributed over a user population.
.
motivating examples in this section we look at two real world bugs in popular javascript libraries.
what these bugs have in common is that traditional debugging information e.g.
the error message the line on which the crash occurs and the stack trace is insu cient to locate the root cause of the defect.
we will show how in each case the crash path provides information that is vital for understanding and xing the bug.
loki issue .
loki is a database written in javascript.
in issue entitled clearing collection breaks index 2a user reports that after clearing a collection i wasn t able to insert new objects without error.
such a report is typically not enough for the developer to reproduce the bug and locate its cause.
a stack trace which may be sent automatically to the server when a crash occurs may provide some hints but is also often insu cient.
to keep example simple imagine that we just try to execute the following four lines example1.js inspired by the text in the report which happen to be enough to encounter the error 1var db new loki example 2var col db.
addcollection omitted 3col .
clear 4col .
insert omitted running this code makes loki throw an exception with the following stack trace typeerror undefined is not a function at collection .add loki .js at collection .
insert loki .js at object .
anonymous example1 .js this stack trace tells us that the crash occurs at line inloki.js which is executed due to the call col.insert on line .
line in loki.js looks as follows this .
idindex .
push obj.id as there is only one function call on this line one can infer that this.idindex.push isundefined.
from this a developer may conclude that the value of this.idindex or its push property is incorrect.
to nd the root cause of the crash we need to know what is the value of this.idindex and why the push property is undefined.
was it never set or was it perhaps mistakenly overwritten?
we cannot answer these questions easily by inspecting the stack trace and source code.
we could use a tool such asgrep to search for this.idindex but such an approach is very crude and may match statements unrelated to the crash.
what we want to know is a where was the object referred to by this.idindex created and b how was the push property of this object modi ed in the time between its creation and the crash.
our crowdie tool computes this information automatically.
applying crowdie to this program reveals that the object referred to by this.idindex originates from line in loki.js this .
idindex at this point the root cause becomes clear this line assigns the idindex property with an empty object instead of an empty array .
arrays have a push method whereas ordinary objects do not which causes the expression this.idindex.push to evaluate to undefined and calling the push method on undefined results in the exception being thrown.
crowdie also reveals that no writes to the push property of the object occur before the crash.
upon realizing this problem a project maintainer xed the issue3by assigning an array instead of an object to this.idindex on line of loki.js.
to nd this problem using crowdie this.idindex is designated as an object of interest.
then crowdie produces the following crash path shown simpli ed here details of the path format are described in section .
and details about the actual path for this bug appear in table start loki.js this.idindex return example1.js col.clear call example1.js col.insert .. call loki.js this.add doc crash loki.js this.idindex.push obj.id with this information the developer would be able to quickly identify the buggy assignment on line .
3commit 5da46aeecda6046f738c6a612c2f181b21487108 900immutable issue .
immutable is a javascript collection library created by facebook.
in issue entitled subcursor cursor.cursor a returns improper type a user reports that the cursor method may return the wrong type of cursor.
the following code fragment example2.js reported by the user is a highly simpli ed version of the actual application code that triggers the bug 1var data immutable .
fromjs a 2var cursor cursor .
from data 3var deepcursor cursor .
cursor a 4assert deepcursor instanceof indexedcursor in this example the stack trace only tells us that the assertion on line fails error assertionerror at object .
anonymous example2 .js we see that the value of deepcursor returned by the call tocursor.cursor has the wrong type causing the assertion to fail.
however it is not obvious whether the call cursor.from data on line or the call cursor.cursor a on line is at fault.
at this point we ask crowdie to nd where the erroneous deepcursor object was allocated and by what path it reached the assertion.
in response crowdie produces the following crash path start cursor.js ..new cursorclass r k c s return cursor.js return makecursor return cursor.js ..subcursor this s return example2.js ..cursor.cursor a crash example2.js assert deepcursor .. this crash path shows that the object was created on line in function makecursor incursor.js which looks as follows 236function makecursor r k c value if arguments .
length value r. getin k var s value value .
size var cursorclass iterable .
isindexed value ?
indexedcursor keyedcursor return new cursorclass r k c s looking at this code we see that an object with the wrong type could be allocated for two reasons function isindexed is buggy or value somehow has an incorrect value.
we also note that makecursor implements overloading by checking the number of arguments on line .
the crash path produced by crowdie not only tells us that the object originated from line but also provides information about the call stack when this object was created.
this call stack can be obtained by observing that return labels on the produced path must have had matching calls that occurred earlier.
from this call stack we learn that makecursor was invoked by subcursor 249function subcursor cursor k value return makecursor cursor .
rootdata newkeypath cursor .
keypath k cursor .
onchange value crucially we observe that subcursor always passes four arguments to makecursor on line and that the fourth value is an argument to subcursor itself.
since it always passes four arguments the condition on line will always evaluate to false when called from subcursor.
furthermore our tool tells us that subcursor in turn was called by keyedcursorprototype.cursor .
the calling code of that function looks as follows .. subcursor this s here we can see that subcursor is passed two arguments even though it has three parameters so the third parameter will take on a default value of undefined.
the subcursor function in turn calls makecursor with this parameter which checks if it received four arguments instead of checking if the fourth argument has the default value undefined!
the core issue is thus that makecursor implements an overloading check in a way that subcursor did not anticipate.
the x5for the issue is to change the overloading check in line to value undefined .
these examples demonstrate how crowdie can provide information that is vital for understanding and xing bugs especially in cases where the error message and stack trace of a crash provides insu cient information.
note that crowdie is not a fully automated debugging process a nontrivial amount of human ingenuity may still be needed.
however in both cases the crash path was su cient to debug the issue.
in particular the typically much longer full execution path from the start of the application was not needed.
here we have presented the crash paths as plain text but we can imagine a scenario where ides naturally show the paths and allow the programmer to jump forwards and backwards through the statements on the path.
.
technique a high level architecture of the kind of system in which we envision our technique to be embedded is depicted in figure .
we assume a distribution model where users shown on the left install their applications through a central server shown on the right .
for example in the case of client side web applications the server is responsible for sending the javascript code to the users.
as another example in the case of a server side application the group of users may consist of a cluster of servers running the application.
finally we envision that app stores for mobile or non mobile devices could be extended with the techniques presented in this paper.
to make this practical an approach to feedbackdirected instrumentation would be required that does not require pushing out new versions to users frequently.
the latter could be accomplished by having selected parts of the instrumentation in an application be enabled or disabled based on an instrumentation policy that it periodically receives from the server.
the server in figure has several components including an instrumentor component for instrumenting applications according to an instrumentation policy that speci es the functions that need to be traced.
it also contains an analyzer component that decides which functions should be instrumented based on an analysis of traces of crashing executions that it receives from users and produces an instrumentation policy accordingly.
in the scenario we envision the instrumentation policy is updated repeatedly each time the same failure is encountered.
5commit 91afb4100eaed6375ceba239ad624a4453684429 901instrumented application instrumentor users analyzer developer complete crash pathoriginal application instrumentation policy serverpartial crash pathfigure a central server deploys instrumented versions of the program to its users.
crashing users report information back to the server.
as users execute the application some of them will inevitably encounter a crash e.g.
an uncaught exception an assertion failure a suspicious operation or a security policy violation .
when this happens the added instrumentation ensures that a crash path is recorded that re ects the set of functions speci ed in the instrumentation policy.
this crash path identi es at least in what function the crash occurred and what local and global variables may be relevant to the crash see section for more details .
the instrumentation ensures that this crash path is uploaded to the analyzer component of the server which in response updates the instrumentation policy accordingly.
note that in general the crash paths that users upload to the server are partial crash paths in the sense that they may not contain the full ow of control from the allocation of an object to the point where the crash occurred.
however when the analyzer component determines that a bug was localized because the crash path is complete the complete crash path is passed to the developer and all instrumentation is disabled for the entire user population.
various features can be added to the architecture discussed above.
for example the server can be con gured to trace multiple bugs concurrently and these e orts can be crowdsourced over di erent subsets of the user population.
furthermore the server can compare crash paths for di erent bugs that it is tracking concurrently try to determine when they are duplicates and prefer the shortest candidate.
.
execution paths the grammar shown in figure de nes the structure of execution paths constructed by our technique.
an execution pathp path is a sequence of labels that are recorded during program execution.
we capture intra procedural controlow using the three labels intra branch s c divides.alt0 start s divides.alt0 crash s the branch s c label records the value of a conditional c in an iforwhile statement s. the start s label records that the object of interest originates from statement s. the crash s label records the statement swhere the program crashed.
we use heuristics to determine the object s of interest in an a crashing statement.
for example if the statement o.f crashes because o.fisundefined then the object ois of interest.
on the other hand if the statement crashes because o.fis not a function then o.fis of interest.
we de ne similar heuristics for other types of statements.
we say that an execution path that begins with a start label and ends with a crash label is a crash path .
intu intra branch s c divides.alt0 start s divides.alt0 crash s v inter call s f divides.alt0return s divides.alt0 enter f divides.alt0exit f label intra divides.alt0inter p path label uni22ef label f fun the set of functions in the program s stm the set of statements in the program figure grammar for execution paths.
itively a crash path identi es a statement where an object was created and a sequence of controlow decisions leading to a crash where that object was somehow involved.
a path that ends with the crash label but does not begin with the start label is a partial crash path.
inter procedural controlow is tracked using four labels inter call s f divides.alt0return s divides.alt0enter f divides.alt0exit f the call s f label records a function invocation from call sitesto function f. the return s label records the completion of a call at statement s. the enter f label records that the controlow has entered function f. the exit f label records that the controlow has left function f. intuitively the call return labels represent a function invocation as seen from the caller whereas the enter exit labels represent a function invocation as seen from the callee.
the reason for requiring both is that our technique does not instrument every function and thus to observe whether or not calls are missing from a trace we must record information inside both the caller and the callee.
in particular an execution path that has the labels call s f enter f exit f return s is complete because it records the invocation of ffrom s the execution inside fand the return of control to s. on the other hand the execution path call s f return s which lacks the enter and exit labels records a call to an uninstrumented function f iffwas instrumented then its execution would have generated the appropriate enter exit labels .
we will discuss in section .
how this information is used to determine whether a crash path is complete.
example i. consider the code fragment of figure and the execution path that is generated when fis invoked with the arguments x y and o the empty object for this example execution crashes when line is reached because o.missingmethod has the value undefined at that point and any attempt to call undefined as a function results in a crash.
the full crash path6is start s1 call s f enter f uni2926 branch s true branch s true crash s5 example ii.
in the example of figure the crash happened due to the arguments passed to fand a stack trace would contain all neccessary information to debug the issue.
however this is not always the case as illustrated by the program of figure .
for this example the crash path is start s9 branch s true exit f uni2926 return s branch s true crash s15 6we will use the notation slwhere lis some line number in this example and subsequent examples to identify the program construct at line l. 9021var empty 2function f x y o if x if y o. missingmethod 7f empty figure example i.
8function f x var o if x return o 13var o f 14if ?
o. missingmethod figure example ii.
16var x 17function f g 18function g h j k 19function h i 20function i 21function j x empty object 22function k l m 23function l 24function m x. missingmethod 25f figure a javascript program.
note that the path begins inside function fwhen the object ois created on line and that it includes the branch choices made until the crash at line .
anything that occurred prior to that time is not part of the crash path.
in particular the crash path does not record the initial call andenter labels forf but it does record the exit and return labels since they occurred after the object was created.
.
feedback directed instrumentation figure shows a small program that we will use to illustrate our feedback directed instrumentation approach.
in this example the function fis called by top level code and invokes g. this function in turn invokes h j and k. the call to hinvokes i. function jcreates an empty object and assigns it to variable x. the call to kinvokes land m. inside ma crash occurs due to a missing method on x. our goal is to discover the crash path beginning with the creation of the empty object inside jand ending with the crash inside m. we could discover such paths by instrumenting the entire program but that would be costly.
instead we propose to perform instrumentation of the program in a feedback directed manner where we gradually instrument more functions until the complete crash path is discovered.
the intuition behind our approach is that instrumentation is performed in a breadth rst manner starting backwards from the function in which the crash occurs.
figure illustrates this concept.
initially the crash is observed to occur inside m which causes mto be instrumented.
the next time the crash is seen it is observed that mwas called from k so kis instrumented as well.
since kcontains two call sites its execution will produce a path that includes two call labels labeled k1and k2in figure .
in the third iteration kand mare instrumented and calls from gtokand from ktolare observed.
in the fourth iterk1 l g1 h m f i j g2 g3 k2figure control ow for the program in figure .
the object is created inside function j. the crash occurs inside function m. the crash path is shown in dashed red lines.
ation g k l and mare instrumented and calls to hand jare observed.
in the fth and nal iteration functions f g h j k l and mare instrumented.
now jis instrumented and each object that is allocated inside a function is tagged with a special property recording where it was created.
when the crash occurs the instrumentation discovers that this property is set and reports the crash path start j return g uni22ef call k m crash s24 this path is highlighted in figure using dashed red lines .
note that the path does not include any controlow that happened prior to entering j. in the end f g h j k l and mhave been instrumented whereas function iand the top level code are left uninstrumented.
this feedback directed process continues until the creation site of the object is discovered.
in the worst case the entire program may end up being instrumented including functions whose execution was irrelevant to the observed crash e.g.
function hin the example .
however as we shall see in section it is often the case that only a small fraction of the code is instrumented in practice.
a limitation of the technique is that it cannot locate the source of uninitialized variables and elds since the absence of data ow cannot be attributed to any particular statement in the program.
.
algorithm we now present a high level description of our algorithm for feedback directed instrumentation.
a key challenge in computing crash paths in a feedback directed manner is dealing with situations where fragments of a path are missing because functions are called that have not been instrumented yet.
for example assume we have a situation where an instrumented function finvokes an uninstrumented function g. this gives rise to a path like uni22ef call s g return s uni22ef note that since gis not instrumented no enter exit labels are generated for it.
such a path is incomplete and indicates thatgshould be instrumented in the next iteration.
figure shows our algorithm as a function that takes one argument s the statement where the crash occurred.
we maintain the last seen execution path in variable pand the set of instrumented functions in i. initially the path contains only the crash label.
we then repeatedly instrument and execute the program until a crash occurs.
the outer 903feedback directed instrumentation s stm 1varp path crash s the current path 2vari p fun s fun instrumented functions 3repeat foreach label lon path p instrument callee ifl call s f instrument caller ifl enter c f repeatedly execute the program until a crash occurs p the path recorded in the last execution ifp is a partial crashing path that matches p p p a longer path has been found 13until pbegins with a start label and contains a matching enter label for each call label 14return p report the crashing path to the developer figure pseudo code for the algorithm.
loop terminates once we have found a complete crash path by checking that pbegins with a start label and contains a matching enter label for each call label.
inside the loop we perform two actions i adding instrumentation for uninstrumented callers and callees based on the last observed partial crash path and ii repeatedly execute the program until the same crash is encountered i.e.
deploy a new instrumentation policy and wait for a user to encounter the crash again we say that two crashes are the same if their crash paths match.
formally a crash pmatches another crash path p if the sequence of labels in pcan be obtained by removing from p any labels that do not occur in p. we use a slightly extended version of the enter label in figure .
speci cally enter c f represents both function fbeing entered and its caller c. this is necessary in cases where a callee is instrumented but not its caller.
our implementation obtains a function s caller by runtime inspection of the stack via the special javascript caller property.
discussion.
our algorithm assumes that the same crash path is encountered repeatedly by users su ently many times to localize the error.
for high priority bugs that occur only once or rarely the instrumentation overhead associated with tracking such bugs should remain low because the crash path will remain short unless the same bug is encountered repeatedly.
thus we expect our technique to have reasonable performance characteristics.
however one could easily imagine a scenario where the techniques presented in this paper are deployed only on high priority bugs that have been seen a certain number of times to avoid introducing overhead due to bugs that occur only rarely.
in each iteration of the algorithm at least one additional function is instrumented so the algorithm is guaranteed to terminate.
in the worst case this may result in the entire program being instrumented.
.
events until now we have assumed that the controlow in a program is determined by the usual intra procedural constructs if while for ... together with inter procedural calls and returns.
however in the case of javascript we must also consider asynchrony and events.
in an event based program event listeners also commonly referred to as callbacks are registered and executed in response to certain events e.g.
the completion of a network request.
for such programs the call stack does not contain information about what happened prior to the execution of the current event listener.26var cache 27var net require net 28var server net .
createserver function c if cache .
data .
length !
c. write cache .
data 33server .
listen function fs.
readfile a. txt function err data cache .
data data figure an event driven node.js program.
figure shows an example of an event driven node.js application.
this program contains a subtle race condition that may cause an exception.
in particular there is no guarantee that the initialization of the cache.data property by the function declared on line will take place before this property is accessed inside the function declared on line .
if the access takes place before the initialization anundefined de reference error will occur on line .
applying our technique to such an execution of this program would reveal the following crash path start s26 uni22ef enter f33 uni22ef exit f33 uni22ef uni2926 enter f28 uni22ef crash s29 which shows that the listener function on line was executed but the listener function on line was not.
from this a developer can infer that the cache.data eld was uninitialized on line and that the code should be changed so that the initialization is guaranteed to happen.
accurate tracking of event listeners presents a minor challenge for our technique since an event listener is invoked without any corresponding call site in the source code.
fortunately event listeners are only executed when the call stack is empty and they maintain the stack discipline.
to capture controlow due to event listeners we instrument every node.js function that may cause the registration of a listener.
for example in figure the node.js functions net.createserver server.listen and fs.readfile are instrumented to record that the functions declared on lines and are event listeners.
with this knowledge we can detect which event listeners were and were not executed when a crash occurs.
once we know the relevant event listeners we instrument them as well as the functions where they were registered.
in the example we discover that event listeners declared on lines and were executed.
thus the registration sites net.createserver and server.listen are relevant so their containing function will be instrumented.
this allows the technique to trace control ow backwards through event listeners.
in general many similar executions may exist in which event handlers are scheduled in di erent orders.
in its current form our technique does not attempt to identify and exploit similarities between executions.
for example consider a scenario where a failing execution involves a sequence of event handlers f g and another involving a sequence f h g where event handler his unrelated to the failure.
in such cases it may be preferable to focus only on the crash path for the former execution because it omits information unrelated to the failure.
in principle our technique can be extended to give priority to executions in which the fewest number of event listeners is executed before a crash.
.
implementation we have implemented our technique using the jalangi instrumentation framework in a tool called crowdie .
overall structure.
the implementation splits the technique into two phases.
in the detection phase the program is instrumented to assign every function object a unique identi er and a global error handler is installed.
this handler catches any thrown exception that reaches the top level and records in which function the exception was thrown.
the detection phase also determines which event listeners if any were executed before the crash.
the detection phase is run repeatedly until an exception is encountered.
its runtime overhead is negligible since only one instruction per function declaration is added.
a separate isolation phase implements the feedback directed technique of section .
.
only the last labels are tracked to prevent the crash path from growing too large.
instrumentation details.
figure presents some of the instrumentation rules used in our tool.
here we aim to be informal and do not describe the ner details of the transformations used and just sketch their overall structure.
more details can be found in the original paper on the jalangi instrumentation framework .
a conditional statement labeled sis instrumented to record the branch label lines .
lines show how a function call sis instrumented to record call and return labels.
likewise lines show how a function declaration fis instrumented to record the enter and exit labels7.
finally an object creation statement sis instrumented to record the length of the path at the moment of creation lines .
this means that every object created inside a function selected for instrumentation knows its o set inside the path.
in addition to these instrumentation steps we assume that the program contains a special crash o function call where ois the object of interest.
this call is intercepted by the instrumentation and generates the crash s label but it also checks if path offset is set to the object o. if so the origin of ohas been found and the start label is inserted at the o set.
if not we have not yet instrumented the function in which the object was created and no start label is generated.
other javascript features.
our tool implements the technique of section .
as well as the mechanisms related to event handling discussed in section .
.
features such as exceptions getters and setters and native functions require additional support and can be added with modest e ort.
support for these features is in progress but has not been needed in any of the case studies discussed in section and we did not exclude any candidate programs due to lack of feature support .
.
evaluation the evaluation of our technique aims to answer the following research questions q1 how useful are the crash paths computed by our tool for understanding and xing real bugs?
7in reality this instrumentation is more complicated since thebody may contain multiple exit points e.g.
explicit return statements or exceptional controlow which must be taken into account by the instrumentation.38s if e s1 else s2 var c e rec branch s c if c s1 else s2 42s f rec call s f f rec return s 44f function body function rec enter f body rec exit f 48s new object var tmp new object tmp .
path offset ... figure instrumentation rules.
q2 how many times must a crash be observed before the crash path has been found?
q3 how much runtime overhead is incurred by users of our tool for computing crash paths?
the rationale behind q1 is to determine whether the information computed by our tool is useful for debugging particularly in cases where the information contained in error messages and stack traces is insu cient.
the purpose of q2 is to determine if the number of times that a bug needs to be encountered is reasonably low.
this is relevant because if the same crash path needs to be encountered many times by di erent users then the usefulness of the technique would be limited to bugs that occur very often.
lastly q3 aims to determine whether runtime overhead is acceptable.
.
experimental methodology crowdie produces information that is intended to assist developers with debugging but manual e ort remains required in diagnosing the problem.
therefore we opt for an evaluation based on case studies in which we apply our tool to real bugs in open source programs taken from github.
for these programs we compute crash paths with our tool manually inspect these crash paths to determine whether they are helpful q1 and measure various aspects of the tool s execution behavior to answer q2 and q3.
selection criteria.
we chose subject programs by looking at bug reports for popular javascript projects on github.
these applications had to satisfy some limitations of our implementation a the program did not make use of eval and b the program was runnable on node.js version .
.
furthermore we required that the reported bug could be reproduced with modest e ort and that the reported issue had an identi able place in the source code where the problem was observable i.e.
a crash caused by an exception being thrown an assertion failure or an incorrect returned value .
lastly we excluded easy bugs where the bug was local to the same function in which the crash occurred i.e.
situations where the line number in an error message or in a stack trace would su ce to diagnose the problem quickly.
subject programs and issues.
for triggering the bug of interest we use small bug triggering examples provided in the bug reports as seen twice in section .
this creates a much simpler scenario than the one crowdie is intended to be used in but no bug reports describe a complete scenario where the bug is encountered in a production environment.
each bug reporter has spent time manually creating these 905program and issue instrumentation recorded path program issue lines func.
iterations func.
length lines func.
alasql v0.
.
bucket js v1.
esprima v2.
esprima v1.
esprima v2.
immutable v3.
.
immutable v3.
.
loki v1.
loki v1.
redis v0.
.
table summary of main results from the case study.
performance benchmarks unit tests program issue tests orig.
partial instr.
full instr.
tests orig.
partial instr.
full instr.
alasql v0.
.
s s 2x s 20x 15s s 3x s 11x esprima v2.
s s 8x s 8x s s 17x s 19x esprima v1.
s s 7x s 8x s s 12x s 14x esprima v2.
s s 8x s 8x s s 15x s 17x immutable v3.
.
s s 5x s 121x s s 3x s 84x immutable v3.
.
s s 60x s 120x s s 29x s 104x loki v1.
s s 9x s 90x s s 4x s 5x loki v1.
s s 1x s 90x s s 3x s 5x table summary of performance results.
small examples before the reporting the bug crowdie could potentially alleviate the need for this manual work.
the leftmost four columns of table identify the selected subject programs and their associated bug reports all taken from github .
each row in the table corresponds to one bug report and one debugging scenario.
the program column shows the name of the application library the issue column shows the number assigned to the bug report.
the lines and functions columns show the number of lines in the source code including whitespace and comments and the total number of function declarations respectively.
alasql is a javascript sql database.
buckets is a data structure library.
esprima is a javascript parser.
immutable is a collection library.
loki is a javascript database.
redis is a redis client for javascript.
the bugs include incorrectly returned objects eld values that are inadvertently corrupted incorrect controlow due to argument passing and various type related errors.
process.
in the case studies we used the following step process for diagnosing a bug report using our tool run the program and observe that a crash occurs manually identify the function and line which caused the crash manually select a subset of relevant local and global variables related to the function and line of interest frequently only a single variable was selected .
in the fully automated scenario the variables would be selected by heuristics as discussed earlier run our tool with the given line and variables as input to compute a crash path manually understand and debug the issue using the computed crash path.
in some cases the crash was caused by an exception that was thrown from a generic error handling function.
in such cases we followed the above steps except that we focused on the previous function on the call stack.
.
experiments we now discuss the results obtained by running our tool.
quantitative results instrumentation and paths.
the columns under the header instrumentation in table show some key characteristics of our feedback directed instrumentation method.
the column iterations shows the number of times the same bug had to occur for the technique to nd the complete crash path.
moreover the column functions shows the number of functions instrumented by the technique in its nal iteration both as an absolute number and as a percentage of the total number of functions.
for example for esprima issue executions were required before the complete crash path was found plus one execution to detect the crash in the rst place.
the columns under the header recorded path report characteristics of the complete crash path found by the technique.
here the column length reports the length of the crash path i.e.
the total number of labels and the column func.
counts the number of functions on the crash path.
regarding the last metric recall that a function might be instrumented although it is not on the crash path so it is interesting to see whether the technique instruments many functions unnecessarily.
returning to esprima issue during the last iteration functions where instrumented corresponding to of the total number functions in the program.
finally the crash path contained labels distributed over source code lines in functions corresponding to only of the total number of functions.
looking at labels might seem like a daunting task for a programmer but multiple labels can be present on each of the source code lines e.g.
in the case of loops and some labels are implied by others e.g.
call enter .
thus the programmer has to look at signi cantly fewer statements labels.
906quantitative results performance.
column func.
under the heading instrumentation in table shows the number and percentage of functions instrumented in the nal iteration by the feedback directed technique.
only between and of functions are ultimately instrumented suggesting good potential for performance improvement compared to full instrumentation.
to measure actual impact on runtime performance we exercised the programs using benchmarks and unit tests available in the source repositories.
table shows the results.
starting with the performance benchmarks the row for alasql issue shows that the benchmark program contained di erent executions and the original program took seconds to execute them all.
using our feedbackdirected approach functions are instrumented see table resulting in a total running time of seconds i.e.
a slowdown by a factor 2x.
in contrast running the benchmark with full instrumentation took seconds i.e.
a factor 20x overhead.
continuing alasql s unit test suite comprises individual tests which took seconds to run originally this was 3x slower with feedback directed instrumentation and 11x slower with full instrumentation.
for the three esprima issues there is negligible di erence in performance between feedback directed and full instrumentation.
for the remaining programs there are signi cant di erences ranging from .1x to 121x.
in general the performance benchmarks show a larger performance di erence than the unit tests when comparing partial and full instrumentation.
we postulate this is because the unit tests cover a broad range of functionality and exercise the code more evenly including the instrumented code whereas the benchmark programs presumably exercise only performance critical components of the code that may avoid instrumentation with our technique.
we investigated why our technique worked so poorly for esprima.
we found that esprima is divided into two components a lexer and a parser.
in each case an unexpected token was generated by the lexer and then caused a crash in the parser.
the problem was not the actual token itself but the controlow that followed.
regardless this architecture and the tight connectedness of the parser itself meant that large parts of the program were ultimately instrumented.
the buckets and redis programs were not included in table since they had no performance benchmark suites.
in summary if we exclude the best and worst running times for both techniques then feedback directed instrumentation has a typical overhead of between 2x 9x compared to an overhead of 8x 90x for full instrumentation.
usefulness.
we previously discussed two of our case studies in section that illustrated how it can be useful to know where an object was allocated what the call stack looked like during that allocation and what properties were not written since that allocation.
space limitations keep us from discussing the remaining case studies in detail but they cover similar and more complex issues.
in each case the crash path provides crucial information about object allocation and initialization the call stack structure at points of interest and the presence or absence of writes to a property of interest.
in each case some amount of human ingenuity remains necessary but we believe that the crash paths computed by crowdie would be helpful for developers.
in particular the size of the code base that developers need to consider is greatly reduced by allowing them to focuson only the source lines in the crash path these reductions can be seen in table .
a detailed analysis of each of these case studies can be found in a technical report .
.
summary of results we can now answer the research questions stated earlier.
q1.
the crash paths computed by crowdie can provide useful assistance to developers but by themselves are not a panacea some amount of human ingenuity remains necessary to complete the debugging task.
q2.
in our case studies between and iterations executions were needed to discover the crash path.
this is a relatively low number suggesting that our technique may be generally useful for widely deployed software except for bugs that are very rarely encountered.
q3.
the typical runtime overhead of the feedback directed instrumentation in crowdie ranges from 2x 9x.
while this is often dramatically better than the overhead of full instrumentation 8x 90x work remains to be done on making the instrumentation more e cient.
furthermore as the results for esprima suggest the architecture of certain applications may make them unsuitable candidates for the technique.
.
threats to validity we selected our subject programs based on issues reported on github.
while these programs are widely used they may not be representative of all programs and likewise the reported bugs that we investigated may not be representative either.
furthermore we selected bug reports that involved crashes thrown exceptions assertions errors ... but not every bug necessarily manifests itself as a crash.
when we debugged these issues we had no prior knowledge of the program.
thus it is possible that a developer familiar with source code might have debugged the program di erently.
on the other hand the debugging scenario we faced with no prior knowledge of the codebase is the hardest possible.
another valid concern is that the experiments are all based on small snippets of code that trigger the bugs.
these scenarios may di er from real life deployment scenarios for which the results could be very di erent from the ones we report here.
these more complex scenarios might require longer crash paths and make crowdie more expensive to use but extra complexity will also make the partial instrumentation of crowdie even more tractable compared to naive full instrumentation.
.
related work numerous techniques have been developed to support debugging.
a key property of our approach is that it helps obtaining critical information about failures that occur in deployed javascript programs.
this setting is particularly well suited for crowdsourced analysis that collects data from user executions since it is easy to deploy new instrumentation policies.
although we focus on errors that manifest as uncaught exceptions in the javascript programs our technique works more generally for example also when debugging assertion failures errors related to suspicious coercions and other bad coding practices or dom related faults .
record and replay techniques.
the ability to record and replay failing executions is valuable for debugging as demonstrated by e.g.
narayanasamy et al.
.
we argue that knowing the part of the execution history that we call 907the crash path is often su cient for the developer to debug the crash and is cheaper to produce in a javascript setting.
the bugredux framework by jin and orso gathers partial execution traces from deployed programs and then uses symbolic execution to synthesize reproducible failures.
symcrash instead uses dynamic symbolic execution and more selective instrumentation.
we avoid the need for symbolic execution by the use of iterative instrumentation.
some techniques utilize static analysis to reduce the instrumentation overhead however the dynamic language features in javascript are known to cause considerable challenges for static analysis .
one challenge to dynamic analysis of deployed javascript applications is that instrumenting javascript programs is known to incur a large runtime overhead.
techniques that attempt to reduce the overhead by only logging sources of nondeterminism as e.g.
chronicler are di cult to apply to javascript.
even though our implementation uses the state of the art jalangi infrastructure we observe a substantial runtime overhead when full instrumentation is enabled which necessitates the more selective instrumentation.
several other tools described in the literature are capable of recording live executions which can subsequently be analyzed by the developers when debugging.
mugshot is capable of capturing events using unmodi ed browsers.
similarly warr and more recently timelapse and dolos can in principle provide full information about failing executions.
ripley instruments javascript applications to enable replaying executions on the server with the purpose of ensuring computational integrity and dodom performs replaying to infer dom invariants not to aid debugging of crashes that users encounter.
however we have seen no concrete usage of these tools in real world debugging.
we believe that record replay tools usually require that the record and replay environments which include browser con guration browser state persistent data e.g.
cookies network speed processor speed and operating system con guration to be exactly same.
such a requirement is too strict and difcult to reproduce in real world scenarios where an application can be run by any user under any possible environment.
crowdie does not su er from such limitations because it does not aim to faithfully replay a buggy execution it simply tries to collect a relevant portion of the controlow path using light weight and targeted instrumentation.
fault localization techniques.
several automated fault localization techniques rely on statistical data from user executions collected in order to assist developers with debugging.
such information may be useful for debugging but it does not provide the crash paths that we argue are valuable when debugging.
for future work it will be interesting to perform a direct experimental comparison with such techniques.
liblit et al.
interestingly note that the stack contains essentially no information about the bug s cause in half of the bugs considered in their experiments which aligns well with our observation that more information about the failing executions is often needed.
the holmes tool localizes faults using path pro les which are constructed by iteratively instrumenting and re deploying programs similar to our technique.
unlike crash paths path pro les only provide statistical information about intraprocedural and acyclic paths.
the autoflox tool by ocariza et al.
performs fault localization for javascript under the assumption that a complete failing execution is known un like our technique that aims to automatically nd the crash path.
our algorithm for nding crash paths is also related to algorithmic program debugging but does not require guidance by the programmer or by formal speci cations.
dynamic program slicing.
our notion of crash paths is related to the use of dynamic slicing for debugging .
such techniques typically compute slices backwards which resembles our construction of crash paths but usually assuming that a complete execution trace is already known.
although many variations of dynamic slicing have been proposed they generally di er from our notion of crash path which comprises a path from the creation of an object of interest to a crashing statement without including all dependencies earlier in the execution.
in principle slicing may be applied subsequently to the crash path to lter away instructions that are likely irrelevant.
other crowdsourced analysis techniques.
crowdsourced analysis has also been suggested for other debugging scenarios.
for example kerschbaumer et al.
use crowdsourced analysis to test for information ow vulnerabilities by letting di erent users track di erent information ows so that a crowd of users can achieve high coverage of all information ows without imposing unacceptable performance overhead on any single user.
likewise kasikci et al.
test potential data races by distributing them over a set of users by giving each user an instrumented version of an application where the purpose of the added instrumentation code is to con rm whether the potential race happens in practice.
to lower the overhead instrumentation is enabled probabilistically.
in contrast we enable instrumentation only when a crash occurs then increase instrumentation until a crash path is discovered and nally disable the instrumentation.
.
conclusions and future work many bugs manifest themselves as objects that have incorrect property values when a failure occurs.
for such bugs error messages and stack traces often provide insu cient information for diagnosing the problem.
we have proposed the notion of a crash path which re ects the control ow from the allocation of a selected object of interest to the crashing statement and argue that this often provides useful information for debugging such problems.
in principle crash paths can be computed by executing a fully instrumented version of a program but this incurs prohibitive runtime overhead.
therefore we have developed a feedback directed instrumentation technique for computing crash paths that we envision to be deployed in a crowdsourced scenario where the same failure can be observed repeatedly.
we implemented the technique in a tool called crowdie and evaluated it in case studies by using it to debug real world issues reported on github for which error messages and stack traces are insu cient to nd and x the bugs.
in these case studies the feedback directed technique requires the same crash to be encountered to times and the runtime overhead generally compares favorably to that of full instrumentation.
directions for future work include achieving a deeper understanding in which situations the feedback directed technique is useful and reducing instrumentation overhead.
we also plan to explore the use of more detailed instrumentation once a complete crashing path has been identi ed in order to prune irrelevant statements from the path.
908references h. agrawal r. a. demillo and e. h. spa ord.
debugging with dynamic slicing and backtracking.
softw.
pract.
exper.
.
h. agrawal and j. r. horgan.
dynamic program slicing.
inproc.
acm sigplan conference on programming language design and implementation pages .
e. andreasen and a. m ller.
determinacy in static analysis for jquery.
in proc.
acm international conference on object oriented programming systems languages applications pages .
s. andrica and g. candea.
warr a tool for highdelity web application record and replay.
in proc.
ieee ifip international conference on dependable systems and networks pages .
apple.
crash reporter.
library mac technotes tn2004 tn2123.html.
j. bell n. sarda and g. e. kaiser.
chronicler lightweight recording to reproduce eld failures.
in proc.
35th international conference on software engineering pages .
b. burg r. bailey a. j. ko and m. d. ernst.
interactive record replay for web application debugging.
in proc.
26th acm symposium on user interface software and technology pages .
y. cao h. zhang and s. ding.
symcrash selective recording for reproducing crashes.
in proc.
acm ieee international conference on automated software engineering pages .
t. m. chilimbi b. liblit k. k. mehra a. v. nori and k. vaswani.
holmes e ective statistical debugging via e cient path pro ling.
in proc.
31st international conference on software engineering pages .
j. a. clause and a. orso.
a technique for enabling and supporting debugging of eld failures.
in proc.
29th international conference on software engineering pages .
l. gong m. pradel m. sridharan and k. sen. dlint dynamically checking bad coding practices in javascript.
in proc.
international symposium on software testing and analysis pages .
w. jin and a. orso.
bugredux reproducing eld failures for in house debugging.
in proc.
34th international conference on software engineering pages .
w. jin and a. orso.
f3 fault localization for eld failures.
in proc.
international symposium on software testing and analysis pages .
j. a. jones and m. j. harrold.
empirical evaluation of the tarantula automatic fault localization technique.
inproc.
20th ieee acm international conference on automated software engineering pages .
b. kasikci c. zam r and g. candea.
racemob crowdsourced data race detection.
in proc.
acm sigops 24th symposium on operating systems principles pages .
c. kerschbaumer e. hannigan p. larsen s. brunthaler and m. franz.
crowdflow e cient information ow security.
in proc.
16th information flow security conference .
b. korel and j. w. laski.
dynamic program slicing.
inf.
process.
lett.
.
b. liblit a. aiken a. x. zheng and m. i. jordan.
bug isolation via remote program sampling.
in proc.
acm sigplan conference on programming language design and implementation pages .
b. liblit m. naik a. x. zheng a. aiken and m. i. jordan.
scalable statistical bug isolation.
in proc.
acm sigplan conference on programming language design and implementation pages .
m. madsen f. tip e. andreasen k. sen and a. m ller.
feedback directed instrumentation for deployed javascript applications.
technical report cs school of computer science university of waterloo .
computer science les uploads les cs .pdf.
j. w. mickens j. elson and j. howell.
mugshot deterministic capture and replay for javascript applications.
in proc.
7th usenix symposium on networked systems design and implementation pages .
microsoft.
windows error reporting.
https msdn.microsoft.com en us library windows hardware dn641144.aspx.
s. narayanasamy g. pokam and b. calder.
bugnet continuously recording program execution for deterministic replay debugging.
in proc.
32st international symposium on computer architecture pages .
g. c. necula j. condit m. harren s. mcpeak and w. weimer.
ccured type safe retro tting of legacy software.
acm trans.
program.
lang.
syst.
.
f. ocariza g. li k. pattabiraman and a. mesbah.
automatic fault localization for client side javascript.
software testing veri cation and reliability .
f. s. ocariza jr. k. bajaj k. pattabiraman and a. mesbah.
an empirical study of client side javascript bugs.
in proc.
acm ieee international symposium on empirical software engineering and measurement pages .
k. pattabiraman and b. g. zorn.
dodom leveraging dom invariants for web .
application robustness testing.
in proc.
ieee 21st international symposium on software reliability engineering pages .
k. sen s. kalasapur t. g. brutch and s. gibbs.
jalangi a selective record replay and dynamic analysis framework for javascript.
in proc.
european software engineering conference acm sigsoft symposium on the foundations of software engineering pages .
e. y. shapiro.
algorithmic program debugging .
mit press cambridge ma usa .
k. vikram a. prateek and v. b. livshits.
ripley automatically securing web .
applications through repli cated execution.
in proc.
acm conference on computer and communications security pages .
s. h. yong and s. horwitz.
using static analysis to reduce dynamic analysis overhead.
formal methods in system design .
x. zhang r. gupta and y. zhang.
precise dynamic slicing algorithms.
in proc.
25th international conference on software engineering pages .