predicting relevance of change recommendations thomas rolfsnes simula research laboratory oslo norway thomgrol simula.noleon moonen simula research laboratory oslo norway leon.moonen computer.orgdavid binkley loyola university maryland baltimore maryland usa binkley cs.loyola.edu abstract software change recommendation seeks to suggest artifacts e.g.
files or methods that are related to changes made by a developer and thus identifies possible omissions or next steps.
while one obvious challenge for recommender systems is to produce accurate recommendations a complimentary challenge is to rank recommendations based on their relevance.
in this paper we address this challenge for recommendation systemsthat are based on evolutionary coupling.
such systems use targeted association rule mining to identify relevant patterns in a software system s change history.
traditionally this processinvolves ranking artifacts using interestingness measures such as confidence and support.
however these measures often fall short when used to assess recommendation relevance.
we propose the use of random forest classification models to assess recommendation relevance.
this approach improves onpast use of various interestingness measures by learning fromprevious change recommendations.
we empirically evaluate our approach on fourteen open source systems and two systems fromour industry partners.
furthermore we consider complimenting two mining algorithms c o change and t armaq .
the results find that random forest classification significantly outperforms previous approaches receives lower brier scores and has superior trade off between precision and recall.
the results are consistent across software system and mining algorithm.
index t erms recommendation confidence evolutionary coupling targeted association rule mining random forests.
i. i ntroduction when software systems evolve the amount and complexity of interactions in the code grows.
as a result it becomesincreasingly challenging for developers to foresee and reasonabout the effects of a change to the system.
one proposedsolution change impact analysis aims to identify softwareartifacts e.g.
files methods classes affected by a givenset of changes.
the impacted artifacts form the basis forchange recommendations which suggests to a developer alist of artifacts that are related to their proposed changesto the code supporting in the process of addressing change propagation and ripple effects .
one promising approach to change recommendation aims to identify potentially relevant items based on evolutionary orlogical coupling.
this approach can be based on a range of granularities of co change information as well as code churn or even interactions with an ide .change recommendation based on evolutionary coupling hasthe intriguing property that it effectively taps into the inherentknowledge that software developers have regarding depen dencies between the artifacts of a system.
our present work considers co change information extracted from a versioncontrol system such as git svn or mercurial.one challenge faced by all recommender systems are false positives.
this challenge becomes acute if developers come to believe that automated tools are mostly wrong .
clearly algorithms with higher accuracy will help address this challenge.
however we can also address this challengewith algorithms that assess the relevance of a proposed recommendation.
in fact the two approaches are complimentary.in this paper we hypothesize that history aware relevance prediction which exploits earlier change recommendations toassess the relevance of a current recommendation and ranksrecommendations according to decreasing relevance can helpmitigate the challenge of false positives.
our approach consists of training a random forest classification model on previous change recommendations with known relevance.
the model is used to give a single likelihood estimate of the relevance of future change recommendations.
automatic assessment of recommendation relevance frees de velopers from having to perform this time consuming task.our work facilitates further automation of the change recom mendation process only notifying the developer when relevantrecommendations are available.
furthermore our approachcompliments existing research work on improving miningalgorithm accuracy as its application is independent of themining algorithm used to generate recommendations.
contributions a we present twelve features describing aspects of change sets change histories and generated change recommendations.
these features are used to build a random forest classification model for recommendation relevance.
b we assess our model in a large empirical study encompassingsixteen software systems including two from our industrypartners cisco and km .
furthermore change recommendations are generated using both c o c hange and t armaq to assess the external validity of our approach.
c we evaluate the importance of each of the twelve features used in ourrelevance classification model.
ii.
o verall approach the overarching goal of this paper is to attach appropriaterelevance scores to change recommendations based on association rule mining.
we consider this question of relevance froma developer viewpoint where relevant means useful for the developer .
we therefore consider a change recommendationrelevant if it contains a correct artifact as one of its top ten highest ranked artifacts.
we propose an approach that uses classification based on random forests to learn from previous change recommendations in order to assess the current one.
thus relevance of .
c circlecopyrt2017 ieeease urbana champaign il usa t echnical research694 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a new recommendation is assessed based on the known relevance of historically similar and dissimilar recommendations.
traditionally the same interestingness measure used to rank the artifacts of a recommendation are also used to assess its relevance .
for example an interestingness mea sure might weight artifacts on a range from to enablingan internal ranking.
given the ranking it is then up to the userto assess whether the recommendation is relevant.
naturally if the top ranked artifacts have received weights close to themaximum in this example the recommendation is assumedrelevant and will likely be acted upon.
recent work found that in the context of software change recommendation agrawal sconfidence interestingness measure performs among the top in class when compared to more complex measures .
considering this result we use confidence as a baseline and setout to compare the relevance predictions given by our proposedapproach against those based on confidence rq does classification based on random forests improve upon the use of confidence as a relevance classifier?
to train our classification model a range of features mustbe introduced that describe attributes related to a change rec ommendation.
the better these features capture key attributes the better we can learn from previous recommendations andconsequently the better we can assess the relevance of a currentrecommendation.
thus our second research question is rq what are the most important features for classifying change recommendation relevance?
in our study we use random forests for their proven per formance and intrinsic ability to assess variable feature importance .
by answering our two research questions weseek to uncover whether change recommendation relevance is a viable venue for further research.
if so our approach mayprove to be an important compliment to existing algorithms forchange recommendation helping to gain both better recom mendations and higher confidence in those recommendations.
iii.
r ela ted work recommendation relevance a shared goal in recommendation systems is uncovering interesting findings in a data set which means that an important research question concernswhat actually characterizes the interestingness of a finding.
over the years numerous measures for interestingness havebeen proposed .
a recent evaluation of 39of these measures in the context of software change recom mendation found that the traditional measures of confidence and support perform just as well as more recent and often more complex measures .
cheetham and price evaluated indicators features that can be used to provide confidence scores for case based reasoning systems .
to provide a recommendation for a new case thek nearest neighbor algorithm was used thus the evaluated features were tightly woven with the kind of output thatthek nearest neighbor algorithm produces.
example features include the number of cases retrieved with best solution and similarity of most similar case.
the features were tested forimportance using leave one out testing in combination with the decision tree algorithm c4.
.
in comparison our use ofrandom decision trees avoids the need for leave out testing offeatures as feature importance is internally accounted for.
le et al.
propose an approach for predicting whether the output of a bug localization tool is relevant .
as forthis paper an output is considered relevant if a true positiveis part of the top recommended artifacts.
while change recommendation can be seen as stopping faults before they happen bug localization is a complementary approach for already existing faults.
state of the art bug localization is basedon comparing normal and faulty execution traces spectrumbased .
in order to predict relevance le et al.
identify 50features related primarily to traces but also considered theweights of recommended suspicious artifacts.
these featureswere then used to train a classification model for relevancebased on support vector machines.
rule aggregation clustering and filtering rolfsnes et al.
propose aggregation of association rules to combine their evidence or interestingness .
aggregation likelyincreases recommendation relevance for example considerthree rules one recommending awith confidence .
and two recommending bwith confidence .
and .
respectively.
traditional approaches would use the highest ranking ruleand thus prioritize aover b. rule aggregation combines the evidence for band thus leads to recommending bover a. several authors propose methods to discover the most informative rules in a large collection of mined association rules byeither clustering rules that convey redundant information or by pruning non interesting rules .
the overall idea is that the removal of rules will reduce the noise in therecommendations made using the remaining rules.
however in contrast to rule aggregation and to the approach proposedin this paper recommendations will be based on only partof the available evidence.
it remains open to future work toinvestigate how this affects their relevance.
parameter tuning recent research highlighted that the configuration parameters of data mining algorithms have a significant impact on the quality of their results .
inthe context of association rule mining several authors havehighlighted the need for thoughtfully studying how parametersettings affect the quality of generated rules .
moonen et al.
investigate how the quality of software change recommendation varied depending on association rule miningparameters such as transaction filtering threshold historylength and history age .
in contrast to that work which focused on configurable parameters of the algorithm this paper considers non configurable features of the query the change history and the recommendation history.
iv .
g enera ting change recommenda tions a. software change recommendation recommender or recommendation engines are information filtering systems whose goal is to predict relevant items for a specific purpose .
a common use of recommendersystems is in marketing where these systems typically leverage authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a shopper s previous purchases and the purchases of other shoppers to predict items of potential interest to the shopper.
in the context of software engineering these systems typically leverage a developer s previous changes together with the changes made by other developers to predict items ofinterest.
software change recommendation takes as input a set of changed entities referred to as a change set orquery and predicts a set of entities that are also likely in need ofchange.
these entities may be any software artifact such as files methods models or text documents.
the study described in this paper considers both files and methods as potential artifacts.
we extract these artifacts from the version controlhistory of a software system.
thus software recommendationhelps answering questions such as given that files f 1and f2and method m changed what other files and methods are likely to need to be changed?
a common strategy for change recommendation is to capture the evolutionary coupling between entities .
in this application entities are considered coupled iff they havechanged together in the past.
the key assumption behindevolutionary coupling is that the more frequently two or moreentities change together the more likely it is that when onechanges the others will also have to be changed.
in the contextof software change recommendation evolutionary coupling iscommonly captured using association rule mining .
b. targeted association rule mining association rule mining is an unsupervised learning technique aimed at finding patterns among items in a data set .
association rule mining was first applied for market basket anal ysis to find patterns rules describing items people typicallypurchase together.
in this context the data set is expressedas a list of transactions where each transaction consists of aset of items.
for example in the domain of grocery stores items likely include products such as milk and cookies and mining a rule such as cookies milk uncovers the tendency of people who buy cookies the rule antecedent t o also buy milk the rule consequent .
this provides valuable knowledge for example suggesting that placing these groceryitems in close proximity will increase sales.
shortly after the introduction of association rule mining srikant et al.
acknowledged that for most applications only a few specific rules are of practical value .
this led to the development of constraint based rule mining where only rules that satisfy a given constraint are mined.
typically constraints specify that particular items must be involved in therule s antecedent.
for example consider a software engineerwho recently made a change to file x. a constraint could specify that rule antecedents must contain x thus limiting recommendation to those involving x. constraints are usually specified by the user in the form of a query at which the mining process is said to be targeted.
the resulting targeted association rule mining algorithms filter from the history all transactions unrelated to the query producing a more focusedset of rules.
so provides a significant reduction inexecution time .to rank the resulting rules numerous interestingness measures have been proposed .
such measure attempt to quantify the likelihood that a rule will prove useful.
the first interestingness measures introduced frequency support and confidence are also the most commonly used .
it is worth formalizing these three.
each is defined in terms of a history h of transactions and an association rule a b where a andbare disjoint sets of items.
to begin with rule frequency is the number of times the antecedent and consequent havechanged together in the history definition frequency frequency a b def t h a b t second the support of a rule is its relative frequency with respect to the total number of transactions in the history definition support support a b def frequency a b h finally confidence is its relative frequency of the rule with respect to the number of historical transactions containing theantecedent a definition confidence confidence a b def frequency a b t h a t support and confidence are often combined in the supportconfidence framework which first discards rules below a given support threshold and then ranks the remaining rulesbased on confidence.
thresholds were originally required tominimize the number of potential rules which can quicklygrow unwieldy.
however the constraints introduced by tar geted association rule mining greatly reduce the number of rules and thus do not depend on a support threshold forpractical feasibility.
c. association rule mining algorithms a targeted association rule mining algorithm takes as input a query qand restricts the antecedents of the generated rules to be various subsets of q. the variation here comes from each algorithm attempting to best capture relevant rules.
consider for example the query q a b c d .
potential rules include a xandb c y. in fact the set of possible antecedents is given by the power set of q. one of most well known algorithms r ose limits the number of rules by requiring that the antecedents are equalto the query q .
thus for a b c d r ose rules are all of the form a b c d x where xis only recommended if there exists one of more transactions where x changed together with all the items of the query.
at the other end of the spectrum c o c hange partitions qinto singletons and considers only rules for each respective singleton .
thus it produces rules of the form a xandb x. while r ose and c o c hange makes use of the largest and smallest possible rule antecedents t armaq identifies the largest subset of qthat has changed with something else in authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the past .
thus t armaq may return the same rules as co c hange when the history is made up of only two item transactions or the same rules as r ose when qis a proper subset of at least one transaction .
however t armaq can also exploit partial matches e.g.
a history including transactions larger than two items but none having qas proper subset .
while it may not be immediately evident t armaq is defined such that its recommendations are identical to those of r ose when rose is able to produce a recommendation.
on the other hand t armaq can produce recommendations far more often than r ose .
as a result we performed our empirical study using c o c hange and t armaq a s the behavior of r ose is subsumed by that of t armaq .
as c o c hange mines only singleton rules and t armaq potentially mines rules which maximize the antecedent with respect to the query they together cover a large range ofpossible recommendations.
v. o verview of model fea tures this section introduces the features that we use to buildour random forest classification model.
we consider threecategories of features features of the query features of the change history and features of the recommendation.
it is worth noting that the features describing the queryare known a priori while features of the change historyand the change recommendation are only known after arecommendation has been generated.
fortunately a changerecommendations can be generated in mere milliseconds and the corresponding feature set can therefore be included without incurring undo computational expense.
a. features of the query query size the first feature of a query we consider is simply its size.
for example if a single method is changed the query size is if two different methods are changed the query sizeis and so on.
furthermore some files may not be able to beparsed for fine grained change information changes to thesefiles only ever increase the query size by .
throughout therest of the paper we use the term artifact as a generic way of referring to both unparsable files and parsable methods.we hypothesize that query size may be important for relevance as when it increases one of the following is likely occurring a the developer is working on a complex feature requiring code updates in several locations.
here increased query sizeindicates specificity.
b on the other hand if a developer is not compartmentalizing the work and thus is working on multiple features at the same time increased query size indicates chaos as unrelated artifacts are added to the same commit.
number of files changed number of methods changed we record the granularity of changes in two separate features the number of files changed and the number of methodschanged.
for example if the methods m1 andm2 change in the file f1 and the method m3 change in the file f2 we record that methods and files have changed.
by including thesemetrics of query granularity we aim to capture the specificity of the corresponding change recommendation.
number of new artifacts if a new file or new method is included in a query we know that nothing has changed together with it previously thus from an evolutionary perspective the new artifact is uncoupled from all other artifacts.
the presence of new artifacts in combination with known artifactsadds uncertainty and is therefore considered as a feature.
b. features of the change history whenever an existing artifact a is changed a list of relevant transactions can be extracted from the change history.
a transaction is relevant if it contains the changed artifact.
from these transactions mining algorithms identify other artifactsthat typically changed with a forming the basis for the resulting change recommendation.
number of relevant transactions the number of relevant transactions is the number of transactions with at least one artifact from the query.
this metrics provides a measure ofthe churn rate i.e.
how often the artifacts change .
mean size of relevant transactions while the number of relevant transactions tells us how often the artifacts found in aquery change it does not tell us how often they change withother artifacts the mean size of relevant transactions attempts to capture this feature.
mean median age of relevant transactions two age related features included involve the change in dependencies between artifacts as software evolves e.g.
because of arefactoring and code decay where artifacts become harder to change a known phenomena in long lived software sys tems .
the feature age of relevant transactions attemptsto capture these two age related aspects.
note that two featuresare actually used the mean age and the median age.
overlap of query and relevant transactions if there are transactions that exhibit large overlap with the query thismight indicate highly relevant transactions .
we capturethis through the overlap percentage .
note that the percentagereports the single largest match rather than the mean.
c. features of the recommendation a recommendation boils down to a prioritized list of association rules giving the potentially affected artifacts.
however different mining algorithms may return different lists.
while the features described so far are independent of the mining algorithm in this section we consider features that are aspectsof the recommendation and thus the particular algorithm used.
confidence and support of association rules a recommendation is constructed from association rules of the form a b. here a includes changed artifacts while b the recommended artifacts.
to be able to distinguish rules weights can be provided through interestingness measures.
one way of providing these weights uses the support and confidenceinterestingness measures definitions and .
traditionally interestingness measures are used in isolation to judge whethera recommendation is relevant .
in this paper weextend their use by considering aggregates of the top rules authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
in order to indicate recommendation relevance.
we include three aggregates the top mean confidence the top mean support and the maximum confidence.
each feature is meant to capture the likelihood of whether there exist at least one relevant artifact in the top ten.
number of association rules if a recommendation consists of a large number of rules two non mutually exclusive situations may exist a the query is large and the contained artifacts have changed with something else in the past or b at least one artifact of the query has changed with a largenumber of other artifacts in the past.
in either case a largerecommendation is a symptom of non specificity and may thusprove a valuable feature for classifying true negatives.
vi.
e xperiment design our empirical study is designed to answer one primary ques tion can we predict if a recommendation contains relevant artifacts?
to answer this question we generate a large recommendation oracle over which we train random forest classification models using the features described in section v. finally weevaluate the resulting models by comparing their performanceagainst two confidence based predictions of relevance.
theseaim to function as a baseline for whether a developer wouldact upon a given recommendation.
maximum confidence a recommendation is predicted as relevant if the confidence of the artifact with the highest confidence is larger than a given threshold.
mean confidence a recommendation is predicted as relevant if the mean confidence of the top ten artifacts isgreater than a given threshold.
the rationale behind maximum confidence mimics a developer who is only willing to consider a recommendation s highestranked artifact while that of mean confidence mimics a developer who is willing to consider the recommendation stop ten artifacts.
our study encompasses change recommendations generated from the change history of sixteen different software systemswith varying characteristics.
two of these systems come fromour industry partners cisco and km .cisco is a worldwide leader in the production of networking equipment we analyzethe software product line for professional video conferencingsystems developed by cisco.
km is a leader in the production of systems for positioning surveying navigation andautomation of merchant vessels and offshore installations.
weanalyze the common software platform km uses across various systems in the maritime and energy domain.
the other fourteen systems are the well known open source projects reported in table i along with change history statistics illustrating their diversity.
the table shows that the systems vary from medium to large size with over unique files in the largest system.
for each system we extractedup to the most recent transactions.
this number of transactions covers vastly different time spans across the systems ranging from almost twenty years in the case ofhttpd to a little over ten months in the case of the linuxkernel.
in the table we report the number of unique fileschanged throughout the most recent transactions as well as the the number of unique artifacts changed.
these artifacts include in addition to file level changes method level changes for certain languages.
1finally the last column of table i shows the programming languages used in eachsystem as an indication of heterogeneity.
the remainder of this section first explains the setup used to generate change recommendations using c o c hange and tarmaq .
it then details how these recommendations are used to train and evaluate models for relevance prediction.
theresults of our study are presented in section vii.
a. generating change recommendations establishing the ground truth the change history of a software system exactly describes transaction by transaction how to re construct the current state of the system.consequently we can assume the majority of the time thateach transaction has some intention behind it and that thechanges in the transaction have some meaningful relation toeach other.
in fact if this assumption is completely misguided recommendations based on change histories would degenerate to random prediction which is clearly not the case.
2thus given a subset qof transaction c a good recommendation algorithm should identify the complement e c q as the set of impacted items.
here ecaptures the ground truth on whether a change recommendation is truly relevant because it includes those artifacts that actually changed alongsideq.
for this reason eis used when evaluating the change recommendation generated for query q. sampling strategy construction of the change scenarios involves two steps sampling transactions and generating queries from each sampled transaction.
we start by fetching the most recent transactions from each subject system.
from these we then determine the most recent transactions whose size is between and .the minimum number ensures that there is always apotential impact set for any given query while the maximumnumber covers at least of all transactions whileaiming to omit large changes such as licensing changes.
fromeach sampled transaction c the impact set eis randomly determined but ensured to consist of at least ten items.
ranking rules the rules mined by each algorithm all share the property that their support is at least one because we operate with an absolute minimal support constraint.
byincluding all rules like this we ensure that both highfrequency as well as low frequency rare rules are includedin the recommendations .
the support measure is not otherwise used for ranking.
when support is used for ranking special care needs tobe taken as rare infrequent rules always rank lower thenmore frequent rules.
this is a result of the downward closure 1we currently extract method level change information from files of c c c and java code.
2the chance of randomly predicting a correct method is number of methods which for any sizable system approaches zero.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t able i characteristics of the ev alua ted softw are systems based on our extraction of the last transactions for each .
software system history number of number of avg.
transaction in yrs unique files unique artifacts size artifacts languages used cpython .
.
python c other mozilla gecko .
.
c c javascript other git .
.
c shell script perl other apache hadoop .
.
java xml other httpd .
.
xml c forth other liferay portal .
.
java xml other linux kernel .
.
c other mysql .
.
c c javascript other php .
.
c php xml other ruby on rails .
.
ruby other ravendb .
.
c javascript xml other subversion .
.
c python c other webkit .
.
html javascript c other wine .
.
c other cisco .
.
c c c python java xml other build config km .
.
c c xml other build config languages used by open source systems are from percentages for the industrial systems are not disclosed.
property any subset of a rule must have equal or larger support relative to the origin rule .
for example given the two rulesr a x andr2 a b x r2cannot have higher support than r1.
by using the confidence measure to rank rules both rare and non rare rules may be ranked highly.
still the frequencyof a pattern continues to inform the relevancy of a rule.
tothis end recall that the top mean support is included as a feature in our prediction model.
b. evaluation of relevance prediction blocked cross validation last block validation is a frequently used scheme for evaluating prediction models.
here the data is split into two blocks with the first block being used to train the model and the second block being used to evaluate it.
this setup has the advantage of respecting thetemporal nature of the data.
however a drawback is thatnot all data is used for both training and prediction .to address this a traditional cross validation setup may beused.
however so violates the temporal nature of time series data and in the worst case may invalidate theresults .
because in time series data future data naturally depends on prior data we use blocked cross validation to fig.
.
the blocked cross validation scheme used in our study.
notice that all blocks except b1 and b10 are used for both training and predictionpreserve the temporal order between training and evaluation.
in our configuration we partition each set of transactions intoten equally sized blocks preserving temporal order between blocks.
we then train nine random forest classification models for each software system and mining algorithm combination.as illustrated in figure each random forest is trained on anincrementally larger subset of the available recommendations.in total 16systems 2algorithms 9forests random forests are trained.
measuring relevance the random forest and confidence based classification models have probabilistic interpretations.
the confidence interestingness measure itself is given by the conditional likelihood p b a where bis the recommended artifact and ais one or more artifacts that changed i.e.
artifacts from the query .
the maximum and mean confidencemodels use this information to capture the likelihood thata developer will act upon a given change recommendation.here a indicates very unlikely while a indicatesvery likely.
in the case of random forests the likelihood is the result of the votes obtained from the collection of treesmaking up the random forest .
each decision tree casts a single vote.
as each tree is built from a random selection ofchange recommendations the end likelihood is an indicationof internal consistency within the data set for a particularscenario.
in other words if a certain scenario always results in a certain outcome it is very likely that similar new scenarios will have the same outcome.
finally in the evaluation sets used throughout our study we encode the possible classes ina similar way the binary options are either not correct intop or correct in top .
vii.
r esul ts and discussion we organize the discussion of our results around the tworesearch questions proposed in section v. throughout thissection we will consider prediction performance for each individual software system and for each of the mining al gorithms c o c hange and t armaq .
by so we get an authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
co change tarmaq b2 b3 b4 b5 b6 b7 b8 b9 b100.
.
.
.
.
.
evaluation blockmaemean conf.
max.
conf.
random forest fig.
.
descriptive view of errors using the mean absolute error mae .
each line shows the mean mae over all systems and the ribbon shows the standard deviation.
indication of how generalizable the results are to other systems and other algorithms.
in the following we briefly introduceeach performance metric before presenting the correspondingresults.
a. rq comparison to confidence as a relevance predictor while comparing the three classification models we focus on two aspects of their relevance predictions the error with respect to the actual relevance and the performance across different classification thresholds.
we start with a descriptive view of the errors exhibited by each classification model for this we use the mean absoluteerror mae .
in our case mae measures the mean absolutedifference between the actual and predicted value for whether there is a correct artifact in the top ten artifacts of a recom mendation.
for example given a certain feature as input therandom forest might give the output .
indicating a likelihood that the resulting recommendation will be relevant.if in actuality we know that for this scenario there is indeed a correct artifact in the top ten the prediction error would be .
.
33because we encode knowing as .
note that lower is better.
figure shows the mae across the software systems for the two mining algorithms.
to reduceclutter we present summarized information where each line isthe mean over all systems and the ribbon indicates the standarddeviation.
for this first look at the data we have also preserved co change tarmaq b2 b3 b4 b5 b6 b7 b8 b9 b100.
.
.
.
.
.
evaluation blockbriermean conf.
max.
conf.
random forest fig.
.
accuracy of classification models using brier scores.
each line shows the mean mae over all systems and the ribbon shows the standard deviation.
models below the horizontal black line tend to classify correctly with regards to a .
classification threshold.
results for each evaluation block.
this enables a view into error fluctuations across time.
first there is no apparent overall trend across the evaluation blocks.
this is good news asit provides evidence that the analysis is stable across time.this is also supported by fitting linear regression lines leftout to minimize clutter .
the random forest model shows less variance in error across systems and algorithms whilefor some systems the maximum confidence model exhibits less overall error.
for the change recommendations where the actual relevance was correct in top the maximum confidence model frequently matches the prediction exactly and therefore minimizes the error for these recommendations.
in terms of accuracy of each classification model a proper scoring rule must be used .
for proper scoring rules the maximum score is achieved if the prediction distribution exactly matches the actual distribution.
one such scoring rule is the brier score.
in the case of binary classification which is our task the brier score is the mean squared error bs nn summationdisplay i pi ai where piis the predicted relevance for scenario i and ai is the actual relevance or .
figure presents the brier scores for each classification model across each evaluationblock software system and mining algorithm.
note that lower authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
co change tarmaq .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
false positive ratetrue positive ratemean conf.
max.
conf.
random forest fig.
.
roc curves for the prediction models trained for each software system and algorithm.
is better.
in the figure the horizontal black line at y .
indicates the brier score of a neutral classification model.
a neutral model always makes the prediction .
whererelevance and non relevance are equally likely.
brier scores below the line indicate a prediction model that tends to be on the right side of the midpoint .
we clearly see therandom forest model being consistently more accurate acrossalgorithms and software systems.
while the error informs us about the overall fit of a prediction model it does not capture performance across differentclassification thresholds.
when classification models are used in practice thresholds must be set to balance true positivesagainst false positives and false negatives.
to investigatethe ability of our three prediction models in these terms we consider the roc curve and the precision recall curve.first the roc curve in figure plots the true positiverate tpr tp tp fn against the false positive rate fpr fp fp tn at classification thresholds from to .
it is immediately apparent that the confidence based models do not meaningfully respond to different classification thresholds as data points are not evenly spread across the x axis.
further more there are strong linear relationships between their tprsand fprs.
this was also reflected in corresponding pearsoncorrelation coefficients where all coefficients were calculatedto be .
or higher.
intuitively the effect we see is that as the classification threshold is lowered the confidence models co change tarmaq .
.
.
.
.
.
.
.
.
.
.
recallprecisionmean conf.
max.
conf.
random forest fig.
.
precision recall curves for the prediction models trained for each software system and algorithm.
for recommendation relevance classify comparably increased amounts of recommendations both correctly and incorrectly.
for example both tpr and fpr increase similarly.
further more observe that the range and domain of the tpr and fpr for the confidence models do not fully extend between and1.
this is the result of a high percentage of change scenariosbeing given the relevance and these scenarios being evenlysplit between true positives tps and false positives fps .
in other words the lack of even distribution of data points results in less variation in tpr and fpr which again is reflectedin the range and domain.
to further support our findings wecompared the partial area under the curve pauc betweenthe roc of the random forests and each of the confidencebased models.
we used roc.test from the r package proc the significance test is based on bootstrapped sampling of multiple aucs and computing their difference.
across allsoftware systems and for both c o c hange and t armaq the pauc were significantly larger p .
for the random forest model.
thus the random forest classifier consistently provide better estimates of relevance across various thresholdscompared to the purely confidence based methods explored.
as laid out earlier relevance prediction can be performed in a background thread that only notifies the developer when there is a high likelihood for a true positive recommendation.in this application the positive class correct in top ten istherefore of the most interest.
notifications that there are authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
no relevant artifacts would be of less use.
with this view the precision tp tp fp of the classification models become imperative.
the task is to find an appropriate classification threshold that makes true positives likely high precision while still maintaining practicality in that recommendationscan be regularly made high recall .
figure shows theprecision recall curves for our three prediction models for eachsoftware system and mining algorithm.
first the abnormalityin slope range and domain for the confidence models canagain be attributed to the weak connection to threshold changes.
furthermore while one usually expects a decreasein precision as recall increases this does not necessarily need to be the case.
the trends for the confidence models infigure are the result of having slightly higher concentrations of positive classifications than negative classificationson lower thresholds.
as thresholds are lowered further morerecommendations become tps and the ratio between tps andfps actually increases.
an implication of this is that at leastfor the confidence measure its value cannot be used directlyas an indication of relevancy.
turning to the random forest models these exhibit greater defined behavior where negative classifications are primarilylocated in lower likelihood thresholds thus precision decreasesas recall increases.
in terms of recommending concrete clas sification thresholds for our random forest model we suggestthat this should be adjusted with respect to the system domain knowledge of the developer for which the recommendation is made.
in table ii we have provided the mean precision and recall across software systems for the example thresholds at0.
and .
.
as developers become more acquainted with a system they should also be able to better differentiate rele vant and non relevant recommendations.
as such experienceddevelopers might afford a higher rate of recall at the cost oflower precision.
a classification threshold of .
becomes reasonable for this group assuming t armaq is used.
for inexperienced developers one wants to minimize confusion and therefore maximize the precision of change recommendations.thus a threshold such as .
might be appropriate for thesedevelopers resulting in change recommendations only havingfalse positives in about to per recommendations.
b. rq analysis of features having empirically established that the random forest classifications models are superior at predicting change recommendation relevance we next consider which features bring the t able ii examples of precision and recall for the random forest classifica tion model .t he st andard devia tion sd captures fluctua tions between softw are systems .
classification threshold .
.
algorithm mean sd mean sd co c hange precision .
.
.
.
recall .
.
.
.
tarmaq precision .
.
.
.
recall .
.
.
.
co change tarmaq 200number of new artifactsnumber of methods changednumber of files changedquery sizenumber of rulestop mean supporttop mean con fidencemaximum con fidencemean size of relevant txesmean age of relevant txesmed.
age of relevant txesnumber of relevant txesoverlap percent number of new artifactsnumber of methods changednumber of files changedquery sizenumber of rulestop mean supporttop mean con fidencemaximum con fidencemean size of relevant txesmean age of relevant txesmed.
age of relevant txesnumber of relevant txesoverlap percent mean decrease in accuracysystem with fine grained change history false true fig.
.
feature importance as determined by mean decrease in accuracy.
each line represents a separate software system the line color style indicates if a fine grained change history was available.
most value to the models.
breiman introduced the concept of variable importance for random forests .
once the decision trees of the random forests have been built the process canself assess the importance of each feature.
the basic idea isto observe if randomly permuting a feature changes prediction performance .
averaging the accuracy changes over all treesgives the mean decrease in accuracy when permuted for each feature.
the corresponding plot for the features included in our model is provided in figure .
for two of the studied software systems km and rails we only have file level changeinformation.
these two systems are shown using the dashed red lines.
naturally permuting the number of methods changed feature does not change accuracy for these two systems as the value is always as reflected in figure .
to begin with t armaq was constructed to produce a focused recommendation that matches the query as closely aspossible .
this is evident in the figure where the number of rules generated being an essential feature for t armaq .
thus for t armaq variation in the number of rules generated meaningfully correlates with recommendation relevance if alarge subset of the query has changed with something else in the past this results in fewer possible rule antecedents andthus fewer rules which evidently increases the likelihood of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a relevant recommendation.
for c o c hange this feature has less importance.
for the remaining features figure shows a rather clear picture the query based features the bottomfour are the least important the attributes they representare better captured by other features.
of the interestingnessmeasure based features the top mean confidence proved most useful.
finally all history related features are comparably important.
the high degree of co variance between software systems suggests that model transfer to other systems is viable.
that is classification models learned on one or more systems should be reusable for a new unknown system.
if this can be shownto work reliably systems that are early in their evolution can still benefit from models generated from more mature systems.
however care must be taken to adapt the feature variation ofthe random forest to fit the variation found in new softwaresystem.
c. threats to v alidity implementation we implemented and thoroughly tested all algorithms and our technique for model classification in ruby and r respectively however we can not guarantee the absence of implementation errors.
variation in software systems we have sought to obtain generalizable results by evaluating over a range of heterogeneous software systems however we also uncovered that relevance prediction performance varies between systems.
future work should investigate the effects of system characteristicson prediction performance.
mining algorithms studied in our evaluation we have studied classification models for recommendations generated using both the c o c hange and t armaq mining algorithms.
for both algorithms we achieve strong results.
however weacknowledge that comparable results cannot be guaranteed forother mining algorithms.
using other interestingness measures in our study we focused on the confidence interestingness measure thus our results are limited to this measure.
as such future work should investigate the use of other interestingness measures both for comparison to the random forest predictor as wellas being included as part of the model.
we also envision that a variation of the relevance prediction presented here mightbe an interestingness measure recommender thus essentially creating an ensemble of measures where the most relevant is used at a given time.
recommendations used for training and evaluation we train and evaluate our classification model over a constructed set of change recommendations.
each recommendation is the result of executing randomly sampled a query from an existing transaction where the complement of the query and the sourcetransaction is used as the expected outcome.
however this approach does not account for the actual order in whichchanges were made before they were committed to the ver sioning system.
as a result it is possible that queries containelements that were actually changed later in time than elementsof the expected outcome.
as such we cannot guaranteethat recommendations used in training and evaluation exactlyreflect each system s evolution.
viii.
c oncluding remarks change recommendation is clearly an asset to a software de veloper maintaining a complex system.
however its practical adoption faces two challenges a recommendations must be both accurate and relevant.
we believe that both challengescan be effectively addressed using historically proven change recommendations.
this paper shows that random forest classification using the features that describe aspects of the change set query change history transactions and generated change recommendations is viable.
we compare the random forest model against the state of the art based on confidence .
we evaluate our approach in a large empirical study across software systemsand two change recommendation algorithms.
our findings areas follows finding the random forest classification model consistently outperforms the confidence based models in terms of accuracy brier scores .
finding the random forest classification model achieves significantly larger area under roc curve than both confidence based models.
finding while the confidence measure is appropriate for ranking of artifacts the values themselves should not be interpreted in isolation as overall estimates of recommendationrelevance.
finding the importance of model features may varies between algorithms.
for example the relevance of t armaq recommendations is best predicted by considering the number of rules generated while this feature is less important for c ochange .
however the remaining features studies showed consistent importance between algorithms.
directions for future work looking forward it would be of interest to study the effects of using stricter and looser definitions of relevance e.g.
relevantif correct in top three vs top twenty .
furthermore rather thanclassification relevance can also be studied as a regressionproblem predicting other recommendation metrics such asprecision recall average precision etc.
in addition we planto study the behavior of relevance classification models overother interestingness measures and investigate the viabilityof model transfer between software systems.
finally we planto look into improving the classification model by includingfeatures such as the number of relevant transactions authoredby core contributors vs occasional contributors the weightingrecent relevant transactions higher than older transactions andthe text similarity scores between change set and relevanttransactions.
a cknowledgment this work is supported by the research council of norwaythrough the evolveit project f20 and the certussfi .
dr. binkley is supported by nsf grantiia and a j. william fulbright award.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.