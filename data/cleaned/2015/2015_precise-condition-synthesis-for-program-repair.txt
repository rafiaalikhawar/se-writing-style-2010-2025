precise condition synthesis for program repair yingfei xiong jie wang runfa yan jiachen zhang shi han gang huang lu zhang key laboratory of high confidence software technologies peking university moe beijing china eecs peking university beijing china xiongyf hg zhanglucs pku.edu.cn sise university of electronic science and technology of china chengdu china yanrunfa outlook.com microsoft research beijing china shihan microsoft.com abstract due to the difficulty of repairing defect many research efforts have been devoted into automatic defect repair.
given a buggy program that fails some test cases a typical automatic repair technique tries to modify the program to make all tests pass.
however since the test suites in real world projects are usually insufficient aiming at passing the test suites often leads to incorrect patches.
this problem is known as weak test suites or overfitting.
in this paper we aim to produce precise patches that is any patch we produce has a relatively high probability to be correct.
more concretely we focus on condition synthesis which was shown to be able to repair more than half of the defects in existing approaches.
our key insight is threefold.
first it is important to know what variables in a local context should be used in an if condition and we propose a sorting method based on the dependency relations between variables.
second we observe that the api document can be used to guide the repair process and propose document analysis technique to further filter the variables.
third it is important to know what predicates should be performed on the set of variables and we propose to mine a set of frequently used predicates in similar contexts from existing projects.
based on the insight we develop a novel program repair system acs that could generate precise conditions at faulty locations.
furthermore given the generated conditions are very precise we can perform a repair operation that is previously deemed to be too overfitting directly returning the test oracle to repair the defect.
using our approach we successfully repaired defects on four projects of defects4j which is the largest number of fully automatically repaired defects reported on the dataset so far.
more importantly the precision of our approach in the evaluation is .
which is significantly higher than previous approaches which are usually less than .
i. i ntroduction motivation.
given the difficulty of fixing defects recently a lot of research efforts have been devoted into automatic program repair techniques .
most techniques generate a patch for a defect aiming at satisfying a specification.
a frequently used specification is a test suite.
given a test suite and a program that fails to pass some tests in the test suite a typical repair technique modifies the program until the program passes all tests.
we acknowledge participates of dagstuhl especially julia lawall y uriy brun aditya kanade and martin monperrrus and anonymous reviewers for their comments on the paper and xuan bach d. le david lo and claire le goues for discussion on their experiment data.
this work is supported by the national basic research program of china under grant no.
2014cb347701 the national natural science foundation of china under grant no.
and microsoft research asia collaborative research program project id fy15 res opp .however the tests in real world projects are usually insufficient and passing all tests does not necessarily mean that the program is correct.
a patch that passes all tests is known as a plausible patch and we use precision to refer the proportion of defects correctly fixed by the first plausible patch among all plausibly fixed defects.
we argue that precision is a key quality attribute of program repair systems.
if the precision of a repair system is similar to or higher than human developers we can trust the patch generated by the system and deploy them immediately.
on the other hand if the precision of a repair system is low the developers still need to manually review the patches and it is not clear whether this process is easier than manual fix.
as an existing study shows if the developers are provided with low quality patches the performance of the developers is even lower than those who are provided with no patches.
however the precisions of existing testing based repair techniques are not high .
as studied by qi et al.
genprog one of the most well known program repair techniques produced plausible patches for defects but only two were correct giving a precision of .
the reason for the low precision as studied by long et al.
is that correct patches are sparse in the spaces of repair systems while plausible ones are relatively much more abundant.
in their experiments often hundreds or thousands of plausible patches exist for a defect among which only one or two are correct.
it is difficult for the repair system to identify a correct patch from the large number of plausible patches.
a fundamental way to address this problem is to rank the patches by their probabilities of being correct and return the plausible patch with the highest probability or report failure when the highest probability is not satisfactory.
this is known as preference bias in inductive program synthesis .
research efforts have been made toward this direction.
prophet and historicalfix rank the patches using models learned from existing patches.
directfix angelix and qlose rank the patches by their distance from the original program.
minthint ranks the patches by their statistical correlation with the expected results.
however the precisions of these approaches are not yet satisfactory.
for example prophet and angelix have precisions of .
and .
on the genprog benchmark .
an important reason for this imprecision as we conjecture is that the existing ranking approaches are too coarse grained.
as will be shown later existing approaches cannot distinguish ieee acm 39th international conference on software engineering ieee acm 39th international conference on software engineering .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
many common plausible if conditions from the correct condition and will give them the same rank.
to overcome this problem in this paper we aim to provide more fine grained ranking criteria for condition synthesis.
condition synthesis tries to insert or modify an if condition to repair a defect.
condition synthesis has been used in several existing repair systems and is shown to be one of the most effective techniques.
for example among all defects correctly repaired by spr more than half of them are fixed by condition synthesis.
our approach combines three heuristic ranking techniques that exploit the structure of the buggy program the document of the buggy program and the conditional expressions in existing projects.
more concretely we view the condition synthesis process as two steps.
variable selection deciding what variables should be used in the conditional expression and predicate selection deciding what predicate should be performed on the variables.
for example to synthesize a condition if a we need to first select the variable a and then select the predicate .
based on this decomposition we propose the following three techniques for ranking variables and predicates respectively.
dependency based ordering.
we observe that the principle of locality holds on variable uses the more recent a variable in a topological ordering of dependency is more likely it will be used in a conditional expression.
we use this order to rank variables.
document analysis.
we analyze the javadoc comments embedded in the source code.
when variables are mentioned for a particular class of conditional expressions we restrict the selection to only the mentioned variables when repairing the conditional expressions of the class.
predicate mining.
we mine predicates from existing projects and sort them based on their frequencies in contexts similar to the target condition.
to our knowledge the three techniques are all new to program repair.
we are the first to propose the locality of variable uses and apply it to program repair.
we also are the first to utilize the documentation of programs to increase precision.
finally predicate mining is the first technique that automatically mines components of patches from the source code in contrast to those mining from patches of existing projects.
as will be shown later the combination of the three techniques gives us high precision in program repair.
based on the high precision we further employ a new repair method that was considered to be too overfitting directly returning the test oracle of the failed test to repair a faulty method.
this is considered overfitting because a test oracle is usually designed for a specific test input and it is not clear whether this test oracle can be and should be generalized to other inputs.
however this overfitting is likely not to exist when the test input belongs to a boundary case.
a boundary case is a case that cannot be captured by the main program logic and for such a case usually a value or an exception is directly returned.
for example a patch we generated inour experiment if marker null return false directly return the oracle value false when the input is null .
since our condition synthesis is precise if we can successfully synthesize a condition that checks for a boundary case it is probably safe to directly return the oracle.
we have implemented our approach as a java program repair system acs standing for accurate condition synthesis and evaluated acs on four projects from the defects4j benchmark.
acs successfully generated patches where are correct giving a precision of .
and a recall of .
.
both the precision and the recall are the best results reported on defects4j so far within our knowledge.
most importantly the precision is significantly higher than previous testing based approaches which are usually less than .
furthermore we evaluated the three ranking techniques on the top five projects from github besides the four projects.
the result suggests that our approach may achieve a similar precision across a wide range of projects.
ii.
m otiv a ting example int lcm math .
abs mulandcheck a gdc a b b if lcm integer .m i n value throw new arithmeticexception return lcm fig.
.
motivating example example.
figure shows the math99 defect in the defects4j benchmark fixed by acs.
this method calculates the least common multiple and is expected to return a non negative value but it fails to handle the case where the method abs returns integer.min value at input integer.min value due to the imbalance between positives and negatives in integer representation.
two tests cover this piece of code.
test has input a b and expects lcm .
test has input a integer.min value b and expects arithmeticexception .
test passes and test fails.
to fix the defect acs tries to directly return the test oracle and adds lines to the program.
in particular acs synthesizes the condition at line .
since we have only two tests a condition is plausible if it evaluates to false on test and evaluates to true on test .
thus there exists many plausible conditions that can make the two tests pass such as b orlcm !
.
as a result we need to select the correct condition from the large space of plausible conditions.
existing approaches are not good at this kind of finegrained ranking.
for example prophet always assigns the same priority to lcm!
and lcm integer.min value because due to efficiency reasons prophet can only consider variables in a condition.
for another example qlose always assigns the same priority to b lcm!
and lcm integer.min value because the three conditions exhibit the same behavior in testing executions which qlose uses to rank different patches.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
to implement fine grained ranking acs decomposes condition ranking into variable ranking and predicate ranking and using three techniques to rank variables and predicates.
dependency based ordering.
our observation is that the principle of locality also holds on variable uses.
if variable xis assigned from an expression depending on y i.e.
x depends on y xhas a higher chance than yto be used in a following conditional expression.
the intuition is that yis more likely to be a temporary variable whose purpose is to compute the value of x. in our example variable lcm depends on variables aand b and thus lcm is more likely to be used in the if condition.
based on the dependency relations we can perform a topological sort of the variables and try to use most dependent variables in the synthesis first.
document analysis.
we further observe that many java methods come with javadoc comments documenting the functionality of the method.
if we extract information from the javadoc comment we could further assist condition synthesis.
as the first step of exploiting comments in this paper we consider one type of javadoc tags throws tag.
tag throws describes an exception that may be thrown from the method such as the following one from math73 in defects4j .
... throws illegalargumentexception if ini tial is not b e t w e e n min and max even i f i t em is em a root according to this comment an exception should be thrown when the value of initial is outside of a range.
to exploit this information for variable selection we analyze the subject of the sentence.
if the subject mentions any variable in the method we associate the variable with the exception.
when we try to generate a guard condition for such an exception we consider only the variables mentioned in the document.
since programmers may not refer to the variable name precisely we use fuzzy matching we separate variable names by capitalization i.e.
elitismrate becomes elitism and rate and determine that a variable is mentioned in the document if the last word usually the center word is mentioned.
note that our current approach only makes the above lightweight use of javadoc comments but more sophisticated document analysis techniques may be used to obtain more information or even directly generate the condition .
this is future work to be explored.
predicate mining.
after we have an ordered list of variables we select predicates for the variables one by one.
based on our observations we have the insight that the predicates used in conditional expressions have highly sparse and skewed conditional distribution given the contexts of the expressions.
we currently use variable type variable name and or the surrounding method name as context.
for example given an integer variable hour predicates such as or are often used.
in our running example lcm indicates the least common multiple on which integer.min value is more frequently used than a large number of observed alternatives such as !
.
for another example in methods whose names contain factorial predicates such as is often used because !
is the largest factorial that a 64bit integer can represent.
based on such insights we prioritize and prune predicates based on their conditional distributions of surrounding contexts.
we approximate such conditional distributions based on the statistics against a large scale repository of existing projects.
concretely we search predicates under similar contexts in a large repository and rank them by their occurrences.
combining the three techniques we could successfully synthesize lcm integer.min value at line .
since this condition is only valid for one value of lcm it is likely to be a boundary case and thus we can safely generate the patch.
iii.
a pproach in this section we explain the details of our approach.
the input of our approach consists of a program a test failed by the program a set of tests passed by the program.
the output is a patch on the program.
a. overview we use two types of templates to fix defects.
the first type is to directly return the oracle as mentioned in the introduction.
we first identify the last executed statement sin the failed test and then insert one of the following statement before s to prevent the failure.
v alue returning .if c return v oracle throwing .if c throw e when the failed test expects a return value value returning is used otherwise oracle throwing is used.
here voreis the expected return value or exception and cis the synthesized condition.
we also use heuristic rules to check whether the synthesized cis a boundary check and discard the patch if it is not a boundary check.
we always insert before the last executed statement because if the defect leads to crash for example the program fails to check a null pointer we usually need to place the guarded return statement right before the crashed statement.
the second type is the modification of an existing condition.
we first locate a potentially faulty if condition c prime and then apply one of the following modifications based on the result of predicate switching.
widening .if c prime if c prime c narrowing .if c prime if c prime !
c we locate the potentially faulty condition by combining spectrum based fault localization sbfl and predicate switching .
both approaches be used to detect potentially faulty conditions.
sbfl scales better while predicate switching is more precise.
in our approach we first use sbfl to localize a list of potentially faulty methods and then use predicate switching on demand within each method.
in this way we achieve a balance between precision and scalability.
the sbfl formula we used in our implementation is ochiai which is shown to be among the most effective spectrum based fault localization algorithms .
if predicate switching negates the original condition from true tofalse we apply the narrowing template otherwise authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
we apply the widening template.
here cis the synthesized condition.
in both types of templates we need to synthesize condition c. we require cto capture the failed test execution i.e.
evaluating to true at the failed test execution.
we first produce a ranked list of variables to be used in the condition.
then for each variable x we produce a sorted list of predicates to be applied on the variable.
for each predicate p we validate whether they can form a condition p x that capture the failed test execution i.e.
evaluates to true on target condition evaluation.
if so we synthesize a condition p x and run all tests to validate the plausibility of the patch.
in this paper we only consider synthesizing conditions containing one variable but note that our idea is general and may be extended to conditions containing multiple variables.
we always apply the oracle returning templates first and the condition modification templates second.
we return the first plausible patch if it is found within the time limit otherwise we report a failure.
some of the above steps require more detailed explanations and we explain them one by one in the rest of the section.
b. returning the oracle extracting the oracle.
when applying the oracle returning template we need to copy the test oracle from the test code to the body of the generated conditional statement.
there are several different cases.
the oracle is a constant.
in this case we only need to directly copy the text of the constant.
the oracle is specified via expected xxxexception.class annotation.
in this case we throws an instance of xxxexception by calling its default constructor.
the oracle is a function mapping the test input to the output.
this case is more complex.
for example the following piece of code is a test method for math3 defect in defects4j .
public void testarray final double a .
final double b .
assert .
assertequals a b matharrays .
linearcombination a b 0d here the oracle is a b which is a function mapping input aandbto the expected result.
acs inserts the following statement into method linearcombination to fix the defect.
if l e n return a b the condition len is generated using our condition synthesis component and is not our concern here.
the key is how to generate a b .
to extract a functional oracle we first identify the related pieces of code by performing slicing.
we first perform backward slicing from the oracle expression the oracle slice then perform backward slicing from the test input arguments the input slices and subtract the input slices from the oracle slice.
in this way we get all code necessarily to be copied but not the code used to initialize the test inputs.
in this example the oracle slice contains line line and the expressiona b the input slices contain line line and the expression aand b. by subtracting the latter slices from the former we get only the expression a b which should be copied to the generated if statement.
finally we rename the variables representing the test input arguments in this case aandb to the formal parameter names of the target method which happens to be still aandbin this example .
determining boundary checks.
we consider a statement if c sas a boundary check if one of the following rules are satisfied.
we use xto denote a variable and vto denote a constant.
rule condition ctakes the form of x v x.equals v or their negations.
the intuition is that sis special logic to compute the result for the boundary case where xequals v. rule condition ctakes the form of x v x v or their negations and stakes the form of throw e. the intuition is that the input is outside of the input domain and an exception should be thrown.
c. v ariable ranking given a target location for condition synthesis we first try to select variables that can be used in the expression.
our variable ranking consists of the following steps preparing candidate variables filtering variables by document analysis and sorting the variables using dependency based ordering.
the second step is already illustrated in section ii.
in the following we explain the first and the third steps.
preparing candidate variables.
we consider four types of variables local variables method parameters this pointer and expressions used in other if conditions in the current method.
strictly speaking the last type is not a variable we nevertheless include it because many defects require a complex expressions to repair.
to treat the last type unified as variables we assume a temporary variable is introduced for each expression i.e.
given an expression e we assume there exists a statement v ebefore the target conditional expression where vis a fresh variable.
not all the above three types of variables can be used to synthesize a plausible condition.
if a variable takes the same value in two test executions but the condition are expected to evaluate to two different values it is impossible to synthesize a plausible condition with the variable.
therefore we first filter out all such variables.
the remaining variables form the candidate variables to be used in condition synthesis.
sorting by dependency.
given a set of candidate variables we sort them using dependency based ordering.
to sort the variables we create a dependency graph between variables.
the nodes are variables the edges are dependency relations between variables.
concretely we consider the following types of intra procedural dependencies.
data dependency .
given an assignment statement x exp xdepends on all variables in exp.
control dependency .
given an a conditional statement such as if cond stmts else stmts prime o rwhile cond authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
stmts all variables assigned in stmts and stmts prime depend on variables in cond .
note that the dependency relations here are incomplete.
for example if exp contains a method call extra dependencies may be caused by the method.
however implementing a complete dependency analysis is difficult and the current relations are enough for ranking the variables.
the dependency graph defines a partial order of the variables and applying topological sorting on it we can obtain a total order.
note there may be multiple variables having the same priority.
we further sort the variables by the distance between the potentially faulty condition and the assignment statement that initializes the variable.
in the rest of the paper we would use priority level to refer to the priority assigned to variables by the partial order and use rank to refer to the rank in final total order.
to ensure the precision of the synthesized condition we use only variables at the first npriority levels in condition synthesis.
in our current implementation we set nas .
as will be shown later in our evaluation the first two levels contain a vast majority of the variables that would be used in a conditional expression.
d. predicate ranking mining related conditions.
we select an ordered list of predicates by predicate mining.
given a repository of software projects we first collect the conditional expressions that are in a similar context to the conditional expression being synthesized.
currently we use variable type variable name and method name to determine a context.
we say two variable or method names are similar if we decompose the names by capitalization into two sets of words the intersection of the two sets are not empty.
we say a variable name is meaningful if its length is longer than two.
assuming we are synthesizing a condition cwith variable xin the method m. a conditional expression c primeis considered to be in a similar context of c i f it contains one variable x prime x primehas the same type as x the name of x primeis similar to xwhen the name of x is meaningful or the name of the method surrounding c primeis similar to mwhen the name of xis not meaningful.
in our current implementation we utilize the search engine of github1so that we can use all open source projects in github as the repository.
each time we invoke the search engine for returning java source files relating to three keywords if tx and nx where txis the type of variable x and nxis the name of xif the name is meaningful otherwise nxis the name of the surrounding method.
counting predicates.
given a conditional expression in a similar context we extract the predicates used in the conditional expressions.
while we can extract any predicate syntactically from the collected conditions we choose to consider a predefined space of predicates due to the following two reasons.
as shown by an existing study arbitrarily expanding the search space often leads to more incorrect patches and even pequal oequal io lt le gt ge pequal prim const oequal .equals obj const io instanceof class name lt numeric const le float const gt numeric const ge float const prim const numeric const boolean const numeric const integer const float const here obj const represents a constant expression evaluating to an object which can be determined conservatively by static analysis class name represents a class name and integer const float const andboolean const represents constant values of integer float boolean type respectively.
fig.
.
the syntax of predicates fewer correct patches.
syntactically different predicates may semantically be the same.
for example 1and is semantically the same for an integer variable.
if we deal with the predicates syntactically we may incorrectly calculate their frequencies.
fig.
shows the syntax definitions of the predicates we considered.
basically there are predicates comparing a primitive variable with a constant testing equality of an object with a constant .equals and testing the class of an object instanceof .
note operators and only apply to floats.
since x vis equivalent to x v 1for integers we normalize the predicates on integers by considering only and .
we also normalize symmetric expressions such as x v and v x by considering only the former.
we deliberately exclude !
operator because the synthesized condition represents cases that are ignored by the developers and it is unlikely the developers ignore a large space such as !
.
more discussion can be found in section v. we use a function pred to extract a multiset of predicates from a conditional expression.
fig.
shows part of the definition of pred .
we recursively traverse to the primitive predicates and return them.
we omit the definitions for floats and the symmetric forms in fig.
as they can be easily derived.
given a set of conditions in similar contexts we apply the pred function to each condition and sort the predicates by their frequencies in the conditions.
to ensure the precision of our approach we will only consider the top kpredicates for condition synthesis.
currently we set kheuristically as .
as will be shown in the evaluation later is enough to cover the correct predicate in most cases.
we also use a predefined set of predicates for cases that are often ignored by developers.
the current set includes tests for boolean true and false such as true tests for minimum and maximum values such as integer.min value and tests for frequently used jdk interfaces such as instanceof comparable .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
pred llbrackete1 e2 rrbracket pred llbrackete1 rrbracket pred llbrackete2 rrbracket pred llbrackete1 e2 rrbracket pred llbrackete1 rrbracket pred llbrackete2 rrbracket pred llbracket!e rrbracket pred llbrackete rrbracket pred llbracketx.equals v rrbracket .equals eval llbracketv rrbracket pred llbracketx v rrbracket eval llbracketv rrbracket pred llbracketxinstanceof l rrbracket instanceof l pred llbracketxi v rrbracket eval llbracketv rrbracket eval llbracketv rrbracket pred llbracketxi v rrbracket eval llbracketv rrbracket eval llbracketv rrbracket pred llbracketxi v rrbracket pred llbracketxi v rrbracket pred llbracketxi v rrbracket pred llbracketxi v rrbracket pred llbracketxf v rrbracket eval llbracketv rrbracket eval llbracketv rrbracket ... pred llbracketv x rrbracket pred llbracketx v rrbracket pred llbracketxi v rrbracket pred llbracketv xi rrbracket ... pred llbracket rrbracket here e1 e2 eare arbitrary expressions xis a variable vis a constant expression eval is a function evaluates a constant expression to a constant value xiis an integer variable xfis float variable and denotes an arbitrary expression not captured by previous patterns.
fig.
.
the pred function iv .
e v alua tion a. research questions our evaluation intends to answer the following research questions.
rq1 how do the three ranking techniques perform on ranking variables and predicates?
rq2 how does our approach perform on real world defects?
rq3 how does our approach compare with existing approaches?
rq4 to what extent does each component of our approach contribute to the overall performance?
b. implementation we have implemented our approach as a java program repair tool.
our implementation is based on the source code of nopol and the fault localization library gzoltar .
natural language processing is implemented using apache opennlp .
our open source implementation and the detailed results of the experiments are available online2.
c. data set our evaluation is performed on two datasets.
the first dataset consists of the top five most starred java projects on github as of jul 15th .
the second dataset consists of four projects from defects4j a bug database widely used for evaluating java program repair systems .
we use both datasets to answer the first question and use the defects in defects4j to answer the rest three questions.
table i shows basic metrics of the two datasets.
among them io is an android app for google i o conference.
http i sta tistics of the defects 4j d a tabase project kloc test cases defects id github projects google i o app io okhttp http universal image loader image retrofit retrofit elasticsearch search defects4j jfreechart chart apache commons math math joda time time apache common lang lang total is an efficient http client.
image is an android library for image loading.
retrofit is a type safe http client.
elasticsearch is a distributed search engine.
chart is a library for displaying charts.
math is a library for scientific computation.
time is a library for date time processing.
lang is a set of extra methods for manipulate jdk classes.
note that defects4j contains five projects in total.
we did not use the fifth project closure because gzoltar does not support this project due to its customized testing format.
this is consistent with an existing study which also dropped closure due to its incompatibility with gzoltar.
since our predicate mining was implemented on a search engine of github we may happen to locate code pieces from the subject projects in which the defects were already fixed.
to prevent such a bias we used the following two techniques our implementation automatically excludes the files from the same project and from all known forked projects we manually reviewed the search results for all correctly repaired defects and deleted all results that may be a clone of the project code.
d. rq1 performance of the three techniques to answer the first question we took the nine projects in our datasets used our three techniques to rank variables and predicates in the conditional expressions in these projects.
table ii dependency based ordering performance project v ariables level level avg.rank p value io .
.
.
.3e http .
.
.
.5e image .
.
.
.9e retrofit .
.
.
.7e search .
.
.
.8e chart .
.
.
.2e math .
.
.
.1e time .
.
.
.2e lang .
.
.
.9e total .
.
.
.0e v ariables shows the number of variables in the conditional expressions.
level shows how many correct variables are ranked in the corresponding priority level.
avg.rank shows the average rank of the correct variable in the normalized form.
p value shows the result of the wilcoxon signed rank test.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
we first evaluated dependency based ordering.
we took each conditional expression in the subjects and checked how the variables used in the conditions are ranked in dependencybased ordering.
table ii shows the results.
we first consider the priority levels of the variables.
as we can see .
of the variables are in the first priority level and .
of the variables are in the first two levels and there is no significant difference between different types of projects.
to further understand how the correct variable is ranked in the final total order we normalized the rank into by this formula rank total where rank is the rank of the variable starting from and total is the total number of variables.
the result is shown in the column avg.rank .
as we can see the average rankings of all projects are significantly smaller than .
we further performed a wilcoxon signed rank test to determine whether our ranking results are significantly different from random ranking and the last column shows that the results on all projects are significant .
.
further considering many of the variables may not be repair candidates the correct variable would be among the earliest variables selected for synthesis.
table iii document analysis performance project conds nodoc nov ars correct incorrect io .
.
.
.
http .
.
.
.
image .
.
.
.
retrofit .
.
.
.
search .
.
.
.
char .
.
.
.
math .
.
.
.
time .
.
.
.
lang .
.
.
.
total .
.
.
.
conds shows the number of exception guarding conditions.
nodoc shows the proportion of conditions that do not have a javadoc comment.
the last three columns show the proportions within those having a document.
nov ars shows the proportion of conditions that have a javadoc comment that does not mention any variable.
correct shows the proportion of conditions where the javadoc comment mentions its variable.
incorrect shows the proportion of conditions where the set of mentioned variables by the javadoc comment is not empty but does not include the correct one.
we then evaluated document analysis.
since a comment usually mentions only a few variables it is clear that document analysis is effective at filtering out variables but it is not clear whether it filters out wrong variables and how many conditions can benefit from document analysis.
to answer the two questions we took all conditions guarding an exception i.e.
conditional statement of the form if c throw x and ran document analysis on those containing one variable.
table iii shows the result.
as we can see from the table in a vast majority of the cases .
the exception is undocumented and among those documented cases .
of the documents do not mention any variable.
this result shows that document analysis can only benefit a small number of conditions.
on the other hand the false positives are significantly lower than the true positives indicating that the positive effect of document analysis would outperform the negative effect.
wealso manually inspected some false positives and found a main cause is that a word may take multiple meanings.
for example a comment mentions a word value which actually refers to the value of variable fieldtype but in the method there happens to have a variable value causing a false positive.
table iv predica te mining performance project preds included first wef wef io .
.
.
.
http .
.
.
.
image .
.
.
.
retrofit .
.
.
.
search .
.
.
.
chart .
.
.
.
math .
.
.
.
time .
.
.
.
lang .
.
.
.
total .
.
.
.
preds shows the number of predicates.
included shows the percentage of predicates that is included in the returned list.
first shows the percentages of predicates are ranked first among all predicates included.
wef k shows the percentages of cases where the wasted effort is smaller than or equal to k. finally we evaluated predicate mining.
we first extracted the predicates in our space from the conditional expressions in the subject projects.
for each predicate we performed predicate mining to retrieve a list of predicates and checked how the original predicates were ranked.
we did not use any pre defined predicates in this process.
if there is a tie including the original predicate we consider the original predicate has the average rank of all predicates in the tie.
note here many predicates cannot lead to the generation of a patch.
a necessary condition of generating patches from a predicate qis that qshould capture evaluates to true the case of the failed test execution.
since we know the original predicate pevaluates to true at the failed execution we check the satisfiability of p q and any qcausing the formula unsatisfiable cannot generate a patch.
we removed all such predicates that cannot generate a patch.
the result is shown in table iv.
as we can see from the table a large proportion .
of predicates are included in the rank result.
this confirms our assumption the predicates are heavily unevenly distributed.
furthermore those included in the list are ranked high with a .
of the predicates are ranked first.
to further understand how often an incorrect predicate is ranked higher than a correct one uniformly we use the measurement wasted effort .
the wasted effort is defined as the number of incorrect predicates ranked higher than the correct one if the correct one is included in the returned list otherwise is defined as the length of the returned list.
as we can see from the table the wasted efforts is in general small in .
of the cases there is no wasted effort and in .
of the cases the wasted efforts are smaller than or equal to .
e. rq2 performance of acs to answer this research question we executed acs against all the bugs in defects4j.
then we manually compared the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
generated patches with the user patches and deem an acs patch to be correct only when we can discover a sequence of semantically equivalent basic transformations that turn one patch into the other.
note that this criterion is conservative and the reported correct patches are a subset of all correct patches.
our experiments were conducted on an ubuntu virtual machine with i7 4790k .0ghz cpu and 8g memory.
we use minutes as the timeout of each defect.
table v repair results on defects 4j project correct inc. precision recallin spacerecall in space chart .
.
.
math .
.
.
time .
.
.
lang .
.
.
total .
.
.
inc. stands for incorrect patches.
there are defects in our dataset.
the results are shown in the first columns of table v. our approach generated patches in total where are correct giving a precision of .
and a recall of .
.
the current recall considers all defects and many defects cannot be fixed by changing a condition or returning an oracle i.e.
not belonging to our defect class .
to understand the recall within our defect class we further manually analyzed all defects4j user patches and selected those that take a form that our approach can generate.
a patch is in space if it modifies an if condition or returns a value or throws an exception with a guarded condition and the condition contains one variable or an expression used in other conditional statements and the predicate on the variable expression is defined in fig.
.
note that this process is also conservative as other defects may also be fixed by our approach using a form different from user patches.
the last two columns of table v show the results.
to our surprise besides the defects we fixed we were only able to further identify one defect time19 whose patch is within the space of our approach giving our approach a recall of .
.
time19 was not repaired because the correct variable is in the 3rd level after ranking and was filtered out.
this result suggests that our approach is able to fix most defects in our space.
the patch generation time is short.
our approach spent in maximum .
minutes to generate a patch with a median .
minutes and a minimum .
minutes.
note that since the web query time greatly depends on the network speed we exclude the web query time.
a more elaborated implementation could use a local repository to avoid most network query time.
we also qualitatively reviewed the defects and the generated patches.
our observation is that although an acs patch usually takes a simple form it can fix challenging defects.
our running example in fig.
requires advanced knowledge with the math library to know that abs may return a negative value.
another example is lang7 in method createnumber of class numberutils which converts a string into a number.
our approach generates the following patch for the method.
if str .
startswith throw new numberformatexception return new bigdecimal str the standard routine is to parse the string to the constructor of bigdecimal and if the string cannot be parsed an exception should be thrown by bigdecimal .
however though unstated in the specification the bigdecimal implementation in java jdk would accept a string with two minus sign but parses it into a wrong value.
thus a guard must be added.
this defect is difficult as we actually deal with a defect in jdk implementation.
f .
rq3 comparison with existing approaches we compare our results with four program repairs systems jgenprog nopol a reimplementation of par mentioned as xpar and historicalfix which are all program repair systems that have been evaluated on defects4j within our knowledge.
among them jgenprog and nopol were evaluated on the same four projects as us while xpar and historicalfix were evaluated on all the five projects .
for a fair comparison we took only the results on the four subjects.
please note that in the experiments the timeout for jgenprog and nopol was set to three hours the timeout for xpar and historicalfix was set to minutes and the timeout for acs was minutes.
though the machines for executing the experiments were different the results are unlikely to favor our approach because our timeout setting is much shorter than others.
table vi performance of rela ted approaches approach correct incorrect precision recall acs .
.
jgenprog .
.
nopol .
.
xpar .
historicalfix110 .
.
1the evaluation was based on manually annotated faulty methods but not automatically located methods.
2historicalfix and par were tested on selected defects from defects4j but the authors of that paper believe all other defects cannot be fixed.
3historicalfix generated correct patches for defects but only were ranked first.
4not reported.
table vi shows the results from different systems.
from the table we can see that our approach has the highest precision among all approaches and is more than four times more precise than the second precise approach.
our recall is also the highest among the five approaches.
some of the other state of the art systems such as angelix and prophet were designed for c and cannot be directly compared.
nevertheless their evaluations on the genprog benchmark shows that they have a precision of .
and .
respectively.
since our precision is noticeably higher than them it might be possible to combine our approach with them to increase their precisions in future.
we also determine whether the fixed defects by acs were also fixed by any other approaches.
we found only defects authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
were fixed by other approaches and were fixed for the first time.
this result shows that our approach can effectively complement existing approaches on fixing more defects.
g. rq4 detailed analysis of the components in this section we evaluate the performance of the three ranking techniques based on the defects in search space.
table vii shows the detailed data about the repair process of the defects.
from the table we analyze the performance of the three techniques as follows.
dependency based ordering.
as we can see from the table dependency based ordering performs a significant role to select the correct variables.
as we can see from can.
column there may be a large number of candidate variables up to variables.
after dependency based ordering the correct variable is usually in the first or the second to select which greatly reduces the risk of producing incorrect patches and the time for repair.
document analysis.
document analysis performs a relatively small but a useful role.
from the table we can see that document analysis was only able to filter one variable which is consistent with the result of rq1 as many exceptions are undocumented.
to understand how much document analysis contributed to our result we further reran acs without document analysis on all defects where document analysis filtered variables.
the result showed that document analysis successfully prevented one incorrect patch to be generated and had not prevented any correct patch.
therefore document analysis did contribute to the overall performance of acs.
predicate mining.
predicate mining also play a significant role of preventing incorrect fixes from being generated.
in theory each candidate variable at a wrong location or each wrong variable ranked higher than the correct variable at the correct location can produce incorrect patches.
this is because we can always generate x vto capture the failed test case where xis the candidate variable and vis the value of xin the failed test execution.
as we can see from prv.
column many incorrect patches have been prevented by predicate mining on the defects.
further considering the large number of defects that are not within the search space we can assume that predicate mining must have prevented a large number of incorrect patches from being generated.
please note that prv.
may be larger than rank because fault localization may initially locate wrong locations.
furthermore as we can see from the blk.
column no correct patch is blocked by predicate mining.
since predicate mining uses both predefined predicates and mined predicates we further inspect how many successful patches whose predicates are predefined and how many are mined from github.
we found that .
out of the patches use mined predicates and .
uses predefined patches.
many mined predicates cannot be easily predefined.
for example below is the patch generated for math35 where the predicate tests the range of a rate which is usually between and .
the two lines are added from two failed tests respectively.table vii detailed performance analysis bug id can.
flt.
rank prv.
blk.
fixed chart14 no chart19 no math3 no math4 no math5 no math25 no math35 no math61 no math82 no math85 no math89 no math90 no math93 no math99 no time15 no lang7 no lang24 no lang35 no unfixed time19 no can.
shows the number of candidate variables in the correct location.
flt.
shows how many variables were filtered out by document analysis.
ranks shows how the correct variable was ranked by dependency based ordering.
prv.
shows how many variables were prevented to generate incorrect patches by predicate mining.
blocked shows whether the correct patch was blocked by predicate mining.
if elitismrate double throw ... if elitismrate double throw ... another example is the patch for math5 where the predicate compares with an instance of the complex class.
if this .
equals new c o m p l e x return inf templates.
we also study how many defects each template fixes.
we found that are fixed by exception throwing are fixed by value returning and are fixed by narrowing.
this result suggests that our approach may be effective in fixing defects related to missing boundary checks.
v. d iscussion alternative method in condition synthesis.
there are two methods to synthesize a predicate and a variable.
for example below is a correct patch we synthesize for math85.
if f a fb if f a fb !
f a fb in our approach acs mines a predicate to capture the failed execution where fa fbis zero and then negate the condition to get the expected result.
an alternative is not to negate conditions and rely on predicate mining to discover a predicate !
that evaluates to false on failed test execution.
we choose the former approach because it gives us more control over the predicate space to exclude the predicates that are unlikely to be ignored by human developers.
currently we exclude !
v as the developers are unlikely to ignore such a large input space.
if we resort to the latter solution we have to at least include !
into the predicate space authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
which unlikely leads to more correct patches than the former approach but nevertheless brings the risk of generating more incorrect patches.
generalizability.
a question is whether our repair results on defects4j can be generalized to different types of projects.
to answer the question we designed rq1 that tested our ranking techniques on different types of projects and the results show that dependency based ordering and predicate mining gives a consistent ranking among different projects.
document analysis heavily depends on how much documentation is provided.
however as rq4 shows document analysis plays a relatively minor role in affecting our results only one variable is removed for defects.
therefore we believe our approach can achieve a similar precision across a wide range of projects.
vi.
r ela ted work automatic defect repair is a hot research topic in recent years and many different approaches have been proposed.
some recent publications have made thorough survey about the field and we discuss only the approaches that are related to condition synthesis and patch ranking.
condition synthesis for program repair.
several program repair approaches adopt condition synthesis as part of the repair process.
typically a condition synthesis problem is treated as a specialized search problem where the search space is the all valid expressions and the goal is to pass all tests.
nopol reduces the search problem as a constraint solving problem and uses an smt solver to solve the problem.
semfix uses a similar approach to repair conditions and other expressions uniformly.
spr uses a dedicated search algorithm to solve the search problem.
dynamoth collects dynamic values of primitive expressions and combines them.
several approaches try to fix a defect by mutating the program which may also mutate conditions.
for example genprog and searchrepair mutate programs by copying statements from other places.
par mutates the program with a set of predefined templates.
however since the goal of these approaches is to pass all tests it is difficult for these approaches to achieve a high precision.
as reported jgenprog the java implementation of genprog and nopol have a precision of .
and .
on defects4j respectively.
patch ranking techniques.
many researchers have realized the problem of low precision and have proposed different approaches to rank the potential patches in the repair space so that patches with higher probability of correctness will be ranked higher.
directfix angelix and qlose try to generate patches that make minimal changes to the original program.
directfix and angelix use syntactic difference while qlose uses semantic differences .
minthint uses the statistical correlation between the changed expression and the expected results to rank the patches.
prophet learns from existing patches to prioritize patches in the search space of spr.historicalfix learns from existing patches to prioritize a set of mutation operations.
autofix ranks the patches by the invariants used to generate them.
compared with these approaches our approach uses more refined ranking techniques specifically designed for condition synthesis.
our approach is also the first to utilize the locality of variables the program document and the existing source code in contrast to the existing patches for ranking.
the full version of this paper contains an example to explain why our ranking technique is more refined.
another way to increase precision is the recently proposed anti patterns .
an anti pattern blocked a class of patches that are unlikely to be correct.
compared with anti patterns our approach aims to rank all patches including those not blocked by anti patterns.
deepfix uses deep learning to directly generate patches.
the precision of this approach depends on the neutral network learned from the training set.
however so far this approach is only evaluated on syntactic errors from students homework and its performance on more complex defects is yet unknown.
qacrashfix is an approach that constructs patches by reusing existing patches on stackoverflow.
qacrashfix achieves a precision of .
however this approach is limited to crash fixes whose answers already exist on the qa site which does not apply to most defects fixed by our approach on defects4j.
defect classes with precise specification.
several approaches target at defect classes where the specification is complete effectively avoiding the problem of weak test suites .
typical defect classes include memory leaks where the specification is semantically equivalent to the original program without leaks concurrency bugs where the specification is semantically equivalent to the original program without concurrency bugs and configuration errors where the specification can be interactively queried from the user.
though these approaches have a high precision they target totally different defect classes compared with our work.
fix with natural language processing.
existing research has already brought natural language processing into program repair.
r2fix generates patches directly from bug report by using natural language processing to analyze bug reports.
different from r2fix in our approach we utilize the document to enhance the precision of program repair and we still require a failed test.
vii.
c onclusion in this paper we study refined ranking techniques for condition synthesis and the new program repair system achieves a relatively high precision .
and a reasonable recall .
on defects4j.
the result indicates that studying refined ranking techniques for specific repair techniques is promising and calls for more studies on more different types of repair technique.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.