a flexible and non intrusive approach for computing complex structural coverage metrics michael w. whalen suzette persony neha rungtaz matt staatsxand daniela grijincu university of minnesota minneapolis minnesota usa email whalen cs.umn.edu ynasa langley research center hampton virginia usa email suzette.person nasa.gov znasa ames research center moffett field california usa email neha.s.rungta nasa.gov xgoogle inc. zurich switzerland email staatsm gmail.com university of st. andrews scotland uk email dana.grijincu gmail.com abstract software analysis tools and techniques often leverage structural code coverage information to reason about the dynamic behavior of software.
existing techniques instrument the code with the required structural obligations and then monitor the execution of the compiled code to report coverage.
instrumentation based approaches often incur considerable runtime overhead for complex structural coverage metrics such as modified condition decision mc dc .
code instrumentation in general has to be approached with great care to ensure it does not modify the behavior of the original code.
furthermore instrumented code cannot be used in conjunction with other analyses that reason about the structure and semantics of the code under test.
in this work we introduce a non intrusive preprocessing approach for computing structural coverage information.
it uses a static partial evaluation of the decisions in the source code and a source to bytecode mapping to generate the information necessary to efficiently track structural coverage metrics during execution.
our technique is flexible the results of the preprocessing can be used by a variety of coverage driven software analysis tasks including automated analyses that are not possible for instrumented code.
experimental results in the context of symbolic execution show the efficiency and flexibility of our nonintrusive approach for computing code coverage information.
i. i ntroduction software analyses often leverage code coverage information to reason about the dynamic behavior of software.
coverage information describes structural elements in the source code such as paths functions statements and branches that have been executed covered .
coverage information is used to assess test adequacy perform test case selection and prioritization and for test suite minimization .
it has also been used for other software maintenance tasks such as predicting fault likelihood and fault localization .
although structural code metrics are defined at the source code level they are measured during execution of the compiled code e.g.
java bytecode.
existing state of the art techniques compute code coverage by monitoring the execution of the instrumented bytecode to determine which coverage obligations are satisfied.
instrumentation involves insertion of trace statements at strategic locations in the bytecode depending on the coverage metric.
then as bytecode instructions are executed the instrumentation facilitates tracking the parts of the corresponding source code that are executed covered .instrumentation based techniques can incur considerable overhead by adding a large number of conditional statements to the original code which in turn can significantly increase the program s execution space.
the problem becomes even worse as the complexity of the coverage criterion increases both in terms of the number of coverage obligations and the number of operators in each obligation.
for metrics such as modified condition decision coverage mc dc a metric widely used in the avionics software domain the overhead of the instrumentation can render the cost of computing the metric prohibitive for programs of even modest size.
another drawback of code instrumentation is that it may interfere with other analyses e.g.
a change impact analysis because the instrumentation adds behaviors to the execution space of the program.
without a clear delineation between the original program behaviors and those arising from instrumentation it is not possible to combine complementary analyses.
finally there are often considerable risks associated with code instrumentation and great care must be taken to ensure the instrumentation does not modify the behavior of the original code e.g.
due to extra evaluations of boolean expressions with side effects.
in this work we introduce a novel preprocessing approach based on static partial evaluation of the decisions in the source code and a source to bytecode mapping procedure to generate the information necessary to efficiently track various structural coverage metrics during execution without the need for code instrumentation.
tracking of the coverage metrics is accomplished by using any tool capable of monitoring the instruction stream such as an instrumented jvm or a software verification tool such as java pathfinder .
in this work we use the symbolic pathfinder tool to track the coverage metrics compute the set of covered obligations and generate test cases that cover the obligations.
our approach offers substantial benefits for computing coverage metrics such as mc dc condition decision multiple condition weak mutation and strong mutation by avoiding the drawbacks of code instrumentation described above.
there are benefits of using our approach for metrics such as branch or statement that do not require the same degree of instrumentation as mc dc however the relative improvement is not as dramatic.
our approach is efficient in that it doesnot increase the amount of code that must be monitored in order to compute the coverage metrics.
it is also flexible enabling complementary automated program analyses which do not have a mechanism to distinguish between the original code and the instrumentation to leverage coverage information to compute novel coverage metrics e.g.
structural coverage metrics over code impacted by a set of changes.
in this work we describe how the preprocessed coverage information can be combined with change impact information computed by a software analysis framework directed incremental symbolic execution dise to analyze evolving software.
to demonstrate the efficiency and flexibility of our approach we perform an empirical evaluation focused on two analyses standard symbolic execution with instrumentationbased coverage measurement and dise as applied to the problem of generating test suites that satisfy mc dc obligations.
we also compute the overhead incurred when using our approach with standard symbolic execution relative to symbolic execution with no measurement.
we selected the mc dc coverage criterion because we and other researchers have found the measurement of mc dc to be a serious bottleneck when applying these analyses.
the results of our study indicate that the application of our preprocessing approach results in significant speedups in test input generation speed up to 4x relative to an instrumentation based approach.
generally low overhead of roughly relative to standard symbolic execution when applied to sufficiently large systems was also observed and the applicability of the approach to dise was confirmed.
this paper makes the following contributions we present a novel idea for leveraging preprocessed information to track coverage obligations during execution of the code under analysis to avoid the issues related to code instrumentation.
we present algorithms to preprocess the coverage conditions and implement the preprocessing algorithms as an eclipse plugin to automatically collect the information relevant to various structural coverage metrics.
we present the algorithms for leveraging the preprocessed coverage information for two mc dc coverage based applications built on symbolic pathfinder symbolic execution for test case generation and dise for regression analysis.
we empirically evaluate our approach to show that the preprocessed coverage information enables efficient coverage based analyses and novel analyses that were not be possible with instrumented code.
ii.
b ackground in software testing the need to determine the adequacy of test suites has motivated the development of several test coverage criteria .
one such class of criteria are structural coverage criteria which measure test suite adequacy in terms of coverage over the structural elements of the system under test.
in the domain of critical systems particularly in avionics demonstrating structural coverage is required forif testgen.needstest mcdc 55 120 testgen.printcommentif a b c mcdc 55 120 verify.ignoreif true if testgen.needstest mcdc 56 120 testgen.printcommentif b a mcdc 56 120 verify.ignoreif true if testgen.needstest mcdc 57 120 testgen.printcommentif c !
b a mcdc 57 120 verify.ignoreif true if testgen.needstest mcdc 58 120 testgen.printcommentif !a mcdc 58 120 verify.ignoreif true if testgen.needstest mcdc 59 120 testgen.printcommentif !b !
c a mcdc 59 120 verify.ignoreif true if testgen.needstest mcdc 60 120 testgen.printcommentif !c !
b a mcdc 60 120 verify.ignoreif true if a b c ... fig.
.
instrumentation required for aand borc certification .
in recent years there has been rapid progress in the creation of tools for automatic directed test generation for structural coverage criteria as well as tools promising to improve coverage and reduce the cost associated with test creation.
a. motivating example the standard mechanism for generating test suites and or measuring the adequacy of test suites involves instrumenting the code and monitoring the instrumentation output during execution.
however for complex test metrics the overhead of measurement can be significant.
to instrument for mc dc for example it is necessary to create two test obligations for every condition basic boolean expression .
to illustrate we use a small code snippet as a example if a b c .. the instrumentation must track whether each test obligation i.e.
specification of a structural component relevant to the coverage metric is satisfied.
this leads to a substantial amount of instrumentation code for example the instrumentation in generates the instrumented code in figure for the single line of code shown in the snippet above.
our goal in showing the instrumented code in figure is not for the reader to fully understand mechanics of the instrumentation it is rather to illustrate how significant the instrumentation can be for a seemingly simple expression.
for programs with significantamounts of boolean logic the size of the instrumented code is often several times as large as the original code.
during execution of the instrumented program the executed annotations record the coverage obligations that have been satisfied.
the annotations however lead to additional branch points that are not in the original program this slows down execution in a standard vm and further exacerbates the path explosion problem when applying analyses such as symbolic execution.
furthermore code instrumentation obscures the original code.
in figure the instrumentation code is the sequence of ifstatements preceding the code under analysis and would be indistinguishable from the code under analysis without a priori knowledge of the naming conventions and other details regarding how the instrumentation tool modifies the source code.
b. structural coverage metrics while a wealth of different structural coverage metrics over source code have been proposed only a handful are commonly used as adequacy criteria.
for a test suite the most common criteria are defined as follows statement coverage requires that each statement within the program is executed at least once.
branch coverage requires that each conditional branch within the program e.g.
if statement evaluates to both true and false at least once.
decision coverage decision coverage requires that each decision evaluates to both true and false.
we follow the rtca do178b c definition in which decision coverage requires that each stand alone boolean expression decision that is not an immediate child of another boolean expression via a boolean operator take on values true and false e.g.
x a and b would require that a and b take on both true false values .
modified decision condition coverage mc dc mc dc requires that each point of entry and exit in the program has been invoked at least once each condition a boolean expression containing no boolean operators in a decision in the program has taken on all possible outcomes at least once and each condition has been shown to independently affect the decision s outcome each metric subsumes the metrics listed above it any test suite satisfying mc dc satisfies decision coverage a suite satisfying decision coverage satisfies branch coverage etc.
in this paper we use the masking form of mc dc to determine the independence of conditions.
in masking mc dc a basic condition is masked if changing its value cannot affect the outcome of a decision.
to better illustrate the definition of masking mc dc consider the expression a and b .
to show the independence of b we fix the value of a to t and vary the value of bto see if the result of the condition also changes with the value of b note that we need to fix the value of aotherwise varying bwill not affect the outcome of the expression.
independence of ais shown in a similartable i top row test suites providing masking mc dc coverage for a and b anda or b and c .
bottom row short circuit mc dc obligations for and or.
aba and b tt t tf f ft fabca and b or c ttf t tft t tff f fft t aba and b tt t tf f f faba or b t t ft t ff f manner.
the top row left element of table i shows the test suite required to satisfy mc dc for the expression a and b .
when we consider decisions with multiple boolean operators we must ensure that the test results for one operator are not masked by the behavior of other operators.
for example given a and b or c the tests for b or c will not affect the outcome of the decision if ais f. the top row right element of table i shows a test suite that would satisfy mc dc for the expression a and b or c .
in c c java and most other imperative languages boolean expressions are evaluated using short circuit evaluation.
in short circuit evaluation the right side subexpressions ofand ororexpressions are not evaluated if the expression is known to be f or t respectively after evaluation of the left side subexpression.
in such cases since the right side subexpression is not evaluated the right hand side value becomes a don t care denoted as shown in the bottom row of table i. since we are analyzing imperative code we assume the short circuit version of mc dc in the remainder of the paper.
iii.
p reprocessing in this section we describe our preprocessing approach based on static partial evaluation of the decisions in the source code to enable efficient tracking of mc dc coverage information at runtime.
the preprocessing information gathered for mc dc can also be used to measure coverage for the other coverage metrics from section ii as described in section iii d. a. example demonstrating independence and masking in java evaluation occurs in the left to right order of the constituent conditions so determining the independence of a condition depends on the location of the condition within the decision.
conditions on the right side of boolean operators may mask out the effect of left side conditions but not viceversa.
on the other hand conditions on the left side of boolean operators may cause the evaluation of right side conditions to be skipped entirely short circuited .
for example consider the complex boolean decision at the top of figure .
the decision tree shown below the decision contains the corresponding java byte code and preprocessing annotations for each condition described in section iii c .
if aevaluates to false then the evaluation of b c is skipped entirely.
if cis evaluated then it must be the case that bevaluated to false and that a evaluated to true.
if cevaluates to false then b c must evaluate to false and the effect of ais masked out.
b. marking functions before we present the preprocessing algorithm we first provide intuition about the information needed by marking functions during runtime to motivate the design of the static partial evaluation.
a marking function is required at runtime to measure mc dc coverage.
in essence a marking function tracks whether each condition within a decision independently affects the decision when the condition is assigned both true and false values.
a concrete example of a marking function is shown in section iv.
to represent the obligations that need to be covered we use triples hdi cj vi to record that a condition cjwhen assigned the valuevindependently affects the decision di.
there are two possible values of v true and false.
we assign each decision a unique index di and each condition within a decision an index relative to the decision cj in figure the decision andcondition markings .
we call the set of triples assigned by a test suite the independence set .
a challenge is that when a condition is evaluated at runtime we do not necessarily know that it has an independent effect on the decision because its effect may be masked out by a condition evaluated subsequently within the same decision.
similarly the evaluation of the current condition may mask out the effect of earlier conditions within the same decision.
during evaluation of a decision at runtime we need to maintain a temporary set temp of triples to record conditions that are relevant but not yet known to have an independent effect.
the marking function performs three operations whenever a condition is evaluated it adds thehdi cj vipair associated with the condition and outcome to temp if the outcome of the condition leads to masking it removes elements associated with previous conditions fromtemp and if the outcome of the condition causes the outcome of the decision to be known it unionstemp into the independence set.
in order to create a marking function we need to know for each condition the index of the condition within the decision to add to the temporary set the indices of all conditions that the condition masks when it evaluates to true or false to remove them from temp and whether the condition terminates the decision to know when to add the contents of temp to the independence set.
in figure these are stored in the condition anddecision markings the masks markings and the terminates markings respectively.
we next present pseudocode for computing the masking and termination information necessary for marking functions.
iload 1 ifeq a c b iload 2 ifne iload 3 ifeq 14if a b c x else y x y decision condition 1masks t f terminates t false f true decision condition 2masks t f terminates t true f falsedecision condition 3masks t f terminates t true f truefig.
.
code snippet with complex decision and its translation into bytecode c. static partial evaluation the pseudocode shown in figure computes the masking and termination information needed by the marking function in order to measure mc dc coverage.
this pseudocode assumes the existence of a simple abstract syntax tree ast for decisions containing andexpr orexpr notexpr and conditionexpr basic boolean expression classes with a handful of helper methods hasparent which returns true false depending on whether the expression is the child of another expression within a decision getparent which returns the parent expression if it exists side which assuming that the expression has a parent returns whether this expression is the l eftor r ight child of a binary expression or the u nary child of a unary expression leftandright which return the left and right children of a binary expression respectively and getindexes which returns the set of condition indices for the tree rooted at the expression.
the preprocessing algorithm in figure consists of three functions partialeval setmask and terminates .
the setmask method computes which preceding conditions in a decision are masked out by a given condition.
the terminates method marks if a given condition terminates a decision for a corresponding truth value.
these methods use the partialeval method to compute the required information.
in order to generate the preprocessed coverage obligations we run the setmask andterminates functions on each truth value true and false of all leaf level conditions in every decision within the program.
the masking and termination information computed for our simple example is shown in figure .
the partialeval function in figure is a short circuit partial evaluator which evaluates a boolean expression givenprocedure partialeval e v ife side r ight then returnv else if e.getparent isaandexpr andv ffthen return ff else if e.getparent isaorexpr andv ttthen return tt else if e.getparent isanotexpr andv ttthen return ff else if e.getparent isanotexpr andv ffthen return tt else return unknown procedure setmask e mask v ifv unknown then returnmask else ife hasparent then ife side right and eisaandexpr andv ff or eisaorexpr andv tt then mask mask e getparent .left .allindexes return setmask e getparent mask partialeval e v else returnmask procedure terminates e v ifv unknown then return f else if note.hasparent then return t else return terminates e getparent partialeval e v fig.
.
pseudocode for masking and terminates functions the valuevof one of its subexpressions e. partial evaluation is used to determine whether or not the decision is guaranteed to complete given a valuation of one of its leaf level expressions and also as we will see to determine the scope of masking.
the function is three valued returning true or false tt or ff if the expression s value can be definitely determined or unknown if it cannot.
to compute masking recall that in short circuit mc dc masking occurs when the right side of an and expression evaluates to false or the right hand side of an orexpression evaluates to true line .
in these cases we want to mask out the affected left side expressions line .
note that in a complex decision a condition may be on both the left side of one operator and the right side of another for example the condition bin figure .
in this case even if the condition is on the left hand side of its immediate parent it may mask out conditions further up the decision tree structure.
we recursively call the setmask function line until the value of the current operator is u nknown .
for termination we check to see whether we can completely determine the outcome of the decision via partial evaluation starting from the assignment of a leaf level condition.
if the outcome of partial evaluation is u nknown then the decision cannot be determined and we return false line .alternately if we complete evaluation of the decision with a t or f value we return true line .
otherwise we continue partial evaluation of the decision.
after the masking and termination information is computed it is mapped to the bytecode generated by the java compiler.
as demonstrated in figure the structure of the original decision is translated into a block of bytecode with conditional branch instructions for each condition ordered sequentially matching the left to right order of the conditions.
we create a mapping between information generated by static partial evaluation to the conditional branch instructions in the java bytecode.
the pseudocode presented in figure is suitable for a subset of java.
the preprocessing of full java requires handling conditional operator expressions ternary operators nested decisions and boolean relational operators such as boolean equality inequality and xor.
note that our implemented algorithm handles all these categories.
for space considerations we only present a subset of the expressions in the paper.
d. decision branch and statement coverage in this work we focus only on mc dc coverage however the preprocessing information computed can also be used to measure decision coverage and branch.
while statement coverage can be measured with minimal effort.
for decision coverage rather than maintain a set of conditions one instead maintains a set of decisions the masking information can be ignored.
instead we simply examine the value v of conditions that terminate the decision if true a hdi vivalue is added to the set of decisions.
to measure branch coverage requires only a small additional bit of information which we have in our implemented preprocessing tool we need to know whether the decision is a control decision that determines the value of an if while or for statement if not we do not record coverage information for it.
statement coverage can be measured by measuring branch coverage then post processing the control flow graph to determine which statements are covered.
the marking functions can also be adapted appropriately for the other structural criteria.
iv.
a pplications once the coverage information is computed by the preprocessor it can be used by any tool capable of monitoring the instruction stream such as a jvm that is instrumented or by utilizing processor debug instructions to trap the instructions in which a condition is evaluated.
software verification frameworks that interpret bytecode e.g.
a model checker or symbolic execution framework can also be used to efficiently compute the set of covered obligations on the fly.
a. test case generation using symbolic execution the algorithm in figure is an instance of a marking function which illustrates how the preprocessed coverage information can be used during symbolic execution to generate test case inputs that cover mc dc obligations.
in symbolicprocedure initialize exploredconds bu er t s0 getinitstate depthfirstsearch hs0 truei procedure depthfirstsearch hs i iferror s ordepth s orgetsucc s then t t generatetestinput return for eachhsi ii2getsucc s do updateobligations si searchtree hsi ii procedure updateobligations s ifisconditionalstmt s then hdi cji getdecisioncondition s v getconditionvalue s v2ft fg bu er bu er fhdi cj vig bu er bu erngetmaskedconds hdi cj vi ifhcj vi2terminates di then exploredconds exploredconds bu er bu er fig.
.
tracking mc dc obligations in symbolic execution execution symbolic values are used in lieu of concrete values for program variables.
a program state s consists of the unique program location identifier and values for the program variables including heap locations.
in symbolic execution the program state also includes a path condition that contains the constraints on the symbolic program variables in the program.
as constraints are added to the path condition during execution it is checked for satisfiability.
a satisfiable path condition represents a feasible execution path whereas an unsatisfiable path condition represents an infeasible path.
in figure the initialize method initializes the set of observed complex conditions exploredconds the temporary buffer bu er and the set of test inputs tto empty.
the depthfirstsearch method is then invoked with the initial program state s0and the initial path condition true .
the depthfirstsearch method in figure explores the symbolic execution space until either a an error is encountered b a user defined depth bound is reached or c the end of the path is reached and there are no more successors to the current state.
note that for programs with recursive methods and loops that operate on symbolic variables a user specified depth bound is required for search termination.
the getsucc method takes as input a symbolic program state and the current path condition to generate the set of successor states.
here we assume that the path conditions are checked for satisfiability within the getsucc method.
for each successor state the updateobligations method is invoked and then the search is recursively called on the successor state si.
theupdateobligations method in figure updates the set of observed test obligations.
at line there is a check to determine whether the current program location corresponds to a conditional branch statement in the object code.
recall that the static partial evaluation maps each conditional branch statement in the object code to a unique condition within a decision in the program source.
at line the getdecisionconditionprocedure initialize p0 impconds exploredconds bu er t s0 getinitstate dise hs0 truei procedure dise hs i iferror s ordepth s orgetsucc s then t t generatetestinput return for eachhsi ii2getsucc s do updateobligations si if not prune s then dise hsi ii procedure prune s if not isconditionalstmt s then return true hdi cji getdecisioncondition s v getconditionvalue s for eachhd0 c0 v0i2impconds0nexploredconds do ifisreachable hdi cj vi hd0 c0 v0i then return true return false fig.
.
pruning the search in dise based on coverage of impacted mc dc obligations in evolving programs method returns a tuple containing the decision diand condition cjfor a given conditional branch statement and at line we get the value of the conditional branch statement tindicates that the branch will be taken and findicates that the branch will not be taken.
the bu er data structure in figure contains all the unmasked conditions for the current decision being evaluated.
at line the condition cjis added to the buffer then at line 15each condition in the buffer masked by cjis removed from the buffer along with its corresponding value.
at line a check is performed to determine if the search has reached a condition whose value terminates a decision and if so adds all of the conditions in the buffer to the exploredcond set and clears the buffer.
note that when the next decision in the program is encountered the buffer is empty.
at the end of symbolic execution the set of exploredconds contains all of the mc dc obligations covered during the analysis and the set tcontains the set of test inputs whose execution guarantees coverage of the obligations in the exploredcond set.
similar algorithms could also be used with other search techniques such as model checking and dynamic symbolic execution and for other analyses such as measuring test adequacy.
b. regression analysis there are several automated program analysis techniques that leverage the structure of the code as well as the semantics of the system under test to reason about it.
these techniques however cannot operate on instrumented code because of the changes to the the structure and semantics of the program caused by the instrumentation.
one such analysis framework is directed incremental symbolic execution dise platform for analyzing evolving software programs .
dise leverages the differences between two related program ver sions to detect and characterize the differences in program behaviors between the two versions.
dise supports various software maintenance tasks such as regression testing regression verification equivalence checking and delta debugging among others.
the inputs to dise are two related program versions p andp0.
a source level abstract syntax tree differencing algorithm computes the set of syntactic changes to presulting inp0.
the changes are treated as slicing criteria and standard control and data dependence analyses are used in the slicing algorithm to compute the set of program statements that may be impacted by the changes.
dise uses the set of impacted locations to direct a symbolic search of the system under analysis to generate path conditions that encode impacted program behaviors.
in this work we extend the dise framework to compute a novel analysis which combines the existing change impact analysis results with the preprocessed coverage information to compute a set of test inputs that satisfy complex structural coverage obligations e.g.
mc dc for program behaviors that may be impacted by the differences between pandp0.
at a high level the modified dise algorithm shown in figure uses information from the static analysis to determine for each impacted conditional branch statement at the bytecode level the corresponding condition and decision.
the set impconds represent the set of tuples containing condition decision and condition values for each impacted conditional branch statement.
the impconds set is provided as input along with the new program p0in figure .
the search strategy and the helper method definitions in figure are similar to those in figure .
the isreachable function takes as input two tuples of decision condition and condition values and checks whether the corresponding conditional branch statement at the object code level is reachable.
in order to check reachability dise performs a conservative check to determine if a path exists in the interprocedural control flow graph from one program location to another.
when there are no unexplored decision condition tuples reachable from the current program location the analysis prunes the search and backtracks.
note that it is possible to prune entire sub trees reachable from the current program location when the current path will not lead to any impacted coverage obligations that have not already been covered.
v. e valuation we empirically evaluate our non intrusive approach for computing with complex structural coverage metrics.
our evaluation addresses the following three research questions rq1 how does our approach for preprocessingmc dc coverage conditions improve the efficiency of test input generation in symbolic pathfinder when compared with an existing state of the art instrumentation based test generation technique ?
rq2 how much overhead does symbolic execution incur when leveraging the coverage condition information computed by our preprocessor?rq3 does a regression analysis technique based on our non intrusive approach outperform a monolithic analysis technique?
a. tool support we use a version of the eclipse plugin from our previous work to instrument the java source code.
the original implementation of the plugin did not include a check to determine if an obligation was previously covered thus computing redundant instrumentation and exacerbating the issues outlined in section ii.
to address this issue we have modified the plugin to check if an obligation was previously covered before attempting to cover it again.
this helps reduce the path explosion problem in the instrumentation algorithm and improves the algorithm performance relative to the original plugin implementation.
this modification was done to avoid bias in the evaluation towards our non intrusive approach.
we implement the preprocessor for computing condition information as an eclipse plugin.
the plugin automatically analyzes the ast generated by the eclipse java compiler to compute the set of conditions and their respective locations in the source code that are relevant for tracking coverage obligations.
the plugin results are saved to an xml file that can then be used during execution of the code under analysis to track coverage obligations.
we implement the test case generation application as an extension to the symbolic pathfinder spf engine for analyzing java bytecode.
for a given system under test our extension reads in the xml and sets up data structures to map information about the uncovered decision condition and value triples in the source code to the java bytecode.
a listener in the extension then monitors the execution of the bytecode and updates coverage information based on the algorithm presented in section iv.
finally we use the regression analysis implemented in the dise framework another extension to spf.
the preprocessor plugin and extension to spf that uses the preprocessed information can be downloaded from b. artifacts we evaluated our technique on six java artifacts.
the first two artifacts are java implementations of two container classes used in .
fibheap is an implementation of a fibonacci heap consisting of 286sloc.
treemap is an implementation of a red black tree extracted from java.util.treemap and consisting of 580sloc.
the third program traffic anti collision avoidance system tcas is a java implementation of a system to avoid air collisions.
it is available from the software artifact infrastructure repository sir 1which consists of sloc.
the fourth artifact the wheel brake system wbs is a synchronous reactive component derived from the wbs case example found in arp .
the wbs is used to provide safe breaking of the aircraft during taxi landing and in the event 1sir repository.
an aborted take off.
the simulink model was translated to c using tools developed at rockwell collins and manually translated to java.
it consists of sloc.
the altitude switch asw and fgs applications are asynchronous reactive components from the avionics domain.
they were developed as a simulink models and were automatically translated to java using tools developed at vanderbilt university .
c. experimental setup we explore one independent variable in our study the method for computing achieved coverage.
two methods are explored the non intrusive approach presented in this work and a state of the art instrumentation based technique.
the two dependent variables in our evaluation are the coverage achieved against time for rq1 and the overall wall clock time required to completely explore all paths rq2 .
note that for rq1 it was not always feasible to run until the entire system was explored as the time required is sometimes too long.
for both research questions time measurements do not include the time required to perform the preprocessing step.
for the artifacts used in this study the preprocessing time to instrument the code or to preprocess the coverage information was a small fraction of the analysis time less than one second .
in this study we control two factors the coverage criterion used and the randomization of symbolic execution s exploration during test generation.
we chose to explore the effectiveness of our approach in the context of mc dc coverage a complex structural coverage criteria mandated for use in critical systems domains such as avionics and automotive systems.
mc dc is also a prime example of a structural coverage criteria that quickly becomes unwieldy when computed using source code instrumentation.
to avoid any bias associated with this search order we randomize which branch is first explored and run each approach artifact combination ten times thus producing ten different sets of results for each combination of artifact approach.
d. results and analysis for each artifact we compute the set of decision condition and value triples for each conditional branch statement in the java bytecode using the preprocessor un instrumented version .
we also create an instrumented version of the program to enable tracking of mc dc obligations.
we randomize the search during symbolic execution for both approaches which entails randomly selecting the next state from the set of possible successors.
the search is bound to one hour.
we run ten trials of each experiment.
figure presents a comparison of the time taken to successfully generate test cases that cover mc dc obligations for each of the six artifacts.
we plot a point on the graph each time an mc dc obligation is successfully covered by the preprocessing approach or the instrumented approach.
the time taken for the coverage of each obligation is plotted on the x axis while the total number of covered obligations normalized is plotted on the y axis.
the maximum numbertable ii overhead for computing mc dc obligations .
artifacts preprocessed std.
sym exe increase p value wbs .
.
.
treemap .
.
.
tcas .
.
.
of obligations covered by the two techniques for a given time period was treated as the total number of obligations in order to normalize the results on the y axis.
three artifacts tcas treemap and wbs completed full symbolic execution within the time bound of one hour whereas for the asw fibheap and fgs examples the search is terminated when the time bound of one hour was reached.
rq1 the results in figure demonstrate that symbolic execution using preprocessed information can quickly discover a large number of coverage obligations compared to the instrumented approach.
for the asw tcas fibheap and fgs artifacts our approach incurs less runtime overhead compared to that of the instrumented approach.
in the wbs example however the instrumented approach begins covering mc dc obligations a fraction of a second before our approach.
this is due to the fact that symbolic execution using the preprocessed information has a constant overhead cost of approximately half a second to read in the preprocessed data and set up the data structures.
in the wbs example this becomes noticeable since the entire analysis is performed within a few seconds.
in the fgs artifact the highest number of mc dc obligations covered by the preprocessed approach among the ten runs before reaching the time bound is whereas the maximum number of covered mc dc obligations by the instrumented approach across ten trials is .
for the asw artifact the preprocessed approach successfully explores a maximum of 79mc dc obligations prior to reaching the time bound whereas the instrumented approach maximally covers 58obligations.
overall for the artifacts analyzed in this study the preprocessed approach improves the efficiency of the test input generation in spf when compared to the state of the art instrumented based test generation technique.
rq2 we measure and report the overhead incurred during symbolic execution when computing the covered mc dc obligations preprocessed as compared to symbolic execution on an un instrumented program std.
sym exe in table ii.
we use the three artifacts that complete execution within the given time bound.
for each artifact we present the total wall clock time taken by each approach in seconds the increase in runtime in percentage and the p value as computed using a bootstrap permutation test.
the wbs and treemap artifacts have a significant overhead of and respectively.
note however that the wbs and treemap artifacts finish generation of the tree in less than seconds.
in these examples the constant time to read in the preprocessed data at the start tends to dominate the total time taken.
whereas the tcas has longer total runtime compared to wbs and treemap examples and here we observe an acceptable overhead of .
time in seconds 020406080100coverage instrumented preprocessed time in seconds .
.
.
.
.
.0coverage a asw b tcas time in seconds .
.
.
.
.
.0coverage time in seconds .
.
.
.
.
.0coverage c treemap d fibheap time in seconds .
.
.
.
.
.0coverage time in seconds .
.
.
.
.
.0coverage e fgs f wbs fig.
.
comparison of the time taken to observe mc dc coverage obligation using the instrumentation approach versus the preprocessing based approach table iii states explored and time taken to compute impacted coverage obligations .
version dise states dise time se states se time v1 v2 v3 v4 v5 rq3 to evaluate the efficiency of our preprocessing approach in the context of a novel analysis we compare the number of states generated and total time taken by dise to cover impacted mc dc obligations compared to standard symbolic execution.
the results for five versions of the tcas artifact found in the sir repository are presented in table iii.
in table iii we present the total number of states explored and the total wall clock time is measured in seconds.
diseexplores fewer states and takes less overall time compared to standard symbolic execution se .
using the preprocessed information we can leverage dise to efficiently compute and cover the set of impacted mc dc obligations.
e. threats to validity external our study is limited to six java programs.
although the results may not generalize to other artifacts we attempted to mitigate this threat by analyzing artifacts from two distinct classes of objects data structure examples and java applications representing embedded systems.
both classes represent considerable challenge for automatic test case generation.
furthermore all of the artifacts used in the evaluation of our approach have been used in previous studies of symbolic execution based techniques.
internal the primary threats to internal validity are the potential faults in the implementation of our algorithms tocompute structural coverage metrics.
we controlled for this threat by testing the tools and implementation of the algorithms on examples that could be manually verified.
it is also possible that another implementation of an instrumentationbased approach exists which does not incur the overhead observed in our current implementation.
to mitigate this threat we improved the current state of the art published instrumentation based approach.
construct we measured the efficiency of each approach based on coverage achieved over time.
naturally the goal of testing is fault detection with coverage serving as a proxy.
we recognize and have indeed demonstrated in our previous work that the relationship between coverage and fault detection is not always straightforward and that work strengthening this relationship is necessary .
vi.
r elated work many code coverage analysis tools have been developed to assess the quality of software testing.
these tools help developers ensure that all or most of the coverage obligations e.g.
statement branch are met during testing and identify the parts of the code that were not covered by the test suite.
a number of commercial tools that perform code coverage analysis have been reviewed in a recent survey including jcover ibm s rational purifyplus and clover for java.
these tools are able to measure different levels of code coverage e.g.
statement line block branch decision method class by monitoring the execution of the program and recording coverage information.
program execution monitoring represents an important challenge for code coverage tools as it is based on program instrumentation which can inflict considerable overhead on the testing process.
most of the tools reviewed in use source code instrumentation while a smaller number use byte code instrumentation including jcover and purifyplus or dynamic runtime instrumentation .
regardless of the instrumentation approach all of the coverage tools described in have a reported instrumentation overhead of more than .
tikir and hollingsworth propose a freely available tool which takes advantage of dynamic instrumentation and periodical garbage collection to remove instrumentation when it does not provide additional coverage in order to reduce the runtime overhead of code coverage .
although they report reduced runtime overhead by compared to the purecoverage commercial tool dynamic deletion of instrumentation code can introduce considerable risk and complexity into the instrumentation process.
another similar coverage tool that uses dynamic instrumentation to perform code coverage is proposed by misurda at al.
.
compared to tikir and hollingsworth s tool the prototype tool in can remove instrumentation code immediately rather than periodically which gives it slightly better performance at branch coverage average slowdown of .
compared with tikir and hollingsworth .
experiments in also reveal an average of .
speed up compared with static instrumentation for branch coverage.
pin provides a dynamic instrumentationapi which uses a customized just in time jit compiler to instrument code before it is translated for execution.
this makes it portable and more efficient due to the optimizations performed by the jit however it has been reported to increase the instruction count over the execution of native applications up to on average .
automated coverage driven testing techniques has been an active area of research for the past several decades .
techniques based on symbolic execution random testing and search based techniques have been developed for complex coverage criteria such as mc dc.
one recent approach based on dynamic symbolic execution dse proposes a new testing criterion label coverage which is intended to be both expressive and efficient in the context of dse .
their approach is capable of computing several coverage criteria including decision condition decision condition and multiple condition coverage.
and it achieves scalability by performing tight instrumentation and iterative label deletion.
on the other hand as noted in the approach is not capable of computing mc dc coverage as it involves both path conditions and in the case of xor and expressions involving boolean arguments choices as to the required test cases.
also it requires modification of the source code to ensure all conditional expressions are side effect free our approach does not require any source code modifications.
the inspiration for this work comes from previous work in which we propose a hardware supported monitoring framework and an efficient algorithm for tracking mc dc based on the framework .
while the work presented in addresses the issue of instrumentation overhead it proposes a very different solution leveraging multicore processor architectures to create a non intrusive general purpose monitoring framework while this work proposes a technique for avoiding instrumentation by pre computing the coverage information.
vii.
c onclusion in this paper we introduced a non intrusive and flexible approach for pre computing structural coverage information.
our approach is based on a static partial evaluation of the decisions in the source code and a source to object code mapping procedure.
the key novelty of our approach is that it uses pre computed coverage information to enable applications to efficiently compute coverage obligations without the need for code instrumentation.
moreover our approach enables new coverage driven analyses that rely on the structure of the code and are therefore not compatible with instrumentationbased techniques.
although the focus of this paper is on mc dc and symbolic execution based applications the initial evaluation of our approach indicates it can support diverse structural coverage metrics and enable a variety of applications to efficiently compute coverage obligations.