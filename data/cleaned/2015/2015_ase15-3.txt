optimistic shared memory dependence tracing yanyan jiang du liy chang xu z xiaoxing ma z jian lu state key laboratory for novel software technology nanjing university department of computer science and technology nanjing university yschool of computer science carnegie mellon university jiangyy outlook.com duli cs.cmu.edu changxu xxm lj nju.edu.cn abstract inter thread shared memory dependences are crucial to understanding the behavior of concurrent systems as such dependences are the cornerstone of time travel debugging and further predictive trace analyses.
to enable effective and efficient shared memory dependence tracing we present an optimistic scheme addressing the challenge of capturing exact dependences between unsynchronized events to reduce the probe effect of program instrumentation.
specifically our approach achieved a wait free fast path for thread local reads on x86 tso relaxed memory systems and simultaneously achieved precise tracing of exact read after write write after write and write after read dependences on the fly.
we implemented an open source rwtrace tool and evaluation results show that our approach not only achieves efficient shared memory dependence tracing but also scales well on a multi core computer system.
keywords concurrency shared memory dependence dynamic analysis i. i ntroduction shared memory and locks though being widely adopted in the ever increasing concurrent programing paradigm are notoriously difficult to reason.
to understand the behavior of such systems a key challenge is how to efficiently keep track of shared memory dependences in a concurrent program s execution.
tracing shared memory dependences enables record and replay of a previous oftentimes erroneous execution as well as facilitates trace analyses for data races and atomicity violations .
to trace the precise order of shared memory accesses a straightforward way is to guard every shared memory access with a lock .
these lock based techniques however may drastically slow down programs.
to make shared memory dependence tracing more efficient recent research work found that thread local accesses are predominant for real world programs and optimistic approaches are therefore proposed to reduce the overall probe effect .
for example octet made thread local memory accesses extremely efficient at the cost of expensive roundtrip coordination for inter thread dependences.
stride ingeniously eliminated all read time synchronization but requires a post execution inference whose soundness may suffer from hash collisions.
care logs even less shared memory dependences but only provides value deterministic replay guarantee.
overall existing approaches attempted to strike a tradeoff between performance and determinism but they also came with limitations either requiring offline interference or introducing expensive synchronization operations on certain occasions.
zcorresponding authors.we in this paper present a novel optimistic shared memory dependence tracing technique to overcome the aforementioned challenges in order to make it more practical.
we are able toefficiently andprecisely trace all three kinds of inter thread shared memory dependences on the fly read after write writeafter write and write after read dependences.
aligning with previous work we propose an optimistic design such that thread local reads are wait free .
our approach complements octet when inter thread shared memory communications are frequent as our slow path is a lockprotected critical section and heavy round trip coordination required by octet is avoided.
to achieve a wait free fast path we trace read after write dependences by combining insights of wait free notification in stride and speculation retry design in our previous work care .
we also address the even more challenging task of online tracing exact write afterthread local read dependences by using a carefully designed hash table of which fast path lookups are wait free.
these algorithms are briefly introduced in section ii and we expand the comprehensive discussion in section iii.
our second contribution is extending our technique to systems of relaxed memory model.
as mentioned earlier our thread local read fast path is wait free.
we further prove that for the most widely spread commodity x86 multiprocessor systems we achieved precise read after write dependence tracing without any memory fence instruction or atomic operation.
the proof also draws a positive conclusion to the applicability of previous deterministic record and replay work as their correctness on x86 tso can be proved by exactly the same technique.
memory fences are carried out to retain fast path wait freeness in the case that write after read dependences are traced or when the memory model is weaker than total store order.
we discuss such relaxed memory model related issues in section iii e. our final contribution is open source implementation of the shared memory dependence tracing tool rwtrace .
we evaluated rwtrace with a series of concurrent benchmarks including desktop scientific and server programs on a multicore machine.
evaluation results show that rwtrace outperforms any lock based approaches and is tens of times faster for several memory intensive benchmarks.
evaluation results also show that our rwtrace tool scales well even if the nonuniform memory access multiprocessor architecture is present.
therwtrace implementation is presented in section iv followed by evaluations on a set of real world benchmarks in section v. finally we present qualitative discussion of related work and conclude our paper in section vi and vii respectively.thread thread v x v write x read x v v x if thread local x v read x v v x read after write dependence of x figure capturing read after write dependences thread thread update read x write x querywrite after read dependence of x figure capturing write after read dependences ii.
o verview a. background behavior of concurrent systems consisting of threads and shared memory is difficult to reason because the shared memory access order largely affects the program outcome.
if two shared memory accesses are performed on the same address by two different threads and at least one of them is a write we say that these two accesses are conflicting.
knowing the exact order of conflicting accesses is crucial to understand the system s behavior.
with such ordering information one can deterministically replay a problematic execution or conduct further testing and analysis in search of faults and defects .
b. optimistically tracing shared memory dependences to efficiently capture inter thread shared memory dependences recent research exploits the access pattern of concurrent programs in which shared memory reads predominate writes and a vast majority of accesses are not involved in an inter thread dependence .
these insights facilitate shared memory dependence tracing approaches that behave differently among shared memory accesses either in a frequent fast path or in a rare slow path.
for example stride does not synchronize for read events at all but requires an offline inference procedure to restore shared memory dependences.
octet achieved extremely efficient fast path for threadexclusive and read shared memory accesses but an interthread dependence requires a much more costly roundtrip coordination.
we propose a novel shared memory dependence tracing recipe following an optimistic design that favors thread localreads1.
to achieve efficient dependence tracing the major challenge is how to make the thread local read fast path waitfree .
according to the types of two incorporated events a shared memory dependence can be categorized as a readafter write write after write or write after read dependence.
for each category we highlight its challenge and our solution as follows.
detailed discussions are expanded in section iii.
write after write dependences .we adopt the standard approach of serializing all write events to the same shared address .
by maintaining the latest writer thread s identifier for each shared address such dependences can be faithfully captured.
read after write dependences .since the thread local reads are predominant the major challenge is how to design an efficient fast path for them.
like we speculatively assume that a read is thread local and perform the read instantly followed by a posterior test of thread locality achieving a fast path when the test is passed.
on the other hand when the thread locality test fails we remedy the effect by a slow path which performs the read again with lock.
however the thread locality test in is too optimistic that may miss real dependences.
we therefore adopt the memory ordering technique proposed in to design a sound thread locality test that always fails for non thread local reads.
figure demonstrates the discovery of a read afterwrite dependence between two threads accessing x a solid line denotes a shared memory dependence while a dashed line indicates a transitively deduced dependence .
in short we associate each address xwith a version identifier v x and perform the update of v x before the write to xwhile queriesv x after performing the read from x. the designated event ordering guarantees that whenever a read event is reading an inter thread value the corresponding update of v x is detected to trigger a thread locality test failure and hence an inter thread dependence is captured.
write after read dependences .efficiently tracing write afterread dependences is even more challenging because there is no synchronization between a thread local read and a write in which a dependence is incorporated i.e.
a write after threadlocal read dependence .
to the best of our knowledge none of existing optimistic dependence tracing scheme can obtain the exact read events for a write after read dependence without a second inference pass2.
to trace write after read dependences we also enforce update is performed before read and query is performed after write as shown in figure .
for each shared address we maintain a hashed mapping to keep track of each thread s latest read event to the address.
by a careful design we make sure that any structural modification to the hash table will only happen in the slow path and hash table update can always succeed for thread local reads achieving a wait free fast path that only contains an o hash table lookup and a shared memory write.
finally we offer users two alternatives in different application scenarios for practical concerns.
if one collects shared 1a read is thread local if the thread had accessed the same address before and there is no other thread writing to it in between.
2octet for example enforces a rdsh!wrex ordering by a global roundtrip coordination but the dependence s precise reader events are lost.memory dependences for a time travel debugging or an offline trace analysis read after write and writeafter write dependences are sufficient for restoring all writeafter read dependences by the deterministic replay algorithm described in .
further analysis in section iii e shows that in this case our read fast path is correct under the x86 tso memory model neither memory fence instruction nor atomic operation is needed .
on the other hand we can also trace every shared memory dependence on the fly at the cost of a few additional operations and a memory fence at each shared memory access.
such full set of dependences can be directly used to perform trace analyses .
iii.
t racing shared memory dependences we take a top down approach in describing our shared memory dependence tracing scheme.
after the notations and definitions listed in section iii a followed by the formalized algorithm in section iii b we first expand the discussion on how read after write and write after write dependences are traced in section iii c. then we present two approaches to tracing write after read dependences in section iii d. finally we conduct the justification of extending our scheme to systems of relaxed memory model in section iii e. a. preliminaries thread and event we assume that a concurrent system consists of threads accessing a shared memory.
each thread t executes a single in program order stream of events et fe1 e2 e ng as defined in x86 tso .
we use the unique identifier ht eiito refer to event eiperformed by t. each event eiis of one of the following types wt v for a write of value vto addressxby threadt.
rt v for a read of value vfrom address xby threadt.
acqt for an acquisition of lock at address xby threadt.tis blocked until the lock is successfully acquired.
relt for a release of lock at address xby thread t. these four types of events are sufficient for defining a sequentially consistent execution model.
we exclude other synchronization events e.g.
thread fork join and monitor events for brevity since they can be easily constructed by proper acq andrelevents.
the x86 tso memory model also defines other memory model specific events like memory fence ft inprocessor lock lt utand store buffer flush p. these notations do not pose any difficulty in understanding our algorithm in a sequentially consistent memory model setting and hence we omit them for brevity.
precise semantics of these events can be found in .
shared memory dependence let us first assume that our target system has a sequentially consistent memory model i.e.
shared memory accesses are not reordered and appear to be atomic .
we will extend our discussions to relaxed memory model in section iii e.lete tetbe the set of all events.
for a sequentially consistent system there exists a total ordersc!
e esuch that every read event in ereturns the most recent written value insc!
.
to capture the behavior of a concurrent system one can naively obtainsc!by serializing all shared memory accesses precluding any possibility of parallelism.
to best recover parallelism we can also decompose the task of tracing sc!into detecting inter thread shared memory dependences and recoversc!later by a linear extension .
specifically to faithfully capture the behavior of a concurrent system both program order dependences and inter thread shared memory dependences are required.
the program order dependencepo!
e eencodes the happens before order between events in the same thread i.e.
ht eiipo!ht ei 1i.
on the other hand an inter thread shared memory dependence indicates that a thread is reading or writing a value that is previously accessed by another thread.
specifically for two shared memory access events ht eiiandht0 ejiperformed on the same address if either eiorejis a write the relative orderht eii !
ht0 ejiis critical for understanding the program s behavior .
according to the type of eiandej such dependences can be categorized into three kinds readafter write raw write after read war and write afterwrite waw which are represented by rraw!w wwar!r andwwaw!w0 respectively.
lethb!be the transitive closure of all the aforementioned dependences i.e.
hb!
tr po!
raw!
war!
waw!
a classical result is that any linear extension ofhb!is a sequentially consistent total order i.e.
a validsc!
and hencehb!is sufficient for deterministic replay.
since program order is trivially preserved by program execution we are most interested in the inter thread shared memory dependences which cannot be transitively deduced by program order in raw!
war!andwaw!
which are sufficient for reproducing and understanding a shared memory system s concurrent execution.
thread locality if threadt s shared memory accesses ht ei1ipo!ht ei2ipo!
po!ht eikiare performed on the same address a and there is no other thread writing ain between we consider all these events thread local excluding the first event.
formally events fht ei2i ht ei3i ht eikig are thread local if there is no write event ht0 ejisuch that t6 t0andht ei1ihb!ht0 ejihb!ht eiki.
the first event ht0 ei1iis excluded because it may be incorporated in a interthread dependence.
thread local events can be combined as a single event in understanding the behavior of a concurrent system and are thus not have to be logged.
we keep this insight in mind in designing our optimistic approach to shared memory dependence tracing.
b. program instrumentation to achieve efficient shared memory dependence tracing we associate each shared address awith a lock l a .
differentalgorithm instrumentation for ht eii rt v 1update ma ht eii 2rt v 3rt ht0 eji 4result thread locality test a ht0 eji discussed in section iii c3 5ifresult cannot prove eiis thread local then acqt rt v0 rt ht00 ej0i update ma ht eii relt override read value of rt vbyv0 log dependence ht00 ej0iraw!ht eii thread locality update a ht00 ej0i algorithm instrumentation for ht eii wt v 1acq 2rt ht0 eji 3wt ht eii 4wt v 5forhtk eki2query ma do log dependence htk ekiwar!ht eii 7rel 8ift06 tthen log dependence ht0 ejiwaw!
ht eii 10thread locality update a ht eii shared memory addresses are allowed to share a lock3.
for each lockl a we also maintain its version v a which denotes the identifier of the latest write event performed when l a is acquired.
v a is in form ofht eiiindicating that the most recent writer to ais thei th event wt vperformed by threadt.
in case that war dependences are traced we further associate each shared address awith a key value pair data structurema.
we usemato keep each thread t s latest event reading address a and therefore we require mato support the following two operations update ma ht eii for updating the latest read event of thread tto beei.
in other words update sets the key t s corresponding value to ei.
query ma for returning allht eiipairs and remove all such pairs in ma.
in section iii d we show that macan be efficiently implemented preserving wait freeness for our read fast path.
as briefly discussed in section ii the key insight of capturing a shared memory dependence between ht eiiand ht0 eji either a raw or war dependence is to instrument 3this is known as the technique of variable grouping and different variable grouping techniques favor different workloads.
for example leap and stride group addresses sharing a common field name while order and octet group addresses in the same object and there also exist finegrained implementations .
this issue is out of our scope and hence not discussed further.the program creating the event ordering of apo!ht eiihb!
ht0 ejipo!b whereaupdates a shared state indicating the existence ofht eiiand this state change is visible at bsuch that we can detect a dependence.
this insight is realized as our shared memory dependence tracing algorithms.
for a read event rt vwith identifierht eii our instrumentation is illustrated in algorithm .
similarly write eventwt vwith identifierht eii s instrumentation is shown in algorithm .
for visual conventions a box indicates that its contained event is the one being instrumented and underlined code snippets are only used for tracing war dependences.
all non boxed shared memory access events rtandwt are performed by our instrumentation.
when we are discussing the rationale of tracing raw and waw dependences in section iii c these underlined codes can be omitted.
c. tracing raw and waw dependences tracing raw dependences instrumentation for a read event algorithm consists of two phases.
we design the first phase to be a wait free speculative read and a thread locality test.
it performs the read event rt as usual line followed by a read of a s latest write event identifier rt line and finally a thread locality test line .
we expand our discussion of thread locality test and its correctness in section iii c3.
we design the test to exhibit only single sided error.
in other words the thread locality test is guaranteed to fail for any inter thread read event assuring that all inter thread raw dependences are captured.
only when the thread locality test cannot confirm a threadlocal read a second phase is carried out to capture the exact inter thread raw dependence lines .
by acquiring a s corresponding lock l a we serialize the read event with any write event to abecause all writes to aare also protected by l a in algorithm .
in this lock protected region we once again perform the read event rt obtainingv0 line whose writer event s identifier is ht00 ej0i line .
we override the read valuevinrt vbyv0 essentially replacing the read in line by the one in line obtaining the exact raw dependenceht00 ej0iraw!ht eii.
our two phase read instrumentation design gains from the fact that thread local reads are far more frequent than the others in real world programs .
the thread locality test consists of only thread local operations and therefore our read fast path i.e.
passing thread locality test in the first phase is wait free and consumes only a few machine instructions.
tracing waw dependences the write instrumentation algorithm protects every write event to address awith lockl a to ensure that all writes to the same address are serialized.
we also update v a in the same lock protected region to establish atomic update of both the value and its version.
by studying the value stored in v a lines filters out thread local writes which can be inferred by the program order and only inter thread waw dependences are logged.
detecting thread locality the challenge of effectively and efficiently tracing raw dependences is the design of a sound and fast thread locality test line in algorithm .the test must be sound so that no real dependence is missed and should be extremely efficient because it is called very frequently.
to implement such test we associate each thread twith vt a a thread local shadow copy of v a .vt a stores t s knowledge about which write event is the latest one performed on a. we allow the thread locality test to produce false negatives failing the test for an actually thread local read .
thus we allow vt a to hold inconsistent i.e.
outdated writer information.
vt a is updated only when an inter thread raw dependence is detected through thread locality update line in algorithm or thread titself is performing a write line in algorithm .
the thread locality test passes only if the actual writer event s identifier ht0 eji fetched by line in algorithm matches the one stored in the shadow copy i.e.
vt a ht0 eji.
note that it is neither practical nor necessary to maintain vt a for everya.
memory access locality indicates that the shadow mapping can be efficiently implemented by a cache like structure of fixed size and any feasible cache replacement strategy .
we now explain why this thread locality test can guarantee to recognize any inter thread raw dependence.
note that our write instrumentation algorithm updates v a before the actual write wt v is performed lines .
once v a is updated any other thread s shadow copy vt a if exists are immediately outdated as if we had performed a global invalidate operation before vwas written to the shared memory.
combined with our read instrumentation algorithm that reads v a after the actual read rt is performed lines we ensure that if rt is reading a value written by another thread vt a must be invalidated beforert is performed triggering a thread locality test failure.
specifically our instrumentation ensures that rt po!
rt andwt0 po!wt0 .
ifwt0 raw!rt is an inter thread raw dependence the transitive law implies thatwt0 hb!rt triggering a thread locality test failure.
we remind our readers that this argument works only for a sequentially consistent memory model.
this careful memory ordering design however may suffer from reordering issues in systems of relaxed memory model.
we will return to this subject in section iii e. from another perspective the thread locality test can also be interpreted as a lightweight imprecise instance of the transitive reduction technique for compacting the shared memory dependence log.
transitive reduction states that for any partial order say !
we can safely remove a dependence a!bif there is some tsuch thata!t t!b.
repetitively removing redundant dependences yields a unique minimum representation of the partially ordered set.
however stateof the art transitive reduction is often performed offline .
exact on the fly transitive reduction requires either heavy instrumentation or customized hardware .
threadlocality test on the other hand only removes dependences for a!bif there isaraw!t tpo!borawaw!t tpo!b achieving a balance of cost and effectiveness.algorithm algorithms for update andquery mais implemented by a hash mapping from thread identifier tto a shared memory address addr 2function update ma ht eii 3begin ifl a is held then we are at line in algorithm addr new wt ei hash insert ma ht addri else we are at line in algorithm addr hash lookup ma t iflookup failed then do nothing thread locality test must fail else update the write after read dependence wt ei mfence 18function query ma 19begin we are at line in algorithm mfence forallht addri2mado rt ei ret ret ht eii hash reclaim ma remove all contents in ma hash insert ma ht new i return ret d. tracing war dependences we provide two independent approaches to tracing war dependences.
the online tracing algorithm captures war dependences on the fly at the cost of incurring a little more runtime overhead retaining the wait freeness for the threadlocal read fast path .
on the other hand the offline algorithm uses only raw and waw dependences to infer war dependences by an extra replay pass.
online tracing war dependences the underlined code in algorithm and algorithm are used for tracing war dependences.
recall that in section iii b we use mato keep each thread s latest read event from address a. let us first assume the atomicity of update andquery .
we update ma before the read is performed and query maafter the write is done.
using the similar argument presented in section iii c3 we enforce update ma ht eii po!rt for a read event lines in algorithm and wt0 po!query ma for a write event lines in algorithm .
therefore for any r rt happening before w wt0 indicating a war dependence the transitive rule implies that r supdate must happen before w squery establishing the fact that no war dependence is missed.
there exists a subtle case when racing read and write events are present.
consider that a war dependence rwar!w is detected before rexecutes line of algorithm .
later r s thread locality test may fail yielding a logged raw dependence w0raw!r w0is not necessarily equal to w .the cycle formed by rwar!whb!w0raw!rclearly violates our presumption of partial order.
fortunately this is the only case of generating a false dependence4that a cycle is formed.
removal of the false war dependence restoring previously known war dependence r0war!wwherer0po!rif exists essentially restores the correct dependence.
the next challenge is how to efficiently implement maand its two operations as a practical wait free concurrent hash table implementation is not yet available .
to keep the fast path wait free we exploit the observation that thread t only claims itself reading a shared address.
in other words anyupdate ofmaperformed by thread toperates on key t. accordingly we implement maas an ordinary hash table and design our algorithm to obey the invariant that key tmust exist inmawhenever thread texecutes update ma ht eii at a thread local read event.
this invariant implies that no structural modification is ever needed for a thread local read as illustrated in algorithm .
we enforce this invariant by a slight modification to our slow path instrumentation.
for any read event rin threadtto be thread local there must be some event upo!rexecuting thread locality update in algorithm or algorithm and uitself is either a write event or a non thread local read event capturing a raw dependence wraw!u.
in both cases u accessesaand is protected by l a .
therefore at this time we insert the key tintomato ensure successful lookups for subsequent thread local reads line in algorithm and lines in algorithm .
such modification only changes the internal implementation ofma and therefore our previous correctness arguments still hold.
nevertheless several interesting cases arise.
the first case is that update may fail to find the key tin the hash table lines in algorithm .
since hash table is only cleared at query in our write time instrumentation there must be another thread executed writing a value.
in this situation we havewt po!queryhb!updatepo!rt0 and the read must not pass the thread locality test.
in other words a hash table lookup failure always indicates that the subsequent threadlocality test will fail.
for a similar reason if query ma and update ma ht eii happened in parallel the read must also not be thread local.
therefore a raw dependence is logged and any incorrect war dependence will be discarded.
we demonstrate a possible hash table implementation in algorithm .
since conflicting hash insert andhash reclaim are protected by the same lock lines in algorithm we thus only need to consider the correctness of racing reads in hash lookup .
since thread tonly operates on key t there will be no racing accesses to the same key.
moreover as long as keytis in the hash table lookup will always succeed no matter the old or the resized new hash table is fetched lines in algorithm .
these justifications are sufficient for ensuring a wait free fast path.
the final issue of tracing war dependences is memory ordering.
in a concurrent system of relaxed memory model 4a war dependence between a write and a thread local read is always a true dependence because a thread local read always happens before any writer afterwards.algorithm an example hash table implementation hstores the