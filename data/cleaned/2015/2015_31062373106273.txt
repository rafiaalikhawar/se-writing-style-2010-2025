finding near optimal configurations in product lines by random sampling jeho oh don batory margaret myers university of texas at austin usanorbert siegmund bauhaus university weimar germany abstract software product lines spls are highly configurable systems.
this raisesthechallengetofindoptimalperformingconfigurationsfor an anticipated workload.
as spl configuration spaces are huge itisinfeasibletobenchmarkallconfigurationstofindanoptimal one.priorworkfocusedonbuildingperformancemodelstopredict and optimize spl configurations.
instead we randomly sample and recursively searcha configuration space directlyto find nearoptimal configurations without constructing a prediction model.
ouralgorithmsaresimplerandhavehigheraccuracyandefficiency.
ccsconcepts softwareanditsengineering softwareconfigurationmanagementandversioncontrolsystems search basedsoftware engineering keywords software product lines searching configuration spaces finding optimalconfigurations acm reference format jehooh donbatory margaretmyers andnorbertsiegmund.
.finding near optimal configurations in product lines by random sampling.
in proceedings of 11th joint meeting of the european software engineering conference and the acm sigsoft symposium on the foundations of softwareengineering paderborn germany september4 esec fse pages.
introduction software product lines spls are highly configurable systems.
this raisesthechallengetofindaconfigurationthathasnear optimal performance.
an spl configuration space is often astronomical in size exponentialintermsof features incrementsinprogramfunctionality and searching it efficiently is hard .
there are many reasons a feature s influence on performance is not easy to determine because feature interactionsintroduce performance dependencies with other features .
techniques for true random sampling of configuration spaces are not known approximationstotruerandomsamplingareusedinstead.and howfew permissionto make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
esec fse september paderborn germany association for computing machinery.
acm isbn ... .
accuracy?
this paper focuses on a fundamental problem in spls to find acceptable configurations whose performance is near optimal.
we donotcreateaperformancepredictionmodel whichthenrequires an optimizer e.g.using a genetic algorithm to find good configurations.
instead we use bdds to count the number of valid configurations in a configuration space thereby enabling true randomsamplingofthespace.
tightbounds on sampling results.
further we identify features thatarestatisticallycertaintoimproveordegradeprogramperformance .weusethesefeaturestorecursivelyconstricttheconfiguration space towards near optimal configurations.
the advantages in more complicated algorithms do now b our accuracy is better thanexisting algorithms and c we use fewer samples.
thenovel contributions of our paper are true random sampling of valid configurations in an spl theoreticalboundsonsearchaccuracyfromuniformrandom samplingof configurations a way to progressively shrink a configuration space by exploitingits shape and statistical reasoning analyses of real systems that shows our approach outper forms prior work in accuracy and the number of samples needed and ademonstrationofthescalabilityofourworktohugeconfigurationspaces.
big picture of prior work topredictperformanceofsplproducts programs amathematical performance model is created.
historically such models are developedmanuallyusingdomain specificknowledge .more recently emphasis has been on general approaches from which performancepredictionmodelsarelearnedordeducedfromperformance measurements of sampled configurations.
such a performancemodelisthengiventoanoptimizer whichnotonlycanfind near optimal configurations but also near optimal configurations that observe user imposed feature constraints e.g.configuration predicates that exclude feature fand includefeature g .
prediction models estimate the performance of valid configurations .
they are deduced from performance measurements of sampled configurations.
the goal is to use as few samples as possible to yield a model that is accurate .
finding a good set of samples to use is one challenge another is minimizing the variancein predictions.
given an spl feature model properties of features and their interactions anduser imposedfeatureconstraints anoptimizercan esec fse september paderborn germany j. oh d. batory m. myers and n. siegmund derivevalidconfigurationsthatsatisfyoneormoreperformance objectives using a general search strategy .
letcbe the set of all legal spl configurations.
1st order performance models have the following form pcis the estimated performanceofansplproduct pcwithconfiguration c c wherec isasetofselectedfeaturesand fiistheperformancecontribution of feature fi pc summationdisplay i c fi linear models are inaccurate as they do not consider feature interactions.
let fijdenote the performance contribution of the interaction of features fiandfj which requires both fiandfj to be present in a configuration fij 0i ffi nelementc fj nelementc.2nd order models take into account way interactions pc parenlefttpa parenleftbta summationdisplay i c fi parenrighttpa parenrightbta parenlefttpa parenleftexa parenleftbta summationdisplay i c summationdisplay j c fij parenrighttpa parenrightexa parenrightbta andmoregenerally n wayinteractionsaddmorenested summation termsto eq.
.
when compared to manually developed performance models an importantdifference becomes apparent.a manuallydeveloped model identifiesoperations o1... invoked by system clients definesafunction oitoestimatetheperformanceofeach operation oi encodes system workloads in terms of operation execution frequencies where iis the frequency of oi and expresses performance pof a program pas a weighted sum of frequency times operation cost p summationdisplay i i oi features complicate the cost function of each operation where configuration c cbecomes an explicit parameter pc summationdisplay i i oi c the key observation is that manual performance models include workload variances in their predictions whereas current spl performance models use a fixedworkload.
workload variations play a significant role in the performance of spl products and should not be omitted.
random sampling.
optimizersandpredictionmodels rely on random sampling but the samples used arenotprovablyrandom.truerandomsamplingwould ineffect enumerateall nlegalconfigurations randomlychooseanumber k ..n and use the kthconfiguration but this is not done becausencould be astronomically large.
one popularalternative is to randomly select features tocreate a configuration followed by a filter to eliminate invalid configurations .
the drawback of this approach is that it creates too many invalid configurations .
another approach uses sat solvers to generate valid configurations but this producesconfigurationswithsimilarfeaturesduetothewaysolvers enumeratesolutions.further satsolverscountthenumberofsolutions by enumeration which is inefficient .
although henard fineed not be a constant it could be a sophisticated expression .et al.
mitigated these issues by randomly permuting the parameter settings in sat solvers true random sampling was not demonstrated.
the top path of figure summarizes prior work the configuration space is pseudo randomly sampled to derive a performance model samplingsareinterleavedwithperformancemodellearning until a model is sufficiently accurate.
that model is then used by anoptimizer alongwithuser imposedfeatureconstraints tofind a near optimal performing configuration.
lj nj w d k figure different ways to find good configurations.
ourapproachisdifferent.first wedonotuseperformancemodelsoroptimizers.wefindgoodconfigurationsbyrandomlyprobing the configuration space directly measuring the performance of these samples under the required workload.
user imposed feature constraintssimplyreduce the space that we probe.
second we use true random sampling.
we encode feature models asbinary decision diagrams bdds for which counting the number of legal configurations is straightforward.
given the numberoflegalconfigurations n wecanrandomlyselectanumber k ..n and traverse a bdd to find the kthconfiguration.
this allows us to create accurate mathematical models based on true randomselection.
third we progressively constrict the configuration space by determining statistically significant features or their absence that contributetogoodperformance.selectingthesefeaturesfocuses on progressively smaller regions of the configuration space that have near optimal configurations.
thebottompathoffigure1summarizesourapproach weuse true random sampling of a constrained configuration space andmeasure the performance of selected configurations for a given workload.
we continue sampling until we reach a configuration that exhibits a satisfactory accuracy .
we demonstrate later that ourtechniqueismoreefficientthanpriorworkinthenumberof samplesused andmoreaccuratethanpredictionmodels.
onlywhen prediction models with fixed workloads are reused will they be less costly but not necessarily more accurate than our approach.
search by random sampling .
countingbinary decision diagrams twotoolsarecommonlyusedtoanalyzepropositionalformulas sat isfiability solvers andbdds.satreliesona conjunctive normalform cnf representationofaformulatofindasolution efficiently.
in contrast a bdd is a data structure that encodes a disjunctionofformulasolutions i.e.disjunctivenormalform dnf .
bdd tools convert non dnf formulas into bdds.
figure shows how a given feature model feature diagram cross tree constraints can be transformed into a propositional 62finding near optimal configurations in product lines by random sampling esec fse september paderborn germany formula thenintoabdd.2fornow ignoretheintegerlabels on edges.
the name of each node is a variable v its dashed line child denotes a falseor assignment to vand its bold line child is atrueor assignment.
a terminal node of a bdd is a or box.
a path from the root to a box assigns values to variables.
a path terminating at the box means that the variable assignments are satisfiable.
path means that all configurations with root a c andd theremainingvariable bisdon t care are valid solutions of this model.
hdwxuh 0rgho 3urs rupxod figure transforming a feature model into bdd.
bddsmakeitfastandeasytocountthevalidconfigurationsfora givenfeaturemodelanduser imposedfeatureconstraints.theinte geroneachedgeinfigure2indicatesthenumberofsolutionswith thosevariableassignments.wecallthisa countingbdd cbdd .
the path has zero solutions path has one solution.
the root or path has three solutions the sum of edges from the root.
here is why cbdds are important cbdds solve an open problem of how to randomly and uniformly select configurations from a valid configuration space.
we can quickly count the size nof a configuration space generate a random number k ..n where all numbers in ..n are equally likely and convert kinto an spl configuration by a cbdd traversal.
in contrast sat solvers count solutionsbyenumeration foralargeconfigurationspaces enumeration is impractical.
the downside of bdds is that when formulas arelarge bddcreationtimemayexceeduserpatienceorstorage requirements of available memory .
analgorithmtocreateandtraverseacbddthatmapsanumbertoaconfigurationisstraightforwardandispresentedin .
asimpleextensionincludesuser imposedfeatureconstraints.in short ouralgorithmcreatesacbddandcountssolutionstofeatureconstrained configuration spaces to sample configurations.
.
performancestairsin configuration spaces exploitingthe shape ofaconfigurationspaceis keytosearching it efficiently.
we may not find the optimal configuration the configurationwiththe optimalperformance but if we can come provably close to that will do nicely.
letcbe set of all legal spl configurations.
let c cand c denote the measured or predicted performance of configuration c.aperformanceconfigurationspace pcs isthesetofall config 2this is an ordered bdd where boolean variables are encountered from root toterminals in the same order.
3this is a reducedbdd meaning unnecessary nodes variables whose values are immaterial to a solution are eliminated.
otherwise a bdd would contain 2number of variablesnodes.performance pairs pcs c c c c where configuration chas the best performance .
now sort the pairs of pcsfrom worst performance to best and plot configurations along the x axis and performance along the y axis.wecallthisa pcsgraph .weexpectedacontinuousgraph suchasfigure3a wherehigh valued isbad worstperformanceis at the far left and low valued is good best performance is at the farright .
anchorsthe far rightpoint on x axisof pcs graphs.
b staired pcs graph a continuous pcs graph performance performance figure pcs graphs.
interestingly markeret al.
discoveredthat pcsgraphs are staired as in figure 3b.
stairs arise from discrete feature decisions somefeaturesarehighly influentialinperformancewhileothers have little or no impact.
consequently a few critical feature decisions define the performance characteristics of a segment of a pcs graph the configuration membership of a stair while less importantfeaturedecisionsaltertheperformanceofnearbyconfigurationsonlyslightly givingastairitswidth andslope .inshort theconfigurationsof a stair share major design decisions .
figure4illustratestwocommonsituations.first likeafractal stairshavesubstairs recursively.substairswithindifferentstairs repeatbecausethesamelesssignificantdecisionsareappliedwithin eachstair seefigure4a .second distinctstairscanoverlapbecause they have similar performance making it difficult to distinguish common decisions.
we use the term pollution when the superposition of distinct stairs forming a downward trending shelf arises.
figure 4b is the basic shape of a pcs graph that we believe is commonin spls and will exploit in this paper.
b pcs graph with overlaps a pcs graph with substairs performance performance stairs within stairsdistinct stairs design decisions figure stairs within stairs.
.
randomselection in pcs graphs letnbetheintervalofintegers oneperconfigurationin c. randomlysampling nintegersfromthisintervalcanberegarded as a combinatorial problem.
as we are interested in finding the probabilitythatthelargestselectedinteger cbest isiunitsaway from c is p c n i parenleftbigg c i n parenrightbigg parenleftbigg c n parenrightbigg 63esec fse september paderborn germany j. oh d. batory m. myers and n. siegmund the expected value of i or the mean distance cbestis to c is e c n c n summationdisplay i 0i p c n i as weare interested inhuge configurationspaces we cangeneralizethisanalysisbyreplacing nwiththerealunitinterval i with dividing each number in n b y c to yield nn c and taking the limit lim c nnto produce i. everypcsgraphismonotonicallydecreasing.ifwerandomly selectnpoints in i cbestwill be closest to .
the cumulative probabilitydistributionfunctionfor cbestis pn x x integraldisplayx 0n xn dx xn the average error en or the mean distance cbestis to is en integraldisplay1 x n xn dx n that is nrandomly selected points partition ion average into n uniform intervals of length1 n .eq.
tells us a simple way to search for a good configuration in a pcs graph randomly select nconfigurations and evaluate the performance of each.
the best performingselection cbest isonaverage adistance1 n 1fromthe best performance at x .
other useful statistics of pnareen the second moment of en and n its standard deviation en integraldisplay1 x n xn dx n n n radicalbig en e2n radicalbigg n n parenleftbigg1 n parenrightbigg2 figure compares the result of eq.
and eq.
sampling and numbers on spaces with different size c shown on the x axis.
to compare two equations the results of eq.
were normalized by the size of c so that both equations indicate normalized distances to shown on the y axis.
lvfuhwh rqwlqxr lvfuhwh rqwlqxr lvfuhwh rqwlqxr 6l h ri wkh lqwhuydo lvwdqfh wr 1rupdol hg figure comparing e c nanden.
for small spaces c eq.
predictions are slightly lowerthaneq.
.when c thereisnodifferencebetween eq.
andeq.
.aswearemoreinterestedinhugeconfiguration spaces we resort to eq.
for therest of this paper.
4xn dxistheprobabilitythatthefirst n 1selectionsareintheinterval and dxis the probability that the last selection is at x nis the normalization constant.
eq.
is an instance of the beta function .
100en sn distance to of random samples q figure enand n.figure plots enand nas percentages in an infinite size configurationspace enand n valuesarevirtuallyidenticalas they lie on top of each other.
here is what figure means if we randomly select n points cbestwill be awayfrom1onthe i axiswith a standard deviation of .
if we select n points cbest will be away from with a standard deviation of .
as n increases the interval shrinks.
we will see later that these numbers are good they say that we do not need many randomselections to find a good performing point.
.
axes of projections and main conjecture 1 cc cc cbdd mapping mapping figure axes of projections.consider the pcs graph of i plane of figure .
in the last section we analyzed the performanceofselecting npoints along the iaxis and choosing the point closest to1.
we are more interested in the pcs graph of plane c .
each point in ihas an equal probability of being selected.
asthecbddmappingis1 to eachpointalong caxisalsohas anequallyprobabilityofbeingselected.westillhavetomeasure c for each selected configuration c but the theoretical results of eq.
abouterrordistancesfrom cbestto1iniaretransferred to error distances from cbestto inc. here is our main conjecture there is a correspondence between beingq from along x axis and q from along y axis in a pcs graphfor small q.supposea pcs graph is defined by k x k x xk figure 8a plots graphs for k .w es a y kis the curvature of a pcs graph.
.
.
.
.
.
.
.
.
.
.
.
a pcs graphs0 .
.
.
.
.
b curvatures in critical zonek k k k k 5performance difference to performance difference to figure pcs graphs and their critical zones.
let sfocus on the interval which contains all configurations whose x axis value is within of .
we call this the critical zone withinoptimalisaball parksettingforpriorwork.figure 8b shows the critical zone of figure 8a.
the y axis plots the distancefrom the best performance at y namely .
although the pcs graphs in figure 8a are non linear the curvature kreduces to the graph s slope at x in the critical zone.
64finding near optimal configurations in product lines by random sampling esec fse september paderborn germany sdfkh hunhoh 3huirupdqfh3huirupdqfh3huirupdqfh3huirupdqfh figure pcs graphs of different spls.
this slope is the first derivative d dx xk k xk and in the limit limx k xk k. that is the slope of a pcs graph in the criticalregion is negative k. observe when k thepcsgraph k x isaline.ifweare q away from onthe x axiswearealsoprecisely q awayfrom on the y axis.
when k 1thegraphis convex.ifweare q from weknow that performance is k q away from .
a convex pcs graphmeansthat liesonaflatshelfwhereanyconfiguration on that shelf is near optimal.
when k 1thegraphis concave.ifweare q awayfrom we arek q away from .
a concave pcs means that does notlieonaflatshelfandfurthersearchingmaybewarranted.
atthis point weneedto lookatactual pcsgraphsto examine theirshape and curvature.
.
pcsgraphsof actual spls four spls were analyzed by siegmund et al.
which were extensively used as the test set for prediction models.5figure shows their pcs graphs.
each is described briefly llvmis a compilerinfrastructure written in c .
ithas featuresand1024configurations wheretestsuitecompilation timeswere measured.
x264isavideoencoderlibraryforh.
mpeg 4avcformat writtenin c.it has16 features and1152 configurations sintel trailerencoding timeswere measured.
berkeleydbc isanembeddeddatabasesystem writteninc.
it has features and configurations where benchmark response times were measured.
apacheis an open source web server.
it has features with configurations where the maximum server load size was measured through autobench andhttperf.
figure shows their pcs graphs in the critical zone.
most have k this means that as cbestapproaches on the x axis we knowitsperformanceisverycloseto .thereasonisthatall configurationslieonaflatshelfwhoseperformancedifferencesare minimal.choosing any configurationon this shelf will do.
spls whose pcs graphs where k pose more of a challenge.
their configurations do not lie on a flat shelf performance noticeablyimprovesasonegetscloserto .ifweknowthecurvature kof apcsgraph wecanestimatehowfarwearefrom .examples 5among6availabledatasets weusedonlysystemsthathadalllegalconfigurations measured.
our analyses of systems with incomplete datasets we felt were misleading although they exhibited similar performance to systems with complete dataset.
note that gathering the performance data of all systems took 2months of cpu time .llvmhas a curvature of k .
if we believe our best sample is q from we can infer that we are2 q f r o m .
from the above a key metric that determines when to stop samplingorifmoresamplingisneededistoestimateapcsgraph s curvature k. more on this in section .
.3huirupdqfh gliihuhqfh wr hunhoh sdfkh n figure pcs graphs of spls in the critical zone.
recursive searching thebestconfiguration cbestoutof10randomsampleswillhave an average error distance of 11along the x axis from .
100randomsamples or10 thepreviousnumber areneededto findcbetterthat reduces the error to .
note that approximately of the additional samples will not perform betterthan cbest.
this is wasteful.
we call this non recursive searching nrs to distinguish it from our upcoming approach.
random sampling with recursion offers improvement.
ideally samples of the original configuration space can identify the best ofthisspace andanother10samplescanconstrictthissmaller spacebyanother10 tothebest1 foratotalcostof20samples.
thisis better this is recursive searching .
thekeydriverforrecursionisperformancestairs.asstairshave differentaverageperformancesduetodifferentfeaturedecisions finding the best performing stair that contains improves the result of sampling.
consider thepcs graph of llvm infigure .
this graph looks almost linear with no stairs.
however stairs become visible as configurationsareanalyzedbasedonfeaturestheyhaveincommon.in each graph of figure configurations are partitioned by whether they include a particular feature or not which is done recursively.
themostinfluentialfeature oritsnegation isselectedtopartition the configurations.
then from the remaining features the most influential feature or its negation regarding the partition that better performs in overall is selected as the next feature to partition.
each graph in figure clearly shows the effect of performance stairs whereonepartitionisconstrictedbythenextviatheselection 65esec fse september paderborn germany j. oh d. batory m. myers and n. siegmund ofa good performing or noteworthy feature.each suchfeature defines a stair .
thus devising an algorithm that finds a good stair onwhichtorecurseisthecrucialnextstep.weusethe statistical recursive searching srs algorithmdefined next.
olfp hqwluh vsdfh olfp jyq olfp jyq lqolqh 3huirupdqfh 3huirupdqfh3huirupdqfh 3huirupdqfh figure recursive stairs of llvm.
.
statisticalrecursive searching srs there are at least two basic approaches to find a good stair.
one directly focuses on the feature decisions that are expected to form the best stair by using common feature decisions in the k best sampledconfigurations.anotherexploitshowstairsarerecursively formed observing feature influence on performance from samples.
we discovered the k best approach has drawbacks finding a goodkvalue is hard.small koftenyields highlyvariant and inaccurateresults.larger krequiresmoresamplestocollectasfewer commonalitiesare found among them.
similarly wediscoveredthesecondapproachalsohasdrawbacks feature interactions and constraints often led to misinterpreting a feature s influence by making decisions inconsistent with .
srscombinestheadvantagesofbothapproacheswhileminimizing their disadvantages.
srs utilizes the k best approach by setting k .
then srs identifies features that are common to the k best andhere sthedifference identifying noteworthy featuresamong them thosefeatures ortheirnegation thatstatisticallyarecertain to improve performance .
srs then constricts the search space to configurations that comply with noteworthy features decisions and the srs algorithmrecurses see algorithm .
.
.
recursion logic.
at each recursive step nrandom samplesaretaken.theperformanceinfluenceoffeaturedecision dis determined as follows d measures the average performance over the nsamples that have feature d. d measures the average performance of thensamplesthat do not have d. d d d is the performance influence of feature d. the sign of d indicates whether dimproves negative value or degrades positive value average performance.
t test d isthe resultof welch st test on whether d is better than d with confidence.welch s t test evaluates the hypothesis that the mean of one samplegroupishigherthantheother .thatis itdetermines whether the d from samples is reliable to distinguish whether d or disanoteworthyfeature.noteworthyfeaturesconstrictthe configuration space for the next recursion by becoming additional constraintsthat samplesmust satisfyat the next recursive step.
.
.
termination logic.
recursion terminates when no new noteworthy features are discovered.
srs assumes that the configurationspacecannotbereducedfurther sothatrandomsamplingon thisregionyieldsagoodconfiguration.ifthesizeoftheconstrictedconfigurationspaceissmallerthan n allconfigurationsinthespace are measured.
algorithm1 srsalgorithm 1procedure srs n fm dset input n number of samples per recursion fm feature model propositional formula dset set of feature decisions initially empty output cbest best configuration found set of features 2samples samplenconfigs.
from fm dset 3sortsamples so thatsamples has best performance 4commons common feature decisions in samples and samples 5foreachdecision incommons do if decision ttest decision then adddecision todset 8ifdsetunchanged from previous recursion then returnsamples 10else return srs n fm dset .
estimatingpcsgraphcurvature k let x r denote the size of a stair in terms of the number of configurations at the rthrecursion where x the number of configurations in the original space.
x r decreases with increasingr.
using cbbds we can compute x r with pin point accuracy.
therearetwoidealvalues valuesthatcannotbecomputedunlessperformancedatafortheentireconfigurationspaceisavailable.
let x r betheerror distance fromthebestsampledconfigurationcbestto along the x axisatr threcursion x r cbest confi s total ofconfi s andlet y r betherelativeperformancedifferencebetweenthe best configuration cbestand atr threcursion as y r cbest we estimate x r and y r from random samples by making the following best case assumptions samplesare x r n 1awayfrom each other on x axis.
recursion always finds the best stair that contains .
pollutionis negligible between cbestand .
6srsmostlyavoidslocalminimabysearchingapcsgraph whichismonotonically decreasing .
this is elaborated in .
66finding near optimal configurations in product lines by random sampling esec fse september paderborn germany figure depicts how x r and y r can be estimated with these assumptions.
e x r our estimate of x r is based on the size of the current stair and number of samples e x r x r x n wherecbestis x r n 1configurationsfrom along x axis.
wecomputetheslopeorcurvature kofastairusingtherightmost1 3ofitssamples.wefound1 3workswell computedby a standard least squares method .
e y r our estimate of y r is a linear extrapolation of cbest using slope kto estimate e cbest k x r n thene y r is e y r cbest e e slope is estimated slope or curvature samples sorted configurationsperformance figure estimating x r and y r .
ateachrecursion wereport triplestothe user to decide whether the best solution found so far is accurate enough therebystoppingtherecursionbeforealgorithm1stops itself and eliminating the need for further costly sampling.
the results of the next section are based on algorithm stopping itself.
evaluation five research questions evaluate our work rq1 doesoursamplingtheoryfornrsmatchobservations?
rq2 is srs more efficient than nrs?
rq3 why does srs work?
rq4 is srs better than existing approaches?
rq5 do nrs and srs scale to large configuration spaces?
toanswerthesequestions weusedthedatabysiegmundetal.
as ground truth presented in section .
.
.
rq1 does our sampling theory for nrs matchobservations?
wecomparedthetheoreticalpredictionsofnrsusing en eq.
withtheaverageofmeasuredvaluesfor x eq.
.forapache eq.
was used instead as the configuration space is tiny.
we performed100experimentsforeachvalueof n.foreachsystem the experiments started with nat to incremented by plotted forcomparisonwith en seefigure13.thesegraphsconfirmaclose agreement between nrs theory and observations their differences are imperceptible.
forrq1 our sampling theory matches empirical observations.
hunhoh sdfkh 7khruhwlfdo sdfkhb7khruhwlfdo lvwdqfh wr ri udqgrp vdpsohv t t sdfkh figure nrs theory vs. empirical observations.
.
rq2 is srs more efficient than nrs?
we compared the accuracy of srs and nrs using an equal number of samples and collected the following data xis the true x axisaccuracyof srs when it terminates nis the number of samples per recursion nis the total number of samples taken by srs and enis the theoretical accuracy of nrs assuming nconfigurations are randomly sampled.
note we do not report yvalues here.
a decrease in xis nevermatchedbyanincreasein yinapcsgraph.
yvalues are important but only when comparing srs with existing approaches whichwe do in rq4.
figure plots averages of experiments with different n values.whileboth xandendecreasesharply withincreasing n xis on average better than en.
hunhoh 0hdvxuhg lvwdqfh wr ri vdpsohv shu uhfxuvlrq lvwdqfh wr ri vdpsohv shu uhfxuvlrq lvwdqfh wr ri vdpsohv shu uhfxuvlrq lvwdqfh wr ri vdpsohv shu uhfxuvlrq 7khruhwlfdo sdfkh figure comparison between srs and nrs.
forrq2 srs is more efficient than nrs when the number of samplesper recursion nexceeds .
67esec fse september paderborn germany j. oh d. batory m. myers and n. siegmund .
rq3 whydoes srs work?
we collected the following measurements to understand how srs performs all taken at srs termination nthe total of samples taken dis the total of noteworthy features selected is the of noteworthy features that belong to and ris depth of recursion.
figure15plotsthesemeasures w.r.t.nforall4systems.reinforcing the results of rq2 thed andrsaturate at n indicating that recursion works as desired.
as nincreases accuracy increases at the cost of a linearly increasing n. hunhoh sdfkh hswk ri uhfxuvlrq ri ihdwxuhv lq 7rwdo ri vdpsohv ri vhohfwhg ihdwxuhv ri vdpsohv shu uhfxuvlrq ri vdpsohv shu uhfxuvlrq ri vdpsohv shu uhfxuvlrq ri vdpsohv shu uhfxuvlrq figure results of srs recursion.
forrq3 srsworksbecauseitrequiresrelativelyfewsamples per recursion it accurately predicts features that belong to and relatively few recursions are needed.
.
rq4 issrsbetterthanexistingapproaches?
wedeterminedthebestconfigurationthatcanbereturnedbyexistingpredictionmodels andderivedtheir yvaluewithrespecttothe total number of samples nused to construct the prediction model.
wecomparedourresultswiththebestresultstodate sarkar2015 andsiegmund2012 7whichhadtheirtoolandgenerated prediction models available at .
.
.
comparison with sarkar2015.
sarkar2015 spredictionmodel uses aclassification and regression tree cart of features based on how randomly sampled configurations can be partitioned by features.
each leaf node of the cart is a group of sampled configurationsthatsharethesamedecisions featureselections .thetree does not cover all features but only the ones that are significant to performance.
when a configuration is queried cart is traversed tofindaleafthatmatchesitsdecisions.theaverageperformance 7it is unclear to us on how to compare our results to a newer version of sigmund2012 as they extend their work with numerical features features whose values are within a range of real numbers simply ignoring numerical features was not possible.of the sampled configurations within the leaf is returned as the predicted performance.
to compare with srs the leaf with the smallest average performance was regarded as the predicted performance of the best configuration.
ywas derived as the relative error between and this value.
using their tool prediction models were created to derive yand averaged for different sample sizes.
figure16plots yofsrsover n aswellasthevaluesderived from sarkar2015 plotted as squares.
the graphs show that srs obtainedthesame yvaluewithfewersamples n andfoundbetter yvalues with same n except when n where statistical reasoningisnotmeaningful.forexample inberkeleydbc sarkar2015 used samples to obtain an accuracy of y see point square squaresmallsolidin figure .
srs needs samples to produce this accuracy.
and whensrs uses110 samples it obtains an accuracy of y .
.
further theirresultsdidnotshowacleartrendoverthenumber of samples as larger ndidnotnecessarily leadto a smaller y.i n contrast srs clearlyshows a decrease of yasnincreases.
here is why cart takes the average performance of configurations as predicted performance which cannot be better than the best sampled configuration among them.
instead srs searches the spacedirectly to find the best performing configuration it can.
hunhoh 903huirupdqfh gliihuhqfh wr 7rwdo ri vdpsohv 3huirupdqfh gliihuhqfh wr 7rwdo ri vdpsohv 3huirupdqfh gliihuhqfh wr 6dundu 6lhjpxqg 3huirupdqfh gliihuhqfh wr 7rwdo ri vdpsohv 7rwdo ri vdpsohv sdfkh figure16 comparisonwithsarkar2015andsiegmund2012.
.
.
comparison with siegmund2012.
siegmund2012 s prediction model assigns performance values to key features and their interactionsusingconfigurationmeasurementsandlinearprogramming.theresultingmodelcanpredicttheperformanceofanylegal configuration.we defined yfor thisprediction model as follows y cpredicted best where cpredicted best is the actual not predicted performance ofcpredicted best the best performing configuration according to theirpredictionmodel.tobuildtheirmodel siegmund2012used different strategies to select configurations.
as different strategies 68finding near optimal configurations in product lines by random sampling esec fse september paderborn germany used different numbers of samples we measured yfor different strategies.
figure plots the prediction model results of siegmund2012as triangles.
as with sarkar2015 srs obtained the same yvalue with fewer samples n and found better yvalues with the same n.for example siegmund2012 used samples to obtain an accuracy of y forllvm seeseepoint triangle squaresmallsolidinfigure16 .srsneededonly17 samplestoproducethisaccuracy.andwhensrsuses62samples it obtained an accuracy of y .
.
like sarkar2015 more samples did not guarantee a better y value norwasthereconsistencyacrosssystems asgreatlydifferent yandnvalues were observed.
srs clearly shows a decrease of yasnincreases.
forrq4 srs outperformsexistingprediction models evenassuming an optimizer always finds the best configuration based on the prediction model.
.
rq5 do nrs and srs scale to large configurationspaces?
zhangetal.
createdlargeconfigurationspacesby composing multiple spls see table .
configurations from each spl are combined by taking the union of their features and summing their performance values.
table combined spls for scalability evaluation combined systems of features of configs.
apache llvm berkeleydbc apache x264 berkeleydbc llvm x264 berkeleydbc apache x264 llvm berkeleydbc demonstratingthescalabilityofnrsissimple eq.
defines nrsperformanceforconfigurationspacesofsize2000toinfinity.
figure showed how spls of size up to match the predictions of eq.
.
averaging experiments for each value of n figure shows how the two smaller composite spls of table whichare200ktimeslargerthanthebiggest 2560ofberkeleydbc in figure13 match eq.
.
extendingfigure for n 20was infeasible as .
of these huge spaces exceeded the memory capacityof our machines .
of random samples distance to .
.
.
.
.
.
.
.
110apache s s berkeleydbc apache s llvm s berkeleydbc e n eqn.
eqn.
figure nrs theory vs observations on large spaces.
demonstrating the scalability of srs is similar.
performance graphs for composite spls should all have the same shape and shouldmatch those of spls with small configuration spaces as in figure .
figure shows this isomorphism in all four composites.
note that srs performs betterthan nrs in large spaces than insmall webelievethattheinitialnoteworthyfeaturessrsselectsarethemosteffectivecandidatesforeachindividualsplinacomposite hencethepercentageimprovementappearsbetter.sothismight be an artifact of using composite spls.
forrq5 nrs and srs scale to large configuration spaces.
as before with smaller spaces srs outperforms nrs.
sdfkh hunhoh hunhoh sdfkh 90 hunhoh sdfkh hunhoh lvwdqfh wr ri vdpsohv shu uhfxuvlrq lvwdqfh wr ri vdpsohv shu uhfxuvlrq lvwdqfh wr ri vdpsohv shu uhfxuvlrq lvwdqfh wr ri vdpsohv shu uhfxuvlrq figure xof large configuration spaces.
.
threatsto validity internal validity.
we used ground truth data of which are measurementsofrealsystems.whiletheremaybeerrorsinmeasurements thisdatasetwasutilizedbyotherresearchers .webelievethatthethreatofcomparingdifferentapproaches was sufficientlycontrolled.
to controlthe randomnessof sampling weperformed100 experimentsandaveragedtheresults.whilethereareoutliersthat threaten our results xfor both nrs and srs followed a betadistribution indicatingthattheyaremarginalandcanbecontrolled.
external validity.
we evaluated our approach based on 6realworld systems with different domains and numbers of features.
we provided a mathematical argument on the system independence of nrs statistical reasoning of srs may depend on the number of featuresandtheirinfluenceonperformance.weareawarethatsrs performancemaynotgeneralizetoallsystemsduetothis identical trends from our evaluations across systems and their combinations gives confidence that our conclusions should hold for other spls.
related work section3placedourresearchinperspectivewithpriorwork.we elaboratekey topics in more detail below.
.
performanceprediction models a performance prediction model is a function c that returns an estimateoftheexpectedperformanceofansplconfiguration c for alllegalconfigurations.asidefromthetwoapproachesdescribedin 69esec fse september paderborn germany j. oh d. batory m. myers and n. siegmund section .
sarkar et al.
used projective sampling to minimize the cost of constructing a cart model for performance prediction.
projective sampling attempts to find the optimal sample size by approximatingthelearningcurveofthepredictionmodel saccuracy.
siegmundetal.
extendedtheir previouswork with numeric features and an iterative process to build performanceinfluencemodels whichwedonotcoveryet.zhangetal.
used fouriertransformationtocreateapredictionmodelthatnotonly predictsperformance butalsoestimatesitsaccuracy itisunclear ifthisapproachscalesbeyond30features.alloftheseworksare notdirectlycomparablewithsrs astheirevaluationmeasuredthe average prediction accuracy over multiple test configurations and do not provide means for finding the near optimal configurations.
.
optimizers anoptimizerfindsconfigurationsthatsatisfymultipleperformance constraints from a given feature model and properties of each feature.
white et al.
proposed an approach based on linear programming which transforms the given feature model with budget constraints into a knapsack problem.
guo et al.
applied a geneticalgorithm tosearch forthe optimalconfiguration.
from randomly selected configurations they crossover good performing configurations for mutation and modify invalid configurations.
sayyad et al.
elaborated on indicator based evolutionary algorithm ibea for selecting optimal features regarding multiple objectives which outperformed other evolutionary algorithms.
they also proposed a heuristic that uses precomputed valid configurationsasaseedfortheevolutionaryalgorithm toimprovethe scalability ofthe approach.
henardet al.
extendedibea with sat solver to generate random configurations and filter out the invalidconfigurationsfrom mutations to improve scalability.
theseevolutionaryapproachesperformrandomizedmutation ofconfigurations whichoftenleadstoinvalidconfigurations.they require significant effort to find suitable parameter settings which are system specific and require more than initial samples .
.
countingconfigurations countingconfigurationsisknownasthe model counting problem which is regarded as a more complicated problem than checking thesatisfiability .satsolverswereextendedtoexactly or approximately count the number of solutions from a given propositionalformula.bddscancountthenumberofsolutionsvia their construction.
this is advantageous when multiple queries are made to a single formula as the bdd can be reused .
benavidesetal.andpohletal.
comparedcsp sat and bdd solvers on counting configurations where bdd was much faster than the others given enough memory.
mendonca et al.
provided a reasoning and configuration engine splot which uses bdd to count the number of valid configurations.
mendonca et al.
proposed heuristics to reduce the size of bdd through variableorderinginferredfromafeaturemodel whichimproves the scalabilityup to features.
.
samplingconfigurablesystems efficient testing strategies for configurable systems rely on sam pling.
liebig et al.
compared different sampling algorithmswith regards to scalability.
random sampling was considered infeasible as most samples were invalid when features are randomly selected duetofeatureconstraints.medeirosetal.
alsocompareddifferentsamplingalgorithmsforfaultdetectioncapability.
their work randomly selected features eliminating invalid configurations.
but again random sampling features does not guarantee randomsamplingof configurations .
incontrast werandomlysamplefromasetofvalidconfigurations.
sat solvers are sat solvers that also can count the numberofsolutions.thekeytousing satistodeterminehowto uniquelymapagivennumbertoaspecificconfiguration.cbdds provide this capability directly .
conclusions creating performance models that can predict the performance of any spl configuration is a worthy goal it must be used with anoptimizer that knows how to search a large configuration space efficiently.butitisalsoanexpensiveapproach astheperformancemodelmustbereusedindifferentsituationstoamortizethecostofitsdevelopment.akeyassumptioninthislineofworkismeasuring performance for a fixed workload should that workload change a new performance model may need to be created.
we eliminated the middle men of performance models and optimizersbyrandomsamplingtheconfigurationspacedirectlyand usingsampledconfigurationstoprogressivelyconstrictthespace.
our paper makes five contributions weshowedhowtruerandomsamplingofasplconfiguration space can be achieved by counting bdds cbdds .
prior work relied on pseudo random sampling weexplainedhowconfigurationspacescanbesearchedby usingnrandom samples and returning the best performancein n. we called this approach non recursive sampling nrs which has theoretically good performance wedemonstratedthatinformationgleanedfromsampledconfigurations yields noticeably better performance than nrsusing statistical recursive searching srs at a minimal increase in algorithm complexity we compared srs to prior work and showed that srs consistently found better performing configurations using fewer samples and we demonstrated how our approach scales to huge spaces.
webelievethatourworkadvancesandsimplifiesthestate ofthe artinfindingnear optimalconfigurationsinlargesplconfiguration spaces.