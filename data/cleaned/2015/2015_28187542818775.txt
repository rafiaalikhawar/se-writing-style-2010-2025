data delineation in software binaries and its application to buffer overrun discovery denis gopan evan driscoll ducson nguyeny dimitri naydichy alexey loginovyand david melskiy grammatech inc. madison wi usayithaca ny usa fgopan edriscoll dnguyen dnaydich alexey melskig grammatech.com abstract detecting memory safety violations in binaries is complicated by the lack of knowledge of the intended data layout i.e.
the locations and sizes of objects.
we present lightweight static heuristic analyses for recovering the intended layout of data in a stripped binary.
comparison against dwarf debugging information shows high precision and recall rates for inferring source level object boundaries.
on a collection of benchmarks our analysis eliminates a third to a half of incorrect object boundaries identified by an ida pro inspired heuristic while retaining nearly all valid object boundaries.
in addition to measuring their accuracy directly we evaluate the effect of using the recovered data for improving the precision of static buffer overrun detection in the defect detection tool codesonar x86.
we demonstrate that codesonar s false positive rate drops by about across our internal evaluation suite for the tool while our approximation of codesonar s recall only degrades about .
i. i ntroduction despite significant efforts by the research community buffer overruns still constitute one of the most serious threats to software security.
many techniques for securing the execution of arbitrary executables have been advanced for example stack canaries aslr dep shadow stacks and control flow integrity .
these techniques provide coarsegrained protections that are reasonably effective against attacks that attempt to hijack or alter the control flow of a program.
however some attacks are much harder to detect and remediate.
for instance non control data attacks modify critical data without directly affecting control flow and buffer overread s can expose sensitive data without having a detectable effect on the program s execution.
against these kinds of attacks the techniques mentioned in the previous paragraph offer little to no protection.
if the positions and sizes of buffers in a program are known then more powerful protection techniques can be applied for example fine grained stack layout transformation slx or insertion of explicit memory safety checks .
in addition static analysis tools can use information about buffers to identify potential buffer overruns.
unfortunately information about buffer sizes and locations is not readily available for stripped binaries.
a means of inferring this information would enable such use cases as this material is based upon work supported by the united states air force under contract no.
fa8650 c .
any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not necessarily reflect the views of the united states air force.vetting cots programs for vulnerabilities prior to deployment improving the analysis of source code that calls third party binary only libraries and applying protections such as slx to cots programs.
existing techniques for inferring object boundaries tend to fall short in one of two ways.
some heuristic based approaches e.g.
ida pro often break large objects into pieces.
the boundaries inferred by such approaches will cause false alarms if used for bounds checking and may even disrupt program functionality if used for program transformation.
other approaches e.g.
assume that a program is memory safe and thus derive bounds that include the potential overruns.
the resulting information is unhelpful for bufferoverrun detection.
in this paper we present a heuristic approach that addresses the following question given an arbitrary stripped executable infer locations and sizes of objects suitable for buffer overrun detection and protection.
we call our approach data delineation analysis dda .
we use the term object to refer to any top level datum such as an array structure or variable regardless of whether or not the binary was created from an object oriented language.
dda starts with a set of object boundaries that is largely a superset of the desired result.
such set can be obtained with the use ida pro or an ida pro like heuristic sect.
iii a .
this superset of object boundaries is then refined systematically by eliminating boundaries that fall within larger objects such as structure instances.
insofar as the initial set of boundaries provides an overapproximation to the ground truth our goal is to eliminate as many spurious object boundaries as we can at the same time we want to retain the true boundaries that enable the detection of actual buffer overruns.
at the heart of dda is a novel technique that we call parameter offset analysis poa .
poa operates by identifying and symbolically propagating possible base pointers to objects.
for each base pointer the set of constant offsets used in memory dereferences is collected to estimate the extent of the object pointed to by the base pointer.
that is if poa sees an instruction mov eax and the value of ebx is recognized as the base pointer pbase the analysis infers that the instruction is performing a field access and concludes ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee icse florence italy that the object pointed to by pbase is at least 132bytes long because four bytes are accessed .
to avoid the pitfall of over approximating object extent based on unsafe memory accesses we rely on the intuition that buffer overruns are more likely to be in loops where the address or offset changes on each iteration or in calls to functions like strcpy that operate on unbounded buffers.
therefore our analysis only makes use of offsets that appear as syntactic constants that is literal values in the program text.
we implemented our approach for bit x86 binaries1and evaluated the analysis prototype on a number of real world benchmarks binaries compiled from c and c code with both gnu gcc and the microsoft visual c compiler.
to evaluate our analysis we conducted two types of experiments we compared the boundaries inferred by our analysis with debug information dwarf2 .
the evaluation showed that our approach yields a low number of both false positives and false negatives for unoptimized builds.
however the analysis precision somewhat decreases at more aggressive optimization levels.
we present a detailed analysis of false positives and false negatives in our experiments.
we used object boundaries derived by our analysis to improve precision of codesonar x86 a commercial heuristic static analysis tool for detecting defects in x86 binaries.
our experiments showed that the use of object boundaries found using parameter offset analysis reduced our approximation of the number of false positive warnings by about while only reducing our approximation of the number of true positives by slightly more than the latter corresponds to increasing false negatives .
interestingly optimized programs saw more benefit from dda on both measures.
contributions.
this paper makes the following contributions we present an approach for recovering data layout in an arbitrary stripped binary.
we describe a scalable implementation of our approach we present an extensive evaluation of our prototype implementation based on comparison of the recovered layout data with debug information.
we evaluate the usefulness of the improved data boundaries when used for static buffer overrun detection using codesonar x86.
ii.
o verview this section provides a high level intuitive overview of the operation of parameter offset analysis poa .
figure shows a code snippet extracted from putty a popular sshclient utility.
our static analysis tool codesonar x86 reports two spurious buffer overruns on lines and when run without poa.
below we explain the root causes of the two false positives and show how poa derives the correct object boundaries allowing codesonar to eliminate the warnings.
1there is nothing in our approach that is specific to x86 or bits and it could be easily extended to x64 and other processor architectures.motivation.
without poa codesonar x86 uses object boundaries largely as they are found by ida pro.
ida pro determines what boundaries exist based in part on the constant offsets from the stack and frame pointers that appear explicitly in the program text see sect.
iii a .
as shown in fig.
des3 decrypt pubkey ossh dereferences addresses esp esp and esp ida pro reports these as object boundaries and codesonar x86 inherits that information from ida pro.
these boundaries split the object ourkeys into three separate chunks causing codesonar to think that the size of var4 whose address is passed to des cbc3 decrypt is bytes as opposed to bytes the true size of ourkeys .
when analyzing des cbc3 decrypt codesonar finds memory accesses at offsets line and line from the formal parameter corresponding to scheds .
however codesonar also sees that var4 is passed as an actual parameter to that function and because the accesses to offsets are beyond what it thinks var4 s size is codesonar emits buffer overrun warnings for lines and .
parameter offset analysis.
poa aims to learn the layout of objects by observing the memory access patterns that appear in a program.
to derive accurate bounds poa must only consider safe memory accesses and ignore the accesses that are out of bounds.
this presents a chicken and an egg problem because accurate bounds are needed to judge which memory accesses are safe.
we rely on the insights described below to resolve this issue.
accesses to fields of structured data are often compiled into instructions that add a constant offset to the base address for the data and then dereference it e.g.
those instructions in lines and of fig.
.
in that example the base address is passed in as the parameter to des cbc3 decrypt and is then loaded intoeax on line .
syntactic constant offsets and from that base pointer are then dereferenced to access the corresponding fields.
meanwhile the most likely buffer overruns occur either in calls to library functions e.g.
the infamous gets or inside loops neither one of these constructs causes access patterns with syntactic constants.
these two observations led us to our guiding principle memory accesses that use syntactically constant offsets have a good chance of being safe.
applied to our running example this principle indicates that the memory accesses on lines and because they use constant offsets from the base address are much more likely to be safe than unsafe.
as a result poa can conclude that var4 which is referenced by those accesses is at least bytes and remove the false object boundaries that ida pro inferred at offsets and .
poa operates by identifying potential base addresses for the objects in a program and collecting for each identified base address the set of constant offsets that are used in its dereferences.
these sets of offsets are used to determine the extent of the objects referenced by each of the base pointers.
icse florence italy1 typedef struct word32 k0246 k1357 word32 iv0 offset word32 iv1 offset descontext void des3 decrypt pubkey ossh sub 427270 sub esp descontext ourkeys ourkeys.iv0 ... mov dword ... ourkeys.iv1 ... mov dword ... des cbc3 decrypt ourkeys lea ecx ... push ecx ... call sub 426c10 static void des cbc3 decrypt descontext scheds sub 426c10 word32 iv0 iv1 ... .... mov eax dword scheds iv0 iv0 mov dword ebx scheds iv1 iv1 mov dword edx sourceida pro andcodesonar x86without ddaddaesp esp esp esp esp esp... var1 var1ourkeys .k0246 .k1357.iv0.iv1 var4var3var2 var4 struct fig.
running example extracted from putty.
source excerpts are shown on the left the corresponding machine code is in the middle and a diagram of the stack under different views is on the right.
the dotted lines in the source diagram indicate subobject boundaries.
the vertical axis is not to scale each element ofourkeys.k0246 andourkeys.k1357 is four bytes as well.
the object var1 is included because of an access to esp that is omitted from the excerpt.
poa is compositional it works bottom up over the call graph computing a summary for each procedure.
the summary consists of a map from a parameter ordinal to a set of offsets that are added to the parameter in an address computation and then dereferenced.
at call sites poa looks at the summaries for the called procedure and if there is a non empty set of offsets associated with a parameter then poa treats the parameter value as a base address and extends its associated set of offsets with the offsets from the summary.
for the running example poa first examines des cbc3 decrypt .
using symbolic execution it tracks the flow of the first parameter represented by a symbolic constant p1 into eax on line .
on line the analysis sees a memory dereference with the symbolic address p1 .
the access is four bytes and so poa adds to des cbc3 decrypt s summary the mapping .
the analysis acts similarly for line leading to the overall summary .
next poa examines des3 decrypt public ossh .
the memory accesses on lines and are ignored because the analysis cannot know whether they refer to scalar local variables or to fields of a local struct as in our example .
on line the address of var4 is loaded into ecx and placed onto the top of the stack which corresponds to passing var4 as the first parameter to des cbc3 decrypt .
at the call site at line the analysis retrieves the summary for the called function sees that there is a non trivial set for the first parameter and uses the information from the summary to conclude that var4 is at least bytes.
the information inferred by the poa is used to modify the ir used by codesonar x86 by merging the three objects at esp esp and esp creating a byte structure.this corrects the data boundary information and eliminates the spurious warnings.
codesonar x86 currently only looks at overruns of an entire top level object and not fields so the fact that the resulting object is a structure instead of a monolithic object is currently ignored.
iii.
d ata delineation analysis data delineation analysis is comprised of three steps step extract a superset of potential object boundaries.
step poa identify a set of aggregate objects.
step refine the set of object boundaries identified in step by eliminating boundaries that fall within any of the aggregate objects identified in step .
the main contribution of this paper is the analysis for performing step above.
steps and are likely to be specific to the clients of the overall data delineation analysis.
a. initial object boundary identification the identification of the initial set of object boundaries is likely to be tied to the implementation specifics of a dda client.
for instance many binary analysis tools use the ida pro disassembler for initial processing of an executable and may adopt the sets of object boundaries identified by ida pro codesonar x86 uses ida pro along with other sources of information to compute its superset of object boundaries.
in addition to codesonar x86 we have a standalone implementation of dda.
that implementation does not explicitly rely on ida pro but instead uses a heuristic that we believe captures the spirit of ida pro s object boundary identification we call this the constant offsets heuristic.
to identify a superset of local object boundaries our heuristic scans each function s instructions looking for dereferences of the form reg c icse florence italywhere regis the stack or frame pointer esp orebp on x86 andcis a constant.
for each such access we add an object boundary derived from c. b. parameter offset analysis parameter offset analysis poa is the main contribution of this paper.
the analysis operates by identifying base addresses of aggregate objects and collecting sets of constant offsets that are used in memory dereferences in conjunction with each base address.
the collected sets of offsets are used to estimate objects sizes.
this section describes how the analysis collects and propagates the offsets how the base addresses are recognized and how the resulting set of object sizes is derived.
offset collection and propagation the analysis proceeds bottom up through the call graph of a program constructing a summary of each function.2letfbe a function.
a summary of fis a map mf p!2z where pis the set of f s parameters andzis the set of integers.
the summary maps each parameter to the set of constant offsets that are used in dereferences of the parameter s value.
consider function des cbc3 decrypt in figure the summary that the analysis constructs for this function has the form .
this captures the fact that the first parameter of the function is used as a base address with offsets dereferenced.
to find instructions that dereference pointers passed in parameters the analysis uses intraprocedural symbolic execution.
symbolic execution starts at the function entry point with a state in which parameter locations are initialized with symbolic constants.
in x86 code the parameters are either placed on the stack above the return address or passed in general purpose registers.
for expediency we perform symbolic execution of all paths in a spanning tree of each function s cfg.
this approximation greatly speeds up the analysis and had very little effect on analysis precision in our experiments.
we recognize four major sources of offset information explicit dereferences.
we check the symbolic value of the dereferenced memory address.
if the address has the form pi c where piis a symbolic constant that corresponds to a parameter and cis a constant value which may vacuously be zero and where kis the size of the access the summary of the function is extended as follows mf mf function calls.
a parameter may be dereferenced by a callee of a function if it is passed transitively.
at each call site we check the symbolic values of each parameter to be 2to handle call graph cycles due to recursion our implementation ignores back edges in such cases summaries of callees may not be available when needed.
in our experiments we have observed only a few cases of imprecision due to this decision.
the precision may be recovered by iteratively repeating the analysis of the functions in strongly connected components of the call graph but we have not implemented this.
3we believe that the precision of the analysis is rarely affected by this simplification because the analysis collects offsets that appear as literal constants in program s text and thus are not affected by loops.passed to the callee.
if the value of callee parameter jis of the form pi c the summary is updated as follows mf mf where translate s c fs cjs2sgandmgis the summary of the callee.
buffer manipulation library calls.
calls to standard buffer and string manipulation functions e.g.
memset and strncpy may dereference parameter values.
for functions that take an explicit length poa checks if that length is a syntactic constant if so poa considers it trustworthy.
this will arise for example when sizeof is used.
at call sites to these buffer functions poa inspects the symbolic values of these parameters.
if the buffer address has the form pi cand the length parameter has a constant value l we extend the summary as follows mf mf hardware assisted loop instructions.
the x86 instruction set contains several instructions that are executed repeatedly in a hardware induced loop until a certain condition is met.
for instance rep stos writes the value from register eax to the memory word addressed by the destination register edi decrements the counter register ecx updates the address in edi based on the direction flag df and repeats until the value in the counter register becomes zero.
for each such instruction we inspect the symbolic values of source and destination registers counter register and direction flag.
if the counter register and direction flag have constant values kanddrespectively and source or destination register has the symbolic value pi c we update the summary as follows mf mf2 4pi7!mf pi c i abs i k sign i d9 identifying base address construction points this analysis phase maps base addresses of objects to sets of offsets that are used in dereferences of those base objects.
for each function and for the global data region the analysis computes a map with signature z!2z.
we will use lfto denote the map for function fand denote the global map as lg.
this analysis phase is similar to the offset collection analysis but instead of symbolic parameter constants we look for global and local addresses.
for instance at each call site we inspect the symbolic values of arguments that are being passed to the callee g if the value of parameter jis an address and mg pj is a non empty set we update the maps as follows the parameter value is a global address a.the global map is updated lg lg the parameter value is a local address sp c where spis the symbolic value of the stack pointer at function entry.
we update the map for the analyzed function as follows lf lf icse florence italycalls to buffer manipulation functions and invocations of hardware loop instructions are treated similarly.
explicit memory dereferences however are skipped they would only yield primitive type objects whose boundaries are already picked up by the the initial object boundary identification.
in our implementation we simplified the above approach slightly we seeded the symbolic execution with a fixed initial value for the stack pointer.
this speeds up the analysis as it opens up more opportunities for constant folding during symbolic execution also it simplifies handling of local memory accesses because symbolic local addresses are reduced to integer constants.
as with the previously described approximations no ill effects have been observed as a result.
local offset analysis.
in our experiments we observed a handful of cases where instead of flat addressing relative to the frame pointer the elements of a local struct are accessed by first loading the base address of the struct into a register and then using field offsets to make an actual dereference.
the following example illustrates this struct s s p p s p x lea eax mov dword ptr 0x5 the analysis described above does not recover accurate sizes for such objects because of constant folding performed during symbolic execution.
for the example above the symbolic value of the dereferenced address is reduced to ebp 0x8 losing information about the object s base address.
to account for such cases we extended the analysis as follows if an instruction assigns an address of a local variable i.e.
a symbolic value sp c to a register we replace the value of that register with specially constructed symbolic constant lc.
at the places where offset sets are collected memory dereferences function calls library calls and hardware assisted loops we check if the dereferenced address has the form lc d and if so we update the lfmapping for caccordingly.
for the example above at line the extended analysis puts a symbolic constant l28intoeax.
thus at line the analysis is able to infer that a local object at address ebp 0x28 is dereferenced with a constant offset 0x20 and update the size of the object accordingly.
aggregate object extraction the final step in our analysis is to extract the actual objects from the l maps described above.
the process we follow is trivial for each mapping in the lmap we extract the set of offsets and determine the starting address of the object note that offsets in the set may potentially be negative and its extent.
the objects that overlap are merged together.
iv.
dda a ccuracy evaluation in this section we describe our evaluation of the accuracy of the boundaries inferred by dda.
we applied our standalone implementation of the analysis to a number of real world x86 programs.
table i presents the results.
the first block in the table shows the results for coreutils binaries small utilities for basic file shell and text manipulation .
we analyzed the coreutils suite at various optimization levels to investigatethe effect of optimization on dda s results.
the next two blocks of benchmarks in the table are larger c programs and c programs respectively compiled without optimization.
all benchmarks were built on ubuntu .
with gcc .
.
.
evaluation methodology.
we compared the set of inferred objects to ground truth as defined by the debugging information emitted by gcc.
in this set of experiments we only concerned ourselves with local variables.
in addition we only compare the parts of each activation record that correspond to explicit variables in the source function frames typically store additional data such as compiler introduced temporaries and spilled register values that dda will infer information about but which has no associated debug information.
there are two types of imprecision our analysis yields.
false positives correspond to inferred object boundaries that do not have counterparts in the ground truth.
false negatives correspond to ground truth object boundaries that are missed by the analysis.
we measure both of these precision is a measure of how many spurious boundaries the analysis infers i.e.
a measure of false positive rate .
recall is a measure of how many true objects the analysis misses i.e.
the measure of false negative rate .
we use the following formulas to compute the two metrics.
let mdenote the number of object boundaries that the analysis correctly identified fp denote the number of false positives andfn denote the number of false negatives.
also let gt m fn denote the number of ground truth object boundaries.
precision gt gt fp recall m gt the two metrics must be used together to assess the accuracy of the analysis for an accurate analysis both precision and recall should be close to .
neither statistic tells the whole story e.g.
finding no boundaries yields precision but recall similarly infering that each byte in the activation record is a separate object yields recall but low precision.
analysis results.
tab.
i presents the experimental evaluation of our analysis.
we report both precision columns on the left and recall columns on the right for several different analysis configurations.
co shows the results for the constant offsets heuristic from sect.
iii a i.e.
when no poa is used .
this data represents a good baseline for the evaluation of the analysis it shows the lowest obtainable precision and the highest obtainable recall for boundary identification.
we also show the results obtained by using standard ida pro mechanisms for detecting local variables.
note that ida pro results are generally comparable to those of constant offset heuristic.
ida pro sports slightly higher precision than constantoffset heuristic which is due to ida pro s use of flirt for recognizing library calls and using that information to infer types for some of the variables.
surprisingly ida pro s recall is slightly lower.
our investigation showed that it was caused by ida pro s failure to recognize variables in function main ... for some of the benchmarks possibly due to the presence of stack alignment operations.
icse florence italytable i a nalysis evaluation .
the vars column shows the number of local variables in the ground truth data .
column ida shows the measurements for ida p ro object detection .
column co shows measurements for the constant offsets heuristic .
the remaining columns show how those measurements are improved with the use of additional poa heuristics .
column deref shows what happens if aggregate objects are identified based on explicit dereferences only .
column loc.shows how measurements improve if the local offset extension is enabled .
column lib shows the effect of taking buffer manipulation functions into consideration .
column all shows the measurement for the full scale data delineation analysis .
finally column 64b it shows the dda results are affected by a simple heuristic for detection of bit integers .
precision recall benchmark vars ida co d eref loc.
l ib all 64b it ida co d eref loc.
l ib all 64b it coreutils .
.
.
.
.
.
.
.
.
.
.
.
.
.
coreutils o .
.
.
.
.
.
.
.
.
.
.
.
.
.
coreutils o2 .
.
.
.
.
.
.
.
.
.
.
.
.
.
grep .
.
.
.
.
.
.
.
.
.
.
.
.
.
irssi .
.
.
.
.
.
.
.
.
.
.
.
.
.
nginx .
.
.
.
.
.
.
.
.
.
.
.
.
.
tcpdump .
.
.
.
.
.
.
.
.
.
.
.
.
.
wget .
.
.
.
.
.
.
.
.
.
.
.
.
.
zsh .
.
.
.
.
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
llvm as .
.
.
.
.
.
.
.
.
.
.
.
.
.
llvm diff .
.
.
.
.
.
.
.
.
.
.
.
.
.
llvm mc .
.
.
.
.
.
.
.
.
.
.
.
.
.
llvm objdump .
.
.
.
.
.
.
.
.
.
.
.
.
.
llvm size .
.
.
.
.
.
.
.
.
.
.
.
.
.
doxygen .
.
.
.
.
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
the subsequent columns show how the results are affected by using various configurations of poa.
d eref shows the measurements for a variant of poa that relies only on explicit memory dereferences.
l oc.
shows the measurements for explicit dereferences only poa with the local offsets analysis extension enabled.
l ibshows measurements if calls to buffer manipulation functions are also taken into consideration.
finally a llshows the measurements for the complete dda.
as the data in tab.
i demonstrates compared to the constant offsets heuristic our analysis improves the precision of data delineation by for c programs by with respect to ida pro and by for c programs without significantly affecting the recall.
that is the use of poa eliminates about half of the false positives yielded by the constant offsets heuristic for c programs and about third of those for c .
the experiments with the coreutils show that optimization significantly decreases the precision of the analysis though the gain compared to the constant offsets heuristic is increased .
our investigation showed that the primary culprit is function inlining the instances of structs are created and manipulated locally and thus poa is not able to identify them.
we examined the false positives and false negatives that our analysis yields and identified several causes.
bit ints.
in a bit build gcc uses two bit words that are manipulated separately to implement bit integer types.
thus our analysis is not able to connect the two words.
this category accounts for the majority of false positives we saw in our benchmarks.
to estimate how much this category of false poitives affects the analysis precision we implemented a simple heuristic for detecting bit integers.
the heuristic identifies pairs of adjacent words in each stack frame that are always read or written together within a basic block and marks themas bit words.
the column 64b itshows how applying this simple heuristic affects the overall results of dda.
on average the heuristic removes about half of the remaining false positives.
however it also has an effect sometimes sizable on the analysis recall.
additional work is needed to make bit integer detection more precise.
incomplete ir.
the standalone dda implementation s reconstruction of program s intermediate representation is not yet complete and does not always recover the entire control flow of a program.
in particular indirect control transfers pose a challenge indirect function calls and control flow due to jump tables is not always properly resolved.
this causes both false negatives and false positives.
passing structures by value.
our techniques are geared towards programs that pass aggregate objects by reference and yields false positives when they are passed by value.
infeasible paths.
we have seen several examples in which poa over estimated the size of objects because the summary it computed for a function included information about paths that were infeasible in some of that function s calling contexts.
for example consider a function that takes a pointer to objects of varying size and adjusts its behavior based on object s dynamic type.
for such function poa may compute a summary that maps the parameter to the size of the largest type it accepts even though some call sites pass smaller objects.
local objects.
if a buffer is used only locally the compiler never generates an access through a base pointer our analysis will not be able to identify it.
these shortcomings of the analysis remain to be addressed in our future work.
icse florence italytable ii c odesonar x86 warning summary information .f.o.
stands for frames only and o .o.for object overrun .
the column gives the number of binaries measured .
the data shown here are normalized to the total number of no dda object overrun warnings in the respective category matched or binary only .
tp proxy fp proxy higher is better lower is better no dda dda no dda dda benchmark f.o.
o.o.
o.o.
f.o.
o.o.
o.o.
windows dbg.
c .
.
.
.
.
.
windows dbg.
c .
.
.
.
.
.
windows debug .
.
.
.
.
.
windows rls.
c .
.
.
.
.
.
windows rls.
c .
.
.
.
.
.
windows release .
.
.
.
.
.
all windows .
.
.
.
.
.
linux .
.
.
.
.
.
all .
.
.
.
.
.
v. s tatic buffer overrun detection evaluation in this section we present our evaluation of the effect of dda on codesonar x86 s ability to find buffer overruns.
we first present an brief overview of our heuristic static analysis tool codesonar x86.
we then describe our evaluation methodology followed by the results.
codesonar overview.
codesonar is grammatech s commercial tool that specializes in static defect detection .
codesonar was originally developed for c and c programs but has been retargeted to also work on machine code.
regardless of the language codesonar uses heuristic analyses to find a diverse set of defects including memory safety errors and api misuses.
the machine code version of codesonar begins with frontend analyses that build an ir of the program.
it uses ida pro for disassembly and initial ir inference but adds many additional advanced analyses to increase the precision of the recovered ir.
the dda implementation resides in the front end because the ir contains information about the objects present in a program.
the codesonar back end then analyzes the ir to determine potential defects.
the ir that the back end uses is common between the different source and binary front ends.
the back end s analyses are heuristics that scale to very large industrialsized programs.
evaluation methodology.
as a portion of codesonar x86 s routine testing we analyze several dozen open source programs to watch for unexpected changes in the reported warnings.
the number of programs and number of warnings are large enough that we cannot manually classify each warning to determine whether it is a true positive or a false positive.
instead we use a proxy for these measurements.
the evaluation procedure for codesonar x86 s warnings proceeds as follows we start with the source version of a program and build it to create a binary.
we run codesonar c c on the source version of the program to produce a list of source warnings.
we run codesonar x86 on the binary to produce a list of binary warnings.
for each binary warning produced by step we automatically classify it into one of three categories matched warnings the binary warning appears to be the same as some source warning these warnings are our proxy for the true positives in the binary analysis.
binary only warnings the binary warning is not the same as any source warning but is warning about a location in the program s source these warnings are our proxy for false positives.
out of scope warnings the binary warning was in an external library e.g.
the c runtime rather than application code these warnings are ignored for purposes of estimating warning accuracy.
finding correspondences between warnings step is done by using debugging information for the binary to get the source file and line number of each binary warning then looking for a source warning of the same type on the same source line.
note that the use of debugging information in this process is only during the evaluation of the results and not during analysis.
we use this measure because codesonar c c is a leading static analysis tool and thus we trust the warnings it produces to be a reasonable approximation to ground truth.
if codesonar x86 finds a warning that codesonar c c did not find or vice versa we expect the chance that it is caused by imprecise ir recovery relative to the source to be much higher than the chance that the binary analysis actually did a better job though this is by no means guaranteed.4out of scope warnings correspond to portions of the binary for which there was no source and thus the source analysis had no opportunity find the warnings we believe excluding them results in a more apples to apples comparison.
codesonar x86 supports two modes of operation for finding buffer overruns.
the first mode looks for overruns only of entire stack frames and heap blocks.
the second mode looks for overruns of individual objects as well it can find an overrun from one object to another within a stack frame and from one global to another.
the first mode we call frame only despite it finding heap overruns too the second we call object overruns .
until our implementation of the analyses described in this paper the object overrun version was not practical to run on real examples as the false positive rate was too high.
we present data for the following configurations frame only no dda this configuration serves as a baseline for the results in this section.
object overrun no dda the improvement to true positives relative to frame only no dda illustrates the benefit 4indeed one motivation behind producing a binary version of codesonar is to make it possible to find wysinwyx what you see is not what you execute problems where defects and vulnerabilities only arise because of compiler transformations or low level implementation decisions.
icse florence italyto consider intra frame overruns the increase in false positives shows the cost.
object overrun dda relative to object overrun no dda the drop in false positives represents the improvement to warnings brought about by better delineation of stack objects.
the drop in true positives represents cases where dda is too aggressive in eliminating boundaries.
for all of the reported configurations we disabled an additional warning pruning heuristic that is enabled by default in codesonar x86 called the scalar guard.
as a result the number of false positive warnings reported in this paper are higher sometimes significantly than what a typical user of codesonar x86 would currently see.
the scalar guard suppresses any non heap buffer overrun warning where the object being overrun is four bytes or less.
the are two reasons we disable the scalar guard for these experiments our long term plan is to disable the scalar guard.
the scalar guard suppresses a vast majority of warnings both false and true warnings.
prior to dda the scalar guard was the only way to enable object overruns without an overwhelming number of false positives even if did cause many true candidates to be dropped.
dda was improved and incorporated into codesonar x86 specifically to support the goal of allowing us to disable the scalar guard.
the scalar guard interacts with dda in unexpected ways.
in particular even though the better object boundaries found through dda should strictly refine the presented warnings the number of warnings would sometimes increase with dda enabled because it increases the size of an aggregate beyond four bytes.
the results are not worse because we gain true positives that the scalar guard suppressed but it makes evaluating the effects of dda more difficult.
disabling the scalar guard eliminates this interaction and leads to a much clearer picture of the effects of better data delineation.
buffer overrun detection results.
we ran codesonar x86 on subject binaries.
most of them binaries are windows programs and libraries and the remaining are linux programs.
each windows test is compiled twice once in debug mode no optimization but still ignoring debugging information and once in release mode optimized .
the four linux binaries are compiled from separate programs all four were optimized.
the increase in analysis time to run dda is negligible in all cases.
tab.
ii show summary data across our benchmark set tab.
iii show full results and more information.
for purposes of evaluating dda we are interested in the change in the numbers more than the absolute values.
there is a noticeable increase in the number of matched warnings when we allow object overruns the total number of matched warnings across the suite almost doubles from the frame only no dda configuration to object overrun no dda.
however object overrun comes at a cost the number of binary only warnings climbs by about 30x.however turning on dda helps substantially.
the number of false positives is cut by almost a factor of while the proportion of lost true positives is not much more than .
in other words dda allows us to retain most of the benefit of being able to find object overruns while at the same time dramatically reducing the number of false positives.
interestingly particularly in light of the results described in sect.
iv dda seems to both help more and hurt less on optimized executables.
comparing the windows debug vs. windows release measures we see that codesonar x86 retains of the true positives in the optimized binaries when dda is enabled vs. only of the true positives for the debug build.
at the same time dda eliminates of false positives in the release binaries vs. only of them in the debug binaries.
considering that the set of programs and libraries are the same across the two sets of runs it is not clear why this happens.
however it is encouraging in terms of real world applicability as we believe optimized code is of the most real world interest.
secondary effects on other warnings.
our work on integrating dda into codesonar x86 was driven by the desire to improve reporting of buffer overruns.
unexpectedly we saw benefits to other warning classes as well.
for example consider the following code snippet struct int x y object memset object sizeof object printf d object.y object.x without dda the codesonar x86 front end breaks up the memory containing object into two variables because there are explicit uses of both of its fields on line .
codesonar treats the call to memset as performing an byte write into the variable corresponding to object.x which is only bytes and reports a buffer overrun on line .
however codesonar also reports another problem.
in part to increase scalability codesonar does not track the effects of illegal memory accesses such as the reported buffer overrun.
as a result codesonar does not consider the memset call to have initialized object.y and it reports a use of an uninitialized variable warning on line for object.y.
dda allows the codesonar x86 front end to infer that the memory belonging to object is all one object.
as a result codesonar s ir sees an byte memset of an byte buffer and thus there is no overrun.
codesonar is also able to determine thatobject.y has been initialized and as a result the use of an uninitialized variable warning is also removed.
in addition codesonar x86 without dda misses reporting the null pointer dereference on line because it does not know that object.y has been set to .
with dda enabled codesonar x86 understands that object.y is initialized to null and reports a warning.
in summary without dda codesonar x86 experiences a false positive buffer overrun warning on line a false positive uninitialized variable warning on line a false negative null pointer dereference on line enabling dda fixes all three problems.
icse florence italyvi.
r elated work our parameter offset analysis was inspired by the howard tool .
however there are some important differences between the two tools.
howard is a dynamic analysis and requires a test suite of a benign inputs that b collectively exercise all potential accesses of aggregate data types.
because dda is a static analysis it does not require a high coverage test suite.
further howard does not honor our position to trust only syntactic constants.
howard infers some of the internal structure of objects as well as information about arrays.
our implementation finds some of this information too e.g.
it determines information about nested structures in similar circumstances as howard but because we do not currently need this information for our applications we discard it.
lin zhang and xu presented a different dynamic analysis called rewards.
rewards is primarily focused on propagating type information from type sinks e.g.
library or system calls backwards and forward to locations that held or will hold a value of the same type it does not appear to find the size of aggregate objects other than those that are passed to a known function in such a manner.
jin et al.
presented a technique for recovering information about what c classes and objects are present in a binary .
their tool objdigger uses interprocedural symbolic execution to track allocations of objects looking at how they are passed to functions that use the thiscall calling convention passing this in the register ecx .
objdigger also recovers some information about the layout of objects based on uses within these functions.
to this extent our work resembles theirs.
however our goals are also very different and this leads each analysis to infer several things that the other cannot.
for example objdigger is much less flexible in the kinds of patterns it recognizes both in terms of only tracking objects through thiscall functions and in the fact that objdigger isn t prepared to learn anything from buffer manipulation functions.
lee avgerinos and brumley present a technique tie for performing type inference on a binary .
while we could probably profit from the kind of information it computes in other scenarios tie both does much more than we need and yet does not quite match our goal.
tie tries to compute actual type information e.g.
signed unsigned integers vs. pointers whereas all we need is the locations and sizes of objects.
at the same time it appears that tie would at least as stated have the soundness problem mentioned in the introduction if a program can overrun a buffer it seems that tie would just infer a larger buffer size.
it would probably be possible to modify tie to honor our only constants are trustworthy rule.
however if you do not need the full power of tie we think that our technique is simpler to understand and implement.
balakrishnan and reps present a technique divine for statically recovering object information from a binary which is a novel combination of value set analysis vsa and a ported version of ramalingam et al.
s aggregate structure identification asi from cobol to x86 machine code.interestingly the goal of divine in some cases is the opposite of our needs a crude description is that divine sometimes attempts to separate e.g.
fields of objects so that separate vsa abstract values can be tracked for each field leading to more precise vsa results .
asi s role in divine is to find opportunities for summarization but it is at a different level than is helpful for us.
in addition to the different goals divine has the soundness problem discussed in the introduction it infers the objects based on the program s access patterns and thus if the program is incorrect so will the inferences be.
vii.
f uture directions in this paper we presented a static analysis for inferring the locations and sizes of global and local data in an arbitrary stripped executable while avoiding the trap of choosing a sound technique that will infer objects that make buggy programs look correct.
the inferred data layout information allows a number of existing techniques for ensuring memory safety to be applied effectively in the absence of source code.
our evaluation of the analysis showed that it achieves good precision at low cost.
we used the data inferred by our analysis to significantly improve the precision of static buffer overrun detection in the defect detection tool codesonar x86.
in the future we plan to further enhance dda.
the current work focuses primarily on detecting the layout of top level objects and ignores their internal structure.
we believe that our approach can be extended in a straightforward fashion to infer information about the internal structure of program data for example structure fields that are themselves structures.
as mentioned before we compute and discard information that naturally leads to finding internal structure.
once we have information about the internal structure there is the potential for finding overruns of the subobjects itself.
the codesonar back end has support for finding warnings of this type in source code though the same thing for binaries would require non trivial extensions even once the internal structure is known.
another improvement to the analysis that we are considering is a more sophisticated tracking of offsets from base pointers.
currently the analysis collects sets of constant offsets.
extending the tracking to support symbolic offsets will improve the precision of the analysis by allowing it to model naturally functions that are similar to memset andmemcpy e.g.
program specific wrappers of those functions .
finally most of our effort during the integration of dda into codesonar x86 was spent on reducing the number of binary only warnings fp proxy with little attention paid to the matched warnings tp proxy that we were dropping at the same time.
we would like to return to the lost matched warnings and either make sure that they are being dropped for a good reason or determine what we can do to retain them without undermining the reduction in fps.
5vsa can be run within the codesonar x86 front end though it was not enabled for our tests.
in addition the divine implementation would not actually create a larger object in codesonar x86 s ir in the presence of an overrun the asi results would not be incorporated in that way.
icse florence italytable iii d ata for codesonar x86experiments .
for summary lines gives the number of tests summarized .
instrs is the number of instructions funcs is the number of functions and time is the number of seconds spent in poa.
tp and fp columns give the number of matched and binary only warnings respectively our proxies for the number of true and false positives .default boundaries dda frame only object overrun object overrun benchmark instrs funcs time tp fp tp fp tp fp bzip2 dxsdk.tutorial00 freeglut .
.
vs9.fractals freeglut .
.
vs9.freeglut freeglut .
.
vs9.lorenz freeglut .
.
vs9.shapes glut libidn .
vs8 libogg libpng .
.
win miniupnpc .
.
vs9 miranda putty.pageant putty.plink putty.pscp putty.putty python .
.
win quakeiii repeater sphinx.sphinx2 allphone sphinx.sphinx2 batch sphinx.sphinx2 client sphinx.sphinx2 server vpx win .ivfenc vpx win .vp8 set maps xmail yasm .
.
vs10 x86.vsyasm yasm .
.
vs10 x86.yasm zlib win windows dbg.
c bzip2 dxsdk.tutorial00 freeglut .
.
vs9.fractals freeglut .
.
vs9.freeglut freeglut .
.
vs9.lorenz freeglut .
.
vs9.shapes glut libidn .
vs8 libogg libpng .
.
win miniupnpc .
.
vs9 miranda putty.pageant putty.plink putty.pscp putty.putty python .
.
win quakeiii repeater sphinx.sphinx2 allphone sphinx.sphinx2 batch sphinx.sphinx2 client sphinx.sphinx2 server vpx win .ivfenc vpx win .vp8 set maps xmail yasm .
.
vs10 x86.vsyasm yasm .
.
vs10 x86.yasm zlib win windows rls.
c cryptopp .
vs8 shareaza .
.
.
tinycad .
.
windows dbg.
c cryptopp .
vs8 shareaza .
.
.
tinycad .
.
windows rls.
c windows dbg.
c windows debug windows rls.
c windows release all windows gnuchess .
irssi .
.
naim .
.
.
.
wu ftpd .
.
linux all icse florence italyreferences c. cowan c. pu d. maier h. hintony j. walpole p. bakke s. beattie a. grier p. wagle and q. zhang stackguard automatic adaptive detection and prevention of buffer overflow attacks in proceedings of the 7th conference on usenix security symposium volume ser.
ssym .
usenix association pp.
.
pax team address space layout randomization grsecurity.net docs aslr.txt.
s. bhatkar d. c. duvarney and r. sekar address obfuscation an efficient approach to combat a board range of memory error exploits in proceedings of the 12th conference on usenix security symposium volume ser.
ssym .
usenix association pp.
.
s. andersen and v .
abella data execution prevention changes to functionality in windows xp service pack microsoft.com en us library bb457155.aspx.
t. chiueh and f. hsu rad a compile time solution to buffer overflow attacks in icdcs pp.
.
stack shield a stack smashing technique protection tool for linux m. abadi m. budiu u. erlingsson and j. ligatti control flow integrity principles implementations and applications acm trans.
inf.
syst.
secur.
vol.
no.
pp.
nov. .
u. erlingsson m. abadi m. vrable m. budiu and g. c. necula xfi software guards for system address spaces in proceedings of the 7th symposium on operating systems design and implementation ser.
osdi .
usenix association pp.
.
m. abadi m. budiu u. erlingsson and j. ligatti controlflow integrity in proceedings of the 12th acm conference on computer and communications security ser.
ccs .
acm pp.
.
c. zhang t. wei z. chen l. duan l. szekeres s. mccamant d. song and w. zou practical control flow integrity and randomization for binary executables in security and privacy sp ieee symposium on.
ieee pp.
.
s. chen j. xu e. c. sezer p. gauriar and r. k. iyer noncontrol data attacks are realistic threats in proceedings of the 14th conference on usenix security symposium volume ser.
ssym .
usenix association pp.
.
b. d. rodes a. nguyen tuong j. d. hiser j. c. knight m. co and j. w. davidson defense against stack based attacks using speculative stack layout transformation in runtime verification ser.
lecture notes in computer science.
springer berlin heidelberg vol.
pp.
.
s. nagarakatte j. zhao m. m. martin and s. zdancewic softbound highly compatible and complete spatial memory safety for c in acm sigplan notices vol.
.
acm pp.
.
cets compiler enforced temporal safety for c in acm sigplan notices vol.
.
acm pp.
.
n. hasabnis a. misra and r. sekar light weight bounds checking in proceedings of the tenth international symposium on code generation and optimization ser.
cgo .
acm pp.
.
m. s. simpson and r. k. barua memsafe ensuring the spatial and temporal memory safety of c at runtime software practice and experience vol.
pp.
.
ida pro interactive disassembler idapro .
g. ramalingam j. field and f. tip aggregate structure identification and its application to program analysis in proceedings of the 26th acm sigplan sigact symposium on principles of programming languages ser.
popl .
acm pp.
.
g. balakrishnan and t. w. reps divine discovering variables in executables in vmcai pp.
.
grammatech inc. codesonar static analysis tool grammatech.com products codesonar.
s. tatham putty a free telnet ssh client greenend.org.uk sgtatham putty .
s. shiraishi v .
mohan and h. marimuthu quantitative evaluation of static analysis tools in software reliability engineering workshops issrew ieee international symposium on nov pp.
.
g. balakrishnan t. w. reps d. melski and t. teitelbaum wysinwyx what you see is not what you execute in vstte pp.
.
a. slowinska t. stancescu and h. bos dynamic data structure excavation tr10.pdf vrije universiteit amsterdam tech.
rep. ir cs february .
howard a dynamic excavator for reverse engineering data structures in proceedings of ndss san diego ca .
z. lin x. zhang and d. xu automatic reverse engineering of data structures from binary execution in ndss .
w. jin c. cohen j. gennari c. hines s. chaki a. gurfinkel j. havrilla and p. narasimhan recovering c objects from binaries using inter procedural data flow analysis in proceedings of acm sigplan on program protection and reverse engineering workshop ser.
pprew .
acm pp.
.
j. lee t. avgerinos and d. brumley tie principled reverse engineering of types in binary programs in ndss .
g. balakrishnan and t. reps analyzing memory accesses in x86 executables in compiler construction ser.
lecture notes in computer science.
springer berlin heidelberg vol.
pp.
.
icse florence italy