learning combinatorial interaction test generation strategies using hyperheuristic search yue jia university college london london wc1e 6bt uk email yue.jia ucl.ac.ukmyra b. cohen university of nebraska lincoln lincoln ne usa email myra cse.unl.edumark harman justyna petke university college london london wc1e 6bt uk email fmark.harman j.petke g ucl.ac.uk abstract the surge of search based software engineering research has been hampered by the need to develop customized search algorithms for different classes of the same problem.
for instance two decades of bespoke combinatorial interaction testing cit algorithm development our exemplar problem has left software engineers with a bewildering choice of cit techniques each specialized for a particular task.
this paper proposes the use of a single hyperheuristic algorithm that learns search strategies across a broad range of problem instances providing a single generalist approach.
we have developed a hyperheuristic algorithm for cit and report experiments that show that our algorithm competes with known best solutions across constrained and unconstrained problems for all real world subjects it equals or outperforms the best result previously reported in the literature.
we also present evidence that our algorithm s strong generic performance results from its unsupervised learning.
hyperheuristic search is thus a promising way to relocate cit design intelligence from human to machine.
i. i ntroduction over the past decade research in search based software engineering has been growing at a rapid pace .
one limitation of much of this work is that search algorithms must be customized for specific instances or equivalence classes of the problem.
for example the existence of constraints in the data set to be optimized often requires a different set of search operators .
hyperheuristic search hs is a new class of optimisation algorithms that may provide a substantial improvement to this bespoke approach .
hs algorithms use dynamic adaptive optimisation to learn strategies without active supervision .
hyperheuristics have been successfully applied to many operational research problems outside of software engineering .
however though they have been advocated as a possible solution to dynamic adaptive optimisation for software engineering they have not hitherto been applied to any software engineering problem .
in this paper we examine the feasibility of using hs in search based software engineering.
to achieve our goal we select a mature and well studied search problem as our exemplar combinatorial interaction testing cit .
cit aims to generate samples that cover all possible value combinations between any set of tparameters where tis fixed usually between and .
software product lines operating systems development environments and many other systems are typically governedby large configuration parameter and feature spaces for which cit has proved useful .
over two decades of research has gone into the development of cit test generation techniques each of which is tailored and tuned to a specific problem .
for example some cit algorithms have been tuned and evaluated only on unconstrained problems while others have been specifically tuned for constrained interaction testing which prohibits certain configurations.
still other cit approaches target specific problem structures such as parameter spaces with few available parameter value choices or are tuned to work on a particular set of real world problems .
colbourn maintains a website of results from many different sources and techniques both published and unpublished in the cit literature while the pairwise.org web portal contains almost tools for pairwise instances of cit alone.
there is also a framework that collates the many different cit algorithms but none of these frameworks or portals can help the tester to choose which algorithm to apply to each cit problem instance.
even when attention is restricted to a single kind of cit algorithm such as simulated annealing there remain further choices to be made for general unconstrained problems the single mutation at a time variant yields a smallest test suites but for binary valued problems a different simulated annealing variant would be recommended while still another variant would be preferred for highly constrained problems .
the tester is therefore presented a bewildering choice between different techniques and implementations from which to choose each of which has its own special properties.
it is unreasonable to expect practicing software testers to perform their own experiments to decide on the best cit algorithm choice for each and every testing problem.
cit users in the research community also find the choices overwhelming.
for example lopez herrejon et al.
ask with all these pairwise testing approaches available the question now is how do they compare?
.
we cannot expect each testing organisation to hire an algorithm designer to build bespoke cit testing implementations for each testing scenario they face.
we need a more general cit approach.
to evaluate the feasibility of using ha as a generalist approach we introduce a simulated annealing hyperheuristic search based algorithm for cit.
our hyperheuristic algorithmlearns the best cit strategy to apply dynamically as it is executed and the chosen strategy may change over time.
this single algorithm can be applied to a wide range of cit problem instances regardless of their structure and characteristics.
for our new algorithm to be acceptable as a generic solution to the cit problem we need to demonstrate that it is effective and efficient across a wide range of cit problem instances when compared to other possible algorithm choices.
to assess the effectiveness of cit solutions we use test suite size which garvin et al.
show to have the greatest impact on overall test efficacy.
to assess efficiency we report computational time as is standard in cit experiments but we also deploy the algorithms in the cloud to provide a supplementary assessment of monetary cost as has been done in other studies .
we compare our hyperheuristic algorithm not only against results from state of the art search cit techniques but also against the best known results in the literature garnered over years of analysis of cit.
this is a particularly challenging quality comparison for any algorithm because some of these best known results are the product of many years of careful analysis by mathematicians not machines.
we show that our hyperheuristic algorithm performs well on both constrained and unconstrained problems and across a wide range of parameter sizes and data sets.
like the best known results some of these data sets have been designed using human ingenuity.
human design ensures that these benchmarks capture especially pathological corner cases and problems with specific structures that are known to pose challenges to the cit algorithms.
overall our results provide evidence to support the claim that hyperheuristic search is a promising solution for cit which suggests it may be useful on other search based problems.
the primary contributions of this paper are .
the formulation of cit as a hyperheuristic search problem and the introduction of the first hyperheuristic algorithm hhsa for solving it.
it is the first use of hyperheuristic learning in the software testing literature.
.
a comprehensive empirical study showing that hhsa is both effective and efficient.
the study reports results across a wide range of previously studied benchmarks.
we also study problem instances from two previous studies where each of the cit problems is drawn from a real world configurable system testing problem.
.
a study using amazon ec2 cloud to measure the real computational cost in us dollars of the algorithms studied.
these results indicate that with default settings our hyperheuristic algorithm can produce competitive results to stateof the art tools at a reasonable cost all pairwise interaction tests reported in the paper for all real world problems and the pairwise benchmarks cost only .
.
.
a further empirical study is used to explore the nature of online learning employed by our algorithm.
the results of this study show that the hyperheuristic search productively combines heuristic operators that would have proved to be unproductive in isolation and that our algorithm adapts its choice of operators based on the problem.ii.
p reliminaries in this section we will give a quick overview of the notation used throughout the paper.
cit seeks to select a set of n test cases that cover all possible value combinations between any set of t parameters.
it produces the selected test set in a covering array ca notation which is typically represented as follows in the literature ca n t vk1 1vk2 vkm m where nis the number of selected tests array size the sum of k1 k mis the number of parameters or factors in each test case denoted by k each vistands for the number of values for each of the kiparameters in turn and tis the strength of the array a t way interaction test suite aims to cover all possible t way combinations of values between any tparameters.
suppose we want to generate a pairwise aka way interaction test suite for an instance with parameters where the first and second parameter can take different values and the third one can only take different values.
then the problem can be formulated as ca n and the model of the problem is .
in order to test all combinations one would need test cases pairwise coverage reduces this number to .
we can also introduce the following constraint the first value of the first and third parameters cannot be combined together.
it turns out that adding multiple constraints can significantly reduce test suite size.
these naturally occur in real world problems thus constrained cit is well fitted for industrial applications .
many different algorithms have been introduced to generate covering arrays.
each algorithm is customised for specific problem instances.
for example there are many greedy algorithms such as aetg ipog and pict .
these methods either generate a new test case on the fly seeking to cover the largest number of uncovered t way interactions or start with a small number of parameters and iteratively add new columns and rows to fill in the missing coverage.
other approaches include metaheuristic search algorithms such as simulated annealing or tabu search .
these metaheuristics are usually divided into two phases or stages.
in the first stage binary search for instance is used to generate a random test suite rof fixed size n. in the second stage metaheuristic search is used to search for a test suite of size n starting with r that covers as many interactions as possible.
and there are other unique algorithms such as those that use constraint solving or logic techniques as the core of their approach .
iii.
h yperheuristic cit a lgorithm there are two subclasses of hyperheuristic algorithms generative and selective.
generative hyperheuristics combine low level heuristics to generate new higher level heuristics.
selective hyperheuristics select from a set of low level heuristics.
in this paper we use a selective hyperheuristic algorithm.
selective hyperheuristic algorithms can be further divided into two classes depending upon whether they are online or offline.
online hyperheuristics are unsupervised learning strategieswhile the algorithms are solving the problem.
offline ones require an additional training step prior to solving the problem.
we use online selective hyperheuristics.
the hyperheuristic algorithm takes the set of navigation operators as input.
a navigation operator is a lower level heuristic which transforms a given solution into a new solution in the search space.
the algorithm layers the heuristic search into two levels that work together to produce the overall solution.
the first or outer layer uses a normal metaheuristic search to find solutions directly from the solution space of the problem.
the inner layer heuristic searches for the best candidate operators for the outer layer heuristics in the current problem state.
as a result the inner search adaptively identifies and exploits different strategies according to the characteristics of the problems it faces.
our algorithm uses simulated annealing sa as the outer search.
we choose sa because it has been successfully applied to cit problems yet even within this class of algorithms there is a wide choice of available approaches and implementations .
we use a reinforcement learning agent to perform the inner layer selection on heuristics.
our overall algorithm hyper heuristic simulated annealing hhsa is depicted in figure and set out more formally as algorithm .
simulated annealing outer layer searchget next operatorapply the operator to current solutionsend the delta fitness valuereinforcement learning agent inner layer searchoperator selectionsoft max reward assignmentaction value random init solutionnavigation operatorsoperator 1operator 2operator n. .
.
update solution withupdate temperaturefitness t e fig.
.
hyper heuristic simulated annealing a. the outer layer simulated annealing a standard simulated annealing sa algorithm is used as the outer layer search.
the sa algorithm starts with a randomly generated n karray as an initial solution.
the fitness value for each solution is the number of uncovered t tuples present in the current array.
the fitness value is also used to represent the current state of the problem i.e.
how many tuples remain to be covered .
this problem state is used to understand how our algorithm learns throughout different stages of the problem.
in each iteration the sa algorithm asks the reinforcement learning agent to choose a best operator for the current problem state.
it then applies the operator and passes the change in fitness value delta fitness back to the agent.
thesa algorithm accepts the new solution if its fitness is the same as or better than the fitness of the previous solution.
otherwise it uses a probability e tness t for accepting the current solution based on the current temperature t. as the sa algorithm proceeds the temperature t is progressively decreased according to a cooling schedule.
decreasing the temperature reduces the probability of sa accepting a move that reduces fitness.
the temperature and cooling schedule settings used in the sa are reported in section iv b. the sa algorithm stops when the current array covers all t tuples or it reaches a preset maximum number of nonimproving moves.
many real world cit models contain constraints or dependencies between parameters.
to incorporate the constraints the outer sa first preprocesses the constraints and identifies all invalid tuples which must not be covered.
since previous work used a sat solver minisat for constraint solving we also use it in our implementation.
other constraint solvers could be used but we wish to be able to compare effectiveness to these existing state of the art cit systems and the best results reported for them.
the outer sa checks constraint violations after applying each operator and proposes a repair if there are any violations.
the constraint fixing algorithm is a simple greedy approach that checks each row of the covering array one at a time.
when the algorithm finds a term violation in a row it attempts to fix the row by changing the value of the parameter which violates the term to a random valid value.
the algorithm is set out formally as algorithm .
if the outer sa fails to fix the array it reapplies the current heuristic operator to generate a new solution.
input t k v c n maxnoimprovment output covering array a a initial array t k v n noimprovement curr missing countmissingtuples a while curr missing6 andmaxnoimprovment noimprovement do op rl agent choose action curr missing a0 local move op a while fix cons violation a0 c do a0 local move op a end new missing countmissingtuples a0 fitness curr missing new missing rl agent set reward op fitness ife fitness temp rand 0 to 1 then if fitness then noimprovement noimprovement else noimprovement end a a0 curr missing new missing end temp cool temp end algorithm hhsa we enclose the sa in a binary search procedure to determine the array size n. this outer binary search procedure is a commonly used solution to iteratively find covering arrays fordifferent values of n until a smallest covering array of size ncan be found.
the outer binary search takes an upper and lower bound on the size of array as input and returns the covering array with a smallest possible size.
the casa tool for cit uses a more sophisticated version of the binary search.
it first tries the same size multiple times and then does a greedy one sided narrowing to improve the final array size.
our implementation also performs this casa style greedy approach to finding the array size but the use of this approach is tunable.
input covering array a constraints c output has violation has violation false xtime foreach rowrinado recheck foreach clause incdo foreach term inclause do ifrhasterm then has violation true else has violation false breakend end ifhas violation then if xtime maxfixtime then break end term clause get random term clause r random fix term r term xtime xtime go to recheck end end end algorithm constraint violation fixing b. the reinforcement learning agent the goal of the inner layer is to select the best operator at the current problem state.
this operator selection problem can be considered an n armed bandit problem in which the narms are the navailable heuristics and the machine learner needs to determine which of these heuristics offers the best reward at each problem state.
we designed a reinforcement learning rl agent for the the inner search as rl agents are known to provide generally good solutions to this kind of so called bandit problem .
as shown in figure the rl agent takes a set of operators as input.
in each annealing iteration the rl agent repeatedly chooses the best fit operator a based on the expected reward of applying it at the current problem state.
after applying the operator a the rl agent receives a reward value from the outer layer sa algorithm based on performance.
at the end of the iteration the rl agent updates the expected reward for the chosen operator with the reward value returned.
the goal of the rl agent is to maximise the expected total reward that accrues over the entire run of the algorithm.
because the reward returned by sa is the improvement of sa s fitness value the rl agent will thus learn to choose the operators that tend to maximise the sa s fitness improvement adapting to changes in problem characteristics.our rl agent uses an action value method to estimate the expected rewards for each of the operators available to it at a given problem state.
that is given a set of operators a fa1 a2 a ig letri fri1 ri2 r ikg be the returned reward values of operator aiat the kthiteration at which ai is applied.
letraibe the estimated reward for ai which is defined as the mean reward value ri1 ri2 rik k received from sa.
to balance the twin learning objectives of exploration and exploitation the rl agent uses a softmax selection rule .
the softmax selection rule is a greedy approach that gives the operator with the best estimated reward the highest selection probability.
for each operator ai the selection probability is defined based on the gibbs distribution erai tpn j 1eraj t which is commonly used for the softmax selection .
a higher value of temperature tmakes the selection of all operators more equal while a lower value makes a greater difference in selection probability.
c. search space navigation operators we have selected a set of six operators to investigate the performance and feasibility of this approach to adaptive learning for cit.
like any general process we choose operators that can be widely applicable and which the learner might be able to combine in productive ways.
since we must be general we cannot exploit specific problem characteristics leaving it to the learner to find ways to do this through the smart combination of the low level heuristics we define.
we have based our operator selection on the previous algorithms for cit.
none of the operators consider constraints directly but some have been used for constrained and some for unconstrained problems.
like other machine learning approaches we need a combination of smart heuristics and standard heuristics since each can act as an enabler for the other.
the first three operators are ones we deem to be entirely standard they do not require book keeping or search for particular properties before application.
the second set contains ones that we deem to be somewhat smart these are designed with domain knowledge and use information that one might expect could potentially help guide the outer search.
the operators are as follows .
single mutation std randomly select a row rand a column c change the value at r cto a random valid value.
this operator matches the neighbourhood transformation in the unconstrained simulated annealing algorithm .
.
add del std randomly delete a row rand add a new rowr0randomly generated.
while casa also includes a row replacement operator it does not just randomly generate a row.
.
multiple mutation std randomly select two rows r1andr2 and crossover each column of r1andr2with a probability of .
.
.
single mutation smart randomly select a missing tuple m which is the combination of columns c1 c n. go through each row in the covering array if there exists a duplicated tuple constructed by the same combination ofcolumns c1 c n find a row containing the duplication randomly and change the row to cover the missing tuple m. otherwise randomly select a row rand change the row to cover the missing tuple m. .
add del smart randomly delete a row r and add a new row r0to cover nmissing tuples.
we define nas the smaller value from k where kis the number of parameters and the number of missing tuples.
this is a simple form of constructing a new row used by aetg .
.
multiple mutation smart randomly select two rows r1 andr2 and compare the frequency of each value at each column fc1andfc2.
with probability of .
the column with higher frequency will be mutated to a random value.
iv.
e xperiments to assess the usefulness of using hhsa as a general approach to cit we built a version and posed the following research questions rq1 what is the quality of the test suites generated using the hyperheuristic approach?
one of the primary goals of cit is to find a smallest test suite defined by the covering array that achieves the desired strength coverage.
it is trivial to generate an arbitrarily large covering test suite simply include one test case for each interaction to be covered.
however such a na ve approach to test generation would yield exponentially many test cases.
all cit approaches therefore work around the problem of finding a minimal size covering array for testing.
the goal of cit is to try to find a smallest test suite that achieves t way interaction coverage for some chosen strength of interaction t. in our experiment we compare the size of the test suites generated by the hssa in three different ways.
we compare against the .
best known results reported in the literature produced by any approach including analysis and construction by mathematicians as is reported in .
.
best known results produced by automated tools.
.
a state of the art sa based tool that was designed to run on unconstrained problems and a state of the art sa based tool that was designed to handle constrained problems well.
rq2 how efficient is the hyperheuristic approach and what is the trade off between the quality of the results and the running time?
another important issue in cit is the time to find a test suite that is as close to the minimal one as possible given time budgeted for the search.
depending on the application one might want to sacrifice minimality for efficiency or viceversa .
this question investigates whether hhsa can generate small test suites in reasonable time.
if the answers to the first two research questions are favourable to our hyperheuristic algorithm then we will have evidence that it can be useful.
however usefulness on our set of problems wide and varied though it is may not be sufficient for our algorithm to be actually used.
we seek to further explore whether its value is merely an artefact of theoperators we chose for low level heuristics.
we also want to check whether the algorithm is really learning .
if not then it might prove to be insufficiently adaptive to changing problem characteristics.
the next two research questions investigate learning.
rq3 how efficient and effective is each search navigation operator in isolation ?
in order to collect baseline results for each of the operators that hhsa can choose we study the effects of each operator in isolation.
that is we ask how well each operator can perform on its own.
we also study the effects of making a random choice from all operators at each stage.
should it turn out that there is a single operator that performs very well across subjects then there would be no need for further study we could simply use the high performing operator in isolation.
similarly should one operator prove to perform poorly and to be expensive then we might consider removing it from further study.
rq4 do we see evidence that the hyperheuristic approach is learning?
should it turn out that hhsa performs well finding competitively sized covering arrays in reasonable time then we have evidence to suggest that the adaptive learning used by the hyperheuristic approach is able to learn which operator to deploy.
however is it really learning ?
this rq investigates in more detail the learning strategies as the algorithm searches.
we explore how the problem difficulty varies over time for each of the cit problems we study and then ask which operators are chosen at each stage of difficulty is there evidence that the algorithm is selecting different operators for different types of problems?
a. experimental setup in this section we present the experiments conducted1.
subjects studied.
there are five subject sets used in our experiments.
the details are summarised below contains pairwise way synthetic models without constraints.
these are shown in the leftmost column of table i. these models are benchmarks that have been used both to compare mathematical constructions as well as search based techniques .
we take these from table from the paper by garvin et al.
.
contains way synthetic models without constraints.
these are shown in the second column of table i. these models are benchmarks that have been used for mathematical constructions and search .
we take these from table from the paper by garvin et al.
.
contains way synthetic models with constraints see table i rightmost two columns .
these models were designed to simulate configurations with constraints in real world programs generated by cohen et al.
and adopted in follow up research by garvin et al.
.
1supplementary data models and results can be found on our website myra artifacts hhsa .table i synthetic subjects syn s yn 3and syn c2.
t he first subject set contains way unconstrained synthetic models from .
t he second subject set contains way unconstrained synthetic models from .
t he last set contains synthetic models designed to simulate real world programs .
subject set syn subject set syn subject set syn c2 subject set syn c2 subjects model subjects model subjects unconstr.
param.
constr.
param.
subjects unconstr.
param.
constr.
param.
s2 34s3 36c2 s1 286334155622203341c2 s16 s2 513822s3 46c2 s2 2863343516121933c2 s17 s2 313s3 324252c2 s3 227422931c2 s18 s2 41339235s3 56c2 s4 25134425121532c2 s19 s2 514431125s3 57c2 s5 2155374355642323641c2 s20 s2 415317229s3 66c2 s6 273436122634c2 s21 s2 6151463823s3 664222c2 s7 2293121332c2 s22 s2 716151453823s3 101624331c2 s8 2109324253632323441c2 s23 s2 4100s3 88c2 s9 2573141516123037c2 s24 s2 616s3 77c2 s10 21303645526424037c2 s25 s2 716s3 99c2 s11 2843442526422834c2 s26 s2 816s3 106c2 s12 21363443516322334c2 s27 s2 817s3 1010c2 s13 21243441526222234c2 s28 s2 1020s3 1212c2 s14 28135436321332c2 s29 s3 1414c2 s15 2503441526122032c2 s30 contains real world models from a recent benchmark created by segall et al.
shown in table ii.
there are cit problems in this subject set generated by or for ibm customers.
the problems cover a wide range of applications including telecommunications healthcare storage and banking systems.
contains real world constrained subjects shown in table ii which have been widely studied in the literature .
the tcas model was first presented by kuhn et al.
.
tcas is a traffic collision avoidance system from the siemens suite .
the rest of the models in this subject set were introduced by cohen et al.
.
spin s and spin v are two components for model simulation and model verification.
gcc is a well known compiler system from the gnu project.
apache is a web server application and bugzilla is a web based bug tracking system.
methodology all experiments but one are carried out on a desktop computer with a core .2ghz intel cpu and 8gb memory.
to understand the trade off between the quality of the results and the cost of the hyperheuristics approach we use the amazon ec2 cloud.
all experiments are repeated five times.
we report the best and the average results over five runs.
b. hhsa configuration there are four parameters that impact the computational resources used by our hyperheuristic algorithm hhsa the initial temperature the cooling rate the cooling step function and maximum number of non improvements allowed before termination is forced.
a higher initial temperature allows hhsa to spend more effort in exploring the search space.
the cooling rate and cooling step function work together to control the cooling schedule for hhsa.
to understand the trade off between the quality of the results and the efficiency of hhsa we use three different configurations hhsa l l ow hhsa m m edium and hhsa h h igh .
the hhsa l and hhsa m configurations only apply the outer binary search to guide hhsa to search for a smallest test suite while the hhsa h configuration additionally applies the greedy search conducted after the binary search.
the settings are shown in table iii.table ii real world subject sets.
real top contains 20models from .
r eal bottom contains 6models with constraints from .
subjects unconstrained parameters constrained param.
real way concurrency storage1 banking1 storage2 3461commprotocol systemmgmt healthcare1 telecom banking2 healthcare2 networkmgmt storage3 proc.comm1 services insurance 26315162111131171311storage4 healthcare3 proc.comm2 storage5 healthcare4 real way tcas spin s spin v gcc apache bugzilla table iii settings for the hhsa l hhsa m and hhsa h configurations .
config.
search initt co rate co step maxno imp hhsa l binary .
.
hhsa m binary .
.
hhsa hbinary .
.
greedy .
.
we chose these settings after some experimentation so that all can be executed in reasonable time for one or more usecases of cit.
in the low setting the time taken is low but the expected result quality is consequently equally low whereas in the higher settings we can explore if additional benefits are gained from the allocation of extra computational resources.table iv sizes and times seconds for syn top and syn bottom .
t hebest column reports the best known results from .
t hesa and casa columns report the size of the unconstrained sa and the casa algorithm .
the size for each hhsa variant reports the best result over five runs .
time is the average runtime seconds .
d iff best indicates the difference between the smallest hhsa variant and the best column .
subject best sa casahhsa l hhsa m hhsa hdiff best diff sa diff casasize time size time size time s2 s2 s2 s2 s2 s2 s2 s2 s2 s2 s2 s2 s2 s2 overall s3 s2 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 overall v. r esults in this section we provide results aimed at answering each of our research questions.
a. rq1 quality of hyperheuristic search we begin by looking at the set of unconstrained synthetic problems table iv for top and way bottom cit.
we see the best reported solutions from the literature followed by a smallest cit sample and its running time for each of the three settings of the hhsa.
the best column follows the format of table from garvin et al.
and includes results obtained by mathematical or constructive methods as well as search.
we also include the size reported in that paper both for the unconstrained sa and casa tools which is optimized for constrained problems.
running times for sa and casa tools are not reported since we did not re run them.
the size and time columns give a smallest size of the cit sample found by hhsa and the average running time in seconds over five runs.
the diff best column reports the difference between the best known results first column and hhsa s best results.
we have also reported hhsa vs. sa diff sa and hhsa vs. casa diff casa .
a negative value indicates that hhsa found a smaller sample.
the sizes of test suites found by hhsa are very close to the benchmarks for all but one of the way unconstrained synthetic models.
in fact in benchmark s2 both the medium and high settings of hhsa find a lower bound.the last subject s2 is interesting because it is pathological and has been studied extensively by mathematicians.
the model has parameters each with values.
the use of customizations for this particular problem such as symmetry has led to both constructions and post optimizations.
the discussion of this model consumes more than half a page in a recent dissertation which is credited with the bound2of .
the best simulated annealing bound of is close to the high setting of hhsa .
there is a larger gap between the results generated by hhsa and best known results on way synthetic models.
on the smaller models hhsa seems to generate sample sizes between the unconstrained sa technique and casa.
however on the larger size models hhsa does not fare as well.
we do see improvement as we increase from low to high and these are all very large search spaces we explore the costeffectiveness trade off in rq2.
we now turn to the constrained synthetic models seen in table v. in this table the column labelled best represents the best known results for casa the only tool on which these synthetic benchmarks have been reported to date .
for the constrained problems hhsa performs as well or better than the best known results except in one case despite the fact that casa is optimized for these subjects.
hhsa requires fewer rows overall than the best reported results.
2this bound was recently reduced by others to .the last comparison we make is with the real benchmarks.
table vi shows a comparison for all of our real subjects against a set of existing tools which were reported in the literature.
again we see that the hhsa performs as well or better than all of the other tools.
for the real benchmarks hhsa reduces the overall number of rows in our samples by and for the open source applications hhsa reduces the way by rows and the way by rows.
summary of rq1.
we conclude that the quality of results obtained by using hhsa is high.
while we do not produce the best results on every model we are quite competitive and for all of the real subjects we are as good as or improve upon the best known results .
table vi sizes and times seconds for real way top r eal way middle and real way bottom .
t hebestknown column shows the best results in the literature and the tools that produced the results .