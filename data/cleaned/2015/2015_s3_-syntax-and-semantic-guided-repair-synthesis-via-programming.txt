singapor e management univ ersity singapor e management univ ersity institutional k nowledge at singapor e management univ ersity institutional k nowledge at singapor e management univ ersity resear ch collection school of computing and information systems school of computing and information systems s3 syntax and semantic guided r epair synthesis via s3 syntax and semantic guided r epair synthesis via programming b y examples programming b y examples xuan bach d .
le singapor e management univ ersity dxb.le.
phdis.smu.edu.sg duc hiep chu institute of science and t echnology a ustria david l o singapor e management univ ersity davidlo smu.edu.sg clair e le goues carnegie mellon univ ersity willem visser stellenbosch univ ersity follow this and additional works at https ink.libr ary.smu.edu.sg sis r esear ch part of the softwar e engineering commons citation citation le x uan bach d .
chu duc hiep l o david le goues clair e and visser willem.
s3 syntax and semantic guided r epair synthesis via pr ogramming b y examples.
.
esec fse pr oceedings of the 11th joint meeting on e uropean softwar e engineering conf erence and a cm sigsof t symposium on foundations of softwar e engineering p aderborn germany september .
.
available at available at https ink.libr ary.smu.edu.sg sis r esear ch this conf erence pr oceeding ar ticle is br ought t o you for fr ee and open access b y the school of computing and information systems at institutional k nowledge at singapor e management univ ersity .
it has been accepted for inclusion in resear ch collection school of computing and information systems b y an authoriz ed administr ator of institutional k nowledge at singapor e management univ ersity .
for mor e information please email cher ylds smu.edu.sg .
s3 s yntax and s emantic guided repair s ynthesis via programming by examples xuan bach d. le singapore management university singapore dxb.le.
smu.edu.sgduc hiep chu institute of science and technology austria duc hiep.chu ist.ac.atdavid lo singapore management university singapore davidlo smu.edu.sg claire le goues carnegie mellon university pittsburgh usa clegoues cs.cmu.eduwillem visser stellenbosch university south africa wvisser cs.sun.ac.za abstract a notable class of techniques for automatic program repair is known assemantics based .
such techniques e.g.
angelix infer semantic specifications via symbolic execution and then use program synthesis to construct new code that satisfies those inferred specifications.
however the obtained specifications are naturally incomplete leaving the synthesis engine with a difficult task of synthesizing a general solution from a sparse space of many possible solutions that are consistent with the provided specifications but that do not necessarily generalize.
we present s3 a new repair synthesis engine that leverages programming by examples methodology to synthesize high quality bug repairs.
the novelty in s3that allows it to tackle the sparse search space to create more general repairs is three fold a systematic way to customize and constrain the syntactic search space via a domain specific language an efficient enumerationbased search strategy over the constrained search space and a number of ranking features based on measures of the syntactic and semantic distances between candidate solutions and the original buggy program.
we compare s3 s repair effectiveness with state ofthe art synthesis engines angelix enumerative and cvc4.
s3can successfully and correctly fix at least three times more bugs than the best baseline on datasets of 52bugs in small programs and bugs in real world large programs.
ccs concepts software and its engineering programming by example dynamic analysis software testing and debugging keywords program repair programming by examples inductive synthesis symbolic execution permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse september paderborn germany association for computing machinery.
acm isbn .
.
.
.
reference format xuan bach d. le duc hiep chu david lo claire le goues and willem visser.
.
s3 syntax and semantic guided repair synthesis via programming by examples.
in proceedings of 11th joint meeting of the european software engineering conference and the acm sigsoft symposium on the foundations of software engineering paderborn germany september esec fse pages.
introduction bug fixing is notoriously difficult time consuming and costly .
hence automating bug repair to reduce the onerous burden of this task would be of tremendous value.
automatic program repair has been graining ground with substantial recent work devoted to the problem inspiring hope of future practical adoption.
one notable line of work in this domain is known as semantics based program repair most recently embodied in angelix .
this class of techniques uses semantic analysis typically dynamic symbolic execution and a set of test cases to infer behavioral specifications of the buggy code and then program synthesis to construct repairs that conform to those specifications.
such approaches have recently been shown to scale to bugs in large real world software .
although scalability has been well addressed one pressing concern in program repair is patch quality sometimes quantified in terms of patch overfitting orgeneralizability .
generated repairs can sometimes overfit to the tests used for repair and fail to generalize to a different set of tests.
this may be caused by weak or incomplete tests or even simply the nature of the repair technique .
various repair approaches have been shown to suffer from overfitting including genprog rsrepair and spr .
semantics based approaches like angelix are no exception to this issue as partially shown in recent studies .
overfitting and patch quality generally remains a challenging problem in the program repair field.
one reason for patch overfitting is that the repair search space is often sparse containing many plausible solutions that can lead the buggy program to pass a given test suite but that may still be judged incorrect .
one way to tackle overfitting is thus to constrain the search space to patches that are more likely to generalize.
other strategies for increasing the quality of outputesec fse september paderborn germany xuan bach d. le duc hiep chu david lo claire le goues and willem visser patches include higher granularity mutation operators antipatterns history based patterns feedback from execution traces or document analysis .
angelix eagerly preserves the original syntactic structure of the buggy program via partialmaxsmt based constraint solving and componentbased synthesis .
however such enforcement alone may not be enough .
furthermore incorporating other strategies or criteria into a constraint based synthesis approach is non obvious since so typically requires novel and often complicated constraint encodings this problem has been pointed out by others see e.g.
chapter of or section of .
this motivates the design of a new repair synthesis technique that can consolidate various restrictions or patch generation criteria enabling an efficient search over a constrained space for potentially higher quality patches.
we present s3 syntax and semantic guided repair synthesis a new scalable repair synthesis system.
s3addresses the challenge of synthesizing generalizable patches via our novel design of three main components an underlying domain specific language dsl that can systematically customize and constrain the syntactic search space for repairs an efficient enumeration based search strategy over the restricted search space defined by the dsl to find solutions that satisfy correctness specifications e.g.
as induced by test suites and ranking functions that serve as additional criteria aside from the provided specifications to rank candidate solutions to prefer those that are more likely to generalize.
our ranking functions are guided by the intuition that a correct patch is often syntactically and semantically proximate to the original program and thus measure such syntactic and semantic distance between a candidate solution and the original buggy program.
unlike other constraint based repair synthesis techniques our framework is highly customizable by design enabling the easy inclusion of new ranking features its design is inspired by the programming byexamples pbe synthesis methodology .
given a buggy program to repair and a set of test cases passing and failing s3works in two main phases.
the first phase automatically localizes a repair to one or more target repair expressions e.g.
branch condition assignment right hand side etc.
.
s3runs dynamic symbolic execution on the test cases to collect failure free execution paths through the implicated expressions.
it then solves the collected path constraints to generate concrete expression values that will allow the tests to pass.
these specifications expressed as input and desired output examples are input to the synthesis phase.
the synthesis phase first constrains the syntactic search space of solutions via a dsl that we extend from synth lib .
our extension allows it to specify a starting sketch or an expression that gives s3clues about what possible solutions might look like.
here the sketch is the original buggy expression under repair.
next s3forms a solution search space of expressions of the same size as the sketch.
finally it ranks candidate solutions via a number of features that approximate the syntactic and semantic distance to the specified sketch.
if s3cannot find any solution of the same size as the sketch it investigates expressions that are incrementally smaller or larger than the sketch and repeats the process.
we evaluate s3by comparing its expressive power and the quality of the patches it generates to state of the art baseline techniques angelix and enumerative and cvc4 twoalternative syntax guided synthesis approaches on two datasets.
the first dataset includes 52bugs in small programs a subset of the introclass benchmark translated to java .1the introclass dataset contains only small programs but provides two highcoverage test suites for each allowing an independent assessment of repair quality.
the second dataset includes 100large real world java bugs that we collected from github.
we focus on java and build a new dataset of real world java bugs for several reasons.
first java is the most popular and widely used programming language and its influence is growing rapidly.2second a realistic real world dataset with transparent ground truth fixes submitted by developers can simplify the critical process of assessing the correctness of fixes generated by program repair tools in the absence of two independent high quality test suites.
existing benchmarks often include bug fixes with many changed lines which can include tangled changes such as new features or code refactoring even curated datasets such as defects4j contain many changes involving a large number of lines.
this complicates evaluation of generated patch correctness.
our dataset is restricted to bugs whose fixes involve fewer than five lines of code alleviating the risk of tangled code changes.
as many current state of the art repair tools target bugs that require only a small number of changed lines our dataset is sufficient for assessing current research.
we assess the quality and correctness of generated repairs in several ways.
for the introclass bugs we assess correctness on independent held out test suites those provided with the benchmark as well as additional tests we generate separate from those used to guide the repair.
we use the developer provided patches as ground truth for the 100real world bugs.
for these bugs we consider a generated patch correct if it is either syntactically identical to the developer provided patch or semantically equivalent via some basic transformations.
on both datasets s3substantially outperforms the baselines.
s3generates correct patches for of bugs from the first dataset angelix enumerative and cvc4 can generate correct patches for and bug s respectively.
on the large real world dataset s3generates correct patches for out of 100bugs while angelix enumerative and cvc4 can only generate correct patches for and bugs respectively.
in summary our novel contributions include we present s3 a scalable repair synthesis engine that is geared towards synthesizing generalizable repairs.
we propose a novel combination of syntax and semantic guided ranking features to effectively synthesize high quality repairs.
new features along these lines can be straightforwardly integrated into s3 by design.
we present a large scale empirical study on the effectiveness of different synthesis techniques in semantics based program repair context.
s3substantially outperforms the baselines in terms of generated repair quality.
we present a dataset consisting of several bugs from large realworld software with transparent ground truth which can enable confident evaluation of machine generated patch correctness.
1we use the subset of introclass to which our repair tools can apply given their applicability to strictly integer and boolean domains.
and s emantic guided repair s ynthesis via programming by examples esec fse september paderborn germany if sourceexcerpt !
null ... if excerpt .
equals line charno charno sourceexcerpt .
length if excerpt .
equals line charno charno sourceexcerpt .
length ... figure a bug in closure compiler revision 1e070472 .
the bug is at lines .
the developer fix is shown on lines it turns a to a in the second line of the if condition.
input desired m1 m2 test charno excerpt.equals line sourceexcerpt.length output a true true b true true figure input output examples for both variables and conditions extracted for the closure compiler bug described in figure .
we use m1 and m2 to refer to the conditions in columns in subsequent exposition.
the last column represents the desired output of the overall branch decision.
we release source code for s3and the aforementioned dataset along with all results in support of open science.
the rest of the paper is structured as follows.
section describes a motivating example followed by section explaining our approach.
section describes our experiments results and observations.
section presents related work section concludes.
motivating example we begin by motivating our approach and illustrating its underlying insight by way of example.
figure shows changes made to address a bug in the closure compiler at revision 1e070472 .
the bug lies in the if condition expression at lines the developer submitted fix is depicted at lines .
this bug can be repaired by simply changing charno sourceexcerpt.length tocharno sourceexcerpt.length while the rest of the condition expression remains unchanged.
table shows example input and desired output examples extracted for this bug at the buggy if condition on two failing test cases.
for each test run the input includes runtime values of variables and method calls at the buggy lines while the output is the value of the branch condition for the buggy lines that would cause the test to pass.
for example for test the input includes runtime values for method calls excerpt.equals line and the variable charno .
the desired output of the branch condition is true.
these input output examples constitute incomplete specifications for each buggy line considered in the program although they are incomplete they are scalably and automatically derivable from provided test cases.
given these specifications examples the space of possible satisfying solutions is large and contains many undesirable options such as excerpt.equals line excerpt.equals line charno both of which among others would lead to the desired outputs on the considered such solutions if returned by a repair synthesis engine create low quality overfitting repairs that lead the program to pass all provided tests but are not correct.
in fact angelix generates an overfitting repair for this bug substituting charno for the entire if condition expression on lines section provides details on our straightforward port of angelix to java .
this repair is quite different from the original expression both syntactically despite angelix s use of constraints to enforce minimal syntactic differences from an original expression and semantically.
the generated condition is indifferent to values of excerpt.equals line and sourceexcerpt.length substantially weakening the branch condition with respect to the original buggy version.
these observations inform insights that can be used to filter trivial solutions.
in this case the correct solution is syntactically and semantically close to the original buggy expression.
fusing syntactic and semantic measures of proximity can help rank the solution space to favor those that are more likely to be correct.
our approach s3 estimates these distances in several ways to constrain the syntactic solution synthesis space increasing the likelihood or producing a generalizable patch see section .
.
.
for the example in figure s3synthesizes a patch that is identical to the one submitted by the developer.
methodology s3works in two main phases.
given a buggy program and a set of test cases the first phase section .
localizes potentially buggy program locations and for each buggy location extracts input and desired output examples that describe passing behavior.
the extracted examples are input to the second phase section .
which synthesizes repairs that satisfy and also generalize beyond the provided examples.
.
automatic example extraction s3first uses fault localization to identify likely buggy expressions or statements in the buggy program.
s3runs the test cases and uses ochiai to calculate suspiciousness scores that indicate how likely a given expression or a statement is to be buggy.
s3iterates through each identified buggy location or group of locations in the case of multi location repair to extract input output examples via a selective dynamic symbolic execution .4for each buggy location s3inserts a symbolic variable to represent replace the expression at the selected location.
it then invokes test cases on the instrumented programs to collect path conditions that do not lead to runtime errors such as assertion errors array index out of bound errors etc.
solving these failure free execution paths returns concrete values of symbolic variables that then can serve as input output examples.
we implement selective symbolic execution procedure on top of symbolic pathfinder spf .
for example consider the buggy code snippet in figure .
s3 identifies that the if condition at lines may be buggy.
s3then replaces the buggy if condition with a symbolic variable making the if condition becomes if .s3runs dynamic symbolic execution on the instrumented program using the provided test cases to collect failure free execution paths runtime variable values and 4for simplicity we describe the process with respect to a single location it extends naturally by installing symbolic variables at multiple locations at once.esec fse september paderborn germany xuan bach d. le duc hiep chu david lo claire le goues and willem visser method calls involved in the buggy location.
solving the collected path conditions returns the values in the output column of figure corresponding to desired values of the symbolic variable .
although this phase shares the same spirit as the specification inference step in angelix there are key differences.
angelix infers specifications by solving models of the form pc oa oe where pcis a path condition produced by symbolic execution of a test oais the actual output and oeis the expected output that is typically manually provided by a user.5the models capture the idea that if the expected output matches the actual concrete test output the corresponding path condition is a test passing path.
solving all test passing paths returns specifications that lead all tests to pass.
this process however can be tedious and error prone since it usually requires users to instrument output variables manually.
for instance if the output is a large array of many elements users must give all expected outputs for all the elements of the array.
s3extracts examples in an automated manner by building on spf automatic junit test interpretation abilities.
for a location i s3extracts examples by solving models of the form pc no errors .
pcis the path condition vi j 1pcj.
the no errors notation means that the conditions describe paths that are guaranteed to not yield assertion errors as described above .
if the path condition pcyields an assertion error s3automatically discards that path.
in another case if an array out of bound error happens s3pops the latest pci leading to the error keeping previous ones vi j 1pcj.
this frees s3 users from manual effort while guaranteeing that the examples are still failure free.
.
repair synthesis from examples examples extracted in the previous phase are input as correctness specifications to the repair synthesizer.
the goal of the synthesizer is to inductively construct a solution that satisfies and also generalizes beyond the provided specifications.
this synthesis procedure is composed of three main parts a domain specific language dsl a search procedure and ranking features.
we begin with an overview and detail each component subsequently.
we start with a dsl extended from synth lib over the integer and boolean domains.
given a background theory tpermitted by the dsl let ube the original buggy expression a formula over the vocabulary of trepresenting the correctness specifications input output examples and la set of expressions over the vocabulary of tof the same type as u. acandidate fix is an expression e lsuch that is valid modulo t. our algorithm then systematically enumerates all candidate fix expressions considering them in ranked order.
the ranking is performed by a set of nranking functions ri i n each of which measures the distance between two expressions e1ande2of the same type.
these ranking features estimate the syntactic and semantic distance between a candidate fix and the original buggy expression.
the intuition is that expressions that are closer to the buggy program are more likely to constitute high quality repairs.
note however that the size of l the search space is often too large to be truly exhaustively enumerated.
for practical purposes wegreedily favor candidate expressions of similar size and syntax 5we refer readers to the angelix manual master doc tutorial.mdto the original buggy expression.
as described in section .
.
we systematically partition the search space enabling different heuristics to be built without difficulty.
algorithm presents pseudocode for s3.
at a high level the search procedure enumerates all expressions in the grammar at a certain expression size range line .
s3finds all candidate enumerated expressions that are consistent with the specifications line .
each candidate is assigned a ranking score by calculating the distance between it and the original buggy expression lines candidates are sorted by score line .
the process returns the solution in lwith the smallest distance if l line .
otherwise it continues until all expression size ranges have been exhausted line .
s3starts enumerating at the size of the original buggy expression line and modifies the size range accordingly up to a bound b line .
the original buggy expression and its size are made available to the synthesis procedure through our sketch extension to the synth lib syntax section .
.
.
algorithm enumeration based synthesis procedure input u original buggy expression correctness specifications g synth lib grammar extended r set of ranking features b synthesis bound function synthesis u g r b i size of u fork 0to b do a ein grammar g e of size from i ktoi k l for all e ado if is valid then e.score p ri rri e u l l e end if end for sort l by ascending order of score iflis not empty then return l.head solution found end if end for return fail end function we next explain the dsl in detail section .
.
the enumerationbased search procedure section .
.
and the ranking features that we propose for the program repair domain section .
.
.
.
.
domain specific language via synth lib .we extend synth lib to systematically constrain s3 s search space.
we choose synth lib for three reasons balanced expressivity .
synth lib is adequately expressive for various tasks in the program repair domain while still sufficiently restrictive to allow an efficient search procedure.
figure describes a simplified grammar for synth lib.
note that it allowssyntax and s emantic guided repair s ynthesis via programming by examples esec fse september paderborn germany intexpr n var intexpr binop intexpr boolexpr intexpr relop intexpr boolexpr lo op boolexpr true false var boolexpr relop lo op binop figure simplified synth lib grammar used in s3.
the definition of integer expressions intexpr including integer constants n integer variables and binary relations.
boolean expressions are defined similarly.
although simple this grammar is sufficiently expressive for repairs over integers in booleans including linear computations and logical relationships.
availability .
synth lib is not esoteric but instead broadly available to various tools for syntax guided synthesis sygus .
this allows for easy comparisons between tools and indeed we use synth lib to compare s3with two other state of the art sygus solvers enumerative and cvc4 .
we believe that an abundance of synthesis techniques will benefit the program repair domain given the rapid growth of the sygus research community along with publicly available implementations .
cost metrics.
synth lib allows for definition of cost metrics like expression size this is useful for calculating ranking features.
we further extended synth lib to allow the specification of a starting sketch which gives clues on where the enumeration procedure should start.
in our case the starting sketch is the original buggy expression capturing our idea that the correct fix is more likely to be syntactically and semantically close to the original code.
the sketch allows ranking features to measure the distance between candidate solutions and the original expression s .
we illustrate with a synth lib script for the example in figure figure shows the corresponding synth lib script.
in figure the first line sets the background theory of the language to linear integer arithmetic lia .
the function being synthesized fis of type int int bool bool keyword synth f un .
the permitted solution space for the function fis described in its body which allows expressions of type boolean.
each boolean expression can then be formed by logical relationships between any two integer or boolean expressions via relational or logical operators.
expressions can also be variables m1in this case is a boolean expression.
the allowed integer expression in the grammar is defined viaintexpr which includes integer variables such as charno andm2 and constants such as .
we next define the constraints consisting of input output examples and the starting sketch.
each constraint is defined by the keyword constraint .
in our example the first constraint says that if the value of m2is the value of m1istrue and the value of charno is the expected output of the function fover charno m2 and m1 istrue.
the second constraint can be interpreted similarly.
these constraints corresponding to the extracted input output examples described in figure .
a sketch the starting point expression is defined by the keyword sketch .
here the sketch is the original1 set logic lia synth fun f charno int m2 int m1 bool bool start bool intexpr intexpr intexpr intexpr or start start and start start m1 intexpr int charno m2 declare var charno int declare var m2 int declare var m1 bool constraint and m2 and m1 true charno f charno m2 m1 true constraint and m2 and m1 true charno f charno m2 m1 true sketch u charno int m2 int m1 bool bool and and m1 charno charno m2 check synth figure synth lib script generated by s3for the example in figure derived using the alternatives layer described in figure .
m1 stands for excerpt.equals line and m2 stands for sourceexcerpt.length .
alternatives !
basic equalities !
basic inequalities basic arithmetic basic logic variables integer constants from examples 1st layer 2nd layer 3rd layer 4th layer 5th layer 6th layer figure search space layers specifiable in the grammar.
buggy expression u. finally the keyword check synthinstructs a synthesizer to start the synthesis process.
.
.
enumeration based synthesis .s3automatically generates a synth lib script for each location under repair and then uses an enumerative search to synthesize generalizable repair expressions conforming to the generated script.
we note that multilocation repair can be achieved by generating the grammar for multiple functions simultaneously we describe the process with respect to a single function for simplicity.
we first explain how the synth lib script is generated and then the search procedure.
we divide the search space into multiple layers each of which allows different components or operators to appear in the synthlib grammar script.
if s3 s search procedure cannot find a solution at a lower layer it advances to the next.
this approach tractably constrains the synthesis search space .
figure shows the six layers.
the first layer allows alternatives of operators existing in theesec fse september paderborn germany xuan bach d. le duc hiep chu david lo claire le goues and willem visser original buggy expression.
for example a pair means that the operators in the pair are alternatives of one another.
if the search procedure cannot find any solution the grammar then cumulatively allows additional variables that do not exist in the original buggy expression denoted by the variables component in the figure .
at the second layer the grammar allows basic inequalities operators and!
in addition to operators in the original expression.
again if this search fails it cumulatively allows for additional variables .
subsequent layers can be interpreted similarly.
we note that at the last sixth layer the grammar allows all components including integer constants appearing in the input output examples.
the reason integer constants are considered last is that such constants may unduly allow trivial solutions this choice is influenced by previous studies .
the design of separate sub search spaces systematically allows us to either prioritize which space to explore first or unify the spaces freely.
we heuristically prioritize the search space by automatically analyzing the surrounding context of the original buggy statement such as the method declaration that contains the buggy statement.
particularly s3automatically looks for expressions in the surrounding context that use the same variables appearing in the buggy statement and analyzes the components used in those expressions.
this gives s3clues on which search space to start from.
if the prioritized search space does not help find solutions s3 searches in the unified search space the sixth layer .
if s3cannot find context to help prioritize the space it follows the procedure described previously starting from the first layer.
.
.
ranking features .we employ the insight that a correct repair is often syntactically and semantically close to a buggy expression statement .
we thus propose features that measure the syntactic and semantic distance between a candidate solution and the original buggy code.
the final ranking score of a candidate solution is the sum of individual feature scores.
s3allows new features to be incorporated without difficulty by contrast constraint based synthesis approaches e.g.
typically require non obvious satisfiable modulo theory smt encodings for new features .
syntactic features.
syntactic features look at differences between candidate solutions and the original buggy expression at the abstract syntax tree ast level.
we do this in three ways ast differencing .
we use gumtree to compare asts.
gumtree produces transformations between asts in the form of actions on ast nodes such as insert delete update or move.
we measure the number of actions needed to transform the original buggy ast to the candidate solution ast.
this feature can be easily calculated by directly applying gumtree on the asts produced by parsing the synth lib grammar script.
cosine similarity .
an ast can also be represented as a vector of node occurrence counts .
the occurrence of each node type e.g.
integer variables or constants or a binary operation in an ast represent a vector of the ast.
the similarity of two asts can then be represented by the cosine similarity of their representative vectors denoted as cosine score .
we then define the distance from the solution s ast to the original ast as cosine score cosine score of denotes that two vectors are identical .
a synth lib grammar explicitly enables typechecking meaning this feature is easy to calculate via an ast traversal to collect type information.
locality of variables and constants .
variables and constants are the primary ingredients of expressions.
thus in addition to capturing abstract changes on the ast we capture lowerlevel differences via the locations of variables and constants in expressions.
we compute the hamming distance between two vectors representing locations of variables and constants in each expression.6for example consider a b as the original expression a b as the first solution and b aas the second solution.
the hamming distance from the original expression for the first and second solutions are and3respectively.
although both solutions are semantically equivalent we may want to prefer the first in the interest of change minimality.
semantic features.
semantic features look at either the difference between a solution siand the original expression u or the semantic quality of siitself.
we propose three semantic features model counting .
model counting c.f.
is often used to count the number of models satisfying a particular formula.
we use this feature to measure the level of disagreement between any two boolean expressions.
that is we say that a solution siand the original expression udisagree with each other if the formula si u si u is valid meaning that si anducannot be both valid at the same time.
we then define the level of disagreement between sianduby the number of models that satisfy the formula which accounts for the semantic distance between them.
as a simple example assume that we have a 10as the original expression u a 13as a solution s1 and a 15as a solution s2.
the semantic distance via model counting between these solutions and uis and respectively.
this simple example generalizes naturally to the typical off byone bug in figure .
output coverage .
this feature looks at how much a solution covers the set of outputs in the set of input output examples.
for instance assume input output examples constraints for two tests t1andt2 on an input i and an output o t1 i o t2 i o i o a trivial solution for this example is simply the constant another solution is the expression i. the first solution overfits to only one output despite the presence of three examples that have two distinct outputs.
the second solution covers all output scenarios in the provided examples making it intuitively less overfitting as compared to the first.
a solution sireceives a ocov iscore of nc no where nois the number of output scenarios in the provided input output examples and ncis the number of output scenarios that the solution sicovers.
the feature score of a solution siis defined as ocov i. the higher ocov i the better the solution si.
anti patterns .
this feature aims to heuristically prevent synthesis from generating trivial solutions.
particularly these patterns are anti duplicate and constant expressions e.g.
a a etc.
expressions containing these patterns typically evaluate to a constant true orfalse and are thus likely to overfit.
and s emantic guided repair s ynthesis via programming by examples esec fse september paderborn germany we filter out these expressions during the synthesis process.
again this can be easily done by traversing the ast produced by the synth lib grammar.
the utility of anti patterns has been explored for search based program repair but not for semantics based counterparts partially because it is difficult to integrate additional such measures directly in the constraintbased synthesis approach .
evaluation this section describes our comparison between s3and state ofthe art semantics based program repair techniques.
we describe experimental setup and research questions in section .
answer those research questions in sections .
.
and present discussion limitations and threats in section .
.
.
experimental setup we ran all experiments on a intel corei5 machine with cores and 8gb of ram.
baseline approaches and settings.
we compare s3to angelix enumerative and cvc4 .
angelix offers its specification inference engine and synthesis engine in separate code packages.
although the specification inference engines behind angelix and s3work on c and java programs respectively angelix s synthesis engine takes as input example based specifications like the synthesis engine of s3.
thus to enable comparisons between s3and angelix we instruct s3 s inference engine to generate the same type of specifications that angelix s synthesis engine uses and instruct both s3 s and angelix s synthesis engines to synthesize the repair based on the same provided specifications.
enumerative and cvc4 are state of the art syntax guided synthesis sygus engines which both take input in the form of synth lib scripts likes3.7this allows straightforward comparison between the tools.
forsingle line patches we run a repair synthesis tool on each buggy location of each program in parallel and stop once a repair is found.
the timeout for synthesis task is set to three minutes each.
for multi line patches we implement the approach described bellow.
angelix tackles patches involving multiple lines by grouping multiple buggy locations and synthesizing repairs for several locations at once.
angelix clusters buggy locations into groups of a user specified size by either locality or suspiciousness score produced by fault localization.
we reimplemented this feature following angelix s source code.8angelix s synthesis engine are run on these specifications.
we implemented our own strategy to tackle multi line patches fors3 enumerative and cvc4 .
each buggy location is repaired separately after which patches for certain locations are grouped.
given a test suite t and patches pi generated by a repair synthesis tool for location i. assuming each patch p pileads the program to pass a set of tests ti t we iterate through all patches and combine those that have ti t. the intuition is that combining 7we refer interested readers to and for a full comparison between sygus engines the implementation for this feature in angelix s source is approximately lines of python code.table top largest programs that s3can correctly patch.
math refers to the apache commons math library closure orientdb math molgenis heritrix kloc these patches may render the whole test suite tto pass which we then verify dynamically.
datasets.
we consider two datasets of buggy programs small programs associated with high coverage test suites.
we experiment with 52java bugs in the smallest subject programs of the introclass program repair benchmark translated to java .
the programs are student written homework assignment from an introductory programming class the goal of the programs is to find the smallest number between four integer numbers.
although the programs are small they feature possibly complicated fixes involving changes in multiple if then else structures.
we include only syntactically distinct programs.
we focus on smallest because it only includes integerand boolean related fixes.
neither angelix nor our framework can yet handle e.g.
floating point numbers or strings primarily due to the limited capability of the constraint solving techniques used in symbolic execution.
a key benefit of focusing on these small programs is that the problems in introclass are associated with two independent high quality test suites.
we use one test suite to guide the search for a repair and the other to assess produced patch quality.
we further augment the dataset by using symbolic pathfinder to generate additional tests.
we do this by manually adding correctness specifications such as logical assertions on the buggy programs and use spf to generate test inputs that expose bugs e.g.
assertion violations.
this results in additional tests.
large real world programs.
our second dataset consists of 100large real world java bugs from 62subject programs featuring ground truth bug fixes submitted by developers.
our dataset only includes bugs with patches that change fewer than five lines of code.
this simplifies quality and correctness assessment of machine generated patches which is especially important because real world test cases can be incomplete or weak specifications of desired behavior .
we build our dataset based on a previously proposed bug fix history dataset which originally consists of around likely bug fixing commits of fewer than five lines of code collected from github.
to further ensure that the collected commits are actually bug fixes we randomly sampled commits and manually checked them to ensure that the commits compile and that the program test cases expose bugs pre commit as compared to post commit test behavior .
we treat tests that fail in the before patched version but pass in the patched version as the failing tests addressed by the bug fixing commit.
since this process is time consuming we stopped once we found bugs from 62programs.
table shows the top five largest programs for which s3can correctly patch bugs.
kloc depicts the number of lines of java code in each project.esec fse september paderborn germany xuan bach d. le duc hiep chu david lo claire le goues and willem visser table repair tool performance on introclass bugs.
angelix s3 enum cvc4 produced pass all22 4held out tests overfit if a b a c a d by s3 a b a c a d by angelix a c a d system.out.println a else if b a b c b d by s3 b a b c b d by angelix no change system.out.println b else if c a c b c d by s3 c a c b c d by angelix c.value d.value system.out.println c else system.out.println d figure a bug in a smallest program correctly fixed exclusively by s3.
we show the patches from s3and angelix.
research questions and metrics.
our core metric is the number of buggy programs that a tool correctly patches.
fully assessing repair quality and correctness is an open problem in program repair research and thus we approximate in several ways.
for the introclass bugs we designate a patch correct if it passes all held out test cases described above.
we divide the spf generated tests randomly using half to augment the tests used to repair and the other half to augment the held out tests.
for the real world bugs a patch is deemed correct if it is syntactically identical to the developer produced patch.
we also manually inspect all the results produced by all repair tools as a sanity check.
in our inspection if it is possible for a machine generated patch to be converted into the corresponding developer s patch via basic transformations we also consider it as correct.
these patches are the minority in our evaluation we separate these in our results and present the patches in prose.
we report overfitting rate or the percentage of produced patches that are incorrect for each tool lower is better and expressive power in terms of the unique buggy programs each tool correctly patches.
our two research questions are then divided by dataset rq1.
how does each tool perform on the dataset of small programs associated with high coverage test cases in terms of correct patches generated overfitting rate and expressive power?
rq2.
how does each tool perform on the dataset of real world programs in terms of correct patches generated overfitting rate and expressive power?
.
performance on introclass table shows the results of each repair synthesis tool on 52bugs from the introclass dataset.
the produced column shows the total number of patches that each tool generated that pass the provided test cases while the pass held out tests shows the number of produced patches that generalize to pass all held out evaluationtable repair tool performance on real world bugs.
s3 s3syn s3sem enum cvc4 angelix produced syntax match manual overfit syn overfit both tests and that we thus consider correct .
overfit shows the percentage of produced patches that do not generalize to the heldout tests lower is better .
note that angelix s multi line patch facility is driven by two parameters number of buggy locations in a group and the criterion used to group them either by locality or suspiciousness score .
these results are based on score based grouping which uniformly outperformed the alternative in our experiments results not shown .
when the group size is set to we allow angelix to try our own multi line patch strategy in case single line repair is unsuccessful.
table shows that s3substantially outperforms the baselines generating significantly more patches allof which generalize to the held out test cases.
the degree to which angelix patches overfit varied by lines considered ranging from a minimum of to a maximum of .
enumerative and cvc4 perform comparably with a very high percentage of overfitting patches.
s3generates correct patches for all the bugs for which angelix enumerative and cvc4 can fix.
s3also generated almost exclusively multi line patches with one exception .
we speculate that the underlying synthesis techniques are the primary source of the baselines weak performance.
enumerative enumerates expressions in increasing size while cvc4 uses unsatisfiability unsat cores to synthesize solutions neither rank candidate solutions but instead conservatively return the first satisfying solution identified.
angelix encodes a simple patch minimality preference criteria in constraints suitable for partialmax smt.
however in these experiments we observed that angelix frequently generated patches that are quite different from the original buggy expressions typically much smaller in size .
these results and observations suggest that s3 s combination of a customizable search space an appropriately managed expression size wise search strategy and numerous ranking functions all contribute to its successful generation of generalizable patches.
figure shows an example of a bug that s3patches correctly but to which the baselines overfit.
for brevity we only show patches from s3and angelix.
this code snippet requires a multi line patch to multiple if conditions.
we show the replacement if expressions from s3and angelix in the code comments.
from the first ifcondition the angelix fix is already incorrect as it fails to capture the necessary relationship between variables aandb.
the condition from s3shares the structure of the original buggy expression capturing the relationships between all variables.
producing this patch is likely assisted by s3 s expression size wise enumerative search which starts from the size of the original buggy expressions.
.
performance on real world programs table shows the results of applying each considered repair tool on100real world bugs from our second dataset.
the first rowsyntax and s emantic guided repair s ynthesis via programming by examples esec fse september paderborn germany ...first bug... if character.isdigit next buggy if condition if character.isdigit next next .
fix by developer if next character.isdigit next fix by s3 ...second bug... return csvbuffer.getmark bufferindex fix buggy expression return bufferindex csvbuffer.getmark fix by developer return csvbuffer.getmark bufferindex fix by s3 ...third bug... while newlength offset fix buggy expression while newlength offset fix by developer while offset newlength fix by s3 ...fourth bug... if this.runningstate !
state running this.runningstate !
state suspended throw new illegalstateexception ... stoptime system.currenttimemillis if this.runningstate state running fix by developer if this.runningstate !
state suspended fix by s3 stoptime system.currenttimemillis figure bugs for which s3generates patches that are not syntactically identical but semantically equivalent to the developer fixes.
shows the total number of bugs for which each tool generated a patch.
because we lack second independent test suites for these programs we use a direct syntactic match to the developer patch to define correctness row syntax match .
we additionally found via manual inspection a small number of additional patches that appear semantically identical to the developer patches we describe these patches for s3below.
the last two rows show the percentage of produced patches that fail to generalize to capture the developerwritten patch as judged via strict syntactic match overfit syn or via both syntactic match and manual inspection overfit both .
s3again substantially outperforms the baseline techniques generating correct patches for many more programs.
only of the s3patches fail to strictly syntactically match the developer fixes.
although manual author inspection is an inadequate mechanism for rigorously assessing patch quality simple syntactic transformation rules can convert these patches to their developer equivalents we separate these out in figure .
in terms of overfitting only of s3 s patches fail to generalize when judged by perfect syntactic fidelity when manual inspection is considered none of the patches overfit.
for angelix enumerative and cvc4 and of the produced patches overfit respectively.
in these experiments we also evaluate the relative contribution ofs3 s syntactic versus semantic feature sets for ranking s3syn ands3semin the table respectively.
when only either syntactic or semantic features are used to rank the solution space the performances of s3varies.
s3synands3semgenerate fewer correct patches with slightly higher overfitting rates suggesting that both kinds of features are beneficial for s3 s performance.
all programs that are correctly fixed by other tools are also fixed by s3.
we note that the number of correctly fixed bugs by the three baselines can be increased to bugs if we combine allbugs correctly repaired by them.
this combination is however still inferior to s3 s performance.
the first bug in figure is an example of a bug that s3fixes correctly while the others do not.
enumerative and cvc4 generate the same fix with each other that does not ultimately pass all tests both synthesize to replace the if condition angelix generates no fix for this bug.
s3 s fix is not syntactically identical but it is semantically equivalent to the developer s fix.
this can be demonstrating by transforming s3 s patch using basic transformation rules e.g.
swapping both left and right hand sides of the operator and converting the integer 46to the character .
.
the fix generated by enumerative and cvc4 on the other hand cannot be transformed to the developer s fix.
we note that the incorrect fix generated by enumerative and cvc4 is largely destructive since it converts the branch condition to always evaluate to true .
this kind of destructive fix can be prevented in s3via the anti patterns feature as described in section .
.
.
in general s3generates more correct patches than the other approaches judged via both syntactic fidelity to the developer fix and via fidelity with respect to basic syntactic transformations.
.
discussion limitations and threats discussion and limitations.
semantics based repair in general exclusively modifies expressions in conditions or on the right hand side of assignments.
additionally such techniques can only synthesize or reason about replacement code including boolean or integer types.
our experience suggests that these limitations are the primary reasons for unrepaired bugs in our experiments.
some bugs require large changes to semantic or control flow structure e.g.
a change from if ... a if ... b toif ... a else if ... b the insertion of new statements or manipulation of variables of types that existing constraint solving technology cannot handle.
resolving these challenges remains future work and can progress apace with progress in the synthesis domain.
however it is noteworthy that semantics based repair techniques are reasonably expressive despite these limitations.
threats to validity.
our results may not generalize to other subject programs beyond those upon which our experiments were conducted.
we mitigate this risk by evaluating our solution on real bugs from many real world programs.
the size of this bug set is commensurate with those used to evaluate prior automated repair techniques e.g.
.
another threat to the validity of our results is our reimplementation of the multi line patch feature of angelix section .
.
however we note this feature is simple and only takes around lines of python code and that we used the existing released implementation as reference.
finally we seek to assess the quality of the produced patches in terms of the degree to which they overfit to the provided test cases or by contrast generalize beyond them .
patch quality especially in an automated repair context is an unsolved research problem.
we assess patch quality using several objective and established measures.
we use independent test suites when possible to quantify overfitting an established methodology .
for real world programs we use syntactic fidelity to the developer patches as the gold standard for correctness.
bugs may often be patched multiple ways and thus this standard is likely stricter than correctnessesec fse september paderborn germany xuan bach d. le duc hiep chu david lo claire le goues and willem visser truly requires.
we also manually inspect all produced patches a process subject to bias but important to safeguard against mistakes.
we present a number of these patches in this paper and publicly release all the results experimental data and our code for open investigations.
related work program repair.
general program repair techniques can typically be divided into two main branches heuristic and semanticsbased repair.
heuristics based repair includes techniques like genprog which heuristically searches for repairs via genetic programming algorithm.
rsrepair and ae replace the search strategy in genprog by random and adaptive search strategies respectively.
these techniques despite scaling well have been shown to produce patches that overfit to the provided test suites .
par generates repairs based on repair templates manually learned from human written patches.
more recently prophet and hdrepair also use heuristic search to generate patches augmented with mined repair models from historical data to rank patches preferring those that match frequent human fix patterns.
tan et al.
propose anti patterns to prevent heuristic tools from generating trivial repairs .
acs targets if condition defects by using fix templates rules to generate patches.
it then leverages document analysis such as on javadoc comments as an additional criterion to rank patches.
semantics based repair techniques such as semfix directfix and angelix use symbolic execution and program synthesis to synthesize repairs.
such techniques however either do not have a notion of patch ranking or only include simple ranking criteria such as syntactic structural differences.
as such semantics based repair approaches can also produce overfitting patches motivating stronger techniques that can generalize beyond weak specifications inferred from tests.
other semantics based techniques include spr which targets defects in if conditions spr can also produce trivial or functionality deleting repairs .
nopol works in a similar spirit to spr and semfix targeting if condition defects using smt based synthesis.
qlose uses program execution traces as an additional criteria to rank patches and encode program repair problem into a program synthesis tool namely sketch .
searchrepair lies between heuristicand semantic based repair using semantic search as its underlying mutation approach to produce higher granularity high quality patches.
however it does not yet scale as well as other approaches.
our technique s3 belongs to the semantics based family and thus is different in kind from the heuristic techniques.
s3can target more bug types than spr nopol and acs which focus on if condition based defects including incorrect assignments ifand loop conditions and expressions in return statements.
unlike acs s3does not use explicit fix templates or document analysis to generate or rank patches integrating such approaches in ranking especially is a possible avenue for future work.
s3is more scalable compared to various semantics based counterparts such as semfix directfix qlose and searchrepair.
s3also allows the inclusion of a variety of ranking features beyond syntactic structural differences considered in prior work.
indeed s3 s ability to incorporate ranking criteria is an important novelty overcoming a known challenge in smt based synthesis .
program synthesis .
generally techniques in this area include inductive example based synthesis and deductive logical reasoning based synthesis.
s3belongs to the inductive family.
flashfill synthesizes programs that work on string domain.
flashextract synthesize programs that automate the data extraction process.
singh et al.
use programming by examples pbe to automatically transform spreadsheet data types .
flashnormalize automatically normalizes texts using pbe.
refazer uses a pbe based approach to automatically learn program transformations.
nofaq synthesizes command repairs from input output examples .
programming via sketching uses a sketch as partial specifications and search for an implementation that satisfies the specification we use a similar idea in the dsl that uses a starting sketch to help rank candidate solutions.
conclusions we proposed s3 a new repair synthesis system that is able to generate high quality general patches for bugs in real programs.
s3consists of two main phases which serve to automatically extract examples that serve as a specification of correct behavior using dynamic symbolic execution on provided test cases and use a synthesis procedure inspired by the programming byexamples methodology to synthesize general patches.
the efficiency and effectiveness of the synthesis procedure is enabled by our novel designs of three main parts including a domain specific language which we extend from synth lib an expressionsize wise enumerative search and syntax and semantic guided ranking features that help rank the highest quality solutions highest in the solution space.
our results showed that s3generates many more high quality bug fixes than even the best performing baseline from prior work.
beyond these results our approach opens a number of opportunities for future repair synthesis techniques.
the specifications in the form of input output examples can be strengthened with specifications inferred by specification mining and other inference techniques possibly enabling integration of inductive and deductive synthesis for a more expressive overall system.
our framework s flexible design allows more features to be investigated and easily integrated into our ranking technique such as for example frequent fix patterns mined from human written patches .
our dataset can also be extended and used to evaluate many more repair systems.
we plan to extend the synth lib grammar to represent more tasks in the program repair domain e.g.
nonlinear computations on the integer domain.
finally machine learning might be useful in automatically classifying bug types to more effectively deal with different kinds of defects automatically.