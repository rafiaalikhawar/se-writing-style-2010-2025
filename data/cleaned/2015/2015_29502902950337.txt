titanium efficient analysis of evolving alloy specifications hamid bagheri department of computer science engineering university of nebraska lincoln bagheri unl.edusam malek department of informatics university of california irvine malek uci.edu abstract the alloy speci cation language and the corresponding alloy analyzer have received much attention in the last two decades with applications in many areas of software engineering.
increasingly formal analyses enabled by alloy are desired for use in an on line mode where the speci cations are automatically kept in sync with the running possibly changing software system.
however given alloy analyzer s reliance on computationally expensive sat solvers an important challenge is the time it takes for such analyses to execute at runtime.
the fact that in an on line mode the analyses are often repeated on slightly revised versions of a given speci cation presents us with an opportunity to tackle this challenge.
we present titanium an extension of alloy for formal analysis of evolving speci cations.
by leveraging the results from previous analyses titanium narrows the state space of the revised speci cation thereby greatly reducing the required computational e ort.
we describe the semantic basis of titanium in terms of models speci ed in relational logic.
we show how the approach can be realized atop an existing relational logic model nder.
our experimental results show titanium achieves a signi cant speed up over alloy analyzer when applied to the analysis of evolving speci cations.
ccs concepts software and its engineering !formal methods software veri cation software evolution keywords formal veri cation evolving software relational logic partial models.
.
introduction formal speci cation languages and the corresponding analysis environments have long been applied to a variety of software engineering problems.
most notably the alloy language and the corresponding analysis engine alloy ana lyzer have received a lot of attention in the software engineering community.
alloy provides a lightweight object modeling notation that is especially suitable for modeling structural properties of a software system.
it has been used to solve a variety of software engineering problems including software design code analysis and test case generation .
given a model of a software system in alloy the alloy analyzer uses a sat solver to automatically analyze the software system s properties speci ed in the form of predicates and formulas.
formal speci cations have much in common with the complex software systems they represent namely they are hard to develop and tend to evolve.
construction of formal speci cations is a non trivial task.
just like most complex software systems formal speci cations are developed iteratively where in each iteration some elements of the model are modi ed removed and new ones are added until the desired delity is achieved.
in each iteration the speci cation is analyzed to help the developer assess its utility x aws and plan the next set of changes.
in addition as software systems tend to evolve over time formal speci cations representing them need to evolve as well.
the evolution of speci cations however is not limited to those that are constructed manually.
in fact automated means of generating formal speci cations from software artifacts often through some form of program analysis have made it signi cantly easier to maintain an up to date speci cation for a changing software system.
such techniques have made it possible to verify an evolving speci cation of a software system after the initial deployment of software possibly at runtime and as it changes.
in such settings the evolving speci cation is continuously analyzed in real time to assess the properties e.g.
security of the corresponding software.
in spite of its strengths alloy analyzer s reliance on computationally heavy sat solvers means that it can take a signi cant amount of time to verify the properties of software.
the ability to analyze the speci cations e ciently is quite important especially when they are developed through an iterative process.
the development of a complex speci cation often involves repeated runs of the analyzer for debugging and assessment of its semantics.
in an online mode where the speci cations are kept in sync with the changing software and the analysis is performed at runtime the time it takes to verify the properties of software is of even greater importance.
there is thus a need for mechanisms that facilitate e cient analysis of evolving speci cations in response to incremental changes.
an opportunity to reduce the analysis time is presented by the fact that in the aforementioned scenarios speci cations are unlikely to change permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
fse november seattle wa usa c acm.
... .
completely from one analysis to the next.
it is therefore desirable to be able to leverage the results of analysis performed on a speci cation to optimize any subsequent analyses on its revisions.
however alloy analyzer as well as its other variants e.g.
aluminum do not provide any mechanism to leverage the results of analysis across evolving speci cations even if they are substantially overlapping.
in this paper we introduce titanium an extension of alloy analyzer for e cient analysis of evolving alloy specications.
the e ciency gain is due to a new method of determining the analysis bounds.
in the conventional alloy analyzer the user de ned bounds used to run the analysis determine the scope of search for models within a nite domain.
the user de ned bound however is typically not the tightest bound for a problem.
the tightest bound for a problem is e ectively determined when all model instances are found.
while this observation by itself is of little value when analyzing an alloy speci cation from scratch it is quite valuable when the analysis is targeted at evolving substantially overlapping speci cations and forms the intuition behind our research.
titanium rst analyzes the structure of a revised specication and identi es a set of relational variables that are shared with the originating speci cation.
it then uses the instances produced for the original speci cation to potentially calculate tighter bounds for such relational variables in the revised speci cation.
by tightening the bounds titanium reduces the search space enabling the sat solver to nd the model instances at a fraction of time needed for the original bounds.
the experimental results show that with the proposed optimization titanium achieves signi cant gains in speed compared to the conventional alloy analyzer.
this paper makes the following contributions e cient analysis of evolving speci cations.
we propose a novel approach for analyzing evolving alloy speci cations that reduces the state space by adjusting the analysis bounds thereby achieving signi cant speed ups.
formal description.
we formally describe the semantic basis of this approach in terms of models speci ed in relational logic and demonstrate how it can be realized atop an existing relational logic model nder without compromising soundness and completeness.
implementation.
we have realized the analysis technique by modifying the alloy analyzer environment resulting in a new version of the tool which we have made publicly available .
experiments.
we present empirical evidence of the e ciency gains using both alloy speci cations found in the prior work and those synthesized in a systematic fashion.
the remainder of this paper is organized as follows.
section uses an illustrative example to describe the intuition behind our technique as well as the necessary background.
section provides a formal description of our approach.
section presents our experimental results obtained in our analysis of both real and synthesized speci cations.
section reviews the related research.
finally section concludes the paper with a summary of our contributions and the avenues of future research.
a a simple model of typing in java 2abstract sig typef subtypes settype 4g 5sigclass interface extends typefg 6one sig object extends classfg 7siginstancef type class 9g 10fact typehierarchyf object root of subtype hierarchy type inobject.
subtypes no self subtyping not typejtint.
subtypes subtype at most one class allt typejlone t. subtypes class 17g 18pred showf some class object some interface 21g 22runshow for2 but type b an updated version of the model 2sigvariablef holds lone instance type type 5g 6fact typesoundnessf allv variablejv.holds.type inv.type 8g listing alloy speci cation examples a a speci cation describing java typing and b new constructs added to the revised speci cation.
.
illustrative example this section motivates our research and illustrates our optimization technique using a simple example.
we describe the example using the alloy and kodkod notations .
section presents a more detailed discussion of our approach.
consider the alloy speci cation for a simpli ed model of typing in java shown in listing .
this speci cation is adopted from and distributed with the alloy analyzer.
each alloy speci cation consists of data types formulas that de ne constraints over data types and commands to run the analyzer.
essential data types are speci ed in alloy by their type signatures sig and the relationships between them are captured by the the declarations of elds within the de nition of each signature.
the running example de nes signatures lines types are partitioned into class and interface types with object introduced as a singleton extending class.
each type may have a set of subtypes and each instance has a speci c class type.
facts fact are formulas that take no arguments and dene constraints that every instance of a speci cation must satisfy thus restricting the instance space of the speci cation.
the formulas can be further structured using predicates pred and functions fun which are parameterized formulas that can be invoked.
the typehierarchy fact paragraph listing lines states that object is the root 281ft1 t2 o1 i1 i g 3object ffo1g fo1gg 4c l a s s ffg fft1g ft2ggg 5i n t e r f a c e ffg fft1g ft2ggg 6i n s t a n c e ffg ffi 1g fi 2ggg 7s u b t y p e s ffg ffo1 o1 g fo1 t1 g fo1 t2 g ft1 o1 g ft1 t1 g ft1 t2 g ft2 o1 g ft2 t1 g ft2 t2 ggg 8type ffg ffi1 o1 g fi1 t1 g fi1 t2 g fi2 o1 g fi2 t1 g fi2 t2 ggg a l l t object c l a s s i n t e r f a c e j!
t i n t .
s u b t y p e s .
.
.
the upper bound for the subtypes relation in the updated speci cation is tightened by titanium 13s u b t y p e s ffg ffo1 t1 g fo1 t2 g ft1 t2 g ft2 t1 ggg listing kodkod representation of the alloy module of listing .
of the subtype hierarchy that no type is a subtype of itself neither directly nor indirectly and that each type may be a subtype of at most one class.
analysis of speci cations written in alloy is completely automated but bounded up to user speci ed scopes on the size of data types.
in particular to make the state space nite certain scopes need to be speci ed that limit the number of instances of each type signature.
the runspeci cation lines then asks for model instances that contain at least one interface and one class distinct from object and speci es a scope that bounds the search for model instances with at most two elements for each top level signature except for type bounded to three elements.
in order to analyze such a relational speci cation bounded by the speci ed scope both alloy analyzer and titanium then translate it into a corresponding nite relational model in a language called kodkod .
listing partially shows a kodkod translation of listing a .
a model in kodkod s relational logic is a triple consisting of a universe of elements also called atoms a set of relation declarations including their lower and upper bounds speci ed over the model s universe and a relational formula where the declared relations appear as free variables .
the rst line of listing declares a universe of ve uninterpreted atoms.1in this section we assume an interpretation of atoms where the rst two t1and t2 represent type elements the next one o1 an object element and the last two i1andi2 instance elements.
lines declare relational variables.
similar to alloy formulas in kodkod are constraints de ned over relational variables.
while in alloy these relational variables are separated into signatures that represent unary relations establishing a type system and elds that represent non unary relations in kodkod all relations are untyped with no difference between unary and non unary relational variables.
kodkod further allows specifying a scope over each relational variable from both above and below by two relational constants .
in principle a relational constant is a prespeci ed set of tuples drawn from a universe of atoms.
these two sets are called upper and lower bounds respectively.
every relation in a model instance must contain all tuples in the lower bound and no tuple that is not in the upper bound.
that is the upper bound represents the whole set of tuples that a relational variable may contain and a lower bound a partial solution for a given model.
1abbreviated atom names are chosen for readability and do not indicate type as in kodkod all relations are untyped.
model instance object ffo1gg c l a s s fft1gg i n t e r f a c e f ft2gg i n s t a n c e ffgg s u b t y p e s ffo1 t2 g ft2 t1 gg type ffgg model instance object ffo1gg c l a s s fft1gg i n t e r f a c e f ft2gg i n s t a n c e ffi 1g fi 2gg s u b t y p e s fft2 t1 g fo1 t1 gg type ffi1 t1 g fi2 t1 gg listing two arbitrarily selected instances for the speci cation of listing a .
consider the object declaration line its upper and lower bounds both contain just one atom o1 as it is de ned as a singleton set in listing .
the upper bound for the variable subtypes type type line is a product of the upper bound set for its corresponding domain and codomain relations taking every combination of an element from both and concatenating them.
the kodkod s nite model nder then explores within such upper and lower bounds de ned for each relational variable to nd instances of a formula which are essentially bindings of the formula s relational variables to relational constants in a way that makes the formula true.
listing shows two di erent instances for the speci cation of listing a .
a model instance can essentially be viewed as an exact bound where the upper and lower bounds are equal.
after analyzing the speci cation both alloy analyzer and titanium produce the same instance set comprising models including symmetries through enumerating all valid instances in relatively the same amount of time i.e.
and ms respectively.
however if the speci cation were to change titanium would leverage the instances produced for the original speci cation to potentially set a tighter bound for the shared relational variables which in turn reduces the size of the state space and improves the analysis time.
figure shows a simpli ed schematic view of the titanium approach using an example consisting of relational variables.
as shown in figure a the user de ned bounds scope the state space in the analysis of original speci cation.
a b c figure simpli ed schematic view of the titanium approach where the dimensions represent relational variables in this case ve hypothetical relational variables r1 r2 r3 r4 and r5 a user de ned bounds for the original speci cation b instance set for the original speci cation and c tightened bounds for the relations that remain una ected in the revised speci cation i.e.
r1 r2 and r3.
each relational variable can be assigned a value within the user de ned bounds.
a value assignment to all relational variables in such a way that do not violate constraints derived from the speci cation represents a satisfying model instance and depicted as a pentagon in figure 1b.
the key observation is that once the satisfying model instances are found we are able to tighten the bounds for a given speci cation such that the same speci cation or one that is substantially the same can be solved signi cantly faster.
figure c shows a situation in which the revised speci cation does not a ect r1 r2 and r3 and thus titanium is able to set tighter bounds than those speci ed by the user for those relations.
of course changed relations and those newly added or a ected by changed relations r4 and r5 in the case of this example would maintain the user de ned bounds for the analysis.
consider listing b for example where a new signature variable is added which may hold an instance and has a declared type.
the additional fact paragraph then states that each instance held by a variable should have types that are subtypes of the variable s declared type.
given the updated speci cation this time titanium leverages the results of the previous run to set a tighter bound for relational variables that have not been changed and have no dependency on the other changed variables.
in this particular example the upper bound for the subtypes relation in the updated model is tightened by titanium listing lines .
out of possible combination of type type elements just pairs are valid as the object element o1 is the root in the subtype hierarchy line and it cannot be a subtype for the other type elements t1andt2 .
this can be easily calculated by taking the union of satisfying model instances from the previous run.
the exploration space thus would be reduced.
as a result titanium is faster in nding a model instance taking ms for it compared to ms that it takes for alloy analyzer to produce the rst model instance.
the time required to compute the whole instance set would also improve from ms to ms in this simple example.
.
approach editing an alloy speci cation produces a new nite re lational speci cation i.e.
a kodkod problem with nitely many distinct model instances.
in this section we show how solutions for the original speci cation can potentially be used to narrow the exploration space of the revised speci cation and in particular whether they constitute a partial solution i.e.
a lower bound and or a partial upper bound for variables in the new speci cation.
our algorithm is described in two steps.
first we assume that the set of relations for the two models are equal.
we then discuss the general algorithm where the universe of discourse including relations may change.
.
basic reasoning de nition instance set .let i be a model instance satisfying the model speci cation s ij s. we calli s an instance set for a model speci cation s where each model instance i2i s satis es the model speci cation s i s fiji2i s ij sg de nition model specialization .letsands0be model speci cations de ned over the same set of relational variables.
we saysis a specialization of s0 s s0 if and only if each model in the instance set of sis also a model instance fors0 i s i s0 .
four di erent scenarios are possible depending on the model specialization relation between instance sets of the two speci cations superset s s0 where the instance set of the revised speci cation includes the original speci cation s instance set.i s thus constitutes the lower bound for relations ins0 as each model instance for sis also a valid instance for s0.
they essentially represent a priori known part i.e.
a partial instance for the changed model speci cation s0 reducing the scope of the sat problem to be solved to nd potentially new instances and thereby improving performance of the analysis.
subset s0 s where the instances of the revised speci cation are contained in the original speci cation s instance set.
i s thus constitutes the upper bound for relations in s0 as each model instance for 30s0is among model instances already found by solving s relieving the need to be rediscovered.
equivalent s s0 s0 s where a set of model instances fors0is equivalent to that of the model s ori s i s0 .
arbitrary no specialization relation exists thus no e ciency gains are possible for the analysis of speci cations0.
note that when the user speci ed scope has been increased in the analysis of the revised speci cation titanium is still able to adjust the lower bound but not the upper bound.
we can then reduce the problem of model specialization to the following propositional formula where p s denotes the propositional formula for a model s p s p s0 p s p s0 intuitively it states that all satisfying solutions to p s are solutions top s0 or more formally the set of model instances forp s is a subset of the instance set of p s0 i p s i p s0 if and only if p s implies p s0 .
note that nite relational models can be represented as propositional models using standard techniques .
indeed the alloy analyzer relies on kodkod that translates speci cations in alloy s relational logic into propositional formulas which then can be solved by o the shelf sat solvers.
speci cally a relational model s in kodkod translates into a formula p s in propositional logic.
there is a one to one correspondence between a relational model s and its counterpart propositional model p s notwithstanding the peripheral variables introduced as a byproduct of the translation process.
the relationship between a model speci cation and its correspondence model instances de ned above for propositional models are thus preserved for nite relational models under this mapping.
for each pair of speci cations sand its revisions0 we can check whether any model specialization holds between them with a sat solver by determining whether the formula p s p s0 is a tautology i.e.
whether its negation is not satis able .
however solving the negation formula p s p s0 can be expensive for large speci cations of substantial systems.
to alleviate this problem and render it more cost e ective we adjusted the formula by leveraging the fact that the two speci cations have many clauses in common as one is derived from the other.
speci cally inspired by th um et al.
we state p s and p s0 as follows p s ps c p s0 ps0 c where psandps0denote the conjunction of clauses exclusive top s andp s0 respectively and c the common clauses.
because ps c cis a contradiction the formula p s p s0 ps c ps0 ps c c then can be rendered as p s ps0 the formula can be further simpli ed as a disjunction of several easier to solve formulas each one is represented as as a conjunction of p s and a sub expression in the cnf representation of ps0.
speci cally consider ps0with thealgorithm extractbase input f formulas r relations output hbrelations bformulas i 1bformulas fg 2brelations fg 3forformula2fdo rels getrelationalv ars formula ifrels rthen bformulas bformulas formula brelations brelations rels end 9end 10returnhbrelations bformulas i cnf representation of ps0 ps0 ps0n.
the formula p s ps0then equals 16i6np s ps0 i the problem of categorization of model changes per our specialization de nition is now reduced to a disjunction of several sub expressions where each one is signi cantly smaller and easier to solve than the original formula.
instead of calling a sat solver to determine satis ability of a rather large formula we can use multiple calls to a sat solver posing a more tractable sub expression each time.
if any sub expression determines to be satis able the entire model specialization evaluates to false possibly before reasoning about all sub expressions further improving the effectiveness of the approach.
moreover except for one clause ps0 i multiple calls to a sat solver solve exactly the same formula.
this enables leveraging the incremental solving capabilities featured in many modern sat solvers to make subsequent runs more e cient each sub expression is modeled as a separate addition of new constraints ps0 i to an already solved formula p s .
.
extended reasoning in the following we present our general approach for situations where both alloy speci cations are not de ned over the same set of relational variables i.e.
relational variables may be added or removed as a result of the speci cation modi cation.
our approach leverages declarative slicing which is a program slicing technique applicable to analyzable declarative languages.
declarative slicing partitions a declarative formula speci cation such as alloy and kodkod into two slices of base and derived where each slice is a disjoint subset of the formula constraints.
a base slice is de ned by a set of relational variables called slicing criterion to be constrained by the formula constraints speci ed in the base slice and an instance of which represents a partial solution that can be extended by an instance of a derived slice for the entire speci cation.
more formally let s hr fibe a speci cation consisting of a set of relational variables rand a set of relational formulas f de ned over r. let sb r randsd r r partition r and sb f fbe the formulas that only involve relations in sb r. we call sb ra base slice forsif and only if 31algorithm superset input f s0 formulas r s relations s0 relations output lb adjusted lower bound set 1hbrelations bformulas i extractbase f r 2lb s0 lb 3ifbformulas s formulas then forr2brelations do lb r t i2i s i val r end 7end 8return lb algorithm subset input f s formulas r s relations s0 relations output ub adjusted upper bound set 1hbrelations bformulas i extractbase f r 2ub s0 ub 3ifbformulas s0 formulas then forr2brelations do ub r s i2i s i val r end 7end 8return ub 8ib2i sb j9id2i sd ib id2i s to derive a base slice from the revised speci cation in a way that its relations are shared with those of the original speci cation we use a constraint partitioning algorithm.
algorithm outlines the partitioning process.
it gets as input a set of relational variables r and a set of relational formulas f. without loss of generality we assume that fis a conjunction of several sub formulas i.e.
f formulas .
as an example the formula in listing line represents this form for the constraints speci cations in our running example listing .
the algorithm then iterates over each such sub formulas extracts the set of relational variables rels constrained by the given formula and evaluates it against the given set of relational variables r. if the formula s variable set rels is a subset of r it is added to the formulas in the base slice bformulas and relsto the base slice relation set brelations whose bounds will potentially be adjusted.
as a result of calling extractbase with the formulas of a speci cation and the shared relational variables of another speci cation the algorithm produces a bases slice.
we thus can reason about and update the bounds of the revised speci cation base slice according to the model specialization relations described in section .
.
algorithm computes the lower bound for the superset scenario outlined in section .
.
it rst calls extractbase with a a set of relational formulas de ned in s0and a set of relational variables shared between the two speci cations as inputs.
note that the base slice relation set brelations is a subset of those relations shared between the two speci cations and they are not necessarily equal.
the algorithm then evaluates a set of formulas in the base slice against those speci ed in s. if the extracted formulas form a subset ofs formulas that means sbaseis a model specializationofs0 base orsbase s0 base as formula is a tautology.
the instance set of sbasethus constitutes the lower bound for the corresponding relational variables in s0.
recall from section that a lower bound for a relational variable represents the tuples that the variable must contain.
the intersection of values assigned to a relation in all instances thus constitutes a lower bound for that relational variable.
algorithm computes the upper bound for the subset scenario outlined in section .
.
it rst calls extractbase with a set of relational formulas de ned in sand a set of relational variables shared between the two speci cations as inputs because this time we want to see whether s0 baseis a model specialization of sbase.
it then evaluates a set of formulas in the base slice against those speci ed in s rather than s as done in algorithm .
if the extracted formulas is a subset of s0 formulas that means s0 base sbase.
the instance set of sbasethus constitutes the upper bound for their corresponding relational variables in s0.
recall that an upper bound for a relational variable represents the tuples that a relational variable may contain.
the union of values assigned to a relation in all instances thus constitutes an upper bound for that relational variable.
finally in the case of equivalent relation recall section .
both upper and lower bounds need to be tightened.
in essence the equivalent relation implies the existence of both superset and subset relations i.e.
s s0 s0 s .
titanium calculates the bounds for equivalent relations by making consecutive calls to algorithms and .
titanium similar to alloy is both sound and complete for the given bounds yet more e cient for analysis of evolving speci cations.
space constraints prevented us from including a proof.
but they follow naturally from the algorithms in section .
and the discussions backed with mathematical notations in section .
.
note that because the problem of reasoning about alloy model edits has been reduced to a satis ability problem as presented in section .
it could still have an exponential run time in the worst case.
therefore in the implementation line in algorithms and we have taken a computationally e ective approach in which whenever ps0 iin formula is not equal to true we conclude that the formula p s p s0 is not a tautology and skip the adjustment of the corresponding bound either lower or upper .
in the next section we evaluate the execution time of our algorithm empirically and show that the proposed optimization technique achieves signi cant improvement compared to the alloy analyzer.
.
tool implementation we have implemented titanium as an extension to the alloy relational logic analyzer.
to implement the algorithms presented in the previous sections titanium modi es both the alloy analyzer and its underlying relational model nder kodkod .
the di erences between alloy analyzer and titanium lie in the translation of high level alloy models into low level bounded relational models and the facility to e ectively determine the scopes of the updated models given the instance set of the original speci cation.
the titanium tool is publicly available at the project website .
experimental ev aluation this section presents the experimental evaluation of titanium.
our evaluation addresses the following research questions 32table results for publicly available and automatically extracted alloy speci cations.
alloy analyzer .
titanium speci cation rels vars clausesanalysisvars clausesadj.
analysis time s time s time s decider .
.
.
wordpress .
.
.
moodle .
.
.
ecommerce .
.
.
dblp .
.
.
library .
.
.
coach .
.
.
webml .
.
.
gmf graph .
.
.
app bundle .
.
.
app bundle .
.
.
app bundle .
.
.
app bundle .
.
.
app bundle .
.
.
rq1 what is the performance improvement achieved by titanium s incremental analysis compared to alloy analyzer?
rq2 what is the overhead of titanium?
how does the titanium s overhead relate to the size of the original instance set?
rq3 how do the e ciency gains in titanium relate to the extent of change in the speci cation?
our experimental subjects are alloy speci cations drawn from a variety of di erent sources and of di erent problem domains.
these speci cations further vary much in terms of size and complexity.
we have compared the performance of titanium to that of the alloy analyzer version .
on three sets of speci cations publicly available alloy speci cations.
we used several alloy speci cations taken from the work of other researchers that were publicly available .
extracted speci cations.
we used several speci cations extracted automatically by various analysis techniques that leverage alloy for analysis of real world software systems .
automatically synthesized speci cations.
we developed a tool for generating a large number of synthesized alloy speci cations.
the complete list of subject systems and their speci cations are available from the project website .
.
improvements in practice for an initial evaluation we wanted to assess the kinds of improvement one could expect in practice.
we thus used several alloy speci cations that were either publicly available or automatically extracted from real world software systems as shown in table .
decider is an object model of a system to support design space exploration.
its model contains classes associations and inheritance relationships all represented as signature extensions in alloy.
wordpress and moodle are object models from two opensource applications obtained by reverse engineering their database schemas.
the wordpress model which is an opensource blog system includes classes connected by associations with inheritance relationships.
moodle is a learning management system widely used in colleges and universities.
its model has classes connected by associations and consists of inheritance relationships.
ecommerce is the object model of an e commerce system adopted from lau and czarnecki that represents a common architecture for open source and commercial ecommerce systems.
it has classes connected by associations with inheritance relationships.
the next ve speci cations i.e.
dblp library coach webml gmf graph are class diagrams automatically transformed into alloy speci cations by the cd2alloy apparatus .
the selected class diagrams are all publicly available taken from di erent sources and previously published as case studies and research papers in the area of uml analysis.
finally the last ve rows represent large speci cations intended for the assessment of security properties in mobile platforms.
each one represents a bundle of android apps installed on a mobile device for detecting security vulnerabilities that may arise as a result of inter application communication adopted from .
for some of the speci cations whose change histories were available we actually used di erent versions of the speci cation which had been manually developed or automatically extracted at di erent times.
for others we made three to ve changes to each speci cation such that the updated speci cations still had valid model instances.
we used a pc with an intel core i7 .
ghz cpu processor and gb of main memory and leveraged sat4j as the sat solver to keep the extraneous variables constant during all the experiments.
we then compared the performance of titanium to that of the alloy analyzer version .
in all these revised speci cations.
the results are provided in table .
the table shows the number of relations for each speci cation the size of the generated cnf given as the total number of variables and clauses the analysis time taken for the model nder as well as the overhead time taken by titanium for adjusting the analysis bounds.
as shown for some experiments the size of cnf variables generated by titanium is less than those generated by alloy.
this is because relations with exact bound that essentially represent partial instances do not 33need to be translated into a sat formula thus reducing the size of the generated cnf.
the results demonstrate the e ectiveness of our algorithm as in every case and for every update the analysis time taken by titanium for computing the instance set of modied speci cations is less than that of using the alloy analyzer.
however we can also see that the results could vary greatly because the improvements could depend on several factors most notably the amount of change and the size of instance set.
this called for further evaluation to determine how such variations a ect the e ciency gains as described next.
.
efficiency vs. size of instance set since in titanium we use the instance sets from the prior run to tighten the bounds for the next run we expect the e ciency gains to be more pronounced in cases with larger instance sets.
in this set of experiments we attempted to corroborate our intuition and obtain empirical evidence of this relationship.
since we needed access to a large number of alloy speci cations and their revisions we developed a tool for generating synthesized alloy models.
independent variables in our experiments are a the size of an alloy model represented as the total number of signatures and elds as both are indeed translated into relations in the underlying relational logic b the number of update operations and c the type of update operations.
as dependent variables we measured the time needed to update the bounds and the time needed to determine the instance set for the updated model.
we discarded all synthesized alloy speci cations that do not have any valid model instances and repeated the entire process until the appropriate number of models were generated.
in the following we describe the approach taken for synthesis of alloy speci cations and their revisions.
alloy speci cation synthesis.
our tool for synthesizing alloy speci cations takes as input ranges for the size of signatures elds and formulas and generates an alloy speci cation as follows.
it starts with the top level signatures which are signatures that are declared independent of any other signature and do not extend another signature.
a toplevel signature may also be de ned as an abstract signature meaning that it has no elements except those belonging to its extensions or de ned as a nonempty signature.
the generator then iterates over the set of top level signatures and adds sub signatures.
within the same iteration singleton signatures that contain a single element are also added.
in the next step elds are added as multi relations in addition to signatures that represent unary relations whose domains and ranges are given by the already de ned signatures.
the last part of the generated module is a set of constraints in a freestanding fact paragraph.
the constraints are generated using formula templates that cover operators de ned in the alloy core language including subset and equality operators in comparison formulas conjunction and universal quanti cation formulas and some binary union intersection join .
and product and unary transpose and transitive closure expressions.
note that the other types of alloy formulas such as existential quanti cation and disjunction can be derived from the core language the generator supports.
as a concrete example of a synthesized speci cation listing shows an alloy speci cation automatically generated given and as the size of signatures elds and constraint formulas respectively.a b s t r a c t s i g a0 f f some a3 a1 g s i g a1 f f one a0 g s i g a2 extends a0 f g one s i g a3 f f some a2 f one a4 g s i g a4 f g one s i g a5 extends a2 f f l o n e a0 g f a c t f a l l o a5 jsome o .
a5 f a l l o a3 j o .
a3 f o .
a3 f a5 a1 a2 g pred show fg run show f o r listing an automatically generated alloy speci cation.
figure analysis time for bound adjustment over the size of the original speci cation instance set.
revised speci cation synthesis.
to produce an update for an alloy model our generator takes as input an alloy model and the number of edits.
it supports the following edit operations on the alloy models create or delete a signature without children change the signature multiplicity2 i.e.
to set one lone orsome one that is di erent from the multiplicity dened in the original speci cation make an abstract signature non abstract or vice versa move a sub signature to a new parent signature add a new eld to a signature declaration or delete a eld change a multiplicity constraint in a eld declaration nally create a new constraint or delete a constraint.
2a signature multiplicity constrains the size of a set corresponding to that signature type.
34figure performance comparison analysis time taken for alloy analyzer and titanium vs. the size of the instance set.
while the rst six types of edits revise relations in the speci cation the last one modi es the speci cation s formulas.
the generation and execution of alloy models and their updates are done using alloy s apis.
experimental results.
we ran the generator with parameters specifying the size of signatures elds and formulas varying in the ranges of and respectively.
the number of edits to create a revised speci cation ranged from to .
for each edit one of the types of operation was randomly selected and applied.
we generated original speci cations and another corresponding revised speci cations for a total of speci cations.
figure shows the boxplots of the analysis time for bound adjustment over the varying size of instance sets for the original speci cations.
according to the diagram the execution time increases roughly linearly with the size of instance sets and for a space of size it takes just about .
seconds for titanium to produce an adjusted bound set showing that the titanium approach is e ective in practice on speci cations with large scale instance sets.
we then compared performance of titanium with the alloy analyzer .
.
in figure we show the results of our measurements comparing the analysis time taken by each of the tools as boxplots with a logarithmic scale.
on average titanium exhibited a improvement over that of the alloy analyzer.
for speci cations with very small instance sets the di erence in performance of the two techniques is negligible yet the e ects of adjusted bounds are clearly visible when the size of instance sets increases.
as illustrated in the diagram the analysis time by the alloy analyzer grows faster than the corresponding time for titanium.
in summary titanium is able to analyze the revised speci cations in a fraction of time it takes to run alloy analyzer and the di erence in analysis time is more pronounced for the larger instance sets as we expected.
.
efficiency vs. extent of change we then assessed how the e ciency gains in titanium relate to the extent of change.
as a given speci cation diverges from the original speci cation and the shared variables and formulas are reduced the e ciency gains are expected to gradually diminish.
in this set of experiments we attempted figure percentage of average improvement vs. the proportion of change for model speci cations of size relations.
to corroborate this expectation and to obtain an empirical understanding of this relationship.
we generated a speci cation with a xed size of relations and automatically revised the speci cation by randomly applying the edit operators described in the prior section on to of its relations resulting in a revised speci cation with to change.
we then measured the time taken by both alloy analyzer and titanium in analyzing the revised speci cation.
we repeated this experiment for times.
in this way we were able to determine whether more changes decrease the e ciency gains in analysis achieved through bound adjustments.
the boxplots in figure show the e ciency gains of using titanium over alloy analyzer.
on average for speci cations of size relations one can expect to obtain more than reduction in analysis time compared to that of the alloy analyzer for up to change in the speci cation.
after that the e ciency achieved through bound adjustments decrease and for changes above of speci cation the improvements are reduced to less than .
thus the extent to which edits can negatively a ect titanium s e ciency gains depends on the proportion of the original speci cation that has changed.
.
related work much work is related to this research.
here we provide a discussion of the related e orts in light of our research.
alloy extensions.
the widespread use of alloy has driven a number of extensions to the language and its underlying automated analyzer .
certain techniques have been developed for exploring model instances from alloy s relational logic constraints .
among others aluminum extends the alloy analyzer to generate minimal model instances.
it relies on a procedure in which tuples are iteratively removed from the tuple set of found model instances until a minimal instance is reached.
macedo et al.
studied the space of possible scenario explorations in the context of relational logic.
this work similar to aluminum mainly focuses on the order in which model instances are explored rather than facilitating the exploration of the solution space for evolving models.
torlak and jackson introduced a heuristic polynomial time algorithm to substantially exclude symmetric instances of relational models given that such model instances present no additional information.
identifying isomorphisms of rela35tional models has no known polynomial time solution.
montaghami and rayside extended alloy to explicitly support speci cation of partial models.
however this research e ort does not consider the analysis of evolving speci cations.
indeed it is commonly acknowledged that development of e cient techniques for the analysis of alloy speci cations is a much needed area of research .
however to the best of our knowledge no prior research has attempted to optimize the performance of analysis time for evolving alloy speci cations.
incremental analysis.
the other relevant thrust of research has focused on incremental solving of constraints speci ed in the rst order logic .
among others uzuncaova and khurshid partitioned a model of constraints into a base and derived slices where solutions to the base model can be extended to generate a solution for the entire model .
titanium is fundamentally di erent in that the problem addressed by uzuncaova and khurshid is in the context of a xed speci cation and the evolution of speci cation is not considered.
moreover the two approaches use declarative slicing for totally di erent purposes in declarative slicing is used to prioritize constraints to rst analyze constraints with higher priorities .
however titanium uses declarative slicing to identify a base set of relations the bounds of which can potentially be tightened in the analysis of evolving speci cation.
ranger uses a divide and conquer method relying on a linear ordering of the solution space to enable parallel analysis of speci cations written in rst order logic.
while the linear ordering allows for partitioning of the solution space into ranges there is no clear way in which it can be extended with incremental analysis capabilities essential for analysis of evolving systems.
e ectively reducing the exploration space has been used in a variety of forms to optimize bounded analysis techniques .
galeotti et al.
presented a technique called taco that targets e cient analysis of jmlspeci cations for linked data structures through translating them into the alloy language.
taco eliminates the values that violate constraints introduced by class invariants via adjusting only the upper bounds for the translated alloy elds.
titanium however is a general solution independent of any particular domain capable of adjusting both upper and lower bounds and aimed at e cient analysis of any evolving alloy speci cation.
to the best of our knowledge titanium is the rst general solution that supports analysis of evolving alloy speci cations.
optimization of other techniques relying on constraint solving.
related to our research are the applications of constraint solving techniques to software engineering problems.
of particular relevance is symbolic execution of software which is a means of analyzing a program to determine what inputs cause each part of a program to execute.
a software program is rst abstractly interpreted to identify a set of symbolic values for inputs and conditional expressions which when solved with the aide of a solver produce concrete values to exercise di erent branches of the program.
similar to alloy analyzer due to their reliance on sat solving engines symbolic execution tools face scalability problems.
substantial recent research has focused on improving the performance of symbolic evaluation techniques .
some of these approaches follow the general strategy of storing and reusing previously solved constraints which result in less calls to the solver thereby improving the performance.
but most closely related to our researchis regression symbolic execution where one attempts to co analyze two program versions which are often very similar.
here the di erences between two versions of a program are rst identi ed and the new run of the symbolic execution on the revised program is then only guided through the regions of the program that have changed.
similar to all of these approaches titanium aims to improve the performance of analysis for alloy speci cations.
however in addition to targeting a di erent type of analysis i.e.
formal speci cations rather than programs it employs a di erent technique that uses the previously calculated instances to tighten the bounds on shared relational variables.
.
conclusion alloy has found applications in a variety of software engineering problems from automated synthesis and exploration of design alternatives to analysis of programs and generation of tests .
the development of solutions for automatically extracting alloy speci cations from software artifacts has made alloy practical for use even after the deployment of software and possibly at runtime .
such applications of alloy however are challenged by the time it takes for an analysis to run especially given that the analysis may need to be repeated frequently.
we presented an approach and an accompanying tool dubbed titanium that signi cantly reduces the time it takes to analyze evolving alloy speci cations.
while the approach is particularly suitable in settings where a speci cation is kept in sync with the changing software system it could also be as e ective in settings where a speci cation is incrementally developed often involving repeated analysis of the speci cation to assess its semantics.
titanium is able to achieve a signi cant speed up by tightening the analysis bounds without sacri cing soundness and completeness.
it rst identi es the shared relational variables between two versions of a given speci cation.
it then uses the instances produced for the original speci cation to determine a tighter bound for the revised speci cation thereby reducing the state space enabling the sat solver to nd the model instances for the revised speci cation at a fraction of time needed for alloy analyzer.
our experimental results using both real alloy speci cations constructed in the prior work as well as synthesized alloy speci cations corroborate the signi cant performance gains achieved through titanium.
while the results obtained so far are quite promising we believe further improvements are possible.
speci cally in spite of the adjustments made to the analysis bounds the solver still needs to solve for the shared constraints.
a promising avenue of future research is a memoization based approach were the constraints solved in a prior analysis of the model are stored and retrieved as encountered in the subsequent analyses.
such an approach would not eliminate the need for adjusting the bounds for relational variables as some of those variables may be used in the derived speci cation.
we have made titanium as well as alloy speci cations and the model synthesizer used in conducting our experiments publicly available for use by other researchers .
.
acknowledgment the authors are grateful to daniel jackson for the discussions regarding the initial idea of this work.
we also thank tim nelson for his help on alloy s symmetry breaking.
.