promoting secondary orders of event pairs in randomized scheduling using a randomized stride mahmoud abdelrasoul north carolina state university usa email mahmoud.a acm.org abstract because of the wide use of randomized scheduling in concurrency testing research it is important to understand randomized scheduling and its limitations.
this work analyzes how randomized scheduling discovers concurrency bugs by focusing on the probabilities of the two possible orders of a pair of events.
analysis shows that the disparity between probabilities can be large for programs that encounter a large number of events during execution.
because sets of ordered event pairs define conditions for discovering concurrency bugs this disparity can make some concurrency bugs highly unlikely.
the complementary nature of the two possible orders also indicates a potential tradeoff between the probability of discovering frequently occurring and infrequently occurring concurrency bugs.
to help address this trade off in a more balanced way randomized stride scheduling is proposed where scheduling granularity for each thread is adjusted using a randomized stride calculated based on thread length.
with some assumptions strides can be calculated to allow covering the least likely event pair orders.
experiments confirm the analysis results and also suggest that randomized stride scheduling is more effective for discovering concurrency bugs compared to the original randomized scheduling implementation and compared to other algorithms in recent literature.
index terms multithreading software debugging software quality parallel programming scheduling algorithms i. i ntroduction the use of concurrency in a program introduces the possibility of encountering concurrency bugs which are bugs whose occurrence depends on how concurrent threads of execution are scheduled relative to each other.
concurrency testing which is testing that aims at discovering concurrency bugs has been an active area of research for decades .
past research explored many techniques for discovering concurrency bugs.
one of these techniques is randomized scheduling where a thread is selected for execution randomly at each step until program execution is complete.
research on randomized scheduling remains active.
variations and extensions of randomized scheduling have been studied in recent literature e.g.
.
randomized scheduling also serves as a building block of some other techniques such as in as a way to explore a program before applying a different algorithm that requires some knowledge of the program.
therefore it is important to have a good understanding of how randomized scheduling can effectively explore the space of possible thread schedules of a concurrent program.
despite the wide use of randomized scheduling in concurrency testing research some aspects of randomized schedulingare not readily explicable.
for example inspecting the results by thomson et al.
suggests that the effectiveness of randomized scheduling for discovering concurrency bugs tends to be worse for programs that encounter a larger number of events during execution.
it is not immediately clear from information found in past research why the effectiveness of randomized scheduling would deteriorate for programs that encounter more events.
to help reach a better understanding of how randomized scheduling discovers concurrency bugs this work focuses on the ability of randomized scheduling to cover the two possible orders of a pair of events.
the more likely order is referred to as the primary order and the less likely order is referred to as the secondary order.
with this focus this work makes the following contributions the work performs a theoretical analysis demonstrating an inherent limitation of the ability of randomized scheduling to discover concurrency bugs in large programs by showing that the number of secondary orders coverable by randomized scheduling with sufficiently high probability is at best inversely proportional to the square root of the total number of events encountered during program execution given any constant ratio between thread lengths.
randomized stride scheduling is developed as a way to modify randomized scheduling to improve the chances of discovering infrequently occurring concurrency bugs by improving the probability of covering secondary orders.
the work sheds light on the potential trade off between the frequency of discovering frequently occurring bugs and infrequently occurring bugs that is suggested by the complementary nature of primary and secondary orders.
experiments are performed and confirm the results of the analysis and also show that randomized stride scheduling is more effective than related techniques described in recent literature.
analysis of the results also shows some limitations in these techniques that are avoided by randomized stride scheduling.
ii.
b ackground a. randomized scheduling a number of variations of randomized scheduling were proposed in concurrency testing literature.
this work specifically considers the variation of randomized scheduling represented in the tool maple as available on .
this randomized .
c ieeease urbana champaign il usa technical research741 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
threadathreadb lock x lock x lock y lock y fig.
.
the necessary conditions for a deadlock represented as a set of ordering edges as also shown in a similar illustration by burckhardt et al.
threadathreadb temp balance temp deposit balance temptemp balance temp deposit balance temp fig.
.
two sets of ordering edges representing the conditions needed to expose an atomicity violation bug.
one set of ordering edges is shown in continuous lines while the other is shown in dotted lines.
covering either one of the two sets is sufficient to expose the bug.
scheduling algorithm is also the same as the one that was implemented previously in the tool calfuzzer which was relied on in other tools e.g.
.
in this implementation of randomized scheduling the program under test is executed by selecting a thread randomly out of the set of enabled threads with equal probability of selecting any thread from this set.
the selected thread is executed up to the next event where events are actions by the program that can result in intentional or unintentional communication between threads1.
once that event is reached random thread selection is performed again selecting any enabled thread including the most recently executed thread if enabled with equal probability.
this process is repeated until the program completes execution or until the program has no enabled threads which completes one run of the program under randomized scheduling.
testing the program under randomized scheduling requires running the program many times following the same process keeping random choices in every run independent from those in other runs with the idea that the randomization can result in exploring variations of thread schedules that uncover concurrency bugs.
as is typical in other work in the literature on randomized scheduling this work assumes that the inputs to the program are predetermined for example by existing test cases and do not vary between runs.
for practical purposes if multiple variations of inputs need to be used during testing the program can be tested separately for each variation as if each variation defines a distinct program to be tested.b.
ordering edges a key concept that is used in this work to reason about the ability to discover concurrency bugs is the concept of an ordered pair of events.
the use of ordered pairs of events to describe the conditions necessary for discovering concurrency bugs was introduced by burckhardt et al.
.
in that work ordered pairs of events were referred to as ordering edges which is the same term that will be used here.
conceptually events represent instances of execution of atomic actions performed by the program.
multiple instances of the same action in the same execution must be identified each by a distinct event.
an ordering edge represents that the first event of the ordered pair occurs before the second event in the instruction interleaving that represents the program execution under randomized scheduling.
sets of ordering edges are sufficient to describe ordering constraints that can expose any concurrency bug.
in fact as may also have been implied by nagarakatte et al.
any instruction interleaving representing the execution of a program under randomized scheduling can be completely described by a set of ordering edges sufficient to define a total order of the events in this interleaving.
for example fig.
shows how the necessary conditions for a deadlock can be described by ordering edges.
moreover as in the example in fig.
some bugs may show when any set out of a number of different sets of ordering edges is satisfied.
other examples of how ordering edges can be used to represent the necessary conditions for bugs are presented by burckhardt et al.
and cai and yang .
to represent an ordering edge that specifies that event ushows before event vin an interleaving that represents the program execution the notation u!vwill be used as was used once in the paper by burckhardt et al.
.
because randomized scheduling as described earlier executes instructions from only one thread at a time any run of the program under randomized scheduling will execute exactly one of the two possible orders of any two events encountered during that run.
when an ordering edge is exercised during an execution of the program the execution of the program will be said to have covered the ordering edge.
iii.
a nalysis of randomized scheduling a. an idealized case a key part of the analysis in this work focuses on the relative order of two events aaandbb that happen on two different threads thread aand threadb in an idealized program.
the analysis also refers to a common predecessor event e0.e0 is the farthest event from the beginning of the program that is known by the structure of the program to always precede bothaaandbb.
the subscript ainaadenotes the number of events in thread aaftere0is executed up to and including aa.
similarly bis the number of events in thread baftere0 is executed up to and including bb.
without loss of generality 1in a single process multi threaded program that depends on shared memory communication such events include shared memory accesses synchronization operations and thread creation and join operations.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
threada threadbstarte0 aa bb fig.
.
illustration of key elements considered in the theoretical analysis it will be assumed that a b. the common predecessor e0may be the first event in the program or can be a later event e.g.
where a thread is instantiated or where blocking communication happens .
fig.
illustrates some of the key elements of the idealized program considered in the theoretical analysis in this work2.
to enable the analysis the following simplifying assumptions will be used neither of the two threads becomes blocked i.e.
the threads will always be enabled after e0is executed.
the sequence of events executed by each of the two threads individually does not change between runs.
the first assumption simplifies the analysis because it implies that the progress of each of the two threads is unaffected by the progress of any thread other than itself.
the assumption also implies that any interleaving of events is feasible if it preserves the order of events after e0within thread aand within thread b. with this assumption the model becomes an idealization because it does not account for effects of blocking communication involving either of the two threads after e0.
the second assumption is needed to allow each event to be assigned an ordinal label that consistently identifies the event across different executions of the program.
therefore with the second assumption aaandbbrefer to the same events in all possible executions of the program.
this assumption also makes the model an idealization because it results in the model not accounting for the possibility of variation of code paths executed by a thread depending on communication with other threads.
the assumption also implies that the relative order of instructions within a thread does not change between runs which suggests sequential consistency.
b. time to reach an event the durations of time that elapse from the end of execution ofe0to the beginning of execution of aaandbbare two random variables taaandtbb respectively.
time is measured in units of time blocks.
a time block is defined as the period of time that starts when the randomized scheduling algorithm selects thread afor execution and ends with the next instance when thread ais selected again for execution.
based on this definition exactly one event of thread ais executed in each time block.
in essence the definition of the time block allows describing the progress of thread busing the most recent 2for simplicity of exposition it will be assumed that the sequence of instructions between e0andaa and similarly between e0andbb are all on the same thread.
however the analysis can directly be generalized to the case where the sequence of instructions is on multiple threads with the mathematical analysis and the results remaining the same.event that has been executed from thread aas a frame of reference.
by this definition taaalways equals a. this definition of the time block preserves the ability to determine the relative order of execution of two events each in a different thread by comparing the time taken to reach each event.
aa!bboccurs if and only if taa tbb which happens with probability p taa tbb whereasbb!
aaoccurs if and only if taa tbb which happens with probabilityp taa tbb p taa tbb .
c. primary and secondary orders of event pairs per the discussion above the two events aaandbbwill define two possible ordering edges that are mutually exclusive aa!bbandbb!aa.
the ordering edge that has the higher probability will be referred to as the primary order of the two events while the ordering edge of the lower probability will be referred to as the secondary order.
if both orders have the same probability either order can be selected to be the primary order while the other becomes the secondary order.
because randomized scheduling treats all threads equally the only property of aaandbbthat can affect which order of the two events is the primary order and which is the secondary order is the number of events until each of aaandbbare reached i.e.
aandb.
becausea b aa!bbis the primary order of the two events and bb!aais the secondary order.
d. probability of an ordering edge as described earlier at each event of the program the randomized scheduling algorithm makes a decision for selecting the next thread to execute from any of thread a threadb or any other enabled threads with equal probability for all choices.
selecting events that are not in thread aor thread bdoes not affect the number of time blocks for execution to reachaaorbb.
therefore events in other threads are not relevant for this discussion and can be ignored.
hence the problem of analyzing randomized scheduling can be correctly reduced to an analysis that assumes that the next event to execute is selected from either thread aor threadbwith an equal probability of p each regardless of the number of threads in the program.
because thread selection at each step is independent from previous selections the amount of time taken until the occurrence of the next event from thread b to be referred to as b is a geometric random variable.
using the formulas in bhas a mean of b p p and variance of b p p2 .
afterbevents from thread b the total amount of execution time from e0tobb i.e.tbb ispb i b. ifbis large the central limit theorem as stated in implies that tbbcan be approximated by a normallydistributed random variable of mean and variance equal to b times the mean and variance respectively of b. therefore the mean and variance of tbbare tbb b tbb 2b authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
because by the definition of the time block as stated earlier taa a the probability of the secondary order is p bb!
aa p taa tbb p tbb a which results in p bb!aa a tbb tbb!
where is the cumulative distribution function of the standard normal distribution.
by substituting the mean and the variance oftbbfrom equations and p bb!aa a bp 2b e. effect of thread length on ability to cover secondary orders equation suggests that given a probability that can be considered sufficiently high for an ordering edge to be coverable by randomized scheduling the ratio of secondary orders that can be discovered with a sufficiently high probability diminishes when the magnitude of a bbecomes larger.
this subsection describes this conclusion and the reasoning behind it in more precise terms.
letpbe the minimum acceptable probability of an ordering edge.
the probability pcan be determined in part based on the number of program runs planned under randomized scheduling as done in the experiments presented later in this work.
if the program will be run many times under randomized scheduling it is reasonable to assume that this minimum acceptable probability is small.
hence it can be assumed thatp which implies that all ordering edges that do not meet this minimum acceptable probability represent secondary orders.
based on equation the following inequality needs to hold true for the ordering edge bb!aa which is the secondary order of aaandbb to be sufficiently likely a bp 2b p that is a bp b p p where 1is the inverse of the cumulative distribution function of the standard normal distribution.
the right hand side of this inequality is a constant that depends only on the predetermined desired probability p. the constant is negative because p .
if we refer to this constant as the inequality can be written as a b p b the lengths of threads aandb i.e.
the number of events in threadsaandbaftere0 will be referred to as laandlb respectively.
because a b it follows that a2 andb2 whereaandbare integers.
equation implies thatamust be an integer in the interval b p b min la b so thatp bb!aa p. the length of this interval is at most p b. because the upper limit of the interval is an integer the maximum number of distinct possible values of ais at most p b.proposition letlb cla wherecis constant and where lbandlaare sufficiently large to make negligible the number of events for which the central limit theorem approximation in equation is invalid.
the ratio of secondary orders coverable by randomized scheduling with probability at least pto the total number of secondary orders is bounded by o pla lb i.e.
is at most inversely proportional to the square root of the total number of events that occur after e0in threadsaand b .
proof letbj!aibe an ordering edge representing a secondary order of the ith event in thread aand thejth event in threadb.
as stated earlier the number of possible values ofiso thatp bj!ai pis at most pj.
therefore given a value for j the maximum possible number of event pairs for which the secondary order is covered by randomized scheduling with a probability of at least pis pj.
considering that jcan be any integer between 1andlb inclusive the number of pairs for which the secondary order has a probability greater than or equal to pis at mostplb j pj .
using the result from it can be found that the most dominant term of this summation is2 l3 b and the value of this summation is in the order of l3 b .
as mentioned earlier this is only a best case that assumes the largest possible range for the possible values of i. therefore the number of secondary orders bj!aithat can be covered with probability at leastpiso l3 b .
given that lb claandcis a constant the number of such secondary orders is o l3 a .
similarly the number of secondary orders ai!bjthat can be covered with probability at least pis alsoo l3 a .
the total number of secondary orders ai!bjandbj!
aiis equal tolalb cl2 a. therefore the ratio of the number of secondary orders that have a probability of at least pto the total number of all secondary orders is o l3 a o l3 a cl2 a o pla .
given thatlb cla it follows that la la lb c .
because c is constant the ratio of the number of secondary orders with a probability of at least pto the total number of all secondary orders is o pla lb .
this result shows that the effectiveness of randomized scheduling deteriorates when the program grows larger because a large proportion of ordering edges becomes unlikely to be covered leaving a large proportion of the possible sets of ordering edges unexplored.
because discovering ordering edges is necessary for discovering potential bugs for which these ordering edges are part of the necessary conditions this result may explain the adverse effect that a large number of events in a program can have on the ability of randomized scheduling to discover bugs as discussed in the introduction.
3this result can be extended to the case where there are more than two threads where all pairs of threads conform to the assumptions stated earlier on a pairwise basis.
it can be shown in this case that the number of secondary orders discoverable with sufficient probability is o pp ili assuming the ratio between lengths of each two threads remains constant i.e.
8i j l i cijlj where cijis constant .
this result can be proved by considering each possible pair of threads individually and aggregating all the results.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
iv.
i mproving randomized scheduling the analysis in the previous section suggests that improving the probability of covering secondary orders can help improve randomized scheduling.
however any potential improvement to the probability of discovering these ordering edges is expected to require a trade off.
because the primary order of an event pair is mutually exclusive with its corresponding secondary order any change to randomized scheduling that can increase the probability of covering secondary orders will result in reducing the probability of covering the corresponding primary orders.
therefore any change that increases the probability of discovering potential bugs for which secondary orders are necessary conditions will inevitably result in decreasing the probability of some potential bugs for which primary orders are necessary conditions.
a modification to randomized scheduling that attempts to increase the probability of secondary orders should try to avoid severely reducing the probability of covering primary orders.
the analysis also suggests that coarser scheduling can improve the ability to cover secondary orders that are not sufficiently likely to show when finer grained scheduling is used.
the analysis connected the low probability of discovering secondary orders to the large number of time blocks that are needed to reach an instruction.
one way to make randomized scheduling more effective for programs that encounter more events during execution is to reduce the number of time blocks needed to reach events such as aaandbb.
considering that the definition of a time block depends on how many times thread ais selected for execution the probability of encountering secondary orders can improve if scheduling is made coarser such that multiple events from the same thread are covered each time the thread is selected for execution.
to make scheduling coarser an integer s the stride will be selected with uniform probability between 1andsmax inclusive at every point where randomized scheduling selects a thread for execution.
the thread that is selected for execution at that point will be executed exclusively until sevents have been encountered or until the thread becomes blocked or completes execution.
the value smax will be referred to as the maximum stride.
ifsmax is set to the scheduling algorithm becomes identical to the original randomized scheduling algorithm analyzed earlier.
if smax is greater than the scheduling algorithm will be referred to as randomized stride scheduling.
for selecting smax although a larger value is desirable because it increases the chance of encountering unlikely ordering edges a larger smax also has a disadvantage because it reduces the number of thread switches that are expected to happen during a run of the program and therefore makes it less likely to discover bugs whose discovery requires covering a combination of several ordering edges.
therefore it is desirable to use the smallest possible smax that does not make any secondary orders too unlikely to be covered.
when considering two threads aandbin a program being run under randomized scheduling the most unlikely ordering edge originating from thread ais the ordering edge al!b1wherealis the last event in thread aandb1is the first event in thread b. this ordering edge is unlikely because it requires that scheduling decisions never result in selecting threadbuntil thread acompletes execution.
a longer stride improves the probability of discovering this ordering edge so the scheduling algorithm should choose a stride that is long enough to make p al!b1 just as high as necessary.
this probability can be calculated as follows p al!b1 1x i 5ip0 ix j 1ud smax a l1 a whereud smax is the discrete uniform distribution for which the possible values are the integers between and smax inclusive.
this expression can be approximated by using the continuous uniform distribution which results in p al!b1 1x i 5ip0 ix j 1uc smax a l1 a whereuc smax is the continuous uniform distribution with the range and o i .
dividing both sides by smax yields p al!b1 1x i 5ip0 ix j 1uc a smax l smax1 a to enable calculating smax based onp al!b1 using this formula some approximation can be helpful.
approximations taken towards calculating smax should try to avoid making the probability less than the targeted probability to help avoid making the less likely ordering edges too unlikely to be encountered during testing.
the term smax can be dropped without making the probability of the left hand side lower than the target.
moreover this term will have a negligible value for values of ithat are small compared to smax which is expected to be large for large programs and the multiplier 5iwill make the corresponding term of the outer summation negligibly small for large values ofi.
this results in p al!b1 1x i 5ip0 ix j 1uc a l smax1 a this approximation allows calculating smax on a per thread basis based only on the length of the thread and the desired probability of covering the least likely ordering edge.
moreover given a desired probability the approximation makes the ratio of the length of the thread to the ideal maximum stride i.e.
l smax constant for all threads in the program under test.
using equation it is possible to estimate l smax based onp al!b1 with the help of monte carlo sampling.
fig.
shows the relation between l smax andp al!b1 estimated this way.
for the experiments in this work only two values of the probability needed to be used so l smax was estimated directly based on monte carlo sampling.
however fig.
suggests that the relation between l smax andp al!b1 can potentially be approximated by an exponential relation.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
lsmaxp al b1 fig.
.
the probability of covering the ordering edge al!b1versus the ratio of thread length to the maximum stride length based on the approximation in equation v. e xperiment a. experiment setup to test the prediction that coarser scheduling can help improve the ability to discover concurrency bugs that are infrequently occurring under the original randomized scheduling an experiment was performed using out of the test programs available from the work by thomson et al.
as the test subjects.
the programs are available for download from the web along with a virtual machine that is set up to run the programs .
of the excluded programs were failing all the time and were reported by thomson et al.
to fail all the time suggesting that the bugs in these programs are not concurrency bugs or at least are not interesting for the purposes of this work.
the two other programs that were excluded are parsec.ferret and parsec.streamcluster2.
when trying to reproduce the results by thomson et al.
the results of these two programs were inconsistent with what was reported.
the test subject parsec.ferret failed all the time while parsec.streamcluster2 never failed.
inspecting the code of parsec.streamcluster2 did not reveal a concurrency bug.
for the programs that were used in the experiment there were also variations of the results from those reported by thomson et al.
nearly all of these variations can be expected because of the randomness intrinsic to randomized scheduling.
for a few programs the differences appeared to be larger than what can be explained by randomness.
therefore the results of running the original randomized scheduling in this experiment are reported in the programs used in this work included real world programs with real world bugs and also artificial programs.
the programs were drawn by thomson et al.
from various sources.
as can be seen in the next section the bugs in the programs also present a wide range of frequencies of occurrence under randomized scheduling and the programs also cover a wide range of the number of events encountered during program execution.
to explore the effect of changing smax three variations of randomized stride scheduling were used.
the first variation usedsmax which is the smallest possible smax that results in coarser scheduling than the original randomized scheduling.
the second and third variations used a value of smax that iscalculated based on the thread length as described in section iv.
the second variation used a ratio l smax that enables discovering the least likely ordering edge with a confidence of in at least one run.
the third variation used a ratio l smax that enables discovering any two independent ordering edges in the same run with a confidence of .
the program was executed for a total of times under each of the three variations of randomized stride scheduling.
for the second and third variations the first runs were performed using smax .
the maximum length of each thread in the runs was used as the estimate of the thread length.
then the program was executed times using the maximum stride lengths calculated based on the estimated thread lengths.
the value of l smax that can achieve the desired confidence in runs of randomized scheduling is approximately .
for the second variation of randomizedstride scheduling and approximately .
for the third variation.
therefore during the experiment the maximum stride for the second and third variations of randomized stride scheduling was set as the ceiling of l andl respectively.
for the purpose of counting events in any thread the only events that were counted were those that implied potential intentional or unintentional communication between threads as described in section ii a and that happened while other threads were enabled.
b. baselines for comparison for comparison the same test subjects were executed under the original randomized scheduling algorithm and also under the randomized scheduling algorithms pct that is described by burckhardt et al.
and rpro that is described by cai and yang .
in addition the results by thomson et al.
were used to extend the comparison to some algorithms that do not depend on randomization namely iterative preemption bounding iterative delay bounding depth first search and the maple heuristic.
for the original randomized scheduling algorithm the program was simply run times under the algorithm.
the seed value for pseudorandom number generation in the original implementation was modified to be based on a finer grained clock to help avoid unintended redundancy between runs.
for the pct algorithm the algorithm depends on a depth parameter d and targets bugs of depth d. when the depth of the targeted bugs is unknown the ideal depth to use for the algorithm is also unknown.
however based on a formula by burckhardt et al.
larger values of dresult in an exponentially smaller guaranteed probability for discovering bugs.
therefore similar to how the length to maximum stride ratio was determined for randomized stride scheduling the formula in was used to calculate the maximum depth that allows the guaranteed probability of discovering a bug to be sufficiently high.
specifically the depth was calculated such that it allows a confidence of at least that a bug with this depth will be encountered in at least one of the program runs under pct.
similar to randomized stride scheduling the first runs used the original randomized scheduling algorithm to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
interlockedworkstealqueueinterlockedworkstealqueuewithstate stateworkstealqueue workstealqueue aget bug2pbzip2 stringbufferaccount bluetooth drivercarter01circular buffer deadlock01din phil2din phil3din phil4 lazy01queuereorder 10reorder 20 reorder 3reorder 4reorder 5stack token ringtwostage 100 twostagewronglock 3wronglock qsort mt ctrace testparsec streamcluster parsec streamcluster3radbench bug1 radbench bug2radbench bug4radbench bug5 radbench bug6safestack bug1splash2 barnes splash2 fft splash2 lu .
.
.
.
failure rate under original randomized schedulingnumber of relevant events in program max.
over runs of original randomized scheduling fig.
.
the results of running the experiment subjects times under the original randomized scheduling.
the annotation on each point indicates the name of the test subject that it represents.
the results in this figure are used in fig.
as a baseline for comparison of other algorithms.
estimate the number of events in the program then the pct algorithm with the parameters based on this estimate was used for runs.
for large programs the depth parameter of the pct algorithm calculated as described above becomes very small.
the only variation of pct in the literature that allows reaching a similar probability guarantee at a greater depth is the rpro algorithm by cai and yang .
although the rpro algorithm was developed to target deadlock bugs the algorithm does not exclude other kinds of concurrency bugs so it was relevant for use in this experiment.
the rpro algorithm uses a parameter r the radius of the bug in addition to the depth parameter d. two variations of the algorithm were used one with radius r and one with radiusr which are the same radii used by cai and yang.
as in cai and yang s work the two variations will be referred to as rpro and rpro .
to calculate the depth to use for the rpro algorithm the same approach that was used for pct was also used for rpro.
the pct and rpro algorithms were implemented as described in their respective papers with minor changes to handle special cases presented by the experiment subjects and to deal with ambiguity in the descriptions of the algorithms.
ambiguities were resolved in a way that should not adversely affect the ability of these algorithms to discover concurrency bugs.
the details of the changes to the algorithms are described in vi.
e xperiment results as discussed in section iv reasonable increases of the maximum stride are expected to improve the ability to discover many infrequently occurring concurrency bugs and shouldalso enable discovering some concurrency bugs that were not discovered by the original randomized scheduling.
at the same time because increasing the probability of discovering secondary orders will necessarily decrease the probability of discovering the corresponding primary orders the frequency of discovering some concurrency bugs can decrease especially for those bugs that are encountered frequently with the original randomized scheduling.
to enable visualizing the results of the experiment using the original randomized scheduling as a baseline fig.
shows the results of running the original randomized scheduling on each test subject.
each test subject corresponds to one point in the figure located according to how frequently the bug in the test subject was found under the original randomized scheduling and how many events were encountered during program execution.
hence test subjects represented by points towards the left side of fig.
are those with bugs that were discovered rarely or not discovered at all by the original randomized scheduling.
for example the topmost leftmost point in the figure represents radbench bug1 which is the program with the largest number of events and also one of the programs where the bug was not discovered by the original randomized scheduling.
using fig.
as a baseline the left hand side panels of fig.
illustrate how the frequency of discovering bugs using the three variations of randomized stride scheduling changes compared to the frequency of discovering the same bugs using the original randomized scheduling.
as expected from the analysis in previous sections the three variations of randomizedstride scheduling all show significant improvement of the ability to discover infrequently occurring concurrency bugs relative to the original randomized scheduling as indicated by authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
11251randomized stride lsmax .
rpro 50randomized stride lsmax .
rpro 10randomized stride smax pct .
.
.
.
.
.
.
.
failure rate under original randomized schedulingnumber of relevant events in program max.
over runs of original randomized scheduling ratio of change .
.
type of change no longer found discovery rate worsened ratio of change less than .
discovery rate improved newly foundfig.
.
an illustration comparing the rate of discovering bugs when testing the experiment subjects using randomized stride scheduling and other techniques using the results of original randomized scheduling in fig.
as a baseline.
points in each panel have the same layout as in fig.
.
numbers inside circles for newly found bugs state the number of times a bug was found for bugs that were not discovered by the original randomized scheduling.
points at the left of each panel.
they also show a decrease in the frequency of discovering frequently occurring concurrency bugs corresponding to points at the right of each panel but these bugs are still discovered fairly frequently.
this pattern of increase and decrease in frequency of bug discovery shows even for the smallest increase in maximum stride smax and is more amplified when the maximum stride increases.
moreover the two variations of randomized stride scheduling where the maximum stride is calculated based on the length of the thread show better ability to discover more of the bugs that were undiscovered by the original randomized scheduling.
inspecting the code around the additional bugs that were found by randomized stride scheduling reveals that the newlydiscovered bugs were indeed discovered because of the boost in the probability of discovering less probable ordering edges.
the four additional bugs that were discovered by randomized stride scheduling follow two different patterns.
in the case of reorder 10 reorder 20 and twostage 100 the occurrence of the bugs requires in part that the main thread of the program completes the creation of a large number of threads and respectively before any of the created threads reaches a point in execution that will make the bug undiscoverable.
a thread schedule that can allow this condition is highly unlikely under the original randomized scheduling but a lot more likely under randomized stride scheduling because the maximum stride associated with the main thread is sufficiently large to give it a chance to make sufficient progress before other threads make too much progress.
the other additional bug discovered by randomized stride scheduling radbenchbug1 shows a different pattern.
it is a much simpler bug but its discovery requires in part that two threads of drastically different lengths reach points close to the end of their execution authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
at approximately the same time.
because the maximum stride is proportional to the thread length randomized stride scheduling enables such a schedule.
on the other hand with the original randomized scheduling a large difference in thread lengths will result in the shorter thread practically always reaching the end of its execution a lot earlier than the longer thread which will prevent the bug from showing.
to compare the overall effectiveness of the algorithms used in the experiment fig.
compares the number of bugs missed by the algorithms that were used in this work and also by the algorithms that were used in thomson et al.
s work.
as can be seen from the figure the variations of randomized stride scheduling with a thread length based maximum stride are the most effective compared to all techniques that were considered in this work and in thomson et al.
s work.
closer inspection suggests that one key reason why pct and rpro missed some bugs that were discovered by randomizedstride scheduling is the limitation on the depth parameter which was necessary to keep the guarantees presented by these algorithms as high as targeted.
because the maximum depth depends on the number of events in program execution the maximum depth used with a program with many events needs to be small to allow achieving these guarantees.
rpro allows the depth to be larger and the results show that it successfully discovers some of the bugs missed by pct.
however it still does not discover some of the bugs discovered by randomized stride scheduling.
for example the experiment subject radbench bug4 is still missed by rpro because of the depth limitation.
the bug in radbench bug4 has a depth of but the maximum depth that could be used both for the pct and rpro algorithms for this program while satisfying the targeted guarantee was .
compared to pct and rpro randomizedstride scheduling does not present the same limitation on the depth of discoverable bugs which allows randomized stride scheduling to discover bugs that are not discovered by pct and rpro.
fig.
provides more information about how pct and rpro compare to randomized stride scheduling.
as can be seen in the figure although randomized stride scheduling shows improvement of the rate of discovering infrequently occurring bugs at the expense of the rate of discovering frequentlyoccurring bugs the other algorithms do not show this pattern of improvement with the same consistency.
moreover some of the bugs that were missed or encountered very infrequently by pct and rpro were bugs that were encountered relatively frequently under the original randomized scheduling algorithm.
this suggests that one advantage of randomized stride scheduling is that it results in a more balanced trade off between the rate of discovering frequently occurring bugs and infrequentlyoccurring bugs.
the results also showed that the original randomized scheduling algorithm discovered exactly the same set of bugs in this experiment as the set of bugs discovered by iterative delay bounding in the experiment by thomson et al.
in addition to one bug discovered only by the original randomized scheduling.
based on the model discussed in earlier sections maple heuristicdepth first searchiterative delay boundingiterative preemption boundingrpro 50rpro 10pctoriginal randomized schedulingrandomized stride smax randomized stride lsmax .
randomized stride lsmax .
number of missed bugsalgorithmfig.
.
number of bugs missed by various algorithms out of bugs.
the data for iterative preemption bounding iterative delay bounding depth first search and maple is from .
this similarity between the two algorithms can actually be expected.
because iterative delay bounding deviates from roundrobin scheduling only systematically and in a very limited way its ability to explore secondary orders is very limited.
it is also expected to have a more limited ability to discover secondary orders than the original randomized scheduling because the systematic nature of iterative delay bounding limits it to schedules that are closer to round robin than the original randomized scheduling.
additional details of the experiment results are available on where the results of running each of the randomized scheduling algorithms on each of the programs are listed.
vii.
t hreats to validity the work presented here is composed of two main parts a theoretical part and an empirical part.
because the first part used an idealization to enable analyzing the problem a threat to its validity is whether its results are generally applicable.
mitigating this concern to a large extent is that the results of the empirical work agreed with the general outcomes of the theoretical work suggesting that these outcomes are of practical significance.
for the empirical part of the work a threat to validity is that the programs and the bugs that were used in this work may not necessarily represent concurrent programs and bugs in general.
one point that helps mitigate this threat to validity is that the programs used for the experiment included programs of various sizes and programs where the bugs occurred at different rates and included programs with both real world bugs and artificial bugs that were drawn by thomson et al.
from multiple different sources.
viii.
r elated work the area of concurrency testing has been an active area of research for decades .
techniques for discovering concurrency bugs that are described in research are various and include static analysis symbolic execution sequentialization systematic exploration of thread schedules coverage based exploration of thread schedules and other techniques and heuristics.
other work has authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
also been done in past research to help with the process of concurrency testing such as concurrency coverage criteria e.g.
concurrency mutation operators and mutation analysis e.g.
and ways to generate test cases or create combinations of test cases that can help expose concurrency bugs e.g.
.
some concurrency testing techniques depend mainly on randomization to uncover buggy thread schedules.
these techniques can be divided into two general categories according to how much control they exercise over thread scheduling in one category scheduling decisions are influenced by injecting noise or delays which can be injected completely randomly or at deliberately selected points according to a heuristic.
a notable tool that falls into this category is contest .
other work that explored this area recently includes work by krena et al.
and fiedor et al.
who worked on comparing noise generation heuristics and hruba et al.
who explored using a genetic algorithm to select the parameters that control noise injection.
in the other category which has been the focus of this work scheduling decisions are controlled more closely either by setting thread priorities that are used by the scheduler of the underlying operating system or runtime to schedule the threads exactly as required by the testing algorithm such as what is used by pct and its parallelized variation ppct or by implementing a thread scheduler that decides which thread to schedule at each relevant event such as what is done by maple as available on .
some of the work on this variation of randomized scheduling includes work that aimed at providing guarantees for the probability of discovering bugs with certain properties including bugs with a maximum specified depth as described by burckhardt et al.
and nagarakatte et al.
and bugs of a specified maximum depth and maximum radius as in the work of cai and yang .
other work aimed at combining randomized scheduling with other techniques such as partial order reduction as done by sen .
randomized scheduling also serves as the basis of some other concurrency testing techniques.
for example it is used as a way to explore the program before applying a different technique that requires some knowledge of the program execution and sometimes it is used to drive program execution subject to some constraints.
examples of such techniques include .
other work explored using randomized scheduling as a basis for saturation based testing for discovering concurrency bugs.
ix.
c onclusion this work demonstrated a number of key points.
first the work showed that the ability of randomized scheduling to cover ordering edges is very limited and is impacted negatively when the number of events in the execution of the program under test increases.
the work also showed that the ability of randomized scheduling to discover rarely occurring concurrency bugs in larger programs can improve when the scheduling is made coarser and discussed the potential tradeoff between discovering frequently occurring and infrequently occurring bugs.
finally an approach for making scheduling coarser was described and experimental results suggested that the approach has advantages over the original randomized scheduling algorithm and over other techniques described in recent literature.
the work introduced the concept of a stride limited by a maximum stride that can be used to control the coarseness of scheduling and to enable achieving a target probability of discovering the most unlikely ordering edge.
the results of the work also confirmed that to discover some bugs more frequently under randomized scheduling other bugs are expected to be discovered less frequently and showed that randomized stride scheduling achieves a better balance regarding this trade off.
although the results show that randomized stride scheduling was significantly more effective than pct and rpro pct and rpro provide mathematical guarantees that are not provided by the original randomized scheduling nor by randomized stride scheduling.
this result suggests that the guarantees provided by pct and rpro come at a cost in terms of the general ability to discover bugs.
the results do not preclude the possibility that pct or rpro could discover more of the bugs if higher values of the depth parameter are used.
however making the depth parameter much higher will result in a vanishingly low guaranteed probability of finding bugs.
no published work that the author is aware of answers the question of what the best way is to select the depth parameter for pct and rpro when the depths of the targeted bugs are unknown.
exploring this question in the future may help find ways to make pct and rpro achieve better results than what is presented in this work.
the results also suggest that there is potential for improvement over the variations of randomized stride scheduling that are described in this work considering that randomized stride scheduling missed out of the bugs that were used in this experiment.
moreover although the results of randomizedstride scheduling showed no degradation of effectiveness at discovering the most infrequently occurring bugs compared to the original randomized scheduling it is conceivable to have bugs that are infrequently occurring under the original randomized scheduling and that become even more infrequent under randomized stride scheduling.
this is possible for example if the reason a bug is infrequently occurring is that it requires covering a large number of ordering edges all of which represent primary orders.
acknowledgment the author would like to acknowledge prof. g. jin at north carolina state university for conversations about this work and for suggestions of wording and suggestions regarding presentation and prof. t. menzies at north carolina state university for conversations about the research direction.
the author is affiliated with microsoft corporation and with north carolina state university.
this work is not meant to represent the points of view of microsoft corporation north carolina state university or any entity or person other than the author.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.