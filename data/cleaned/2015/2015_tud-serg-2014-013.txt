work practices and challenges in pull based development the integrator s perspective georgios gousios andy zaidman margaret anne storeyy arie van deursen delft university of technology the netherlands email fg.gousios a.e.zaidman arie.vandeursen g tudelft.nl yuniversity of victoria bc canada email mstorey uvic.ca abstract in the pull based development model the integrator has the crucial role of managing and integrating contributions.
this work focuses on the role of the integrator and investigates working habits and challenges alike.
we set up an exploratory qualitative study involving a large scale survey involving integrators to which we add quantitative data from the integrator s project.
our results provide insights into the factors they consider in their decision making process to accept or reject a contribution.
our key findings are that integrators struggle to maintain the quality of their projects and have difficulties with prioritizing contributions that are to be merged.
i. i ntroduction pull based development as a distributed development model is a distinct way of collaborating in software development.
in this model the project s main repository is not shared among potential contributors instead contributors fork clone the repository and make their changes independent of each other.
when a set of changes is ready to be submitted to the main repository they create a pull request which specifies a local branch to be merged with a branch in the main repository.
a member of the project s core team from hereon the integrator1 is responsible to inspect the changes and integrate them into the project s main development line.
the role of the integrator is crucial.
the integrator must act as a guardian for the project s quality while at the same time keeping several often more than ten contributions inflight through communicating modification requirements to the original contributors.
being a part of a development team the integrator must facilitate consensus reaching discussions and timely evaluation of the contributions.
in open source software oss projects the integrator is additionally taxed with enforcing an online discussion etiquette and ensuring the project s longevity by on boarding new contributors.
the pull based development process is quickly becoming a widely used model for distributed software development .
on github alone it is currently being used exclusively or complementary to the shared repository model in almost half of the collaborative projects.
with github hosting more than million collaborative projects and competing services such as bitbucket and gitorious offering similar implementations of the pull based model we expect the pull based development 1also referred to as integration manager distributed git distributed workflows.
we use the term integrator for brevity.model to become the default model for distributed software development in the years to come.
by better understanding the work practices and the challenges that integrators face while working in pull based settings we can inform the design of better tools to support their work and come up with best practices to facilitate efficient collaboration.
to do so we set up an exploratory qualitative investigation and survey integrators on how they use the pull based development model in their projects.
our field of study is github using our ghtorrent database we aimed our survey at integrators from high profile and high volume projects.
an explicit goal is to learn from many projects rather than study a few projects in depth.
we therefore use surveys as our main research instrument generously sprinkled with open ended questions.
we motivate our survey questions based on a rigorous analysis of the existing literature and our own experience with working with and analysing the pull based model during the last years.
we conducted a two round pilot and main survey with and respondents respectively.
our main findings reveal that integrators successfully use pull requests to solicit external contributions and we provide insights into the decision making process that integrators go through while evaluating contributions.
the two key factors that integrators are concerned with in their day to day work are quality andprioritization .
the quality phenomenon manifests itself by the explicit request of integrators that pull requests undergo code review their concern for quality at the source code level and the presence of tests.
prioritization is also a concern for integrators as they typically need to manage large amounts of contributions requests simultaneously.
ii.
b ackground and related work the goal of distributed software development methods is to allow developers to work on the same software product while being geographically and timezone dispersed .
the proliferation of distributed software development techniques was facilitated by the introduction of online collaboration tools such as source code version control systems and bug databases .
the main differentiation across distributed software development methods is the process of integrating an incoming set of changes into a project s code base.
this change integration process has gone through many phases as the collaboration tools matured and adapted to changingdevelopment needs pull based development is the latest of those developments.
in distributed software development the first step towards integrating changes is evaluating the proposed contributions.
this is a complex process involving both technical and social aspects .
mockus et al.
analyzed two early oss communities mozilla and apache and identified common patterns in evaluating contributions namely the commit then review process.
as an alternative the apache community also featured a review process through mailing list patch submissions.
rigby and storey examined the peer review process in oss mailing lists and found that developers filter emails to reduce evaluation load prioritize using progressive detail within emails containing patches and delegate by appending names to the patch email recipients.
jiang et al.
analyzed patch submission and acceptance in the linux kernel project which is using a preliminary pull based development model and found that through time contributions are becoming more frequent while code reviews are taking less time.
as the change submission and integration models evolve so do the evaluation processes.
bacchelli and bird refer to lightweight branch based peer reviews as modern code review.
this kind of peer review is similar to the reviews taking place in pull based development in many aspects with an important difference the process for accepting a contribution is pre determined and requires sign off by a specific number of integrators.
they find that while the stated purpose of modern code review is finding defects in practice the benefits in knowledge transfer and team awareness outweigh those stemming from defect finding.
in a similar quantitative study rigby and bird analyzed branch based code review processes in oss and commercial systems and found that reviewed patches are generally very small while two reviewers find an optimal number of defects.
in recent work gousios et al.
and tsay et al.
investigated quantitatively what factors underline the acceptance of contributions in pull based development both find similar effects but the dominating factors hotness of project area and social distance respectively are vastly different.
this difference suggests that there may be no underlying processes for contribution evaluation in pull based development that are in effect across projects.
in turn this calls for a more indepth qualitative study to help us understand how integrators evaluate contributions.
initial qualitative evidence on how integrators assess contributions has been reported by pham et al.
but the focus of this work was the evaluation of testing practices rather than the pull based development model.
a number of social aspects also affect the evaluation of contributions.
duchneaut found that developers looking to get their contributions accepted must become known to the core team .
then core team members would use the developer s previous actions as one of the signals for judging contributions.
similarly krogh et al.
found that projects have established implicit joining scripts to permit new developers to contribute to the project according to which theyexamine the developers past actions to permit access to the main repository.
there is no empirical evidence on whether the developer s previous actions play a significant role in contribution assessment in the context of pull based development in fact quantitative data from gousios et al.
suggest otherwise.
finally marlow et al.
found that developers on github use social signals such as the developer s coding activity and the developer s social actions e.g.
following other developers in order to form an impression of the quality of incoming contributions.
iii.
r esearch questions our examination of the literature revealed that while several researchers have examined how developers evaluate contributions and collaborate in the context of oss or more recently github no work has examined yet how integrators perceive pull based development.
with pull based development rapidly rising in popularity it is important to expand our understanding of how it works in practice and what challenges developers in general and integrators in particular face when applying it.
consequently our first question explores how integrators employ the pull based development model in their projects at the project level rq1 how do integrators use pull based development in their projects?
to make the analysis easier we further refine rq1 in the following subquestions rq1.
how do integrators conduct code reviews?
rq1.
how do integrators merge contributions?
after a contribution has been received the integrators must decide whether it is suitable for the project or not.
recent quantitative work identified that across projects simple factors such as the recent activity of the project area affected by the contribution and social distance between the contributor and the integrator can be used to predict whether a contribution will be accepted or not.
what criteria do the integrators use to make this decision?
this motivates our second research question rq2 how do integrators decide whether to accept a contribution?
when evaluating contributions in collaborative environments a common theme is quality assessment .
in the context of pull based development the asynchrony of the medium combined with its high velocity may pose additional e.g.
timing requirements.
it is beneficial to know what factors the integrators examine when evaluating the quality of a contribution and what tools they use to automate the inspection as the results may be used to design tools that automate or centralize the evaluation process.
therefore our third research question is as follows rq3 how do the integrators evaluate the quality of contributions?
on busy projects or in projects with busy integrators contributions can pile up.
it is not uncommon for large projects for example ruby on rails to have more than pullrequests open at any time.
how do integrators cope with such a situation?
how do they select the next contribution to work on when many need their immediate attention?
this leads to our fourth research question rq4 how do the integrators prioritize the application of contributions?
the challenges of online collaboration have been a very active field of study also in the field of distributed software development .
the pull based development setting is unique the asynchrony between the production of the code and its integration in a project s code base along with the increased transparency afforded by platforms like github theoretically allow contributors and integrators to co ordinate more efficiently.
but is this so?
how do integrators perceive the theoretical advantages of pull based development in practice?
by understanding the challenges that integrators face when applying pull based development in their projects we may better understand the limits of the pull based method and inform the design of tools to help them cope with them.
this leads to our final research question rq5 what key challenges do integrators face when working with the pull based development model?
iv.
s tudy design we conduct a mixed methods exploratory study using mostly qualitative but also quantitative data that consists of two rounds of data collection.
in the first round we run a pilot survey among a limited set of selected integrators.
after analyzing the results of the first round we identify emerging themes specifically quality and prioritization which we addressed by including related questions in the second round.
the survey results of the second round were further augmented and partitioned by quantitative results for each specific project.
in this section we describe our research method in detail.
a. protocol since our aim is to learn from a large number of projects we use surveys which scale well.
survey design the study takes place in two rounds a pilot round that can give us the opportunity to field test our initial questions and the final round through which we gather the actual responses.
both surveys are split into three logical sections demographic information multiple choice or likert scale questions and open ended questions.
the open ended questions are intermixed with multiple choice ones usually the developer has to answer an open ended question and then a related one with fixed answers.
to further elicit the developer s opinions in all questions that have predefined answers but no related open ended question we include an optional other response.
finally throughout the survey we intentionally use even likert scales to force participants to make a choice.
overall and excluding demographic questions the survey includes openended questions likert scale questions with an optionalopen ended response and multiple choice questions with no optional fields.
the respondents could fill in the survey in about minutes.
the purpose of the survey pilot is to identify themes on which we should focus the main survey.
as such the pilot survey includes fewer open ended questions but all multiple choice questions have optional open ended reply fields.
this allows us to test our initial question set for strongly correlated answers we removed several potential answers from multiple choice questions and identify two topics namely quality and prioritization which we address in the main survey round.
attracting participants in previous work we presented evidence that most repositories on github are inactive single user projects.
to ensure that our sample consists of repositories that make effective and large scale use of pull requests we select all repositories in our ghtorrent dataset that have received at least one pull request for each week in the year repositories .
for each repository we extract the top pull request integrators by the number of pull requests that they have merged and send an email to the first developer whose email is registered with github.
for the pilot phase we emailed of those integrators randomly and received answers answer rate .
for the data collection phase we emailed integrators from the remaining projects and received answers answer rate .
the survey was published online and its web address was sent by personal email to all participants.
we did not restrict access to the survey to invited users only.
in fact several survey respondents forwarded the survey to colleagues or advertised it on social media twitter without our consent.
after comparing the response set with the original set of projects we contacted we found that of the responses came through third party advertising of the survey.
the survey ran from apr to may .
to encourage participation we created a customized project report for each of the emailed integrators.
the report includes plots on the project s performance in handling pull requests e.g.
mean close time on a monthly basis.
the reports for all projects have been published online2and were widely circulated among developers.
of the survey respondents also expressed gratitude for their report through email.
b. participants the majority of our respondents self identified as project owners while work for industry.
most of them also have more than years of software development experience and considerable experience years in geographically distributed software development .
an overview of the respondents profiles can be found in figure .
to identify the leading groups of respondents based on the combined effect of experience role in the project and work place we ran the kmodes clustering algorithm a variation of kmeans for categorical data on the dataset.
the clustering results revealed that1 3of the respondents are project project owner or co owner source code contributor documentation contributor other please specify developer roles 35432the industry the academia the government open source softwaredevelopers work for 415334no yesworking exclusively on repository developer experience years developer experience distributed software development years never developer experience open source software years fig.
respondent demographics owners with more that years of industrial experience of those around also worked exclusively on the projects they responded about.
c. analysis we applied manual coding on the seven open ended questions as follows initially three of the four authors individually coded a different set of out of answers for each question.
at least one and up to three codes were applied to each answer.
the extracted codes were then grouped together and processed to remove duplicates and in cases to generalize or specialize them.
the new codes were then applied on all answers.
when new codes emerged they were integrated in the code set.
on average more codes were discovered because we decided to code the full dataset.
finally the order of code application reflected the emphasis each answer gave on the code topic.
in the survey we asked integrators to optionally report a single repository name for which they handle most pull requests.
of the respondents did so.
for the remaining answers we either resolved the repository names from the developer s emails since integrators were invited to participate based on a specific email or by selecting the most active project the developer managed pull requests for while we also fixed typos in repository names.
we excluded from further analysis answers for which we could not obtain a repository name answers .
after we resolved the repository names we augmented the survey dataset with information from theghtorrent database .
specifically for each project we calculated the mean number of pull requests per month and the mean number of integrators for the period july to july .
using those metrics and for each one of them we split the project population in three equally sized groups small medium and large .
finally we excluded answers from projects that received no pull request in this time frame answers .
none of these were in our original contact list.
v. r esults in this section we present our findings per research question.
to enable traceability we include direct quotes from integrators along with the answer identified in our dataset e.g.
r1 corresponds to answer .
similarly in the case of coded open ended questions we present the discovered codes slanted.
a. rq1 how do integrators use pull based development in their projects?
overall use to understand why and how projects use the pull based development model we asked integrators a multiple choice question that included the union of potential uses of pull requests that have been reported in the literature .
respondents also had the opportunity to report other uses not in our list.
the results show figure that projects use pull requests for a multitude of reasons.
overwhelmingly of the integrators use the pull based development model for code reviews and resolvesoliciting contributions from external partiesreviewing codediscussing new features before those are implementeddistributing work and tracking progressissue fixesother percentage of projectsanswer i insist on pull requests being split per feature i merge pull requests fast to ensure project flow i prefer pull requests to be tied to an open issuei am pedantic when enforcing code and documentation style i ask for more work as a result of a discussion i close pull requests fast in case of unresponsive developers i try to restrict discussion to a few comments i try to avoid discussion percentageresponse never occasionally often alwaysq24 what is your work style when dealing with pull requests?
a use github facilities the merge button pull the proposed branch locally merge it with a project branch and then push squash the commits of the proposed branch merge it with a project branch and then push create a textual patch from the remote branch apply this to a project branch and then push percentageresponse never occasionally often alwaysto merge pull requests integrators i review code in all pull requestsi delegate reviewing to more suitable code reviewersi use inline code comments in pull requestsi only review code in commitscode review is obligatory for a pull request to be mergedthe community participates in code reviewsother percentage of projectsanswer fig.
how projects use pull requests issues.
perhaps more interesting is that half of the integrators use pull requests to discuss new features as r710 commented experimenting with changes to get a feel if you are on the right path .
this is a variation of the github promoted way of working with pull requests 3where a pull request is opened as early as possible to invite discussion on the developed feature.
of the integrators use pull requests to solicit contributions from the community which seems low given the open nature of the github platform.
we examined this response quantitatively using the ghtorrent database indeed for percent of the projects that responded no pull request originated from the project community.
there is a small overlap between projects responding that they do not use pull accessed jul 2014requests to solicit contributions from the community and those that actually did not receive a pull request.
moreover another of the projects reported that they have used pull requests to solicit contributions from the community even though they did not receive any external pull requests.
only or of the respondents indicated that they use pull requests for something else.
the analysis of the answers reveals that the majority of the replies nevertheless aligns with the offered choice answers with two notable exceptions.
respondent r635 mentions that they use pull requests in every commit we make.
we have a policy of having every commit even bumping up version number for next release coming in on a pr.
.
the project has effectively turned pull requests into a meta version control system one that only allows reviewed code to be merged.
this merging behaviour27 new featuresbug fixes refactorings excluding changes required for the above percentageresponse non existent once per month once per week dailyhow often do the following types of pull requests occur in your project?
new features bug fixes refactorings excluding changes required for the abovelargemediumsmall largemediumsmall largemediumsmall percentageresponse non existent once per month once per week dailyhow often do the following types of pull requests occur in your project?fig.
types of contributions according to project size.
is also in place within microsoft and in the android project .
another integrator is using pull requests as a time machine mechanism r521 ideally any change because using prs makes it easier to rollback a change if needed .
types of contributions following leintz and swanson we distinguish perfective implementing new features corrective fixing issues and adaptive preventive refactoring maintenance.
we asked integrators how often they receive contributions for these types of maintenance activities.
percent of the projects receive bug fixes as pull requests once a week half of them receive new features once a week while only of them receive a refactoring more often than once a week.
what is more interesting though is the distribution of responses per project size as this is reflected by the number of pull requests a project gets per month.
large projects receive bug fixes through pull requests almost daily whilemore than of them receive proposed refactorings weekly.
moreover we observe important differences between large and medium projects in both frequencies of incoming refactorings and bug fixes.
intuitively integrating refactorings is typically more difficult than integrating bug fixes we therefore expect large projects to face significant problems with prioritizing the order of application of pull requests so as to avoid conflicts.
for small projects the most frequent type of maintenance activity is corrective maintenance even though the frequency of incoming changes is not as high.
overall integrators had little reservation to integrate pullbased development in their maintenance lifecycle as can be seen .
this is an indication that pull based development is not only suitable as a patch submission mechanism the reason it was designed for but also as an integral part of how projects are developed.
in turn this calls for a revision of how development methods regard source code patches instead of featuring just ad hoc changes they are increasingly being used as the atomic element of software change.
code reviews in the time between a contribution submission and before it is accepted it becomes a subject of inspection.
of the projects indicate that they do explicit code reviews on all contributions only of the projects do not do either but those have specified alternative ways of code reviews as described below .
on github anyone can participate in the inspection process.
of the integrators report that the project s community people with no direct commit access to the repository actively participates in code reviews this is in contrast with gousios et al.
where we found that in all projects we examined the community discussing pull requests was bigger than the core team.
in current code reviewing practices using tools such as gerrit or codeflow code review comments are intermingled with code and a predetermined approval process is in place.
github offers a more liberal code reviewing system where users can provide comments on either the pull request as a whole the pull request code or even in individual commits comprising the pull request but imposes no approval process.
of the integrators use inline code comments in the pull request to do code reviews only of the integrators report that they use commit comments.
the absence of strict acceptance process support has created a market for code reviewing tools of the or of the integrators that indicated they are code reviews in another way or mentioned that they are explicitly using a different tool for code reviews.
projects have established processes for code reviews.
one of them is delegation of the integrators delegate a code review if they are not familiar with the code under review.
delegation is again not a strictly defined process on github by convention it can occur by referencing username a user name in the pull request body but integrators report other ways to delegate work for example r62 uses video conferencing to discuss pull requests and assign work load while others e.g.
r577 r587 use external tools with support for delegation.
another process is implicit sign off at least 20integrators reported that multiple developers are required to review a pull request to ensure high quality.
typically this is reviewers e.g.
r481 we have a rule that at least of the core developers must review the code on all pull requests.
.
rigby and bird also report a similar finding in gerrit based industrial projects .
integrating changes when the inspection process finishes and the contributions are deemed satisfactory they can be merged.
a pull request can only be merged by core team members.
the versatility of git enables pull requests to be merged in various ways with different levels of preservation of the original source code properties.
briefly a pull request can be integrated either through github s facilities or a combination of low level gitcommands such as merge or cherry pick .
we gave integrators a list of ways to perform merges as identified in and asked them how often they use them but also allowed them to describe their own.
in of the cases integrators use the github web interface often or always to do a merge this number is actually close to what we obtained by quantitatively analyzing pull requests in and .
only in and of the cases do integrators resort to cherrypicking or textual patches respectively to do the merge.
as identified by the integrators in the comments the command line gittool is mostly used in advanced merging scenarios where conflicts might occur.
also or of the respondents mentioned that they are using rebasing history rewriting in the following ways i placing the new commits in the source branch on top of the current ones in the target branch e.g.
r306 and r316 which effectively merges the two branches while avoiding redundant merge commits and ii asking the contributor to squash pull request commits into one before submitting the pull request.
moreover integrators indicated that they allow their continuous integration system to do the merge e.g.
r157 or use scripts to automate merges between feature branches e.g.
r321 .
overall integrators emphasize the preservation of commit metadata by avoiding textual patches and cherry picking while some of them use history rewriting to avoid the formation of complicated networks of branches and merges.
rq1 integrators successfully use the pull based model to accommodate code reviews discuss new features and solicit external contributions.
of the integrators conduct explicit code reviews on all contributions.
integrators prefer commit metadata preserving merges.
b. rq2 how do integrators decide whether to accept a contribution the second research question elicits the signals that integrators use to decide on the fate of a contribution.
we asked integrators an optional open ended question and received answers.
the results are summarized in figure 5a.
the decision to accept the most important factor leading to acceptance of a contribution is its quality.
quality has many manifestations in our response set integrators examine thesource code quality and code style of incoming code along with its documentation andgranularity code style and whether or not it matches project style.
overall programming practice lack of hacks and workarounds.
r32 .
at a higher level they also examine the quality of the commit set and whether it adheres to the project conventions for submitting pull requests.
a second signal that the integrators examine is project fit .
as respondent r229 states the most important factor is if the proposed pull request is in line with the goals and target of the project .
a variation is technical fit does the code fit the technical design of the project r90 most important to us is that the contribution is in keeping with the spirit of the project s other apis and that its newly introduced code follow the total and functional style of the rest of the codebase ?
integrators also examine the importance of the fix feature with respect to the current priorities of the project.
this is common in case of bug fixes if it fixes a serious bug with minimal changes it s more likely to be accepted.
r131 .
a third theme that emerged from the integrator responses is testing.
apart from assessing the quality of contributions using higher level signals integrators also need to assess whether the contributed code actually works.
initially integrators treat the existence of testing code in the pull request as a positive signal.
success of test runs by a continuous integration system also reinforces trust in the code all tests must pass integration testing on all supported platforms.
.
.
r94 .
finally integrators resort to manual testing if automated testing does does not allow them to build enough confidence if other developers verified the changes in their own clones and all went fine then we accept.
r156 .
it is interesting to note that the track record of the contributors is ranked low in the integrator check list.
this is in line with our earlier analysis of pull requests in which we did not see a difference in treatment of pull requests from the core team or from the project s community .
finally technical factors such as whether the contribution is in a mergeable state its impact on the source code or its correctness are not very important for the eventual decision to merge to the majority of respondents.
in such cases integrators can simply postpone decisions until fixes are being provided by the contributors .
.
.
occasionally i go through discussion with committer on how to do things better or keep the codestyle held in the whole project r300 .
the postponing effect has also been observed by rigby and storey .
reasons to reject an issue related to acceptance is that of rejection.
why are some pull requests rejected?
intuitively we would expect that negating one or more acceptance factors e.g.
the pull request code is bad style wise or tests are missing should be a reason enough to reject a pull request.
nevertheless we gave integrators a list of reasons for which a pull request can be rejected and asked them to indicate the top .
the list corresponded to the rejection reasons we identified by manually analyzing rejected pull requests in .
the integrators were also free to identify new reasons.
overall the top three reasons for rejection identified by integrators are technical quality of the projects testing38 existence of tests in the pull request number of commitsnumber of changed lines number of discussion commentspull requester track recordpull request affects hot project area percentageresponse not important mildly important quite important very importantimportance of factors to the decision to accept a pull request a importance of factors to the decision to accept a pull request.
mergabilityimpactcontributor track recordcorrectnesspr qualityresponsivenessdiscussionproject conventionsgranularityworksreviewedfeature importancedocumentationtestingtechnical fitproject fitcode stylecode quality percentage of responsesrank topsecond third b what affects the decision to accept a pull request existence of tests in the pull requestexistence of tests in the project number of commitsnumber of changed lines number of discussion commentspull requester track recordpull request affects hot project area percentageresponse not important mildly important relatively important very importantimportance of factors to the time to make the decision to accept a pull request c importance of factors to the decision to accept a pull request.
project conventionscontrib track recordtechnical qualityhotnessworkloadreviewedcommit qualitydocumentationmergabilitycode styleimpacttestingimportanceproject schedulingcode qualitydiscussionresponsivenesscomplexityreviewer availability percentage of responsesrank topsecond third d what affects the time to decide on a pull request.
the pull request conflicts with another pull request or brancha new pull request solves the problem betterthe pull request implements functionality that already exists in the projectexamination of the proposed feature bug fix has been deferredtests failed to run on the pull requestthe implemented feature contains technical errors or is of low qualitythe pull request does not follow project conventions style other percentage of projectsanswer e common reasons for rejection.
fig.
acceptance and rejectionfailures and failures to follow project conventions .
from the open ended answers only one new reason emerged namely the unresponsiveness of the pull request submitter .
time to make a decision the factors that strongly affect the time to make a decision are mostly social and as expected have timing characteristics as well.
the most important one affecting of the projects is reviewer availability .
the problem is more pronounced in projects with small integrator teams and no full time paid developers.
another social factor is contributor responsiveness if the pull request contributor does not come back to requests for action fast the evaluation process is stalled.
long discussions also affect negatively the time to decide but they are required for reaching consensus among core team members especially in case of controversial contributions e.g.
r22 r81 r690 .
for changes that have not been communicated before discussions are also mandatory if the change is out of the blue or if it has been discussed with the other developers up front.
r287 technical factors such as the complexity of the change code quality code style and mergability of the code also affect negatively the time to decide on a pull request.
the reason is that the code inspection reveals issues that need to be addressed by the contributors.
rq2 integrators decide to accept a contribution based on its quality and its degree of fit to the project s roadmap and technical design.
c. rq3 what factors do the integrators use to examine the quality of contributions?
when examining contributions quality is among the top priorities for developers.
with this research question we explore how integrators perceive quality and what tools they use to assess it by means of a pair of compulsory open ended and multiple choice questions.
the results are summarized in figure .
perception one of the top priorities for integrators when evaluating pull request quality is conformance .
conformance can have multiple readings for r39 conformance means it matches the project s current style or at least improve upon it project style while for r155 conformance is to be evaluated against fitting with internal api usage rules architecture fit .
many integrators also examine conformance against the programming language s style idioms e.g.
pep8 for python code .
integrators expect the contributed code to cause minor friction with their existing code base and they try to minimize it by enforcing rules on what they accept.
integrators often relate contribution quality to the quality of the source code it contains.
to evaluate source code quality they mostly examine non functional characteristics of the changes.
source code that is understandable andelegant has good documentation and provides clear added value to the project with minimal impact is preferred.
apart from source code the integrators use characteristics of the pull request as proxies to evaluate the quality of the submission.
the quality or even the existence of thepull request documentation signifies an increased attention to detail by the submitter a submitter who includes a clear description of what their pull request does have usually put more time and thought into their submission r605 .
the integrators also examine the commit organization in the pull request well written commit messages one commit about a single subsystem each commit compiles separately r610 and its size.
in the later case the integrators value small pull requests as it is easier to assess their impact r246 .
.
.
the code has the minimum number of lines needed to do what it s supposed to do or r330 is the diff minimal?
.
testing plays an important role in evaluating submissions.
initially the very existence of tests in the pull request is perceived as a positive signal.
the integrators also examine whether the changes in the pull request are covered by existing or new tests test coverage while in of the cases they report that they exercise the changes manually manual testing .
moreover in performance critical code performance degradation is frowned upon and in some cases integrators require proof that performance is not affected by the proposed change e.g.
in r72 performance related changes require test data or a test case .
finally integrators use social signals to build trust for the examined contribution.
the most important one is the contributor s reputation .
the integrators build a mental profile for the contributor by evaluating their track record within the project r405 who submitted the pr and what history did we have with him her?
or by searching information about the contributor s work in other projects r445 looking at the other contributions in other projects of the pull author .
some integrators also use interpersonal relationships to make judgements for the contributor and by proxy for their work.
the process of impression building through social signals has been further elaborated by marlow et al.
.
tools quality evaluations can be supported by tools.
to evaluate how often projects use tools we gave integrators a selection of tools and asked them which ones they use in their projects.
the vast majority of projects use continuous integration either in hosted services or in standalone setups.
continuous integration services such as travis and cloudbees allow projects to run their test suites against incoming pull requests while integration with github enables them to update pull requests with test outcomes.
on the other hand few projects use more dedicated software quality tools such asmetric calculators or coverage reports .
it is interesting to note that practically all projects that use more advanced quality tools run them through continuous integration.
integrators responded that they are using other tools.
by going through the responses we see that integrators use a rather limited toolset.
specifically only a handful of integrators reported that they are using linting tools4while dedicated static analysis tools are used in just two large scale c projects in our sample.
in two more cases the integrators 4tools that find common mistakes e.g.
uninitialized variablestechnical correctnessroadmaparchitecture fitsimplicitycommunication discussionchange localityquality check automationclear purpose performancecommit qualityadded valuetest manualsizeproject conventionsauthor reputationexperienceunderstandabilitydocumentationtest resultcode reviewcode qualitytest coveragestyle conformance percentage of responsesrank topsecond third a factors the developers examine when evaluating the quality of contributions.
continuous integration i.e.
via travis jenkins cloudbees manual test executioncode quality metrics i.e.
via code climate or sonar coverage metricsformal code inspections from specialized testersother percentage of projectsanswer b tools used for quality evaluations.
fig.
contribution quality examination.
reported that they rely on the language s type system to eliminate bugs.
finally the majority of integrators answered that they evaluate the quality manually e.g.
r291 my brain is a powerful testing environment or r353 good eyes and many eyes even when they were asked what tools they are using to do so.
rq3 top priorities for integrators when evaluating contribution quality include conformance to project style and architecture source code quality and test coverage.
integrators use few quality evaluation tools other than continuous integration.
d. rq4 how do the integrators prioritize the application of contributions?
our fourth research question examines the factors integrators use to prioritize their work on evaluating contributions.
to discover them we asked integrators a compulsory open ended question.
the results are summarized in figure .
the first thing that integrators examine is the contribution s urgency .
in case of bug fixing contributions the criticality of the fix is the most important feature to prioritize by.
integrators examine at least the following factors to assess criticality i the contribution fixes a security issue ii the contribution fixes a serious new bug iii the contribution fixes a bug that other projects depend upon and iv number of issues blocked by the unsolved bug.
in the case of a contribution implementing new features integrators examine whether the contribution implements customer requested features or features required for the development of other features.
several integrators also mentioned that they just examine the type of the contribution before itscriticality it is usually project policy to handle bug fixing contributions before enhancements as is the case with r446 bug fixes first then new features.
only if all bug fix pull requests are treated.
the pull request ageplays an important role in prioritization for integrators.
it is interesting to note that many integrators prefer a first in first out treatment of the pull requests before applying other prioritization criteria.
similarly easy to assess and therefore less complex pull requests are preferred by integrators.
the size of the patch even through usually related to complexity is used to quickly filter out small easy to integrate contribution and process them first e.g.
r490 the lower the number of lines files changes the more likely i am to process it first.
thecontributor s track record is a relatively important factor for prioritization and usually known contributors get higher priority.
as r82 states it if i know the person they get high priority.
sorry strangers.
.
a related criterion is the contributor s origin if the contributor is another core team member or in business settings a colleague some projects assign priorities to his her contributions e.g.
r106 r183 r411 while some others specifically favour community contributions e.g.
r161 r398 .
finally it is interesting to note that of all integrators in our sample are not using any prioritization processes at all.
when prioritizing contributions integrators must apply multiple criteria in a specific sequence.
figure 6a depicts the frequencies of prioritization criteria usage for all reported application sequences.
what we can see is that criticality urgency and change size contribute to most prioritizationage complexity contributor origin contributor track record criticality of fix dependencies existence of tests impact merge conflicts project roadmap quality review cycle reviewer availability reviewer familiarity size of change type urgency of feature age complexity contributor origin contributor track record criticality of fix dependencies existence of tests impact merge conflicts project roadmap quality relevance to project review cycle reviewer availability reviewer familiarity size of change test result type urgency of feature age complexity contributor origin contributor responsiveness contributor track record criticality of fix dependencies existence of tests impact merge conflicts project roadmap quality relevance to project review cycle reviewer availability reviewer familiarity size of change test result type urgency of feature no 3rd criterion a factors used for prioritization and their order of application left to right .
the thickness of each line corresponds to the frequency the particular prioritization order appeared in our response set.
i delegate to devs more experienced with the specific subsystem i process them serially i just discard very old pull requestsi discard too discussedi trust pull requests from reputed pull requestersi assess the technical quality of the pull request percentageresponse never occasionally often alwayshow do you triage pull requests?
fig.
triaging and prioritization.
criteria application sequences while most integrators report that they apply at most two prioritization criteria.
rq4 integrators prioritize contributions by examining their criticality in case of bug fixes their urgency in case of new features and their size.
bug fixes are commonly given higher priority.
one fifth of the integrators do not prioritize.
e. rq5 what key challenges do integrators face when working with the pull based development model?
we asked integrators an optional open ended question and received answers.
we found two broad categories of challenges technical challenges hamper the integrator s ability to work effectively while social challenges make it difficult for integrators to work efficiently with other project members.
technical challenges at the project level maintaining quality is what most integrators perceive as a serious challenge.
as incoming code contributions mostly originate from non trusted sources adequate reviewing may be required by integrators familiar with the project area affected by it.
reviewer availability is not guaranteed especially in projects with no funded developers.
often integrators have to deal with solutions tuned to a particular contributor requirement or an edge case asking the contributor to generalize them to fit the project goals is not straightforward.
a related issue is feature isolation contributors submit pull requests that contain multiple features and affect multiple areas of the project.
as put by r509 huge unwieldy complected bundles of hey iadded a lot of features and fixes all at once!
that are hell to review and that i d like to partially reject if only the parts were in any way separable... .
several issues are aggravated the bigger or more popular a project is.
integrators of popular projects mentioned that thevolume of incoming contributions is just too big e.g.
ruby on rails receives on average new pull requests per day consequently they see triaging and work prioritization as challenges.
as requests are kept on the project queue they age the project moves ahead in terms of functionality or architecture and then it is difficult to merge them without real or logical conflicts .
moreover it is not straightforward to assess the impact of stale pull requests on the current state of the project or on each other.
another category of technical challenges is related to the experience of the contributor.
integrators note that aspiring contributors often ignore the project processes for submitting pull requests leading to unnecessary communication rounds.
when less experienced developers or regular users attempt to submit a pull request they often lack basic git skills e.g.
r42 lack of knowledge of git from contributors most don t know how to resolve a merge conflict.
.
new contributors can be a valuable resource for a project integrators report that they avoid confrontation in an effort to onboard new users.
many of the challenges reported by the integrators are bound to the distributed nature of pull based development.
lack of responsiveness on behalf of the contributor hurts the code review process and by extension project flow.
this isaccepting blamecommunicating goals and standardscontext switchingmultiple communication channelsreaching consensuspoor notificationsproject speedprocess ignorancetimezonescoordination among contributorscoordination among integratorsimpactpolitenessasking more workbikesheddinghit n run rpspoor documentationagesyncingfeature isolationdeveloper availabilityconflictsdifferences in opinionmotivating contributorsgeneralizing solutionstoolsgit knoweledgesizereview toolstestingresponsivenessmaintain visionvolumeexplaining rejectionreviewingmaintaining qualitytime .
.
.
.
percentage of responsesrank topsecond thirdfig.
biggest challenges when working with the pull based development model.
especially pronounced in the case of hit and run pull requests as they place additional reviewing and implementation burden on the integrator team.
integrators mention that the lack of centralized co ordination with respect to project goals can lead to chaos.
lots of people trying to reach the same goal without coordinating r155 .
finally integrators also report inefficiencies in the github platform itself.
specifically many integrators complained about the quality of the code review tool offered by github r567 a good code review tool with code analysis possibilities can help and made comparisons to their favourite ones e.g.
r288 the mechanism itself is a huge step backwards from reviewboard while others did not like the way github handles notifications e.g.
r514 sifting through the github information flood to find what if any i should address.
.
social challenges integrators often have to make decisions that affect the social dynamics of the project.
integrators reported that explaining the reasons for rejection is one of the most challenging parts of their job as hurting the contributor s feelings is something they seek to avoid.
as r255 explains telling people that something is wrong without hurting their feelings or giving them an incorrect idea of my intentions.
.
similarly integrators find that asking for more work from the contributors e.g.
as a result of a code review can be difficult at times as they .
.
.
worry about alienating our valued contributors r635 .
motivating contributors to keep working on the project even in the face of rejected contributions is not easy for integrators either.
reaching consensus through the pull request comment mechanism can be challenging.
integrators often find themselves involved in a balancing act of trying to maintain 5r708 describes hit and run pull requests nicely they contributors send a pull request with a bug but when i ask them to fix them then they just vanish and don t respond to github e mails.
their own vision of the project s future and incorporating or rejecting contributions that are tuned to the contributor s needs.
differences in opinion compared to the relative anonymity of the pull request comment mechanism can lead to unpleasant situations.
integrators may need to take action to maintain discussion etiquette e.g.
r449 dealing with loud and trigger happy developers.
enforce politeness rules or to stop long unhelpful bikeshedding discussions r586 be objective and avoid off topics in discussions .multiple communication channels are not helping either integrators find it difficult to synchronize between multiple sources.
on a more personal level integrators find it difficult to handle the workload imposed by the open submission process afforded by the pull based development model.
for many of our respondents managing contributions is not their main job consequently finding free time to devote on handling a pull request and context switching between various tasks puts a burden on integrators.
as r470 notes managing pull requests is not my full time job but it is a component of it.
mostly it is difficult to keep track of them while also completing my other tasks.
.
rq5 integrators are struggling to maintain quality and mention feature isolation and total volume as key technical challenges.
social challenges include motivating contributors to keep working on the project reaching consensus through the pull request mechanism and explaining reasons for rejection without discouraging contributors.
vi.
d iscussion in this section we compare and contrast our findings with existing work and present future work directions.
a. quality throughout our analysis the issue of quality evaluation was recurring.
the respondents directly linked quality with acceptance while also described maintaining quality as a big challenge.
according to integrators quality emerges from attention to detail code style documentation commit formatting and adherence to project conventions all help to build confidence in the contribution.
the issue of quality evaluation has been repeatedly mentioned in works on patch submission lightweight code review and testing in this sense our work reinforces earlier findings.
in addition we document in detail what factors integrators examine in contributions when quality assessments.
an open question is how to efficiently automate the quality evaluation for pull requests.
while tools that automate the evaluation of many tasks that the developers do to determine quality e.g.
code style analyzers test coverage metrics for software quality impact analysis etc do exist we have seen that developers go little beyond testing and continuous integration.
to solve this issue one could envisage a pluggable platform that given a pull request update runs a suite of tools and automatically updates the pull request with a configurable quality score.
for the platform to be useful it will have to automatically learn from and adapt to project specific behaviours.b.
testing integrators overwhelmingly use testing as a safety net when examining contributions.
the inclusion of tests in a contribution is perceived as a positive signal while reverse coverage is evaluated by many integrators.
of our respondents run tests automatically through continuous integration services.
pham et al.
examined how testing works on github our work confirms many of their findings e.g.
use of testing as a quality signal manual examination when continuous integration fails and complements it with more quantitative data about test diffusion on github projects.
moreover it is interesting to pinpoint the contradiction with the results of our previous work where we found that inclusion of test code in a contribution was not a strong factor influencing either the decision to accept or the time to decide tsay et al.
report a similar result .
we speculate that this difference is due to how we modeled test inclusion continuous rather than a dichotomous feature in our previous study.
c. work prioritization in large projects integrators cannot keep up with the volume of incoming contributions.
a potential solution could be a recommendation system that provides hints on which contributions need the integrator s immediate attention.
existing work on assisted bug triaging e.g.
or is not directly applicable to the pull based model as a pull request is not necessarily as static as a bug report.
researchers might need to come up with different methods of work prioritization that take into account the liveness and asynchrony of the pull request model.
our analysis of how developers prioritize contribution is a first step in this direction.
d. developer track records one finding of this work is that a developer s track record while present in our response set is not a commonly used criterion to assess or prioritize contributions by.
with the raise of transparent work environments and based on previous work on the subject one would expect that the developer s track record would be used by the majority of integrators to make inferences about the quality of incoming contributions.
despite this the track record is mostly used as an auxiliary signal in both figure 5a and figure 6a we can see that developers equally mentioned the track record as top and second criterion for quality evaluation and prioritization.
e. community building community building through collaboration has been studied extensively in the context of oss projects .
a common theme in those studies is that recruitment of new developers can be challenging as core teams are reluctant to give access to the main repository without an initiation process .
integrators in our study actually mentioned the opposite it is maintaining the community momentum and motivating contributors to do more work that is not easy.
through transparency and lowered barriers to participation the pull based model can act as glue for communities buildaround projects if integrators are keen enough on fostering their project s communities by helping newcomers cope with tools and project processes prioritizing the examination of community contributions and in the extreme case not rejecting unwanted contributions.
f .
a modern theory of software change in the recent years we are witnessing that collaborative lightweight code review is increasingly becoming the default mechanism for integrating changes in both collocated and distributed development.
effectively the pull request in various forms is becoming the atomic unit of software change.
existing works e.g.
neither did anticipate lightweight code reviews nor asynchronous integration of changes.
this work can contribute to theory building by providing empirical evidence about the common practices of pull based development.
vii.
l imitations we carefully designed the survey to gain insight into the work practices and challenges faced by integrators in pullbased development.
we thoughtfully crafted the wording of each of the questions to avoid ambiguous or leading questions refining them through small pilot tests and consults with other researchers with survey research expertise and refined the questions yet further through a larger pilot study.
the response categories we supplied for many of the questions were based on the existing literature and were likewise refined through the pilot studies.
for the questions that had multiple response options we supplied an additional other field which was used to uncover responses not considered that we later coded.
despite our best efforts this work may be subject to the following limitations generalizability since we did purposive sampling from the population of integrators the findings may not apply to other populations of integrators e.g.
developers using other tools integrators that work private projects on github or integrators that are not in the top three integrators for a given project .
moreover in previous work we found that the median number of pull requests across repositories is in our sample the smallest project had more than .
we expect that if the study is repeated using random sampling for projects the results will be slightly different as the average project does not use pull requests in a high capacity.
furthermore the integrators that responded to our survey may have introduced an additional bias to the results non responders may have had different insights or opinions .
researcher bias it is possible that researcher bias may have influenced the wording of questions perhaps to be leading as well as the coding of the open ended questions.
as discussed above we tested the questions through pilots and had experts evaluate it for this concern.
in terms of the analysis of the open ended questions we conducted a pilot study and three of us separately coded a sample of the responses to derive these codes.research reactivity the ordering of questions one may provide context for the next one the open ended questions as well as a respondent s possible tendency to to appear in a positive light for example they wish to think they are fair or logical may have influenced the accuracy of the answers provided.
viii.
c onclusions our work studies the pull based development model from the integrator s perspective.
our goal is to better understand the work practices of integrators working with the pull based development model and to identify the challenges they face when integrating contributions.
the key contributions of this paper are as follows a novel way of using the ghtorrent dataset to generate targeted reports large scale surveys and augmenting qualitative datasets with quantitative data.
a publicly available data set with anonymized survey answers.
a thorough analysis of survey data resulting in answers to our research questions on topics such as work practices in pull based development quality evaluation of contributions work prioritization and open challenges when working with pull requests.
our anonymized response set our coded open ended questions and custom built r based analysis and plotting tools are available in the github repository gousiosg pullreqs survey.
this data set complements existing quantitative data sets e.g.
our own widely used ghtorrent data set and provides much needed context for analyzing and interpreting that data.
furthermore our survey brings additional insights to the insightful but smaller scale interviews that have been conducted by other researchers on the pull based model e.g.
.
we welcome replications of this work potential directions include replications with integrators that use different non github repositories e.g.
bitbucket work on private repositories and work on non pull request intensive projects.
these replications will help in moving towards a theory of how pull based development impacts distributed software development.
last but not least our findings point to several research directions see section vi and have implications for both practice and research.
based on our results integrators can structure their contribution evaluation processes in an optimized way and be informed about common pitfalls in community management.
researchers can reuse our research methods and datasets to conduct large scale mixed methods research while they can use our research findings as a basis to drive their work on pull request quality evaluation and work prioritization tools.