active hotspot an issue oriented model to monitor software evolution and degradation qiong feng yuanfang cai drexel university philadelphia pa qf28 yc349 drexel.edurick kazman university of hawaii sei cmu honolulu hi kazman hawaii.edudi cui ting liu xi an jiaotong university xi an china cuidi tingliu mail.xjtu.edu.cnhongzhou fang drexel university philadelphia pa hf92 drexel.edu abstract architecture degradation has a strong negative impact on software quality and can result in significant losses.
severe software degradation does not happen overnight.
software evolves continuously through numerous issues fixing bugs and adding new features and architecture flaws emerge quietly and largely unnoticed until they grow in scope and significance when the system becomes difficult to maintain.
developers are largely unaware of these flaws or the accumulating debt as they are focused on their immediate tasks of address individual issues.
as a consequence the cumulative impacts of their activities as they affect the architecture go unnoticed.
to detect these problems early and prevent them from accumulating into severe ones we propose to monitor software evolution by tracking the interactions among files revised to address issues.
in particular we propose and show how we can automatically detect active hotspots t or e v e a l architecture problems.
we have studied hundreds of hotspots along the evolution timelines of open source projects and showed that there exist just a few dominating active hotspots per project at any given time.
moreover these dominating active hotspots persist over long time periods and thus deserve special attention.
compared with state of the art design and code smell detection tools we report that using active hotspots it is possible to detect signs of software degradation both earlier and more precisely.
index t erms software evolution architecture debt i. i ntroduction software degradation has a strong negative impact on software quality and productivity and may cause significant financial losses e.g.
.
curtis et al.
reported that on average there is of technical debt for every loc in complex software systems .
these severe debts do not happen overnight.
developers evolve software by continuously addressing issues fixing bugs and adding new few features and architecture flaws emerge quietly and largely unnoticed .
these problems may continuously evolve grow in scope and significance until the system becomes difficult to maintain.
developers are largely unaware of the accumulating debt they are focused on their immediate tasks of adding features and fixing bugs.
as a consequence the cumulative impacts of their activities as they affect the architecture go unnoticed.
when these problems are finally detected the damage is already done and the problems may be very costly to fix.
identifying these debts early is thus crucial.
existing tools detect technical or architectural debts either from one snapshot of the software source or compiled such as sonarqube and structure101 or using acombination of code snapshots and revision history such as dv8 .
tools using snapshots only tend to report a large number of problems.
for example sonarqube detected files with major or blocker smells in tika .
out of just files nearly making it difficult for the user to select and prioritize true debts .
tools that leverage revision histories are more likely to identify true debts since the project history records penalties in terms of bugs and changes.
but these tools usually have some user settable thresholds.
in order to detect severe problems the thresholds are not small.
for example one anti pattern detected by dv8 is called unstable interface .
according to its default setting a file will be detected as an unstable interface if it has of all the project s files as dependents and has co changed with at least of them at least two times .
when this anti pattern is detected the problem has already had an impact.
similarly for all these tools how early and how accurate debts are detected depends on threshold settings.
for example a class won t be detected as a god class until its size or complexity reaches specified thresholds.
in this paper we propose a novel model active hotspot ah that can be used to detect and monitor the emergence and evolution of software degradation by tracking how files and their relations are changed within each issue such as adding a new feature or fixing a bug.
in other words we use issues as first class entities of evolution and data sources of our analysis .
concretely we first track and treat the source files that are modified to address multiple issues as seed files calculate their architectural and semantic relations through four propagation pattern which will be described in next paragraph with other modified files and form the minimal number of file groups each of which is an active hotspot orhotspot .
to study how changes propagate from to seed files we manually examined a large number of relations among files modified to address various issues.
we have identified recurring and repetitive patterns over many projects dissemination changes to one file propagate to multiple dependent files oneto many concentration changes to multiple files cause another file to change many to one domino changes to one file cause ripple effects to a sequence of dependent files and scattershot changes that scatter in multiple files without syntactic dependencies.
34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
using active hotspots we studied the evolution of largescale open source projects and revealed the following results during a period of evolution measured as issue fixes there always exist a few dominating hotspots usually or and rarely more than that attract the majority of files that were modified to address issues.
these dominating hotspots tend to be persistent and long lasting of dominating hotspots we found in all projects their average life time is .
months.
some of them persist through the entire life of the project.
these two observations imply that these dominating hotspots are focal points of evolution that deserve special attention.
the number of files involved in hotspots is not correlated with the size of the project which contrasts with most tools whose reported problems and measures grow as the project grows.
this means that even when a project grows the development team won t necessarily be overwhelmed by increasing numbers of reported problematic files.
considering the identification of change prone errorprone files as an information retrieval problem we used active hotspots to detect such files and revealed that compared with state of the arts techniques hotspots can identify changeprone and error prone files more precisely.
using hotspots as an architecture debt detection tool our empirical study shows that compared with state of theart techniques hotspots can reveal major problems especially architecturally important files that are root causes of architectural debt much earlier.
this empirical study presents strong evidence that active hotpots can be leveraged to identify true architectural debts earlier and more effectively so that they can be prevented from incurring severe losses.
ii.
h otspot definitions in this section we define our core concepts.
seed file a file revised by multiple issues in a given time period.
the rationale is that if a file is repetitively changed by multiple issues for different reasons then this file may have violated the single responsibility principle .
the user can set a threshold to determine the number of commits for a file to be a seed.
in the study reported in this paper we consider files changed for issue fixing two or more times as seed files.
propagation file if a file changed together with a seed file in one of propagation patterns which we will explain in ii a then we call it a propagation file .
for example suppose fais a seed file and changed together with fbandfc.i ffbinherits from fa and fcinherits from fb we consider fbandfcas thepropagation files offa.
moreover in this case we classify these three files as following the domino propagation pattern one of the types of propagation patterns among files.
active hotspot or hotspot a set of files that were changed together during a given time period including a set of seed files vseed and a set of propagation files vprop.
formally a hotspot can be represented as a directed connected graph hotspot t v e in which vis the union of seed files and propagation files i.e.
vseed vprop and e a dissemination b concentration c domino d scattershot fig.
change propagation patterns is a set of ordered pairs of files within v and each pair of files has propagation pattern relations among them.
there may be multiple mutually exclusive hotspots during a given time period.
in the study reported here we only include propagation files through one of the four propagation patterns into a hotspot because these four patterns are widespread as we will show and these patterns are the atomic relations forming higher level architecture problems.
a. propagation patterns to better understand file relationships in co commits and how issues propagate among these files we manually examined bug patches from multiple systems that revised five files or more and categorized the relations among the files involved in each bug fix.
we observed that overwhelmingly out of times their relations follow four recurring patterns dissemination figure 1a .
methods or fields were modified added deleted from one file and several other files using these changed methods or fields were updated accordingly.
this pattern involves one file such as a parent or utility class and several dependent classes.
the bug patch for jdt bug 4270721is such an example.
the purpose of this patch was to fix a compilation failure when the type of a method is ambiguous.
the solution is to change the matching strategy in type binding.
the change started by modifying the sismorespecific method in class expression.java then all its subclasses conditionalexpression.java lambdaexpression.java messagesend.java and referenceexpression.java were changed accordingly.
in this patch conditionalexpression.java and messagesend.java used the updated method sismorespecific and needed to change the way the method was called.
the other two classes lambdaexpression.java and referenceexpresssion.java needed to replace the original matching method typebinding.equalsequals with the newly updated sismorespecific .
this patch represents the dissemination pattern where changes to one file propagate to multiple files that depend on it.
expression.java public boolean sismorespecific typebinding s typebinding t typebinding expressiontype this .resolvedtype if expressiontype null !expressiontype.isvalidbinding return false if s.isbasetype t.isbasetype return s.iscompatiblewith t return s.findsupertypeoriginatingfrom t !
null return s.iscompatiblewith t 1due to the limitation of paper size we only present patches directly related to the pattern.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
conditionalexpression.java public boolean sismorespecific typebinding s typebinding t if super.sismorespecific s t messagesend.java public boolean sismorespecific typebinding s typebinding t if super.sismorespecific s t lambdaexpression.java if super.sismorespecific s t referenceexpression.java if super.sismorespecific s t concentration figure 1b .
this pattern describes the case where one class changes due to changes to multiple other classes it depends on.
that is two or more files were modified to change add delete methods or fields and another file which depends on them has to be updated.
take jdt bug as an example class iproblem.java adds an intfield superaccesscannotbypassdirectsuper and another class problemreasons.java also adds an intfield attempttobypassdirectsuper .
the third class problemreporter .java needs to use both of the newly added fields in its method illegalsuperaccess .
this pattern describes the cases where one class is dependent on the changes from multiple other classes through structural dependencies.
core compiler iproblem.java int superaccesscannotbypassdirectsuper typerelated internal compiler lookup problemreasons.java final int attempttobypassdirectsuper internal compiler problem problemreporter.java public void illegalsuperaccess typebinding supertype typebinding directsupertype astnode location if directsupertype.problemid !
problemreasons.attempttobypassdirectsuper needimplementation location handle iproblem.superaccesscannotbypassdirectsuper domino figure 1c .
this pattern describes the case where changes originated in one file ripple through multiple other files resulting in a cascade of consequent changes.
the patch for jdt bug is such an example class problemreasons.java was first modified by adding an intfield serviceimpldefaultconstructornotpublic .
after that another class problemreporter .java was also changed to add a new method invalidserviceimpl that used the newly added field inproblemreasons.java .
finally the third class moduledeclaration.java also added a new method validate which uses the method invalidserviceimpl added in the second class problemreporter .java .
this pattern describes the well known ripple effects caused by direct and indirect structural dependencies.
lookup problemreasons.java final int serviceimpldefaultconstructornotpublic problem problemreporter.java public void invalidserviceimpl int problem typereference impl string args new string charoperation.chartostring impl.resolvedtype.readablename case problemreasons.serviceimpldefaultconstructornotpublic ast moduledeclaration.java private void validate typereference serviceinf typereference serviceimpl if problemid !
problemreasons.noerror this .scope.
problemreporter .invalidserviceimpl problemid serviceimpl scattershot figure 1d .
this pattern is similar to code clones where similar patch logic is injected into multiple files.
for example jdt bug was private interface methods should not be visible outside .
the patch modified the same method isprivate in classes methodbinding.java referencebinding.java and scope.java .
these classes are responsible for verification logic and shared this crosscutting concern.
if method accessibility needs to be changed in the future it is possible that these three classes need to be changed together again.
files involved in the scattershot pattern may or may not have structural dependencies among them but the methods that were changed in this pattern do not have structural relations.
methodbinding.java if this .declaringclass.isinterface isstatic !isprivate referencebinding.java if method null method.isstatic method.redeclarespublicobjectmethod scope method.isprivate scope.java if candidate.isstatic candidate.declaringclass.isinterface !candidate.isprivate these results are generalizable.
we created a tool to identify these recurring patterns and analyzed bug patches that modified files or more.
this analysis showed that .
of them participated in at least one of these four patterns suggesting that these patterns are widespread.
besides these patterns are the atomic relations forming higher level architecture problems.
for instance when multiple disseminations with the same top file are combined this top file will have a large number of dependents and may be qualified as wide hierarchy design smell in designite or unstable interface anti pattern in dv8.
iii.
i llustrative example figure illustrates the evolution of a hotspot simplified from the apache camel project.
we split its evolution history into sliding evolution windows each consisting of issues that modify at least one source file.
each window is issues apart from the next the first evolution window w1 starts when the 1st issue was resolved and ends when the 100th issue was resolved and w2starts at the 21st issue and ends with the 120th issue and so forth.
figure is labeled with consecutive evolution windows.
an oval denotes an issue and the circles within it are the files added deleted modified to address the issue.
a red circle denotes a file changed by more than one issue in the evolution window a seed file .
a yellow circle denotes a propagation file participating in one of the propagation patterns with seed files which we call propagation files .
other files represented by small unlabeled gray circles are modified but have no relations with the seed files.
an active hotspot ah consists of all the red and yellow circles and their relations.
each hotspot is identified by their seeds files.
if two hotspots share any seed files we consider them as the same hotspot.
inw229 the file named defaultcamelcontext.java f1 w a s modified by two different issues which makes it a seed file.
f1andf2 5depends on f6 camelcontext.java and they form a dissemination pattern.
since f2 6is only modified by one issue in this evolution window they are colored yellow denoting that even if they are not seed files they participated in at least one propagation pattern and all six files form an active hotspot in w229.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
the life cycle of an active hotspot in camel in the next evolution window w230 f6became a seed file since it was revised by two different issues and four more seed files were detected.
as a result these seeds files and the propagation files expanded the hotspot to files.
in w231 the hotspot still had files but f9replaced f12as a seed file.
in w232 f1 f6 f4 and f11remain to be seed files but the hotspot shrank to files.
in w233andw234 the hotspot further shrunk to files.
this example is extracted from nine years of camel s evolution history that consists of issues.
as we can see from the dataset f1appeared to be a seed file as early as in the first evolution window and f11became a seed file in w93.
these two files remain to be actively leading hotspots all through the lifecyle of camel.
in window f11remained to be the seed of a hotspot with files.
after that this groupbecame less active until window when f1andf11started to lead a file hotspot again.
these files remains to be activetill the very last of the evolution history window whenthe hotspot grew to files.
iv .
h otspot detection based on these definitions we detect hotspots as follows we first extract all the seed files within any a given time period and then find all the files that participated with these seed filesthrough any of the four propagation patterns.
the seed filesand all propagation files form an active hotspot.
figure depicts the overall process of our approach with the followingfour steps step detecting seed files.
this step takes issue records and revision history records as inputs as well as a specified fig.
overview of our approach period of time and outputs a set of seed files.
specifically weextract issue ids from a system s issue tracking system andmatch them with its commit history with the assumption thatif a system is well managed a commit should be associatedwith an issue id.
we extract the source files committed toresolve each issue and output files that were changed for at least two issues as a set of seed files.
in this step all test files are filtered out as we focus our investigate only on source files.
step extracting dissemination concentration and domino patterns.
in a given period of time for each commit we use the command git show to extract all the source files changed by that commit and use a reverse engineering toolunderstand to extract syntactic dependencies among thesesource files such as inherit calland useetc.
this dependency information can be used to detect dissemination concentration authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm generate hotspots from seedfiles and a list of propagation patterns 1function generatehotspot seed files pps input seed files and a list of propagation patterns pps with each pattern represented by v e output a list of hotspots with each hotspot v e 2initialize fileset as a set 3for each seed file inseed files do for each ppinpps do ifseed file is one node in ppthen put all nodes files in ppinto fileset end end 9end 10put all seed files into fileset 11change fileset to a list filelist 12initialize a unionfind ufwith the size of filelist 13for each ppinpps do iffileset contains any two files f1 f2 in ppthen index filelist.index f1 index filelist.index f2 uf.union index i n d e x end 19end 20initiate a list of hotspots with each hotspot v e 21populate file names in the same group in unionfind uf as the nodes of one hotspot into hotspots 22for each hotspot inhotspots do for each ppinpps do ifppcontains a edge between any two files f1 f2 in hotspot then populate this edge into this hotspot end end 28end 29return hotspots and domino patterns among the changed source files.
for example if one changed file callmultiple other changed files then a concentration pattern will be detected.
step extracting scattershot pattern.
in a given period of time for each commit we use git diff to extract added deleted or changed lines in each source file.
after that we apply simian to detect similar code pieces clones among the changed code entities of all source files.
if any two source files have at least one similar changed line then we say these two files have a clone relation and three files with a clone relation form a scattershot pattern.
step calculating active hotspots.
using the seed files output from step and the four pattern information from steps and as inputs this step generates a set of mutually exclusive hotspots in both csv and json formats so that these hotspots can be visualized using other tools.
specifically we bind files participated in the same patterns with a seed file withthe seed file into a hotspot.
if another hotspot is sharing one or more same files with this hotspot then these two hotspots will be merged together into one single hotspot.
the details are shown in algorithm .
our r script can be used to visualize issues interaction shown in figure and the detailed pattern information can be shown in dv8.
v. e mpirical study the objective of our empirical study is to understand the nature and potential of active hotspots file groups generated from evolution history using issues as first class analysis artifacts.
for this purpose we studied the evolution history from large scale open source projects and their basic data are shown in table i. as we introduced in section iii we split the project s evolution history into multiple sliding evolution windows each consisting of issues that modify at least one source file and each window is issues apart from the next.
we choose issues as a window size as our previous approach shows that issues can provide valuable information with a reasonable size.
we will discuss this threshold in section vi.
as shown in table i the number of evolution windows differs for different projects ranging from to depending on the length of the history and their activeness i.e.
the number of issues that are resolved we do not consider open issues in this experiment as they are continue changing .
the table also shows that the number of hotspots detected within each window ranges from to .
the average number of hotspots detected within a evolution window is .
.
we investigate research questions.
the first three help us understand active hotspots in terms of their life cycles and sizes.
the last two test the potential of using active hotspots to detect problematic files and architecture debts in terms of timeliness and efficiency.
rq1 how files are distributed among the multiple hotspots detected within a period of time?
that is do files tend to aggregate into a few hotspots or are they usually randomly distributed?
if a small number of hotspots always attract a large number of files then these hotspots are more likely to have architecture issues and thus deserve special attention.
we would like to understand if such dominating hotspots exist in most projects and if so how many such dominating hotspots can be normally found.
rq2 do active hotspots tend to be long lasting remaining active over a system s evolution or are they transient?
since a given time period of evolution usually contains multiple hotspots it is possible that some hotspots are more long lasting than others.
active hotspots that persist over a long period of time are change prone by definition and should be a focal point of interest as these are potential architecture debts.
if most projects have such long lasting hotspots this implies that architecture debts are ubiquitous.
in this case it is important not only to track these change prone file sets but also to reveal their architectural relations and how changes bugs propagate.
rq3 are the sizes of hotspots correlated with the sizes of projects?
research has shown that the sizes of files authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i subjects and hotspots start time file range issues windows min ah max ah avg ah file dominatingah file allahlongesthotspotlife in months accumulo .
.
ambari .
.
avro .
.
calcite .
.
camel .
.
cassandra .
cxf .
.
derby .
.
hadoop .
hbase .
.
kafka .
.
kylin .
.
mahout .
.
maven .
.
openjpa .
.
pdfbox .
.
pig .
.
spark .
.
tika .
.
wicket .
.
zookeeper .
.
min .
.
max .
.
average .
.
.
.
min max avg ah mininum maximum average number of active hotspots among all evolution windows and projects have strong correlations with several measures of interest essentially bigger projects and bigger files score worse for almost every measure of productivity and quality that a project manager cares about.
for example the larger the project the more code smells can be found the larger a file is the more likely it is error prone.
here we would like to understand if the size of active hotspots is also correlated with the size of the project.
if hotspots are not correlated with size then we could feel greater confidence that they are truly measuring debt.
rq4 if we consider the identification of problematic files as an information retrieval problem and we use active hotspots to detect such problematic files compared with state of the art smell detection techniques do active hotspots provide better precision and recall?
ideally a tool should have a balanced precision and recall to help a user pinpoint problematic files.
rq5 if we use active hotspots to detect architecture debts compared with state of the art techniques can they reveal the existence of architecture problems earlier?
since we are tracing software evolution by tracking issue interactions we hypothesize that active hotspots can reveal architectural problems earlier in a project s timeline than existing approaches.
next we introduce our empirical study of these questions in each of the subsections.
a. dominating hotspots table i shows that evolution windows usually contain multiple hotspots.
we want to examine how files are distributed among these hotspots.
our first observation is that in any window there usually exist a few hotspots that are dominating meaning that they attract the majority of files that were changed during that time period.
consider hotspots with 5or more files which we set as the minimum threshold for a file group to be considered to have structural impact as dominating hotspots.
we observe that out of all windows only windows in out of projects have no hotspots of or more files.
this means that during most of these projects evolution there existed dominating hotspots.
our second observation is that the number of such dominating hotspots is small.
of all windows only of them have more than dominating hotspots.
camel and ambari have out of and out of such windows respectively all other projects have or fewer.
in other words in the vast majority of windows studied the number of dominating hotspots ranges between and .
our third and most important observation as shown in column fl dominatingah fl allah of table i is that .
to of files in hotspots are captured by dominating hotspots on average about of files are aggregated into dominating hotspots.
of all projects only the dominating hotspots in camel cxf and wicket have fewer than of all hotspot files and respectively on average.
the implication is that during most of the evolution period files in hotspots tend to aggregate into a few instances of dominating hotspots.
as an example figure shows the hotspot statistics in zookeeper from to .
the purple line shows the number of dominating hotspots in each window.
the blue line shows the file count within them and the red line shows the total file count of all hotspots.
the figure shows that at each evolution window there are at most dominating hotspots which on average captured of all hotspot files the red line and the blue lines are very close to each other.
now we are ready to answer rq1 indeed during most authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
evolution periods there usually exist just a handful of big hotspots which can be called dominating hotspots that link the majority of active files together.
these dominating hotspots should be the focal points for analysis.
sliding windowsize may nov jun oct mar sep hotspotfiles plus5hotspotfiles plus5hotspot fig.
zookeeper hotspot statistics b. persistent hotspots now that we have discovered that at any period of evolution there are just a few dominating hotspots we would like to examine if these dominating hotspots tend to be persistent and long lasting.
if the answer is yes it mean that these files especially the seed files must be change prone and or errorprone and thus have incurred the most maintenance costs.
fig.
dominating hotspot s life in months we studied dominating hotspots covering all projects.
the boxplot in figure shows that their lifespan ranges from months to months with an average .
months and a median .
months.
as shown in the last column of table i the most persistent hotspot within each project lasts between kylin to months maven and the average is months.
as an example figure shows the persistence of zookeeper s dominating hotspots.
in this figure the first column shows the starting date of an evolution window.
the numbers in the diagonal cell are the total number of dominating hotspots and the number in cell i j i j refers to the number of hotspots that existed in earlier window jand remain in the current evolution window i. for example cell shows that there are hotspots in window .
cell shows that there are hotspots that last from window to window .
now we are ready to answer rq2 dominating hotspots can last a long time they are persistent and long living which again shows that they should be the focal points of analysis.
fig.
zookeeper dominating hotspot persistence c. correlation with project size given these results we now hypothesize that hotspots can be used to detect problematic files and architecture problems during evolution.
prior research has shown that the sizes of files and projects have strong correlations with several measures of interest.
essentially bigger projects and bigger files score worse for almost every measure of productivity and quality that a project manager cares about the larger the project the more code smells can be found the larger a file is the more likely it is error prone.
here we investigate whether the number of files involved in hotspots is also correlated with project size.
if the answer is yes then it is possible that hotspots are not very different from other analysis techniques if the answer is no it means hotspots are independent and even when a project grows the development team won t be overwhelmed with increasing numbers of reported flaws.
to assess this hypothesis we compared the numbers of distinct problematic files reported by hotspots and by other tools and calculated their correlations with project sizes in terms of file counts and lines of code loc .
as an example table ii shows the number of files reported as having code design problems detected by all tools from tika .
to tika .
.
the data reveal that except for hotspots when the tika project increased from files to files the number of reported files by all these tools monotonically increased.
for example files with smells detected by designite increased from to to of the project files .
by contrast the hotspot approach is the only one in which the file counts are not correlated with project sizes.
since structure101 sonargraph and sonarqube require successful builds of a project by maven or gradle as input tika is the only project where we could build a series of snapshots from its source code in its git repository.
as a result to test if this observation is generalizable for other projects we only compared the number of files with problems reported by designite and dv8 with hotspots because these tools only require source code as input.
using snapshots from our subjects we first did a shaprio wilk normality test to see if the samples reported by these tools follow a normal authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii smells detected in tika version file designite file dv8 file sonarqube file sonargraph file structure101 file hotspot file proj loc proj tika .
tika .
tika .
tika .
rc1 tika .
tika .
table iii shapiro wilk normality test file in designite file in dv8 file in hotspotproj file loc w .
.
.
.
.
p value .4e .3e .9e .9e .7e table iv pearson correlation file designite file dv8 file hotspot file p loc p file p loc p file p loc p coefficient .
.
.
.
.
.
p value .2e .2e .2e .2e .
.
distribution which is confirmed as shown in table iii.
then we did a pearson correlation test between the reported file counts the total file counts and total lines of code in each snapshot.
table iv shows that files with smells detected by designite are highly correlated with project file counts and lines of code with a coefficient .80and0.
.
dv8 produces similar results.
only the number of files captured by hotspots are not correlated with size with pearson coefficients of .
and .
.
now we are ready to answer rq3 the number of files that should be the focal points of analysis is solely related to the intensity of issue interactions and the architectural relations among files and not to project or file sizes.
d. capturing bug change prone files table v predicting change prone and bug prone files change2 change3 precision recall f1 precision recall f1 designite .
.
.
.
.
.
sonarqube .
.
.
.
.
.
sonargraph .
.
.
.
.
.
structure101 .
.
.
.
.
.
dv8 .
.
.
.
.
.
hotspot .
.
.
.
.
.
bug2 bug3 precision recall f1 precision recall f1 designite .
.
.
.
.
.
sonarqube .
.
.
.
.
.
sonargraph .
.
.
.
.
.
structure101 .
.
.
.
.
.
dv8 .
.
.
.
.
.
hotspot .
.
.
.
.
.
files in hotspots by definition are change prone and or error prone since they are constructed by seed files and propagation files that changed together with them.
for this reason we hypothesize that hotspots could be leveraged for change bug prediction.
here we compare hotspots and files with smells reported by other tools in a given snapshot in terms of their ability to capture bug prone and change prone files in the next snapshot.to investigate this question we chose out of the projects from which we could successfully create a build for a release so that we could compare all tools including sonarqube sonargraph and structure101.
for each of the projects we chose a release in so that we could use the most recent evolution period as an oracle .
since hotspots and dv8 both require revision history as input we used the revision log that includes bugs before the selected releases for both tools to make a fair comparison.
to form an oracle data set for error proneness and changeprone prediction we included bug fixes and general fixes after the selected release date.
all the files that had been modified by or more bug fixes form a bug2 file set similarly all the files that had been modified by or more general fixes both bug and non bug fixes form a change2 file set.
bug3 including files modified by or more bug fixes is a subset of bug2 change3 is a subset of change2 so on and so forth.
table v shows the results for all tools.
we excluded change1 and bug1 since files belonging to change but not change2 i.e.
files that are only changed once should not be counted as change prone or error prone.
the table shows that hotspots and structure101 have relatively low recall and high precision because they reported smaller numbers of files.
the other tools have high recall at the expense of low precision because they report a large number of files.
the f1 score provides a more balanced measure the grey cells indicate that hotspots always have the best f1 score.
take bug2 for example on average .
of all the files in dominating hotspots have bugs at least two times in the next evolution period and they cover about .
of all the error prone files.
besides though other tools report a large number of problematic files hotspots detected files which can not be detected by other tools.
we manually inspected these files source code and their relations with other files and identified these files as flawed files.
and these files continuously incur bugs or changes after the selected releases.
these data illuminate rq4 compared with other tools hotspots can capture error prone and change prone files more effectively and thus have the potential to be used for bug change prediction and localization.
since dominating hotspots a big directed graph with propagation relations are the majority of hotspot files it means that these files contributed significantly to error and change proneness which we propose is through their propagation patterns.
e. early detection of architectural problems authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table vi hotspot can reveal architecture flaw early detected in dv8detected in earlier hotspotaverage months advanced detected in hotspot unstable interface .
crossing .
our main objective by focusing on dominating hotspots is to detect architectural problems early so that they can be prevented from growing too big or too complex.
we would like to examine if hotspots can reveal severe architectural problems earlier compared with other architectural debt detection tools.
this comparison is challenging.
consider dependency cycles which are checked by most tools as an example.
even though an active cycle can be observed immediately if we extract changed files relations during one fix we cannot compare it with the cycles detected by other tools systematically because the members of a cycle change over time and it is impossible to uniquely trace a cycle especially when different tools define cycles slightly differently.
similarly for fat files god classes etc.
it is intuitive that if a file is repeatedly changed then it may be a hotspot and may become overly complex.
to check how early these problems can be detected we would need to create multiple builds to run sonarqube structure101 etc.
which is not practical.
since hotspots focus on files repeatedly changed by multiple issues we wanted to investigate if and to what extent these files were architecturally important.
the earlier such files can be identified the more likely their problems can be promptly detected and fixed.
among the types of anti patterns reported by dv8 two of them also detect files with architectural consequences and contribute most of the maintenance cost.
one is unstable interface a file that has many dependents and co changed with them often and the other is crossing a file with high fan in and fan out that co changes frequently with both its dependents and the files it depends on.
since both anti patterns detect architecturally important files and their impact scope we examine if hotspots can identify these key files early.
to conduct this experiment we first detected unstable interfaces and crossings from a series of snapshots in a project and noted the snapshot time when they were first detected.
we then scanned our hotspots starting from the first snapshot s release time to the last snapshot s release time to examine whether the unstable interface and crossing files identified in dv8 can be found in a hotspot if and how much earlier these files can be detected than when they are first detected by dv8.
the results are as follows dv8 detected unstable interfaces and crossing files from all the projects.
of these files out of unstable interfaces are detected within hotspots and out of crossing files are detected within hotspots.
we manually examined the files which we did not find in our hotspots and found that of these files are in the hadoop project which is an ecosystem and use different issue ids such as hdfs or yarn tomark commits in other modules.
in our experiment we used hadoop to extract issues.
these files can be found in our hotspots if we modify our issue id system.
the other files are neither seed files nor files connecting to seed files and can not be detected within hotspots.
these files are all structurally connected to other files but their co changes are not captured by multiple issue fixes.
thus we know that .
of these key files can be identified through hotspots.
of these files that are captured by hotspots they are all detected earlier than by dv8 as shown in table vi.
on average hotspots can detect unstable interfaces and crossings months and months earlier respectively.
using figure as an example.
f1andf6signal the most severe architectural problem many files depend on them and they change together frequently with many other files this is a typical unstable interface flaw .
out of the evolution windows examined these two files are part of a hotspot and times respectively.
our tool detected these two files in hotspots during the first window.
dv8 by contrast will not flag them as problematic until enough revision history has been accumulated to indicate that other files are regularly changing together with f1and f6.
these problems could easily go unnoticed until they incur severe costs.
actually given the default settings of dv8 using the same revision history as hotspots dv8 wouldn t have reported them at all unless we changed the settings or provided longer revision history.
as another example a hotspot found in window in derby the file connection.java has fan outs and fan ins but it is not until this grows to fan ins and fanouts in version .
.
.
that dv8 reported it as a crossing since its default setting are fan ins and fanouts.
using hotspots the user does not need to consider how to change the tool settings.
instead they just need to select evolution periods of interest such as a sprint a release or the time after refactoring.
this then answers rq5 by closely monitoring software evolution through issues it is possible to identify architectural problems earlier in the lifecycle.
vi.
d iscussion hotspots and architectural anti patterns.
in section v e we prove that hotspots can detect architectural important files unstable interface and crossing earlier than dv8.
the rational behind this is that hotspots are constructed through issue interactions e.g.
files addressing two issues are overlapped which shows early sign of architecture problems.
if two issues are addressing different problems then the shared files violate the single responsibility principle.
if two issues are addressing the same problems then the design of shared files also deserve further investigations.
in addition hotspots also incorporate a small architecture unit which shows changes propagate among multiple files in a real system.
these propagation patterns and their combinations can indicate architecture flaws.
for example we observed that the last file in one domino instance is also the first file of another domino instance and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
though these two domino chains changes propagate not only among multiple files but also across multiple packages subsystems.
if the chain is long and files in this chain are in different packages files may be forgotten during bug fixing.
and this is similar to an anti pattern message chain defined by fowler et al.
we also have similar observation with other patterns and their combinations.
so we can say each propagation pattern is an atomic relation forming higher level and more severe architecture problems.
combining issue interactions with these propagation patterns hotspots can represent the most active architectural unit and indicate possible architectural problems to avoid further architectural decay.
next we discuss the limitations of our proposed models and the threats to validity of our study.
limitations.
first the accuracy of our study depends on the quality of project revision histories.
recent studies state that it is possible for one commit to fix multiple issues or for a commit to not be explicitly linked to an issue.
our analyses assume that files fixing an issue are related to each other though we do remove issues which modified more than source files to reduce noise.
we intend to further assess this threat via qualitative analysis.
second our definition of active hotspot uses seed files and includes files with propagation relations with them.
there may exist more effective ways to find more precise hotspot e.g.
at method level instead of file level.
improving and further evaluating the hotspot detection algorithm is future work.
finally the activeness of a system will significantly influence the detected hotspots.
consider avro this system has not been very active in recent years.
as a result few hotfiles can be found and the detected hotspots are small.
it is possible that there are many files in the system still have code design or architecture problems.
however if the system remains to be inactive these problems may not generate extra maintenance costs and hence shouldn t be counted as technical debts.
investigating how to assess the activeness of a project and how the activeness influences our models are parts of our future work.
threats to validity.
one major threat to validity of our empirical study is the choice of using issues as the unit of evolution window.
it is not clear if the results will differ if we chose a different length or how to optimally choose the length of an evolution window.
conducting sensibility analysis on the sizes of evolution windows is our future work.
in practice an evolution window could be a sprint a release a period after refactoring etc.
another threat to validity is choosing files as the threshold of being a dominating hotspot.
we will also test the sensibility of this threshold in the future.
similar to the choice of issues as the unit of evolution windows in practice the existence of dominating hotspots will be prominent and there is no need to set such a threshold.
an external validity is that we only studied open source projects all of which were implemented in java and all of which are from the apache ecosystem.
while we have no reason to assume that the effects that we have studied wouldbe different with different programming languages we can not currently claim that our results can be generalized to projects implemented using other languages.
similarly we have no expectation that our results would differ in closedsource contexts or projects from other oss ecosystems but this remains a potential threat.
vii.
r elated work software evolution.
chapin et al.
proposed a method to classify evolution types based on a semi hierarchical manner of the change in four aspects from documentation to functionality.
godfrey et al.
compared software evolution with biological evolution and examined how software evolves in response to environmental pressure and emergent design.
tu et al.
studied the evolution of the linux kernel and discussed why linux continues to exhibit such strong growth.
robles at al.
studied the evolution of a linux distribution debian with respect to its overall size use of programming languages maintenance of packages and file sizes over seven years.
architecture evolution has also been explored .
chaikalis et al.
incorporated structural and domain information such as the creation of relations among existing and new classes and the removal of edges into a networkbased prediction model.
they used open source projects to evaluate this model and showed that their derived models can provide insight into future trends.
zimmermann examines architectural refactoring as an evolution technique that revisits decisions and identifies related design implementation and documentation tasks.
xiao et al.
also studied the evolution of architectural debt and showed how such debts grow.
the above studies on software evolution focus on the evolution of software architecture knowledge bases and so forth.
our study is complementary to these studies by investigating software evolution through one of the smallest architectural unit active hotspot and studying active hotspot s evolution continuously by sliding issue s winodws instead of focusing on separate releases.
architecture problem identification.
the following work is the state of art in terms of identifying architectural problems underlying high maintenance.
xiao et al.
revealed that most error prone files often connected into just a few file groups and proposed types of architectural debts.
mo et al.
proposed five file level architectural flaws and proved that these flaws are highly correlated with error proneness and change proneness.
mondal et al.
investigated bug propagation through code clones and conclude that up to of code clones in a bug fix can be related to bug propagation.
our study identifies three other common ways for a bug to propagate and use them to construct active hotspot .
different from this prior work our approach is the first attempt to monitoring software evolution by tracking how issues interact.
the concept of active hotspot takes into consideration the temporal natural of architecture connections and as we will explain later enables more precise and timely identification of architecture problem that may grow into authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
severe debts.
hence designers can treat these problems early before incurring significant loss.
change propagation as defined in to guarantee the proper funtionality of a software system when a particular entity is changed it is required to change other entities of the software system.
researchers have constructed a change propagation model from historical co change code structure name similarity etc.
and measure the model s precision and recall.
furthermore researchers have been analyzing more fine grained change impact .
for instance chianti first decomposes differences between two programs into atomic changes such as changed methods cm and added field af .
wang et al.
did an empirical study of multi entity changes in real bug fixes and they discovered six recurring patterns.
similar to their techniques we also studied propagation patterns.
however to construct one of the smallest architectural unit at the file level we studied files propagation patterns.
we discovered recurring propagation patterns at the file level and files involves these patterns tend to propagate changes to other files.
code smells anti patterns.
numerous studies claimed that code smells and anti patterns are the causes of significant maintenance costs.
many tools have been developed to reveal code smells and anti patterns.
however recent studies suggest that code smells which indicate bad design are notthe root causes of maintenance costs.
instead file size and the number of revisions are more strongly correlated with maintenance costs.
using popular code smell detection tools developers can detect numerous code smells but not all of them are real issues or incur high maintenance costs.
our study focuses on bug propagation patterns that have already shown they incur high maintenance costs.
using these an analyst can focus on the true maintenance difficulty in a project and pinpoint the underlying design problems at the finest granularity.
as discussed in v d we compared our active hotspot with other state of the art smell detection tools and proved active hotspot can use less files to capture more maintenance files in the future.
viii.
c onclusion in this paper we proposed a model called active hotspots that can be used to monitor software evolution and detect potential degradation using issues as first class entities.
an active hotspot is formed by seed files that are changed by multiple issues and the files that are connected with them through one of the propagation patterns.
using active hotspots as lenses we studied the evolution history of open source projects.
the data revealed that within any evolution period the majority of files revised for issue fixing are just aggregated into a few dominating hotspots and most of these dominating hotspots are persistent and remain active for a long time implying that these dominating hotspots should be the focal points of activity and deserve special attention.
different from most code design or architecture smell detection tools the number of files within hotpots do not increase with the size of the project meaning that developerswon t be overwhelmed by increasing numbers of reported flaws as the project grows.
we also showed that hotspots have the potential to be leveraged for bug and change localization.
most importantly by monitoring the emergence and evolution of hotspots it is possible to detect architectural problems early so that these problems won t accumulate into severe maintenance costs.