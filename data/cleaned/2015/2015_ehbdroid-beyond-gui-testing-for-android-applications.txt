ehbdroid beyond gui testing for android applications wei song school of computer sci.
eng.
nanjing university of sci.
tech.
nanjing china wsong njust.edu.cnxiangxing qian school of computer sci.
eng.
nanjing university of sci.
tech.
nanjing china xiangxingqian gmail.comjeff huang parasol laboratory texas a m university college station tx usa jeff cse.tamu.edu abstract with the prevalence of android based mobile devices automated testing for android apps has received increasing attention.
however owing to the large variety of events thatandroid supports test input generation is a challenging task.in this paper we present a novel approach and an open source tool called ehbdroid for testing android apps.
in contrast to conventional gui testing approaches a key novelty of ehbdroidis that it does not generate events from the gui but directlyinvokes callbacks of event handlers.
by so ehbdroid can efficiently simulate a large number of events that are difficult to generate by traditional ui based approaches.
we have evaluatedehbdroid on a collection of real world large scale androidapps and compared its performance with two state of the art uibased approaches monkey and dynodroid.
our experimental results show that ehbdroid is significantly more effective andefficient than monkey and dynodroid in a much shorter time ehbdroid achieves as much as .
higher statement coverage .
on average than the other two approaches and found bugs in these benchmarks including new bugs that the othertwo failed to find.
index t erms android automated testing event generation event handlers i. i ntroduction despite the popularity of mobile apps testing them faces significant challenges.
the difficulty lies in two main aspects.
first the space of events is often enormous.
there could be an infinite number of ui events if the app s state is cyclic and there are more than a hundred different kinds of system broadcasting events supported by android currently .
it is impractical to generate all possible events and their permutations.
second many ui events e.g.
drag hover and most system and inter app events are difficult to generate.
for example generating a drag event requires that the drag should start at a certain position and end at another and only when the distance between the two positions is larger than a certain value can the event be regarded as a successful drag.
in addition certain ui events can only be triggered if their preconditions are satisfied e.g.
inputs to all the relevant widgets are provided .
the probability to simulate all combinations of the widget inputs is very small .
thus it is hard to simulate such ui events thoroughly.
for many system events proper data e.g.
arguments needs to be constructed and dispatched correctly to the app.
for inter app events they can only be triggered by external apps under certain conditions.although mobile app testing has attracted a large body of active research existing approaches andtools are still unsatisfactory.
according to a recent study most existing approaches are ui based and they are either too slow to generate events or cannot effectively generate certain events.
more efficient and effective automated testing techniques are required to ensure correctness reliability and security of mobile apps.
in this paper we present a new approach and an open source tool called ehbdroid event handler based for testing android apps.
ehbdroid is implemented and evaluated for android.
however the idea of event handler based testing is not limited to android but general to event driven systems.
ehbdroid is based on a simple but important observation in event driven systems there often exists a correspondence between an event and an event handler.
the events that occur on the ui are eventually passed to and are handled by their event handlers e.g.
callback functions in android .
hence instead of attempting to generate ui events we can trigger their event handlers callbacks directly.
the callback instrumentation can be inserted into the app via either static analysis or code re writing at class loading time.
there are several advantages of ehbdroid over traditional ui based approaches.
first it can invoke a set of callback functions quickly because the testing does not need to wait for the latency induced by gui and the cost of message passing in the system.
second it can test the callback functions thoroughly even if some of them cannot be easily invoked through the gui.
for many events such as system events and complex ui events it is much easier to generate calls to their event handlers directly than to generate events from the ui.
consequently it provides high code coverage in a short testing time.
third the events for the test are systematically generated and are not redundant i.e.
the events do not invoke the same functions repeatedly.
although the basic idea of ehbdroid is simple we are not aware of any previous research or infrastructure that explored this idea.
a most related tool is dynodroid .
it instruments the android framework and relies on the vm to generate aconsiderable number of ui inputs and system level events that are relevant for the apps and uses a pre configured selection strategy to select an event to execute.
however dynodroid .
c circlecopyrt2017 ieeease urbana champaign il usa t echnical research27 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
is less effective and efficient than ehbdroid because of its black box nature i.e.
it only generates a limited range of events and for each generated event it relies on the android framework to pass the event to the event handler rather than invoking the event handler directly.
to realize ehbdroid there are several challenges how to identify the event handlers in android and construct their invocations?
how to construct valid runtime event data passed to the event handlers?
how to systematically invoke the event handlers such that the app behavior can be effectively tested withoutredundant exploration?
these challenges are often specific to the implementation of the event driven framework.
for the first challenge we identifythree registration patterns for event handlers in android.
based on these patterns ehbdroid is able to automatically instrument all callbacks in the android api.
for the secondchallenge by using default value for data of primitive types and runtime instances of event sources which are available in the app context for those of reference types ehbdroid constructs many meaningful runtime arguments for invokingthe callbacks.
for the third challenge instead of invoking those callbacks randomly ehbdroid performs an activity directed depth first search to effectively traverse different activitieswithout redundant exploration.
we implement ehbdroid as an automated testing tool based on the soot framework .
ehbdroid is open source and is publicly available on github .ehbdroid has been evaluated on real world android apps from f droid and google play store and compared with two stateof the art ui based testing tools monkey and dynodroid .
the results suggest that ehbdroid is significantly more efficient and effective than the other two approaches.
ehbdroid achieves as much as .
higher statement coverage .
on average than monkey and dynodroid for these apps.
for all apps ehbdroid can quickly cover all activities in ten minutes whereas for many apps monkey and dynodroid either cannot generate events to cover certain activities or get a much lower code coverage even in an hour.besides ehbdroid detected bugs in these apps of which were not found by the other two.
to summarize we make the following contributions we develop an event handler based testing approach ehbdroid for testing android apps without the need to generate events.
the approach of ehbdroid applies not only to android apps but also to general event driven systems.
though conceptually simple to the best of our knowledge ehbdroid is the first event handler based approach for android app testing.
we present a general and systematic testing strategy to simulate ui system and inter app events in android by instrumenting and automatically invoking their callbacks.
able i android event types and their registra tion pa tterns xxxxxxxxeventpatternstatic a static b dynamic overridden ui systemreceiver service inter app we have successfully instrumented all callbacks in android api with valid arguments.
we present an open source tool that realizes our approachand we have conducted extensive experiments showing significant performance improvements of our approach over the state of the art.
the remainder of the paper is organized as follows.
section ii introduces the background on android event regis trations.
section iii presents our approach.
section iv introduces the implementation of ehbdroid .
section v evaluates ehbdroid .
section vi discusses limitations of ehbdroid.
section vii reviews related work and section viii concludes.
ii.
a ndroid event registra tion android apps are event driven programs with abundant ui events system events and inter app events.
based on our study of the android api we identify three event registration patterns cf.
table i which are useful for the instrumentation of our approach.
pattern static registration pattern a static registration pattern is defined as s.elm where sis an event source declared in the xml resource file and elm represents an element method or field of sdeclared in the same file a if sis a view elm is the method invoked by the event handler of s. b if sis a component i.e.
activity service or receiver elm is an intent filter object defined by s. pattern a is only applicable to ui events and their handlers and pattern b is only applicable to system andinter app events and their handlers.
fig.
a shows an example of static registration pattern for ui events where button is a view and click is the method invoked by the event handler ofbutton.
fig.
a presents an example for service event registration where service is a component and intent filter is its attribute.
pattern dynamic registration pattern a dynamic registration pattern is defined as s.rm h in the app code where sis the source of an event rm is the registration method of s and his the event handler that sregisters.
pattern applies to both ui and system events.
in fig.
b btn is a view setonclicklistener is the registration method and listener is the event handler.
in fig.
b sm is a service registerlistener is the registration method and lis the event handler.
pattern callback overridden pattern a callback overridden pattern is defined as s.callback where sis the source of an event e and callback corresponds to e s event handler.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
pattern is only applicable to view events.
for this pattern one should override the corresponding callbacks in the app code.
the following six callbacks are frequently used in this pattern onlistitemclick performclick ontouchevent onkeyup onkeydown performlongclick .
fig.
c presents an example where myview is a view and performclick is the overridden method.
view callback button android id .
android onclick click a 1btn .
setonclicklistener listener b 1class myview extends view void performclick c fig.
.
examples of ui event registration service name musicservice intent filter ... intent filter service a 1sensormanager sm getsystemservice l new sensoreventlistener void onsensorchanged 4sm.
registerlistener l b fig.
.
examples of service event registration iii.
ehb t esting in this section we propose the event handler based testing approach for android apps.
a. motivation and challenges fig.
exhibits a code snippet from the opensudoku app which involves one ui event and one system event.
for the ui event the corresponding ui element event handler and callback are listview f olderlistactiviy and onlistitemclick respectively.
for the system event the corresponding eventhandler and callback are sm and onsensorchanged .
to test this app with traditional ui based approaches these two eventsmust be triggered as the test inputs.
however generating these two events is not easy because triggering the ui event needs to click the right list item on the screen and triggering the system event needs to simulate a sensor change.
moreover once being triggered these two events have to be analyzed by the underlying android os and then passed to their event handlers through numerous layers of the android framework which can slow down the testing.
to test this app we directly invoke both of the two callbacks onlistitemclick and onsensorchanged in the app code as shown in the grey region rather than trigger the correspond ing events from the ui hierarchy.
in this way not only the two yrlghke7hvw v vwhphyhqw 6hqvru yhqwvh vp jhw6hqvru yhqw vho rq6hqvru kdqjhg vh hyhqw iru lqwl l oy vl h l 9lhzy oy jhw klog w l orqjlg oy jhw gdswhu jhw whp g l wklv rq lvw whp olfn oy y l lg fodvv roghu lvw fwlylw h whqgv lvw fwlylw yrlgrq uhdwh xqgohexqgoh v vwhphyhqw 6hqvru0dqdjhuvp jhw6 vwhp6huylfh 6hqvru yhqw lvwhqhuvho qhz6hqvru yhqw lvwhqhu yrlg rq6hqvru kdqjhg 6hqvru yhqw v vp uhjlvwhu lvwhqhu vho hyhqw lvw9lhz oy jhw lvw9lhz lqyrnhgzkhqolvwlwhplvfolfnhg yrlgrq lvw whp olfn lvw9lhzo 9lhzy lqwsrv orqjlg qwhqwl qhz qwhqw wklv 6xgrnx lvw fwlylw fodvv l sxw wud b 5b lg vwduw fwlylw l dooedfn lqyrfdwlrqv fig.
.
a motivating example from the opensudoku app events can be simulated easily but the testing itself can also be performed more efficiently.
considering the large number of events and the difficulty of event generation in many cases our approach is a promising alternative for app testing.
challenges.
however there are several challenges in realizing the idea above we need to identify the event handlers that is the callback functions and construct their invocations.
androidprovides different callbacks as a part of the framework and besides there can be many user defined or overridden callbacks.
it is challenging to correctly identify them and construct their invocations.
we have to construct valid arguments for the callback invocations.
for example the callback onlistitemclick has four different types of parameters listview view position and id.
it is uneasy to obtain valid values for the parameters from the app.
we should insert these callbacks at proper locations in the app and to control their invocations such that the app canbe systematically tested.
it is challenging to insert these invocations without breaking the lifecycle of activities and to invoke them to effectively cover different activities.
b. invoking event handlers we first identify all event registration statements in the app based on the three patterns presented in section ii.
algorithm 1performs a linear scan of the app to find all events and their handlers declared either in the xml resource files or in the app code .
then for each event registration statement we construct an instrumented invocation statement which will be authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm search for events and their handlers input the apk file of an android app output e xml elements matching with pattern s statements matching with pattern m methods matching with pattern 1for each xml resource file f app do for each xml element e fdo ifematches with pattern then e e e 5for each class c app do for each m cdo ifmmatches with pattern then m m m for each statement s mdo ifsmatches with pattern then s s s inserted into the app according to the invocation pattern of event handlers defined below.
pattern invocation pattern the invocation pattern for event handlers used for the instrumentation is defined ash.callback s where sis the event source hthe registered event handler and callback the callback method of h. to construct the callback invocation we need to identify the three elements s h and callback for each event registration pattern.
for pattern a and pattern view sis the event source elm is the callback and the object that defines elm is the event handler h. for pattern b component sis the event source and elm is the intent filter.
in this case the life cycle method of sis the callback and the class that defines this method is the corresponding event handler.
for this pattern besides s the intent filter elm is also the parameter of the callback.
for pattern we can obtain the callback from the event handler registered by the registration method rm.
figs.
4a 4c present the instrumented invocation statements forthe ui event registration examples in figs.
1a 1c respectively.
fig.
4d shows the instrumented invocation statements for the service event registration examples in fig.
.
m is click method 2object c m.getclass .
newinstance 3c .
click btn a listener .
onclick btn b 1myview.newinstance .performclick c activity mainactivity 2receiver ma bootreceiver.newinstance intent intent createintent intentfilter 4ma.onreceiver mainactivity intent d fig.
.
examples of invocation patterns for instrumentation c. constructing callback arguments for all the callbacks provided in the android api we have successfully instrumented their invocations in apps.
inthis subsection we describe how to construct valid arguments for these callback invocations.
one way to construct the callback arguments is to collect the runtime data for a few test runs e.g.
with existing test cases and use the collected data as the arguments.
nevertheless this method requires the existence of good test inputs.
after analyzing the callbacks we propose a simple yet effective method to construct valid arguments based on the default values and from the app context.
this method is complementary to the first method and it does not require extra test runs.
using default values .
data types in java can be divided into primitive types and reference types.
for primitive data types android api usually provides default valid values.
for this kind of parameters we use their default values as arguments for the corresponding callback invocations.
if a callback involves several parameters we enumerate all combinations of their default values.
deriving from app context.
for parameters of thereference data types the valid values objects can be obtained from the app context.
these parameters are usually connected with the event source and thus can be obtained by invoking relevant apis of the event source.
for arguments that cannot be directly obtained from the app context we can get them through java reflection.
for instance to construct the arguments for the ondrag callback we cannot get a dragevent instance via new dragevent directly because only a private construction method is provided.
instead we utilize java reflection toget the private constructor set its accessibility to true andfinally get an instance via invoking class.newinstance .
example.
the grey region in fig.
illustrates how we construct the callback arguments for the motivating example.take the callback onlistitemclick listview lv view v int pos long id as an example.
its first argument is a listview instance which can be obtained from the app context.
the second is the view that is clicked within the listview.
the third is the position of the view in the listview.
the last is the row id of the view.
the last three parameters are all correlated with the first parameter lv and thus can be constructed from it.
lines show how to obtain the second third and fourtharguments.
line is the instrumented callback invocation.
the reason why we do not use default values for the parameters of primitive types is to enumerate all possible values.
notethat our approach can automatically construct such arguments from the correlated objects using android apis.
d. exploration strategy the logic of an app can often be described as a state machine or a directed graph where nodes represent activities and edges the activity transitions caused by events cf.
definition .
fig.
depicts a part of the state machine of the opensudoku app.
note that the state machine is just to help readers understand our approach it is unnecessary to explicitlyconstruct it in our approach.
definition app abstraction an app can be abstracted as a state machine a e where authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
soduku list sudoku play file listfolder listsudoku edit game 6ettingse1 e6 e7e4 e5 sudoku exporte2e3 e8e0 fig.
.
part of the state machine of the opensudoku app.
ais an activity set a0 a is the main activity and ai a is called the current activity if it is active on the screen of the user device.
eis the set of all possible events in the app and e ai e is the set of events that can be triggered in ai.
a e a is a ternary transition relation.
without loss of generality our testing focuses on event coverage i.e.
aiming to cover all events in an app.
to this end all nodes activities where events can be triggered shouldbe visited.
android provides an activity stack managing all activities which allows us to use a depth first search strategyfor activity event traversal.
beginning from the main activity a we first identify the event handlers callbacks of events in e a0 .
then we invoke all these callbacks in a random but valid order cs .
that is each callback can only be invoked if the correspondingevent is valid at the current state of a if there is more than one valid event the invocation order of these callbacks israndom.
notably the invocation of some event handlers in cs may cause the transitions from a 0to other activities.
these activities are automatically pushed into the android activitystack.
after all event handlers in a 0are invoked the activity aiat the top of the stack is popped.
the same strategy is used to explore all event handlers in ai.
the above procedure iterates until all activities of the app are explored.
to ensure that our instrumentation is valid the callbacks should be invoked in a similar way as the user s click on the ui elements.
with this in mind for each activity we build a specific menu item test with its event handler en capsulating a valid callback sequence of events in e a i .
in the following example the menu item test registers alistener onmenuitemclicklistener whose callback is onmenuitemclick .
in the callback the invocations of event handlers are instrumented.
1menuitem menuitem new menuitem test 2onmenuitemclicklistener oml 3oml new onmenuitemclicklistener void onmenuitemclick inserting invoking statements 7menuitem.setonclicklistener oml algorithm presents our test exploration strategy which accepts the instrumented apk file as input.
in the algorithm algorithm ehbdroid test exploration input the instrumented apk file of an android app 1s s.push mainactivity 2while sis non empty do currentactivity s.pop ifcurrentactivity lthen l l currentactivity trigger new event test for each activity aigenerated by test do s.push ai else click navigation back besides the android activity stack a list lis utilized to denote the activities that have been explored.
algorithm works as follows if currentactivity has not been explored all event handlers in currentactivity are triggered by clicking test and the generated activities are all pushed into s. otherwise the testing continues to explore next activity on the top of the stack by pressing back .
the algorithm terminates when the activity stack sbecomes empty.
since each activity is explored only once time complexity of algorithm is linearin the number of activities.
example.
consider the example in fig.
where sodukulist is the main activity.
when the instrumented test menu item in sodukulist is clicked event handlers of the five events e e4insodukulist are triggered and the generated activities are pushed into the stack s following a random order e.g.
sodukuedit sodukup lay sodukup lay f olderlist and sodukuedit.
although there are repeated activities in s their exploration is not redundant according to algorithm .
next sodukuedit is explored as it is at the top of s. the other activities are all explored similarly.
iv .
i mplement a tion we have implemented ehbdroid as a fully automated tool based on soot .
fig.
depicts its architecture which consists of two main parts an instrumentor that instruments the target app and a testing explorer that tests the app.
important modules of the two parts are explained below.
xml parser and recognizer.
the first step of ehbdroid is to search different event registration patterns in both thexml resource files and the app code.
the xml parser utilizes xmlprinter to parse the input xml resource files.
based on pattern it searches for two kinds of tuples.
the first kind consists of a view and a method while the second kind consists of a component and one or more intent filters.
all these tuples are stored in a map.
the recognizer then searches for all statements that match with pattern and pattern .
all qualified statements are summarized in a set of java objects.
in each of the java objects there are three different fields event source registered methods event handlers.
dispatcher.
the dispatcher determines the activities that contain the event sources identified by the xml parser and the recognizer.
it constructs in each activity a test menu item that manages the invocation statements for the corresponding authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
apk qyrfdwlrq 0dqdjhu qyrfdwlrq xloghu5hfrjql hu 3duvhu rjjhu lvsdwfkhu qvwuxphqwhg apk ktz .gtjrkxy t uigzout gtj rummotm yzszy h loh qvwuxphqwhu soruhu olfn edfn olfn 7hvw xuuhqw fwlylw qr hvylvlwhg?
fig.
.
architecture of ehbdroid.
callbacks.
the target activity of the invocation statement is determined as follows.
if the event source is a view the target activity is obtained by view.getcontext .
if the event source is a component i e. activity service receiver thecorresponding event can be triggered in any activity.
without loss of generality in this case the main activity is considered as the target activity.
invocation builder.
this module constructs the invocation statements according to pattern .
the arguments of callbacksare constructed according to the two means presented in section iii c. for inter app events since the corresponding activities are started by third party apps we simulate these apps by directly instrumenting the statements that start new activities like startactivity intentfromintentfilter in the main activity of the app to be tested.
invocation manager.
an invocation manager corresponds to our instrumented event test and is realized by a test menu item in each activity.
a valid sequence of callback invocations in an activity is gathered in the event handler of test .
once the test menu item is clicked all instrumented statements in the activity will be triggered.
explorer .
by maintaining a list of visited activities the explorer can determine whether the current activity has beenexplored.
if an activity has not been explored the explorer will automatically click the test menu item in the activity to explore it.
otherwise the explorer clicks back and the another activity on the top of the android activity stack becomes the current activity.
the above step iterates until the activity stack becomes empty.
we leverage monkeyrunner in the android automated testing framework to send the devicetwo ui events click test and press back .
the current activity is obtained by the command adb shell dumpsys activity ofandroid debugging bridge .
after introducing the implementation of ehbdroid we discuss how it handles crashes and how it is used for debugging.
handling crashes.
in android when an uncaught exception occurs the app will crash and terminate.
to ensure that thetesting continues until all event handlers are explored we instrument every invocation statement in a try catch block.
thus when an exception bug is found we can record the exception information and go on testing.
enhancing debugging .ehbdroid also allows to piggyback the instrumentation to generate execution logs logger is in charge of this.
.
the log records the runtime state of each event e.g.
activity event source event handler and callback which is useful for debugging.
for example when a failureoccurs the recorded events can be used by robotium or other ui based tools to reproduce the failure.
moreover the corresponding bug can be easily located by inspecting the failing event handler.
v. e v alua tion we have evaluated ehbdroid on a collection of realworld android apps from f droid and google play and com pared it with two popular ui based app testing approaches monkey and dynodroid both of which have proven fault detection ability .
through the experimental evaluation we aim at answering the following three research questions rq1 code coverage can ehbdroid achieve a higher code coverage than the other two approaches?
rq2 testing efficiency how efficient is ehbdroid in terms of event handlers triggered per minute?
rq3 fault detection ability compared with the other two approaches can ehbdroid find more bugs?
benchmarks.
table ii lists the apps used in our evaluation.
these apps are randomly chosen from f droid and googleplay with no prior knowledge about their event handlers.
the first from f droid are popular benchmarks with a wide variety of functionalities with 21k lines of code jimple methods and activities on average for each app.
the other apps from google play are all large and complex apps among the top in the android market with 96k lines of code .7k methods and activities on average.
experimental setup.
the monkey tool is a part of the android sdk and is widely used by developers.
it regardsthe app under test as a black box and randomly generates ui touch x y events.
since the number of generated events in monkey can be configured by users in our experiment we set a sufficiently high bound 1m events to ensure that monkey does not stop too early in order to make a fair comparison.dynodroid enhances monkey by reducing the possibility of redundant event generation.
we employ the default setting biasedrandom strategy of dynodroid in our experiment.
all experiments were performed on a pc with a 4gb memory and .4ghz processor running linux and android4.
.
all experimental data were averaged over three runs.
a. code coverage we use statement coverage as the criterion to compare the testing effectiveness of different approaches.
because existing tools for calculating statement coverage such as jacoco and emma require java source code they cannot be authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t able ii benchmarks used in our experiments app name loc class method act agrep androidomatick audiobook browser dalvikexplorer kolen vector atomic podax nectroid notepad opensudoku ringdroid sanity tippytipper virtualdataline vudroid dashclock pedometer apollo sipua anima editor qksms k9 average tinyflashlighted adobereader fightpic colornote podcast adobeair wordpress pokegowallpaper beautyplus wikipedia average used in our scenario where only the apk file is available.
we hence implement a new tool called asc android statement coverage for calculating the statement coverage for apk files.asc first uses static analysis to extract the length of each basic block of each method.
then it instruments a statement at theend of each block to print the length of the executed block.
the total lines and visited lines of statements can be calculated byl n summationtext i 1liandlv n summationtext i 1bi li respectively where nis the number of blocks in the app lithe length of a block and bi or indicates whether the block is executed.
overall results .
we test each benchmark with the three tools and collect the coverage statistics for both the first minutes and the end of an hour.
table iii reports the results.
for all the benchmarks ehbdroid was able to finish testing i.e.
no more activities to explore in minutes and formost benchmarks in f droid and in google play ehbdroid achieved a much higher coverage than the other two tools in minutes.
for the f droid benchmarks onaverage the coverage of ehbdroid is .
and .
higherthan monkey and dynodroid respectively.
for the google play apps the difference is even larger.
ehbdroid achieves as much as more coverage than monkey on colornote and .
on average.
dynodroid failed to run on all of these apps because it requires instrumenting the manifest file before testing which throws exceptions in these large apps.
given more testing time both monkey and dynodroid were able to increase coverage for many apps.
however after one hour their achieved statement coverage is still smaller than that by ehbdroid .
for apps from f droid the average coverage by monkey and dynodroid is close to smaller than ehbdroid .
nevertheless for those from googleplay the difference is still significant.
compared to monkey ehbdroid achieved as much as .
higher statement coverage and .
higher on average in an hour.
result analysis.
our empirical results suggest that ehbdroid is more effective and efficient than the other two uibased testing approaches.
this confirms the advantage of ehbdroid over monkey and dynodroid by directly triggering event handlers of ui system and inter app events whereasmonkey and dynodroid can only trigger a part of ui events and some system events monkey cannot .
for instance the opensudoku app contains a few context menu events which require two steps to trigger long pressing and clicking on thepop up menu item.
monkey and dynodroid hardly trigger these events as they do not consider long press events letalone their combinations with a successive click.
we also found that it is difficult for monkey anddynodroid to generate events associated with navigation drawers listitems preferences etc.
for instance the app colornote has a navigation drawer containing a few items that drive usersto different activities.
usually these items are invisible until the navigation view is clicked.
however when one of these items is clicked other items are invisible again.
hence given a limited time monkey and dynodroid can only trigger a few items but not all of them.
in contrast ehbdroid guarantees to trigger callbacks for all items because those events correspond to the same callback and their event handlers can be invoked easily by ehbdroid with different parameters.
another reason why ehbdroid achieves a higher statement coverage than the other two tools is that when most events in an activity do not cause activity jump the ui based approaches often fall into a loop which is hard to jump out.
the loop consumes time but does not explore more app behavior.
for example in an activity of the podcast app also colornote there are many enabled events that do not cause activity jump monkey stayed in this activity for a long time until the sole event that can cause activity jump was triggered.
for a few apps such as agrep and kolen the statement coverage of ehbdroid is lower than that of monkey or dynodroid.
the reasons are two fold.
first ehbdroid currently does not support text input .
in agrep a submit button is unavailable when the edit texts for userid and password are empty.
hence ehbdroid cannot reach the successor activities.
second for performance reason ehbdroid currently does not handle all items in a list because such authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t able iii experiment al results rq1 c ode coverage and rq2 t esting efficiency app name statement coverage 10min statement coverage 1h events per minute monkey dynodroid ehb monkey dynodroid ehb monkey dynodroid ehb agrep .
.
.
.
.
.
androidomatick .
.
.
.
.
.
audiobook .
.
.
.
.
.
browser .
.
.
.
.
.
dalvikexplorer .
.
.
.
.
.
kolen .
.
.
.
.
.
vector .
.
.
.
.
.
atomic .
.
.
.
.
.
podax .
.
.
.
.
.
nectroid .
.
.
.
.
.
notepad .
.
.
.
.
.
opensudoku .
.
.
.
.
.
ringdroid .
.
.
.
.
.
sanity .
.
.
.
.
.
tippytipper .
.
.
.
.
.
virtualdataline .
.
.
.
.
.
vudroid .
.
.
.
.
.
dashclock .
.
.
.
.
.
pedometer .
.
.
.
.
.
apollo .
.
.
.
.
.
sipua .
.
.
.
.
.
anima .
.
.
.
.
.
editor .
.
.
.
.
.
qksms .
.
.
.
.
.
k9 .
.
.
.
.
.
mean .
.
.
.
.
.
animeradio .
.
adobereader .
.
.
.
fightpic .
.
.
.
colornote .
.
.
.
podcast .
.
.
.
adobeair .
.
.
.
wordpress .
.
.
.
pokegowallpaper .
.
.
.
beautyplus .
.
.
.
wikipedia .
.
.
.
mean .
.
.
.
item events often trigger the same behavior.
we set a fixed number e.g.
to limit the invocation times of the callback onitemclicked with the assumption that most of the items are handled in the same way.
thus if a listitem contains more than items each of which is handled differently some app behavior may be missed.
low code coverage .
for most apps the achieved statement coverage by all the three tools is low less than .
there are several reasons.
first in many apps there exists a large portion of code that is not relevant to the business logic of the app.
such code can only be reached under specific scenarios such as bug reporting version updating exception handling etc.
second some apps have dead code that can never be explored.
for example sipua contains a large number of branches and methods that can never be reached.
third some activities failto be explored due to the missing of certain events for activity jumping.
when such an event is missed the target activity and its successor activities may not be explored.
fourth certain code requires special permissions and is not accessible toordinary users.
for example commercial apps usually provide both a free version and a paid version.
the paid functionalities can only be explored via a paid account.
b. testing efficiency the last three columns in table iii report the number of events for monkey and dynodroid or event handlers for ehbdroid generated per minute by the three tools.
we use this metric to further show the testing efficiency of the three approaches.
monkey is the fastest approach among the three.
it generates .5k events and 3k events per minute for the f droidand google play apps respectively.
however these events contain a large number of redundant i.e.
repeated or invalid events that are not useful in exploring new app behavior.
dynodroidcollects events and sends them to the app at a fixed frequency once every 5s via the android debug bridge.
accordingly the number of events generated per minute by dynodroid is a constant .
among these events there may also exist redundant or invalid events.
in contrast each event authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t able iv experiment al results rq3 f ault detection ability app name monkey dynodroid ehbdroid agrep notepad opensudoku ringdroid sanity padometer apollo k9 colornote adobereader total handler invocation by ehbdroid is unique and non redundant.
moreover the speed of ehbdroid is more than twice as that of dynodroid generating events per minute.
since in our experiment the average time to instrument one app is one minute ehbdroid is still more efficient even if the instrumentation time is included.
another reason why ehbdroid is more efficient than monkey and dynodroid lies in the fact that with one click on test all event handlers in the current activity are invoked together by ehbdroid which avoids the latency caused by gui and the cost of message passing in the system.
inparticular if an activity contains many events that cause activity jumping the testing time can be improved significantly bydynodroid because activity jumping is expensive and the ui based approaches must jump back and forth repeatedly totrigger all events in that activity.
for example tippytipper is a rate calculator containing buttons.
to test all the buttons dynodroid needs 100s while ehbdroid takes only 2s to invoke the callbacks times.
c. fault detection ability table iv summarizes all bugs found by the three tools in our experiments where represents bugs found after an hour.
in ten minutes ehbdroid found a total of bugs manifested as crashes or runtime exceptions in these apps whereas monkey anddynodroid only found five and four respectively.
after running for an hour monkey and dynodroid found two and three more bugs respectively.
overall ehbdroid found five new bugs that could not be found by monkey and dynodroid and all bugs that found by monkey and dynodroid were also found by ehbdroid .
these bugs fall into three classes ui bugs inter app bugs and special bugs.we have also manually inspected these bugs and confirmed their validity.
we next describe them in detail.
eight ui bugs .
these bugs were found in apps agrep opensudoku ringdroid sanity padometer apollo k9 and colornote byehbdroid .
except colornote the other seven were also found by monkey and dynodroid.
when the corresponding events are triggered these apps crash.
for example in the k9 mail client when an option button in the setting activity is clicked the app terminates abnormally.
the erroris due to the fact that in the corresponding event handler k9 uses an implicit intent to start a new activity but neither the app nor the device can handle the intent.
the ui bug of the app colornote was found in activity preferenceactivity by ehbdroid .
the other two tools failed to find this bug because they did not reach activity preferenceactivity .
three inter app bugs .
these bugs are found in apps notepad opensudoku and k9 byehbdroid.
these bugs are caused by the mismatches between some intent filtersand the received intents.
the code below shows such a bug detected in k9.
the activity messagelist defines an intentfilter in the manifest file to filter the incoming intents.
messagelist employs the method decodeextra to resolve intents requiring that the attribute action of the intent should be android.view.action.view line and the attribute data of the intent should contain a non null path line .
if data does not contain a path attribute when line is executed an exception is thrown and the app crashes.
monkey and dynodroid failed to find this kind of bugs because they do not consider inter app events.
class messagelist extends activity 2boolean decodeextras intent intent if android.intent.action.view .equals action intent.getdata !
null list locallist intent .
getdata .
getpathsegments string path string locallist .
get activity name messagelist intent filter action name android.intent.action.view data host messages scheme email category name android.intent.category.default intent filter activity one special bug .
this bug was found in adobereader byehbdroid .
it is special because it is in an event handler of a view that is invisible from the screen.
thus fromthe perspective of end users it is not a bug but from the perspective of programmers it is.
the code below illustrates the bug.
note that automationt.class is not declared in the manifest file.
hence the app violates the rule that an activityis valid only if it is declared in the manifest file.
when the nonvisible menu item is triggered the app crashes.
neither monkey nor dynodroid can find this bug whereas ehbdroid can because it can obtain all the menu items via menu.getmenuitems and directly trigger the events through onoptionsitemselected item .
1boolean onoptionsitemselected menuitem item 2swtich item .
getid 3case intent i new intent this automationt.
class startactivity i vi.
l imit a tions except the callbacks provided by android currently ehbdroid does not specially consider user defined callbacks.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fortunately we find that many user defined callback functions are invoked by the callbacks in android and thus these userdefined callback functions can also be explored by ehbdroid .
nevertheless since an event handler may be called in apartial invocation context that differs from the real scenario ehbdroid may yield false alarms false positives that are never triggered by end users though some of the false alarmsare still helpful for programmers.
since the mechanism of ehbdroid is parallel to the event generation it is orthogonal to the coverage criteria and ex ploration strategy.
currently ehbdroid is at an early stage.
although a depth first search strategy is used for activityexploration the event handlers belonging to an activity are invoked in a random though valid order and only event coverage is considered.
thereby ehbdroid is not compared with the model based and more advanced app testing tools that are based on event event sequence generation such as guiripper swifthand sapienz etc.
ehbdroid relies on soot for app instrumentation.
however soot fails to instrument certain large apps with more than two dex files.
besides some apps prevent from being instrumented by hiding dex files checking signatures etc.
thus ehbdroid may fail to instrument such apps.
vii.
r ela ted work for android app testing a large body of work focuses on test input generation i.e.
event generation.
according to theirexploration strategies existing approaches fall into three categories random testing or fuzzing which generates random events to apps model based testing which generates events according to certain models such as finite state machines of apps and advanced testing which uses more sophisticated techniques such as symbolic execution to generate events.
compared to existing work ehbdroid is distinguished by not generating events but directly invoking callbacks of therelevant event handlers which is more efficient and effective.
considering the correlation between events and event handlers our testing approach applies to general event driven systems.
random testing.
besides monkey and dynodroid most early work focuses on random testing .
amal fitano et al.
present a crawling based approach to generate random but unique test inputs.
there exist many tools for generating inter app events by random generationof intent values .
null intent fuzzer concentrates on revealing crashes of activities that fail toproperly check input intents.
intent fuzzer focuses on generating invalid test events with the goal of testing therobustness of apps.
the primary limitation of random testing is that it often generates redundant events that are not useful for exploring new app behavior.
model based testing.
this line of research often requires a gui model of the application and has been intensivelystudied in gui testing .
the gui model can be obtained manually or via static dynamic analysis .
hierarchy viewer is a tool for generating gui models for android apps.
based on the gui model events can begenerated to systematically explore the behavior of the app.
for instance guiripper dynamically constructs an event flow graph for an android app and follows a depth firstexploration strategy to test the app.
orbit adopts the same exploration strategy but it is a white box approach thatutilizes the source code of the app to determine the events that can be triggered in each activity.
similar approaches and tools can be found in .
however the effectiveness of these approaches heavily relies on the quality of the gui model.
in practice the models are often very abstract and may not capture the complete behavior of the apps.
advanced testing.
jensen et al.
use symbolic testing to generate event sequences that reach specified target locations .
acteve utilizes concolic execution to track events from their generation to their processing.
these approaches instrument both the android framework and the app and can generate more complex event sequences that the other tools cannot.
however the scalability of symbolic testing is often limited.
similar approaches can be found in .
by analyzing the interactions between widgets t rimdroid employs the constraint solver to generate a subset of event sequences which can achieve a comparable coverage as the exhaustive combinatorial testing.
evodroid employs evolutionary algorithms to generate complex eventsequences.
sapienz uses search based testing to automatically explore test sequences to minimize the length ofevent sequences and simultaneously maximize code coverage and fault revelation.
the tool appdoctor also triggers event handlers to simulate events.
however it only considers types of events and merely focuses on specific bugs that cause apps to crash.
in addition it uses java reflection to trigger event handlers which is not so efficient.
in contrast to appdoctor ehbdroid directly invokes event handlers based on instrumentation which is more general and more efficient.
viii.
c onclusions we have presented a new approach called ehbdroid for testing event driven systems and specifically discussed its concretization for testing android apps.
the key advantage of ehbdroid is that by directly invoking the event handlers it avoids the difficulty of generating complex events that are hardto trigger by traditional ui based approaches and it avoids the latency induced by the gui and the cost of message passing in the system.
we have presented an open source tool and evaluated its performance on a collection of realworld android apps.
experimental results demonstrate that ehbdroid can quickly reach higher statement coverage than the state of the art ui based testing approaches and it is morepowerful than the other approaches for finding bugs.
a cknowledgments this work was supported in part by the national key r d program of china under grant no.
2017yfb1001801 thenatural science foundation of jiangsu province under grant no.
bk20171427 and the fundamental research funds for the central universities under grant no.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.