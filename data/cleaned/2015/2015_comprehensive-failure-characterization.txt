comprehensive failure characterization mitchell j. gerrard and matthew b. dwyer university of nebraska lincoln lincoln ne usa fmgerrard dwyerg cse.unl.edu abstract there is often more than one way to trigger a fault.
standard static and dynamic approaches focus on exhibiting a single witness for a failing execution.
in this paper we study the problem of computing a comprehensive characterization which safely bounds all failing program behavior while exhibiting a diversity of witnesses for those failures.
this information can be used to facilitate software engineering tasks ranging from fault localization and repair to quantitative program analysis for reliability.
our approach combines the results of overapproximating and underapproximating static analyses in an alternating iterative framework to produce upper and lower bounds on the failing input space of a program which we call a comprehensive failure characterization cfc .
we evaluated a prototype implementation of this alternating framework on a set of c programs from the sv comp benchmarks and the data indicate that it is possible to efficiently accurately and safely characterize failure spaces.
i. i ntroduction significant effort in software development is directed at determining whether programs behave as intended.
while a test engineer might consider the discovery of evidence of a program failure as the end of the story in reality it is just the beginning.
for example a development team may follow up by triaging and understanding the failure then repairing the fault that led to the failure and finally validating its correctness and deploying the fix.
while it is possible to perform this work manually there has been significant research into automating these facets of software development e.g.
.
all of these development steps could benefit from expanding the description of the failure from a single input vector to a more comprehensive characterization.
triaging could potentially identify duplicate reports more easily understanding could be improved by identifying multiple ways that the failure could be exhibited repairs could be made more robust by covering the full failing input space and validation could be focused on the space of inputs indicated by such a failure characterization.
in this paper we explore methods that begin with a single indication of a program failure and construct a rich characterization of the program behavior that may exhibit that failure.
our aim is that this failure characterization be both comprehensive in that it characterizes all failing behavior and constructive in that it definitively characterizes failing behavior.
moreover we seek to render the characterization in a form that can be exploited by both automated and manual methods.
towards this end we define a comprehensive failurecharacterization cfc as a pair of logical formulae that bound the failing input space of a program.
imagine a failure report that includes the test input test .
we seek to compute a pair of formula that define an upper bound e.g.
i1 i2 i and a lower bound e.g.
i1 i2 i i2 on the failing input space iirepresents the ith input.
the upper bound defines the space of inputs on which the program may fail whereas the lower bound defines the space of inputs on which it must fail.
we conjecture that this richer failure information can be leveraged in manual and automated development processes.
for example the upper bound above indicates that the third input is not implicated in the failure which may simplify program understanding.
whereas the lower bound establishes a minimal set of inputs for regression testing the upper bound establishes a maximal set since inputs outside of that bound are guaranteed to be failure free.
we discuss selected applications of cfcs in sec.
vi.
we explore the combination of over and underapproximating static program analyses to compute cfcs.
overapproximating analysis tools such as absint astr ee facebook infer and mathworks polyspace have the ability to prove the absence of certain types of program failures.
this benefit comes with the downside that reports of failures from these tools may be spurious they may not correspond to executable program behavior.
underapproximating analysis tools such as microsoft sage klee and mayhem have the advantage that they never report a spurious failure.
this benefit comes with the downside that they may miss failures and thus cannot prove their absence.
for more than a decade researchers have understood that there are advantages in using these approaches in combination e.g.
.
conceptually these techniques alternate the application of over and underapproximating analyses with the output of each driving the other toward convergence.
rather than develop a bespoke alternating analysis we develop a framework to extract and combine information from existing static analysis tools to achieve the efficient accurate and safe computation of cfcs.
the resulting framework for alternating characterization of failures acf leverages the strengths of existing state ofthe art analysis techniques and tools while tolerating their limitations.
we illustrate the acf framework in the next section and describe it in more detail in sec.
iii.
we describe an instance of the framework for c programs that incorporates state of the art c analyzers in sec.
iv.
we report on an .
c ieeease urbana champaign il usa technical research365 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
i n t main i n t argc char a rg v f i n t x a t o i ar g v i n t y a t o i ar g v i n t tmp i f y f i f x x x f o r i n t i i y i tmp i 10ge l s ef tmp y y 12g a s s e r t tmp 14g a example c program fcpa y y b cfc calculated with cpa fua y y fua c cfc calculated with ua fig.
example program with calculated cfcs evaluation that assesses the efficiency accuracy and safety of acf to a corpus of c programs in sec.
v. ii.
o verview in this section we describe the concept of a cfc and our proposed analysis framework to compute failure characterizations using the small simple example in fig.
1a.
a detecting failures there are a variety of methods for detecting program failures but we focus here on the use of state of the art static program analyzers.
these tools vary in their cost in their ability to detect failures and in the guarantees that they provide about failure reports.
for example cpachecker cpa is the analyzer that finished second in the sv comp competition .
when run on the example with the svcomp option the tool reports a failure when the false branch is taken at line .
this is however a spurious failure report that arises because cpa is designed to overapproximate program behavior so as to soundly prove the absence of failures.
the abstraction of the program state used by cpa leads to this inaccurate failure report a problem that is inherent with overapproximation.
different analyzers may report different failures and with different fidelity.
for example ultimateautomizer ua the overapproximating analyzer that won the and sv comp competition reports a failure when the true branch at line 5is taken then the false branch at 6and the loop header at .
executing this path leads to a violation of the assertion at line 13and thus represents a definite failure of the program.
unlike cpa and ua civl is an underapproximating analyzer for c programs.
it also reports the failure detected by ua and moreover it is able to compute that the failure corresponds to running the program with the second parameter equal to i.e.
it computes a constraint y that characterizes the failing input subspace.
for clarity in the presentation we use yto model the value of variable y. note that an underapproximator like civl could have missed the failure by first analyzing the loop and timing out here civl gets lucky by exploring the false branch first.
b alternating characterization of failures our proposed framework seeks to compute a efficient accurate and safe characterization of program failures.
our insight is thatthis can be achieved by alternating the application of over and underapproximating static analyses to leverage their strengths while accommodating their weaknesses.
figure sketches the architecture of the acf framework.
the analysis accepts a program p and a reachability property as input assert statements are a natural means of expressing .
it computes a comprehensive failure characterization f which consists of an upper bound that is guaranteed to subsume all failing behavior and a lower bound that is guaranteed to be subsumed by all failing behavior.
fis constructed incrementally by combining characterizations of failure subspaces f that are computed by iterations of the acf framework.
the framework relies on the notion of conditional program analysis where information is computed about partial analysis results and then used to direct subsequent analysis for instance to avoid repeatedly analyzing program behavior.
there are five major phases of the framework numbered in the black circles depicted in fig.
along with the data and control flows between them.
we elide some detail here but present a complete explanation in sec.
iii and in alg.
.
the possible failure 1phase seeks to detect a new potential program failure using an overapproximating analysis a. it uses the upper bound of the most recently computed failure subspace f up to condition the analysis to explore new behavior.
if ais unable to detect a new failure then the conditioning c isgeneralized and the analysis repeated.
when generalization is required we say that the conditioning was ineffective.
this iterative process will lead to the detection of a new failure or to proving the absence of additional failures then the final effective conditioning is used to define the failure subspace to merge withf abbreviated m in the figure .
the phase returns evidence of a failure or validity as eo where validity is denoted e and the effective conditioning c that allowed ato compute that result.
the definite failure 2phase seeks to confirm a potential failure or demonstrate that it is spurious using an underapproximating analysis a. it uses the overapproximating evidence of failure eo to condition the analysis to explore behavior in the neighborhood of the potential failure.
this phase also uses an iterative refinement of conditioning to compute a characterization of the failure e which is returned as eu.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
p f6 ?a gen. m f a v fvgeo e p cond c a spec .eu e a slice fpossible failure1 definite failure2 block valid3embed condition4slice failure 1f up veo c eo c0 1eoeuf v c c c c01 fig.
alternating characterization of program failure in this case however the conditioning is specialized to further restrict the analysis.
if the refinement process fails then ais applied to characterize a region of valid behavior by detecting violations of under the conditioning of eo this is used to block subsequent spurious failure reports.
these phases are complementary.
for example the first exploits abstraction approaches to efficiently analyze looping program behavior whereas the second exploits symbolic representations to accurately analyze complex branching along program paths.
the alternations of these phases use conditioning in complementary ways.
conditioning directs overapproximating analyses away from failure subspaces that have been already analyzed and directs underapproximating analyses towards a subspace that harbors a potential failure.
c an example consider a configuration of the framework where ais cpa and ais civl.
the analysis begins withf6 ?
by running phase 1using cpa with f up false i.e.
no behavior is excluded from the conditioned analysis.
as explained above cpa reports a failure along the path 13which is encoded in eo and cis initially false.
since evidence of a failure is found the comparison with e is false and acf continues to the right in the figure in this case the conditioning is trivial so the program is unchanged.
phase 2useseoto condition civl by directing it to analyze the failing subspace of behavior reported by cpa.
civl is unable to find an error so it analyzes the complementary property to compute y 0as evidence of valid behavior which is returned as euand which is fed back as vto begin a second iteration.
on this iteration f ?andv y 0which activates phase 3to block cpa s analysis from considering that path.
this succeeds in avoiding the spurious failure and cpa reports a new failure eo 13withc v y .
with non trivial conditioning phase 4embeds y into the program using an assume statement to ensure that no subsequent analysis considers it.
in the second execution of phase civl confirms this failure and computes eu y x y .
phase 5is able to determine that input xis independent of the failure through a form of program slicing and calculates a safe failure characterization off which is fed back to begin a third iteration.cpa attempts to restrict analysis to exclude f up but its abstractions are too imprecise and it finds the same error as before.
this triggers the generalization of the upper bound of fto be y 0which is effective in blocking further failure reports by cpa and the algorithm terminates with f f y y g. figure 1b illustrates the bounding characterization of the failure space that is computed the integer values of xandyare given on the respective axes failures may be exhibited when y the light gray space and they must be exhibited when y the darker gray space.
this execution of the acf framework required iterations involving conditioned runs of cpa conditioned runs of civl for and for generalization of failure characterization blocking of set of valid behaviors slicing of clause and variable from the characterization and it resulted in a cfc whose upper bound substantially overapproximates the lower bound.
instantiating the framework with ua instead of cpa and running on the same program requires just conditioned runs of ua and civl and involves no generalization.
slicing is applied to each element of the computed cfc to remove a clause and the resulting upper and lower bounds coincide as illustrated in fig.
1c.
iii.
a nalternating cfc f ramework letpbe the domain of programs and the domain of reachability properties.
a program analysis a targets a pair of elementshp i p2pand in order to provide information about whether the executions of pconform to i.e.
whether pj .
most modern program analysis frameworks produce some form of evidence about their claims of property validity or violation.
evidence of a violation can be as complete as a trace of program execution leading to a potential failure or as partial as designating a single statement at which the failure may occur.
a general model for such evidence termed an error automaton has been developed by the organizers of svcomp .
these automata would be used as evidence of failure for an overapproximating analysis e.g.
eoon output from 1or3.
error automata have a start state that coincides with the initial program state and transitions that are labeled by control flow branches.
the language of an error automaton authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
is a set of program executions e.g.
the set of all executions for an automaton that accepts immediately or a single execution which has a single enabled transition at each state.
letebe the domain of evidence produced by a program analysis.
this would include evidence of property validity e or violation e .
an evidence producing program analysis is a p !e.
all analyzers in the sv comp competition are evidence producing.
an overapproximating analysis a2ais one where a p e pj .
an underapproximating analysis a2ais one where a p e p6j .
conceptually ais capable of proving property validity and ais capable of proving property violation.
we assume that a program p2p has a set of input statements i2i that return well typed values where dom i is the domain of i s type.
to simplify the presentation of acf in this paper we formalize the analysis for programs that read from each input statement a single time thus the input domain of pisd q i2idom i and thus dis finite.
the framework and the implementation described in sec.
iv work more generally by modeling the kth execution of an input statement by the pair i k and the input domain as the union of execution specific input domains q j ndom i j where the inputs on an execution are h i1 in n i. the implementation can enforce a bound on the length of sequence to restrict analysis to a finite d in this it may lose accuracy by characterizing all inputs beyond the given length as potentially failing.
we consider sequential programs in this work leaving extensions to concurrency for future work.
a. failure characterization we characterize failures using logical formulae that encode regions of don which failures are detected.
let fp be an exact characterization of the input space on which the program fails relative to .
definition .
a comprehensive failure characterization cfc is a pair of logical formulae that bound the program s failure space fp such that c f c. cfcs lie between two extremes an exact cfc where the bounds coincide i.e.
c c f and a trivial cfc where the bounds are non informative i.e.
.
we work with a particularly advantageous form of cfc that permit algorithms to operate on elements of the cfc encoding.
definition .
a disjoint cfc is a set of pairs of formulae f where f2fcan be written f and such that the upper bounds are disjoint 8f f02f f6 f0 f up f0 up false and the upper bounds subsume the lower bounds 8f2f f up f lo false.
we write upper f s f2ff up andlower f s f2ff lo.
in a disjoint cfc there may be elements of the upper bound for which the associated lower bound cannot be characterized precisely.
in such a case the lower bound is false.while this lower bound is non informative its use is logically consistent given the disjunctive nature of the lower bound.
ideally fencodes a small failing subspace of d. in the worst case upper f d and all of the input space is implicated.
even here acf is able to isolate the imprecision to one element of the partition that will have as its upper bound the complement of the disjunction of all of the other upper bounds.
the remaining partitions provide useful information about failures especially in their lower bounds.
for example on the program ackermann02 false unreachcall true no overflow true termination.c ua directs civl to the failure and after blocking this exact characterization ua declares the remaining program failure free.
this is the ideal case.
at the other extreme on the program pc sfifo 2falseunreach call false termination.cil.c ua directs civl to a failure on the first iteration.
after this failure is blocked the overapproximators can neither find a new failure nor declare the program safe and the upper bound moves to true.
b. conditioning program analysis the goal of conditioning is to restrict the program behavior that is subjected to analysis.
for example to restrict the propagation of abstract states across a branch in aor prune the exploration of a subtree in a. there are many possible ways to define conditioning and in this work we employ two different approaches.
first given eoas an error automaton the automaton structure is used to direct the state space search performed by a. any branches that are inconsistent with eogo unexplored.
second given euas a logical formula defined over d we instrument the program with the statement assume e u to inform athat it need not consider that behavior.
regardless of the approach used we denote the conditioning of p s behavior for analysis asp cond c for conditioning c. while conditioning aaims to restrict the analysis to avoid previously analyzed failing subspace it does not guarantee that this will be effective.
for example if the expression e inassume e l cannot be precisely modeled by a s abstract domain then the semantics of the assume will be overapproximated.
generalization is used to address this issue.
dually conditioning aaims to restrict the analysis to a failing space of the program behavior in order to confirm the failure and characterize it.
effective conditioning for a means that the failures that are characterized are guaranteed to be executable.
when such guarantees are not computed e.g.
due to timeouts or overapproximation in underlying constraint solvers specialization further restricts the conditioning.
within phases 1and 2the use of conditioning is speculative in that we are seeking to determine if the conditioning is effective.
in the overall flow of the acf algorithm phase 2generates candidate conditioning phase 1confirms that it is effective or generalizes it until it is and phase 4embeds it into the program model for use in all subsequent analyses.
c. an alternating cfc algorithm the structure of the algorithm is depicted in fig.
.
algorithm provides additional details of the computation of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
cfcs.
the acf algorithm depends on certain properties of the algorithms that it combines.
specifically it assumes that over and underapproximating program analyses are typed a p !fe e ?g a p !fe ?g where?encodes the inability of the analysis to compute a result e.g.
due to a timeout encountering an unsupported language feature or unsoundness relative to the nature of the analysis approximation.
in addition it assumes the strict monotonicity and antimonotonicity of generalization and specialization relative to a finite order on formulae respectively.
function possible lines along with lines realize phase .
the additional detail in the algorithm is in the use of a cache of previously computed analysis results seen and the logic that continues generalization as long as no new analysis result is seen or the conditioned analysis is ineffective.
note here that the generalization process will converge to true due to monotonicity.
line will merge the new component of the cfc into fensuring that the result is a disjoint cfc.
function definite lines along with line realize phase .
here the original conditioning c is recorded inc0 for later use should the analysis not be able to detect a failure.
as above the iterative specialization of conditioning will terminate when the conditioned analysis is effective or when the specialization reaches the limiting false value due to anti monotonicity.
if a sound underestimating characterization of the failure e is found it is returned.
otherwise the original conditioning is used to analyze the negation of the property i.e.
to find a definitive characterization of program behavior that is consistent with .
this may be ineffective in which case evidence of valid behavior isfalse which will trigger termination on the next iteration in phase .
the main acf algorithm initializes the data structures lines and then begins the alternating iterative computation of a cfc.
note that the algorithm uses p0as the version of p that accumulates the effective conditioning across iterations.
the pair f vdrive the behavior of each iteration.
one or the other is well defined the other has value ?
the configuration is used to select the phase to execute.
once completed if the phase has determined at line that there are no additional failures or that awas ineffective then the accumulated cfc f is returned.
otherwise effective conditioning was computed and it is embedded into the program at line .
line applies slicing to the program using the evidence of failure eu which can be thought of as encoding a program trace.
a dynamic slicing algorithm can be used to eliminate branches from the trace that are independent of the failure.
finally lines determine whether the results of phase 2computed evidence of failure or evidence of validity and update the f vpair accordingly.algorithm alternating characterization of failures function possible p c .detect possible failure e a p cond c while e2seen e ?
c6 true do c generalize c e a p cond c end while seen seen feg return e c .
evidence effective conditioning end function function definite p c .detect definite failure c0 c e a p cond c while e ?
c06 false do c0 specialize c0 e a p cond c0 end while ife e then return e .
failure evidence else return a p cond c .validity evidence end if end function function acf p f v f v false seen p0 p loop iff6 ?then eo c possible p0 f up f merge f f g else eo c a p0 cond s v ifeo ?
c false then f f f false v f2f f up v v2v v g else v v fvg end if end if ifeo e eo ?then return f end if p0 p0 c .
embed conditioning henceforth eu definite p0 eo es slice p0 eu ifeu e then f v ?
else f v ?
e s end if end loop end function authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
theorem termination .
algorithm terminates if aand aterminate and generalize and specialize are strictly monotone and anti monotone relative to a finite ordering on formulae respectively.
proof.
there are three loops in the algorithm lines lines and lines .
termination depends on the existence of an ordering on the formulae that are used to encode conditioning.
the framework can be instantiated with any finite ordering.
for example containment ordering on sets of conjuncts from a cnf encoding of formulae.
an execution of lines is guaranteed to terminate if every call to a a terminates and if generalize specialize produces a result that is greater lesser in the ordering due to the finite bound on chains in the ordering.
the outermost loop executes once for each element of f andvthat is computed.
new elements are only computed if the conditioning is effective or in two special cases the loop at line exits because c true in which case e ?which triggers termination at line or line is executed which is also followed by termination at line .
there can be only finitely many elements of fandv since the upper bounds off2fand the elements of vare disjoint and their union must be a subset of d. theorem safety .
algorithm terminates with fsuch that the failure space of prelative to fp is bounded by f lower f fp upper f .
proof.
for all elements of f the lower bounds are computed byaand then sliced.
by definition acomputes a safe underapproximation and thus any failure detected is guaranteed to be feasible.
if no failure is detected then false is used as the lower bound which is guaranteed to be safe.
slicing only eliminates subformulae that are provably independent from the failure characterized by the partition.
thus while the sliced lower bound may subsume the original error detected by ait is guaranteed to underapproximate the space of all errors that are equivalent up to execution of independent branches.
for any iteration of the acf algorithm the upper bounds from all prior iterations are conditioned into the program by line and the upper bound from the current element of fis conditioned in possible.
the algorithm terminates only if the conditioning of all upper bounds permit a to prove the program free of failures or a final run of aresults in?in which case line adds an element to f that guarantees that upper f d. the first case guarantees that the upper bounds of fare safe since acomputes a safe overapproximation and the second case is trivially safe.
iv.
a p rototype acf i mplementation to explore acf we implemented alg.
along with incorporating or adapting other analysis tools to define the following components analyses slicing conditioning generalization and specialization.
our implementation consists of non comment source lines nsloc of ruby.
we chose ruby because it hasfacilities for easily processing text based files which plays an important role in integrating external tools e.g.
parsing tool output.
these facilities also enabled us to implement the source level instrumentation that is required by conditioning.
the prototype implementation including the source code docker image and all of the underlying data from our study is available at analyses we focused on analysis tools that participated in the annual international competition on software verification sv comp .
this allowed us to take advantage of the alreadyexisting corpus of hundreds of benchmarks of c programs submitted by the community.
the competition also requires that these tool report possible failures in a specified language so there was a common interface that we could build on.
our implementation permits multiple overapproximators to be used in a sequential portfolio i.e.
we run one after the other in sequence we plan to replace this with a parallel portfolio to reduce analysis time.
we incorporate ua and cpa since both performed well in the two most recent sv comp instances.
in addition to the standard sequential configuration of cpa we also used two other cpa configurations that participated in the competition one that combines a value analysis a predicate analysis and a technique for caching analyzed blocks and another that implements a variant of k induction .
ua and three different configurations of cpa constitute our portfolio of overapproximators.
the prototype also uses a portfolio of underapproximators but we have only populated it with civl.
the portfolio management implementation establishes an execution time bound ensuring that all analysis runs terminate.
slicing to determine which branches were relevant in triggering the failure we implemented a version of xin and zhang s dynamic slicing algorithm on the civl representation of the replayed failure trace.
this algorithm detects branches on the failing trace that are independent from the failure and consequently can be removed.
because this slicing algorithm detects only dynamic control dependence to ensure a safe underapproximation one whose logical formula encodes definite failure traces we also run an inexpensive static analysis.
this static analysis seeks to determine that branches not taken will not impact the detected failure.
to do this for each branch identified as independent we run a depth first search dfs on sub control flow graph rooted at the branch not taken in the trace the dfs backtracks when it rejoins the failure trace.
if the dfs encounters a suspicious statement then we assume that there may be a dependence and revert the classification of the branch as independent.
we define a suspicious statement as one of assignment to a variable that is data dependent on the failure a goto statement a function call and any statement involving pointers including arrays .
slicing is implemented as a configuration option sliceanalysis within civl s error replay feature.
the implementation consists of nsloc of java code.
conditioning there are two kinds of conditioning in an acf.
the first is a standard application of directed symbolic execution where the execution engine is guided down specified authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
branches instead of exploring all possible branches.
this kind of conditioning only applies to the underapproximators.
the directions at each branch come from the witness graphml files produced by the overapproximator when a possible failure is reported.
if a branch is not specified in the witness file then we inject no instrumentation at this branch and the underapproximator will do its standard exploration of both branches at that point.
this is implemented as a configuration option direct within civl s verify feature.
the implementation consists of nsloc of java code.
in our experience both ua and cpa produce witnesses that give full direction though our implementation of directed symbolic execution can also handle partial direction.
the other kind of conditioning is seen by both the over and underapproximators.
this is the injection of assume statements intended to direct the tools away from exploring already analyzed subspaces.
within the assume statements we place the negated formulae of the upper characterization.
we place the assume statements just before the points at which a failure is asserted.
this was an implementation decision that guaranteed that all inputs have been read before assuming constraints on their values.
in the future we would like to explore placing the assume statements at the top of the program to immediately prune the state space that has yet to be explored.
overapproximator conditioning is implemented in our ruby code base.
generalization initially acf attempts to condition f up line in alg.
to avoid previously detected failures.
if that is unsuccessful generalization is applied to compute effective conditioning.
the prototype implements a structural generalization of f up which is always a conjunctive formula.
to generalize a conjunction of nclauses we first construct the powerset lattice over the set of conjuncts this lattice has height n f up as the top element at height n and true as the bottom element at height .
having failed to demonstrate that the element at height nconstitutes effective conditioning we determine whether the elements at height i.e.
the singleton clauses are effective.
for those that are effective we compute the leastupper bound and determine if it is effective if ksingletons are effective then the lub will be at height k. we refer to this as a round of a binary search on the conditioning sublattice.
each round successively narrows that sublattice by raising the height of the bottom and lowering the height of the top.
this process defines a bounded finite order and thus generalization is guaranteed to terminate.
generalization returns the effective condition that is lowest in the lattice.
if none are effective then true is returned.
generalization is implemented in our ruby code base.
for very large formulae we control runtime by specifying an upper bound on the number of rounds of generalization that can be computed.
specialization in our prototype acf there is no implementation of specialization.
the need for specialization the underapproximator returning a failure report that cannot beverified with certainty did not arise in the programs analyzed.
v. a nexploratory study of acf we conducted a study to explore the cost and effectiveness of acf for computing cfcs of c programs.
our goal is to provide information about the efficiency accuracy and safety of the acf framework.
rq1 how does the total acf runtime and the runtime of acf components vary across programs?
rq2 how does the accuracy of the computed cfcs vary across programs?
rq3 how do the acf components that ensure safety influence the efficiency of acf?
a. subject selection our study uses a selection of the sv comp benchmarks .
in particular we started with the set of c programs in the benchmark that have failures these are a combination of real failures and seeded failures.
our goal is to explore the cost effectiveness acf so we limited ourselves to programs on which at least one overapproximator completed within the timeout of seconds.
this left c programs with failures.
sv comp has both failing and non failing variants of c programs and in acf we expect to condition analyses so that they can ultimately verify a program failurefree.
for this reason we removed benchmarks for which the non failing variant could not be proven so by an overapproximator within the timeout.
a similar filtering removed benchmarks based on the ability of the underapproximator to complete its analysis.
this left c programs for our study.
during the course of our study we detected sv comp benchmarks that either read no input or read no input on failing behaviors.
we do not think that these are representative of real programs failures since all program runs lead to failure and keeping these in our study would inappropriately albeit positively bias our results.
using a maximum run time for acf of hours led us to drop another programs.
this selection process resulted in a diverse set of failing c programs that span the gamut of categories in sv comp.
b. experimental setup our implementation is purely sequentially and was executed on a opteron processor .
ghz with gb of ram running scientific linux.
our analysis portfolio used configurations of cpa version .
.
ua version .
.
and civl version .
.
with a minute timeout.
c. results and discussion we report results of running our acf implementation on the sv comp c programs both in aggregated data and through a series of plots that depict the variability of informative metrics across the programs.
all of the underlying data from our study is available at each plot uses a single impulse to record the metric for the run of acf on a program.
the impulses are plotted from high authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
180slice time sec definite failure time sec possible failure time sec generalization time sec fig.
total and component acf runtime table i acf runtime rounded to the nearest second component avg.
max.
min.
total possible .
definite .
generalize .
slice .
total to low moving left to right on the horizontal axis.
these plots are effective at depicting the trend across the set of subject programs.
note that the ithimpulse in a pair of plots may not correspond to the same program.
rq1 efficiency table i reports the average maximum and minimum times in seconds to run acf in our study.
the average time to compute a cfc is .
hours.
this runtime is dominated by the cost of running overapproximators and generalization each taking on average just over of the runtime.
not listed in the table is the cost of the core acf implementation which for example integrates the components performs conditioning and merges disjoint partitions.
this comprises .
of the analysis time on average.
figure shows substantial variability in runtime across the programs.
this is a stacked impulse plot with generalization on the lowest part of the impulse then possible failure time then definite failure and slice time at the top.
definite failure and slice times are visible when zooming in on the plot.
figure shows the variability in the number of iterations of acf needed to reach convergence.
this ranges from to across the data set but more than a third of the programs required or more iterations.
this is due to at least in part to the fact that for more than programs the overapproximators detected spurious failure reports which had to be blocked to reach convergence.
while the reported runtime of acf is significant the study has revealed two possible performance optimizations.
first replacing our sequential portfolio with parallel execution of instances of awill reduce possible by up to a factor of .
while this best case is unlikely to be observed more than half of the benchmarks encountered timeouts as many as for cpa and for ua in a single run which suggests significant room for improvement.
180number of iterationsfig.
acf iterations to convergence second each round of generalization analyzes two layers of the powerset lattice of conjuncts for a given f up.
the first round involves a single run of aconditioning all conjuncts i.e.
the full formula and jf upj runs each conditioning a single conjunct.
we limited our experiments to a single round and across the generalization instances in the study we observed jf upj with an average of .
we use the sequential portfolio to solve these which means that parallelizing generalization could reduce runtime by a factor of and a factor of on average.
rq2 accuracy the accuracy of a cfc should be judged based on the the input space it describes i.e.
how many failing inputs are not characterized by the lower bound how many non failing inputs are characterized by the upper bound.
this presupposes we know the exact failure space of the program which is hard to determine.
in this study we use two proxy measures to provide information on accuracy.
first we know that any cfc partition that is exact is completely accurate the upper and lower bounds coincide.
second we know that any cfc partitions that have true as an upper bound are inaccurate since we removed programs from the study that failed on all inputs.
intuitively the greater the number of exact partitions and the fewer the number of true partitions the more accurate the analysis.
the cfcs for all programs in the study were comprised of partitions.
of these .
were exact and had true values as upper bounds.
figure middle plots the variability across the examples in terms of the number of partitions computed for the cfcs and whether those partitions were exact or inexact.
the significant number of inexact partitions corresponds to the need for generalization across the study subjects.
generalization influences the accuracy of upper bounds but slicing influences the accuracy of lower bounds i.e.
they are generalized yet they remain underapproximations.
figure left plots the effect of slicing across the study.
for more than a third of the programs some slicing is performed indicating its value.
slicing has an effect on performance as well since reducing the size of f up reduces the cost of generalization.
our prototype acf computed exact cfcs for programs.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
180conjuncts sliced 180inexact partitions exact partitions 180generalizationsfig.
data on acf accuracy and safety for programs the gap in bounds across all partitions in the computed cfc was a single conjunct generalization moved just one step up the lattice.
the maximum gap in our study as measured by conjuncts was .
in total cfcs for of the programs had non true upper bounds indicating that they characterized a strict subset of the input space as failing.
our study does not quantify accuracy in absolute terms nor does it quantify the partition gaps in terms of their semantics i.e.
the size of the partitions input subspace.
we plan to explore this in future work.
the study does provide evidence that even when acf is configured with a limited form of generalization it can converge to cfcs that bound the failure space to a strict subset of the input space.
rq3 safety the safety of cfcs computed by acf is based on the soundness of aandaand the use of generalization.
we take the former as a given and present data on the use of generalization in fig.
right .
more than two thirds of the subject programs require at least some generalization.
this is a clear indication of the necessity of generalization for computing safe cfcs.
the discussion above describes the runtime cost of generalization and while we have suggested ways that cost may be reduced that cost is unavoidable in computing safe cfcs.
d. validity and generalizability of findings with regard to internal validity we have conducted extensive testing and post analysis of the computed cfc data to ensure that it is safe and have only used static analyses that have proven to be robust in the sv comp competitions .
the sv comp benchmark suite while limited is updated annually to reflect the challenges to static analyses found in the broader population of c programs.
while we do not claim generalizability of our results to all c programs using svcomp programs constitutes a common convenience sample used in evaluating c static analysis tools.
moreover its use promotes the replicability and reproduction of our study.
vi.
a pplying cfc s we conjecture that cfcs have a wide range of software engineering applications.
we discuss two such applications.
fault repair and fix completeness the literature has demonstrated the challenges of fixing a bug completely i.e.
fixing all manifestations of a fault in a code base.
recent studies of a range of code bases have reported the occurrence of bug fixes that are incomplete at rates of and more than .
analysis of this incompletenessstems from multiple sources but all of these studies find that a failure to fully understand the failing program behavior is a significant contributing factor.
a key step in repair whether manual or automated clearly involves a complete characterization of how a failure may be exhibited.
cfcs compute exactly that.
to understand how this might be used consider the recent automated fault repair technique angelix .
like most automated repair techniques angelix relies on a test suite both as the definition of the failing input space and as an encoding of the repair correctness criteria.
computing cfcs for failing tests would produce a safe characterization of the failing input space that can be used to direct angelix s symbolic execution based repair method to produce more robust repairs.
quantitative program analysis recent years have seen the development of quantitative program analyses built on a combination of symbolic execution and model counting .
these have been shown to be useful in computing quantitative information about program behavior ranging from system reliability estimates to secure information flow and side channel attacks .
these techniques work by exploring the symbolic state space of a program formulating path conditions for reachable states invoking exact or approximate model counting techniques to estimate the size of the input space satisfying those conditions and then computing the appropriate quantitative metric e.g.
probability of failure probability of information leakage etc.
unfortunately these techniques suffer from the limitations of all symbolic execution techniques their abstractions are not well suited for characterizing loops.
this leads them to designate regions of program behavior that are not analyzed e.g.
because of bounds on the symbolic execution as uncertain e.g.
gray nodes in .
acf offers a means of addressing this uncertainty since ais designed to analyze looping behavior.
a cfc f computed by acf is well suited to subsequent quantitative analysis.
first fis made up of disjoint elements each of which can be counted independently and the resultant counts can be summed.
given the complexity of model counting this can offer exponential reductions in cost.
second for a given element f2f when f up f lo one need count only a single formula.
moreover the coincidence of upper and lower bounds provides more precise information for the input subspace characterized by such elements.
third and most importantly a cfc guarantees that inputs in upper f authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
do not lead to program failures thus the uncertainty of quantitative analysis results is due only to the gap in f s bounds i.e.
upper f lower f which again can be computed on a per partition basis.
vii.
r elated research there has been significant recent interest in program analyses that mix may and must analyses e.g.
but these ideas go back more than two decades e.g.
to seminal work on abstraction based model checking .
perhaps the best known and most influential alternating analysis framework is counterexample guided abstraction refinement cegar .
cegar performs a forward analysis using overapproximating abstractions of program states and when a potential error is detected it switches to a backward underapproximating analysis whose results are used to refine the overapproximation for the next round.
the acf algorithm shares the basic alternation approach but it only indirectly influences the abstractions used in an analysis through conditioning e.g.
predicate abstraction may key off assume statements.
the analyses described above seek to either prove a program free of failures or produce a failure witness.
in contrast acf accumulates and generalizes the set of witnesses until it can prove remaining program behavior free of failure at which point it returns a cfc.
our work builds on an increasingly sophisticated and costeffective corpus of static analysis and verification tools.
the competition on software verification involved c static analysis tools.
sv comp defines a rich error witness interchange format which facilitates the combination of analyses in acf.
our selection of cpa and ua was based largely on the robustness of those tools and their performance in the two most recent sv comp instances but the tools in the competition represent an enormous range of technical approaches and one could easily constitute an instance of acf out of a much larger portfolio of these techniques.
a key aspect of acf is the use of assumptions to block a from analyzing portions of the program state space.
this is inspired by the conditional model checking approach developed by cpa .
in essence the iterations of acf build an increasingly general condition that blocks potentially failing behavior until the remaining behavior is failure free.
unlike conditional model checking acf uses generalization specialization techniques to broaden restrict the upper lower bound of potentially failing program subspaces so as to compute safe cfcs.
we use the civl symbolic execution system for c asasince it also participated in the two most recent svcomp competitions.
unlike the overapproximating analyses we used we had to modify civl to incorporate it into acf.
this was primarily due to the need to direct the symbolic execution to a potentially failing subspace of behavior.
we note that this simply implements the idea of directed symbolic execution from the work of ma et al.
.
we could have incorporated other underapproximating analyses into acf such as cbmc or its successors with appropriate support for direction.
from the cfc perspective the most closely related work is from kim et al.
and gu et al.
.
kim et al.
introduce the notion of bug neighborhood which is conceptually similar to the upper bound of a cfc but it is formulated only in the case of null reference failures it does not characterize the failure space constructively in terms of the program input space and it does not provide a definitive lower bound.
gu et al.
introduce the notion of the coverage of a fix i.e.
the extent to which a fix handles all inputs that trigger a bug.
cfcs seek to accurately and safely characterize the failure to provide an upper bound on the required coverage for a fix.
while gu et al.
rely on a bounded series of successively general underapproximations to maximize coverage acf uses alternation.
this allows acf to exploit the power of overapproximating abstraction to efficiently summarize non failing program subspaces and ultimately converge with a safe upper bound.
viii.
c onclusions this paper introduces the concept of a comprehensive failure characterization which provides a constructive formulation of the failing input space of a program.
it also presents a general algorithmic framework for computing cfcs that exploits the power of alternating over and underapproximating static analyses along with refinement approaches.
the acf framework is guaranteed to compute safe cfcs and it incorporates several mechanisms to improve their accuracy.
data from an exploratory study on a prototype implementation of acf for c programs reveals that it is possible to compute cfcs with a good degree of accuracy in a matter of hours.
moreover the study reveals multiple opportunities for optimization that offer the chance to significantly reduce acf runtime and thereby enable more thorough generalization by running more than one round which will boost accuracy.
the acf framework can incorporate a wide variety of analyses and strategies and our future work will explore that space.
in future work we plan to explore incorporating all of the sv comp analyzers in a parallelized portfolio and to incorporate more semantics based generalization strategies.