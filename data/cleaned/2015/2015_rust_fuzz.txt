fuzzing the rust typechecker using clp kyle dewey jared roesch ben hardekopf university of california santa barbara fkyledewey jroesch benh g cs.ucsb.edu abstract language fuzzing is a bug finding technique for testing compilers and interpreters its effectiveness depends upon the ability to automatically generate valid programs in the language under test.
despite the proven success of language fuzzing there is a severe lack of tool support for fuzzing statically typed languages with advanced type systems because existing fuzzing techniques cannot effectively and automatically generate well typed programs that use sophisticated types.
in this work we describe how to automatically generate well typed programs that use sophisticated type systems by phrasing the problem of well typed program generation in terms of constraint logic programming clp .
in addition we describe how to specifically target the typechecker implementation for testing unlike all existing work which ignores the typechecker.
we focus on typechecker precision bugs soundness bugs and consistency bugs.
we apply our techniques to rust a complex industrialstrength language with a sophisticated type system.
i.introduction the central idea of a language fuzzer is to automatically generate valid programs in a given language which are then fed to a language implementation under test in order to check for crashes or miscompilations.
this idea is well established as a confidence building and bug finding technique for compilers and interpreters for example thousands of bugs have collectively been found by the jsfunfuzz langfuzz and csmith language fuzzers.
however no existing language fuzzers target any staticallytyped languages with advanced type systems that include features such as parametric or subtype polymorphism generics pattern matching type classes etc that is languages such as java c ml haskell scala swift and rust.
the reason behind this lack of tool support is that current language fuzzing techniques are unable to effectively and automatically generate well typed programs in such languages.
moreover even for languages with simple type systems that canbe fuzzed using current techniques the typechecker is viewed merely as an obstacle that must be overcome in order to test the rest of the language implementation rather than a component worthy of being tested for its own sake.
the typechecker is responsible for enforcing guaranteed program behaviors such as memory safety the more complex a language s type system is the more important it becomes that the typechecker itself is tested for correctness.
current language fuzzing methods do not address the necessary techniques and methodology for testing a typechecker.
in this paper we advance the state of the art in language fuzzing in several ways.
first we take advantage of the wellknown idea of propositions as types andprograms as proofs also known as the curry howard correspondance in order to phrase the problem of well typed program generation as a constraint satisfaction problem expressible in constraint logic programming clp e.g.
prolog .
because a type isa logical proposition we can straightforwardly encode types and type systems using clp.
because programs are proofs querying the clp engine whether a type is true corresponds to generating a well typed program.
the nondeterminism inherent in clp languages means that when there are multiple possible proofs i.e.
multiple well typed programs the clp engine can easily generate all possible solutions that is it can output as many well typed programs as we desire.
this method for automated program generation allows us to take advantage of long standing existing implementations of clp and community wisdom about effectively using clp .
our second advance describes techniques for specifically testing typechecker implementations.
the three main kinds of typechecker bugs we target are precision bugs where the typechecker conservatively rejects well behaved programs it should accept soundness bugs where the typechecker optimistically accepts potentially ill behaved programs it should reject and consistency bugs where the typechecker treats a set of equivalent programs in terms of being well or illtyped inconsistently accepting some while rejecting others.
testing for precision bugs requires only that we generate well typed programs as described previously and then determine whether the typechecker erroneously rejects them.
testing for soundness bugs requires that we generate illtyped programs to see whether the typechecker erroneously accepts them.
however merely generating arbitrarily ill typed programs is trivial and mostly ineffective the trick is to generate programs that are non obviously ill typed i.e.
ones that could conceivably be accepted even by a typechecker that has been carefully implemented and reviewed.
in order to accomplish this feat we describe a principled and automatic technique for generating almost well typed programs that builds on our previous clp based technique for generating well typed programs.
testing for consistency bugs requires that we generate equivalence classes of programs that are all welltyped or ill typed in the same way and then determine whether the typechecker accepts or rejects all of them similarly.
we use a set of simple code transformations in clp that allow us to generate such type equivalent programs.
to demonstrate the practical utility of our techniques we apply them to testing the rust language typechecker implementation.
rust is a statically typed language with an advanced type system that is being actively developed by mozilla.
rust s type system serves as an excellent case study of our techniques as it is highly sophisticated lacks a formal specification and is under constant modification.
these properties are endemic to real industry strength languages and tackling them head on allows us to push our own techniques to their limits.
while the lack of a formal type system specification prevents us from establishing ground truth regarding what is well typed it serves to open a dialog with the languagedevelopers regarding the implications of the type system and typechecker implementation decisions they make.
that is our work can be used to find oddities and problems with a type system under development and these issues can be fed through the development cycle to allow for further type system refinement as well as typechecker fixes.
we have worked closely with the rust development team during this case study and our efforts have raised a number of questions that the rust developers have had to debate and think hard about in order to decide what is and is not correct behavior.
overall we make the following contributions in this work an approach for generating well typed programs in statically typed languages with advanced type systems.
section iii a technique for testing the precision of typechecker implementations based on the approach described above.
section iv a a technique for testing the soundness of typechecker implementations based on our notion of almost welltyped programs.
section iv b a technique for testing the consistency of typechecker implementations based on our notion of type equivalent programs.
section iv c the application of all the above techniques towards fuzzing the rust language typechecker implementation along with an evaluation and discussion of the results.
sections v and vi ii.
related work we discuss existing work relevant to language fuzzing.
none of the language fuzzers discussed below even the ones targeting statically typed languages attempt to test the typechecker itself.
the most common approach to language fuzzing employs stochastic grammars which perform a random walk over a context free grammar according to some probability distribution in order to generate syntactically valid programs.
there are many existing fuzzers based on this technique including jsfunfuzz cross fuzz and arithfuzz .
the advantage of the stochastic grammar technique is that it is both simple and language agnostic a property exploited by langfuzz to test both javascript and php.
the downside is that this technique implicitly assumes that syntactic validity is the only important property for test programs to have as program generation constraints are based solely on the language grammar.
the stochastic grammar approach is not well suited to statically typed languages with non trivial type systems as the probability of randomly generating well typed programs is typically extremely low.
there has been a significant amount of work that attempts to adapt stochastic grammars to fuzz statically typed languages.
one idea is to restructure the language grammars to incorporate type system information directly into the grammar and thus emit only well typed terms as seen in mckeeman and st amour et al.
.
this approach necessarily gives up on certain kinds of programs where the type information is too complex to express in a grammar tothe point where it is unable to express most valid programs as the language and type system under test become more and more complex.
a second idea is to generate syntactically valid programs and then filter out ill typed programs post hoc as in gligoric et al.
.
the effectiveness of this approach is dependent on the relative frequencies with which welltyped and ill typed programs are generated and experience has shown that the number of well typed programs is usually dwarfed by the number of ill typed programs.
a third idea is to augment the stochastic grammar to integrate additional checks and analyses as done for csmith .
this approach however is very specific to the language under test and can be extremely complex to implement and maintain.
overall there are many hurdles to overcome in order to make stochastic grammars emit well typed programs as the technique fundamentally does not concern itself with type information.
a simpler approach is to develop a program generation strategy with a built in knowledge of type systems enabling the direct generation of well typed programs.
for example both eclat and jcrasher generate well typed java programs by design.
however these techniques are still problematic from the standpoint of testing statically typed languages in general as both generation strategies are highly specific to testing java code.
moreover they are limited in several ways.
first they must take in existing classes and inheritance hierarchies as input and cannot generate new classes and inheritance hierarchies.
second they are fundamentally incapable of handling generics parametric polymorphism and higherorder functions these are inherent limitations of the underlying technique.
these restrictions are all side effects of the way in which generation proceeds as the underlying generation algorithm is specific to the subset of java that was chosen to be generated.
overall while eclat and jcrasher are capable of generating well typed programs their generation algorithms lack expressiveness and generality.
fetscher et al.
discuss a more general approach for well typed program generation that can be applied to arbitrary languages though their focus is on testing semantic properties of a formal language definition rather than fuzzing a language implementation.
the central idea is to model a language s type system using plt redex and then apply a custombuilt constraint solver to generate programs which are welltyped according to the given model.
while this approach is more general than eclat or jcrasher it is subject to technical problems which practically limit its usage to simple type systems lacking advanced features like parametric polymorphism.
in contrast our clp based technique reuses existing high performance clp engines e.g.
and can easily handle more advanced type system features.
most importantly we describe techniques to generate typeequivalent programs and programs which are ill typed in subtle ways whereas fetscher et al.
only describes the generation of well typed programs.
overall our focus is on testing the typechecker itself whereas fetscher et al.
is concerned only with getting programs past the typechecker.
another general approach is seen in program synthesis e.g.
wherein programs with highly specific behaviors are automatically constructed usually with the help of preexisting smt solvers .
while synthesis techniques are certainly applicable to fuzzing statically typed languages they tend to be prohibitively complex and computationally expensive for this purpose.
synthesis problems often involve many constraints from different domains whereas most type systems e.g.
those described in pierce require only relatively simple equality constraints.
moreover typing rules are often written in the style of inductive inference rules which smt solvers cannot handle without some additional translation .
overall the concern with fuzzing is to generate programs with relatively few constraints as quickly as they can be tested whereas with synthesis the interest is in generating some program which satisfies some high complexity constraints.
while tens of seconds per program may be considered acceptable or even fast for a synthesis problem e.g.
this is impractically slow for fuzzing purposes.
as such program synthesis is not a very applicable way to view the fuzzing problem.
in our own prior work we showed how to use clp to fuzz dynamically typed languages with special focus on javascript.
the paper briefly mentions a very simple unsound type system for javascript designed to avoid common runtime errors.
in this work we focus specifically on testing typecheckers for statically typed languages with advanced type systems.
while at a high level both that paper and this one use clp to fuzz languages the focus and techniques of the two papers are completely different.
groce et al.
s swarm testing describes a program generation strategy that intentionally restricts itself to a subset of language features in order to focus testing on that chosen subset.
for example in a language with conditionals loops and assignment one may choose to generate programs containing only loops and assignment in order to allow more indepth testing of those features and their interactions with each other.
while this technique theoretically gives up on finding certain bugs i.e.
those that arise from the eliminated language features in practice it has been shown that swarm testing ends up finding more bugs in a given timeframe than does testing on the entire language at once.
the reason why is that generating programs which hammer on a particular language feature or interaction between specific features becomes much more likely in this restricted space and bugs tend to involve only a handful of features.
groce et al.
have shown that this technique works for fuzzing languages based on syntactic features and for testing apis.
we extend this idea with our clp based technique by developing specialized fuzzers which individually target subsets of rust s type system as described in section v b. equivalence modulo inputs emi is a compiler optimization and code generation testing technique wherein programs are generated which should behave in semantically identical ways given identical inputs .
that work explores inserting dead code into existing programs in order to generate inputequivalent programs.
in our work we employ code translations that take a given program and derive other programs which are type equivalent e.g.
if the given program was well ill typed then the derived programs will also be well illtyped for similar reasons .
while the original emi work is focused on testing optimizations and code generation our work is specific to finding consistency bugs in typecheckers.iii.
generating well typed programs in this section we describe how to phrase the problem of well typed program generation in terms of constraint logic programming clp .
we use as an example the problem of generating well typed programs in system f the polymorphically typed lambda calculus.
we use system f as a relatively simple way to explain the general ideas behind our approach.
clp is capable of expressing much more complicated type systems as demonstrated by our application of these ideas to rust section v .
no existing fuzzers can handle even something as simple as system f because of its higher order functions and parametric polymorphism.
while clp is a better solution for generating well typed programs for language fuzzing than any current method it is not a perfect solution.
we conclude this section by describing some of the pitfalls of clp with respect to well typed program generation.
a. clp for program generation a well known result in programming language theory states that logical propositions correspond to types and programs correspond to proof terms.
this relation is often called the curry howard correspondence after the logicians who first observed it.
given a logical proposition a we can use the rules of logic to create a proof term mthat encodes the proof ofa.
the curry howard correspondence states that a can be viewed as a type and mas a program of that type writtenm a. thus we can use a logical theorem prover to derive programs of a given type.
the space of possible provers we could use is vast.
we observe that typing rules are written as nondeterministic inductive inference rules that operate over equality constraints.
this observation naturally leads to the use of prolog like languages which explicitly feature nondeterminism as well as equality constraints via unification .
we can then easily reuse existing tools e.g.
because with prolog like languages the execution model has a very close correspondence to common type system representations.
throughout this paper we refer to prolog like languages as clp languages where clp generalizes logic programming to integrate arithmetic constraint solvers in fact modern prolog implementations such as gnu prolog and swiprolog are clp languages in this sense .
while typical type systems do not need arithmetic constraints they are useful for more advanced type systems such as rust s as detailed in section v b. b. example system f the best way to explain how to use clp for well typed program generation is by example.
here we demonstrate how to use clp to generate well typed programs in system f the polymorphically typed lambda calculus.
the key points to observe are that the clp specification closely mirrors the formal type system definition and we use only the standard features of clp languages which means that we can use offthe shelf clp implementations to generate programs.
figure describes the syntax of system f. types are either type variables function types or polymorphic types.
2type j !
2j e2exp xj x eje1e2j eje fig.
syntax for system f where is a type variable is a polymorphic type xis a program variable e is a type abstraction that creates an expression of polymorphic type and e instantiates a polymorphic expression to a specific type .
x x var x e x e !
2abs e1 !
e2 e1e2 2app e e tabs e e tapp fig.
typing rules for system f where is a type environment mapping variables to types and substitutes the type for free occcurances of in type .
an expression is either a variable a function abstraction a function application a type abstraction or a type application.
type abstractions parameterize an expression by a type in the same way that function abstractions parameterize an expression by a value.
type application specializes an expression the body of a type abstraction to a given type in the same way that function application specializes an expression the body of a function abstraction to a given value.
figure describes the typing rules for system f. the rules usejudgements of the form e .
a judgement is a statement given type environment that maps the variables in scope to their types the expression ehas type .
each rule has a single judgement as its conclusion on the bottom of the horizontal line and zero or more judgements as premises on the top of the horizontal line .
a rule provides justification for drawing the given conclusion only if we can prove the truth of each premise.
the first three rules var abs and app are exactly the same as the simply typed lambda calculus.
the last two rules handle polymorphism tabs introduces a polymorphic type and tapp eliminates a polymorphic type.
figure shows a translation of the formal typing rules from figure into clp using a prolog like syntax where lower case identifiers represent user defined predicates and functions capitalized identifiers represent variables commas represent conjunction represents reverse implication and periods signal the end of a clause.
all variables are implicitly quantified e.g.
the clause foo a b bar a c actually represents the clause8a b.foo a b 9c.bar a c which means given some aandb we can derive foo a b if we can show there is some csuch that bar a c .typing gamma var x t lookup gamma x t .
typing gamma lam x t1 e arrow t1 t2 add x t1 gamma newgamma typing newgamma e t2 .
typing gamma app e1 e2 t2 typing gamma e1 arrow t1 t2 typing gamma e2 t1 .
typing gamma tlam a e poly a t typing gamma e t .
typing gamma tapp e t1 t3 typing gamma e poly a t2 subst a t1 t2 t3 .
?
typing e t write e fail .
fig.
clp specification of system f where lookup add and subst are helper predicates with the obvious functionality whose definitions are not shown here.
the final query will output an infinite stream of well typed system f programs.
the figure contains five clauses one for each typing rule in figure and a query which represents what the clp engine should try to prove.
the typing predicate represents a type judgement typing gamma e t stands for e .
the head of a clause the part before the symbol is the conclusion of the inference rule the body of a clause contains the premises of the inference rule.
the type environment is represented using a list associating variables with their types we use the helper predicate lookup gamma x t to determine what type tis associated with variable xin type environment gamma and the helper predicate add x t gamma newgamma to compute a new type environment newgamma copied from the original type environment gamma but associating variable xwith type t. we also use the helper predicate subst a t1 t2 t3 to compute a new type t3derived from t2but with all free instances of type variable areplaced with type t1 i.e.
t3 t2 .
we omit the definitions of these helper predicates from the figure for space reasons but the entire code listing is available in the supplementary materials1.
consider the query at the bottom of figure .
because variables are implicitly quantified it actually represents the query 9e t. typing e t write e fail .
in other words prove there exists some expression eand type tsuch that given the empty type environment expression e has type t then output the expression e then fail .
in order to satisfy the first conjunct the clp engine must construct a satisfying expression and its type the second conjunct is a built in side effecting operation that outputs its argument the third conjunct will immediately fail.
because clp is nondeterministic failure triggers backtracking the engine will backtrack to the last nondeterministic decision it made and make a different one.
this implies that the engine will find adifferent expression ewith some type t assuming each expression has at most one type output it then fail again.
this process will continue indefinitely attempting to output the infinite set of well typed system f programs.
there is however a subtle problem with how programs in system f are enumerated with this example.
when performing nondeterministic search over clauses clp engines employ a kyledewey ase15.zipdepth first search strategy executing alternatives in the order they are presented.
for this example this means the clp engine will always choose to produce ever deeper lambda abstractions as opposed to employing some of the later rules.
this problem can be easily addressed by adding code to make lambda abstraction and other alternatives fail under certain conditions causing the clp engine to backtrack and choose a different alternative.
different mechanisms of causing failure correspond to different search strategies for example adding a bound on the number of recursive calls made to typing implements a bounded exhaustive search and adding probabilistic failure amounts to performing a random search.
more details on alternate search strategies and their implementation can be found in our prior work.
c. pitfalls of clp while there are substantial advantages to using clp for well typed program generation it does have certain problems that make it an imperfect solution.
we identify and describe the two biggest problems we have encountered when using clp for this purpose.
fundamental performance issues.
typing rules generally assume that they are operating over complete programs and are attempting to make a judgement whether that program is well typed i.e.
they are operating as acceptors rather than generators .
ideally when implemented in clp any acceptor is also a generator by default given a predicate pthat describes terms with some desired property p t operates as an acceptor for a concrete term twhile9x p x operates as a generator that will bindxto some satisfying concrete term.
however naively translating typing rules into clp can lead to performance issues.
for example while the ordering of clauses in a conjunction is irrelevant from a strictly logical standpoint in practice it is significant.
a poor ordering can lead to asymptotically worse performance or even nontermination .
we have also found that it may be necessary to place bounds on types to ensure termination using techniques described at the end of section iii b. lack of constructive negation.
clp in general lacks the ability to constructively negate a predicate.
in other words it is not possible to have the clp engine construct a term that deliberately fails to satisfy a given predicate.
given a predicate p we can query9x p x but we cannot query 9x p x .
clp languages often implement a notion called negation by failure but that is not constructive i.e.
it cannot construct terms only filter out unsatisfying terms .
in order to get the effect of constructively negating a predicate p we must create a new predicate pthat constructively describes the negation ofp.
this new predicate will contain redundant code and the resulting specifications are longer and more confusing.
attempts have been made to solve this problem e.g.
but those solutions require specialized clp implementations and still require additional code and effort.
iv.
finding typechecker bugs a language s type system provides guarantees about program behavior i.e.
it excludes behaviors that the language developers have deemed bad .
the type system is essentially alogical theory by which the typechecker attempts to prove that a program does not exhibit these bad behaviors.
one can think of the typechecker as a filter which allows through all programs that it can guarantee are well behaved while forbidding all programs that it cannot guarantee are well behaved.
because exactly determining which programs are wellbehaved or ill behaved is provably undecidable the typechecker will conservatively reject some potentially wellbehaved programs the fewer such programs it rejects the more precise the typechecker is.
however the typechecker should never accept any program that is potentially ill behaved this requirement is called soundness .
in addition the typechecker should be consistent in its decisions to avoid programmer confusion similar programs from a typing perspective should all be accepted or rejected similarly.
in this section we describe methods and techniques for detecting bugs in a typechecker implementation.
we focus specifically on precision bugs soundness bugs and consistency bugs though at the end we also discuss a few other kinds of bugs that we encounter as a side effect of our main focus.
determining what exactly constitutes a bug requires a specification to compare against.
a formal specification would be best for typecheckers this would be a formal type system but is not always available especially for a language under rapid development.
in the absence of a formal specification we rely on an informal notion of developer intent gleaned from discussions with the language developers themselves.
when we say spec below we are referring to either the formal or informal specification whichever is available.
we do not consider the problem of determining whether the spec itself is correct e.g.
proving the soundness of the type system though that is an interesting problem to tackle in the future.
a. finding precision bugs we wish to automatically generate programs that expose precision bugs in the typechecker.
we first need a definition that tells us when a program exposes a precision bug definition .hprecision bugia program exposes a typechecker precision bug if the program is well typed according to the spec but the typechecker rejects the program.
because the spec can be informally defined it may be uncertain whether the program is well typed according to the spec.
even if we can guarantee that the program is wellbehaved the type system implemented by the typechecker may not be able to prove that fact and in that case the program should be rejected by the typechecker.
however we can give a more specific condition under which the program should probably have been accepted corollary.
a program exposes a precision bug if the typechecker has computed information that implies the program is well typed but rejects the program anyway.
for example suppose that the typechecker can infer the program is well typed if it can prove some proposition q. it has already proved proposition p and it knows that p q. thus the typechecker should be able to derive qand declare the program well typed.
however if it ignores that information and rejects the program then we say it has a precision bug.typing gamma app e1 e2 t2 typing gamma e1 arrow t1 t2 typing gamma e2 t3 n t3 t1 .
fig.
clp specification of almost well typed system f. the only change is to the clause for the apprule the rest of the clauses are the same as figure and are omitted here.
the n operator is negationby failure.
from these definitions it suffices to generate well typed programs using the technique described in section iii run them through the typechecker and see whether the typechecker accepts them or not.
if a program is rejected then given a formal spec we are guaranteed that we have exposed a bug.
given an informal spec we have exposed a case where either there is a bug in the typechecker or the language developers need to tweak their notion of well typedness to refine the informal spec.
b. finding soundness bugs we wish to automatically generate programs that expose soundness bugs in the typechecker.
we first need a definition that tells us when a program exposes a soundness bug definition .hsoundness bugia program exposes a typechecker soundness bug if the program is not well typed according to the spec but the typechecker accepts it as valid.
thus in order to expose soundness bugs we must generate ill typed programs.
in concept this is trivial simply generate syntactically valid programs and filter out all those that are well typed as the generated programs grow larger the odds of a syntactically well formed program also being well typed tend to shrink exponentially .
however the resulting ill typed programs are generally obviously ill typed such that even a buggy typechecker would probably be able to correctly reject them.
intuitively we want the ill typed programs to be nonobvious so that even a mostly correct typechecker might still trip up and incorrectly accept them.
for this purpose we introduce the notion of almost welltyped programs.
the idea is simple given a set of type system rules we pick a subset of the rules premises and negate them.
any program that is well typed according to the modified type system is almost well typed according to the original type system that is the program is ill typed but in a precisely controlled way.
this notion is independent of the particular type system that the typechecker implements allows us to tune the degree of ill typedness at a fine granularity by choosing how many and which premises to negate and is intended to mirror likely mistakes that might be made when implementing the typechecker for example forgetting to check a rule s premise or checking it incorrectly .
example almost well typed system f. we illustrate this idea using the system f example from section iii.
consider figure which gives the typing rules for system f. suppose that we decide to negate the second premise of the app rule which says e2 i.e.
that the type of the argument matches the type of the function s parameter .
negating thispremise means ensuring that the type of the argument e2is notthe type of the function parameter .
figure gives a modified implementation of the app rule using clp which can be compared to the clp implementation given in figure .
the clause in figure is generating a type t3fore2and then ensuring that t3isnotthe same as t1.
we would prefer to use constructive negation to create a type t3that is different fromt1by construction however as discussed in section iii c this is not possible in typical clp languages.
thus the almost well typed implementation must spell out to the clp engine what negation means in the context of each negated premise.
while this example requires that every function application in the generated program is ill typed we can also specify that only a certain number of function applications are ill typed e.g.
that there is exactly one ill typed function application and all the rest are well typed.
in general for any almost welltyped program generation we can specify how many times each negated premise is used versus the original premise.
we accomplish this by adding a counter that counts the number of times a negated premise is applied if the counter exceeds some bound then the negated premise cannot be used anymore and the generator must use the original non negated premise.
c. finding consistency bugs we wish to automatically generate programs that expose consistency bugs in the typechecker.
we first need a definition that tells us when two programs expose a consistency bug definition .hconsistency bugitwo programs together expose a typechecker consistency bug if the well typedness ill typedness of one implies the well typedness ill typedness of the other and the typechecker accepts one program and rejects the other.
to find consistency bugs according to this definition we need a method to generate type equivalent programs that is programs that satisfy point in definition .
generally type equivalence is specific to the language under test.
for expository reasons we provide a simple example to illustrate the general idea.
consider the following program let x e1ine2 where is some type and e1ande2are arbitrary expressions.
the overall meaning of this program is to evaluate e1down to a value of type assign the result to the variable x and then evaluate e2withxin scope.
with this simple setup we can automatically transform this program into the equivalent one below let t e1in let x t ine2 which preserves the meaning and typedness whether welltyped or ill typed of the original program.
if one of the above programs is accepted by a typechecker and the other is rejected then the typechecker has a consistency bug.
in order to systematically check for consistency bugs we first generate well typed and almost well typed programs according to the methods described in sections iv a and iv b then apply a series of language specific transformations on the resulting programs to create type equivalent sets of programs then run each type equivalence class of programs through the typechecker to see whether they are all accepted or rejected.d.
other kinds of bugs while our main focus is on precision soundness and consistency bugs in the process of finding them we can encounter other kinds of bugs as well.
two common kinds of bugs that we may encounter are parser bugs and crash bugs as defined below.
definition .hparser bugia program exposes a parser bug if it is syntactically well formed according to the spec but the parser rejects it.
definition .hcrash bugia program exposes a crash bug if it causes the compiler to crash when compiling it.
not all bugs neatly fit into the aforementioned categories.
we call these miscellaneous bugs as defined below definition .hmiscellaneous bug ia program exposes a bug which is not clearly identifiable as a precision soundness consistency parser orcrash bug.
we do not do anything special to find these three additional kinds of bugs but merely make a note when our testing encounters them.
v. testing the rust typechecker in this section we describe mozilla s rust language with particular attention to its type system as well as a set of program generators that we have implemented for the rust typechecker using the techniques described in section iv.
rust serves as an interesting case study for our techniques because it is under active development and features a sophisticated but informally defined type system.
the lack of formal specification means that we cannot establish ground truth regarding typedness but must instead establish a dialogue with the rust developers to evaluate the results of our testing.
this situation is common in large scale industrial strength language development and our successful application of these techniques to rust demonstrates that they can handle such languages.
this work is the first to successfully generate well typed rust programs and to systematically test the rust typechecker.
all of the program generators described here are available in the supplementary materials2.
a. rust background rust is intended to be a systems level programming language along the lines of c and c but with much greater safety guarantees afforded by its type system.
rust supports tuples records generics parametric polymorphism type classes associated types linear types and borrowing.
we briefly describe some of the less common typing features type classes associated types linear types and borrowing.
type classes.
first introduced in haskell type classes provide a more principled way of allowing for ad hoc type polymorphism.
a type class declares a set of polymorphic function signatures that must be implemented by all members of that class.
polymorphic type variables can then be constrained to require that they belong to a given type class.
type classes are interesting from a well typed program generation kyledewey ase15.zipstandpoint because determining well typedness requires reasoning about type constraints arising from an intricate mixture of syntactic and semantic features.
associated types.
a useful feature seen in standard ml c haskell and rust among others is that of associated types which are intended to simplify polymorphic code.
this feature allows auxiliary type variables to be associated with some type such that these auxiliary variables are implicitly passed whenever isexplicitly passed.
in practice this feature can dramatically cut down on the number of type variables which must explicitly be passed in the code greatly reducing boilerplate.
linear types.
one of the most recognized features of rust is its use of linear types over memory regions .
rust did not pioneer the use of linear types see e.g.
among others but it is the first language to use them that has substantial industry support.
rust uses linear types for automated memory management without garbage collection or reference counting.
by default all variables are linearly typed.
the key property that linear types enforce is that any linearlytyped variable is used exactly once.
intuitively a linearlytyped variable s value is a resource that is consumed when that variable is used.
if a linearly typed variable goes out of scope and its associated value has not been consumed then the underlying memory for that value can safely be reclaimed.
consider the following ill typed rust code fndup1 a b a a b b a a f a a g this code declares a polymorphic function dup1 with two parameters aandbwhose return type is a tuple with elements the same type as parameter a. this code is ill typed because ais used twice in the body of the function to construct the pair being returned.
the following version is well typed fndup2 a b a1 a a2 a b b a a f a1 a2 g the values of parameters a1anda2are consumed to produce the return value while parameter bis unused and thus its value is unconsumed.
therefore b s value will be automatically reclaimed when dup2 returns.
borrowing.
linear typing is severely restrictive in practice as shown in the previous dup1 example where it was not possible to duplicate the parameter a. to alleviate this problem rust relaxes linearity in a sound manner using