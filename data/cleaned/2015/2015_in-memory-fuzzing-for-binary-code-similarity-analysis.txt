in memory fuzzing for binary code similarity analysis shuai wang and dinghao wu the pennsylvania state university university park pa usa fszw175 dwug ist.psu.edu abstract detecting similar functions in binary executables serves as a foundation for many binary code analysis and reuse tasks.
by far recognizing similar components in binary code remains a challenge.
existing research employs either static or dynamic approaches to capture program syntax or semanticslevel features for comparison.
however there exist multiple design limitations in previous work which result in relatively high cost low accuracy and scalability and thus severely impede their practical use.
in this paper we present a novel method that leverages inmemory fuzzing for binary code similarity analysis.
our prototype tool imf sim applies in memory fuzzing to launch analysis towards every function and collect traces of different kinds of program behaviors.
the similarity score of two behavior traces is computed according to their longest common subsequence.
to compare two functions a feature vector is generated whose elements are the similarity scores of the behavior trace level comparisons.
we train a machine learning model through labeled feature vectors later for a given feature vector by comparing two functions the trained model gives a final score representing the similarity score of the two functions.
we evaluate imf sim against binaries compiled by different compilers optimizations and commonly used obfuscation methods in total over one thousand binary executables.
our evaluation shows that imfsim notably outperforms existing tools with higher accuracy and broader application scopes.
index terms in memory fuzzing code similarity reverse engineering taint analysis i. i ntroduction determining the similarity between two components of binary code is critical in binary program analysis and security tasks.
for example binary code clone detection identifies potential code duplication or plagiarism by analyzing the similarities of two binary components .
patch based exploitation compares the pre patch and post patch binaries to reveal hidden vulnerabilities fixed by the patch .
malware research analyzes similarities among different malware samples to reveal malware clusters or lineage relations .
so far a number of binary similarity analysis tools have been developed with different techniques.
the de facto industrial standard tool b indiffidentifies similar functions mostly through graph isomorphism comparison .
this algorithm detects similar functions by comparing the control flow and call graphs.
moreover recent research work proposes advanced techniques to identify the hidden similarities regarding program semantics .
given the critical role of similarity analysis in binary code we observe several weaknesses in existing research.
for example dynamic analysis based methods usually have coverage issues which naturally impedes their work from testing every function in binary code.
typicalstatic methods can test any program component but they may suffer from real world challenging settings such as compiler optimizations or program obfuscations .
to overcome such limitations we propose imf sim which leverages in memory fuzzing to solve the coverage issue and reveal similarities between two binary code components even in front of real world challenging settings.
fuzz testing or fuzzing is a widely used software testing technique that exercises a program by providing invalid or random data as inputs.
compared with traditional testing techniques where a single input is used to test one execution trace fuzzing can largely improve the code coverage and increase the chances of exposing hidden bugs.
despite its simplicity in the concept fuzz testing is proven as robust and effective in the real world settings and is widely used for software testing .
while most standard fuzz testing mutates the program inputs we have noticed a special fuzzing technique that is designed to directly fuzz the content of assembly registers or memory cells i.e.
in memory fuzzing chapters and in .
in memory fuzzing can start one fuzzing execution at any program point.
while most testing techniques suffer from generating proper inputs to reach certain program points in memory fuzzing can start at the beginning of any instruction.
hence every program component becomes testable.
while fuzzing technique is originally proposed for software testing we observe that rich information regarding the program runtime behavior is indeed revealable during fuzzing without additional efforts.
that means semantics based similarity analysis shall be boosted through well designed fuzz testing.
to this end we propose imf sim a fuzzing based similarity analysis tool that overcomes multiple design limitations of existing research details are discussed in xii with higher accuracy and broader application scopes.
in particular imf sim leverages in memory fuzzing to launch dynamic testing towards every function for multiple iterations and records program runtime behaviors.
we collect different kinds of program behaviors referred as behavior traces in this paper for each function and behavior traces from two functions are compared through their longest common subsequence.
for each comparison pair of two functions we generate a vector including the jaccard index rates the jaccard index rate of two behavior traces is derived from their longest common subsequence of the behavior trace level comparisons and we then label sample vectors to train a machine learning model.
later given a vector by comparing two functions the trained model provides a similarity score.
.
c ieeease urbana champaign il usa technical research319 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the main contributions of this paper are as follows.
we identify design limitations of existing research in similarity analysis of binary components and propose imfsim a novel method that uses fuzz testing techniques for function level similarity analysis in binary code.
imf sim employs the in memory fuzzing technique which is originally designed for assembly level testing.
we propose several advanced methods to overcome the unique challenges and reveal the hidden power of the fuzzing technique in our new context.
benefit from its runtime behavior based comparison imf sim is effectively resilient to challenges from different compilers optimizations and even commonly used program obfuscations.
we evaluate imf simon over one thousand widely used binaries produced by various compilation and obfuscation settings.
our evaluation shows that imf sim has promising performance regarding all the settings and outperforms the state of the art tools.
ii.
m otivation in this section we summarize the limitations of previous binary code similarity analysis work and also highlight the motivation of our research.
we discuss the design choices of existing work in multiple aspects here.
dynamic analysis.
many program runtime behaviors such as memory accesses function calls and program return values are descriptors of program semantics to some extent.
some existing work leverages dynamic analysis and software birthmarks for function level similarity analysis .
however an obvious issue for existing dynamic analysis is the potential low coverage of test targets e.g.
functions .
theoretically generating program inputs to guarantee the reachability of every code component is an undecidable problem.
that means those existing dynamic tools are in general unable to analyze allthe functions in binary executables which drastically limits its application scope.
although concolic testing techniques can improve the coverage however most of these techniques suffer from scalability issues on large programs.
static analysis.
static similarity analysis can start from any program point and fully cover every test target which is on this aspect better than dynamic techniques .
indeed many recent work in this field leverages symbolic execution techniques to retrieve program semantics.
by leveraging constraint solvers semantics equivalent program components are identifiable in a rigorous way.
however static analysis can have limited capabilities for real world programs such as complex control flows e.g.
opaque predicates libraries or system calls.
in addition similarity analysis through constraint solving may have noticeable performance penalty .
our proposed technique imf sim is derived from typical dynamic testing techniques with concrete inputs.
thus common challenges for static analysis should not be obstacles for our technique.
moreover to solve the code coverage issue of previous dynamic tools imf simleverages a unique fuzzing paradigm in memory fuzzing to launch the execution at the beginning of every test target.
furthermore fuzz testing naturally improves the code coverage within eachtest component as it mutates the inputs for iterations and aims to exhaust execution paths in a best effort.
program syntax information.
to balance the cost and accuracy many static analysis based techniques capture relatively light weight features such as the number of instructions opcode sequences and control flow graph information .
however note that one major application of binary code similarity analysis is for malware study.
thus to better understand the strength and weakness of similarity testing tools we should consider commonly used obfuscation techniques as well.
typical obfuscations are designed to change the program syntax and evade the similarity analysis .
as a result syntax based techniques can become inefficient in the presence of obfuscations.
however as imfsim leverages dynamic analysis to collect program runtime behaviors commonly used obfuscations should not impede it.
we evaluate imf sim on three widely used program obfuscations and it shows promising results in all the settings.
iii.
imf sim we now outline the design of imf sim.
the overall workflow is shown in fig.
.
to compare two functions in two binary executables we first launch in memory fuzzing to execute the functions for iterations and record multiple kinds of behavior traces xiii a .
the central challenge at this step is the lack of data type information.
for example we have no pre knowledge on whether a function parameter is of value or pointer type and misuse of a non pointer data as a pointer can lead to memory access pointer dereference errors.
to address this issue we propose to use backward taint analysis to recover the root of a pointer data flow whenever a dereference error occurs on this pointer.
later we re execute the function and update the recovered dataflow root e.g.
an input of the function with a valid pointer value xiii b .
after collecting behavior traces for each fuzzing iteration third column in fig.
we then concatenate behavior traces of the same kind e.g.
behavior traces representing heap memory accesses to build the final behavior traces each of which records one type of runtime behavior through multiple fuzzing iterations.
to compare two functions two behavior traces of the same kind are used to calculate a jaccard index rate xiii c the jaccard index rates of all the behavior traces are gathered to form one numeric vector for two functions.
we label sample vectors according to the ground truth and train a machine learning model xiii d .
later for a given vector of two functions the trained model can yield a similarity score.
for a given function f1in binary bin1 to find its matched function in bin2 we compare f1against every function in bin2 and take the sorted top one matching as the final result.
imf sim consists of four modules namely the fuzzing module taint analysis module similarity analysis module and machine learning module.
the in memory fuzzing module of imf simis built on top of pin a widely used dynamic binary instrumentation tool .
we develop a plugin of pin i.e.
a pintool for the in memory fuzzing functionality.
this module consists of over lines of c code.
the other three modules are all written in python consisting of over lines of code.
scope and limitations.
imf sim is mainly designed for similarity testing among binary components.
although in this authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
tar get function foo mov rdi rcx cmp rsi 0x10 je l add rax rbx ... l mov r12d edx mov 0xff rcx ...in memory fuzzing foo mov rdi rcx cmp rsi 0x10 je l add rax rbx ... l mov r12d edx mov 0xff rcx ...rdi 0x0 rsi 0x0 .. .
.
.
.rdi 0x0 rsi 0xf f rdi 0x0 rsi 0x1fe foo mov rdi rcx cmp rsi 0x10 je l add rax rbx ... l mov r12d edx mov 0xff rcx ...rdi 0x0 rsi 0x8f7program beha viors heapread 0x12 0x34 ... heapwrite 0x01 0x23 ... return 0x00 ... .. .
.
.
.
heapread 0x12 0x99 ... heapwrite 0x01 0xff ... return 0x1f ...beha vior traces heapread 0x12 0x34 ... 0x12 0x99 ... ... heapwrite 0x01 0x23 ... 0x01 0xff ... ... .
.
.
.
.
.
return 0x00 0x1f ...concatlcs comparison behavior trace of heapreadfunction a behavior trace of heapreadfunction bfeature v ector of elements .
.
.
.
.
.
jaccardinde x learning predication x k k2 k3 vote k fig.
.
the workflow of imf sim.concat in the figure stands for concatenation .
research we utilize imf sim to analyze the function level similarity as in memory fuzzing supports to execute any program component the fuzzing inputs need to be deliberately selected regarding the context it should be interesting to investigate whether our technique can be used to find similar code to an arbitrary trunk of code instead of a whole function.
imf sim captures the program runtime behaviors thus stripped binaries which contain no debug or program relocation information are supported by imf sim.
furthermore our evaluation shows that syntax changes due to different compilers optimizations or even commonly used obfuscations can also be analyzed without additional difficulties.
the employed dynamic analysis infrastructure pin is designed to instrument x86 binaries.
in this work we implement imf sim to instrument binaries on bit linux platforms i.e.
binaries with the elf format .
it is not difficult to port imf simto other platforms supported by pin e.g.
windows or bit linux .
naturally users need to provide the range information i.e.
the starting and ending addresses of the test function before processing.
although the function information is indeed absent in most stripped binaries recent work has provided promising results to precisely recover such information .
a. in memory fuzzing in this section we introduce the design of the in memory fuzzing module.
our fuzzing module is designed following the common design of a fuzzer.
in general we first setup the environment for fuzzing xiii a1 .
before each test iteration we mutate one input and then launch the fuzzing execution xiii a2 .
we collect the behavior traces during each fuzzing iteration xiii a3 .
after one iteration of fuzzing we resume from the starting point mutate one input and launch the next iteration until we have iterated for the predefined times xiii a4 .
we now elaborate on each step in details.
environment setup to present a fair comparison regarding program behaviors we first create an identical environment before the test of each function.
to this end we set all generalpurpose registers to zero and maintain a memory access map.
this map will be updated before every memory write operation the key of each item is the memory address and the valueis the memory cell s content before each fuzzing iteration.
the memory access map is used to reset the environment to its original status at the end of each fuzzing iteration.
in the absence of program type information on assembly code it is likely to encounter memory access errors during execution.
for each invalid memory access we use backward taint analysis to recognize the root of the memory address dataflow within the test function and update the root with a valid memory address.
to this end we allocate a chunk of kb memory referred as vmem on the heap when setting up the environment.
we also initialize every bit long memory cell in vmem 1with a valid memory address that refers to a random position within vmem this method guarantees most memory accesses through address computation and multi level pointer dereferences are still valid.
since memory write could break valid pointers in vmem we create another memory region v mem with the same size and intercept memory write towards vmem .
the intercepted memory writes will be redirected to vmem .
note that we use the same seed to initialize the random number generator before initializing the memory chunk vmem .
this approach guarantees the memory chunk is identical among different testing.
the pointer that refers to the middle of this chunk is used to fix the root of an invalid memory address data flow xiii b .
at the program entry point we update the value of the instruction pointer register i.e.
rip for the bit x86 architecture the execution flow is then redirected to the first instruction of the target function.
we then launch the above procedure to initialize the context and memory.
input mutation as we are focusing on analyzing the function level similarity function inputs naturally serve as the mutation targets.
according to the calling convention on the bit x86 architecture caller functions use sixpredefined registers to pass the first six arguments to callees.
functions with more than six parameters use the memory stack to pass additional arguments.
imf sim mutates those six predefined registers to fuzz the first six potential arguments.
for a function with equal or less than six parameters all of its inputs are mutated by imf sim.
as for functions with more than six parameters their first six arguments are mutated.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
typically the fuzzing process mutates program inputs randomly or following certain predefined rules both approaches are widely adopted by fuzzers.
our implementation follows a common approach step fuzzing to mutate the inputs.
starting from zero we increment one input with a predefined step while preserving the others each time the step is set as 0xff in our current prototype implementation.
we mutate one register for ten times while preserving the rest which leads to sixty execution iterations in total for one function.
function execution during the process we keep track of multiple kinds of program behaviors behavior information is used for similarity comparison.
in addition to facilitate the backward taint analysis we also record the already executed instructions the context information including the value of every general purpose register of every executed instruction is recorded as well.
whenever encountering a pointer dereference error this information will be dumped out as the input of our taint analysis module xiii b .
imf simcaptures various kinds of runtime behaviors.
one important design concept of imf sim is that it treats the target function as a blackbox.
that means we only capture theinteraction between the monitored function and its runtime environment.
this design choice should be more resilient towards potential changes on the target program.
for example compiler optimized programs tend to use registers instead of the memory stack to store function local variables.
hence monitoring of stack memory access could be impeded by this optimization.
we present the captured features as follows featurenis abbreviated as fn value read from or write to the program heap f f2 .
memory address offsets for reading the .plt.got section f .
memory address offsets for reading the .rodata section f4 .
memory address offsets for reading f or writing f the.data section.
memory address offsets for reading f or writing f the.bss section.
system calls made during execution f .
memory address offsets for accessing vmem f10 or vmem f11 .
function return value f .
as we intercept the memory accesses we record the value read from or write to the heap region respectively f 1and f2 .
we also record memory address offsets used to access four global data sections for each memory access the offset is calculated regarding the base address of the target section .
.data and.rodata sections store global data objects .bss stores uninitialized objects while .plt.got section stores routines to invoke functions in the dynamically linked modules.
for .plt.got androdata sections we keep track of every memory read access as these two sections are readonly f .
we keep both read and write for other three sections f .
considering there could exist many zero bytes in the memory we assume that the memory address offset is a more informative feature than the visited content in a memory access.
hence while the concrete value read from or written to the heap region is recorded as f1andf2 we calculate the memoryaddress offsets of the visited memory cells for f3 .
note that heap has multiple memory allocation strategies which could put the same data at different places.
thus we conservatively employ the value instead of the offsets as features for f1and f2.
on the other hand as global data sections in the memory essentially preserve the relative positions in original binary executables it is mostly safe to use the memory offsets as features.
by reading the symbol tables of the input executables symbol tables still exist in even stripped executables to provide exported function information for dynamic linkage memory addresses for accessing the .plt.got section can be mapped to dynamic linked function names.
in other words we have indeed recorded the invoked library functions.
besides system calls are recorded as well f .
recall we create two special memory regions v mem 1and vmem and fix memory access errors with valid pointers towards those regions xiii a1 .
we create two features to represent memory read and write towards them f 10andf11 .
specified by the bit x86 architecture calling convention callees pass the return value to the call site through register rax.
to capture potential return value we record the value of rax at the end of every execution f .
in total we collect features as shown in the third column of fig.
each of which is actually a sequence of numeric values in this step.
termination and exceptions of one fuzzing iteration during execution we can encounter normal exits execution exceptions and even infinite loops.
we rely on the following rules to terminate the current iteration of execution.
rule 1function execution normally ends at return or interprocedural jump instructions.
rule 2a configured timeout has expired.
the first rule identifies the normal end of a function execution.
note that compiler may optimize return instructions into jump instructions so in addition to return instructions we also check inter procedural jump instructions.
when the target function is inside a recursive call we cannot immediately terminate the execution only by the first rule.
hence we keep a counter to record the number of invoked target function the counter will be incremented every time when the target is called and decremented when it is returned.
we terminate the fuzzing iteration only when the counter is zero.
the dynamic instrumentor we employed can register several handling routines to receive exceptions and signals.
handling routines check the type of exceptions errors due to invalid memory accesses will be fixed through backward taint analysis xiii b .
however given the diverse semantics of test candidates it is still possible to encounter exceptions that are hard to fix e.g.
some library functions require the parameter to be a valid file descriptor which is hard to provide in our context .
to circumvent such issue we keep track of the most recently executed instruction within the target function execution will be resumed from the next associated instruction in the target function when encountering such exceptions.
fuzzing stop recall our current implementation executes each function for sixty iterations and at the end of each execution we check whether we have reached this threshold.
if not we reset the environment mutate one input and relaunch the execution at the beginning of the test function.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
1mov rdi 0x8 rbp 2mov 0x0 0xc rbp 3jmp l2 4l1 5mov 0x8 rbp rax 6lea 0x4 rax rdx 7mov rdx 0x8 rbp 8mov rax eax 9add 0x1 0xc rbp cmp 0x4 0xc rbp 11l2 jle l1c f c f ... a in place recovery.v addr v addr v addr v addr v addr ... b feature trace of memory access.
1mov rdi 0x8 rbp 2mov 0x0 0xc rbp 3jmp l2 4l1 5mov 0x8 rbp rax 6lea 0x4 rax rdx 7mov rdx 0x8 rbp 8mov rax eax 9add 0x1 0xc rbp cmp 0x4 0xc rbp 11l2 jle l1fix crash c root cause oriented recovery.v addr v addr v addr v addr v addr ... d feature trace of memory access.
fig.
.
comparison between the in place method and the root cause oriented method.
the assembly instruction is in at t syntax.
c f stands for crash then fix in place .
vaddr is a valid memory address used to fix the memory access error.
since each function is fuzzed for sixty iterations for each type of monitored program behavior we indeed collect sixty traces.
before we launch the next step analysis we concatenate behavior traces describing the same type of program behavior into a long trace.
that means for each function we finally get behavior traces for usage as we monitor features .
b. backward taint analysis as previously discussed without program type information it is likely to misuse data of value type as inputs for functions with pointer parameters.
if we terminate the execution whenever encountering pointer dereference errors only incomplete behaviors will be collected.
an in place strategy to solve the issue is to update the memory access through an illegal address with a valid address the execution can be then resumed from the current instruction.
despite the simplicity this method does not solve the root cause of memory access errors and the collected behavior traces can become uninformative.
fig.
2a presents assembly code generated by compiling a function this function contains a loop to access every element of an array.
the base address of the array is passed in through the first argument of the function i.e.
register rdi and stored onto the stack line .
later the memory address flows to rax line .
inside the loop the base address of the array is incremented line to access each memory cell line .
suppose the function argument rdi is incorrectly assigned with data of value type.
when memory access error happens line the in place method discussed above would only update rax to facilitate the current memory access at line .
memory access fails again as the pointer on the stack is notupdated and only memory cell v addr will be accessed and recorded for such case .
on the other hand if we backtrack the pointer data flow to theroot and update it with a valid pointer line in fig.
2c memory accesses originated from the root would not fail line .
more importantly the typical memory access behavior of a loop incremental memory visit with a fixed step can be mostly revealed from the collected behavior trace .
considering such observation we propose to leverage backward taint analysis to identify the root cause of a memory access failure.
given a pointer dereference error we taint the pointer and propagate the taint backwards until reaching the root e.g.
a function input parameter .
we then re execute the function from the beginning and when encountering the root we update it with a valid pointer.
we now elaborate on each step in details.
given a memory access failure the first step is to identify the register that is supposed to provide a valid pointer i.e.
the taint source .
we leverage pin api get base register to get the base register of this memory access.
we take the base register as the starting point of our taint analysis.
we then dump the executed instructions.
as mentioned earlier we record the context information associated with every executed instruction xiii a3 .
here the recorded contexts are also dumped out.
the dumped instructions contexts and the taint source register are the inputs of our taint analysis module.
the next step is to leverage taint analysis to identify the taint sink the root cause .
our taint analysis tool first parses the dumped instructions into its internal representations.
then starting from the taint source the taint engine iterates each instruction and propagates the taint label backwards.
the taint propagation will be stopped after we iterate all the instructions.
we then take the most recently tainted code which can be either a register or a memory cell as the sink point.
the taint module follows the common design of a taint analysis tool.
we create a bit bit vector for each bit register.
as registers are represented by bit vectors tainting is indeed on the bit level.
this bit level tainting guarantees operations on small length registers can also access and propagate the taint.
to record taint propagation through memory cells our taint engine keeps a lookup table each element in the lookup table is a memory address indicating the referred memory cell is tainted.
tainting operation will insert new elements into this table while untainting will delete the corresponding entry.
as we perform static analysis on the execution traces straight line code the taint analysis is actually quite efficient.
in addition before analyzing each instruction our taint engine updates registers with concrete values acquired from the context information associated with the current instruction.
that means even for memory read write operations with composite addressing we know exactly what the memory address is.
approximations made by most static analysis are not needed.
table i shows the propagation rules adopted in our work.
six potential backward taint flows are summarized in table i and our current policy propagates taint for the first one.
when the left variable of an assignment instruction has taint policy in table i we assume the taint is from the right variable.
thus we propagate the taint to the right value could be a register or memory cell and remove the taint on the left value.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i taint flows under different conditions and their corresponding backward propagation rules .
policy instructionist isutaint policytainted?
tainted?
t u x u t t u x t u x x t t u x t t u x t t u x x symbol tandustand for register memory access or constant data.
denotes arithmetic or logic operators.
b taints b while b removes the existing taint label from b. besides this case we conservatively keep the taint without any propagation.
after the taint analysis is complete we return the discovered sink to the fuzzing module.
there could exist multiple memory access errors during the execution of one function each of which originates from a different taint sink.
thus the fuzzing module keeps a list of all the identified taint sinks and fixes encountered sink points by checking the list.
c. longest common subsequence as presented earlier we acquire multiple behavior traces by fuzzing a function.
to analyze the similarity of two functions we compare each behavior trace of the same kind.
in particular we utilize the longest common subsequence lcs algorithm to calculate the similarity among two traces.
the longest common subsequence problem identifies the longest subsequence that appears in all sequences.
we note that since lcs allows skipping non matching elements it naturally tolerates diverse or noise on the behavior traces due to program optimizations or even obfuscations.
to facilitate further learning step we seek to create numeric comparison outputs.
thus instead of directly using the common subsequence a jaccard index is derived from the lcs of two traces.
the calculated jaccard index is a numeric value ranging from to .
thus to compare two functions we build a numeric vector including jaccard indices of all the recorded features.
jaccard index.
given two behavior traces t 1andt2 the jaccard index is calculated in the following way j t1 t2 jt1 t2j jt1 t2j jt1 t2j jt1j jt2j jt t2j thejt1 t2jis the length of lcs between t1andt2 while jt1j jt2jrepresent the length of t1andt2 respectively.
thej t1 t2 is a numeric value ranging from to two sequences are considered more similar when the jaccard index is closer to .
as numeric vectors built in this step describe the similarity of two functions regarding different program behaviors each element in the vector is indeed a feature in the comparison.
thus we denote these vectors as feature vectors following the common sense.
d. training after collecting feature vectors we train a machine learning model for prediction.
later for a feature vector from the comparison of two functions the trained model yields aprobability score range from to showing the possibility that two functions are matched.
in this research we choose to train a tree based model i.e.
extra trees for prediction.
comparing with kernel based models e.g.
svm or neural network based models tree based models do not assume the underlying distributions e.g.
gaussian of the data set and are considered more understandable for human beings.
tree based model essentially trains a set of decision trees on sub samples and leverages a voting process on top of the decision trees for the final results .
while the well known tree based model i.e.
random forest uses several optimizations in constructing decision trees extra trees makes them at random.
our tentative test shows that random forest model can be trapped in over fitting e.g.
good performance on training sets while worse on test sets and we consider the over fitting is mostly due to its optimizations.
however without further information to solve this issue we choose extra trees in our research regarding its more generalized settings.
besides without the optimizations extra trees usually has a shorter training time.
we leverage the python machine learning library sklearn for the model training process .
although the trained model is usually used for a binary prediction problem i.e.
given a feature vector by comparing two functions it yields whether they are matched or not we use the trained model in a slightly different way.
that is we configure the model to return a probability score i.e.
the similarity score for each input vector indicating the possibility to label this vector as one i.e.
two functions are matched .
as for the parameters we set the number of estimators i.e.
number of decision trees as which leads a time accuracy trade off and use the default value for all the other parameters.
before the training process we first label the feature vectors.
a feature vector is labeled as a positive sample when it is produced by comparing functions that are supposed to be matched.
such ground truth is acquired by comparing the function name we assume two functions are similar only if they have the same name.
we introduce how we get such ground truth for our evaluation in xiv .
we label the rest as negative samples.
we also balance the positive and negative training samples before training.
further discussions on the applicability of our machine learning based approach will be presented inxv.
iv.
e valuation we now present the evaluation in this research.
there are features recorded along the analysis xiii a3 and our first evaluation studies the importance of each captured feature regarding our predication task.
we then launch a standard tenfold validation towards imf sim binaries produced by nine different compilation settings are tested.
the second step is cross compiler validation we launch experiments regarding six cross compiler settings.
in the third step evaluation we validate imf simby comparing normal binary code and their obfuscated versions.
note that both second and third step evaluations are cross model validations.
that is we train the model with data used in step one and verify the trained model with new data produced for experiments in step two and three.
this cross model validation step is necessary as when authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deploying in real world scenarios imf sim is supposed to train with standard training sets e.g.
data used in step one and do prediction towards binaries from various compilation and event obfuscation settings typical cases are tested in step two and three .
we present further discussion in xv.
similar with previous research we measure the performance of imf sim regarding its accuracy i.e.
the percentage of correctly matched functions.1for a function f1 in binary bin1 we iteratively compare it with functions in binary bin2and take the comparison pair with the highest similarity score i.e.
rank one as the matched pair.
in addition we also evaluate whether a function can find its correct match when checking the top three and five function pairs rank three and rank five .
it is reasonable to assume experts can further identify the correct match with acceptable amount of efforts given three or five function pair candidates.
moreover there could exist several comparisons that have equivalent similar rates e.g.
the similar rate of rank and rank is equal to .
.
however we do not consider such possibility and only take the first n n is or matches for consideration.
we now introduce the data set and the ground truth in the evaluation.
data set.
we employ a widely used program set gnu coreutils as the data set in our research.
coreutils version .
consists of binaries which provide diverse functionalities such as textual processing and system management.
we rule out binaries with destructive semantics e.g.
rm which leads to remaining programs.
as previously mentioned we compare normal binary code with their obfuscated versions.
we employ a widelyused obfuscator obfuscator llvm in our evaluation obfuscator llvm is referred as ollvm later .
ollvm is a set of obfuscation passes implemented inside llvm compiler suite which provides three obfuscation methods i.e.
instruction substitution bogus control flow i.e.
opaque control flow predicate and control flow flattening .
all of these methods are broadly used in program obfuscation.
we leverage all the implemented methods to produce binaries with complex structures.
in summary our data set consists of three variables leading to unique binaries in total compiler.
we use gnu gcc .
.
intel icc .
.
and llvm .
to compile programs.
optimization level.
we test three commonly used compiler optimization settings i.e.
o0 o2 and o3.
obfuscation methods.
we test program binaries obfuscated by three commonly used methods which are provided by obfuscator llvm version .
.
.
comparison with existing work.
we compare imf sim with the state of the art research work bingo and blanket execution i.e.
blex that deliver function level similarity analysis.
both research work employ coreutils as the dataset in the evaluation.
we compare imf simwith them by directly using data provided in their paper table v .
we also compare imf sim with the industrial standard binary diffing tool b indiff .
blex and b ingoare also compared with b indiffin their paper.
we use b indiff v4.
.
to evaluate all the experiment settings table iii 1same with previous research we use accuracy instead of precision recall rate for the evaluation.
note that accuracy is not equal to precision.table ii feature importance evaluation .
the definition of each feature is presented in xiii a3.
featur e importance featur e importance featur e importance f1 .
f2 .
f3 .
f4 .
f5 .
f6 .
f7 .
f8 .
f9 .
f10 .
f11 .
f12 .
table iv table vi .
benefit from well designed graph isomorphism comparisons b indiffis also stated as resilient towards different compilers and optimizations .
ground truth.
although our technique itself does not rely on the debug and symbol information inside the binary executables we compile the test programs with debug symbols to get the function information.
particularly we disassemble the binary code with a disassembler objdump and then read the function name and range information from the disassembled outputs.
the ground truth in our work is acquired by comparing the function names.
two functions are considered matching only if they have the same name.
besides the range starting and ending memory addresses of each function serves as the input of imf sim.
a. feature importance we first evaluate the importance of each feature we captured.
that is we try to answer the question that with respect to different features how much does each feature contribute to the overall effectiveness of imf sim.
the machine learning model implementation sklearn provides standard apis to acquire such data .
to this end we fit our model with all the test samples and present the importance of each feature.
the results are shown in table ii.
in general four features have the importance of over and eleven features over .
the only outlier f is memory writes towards the global data section which has an importance of .
.
overall our evaluation shows that most of the features have noticeable importances and we interpret our feature selection step xiii a3 as reasonable.
b. ten fold validation in this section we perform a standard approach i.e.
tenfold cross validation to test the performance of imf sim.
in general this validation divides the total data set into subsets and tests each subset with the model trained by the remaining .
in this step binary code produced by nine compilation settings are employed.
table iii presents the evaluation results of three ranks respectively.
the accuracy rate represents the average of the tests.
even through we train the model with data of six different comparison settings together we separately verify the trained model regarding test data of each setting leading to six categories.
on average imf sim has over rank one similarity score and the accuracy rate goes to over regarding the rank five matches.
the evaluation data shows that compiler optimizations indeed affect the performance.
on the other hand we observe the performance is notably increased regarding rank three and rank five.
hence we interpret that users are very likely to identify the real matching pair by further analyzing the first three or five matches.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii ten fold validation towards c o r e u t i l s binaries .
rank one rank thr ee rank fi v e bindi ff gcc o0 vs.gcc o3 .
.
.
.
gcc o2 vs.gcc o3 .
.
.
.
icc o0 vs.icc o3 .
.
.
.
icc o2 vs.icc o3 .
.
.
.
llvm o0 vs.llvm o3 .
.
.
.
llvm o2 vs.llvm o3 .
.
.
.
av erage .
.
.
.
table iv cross compiler validation .
rank one rank thr ee rank fi v e bindi ff gcc o0 vs.icc o3 .
.
.
.
gcc o0 vs.llvm o3 .
.
.
.
icc o0 vs.gcc o3 .
.
.
.
icc o0 vs.llvm o3 .
.
.
.
llvm o0 vs.gcc o3 .
.
.
.
llvm o0 vs.icc o3 .
.
.
.
av erage .
.
.
.
imf simshows consistent results comparing with b indiff regarding icc llvm o2 vs. o3.
both imf sim and b indiffyield very high accuracies for these two comparison settings.
our further study on the disassembled outputs shows that assembly code produced by icc llvm o2 is indeed similar to their corresponding o3 level.
in addition while the comparisons between binaries compiled by llvm o0 vs. o3 show better performance the evaluation results for gcc andicc o0 vs. o3 are similar.
we consider binaries compiled by gcc andicc show similar behaviors regarding features imf sim captures and our further evaluations report consistent findings.
in general while the de facto industrial tool b indiffsuffers from heavy compiler optimizations we interpret imf sim shows promising results regarding such challenging settings.
c. cross compiler validation in this section we launch evaluations to compare binaries produced by different compilers.
to this end we train a model leveraging all six groups of data used in the first evaluation xiv b .
the trained model is then used to verify comparisons with cross compiler settings.
given the intuition that compiler optimization obfuscates programs evaluation in table iii is consistent with this intuition we compare binary code under the most challenging setting i.e.
comparing un optimized o0 binary code with the heavily optimized o3 code.
the evaluation results are presented in table iv.
stating the challenge imf sim actually performs well in most of the settings.
we observe the comparison between gcc icc andllvm show similar results especially for llvm o0 vs.gcc icc o3.
we interpret the results are consistent with our findings in xiv b binaries compiled by gcc and icc compilers show similar behaviors in front of imf sim.
besides while comparisons between llvm o0 and gcc icc o3 show relatively low performance in terms of rank one score rank three scores are improved to over .
on the other hand b indiffperforms poorly in terms of all the settings in this evaluation on average .
accuracy score .table v compare imf sim with the state of the art research work blex and bingo and de facto industrial standard tool bindiff .5means such data is not available .
im f sim bindi ff bl ex bingo llvm o0 vs.llvm o3 .
.
.
llvm o2 vs.llvm o3 .
.
.
gcc o0 vs.llvm o3 .
.
.
llvm o0 vs.gcc o3 .
.
.
gcc o0 vs.gcc o3 .
.
.
.
gcc o2 vs.gcc o3 .
.
.
.
gcc o0 vs.icc o3 .
.
.
d. comparison with existing work as aforementioned we compare imf sim with two stateof the art research work .
table v presents the comparison results we also include b indiff s data for reference .
blex evaluates results of three different compilation optimization settings last three rows in table v .
b ingoreports more settings and we use settings that overlap with our evaluation row .
in general we interpret that all the four tools show similar findings that heavy compiler optimizations bring in additional challenges i.e.
comparison between o2 and o3 yields better results than o0 vs. o3.
on the other hand imf sim can outperform all tools in all these settings.
as previously discussed b indiff which leverages program control flow as features to analyze the similarities shows notably low resilience towards heavy compiler optimizations comparisons between o0 vs. o3 are much worse than o2 vs. o3 for b indiff .
on the other hand the other three semantics based tools are considered more stable regarding optimizations.
bingo captures semantics information mostly through symbolic execution and i o sampling and it has relatively poor performance comparing to the other two dynamic execution based tools.
imf sim and blex both acquire more precise information by indeed executing the test targets.
however different from blex which forces to execute every instruction of the test target and breaks the original execution paradigm imf simfixes pointer dereference error on demand and reveal the original program behavior in a more faithful approach.
in sum we interpret the comparison results as promising.
e. comparison with obfuscation code in addition to the evaluations of normal binaries we also launch comparisons between normal binaries and their corresponding obfuscated code.
we follow the same approach asxiv c to train the model.
we leverage all the obfuscation methods provided by ollvm to obfuscate binary code optimized with o3 ollvm employs compiler llvm to compile the code .
given three groups of obfuscated code we then compare each group with three sets of normal code.
the evaluation results are presented in table vi.
instruction substitution sub.
replaces simple operations e.g.
addition into semantics equivalent but syntax level more complex formats.
despite its efficiency of misleading syntax based similarity analysis such obfuscation can hardly defeat imfsim which captures program semantics runtime behaviors .
bogus control flow bcf.
inserts opaque predicates to protect conditional branches such predicate is usually difficult to be authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table vi validation towards obfuscated code compiled by ollvm with o3 optimization level ollvm employs l l v m compiler .
comparison obf.
rank one rank three rank fiv e bindi ff llvm o0 bcf.
.
.
.
.
gcc o0 bcf.
.
.
.
.
icc o0 bcf.
.
.
.
.
llvm o0 fla. .
.
.
.
gcc o0 fla. .
.
.
.
icc o0 fla. .
.
.
.
llvm o0 sub.
.
.
.
.
gcc o0 sub.
.
.
.
.
icc o0 sub.
.
.
.
.
av erage .
.
.
.
reasoned until runtime .
we observed that analysis results become worse regarding this obfuscation technique.
considering our fuzzing strategy as relatively simple we interpret the results as reasonable opaque predicate complicates the monitored execution behaviors and also potentially impedes our fuzzer from drilling into the guarded branch.
we also observe that fewer functions are correctly matched when applying the control flow flattening obfuscation fla. .
in general control flow flattening changes the structure of the original control flow into a flatten structure the execution flow is chained by switch statements to iterate basic blocks .
considering such design it is not surprising that the collected behavior traces of imf sim are affected due to this structure level changes.
nevertheless comparing with bindiffwhich relies on program control flow information for analysis imf sim still demonstrates the obfuscation resilience and outperforms this industrial strength tool.
f .
processing time our experiments are launched on a machine with intel xeon r e5 cpu .90ghz and 128gb memory.
in this section we report the processing time of imf sim.
feature generation.
in our evaluations we test groups of comparison each of which consists of program pairs.
we measure the total feature generation time from starting to execute the first test binary until finishing producing the feature vector of the last comparison.
we report that imfsim takes .
cpu hours to process all the comparisons pairs groups .
on average it takes around .
cpu hour to compare two binaries.
note that the report time indeed underestimates imf sim s processing speed as in our prototype implementation a binary re generates behavior traces for each comparison a binary can participant in multiple comparisons .
we also report the processing time of b indiff is .
cpu seconds.
b ingois reported as efficient as well .
in general our study shows that lightweight static feature based tools can take much less time to process like bindiffand b ingo however they suffer from relatively worse comparison accuracies according to our evaluations xiv .
on the other hand blex reports to take cpu days cpu hours to process binaries while our work takes .
cpu hours for comparison pairs.
although test cases used by imf sim and blex are not exactly the same and blex uses different hardware to measure the processing time we can still see that dynamicanalysis based approaches despite its much better comparison accuracies would lead to relatively high performance penalties in general.our study reveals one task that takes a large amount of processing time the calculation of longest common subsequence lcs .
this algorithm itself has a relatively high computation complexity.
however since each comparison task performed by imf simis independent with each other the realtime can be reduced by employing more cpu cores.
model training and prediction.
the training of the extratrees model takes .
cpu seconds.
given the trained model and the generated feature vectors prediction is straightforward.
we report that total prediction time is .
cpu seconds for all the experiments in xiv b xiv c andxiv e. recall we undertake groups of comparisons each of which consists of binary pairs.
thus on average it takes .
cpu seconds to compare one pair of binaries.
in general we consider the overall model training and predication as effective.
furthermore since we are using extra trees as the learning model it is actually suitable to speedup the real training time by employing multiple cpu cores.
v. d iscussion obfuscations.
we have evaluated imf sim on both benign and obfuscated binary code.
as discussed in xii the dynamic testing approach used in imf sim is indeed quite robust even in the presence of code obfuscation techniques program runtime behaviors are revealed and captured during the execution.
on the other hand previous static analysis based similarity testing may be impeded.
according to our experiments control flow flattening obfuscation which transforms the structure of the control flow affects the accuracy.
moreover our evaluation shows that imf sim still preserves a quite promising result with diverse settings xiv .
note that many binary reverse engineering and analysis tasks e.g.
indirect memory addressing are theoretically undecidable results from computability theory suggest that it could be very difficult to propose impeccable solutions.
hence it is challenging if possible at all to propose a technique that can defeat all known or to be invented obfuscations.
certainly imf sim is not designed to defeat all of them.
nevertheless imf sim shows its practical value in the presence of commonly used obfuscations.
code coverage.
we have also performed some tentative tests on the code coverage of imf simbefore launching the experiments of function similarity.
the results are promising with an average .
instruction coverage.
in general we consider the experiments and the comparisons with state of the art tools have shown promising results given the current coverage.
additionally code coverage could be further improved through advanced grey box fuzzing technique we leave it as one future work to adopt such advanced techniques in imf sim.
on the other hand we believe pushing the code coverage to the extreme as blanket execution does may not be the best practice in our context i.e.
similarity analysis .
improving the code coverage at a best effort while preserving theoriginal execution paradigm shall be a better way to collect features that can truly reveal the program behavior.
our evaluation also reports consistent findings.
we present further comparisons with blex in xvi.
applicability of the machine learning based approach.
we do not undertake an explicit model tuning step in this authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
work.
the key motivation is that by adopting the default setting of the well studied model except setting the number of decision trees as we have already observed promising results xiv .
further tuning step can be launched by following standard procedures which is well documented by the machine learning library we use .
we note that our classifier is not over specialized regarding obfuscation.
we train imf sim with only normal program binaries compiled by three most commonly used compilers on linux platforms and further test the learned model regarding a much broader setting e.g.
commonly used obfuscation methods .
our training set is considered standard which is straightforward to produce and should be used together.
this is actually how imf sim is supposed to use in practice training with a whole set of well known binaries and test with other unknown settings in the wild.
for example when performing malware similarity analysis for unknown malware samples malware researchers can employ samples from several commonly used malware families to train the model and let this model to decide the similarity among different unknown pieces.
future work.
although in this paper we adopt in memory fuzzing for function level similarity analysis as previously mentioned in memory fuzzing is indeed capable of launching test towards any program component.
besides we also plan to further extend our technique by studying the challenges and solutions in detecting similar binary components among large sets of program binaries.
conceptually one potential approach is to put features of each binary component e.g.
a function or a basic block into a pool and for a given binary component querying towards the pool.
to improve the efficiency coarse grained syntaxbased clustering in the pool can be launched before using thesemantics based comparison of imf sim.
vi.
r elated work in this section we review the existing work in finding similar components in programs.
in particular we focus on similarity analysis in executable files.
there also exist orthogonal approaches that aim at finding code similarity at the source code level .
we will not discuss this type of work since analysis on binary code has its own unique challenges and applications.
naturally syntactic features such as opcode e.g.
radiff2 instructions and control flow structures e.g.
b indiff and execution traces are extracted from the binary code and used for static comparison and clustering .
further studies propose to leverage the semantics information to compare binary components .
cop combines symbolic execution with longest common subsequence lcs based similarity analysis for software plagiarism detection their work is considered robust against different compilers and optimizations .
ming et al.
detects code similarity by equivalence checking of system call sliced segments.
these semantic methods are not very scalable.
david et al.
decompose components of an executable and use statistical reasoning over small components to establish the similarity.
their method is mostly proposed as searching vulnerable procedures in a candidate binary pool and noevaluation is reported in terms of obfuscated code.
some recent work also extends the application scope by searching for semantics equivalent components or similar bugs in binary code cross different architectures .
b ingo lifts instructions into intermediate representations and capture the semantics level similarity through i o samples of function model traces.
however our evaluation shows that b ingohas relatively poor performance regarding different compilation and optimization settings.
probably the most similar work with imf sim is blex blanket execution proposed by egele et al.
.
they propose a new execution model i.e.
blanket execution to execute a part of a binary in a controlled context for similarity comparison.
a typical blanket execution starts from the beginning of the target function and exhaustively executes every instruction in the function.
a typical blanket execution could iterate for multiple rounds.
once an error happens such as a memory access error it restarts from the so far unexecuted instruction to make sure each instruction is executed at least once.
program behaviors are collected during execution.
independently godefroid proposes a similar idea referred as micro execution in his work for testing and bug detection in binary code.
the main difference between the previous work and imf sim is that while blanket execution and micro execution break the common paradigm of program execution to greatly improve the instruction coverage imf sim leverages fuzzing and backward taint analysis to exercise a program s normal execution with better path coverage.
in other words feature traces collected in imf sim naturally represent the true program behaviors which further facilitates the longest common subsequence technique to reveal the similarity among even noisy behaviors.
however as the features do not always truly reflect the normal program behavior in blanket or micro execution features are coarsely maintained into a set for comparison .
in general imf sim can better reveal the hidden similarity in challenging settings as shown in our experimental results.
vii.
c onclusion in this paper we present imf sim a tool that identifies similar functions in binary code.
imf sim uses a novel method that leverages in memory fuzzing to execute all the functions inside a binary program and collect behavior traces to train a prediction model via machine learning.
our evaluation shows that it is effective in resilience to the challenges from different compilation settings and commonly used obfuscation methods.
the experimental results also show that imf simoutperforms the state of the art research and industrial standard tools like bingo blex and b indiff.
acknowledgment we thank the ase anonymous reviewers and tiffany bao for their valuable feedback.
this research was supported in part by the national science foundation nsf under grant cns and the office of naval research onr under grants n00014 n00014 and n0001417 .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.