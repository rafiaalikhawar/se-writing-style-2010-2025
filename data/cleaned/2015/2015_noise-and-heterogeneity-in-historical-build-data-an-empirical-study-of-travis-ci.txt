noise and heterogeneity in historical build data an empirical study of travis ci keheliya gallaba mcgill university montr al canada keheliya.gallaba mail.mcgill.cachristian macho university of klagenfurt klagenfurt austria christian.macho aau.at martin pinzger university of klagenfurt klagenfurt austria martin.pinzger aau.atshane mcintosh mcgill university montr al canada shane.mcintosh mcgill.ca abstract automated builds which may pass or fail provide feedback to a development team about changes to the codebase.
a passing build indicatesthatthechangecompilescleanlyandtests continueto pass.afailing a.k.a.
broken buildindicatesthatthereareissues that require attention.
without a closer analysis of the nature of buildoutcomedata practitionersandresearchersarelikelytomake twocriticalassumptions buildresultsarenotnoisy however passing builds may contain failing or skipped jobs that are actively or passively ignored and builds are equal however builds vary in terms of the number of jobs and configurations.
toinvestigatethedegreetowhichtheseassumptionsaboutbuild breakagehold weperformanempiricalstudyof3.7millionbuild jobsspanning1 276opensourceprojects.wefindthat of passingbuildshaveanactivelyignoredfailure ofbuildshave a misleading or incorrect outcome on average and at least of the broken builds contain passing jobs i.e.
the breakage is local to a subset of build variants.
like other software archives build data is noisy and complex.
analysis of build data requires nuance.
ccs concepts software and its engineering software verification and validation software post development issues keywords automated builds build breakage continuous integration acm reference format keheliyagallaba christianmacho martinpinzger andshanemcintosh.
.
noise and heterogeneity in historical build data an empirical studyoftravisci.in proceedingsofthe201833rdacm ieeeinternational conference on automated software engineering ase september montpellier france.
acm new york ny usa 11pages.https permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
introduction aftermakingsourcecode changes developersexecuteautomated buildstochecktheimpactonthesoftwareproduct.thesebuilds are triggered while features are being developed when changes have been submitted for peer review and or prior to integration into the software project s version control system.
tools such as travis ci facilitate the practice of continuous integration ci where code changes are downloaded regularly ontodedicatedserverstobecompiledandtested .thepopularity of development platforms such as github and ci services such as travis ci have made the data about automated builds from a plethora of open source projects readily available for analysis.
characterizing build outcome data will help software practitioners and researchers when building tools and proposing techniques to solve software engineering problems.
for example rausch et al.
identifiedthemostcommonbreakagetypesin14javaapplications and vassallo et al.
compared breakages from opensourcejavaprojectstothoseofafinancialorganization.while these studies make important observations understanding the nuances and complexities of build outcome data has not received sufficientattention bysoftwareengineering researchers.earlywork by zolfagharinia et al.
shows that build failures in the perl project tend to be time and platform sensitive suggesting that interpretation of build outcome data is not straightforward.
tosupportinterpretationofbuildoutcomedata inthispaper we set out to characterize build outcome data according to two harmful assumptions that one may make.
to do so we conduct anempiricalstudyof3 071buildresultsspanning1 276open source projects that use the travis ci service.
noise.first one may assume that build outcomes are free of noise.
however wefindthatinpractice somebuildsthataremarkedas successfulcontainbreakagesthatneedattentionyetareignored.for example developersmaylabelplatformsintheirtravisciconfigu rations as allow failure to enable experimentation with support for a new platform.
theexpectation is that once platform support has stabilized developers will remove allow failure however thisisnotalwaysthecase.forexample the zdavatz spreadsheet1 projecthashadthe allow failure featureenabledfortheentire lifetimeoftheproject fiveyears .exampleslikethissuggestthat noise is likely present in build outcome data.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france keheliya gallaba christian macho martin pinzger and shane mcintosh there are also builds that are marked as broken that do not receive the immediate attention of the development team.
it is unlikelythatsuchbrokenbuildsareasdistractingfordevelopment teams as one may assume.
for example we find that on average two in every three breakages are stale i.e.
occur multiple times in aproject sbuildhistory.toquantifytheamountofnoiseinbuild outcome data we propose an adapted signal to noise ratio.
heterogeneity.
second one mayassume thatbuilds are homogeneous.
however builds vary in terms of the number of executed jobsandthenumberofsupportedbuild timeconfigurations.for example ifthetravisciconfigurationincludesfourrubyversions and three java versions to be tested twelve jobs will be created per build because combinations are possible.
zolfagharinia et al.
observedthatautomatedbuildsforperlpackagereleases take place on a median of environments and seven operating systems.buildsalsovaryintermsofthetypeofcontributor.indeed buildoutcomeandteamresponsemaydifferdependingontherole of the contributor core peripheral .
in this paper we study build heterogeneity according to matrixbreakagepurity breakagereasons andcontributortype.wefind that environment specific breakages are as common as environment agnostic breakages the reasons for breakage vary and can be classified into five categories and subcategories and broken builds that are caused by core contributors tend to be fixed sooner than those of peripheral contributors.
take away messages.
build outcome data is noisy and heterogeneous in practice.
if build outcomes are treated as the ground truth this noise will likely impact subsequent analyses.
therefore researchersshouldfilteroutnoiseinbuildoutcomedatabeforecon ductingfurtheranalyses.moreover tooldevelopersandresearchers whodevelopandproposesolutionsbasedonbuildoutcomedata need to take the heterogeneity of builds into account.
in summary this paper makes the following contributions anempiricalstudyofnoiseandheterogeneityofbuildbreakage in a large sample of travis ci builds.
a replication package containing travis ci specificationfiles metadata build logs at the job level and our data extraction and analysis scripts.
a taxonomy of breakage types that builds upon prior work.
paper organization.
theremainderofthepaperisorganizedas follows section 2describestheresearchmethodology.sections and4present our findings related to noise in build outcome and buildheterogeneity respectively.section 5discussesthebroader implicationsofourstudyfortheresearchandtoolbuildingcommunities.section 6outlinesthethreatstovalidity.section 7surveys related work.
finally section 8concludes the paper.
study design inthissection wedescribeourrationaleforselectingthecorpusof studiedsystemsandourapproachtoanalyzethislargecorpusof builddata whichfollowsmockus four stepprocedure formining software data.
figure 1provides an overview of our approach.
corpus of candidate systems we conductthis studyby usingopenly available projectmetadata andbuildresultsof githubprojectsthatusethetravisciservice to automate their builds.
github is the world s largest hosting serviceofopensourcesoftware witharound20millionusersand57 million repositories in .3a recent analysis shows that travis ci is the most popular ci service among projects on github.
.
retrieve raw data we begin by retrieving the travistorrent dataset which containsbuildoutcomedatafromgithubprojectsthatusethetravisciservice.asofourretrieval thetravistorrentdatasetcontains data about buildjobs that belong to buildsspanning github projects.
those builds include one to build jobs median of .
in addition to build related data the travistorrentdatasetcontainsdetailsaboutthegithubactivitythat triggeredeachbuild.forexample everybuildincludesacommit hash areferencetothebuildtriggeringactivityinits gitrepository the amount of churn in the revision the number of modified files andtheprogramminglanguageoftheproject.travistorrent also includes the number of executed and passed tests.
travistorrentalonedoesnotsatisfyalloftherequirementsof ouranalysis.sincetravistorrentinfersthebuildjoboutcomeby parsingtherawlog itisunabletodetecttheoutcomeof794 jobs .
.furthermore travistorrentprovidesasingle brokencategory whereastraviscirecordsbuildbreakageinthree different categories see subsection .
.
to satisfy our additional data requirements we complement the travistorrent dataset by extracting additional data from the restapithatisprovidedbytravisci.fromtheapi wecollect the ci specification i.e.
.travis.yml file used by travis ci to create each build job and the outcome of each build job.
to enable furtheranalysisofbuildbreakages wealsodownloadtheplain text logs of each build job in the travistorrent dataset.
.
clean and process raw data since we focus on build breakages we filter away projects that do not have any broken builds.
this excludes from our analysis toy projectsthathaveconfiguredciinitiallybutdonotuseciservices.
projects out of survive this filter.
weobservethat996buildlogsdonotparsecleanly.whenretrievingtheselogs thetravisciapireturnedatruncatedorinvalid response.
we also filter these logs out of our analysis however we donotethatthese996logsaccountforanegligibleproportionof the sample of analyzed build logs .
.
.
construct meaningful metrics inthissubsection wefirstdefinethetravisciconceptsthatare useful for understanding our work.
then we define the metrics that we use to operationalize the study dimensions.
core concepts in travis ci.
in this paper we adhere to the terminology as defined in the official travis ci documentation.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
noise and heterogeneity in historical build data ase september montpellier france !
!
figure an overview of the approach we followed for data analysis.
ajobis anautomated process that clonesa particular revision ofagitrepositoryintoa virtual environmentandthencarriesout a series of tasks such as compiling the code and executing tests.
eachjobiscomprisedofthreemain phases install script and deploy.eachphasemaybeprecededbyabeforesub phaseorfollowed by an after sub phase.
these sub phases are often used to ensurethatallofthepre conditionsaresatisfiedbeforethemain phase is executed before install before script before deploy and allofthepost conditionsaremetafterexecutingthemainphase commands after success after failure after deploy .
abuildis comprised of jobs.
for example a build can have multiplejobs eachofwhichteststheprojectwithadifferentvariant ofthedevelopmentorruntimeenvironment.onceallofthejobs in the build are finished the build is also finished.
for each job travis ci reports one of four outcomes passed.the project was built successfully and passed all tests.
all phases terminate with an exit code of zero.
errored.
if any of the commands that are specified in the before install install orbefore script phases of the build lifecycle terminate with a non zero exit code the build is labelled as errored and stops immediately.
failed.ifacommandinthe scriptphaseterminateswitha non zero exit code the build is labelled as failed but execution continues with the after failure phase.
cancelled.
a travis ci user with sufficient permissions can abort the build using the web interface or the api.
such builds are labelled as cancelled.
projectsthat use thetravis ciserviceinform travis ciabout how build jobs are to be executed using a .travis.yml configurationfile.thepropertiesthataresetinthisconfigurationfilespecify which revisions will initiate builds how the build environments are to be configured for executing builds and how different teams orteammembersshouldbenotifiedabouttheoutcomeofthebuild.
furthermore the configuration file specifies which tools are required during the build process and the order in which these tools need to be executed.
metrics.
based on the above concepts we define seven metrics to analyze build breakage.
these metrics are not intended to be complete but instead provide a starting point for inspecting build breakage for suspicious entries that future work can build upon.
our initial set of metrics belong to two dimensions.
build noise metrics.
in this dimension we compute the rateatwhichbuildbreakageis activelyignored andpassively ignored.inaddition wemeasurethe stalenessofeachbroken build i.e.
the rate at which breakages are recurring.
finally we compute the signal to noise ratio snr to measure the proportionofnoiseinbuildoutcomedatacausedbypassively and actively ignored build breakage.
build heterogeneity metrics.
inthisdimension foreach broken build we compute the matrix breakage purity and classifybrokenbuildsbythe rootcause.forpracticalreasons weextractrootcausesforbuildbreakagefromthe67 267jobs that use the maven build tool.
this allows us to build upon the mavenlog analyzer whichcan classifyfive types and24subtypesofmavenbuildbreakage.finally weclassify each of the version control revisions that are associated with each build according to contributor type i.e.
core or peripheral contributors .
.
analyze and present results using the metrics that we define in section .
we plot their valuesusingbarcharts linegraphs scatterplots andbeanplots and conduct statistical analyses using spearman s wilcoxon signed rank tests and cliff s .
noise in build breakage data the final build outcome does not always tell the complete story.
indeed abrokenbuildoutcomemaynotindicateaproblemwith thesystem butratheraproblemwiththebuildsystemortestsuite.
conversely apassingbuildoutcomemayonlybelabeledassuch because breakages in particular jobs are being ignored.
inthissection wepresenttheresultsofournoisinessstudyin termsofoutcomesofbuildsthatareactivelyignored .
passively ignored .
or stale .
.
we also provide an overview of the signal to noise ratio in the studied corpus .
.
.
actively ignored by developers motivation.
supportfornewruntimeenvironmentsisoftenslowly rolledoutthroughadaptivemaintenance .whilesupportfor newplatformsareintheexperimentalstage developersmayignore build breakage on these platforms.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france keheliya gallaba christian macho martin pinzger and shane mcintosh topreventfailingjobsinexperimentalareasofthecodebasefrom causingbuildbreakage travisciuserscansetthe allow failure propertywhentestingagainstversionsorconfigurationsthatdevelopersarenotreadytoofficiallysupport.6inotherwords ajobmay fail however because the developers chose to ignore the outcome ofitsconfiguration theoutcomeofthebuildispassing.soifanalyses assume the build is successful because the reported outcome is passing actively ignored breakages may introduce noise.
therefore weanalyze how oftenbreakages areactively ignoredin our corpus.
approach.
we begin by selecting all of the passing builds inourdataset.fromthosebuilds weselecttheoneswithfailingjobs.
then weretrievethecorrespondingversionofthe .travis.yml foreachofthoseselectedbuildsandcheckifthe allow failure property is enabled for the failing jobs.
results.
inadditiontocomputinghowoftenpassingbuildscontain failing jobs figure 2shows how the percentage of actively ignored failing jobs is distributed in passing builds that had at least one ignored failed job.
observation of passing builds have an actively ignored failure.ofthe496 240passingbuildsinourcorpus 904builds had at least one actively ignored failure.
moreover figure 2shows that in the passing builds that had at least one actively ignored failing job the median percentage of ignored failing jobs is .
in an extreme case of the jobs were actively ignored.
we observethisinthe rubycas rubycas client7projectwherethe allow failure property is set in out of the jobs.8upon closer inspection we observe that this is an example of the intended use of the allow failure property.
this build specifies eleven ruby versions as runtimes and four gemfiles for dependency management.sixofthecombinationsareexplicitlyexcluded.thus 38jobs arecreatedforeachbuild .allofthe33jobsthathave theallow failure property set fail.
in subsequent builds after several source code changes by the development team all of these failingjobsbegintopass.finally thedevelopmentteamremoves theallow failure property from these jobs with an accompanying commit message that states that builds should fail on released versions of ruby and rails .
the development team only ignored failureswhiletheyimprovedtheirsupportformultiplerubyand rails versions.
onthe otherhand the allow failure settingcan bemisused.
forexample inthe zdavatz spreadsheet9project the allow failure property whichissetintheinitialbuildspecificationoftheproject is never removed from the build specification throughout the fiveyearhistoryoftheproject.10furthermore inourcorpus wedetect projects that had the allow failure property set in all of their builds.theseprojectswerenotshort lived with31to769builds in each project median of .
this suggests that although the intendedpurposeofthe allow failure propertyistotemporarilyhidebreakages developmentteamsdonotalwaysdisablethis property after it has been set leaving the breakages hidden.
percenta ge of i gnored failed jobsfrequency figure2 percentageofignoredfailedjobsinpassingbuilds thathadatleastoneignoredfailedjobacrossallprojects.upto of the jobs are actively ignored.
passingbuildoutcomesdonotalwaysindicatethatthebuild was entirely clean.
.
passively ignored by developers motivation.
buildbreakageisconsideredtobedistractingbecause it draws developer attention away from their work to fix build reported issues .
if development can proceed without addressing a build breakage we suspect that the breakage is not distracting.
sincethese passively ignoredbreakages may introduce noiseinanalysesthatassumethatallbreakagesaredistracting.we set out to analyze how often breakages are passively ignored.
approach.
to detect passively ignored breakages we construct andanalyzethedirectedgraphofrevisionsfromtheversionhistory that have been built using travis ci.
build filtering.
we start by selecting the git trigger commit and the git prev built commit fields of each buildfromtravistorrent.the git trigger commit field referstotherevisionwithintherepositorythatisbeingbuilt.
the git prev built commit field refers to the revision thatwasthetargetoftheimmediatelyprecedingbuild.multi plebuildsmaybeassociatedwithone git trigger commit because developers can configure travis ci to run buildsat scheduled time intervals even if no new commits have appeared in the repository.11builds can also be triggered by thetravisciapi regardlessofwhethertherearenewcommits in the repository.12we remove such duplicate builds by checking for builds that have event type property set tocronorapi.
this reduces the number of builds from 209to676 .traviscialsotriggersbuildswhen git tags are created even if the tagged commit has already been built.we remove buildsthat weretriggered bytag pushes bycheckingfornon nullvaluesforthe tagsproperty.this reduces the number of builds to .
however there are authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
noise and heterogeneity in historical build data ase september montpellier france multiple builds remaining for one git trigger commit because manual build invocations can be made via the travis ciwebinterface.thesemanualinvocationscannotbedistinguished from regular builds that were triggered by git pushes.
therefore when multiple builds are encountered forone git trigger commit theearliestbuildisselected.
this reduces the number of builds to .
graphconstruction.
nodesinthegraphrepresentbuildtriggeringcommits whileedgesconnectbuildschronologically.
all nodes are connected by edges from git prev built commit node to git trigger commit node.
graph analysis.
we use the directed graph to identify build triggering commits from which others branch.
we selectthosebranchpointbuild triggeringcommitsthathavea non passing outcome.
then we traverse all of the branches of such builds in a breadth first manner to find the earliest build where the outcome is passing.
finally we countthe number of builds along the shortest path between the breakage branch point and the earliest fix.
results.
figure3showsthebrokenbuildsthatareatthebranch points in the version history of the project.
to some degree developers passively ignored these failures by not immediately fixing them and continuing development in multiple paths.
observation breakages often persist after branching.
of the builds that are triggered by commits at branch points are broken.
of those commits that are branched when the build was broken builds are not fixed in the immedi ately subsequent build.
these breakages are suspicious because developershavenotimmediatelyfixedthesebreakagesandhave continued development.
figure3shows that commits are branched from up to twelve times when the build was broken.
in the builds that were not immediately fixed several commits appear before the fix does.
figure4shows the maximum and median durations where the projects remained broken in the studied projects.
observation breakages persist for up to days and seven days on average before being fixed.
in one extreme case the orbeon orbeon forms project13had485consecutivebuildbreakages over 423daysbeforefinallythebreakagewasaddressed.uponfurther investigationofthisbreakage wefindthatthebuildisbrokendueto multiple test failures over time.
by analyzing the commit messages of the broken builds in this sequence we find only of these commits mention fixing the broken build of occurrence of each term build regression test .
however near the end of the longbuildbreakagesequence twocommitsbeforethebuildstarted passing again the developer has started skipping tests mentioning fornow don trunintegrationanddatabasetests .14thisshows that the build breakages were not the focus of the development activityuntiltheendofthesequencewhentheyturnedoffthetests that were causing the breakage.
wefindthat761projectshavebreakagesthatpersistformore thanoneday 547projectshavebreakagesthatpersistformorethan one week and projects have breakages that persist for more of branchespercentage of builds type of builds failed after branching failed figure developers branch out into multiple development paths branches even after build breakages.
percentage ofbroken builds at branch points are shown in white.
per centage of broken builds that continued to be broken afterbranching are shown in grey.
there are no broken builds with branches.
hour day week month y ear broken time in log scale projectmax median figure in some cases builds can remain broken for days.thegraphshowsthemaximumandmediandurationsthat each project s build remained broken ordered by themaximum duration.
than one month before getting fixed.
in eight projects consecutive build breakages persist for more than one year before getting fixed.
the overall median length of the failure sequences is five while project specific medians range between .
in83 ofbranchesfrombrokenbuilds thebreakagepersists.
these breakages persist for up to commits.
.
staleness of breakage motivation.
developers can passively ignore breakages for different reasons.
we identify the stalenessof a build breakage whether the project has encountered a given breakage in the past as one of the reasons for ignoring a build breakage.
a new breakage is different from a stale breakage because developers may have become desensitized to stale breakages.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france keheliya gallaba christian macho martin pinzger and shane mcintosh projectstale breakages percentage figure percentage of stale breakages in each project can range from to .
approach.
inthissection weinvestigatehowmanytimesdeveloperscomeacrossthesamebreakagerepeatedlyinthehistoryof a project with respect to the length of build breakage sequences.
thesestalebreakagescanoccureitherconsecutivelyorintermittently.
hence we extend the maven log analyzer developed by machoetal.
.weuseittocomparetwotraviscibuildjobs and check the similarity of the breakages.
to make the comparison efficient thisisdoneintwosteps.first thelogsofbuildjobsare parsed and checked if they are breaking due to the same reason e.g.
compilationfailure testexecutionfailure dependencyresolutionfailure .ifthereasonforfailuresareequalthenthedetails of the failure are also checked e.g.
if both breakages are due to compilation failure check if the compilation error is the same .
results.
figure5shows the percentage of stale build breakages in each project in descending order.
observation of the breakages out of that we analyze are stale breakages.
on the project level staleness of breakages ranges from to with a median of .
in the eirslett frontend maven plugin15project whereweobservethemaximumpercentageofstalebreakages itwasduetothesame dependency resolution failure recurring in builds.
two of every three build breakages that we analyze are stale.
.
signal to noise ratio motivation.
inpreviousanalyses wefindthatbuildbreakagesthat are ignored by developers and build successes that include ignored breakages can introduce noise in build outcome data.
ho wever the overall rate of noise in build outcome data is not yet clear.
such an overviewisusefulforresearcherswhousebuildoutcomedatain their work to better understand the degree to which noise may be impacting their analyses.
approach.
toquantifytheproportionofnoiseinbuildoutcome datacausedbypassivelyandactivelyignoredbuildbreakage we build failure sequence length threshold t c signal to noise ratioparameter overall branches only figure for every builds there is at least one build withanincorrectstatus.thesignal to noiseratioincreases when a higher build breakage sequence length is chosen.
adopt the signal to noise ratio snr as follows snr truebuildbreakages truebuildsuccesses falsebuildbreakages falsebuildsuccesses where truebuildbreakages i.e.
signal is the number of broken builds that are not ignored by developers truebuildsuccesses i.e.
signal is the number of passing builds without ignored breakages falsebuildbreakages i.e.
noise is the number of broken builds thatareignoredbydevelopers and falsebuildsuccesses i.e.
noise is the number of passing builds with ignored breakages.
tocompute falsebuildbreakages athreshold tcmustbeselected such that if the number of consecutive broken builds is above tc all buildsin such sequences areconsidered false build breakages.
instead of picking any particular tcvalue we plot an snr curve as the threshold tc is changed.
results.
figure6shows the snr curve for the subject systems.
observation a stcdecreasesfrom485to1 thesnrdecreases from .
to .
.
since falsebuildsuccesses is not impacted by tc themaximumsnrisobservedwhen falsebuildbreakages iszero i.e.
when tcissettothemaximumvalue .theminimumofsnr is observed when tcis one and therefore all broken builds that are not immediately fixed are considered false build breakages.
if false breakages are defined to be only in consecutive breakages withbranches in them the signal to noise ratio ranges from .
to .
.
oneinevery7to11builds isincorrectlylabelled.
thisnoisemayinfluenceanalysesbasedonbuildoutcome data.
heterogeneity in build breakage data thewayinwhichbuilds areconfiguredandtriggeredvaryfrom project to project.
this heterogeneity should be taken into con sideration when designing studies of build breakage.
below we demonstrate build heterogeneity using three criteria.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
noise and heterogeneity in historical build data ase september montpellier france of jobs in buildimpure breakages percentage figure percentage of impure build breakages increases with the number of jobs in each build.
.
matrix breakage purity motivation.
ifasoftwareprojectneedstobetestedinmultipleenvironmentswithdifferentruntimeversions ciservicesliketravis ciprovidetheabilitytodeclaretheseoptionsinamatrixof runtime environment andexclusions inclusions sections.abuildwillexecute jobs for each combination of included runtimes and environments.
if a build is broken only within a subset of its jobs the breakage may be platform or runtime specific.
these environmentspecificbuildbreakagesmayneedtobehandleddifferentlyfrom theenvironment agnosticbreakages.thus wewanttoknowthe extent to which real breakages are environment specific.
approach.
to study the environments that are affected by a build breakage we define matrix breakage purity as follows matrix breakage purity failedjobsinbuild alljobsinbuild amatrix breakage purity below one indicates that the jobs that were run in some environments passed.
we compute the matrix breakage purity for all builds in our dataset and count the number of builds with values below one.
we label all builds that have a matrix breakage purity below one as impure build breakages.
results.
figure7showshowthepercentageofimpurebuildbreakages varies with respect to the number of jobs per build.
observation atleast44 ofbrokenbuildscontainpassingjobs.
indeed environment specificbreakagesarealmostascommonas environment agnostic breakages.
giventhedifferenceinsemanticsbetweenpureandimpurebuild breakage researchers should take this into account when selecting build outcome data for research.
for example in build outcome prediction ifpredictionmodelsaretrainedusingdatathattreats environment specific and environment agnostic breakages identically themodelfitnesswilllikelysuffer.moreover theinsights thatarederivedfromthemodelswilllikelybemisleading sincethe two conflated phenomena will be modelled as one phenomenon.
observation builds with a greater number of jobs are more likely to suffer from impure build breakages.
figure7shows that the number of jobs in a build and the percentage of broken builds that havepassingjobsarehighlycorrelated.aspearmancorrelationtestyieldsa of0.
withp .
.whilepurebuildbreakage iscommoninbuildswithfewjobs whenthenumberofjobsper build exceeds three impure build breakage are more frequent than pure ones i.e.
impure breakage percentage .
environment specific breakage is commonplace.
once the numberofjobsexceedsthree impurebreakagesoccurmore frequently than pure breakages.
.
reason for breakage motivation.
builds can break for reasons that range from style violations to test failures.
different types of failures have different implications.
for example while a style violation might be correctedeasily fixingatestfailuremightrequiretimeandeffortto understand and address.
since subsequent analyses of build data should handle different types of breakages in different ways we want to know how types of build breakage vary in reality.
approach.
toanalyzethereasonsforbuildbreakageinourcorpus we extend the maven log analyzer mla .
our extension first parses the travis ci log file and extracts the sections of the log thatcorrespondtoexecutionsofthe mavenbuildtool.then each of thesemavenexecutions are fed to mla to automatically classify the status of each execution.
in addition to the breakage types that wereidentifiedintheoriginalwork ourextendedversionof mlaalsodetectsthebuildbreakagetypesthatwerereportedby vassallo et al.
and rausch et al.
as well as ten previously unreported breakage categories.
if mla classifies all mavenexecutions within a broken build assuccessful thebuildislabelledasa non maven breakage.nonmaven breakages are further classified as pre maven if a failing commandisdetectedinthetraviscilogbeforethe mavencommands and post maven otherwise.
intotal usingourextendedmla weclassify67 267brokenbuild jobs of projects that use mavenas the build tool.
results.
table1classifies the broken mavenbuilds by reason.
observation although a large proportion of build breakages are due to the execution of antfrom within maven most of these breakages belong to one project.
table1shows that there are instances of breakage where the external goal of executing an ant build from within a mavenbuild failed.
this accounts for .
of the goal failed breakages in our corpus.
however this is an exampleofananomalythatdissipateswhenexaminedmoreclosely.
indeed we find that all of these breakages occur in only two of the studiedprojects theoverwhelmingmajority ofwhichoccur in thejruby jruby17project.
according to developer discussions antis used inside the mavenbuild ofjruby jruby for executing tests.18however this complex build setup which requires 250mb of dependencies causes build to fail intermittently.
the developers hopethatthebreakageswillnotoccuroncethebuildiscompletely migrated to maven.
observation in our corpus most breakage is due to commands otherthanmainbuildtool maven.weobserve41 jobsare 16more details about reasons for breakage are available online software rebels bbchch wiki build breakages in maven authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france keheliya gallaba christian macho martin pinzger and shane mcintosh table distribution of build breakages in mavenprojects basedonthecategoriesproposedbyvassalloetal.
.and rausch et al.
.
global percentage of each category isshown in brackets.
category subcategory projects dependency resolution .
test execution failed unit .
integration .
total .
compilation failed production .
test .
total .
goal failed pre processing .
static analysis .
dynamic analysis .
validation .
packaging .
documentation .
release preparation .
deployment remote .
deployment local .
support .
ant inside maven .
run system java program .
run jetty server .
manage ruby gems .
polyglot for maven .
total .
broken outside maven no log available .
failed before maven .
failed after maven .
travis aborted .
travis cancelled .
total .
new build breakage categories that did not appear in prior work.
broken due to reasons other than mavenexecutions failing.
this can be either due to a command that was executed by travis ci outside of maven returning an error the user canceling the build or travis ci runtime aborting the build because it exceeded the allocated time.
observation onlyasmallamountofbreakagecanbeautomatically fixedby focusing ontool specific breakage.
for example build jobs are broken because dependency resolution has failed.
this suggests that recent approaches that automatically fix dependency relatedbuildbreakage willonlyscratchthesurfaceofthebuildbreakageproblem.moreover compilationandtest execution failures only account for another .
of the breakage inourcorpus.futureautomaticbreakagerecoveryeffortsshould look beyond tool specific breakages to the ci scripts themselves in order to yield the most benefit for development teams.
ofthebrokenbuildsinourcorpusfailedduetoproblems outside of the execution of the main build tool.
since toolspecificbreakageisrare futureautomaticbreakagerecovery techniques should tackle issues in the ci scripts themselves.
.
type of contributor motivation.
both core and peripheral contributors trigger builds.
sincecorecontributorslikelyhaveadeeperunderstandingofthe project than peripheral contributors builds that are triggered bycorecontributorsmighthavebreakageratesandteamresponses broken passedcore contributor peripheral contributor figure8 percentageofbrokenandpassingbuildsclassified bycontributortype.horizontalblacklinesshowthemedian values.
that differ from those of peripheral contributors.
we set out to investigatethedifferencesofbuildoutcome inthesetwocategories of contributors.
approach.
for analyzing this dimension we use the two main outcomesof eachbuild passed orfailed andwhetherthe builds were triggered by a commit that was authored by a core team member.weusethecorememberindicatorfromthetravistorrent dataset 19which is set for contributors who have committed at least once within the three months prior to this commit gh by core team member .
then we use the broken time and thelengthofbrokenbuildsequencestoinvestigatetherelationship between the contributor type and build breakage.
results.
figure8showshowthepercentageofbuildoutcomesare distributed across projects classified by contributor type.
observation buildstriggeredbycoreteammembersarebreak significantly more often than those of peripheral contributors.
a wilcoxon signed rank test indicates that breakage rates in core contributors are higher than those of peripheral contributors p .
however the effect size is negligible cliff s .
.
duetohavingmoreexperience coreteammembersinthedevelopmentteamsareassignedtocomplextasks whichmayexplain why breakage ratestend to be alittle higher.
the wilcoxontest is inconclusivewhencomparingratesofpassingbuildsamongcore and peripheral contributors.
figure9shows how long build breakages persist classified by contributor type.
figures 9aand9bshow the length of build breakage sequences in terms of commits and time respectively.
observation breakages that are caused by core contributorstendtobefixedsoonerthanthoseofperipheralcontributors.
a wilcoxon signed rank test indicates that breakages caused by core contributors tend to persist for significantly less time than those of peripheralcontributors p .
however theeffectsizeis negligible cliff s .
.
another wilcoxon signed rank test indicatesthatbreakagesofcorecontributorspersistforfewerconsec utivebuildsthanthoseofperipheralcontributors p .
however the effect size is also negligible cliff s .
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
noise and heterogeneity in historical build data ase september montpellier france2 broken sequence lengthperipheral contributor core contributor a chains of consecutive breakages caused by peripheral contributors tend to be longer.
broken time in hours peripheral contributor core contributor b build breakages caused by peripheral contributors take more time to repair.
figure9 buildbreakagescausedbyperipheralcontributors remain broken significantly longer than those of core contributors.
horizontal black lines show the median values.
thelongertimetakenbyperipheralcontributorsmightbedue to multiple attempts of trial and error before fixing a breakage while core members might be able to identify the root cause of the breakage sooner.
therefore it may be worthwhile for the researchers working on automatic build breakage repair to focus on build breakages that are caused by peripheral contributors.
brokenbuildsthatarecausedbycorecontributorstendtobe fixed sooner than those of peripheral contributors.
implications wenowpresentthebroaderimplicationsofourobservationsfor researchers and tool builders.
.
research community buildoutcomenoiseshouldbefilteredoutbeforesubsequent analyses.
passingbuildsmightcontainbreakagesthatareignored.
long sequences of repeated breakages might be ignored by thedevelopers as false breakages.
if the noise due to false successes andfalsebreakagesisnotfilteredout theresultsfrom prediction models may lead to spurious or incorrect conclusions.
heterogeneityofbuildsshouldbeconsideredwhentraining buildoutcome predictionmodels.
somebreakagesarelimited tospecificenvironmentswhileothersarenot.thereasonforbreakages vary from trivial issues like style violations to complex test failures.
breakages are often not caused by development mistakes but by resource limitations in the ci environment.
indeed build outcomeincludesmanycomplexcategoriesthatcannotbeaccuratelyrepresentedinthepredictionmodelsusingonlya broken or clean label.
.
tool builders automaticbreakagerecoveryshouldlookbeyondtool specific insight.whilerecentlyproposedtoolscanautomaticallyrecoverfrom tool specific build breakage we find that this category only accounts for a small proportion of ci build breakage in ourcorpus.
future efforts in breakage recovery should consider cispecific scripts for example detecting those scripts that are at risk of exceeding the allocated time prior to execution.
richerinformationshouldbeincludedinbuildoutcomereportsanddashboards.
currently build tools and ci services provide users with dashboards that show passing builds in green and broken builds in red.
however we found hidden breakages among passing builds and non distracting breakages among broken builds.
moreover heterogeneity of breakages introduce further complexities.buildoutcomereportingtoolsanddashboardsshouldconsiderprovidingmorerichinformationabouthidden non distracting and stale breakages as well as breakage purity and type.
threats to validity constructvalidity.
threats to construct validity refer to the relationshipbetweentheoryandobservation.itispossiblethatthere are build failure categories that our scripts are unable to detect.
by implementing the categories that were reported in prior work andthenmanuallycheckingasubsetoflogsalongwiththeir detectedfailurecategories weensuremostofthe mavenplug ins and their failure categories are covered by our scripts.
there are likely to be other factors that introduce noise and variabilityinbuildoutcomes.asaninitialstudy wefocusonthe aspectsthatwethinkdemonstratenoiseandheterogeneityofbuilds in this work.
our list of aspects is not intended to be exhaustive.
internalvalidity.
threatstointernalvalidityarerelatedtofactors internal to our study that can influence our conclusions.
in the analysisofpassivelyignoredbreakages weassociatecontinuous breakageofabuildwithdevelopersignoringthebreakage.however developersmaybeunsuccessfullyattemptingtofixthesebreakages during the breakage chain.
we do not suspect that this is the most frequentexplanationbecausewefindseveralcaseswheretheinitial breakage has several branches implying that several developersinherited the breakage .
although it can be assumed that thesebranches are created to fix the build it is unlikely that twelve branchesarecreatedonlyforbugfixing.wefurtherinvestigatethestalenessofbreakages observingthatthesamebuildbreakagesare often repeated in these long chains.
externalvalidity.
threatstoexternalvalidityareconcernedwith the generalizability of our findings.
we only consider open source projects that use the travis ci service and are hosted on github.
however because github is one of the most popular hosting platforms for open source software projects and travis ci is the most widelyadoptedciserviceamongopensourceprojects ourfindings are applicable to a large number of open source projects.
similar to that we only consider projects that use mavenfor analyzing reasons for build breakage.
however mavenis one of the most popularbuildtoolsforjavaprojects andthereforeourfindings arewidelyapplicable.nonetheless replicationstudiesusingdata from other hosting platforms other ci services and other build tools may provide additional insight.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france keheliya gallaba christian macho martin pinzger and shane mcintosh related work inthissection we describe therelatedworkwithrespecttobuild breakage and continuous integration.
.
build breakage build breakage has attracted the attention of software engineering researchers at many occasions during the past decade.
the rate at which builds are broken has been explored in the past.
kerzazi et al.
have conducted an empirical study in a large software company analyzing builds that were executed overaperiodofsixmonthstomeasuretheimpactofbuildbreakages observing a build breakage rate of .
which generates an estimated cost of .
to .
person hours.
seo et al.
studied nine months of build data at google finding that .
and37.
ofjavaandc buildswerebroken.tufanoetal.
found only of the change history of subject systems is successfully compilable and that broken snapshots occur in of thestudiedprojects.hassanetal.
showedthatatleast57 of the broken builds from the top java projects on github can be automatically resolved.
to better understand and predict build breakage past studies have fit prediction models.
hassan and zhang have demonstratedthatdecisiontreesbasedonprojectattributescanbeused topredictthecertificationresultofabuild.wolfetal.
useda predictive model that leverages measures of developer communication networks to predict build breakage.
similarly kwan et al.
usedmeasuresofsocio technicalcongruence i.e.
theagreementof thecoordinationneedsestablishedbythetechnicaldomainwith theactualcoordinationactivitiescarriedoutbyprojectmembers to predict build outcome in a globally distributed software team.
in recent work luo et al.
have used the travistorrent dataset to predict the result of a build based on features.
they found that the number of commits in a build is the most important factor that can impact the build result.
dimitropoulos et al.
use the samedatasettostudythefactorsthathavethelargestimpacton build outcome based on k means clustering and logistic regression.
for communicating the current status of the build downs et al.
proposed theuseof ambientawarenesstechnologies.they have observed by providing a separate easily perceived commu nication channel distinct from standard team workflow for com municating build status information the total number of builds increasedsubstantially andthedurationofbrokenbuildsdecreased.
tohelpdeveloperstodebugbuildbreakage vassalloetal.
pr opose a summarization technique to reduce the volume of build logs.
formitigating the impactof buildbreakage in thecontext of component based software development van der storm have shown how backtracking can be used to ensure that a working version is always available even in the face of failure.
broadlyspeaking the priorworkhastreated buildbreakageas aboolean passorfaillabel.inthispaper weadvocateforamore nuanced interpretation of build breakage that recognizes the noise in build outcome data and heterogeneity of build executions.
.
continuous integration recent work has studied adoption of ci in the open source community.
beller et al.
have released a dataset based on travis ciand github that provides easy access to hundreds of thousandsof ci builds from more than open source projects.
efforts similartothishavemadeseveralstudiesofcibuildspossible.by analyzing open source projects on github and surveying developers hilton et al.
report on which ci systems developersuse how developers use ci and reasons for using ci or not .
theadoptionofcihasanimpactonotherprojectcharacteristics.
hilton et al.
found that when using ci developers have to choose between speed and certainty better access and information security and more configuration options and greater ease of use.
vasilescu et al.
observe that ci adoption is often accompanied by a boost in the productivity of project teams.
recent community interest in ci has yielded a resurgence of build breakage research.
for example vasilescu et al.
studied 223githubprojectsandfoundthatthecibuildsstartedbypull requestsaremorelikelytofailthanthosestartedbydirectcommits.belleretal.
havestudiedtestingpracticesinciof javaandruby projects observing that testing is the most frequently occurring typeofbuildbreakage.rauschetal.
identifiedthemostcommonerrorcategoriesincibuildsbasedon14opensourcejavaappli cations.zampettietal.
havestudiedtheusageofstaticanalysis tools in open source java projects that are hosted on github and using travis ci.
vassallo et al.
compare the ci processes andoccurrencesofbuildbreakagesin349opensourcejavaprojects and projects from a financial organization.
labuschagne et al.
havealsoobservedthattherearelongstretchesofbroken buildsduetoprojectsnotconfiguringtraviscicorrectlyornot examiningthetraviscioutput.toaccountforthis theyremoved the of the projects that had the most and the fewest failures.
while prior work helps to understand build breakage and ci in practice we focus on the trustworthiness of off the shelf historical ci build data.
our observations yield insights that can guide futurestudiesofandtooldevelopmentforbuildbreakageinthecicontext see section .
conclusion automated builds are commonly used in software development to verifyfunctionalityanddetectdefectsearlyinsoftwareprojects.an off the shelfusageofbuildoutcomedataisimplicitlysusceptibletoharmfulassumptionsaboutbuildbreakage.byempiricallystudyingbuildjobsof1 276opensourceprojects weinvestigatewhethertwo assumptionshold.first thatbuildresultsarenotnoisy however we find in every eleven builds there is at least one build with a misleading or incorrect outcome on average.
second that builds arehomogeneous however wefindbreakagesvarywithrespect to the number of impacted jobs and the causes of breakage.
researcherswhomakeuseofbuildoutcomedatashouldmake sure that noise is filtered out and heterogeneity is accounted forbefore subsequent analyses are conducted.
build reporting tools anddashboardsshouldalsoconsiderprovidingaricherinterface to better represent these characteristics of build outcome data.
infuturework weplantostudyhowmuchofanimpactnoise andheterogeneitycanhaveoncommonanalysesofhistoricalbuilddata.wealsoplantoinvestigatewhetherbreakagetypevarieswith respect to contributor type and other commit factors.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
noise and heterogeneity in historical build data ase september montpellier france