sentimoji an emoji powered learning approach for sentiment analysis in software engineering zhenpeng chen key lab of high confidence software technology moe peking university beijing china czp pku.edu.cnyanbin cao key lab of high confidence software technology moe peking university beijing china caoyanbin pku.edu.cnxuan lu key lab of high confidence software technology moe peking university beijing china luxuan pku.edu.cn qiaozhu mei school of information university of michigan ann arbor usa qmei umich.eduxuanzhe liu key lab of high confidence software technology moe peking university beijing china xzl pku.edu.cn abstract sentiment analysis has various application scenarios in software engineering se such as detecting developers emotions in commit messages and identifying their opinions on q a forums.
however commonly used out of the box sentiment analysis tools cannot obtain reliable results on se tasks and the misunderstanding of technical jargon is demonstrated to be the main reason.
then researchers have to utilize labeled se related texts to customize sentiment analysis for se tasks via a variety of algorithms.
however the scarce labeled data can cover only very limited expressions and thus cannot guarantee the analysis quality.
to address such a problem we turn to the easily available emoji usage data for help.
more specifically we employ emotional emojis as noisy labels of sentiments and propose a representation learning approach that uses both tweets and github posts containing emojis to learn sentiment aware representations for se related texts.
these emoji labeled posts can not only supply the technical jargon but also incorporate more general sentiment patterns shared across domains.
they as well as labeled data are used to learn the final sentiment classifier.
compared to the existing sentiment analysis methods used in se the proposed approach can achieve significant improvement on representative benchmark datasets.
by further contrast experiments we find that the tweets make a key contribution to the power of our approach.
this finding informs future research not to unilaterally pursue the domain specific resource but try to transform knowledge from the open domain through ubiquitous signals such as emojis.
ccs concepts information systems sentiment analysis .
corresponding author xuanzhe liu xzl pku.edu.cn .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn .
.
.
.
emoji sentiment analysis software engineering acm reference format zhenpeng chen yanbin cao xuan lu qiaozhu mei and xuanzhe liu.
.
sentimoji an emoji powered learning approach for sentiment analysis in software engineering.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
introduction software development is a highly collaborative activity that is susceptible to the affective states of developers .
on the one hand negative sentiments can make developers underperform in the software projects that they contribute to and lead to longer issue fixing time .
therefore project managers need to stay aware of the affective states of developers in order to detect negative sentiments and take timely necessary actions to ensure high productivity of developers .
on the other hand understanding the sentiments in developers discussions can help software practitioners be aware of collective opinions about specific se topics e.g.
adding a new feature in software or artifacts e.g.
software libraries or apis which can then help their further actions about these topics and their usage and improvement of these artifacts.
sentiment analysis has been a frequently used natural language processing nlp technique in se.
it aims to identify the affective states and subjective opinions in texts.
many out of the box sentiment analysis tools e.g.
sentistrength not designed for se related texts have been applied to se tasks but recent work has indicated that they cannot produce reliable results on se tasks .
furthermore islam and zibran applied sentistrength to an serelated dataset and found that misunderstanding of domain specific meanings of words namely technical jargon in the rest of this paper accounts for the most misclassifications.
such a finding inspires a series of research efforts in recent years to generate se specific datasets and develop customized sentiment analysis methods based on them .
various machine learning or deep learningarxiv .02202v1 jul 2019esec fse august tallinn estonia zhenpeng chen yanbin cao xuan lu qiaozhu mei and xuanzhe liu techniques have been applied but the performance still falls short of producing adequate results in practice for some se tasks .
one possible reason behind the poor performance could be the customized methods that are trained based on scarce se related labeled data only thousands of samples and inevitably lack the knowledge of other expressions that are not contained in them.
given the large volume of english vocabulary these missing expressions are indeed non trivial.
to tackle this problem a straightforward solution is to annotate abundant se related texts with sentiment labels.
however manual annotation on a large scale is quite difficult time consuming and error prone .
instead recent work in nlp attempted to employ emotional emojis as noisy labels of sentiments on social media .
as emojis become an emerging ubiquitous language used worldwide emoji labeled texts are easily available which can help tackle the scarcity of manually labeled texts and thus benefit the sentiment analysis tasks .
inspired by this work we aim to explore the emoji usage data into sentiment analysis in se.
here then comes a question.
where should we extract such data?
in fact emojis not only pervasively exist in social media but are also widely adopted in the communication of developers to express sentiment .
for example in the post thanks for writing this great plugin 1on github the emoji can be considered a positive sentiment signal.
in order to ensure the representativeness of emoji usage data we employ posts containing emojis from both twitter a typical social media platform and github a typical software development platform .
here the core insight is posts from github can provide more technical information beyond the limited labeled data while posts from twitter can help learn more general sentimental patterns that are shared in both technical and non technical communication .
we propose sentimoji an emoji powered learning approach for sentiment analysis in se.
through sentimoji vector representations of texts are first derived based on modeling how emojis are used alongside words on twitter and github.
these sentiment aware representations are then used to predict the sentiment polarities on the labeled data.
to evaluate the performance of sentimoji we answer two research questions rq1 how does sentimoji perform compared to the existing sentiment analysis methods in se?
by rigorous contrast experiments we find that sentimoji can significantly outperform existing sentiment analysis methods in se on all the selected benchmark datasets.
this finding indicates that the incorporation of emoji usage data is a promising solution to the se customized sentiment analysis.
rq2 which training corpora contribute more to the power of sentimoji?
we find that github posts do not make a key contribution.
the combination of large scale tweets and a small amount of labeled data can already achieve satisfactory performance.
such results highlight the significance of the general sentimental patterns learned from tweets.
our finding informs future research not to focus only on the domain specific resource.
instead they can also pay attention to the general sentimental patterns that can be easily extracted from the open domain.
the main contributions of this paper are as follows retrieved in november .
we propose an emoji powered learning approach for se customized sentiment analysis which utilizes tweets to capture the general sentimental expressions and github posts as well as manually labeled data to incorporate the technical jargon.
we demonstrate the effectiveness of sentimoji for se tasks using four representative benchmark datasets.
sentimoji can significantly improve the state of the art results on all these datasets.
we explore the underlying reasons behind the performance of sentimoji by rigorous contrast experiments and provide future research some insightful implications.
the rest of this paper is organized as follows.
section summarizes the literature related to this study.
section presents the workflow of sentimoji.
section compares sentimoji with baseline methods on representative benchmark datasets and answers the two research questions based on the achieved results.
section summarizes the lessons learned in this study and the implications.
section discusses the threats that could affect the validity of this study followed by concluding remarks in section .
related work we start with the literature related to this study.
our research is particularly inspired by two streams of literature sentiment analysis in se and emojis in sentiment analysis.
.
sentiment analysis in se in recent years sentiment analysis has been widely applied in se for enhancing software development maintenance and evolution .
most of these studies used the out of the box sentiment analysis tools e.g.
sentistrength nltk and stanford nlp trained on non technical texts.
among these tools sentistrength is considered to be the most widely adopted one in se studies .
however some researchers noticed unreliable results when directly employing such tools for se tasks .
jongeling et al.
observed the disagreement among these existing tools on the datasets in se and found that the results of several se studies involving these sentiment analysis tools cannot be confirmed when a different tool is used.
to investigate the challenges in sentiment analysis in se islam and zibran applied the most popular sentistrength to some labeled issue comments extracted from jira issue tracking system and conducted an indepth qualitative study to uncover twelve difficulties in identifying the sentiments of se related texts by analyzing the misclassified samples.
among the identified difficulties lacking domain specific knowledge is demonstrated to be the most dominant accounting for about of the classification errors.
since then how to effectively leverage se related texts to introduce technical jargon becomes the main direction of the sentiment analysis in se .
against such a background many se customized sentiment analysis tools and methods are proposed including sentistrength se senticr senti4sd etc.
we take them along with the most popular sentistrength as baseline methods in this study and introduce them detailedly in section .
.sentimoji an emoji powered learning approach for sentiment analysis in software engineering esec fse august tallinn estonia .
emojis in sentiment analysis traditional sentiment analysis in nlp is mainly performed in unsupervised orsupervised ways.
unsupervised tools e.g.
sentistrength simply make use of lists of words annotated with sentiment polarity to determine the overall sentiment of a given text.
however fixed word lists cannot cope with the dynamic nature of the natural language .
then researchers started to use labeled text to train sentiment classifiers for different purposes in a supervised way.
however it is time consuming to manually annotate text on a large scale thus resulting in a scarcity of labeled text.
to tackle this problem many researchers attempted to perform sentiment analysis in a distantly supervised way.
for example they used binarized emoticons and specific hashtags as a proxy for the emotional contents of a text.
recent studies extended the distant supervison to emojis a more diverse set of noisy labels .
as emojis are becoming increasingly popular and have the ability to express emotions they are considered benign noisy labels of sentiments in current sentiment analysis .
the sentiment information contained in the emoji usage data can supplement the limited manually labeled data.
recently to address the challenge of sentiment analysis in se researchers also started to analyze emoticons and emojis in software development platforms so as to find some potential solutions.
claes et al.
investigated the use of emoticons in open source software development.
lu et al.
analyzed the emoji usage on github and found that emojis are often used to express sentiment on this platform.
furthermore imtiaz et al.
directly used emojis as the indicators of developers sentiments on github.
calefato et al.
and ding et al.
took emoticons into account in their proposed sentiment analysis techniques built on se related texts.
all of them demonstrated the feasibility of leveraging these emotional cues to benefit sentiment analysis in se.
following this line of research this study leverages the large scale emoji usage from both technical and open domains to address sentiment analysis in se.
methodology as we mentioned before sentiment analysis is a traditional nlp task.
in this section we give a brief description to the fundamental concepts of related techniques and then illustrate the workflow of sentimoji detailedly.
.
preliminaries we first present some background knowledge on the nlp techniques that will be used in this paper including word embedding long short term memory lstm network and fine tuning.
.
.
word embedding to eliminate the discrete nature of words word embedding is employed by nlp tasks to encode every single word into a continuous vector space as a high dimensional vector.
it is usually trained by learning from large scale corpus via glove cbow or skip gram algorithm .
in this paper the skip gram algorithm is employed for word embedding.
this algorithm scans each example in the training corpus and uses each word it has scanned as an input to predict words within a certain range before and after this word.
by such a prediction task words that commonly occur in asimilar context are embedded closely in the vector space which captures the semantic relationship between words.
.
.
lstm recurrent neural network rnn is a kind of neural network specialized for processing sequential data such as texts.
it connects computational units of the network in a directed cycle such that at each time step a unit in rnn takes both the current input and the hidden state of the same unit from the previous time step as the input.
due to the recurrent nature of rnn it can capture the sequential information which is important to nlp tasks.
however due to the well known gradient vanishing problem vanilla rnns are difficult to train to capture long term dependency for sequential texts.
lstm addresses this problem by introducing a gating mechanism to determine when and how the states of hidden layers can be updated.
each lstm unit contains a memory cell an input gate a forget gate and an output gate.
the input gate controls the input activations into the memory cell and the output gate controls the output flow of cell activations into the rest of the network.
the memory cells in lstm store the sequential states of the network and each memory cell has a self loop whose weight is controlled by the forget gate.
the lstm structure ensures that the gradient of the long term dependencies cannot vanish.
.
.
fine tuning labeled data are often limited for nlp tasks especially new ones.
for such tasks training a neural network from scratch with limited data may result in over fitting.
one approach to getting around this problem is to take a network model which has been trained for a given task to perform the target task.
this process is commonly called fine tuning .
assuming the target task is similar to the original task fine tuning enables us to take advantages of the prior efforts on feature extraction i.e.
the pre trained parameters of the network .
the first step of fine tuning is to replace the last fullyconnected layer of the original network with a new one that can output a probability vector whose dimension is the desired number of classes in the target task.
then we can use the labeled data for the target task to fine tune parameters of the original network and make the network be suitable for the new task.
.
the sentimoji approach sentimoji is an se customized sentiment classifier trained based on a small amount of labeled se related data as well as large scale emojilabeled data from both twitter and github.
as emojis are widely used to express sentiment we learn sentiment aware representations of texts by using emoji prediction as an instrument.
more specifically we use emojis as noisy labels of sentiments and learn vector representations of sentences by predicting which emojis are used in a sentence.
sentences that tend to occur with the same emoji are represented similarly which captures the sentiment relationship between sentences and can thus benefit the downstream sentiment classification.
since such a representation model trained on large scale tweets has been off the shelf i.e.
deepmoji model .
we directly build sentimoji upon deepmoji.
it takes a two stage approach fine tune deepmoji using emoji labeled texts from github to incorporate technical knowledge.
the fine tuned model is still a representation model based on the emoji prediction taskesec fse august tallinn estonia zhenpeng chen yanbin cao xuan lu qiaozhu mei and xuanzhe liu figure the architecture of deepmoji.
and we call it deepmoji se use deepmoji se to obtain vector representations of the sentiment labeled texts and then use these vectors as features to train the sentiment classifier.
next we describe the existing deepmoji model and the two stage learning process in details.
.
.
deepmoji model felbo et al.
learned deepmoji model through predicting emojis used in tweets.
to this end they collected .
billion tweets denoted as t selected the top emojis in this corpus and excluded the tweets that do not contain any of these emojis.
for each remaining tweet they created separate samples for each unique emoji in it.
for example good idea!
can be separated into two samples i.e.
good idea!
and good idea!
.
finally the generated .
billion samples denoted as et were used to train the representation model.
the model architecture is illustrated in figure .
first for a given sample words in it are inputted into the word embedding layer pretrained on t. in this step each word can be represented as a unique vector.
these word vectors are then processed by two bi directional lstm layers and one attention layer.
through these steps the sample can be represented as one sentence vector instead of several word vectors.
finally the softmax layer treats the sentence vector as the input and outputs the probabilities that this sample contains each emoji.
taking the real emoji contained in each sample in etas ground truth the model learns parameters by minimizing the output error of the softmax layer.
the details of the model architecture are described below.
word embedding layer.
the word embedding layer is pre trained based on t. through this layer each sample in etcan be denoted as x e where x as the word vector sequences of the plain text removed emoji dias the vector representation of the i th word and eas the emoji contained in the sample.bi directional lstm layer.
given the input x at step t lstm computes unit states of the network as follows i t uidt wih t bi f t ufdt wfh t bf o t uodt woh t bo c t ft c t i t tanh ucdt wch t bc h t o t tanh c t where i t f t o t c t and h t denote the states of the input gate forget gate output gate memory cell and hidden layer at stept.w u b and denote the recurrent weights input weights biases and element wise product respectively.
in order to take both the past and the future words of the current word at each time step into consideration we employ bi directional lstms instead of the traditional lstm.
each bi directional lstm network contains two sub networks i.e.
a forward network and a backward network to encode the sequential contexts of each word in the two directions respectively.
we thus compute an encoded vector hiof each word vector diby concatenating the latent vectors from both directions hi hi hi where hiand hidenote the forward and backward states of di respectively.
in order to enable the unimpeded information flow in the whole model the outputs of the two lstm layers and the word embedding layer are concatenated by the skip connection algorithm then as input into the attention layer.
specifically each word of the input sample is further represented as ci ci di hi1 hi2 where di hi1 and hi2represent the encoded vectors of the i th word extracted from the word embedding layer and the first and second bi directional lstm layers.
attention layer.
since not all words contribute equally to the overall sentiment polarity of the sample the model employs the attention mechanism to determine the importance of each word.
the attention score i.e.
the importance of the i th word is computed as i exp w ci l j 1exp w cj where wis the weight matrix of the attention layer.
then the sample can be represented as the weighted sum of all words in it v l i 1 ici.
softmax layer.
the final representation vis inputted into the softmax layer to output a dimension probability vector each element of which denotes the probability that this sample contains one specific emoji.
deepmoji learns parameters by minimizing the cross entropy between the output probability vectors and the one hot representations of the emoji actually contained in each sample.
through suchsentimoji an emoji powered learning approach for sentiment analysis in software engineering esec fse august tallinn estonia a learning phase the plain texts occur with the same emoji can be represented similarly.
.
.
stage fine tuning deepmoji using github data as deepmoji is trained on tweets we need some developergenerated emoji labeled texts to customize it into an se specific setting.
to this end we use the conversation data i.e.
issues issue comments pull requests and pull request comments in the githubemoji dataset collected by lu et al.
which cover more than one hundred million posts on github to fine tune the parameters of deepmoji.
we first conduct the following procedures to pre process the github data.
we tokenize all the texts into words and convert all the words into lowercase.
then we replace urls