combining multi objective search and constraint solving for configuring large software product lines christopher henard mike papadakis mark harmany and yves le traon interdisciplinary centre for security reliability and trust university of luxembourg luxembourg yuniversity college london gower street london christopher.henard uni.lu michail.papadakis uni.lu mark.harman ucl.ac.uk and yves.letraon uni.lu abstract software product line spl feature selection involves the optimization of multiple objectives in a large and highly constrained search space.
we introduce satibea that augments multi objective search based optimization with constraint solving to address this problem evaluating it on five large real world spls ranging from to features with respect to three different solution quality indicators and two diversity metrics.
the results indicate that satibea statistically significantly outperforms the current state of the art p for all five spls on all three quality indicators and with maximal effect size a12 .
we also present results that demonstrate the importance of combining constraint solving with searchbased optimization and the significant improvement satibea produces over pure constraint solving.
finally we demonstrate the scalability of satibea within less than half an hour it finds thousands of constraint satisfying optimized software products even for the largest spl considered in the literature to date.
i. i ntroduction a software product line spl is a collection of related software products all of which share some core functionality yet each of which differs in some specific features.
software engineers use spls to increase software reusability and to rationalise software maintenance and evolution effort across a range of related products .
however without automated support this feature selection process is likely to be highly suboptimal it requires the simultaneous satisfaction of multiple objectives such as matching user preferences minimizing product cost and satisfying technical feasibility constraints in feature spaces defined by many thousands of features.
in such large constrained spaces human intuition is insufficient to find optimal or near optimal software products.
in order to reduce configuration effort and optimize the resulting product choices automated techniques for feature selection have been introduced.
a recent survey of spl product optimization can be found elsewhere .
the problem of feature selection was first addressed in by white et al.
who introduced an approach called filtered cartesian flattening to select features from a feature model but this was only able to cater for single optimization objectives.
in guo et al.
introduced a genetic algorithm for the same problem demonstrating that it outperformed filtered cartesian flattening on synthetically generated spls but did not present results for any real world spls.these previous approaches were all single objective approaches.
therefore they could not construct software products from spls for which multiple perhaps conflicting and competing objectives needed to be optimized.
sadly such single objective solutions are unsuited to most real world spl feature selection problems which are multi objective .
however in wu et al.
introduced a multi objective optimization formulation that was evaluated on a mail server system case study.
in sayyad et al.
provided a detailed investigation of the multi objective spl feature selection problem in four related papers that collectively established the current state of the art.
their first paper demonstrated that search based optimization can be used to find products that optimize multiple objectives.
they evaluated on real world spls replicating their results and reporting on parameter tuning effects .
finally sayyad et al.
introduced additional heuristics to improve the scalability of their approach which is an important consideration for spl optimization since spls can be very large.
none of these previous approaches to spl feature selection have included any explicit technique to handle constraints leaving open the question of how best to optimize spl feature selection in the presence of constraints.
this is an important open question because most real world spls are highly constrained and solutions that fail to respect such constraints are likely to be rejected by both developers and their users.
indeed many constraint violating solutions will prove to be simply unbuildable constraints often determine whether or not a product can be feasibly constructed.
furthermore this paper shows that concentrating on constraint respecting solutions also allows the search to find software products that significantly outperform the state of the art.
we introduce satibea a search based spl feature selection algorithm augmented by constraint solving and two smart search operators.
satibea guides the automated search to constraint respecting solutions that maximise multiple objectives in reasonable time.
our empirical study which include the largest yet reported spl demonstrates that satibea is a scalable and significant improvement over the current stateof the art.the primary contributions of the paper can be summarised as follows we introduce satibea a new algorithm for spl selection and evaluate it on real world spls ranging from to features with respect to quality indicators and two diversity measures.
we perform independent executions to support inferential statistical testing for significance and assessment of effect size.
we show that satibea significantly outperforms the current state of the art with maximal effect size according to all solution quality indicators and for all spls.
we demonstrate the importance of augmenting search with constraint solving in such constrained spaces as spls we present results that show that our simple constraint solving approach alone can also significantly outperform the state of the art with maximal effect size with respect to all solution quality indicators in spls including the largest one linux.
we demonstrate the added value of our combined approach with smart operators over constraint solving alone.
over the comparisons spls each with quality indicators we find that satibea significantly outperforms constraint solving alone in and with maximal effect size in .
we demonstrate satibea s scalability.
scalability is a known and important issue for both spls and search based software engineering .
the remainder of the paper is organized as follows sections ii and iii introduce and motivate the concepts and the propositions underlying the present paper.
section iv details the proposed approaches.
the studied research questions and the experimental setup are detailed in sections v and vi.
experimental results are presented and discussed in sections vii and viii.
finally section ix examines work related to the present one and section x concludes the paper.
ii.
b ackground this section introduces background concepts on spls and multi objective optimization that are used in the paper.
a. software product line engineering software engineers build many variations of their systems in order to match the specific needs of particular clients .
software product line engineering sple is a software development paradigm designed to handle this situation.
it involves the creation and the management of an spl which encompasses the different variants called products.
sple appeared in with the development of feature oriented domain analysis .
the benefits of sple include the reduction of the maintenance effort lower development costs and a faster time to market .
the variabilities and commonalities among software products are expressed in terms of features .
each feature is an abstraction of a functionality or property of the software products.
feature model feature models fms are the standard and compact representation of the possible products of an spl .
an fm defines the valid feature combinations by expressing constraints between them.
as an example consider the fm depicted in figure .
it contains features.
some features are mandatory included in every product e.g.
the draw feature.
other features are constrained to co occur.
for instance the color feature requires the color palette .
an fm can be translated to a boolean formula in conjunctive normal form cnf .
such formulas are a conjunction ofnclausesc1 cn where a clause is a disjunction of m literals.
a clause is a constraint between some features of the fm and a literal is a feature that is selected fj or not fj fm vn i w j2 lj wherelj fjorfj.
for instance the fm of figure contains m 9features and encompasses n constraints represented as follows in cnf f1 f2 f1 f1 f2 f3 f1 f1 f3 f4 f1 f5 f1 f1 f5 f6 f3 f7 f3 f3 f6 f7 f8 f5 f9 f5 f5 f8 f9 f8 f9 f7 f4 f4 f8 f9 f4 .
the corresponding cnf formula is a conjunction of all the constraints fm f1 f2 f1 f1 f2 f3 f1 f1 f3 f4 f1 f5 f1 f1 f5 f6 f3 f7 f3 f3 f6 f7 f8 f5 f9 f5 f5 f8 f9 f8 f9 f7 f4 f4 f8 f9 f4 .
product configuration a product configuration ccorresponds to the features that are present or not in a given product c fl1 lmgwherelj fjorfj.
for instance with respect to figure c1 ff1 f2 f3 f4 f5 f6 f7 f8 f9gis a configuration representing the software product proposing all the features except rectangular selection and black and white rendering.
this configuration is valid since it satisfies the constraints of the fm described in the previous subsection.
by contrast c2 ff1 f2 f3 f4 f5 f6 f7 f8 f9gviolates the constraint f1 f2 and is thus invalid.
b. multi objective optimization multi objective optimization moo refers to the process of optimizing more than one objective at the same time.
the aim of these approaches is to search for optimal or nearly optimal solutions requiring trade offs between two or more conflicting objectives.
let xbe the set of all the possible product configurations of an spl and let v t be a vector of kobjective functions.
if each objective has to be rastergraphicseditor draw colorpalette selection rendering blackwhite color rectangular bycolor mandatory optionalor exclusive orrequires excludes fig.
a feature model of a raster graphics editor.
it represents the features of the software product line and their constraints.minimized moo aims at finding x1 xk i.e.
the solutions to the problem such as vis minimized.
the minimization of vis the process of optimizing simultaneously the kobjective functions .
letx1andx2be two potential solutions to the problem.
we say thatx1dominatesx2 written as x1 x2if and only if 8i2f1 kgfi x1 fi x2 and9i2f1 kgfi x1 fi x2 .
givenx1 xnpotential solutions to the moo problem the pareto front corresponds to the subset of these potential solutions that are non dominated by the others.
an example of pareto front is illustrated by figure for two objectivesf1andf2to minimize.
in this example x1 x2 x4 x6andx7are in the pareto front set since they are not dominated by any other solution.
by contrast x10is dominated among others by x2 x2 x10 .
so it does not lie on the front.
finally we denote as pareto front size the number of solutions in the pareto front.
c. state of the art the ibea method the indicator based evolutionary algorithm ibea is an evolutionary moo technique using quality indicators to guide the search towards the optimal solutions.
ibea has the ability to exploit user preferences.
the advantages of this algorithm over other search techniques for the spl configuration problem have been shown in .
sayyad et al.
proposed setting the number of constraints that are violated as a minimization objective within the search process in order to deal with the spl constraints.
the user preferences are also modeled as additional optimization objectives.
the approach applies the standard mutation i.e.
flipping bits of the offspring with a specific probability and crossover operators.
their results provide evidence that this practice can lead to invalid and marginally invalid configurations.
they also suggest that ibea is capable of providing a wide range of valid configurations that exploit and optimize user preferences.
the results of sayyad et al.
were reinforced by the study of olaechea et al.
who demonstrated on small models that ibea is capable of finding the optimal solutions.
olaechea et al.
also showed that is feasible to compute exact solutions when considering models with fewer than features.
this bound indicates the need for approximation algorithms such as ibea for the cases of larger models.
empirical evidence has been provided to show that by enhancing the initial population of the algorithm with one solutions pareto front fig.
an example of pareto front with two objectives f1and f2to minimize.
the solutions x1 x2 x4 x6andx7are in the pareto front since they are not dominated by any other.valid configuration called seed ibea is capable of scaling on very large fms has also been provided .
according to the studies of sayyad et al.
one seed that is rich i.e.
one configuration with many features selected is adequate for improving the search process and more effective than using many seeds.
we only consider large spls and thus we compare with this approach which forms the current state ofthe art.
in the rest of the paper we refer to it as the state ofthe art or as the ibea approach.
iii.
m otivation automatic configuration of spls is a challenging problem.
the problem is very hard for large models where most of the existing approaches fail.
one such approach is the random one.
to demonstrate the difficulty of the problem we implement a baseline approach that randomly selects and deselects features of the model.
by applying the baseline for minutes we expect to generate a large set of configurations some of which we might suppose would turn out to be valid according to the constraints.
however after the application on our studied models refer to section vi a for further details we found no valid configuration out of the solutions produced for the subjects in total.
this simple fact shows that the problem is hard and cannot be tackled with ad hoc solutions.
additionally the results of sayyad et al.
show that both the ibea and nsga ii approaches fail to provide any valid solution after minutes of execution when their population is not seeded.
similarly the study of olaechea et al.
demonstrates that it is infeasible to compute exact solutions for models with more than features.
collectively these results highlight the challenges posed by constrained industrial scale spls.
iv.
t he proposed approaches one of the most challenging spl optimization tasks is the automatic generation of valid configurations.
the current state of the art uses ibea to search and find valid solutions.
an alternative to search would involve the use of a sat solver .
in this case a valid configuration is a satisfiable model found by the solver.
to this end one might attempt to enumerate all the valid solutions of a model and select those that are optimal with respect to the other objectives.
however the large number of valid configurations makes this simplistic approach infeasible .
as a result some form of searchbased technique is needed.
to effectively perform search we seek to combine the benefits of both constraint solving and searching in a complimentary way.
the question this raises is how best to perform such a combination.
to achieve this two key aspects are considered diversity promotion and search using smart operators.
these aspects are taken into account in our approach called satibea .
we also define a filtered technique which only bestows the diversity promotion.
so allows to empirically assess its contribution to satibea success in isolation.a.
diversity promotion we wish to promote maximal diversity of sat solutions in a cheap way.
we do this by randomly permuting the parameters that control the search for constraint satisfying solutions processed by the sat solver.
more specifically there are three different sat parameters that we permute constraint order .
this is the order in which the constraints are considered.
literal order .
this is the order in which the literals of each constraint are ordered.
phase selection .
this is the orderftrue falsegin which assignments to variables are instantiated.
by randomly permuting these three parameters at each iteration of the sat execution we increase the diversity of solutions found.
to empirically assess the degree of diversity promotion dp this creates we use a dissimilarity metric as it is defined in .
based on the jaccard distance this metric captures degrees of difference between the selected and unselected features of two configurations.
the metric takes values between and .
a value of signifies that the two configurations differ completely while signifies that the two considered configuration are the same.
table i records the results of the above mentioned dissimilarity metric for solutions produced on a set of subject models with and without dp.
these subjects are introduced in section vi a. specifically table i records a the average dissimilarity between two configurations that are consecutively generated by calling the solver times b the set dissimilarity i.e.
the dissimilarity between any two configurations from a set of configurations produced by the solver and c the percentage increase in the diversity of the configurations as measured by the a and b cases.
the dissimilarity between two consecutive configurations ci cjis measured by d ci cj jci cjj jci cjj jci cjj.
the dissimilarity of a set of nconfigurations is measured by d c1 cn n pn j id ci cj .
finally the increase in the diversity is calculated as follows increase with dp without dp without dp .
as it can be seen in table i the permutation of the sat parameters allows the diversity of the solutions to increase by in the worst case for the consecutive calls to the solver.
for the set of configurations the diversity increase was in the worst case and more than in the best case.
b. smart operators we introduce two operators that are smart in the sense that they are constraint aware and using diversity promotion.
smart mutation this mutation operates by finding the features that are not involved in the violations of constraints.
it keeps their values and asks the solver to find a solution for the rest by assuming the values of the rest of the features.
consider an fm with features and constraints fm f1 f5 f2 f3 f2 f5 .
the configuration c ff1 f2 f3 f4 f5gis invalid because the two constraints f1 f5 and f2 f5 which involve the features f1 f2andf5 are violated.
we remove the assignment of these features andtable i dissimilarity with and without diversity promotion dp on configurations per model.
consecutive configurations set of configurations without dp with dp increase without dp with dp increase linux .
.
.
.
uclinux .
.
.
.
fiasco .
.
.
.
freebsd .
.
.
.
ecos .
.
.
.
makecpartially valid i.e.
c cpartial f f3 f4 g. this partial configuration is given to the sat solver which will complete it to return a valid configuration.
for instance it can return the following configuration c0 ff1 f2 f3 f4 f5g.
as a result chas been mutated into c0.
smart replacement this operator randomly picks a configuration from the solutions and replaces it with a new valid one improving the quality and diversity of the solutions.
c. the satibea approach satibea augments ibea with the smart operators.
diversity promotion is used in the optimization process through these two operators.
satibea also employs a form of memory by keeping track of all the valid configurations produced by the algorithm.
based on these solutions we compute the pareto front.
thus the population is evolved via the four following operators mutation .
this is the standard bit flip operator of ibea.
it iterates over the bits i.e.
the feature options of the offspring i.e.
the configuration and flips them with a specific probability.
crossover .
this is the standard single point crossover operator of ibea.
it combines two solutions i.e.
configurations by replacing the bits of the first one from the beginning of the offspring up to the crossover point with those of the second one.
smart mutation as described in section iv b1.
smart replacement as introduced in section iv b2.
d. the filtered approach to investigate the contribution of the diversity promotion to satibea s performance we also define a simple algorithm that simply randomly samples over diversity promoted sat solutions.
we refer to this approach as the filtered one.
v. r esearch questions we first empirically evaluate satibea against the current state of the art .
this is a natural first research question since there is no point in evaluating further if our new algorithm cannot convincingly outperform the state of the art.
rq1.
how does the satibea compare with the current stateof the art?
since the results of rq1 indicate that satibea does indeed convincingly outperform the state of the art we turn to the question of examining why.
naturally since one of ourprimary novelties lies in the incorporation of sat solving into the search for constraint respecting solutions we next investigate and report on the effectiveness of sat solving alone.
how well would sat solving perform against the current state of the art on its own?
this motivates rq2 rq2.
how well does the state of the art perform against constraint solving alone randomly selected solutions filtered by sat i.e.
the filtered approach ?
perhaps surprisingly we found that the filtered approach outperforms the state of the art.
this provides compelling evidence that constraint solving does have an important role to play in the search for optimized products automatically configured from spls.
however it also raises a further question does satibea significantly outperform constraint solving alone?
if the answer is no then all the value in our new satibea approach derives from our incorporation of constraint solving with search based optimization and our smart mutation operators offering little added value.
in order to check that this is notthe case we investigate rq3 below rq3.
how well does satibea perform against constraint solving alone randomly selected solutions filtered by sat i.e.
the filtered approach ?
at this point in our study we will have considered whether our new algorithm satibea outperforms the state of the art rq1 whether constraint solving plays an important role in its performance rq2 and whether satibea adds value to the search for constraint respecting optimized software products over and above pure constraint solving alone rq3 .
our final question concerns the execution time required to achieve these results.
even if satibea convincingly outperforms all alternatives this will be of little consequence if it does not scale well to the challenges of very large spls involving billions of possible configurations over thousands of features.
we therefore conclude our study by reporting on the time taken to complete the execution of satibea on the largest spl for which results have been reported in the literature to date.
rq4.
what is the execution time required to find constraintrespecting optimized software products from the largest spl hitherto considered in the literature?
vi.
e xperimental setup this section presents the settings of the conducted experiments.
specifically it describes the subjects the optimization objectives and the employed metrics.
a. subjects the study uses fms taken from the linux variability analysis tools lv at repository1.
the characteristics of the fms are described in table ii.
for each of them it presents the version used and the number of features and constraints it contains.
following the evaluation approach used by sayyad et al.
each feature of each fm has been augmented with attributes cost used before and defects .
the values for these attributes have been set arbitrarily with a uniform ii feature models used in the empirical study.
feature model version features mandatory constraints linux .
.
.
uclinux fiasco freebsd .
.
ecos .
distribution cost takes real values between 0and15 used before takes boolean values and defects takes integer values between 0and10.
the following dependency among these attributes is used if not used before then defects .
b. optimization objectives in this study we are measuring the following objectives correctness .
we seek to minimize the constraints of the fm that are violated by a configuration.
richness of features .
we seek to minimize the number of deselected features in a configuration.
features that were used before .
we seek to minimize the features that were not used before i.e.
minimize the number of false for this attribute.
known defects .
we seek to minimize the number of known defects in a configuration.
cost.
we seek to minimize the cost of a configuration.
in practice based on the needs and the historical data of engineers other objectives can be also used.
we selected these five objectives to ensure identical settings as those reported for the state of the art .
c. settings all the experiments were performed on a quad core .
ghz with 24gb of ram.
to enable a fair comparison with the state of the art we used exactly the same settings as the ones of sayyad et al.
.
these settings are population size archive size crossover rate .
and0.
mutation probability.
the mutation probability refers to the probability that an optional feature of the model will be flipped.
regarding the configurations we systematically set mandatory features features that have to be present in any configuration as selected and dead ones features that cannot be part of any configuration as unselected in the initial population of ibea.
we also prevented ibea from flipping these features during the mutation process.
flipping these features always leads to invalid configurations.
thus this practice helps ibea to find valid configurations.
the same evaluations settings were undertaken in the study of sayyad et al.
.
we carefully followed all the recommendations of sayyad et al.
in our experiments.
unfortunately it is impossible to produce the same seeds.
since the work of sayyad et al.
is not currently accompanied by any data or implementation we simply followed the guidelines they give in their paper.
therefore we have produced seeds using the solver by maximizing the number of selected features.
this is done by setting the sat parameter phase selection to assign true to thetable iii selected features in the seeds used by ibea.
feature model selected features selected features in linux uclinux fiasco freebsd ecos variables.
note that this parameter was also used for diversity promotion see section iv a .
we thus produce one rich seed per model as suggested by sayyad et al.
.
table iii describes the number of features selected in each seed.
similarly the settings for satibea are the same as for ibea i.e.
population size archive size crossover rate .
.
the probability to use the standard mutation of ibea bitflip which mutates a chromosome is set to .
.
the probability to flip a feature is set to .
per feature.
the probabilities of mutating using the smart mutation and the smart replacement is .
for both cases.
we employed the sat4j sat solver and used the jmetal framework for the implementation of ibea and for the quality and diversity metrics see section vi d .
we independently applied each approach times per fm with minutes of execution time for each algorithm.
invalid configurations were discarded for all the studied techniques.
recall that invalid configurations are useless in practice.
d. metrics to evaluate the studied approaches we follow two directions we measure the proximity of the solutions found from the optimal ones i.e.
their quality and we evaluate the diversity of the solutions.
note that diversity is only useful when there is quality a single diamond is preferable to an arbitrary number of diverse glass fragments.
in other words it is useless to have diverse solutions that are all dominated by a single one.
therefore the diversity metrics should be considered only when comparing solutions of similar quality.
since the global optimum cannot be known in all cases as with all np hard problems a reference front is used in evaluation.
it consists of the best solutions found by all the studied approaches and it is defined as follows given npareto fronts a1 an and if j m n the reference front arefis defined as aref fx1 xmj 8xj2aref 69x02sn i 1ai x0 xj g. it should be noted that aref ai an.
quality metrics these metrics ensure that we find high quality solutions.
following the evaluation approach suggested by knowles et al.
we use three metrics to evaluate the quality of the configurations of the pareto front hypervolume epsilon andinverted generational distance .
a hypervolume hv this metric represents the volume of the objective space that is dominated by the pareto front a. it evaluates how well a pareto front fulfills the optimization objectives.
it is written hv and defined in as follows hv a s x2a where s is the lebesgue measure of a set s kis the number of objectives r is the reference point and is thek dimensional hypercuboid consisting of all the points dominated by the point x. the reference point is the maximum value that belongs to the reference front.
a higher hv denotes a better pareto front.
b epsilon this metric measures the shortest distance that is required to transform every solution in a pareto front ato dominate the reference front .
if x t2r kis a solution it is defined as a a ref inf x2rf8x02aref9x2ajx x0g where x x0if and only if81 i k xi x0i.
this indicator denotes how close ais to the reference front and thus lower values are preferable.
c inverted generational distance igd this metric is the average distance from the solutions belonging to the reference front to the closest solution in a pareto front a .
igd is defined as follows igd a a ref p x02arefd x0 a pfs aref whered x0 a is the minimum euclidean distance between x0and the other points in aand pfs is the pareto front size see section vi d2a .
for the lower the value of igd the closerais to the reference pareto front.
diversity metrics these metrics ensure that the decision maker has a variety of solutions to choose.
we use two diversity metrics the pareto front size and the spread of the solutions in the explored space.
a pareto front size pfs this metric is the number of solutions in a pareto front a. it is calculated as the cardinality of the pareto front set i.e.
pfs a jaj.
a higher pareto front size is preferred since more options are given to the user.
however this is only important when high quality is preserved.
b spread s the spread measure defines the extent of spread in the solutions of the pareto front a. it is defined in as follows s a df dl ppfs a i 1jdi dj df dl pfs a d wherediis the euclidean distance between consecutive solutions of a d is the average of the di s anddfanddlare the euclidean distance between the extreme solutions and the boundary solutions of a. a higher spread denotes a better pareto front since it reflects more diverse solutions i.e.
distributed among all the optimization objectives.
e. statistical analysis and tests to check the statistical significance of the differences between the algorithms we performed a statistical test using the mannwhitney utest two tailed at a significance level.
it is a non parametric test and thus it makes fewer assumptions regarding the underlying populations.
based on this test we obtain an estimation about the probability i.e.
pvalue that one algorithm gives different values than the other.
furthermore to reduce the threats of having type i errors in the cases of multiple comparisons i.e.
incorrect rejection of a true null hypothesis we also consider the standard bonferroni adjustment .
this is a conservative but safe adjustment because it reduces the chances of type i errors.
following the advice of arcuri and briand and wohlin et al.
table iv state of the art vs the proposed approaches comparison in terms of quality metrics i.e.
hypervolume hv epsilon and inverted generational distance igd and diversity metrics i.e.
pareto front size pfs spread s on independent runs per approach.
higher values are preferred for hv pfs ands.
lower values are preferred for andigd .
ibea i filtered f satibea si si vs i f vs i si vs f median avg median avg median avg p value a12p value a12p value a12linux qualityhv .75e .00e .
.
.
.
.02e .02e .62e .
.
.
.
.
.
.
.96e .97e .02e igd .
.
.
.
.
.
.02e .02e .02e 1diversitypfs .
.
.
.
.54e .56e .43e .
s .
.
.
.
.
.
.11e .
.77e .
.
.56uclinux qualityhv .
.
.
.
.
.
.02e .02e .02e .
.
.
.
.
.
.87e .38e .30e igd .
.
.
.
.
.
.97e .60e .97e 1diversitypfs .
.
.
.95e .95e .02e s .
.
.
.
.
.
.02e .20e .
.02e 0fiasco qualityhv .
.
.
.
.
.
.02e .02e .92e .
.
.
.
.
.
.
.01e .10e .
.
igd .
.
.
.
.
.
.02e .02e .
.56diversitypfs .
.74e .74e .01e s .
.
.
.
.
.
.02e .02e .08e .20freebsd qualityhv .
.
.
.
.
.38e .39e .
.02e .
.
.
.
.
.61e .61e .98e igd .
.
.
.
.
.61e .60e .02e 1diversitypfs .
.
.
.62e .60e .00e s .
.
.
.
.
.02e .
.60e .
.02e 1ecos qualityhv .
.
.
.
.
.
.02e .02e .02e .
.
.
.
.
.
.02e .53e .53e igd .
.
.
.
.80e .77e .02e .02e .02e 1diversitypfs .
.00e .99e .02e s .
.
.
.
.
.
.02e .02e .02e we also report the non parametric effect size measure a12 introduced by vargha and delaney .
it measures the extent to which the first algorithm outperforms the second one.
according to vargha and delaney the differences between populations are considered as small medium and large when a12is over .
.
and .
respectively.
vii.
e xperimental results the results for each approach are analyzed in section vii a. sections vii b and vii c discuss the rq1 rq3.
finally section vii d presents results regarding the execution time of satibea on the largest spl of the literature.
a. results this section presents the result of the approaches when applied to the five models.
these results are recorded in table iv.
this table is composed of two parts.
the columns ibea i filtered f andsatibea si records the measured details about each approach.
in particular it records for executions the median and average column avg values of the measured metrics.
the second part i.e.
columns si vs i f vs i and si vs f records the results of the statistical analysis results i.e.
thep values and the effect sizes a12.
the rows of the table record the results per examined model hypervolume measure rows hv epsilon rows inverted generational distance rows igd pareto front size rows pfs and spread metric rows s for the the runs per approach.
in addition figure 3a shows the distribution of the hvs on the runs for all the models and the evolution of the hv over time for linux is depicted in figure 3b.
b. comparing satibea and filtered with the state of the art answering rq1 and rq2 our results indicate that satibea outperforms the current state of the art ibea .
the statistical analysis results with respect to the quality metrics column si vs i suggest that all the differences are significant with maximal effect size a12 .
the resulting p value are so small that nothing changes when applying the bonferroni correction.
regarding the diversity metrics satibea provides better results with respect to pfs but worse with respect to s. however s is a diversity metric which is only important when there is quality in the solutions found e.g.
hv .
additionally these results reveal that satibea is much00.
.
.
.
.
.
.
linux uclinux fiasco freebsd ecoshypervolumeibea filtered satibea a distribution of the hypervolumes on the runs .
.
.
.
.
.
.
.
.
30hypervolume time in minutessatibea on linux b hypervolume over time for satibea on linux fig.
distribution and evolution of the hypervolumes.
better when it is applied on the two most heavily constraint models i.e.
linux and freebsd.
in the median case of linux figure satibea produces configurations that cover approximately times more wider space i.e.
hypervolume than ibea.
in the median case of freebsd ibea failed to find even one solution that is valid.
furthermore the solutions found by satibea do not only provide more options as shown by the pfs values than the state of the art but they are also more stable as shown in figure 3a.
all these results indicate the superiority of our method.
our results also indicate that the filtered approach is better than the state of the art.
the statistical analysis results with respect to the quality metrics and column f vs i suggest that in all but the uclinux model the differences are significant.
the differences have high effect size a12 on all the four models it wins.
also the statistical results do not change by applying the bonferroni correction.
similarly to satibea in the cases of diversity the filtered provides better results with respect to pfs but worse with respect to s. however as already mentioned this does not indicate that ibea is better.
conclusively both proposed approaches are better than the current state of the art.
noticeable is the fact that satibea wins the current state of the art in all the employed quality metrics with maximal effect size a12 .
in addition when a more heavily constrained is considered satibea performs much better than the state of the art.
c. comparing satibea with filtered answering rq3 our results indicate that satibea wins the filtered method in all the model according to the hv metric.
for instance for freebsd the median hv achieved by satibea is almost twice the one of filtered i.e.
.
vs .
.
these results are also statistically significant both with and without bonferroni correction with a relatively high effect size above a12 on all the case.
according to the epsilon and igd metrics satibea wins in all the models with statistical significance except from the fiasco where they are approximately equal.
regarding the effect sizes of the diversity measures the two approaches are comparable with satibea having a slight advantage.
with respect to s satibea has a big difference in two cases a medium difference in one and it looses or it is equal in two cases.
with respect to pfs it winsin three cases and looses in two.
therefore since diversity is not so important if we do not have quality overall our results demonstrate that satibea is the clear winner.
it provides the best results statistically significant and can handle effectively heavily constrained fms.
conclusively answering rq3 our results suggest that satibea is able to outperform the filtered approach with hv values ranging from .
to .
.
d. execution time of satibea answering rq4 our results indicate that the hv of the solutions achieved by satibea converges markedly the first minutes figure 3b .
after this point the hv increases very slowly suggesting that satibea stabilised on its ultimate solution in minutes.
this is an important finding since linux is the largest available spl hitherto reported upon in the literature.
both the smart replacement and the smart mutation operators which use the solver take less than six seconds.
thus they help the fast convergence of the search process.
viii.
d iscussion this section discusses practical implications and threats to the validity of the findings reported in the present work.
a. practical implications in the spl context the major challenge is the production of valid configurations.
it is clear that until all constraints are satisfied the configuration is invalid.
in other words an invalid product configuration is totally useless from practical perspective.
therefore the effort put by the search approach in optimizing the other objectives is wasted when the resulting configuration is invalid.
to investigate this we analyze the results of the linux fm.
specifically we group the pareto front solutions of ibea according to the number of violated constraints.
we visualize this situation by computing the hypervolume values when the algorithm minimizes the violated constraints.
figure depicts the hypervolume achieved by the pareto front solutions according to each number of violated constraints.
we can observe that as the number of violated constraints decreases the hypervolume also decreases.
these results show that the constraints hamper the search process.
indeed the graph clearly suggests a decreasing trend.
thisis formally confirmed by a linear regression which bestows a relationship of the form f x x .
this fit is good given its coefficient of determination r2 of .
.
in other words our linear fexplains of the recorded values.
finally it is clear that when no constraint is violated the hypervolume is almost .
since the hypervolume represents how well the objectives are optimized it shows that ibea fails to fulfill the other objectives when dealing with valid configurations.
as a result the optimization of the other objectives is limited by the minimization of the violated constraints.
this explains why ibea performs poorly compared to the filtered approach.
these results introduce the need for handling constraints independently of the search.
thus hybrid methods like satibea are the key to success.
our evaluation focuses on large spls because they are typically used in industry and they motivate the need for automation.
generally our results show that when the number of constraints increases the difficulty faced by the search approaches also increases.
fortunately our results reveal that a higher number of constraints implies a higher gap between the effectiveness of the proposed and the current state of the art approaches.
additionally it should be noted that satibea has an additional benefit over the state of theart it does not require any seeds.
thus it avoids the necessary off line computation of the seeds which according to sayyad et al.
consumed approximately hours.
apart from optimizing the objectives the proposed approach can have additional applications.
an interesting one is to help engineers into correct and maintain fms.
to achieve this engineers can select multiple fm variants that represent the potential problems or changes in the original fm.
then valid configurations with respect to the fm variants can be selected and evaluated towards the original fm.
such an approach can be automated as proposed by henard et al.
.
the important step here is the selection of valid configurations from the erroneous fm variants that will reflect both the potential problems and the targeted changes of the original .
.
.
.
.
.
2500hypervolume violated constraintsr2 .955pareto front solutions linear regression fig.
impact of the violated constraints on the hypervolume for linux.
as solutions tend to conform to the constraints of the model the optimization of the other objectives degrades.fm.
one could argue that this can be achieved with invalid configurations of the original fm.
however it is unclear how to produce invalid configurations that are both relevant and helpful in correcting the model.
finally we note the importance of the various quality metrics.
the hypervolume metric represents the extent in the optimization of user objectives.
any improvements of this metric yields a strictly better quality value .
in other words a very small change in the hypervolume implies a relatively big impact in practice.
regarding the spread diversity measure spread configurations represents solutions that are diverse in the space of the objectives i.e.
which achieve different trade offs.
concretely the spread configurations suggest that there are configurations in favor of each considered objective.
solutions with low spread fail to propose multiple alternative trade offs.
however as already stated in section vi d diverse solutions with low quality are not meaningful in practice.
b. threats to validity several threats to the validity of the present study are identified.
our results are based on five spls.
hence it is possible that our conclusions do not generalize to other cases.
to reduce this threat we took four different and large fms with different number of features and constraints.
in particular the fms we chose have a varied density of constraints i.e.
the number of constraints per feature vary.
we used both slightly and heavily constrained models such as linux and uclinux with an average of respectively and .
constraints per feature.
another threat is due to the randomness involved in the approaches studied.
indeed there is a chance that the observed results happened by chance.
to reduce this threat we performed each approach times independently thereby reducing the influence of random effects.
another threat is identified due to potential errors unknown parameters or differences in the implementation.
in addition the machines used may influence the results.
to reduce this threat we performed a careful verification of our results and several manual tests at all stages of our implementation.
additionally we make publicly available both our implementation and our data.
finally a threat is due to the artificial way the values of the attributes were assigned i.e.
the actual usage scenario and to the replication of the state of the art.
unfortunately there is no available implementation of the previous work .
to overcome this issue we carefully replicated and verified multiple times all parameters and the technical details of the experiments as described in .
additionally we used the same framework algorithms and settings as the previous work.
ix.
r elated work one of the first approaches that aimed to optimize multiple configuration goals is attributed to olaechea et al.
.
this method uses a special form of fms called attributed fms which record quality attributes for the features.
this technique uses exact solving and consider fms with one to three objectives.
however it fails to scale due to the computation of the exhaustive search it performs.
the authors used fmswith up to features.
sayyad et al.
proposed the use of advanced multi objective evolutionary algorithms for spls with five objectives to optimize.
they experiment with five algorithms and conclude that ibea is the most suitable one for the spl context.
sayyad et al.
were the first to the authors knowledge to use constraint violation as an objective for the search process.
this approach was later extended by sayyad et al.
with the aim of scaling to large spls.
it is this technique that is investigated by the present paper i.e.
ibea.
however as shown by our results the proposed techniques satibea and filtered are by far more effective.
another approach that aims to optimize many objectives is due to henard et al.
.
in this work a genetic algorithm is employed to generate a set of valid configurations.
the approach employs a sat solver to select valid configurations while maximizing the t wise coverage of the selected set of configurations and taking into account other parameters such as the cost of the configurations.
despite the promising results it fails to scale to large fms mainly due to the expensive twise coverage computation .
in contrast satibea seeks to provide scalable solutions for the moo problem of configuring products for spls.
regarding constraints handling with evolutionary approaches several methodologies are proposed in the literature such as including constraint knowledge in the fitness function .
in this work we use an external sat solver to repair valid configurations smart mutation operator and to generate valid configurations smart replacement .
most of the existing approaches generate configurations that conform to the fm constraints while optimizing a single other objective.
benavides et al.
imposed constraints modeling extra functional properties of the spl features.
they then applied constraint satisfaction solvers to generate all the possible configurations the optimal ones etc.
another attempt to optimize the extra functional properties of configurations was by white et al.
.
they proposed to transform the product configuration problem into a multi dimensional multichoice knapsack problem to use known techniques to tackle it.
white et al.
developed a tool for the multi step configuration of evolving fms.
they show that it is possible to derive configurations automatically by mapping the spl configuration problem to a constraint satisfaction one.
aiming att wise coverage perrouin et al.
developed a tool based on the alloy sat solver.
other work e.g.
used a sat solver to generate valid set of configurations.
unlike the methods presented in the present paper these methods optimize only a single objective i.e.
either the t wise coverage or some form of attribute coverage.
furthermore these approaches fail to scale to large fms.
there are few techniques that scale to very large spls.
johansen et al.
use the covering array method based on a sat solver to generate configuration sets that cover all the t wise interactions between the features of an spl.
similarly a search based approach that achieves scalable but partial twise coverage has been introduced in .
however none of them targets multiple objectives.
perhaps the closest work to the present one is the one of guo et al.
.
guo et al.
proposethe use of a genetic algorithm to tackle multiple objectives.
to achieve this it aggregates all objectives into one.
this practice fails to produce a wide range of configurations and results in a single configuration that is only optimized for a specific objective weighting scheme.
additionally it uses a repair process to make the candidate solutions valid with respect to the constraints of the fm.
this process restricts the search process .
since it was evaluated on artificial models and thus it is currently unclear whether it can provide satisfactory solutions for real word fms.
our study involves the satisfaction of multiple objectives for large heavily constrained and real world fms such as the linux kernel.
approaches for the automated analysis of fms have proliferated these last years .
such techniques enable to extract information from the fm such as identifying the mandatory features or count the valid configurations of an spl.
these techniques rely on binary decision diagrams or solvers such as sat or satisfiability modulo theory smt solvers.
the efficiency of these techniques has been investigated by pohl et al.
with the conclusion that these approaches induce a certain overhead and that there is still room for improvement.
the use of sat solvers for reasoning on fms has been reported as being an easy task .
in this work the authors conclude that the previous reports on the efficiency of sat solvers is not incidental in practice.
the fms used in this work are extracted from existing code such as the linux kernel.
to the best of our knowledge the efficiency of automated analysis techniques have not been investigated on such models.
finally augmenting the features of fms with quality attributes such as cost has been used in several previous studies e.g.
.
x. c onclusion and future work we have demonstrated that our spl optimization approach satibea significantly outperforms the current state of theart with maximal effect size.
we also provide results that show that it is important to include constraint solving techniques in spl optimization approaches and that our technique scales to the largest spls hitherto considered in the literature.
since reproducibility has been identified as a central tenet of the research in software engineering we make the source code of our implementation and our experimental data publicly available at .
future work will investigate alternative ways to improve the search process.
specifically practices like parameter tuning supervised search or hybrid approaches involving both constraint driven and genetic search will be considered.
xi.
a cknowledgements mike papadakis is supported by the national research fund luxembourg inter mobility .
mark harman is supported by engineering and physical sciences research council the epsrc grants genetic improvement of software for multiple objectives gismo ep i033688 and dynamic adaptive automated software engineering daase ep j017515 .