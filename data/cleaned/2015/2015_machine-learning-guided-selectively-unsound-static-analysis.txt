machine learning guided selectively unsound static analysis kihong heo seoul national university seoul koreahakjoo oh korea university seoul koreakwangkeun yi seoul national university seoul korea abstract we present a machine learning based technique for selectively applying unsoundness in static analysis.
existing bugfinding static analyzers are unsound in order to be precise and scalable in practice.
however they are uniformly unsound and hence at the risk of missing a large amount of real bugs.
by being sound we can improve the detectability of the analyzer but it often suffers from a large number of false alarms.
our approach aims to strike a balance between these two approaches by selectively allowing unsoundness only when it is likely to reduce false alarms while retaining true alarms.
we use an anomalydetection technique to learn such harmless unsoundness.
we implemented our technique in two static analyzers for full c. one is for a taint analysis for detecting format string vulnerabilities and the other is for an interval analysis for buffer overflow detection.
the experimental results show that our approach significantly improves the recall of the original unsound analysis without sacrificing the precision.
keywords static analysis machine learning bug finding i. i ntroduction any realistic bug finding static analyzers are designed to be unsound.
ideally a static analyzer is expected to be sound precise and scalable that is it should be able to consider all program executions and hence do not miss any intended bug while avoiding false positives and scaling to large programs.
in reality however achieving the three at the same time is extremely challenging and therefore existing commercial static analysis tools e.g.
and published static bug finders e.g.
trade soundness in order to obtain acceptable performance in precision and scalability.
to our knowledge all of the existing unsound analysis tools are uniformly unsound.
for instance since loops and unknown library calls are major sources of imprecision in static analysis most static bug finding tools compromise soundness in analyzing them e.g.
loops are unrolled for a fixed number of times and subsequent loop iterations are ignored entirely and unknown library calls are considered as pre defined behaviors such as skip.
all of these approaches are uniformly unsound in that they ignore every loop and library call in a given program regardless of their different conditions.
however this uniform approach to unsoundness has a considerable shortcoming it causes the analysis to miss a significant amount of real bugs.
for instance our taint analysis for detecting format string vulnerabilities ignores the possible corresponding authorsdata flows of all unknown library calls in the program and therefore only report false alarms in the benchmark c programs section v .
however it only managed to detect bugs among the potentially detectable format string bugs.
in other words this unsound analysis has low false positive rate fpr false alarms all alarms but it has high false negative rate fnr missing bugs all bugs .
on the other hand a simple minded uniformly sound analysis poses the opposite problem it has low fnr at the cost of high fpr.
for example a simple solution to decrease the fnr of the unsound taint analysis is to modify the analysis to consider the potential data flows of every unknown library call in the program.
this uniformly sound analysis is able to find all bugs in the benchmark programs.
however it reports false alarms too.
our work is to reduce the fnr of an unsound bug finder while maintaining the original low fpr by being selectively unsound only when it is likely to be harmless.
for example we unsoundly analyze library calls only when it is likely to reduce fpr while maintaining low fnr.
with our approach the selectively unsound taint analysis reports real bugs among with false alarms only.
we achieve this by using a machine learning technique that is specialized for anomaly detection .
our key insight is that the program components e.g.
loops and library calls that produce false alarms are alike predictable and sharing some common properties.
meanwhile the real bugs are often caused by different reasons that are atypical and unpredictable in their own ways section iii b2 .
based on this observation we aim to capture the common characteristics of the harmless and precision decreasing program components by using one class support vector machines.
the entire learning process in our approach i.e.
generating labelled data and learning a classifier is fully automatic once a codebase with known bugs is given.
the experimental results show that our method effectively reduces false negatives of the baseline analyzer without sacrificing its precision.
we evaluated our method with two realistic static analyzers for c and open source benchmarks.
the first experiment is done with a taint analysis for finding out formatstring bugs.
in our benchmarks with bugs the baseline uniformly unsound analysis detects bugs with false alarms fpr fnr .
uniformly improving the soundness impairs the precision too much it reports real bugs with ieee acm 39th international conference on software engineering ieee acm 39th international conference on software engineering .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
str hello world for i !str i buffer access skip size positive input for i i size i skip ... str buffer access fig.
.
example program false alarms fpr .
our selectively unsound analysis maintains the original precision while greatly decreasing the number of false negatives it reports bugs with false alarms fpr fnr .
the second experiment is done with an interval analysis for buffer overflow detection where we control the soundness for both loops and library calls.
in the benchmarks with bugs the uniformly unsound analysis detects bugs with false alarms fpr fnr .
the uniformly sound analysis detects bugs with false alarms fpr .
our selectively unsound analysis detects bugs with false alarms fpr fnr .
to summarize our contributions are as follows we present a new approach of selectively employing unsoundness in static analysis.
all of the existing bugfinding static analyzers are uniformly unsound.
we present a machine learning technique that can automatically tune a static analysis to be selectively unsound.
our technique is based on anomaly detection with automatic generation of labelled data.
we demonstrate the effectiveness of the technique by experiments with two bug finding static analyzers for c. ii.
o verview we illustrate our approach using a static analysis with the interval domain.
the goal of the analysis is to detect buffer overflow bugs in a program.
for simplicity we only concern with loops in this section which could be a potential cause of the buffer overflow bugs.
consider a simple program in figure .
in the program there are two loops and two buffer access expressions.
the first loop iterates over a constant string until the null value in the string is found.
in the loop buffer access is always safe since iis guaranteed to be smaller than the length of str inside the loop.
on the other hand buffer access is not always safe because the index ihas the value of size after the second loop which can be an arbitrary value due to the external input and may cause a buffer overflow.
a. uniformly unsound analysis consider an analysis that is uniformly unsound for every loop.
that is all the loops in the given program are unrolled for a fixed number of times and subsequent loop iterations are ignored during the analysis.
from the perspective of such an unsound analysis the example program is treated as follows.str hello world i if !str buffer access skip size positive input i if i size skip ... str buffer access note that each loop is unrolled once and replaced with an ifstatement.
the analysis does not report a false alarm for buffer access since the value of iremains as .
however it also fails to report a true alarm for buffer access the value ofiis approximated to hence the analysis considers the buffer access to be safe.
b. uniformly sound analysis on the other hand a sound interval analysis can detect the bug at buffer access with a false alarm at buffer access .
inside the first loop the analysis conservatively approximates the value of ito since this value is not refined by the loop condition !str .
it is because the interval domain cannot capture non convex properties e.g.
i negationslash where is the null index of str .
thus the analysis reports an alarm for buffer access as a potential buffer overflow error which is a false alarm that we want to avoid.
meanwhile the variable iin the second loop is upper bounded by size whose range is approximated as due to the unknown input value.
therefore the analyzer reports an alarm for buffer access which is a true alarm in this case.
c. selectively unsound analysis our selectively unsound analyzer applies unsoundness only to the loops that are likely to remove false alarms only.
in the example program in figure we ignore the first loop since analyzing it soundly results in reporting a false alarm at buffer access .
the second loop on the other hand needs to be analyzed soundly since it has the possibility of causing an actual buffer overflow.
the selectively unsound analysis on the given program corresponds to analyzing the following program.
str hello world i if !str buffer access skip size positive input for i i size i skip ... str buffer access note that we only unroll the first loop not the second loop.
by being unsound for the first loop and sound for the second loop the analysis is able to report the true alarm for buffer access while avoiding the false alarm for buffer access .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
d. our learning approach we achieve the selectively unsound analysis via machine learning based anomaly detection.
assume that we have a codebase and a set of features.
the codebase is a set of programs in which all the bugs are found and their locations are annotated so that we can classify alarms into true or false alarms.
then we need to decide which set of program components to apply unsoundness selectively.
in our example it is the set of loops in the program we want to analyze.
the features in this case describe general characteristics of the loops.
the learning phase consists of three steps.
we collect harmless loops from the codebase.
a loop is harmless if unsoundly analyzing the loop does not cause to miss real bugs but reduces false alarms.
for simplicity we assume there is only one program in the codebase and the program contains nloops.
when analyzed soundly it reports certain number of true alarms and false alarms.
then we examine each loop by replacing it with an if statement i.e.
unrolling one by one and compare the result to that of the original program.
if the replacement of a loop makes the number of true alarms remain same but makes the number of false alarms decrease we consider the loop to be harmless.
we collect all the loops satisfying the condition.
next we represent the loops as feature vectors.
once all the harmless loops in the codebase are collected we create a feature vector for each loop using the set f f1 f2 ... f k wherefiis a predicate over loops.
for example f1may indicate whether a loop has a conditional statement containing nulls.
finally having the generated feature vectors as training data we learn a classifier that can distinguish such harmless loops.
we use one class classification algorithm for learning the classifier that requires only positive examples i.e.
harmless loops .
we use the anomaly detection algorithm to learn the common characteristics and regularities of the harmless loops.
in the testing phase the classifier takes the feature vectors of all the loops in a new program as an input.
if the classifier considers a loop to be harmless then the loop is analyzed unsoundly meaning that it is unrolled once and replaced with an if statement.
otherwise if the classifier considers a loop to be harmful i.e.
anomaly then the loop is analyzed soundly.
iii.
o urtechnique our goal is to find harmless components and selectively employ unsoundness only to them.
in this section we describe how to build a selectively unsound static analyzer in detail.
first we introduce a parameterized static analysis that applies unsoundness only to certain program components.
then we explain how to learn a statistical model from an existing codebase which is used to derive a soundness parameter.a.
parameterized static analysis our analysis employs a parameterized strategy for selecting the set of program components that will be analyzed soundly.
this is a variant of the well known setting for the parameterized static analysis except the parameter controls the soundness of the analysis not the precision.
letp pgm be a program that we want to analyze.
cp is the set of program points in p.jpis the set of program components such as the set of loops the set of library calls or the set of other operations in p. in the rest of this section we omit the subscript pfrom cpandjpwhen there is no confusion.
the selectively unsound static analyzer is a function f pgm j c which is parameterized by the soundness parameter j i.e.
a set of program components .
given a program pand its parameter the analyzer outputs alarms i.e.
a set of program points .
a soundness parameter j is a set of program components which need to be analyzed soundly.
in other words it selects the program components that are likely to produce true alarms as a result of detecting real bugs in the program.
for instance when j j1 jn is the set of loops in the program p ji means that the ith loop in the program is not considered to be harmless we analyze the loop as it is rather than unrolling the loop once and ignoring all the subsequent loop iterations.
we want to find a good soundness parameter which allows the analyzer to apply costly soundness only to the necessary components which are not harmless.
let 1be the parameter where every component is selected and 0be the parameter where no component is selected.
then f p denotes the analysis that is fully sound which can detect the maximum number of the real bugs along with lots of false alarms.f p means the fully unsound analysis reporting the minimum number of false alarms with risk of missing many real bugs.
for our analysis it is important to find a proper parameter which strikes the balance between 1and0 reporting false alarms as few as possible while detecting most of the real bugs.
b. learning a classifier we want to build a classifier which can predict whether a given program component is harmless or not.
the classifier in our approach exploits general properties of harmless components and uses the information for new unseen programs.
features we define features to capture common properties of program components.
features are either syntactic or semantic properties of program components which have either binary or numeric values.
for simplicity we assume them to be binary properties fi j .given a set of features we can derive a feature vector for each program component.
suppose that we have nfeatures f f1 ... f n .
with the set of features each program component j jcan be represented as a feature vector f j angbracketleftf1 j ... f n j angbracketright.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
our approach requires analysis designers to come up with a set of features for each parameterized static analysis f.i n section iv we discuss how to construct program features with two case studies for loops and library calls.
learning process a classifier is defined as a function c n which takes a feature vector of a program component as an input.
it returns if it considers the component to be harmless or otherwise.
we define a model m pgm j that is used to derive a soundness parameter for a given program as follows m p j j c f j .
the model collects the program components that are potentially harmful which may cause real bugs.
with the model we run the static analysis for a new unseen program p f p m p .
that is we first obtain the soundness parameter m p from the model and instantiate the static analysis with the parameter.
as a result the analysis becomes sound for the program components that are selected by the parameter from the model and unsound for the others.
we learn the model with one class support v ector machine oc svm .
oc svm is an unsupervised algorithm that learns a model for anomaly detection classifying new data as similar or different to its training data.
our intuition is that harmless program components tend to be typical sharing common properties whereas harmful components are atypical therefore difficult to be characterized.
it is because bugs in the real world are introduced unexpectedly by nature.
in addition collecting examples for all kinds of bugs is infeasible whereas collecting and generalizing the characteristics of harmless components is relatively easy to achieve.
therefore we use this one class classification method it only requires positive examples e.g.
harmless loops that are expected to share some regularities learns such regularities and classifies new data as similar or different to its training data.
note that the characteristics of harmless components are largely determined by the design choices of a given static analysis e.g.
abstract domain whereas that of harmful components are not affected by the analysis design.
for example for an interval analysis of c programs the following loops are typically harmless loops iterating over constant strings str hello world for i !str i false alarm ... as explained before analyzing such loops soundly is likely to cause false alarms rather than detecting true bugs because of the non disjunctive limitation of the interval domain.
loops involving variable relationships p malloc len for i i len i p ... false alarm sound analysis of this kind of loops is likely to produce false alarms because of the non relational limitation ofalgorithm training data generation t for all pi bi pdo ai f pi at af ai bi ai bi for allj jpido a prime i f pi j a prime t a prime f a prime i bi a prime i bi if a prime t at a prime f af then t t f j end if end for end for the interval domain.
the analysis cannot track the relationship between the value of len the value of i and the size of buffer p. generating training data from an existing codebase we generate training data for learning the classifier.
the training dataset is composed of a set of feature vectors.
note that we only collect the feature vectors of harmless components because oc svm is designed to learn the regularities of positive examples.
the positive examples in our case are the harmless components.
the codebase of the system is a set of annotated programs p p1 b1 ... pn bn in which each program piis associated with a set of buggy program points bi cpi.
once all the programs in the codebase is annotated accordingly we can automatically generate training data for the classifier.
we first applies unsoundness to each component one by one runs the analysis and collects the feature vectors from all the harmless components in the given codebase.
we consider a program component to be harmless if the number of true alarms remains same and the number of false alarms is decreased when analyzed unsoundly.
the algorithm for generating training data is shown in algorithm .
for each program piin the codebase we run the fully sound static analysis and classify the output alarms aiinto true alarms atand false alarms af line and .
then for each program component j jpi we run the static analysis without the jth component i.e.
j line .
the component jis considered to be harmless when the analysis which is unsound for jstill captures all the real bugs i.e.
a prime t at but reports fewer false alarms i.e.
a prime f af compared to the fully sound analysis line .
we collect feature vectors from all the harmless program components into the training set t n. iv .
i nstance analyses in this section we present a generic static analysis that is selectively unsound for loops and library calls as well as a set of features for them.
we have chosen loops and library calls because they are the main sources of false alarms from realworld static analyzers and thus often made unsound in practice e.g.
.
in the analysis loops are unrolled for a fixed number of times and library calls are simply ignored authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
f l e s s f c1 c2 s f c2 f c1 s f ifec 1c2 s f c1 unionsqf c2 f while lec s braceleftbigg fix x.s unionsqf c x ifl f c s otherwise f l libl s braceleftbigg s ifl s otherwise fig.
.
static analysis selectively unsound for loops and library calls as skips.
our aim is to selectively unroll and ignore loops and library calls respectively only when so is harmless.
we present two instances of the analysis one for an interval analysis and the other for a taint analysis.
the interval analysis is used to find out possible buffer overflow errors and the taint analysis is for detecting format string vulnerabilities i.e.
uses of unchecked user input as format string parameters of certain c functions such as printf .
the soundness of these instance analyses is tuned by our technique section iii where we used the same set of features designed for the generic analysis.
in section iv a we define the generic analysis with features.
section iv b and section iv c present two instances namely the interval analysis and the taint analysis.
a. a generic selectively unsound static analysis abstract semantics we consider a family of static analyses whose soundness is parametric for loops and library calls.
consider the following simple imperative language c l e c1 c2 ifec 1c2 whilelec l libl e n l alloc l e l e1 e2 l x e e1 a command is an assignment sequence if statement while statement or a call to an unknown library function.
in the program loops and library calls are labelled and the set of labels forms jin section iii a. the parameter space is the set of all subsets of program labels i.e.
j .
we assume that labels in the program are all distinct.
an expression is an integer n l value expression l array allocation allocl e whereeis the size of the array to be allocated andlis the label for the allocation site address of expression l or compound expression e e .
an l value expression is a variable x or array access expression e1 .
the abstract semantics of the analysis is defined in figure .
the analysis is parameterized by j a set of labels and is unsound for loops and library calls not included in .
the abstract semantics is defined by the semantic function f c s s where sis the domain of abstract states mapping abstract locations to abstract values i.e.
s l v. the analysis is generic in that abstract locations l and values v are unspecified.
they will be given for each analysis instance in subsequent subsections.
we assume that the abstract domain is accompanied by two functions l l s l and v e s v which compute abstract locations and values of given l value and r value expressions respectively.
the abstract semantics is standard except for the selective treatment of soundness.
for a loop statement whilelec l va r allocsite v i l a i l u z a l i i l x s x l e s v e s .
l e1 s a angbracketlefta angbracketright v e1 s .
v n s angbracketleft angbracketright v l s unionsqtext s l l l l s v alloc l e s angbracketleft l angbracketleftl v e s .
angbracketright angbracketright v l s angbracketleft l l s angbracketright v e1 e2 s v e1 s v e2 s fig.
.
abstract domain and semantics for interval analysis l va r allocsite v latticetop l l x s x l e1 s v e1 s .
v n s braceleftbigg angbracketleft latticetop angbracketright ifn t angbracketleft angbracketright otherwise v l s unionsqtext s l l l l s v allocl e s angbracketleft l angbracketright v l s angbracketleft l l s angbracketright v e1 e2 s v e1 s unionsqv e2 s fig.
.
abstract domain and semantics for taint analysis the analysis applies the usual sound fixed point computation fixis a pre fixpoint operator when the label lis included in the parameter .
when a loop is not included in the analysis ignores the loop and execute the body conly once i.e.
unrolling the loop once .
for unknown library calls the analysis conservatively updates the return location lwhenl is chosen i.e.
l .
otherwise we completely ignore the effect of the library call.
thus determines how soundly we analyze the program with respect to loops and unknown library calls.
for instance when j the analysis is maximally conservative for loops and library calls and when the analysis is completely unsound and ignores all of the loops and library calls in the program.
features we have designed a set of features for loops and library calls which can be used for instantiating the generic analysis above.
we examined open source c programs and identified features figure that describe common characteristics of loops and library calls in typical c programs.
the features are classified into syntactic and semantic features.
a syntactic feature describes a property that can be checked by a simple syntax analysis.
for example a syntactic feature characterizes loops whose conditional expressions involve constant values or library calls whose return type is an integer.
a semantic feature describes a property that requires a yet simple data flow analysis.
for instance a semantic feature for loops describes that the loop condition involves an expression whose value depends on some external input of the program c input external input authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
b c while a b ... to figure out that the value of bcomes from the external input we need to track the data flow of the external value.
each feature is either binary or numeric where all the numeric features are normalized to a real number between and based on relative quantities within a single program.
we designed those features with generality in mind so that the features can be reused for different analyses as much as possible.
note that the features in figure are not dependent on a particular static analysis but describe rather general syntactic and semantic program properties.
we use the same set of features for the interval and taint analyses and show that we can effectively tune the soundness of both analyses with the single set of features as shown in section v. b. instantiation interval analysis we first instantiate the generic analysis with the interval domain and use it to find out potential buffer overflow errors in the program.
the generic analysis left out the definitions of abstract locations l abstract values v and the evaluation functions for them landv .
these definitions for the interval analysis are given in figure .
an abstract location is either a variable or an allocation site.
an abstract value is a tuple of an interval i which is an abstraction of set of numeric values a pointsto set l and a set of abstract arrays a .
abstract array angbracketlefta o s angbracketrighthas the abstract location a l offset o i and size s i .
the evaluation function ltakes an lvalue expression and an abstract state and computes the set of abstract locations that the l value denotes.
the function v e s evaluates to the abstract value of eunders.
in the definition we write v e s .nfor thenth component of the abstract value of v e .
the analysis reports a buffer overflow alarm when the index of an array can be greater than its size according to the analysis results.
for example consider an expression arr .
suppose the analysis concludes that arr has an array of angbracketleftl angbracketright i.e.
an array of size and the interval value of idx is .
the analysis raises an alarm at the array expression because the index value may exceed the size of the array e.g.
when the size is 5and the index is .
c. instantiation taint analysis the second instance is a taint analysis for detecting format string vulnerabilities in c programs.
the abstract domain and semantics are given in figure .
the analysis combines a taint analysis and a pointer analysis and therefore an abstract location is still either a variable or an allocation site.
an abstract value is a tuple of a taint value and a points to set.
the taint domain consists of two abstract values latticetopis used to indicate that the value is tainted and represents untainted values.
for simplicity we model taint sources by a particular sett zof integers constant integer ngenerates a taint value latticetopifn t. in actual implementation latticetopis produced by function calls that receives user input such as fgets .t h eanalysis reports an alarm whenever a taint value is involved in a format string parameter of functions.
v. e xperiments we empirically show the effectiveness of our approach on selectively applying unsoundness only to harmless program components.
we design the experiments to address the following questions effectiveness of our approach how much is the selectively unsound analysis better than the fully sound or fully unsound analyses?
efficacy of oc svm does the one class classification algorithm outperform two class classification algorithms?
feature design how should we choose a set of features to effectively predict harmless program components?
time cost how does our technique affect cost of analysis?
a. setting implementation we have implemented our method on top of a static analyzer for full c. it is a generic analyzer that tracks all of numeric pointer array and string values with flow field and context sensitivity.
the baseline analyzer is unsound by design to achieve a precise bug finder it ignores complex operations e.g.
bitwise operations and weak updates and filters out reported alarms that are unlikely to be true.
we modified the baseline analyzer and created two instance analyzers an interval analysis and a taint analysis as described in section iv.
for each analysis we built a fully sound version baseline a uniformly unsound version u niform and a selectively unsound version s elective with respect to the soundness parameter in section iv.
in the interval analysis for buffer overflow errors u niform is set to be uniformly unsound for every loop and library call and s elective is selectively unsound for them.
in the taint analysis for format string vulnerabilities u niform is uniformly unsound for all the library calls but not for loops and s elective is selectively unsound for them.
to implement the oc svm classifier we used scikit learn machine learning package with the default setting of the algorithm specifically we used the radial basis function rbf kernel with .1and .
.
benchmark our experiments were performed on programs whose buggy program points are known.
they are the programs from open source software packages or previous work on static analysis evaluations .
table i and ii contain the list of the benchmark programs for the interval and the taint analysis respectively.
sm x bind x and ftp x are model programs from which contain buffer overflow vulnerabilities.
most of the bugs in the benchmarks are reported as critical vulnerabilities by authorities such as cve .
in total our benchmark programs have real buffer overflow bugs and real format string bugs.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
target feature property type description loopnull syntactic binary whether the loop condition contains nulls or not const syntactic binary whether the loop condition contains constants or not array syntactic binary whether the loop condition contains array accesses or not conjunction syntactic binary whether the loop condition contains or not idxsingle syntactic binary whether the loop condition contains an index for a single array in the loop idxmulti syntactic binary whether the loop condition contains an index for multiple arrays in the loop idxoutside syntactic binary whether the loop condition contains an index for an array outside of the loop initidx syntactic binary whether an index is initialized before the loop exit syntactic numeric the normalized number of exits in the loop size syntactic numeric the normalized size of the loop arrayaccess syntactic numeric the normalized number of array accesses in the loop arithinc syntactic numeric the normalized number of arithmetic increments in the loop pointerinc syntactic numeric the normalized number of pointer increments in the loop prune semantic binary whether the loop condition prunes the abstract state or not input semantic binary whether the loop condition is determined by external inputs gvar semantic binary whether global variables are accessed in the loop condition fininterval semantic binary whether a variable has a finite interval value in the loop condition finarray semantic binary whether a variable has a finite size of array in the loop condition finstring semantic binary whether a variable has a finite string in the loop condition lcsize semantic binary whether a variable has an array of which the size is a left closed interval lcoffset semantic binary whether a variable has an array of which the offset is a left closed interval absloc semantic numeric the normalized number of abstract locations accessed in the loop libraryconst syntactic binary whether the parameters contain constants or not void syntactic binary whether the return type is void or not int syntactic binary whether the return type is int or not cstring syntactic binary whether the function is declared in string.h or not insideloop syntactic binary whether the function is called in a loop or not args syntactic numeric the normalized number of arguments defparam semantic binary whether a parameter are defined in a loop or not useret semantic binary whether the return value is used in a loop or not uptparam semantic binary whether a parameter is update via the library call escape semantic binary whether the return value escapes the caller gvar semantic binary whether a parameters points to a global variable input semantic binary whether a parameters are determined by external inputs fininterval semantic binary whether a parameter have a finite interval value absloc semantic numeric the normalized number of abstract locations accessed in the arguments argstring semantic numeric the normalized number of string arguments fig.
.
features for typical loops and library calls in c programs b. effectiveness of our approach we evaluate the effectiveness of our approach by comparing precision of s elective to that of the other analyzers baseline and u niform .
we use cross validation a model validation technique for assessing how the results of a statistical analysis will generalize to new data.
we show the results from three types of cross validation leave one out fold and fold cross validation.
leave one out cross validation this is one of the most common types of cross validation which uses one observation as the validation set and the remaining observations as the training set.
in case of the interval analysis for example among the benchmark programs one program is used for validating and measuring the effectiveness of the learned model and the other remaining programs are used for training.
table i shows the results of the leave one out crossvalidation for the interval analysis.
we measured the number of true t and false f alarms from b aseline u niform and selective .
in terms of true alarms b aseline detects real bugs fnr .
in the programs.
while u niform detects only bugs fnr .
s elective effectively de baseline selective uniform program loc bug t f t f t f sm .5k sm .8k sm .7k sm .7k sm .7k sm .4k sm .1k bind .2k bind .7k bind .5k bind .1k ftp .8k ftp .5k ftp .5k polymorph .
.
.7k ncompress .
.
.9k .compress .0k spell .
.2k man .5h1 .7k .bzip2 .7k gzip .
.4a .2k bc .
.0k sed .
.
.9k total table i the number of alarms in interv al analysis authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
baseline selective uniform program loc bug t f t f t f mp3rename .
.6k ghostscript .
.5k uni2ascii .
.7k pal .
.
.4k shntool .
.
.3k sdop .
.9k latex2rtf .
.
.7k rrdtool .
.
.8k daemon .
.
.4k rplay .
.
.0k urjtag .
.2k a2ps .
.6k dico .
.3k total table ii the number of alarms in taint analysis tf050100two fold tfthree fold baseline selective uniform fig.
.
performance with different training and test data tects bugs fnr .
.
meanwhile b aseline reports false alarms fpr .
.1uniform on the other hand reports false alarms fpr .
which indicates alarms can be potentially removable by being unsound for loops and library calls.
among the alarms s elec tive can remove .
of them fpr .
.
table ii shows the results for the taint analysis.
in total baseline detects all of the real format string bugs in the programs while u niform detects only bugs fnr .
.
on the contrary s elective effectively detects bugs fnr .
.
meanwhile b aseline u niform and selective report and false alarms respectively.
that is among false alarms which can be potentially removable by being unsound for library calls s elective can remove .
of them.
the result implies that selectively applying unsoundness is also crucial for reducing fpr of the analysis.
for the interval analysis the fpr is .
for b aseline and .
for uniform whereas .
for s elective on average.
for the taint analysis the fpr is .
for b aseline .
for selective .
for u niform on average.
two and three fold cross validation next we evaluate the performance of the interval analysis with fold and fold cross validation.
the benchmark is randomly divided into or subsets that are equal size.
then one of them is used as the validation set and the others as the training sets.
we repeated this process ten times and reported the number of alarms for 1in practice eliminating these false alarms is extremely challenging in domain unaware static analysis because they arise from a variety of reasons e.g.
large recursive call cycles unknown library calls complex loops heap abstractions etc.each trial.
figure shows the number of true and false alarms for each trial of fold and fold cross validation.
the numbers are normalized with respect to the number of alarms produced by b aseline .
in total b aseline reported true alarms and false alarms.
s elective detected .
true alarms whereas u niform detected only .
true alarms in the fold cross validation.
compared to b ase line selective reduced .
false alarms while uniform reduced .
.
during the fold crossvalidation b aseline reported true alarms and false alarms.
in terms of true alarms s elective detected .
true alarms whereas u niform managed to detect only .
true alarms.
as for false alarms among .
false alarms that are reduced by u niform selective was able to reduce .
.
c. efficacy of oc svm in this section we justify the use of oc svm for learning common properties of harmless program components.
we compare the performance of s elective whose classifier is learned by oc svm to that of three other analyzers with a binary classifier and two random classifiers respectively.
let b inary be the analyzer with a binary classifier.
we use c svm for the binary classifier which is a support vector machine based binary classification algorithm .
it learns two classes of training data i.e.
a set of harmless components and the complement set and then decides whether a new input is harmless or not.
in these experiments we used the interval analyzer with leave one out cross validation.
rand a and r and b are the analyzers with random classifiers that are built and used for the comparison.
r and a randomly classifies components as harmless with the probability of .
.
stochastically a half of loops and library calls are selected as harmless.
r and b randomly classifies components as harmless with the same probability of the oc svm.
we ran each analyzer times and measured the number of alarms for each trial.
figure compares the number of true and false alarms produced by s elective b inary r and a and r and b for trials.
b inary reports more true alarms than s elective binary reports true alarms whereas s elective reports true alarms.
however using b inary considerably sacrifices the precision it reports false alarms whereas selective reports only .
the results from r and a and rand b are also inferior to s elective r and a reports .
false alarms and .
true alarms and r and b reports .
false alarms with .
true alarms on average.
the result shows s elective clearly outperforms the other classifiers.
s elective is more precise than b inary indicating that the anomaly detection by oc svm is more suitable to find harmless components than the binary classification.
also s elective always detects more bugs and reports less false alarms than other analyzers with the random classifiers.
despite the fact that r and b detects more bugs than r and a authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
true alarms trialsselective binary randa randb false alarms trialsselective binary randa randb fig.
.
comparison between s elective b inary r and a and r and b it is still insignificant since both of them are much more imprecise than our system.
d. feature design wining features the learned classifier tells us which feature is most useful for learning harmless unsoundness.
the features we used capture general characteristics of harmless program components.
in order to determine the ordering of features we used information gain which is the expected reduction in entropy when a feature is used to classify training examples in classification low entropy i.e.
impure data is preferred .
the results show that harmless loops tend to have pointers iteratively accessing ptrinc arrays array or strings finstring with loop conditions that compare array contents with null null or constant values const .
these features collectively describe loops like the first example loop in section ii.
the result also shows that most harmless library calls for the interval analysis return integer values int and manipulate strings cstring .
this is because our interval analyzer aggressively abstracts string values so unsound treatment of string libraries e.g.
strlen strcat is likely to improve the analysis precision.
for the taint analysis the results show that library calls with less arguments args and abstract locations absloc e.g.
random strlen are likely to be irrelevant to propagation of user inputs compared to ones with more arguments e.g.
fread recv .
different feature sets we measured the performance of the classifier with less features in three ways with syntactic features only with semantic features only and with randomly chosen half of the features.
for the interval analyzer the classifier learned with only syntactic features reported more bugs but more false alarms than the classifier with all features the classifier with only semantic features reported more false alarms and missed more bugs and the classifier with half of the features reported more false alarms and missed more bugs on average.
e. time cost we measured how long it takes to run each analysis on our benchmark programs and compare it with the time that ourselective unsound analysis takes.
for the benchmark programs in table i the sound interval analysis b aseline took .
seconds for analyzing all the listed programs u niform only took .
seconds reducing the total time by .
seconds .
.
s elective took .
seconds reducing the total time by .
seconds .
.
r and a and r and b took longer than s elective .
and .
seconds respectively.
in summary s elective takes less time than b aseline rand a and r and b. f .
discussion as addressed in the experiments our technique may miss some true alarms which can be detected by the fully sound analysis or fail to avoid some false alarms which are not reported by the fully unsound analysis.
in this section we discuss why these limitations occur and how to overcome.
remaining false alarms compared to the fully unsound analysis our technique reports more false alarms.
it is mainly because reporting the false alarms is inevitable in order to detect true alarms.
consider the following example program excerpted from sm 1size positive input 2arr malloc size 4for i i size i 5arr ... buffer access 6arr ... buffer access by soundly analyzing the loop the analysis reports an alarm for the buffer overflow bug at line at the cost of a false alarm at line .
the unsound analysis removes the false alarm but it also fails to report the true alarm.
our selective method may decide to analyze such a loop soundly in order to detect the bug even though reporting the false alarm is inevitable.
we found that these inevitable false alarms are the primary reason for s elective to report more false alarms compared to uniform .
for example when analyzing sm in our benchmark programs five among six false alarms are inevitable.
in order to remove such false alarms in a harmless way we need a more fine grained parameter space for soundness so that we can apply different degrees of soundness to different statements in a single loop which would be an interesting future direction to investigate.
missing true alarms compared to the fully sound analysis our technique reports less true alarms.
it is mainly because the bugs are involved in typically harmless loops.
consider the following code snippet from man .5h1 1char arr string 2size positive input 3for i i size i 4skip 5arr buffer access 7for i !arr i buffer access 8skip the two buffer access expressions both contain buffer overflow bugs.
however our technique detects the first bug but not the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
second.
it is because it classifies the second loop as harmless it learns that loops that iterate constant strings are likely to be harmless.
however we found that most of the missing bugs share the root causes with other bugs detected by our technique.
for instance in the above example fixing the first bug at line automatically fixes the second one.
in our case therefore missing true alarms is in fact not a huge drawback in terms of practicability.
vi.
r ela ted work a. unsoundness in static analysis existing unsound static analyses are all uniformly unsound e.g.
.
in addition to their unsound handling of every loop and library call in a given program they consider only a specific branch of all conditional statements in a program deactivate all recursive calls or ignore all the possible inter procedural aliasing .
as shown in this paper these uniform approaches have a considerable drawback it significantly impairs the capability of detecting real bugs.
this paper is the first to tackle this problem and presents a novel approach of selectively employing unsoundness only when it is likely to be harmless.
mangal et al.
proposed an interactive system to control the unsoundness of static analysis online based on the user feedback .
they define a probabilistic datalog analysis with hard and unsound soft rules where the goal of the analysis is to find a solution that satisfies all of the hard rules while maximizing the weight of the satisfied soft rules.
the feedback from analysis users is encoded as soft rules and based on the feedback the analysis is re run and produces a report that optimizes the updated constraints.
in our setting non datalog however it is not straightforward to tune the unsoundness from user feedbacks.
instead our approach automatically learns harmless unsoundness and selectively applies unsound strategies depending on the different circumstances.
our goal is different from the existing work on unsoundness by christakis et al.
which empirically evaluated the impact of unsoundness in a static analyzer using runtime checking.
they instrumented programs with the unsound assumptions of the analyzer and check whether the assumptions are violated at runtime.
on the contrary we introduce a new notion of selective unsoundness and evaluate its impact in terms of the number of true alarms and false alarms reported.
b. parametric static analysis our work uses a parametric static analysis in a novel way where the parameters specify the degree of soundness not the precision setting of the analysis.
the existing parametric static analyses have been focused on balancing the precision and the cost of static analysis .
they infer a cost effective abstraction for a newly given program by iterative refinements impact pre analyses or learning from a codebase .
on the other hand our goal is to find a soundness parameter striking the right balance between existing fully sound and unsound approaches.
furthermore the existing techniques for deriving static analysis parameters e.g.
cannot be used for our purpose since it is simply impossible to automatically judge truth and falsehood of alarms.
we address this problem by designing a supervised learning method that learns a strategy from a given codebase with known bugs.
because we have labelled data using the learning algorithm via black box optimization is inappropriate.
instead we use an off the shelf learning method which uses the gradient based optimization algorithm and works much faster than the black box optimization approach.
c. statistical alarm filtering our approach is orthogonal to statistical post processing of alarms .
the post processing e.g.
ranking approach aims to remove false positives reported false alarms .
instead our approach aims to remove false negatives unreported true alarms .
from the undiscerning uniformly unsound analysis that will have too many unreported true alarms we tune it to be selectively unsound.
these post processing systems are also complementary to our approach.
because in practice any realistic bug finding static analyzer cannot but be unsound for the analysis precision and scalability our technique provides a guide on how to design an unsound one.
the existing post processing techniques e.g.
ranking can be anyway applied to the results from such selectively unsound static analyzers.
vii.
c onclusion in this paper we presented a novel approach for selectively employing unsoundness in static analysis.
unlike existing uniformly unsound analyses our technique applies unsoundness only when it is likely to be harmless i.e.
in a way to reduce the number of false alarms while retaining true alarms .
we proposed a learning based method for automatically tuning the soundness of static analysis in such a harmless way.
the experimental results showed that the technique is effectively applicable to two bug finding static analyzers and reduces their false negative rates while retaining their original precision.
acknowledgment we thank jonggwon kim and woosuk lee for their implementation of the taint analysis and mina lee for comments on an early version of the paper.
this work was partly supported by samsung electronics samsung research funding center of samsung electronics no.srfc it1502 and institute for information communications technology promotion iitp grant funded by the korea government msip no.b071716 development of homomorphic encryption for dna analysis and biometry authentication and no.r0190 development of vulnerability discovery technologies for iot software security .
this work was also supported by bk21 plus for pioneers in innovative computing dept.
of computer science and engineering snu funded by national research foundation of korea nrf 21a20151113068 and basic science research program through the national research foundation of korea nrf funded by the ministry of science ict future planning nrf 2016r1c1b2014062 .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.