mit open access articles alloy a general purpose higher order relational constraint solver the mit faculty has made this article openly available.
please share how this access benefits you.
your story matters.
as published .
s10703 publisher springer science and business media llc persistent url version author s final manuscript final author s manuscript post peer review without publisher s formatting or copy editing terms of use creative commons attribution noncommercial share alike alloy a higher order relational constraint solver aleksandar milicevic joseph p. near eunsuk kang daniel jackson massachusetts institute of technology cambridge ma usa aleks jnear eskang dnj csail.mit.edu abstract the last decade has seen a dramatic growth in the use of constraint solvers as a computational mechanism not only for analysis and synthesis of software but also at runtime.
solvers are available for a variety of logics but are generally restricted to first order formulas.
some tasks however most notably those involving synthesis are inherently higher order these are typically handled by embedding a first order solver such as a sat or smt solver in a domain specific algorithm.
using strategies similar to those used in such algorithms we show how to extend a first order solver in this case kodkod a model finder for relational logic used as the engine of the alloy analyzer so that it can handle quantifications over higher order structures.
the resulting solver is sufficiently general that it can be applied to a range of problems it is higher order so that it can be applied directly without embedding in another algorithm and it performs well enough to be competitive with specialized tools on standard benchmarks.
although the approach is demonstrated for a particular relational logic the principles behind it could be applied to other first order solvers.
just as the identification of first order solvers as reusable backends advanced the performance of specialized tools and simplified their architecture factoring out higher order solvers may bring similar benefits to a new class of tools.
categories and subject descriptors i. .
d. .
very high level languages d. .
constraint and logic languages general terms logic higher order alloy languages keywords constraint solving higher order logic relational logic program synthesis alloy .
introduction as constraint solvers become more capable they are increasingly being applied to problems previously regarded as intractable.
program synthesis for example requires the solver to find a single program that computes the correct output for all possible inputs.
this quantifier pattern is aparticularly difficult instance of higher order quantification and no existing general purpose constraint solver can reliably provide solutions for problems of this form.
instead tools that rely on higher order quantification use ad hoc methods to adapt existing solvers to the problem.
a popular technique for the program synthesis problem is called cegis counterexample guided inductive synthesis and involves using a first order solver in a loop first to find a candidate program and second to verify that it satisfies the specification for all inputs.
if the verification step fails the resulting counterexample is transformed into a constraint that is used in generating the next candidate.
in this paper we present alloy a general purpose higher order bounded constraint solver based on the alloy analyzer .
alloy is a specification language combining first order logic with relational algebra the alloy analyzer performs bounded analysis of alloy specifications.
alloy admits higher order quantifier patterns and uses a general implementation of the cegis loop to perform bounded analysis.
it retains the syntax of alloy and changes the semantics only by expanding the set of specifications that can be analyzed making it easy for existing alloy users to adopt.
to solve constraints alloy first finds a candidate solution by changing the universal quantifier into an existential and solving the resulting first order formula.
then it verifies that candidate solution by attempting to falsify the original universal formula again a first order problem if verification fails alloy adds the resulting counterexample as a constraint to guide the search for the next candidate and begins again.
when verification succeeds the candidate represents a solution to the higher order quantification and can be returned to the user.
to our knowledge alloy is the first general purpose constraint solver capable of solving formulas with higherorder quantification.
existing solvers either do not admit these quantifier patterns or fail to produce a solution in most cases.
alloy by contrast is both sound and complete for the given bounds.
and while alloy is unlikely to scale as well as purpose built solvers for particular higher order applications it uses a backend model finder that performs incremental solving making it more efficient than naive approaches.we have evaluated alloy on a variety of case studies taken from the work of other researchers.
in the first we used alloy to solve classical higher order np complete graph problems like max clique and found it to scale well enough for uses in teaching fast prototyping modeling and bounded verification.
in the second we encoded a subset of the sygus program synthesis benchmarks and found that while state of the art synthesis engines are faster alloy at least beats all the reference synthesizers provided by the competition organizers.
the contributions of this paper include the recognition of higher order solving as the essence of a range of computational tasks including synthesis a framework for extending a first order solver to the higher order case consisting of the design of datatypes and a general algorithm comprising syntactic transformations skolemization conversion to negation normal form etc.
and an incremental solving strategy a collection of case study applications demonstrating the feasibility of the approach in different domains including synthesis of access control policies synthesis of code execution of np hard algorithms and bounded verification of higher order models and showing encouraging performance on standard benchmarks the release of a freely available implementation for others to use comprising an extension of alloy .
.
examples .
classical graph algorithms classical graph algorithms have become prototypical alloy examples showcasing both the expressiveness of the alloy language and the power of the alloy analyzer.
many complex problems can be specified declaratively in only a few lines of alloy and then in a matter of seconds fully automatically animated for graphs of small size by the alloy analyzer.
this ability to succinctly specify and quickly solve problems like these algorithms that would be difficult and time consuming to implement imperatively using traditional programming languages has found its use in many applications including program verification software testing fast prototyping as well as teaching .
for a whole category of interesting problems however the current alloy engine is not powerful enough.
those are the higher order problems for which the specification has to quantify over relations rather than scalars.
many well known graph algorithms fall into this category including finding maximum cliques max cuts minimum vertex covers and various coloring problems.
in this section we show such graph algorithms can be specified and analyzed using the new engine implemented in alloy .suppose we want to check tur n s theorem one of the fundamental results in graph theory .
tur n s theorem states that a k free graph with nnodes can maximally have k n2 2kedges.
a graph is k free if it contains no clique withk 1nodes a clique is a subset of nodes in which every two nodes are connected by an edge .
figure shows how tur n s theorem might be formally specified in alloy.
first a signature is defined to represent the nodes of the graph line .
next the clique property is embodied in a predicate lines for a given edge relation and a set of nodes clq it asserts that every two different nodes in clqare connected by an edge the maxclique predicate lines additionally asserts that no other clique contains more nodes.
having defined maximum cliques in alloy we can proceed to formalize tur n s theorem.
the turan command lines asserts that for all possible edge relations that are symmetric and irreflexive line if the max clique in that graph has knodes k mclq the number of selected edges e edges .div must be at most k n2 2k the number of tuples in edges is divided by because the graph in setup of the theorem in undirected .
running the turan command was previously not possible.
although the specification as given in figure is allowed by the alloy language trying to execute it causes the analyzer to immediately return an error analysis cannot be performed since it requires higher order quantification that could not be skolemized .
in alloy in contrast this check can be automatically performed to confirm that indeed no counterexample can be found within the specified scope.
the scope we used nodes ints from to allows for all possible undirected graphs with up to nodes.
the upper bound for ints was chosen so that it ensures that the formula for computing the maximal number of edges k n2 2k never overflows for n which implies k .
the check completes in about seconds.
to explain the analysis problems that higher order quantifiers pose to the standard alloy analyzer and how those problems are tackled in alloy we look at a simpler task finding an instance of a graph with a subgraph satisfying the maxclique predicate.
the problematic quantifier in this case is the inner noclq2 set node constraint which requires checking that for all possible subsets of node not one of them is a clique with more nodes than the given set clq.
a direct translation into propositional logic and the current sat based backend would require the analyzer to explicitly and upfront enumerate all possible subsets of node which would be prohibitively expensive.
instead alloy implements the cegis approach.
to satisfy the maxclique predicate alloy proceeds in the following steps .
first it finds a candidate instance by searching for a clique clqandonly one set of nodes clq2 thatis not a clique larger than clq.
a possible first candidate is given in figure a the clique nodes are highlighted in green .1some sig node between every two nodes there is an edge 3pred clique all disj n1 n2 clq n1 n2 inedges no other clique with more nodes 7pred maxclique clique noclq2 set node clq2!
clq and clique and clq2 clq symmetric and irreflexive pred edgeprops edges inedges and noedges iden max number of edges in a k free graph with nnodes is k n2 2k check turan all edges node node edgeprops implies some mclq set node maxclique let n node k mclq e edges .div e k.minus .mul .mul .div .div for 7but .. int figure .
specification of turan s theorem for automatic checking in alloy .
a a maxclique candidate b a counterexample for a c final maxclique instance d a maxmaxclique instance figure .
automatically generated sample instances satisfying themaxclique andmaxmaxclique predicates.
at this point clq2 could have been anything that is either not a clique or not larger than clq.
.
next alloy attempts to falsify the previous candidate by finding again only one set of nodes clq2 but this time such that clq2 isa clique in larger than clq for the exact concrete graph found in the previous step.
in this case it finds one such counterexample clique red nodes in figure b refuting the proposition that clqfrom the first step is a maximum clique.
.
alloy continues by trying to find another candidate clique encoding the knowledge gained from the previous counterexample explained in more detail in section and to prune the remainder of the search space.
after a couple of iterations it finds the candidate in figure c which cannot be refuted so it returns that candidate as a satisfying solution.
alloy handles higher order quantifiers in a generic and model agnostic way meaning that it allows higher order quantifiers to appear anywhere where allowed by the alloy syntax and does not require any special idiom to be followed.
once written the maxclique predicate despite containing a higher order quantification can be used in other parts of the model like any other predicate just as we used it to formulate and check tur n s theorem.
using a higher order predicate inside another higherorder predicate is also possible.
it might not be obvious that theturan check contains nested higher order quantifiers so a simpler example would be finding a max clique with a maximum sum of node values sig node val one int auxiliary function returns the sum of all node values fun valsum int sum n nodes n.val clq is a max clique with maximum sum of node values pred maxmaxclique maxclique noclq2 set node clq2!
clq and maxclique and valsum valsum run maxmaxclique for running the maxmaxclique command spawns nested cegis loops every candidate instance and counterexample generated in the process can be opened and inspected in the standard alloy visualizer.
a sample generated instance is shown in figure d .
.
policy synthesis policy design and analysis is an active area of research.
a number of existing tools use a declarative language to specify policies and a constraint based analysis to verify them against a high level property.
in this section we demonstrate how alloy can be used to automatically synthesize a policy that satisfies given properties.
figure shows an alloy model that describes the problem of grade assignment at a university based on the running example from .
a policy specification contains three basic concepts roles actions and resources .
a system consists of a set of users each having one or more roles and performing some actions on a set of resources.
a policy acl is a set of tuples from role toaction toresource describing a set of allowed actions.
for example a policy containing only a single tuple faculty assign extgrade means that a user may assign an external grade only if it has the faculty role.
there are two desirable properties over this system students should not be able to assign external grades and no user should be able to both assign and receive external grades.
a policy is considered valid if and only if when quantified over every possible combination of user roles and behaviors it ensures that the properties hold.
this higherorder property is encoded in the valid predicate.running alloy to search for an instance satisfying the valid predicate completes in about .
seconds and retuns anempty policy which is technically valid but not very useful since it allows no actions to be performed by anyone!
.
fortunately we can leverage the higher order featur of alloy to synthesize more interesting policies.
for example additional lines of alloy are enough to describe the most permissive policy as a policy that is valid such that no other valid policy has more tuples in it lines .
it takes about .
seconds to generate one such policy faculty receive extgrade faculty assign resource student receive resource student assign intgrade ta receive resource ta assign intgrade this policy provides a starting point for further exploration of the policy space.
the designer may decide for example that students should not be able to assign intgrade add another property and then repeat the synthesis process.
basic signatures 2abstract sig resource 3abstract sig action abstract sig role sig user performs describes the behavior of users 6pred enforce acl role action resource roles user role performs user action resource all u user a action r resource u can perform a on r only if allowed by acl u a r inperforms some ro u.roles ro a r inacl domain specific concepts one sig faculty student ta extends role one sig intgrade extgrade extends resource one sig assign receive extends action properties pred prop1 roles user role performs user action resource no student can assign external grade nou user u.roles student and assign extgrade inu.performs pred prop2 roles user role performs user action resource no user can both receive and assign external grades nou user assign receive inu.performs.extgrade assumption no user can both be a faculty and a student ta pred nodualroles nou user faculty inu.roles and some student ta u.roles acl satisfies properties over every user role and behavior pred valid all roles user role performs user action resource enforce and nodualroles implies prop1 and prop2 acl allows the most number of actions while being valid pred mostpermissive valid noacl role action resource acl !
acl and valid and acl acl figure .
grade assignment policy in alloy .
background and key ideas skolemization many first order constraint solvers allow some form of higher order quantifiers to appear at the language level.
part of the reason for this is that in certain cases quantifiers can be eliminated in a preprocessing stepcalled skolemization .
in a model finding setting every toplevel existential quantifier is eliminated by introducing askolem constant for the quantification variable and replacing every occurrence of that variable with the newly created skolem constant.
for example solving the following higher order formula some s set univ s means finding one set swith more than elements i.e.
sin univ s which is first order and thus solvable by general purpose constraint solvers.
throughout following the convention of the alloy analyzer skolem constants will be identified with a dollar sign as a prefix.
cegis counterexample guided inductive synthesis is an approach for solving higher order synthesis problems which is extended in alloy to the general problem of solving higher order formulas.
the goal of cegis is to find one instance e.g.
a program that satisfies some property for all possible environments e.g.
input values some p program all env var int spec .
step search.
since this formula is not immediately solvable by today s state of the art solvers the cegis strategy is to first find a candidate program and oneenvironment for which the property holds some p program some env var int spec .
this formula is amenable to automated first order constraint solving as both quantifiers can now be skolemized.
step verification.
if a candidate is found the next step is to check whether that candidate might actually satisfy the specification for all possible environments.
the verification condition thus becomes all env var int spec .
the outer quantifier from the previous step some p program is not present in this formulation because the verification condition is to be checked for exactly the candidate program generated in step the concrete program p .
this check is typically done by refutation that is by trying to find a counterexample for which the verification condition does not hold.
negating the verification condition and pushing the negation through to the leaf nodes changes the quantifier from alltosome which becomes skolemizable resulting in a first order formula that is now easily solved some env var int not spec step induction.
the previous step either verifies the candidate or returns a counterexample a concrete environment for which the program does not satisfy the spec.
instead of simply continuing the search for some other candidate program and repeating the whole procedure a key idea behind the cegis method is adding an encoding of the counterexample to the original candidate condition some p program some env var int spec spec consequently all subsequent candidate programs will have to satisfy the spec for the concrete environment env cex.
this strategy in particular tends to be very effective at reducing the search space and improving the overall scalability.
cegis for a general purpose solver.
existing cegisbased synthesis tools implement this strategy internally optimizing for the target domain of synthesis problems.
a key insight of this paper is that the cegis strategy can be implemented generically and efficiently inside a general purpose constraint solver .
for an efficient implementation however it is important that such a solver be optimized with the following features partial instances .
the verification step requires that the verification condition be solved against the previously discovered candidate being able to explicitly set that candidate as a part of the solution to the verification problem known upfront i.e.
as a partial instance tends to be significantly more efficient than encoding the candidate with constraints .
incremental solving .
except for one additional constraint the induction step solves exactly the same formula as the search step.
many modern sat solvers already allow new constraints to be added to already solved propositional formulas making subsequent runs more efficient because all previously learned clauses are readily reusable .
atoms as expressions .
the induction step needs to be able to convert a concrete counterexample given in terms of concrete atoms i.e.
values for each variable to a formula to be added to the candidate search condition.
all atoms therefore must be convertible to expressions.
this is trivial for sat solvers but requires extra functionality for solvers offering a richer input language.
skolemization .
skolemizing higher order existential quantifiers is necessary for all three cegis steps.
we formalize our approach in section assuming availability of a first order constraint solver offering all the features above.
in section we present our implementation as an extension to kodkod a first order relational constraint solver already equipped with most of the required features .
.
semantics we give the semantics of our decision procedure for bounded higher order logic as implemented in alloy in two steps.
first we formalize the translation of a boolean possibly higher order formula into a proc datatype instance corresponding to an appropriate solving strategy next we formalize the semantics of proc satisfiability solving.
figure gives an overview of all syntactic domains used throughout this section.
we assume the datatypes in fig a alloy syntactic domains qp qp forall quant pexists proc proc fol form formula or disjs proc ea conj fol qps qp b solver data types mult one set decl decl mult mult var expr quantop binop leftrightline formula quant op quantop decl decl body formula binform op binop lhs rhs formula notform form formula ... expr ... relational expressions irrelevant here figure .
overview of the syntactic domains.
a semantic functions t formula proc top level formula translation s proc instance proc evaluation solving formula proc intermediate formula translation proc proc proc proc composition conjunction proc proc proc proc composition disjunction b functions exported by first order solver solve formula instance option first order solver eval instance expr value evaluator replace formula expr value formula nnf formula formula nnf conversion skolemize formula formula skolemization formula formula formula conjunction formula formula formula disjunction true formula true formula false formula false formula c built in functions fold a e a a e a functional fold reduce a e a e a fold w o init value map e t e t functional map length e int list length hd e e list head tl e e list tail e e e list concatenation e e e list cross product fail string void runtime error figure .
overview of used functions a semantic functions b functions provided by the first order solver c built in functions.
ure b are provided by the solver on top of these basic datatypes alloy defines the following additional datatypes fol a wrapper for a first order formula that can be solved in one step by the solver or a composite type representing a disjunction of proc s ea a composite type representing a conjunction of a first order formula and a number of higher order universal quantifiers each enclosed in a qpdatatype .
the intention of the qpdatatype is to hold the original universally quantified formula the forall field and a translation of the same formula but quantified existentially the pexists field the latter is later used to find candidate solutions formalized in section .
.
figure a lists all the semantic functions defined in this paper.
the main two are translation of formulas into proc s t defined in figure and satisfiability solving s defined in figure .
relevant functions exported by the solver are given in figure b while other functions assumed to be provided by the host programming language are summarized in figures c .
for simplicity of exposition we decided to exclude the treatment of bounds from our formalization as it tends to be mostly straightforward we will however come back to this point and accurately describe how the bounds are constructed before a solver invocation.
syntax note.
our notation is reminiscent of ml.
we use the .
syntax to refer to field values of datatype instances.
if the left hand side in such constructs resolves to a list we assume the operation is mapped over the entire list e.g.
ea.qps.forall is equivalent to map q q forall ea.qps .
.
translation of formulas into proc objects the top level translation function t figure line ensures that the formula is converted to negation normal form nnf and that all top level existential quantifiers are subsequently skolemized away before the formula is passed to the function.
conversion to nnf pushes the quantifiers towards the roots of the formula while skolemization eliminates top level existential quantifiers including the higherorder ones .
alloy aggressively uses these techniques to achieve completeness in handling arbitrary formulas.
translating a binary formula which must be either a conjunction or disjunction since it is in nnf involves translating both left hand and right hand sides and composing the resulting proc s using the corresponding composition operator for conjunction and for disjunction lines .
an important difference between the two cases however is that a disjunction demands that both sides be skolemized again thus the use of tinstead of since they were surely unreachable by any previous skolemization attempts.
this ensures that any higher order quantifiers found in a clause of a disjunction will eventually either be skolemized or converted to an eaproc .
a first order universal quantifier determined by d.mult being equal to one whose body is also first order line is simply enclosed in a fol proc line .
otherwise an eaproc is returned wrapping both the original formula d divides.alt0f and the translation of its existential counterpart p tj d divides.alt0fk .
the existential version is later used to findt formula proc .tjfk jskolemize nnf fk formula proc .
jf1 f2k tjf1k tjf2k .
jf1 f2k jf1k jf2k .
j d divides.alt0fk fail can t happen .
j d divides.alt0fk let p tj d divides.alt0fkin .
ifd.mult isone pisfol then .
fol d divides.alt0f .
else .
ea fol true .
jfk fol f proc proc proc .p1 p2 matchp1 p2with .
fol fol fol p1.form p2.form .
fol or or map p p1 p p .disjs .
fol ea ea p1 p2.conj p2.qps .
or or or map p q p q p .disjs p2.disjs .
or ea or map p p p1 p .disjs .
ea ea ea p1.conj p2.conj p1.qps p2.qps .
p2 p1 proc proc proc .p1 p2 matchp1 p2with .
fol fol fol p1.form p2.form .
fol or or map p p1 p p .disjs .
fol ea or .
or or or p1.disjs p2.disjs .
or ea or p1.disjs .
ea ea or .
p2 p1 figure .
translation of boolean formula s toproc s. candidate solutions which satisfy the body for some binding ford whereas the original formula is needed when checking whether generated candidates also satisfy the property forallpossible bindings i.e.
the verification condition .
in all other cases the formula is wrapped in fol line .
.
.
composition of proc s composition of proc s is straightforward for the most part directly following the distributivity laws of conjunction over disjunction and vice versa.
the common goal in all the cases in lines is to reduce the number of proc nodes.
for example instead of creating an ornode for a disjunction of two first order formulas line a folnode is created containing a disjunction of the two.
other interesting cases involve the eaproc .
a conjunction of two eanodes can be merged into a single eanode line as can a conjunction of a foland an eanode line .
a disjunction involving aneanode always results in the creation of a new ornode.s proc instance option .sjpk matchpwith .
fol solvep.form .
or iflengthp.disjs then none else match sjhdp.disjskwith .
none sjor tlp.disjs k .
some inst some inst .
ea letpcand fold p.conj p.qps.pexists in .
match sjpcand kwith .
none none .
some cand letfcheck fold true p.qps.forall in .
match sjtj fcheck kkwith .
none some cand .
some cex fun repl q replace q.body q.decl.var eval cex q.decl.var .
letf cex map repl p.qps.forall in .
letfcex fold true f cexin .
sjpcand tjfcexkk figure .
satisfiability solving for different proc s. the resulting instance object encodes the solution if one is found.
.
satisfiability solving the procedure for satisfiability solving is given in figure .
a first order formula enclosed in fol is given to the solver to be solved directly in one step line .
anor proc is solved by iteratively solving its disjuncts lines .
an instance is returned as soon as one is found otherwise none is returned.
the procedure for the eaproc s implements the cegis loop lines .
the candidate search condition is a conjunction of the first order p.conjproc and all the existential proc s fromp.qps.pexists line .
if solving the candidate condition returns no instance the formula as a whole is unsatisfiable line .
if a candidate is found the procedure checks whether that candidate actually satisfies all possible bindings for the involved quantifiers.
the verification condition fcheck becomes a conjunction of all original universal quantifiers within this ea line .
the procedure proceeds by trying to refute this proposition that is by attempting to satisfy the negation of the verification condition line .
if the refutation step is unsuccessful line the previously discovered candidate is returned as a satisfying instance for the formula as a whole otherwise the search continues by asking for another candidate which additionally satisfies the returned counterexample line .
encoding the counterexample into a formula boils down to obtaining a concrete value that each quantification variable has in that counterexample by means of calling the evalfunction exported by the solver and embedding that value directly in the body of the corresponding quantifier lines .
.
treatment of bounds bounds are a required input of any bounded analysis for an analysis involving structures the bounds may include not only the cardinality of the structures but may also indicate that a structure includes or excludes particular tuples.
suchbounds serve not only to finitize the universe of discourse and the domain of each variable but may also specify a partial instance that embodies information known upfront about the solution to the constraint.
if supported by the solver specifying the partial instance through bounds as opposed to enforcing it with constraints is an important mechanism that generally improves scalability significantly.
although essential the treatment of bounds in alloy is mostly straightforward including it in the above formalization figures and would only clutter the presentation and obscure the semantics of our approach.
instead we informally but precisely provide the relevant details in the rest of this section.
bounds may change during the translation phase by means of skolemization every time an existential quantifier is skolemized a fresh variable is introduced for the quantification variable and a bound for it is added.
therefore we associate bounds with proc s as different proc s may have different bounds.
whenever a composition of two proc s is performed the resulting proc gets the union of the two corresponding bounds.
during the solving phase whenever the solve function is applied line bounds must be provided as an argument we simply use the bounds associated with the input proc instance p .
when supplying bounds for the translation of the verification condition tj fcheck k line it is essential to encode the candidate solution cand as a partial instance to ensure that the check is performed against that particular candidate and not some other arbitrary one.
that is done by bounding every variable from p.bounds to the exact value it was given in cand fun add bound b var b r uni21a6eval cand var bcheck fold add bound p bounds p bounds variables finally when translating the formula obtained from the counterexample fcex to be used in a search for the nextcandidate line the same bounds are used as for the current candidate pcand.bounds .
.
implementation we implemented our decision procedure for higher order constraint solving as an extension to kodkod .
kodkod the backend engine used by the alloy analyzer is a bounded constraint solver for relational first order logic thus variable as used previously translates to relation in kodkod and value translates to tuple set .
it works by translating a given relational formula together with bounds finitizing relation domains into an equisatisfiable propositional formula and using an of the shelf sat solver to check its satisfiability.
the alloy analyzer delegates all its model finding constraint solving tasks to kodkod.
no change was needed to the alloy analyzer s existing translation from the alloy modeling language to the intermediate logic of kodkod loosening kodkod s restrictions on higher order quantification exposes the new functionality immediately at the level of alloy models.
the official kodkod distribution already offers most of the required features identified in section .
while efficient support for partial instances has always been an integral part of kodkod only the latest version .
comes with incremental sat solvers and allows new relational constraints as well as new relations to be added incrementally to previously solved problems.
by default kodkod performs skolemization of top level existential quantifiers including higher order ones the semantics of our translation from boolean formulas to proc s ensures that all quantifiers regardless of their position in the formula eventually get promoted to the top level where they will be subject to skolemization.
conversion from atoms to expressions however was not available in kodkod prior to this work.
kodkod imposes a strict separation between the two abstractions so allows it to treat all atoms from a single relation domain as indistinguishable from each other which helps generate a stronger symmetry breaking predicate.
since encoding each counterexample back to the candidate condition is absolutely crucial for cegis to scale we extended kodkod with the ability to create a singleton relation for each declared atom after which converting atoms back to expressions relations becomes trivial.
we also updated the symmetry breaking predicate generator to ignore all such singleton relations that are not used in the formula being solved.
as a result this modification does not seem to incur any performance overhead we ran the existing kodkod test suite with and without the modification and observed no time difference in both cases the total time it took to run tests was around 230s .
aside from the fact that it is written in java our implementation directly follows the semantics defined in figures and .
additionally it performs the following important op timizations the constructor for ordata type finds all fol proc s in the list of received disjuncts and merges them into one and it uses incremental solving to implement line from figure whenever possible.
.
case study program synthesis program synthesis is one of the most popular applications of higher order constraint solving.
the goal of program synthesis is to produce a program that satisfies a given high level specification.
synthesizers typically also require a loose definition of the target program s structure and most use an ad hoc cegis loop relying on an off the shelf first order constraint solver to generate and verify candidate programs.
the sygus syntax guided synthesis project has proposed an extension to smtlib for encoding program synthesis problems.
the project has also organized a competition between solvers for the format and provides three reference solvers for testing purposes.
we encoded a subset of the sygus benchmarks in alloy to test its scalability.
these benchmarks have a standard format are well tested and allow comparison to the performance of the reference solvers making them a good target for evaluating alloy .
we found that alloy scales better than all three of the reference solvers.
.
example encoding to demonstrate our strategy for encoding program synthesis problems in alloy we present the alloy specification for the problem of finding a program to compute the maximum of two numbers the max benchmark .
the original sygus encoding of the benchmark is reproduced in figure .
synth fun max2 x int y int int start int x y start start start start ite startbool start start startbool bool and startbool startbool or startbool startbool not startbool start start start start start start declare var x int declare var y int constraint max2 x y x constraint max2 x y y constraint or x max2 x y y max2 x y figure .
max benchmark from the sygus project.
we encode the max benchmark in alloy using signatures to represent the production rules of the program grammar and predicates to represent both the semantics of programs and the constraints restricting the target program s semantics.
programs are composed of abstract syntax nodes which can be integer or boolean typed.
abstract sig node abstract sig intnode boolnode extends node abstract sig var extends intnode one sig x y extends var sig ite extends intnode condition boolnode then elsen intnode sig gte extends boolnode left right intnode integer typed nodes include variables and if then else expressions while boolean typed nodes include greater thanor equal expressions.
programs in this space evaluate to integers or booleans integers are built into alloy but we must model boolean values ourselves.
abstract sig bool one sig booltrue boolfalse extends bool the standard evaluation semantics of these programs can be encoded in a predicate that constrains the evaluation relation.
it works by constraining all compound syntax tree nodes based on the results of evaluating their children but does not constrain the values of variables allowing them to range over all values.
pred semantics all n ite eval in int and eval booltrue implies eval eval else eval eval all n gte eval in bool and eval eval implies eval booltrue else eval boolfalse all v var one eval and eval in int the program specification says that the maximum of two numbers is greater than or equal to both numbers and that the result is one of the two.
pred spec eval eval and eval eval and eval eval or eval eval finally the problem itself requires solving for some abstract syntax tree such that for all valid evaluation relations i.e.
all possible valuations for the variables the specification holds.
pred synth all eval node int bool semantics implies spec a. run synth for 4but 2int we present the results of our evaluation including a performance comparison between alloy and existing program synthesizers in section .
.
.
optimizations originally motivated by the formalization of the synthesis problem as presented in section we designed and implemented two general purpose optimization for alloy .
.
quantifier domain constraints as defined in listing a. the synth predicate although logically sound suffers from serious performance issues.
the most obvious reason is how the implication inside the universal higher order quantifier the semantics implies the spec affects the cegis loop.
to trivially satisfy the implication the candidate search step can simply return and instance for which the semantics does not hold.
furthermore adding theencoding of the counterexample refuting the previous instance is not going to constrain the next search step to find a program and a valuation for which the spec holds.
this cycle can go on for unacceptably many iterations.
this reflects an old philosophical problem in first order logic all men are mortal is only equivalent to for all x if x is a man then x is mortal in a rather narrow modeltheoretic sense.
the case of a non man being non mortal is a witness to the second but not to the first.
to overcome this problem we can add syntax to identify the constraints that should be treated as part of the bounds of a quantification.
the synth predicate now becomes pred synth all eval node int bool when semantics spec the existing first order semantics of alloy is unaffected i.e.
all xwhen d p all x d implies p some xwhen d p some x d and p a. the rule for pushing negation through quantifiers used by the converter to nnf becomes not all xwhen d p some xwhen d not p not some xwhen d p all xwhen d not p which is consistent with classical logic .
the formalization of the alloy semantics needs only a minimal change.
the change in semantics is caused by essentially not changing how the existential counterpart of a universal quantifier is obtained only by flipping the quantifier and keeping the domain and the body the same line figure .
consequently the candidate condition always searches for an instance satisfying both the domain and the body constraint or in terms of the synthesis example both the semantics and the spec .
the same is automatically true for counterexamples obtained in the verification step.
the only actual change to be made to the formalization is expanding q.body in line according to the rules in listing a. .
going back to the synthesis example even after rewriting thesynth predicate unnecessary overhead is still incurred by quantifying over valuations for all the nodes instead of valuations for just the input variables.
another consequence is that the counterexamples produced in the cegis loop do not guide the search as effectively.
this observation leads us to our final formulation of the synth predicate which we used in all benchmarks presented in section .
pred synth all env var int some eval node int bool when env ineval semantics spec a. even though it uses nested higher order quantifiers it turns out to be the most efficient.
the reason is that the innermost quantifier over eval always takes exactly one iteration to either prove or disprove the current env because for a fixed env eval is uniquely determined.
.
strictly first order increments we already pointed out the importance of implementing the induction step line figure using incremental sat solving.
a problem however arises when the encoding of the counterexample as defined in lines is not a firstorder formula since not directly translatable to sat it cannot be incrementally added to the existing sat translation of the candidate search condition pcand .
in such cases the semantics in figure demands that the conjunction of pcand andtjfcexkbe solved from scratch loosing any benefits from previously learned sat clauses.
this problem occurs in our final formulation of the synth predicate listing a. due to the nested higher order quantifiers.
to address this issue we relax the semantics of the induction step by replacing sjpcand tjfcexkk line with funtfo f match p tjfkwith fol p or reduce map tfo p disjs ea fold p conj map tfo p qps pexists sjpcand tfo fcex k thetfofunction ensures that fcexis translated to a firstorder proc which can always be added as an increment to the current sat translation of the candidate condition.
the trade off involved here is that this new encoding of the counterexample is potentially not as strong and therefore may lead to more cegis iterations before a resolution is reached.
for that reason alloy accepts a configuration parameter accessible via the options menu offering both semantics.
in section we provide experimental data showing that for all of our synthesis examples the strictly first order increments yielded better performance.
.
evaluation .
micro benchmarks to assess how well alloy scales on higher order graph problems we selected the following classical problems max clique max cut max independent set and min vertex cover .
we specified each of the four problems in alloy see figure for the full alloy specification and executed them on a set of pre generated graphs measuring the performance of the tool in successfully producing a correct output.
it can be expected that verification problems requiring the discovery of a graph with such properties would require comparable computational resources.
experiment setup we used the erd os r nyi model to randomly generate graphs to serve as inputs to the benchmark problems.
to cover graphs with a wide range of densities we used probabilities .
.
.
.
.
for inserting an edge between a pair of nodes in a graph.
in total we generated different graphs with sizes ranging from to nodes.
to additionally test the correctness of our implementation we compared the results return by alloy to those ofsig graph nodes set node edges set edge edges.
src dst innodes sig edge src one node dst one node src !
dst sig node every two nodes in clq are connected pred clique clq ing.nodes all n1 clq n2 clq n1 some e g.edges e.src n1 and e.dst n2 ore.src n2 and e.dst n1 pred maxclique clique noclq2 set node clq2 !
clq and clique and clq2 clq edges that cross the two disjoint node set as determined by the cut fun crossing set edge let cut g.nodes cut e g.edges e.src incut and e.dst incut or e.dst incut and e.src incut pred maxcut cut ing.nodes nocut2 set node cut2 ing.nodes and cut2 !
cut and crossing crossing an independent set is a set of nodes no two of which are neighbours pred independentset indset ing.nodes all disj n1 n2 indset no e g.edges e.src n1 and e.dst n2 or e.src n2 and e.dst n1 pred maxindependentset independentset noindset2 set node indset2 !
indset and clique and indset2 indset a vertex cover is a set of nodes such that every edge in g is adjacent to at least one node in the set pred vertexcover cover ing.nodes all e g.edges e.src incover ore.dst incover pred minvertexcover vertexcover nocover2 set node cover !
cover2 and vertexcover and cover2 cover figure .
four micro benchmark problems in alloy known imperative algorithms for the above problems1and made sure they matched.
the timeout for each run solving a single problem for a given graph was set to seconds.
results figure plots the average solving time across graphs size.
the results show that for all problems but max cut alloy was able to handle graphs of sizes up to nodes in less than a minute max cut started to time out at around nodes .
our original goal for this benchmarks was to be able to solve graphs with nodes and claim that alloy can be effectively used for teaching specification animation and small scope checking all within the alloy analyzer gui which is one of the most common uses of the alloy technology .
these results however indicate that executing higher order specifications can be feasible even 1formax clique andmax independent set we used the bron kerbosch heuristic algorithm for the other two no good heuristic algorithm is known and so we implemented enumerative search.
in both cases we used java.
solving time s nodes max clique max cut max indep.
set min vertex cover figure .
average solving times for benchmark algorithms candidates nodes max clique max cut max indep.
set min vertex cover figure .
average number of candidates considered for benchmark algorithms for declarative programming where a constraint solver is integrated with a programming language e.g.
which is very encouraging.
figure shows the average number of candidate solutions alloy explored before producing a final output.
as the graph size became larger the number of candidates also increased but in most cases alloy was able to find a correct solution under candidates.
one exception was the max cut problem for graphs of size alloy considered up to candidates after which the resulting constraints became too hard for the sat solver leading to a timeout.
figure show average solving times for individual probability thresholds used to generate graphs for the micro benchmark experiments.
lower the threshold t denser the graph is similarly higher t values lead to sparser graphs .
in general the solving time tends to be greater for denser graphs as the search space is bigger.
this trend is especially evident in the max cut problem figure b where the solving time increases drastically for t .
until alloy times out at graphs of size .
on the other hand sparsity does not necessarily lead to faster performance.
for example in the max clique and max independent set note how alloy takes longer on graphs with t .
figures a and c than on those with lower threshold as the graph size increases.
we believe that this solving time s nodes t .
t .
t .
t .
t .
a max clique solving time s nodes t .
t .
t .
t .
t .
b max cut solving time s nodes t .
t .
t .
t .
t .
c max independent set .
.
.
.
.
.
.
.
solving time s nodes t .
t .
t .
t .
t .
d min vertex cover figure .
avg.
times per each threshold for graph benchmarks is because sparser graphs tend to permit fewer cliques and independent sets than more densely connected graphs.
.
program synthesis out of total benchmarks in the sygus project we encoded the that do not involve bit vectors and compared the performance of alloy in finding correct programs to thatof the provided reference solvers.
while it is possible to encode bit vectors in alloy the language does not support them natively and a relational encoding would almost certainly incur performance penalties.
we ran the same benchmarks on the same computer using the three reference solvers.
our test machine had an intel dual core cpu 4gb of ram and ran ubuntu gnu linux and sun java .
.
we set alloy s solver to be minisat.
figure compares the performance of alloy against the three sygus reference solvers and sketch a highlyoptimized state of the art program synthesizer.
according to these results alloy scales better than the three reference solvers and is even competitive with sketch.
on the array search benchmarks sketch outperforms alloy for larger problem sizes but on the maxbenchmarks the opposite is true.
both solvers scale far more predictably than the reference solvers but alloy has the additional advantage due to its generality of a flexible encoding of the target language s semantics while sketch relies on the semantics of the benchmark problems being the same as its own.
we also used the program synthesis benchmarks to answer two questions unique to alloy .
first we evaluated the optimization discussed in section .
by running the benchmarks with and without it.
figures a and b show that for the maxandarray benchmarks respectively using firstorder increments decreases solving time significantly and often causes the solver to scale to slightly larger sizes.
second we evaluated the benefits to be gained by specifying tighter bounds on the problem domain by placing tighter limits on the abstract syntax tree nodes considered by the solver.
figures c and d show that for maxandarray respectively significant gains can be realized by tightening the bounds in the case of max tighter bounds allow alloy to improve from solving the argument version of the problem to solving the argument version.
for these experiments scope specifies the exact number of each ast node required scope specifies exactly which types of ast nodes are necessary and scope specifies only how many total nodes are needed.
other solvers also ask the user to bound the analysis sketch for example requires both an integer and recursion depth bound but do not provide the same fine grained control over the bounds as alloy .
table contains both the running time and the number of candidates considered in solving each benchmark under each of the three scopes discussed above.
because they involve so few nodes the bounds for the poly benchmarks could not be tightened beyond the most general scope.
the results for the other benchmarks indicate that carefully considered scopes can result in significantly better solving times other researchers have also reported similar findings .
these results show that alloy not only scales better than naive approaches to program synthesis but can also in certain cases be competitive with state of the art solvers based on years of optimization.
moreover alloy requires only .
.
max max max max array search array search array search array search 5solving time s benchmarkalloy enumerative stochastic symbolic sketchfigure .
performance comparison between alloy and reference solvers.
the simple model presented here which is easier to produce than even the most naive purpose built solver.
due to its generality alloy is also in some respects a more flexible program synthesis tool it makes it easy for example to experiment with the semantics of the target language while solvers like sketch have their semantics hard coded.
problem scope scope scope steps time ms steps time steps time poly poly poly poly poly max max max max max n a t o n a t o max n a t o n a t o max n a t o n a t o array array array array n a t o n a t o table .
performance on synthesis benchmarks .
related work the ideas and techniques used in this paper span a number of different areas of research including constraint solvers synthesizers program verifiers and executable specification tools.
a brief discussion of how a more powerful analysis engine for alloy as offered by alloy may affect the plethora of existing tools built on top of alloy is also in order.
constraint solvers smt solvers by definition find satisfying interpretations of first order formulas over unbounded domains.
in that context only quantifier free fragments are decidable.
despite that many solvers e.g.
z3 support certain forms of quantification by implementing an effi a .
8solving time s arguments to maxpartial increments full increments b .
5solving time s array sizepartial increments full increments c .
8solving time s arguments to maxscope scope scope d .
5solving time s array sizescope scope scope figure .
effects of increment type and scope on solving time cient matching heuristic based on patterns provided by the user .
certain non standard extension allow quantification over functions and relations for the purpose of checking properties over recursive predicates .
in the general case however this approach often leads to unknown being return as the result.
many tools that build on top of an smt solver raise the level of abstraction of the input language so that they can provide quantification patterns that work more reliably in practice.
for instance boogie is an intermediate verification language that effectively uses quantifiers for the task of program verification but does not allow assertions to be higher order.
sat solvers on the other hand are design to work with bounded domains.
even though they accept only propositional formulas tools built on top may support richer logics including higher order quantifiers.
one such tool is kodkod which at the language level allows quantification over arbitrary relations.
the kodkod analysis engine however is not capable of handling any higher order formulas.
rosette builds on top of kodkod a whole suite of tools for embedding automated constraint solvers into programs for a variety of purposes including program synthesis.
rosette like many other synthesizers implements a synthesis algorithm internally.
in contrast to alloy at the user level this approach enables only one predetermined form of synthesis namely the user specifies a grammar and a property and rosette then finds an instantiation of that grammar satisfying the property .synthesizers state of the art synthesizers today are mainly purpose built.
domains of application include program synthesis e.g.
sketch storyboard jennisys comfusy pins automatic grading of programming assignments synthesis of data manipulation regular expressions and so on all using different ways for the user to specify the property to be satisfied.
a recent effort has been made to establish a standardized format for program synthesis problems this format is syntax guided similar to that of rosette and thus less general than the format offered by alloy .
in other words while each such tool is likely to beat alloy in its own concrete domain it would be hard to apply the tool at all in a different domain.
program verifiers program verifiers benefit directly from more expressive specification languages equipped with more powerful analysis tools.
in recent years many efforts have been made towards automatically verifying programs in higher order languages.
liquid types and hmc respectively adapt known techniques for type inference and abstract interpretation for this task.
bj rner et al.
examine direct encodings into horn clauses concluding that current smt solvers are effective at solving clauses over integers reals and arrays but not necessarily over algebraic datatypes.
dafny is the first smt based verifier to provide language level mechanisms specifically for automating proofs by co induction .
executable specifications many research projects explore the idea of extending a programming language with sym bolic constraint solving features e.g.
.
limited by the underlying constraint solvers none of these tools can execute a higher order constraint.
in contrast we used rby our most recent take on this idea where we embed the entire alloy language directly into ruby equipped with alloy as its engine to run all our graph experiments where rby automatically translated input partial instances from concrete graphs as well as solutions returned from alloy back to ruby objects demonstrating how a higher order constraint solver can be practical in this area.
existing alloy tools certain tools built using alloy already provide means for achieving tasks similar to those we used as alloy examples.
aluminum for instance extends the alloy analyzer with a facility for minimizing solutions.
it does so by using the low level kodkod api to selectively remove tuples from the resulting tuple set.
in our graph examples we were faced with similar tasks e.g.
minimizing vertex covers but in contrast we used a purely declarative constraint to assert that there is no other satisfying solution with fewer tuples.
while aluminum is likely to perform better on this particular task we showed in this paper section .
that even the most abstract form of specifying such minimization maximization tasks scales reasonably well.
rayside et al.
used the alloy analyzer to synthesize iterators from abstraction functions as well as complex non pure a vl tree operations from abstract specifications .
in both cases they target a very specific categories of programs and their approach is based on insights that hold only for those particular categories.
.
conclusion software analysis and synthesis tools have typically progressed by the discovery of new algorithmic methods in specialized contexts and then their subsequent generalization as solutions to more abstract mathematical problems.
this trend evident in the history of dataflow analysis symbolic evaluation abstract interpretation model checking and constraint solving brings many benefits.
first the translation of a class of problems into a single abstract and general formulation allows researchers to focus more sharply resulting in deeper understanding cleaner apis and more efficient algorithms.
second generalization across multiple domains allows insights to be exploited more widely and reduces the cost of tool infrastructure through sharing of complex analytic components.
and third the identification of a new reusable tool encourages discovery of new applications.
in this paper we have argued that the time is ripe to view higher order constraint solving in this context and we have proposed a generalization of a variety of algorithms that we believe suggests that the productive path taken by first order solving might be taken by higher order solving too.
the value of our generalization does not in our view rest on its performance in comparison to today s specialized tools although we think it is quite respectable but instead on the potential for future development of tools that exploit it.