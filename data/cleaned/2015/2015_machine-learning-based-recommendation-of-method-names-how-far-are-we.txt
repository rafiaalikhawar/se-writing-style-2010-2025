machine learning based recommendation of method names how far are we lin jiang school of computer science and technology beijing institute of technology beijing china jianglin17 bit.edu.cnhui liu school of computer science and technology beijing institute of technology beijing china liuhui08 bit.edu.cnhe jiang school of software technology dalian university of technology dalian china jianghe dlut.edu.cn abstract high quality method names are critical for the readability and maintainability of programs.
however constructing concise and consistent method names is often challenging especially for inexperienced developers.
to this end advancedmachine learning techniques have been recently leveraged torecommend method names automatically for given method bod ies implementation.
recent large scale evaluations also suggestthat such approaches are accurate.
however little is known about where and why such approaches work or don t work.
to figure out the state of the art as well as the rationale forthe success failure in this paper we conduct an empirical studyon the state of the art approach code2vec .
we assess code2vec on a new dataset with more realistic settings.
our evaluationresults suggest that although switching to new dataset does not significantly influence the performance more realistic settings do significantly reduce the performance of code2vec .
further analysis on the successfully recommended method names alsoreveals the following findings around half .
of theaccepted recommendations are made on getter setter methods a large portion .
of the successfully recommended method names could be copied from the given bodies.
to further validate its usefulness we ask developers to manually score thedifficulty in naming methods they developed.
code2vec is then applied to such manually scored methods to evaluate how oftenit works in need.
our evaluation results suggest that code2vec rarely works when it is really needed.
finally to intuitively reveal the state of the art and to investigate the possibility of designing simple and straightforward alternative approaches we proposea heuristics based approach to recommending method names.evaluation results on large scale dataset suggest that this simpleheuristics based approach significantly outperforms the state of the art machine learning based approach improving precision and recall by .
and .
respectively.
the comparison suggests that machine learning based recommendation of methodnames may still have a long way to go.
index t erms code recommendation machine learning i. i ntroduction identifiers are widely employed to identify unique software entities.
according to a recent study identifiers accountfor approximately of the source code in terms of characters.
a well constructed identifier not only follows language specific naming conventions but also conveys intention re sponsibility of its associated software entity .
consequently corresponding authorhigh quality identifiers have significant influence on the readability of source code .
method names are a special kind of identifiers employed to identify methods.
methods are the smallest named unitsof aggregated behaviors and serve as a cornerstone of ab straction .
the readability of such methods is critical inunderstanding the functionality of programs and the interactionamong different units methods .
however constructing high quality method names is often challenging especially forinexperienced developers .
to facilitate the construction of method names a few automatic approaches have been proposed recently to recommendmethod names according to given method bodies implementa tion .
all such approaches leverage advanced machine learning techniques and thus in this paper we call them ml based approaches.
the rationale of such approaches isthat method names are associated with certain features ofmethods and the association could be learned automaticallyby advanced machine learning techniques.
method features frequently employed by such approaches include source code metrics e.g.
cyclomatic complexity the sequence of iden tifiers within the method body and paths connecting nodesin the abstract syntax tree ast of method body .machine learning techniques that are frequently employed by such approaches include log bilinear neural network con volutional neural network conditional random fields and attentional neural network .
existing approaches exhibithigh accuracy and the state of the art approach code2vec achieves high precision of .
and high recall of .
.
although such approaches are overall accurate in recommending method names little is known about where and why they work or don t work.
we also know little about the useful ness of such approaches.
to this end in this paper we performa comprehensive assessment and in depth analysis on the state of the art approach i.e.
code2vec with more realistic settings i.e.
cross project validation and excluding overriding methods on a new dataset.
evaluation results suggest that although switching datasets does not significantly influencethe performance of code2vec more realistic settings do lead to significant reduction in performance.
further analysis onthe cases where code2vec succeeds suggests that ui .
oufsobujpobm pogfsfodf po vupnbufe 4pguxb sf ohjoffsjoh authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
first around half .
of the accepted method names are made for getter setter methods.
second a large portion .
of successfully recom mended method names could be copied from identifierswithin given bodies.
that is the recommended methodname for the given body has been typed in the bodybefore recommendation is requested.
these findings suggest that code2vec succeeds rarely when it is strongly needed.
to further validate its usefulness weask developers to manually score the difficulty in constructingnames for java methods and then request code2vec to make recommendations for them.
results confirm the conclu sion that code2vec rarely works when it is really needed.
to intuitively illustrate the state of the art and to investigate the possibility of designing simple but effective approaches we propose a he uristic based approach to recommending method na mes called hema for given method bodies.
it is essentially a sequence of simple heuristics which makes iteasy to follow.
evaluation results suggest that it significantlyoutperforms the state of the art ml based code2vec .
the paper makes the following contributions first a comprehensive assessment and in depth analysis of the state of the art approach in ml based methodname recommendation.
the analysis not only reveals the state of the art but also discovers where and why the approach works or doesn t work.
second a simple and straightforward approach in rec ommending method names.
it significantly outperformsthe state of the art ml based complicated approach inthe evaluation which suggests that ml based approaches may still have a long way to go.
the rest of this paper is structured as follows.
section ii presents related work.
section iii introduces empirical setting and section iv presents results and analysis.
section v proposes a heuristics based approach.
section vi discusses related issues and section vii presents conclusions and future work.
ii.
r elated work a. recommendation for method name the quality of identifiers proved to have a significant impact on the readability and maintainability of software source code method names as a special kind of identifiers are especially important because they serve as cornerstoneof abstraction for aggregated behaviors .
consequently aseries of approaches have been proposed to improve the qualityof method names.
h st and stvold develop a technique for automatically inferring naming rules of methods based on the return type control flow and parameters.
a rule violation indicates aconflict between the name and the associated implementationof a method.
to resolve the conflict they filter relevant phrasesfor rule violations by sorting the candidate list according tothe rank of the semantic profile in candidate phrase corpus aswell as the semantic distance from the inappropriate phrase tothe candidate phrase.allamanis et al.
tackle the problem of method naming by introducing a log bilinear neural language model whichincludes feature functions that capture long distance contextin source code and a subtoken model that can predict neolo gisms i.e.
names that do not appear in the training set.
themodel embeds each token into a high dimensional continuousspace and suggest the name that is most similar in this spaceto those in the method body.
allamanis et al.
later takethe method naming as a problem of extreme summarization ofsource code where the method name is viewed as the summaryof a method body.
to generate the summary they introducean attentional neural network that employs convolution onthe input tokens in the body.
the network can learn high level patterns in source code that uses both the structure ofmethod body and the identifiers to detect and explain complexconstructs.
alon et al.
propose a general path based approach for representation of methods.
the main idea is to represent amethod using the bag of paths between leaves in its ast and identifiers associated with corresponding leaves.
this allowsmachine learning models to leverage the structured nature ofsource code rather than treating it as a flat sequence of tokens.
code2vec published by alon et al.
further represents a method body into a distributed vector by aggregating thebag of ast paths with attentional network .
the attention mechanism computes a weighted attention value for each of the ast paths in a method and aggregate them into asingle vector by weighted summation to represent the methodbody.
the vectors of methods that share similar ast struc tures are close to each other in the continuous distributionspace and thus capture semantic similarity between methods as well as between method names.
through training with abundant ast structures in large scale open source projects code2vec can retrieve highly similar i.e.
close in the vector space method bodies with the given one and recommends toreuse names of such methods.
alon et al.
apply code2vec to method name recommendation and evaluation results suggestcode2vec achieves the state of the art on this task.
another deep learning based method name recommendation approach is proposed by liu et al.
.
they embed method names and method bodies into numerical vectors with para graph vector and word2vec cnns respectively.
for a givenmethod m they retrieve the set of method names noted ns that are close to min the name vector space and the set of methods names noted bs whose bodies are close to min the body vector space.
if bs intersectiontextns method mshould be renamed and the proposed approach suggests alternativeconsistent names.
we do not evaluate this approach becauseit is not published yet at the time of completing this paper.
infuture we would like to empirically investigate it and compare it again the proposed approach.
b. recommendation for other identifiers there are also a lot of automated approaches proposed to improve the quality of identifiers e.g.
class field variable andparameter names.
caprile and tonella first propose an ap authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
proach to standardize program identifiers.
they first generate a dictionary that transforms composing words in identifiers intotheir associated standard terms.
second they infer a standardsyntax from examples representative of the different formsthat can be associated to the main grammatical functions forarranging those standardized terms into a sequence.
deissenboeck and pizka suggest that well formed identifier names should be both concise and consistent i.e.
asingle identifier represents a single concept throughout theprogram .
they propose a formal model which is based onbijective mappings between concepts of methods and names to provide a solid foundation for the definition of concise and consistent naming.
in a follow up experiment lawrieet al.
surveyed the identifiers found in mslocof c c fortran and java source code to determine theextent of violations of concise and consistent naming.
thesyntactic methodology employed by lawrie et al.
identifies potential violations of concise and consistent naming which include some conventional patterns of naming found in javainheritance trees.
thies and roth identify and rename inconsistent identifiers through static code analysis.
the rationale of their approach is that variables on different sides of the same assignment had better be named consistently.
they considertwo types of assignments assignments between variables andassignments between variables on the left side and methodinvocations on the right side .
they represent variables andmethod invocations involved in assignments as nodes and connect nodes with edges that are involved in the same assignments.
based on the resulting graph they identify in consistent identifiers with heuristics.
allamanis et al.
propose a framework called naturalize that learns the coding conventions used in a code base and suggest natural identifier names to improve stylistic consistency.
naturalize works by identifying names orformatting choices that are surprising according to a probabil ity distribution learned with n gram model over source codetokens.
when surprised naturalize determines whetherit is sufficiently confident to suggest a renaming.
if yes it unifies the surprising name with one that is preferred in similar contexts elsewhere in its training set.
lear proposed by linet al.
is a variation of naturalize.
it differs fromnaturalize in the following aspects.
first lear focuseson such tokens only that contain lexical information.
second lear checks the validity of possible renaming identifierswhereas naturalize does not.
raychev et al.
build a scalable prediction engine called jsnice for predicting properties including both type andname of identifiers in the context of javascript.
they firstconvert source code into a representation called dependency network that captures relationships between program elements whose properties are to be predicted with elements whoseproperties are known.
once the network is obtained theyperform structured prediction based on a learned conditionalrandom field model.
pradel and sen formulate the problem of name basedbug detection as a binary classification problem.
they develop a framework to generate training data and to train abinary classifier.
they create training data by simple programtransformation that yields likely buggy programs.
the binaryclassifier is then trained on such automatically generated train ing data negative samples as well as buggy free programs positive samples .
c. machine learning based code recommendation recommender systems have a wide range of applications in software engineering to improve productivity and reliabil ity .
many of these systems employ machine learning techniques to assist developers in writing or maintaining software source code.
the most popular recommender systemused in integrated development environments ides is coderecommendation system .
hindle et al.
are the first toemploy n gram model in recommending the next code token for developers by statistically learning the repetitiveness of source code in token level.
following their work a seriesof n gram based approaches are proposed to recommend thenext token by exploiting large scale dataset augmentingwith semantic information employing formal propertiesof code and adding cache mechanism .
apart from token level models graphic probability models are also successfully employed to recommend the next api methodcall such models statistically learn the probabilitydistribution of api usage graphs extracted from sourcecode snippets and then recommend the next api by computing the appearance probability of each api against a given usagegraph.
another line of machine learning based code recommendation approaches leverage extensively used deep neuralnetworks.
raychev et al.
first employ rnn model forcode recommendation and white et al.
also demonstrateits high effectiveness in recommending sequential source code.
li et al.
augment rnn model with attention mechanism and pointer copy component to recommendthe next ast node in both type and name of identifiers.
iii.
e xperimental setup this section specifies the setup of the experiment i.e.
approaches selected for the evaluation research questionsexpected to answer and metrics employed to quantitativelyassess the performance of the evaluated approaches.
a. evaluated approach to evaluate the state of the art in ml based recommendation of method names we select code2vec for the evaluation.
code2vec is selected because of the following reasons.
first it represents the state of the art in this field.
as introducedin section ii code2vec was proposed recently on popl and proved significantly more accurate than alternative approaches .
second the source code of its implementation is publicly available which significantly facilitates theevaluation.
it also facilitates other researchers to replicate theexperiment.
we make the replication package of the evaluationpublicly available on github to facilitate third party replication and further investigation.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
b. research questions the experiment investigates the following research questions rq1 how well does code2vec work on datasets other than the one employed by the original evaluation con ducted by the authors of code2vec ?
rq2 how well does code2vec work with more realistic settings?
rq3 can code2vec generate method names correctly when the given method bodies do not contain method name tokens?
rq4 where and why does code2vec work?
rq5 where and why does code2vec fail?
rq6 i s code2vec useful for developers?
how often does code2vec recommend correctly for methods that are challenging to name manually?
research question rq1 validates whether code2vec keeps highly accurate when evaluation data is replaced.
code2vec was originally evaluated on a big dataset called original dataset for short .
besides that we employ another publicly available dataset called new dataset for short that consists of top starred java projects from github.
an swering this question may reveal the generality of code2vec .
research question rq2 validates code2vec s sensibility to the empirical settings.
the original evaluation conducted in is file based i.e.
java files from subject applications areshuffled and randomly divided into three groups training validation and testing sets .
as a result while recommendingmethod names for a project code2vec may exploit a large number of files from the same project.
we call such validation setting file based validation .
although file based validation is reasonable it is quite often that developers create new projectsfrom scratch and thus they don t have enough data fromthe current project to train the method name recommendationmodels.
project based validation fits this scenario.
it also releases developers from on site training which requests deep understanding of the underneath learning models.
in thissetting project based validation we pre train code2vec offline with a corpus of open source subject applications and nosource code from the testing project is exploited for training.the key advance of project based validation is that the time and resource consuming model training is conducted once and for all before such models are actually exploited by develop ers for method name recommendation.
the third validationsetting is project based non overriding validation .
the only difference between project based non overriding validation and project based validation is that overriding methods are excluded by the former pattern but included by the latter.although the original evaluation in excludes constructorsbecause it is unlikely that developers do not know how to nameconstructors they do not exclude overriding methods that arequite similar to constructors.
overriding methods share the same names with methods they override and thus it is unlikely that developers need help in naming such methods.research question rq3 investigates the performance of code2vec when the given method bodies do not contain the method name tokens.
answering research question rq3 mayreveal to what extent code2vec can coin instead of copy method names correctly.
research questions rq4 and rq5 investigate the strengths and weaknesses of code2vec .
it is likely that code2vec works well on one category of methods but works badly on anothercategory.
answering these two research questions may revealwhere code2vec succeeds fails and the rationale for the success failure.
research question rq6 concerns the usefulness of code2vec .
the usefulness depends on both accuracy of the recommendation and the difficulty of method name construction.
ifcode2vec frequently fails when requested to recommend difficult method names i.e.
when really needed it wouldbe useless for developers.
to this end we manually scorethe difficulty in method name construction and evaluate theusefulness of the approach based on the scores.
answeringresearch question rq6 helps to reveal how often code2vec works when it is really needed.
c. metrics commonly employed metrics for method name recommendation include p recision k recall k and f1 k .
precision kpresents the precision of top krecommendation and it is computed as follows p recision k naccepted k nrecommended where naccepted kis the number of cases where the evaluated approach succeeds and nrecommended is the number of cases the evaluated approach tries.
notably the approach succeeds ifand only if one of items within the top krecommendation list is accepted.
in our evaluation a recommended method name is accepted if and only if it is identical to the one manually constructed by developers.
however it is possible that therecommended name is acceptable although it is differentfrom the original one especially when the original one is animproper name.
consequently the performance we report isexactly the lower bound i.e.
the actual performance could be slightly higher from what we report in the paper.
similarly recall kandf1 kare computed as follows recall k n accepted k ntested f1 k p recision k recall k p recision k recall k where ntested is the number of tested methods i.e.
the size of testing set.
for approaches e.g.
code2vec that always make recommendation regardless of the input ntested is equal to nrecommended .
consequently their precision and recall are always equal i.e.
p recision k recall k. authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i ev aluation results on different datasets datasets number of methodsprecision recall mrr rank rank rank original dataset .
.
.
.
new dataset .
.
.
.
in addition we employ the mean reciprocal rank to assess the performance of method name recommendation approaches.it is computed as follows mrr ntestedntested summationdisplay i rank i where rank iis the rank of correct name within the recommendation list for the i th testing method.
iv .
r esults and analysis a. rq1 comparable performance on different datasets to address research question rq1 we evaluate code2vec on a new dataset as well as its original dataset employed inpaper .
to be aligned to the evaluation in paper werandomly select java files from each of the datasets astesting set and another as validation set.
others areemployed as training set.
evaluation results are presented in table i. the first column presents datasets employed for the evaluation.
the secondcolumn presents the size of involved datasets.
the third to fifthcolumns show the performance precision recall of code2vec to quantitatively present how often correct method names appear in the top krecommendation list.
the last column presents the mean reciprocal rank of code2vec .
notably for code2vec its recall is always equal to the precision.
the reason has been presented in section iii c. from the table we make the following observations first code2vec is accurate in recommending method names.
the top recommendation is often at a chance of .
on original dataset and .
on new dataset correct.
ithas a great chance .
on original dataset and .
on new dataset to present the correct method names on its top recommendation list.
high mrr .
and .
also suggests that the correct names are oftenranked on the top.
second switching datasets does not result in significantreduction in performance.
although the precision recall isslightly reduced e.g.
from .
to .
on rank the major reason for the reduction is the size of new dataset the number of methods in new dataset is only .
of that inoriginal dataset .
we conclude from the preceding analysis that code2vec overall is accurate and switching to a new large scale datasetdose not result in significant reduction in performance ofcode2vec .
fig.
.
evaluation results with different settings b. rq2 realistic settings result in reduced performance to address research question rq2 we evaluate code2vec on our new dataset with different settings i.e.
file based validation project based validation and project based nonoverriding validation .file based validation partitions dataset into training validation and test sets at file level whereas theother two validations work at project level.
the only differ ence between project based validation and project based nonoverriding validation is that overriding methods are excluded by the latter but included by the former.
evaluation results with different settings are presented in fig.
.
from the figure we make the following observations first switching evaluation setting from file based validation toproject based validation decreases the performance significantly.
the precision recall is signifi cantly reduced by .
.
.
.
atrank .
.
.
.
at rank and40.
.
.
.
at rank .
second excluding overriding methods further decreasesthe performance of code2vec .
notably overriding methods are popular and account for 986of methods in the dataset.
excluding such methods reduces precision recall by .
.
.
.
at rank .
.
.
.
at rank and14.
.
.
.
at rank .
third overall code2vec works well with different settings.
its precision recall keeps greater than regardless of the change in settings suggesting that on more than one fifth of cases code2vec succeeds in inferring the exact method name.
the high mrr .
.
and .
infile based validation project based validation and projectbased non overriding validation respectively also suggests that code2vec is quite promising.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii ev aluation results on unseen seen tokens token types total nt correct nc nc nt unseen tokens .
seen tokens .
we have not yet fully understand why switching from file based validation toproject based validation results in so much reduction more than in performance.
a possiblereason for the significant reduction is that file based validation leverages the nature of source code local repetitiveness .
it proved that source code has the characteristic of local repetitiveness within projects and machine learning modelsmay learn special patterns that are specific to a given projectif they are trained with part of the project and then applied tothe other part of the project .
file based validation exploits the major part of a subject application while another small part of the same application is under test.
as a result code2vec can take full advantage of local repetitiveness.
however project based validation partitions data at the granularity of projects i.e.
a single project as a whole is taken aseither testing data or training data but never the both at the same time .
consequently it cannot take advantage of local repetitiveness as file based validation does.
we conclude from the preceding analysis that the performance of code2vec decreases significantly on more realistic settings.
however its overall performance is still promising.
c. rq3 coining method names to address research question rq3 we evaluate the performance of code2vec in generating seen and unseen method name tokens respectively.
for each of method names in new dataset we split it into tokens according to the camel case naming convention.
a token tfrom method name mn is a seen token if tappears case insensitive in the body named bymn.
otherwise it is an unseen token.
we assess how often code2vec can successfully recommend seen unseen method name tokens during project based non overriding validation conducted in section iv b. evaluation results are presented in table ii.
the first column presents the types of method name tokens unseen tokens and seen tokens.
the second column presents total number of seen unseen method name tokens in the testing set.
thethird column presents the number of correctly recommendedseen unseen method name tokens.
a token tfrom method name mnis correctly recommended if and only if the name recommended for the method body of mn contains token t. the forth column presents the chance that seen unseen method name tokens are recommended correctly.
the chanceis computed by dividing the number of correctly recommendedseen unseen method name tokens by the total number.
from the table we make the following observations first a large percentage of method name tokens .
are unseen i.e.
theydo not appear in the input method bodies .
consequently ml based approaches that strongly rely on copy mechanism to select tokens from input have significant limitation ontheir maximal potential.
second code2vec works quite well in recommending unseen method name tokens.
it successfully generates .
of unseen tokens.
its performance in generating unseen method name tokens is even comparable to that .
on seentokens.
code2vec can generate unseen method name tokens because it does not select copy tokens from its input i.e.
method body.
in contrast it extracts features of methods i.e.
pathsconnecting nodes in the ast of method bodies and associatessuch features with method names.
as a result if the givenmethod body mb shares the same or highly similar features with another method body mb2 in the training set code2vec may recommend the method name name mb2 o f mb2for mb1even if the tokens of name mb2do not appear in mb1.
a typical example is presented in listing .
code2vec successfully coins the method name for the testing method online though the token contains doesn t appear in the body.
through retrieving training methods named as contains e.g.
the method on line we find that their syntax structuresexploited by code2vec are always similar.
thus code2vec can successfully recognize the specified method body associatedwith contains and suggest to reuse the training method name.
1public static boolean contains string str string array for string s array if str .
equals s return true return false 9public static boolean contains int values int candidate for int i i values .
l ength i if values candidate return true return false listing .
an example of coined method name from the analysis in the preceding paragraphs we conclude that code2vec works well in generating unseen method name tokens.
d. rq4 where and why code2vec works to investigate where and why code2vec works we manually analyze cases where it works during project based nonoverriding validation .
notably code2vec succeeds on a large number of methods and thus it is challenging if notimpossible to manually analyze all of these methods.
to this end we randomly sample one thousand of these methods for manual analysis.
based on the manual analysis we make thefollowing observations first a large portion .
of accepted namesare recommended for getter setter methods.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
common ast pattern of getter methods second it is quite often at a chance of .
that the correct method name could be copied from the correspondingmethod body.
in the rest of this paper we call such methodsname contained methods.
to investigate why code2vec works well on getter setter methods we manually analyze features of such methods.
two typical getter methods are presented in listing .
their asts are presented in fig.
.
from this figure we observe thatthe two trees are highly similar and thus their features i.e.
paths that connect each pair of terminal nodes in the ast arealso highly similar.
according to our manual analysis mostof getter methods have highly similar asts.
consequently code2vec can distinguish getter setter methods because of the features and generate method names according to the terminal node on the bottom right corner of the ast.
1public int getpadding return padding 5public int getlength return length listing .
getter methods 1public void reset delegation reset operation 6public void reset string operation delegation and server reset operation true public void reset string newoperation boolean logoperationonchange server if t i m e !
null if operation .
equals new operation logoperationonchange logoperation operation ela psedtime time new date .
gettime if !
operation .
equals newoperation operation n ewoperation log .
info string .
format operation s started .
newoperation listing .
delegations fig.
.
common path of delegations name contained methods are created for various reasons e.g.
delegations.
a delegation is such a method that does nothing except passing messages between its invoker andanother method called server .
a typical example is presented in listing .
three overloading methods share the same name reset which is required by overloading mechanism.
overloading method with fewer parameters e.g.
the one on line often serves as a delegation to more complex one e.g.
theone on line with default arguments.
as a result the name reset of invoked method appears within the method body of the delegation on line and it happens that this name is identical to that of the delegation.
the same is true for another delegation on line whose server is the method defined on line .
according to our manual analysis delegationsaccount for a large percentage .
of the name containedmethods.
to investigate why code2vec works well on delegations we analyze the ast of delegations.
asts of the delegations inlisting are presented in fig.
.
from this figure we observethat such delegations share a common path shown in dashedline .
the path travels from the method name terminal nodereset to the root of the tree methoddeclaration passes the root of method body blockstatement and the only statement expressionstatement and methodcallexpression and finally reaches the name of invoked method another terminal nodereset .code2vec can learn to decide whether a given method body is a delegation by looking for such a path ignoring thetwo terminals .
if a delegation code2vec suggests to reuse the name of invoked method as the name of the delegation.
we conclude from the preceding analysis that code2vec works well on getter setter methods and delegations.
the rationale for the success is that such methods have common structures in their asts.
e. rq5 where and why code2vec fails to investigate where and why code2vec fails we conduct another manual analysis that is highly similar to that in authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
section iv d. the only difference is that here we analyze one thousand failed cases during project based non overriding validation whereas section iv d analyzes successful cases.
based on the manual analysis we figure out the following major reasons for the failure.
first out of vocabulary method names are the primary for the failure.
a method name is outof vocabulary if and only if none of the methods in trainingset is named with it.
notably code2vec builds a vocabulary of method names by collecting all unique method names inthe training set and selects a name from this vocabulary as the recommendation for a given method body.
consequently if the optimal method name is not included in the vocabulary code2vec has no chance to generate it.
this kind of methods are common accounting for of meth ods in the testing set.
as a result code2vec fails frequently for this reason.
employing open vocabulary or coining methodname by composing tokens may help to further improve theperformance.
the second reason for the failure is that the exploited method features are often insufficient to infer method names.listing presents a typical example.
method bodies of deepcopy and build are almost identical except for the data type tincrement vs. reportattributes .
consequently their ast paths exploited by code2vec as method features are highly similar as well.
as a result code2vec recommends the same name for them.
another example is presented in listing where two methods errand rawerror from different applications have the same method body.
however they are nameddifferently by their authors.
all of these examples suggest thatthe exploited feature sometimes even the whole input methodbody is often insufficient to infer method names.
to furtherimprove the performance additional information e.g.
theirenclosing classes should be exploited as well.
1public tincrement deepcopy return n e w tincrement this 5public reportattributes build return n e w reportattributes this listing .
similar methods named differently 1public static void err string m s g system.
err .
println m s g 5public static void rawerror string m s g system.
err .
println m s g listing .
identical methods named differently the third reason for the failure is improper method names in the testing set.
during the evaluation all recommendednames are compared against original names associated withtesting methods i.e.
the code2vec fails if the recommended name is different from the original one.
however it is likely that the recommended name could be even better than theoriginal one.
in such cases code2vec fails and we call suchcases false negatives.
for example code2vec generates name initrecyclerview for the method on line in listing .
the recommended name is better than the original one initializerecyclerview because the abbreviation init significantly shortens the identifier whereas keeps the readability.
notably init has been widely employed to represent initialize e.g.
in a large number of jdk methods and thus it is not difficult for experienced developers to guess the meaning.
therecommended new name also successfully corrects the spellingof recyclerview to make it consistent with camel casenaming convention.
another example is presented on line for which code2vec generates name setpassword .
it is better than the original name password because the latter fails to reveal the intent of method and violates naming conventions method names should be a verb or a verb noun phrase .
1private void initializerecyclerview recyclerview .
lay outmanager l ayoutmanager new gridlayoutmanager getactivity recyclerview .
setlayoutmanager layoutmanager recyclerview .
sethasfixedsize true adapter new recyclerviewadapter getactivity .
getapplicationcontext recyclerview .
setadapter adapter public keycloakbuilder password string password this .
password password return this listing .
improper method names in testing set f .
rq6 limited usefulness for developers to answer research question rq6 we investigate how often code2vec works when it is strongly needed.
the investigation is conducted as follows first we invite six developers involved in a commercial project for the evaluation.
the commercial project has been released recently by a giant of it industry to conduct largescale software refactorings.
second for each of the participants we randomly select one hundred methods developed by himself herself.
third we request all participants to score the difficulty in naming sampled methods.
notably participants do not scoremethods developed by other developers and thus each ofthem score exactly one hundred methods.
the scores rank between one and five i.e.
point scale whereone represents least difficulty and five represents highestdifficulty.
fourth we apply code2vec ofproject based non overrding validation to the scored methods and validate the recommendations against manually constructed names.
evaluation results are presented in table iii.
the first column presents the difficulty scores in naming methods.
thesecond column presents the number of methods with the spe cific difficulty.
the third column presents the precision recallofcode2vec at rank on the given methods.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii ev aluation results on manually scored methods scores number of methods precision recall very easy .
easy .
normal .
difficult .
extremely difficult .
total .
from the table we make the following observations first a significant percent of methods are difficult to name even for authors of such methods.
we note that out of600 methods are extremely difficult to name and 50are difficult to name.
in total .
of the methods are difficult to name for experienced developers.
second the overall precision recall .
of code2vec is comparable to that on large scale dataset employed insection iv b where its precision at rank is .
.
itsuggests that conclusions drawn on open source applicationsmay hold on commercial closed source applications as well.
third code2vec works well on very easy to name methods resulting in high precision of .
.
finally code2vec rarely succeeds on difficult to name methods where recommendation on method names is stronglyneeded.
it fails on all of extremely difficult to namemethods and out of difficult to name methods.
overall its precision on such methods is significantly reduced to .
.
we also notice that its precision decreases signifi cantly with the increase of difficulty scores.
from the analysis in the preceding paragraph we conclude that code2vec rarely works when it is strongly needed.
g. threats to v alidity a threat to the external validity is that we employ only one new dataset to validate the impact of switching datasets on the performance of code2vec .
it is likely that our conclusion may not hold if other datasets are involved.
to reduce thethreat we perform our assessment and analysis on a large scale dataset composed of projects.
it is challengingto collect additional comparable dataset for the evaluation.another threat to external validity is that only manuallyscored methods are involved in our experiment to assess theusefulness of code2vec .
it is challenging to recruit more expert developers from the industry for the evaluation.
another threatto validity concerning the manual scoring is that the scoringis rather subjective.
consequently conclusions drawn on such participants may not hold for other developers.
a threat to construct validity is that we assess the correctness of generated names based on their equivalence tothe manually constructed ones.
however as introduced in section iv e it is likely that the recommended method namescould be better than manually constructed ones which makesthe assessment inaccurate.
to reduce the threat we employ only top starred projects where most of the method names arelikely well constructed.
v. h euristics based alternative approach code2vec is a complicated ml based approach that is difficult to interpret.
it also requires training on a large corpusof high quality source code that is both time consuming and resource consuming.
to investigate the possibility ofdesigning a simple and straightforward approach for methodname recommendation in this section we propose a heuristics based approach hema that outperforms code2vec .
the implementation source code of hema is publicly available on github .
a. overview hema is essentially a sequence of heuristics.
for a given method body mb hema works as follows first based on a sequence of heuristics hema decides whether mb is a getter setter method.
if yes hema generates method name for it automatically based onanother sequence of heuristics.
second based on a sequence of heuristics hema decides whether mb is a delegation.
if yes hema generates method name for it automatically based on another se quence of heuristics.
third if the preceding heuristics fail hema employs a sequence of heuristics to retrieve methods in a large corpus that share the same return type and parameters both parameter names and parameter types but regardlessof parameter orders with mb.
from the resulting set of methods notated as s m hema picks up the most popular method name and suggests it to mb.i fsm hema refuses to make any recommendation.
details of the key steps are presented in the following sections.
b. distinguishing getter setter methods getter and setter methods often follow common patterns.
one of the most well known patterns for getter methods is return field whereas field param is for setter methods.
following these patterns we define a sequence ofheuristics to distinguish getter and setter methods from others.
for a given method body mb hema distinguishes whether mbis a getter method as follows first if the given method body returns nothing i.e.
the return type is void the given method is not a getter second if the given method body contains more than one returnstatements hema will not recognize it as a getter method third if the value returned by the only returnstatement is a field notated as field declared within the enclosing class it is a getter method.
for the potential getter method hema composes a method name as get field .
hema distinguishes method body mbas a setter method if the given method body has at least one parameter authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv comparison between hema and code 2vec scoreshema code2vec precision recall f1 precision .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
total .
.
.
.
the body is composed of a single assignment the left hand side of the assignment is a field notated as field declared within the enclosing class and the right hand side of the assignment is a parameter of the method notated as param .
for the potential setter method hema composes the method name as set field .
c. distinguishing delegations for a given method body mb hema distinguishes it as a delegation if the method body contains a single statement and the statement is a returnstatement that returns an invocation on another server method notated as smethod .
for the potential delegation hema recommends to reuse the name of invoked method i.e.
smethod .
d. frequency based name recommendation if the given body mbis neither geter setter nor delegation hema retrieves a set of methods sm that share the same return type and the same parameter list including both param eter types and names but regardless of the order of parameters .ifs mis empty hema refuses to make any recommendation.
otherwise it selects the method name with highest frequencyins m and recommends to use this name for the given method body.
e. comparison against code2vec to compare hema against code2vec we evaluate hema on the new dataset employed in section iv b with projectbased non overriding validation .
evaluation results suggest that hema significantly outperforms code2vec .
its precision recall and f1 at rank are .
.
and .
respectively.
in contrast the precision of code2vec at rank is .
notably its recall and f1 are equal to the precisionas explained in section iii c .
compared to state of the art code2vec hema successfully improves precision recall and f1 by .
.
.
.
.
.
.
.
and .
.
.
.
re spectively.
we also evaluate hema with manually scored dataset used in section iv f to compare the usefulness of hema againstcode2vec .
evaluation results at rank are presented in table iv.
from the table we observe that hema outperforms code2vec on difficult to name methods improving the precision recall and f1 from .
to .
.
and5.
respectively.
one of the reasons for the improve ment is that the frequency based name recommendation employed by hema works for many complicated method bodies.
this heuristic alone successfully generates method names for8.
of the testing methods in new dataset .
from the analysis in the preceding paragraphs we conclude that the heuristics based hema significantly outperforms the state of the art ml based code2vec .
vi.
d iscussion a. implications the empirical study in section iv and the alternative approach proposed in section v have the following implications empirical settings are critical we switch from casual empirical setting to more realistic ones in section iv b andresults suggest that the switching leads to significant reduction in performance.
it implicates that empirical settings should be carefully designed and should be as close as possible to realscenarios in the industry.
it is quite often that researchers espe cially those from fields e.g.
ai and nlp other than softwareengineering pay little attention to the application scenarios of proposed automatic software engineering tools approaches.
as a result the empirical settings are significantly differentfrom real scenarios and thus the evaluation results fail toreveal the reality of such approaches.
notably recent empiricalstudy conducted by hellendoorn et al.
results in similarimplications.
they analyze empirical settings employed in the evaluation of code completion tools and suggest that such settings are essentially different from real ones in practice.they empirically switch to more realistic settings and resultssuggest that the switching leads to significant reduction inperformance.
our findings are highly consistent with theirs.
a friend in need is a friend indeed evaluation results in section iv f suggest that although the overall per formance of code2vec is promising it is not much useful.
the major reason is that it frequently works when it is not stronglyneeded but fails when it is in need.
the evaluation may suggest that overall performance alone could be insufficient to measure the usefulness of automatic software engineering tools.
weshould allocate priority to cases where the tools are urgentlyneeded and assess how often the tools work in such cases.
complex approaches are not necessarily better than simple and straightforward ones to investigate the possibility of designing a simple and straightforwardapproaches whose performance is comparable to code2vec w e propose a heuristics based approach called hema .
evaluation results in section v e suggest that this simple approach significantly outperforms the state of the art ml based code2vec .
the finding is consistent with recent reports by fu andmenzies and by liu et al.
in that complex approachesare not necessarily better than simple and straightforwardones.
the empirical study conducted by fu and menzies authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
suggests that simple differential evolution de and svm are comparable to if not better than complex convolutionalneural network cnn in retrieving linkable questions fromstack overflow.
the empirical study conducted by liu etal.
suggests that the classical k nearest neighbor model knn works even better than advanced state of the art deeplearning models in generating commit messages.
our eval uation as well as existing reports suggest thatsimple and straightforward approaches are worth a shot beforecomplicated and time consuming techniques are exploited forsoftware engineering tasks.
coining method names with tokens outside method body as suggested by the evaluation results in section iv e of method names in testing set are not used as methodnames in the large scale training set.
consequently methodname recommendation approaches e.g.
code2vec that encode method names as a whole fail to generate such names unseenin their bodies.
a potential way to solve this issue is to encodetokens instead of whole method names and to coin method names at fine grained token level.
however we also notice from table ii that only .
of the method name tokens could be copied from the input associated method bodies .
consequently coining methodnames with tokens from the method body only could beinsufficient.
enlarging the search scope is potentially a good solution up to of the method name tokens can be found within the enclosing class and up to can be found withinthe enclosing package.
b. limitations the first limitation of the empirical study is that only one state of the art approach i.e.
code2vec is involved in the study.
notably ml based approaches especially deeplearning based ones are often time and resourceconsuming.
consequently involving more baselines in the study could significantly increase the cost in both computing resource and human resource of manual analysis.
for example we evaluated convolutional attention network with theemployed datasets and it failed to generate complete results inseveral days.
we only select code2vec for evaluation because it represents the state of the art and proved significantly better than other approaches .
however in future work involving more baseline approaches in the empirical study may increasethe generality of conclusions drawn on the empirical study.
the second limitation is the limited usefulness of alternative approach proposed in section v. we design this approach tointuitively reveal the state of the art as well as the possibility ofdesigning simple but effective approaches.
evaluation results in section v e suggest that it has successfully accomplished its mission.
however it should be noted that most of methodnames it recommends successfully are associated with simplemethods like getter setter and delegations.
developers rarelyneed help in naming such simple methods which may suggestthat usefulness of the approach is limited.vii.
c onclusions and future work researches have recently achieved significant advances in machine learning techniques.
as a result many of the result ing advanced machine learning techniques are exploited tosolve software engineering tasks e.g.
code completion andmethod name recommendation.
although machine learningbased approaches are proved accurate in generating methodnames existing evaluations fail to reveal their real performancefor various reasons e.g.
arbitrary empirical settings.
suchevaluations fail to reveal where and why existing approacheswork or do not work.
to this end in this paper we conductan empirical study on the state of the art method name recom mendation approach code2vec with more realistic settings.
our evaluation results suggest that code2vec deserves significant improvement.
to intuitively reveal the state of the art and toinvestigate the possibility of designing simple and straight forward alternative approaches we also propose a heuristics based approach to recommending method names according to given method bodies.
our evaluation results suggest thatit outperforms code2vec significantly and improves precision and recall by .
and .
respectively.
implication of the empirical study is severalfold.
first empirical setting is critical for empirical study and improper setting can significantly warp conclusions drawn on the em pirical study.
second the usefulness of automatic softwareengineering tools should not be assessed solely by theirperformance e.g.
precision and recall.
third advanced andcomplex approaches are not necessarily better than simple and straightforward approaches.
finally machine learning based recommendation of method names may not work as well asexpected.
with more rigorous settings the deep learning basedcode2vec fails frequently.
however in this paper we empirically evaluate code2vec only and other machine learning based approaches may outperform code2vec in our settings.
in future it should be interesting to investigatethis question.
future work is needed to investigate the correlation between difficulty in naming method names and source code metrics.in this paper we measure the difficulty subjectively by askingdevelopers to give a number ranking from to to representthe difficulty.
such subjective ranking could be inaccurate.
in future it would be interesting to investigate more accurate and more objective ways to measure the difficulty in namingmethods.
in future it is also interesting to investigate whetherclone detection techniques could be exploited to retrievesimilar methods in corpus and whether such techniques could outperform the heuristics presented in this paper section v .
a cknowledgment the authors would like to say thanks to the anonymous reviewers for their valuable suggestions.
the work is partially supported by the national natural science foundation of china and the national key research and development program ofchina 2016yfb1000801 .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.