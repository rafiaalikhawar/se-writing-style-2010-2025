lightweight adaptive filtering for efficient learning and updating of probabilistic models antonio filieri university of stuttgart stuttgart germanylars grunske university of stuttgart stuttgart germanyalberto leva politecnico di milano milan italy abstract adaptive software systems are designed to cope with unpredictable and evolving usage behaviors and environmental conditions.
for these systems reasoning mechanisms are needed to drive evolution which are usually based on models capturing relevant aspects of the running software.
the continuous update of these models in evolving environments requires efficient learning procedures having low overhead and being robust to changes.
most of the available approaches achieve one of these goals at the price of the other.
in this paper we propose a lightweight adaptive filter to accurately learn time varying transition probabilities of discrete time markov models which provides robustness to noise and fast adaptation to changes with a very low overhead.
a formal stability unbiasedness and consistency assessment of the learning approach is provided as well as an experimental comparison with state of the art alternatives.
i. i ntroduction non functional properties such as reliability performance or energy consumption are a central factor in the design of software systems moving from the niche of critical systems to everyday software.
probabilistic quantitative properties which are able to characterize the uncertainty and unpredictability of external phenomena affecting software behavior from the interaction with the users to the contention on accessing physical resources.
for this reason significant research effort has been conducted in recent years about specification and verification of probabilistic quantitative properties .
these verification approaches commonly build upon convenient formal models able to capture the probabilistic nature of the described phenomena e.g.
markov models or queuing networks .
however most of these models are constructed at design time based on initial assumptions about the software and its execution environment.
these assumptions might be invalidated by unforeseen changes the software may undergo during its execution .
to handle this issue probabilistic models need to be continually updated during runtime to provide a current view on the running systems supporting also the runtime verification of the desired properties.
in general designing time efficient and accurate algorithms to keep a probabilistic model continuously updated during runtime is an open problem deeply investigated by the software engineering community .
an early example is the kami approach that uses a bayesian estimator to learn transition probabilities of discrete time markov chains dtmcs .
however the longer a kami estimator runs the higher the effect of the historical data is on the estimation.thus kami is producing inaccurate results once the probabilities change.
the authors of the initial kami approach have also noticed this and have extended their approach with a change point detection algorithm which resets the estimation once the observed transition probabilities have significantly changed.
adding a change point detection method to kami significantly increases the robustness towards change however it comes at the cost of an increased runtime overhead.
the cove approach enhances kami s bayesian estimator by adding an aging mechanism to forget old information.
cove results are thus more robust to changes however the intrinsic noise filtering capability of the original bayesian estimator is weakened by the aging mechanism leading to more noisy estimates.
cove has been extended with a procedure to automatically set an optimal aging factor .
in the area of performance tracking kalman filters are configured and used to estimate performance measures and to keep them updated at runtime .
kalman filters are well known for their ability to reduce input noise and to provide smooth estimates.
however this comes at the price of slower responses to abrupt changes.
a good trade off between these two aspects usually requires a non trivial tuning of the algorithm s parameters.
trading off noise rejection prompt reaction to changes and computational overhead remains an open problem.
in this paper we propose a novel lightweight adaptive filter to learn and continuously update the transition probabilities of a dtmc that is specifically designed to improve the trade off between smooth estimation and prompt reaction to changes is equipped with an online auto tuning procedure to robustly discriminate between actual changes and outliers isprovably stable unbiased and consistent with a formal quantification of its convergence time and its noise filtering strength requires a negligible runtime computational overhead.
we implemented our approach in python and formally proved cp.
section iv that the algorithm satisfies the desired properties.
we further performed a preliminary experimental evaluation cp.
section vi with common input data patterns to highlight the strengths and weaknesses.
additionally we applied the algorithm to learn the operational profile of a large case study to underpin these results cp.
section vii .
ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee icse florence italy ii.
b ackground this section briefly recalls essential background concepts for our approach.
in section ii a a formal definition of discrete time markov chains dtmcs is provided.
in section ii b we will introduce basic definitions and assumptions about statistical inference for dtmcs.
a. discrete time markov models a discrete time markov chain is a state transition system where the choices among successor states are governed by a probability distribution.
formally a dtmc is a tuple s s p l ap where sis a finite set of states s02sis the initial state p s s!
is a stochastic matrix apis a set of atomic propositions and l s!2ap is a labeling function that associates to each state the set of atomic propositions that are true in that state.
an element pij of the matrix prepresents the transition probability from state sito statesj i.e.
the probability of going from state sito state sjin exactly one step.
the probability of moving from sitosjin exactly two steps can be computed asp sx2spix pxj that is the sum of the probabilities of all the paths originating in si ending insj and having exactly one intermediate state.
the previous sum is by definition the entry i j of the power matrix p2.
similarly the probability of reaching sjfromsiin exactlyksteps is the entry i j of matrixpk.
as a natural generalization the matrixp0 irepresents the probability of moving from state sito statesjin zero steps i.e.
1ifsi sj 0otherwise.
sincepis a stochastic matrix the sum of the elements for each of its rows has to be .
formally each row iofp identifies a categorical distribution .
furthermore thanks to the markov property these categorical distributions are pairwise probabilistically independent since the choice of the next state only depends on the current one.
this property will be exploited in the next section to support the definition of a localized learning approach of the transition matrix p. b. statistical learning for dtmcs the identification of dtmc models from the observation of a running system is a well known statistical problem with relevant applications in many disciplines including software engineering .
in this paper we focus on learning the transition probability matrixpof a dtmc assuming its structure does not change i.e.
only transition probabilities may be unknown or subject to change .
thanks to the markov property this problem can be reduced to the independent learning of n independent categorical distribution where nis the number of states composing the dtmc.
this simplifies both the monitoring and the learning tasks.
several approaches have been proposed in literature including maximum likelihood estimators and bayesian estimators .
the latter have recently gained more relevance for online learning thanks to the usually faster convergence and the ability to embed expert knowledge inthe form of an assumed prior next state distribution .
despite their ability to estimate the actual transition probabilities even in presence of noisy observations for timeinvariant processes most statistical approaches fail to promptly react to changes in the transition probability.
this leads to slow convergence time after a change and consequently poor accuracy and reliability of the estimates.
iii.
l earning through filters in this section we will introduce our online learning approach for dtmcs based on filtering.
the input to our systems is a sequence of measures representing the average transition frequency from a state sito each state sjover a period of observation.
calling kthek th period of observation also referred to as time step the average transition frequencies pm ij k at time step kare defined as nij k p xnix k where nij k is the number of transitions from sitosjoccurred at time stepk.
since those counts are obtained by monitoring the system for a limited time we assume the observed frequencies to include an additive zero mean noise component accounting for both the uncertainty of the sampling procedure and possible issues with the monitoring infrastructure e.g.
communication delays .
the values of the noise for each time step are assumed to be independent among one another and approximately normally distributed with unknown variance .
for the considerations stated in section ii b we will instantiate a filter for each state aiming at learning its next state distribution.
a similar approach is followed by most state of the art approaches for learning dtmcs .
to describe our approach let us first focus in section iii a on the estimation of a scalar parameter not subject to any constraint.
in section iii b we will extend the approach to cope with multiple dependent variables whose sum has to be equal to a given value.
this extension is needed to handle the structural dependencies among transitions of a dtmc originating from the same state.
finally in section iii c we will introduce an online auto tuning procedure to automatically adapt the change point detection mechanism of the filter to cope with changing and unpredictable operation scenarios.
a. learning a scalar measure the goal of our learning procedure is to estimate an unknown time varying probability vector p k from the noisy measurements pm k .
the output of the filter will be an estimatebp k ofp k .
the simplest viable filter for our purpose is a unity gain first order discrete time filter whose dynamics is described in equation bp k a bp k a pm k a for this filter high values of a i.e.
close to provide good noise filtering and smoothing which is desirable to estimate a stationary probability from noisy observation.
however the tracking of abrupt e.g.
stepwise variations of p k would be very slow.
on the other hand small values of a i.e.
close to would promptly follow abrupt variations of p k but at the price of poor noise filtering.
an example of such behavior is shown in figure .
ideally we would like to have icse florence italy0.
.
.
.
.
a a .
.
.
.
.
b a fig.
.
noise filtering versus fast change tracking for the filter of equation .
aclose to 1when thep k is stationary in order to obtain a smooth estimation while aclose to 0whenever a change in p k occurs.
our goal in the remainder of this section is to introduce our strategy for the dynamic adaptation of a based on the the behavior of p k as we can observe it through the measurement pm k .
the strategy we propose is to control ain the range between two asymptotic bounds aloandahi.
for a stable and nonoscillatory behavior of the estimation process we require alo ahi we will come back to stability later .
we want our adaptation mechanism to drive atowardahiwhen the process is stationary and toward aloin presence of a change.
to distinguish these two situations we propose to consider the observed probability distribution of the input measurements pm k .
indeed being produced by monitoring the process for a limited amount of time i.e.
a time step these measurements usually show a certain degree of dispersion around the actual valuep k .
let us assume for now we can quantify such dispersion and use it to define a threshold ethr 0such that an input measure distant more than ethrfrom the current estimatebp k can be likely assumed to be the bad smell of a change point1.
for smoothness reasons let us define the value of a k the introduction of the adaptation mechanism made it timedependent as a k a0 afa e k ethr wherea0 ahi alo a 0tunes the adaptation speed the larger the faster default and e k jpm k bp k jandfa !
is a continuous differentiable strictly monotonically decreasing function such that lim x!
1fa x f a lim x!1fa x to ensure that alo a k ahi8emag k we choose fa x arctan x where is a design parameter determining the gradient of fa around the origin and in turn the speed of transition between the two asymptotic values .
notice that the definition of fa in terms of the arctan function satisfies all the requirements stated above.
furthermore the selection ofarctan is typical when arbitrarily steep transitions between two values are required to be obtained through a continuous and continuously differentiable function.
alternative definitions of fa are possible but their analysis is beyond 1this intuition is used in several statistical tests about the mean of a population and for the identification of outliers .the scope of this paper.
higher order filters can also provide for a finer specification of the transition function though with an increase computational complexity and in general less provable stability result.
our solution aims at achieving the simplest strategy suitable for solving our problem and with the lowest possible computational overhead.
combining equations and under the assumption that we have properly quantified ethr results in the nonlinear discrete time dynamic equations of our learning filter e k jpm k bp k j a k a0 a fa e k ethr bp k a k bp k a k pm k where in a mathematical sense pmis the input and bpboth the state and the output of the dynamic system .
the filter in is the core of our learning approach.
in the next section we will extend it to estimate categorical distributions instead of scalar values while in section iii c we will formally describe the online adaptation mechanism that allows for automatically adjusting the value of ethr and consequently of a k .
b. learning categorical distributions the filter defined in the previous section can be used to estimate each single probability pijindividually.
however the obtained estimates for each row of pwould most likely not constitute correct categorical distributions sum is not .
in order to ensure the estimation of correct categorical distribution of each state si we will first estimate each probability pijindividually and then applying a convenient correction procedure.
this procedure minimizes the euclidean norm of the distance between the vector bpof the uncorrected estimates and the vector of the corrected one subject to a unity sum constraint for the latter and only positive probabilities by construction .
formally let bpandcpcbebp k andcpc k 0our correction procedure requires to solve the following optimization problem min bpc k bpc k bp k bpc k bp k subject topn i 1bpci k using the lagrange multipliers method to solve this optimization problem the lagrangian of the problem is l k nx i bpci k bpi k nx i 1bpci k !
and solving the corresponding karush kuhn and tucker kkt equations leads to the affine correction formula cpc k fc bp k hc wherefc in 1n nn hc 1n n and the symbol 1p c denoting a p cmatrix with unity elements and inbeing the identity matrix of order n. in the remainder of this paper we will always refer to the corrected estimator for the transition probabilities of a dtmc i.e.bpij bpcij unless otherwise specified.
icse florence italyc.
online filter adaptation the core element of the online adaptation mechanism is the dynamic correction of the parameter ethr.
this parameter has to capture the dispersion of an input measurement pm k around the actual value it is measuring p k .
an effective and sequentially computable index of the dispersion of a probability distribution is its variance.
an efficient and numerically stable algorithm for the sequential i.e.
sample by sample estimation of the variance has been proposed by knuth and reported in algorithm .
n mean m2 forx in data do n n delta x mean mean mean delta n m2 m2 delta x mean end variance m2 n algorithm knuth s algorithm for seq.
variance estimation.
we adapt knuth s algorithm by executing the body of the loop for each incoming measurement pm k and updating the input variance .
this way we can efficiently keep our dispersion index updated after every new measure is gathered.
in order to compute ethr we assume the input measurements to have gaussian distribution centered around the actual measure and with variance .
we then want to decide for each incoming measurement if it can be reasonably explained under this assumption or not.
to do so we operate similarly to a statistical hypothesis test on the mean of the input distribution.
our hypothesis is that the actual mean of the input distribution is bp k i.e.
the latest estimate from our filter and try to decide whether the measurement pm k is far enough from bp k to contradict our hypothesis.
since the variance of the input distribution has been estimated we should refer in this case to a t test .
however assuming enough measurements have been retrieved as a rule of thumb at least we can safely use a z test .
after deciding a confidence value we can decide whether the last measurement retrieved should be considered explainable with the current estimation or the outcome of a change in the process it may also be the case of an outlier but we will discuss how to handle this situation later on .
in particular we assume a change point occurred if jpm k bp k j z1 where p 2is the standard deviation of the input distribution.
equation can be straightforwardly used to adjust the value of ethrafter a new sample has been gathered ethr k k z1 k the decision about constitutes a trade off between a quick response to smooth changes in the process and robustness to measurement outliers.
particularly relevant for this decision is the average number of transitions observed in each timestep a small number will likely lead to noisy measurements and increases the likelihood of outliers in such case a very small value of is recommended see also section vi .
d. on the filter configuration the filter introduced in section iii a has four configuration parameters alo ahi and .
while the role of has been already discussed in the previous section we will briefly and informally discuss here how the values of the others affect the performance of the filter.
some addition formal considerations will be provided in section iv .
intuitively there are two extreme operating conditions for a filter the probability to be estimated is stationary or it is undergoing an abrupt change.
in the first case we aim at obtaining a clean and smooth estimate.
this means we would like ato be close to .
if the input measurements come from a stationary distribution they will most likely be recognized as compatible with the current estimate see section iii c .
this will drive the value of a asymptotically toahi.
thus setting ahiclose to 1will provide smooth estimates of a stationary probability.
analogous considerations can be stated for the case of abrupt changes when the value ofawill be moved toward its lower bound alo.
however while it is quite safe to set ahivery close to bringing aloclose to 0reduces the filter s robustness to outliers.
indeed allows to set a threshold to decide if an input measurement is not compatible with the current estimate.
however there is always the chance that an extreme measurement is over the threshold and brings atowardsalo.
thus a more conservative choice of alois recommended if the input measures are known to have a high variance.
a rule of thumb to decide such value is that alocan be considered as the maximum degree of trust on a new input measurement.
however setting alo 3may produce a sensible slow down in change point tracking and should be done carefully.
the value of determines how fast to move from alo toahiand vice versa.
high values of are recommended to obtain prompt switches when a change occurs.
finally a hidden parameter to consider is the duration of a time step.
indeed longer time steps may allow to collect more events within the period which in turn improves the quality of the input measurements which are the transition frequencies computed over each time step .
however since the filter updates its estimates every time step extending their duration may slow down the filter reaction to changes.
iv.
f ormal assessment the proposed adaptive filter requires a constant number of operations each time step as easily observable from equation and the filter adaptation procedure in algorithm .
furthermore the operations are mostly elementary floating point operations and only a minimal amount of memory is required making our approach suitable to be executed even on low power devices e.g.
embedded systems .
an empirical estimation of the actual execution time on a general purpose computer will be shown in section vi.
icse florence italyhowever the low computational overhead was only one of our goals.
in this section we will formally prove several other critical properties of our approach.
the proofs will provide a theoretical guarantee about its applicability and the quality of its results.
an empirical assessment based on selected case studies and the comparison with state of the art alternatives will also be provided in section vi.
in section iv a we will prove the stability of our system i.e.
its ability to converge to a steady state equilibrium for every constant value of the input.
in section iv b we will prove that our filter is an unbiased and consistent estimator of the transition probabilities we aim at learning.
in section iv c we will precisely quantify the ability of our filter to reduce the noise in the input measurements i.e.
their variance under the weak assumption of gaussian distribution as a function of the filter s configuration parameters.
finally in section iv d we will assess the settling time required for our estimates to converge after a change as occurred.
a. stability a dynamic system is asymptotically stable if there exists an equilibrium point to which the system tends i.e.
for any given constant input the output converges to a specific value within a convenient accuracy regardless of the initial state .
as time tends to infinity the distance to the equilibrium point has to tend to zero.
our filter is formally defined by the dynamic system of equation .
in the following we will prove that the filter always converges to an equilibrium value regardless its initial conditions and for all the valid values of the input measures.
let be subject to the constant input pm k pm.
the corresponding equilibrium value bpcan be obtained by computing the fixed point solutions of the dynamic system bp a bp a pm whereais the equilibrium value for a k .
this yields the unique solution bp pm since the case a is excluded by construction equation .
also since at the computed equilibrium e because of equation we can compute the value of a as follows a a0 afa ethr hence for any pmthere is one equilibrium with bp pm and agiven by .
to prove the stability of all equilibria i.e.
the stability of the filter in every operating condition we can analyze the response of the system to a deviation from such equilibrium .
we define the system output variation with respect to the equilibrium value as bp k bp k bp combining equation with the last equation in bp k a k bp k a k pm k bp defining now the input variation with respect to the equilibrium value as pm k pm k pm we have bp k a k bp k a k pm k furthermore exploiting again the equilibrium e k jpm k pm bp k bp j jpm k bp k j and the estimator can be rewritten in input output variational form as a k a0 a fa jpm k bp k j ethr bp k a k bp k a k pm k for the purpose of the equilibrium stability it is required to study the motion of under the constant input corresponding to the equilibrium i.e.
with pm k .
this means analyzing the system a k a0 a fa jbp k j ethr bp k a k bp k given the bounds on a k inherent to fa br k in eventually converges to zero irrespectively of its initial value.
thus all the equilibria of the dynamic system in equation are globally asymptotically stable.
the stability proof guarantees the applicability of our learning approach under any possible valid input measurements in particular to learn the transition probability of any dtmc.
b. unbiasedness and consistency denoting with pothe true constant value of the measure to estimate from equation and the stability proof provided in the previous section it follows that lim k!1bp k po8bp hence we can state lim k!1e poand lim k!1e thus the estimator is asymptotically unbiased and consistent.
c. variance of the estimate consider the case where the input measurements provided to our filter are a realization of a white gaussian noise input i.e.
a gaussian distribution with mean 0and variance w i.e.
the simplest distribution allowing to arbitrarily set its variance .
for the sake of simplicity assume ato be a constant value.
the ratio of the output variance over the input variance w is theh2norm of the estimator i.e.
of the linear timeinvariant dynamic system with input pm k and outputbp k .
the z transform of the filter s transfer function is g z a z a itsh2norm can be expressed as jjgjj vuuttr 1x k 0g k gt k !
whereg k is the system s impulse response i.e.
the inverse ztransform of its transfer function .
in our case then g k z a z a a a k which leads to jjgjj vuut1x k a a 2k r a a2 icse florence italynote thatjjgjj 2tends to and0 whenatends to and respectively.
this means that the output variance is never greater than that of the input and is reduced by higher values ofa.
this is in line with the intuitive considerations on the impact of large and small values of aprovided in section iii a. d. convergence time for an intuitive analysis assume pm k undergoes a step from zero to one and that the convergence time kcis taken as the number of steps required to drive the estimation error magnitude down to the same threshold ethrused for switching from the fast tracking to the sharp filtering modes of the system by moving atowardsaloandahi respectively.
this immediately leads to determine kcas the minimum value of k s.t.ak lo ethr kc logethr logalo v. r elated work markov model learning and inferring of transition probabilities of a dtmc has been widely used in different domains .
two additional requirements for software engineering applications are the possibility of embedding experts or domain knowledge and the ability of performing the estimation online by continuously improving on the prior knowledge initially assumed.
one of the first approaches providing these features is kami .
this approach implements an established bayesian estimator to learn the transition probabilities of a dtmc online.
it requires a low computational overhead and provides high accuracy and noise filtering for the estimation of stationary processes.
however it provides slow responses in presence of changes .
the same authors faced the problem of change point detection again following a bayesian approach.
the resulting technique is designed to operate offline on recorded execution traces.
it is quite accurate in identifying change points however it involves the use of a gibbs sampling techniques to compute the posterior change point distribution .
such randomized method requires a large number of operations for each change point probe.
this requires a relatively high computational power which might be too expensive to be deployed on many embedded system.
the execution time is orders of magnitudes higher than the original approach.
in the authors propose an approach for the continuous tracking of time varying parameters of performance models.
the approach is based on extended kalman filters and is able to estimate also correlated parameters to take into account nonlinear constraints among their values and to embed a prior knowledge about the distribution to estimate.
however as reported by the authors kalman filters provide their optimal performance when the model describing the temporal evolution and the dependencies among parameters is linear.
despite having been proposed in the domain of performance the approach of can be easily adapted to also learn the time varying transition probabilities of a dtmc.
thesimplest way is to use a kalman filter to estimate each single transition probability and then to apply the correction strategy we introduced in section iii b for the transitions originating from the same state.
the configuration of the kalman filters requires specifying two parameters the measurement error covariancerand the disturbance error covariance q .
if we estimate each single transition probability independently the two matrices reduce to two scalar values randq representing the variance of the measurement error and the variance of the disturbance error.
informally a high value of rmeans a poor information from measures while a high value of qmeans high drift expected for the parameters estimates.
by tuning these two parameters it is possible to define a tradeoff between noise filtering thus smoother estimates and quick reaction to changes in the estimated probabilities.
another approach based on bayesian estimation that aims at overcoming the limitations of kami in presence of changing transition probabilities is the cove approach .
the basic intuition is to scale of each input measurement with an aging factor that gives more relevance to recent observations .
in presence of a change this input aging allows to quickly discard old information and to give more relevance to the new ones.
the configuration of this approach requires the specification of a prior knowledge for the distribution to estimate the confidence c0 0on such an initial prior and the value of a parameter cwhich determines the aging factors a input measurement which has been observed ttime steps ago it will be discounted by a factor in the order of t c. cove has been extended with a procedure to automatically adjust the values of c0and c .
in the special case for the aging factor c cove reduces to kami.
vi.
e xperimental evaluation in this section we report on the experimental evaluation of our lightweight adaptive filtering approach to learn transition probabilities of a dtmc.
we will benchmark it against related approaches with respect to i the estimation accuracy and ii the time required for the estimations.
following from the discussion in section v we selected for comparison the two algorithms by calinescu et al.
and zheng et al.
.
they will be referred to as cove andkalman respectively.
the three approaches will be compared in this section on six different change patterns.
on the first part of the comparison we will consider a selected case of each pattern for which visualizing the behavior of the estimates and assessing their accuracy.
the scope of the comparison will be then extended to a set of 000execution traces composed by both randomized realizations of each pattern and combination thereof.
finally we will report on the computation time required by the three approaches and discuss possible threats to validity.
accuracy metrics.
as accuracy metrics the mean average relative error mare similar to will be used mare 1nnx i p i p i p i icse florence italywhere p i represents the estimate at time i p i the actual value to estimate and nis the number of points.
experimental settings.
we implemented all the approaches in python v2.
and executed the experiments on a quadcore intel r xeon r cpu e31220 .10ghz with 32gb of memory and running an ubuntu server .
.
64bit.
the memory consumption of the three approaches was negligible.
our implementation is available at .
the three algorithms are compared on their performance on estimating the next state distribution of a state of a dtmc i.e.
a row of its transition matrix .
the input traces are composed by sequences of events.
each event is an integer number identifying the destination state of the taken transition.
this destination state is randomly selected according to known time varying transition probabilities.
for the sake of readability of the experiments the number of reachable states has been set to .
this choice does not affect the assessment of the accuracy of the estimates for none of the approaches since the accuracy of the estimates is not directly affected by the number of transitions.
the comparison of the execution times of the three approaches is also not effected by this choice since such time grows linearly with the number of reachable states for all the approaches.
thus the comparison is straightforwardly generalizable to larger problems.
explorative study.
figures 3a to 3f report how the three approaches perform with respect to six change patterns.
before going into details of these figure we briefly discuss the configuration settings for each of the three approaches.
tools configuration.
concerning cove we tried both the static parametrization proposed and the adaptive one introduced in .
the latter provides for an online tuning to trade accuracy for change reaction time.
however since the inter arrival time of the events in these settings is constant the online tuning method does not provide significant improvement on the optimal static configuration proposed in .
for this reason we report here the result of the superior static parameter settings with c0 and c .
forkalman we set the parameter qto the square of the maximum change to be captured in a single time step as recommended in which in our case yields q notably kalman filters are in general robust to bad initial values of qby continuously tuning their behavior on incoming data .
concerning the value of rjust general recommendations have been proposed in .
coherently with them we set r q .
this is also common practice in the area of control .
the kalman approach has been developed for tracking performance measures and is not directly applicable to the constraints of categorical probability distributions for dtmcs.
consequently we used it to estimate each single transition probability and then applied the same correction procedure we introduced for laf in section iii b. concerning laf we configured it to have prompt reactions to changes to consider as outlier a measure having maximum probability to occur and to provide relatively good filtering capabilities both while theestimated probability is stationary a hi and during its changes a lo .
notice that higher values of ahi would improve the noise reduction capabilities of laf but slow down its convergence after a change.
on the other hand lower values of alowould make the reaction to changes more drastic which has the counterpart of increasing the risk of erroneously following possible outliers.
finally while cove can update its estimates after each new event kalman andlaf update theirs every time step.
for this reason we defined a time step to occur every 75events.
this value is relatively small.
however a large time step may slow down the reaction to changes see section iii d .
experimental results.
we executed and compared the three approaches over six input data patterns that are commonly used to evaluated the related approaches noisy step ramp square wave triangle wave and outlier.
by covering these input data patterns we are stressing different aspects of the learning problem.
table i six patterns benchmark .
laf kalman cove noisy .
.
.
step .
.
.
ramp .
.
.
square .
.
.
triangle .
.
.
outlier .
.
.
the accuracy results mare for a single run of all the input patterns are reported in table i. for readability we report in figures 3a to 3f only the estimates of the probability of moving toward one target state.
for all the plots in figures 3a to 3f a dashed grey line represents the actual transition probability to estimate while the continuous black line represents its estimate.
in the following we discuss each of the six transition patterns and the performance of the three approaches.
noisy.
for this case figure 3a we do not sample from the actual stationary transition probabilities but we add them a white noise with standard deviation .
for laf andkalman this white noise adds to the unavoidable measurement noise.
after an initial transitory both laf and kalman roughly converge to the actual mean value of the estimated probability .
and provide similar values for the mare index.
in this situation laf has not perceived any significant change in the measures and is thus operation as a low pass filter with pole inahi.
hence increasing ahiwould lead to a slower initial convergence but smoother estimate as it is for kalman whose optimality properties in this scenario are well studied the worst accuracy of kalman is mostly due to the initial slow convergence .
cove converges almost immediately but with a poor filtering of the input noise.
step.
in the step change pattern the estimated probability suddenly changes from to0 .
kalman provides the smoothest estimates though at the price of a slower reaction to the change.
on the other hand laf promptly reacts to the change.
notice on figure 3b the exponential convergence toward the new estimate as expected from the stability proof and the settling time assessment of section iv .
the settling icse florence italytime can be improved by reducing the value of alo.
however too small values of it may lead to overshooting due to an overreaction.
while cove reacts immediately to the change its estimates keep being noisy.
notably in this case laf is about two times more accurate than the others.
ramp.
the estimate transition probability moves here linearly from .
to .
in 000time points.
this situation is particularly stressful for the change point detection mechanism of laf whose ethrgets continuously updated until the variance estimator converges to the new steady value.
the accumulation of the errors of the internal variance estimator and the main laf filter might lead to false positives during or right after the ramp as in figure 3c around time .
in this cases a not too small value of alo as a rule of thumb between and may reduce the deviation after the false detection and allow for a faster recovery as evident from the figure.
as expected from kalman can cope reasonably well with smooth changes however it is slower than laf which leverages change reaction to perform step shaped cuts of the estimate error see figure 3c around time 000and19 .
cove reacted immediately to the change and has been able to follow the ramp though with the usual noise.
also in this case laf is about two times more accurate than the others.
square wave.
the square wave amplifies the issues relate to the step change by allowing for a shorter learning time before each change.
while kalman suffers a slow convergence rate laf andcove follow the changes again with cove producing a more noisy output.
under this scenario the accuracy of laf is about three times higher than kalman while producing a smoother estimate than cove.
triangle wave.
in this case smooth changes between two probability values alternates periodically.
with respect to the case of ramp the slopes are steeper requiring a faster convergence to the estimators.
cove can follow the changes as quickly as for the ramp case.
kalman provides smooth estimates but its convergence time is too long and fails to follow the repeated changes.
on the other hand laf copes with the continuous changes by combining a shorter convergence rate of the adaptive low pass filter with occasional step shaped error cuts triggered by the change point detection mechanism as already observed for the ramp .
however as for the case of the ramp the continuously changing distribution may lead to the accumulation of internal estimation errors that increase the chance of false positives see time 000of figure 3e whose effects are recovered by alo .
outlier.
in the last case we artificially introduced an outlier with the duration of events.
laf and kalman show a negligible reaction to the outlier.
this is both due to the filtering actions of the two and to the fact that operating on a time window the impact of the outlier is already reduced by the preliminary computation the window s transition frequencies.
despite the triggering of a false change detection alo 3keeps the filter robust to outliers making it achieve an accuracy slightly higher then kalman whose effective in filtering outliers is known .
notice that as for the caseofnoisy the main loss of accuracy of kalman is due to the initial convergence.
the very fast reaction to change of cove made it quickly follow the outlier though recovering to the correct estimate right after.
general comments.
as final remarks we noticed that cove provides a very fast reaction to changes which make their presence almost irrelevant as for the impact on the mare.
this comes however at the price of having noisy estimates.
to obtain a similar behavior with laf bothaloandahihave to be set to very low values this way laf will approximate a low pass filter with a very small pole which looking at the equations would behave similarly to cove.
a well known problem of statistical estimation for probability values is the difficulty of catching rare events i.e.
with probability close to or close to since this implies another transition probability has to be very small .
this issue is present for the three approaches.
the stability prove of the two filters laf and kalman guarantees that they will eventually converge to the estimated probability however for such extreme cases the convergence time might be longer.
randomized pattern instances.
to further investigate the accuracy of our filter we generated for each pattern a set of1 random instances and analyzed the performance of the three approaches on this broader set of problems.
concerning the generation of the random instances noisy and outlier require to generate a baseline stationary distribution and respectively the standard deviation of the noise sampled between and and the duration of the outlier we take as amplitude half of the maximum gap allowed by the baseline distribution all the other patterns require to define two distributions and for the square and triangle wave patterns the period of the wave n withn2 .
the mares of the three approaches are reported in the first six boxplots in figure 3g.
notably the results for all the patterns resemble the accuracies reported in table i for the exploratory study thus the behavior of the three approaches in each of the six change patterns does not depend on average on the characteristics of the specific instance of such pattern.
finally the last box of figure 3g varmix shows the accuracy of the three approaches on long traces from to 000events obtained by sequentially combining multiple random instances of the six patterns.
the duration and of each instance and their oerder are randomized as well.
the results ofvarmix confirm the earlier results of the single patterns.
in particular kalman suffers from the presence of fast changes while the mare of cove is not significantly affected by these changes but by the high noise of its estimates.
runtime overhead.
on average over runs laf kalman and cove required and ms to process 000events.
consequently laf reduces the runtime overhead of kalman and cove.
notice that laf and kalman update their estimates every time window while cove updates every new measure.
threats to validity.
a threat to external validity is the use of predefined input data patterns for the comparison of icse florence italythe approaches and the ability to generalize these results to common traces of realistic software systems.
we have selectedthese inputs inline with common theory common practice incontrol theory to stress the response of dynamic systems step ramp and of filters in particular noisy periodic outlier and the related approaches and could observesimilar patterns also in qos data sets of web services andweb systems cp.
next section vii .
consequently we arguethat a good performance for these basic input data types willalso results in a good general performance.
the threats to internal validity include obviously the selection of the parameters c c qandrfor the related approaches and the number of events per time step.
we have specificallyselected these parameters with defaults that are also definedin the original papers.
furthermore parameter sweeps otherthe range of these parameters confirmed that they where goodchoices for our experiment.
another threat to internal validityis the implementation of the related approaches and measure ment environment.
as can be seen from the experimentalsetup we tried to avoid systematic measurement errors andfor the implementation we did follow the instructions for thealgorithms provided in the original literature.
vii.
a pplication to a realistic problem a common application of dtmc learning is to learn users behavior for a software system e.g.
.
this problem canbe refined to the scenario of estimating the probability of auser browsing from one webpage to another capturing onlinelog events.
to evaluate suitability of laf in this scenario we took the open logs of the world cup website .
the logs spread over a period of about months.
the website is composed of a total of over pages.
wemapped every webpage to a unique integer identifier.
eachline of the log includes a unique client id.
to identify aclient session we set a timeout of minutes after the lastoccurrence of the client id to consider the corresponding userdisconnected.
a session is thus described by the sequence ofpairs visited by a client.
during a session theclient is expected to move from one page to another followingnavigation links.
for demonstration purpose we show infigure the online estimation of the transition probabilityfrom the page english teams teambio160.htm to the page english competition statistics.htm .
the monitored webpage has been active for about days for a total of recorded transitions.
we reduced thegranularity of the observations by applying a sliding windowof seconds.
excluding the windows where no eventsoccurred windows have been processed.
the gray line represents the transition frequency observed during the corresponding window reported on the x axis.
theblack thicker line represents the value of the laf estimate.
since we do not know the real value to be estimated it is hard to evaluate the ability of laf to capture the average transition probability other than by visual inspection indeed a proper computation of mare would require to know the fig.
.
estimate of a transition probability from the worldcup98 case study x axis in time windows .
actual transition probability of whom the observed transition frequencies are realizations .
however it is easy to recognizein figure the occurrence of several patterns we analyzedpreviously in this section for which a deep quantitative inves tigation has been provided.
the execution time over runs to estimate the transition probabilities from the observed state destination states have been and ms forlaf kalman and cove respectively.
since cove operates per transition its execution time is higher than laf and kalman which instead updates their estimates every transitions andperformed inline with the results on the benchmark patterns.overall with the new algorithm laf we have been able to process the data for this realistic case and we could confirmthe results of the experimental evaluation.
viii.
c onclusions in this work we presented a lightweight adaptive filter for online learning of the transition matrix of a dtmc.
weproved it is stable and provides an unbiased and consistentestimate of the transition probabilities.
we also quantified itsability to reduce the variance of noisy input measurementsand its convergence time after a change has occurred.
thefilter introduces a minimal computational overhead beingable to process events in about .
seconds on a general purpose computer.
its memory demand does notdepend on the number of events to be processed and it is fairlynegligible.
the experimental results show an high accuracy ofthe obtained estimates.
we plan to extend this work along several directions.
first we will expand the developed algorithm to other probabilisticquality evaluation models including queueing networks forperformance analysis and integrate it into a general frameworkfor continual verification .
second we plan to increase theorder of the filter to further improve its ability of trading offreaction to changes versus robustness to outliers.
finally weplan to investigate the combination of laf with forecastingtechniques for proactive problem detection.
a cknowledgements this work has been partially supported by the dfg german research foundation under the priority programme spp1593 design for future managed software evolution.
icse florence italy0.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
a stationary signal with white noise .
.
.
.
.
.
.
.
.
.
.
.
.
b step gap .
.
.
.
.
.
.
.
.
.
.
.
.
c ramp gap duration steps .
.
.
.
.
.
.
.
.
.
.
.
.
d square wave gap period steps .
.
.
.
.
.
.
.
.
.
.
.
.
e triangle wave gap period steps .
.
.
.
.
.
.
.
.
.
.
.
.
f outlier gap duration steps .
.
.
.
.
.
.
.
.
noisy outl ramp squar step trian varmix .
.
.
.
.
.
.
.
.
noisy outl ramp squar step trian varmix .
.
.
.
.
.
.
.
.
noisy outl ramp squar step trian varmix g boxplots of the relative error over random instances of the six change patterns and combinations thereof.
fig.
.
first six rows estimates of the probability of moving toward the first state obtained by laf left column kalman central column and cove right column .
last row iqr boxplots of the relative errors obtained over random instances of the six patterns and combinations thereof.
icse florence italyreferences a. aziz k. sanwal v .
singhal and r. brayton model checking continuous time markov chains acm trans.
comput.
log.
vol.
no.
pp.
jul c. baier j. p. katoen and h. hermanns approximate symbolic model checking of continuous time markov chains in proceedings of the 10th international conference on concurrency theory concur vol.
.
springer pp.
c. baier b. r. haverkort h. hermanns and j. p. katoen model checking algorithms for continuous time markov chains ieee trans.
softw.
eng.
vol.
no.
pp.
a. bianco and l. de alfaro model checking of probabilistic and nondeterministic systems in proceedings of the 15th conference on foundations of software technology and theoretical comp.
science fsttcs vol.
.
springer pp.
h. hermanns j. p. katoen j. meyer kayser and m. siegle a tool for model checking markov chains international journal on software tools for technology transfer sttt vol.
no.
pp.
feb m. z. kwiatkowska g. norman and d. parker probabilistic symbolic model checking with prism a hybrid approach int.
journal on software tools for technology transfer sttt vol.
no.
pp.
aug l. grunske specification patterns for probabilistic quality properties in30th international conference on software engineering icse .
acm pp.
l. baresi e. d. nitto and c. ghezzi towards open world software issues and challenges ser.
sew.
ieee pp.
b. h. c. cheng r. de lemos h. giese p. inverardi j. magee j. andersson b. becker n. bencomo y .
brun b. cukic g. d. m. serugendo s. dustdar a. finkelstein c. gacek k. geihs v .
grassi g. karsai h. m. kienle j. kramer m. litoiu s. malek r. mirandola h. a. m uller s. park m. shaw m. tichy m. tivoli d. weyns and j. whittle software engineering for self adaptive systems a research roadmap in software engineering for self adaptive systems ser.
lncs vol.
.
springer pp.
.
r. calinescu k. johnson y .
rafiq s. gerasimou g. c. silva and s. n. pehlivanov continual verification of non functional properties in cloud based systems in proceedings of the 5th international workshop non functional properties in modeling analysis languages and processes miami usa september vol.
pp.
.
g. s. blair n. bencomo and r. b. france models run.time ieee computer vol.
no.
pp.
i. epifani c. ghezzi r. mirandola and g. tamburrelli model evolution by run time parameter adaptation in proceedings of the 31st international conference on software engineering icse .
ieee pp.
a. filieri c. ghezzi and g. tamburrelli a formal approach to adaptive software continuous assurance of non functional requirements formal aspects of computing vol.
pp.
r. calinescu y .
rafiq k. johnson and m. e. bakir adaptive model learning for continual verification of non functional properties inacm spec international conference on performance engineering icpe dublin ireland march .
acm pp.
t. zheng c. m. woodside and m. litoiu performance model estimation and tracking using optimal filters ieee trans.
softw.
eng.
vol.
no.
pp.
i. epifani c. ghezzi and g. tamburrelli change point detection for black box services in proceedings of the 18th acm sigsoft international symposium on foundations of software engineering fse .
acm pp.
r. calinescu k. johnson and y .
rafiq using observation ageing to improve markovian model learning in qos engineering in second joint wosp sipew international conference on performance engineering icpe .
acm pp.
a. filieri l. grunske and a. leva lightweight adaptive filtering for dtmc learning supplementary material publications preprints icse .
hewlett packard labs worldcup98 web logs html contrib worldcup.html.
c. baier and j. p. katoen principles of model checking.
mit press .
w. pestman mathematical statistics ser.
de gruyter textbook.
de gruyter .
s. ross stochastic processes ser.
wiley series in probability and statistics probability and statistics.
wiley .
t. w. anderson and l. a. goodman statistical inference about markov chains the annals of mathematical statistics vol.
no.
pp.
.
c. chatfield statistical inference regarding markov chain models j. r. stat.
soc.
vol.
no.
pp.
.
a. immonen and e. niemel survey of reliability and availability prediction methods from the viewpoint of software architecture sosym vol.
no.
pp.
r. c. cheung a user oriented software reliability model ieee trans.
softw.
eng.
vol.
no.
pp.
a. filieri c. ghezzi v .
grassi and r. mirandola reliability analysis of component based systems with multiple failure modes component based software engineering cbse pp.
m. kwiatkowska quantitative verification models techniques and tools in proceedings of the the 6th joint meeting of the european software engineering conference and the acm sigsoft symposium on the foundations of software engineering esec fse .
acm pp.
a. filieri c. ghezzi and g. tamburrelli run time efficient probabilistic model checking in proceedings of the 33rd international conference on software engineering icse .
acm pp.
r. calinescu l. grunske m. z. kwiatkowska r. mirandola and g. tamburrelli dynamic qos management and optimization in servicebased systems ieee trans.
softw.
eng.
vol.
no.
pp.
a. filieri c. ghezzi a. leva and m. maggio self adaptive software meets control theory a preliminary approach supporting reliability requirements in proceedings of the 26th ieee acm international conference on automated software engineering ase .
ieee cs pp.
reliability driven dynamic binding via feedback control insoftware engineering for adaptive and self managing systems seams icse workshop on june pp.
a. filieri and c. ghezzi further steps towards efficient runtime verification handling probabilistic cost models in proceedings of the first international workshop on formal methods in software engineering rigorous and agile approaches ser.
formsera .
ieee press pp.
.
i. meedeniya and l. grunske an efficient method for architecturebased reliability evaluation for evolving systems with changing parameters in ieee 21st international symposium on software reliability engineering issre .
ieee cs pp.
c. robert the bayesian choice from decision theoretic foundations to computational implementation ser.
springer texts in statistics.
springer .
a. law simulation modeling and analysis ser.
mcgraw hill series in industrial engineering and management science.
mcgraw hill education .
k. astr om and b. wittenmark computer controlled systems theory and design.
dover publications .
w. levine the control handbook ser.
electrical engineering handbook.
taylor francis .
icse florence italy f. cellier and e. kofman continuous system simulation.
springer .
k. ito and k. kunisch lagrange multiplier approach to variational problems and applications ser.
advances in design and control.
society for industrial and applied mathematics .
h. w. kuhn and a. w. tucker nonlinear programming in proc.
2ndberkeley symposium on mathematical statistics and probabilistics.
berkeley university of california press pp.
.
d. knuth the art of computer programming seminumerical algorithms ser.
addison wesley series in computer science and information processing.
addison wesley .
c. robert and g. casella monte carlo statistical methods ser.
springer texts in statistics.
springer .
c. chatfield the analysis of time series an introduction ser.
chapman hall crc texts in statistical science.
taylor francis .
a. filieri h. hoffmann and m. maggio automated design of self adaptive software with control theoretical formal guarantees inproceedings of the 36th international conference on software engineering icse ser.
icse.
acm pp.
a. amin l. grunske and a. colman an automated approach to forecasting qos attributes based on linear and non linear time series modeling in proceedings of the 27th ieee acm international conference on automated software engineering ase .
ieee sept pp.
c. ghezzi m. pezz e m. sama and g. tamburrelli mining behavior models from user intensive web applications in proceedings of the 36th international conference on software engineering icse .
acm pp.
a. amin a. colman and l. grunske an approach to forecasting qos attributes of web services based on arima and garch models in proceedings of the ieee 19th international conference on web services icws .
ieee june pp.
icse florence italy