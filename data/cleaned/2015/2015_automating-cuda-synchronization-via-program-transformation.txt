automating cuda synchronization via program transformation mingyuan wu department of computer science and engineering southern university of science and technology shenzhen china mail.sustech.edu.cnlingming zhang department of computer science university of texas at dallas dallas usa lingming.zhang utdallas.educong liu department of computer science university of texas at dallas dallas usa cong utdallas.edu shin hwei tan department of computer science and engineering southern university of science and technology shenzhen china tansh3 sustech.edu.cny uqun zhang department of computer science and engineering southern university of science and technology shenzhen china zhangyq sustech.edu.cn abstract while cuda has been the most popular parallel computing platform and programming model for generalpurpose gpu computing cuda synchronization undergoes significant challenges for gpu programmers due to its intricate parallel computing mechanism and coding practices.
in this paper we propose aucs the first general framework to automate synchronization for cuda kernel functions.
aucs transforms the original llvm level cuda program control flow graph in a semantic preserving manner for exploring the possible barrier function locations.
accordingly aucs develops mechanisms to correctly place barrier functions for automating synchronization in multiple erroneous challenging to be detected synchronization scenarios including data race barrier divergence and redundant barrier functions.
to evaluate the effectiveness and efficiency of aucs we conduct an extensive set of experiments and the results demonstrate that aucs can automate out of erroneous synchronization scenarios.
index t erms cuda program repair synchronization automation program transformation i. i ntroduction cuda has recently become a dominating parallel computing platform and programming model for general purpose gpu gpgpu computing due to its advantages in simplifying i o streams to memories and dividing computations into sub computations by parallelizing programs in terms of grids and blocks and enabling more flexible cache management that speeds up the floating point computation of cpus.
cuda is thus considered rather powerful and widely adopted in deep neural network related applications for efficiently processing relevant matrix computations.
albeit its advantages in gpu computing cuda programming undergoes significant challenges for gpu programmers due to its specific parallel computing mechanism and coding practices .
since cuda based gpu programs enable synchronization which significantly differs from cpu corresponding authorprograms by using barriers rather than locks and applying happens before relations gpu programmers are expected to be competent domain experts for delivering correct program outputs with limited benefits from their knowledge of traditional cpu programs.
however the synchronization management skills of gpu programmers can be seriously challenged.
in particular since massive parallelism in cudabased gpu computing can be invoked by ballooning excessive thread interleavings any two from thousands of threads accessing the same memory cell might trigger a data race and lead to incorrect computation results which are somewhat hard to be discovered by gpu programmers .
moreover programmers unawareness of using third party programs libraries of kernel functions can be another major reason to cause program execution failures.
for instance a data race can also be caused when programmers mistakenly delegate synchronization to the third party programs or libraries which are not designed for such purpose .
therefore it is essential to assist gpu programmers by automating synchronization of cuda programs for effectively developing gpu programs.
in this paper we propose aucs which to the best of our knowledge is the first general framework to automate llvmlevel synchronization for cuda programs in multiple erroneous synchronization scenarios.
to be specific we automate cuda synchronization in llvm bitcode instead of source code because integrated as part of compiler optimization llvm level synchronization can be effective in concealing programming details from gpu programmers such that they can focus on delivering high level program functionalities and automating source code level synchronization via patching can possibly deteriorate the source code with inferior readability and maintainability.
we first specify the erroneous cuda synchronization scenarios the data race scenario that occurs when programmers fail to implement synchronization inside kernel functions the barrier divergence scenario that occurs when program7482019 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
mers implement incorrect synchronization to cause barrier divergence inside kernel functions and the redundant barrier function scenario that occurs when programmers implement redundant synchronization inside kernel functions .
next aucs transforms the scenarios to be their corresponding automatic bug repair problems and solves them in their llvmbitcode level respectively.
in particular aucs leverages a llvm bitcode tool that automatically detects cuda synchronization bugs.
based on the detected cuda bugs aucs applies a llvm level program transformation rule to transform the original llvm bitcode control flow graph cfg while preserving the original semantics.
our program transformation is able to expose the possible barrier function locations in the original program or create the potential barrier function location when no such location exists in the original program.
as a result aucs develops a set of mechanisms to automate synchronization under multiple synchronization scenarios i.e.
correctly placing barrier functions for eliminating data race and barrier divergence and removing unnecessary barrier functions after detecting the synchronization problem.
eventually aucs can automatically enable correct synchronization in llvm bitcode of cuda kernel functions to alleviate the concerns and cost from gpu programmers on implementing correct synchronization in source code.
to evaluate the effectiveness and efficiency of aucs on automating synchronization for cuda programs we conducted a set of experiments based on a real world benchmark which consists of four github projects with erroneous synchronization scenarios.
our experimental results suggest that aucs can effectively automate synchronization for cuda kernel functions by fixing data race bugs barrier divergence bugs and redundant barrier divergence bugs in their llvm bitcode in relatively short time.
in summary our paper makes the following contributions to the best of our knowledge we develop the first general framework namely aucs that automates synchronization for cuda kernel functions by correctly placing barrier functions in their corresponding llvm bitcode.
we introduce a set of program transformation rules that automatically generate synchronization for cuda programs at the llvm bitcode level.
our transformation rules aim to preserve the semantics of the modified programs.
we evaluate aucs under multiple experimental setups.
the results suggest that aucs is able to automate synchronization under most of the erroneous synchronization scenarios in the studied projects under limited time cost.
the rest of the paper is organized as follows.
section ii introduces the background of this paper including cuda overview parallel computing mechanism synchronization bug types and llvm bitcode.
section iii introduces a motivating example to illustrate the challenges on automating synchronization for cuda programs.
section iv demonstrates aucs including the proof for the semantic preserving property of its program transformation and the corresponding mechanismsgrid block ......thread thread thread thread thread threadblock ......thread thread thread thread thread thread fig.
cuda hierarchy of automating synchronization under multiple scenarios.
section v presents the evaluation on the effectiveness and efficiency of aucs .
sections vi to viii present the related work threats to validity and conclusions of the paper respectively.
ii.
b ackground in this section we give an overview on cuda the cuda parallel computing mechanism typical cuda synchronization bugs and the llvm level cuda synchronization bug detection.
a. cuda overview and parallel computing mechanism cuda provides a runtime library and an extended version of c c for gpu programmers such that they can use gpu hardware for general purpose computing.
cuda operates on a heterogeneous programming model where it involves both the cpu and gpu.
in cuda the host refers to the cpu and its memory while the device indicates the gpu and its memory .the device programs need to be allocated with resources from host programs prior to execution.
eventually the allocated resources e.g.
global memory need to be retrieved after cuda program execution.
a typical cuda program contains three runtime stages host resource preparation kernel function execution and host resource retrieval.
in particular a kernel function refers to the part of cuda programs that is invoked during device execution and is the focus of this paper.
thread is the basic execution unit in kernel functions.
specifically in the physical level a warp is a set of threads all of which are expected to execute the same instruction at any time except when incurring branch divergence while in the logic level cuda imposes a hierarchy where a block contains one or more threads and a grid contains one or more blocks.
kernel functions are executed by setting dimensions of grids and blocks.
these functions divide computation into sub computations and dispatch each sub computation to different threads accordingly.
eventually the results of subcomputations can be merged as the final result of the overall computation through applying algorithms such as reduction.
figure shows the hierarchy of the parallel computing mechanism of cuda kernel functions.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
tid threadidx .x .... if y a c fval2reduce f else fval2reduce infinity syncthreads fix by adding syncthreads get block min will write data to f val2reduce int ip get block min f val2reduce f idx2reduce float up value p f val2reduce .... fig.
an example of data race .... sdist dist sidx s idx removing the barrier function next line syncthreads fix b y m o v i n g the barrier out .
syncthreads fig.
an example of barrier divergence b. cpu synchronization vs. cuda synchronization traditional cpu programs e.g.
java programs use a lockbased mechanism to synchronize different threads.
in particular instead of accessing memory with other threads as a group at the same time a thread accesses a memory cell shared with other threads by acquiring a lock from the memory cell.
if the lock is free the thread obtains the lock accesses the memory cell and continues executing the remain statements while other threads have to enter pending state until the lock is released.
otherwise the thread enters pending state.
different from cpu synchronization cuda synchronization applies barriers to synchronize threads where all the threads in one block must wait before any can proceed.
in particular a barrier is represented as a barrier function syncthreads in cuda kernel functions.
when a thread reaches a barrier function it is expected to proceed to next statement if and only if all the threads from the same block have reached the same barrier function.
c. cuda synchronization bug patterns according to there are three major synchronization bug types in cuda kernel functions data race barrier divergence and redundant barrier function.
data race.
data race refers to that the visit order of read write actions or write write actions from two or more threads cannot be determined in cuda programs.
figure presents an example with bug fixing revision no.
febf515a82 in the file smo kernel.cu of one highly rated github project thundersvm .
we can observe that the if statement writes to the memory of f val2reduce meanwhile the function get block min writes to the same memory inside the device.
this causes a write write bug and could be fixed by inserting syncthreads .
int tid threadidx .x smedian f l t max sidx syncthreads if i iterations ... sidx i smedian m .... fig.
an example of redundant barrier function barrier divergence.
a barrier divergence occurs when more than one threads belonging to the same block complete their tasks and leave the barrier while some other threads in the same block have not reached the barrier yet.
a sample barrier divergence can be found in the bug fixing revision no.
0ed6cccc5ff in the file nearest neighbour.hpp from the project arrayfire presented in figure where it can be observed that all the threads in the same block are ensured to reach the same barrier in every execution of the kernel function by moving the statement of syncthreads outside the given branch.
redundant barrier function.
a barrier function is defined to be redundant when no data race is triggered after deleting it.
a redundant barrier function can result in the inferior program performance in terms of time and memory usage.
for instance a sample redundant barrier function can be found in the bug fixing revision no.
31761d27f01 in the file kernel homography.hpp from the project arrayfire presented in figure .
we can observe that the associated block is one dimensional since from line the value of tid is assigned only from threadidx.x .
moreover the tid s are identical among different threads from the same block.
therefore only one thread is allowed to access s median and s idx leading to a redundant barrier function in line since no race can be triggered in s median o r s idx after deleting the barrier function.
d. llvm level cuda synchronization bug detection low level virtual machine llvm is a compiler framework for program analysis and transformation of source code where llvm bitcode is a low level code representation in static single assignment ssa form .
in particular llvm bitcode includes the following novel features languageindependent type system type conversion and low level address arithmetic instructions and low level exception handling instructions.
simulee is a llvm level cuda synchronization bug detection tool.
in particular it first uses evolutionary programming to automatically generate the input for kernel functions that can trigger cuda synchronization bugs.
next by simulating kernel function execution with the buginducted input simulee detects synchronization bugs and the associated locations in the original program.
moreover there are other synchronization bug detection approaches for cuda authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
programs e.g.
gpuv erify civl and esbmcgpu which are designed for source code level other than llvm bitcode level synchronization bug detection.
in this paper we use simulee to detect cuda synchronization bugs for automating cuda synchronization because it can detect multiple bug types including data race redundant barrier function and barrier divergence automatically and it can simulate runtime cuda programs without incurring much overhead for extra processing e.g.
searching which makes it more efficient than the static dynamic analysis based approaches that usually demand large search space .
iii.
m otiv a ting example in this section we use a sample code snippet to illustrate why automating synchronization is beneficial and challenging for developing cuda kernel functions.
in particular the sample code snippet is chosen from gkleetest and presented in figure while its corresponding llvm bitcode is presented in figure and its control flow graph cfg is presented in figure .
assuming the grid dimension is and the block dimension is it can be derived that the code snippet in figure introduces a data race bug between lines and when executing the kernel function.
specifically when num elements is set to thread writes data toinput array while thread reads data from input array and thread writes data to input array while thread read data from input array .
correspondingly in its llvm bitcode such race takes place between label and label in figure .
data race in cuda programs can be fixed by adding barrier functions.
for instance in figure since the data race takes place in different branches a barrier function should be added into one of the branches e.g.
either label or label in figure .
however it would lead to barrier divergence.
to illustrate in figure by adding a barrier function in label the thread that executes label would never reach that barrier function and vice versa.
to conclude a complete automatic synchronization mechanism for cuda kernel functions can be challenging because it should not only automatically detect and fix the existing synchronization bugs in the original cuda kernel functions i.e.
data race barrier divergence and redundant barrier functions but also avoid potential barrier divergence caused by adding barrier functions for fixing data race.
hence we formulate the automatic synchronization problem for cuda programs as a problem of identifying the correct locations for placing barrier functions .
in this example a barrier function is expected to be added in the basic block between label and label if there is any to fix the data race without causing barrier divergence for automating synchronization for cuda kernel functions.
however since no such basic block exists fixing this data race remains challenging.iv .
a pproach in this section we propose aucs a general framework that automatically synchronizes cuda kernel functions.
since automating synchronization for cuda kernel functions is essentially locating barrier functions properly how to locate barrier functions properly is the key process.
in aucs w e first propose a program transformation rule to transform llvm bitcode cuda programs llvm cuda for identifying barrier function locations and provide proofs for ensuring its semantic preserving property.
next we demonstrate how aucs leverages our transformed llvm cuda to automate synchronization for cuda kernel functions.
a. program transformation based on the cfg concepts it can be derived that a barrier function should only be placed in a proper basic block of the program for correct execution without incurring synchronization bugs.
specifically correctly placing barrier function is equivalent to detecting whether there exists such basic block and if not whether it is possible to create such basic block.
moreover it is essential to preserve the original semantics after such program simplification.
for instance in figure with a semantic preserving program structure simplification approach we can generate a basic block between label and label by changing the original cfg for placing a barrier function to fix the data race without changing the original program semantics.
in the following we propose a semantic preserving program transformation approach for correctly placing barrier functions.
specifically we first list a set of definitions for constructing llvm cuda cfgs.
next based on the definitions we propose a set of program transformation rules.
at last we prove that such program transformation rules are semanticpreserving.
definition label refers to llvm bitcode label which is a set with multiple statements of llvm bitcode programs corresponding to cuda kernel functions.
each statement belongs to a label .
different labels are connected by br instructions as presented in figure .
in particular label is the fundamental component for cfg which contains multiple llvm instructions in llvm bitcode such that the original cuda program semantics can be maintained in llvm bitcode.
stable label is a label which does not contain any write instruction.
branch graph is a directed acyclic graph that represents a llvm bitcode program without loop edges .
its nodes and edges are the same as in a llvm bitcode cfg except for loop edges .
execution path refers to a single thread s label sequence in a complete execution of a cuda kernel function.
note that the intersection of two execution path s is a set of labels belonging to both execution path s. loop edge refers to a transition relation between two labels .
suppose there is an execution path authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
global void device global unsigned int input array int num elements int my index blockidx .
x blockdim .
x threadidx .x stop out of bounds access if m y index num elements if m y index input array my index else input array input array fig.
c version for gkleetest example1define void z13device globalpji i32 input array i32 num elements alloca i32 align ... br i1 label label label .
.
.
br i1 label label label .
.
.
br label label .
.
.
br label label br label label ret void fig.
llvm version for gkleetest example entry end label 15label label label 11label label fig.
topological structure of llvm where the first is executed before than the first .
the transition from to is defined as a loop edge .
basic block is a label that intersects all the possible execution path s of a cuda kernel function.
program state is a key value dictionary structure that records all the states of a cuda kernel function where the keys refer to the variables names and the values refer to their corresponding runtime values.
entry condition is a boolean expression for a single label .i fa n execution path satisfies entry condition it would contain its corresponding label .
the value of entry condition is computed by one or more variables in program state .
branch independent is a relation between two different labels .
suppose that we have one label named the other label named .
if there is no path from to and no path from to in their branch graph then and are defined to be branch independent .
semantic independent suppose that there are two different execution path s named 1and 2 i f 1 2 2and their difference set 1 2does not contain any write instruction then 1and 2are defined to be semantic independent .f o r instance assume that 1 and 2 .
it can be derived that 1 2 .
assuming that b andddo not contain any write instruction 1and 2 are semantic independent .
we adopt the small step operational semantics for llvm cuda from gklee .
figure presents an excerpt of our modification on the llvm cuda syntax which are current label and entry condition .
figure shows the correspondingprogram state var mapsto value current label p label entry condition c fig.
syntax for modified llvm cuda stmt brpi p t p label mapsto p i stmt brcipipj turnstileleftci p t p label mapsto p i stmt brcipipj turnstileleft ci p t p label mapsto p j fig.
llvm cuda transition rules for label operational semantics for the llvm cuda transition rules.
in particular current label refers to the label executed by the current program counter.
when statement br pi is executed the current label is changed to pi without any condition according to rule .
in rule and rule if entry condition ci is true current label is changed to pi otherwise pj .
program transformation llvm cuda transformation is initialized by deriving the topological sorting of the branch graph .
accordingly the original cfg is restructured by adding one basic block between two topologically adjacent labels with setting their edges based on figure .
the details of the program transformation are presented in algorithm where delete edge without loop deletes the edges of the given label except loop edges set condition edge creates a conditional edge between label s according to rule and rule in figure and set edge creates a non conditional edge between labels according to rule in figure .
specifically program transformation is initialized to obtain a topological ordering of branch graph at line .
next each label is parsed as topological ordering at line .
in line the entry condition is resolved for the current label followed by deleting the original edges of each label except loop edges at line .
from authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
entry end a d b c a before transformation entry end a b c d basic block created by algorithm b after transformation fig.
an example of program transformation algorithm transformation input branch graph graph conditions output graph function transforma tion topology topological sort branch graph previous node label for each label in topology do enter condition conditions next node label delete edge without loop each label graph set condition edge previous node enter condition each label graph set condition edge previous node !enter condition next node graph set edge each label next node graph previous node next node return graph line to line the current label generates a new predecessor label with a entry condition satisfaction edge pointing to it and a new successor label with a entry condition satisfaction edge pointed from it.
in addition the generated predecessor label points to the generated successor label with a entry condition dissatisfaction edge.
for instance an example of program transformation is demonstrated in figure where figure a and figure b both refer to the identical cfg.
the circle nodes in figure a represent the original label s before program transformation and the rectangle nodes in figure b represent the generated label s after program transformation .
algorithm is input with the function for extracting entry condition for each label demonstrated in algorithm which is initialized by a branch graph and an empty dictionary in which label is a key and a entry condition which is the corresponding value.
the entry condition for each label is generated according to rule and rule .
in rule airefers to the boolean expressions set owned by i th predecessors of label .
in rule airefers to a single boolean expressionalgorithm construct label conditions input branch graph output condition dict function construct condition topology topological sort branch graph cond dict for each label in topology do labels find pre label each label cond lst list for label labels do iflabel transmits condition to each label then cond lst.append cond condition else cond lst.append cond for each cond cond lstdo ifcond is empty then cond each cond cond cond each cond for each label cond do final cond empty logic expression for condition cond do final cond final cond condition cond final cond return cond belonging to cond .
algorithm is initialized with collecting boolean expressions for each label according to rule .
then the entry condition for each label is generated by rule .
from line the cond of each label is constructed based on rule and the entry condition for labels is generated based on rule from line where find pre label in line is implemented to find all the predecessors of the given label .
consider the example in figure .
suppose that the br instruction of label is based on a boolean expression 0 when 0istrue label transits to label .
thus the cond label 0 .
suppose that the br instruction of label is based on a boolean expression 1 label transits to label when 1istrue otherwise transits to label .
as a result the cond 0 1 andcond 0 1 .
therefore using rule we obtain cond bycond label cond 0 .
and the entry condition forlabel is 0based on rule .
cond m intersectiondisplay i 1ai m predecessor number entercondition n logicalanddisplay i 1ai n cond semantic reserving theorems in this section we propose and prove two theorems to validate that our program transformation is able to preserve the semantics of the original program where theorem is the basis of theorem .
theorem .
given a llvm cuda cfg and its branch graph i ft w o labels are branch independent in their entry authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
condition s cannot be both true.
proof.
the proof will be done by contradiction.
consider two labels and from which are branch independent for the lowest common ancestor of and there exists a boolean variable for .
when is true is defined to be added into execution path otherwise is defined to be added into execution path .
suppose that and have the same entry condition .
this indicates that there exists at least one descendant label of which reassigns .
since llvm static single assignment ssa form enforces that each variable is only assigned once in a single label this leads to a contradiction.
thus if two labels and are branchindependent in their entry condition s cannot be both true.
therefore theorem holds.
theorem .
given a llvm bitcode cfg for each execution path in there exists a semantic independent execution path contained in the generated cfg byprogram transformation given and its branch graph as input.
proof.
we prove that theorem holds by induction on the number of label s num label .
fornum label this is the case where there is an execution path 1generated from with one label whose initial entry condition is 1. accordingly an execution path 2with two labels can be generated in cfg by passing 1to cfg where one label is a stable label created by program transformation and the other is the label in 1.a s 2contains a stable label without write instruction and the only label of 1. therefore 1and 2 satisfy the conditions of being semantic independent .
suppose that theorem holds for num label n .
for num label n this is the case where there exists an execution path 1generated from with n labels and the program state at the n th label is epsilon1.
as theorem holds when num label n an execution path 2issemantic independent with 1 s n previous labels .
accordingly epsilon1is contained in 2and program state is the same between 1and 2 before epsilon1.
therefore if epsilon1has a loop edge jump according toprogram transformation such loop edge is reserved in with the identical successor label in both 1and 2according to rule .
on the other hand if epsilon1does not have a loopedge jump the successor label of 2can be determined either from the labels it points to or the branch independent labels .
suppose that the successor label in 1is epsilon11 since the current program state of 2is the same as 1 epsilon11 sentry condition in 2is also satisfied.
thus epsilon11can be one successor label in 2 according to rule .
as a result it can be ensured that there are only basic block s generated by program transformation between epsilon1and epsilon11because if there exists any other label between epsilon1and epsilon11in then it must be branch independent with epsilon11.
according to theorem their entry condition s cannot be both true and according to rule the basic block generated by program transformation is always selected when the other choice is branch independent .
the final state for this situation is presented at figure .
therefore all the elements of the difference set 2 1arestable label s. hence 2and 1are semantic independent fornum label n. thus theorem is true.
1 bracketleftbig ... bracketrightbig 2 bracketleftbigg square ... square bracehtipupleft bracehtipdownright bracehtipdownleft bracehtipupright basic block ... square ... square bracehtipupleft bracehtipdownright bracehtipdownleft bracehtipupright basic block 1 bracketrightbigg fig.
if epsilon1does not have a loop jump to epsilon11 to conclude it can be derived that by applying the program transformation rule we are able to transform the original complex cfg structure by generating basic block with stable label s while preserving the original semantics.
therefore to properly locate barrier functions the original cuda kernel functions can be transformed to be to properly locate barrier functions in the generated stable label s. b. overall framework of aucs figure presents the overall framework of aucs .aucs is initialized by compiling cuda kernel functions to llvm bitcode and using simulee to detect synchronization for such llvm bitcode.
in particular a data race bug is reported as a pair of statements executed by different threads.
barrier divergence bugs and redundant barrier function bugs are reported with the locations of their associated buggy barrier functions.
next aucs transforms the original program based on program transformation rule s. in particular aucs flattens the original llvm bitcode by adding extra stable label s. for data race bugs aucs provides a mechanism to find the appropriate stable label for placing barrier functions.
for barrier divergence bugs aucs first removes the buggy barrier functions and then applies the mechanisms for handling data race for properly placing barrier functions.
for redundant barrier functions based on the memory model generated from simulee aucs detects and removes all redundant barrier functions in given kernel function.
at last aucs automatically captures the erroneous synchronization in llvm cuda and fixes them.
recognizing synchronization bugs based on the aforementioned definitions in section iv a1 cuda synchronization bugs can be depicted as follows.
data race can occur in an intra label and inner label manner.
specifically the statements which incur data race bugs can be grouped as inner label statements where such statements belong to the identical label and intra label statements where such statements belong to different labels .
barrier divergence is only possible to occur when a barrier function is located in a non basic block label .
automating data race scenarios since it is possible to incur barrier divergence by adding barrier functions to fix data race as in section iii aucs attempts to fix data race without incurring barrier divergence for both inner label and intra label data race inducted statements.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
overview of aucs algorithm auto synchronization for data race input label label branch graphb graphg output graph function auto sync race topology topological sort b iflabel topology label 1then swap label label iflabel 1i s basic block then add barrier at label return graph iflabel 2i s basic block then add barrier at label return graph predecessor find basic predecessor label b successor find basic successor label b predecessor find basic predecessor label b successor find basic successor label b ifsuccessor negationslash successor 2then add barrier at successor return graph sub br extract graph b predecessor successor sub graph extract graph g predecessor successor cond construct condition sub br sub graph transform sub br sub graph cond replace original graph g sub graph successor1 insert barrier at the new predecessor basic block of label return graph intra label statements.
for a data race incurred among intra label statements aucs first sorts the execution order of the two associated labels.
next it identifies their respective predecessor and successor basic block s.aucs would determine if it needs to apply program transformation based on whether the two labels share the identical predecessor successor basic block s. lastly aucs adds barrier functions accordingly.
we introduce the details of this mechanism in algorithm where find basic predecessor is used to find the predecessor basic block find basic successor is used to find the successor basic block of the given label andextract graph extracts the sub graph from the given original graph bounded by two given labels .
specifically algorithm is initialized by inputting two labels label label branch graph branch graph and cfg graph .
in lines assuming that label is ensured to happen before label if label or label is a basic block we can add barrier functions directly without incurring barrier divergence in lines according to section iv b1.
on the contrary the predecessor and successor basic block for label and label can be found in lines .
specifically in lines if the predecessor and successor basic block are not identical we can add barrier function at the nearest basic block after label to synchronize the program.
otherwise if the predecessor and successor basic block are identical aucs extracts the associated sub cfg and sub branch graph in lines according to the given predecessor and successor basic block and constructs entry condition s for each label in the extracted sub cfg in line .
next it applies program transformation to the sub cfg in order to create a basic block between label and label in lines .
as a result adding a barrier function in the stable label generated by program transformation can automate synchronization of cuda kernel functions by eliminating data race bugs.
inner label statements.
when the data race induced statements are in the same label aucs splits the original label at the first statement into two labels and transfer the original inner label data race to intra label data race which can be fixed by applying algorithm .
note that so far aucs is not designed for the synchronization scenario where different threads are executed under different iterations for the same loop.
please refer to more details discussed in section v. automating barrier divergence scenarios automatically fixing barrier divergence bugs is expected to be intricate because barrier divergence is highly involved with data race.
specifically an intuitive solution is to simply remove the barrier functions in which the barrier divergence takes place.
however since a barrier divergence bug indicates possible data race bugs among different non basic block labels i t is possible that deleting the barrier function might introduce a new data race bug into the program.
on the other hand manually fixing data race might lead to a barrier divergence bug while the data race bug takes place in a non basic block .
for instance revision d88e6a3540f of arrayfire tried to fix data race but incurred additional barrier divergence which was fixed in 0d0d7d1285a .
aucs on the other side enables an effective solution for fixing barrier divergence by transforming it to automatically fixing data race.
in particular aucs first deletes all the barrier functions that cause barrier divergence reported by simulee .
next simulee is called again to check whether there is any data race.
if not it indicates that the barrier divergence is already fixed otherwise we can apply the approach iv b2 to fix the generated data race bugs.
automating redundant barrier function scenarios to fix the redundant barrier function bugs aucs applies simulee to effectively detect the locations of the unnecessary barrier functions and remove them.
overall by applying simulee and the program transformation for flattening the original program cfg aucs can effectively detect the synchronization bugs identify create the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
proper locations for adding barrier functions to fix various erroneous synchronization scenarios.
therefore aucs can automate synchronization for llvm bitcode of cuda kernel functions such that the developers could save time and effort in fixing all erroneous synchronization scenarios.
c. v alidation algorithm applies program transformation to the erroneous synchronization scenarios and inserts barrier functions in discovered created basic block s. according to theorem the original program semantics remain unchanged.
we invoke simulee to validate the llvm bitcode generated byaucs to check if the synchronization bug has been fixed.
it is essential to consider whether adding barrier function to cuda programs can inject barrier divergence bugs in fact since barrier functions are always inserted in basic block s that are executed by all the threads according to the definition of basic block no new synchronization bug can be introduced into the original llvm cuda within the scope of this paper.
v. e xperimental ev alua tion in this section we conduct a set of experiments to evaluate the effectiveness and efficiency of aucs .
we select all the erroneous synchronization scenarios including data race barrier divergence and redundant barrier function from gklee benchmark and three real world popular cuda projects from simulee dataset arrayfire stars commits and 364k loc kaldi stars commits and 381k loc thundersvm stars commits and 343k loc .
such studied projects were systematically selected in prior work .
a. experimental setup we performed our evaluation1on a desktop machine with intel r xeon r cpu e5 and gb memory.
the operating system is ubuntu .
.
we use the default values for all the parameters for running simulee .
b. result analysis table i shows the experimental results where the first three columns are used to identify the specific erroneous synchronization scenarios.
the next two columns present the bug types and the automatic synchronization results performed byaucs .
the following column shows whether it is feasible for autosync to automate synchronization.
we split the execution time into two parts in the last two columns the detection cost and automatic synchronization cost.
for each automatic erroneous synchronization scenario we use both simulee and manual analysis to confirm whether the relevant synchronization bug is fixed or not.
in particular the manual analysis is used to observe whether the generated llvm bitcode is semantically equivalent with the corresponding patch committed by developers.
1please refer to for aucs details.
shared float shrdmem 2float desc shrdmem ... 4if f total feat const int histlen const int hist off tid x histsz desc len ... for int i t i d x i histlen histsz i bsz x desc .f syncthreads barrier divergence ... for int l t i d x l desc len l bsz x desc desc syncthreads barrier divergence for int l t i d x l desc len l bsz x desc desc ... ... fig.
simplified revision ee4d0bd77d7 for arrayfire effectiveness first we apply aucs to a total of erroneous synchronization scenarios from the selected dataset.
aucs can successfully automate synchronization for of them from table i. specifically aucs can successfully resolve difficult erroneous synchronization scenarios.
e.g.
the motivating example in section iii.
fixing data race bugs manually may introduce new barrier divergence bugs.
for instance the revision d88e6a3540f of arrayfire attempted to fix a data race bug but incurred an additional barrier divergence bug which was fixed in a subsequent revision 0d0d7d1285a.
in contrast our experiment shows that aucs is able to successfully synchronize llvm cuda in one step fully automatically without causing barrier divergence.
additionally aucs can also automate more erroneous synchronization scenarios compared to autosync which uses a cost model to select an optimal placement for the barrier function.
such approach cannot fix either the motivating example in section iii or the erroneous synchronization scenarios when there is no basic block between buggy statements which frequently occur in real world projects.
for example the revision ee4d0bd77d7 of arrayfire is presented in figure .
the barrier function should be inserted at lines and to synchronize data.
meanwhile because the statements between line and line do not belong to any basic block and they are inside an if block there should not be any barrier function inside this block.
otherwise a barrier divergence bug would be introduced.
since autosync cannot restructure code it cannot fix this bug by inserting barrier functions into the original code.
in addition autosync cannot fix a read write singlestatement data race such as a a because a barrier function cannot be inserted within a single statement.
however it can be resolved by aucs because aucs can translate such statement into two independent instructions in llvm cuda and further resolve it.
specifically the sixth column of table i shows if a synchronization scenario is beyond the search space of autosync.
it can be observed that of erroneous synchronization scenarios are beyond the search space of autosync.
we can observe that there are four erroneous synchro756 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i evaluation results project revision kernel function bug type aucs this work autosync feasibility detection time cost s aucs time cost s gkleet ests 10eb6373d53 device global data race .
.
gkleet ests 10eb6373d53 colonel data race .
n a gkleet ests 10eb6373d53 dl deadlock barrier divergence .
.
gkleet ests 10eb6373d53 dl deadlock barrier divergence .
.
arrayfire 0a8371a876b computeev alhomography data race .
.
arrayfire a7a297ba814 scan nonfinal kernel data race .
.
arrayfire a7a297ba814 scan dim nonfinal kernel data race .
.
arrayfire 0c5a38182b7 hamming matcher data race .
.
arrayfire 0c5a38182b7 hamming matcher unroll data race .
.
arrayfire d7abcf2358e jacobisvd data race .
.
arrayfire c59116e3ec3 warp reduce data race .
.
arrayfire a515b112076 scan dim kernel data race .
.
arrayfire d88e6a3540f warp reduce data race .
.
arrayfire 1050816e422 hamming matcher data race .
.
arrayfire 1050816e422 hamming matcher unroll data race .
.
arrayfire 0ed6cccc5f f select matches barrier divergence .
.
arrayfire dfbfca5fb77 select matches barrier divergence .
n a arrayfire 0e0c726d7d0 hamming matcher unroll barrier divergence .
n a arrayfire ee4d0bd77d7 computedescriptor barrier divergence .
.
arrayfire 0d0d7d1285a warp reduce barrier divergence .
.
arrayfire 31761d27f01 computemedian redundant barrier function .
.
arrayfire faefa30c3a0 harris response redundant barrier function .
.
kaldi bc13196e7fe add diag mat mat barrier divergence .
n a thundersvm febf515a826 nusmo solv ekernel data race .
.
nization scenarios that aucs cannot resolve.
in particular for the revision 10eb6373d53 from gkleetests the data race in the kernel function colonel is a single instruction race which is a write write data race that incurs at the same llvm bitcode instruction.
such scenario cannot be resolved by inserting barrier function.
the revision bc13196e7fe of kaldi dfbfca5fb77 and 0e0c726d7d0 of arrayfire are another set of synchronization scenarios that cannot be resolved by aucs .
in those scenarios different threads execute the same loop with different number of iterations.
meanwhile a barrier function should be put inside the loop to synchronize data because of data race.
under such settings even if the barrier function is located in the basic block inside the loop when some threads complete fewer iterations than others they would leave the loop while other threads have not completed the loop.
therefore that incurs barrier divergence.
nevertheless autosync cannot fix any of those synchronization bugs either.
efficiency we can observe from table i that the detection part from simulee is the most time consuming part.
taking into account the detection time the average time cost for the whole process is .21s.
meanwhile the average time cost for automatic synchronization is .056s which occupies only .
of the total time cost calculated as the time cost of aucs devided by detection inclusive total time cost .
the max time cost for automatic synchronization is .368s.
overall our results show that aucs can generate suitable llvm bitcode patches for real world projects rapidly.
vi.
threa ts to v alidity in terms of external threat to validity the effectiveness ofaucs has only been evaluated in the erroneous synchronization scenarios and may not be able to generalize to other datasets.
nevertheless we mitigate this threat by taking erroneous synchronization scenarios from two sources gkleetests and simulee s dataset .in addition we identify two main limitations of aucs .
firstly that aucs depends on the detection tool for cuda synchronization bugs.
in our work we use simulee to detect cuda synchronization bugs and pass the result to aucs .n e v ertheless our experiment results demonstrate that aucs can automatically synchronize target kernel function effectively when the detection part is robust and reliable.
secondly aucs cannot handle the situation when different threads execute the same loop in different iterations and data synchronization is needed inside the loop.
although this situation rarely occurs in the data set we explored we leave the synchronization of such scenarios as future work.
vii.
r ela ted work cuda synchronization bug detection.
while the approaches regarding traditional software bug detections have been largely studied there are quite limited studies on cuda synchronization bug detection.
several techniques exist for verifying the correctness of synchronization for multi threaded cpu programs .
in this work we choose simulee as our detection part to detect synchronization bugs since it has been shown to represent the state of the art in terms of performance and detection ability.
simulee is a dynamic detection tool that uses test inputs generated by evolutionary programming.
on the other hand gklee traces execution flow of threads and collects write statement set and read statement set then determines whether there is any synchronization bugs by applying smt solver.
ldetector instrumented compiler to detect races by using diffs between memory snapshots.
curd is a compiler based race detector like which uses llvm to instrument memory accesses and barriers in a real running process.
synchronization bug repair.
automated debugging techniques have been proposed to localize and fix different types of bugs.
in the context of synchronization bugs there are many automated program repair approaches authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
for traditional multi thread cpu programs.
cfix inserts synchronization operations into buggy code to make a correct patch and selects best patch among the candidates to achieve a better performance.
pfix fixes synchronization bugs by inferring locking policies from memory access pattern.
program synthesis is another research area that is closely related to automated program repair.
program synthesis techniques have been successfully applied in the context of program repair to automatically synthesize expression statements for repairing buggy programs .
in the context of program synthesis autosync is the most closely related work to our paper.
similar to our work autosync fixes synchronization problems for gpu kernels by inserting barrier functions.
there are several key differences of our work compared to autosync autosync relies on gpuv erify for determining the race location and providing a black box correctness oracle whereas we use program transformation for finding the correct location for placing the barrier functions autosync assumes that the race location exists in the buggy gpu programs but we show in section iii that creation of new blocks is needed for fixing more complex synchronization bugs and our approach is more general than autosync as we consider all synchronization scenarios including data races barrier divergence and redundant barrier function.
compiler optimization.
compilers have applied different methods to transform the structure of original code without changing its semantics.
bacon et al.
introduced a bunch of transformation methods to restructure the original program in order to achieve a better performance.
as our program transformation acts on the llvm bitcode level and our results show that aucs could automate synchronization for cuda programs rapidly a potential future work would be to integrate the workflow of aucs as part of compiler optimization.
viii.
c onclusions in this paper we propose an automatic synchronization tool named aucs for cuda program in order to save developers from designing error prone and complicated synchronization mechanism.
fixing synchronization bugs for cuda programs is challenging because the barrier functions should be located atbasic block s to avoid barrier divergence.
based on the detection reported by simulee aucs creates basic block s among the buggy statements via program transformation without changing the original semantics for barrier functions to synchronize the data flow.
aucs can automatically synchronize of synchronization scenarios from the three real world cuda projects and gklee benchmark.
ix.
a cknowledgement this work is partially supported by the national natural science foundation of china grant no.
and no.
shenzhen peacock plan grant no.
kqtd2016112514355531 and science and technology innovation committee foundation of shenzhen grant no.
zdsys201703031748284 and no.
jcyj20170817110848086 .
this work is also partiallysupported by national science foundation under grant no.
ccf and amazon.
the authors also thank yicheng ouyang for the help with editing the paper.