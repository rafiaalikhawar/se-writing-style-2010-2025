software performance self adaptation through efficient model predictive control emilio incerto gran sasso science institute viale francesco crispi l aquila italy emilio.incerto gssi.itmirco tribastone imt school for advanced studies piazza san francesco lucca italy mirco.tribastone imtlucca.itcatia trubiani gran sasso science institute viale francesco crispi l aquila italy catia.trubiani gssi.it abstract a key challenge in software systems that are exposed to runtime variabilities such as workload fluctuations and service degradation is to continuously meet performance requirements.
in this paper we present an approach that allows performance self adaptation using a system model based on queuing networks qns a well assessed formalism for software performance engineering.
software engineers can select the adaptation knobs of a qn routing probabilities service rates and concurrency level and we automatically derive a model predictive control mpc formulation suitable to continuously configure the selected knobs and track the desired performance requirements.
previous mpc approaches have two main limitations i high computational cost of the optimization due to nonlinearity of the models ii focus on long run performance metrics only due to the lack of tractable representations of the qn s time course evolution.
as a consequence these limitations allow adaptations with coarse time granularities neglecting the system s transient behavior.
our mpc adaptation strategy is efficient since it is based on mixed integer programming which uses a compact representation of a qn with ordinary differential equations.
an extensive evaluation on an implementation of a load balancer demonstrates the effectiveness of the adaptation and compares it with traditional methods based on probabilistic model checking.
index terms adaptive software control theory model predictive control performance requirements i. i ntroduction in software intensive systems runtime variability is a major impediment to satisfy quantitative non functional properties such as performance and reliability a configuration that is initially optimal with respect to some given qualityof service qos requirements e.g.
throughput or mean time to failure may suddenly become poor when certain events such as workload fluctuations or breakdowns steer the system toward a sensibly different operating point.
in this context self adaptation is a promising paradigm where uncertainty is managed by continuously monitoring the current execution conditions and planning a reconfiguration using a model of the system under analysis .
runtime adaptation introduces two main difficulties.
first the system model must be analyzed under strict time constraints to ensure fast reactions.
second an effective strategy must be devised to explore the adaptation space as i.e.
the set of all feasible system configurations that can be obtained by tuning the adaptation knobs.
indeed the typically huge sizeof the as represents one of the major limitations for applying state of the art approaches to real world scenarios .
some recent work has looked at ways of efficiently exploring the parametric as also using satbased methods however available solutions only concern the long run i.e.
steady state performance indices.
any adaptation strategy based on such indices as also done in ignores the system s whole timecourse dynamics.
actually reaching a steady state may not even be guaranteed based on the degree of variability hence defying any prediction and adaptation effort.
in this paper we deal with self adaptation for performancerelated qos requirements and focus on software systems that can be described by queuing networks qns a well estabilished model in software performance engineering e.g.
.
the analysis of the qn s timedependent evolution suffers the well known problem of state space explosion arising from the huge state space of the underlying markov chain.
to tackle this issue we consider a compact approximate representation of qns based on ordinary differential equations odes .
viewing a qn as a dynamical system governed by odes unleashes a range of techniques that would not be otherwise applicable.
for instance filieri et al.
use odes in a closed loop control strategy but the control acts on a single parameter.
the novelty of our approach is the formulation of the performancedriven self adaptation problem using model predictive control mpc a well known technique based on on line numerical optimization which allows multiple knobs.
this provides a more expressive adaptation strategy that may automatically act on system settings of different nature routing probabilities service rates and concurrency levels .
the basic idea behind mpc is to perform an optimization at each time step during the system evolution.
the model is initialized with the currently measured state of the system.
the optimization automatically finds the values of the control signals i.e.
the model parameters related to the adaptation knobs that best steer the system toward a given reference trajectory e.g.
a qos requirement such as throughput or response time over a given time horizon.
thus mpc returns an optimal value for each control signal at each time step across that horizon.
adaptation takes place according to the .
c ieeease urbana champaign il usa technical research485 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
receding horizon control paradigm only the values for the next time step are applied whereas all subsequent ones are discarded .
when mpc is started at the next iteration the newly measured state will readily feed back the effect of the adaptation into the system and become the starting point for the optimization over the next time horizon.
unfortunately applying mpc is not straightforward.
its main limitation is the typically high computational cost.
indeed state of the art approaches report significant overheads even for small models and short prediction horizons .
for qns the main sources of complexity are i the nonlinearity of the ode model as it needs to account for threshold type service rates that depend on the state of the system ii the exponential complexity of the optimization due to the multidimensionality of the control signals space.
the practical consequence is that the execution of a single optimization problem can be time consuming reducing the maximum frequency at which the controller can operate.
this may significantly degrade its effectiveness if the system under control has faster dynamics because the controller will not keep track of potentially many events across two steps.
ideally one would like to design the controller s computational loop such that it can operate at a frequency close to the system dynamics.
as a main technical result of this paper we achieve this by formally translating the original nonlinear mpc problem into a mixed integer programming mip one.
this is an equivalent representation where the model becomes linear time invariant and the control signals become exogenous inputs leading to a quadratic programming problem that enjoys very efficient solution techniques .
we tested our mpc approach on an implementation of a load balancing system.
our results show its effectiveness in adapting to events such as performance degradation of a server and sudden changes in the system workload.
our formulation does allow reaction times that are orders of magnitude faster than a naive nonlinear mpc design.
indeed we show that such nonlinear mpc would not be able to track the dynamics of our testbed effectively.
a scalability assessment of the computational requirements of our mip approach shows that it can yield control loops as fast as .
s on commodity hardware even for large prediction horizons.
our work advances the state of the art in applications of mpc which so far have been designed for ad hoc solutions to specific case studies always considering a single adaptation knob .
in addition it compares very favourably against analogous runtime adaptation strategies based on probabilistic model checking.
to show this we consider the markov chain interpretation of the qn and develop a controller based on markov decision processes using the prism model checker similarly to .
we show that the execution time of mpc controller is essentially independent from the system size whereas the markov decision process suffers from state explosion to the extent that it does not return an adaptation strategy fast enough to track runtime variability.
the remainder of this paper is organized as follows.
section ii provides an overview of our approach.
section iii sets fig.
approach overview up the mpc problem and the mathematical formulation is reported in appendix.
section iv numerically demonstrates the effectiveness and the scalability of our approach on a real system.
section v discusses the threats to validity.
section vi presents related works and section vii concludes the paper and outlines future work.
ii.
o verview and running example figure depicts the overview of the approach we propose.
a the starting point is a system specification that can be translated into a qn.
although the definition of such a system specification is outside the scope of this work we argue that it could be based on existing model driven approaches.
indeed in the literature there are techniques that translate software designs into performance models e.g.
.
we call a parametric qn the model including the following two main characteristics of the system specification i1.
the elements that can act as adaptation knobs and the range of values that each adaptation knob can take i2.
the adaptation goals defined as desired set points for certain performance metrics these represent the given qos requirements for the system.
which adaptation knobs to use mainly depends on the possibility that those architectural elements may be changed at runtime in the actual implementation.
for instance in the model of a server choosing its concurrency levels as an adaptation knob requires the implementation to dynamically kill spawn new threads processes.
we will study such a case in section iv.
the adaptation goal can be described in terms of set points for either queue lengths how many clients jobs are waiting for service at a station or throughputs how many clients are served per unit time .
we focus on these for ease of presentation but we stress that this is general enough to encode other important performance metrics such as utilization and response time see for a discussion on this.
b for a given parametric qn the controller can be automatically synthesized.
in particular we first obtain an ode system using an approach similar to .
using wellknown arguments that relate the ode dynamics to a stochastic markov chain based interpretation of the qn behavior e.g.
the ode solution gives an estimate of the average queue length at each station.
importantly the model authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
size is independent of the number of jobs in the system unlike in markov chains for qns where the size grows exponentially.
c the ode system will then be discretized in time such that it can give a finite set of constraints for the mpc problem.
the constraints further encode the feasible ranges of the adaptation knobs and the values for all other parameters which are assumed to be fixed i.e.
non controllable .
the adaptation goal is translated into the objective function of the mpc problem.
this can be systematically turned into the equivalent mip problem which can be efficiently solvable by a wide array of both commercial and open source solvers.
d the mpc philosophy leads to a natural implementation as a mape k loop controller.
in the monitor phase the current system state is measured and used as input parameter for updating the system model embedded in the mip formulation.
the solution of the optimization problem implements the analysis planning phase.
finally in the execution phase the computed control signals are applied to the running system.
the knowledge block is thus represented by the model constraints embedded in optimization problem.
running example we use a load balancing system but we remark that the proposed approach is applicable to qn models of any topology.
load balancing is an established design technique in performance engineering whose goal is to distribute incoming requests jobs across several computational units in order to prevent overload conditions and the consequent performance degradation.
once a request enters the system at runtime a dispatcher the load balancer selects a particular station to which the processing is delegated.
this system can be configured by tuning a number of parameters related to both the software and the hardware such as the dispatcher s strategy and the concurrency level i.e.
how many servers can work in parallel at each station.
events that may jeopardize the performance of the system include degradation of the quality of a server e.g.
to account for a hardware issue or unexpected increases in the system workload e.g.
as a consequence of peak off peak patterns .
the goal of self adaptation is to efficiently explore the system s configuration space guided by qos requirements such as throughput maximization and balancing of the station s load under given resource constraints such as the maximum concurrency level at the stations.
iii.
e fficient qos a daptation in this section we precisely define all the steps informally overviewed in section ii.
a. parametric qn let us consider a set of stations s. aparametric qn is described by a set of parameters denoted by p as follows si2pis the concurrency level of station i withi2s i2pis the service rate of station i withi2s pi j2pis the routing probability i.e.
the probability that a request from station igoes toj withi j2s fig.
parametric qn for a load balancing system to formally define the adaptation space we denote by v sthe subset of adaptation knobs consisting of the userdefined parameters that can be controlled at runtime.
for each adaptation knob v2vwe indicate by viand vithe minimum and maximum values allowed for that parameter respectively.
for each parameter that is fixed i.e.
p2s v pis its given value.
finally we denote by xi i2sthe initial condition i.e.
the initial number of jobs assigned to station i. we consider a set of rqos requirements.
for the r th requirement we let kindrbe either thiorqi to denote the throughput or the queue length at some station i respectively.
analogously the corresponding setpoint is denoted by valuer.
similarly to we focus on a model supporting the specification of a single class of jobs.
we comment on the limitations of this assumption and on possible ways to mitigate it in section vii.
to formally justify the ode approximation the service rates iare assumed to be exponentially distributed.
however using our framework can be extended to the nonexponential case via an approximation based on phase type distributions .
figure depicts the parametric qn for the load balancing system.
station n0is the dispatcher while stations n1and n2are the two processing ones.
the adaptation knobs are indicated in red.
in section iv we consider the adaptation goal to have balanced queue lengths at stations n1andn2with jobs.
in our framework this can be done by having r requirements with kind q1 value kind q2 andvalue .
as intuition suggests if stations n1andn2 are identical then the optimal strategy chooses equal routing probabilities p0 p0 .
however this does not hold any longer if at runtime there is an event that breaks this symmetry such as the degradation of the service rate of either server.
intuitively such a degradation can be compensated by increasing the probability that a job is sent to the faster server and or increasing the concurrency level of the degraded one.
b. ode model the ode model is automatically derived from the parametric qn and it gives estimate of the average queue lengths xi t as a function of the qn parameters i.e.
service rate routing probabilities number of servers .
the evolution of the qn is described by the following ode system dxi t dt i t minfxi t si t g x j2spj i t j t minfxj t sj t g authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
with initial condition xi for alli2s.
the quantity i t minfxi t si t g represents the overall nonlinear instantaneous throughput of each station when the queue length xi t in stationiis less than the available servers si t then the xi t jobs are served in parallel otherwise some of the jobs are enqueued and only si t of them are processed at once.
the throughputs may be weighted by the routing probabilities pj i t because a station may receive only a fraction of the jobs elsewhere.
the validation of the ode model has been performed by comparing prediction results against real measurements in order to assess its accuracy see section iv for further details.
c. nonlinear mpc formulation discrete time model in order to employ mpc we rely on a time discretization of the ode model with a finite step size t. mpc finds the optimal values of the adaptation knobs over a time horizon of hsteps.
simple algebraic manipulations yield a formulation that reads in matrix notation x k a x k x k wherex k xi k i2sare the queue lengths of the qn at stepk i.e.
at time k t and matrix a x k has components ai j x k withi j2s given by ai j x k i k tminfxi k si k g i j pj i k j k tminfxj k sj k g i6 j objective function we now define the objective function of the mpc optimization problem starting from the qos requirements in the parametric qn.
specifically for each time stepk h we consider the vector of performance metrics m k m1 k mr k where eachmi k i rcan be either of the following mi k j k minfxj k sj k g ifkind ri thj xj k ifkind ri qj similarly the required set points are collected in the vectors r k r1 k rr k withri k value ri .
our goal is to minimize the error between the performance indices and their reference values i.e.
e k m k r k across all time steps in the horizon k h .
thus overall the objective function is defined as follows minimizeh 1x k 0e k te k where tindicates matrix transposition.
the discretization in allows us to embed the dynamics of the model as a discrete set of constraints in the optimization problem by unfolding over htime steps x a x x x a x x x h a x h x h to these we add si k 2fsi si sig s i k 2v i i k i i k 2v pi j k x j2spi j k pi j k 2v si k si si k 2s v i k i i k 2s v pi j k pi j pi j k 2s v fork h where define the ranges for the adaptation knobs and set the values for the fixed parameters.
we remark that the specification of includes integer variables because they represent server multiplicities which may vary discretely.
mpc is the problem of minimizing subject to the constraints .
in addition to all qn parameters the decision variables of this problem are also the vectors x x .
.
.
x h these represent the predictions on future states of the system once the optimal values of the adaptation knobs are applied.
instead x is the vector of the current queue lengths which are measured and plugged into the problem at runtime.
the efficiency issues of this mpc setup as will be demonstrated numerically in section iv are due to the nonlinearities from the multiplication of decision variables i.e.
pi j k i k and the threshold type service dynamics arising from expressions such as minfxi k si k g. in the next section we will use this nonlinear problem as the basis for developing an equivalent mip formulation.
d. mip formulation the mip formulation relies on a linear time varying system with auxiliary virtual adaptation knobs which will be then related to the original ones.
we define the new ode system dxi t dt cni t x j2s cnj t cpj i t i2s wherecni t represents the virtual service rate for station i andcpi j t is a virtual routing probability.
setting cn k cni k i2sandcp k cpi j k i j2s can be written x k x k cn k cn k 1cp k where 1denotes a matrix of all ones of appropriate size.
in appendix a we demonstrate an exact correspondence between the original nonlinear mpc problem and the mip formulation over the variables appearing in .
this leads us to state the following theorem theorem .
denoting bys f i k p i j k s i k gan optimal solution to there exists an mpc problem based on an mip formulation with dynamics such that its optimal solutions0 fcn0 i k x0 i k cp0 i j k s0 i k gsatisfies authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
i k cn0 i k x0 i k tifx0 i k s0 i k cn0 i k s0 i k tifx0 i k s0 i k p i j k cn0 i k cp0 i j k cn0 i k s i k s0 i k for allk h .
this is of key relevance in our formulation since all nonlinearities have been removed and solutions are efficiently derived.
e. adaptation logic the mip problem can be used for performance selfadaptation.
the algorithm is re iterated at each time step a feed the mip program with the state of the qn by assigning the current queue length at station ito variablexi the fixed service rates of station ito variables i the fixed routing probability between station iand stationjto variables pi j the fixed number of servers of station ito the variable si b solve the mip problem obtaining the optimal sequence cn0 i k x0 i k cp0 i j k s0 i k fork h .
c with theorem obtain the values for the concrete adaptation knobs i k s i k andp i j k fork only discarding the others.
d apply i s i andp i j to the system.
by discarding the future predictions and running the optimization at every time step instead i.e.
the receding horizon control the system can react to changes as early as possible.
we postpone to section vii the discussion on how to track the state of the system and parameterize the qn model.
mpc parameter setting.
in our approach the modeler is required to choose two parameters the ode discretization step tand the optimization horizon h. here we discuss how these parameters may be chosen in practice.
the discretization step taffects the quality of the numerical solution of the ode model for the qn network the smaller tthe more accurate the solution.
on the other hand hrepresents the optimization horizon in terms of the number of such tsteps.
so for a given time interval of interest smaller values trequire larger values of h. this has an effect of the computational cost of the optimization because constraints and decision variables grow with h see .
since the optimization is performed at runtime the time to complete an entire adaptation loop consisting of measuring the current state of the system running mpc and applying the control should be comparable to the dynamics of the system under control.
indeed an adaptation loop that is slow relatively to the system will not be able to keep track of the possibly many events occurring during the adaptation itself.
taking into account these constraints we propose the following strategy for choosing hand t i choose a duration aof the adaptation loop comparable to the system dynamics.
this can be done by examining fig.
hat architecture the service rates of the qn model which provide an estimation of the time required to process the different activities in the system.
ii fix a value of tthat ensures an accurate enough ode solution.
this can be done by solving the ode with standard numerical solvers imposing a desired level of accuracy.
their output will provide the sequence of discrete time steps to maintain that accuracy.
iii choose a value of hsuch that the adaptation loop can execute within atime units.
this can be done off line by running tests on the hardware on which the controller will be deployed.
with this procedure it may be possible that hbecomes small enough that it does not cover the time of the adaptation loop d i.e.
h t a. this invalidates the controller.
to tackle this issue steps i iii may be repeated by for instance considering a faster hardware for the controller to decrease a or accepting a larger tolerance by increasing t. finally we remark that it is possible to take into account the interplay between aandhin the mpc setup one may additionally impose that the control signals do not vary for a number of tsteps equal to a so as to exclude optimal control sequences that vary faster than a which is the technological constraint of the problem.
formally this is done by extending the constraint set with v v v c v c v c v 2c and so on for all decision variables v2v wherecis the least integer such that c t a. we used this approach in the experiments reported in the next section.
iv.
e valuation we evaluate the effectiveness and the scalability of the proposed mpc approach on a real system.
a virtual machine hosting the experimental infrastructure is publicly available at a. system description and implementation for conducting our study we relied on an in house developed web application called hat heavy task processing application meant to serve user requests characterized by a cpu intensive load.
hat was deployed as a nodejs based load balancing system running on the ubuntu server .
linux distribution.
figure depicts the architecture c1and c2represent the processing nodes lb identifies the dispatcher while ctrl is the controller component.
component authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i system parameters for the validation experiments parameter value description .
user s think rate s0 users think activities are independent s1 number of cores for node c1 s2 number of cores for node c2 p01 p02 .
balanced routing p10 p20 user issues a new request after service wrepresents the workload generator issuing requests to lb.
in particular following the load balancing paradigm see section ii user requests are randomly distributed across the processing components according to the routing probabilities p01 p02.
requests are processed on the server using php and reported to the user as a html page.
we implemented was a multi threaded python based workload generator.
each thread runs an independent concurrent user that iteratively accesses the system interposing an exponentially distributed delay i.e.
the think time between successive requests.
nodes lb c1 and c2 are nodejs servers equipped with runtime reconfiguration capabilities.
in particular relying on the http proxy and cluster libraries we enabled the reconfigurations of the routing probabilities used by lb and the number of active processes and cpu cores assigned to c1andc2.
these reconfigurations are triggered at runtime by the ctrl component in a mape k loop through operating system signals see figure .
ctrl ran the mip optimizations using the well known cplex tool.
to this end we defined a model to text transformation m2t suitable to translate the system of a odes in a julia specification that combined with the jump library provides a common programming interface api for different optimization solvers.
finally we monitored the queue lengths of c1 andc2using the netstat utility.
to facilitate the replicability we deployed all nodes of hat on a single linux machine with gb of ram gb ssd and xeon cores at .
ghz.
each hat node was assigned dedicated cpu cores.
b. model parametrization and validation the model for this system is the qn in figure .
station n0 represents the workload generator.
the service rate accounts for both the think time of the users and the time spent by the controller to dispatch the requests.
indeed since the latter was negligible ctrl is not explicitly represented in the qn.
instead stations n1andn2model the processing nodes of hat.
the number of servers s1ands2represent the number of cpu cores assigned to the processing nodes.
with our hardware configuration we measured the average time to serve a request as s. hence we fixed rate parameters .
to validate the model we executed the system with a balanced configuration consisting of equal routing probabilities and one core for both c1andc2 while increasing the population of circulating users denoted by w withw2f10 100g.
each user has an average think time of s drawn from an exponential distribution .
the corresponding parameters of the qn model are summarized in table i. w concurrent users 05101520queue length jobs measured ode a c1queue length w concurrent users 05101520queue length jobs measured ode b c2queue length w concurrent users 102030405060708090100utilization measured ode c c1utilization w concurrent users 102030405060708090100utilization measured ode d c2utilization w concurrent users 01234567throughput req s measured ode e system throughput w concurrent users 0123456response time s measured ode f system response time fig.
qn model validation for each value of wwe measured the following average indices in steady state throughput response time and utilization of the processing nodes.
we verified that a session duration of minutes was sufficient to attain steady state in all cases.
figure depicts the validation results by comparing the steady state prediction values of the qn model dashed lines with the measured ones of the real system averaged on30repetitions.
the error bars on the measurements curves show the confidence intervals.
the results demonstrate that the model can predict the trends of the real system satisfactorily.
we consider the errors acceptable especially since a fairly simple three equation deterministic model abstracts away from many low level interactions e.g.
virtual machine host operating system message passing networking stack which introduce sources of disturbance in addition to the stochasticity of the workload.
c. adaptation evaluation we evaluated the effectiveness of our approach by studying two non trivial adaptation scenarios s1 hardware degradation.
starting from a balanced set up where the processing nodes c1andc2are identical we inject degradation events where the service rate of c1is drastically reduced.
the objective of the adaptation is to properly redirect users to c2with higher probability.
s2 workload fluctuation.
we inject an increasing number of users into the system.
the objective of the adaptation is to keep the queue lengths at c1andc2balanced and around a target value by acting on both the routing probabilities and the number of cores at the processing nodes.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
time steps t .2s 1234567throughput req s control no control a system throughput no degradation degradation a00.
.
.
.
.
.
.
.
.91routing probabilitiesp01 p02 b optimal control signals fig.
hardware degradation experiment hardware degradation we synthesized hardware degradation events by allowing node c1to perform six times the amount of original processing of a request whenever instructed to do so by our experimental infrastructure by means of a signal triggered by the workload generator .
thus upon degradation the service rate of c1 was assumed to be .
we ran the system for minute long sessions under a workload of w concurrent users where we alternated periods of normal operation i.e.
and degradation every minutes.
during normal operation we considered settings as in table i the number of server cores was fixed .
the control objective has been set to find the value for the routing probabilities p01 p02 that maximize the system throughput.
following the strategy described in section iii e we fixed an ode sampling interval t 1s and an activation loop a s after a profiling and simulation phase.
this allowed a control horizon h which ensured a look ahead of two adaptation loops.
in that phase we numerically verified that the chosen parameters did not reduce the accuracy of the odes steady state solution.
we ran the system both with and without the controller for comparison.
figure 5a reports the average throughput dynamics in both cases averaged over repetitions the x axis reports time steps with a granularity of .
s .
the occurrence of hardware degradation events is indicated by the dotted vertical lines.
the straight horizontal lines indicate the maximum theoretical system throughputs under the degradation condition simply estimated as the sum of the processing rates of nodes c1andc2 equal to .
during normal operations the controlled system and the uncontrolled achieve the same throughput.
this is because the balanced deployment p p02 represents the optimal solution.
when degradation kicks in the effect of the control is evident the throughput of the uncontrolled system decreases to as little as 2requests per second while the controlled system attains values around the theoretical maximum.
maintaining equal probabilities when c1is degraded causes the majority of user requests to be waiting at c1.
instead the controller tends to increase p02during degradation.
these considerations are supported by figure 5b showing the statistics averages and standard deviations of the optimal values of the control signals.
during degradation the controller sends of requests to c2on average.
instead without degradation the mip returns the balanced configuration as the optimal one.
workload fluctuation we designed this experiment by starting with a workload of w users and introducing new users into the system every minute until reaching w .
here the control objective is to maintain the queue lengths of c1andc2at the fixed threshold i.e.
ql .
this represents a critical condition for the balanced singleserver deployment from figures 4a and 4b it is possible to observe that the system could not maintain the requirement on its own for larger workloads than concurrent users.
here the decision variables are the routing probabilities of the load balancer and s1ands2 i.e.
the number of cores for c1and c2 respectively with s1 s22f1 2g.
for the uncontrolled case used for comparison we chose s1 s2 and p01 p02 .
we also chose h t a following similar reasoning made for the previous scenario.
figures 6a and 6b report the queue lengths dynamics averaged over 30repetitions for c1andc2 respectively.
the dotted vertical lines denote the points when the workload changes.
the straight horizontal lines indicate the average queue length computed at each workload level.
at low workload levels w andw the behavior of both cases is similar since the balanced single server version is still suitable to fulfil the requirement ql as expected from figures 4a and 4b.
however for larger workloads the queue lengths of the uncontrolled system start to increase.
larger values of w lead to less balanced queues in the uncontrolled case.
this is not in contradiction with the intuitive argument that they should be equal on average because this holds true for a large enough number of replicas.
instead the replicas analyzed do show a strong stochastic noise.
this is robustly controlled by our mpc approach which considerably reduces the queue length difference between c1andc2at all workload levels.
more importantly it keeps the queue lengths always under the prescribed threshold on average.
figure 6c reports the statistics averages and standard deviations of the optimal values of the control signals during each level of workload intensity.
the average number of servers used increases with w. to reach the target for w the optimal strategy used about 5servers on average.
the statistics on the routing probabilities confirm that the average optimal strategy is to direct users to either server equally likely.
d. scalability evaluation in this section we provide the numerical evidence that the main technical result of the paper namely the equivalent mip formulation and correspondence through theorem appears to be essential for the applicability of mpc to the qn models previously examined.
we argue this by reporting considerably larger runtimes for the solution of the original nonlinear program which preclude its use in our experiments.
to this end we used the well known couenne algorithm for solving the nonlinear instances.
we remark that since our problem formulation is convex its solutions are globally optimal thus for a fair comparison we compared against a nonlinear solver that searches a global solution as well.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
time steps t .2s 05101520253035queue length .
.
w .
.
w .
.
w .
.
w .
.
w 120control no control no control avg control avg a c1queue length time steps t .2s 05101520253035queue length .
.
w .
.
w .
.
w .
.
w .
.
w 120control no control no control avg control avg b c2queue length w00.
.
.
.
.
.
.6control signals valuesp01 p02 s1 s2 c statistics of optimal control signals fig.
workload fluctuation experiment table ii optimization runtimes to timeout after s hardware degradation workload fluctuation h minlp s mip s minlp s mip s to to to to to we parameterized the optimization problems for both the adaptation scenarios of section iv c as a function of the control horizon h since it represents the largest source of complexity for both the linear and the nonlinear formulations.
each entry of table ii gives the optimization runtimes expressed in seconds averaged over adaptation steps.
in the experiments we set a timeout of s. three main observations can be made based on these results.
i the solution of our formulation is obtained orders of magnitude faster than the globally optimal solution of the equivalent nonlinear problem for the most challenging examples this promotes our approach as an effective one when fast adaptation times are required being able to optimize over variables in few tenths of a second.
ii as expected thanks to the linearity of the mip problem the required solution time does not explode when the control horizon his increased.
iii the workload fluctuation scenario is harder than the hardware degradation one for equal values of h. this is due to the larger number of integer variables involved required to represent the multiplicities of cpu cores at c1andc2.
we stress how in that case even for smaller values of hthe nonlinear solution becomes practically inapplicable while our formulation is still feasible for h .
for instance minlp controller would not be able to track the workload fluctuation experiment since its average solution time with h 10is larger than the time between changes of the workload i.e.
60s .
e. comparison with markov decision processes in this section we compare our mip formulation against an analogous one using probabilistic model checking when both are employed for solving the same adaptation step of theworkload fluctuation scenario.
we used the markov chain interpretation of a qn which is approximated by our odes table iii mdp comparison to timeout after s mip markov decision processes w runtime s runtime s states transitions to to to and developed a markov decision process mdp controller in the prism model checker similarly to what presented in .
in order to allow the adaptation of routing probabilities in the discrete state space we discretized the interval in steps a granularity used by real world load balancers .
table iii compares the runtimes for the first adaptation step as a function of the workload level w varying from to and with a control horizon fixed to h .
we observe that mip is orders of magnitude faster than mdp which appears to be inapplicable for that adaptation scenario since its solution time is larger than the time between two workload variations i.e.
the control signals are computed when the workload level is already changed .
furthermore due to the state space explosion the mdp runtime depends on the workload size while the mip formulation is almost unaffected.
we remark however that mdp is a general approach to selfadaptation whereas our mip formulation is specific to qns for any topology .
v. t hreats to validity the building of a qn model brings about two main concerns the definition of the structure topology and its parameterization.
these are in general specific to the system under study.
however we remark that there are already robust solutions for particular classes of systems.
for well known software architectures such as multi tiered and load balancing systems there is substantial literature with validated models see section vi .
moreover as discussed in section ii many approaches have been proposed to derive qn models from higher level software designs e.g.
.
in our experiments we considered a straightforward parameterization of the parameters that were not adaptation knobs e.g.
the service rates performing it off line.
for the hardware authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
degradation scenario we assumed to detect the decrease in the service rate when it happened.
these choices were made for simplicity the parameterization being outside the scope of this work.
however we remark that our mpc formulation naturally allows for a more careful on line parameterization the current estimates may be encoded in the optimization problem as new constraints.
on line estimation can be done using i measurement based approaches that monitor the actual system and update parameters accordingly e.g.
with kalman filters and bayesian estimators ii model based predictions to derive missing parameters iii user defined probability distribution functions .
as already discussed in section iv d our simple load balancing system would not be controllable using a naive nonlinear mpc approach.
it is easy to see that the number of variables in the mpc problem grows quadratically with the system size.
a thorough study of how this impacts on the practical usability of our approach will be part of our future work as will further experimentation in other hardware software settings such as different servers e.g.
apache with graceful restart or deployment platforms.
vi.
r elated work research challenges for self adaptive software systems are provided in .
our approach focuses on two main critical points of self adaptation i.e.
expressiveness and effectiveness as discussed hereafter.
adaptation expressiveness.
some approaches aim to control and adapt the admission of incoming requests.
in a load control mechanism for a web server system with controltheoretic methods is designed.
the system is modeled as a g g queue and the server is controlled by an admission system that collects the steady state server utilization and adapts the probability of incoming requests.
in a qn model predictor is used to strengthen the adaptive feedback.
similarly to the controller checks steady state performance results vs requirements and adjusts the admitting probability to meet such requirements.
predictions of the qn model are demonstrated to provide a better accuracy for the adaptation.
our work differs from since it considers transient dynamics and is not restricting to admission control.
in an mpc algorithm is developed to forecast incoming workload and derive adaptation strategies on cloud resources.
differently from our approach the optimization is limited to the allocation of resources and performance results are computed with the mv a algorithm without considering transient dynamics.
in a control theoretic solution to the dynamic capacity provisioning for cloud is presented.
specifically the number of active servers is adapted with mpc to reduce the total operational cost in terms of energy consumption.
our approach is different since our adaptation is not limited to switching on and off servers.
adaptation effectiveness.
in an auto scaling methodology for cloud resources is presented for web application providers.
it predicts the workload of web requests and returns the optimal number of vms by utilizing queueing theory.however the optimization results to be a complex nonlinear function that is hard to simplify by mathematical methods.
on the contrary our approach enables the formulation of the qos adaptation problem as an efficient mip one.
further approaches that make use of control theory formal guarantees are where a closed loop strategy is proposed to enable an adaptive software system s dynamic behavior.
in the designed controller continuously determines the value of a single control variable e.g.
the processor s clock speed which represents a setting for the corresponding tunable parameter.
in qn performance models are investigated and each queueing center is equipped with a controller that considers predefined values of service rates and provides as output the rate of that specific qn center while considering external disturbances.
differently from our approach simultaneously considers multiple adaptive parameters of different nature and the optimal control provides as output values to scale service rates number of servers and routing probabilities at the same time.
recently baresi et al.
presented a technique to auto scale the cpu cores of containerized applications by means of a planner which consists of a discrete time feedback controller .
instead our approach considers the system transient dynamics relying on a model predictive technique with receding control horizon to forecast the system evolution.
vii.
c onclusion in this paper we have presented an efficient self adaptive approach to continuously meet performance requirements using model predictive control.
selected adaptation knobs of a qn such as routing probabilities service rates and concurrency levels are automatically and continuously configured.
a technical limitation of our own approach is the singleclass assumption in the qn model.
we remark however that for some real world systems this can be sufficiently expressive e.g.
.
furthermore the linearization technique proposed in this paper can be straightforwardly applied to other more expressive models such as stochastic petri nets which feature minimum like expressions for the firing rates due to the amount of tokens at each incoming place e.g.
.
instead in future work we aim to develop similar ideas for other multiclass models such as fluid layered queuing networks .
appendix in this appendix we describe how to get our linear representation from the original one of which contains nonlinear terms such as pi j k i k tminfxi k si k g to do so we initially consider the case where xi k si k then we remove the nonlinearity by using appropriate constraints to account for the fact that the actual instantaneous throughput cannot exceed i k si k .
under the assumption that xi k si k the consistency between and is ensured by the relations cni k i k xi k t cni k cpi j k pi j k i k xi k t authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
solving as a function of the variables i k andpj i k gives i k cni k xi k t pi j k cni k cpi j k cni k substituting these expressions in and we get the following constraints for the new variables cni k xi k t i cni k xi k t i cpi j k cni k x j2scpi j k cni k jsj to account for the nonlinearity of the service rates we interpret the expressions for throughput as follows i k minfxi k si k g this means that at most si k jobs can be served at once i.e.
a concurrency level limitation .
using the upper bound for the service rate i k i we can write i k xi k isi k i k isi k xi k the basic idea under these equations is that we are translating the upper bound on the throughput into an upper bound of the service rate i k .
in particular if xi k si k then isi k xi k i thus the maximum service rate for station i is limited by constraint instead if xi k si k then isi k xi k ihence the service rate of station iis limited by the resource constraints as if the system was linear.
using we are able to translate the constraints over the original adaptation knobs into linear constraints over the virtual ones yielding cni k ixi k t cn i k isi k t a similar reasoning is made for the lower bound of each service rate.
the constraint i k min i isi k xi k captures the fact that the chosen rate cannot be less than its given lower bound i. the second argument of the above minimum expression instead handles the case when xi k si k .
the minimum allowed service rate will be scaled down by the factor si k xi k with respect to the user defined minimum value i. this ensures that the minimum throughput allowed in the linear model it is always equal to the minimum throughput specified in the original formulation.
in this case as expected using equation can be written as cni k i tminfxi k si k g we remove the nonlinearity of the above min expression by introducing the binary variables di k for eachi2s.
withthe further variables dmini k i2s we encode the value minfxi k si k gusing the constraints dmini k xi k di k dmini k si k di k dmini k xi k dmini k si k where is an arbitrary scaling factor chosen such that jxi k si k jfor8i2s.
this leads to the desired upper bound forcni k cni k idmini k t we develop an objective function consistent with specifically we denote by m0 k m0 k m0 r k the vector of performance metrics to be tracked where each mi k i ris defined as follows m0 i k cnj k ifkind ri thj xj k ifkind ri qj similarly to r k is the vector of reference values for each time stepkwithri k value ri ande0 k m0 k r k is the error to be minimized.
the objective function for the mip formulation is given by f h 1x k 0e0 k te0 k putting all these results together the mip formulation results to be specified as follows minimizeu0 k f u0 k fcni k cpi j k si k di k g subject to eqs.
si k si si k 2s v cni k ixi k t i2s v cpi j k cni k pi j pi j2s v fork h where with we set the values for the qn parameters.
the integer variables di k ensure that the lower bounds used during the optimization are consistent with the userdefined values i. indeed the removal of from our formulation leads the minimum throughput ixi k to increase by a factorxi k si k whenxi k si k .
it is worth noticing that the objective function is composed only of quadratic terms over the decision variables making the above mip program a quadratic one and still efficiently solvable with standard convex optimization techniques.
this theoretical formulation results to be of key relevance for the efficiency of our mpc formulation.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.