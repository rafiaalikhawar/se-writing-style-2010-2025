how reliable is the crowdsourced knowledge of security implementation?
mengsu chen felix fischer na meng xiaoyin wang jens grossklags virginia tech technical university of munich university of texas at san antonio mschen vt.edu flx.fischer tum.de nm8247 vt.edu xiaoyin.wang utsa.edu jens.grossklags tum.de abstract stack overflow so is the most popular online q a site for developers to share their expertise in solving programming issues.
given multiple answers to a certain question developers may take the accepted answer the answer from a person with high reputation or the one frequently suggested.
however researchers recently observed that so contains exploitable security vulnerabilities in the suggested code of popular answers which found their way into security sensitive highprofile applications that millions of users install every day.
this observation inspires us to explore the following questions how much can we trust the security implementation suggestions on so?
if suggested answers are vulnerable can developers rely on the community s dynamics to infer the vulnerability and identify a secure counterpart?
to answer these highly important questions we conducted a comprehensive study on security related so posts by contrasting secure and insecure advice with the community given content evaluation.
thereby we investigated whether so s gamification approach on incentivizing users is effective in improving security properties of distributed code examples.
moreover we traced the distribution of duplicated samples over given answers to test whether the community behavior facilitates or prevents propagation of secure and insecure code suggestions within so.
we compiled different groups of similar security related code examples and labeled their security identifying secure answer posts and insecure answer posts.
compared with secure suggestions insecure ones had higher view counts vs. received a higher score vs. and had significantly more duplicates .
vs. .
on average.
of the posts provided by highly reputable so called trusted users were insecure.
our findings show that based on the distribution of secure and insecure code on so users being laymen in security rely on additional advice and guidance.
however the communitygiven feedback does not allow differentiating secure from insecure choices.
the reputation mechanism fails in indicating trustworthy users with respect to security questions ultimately leaving other users wandering around alone in a software security minefield.
index terms stack overflow crowdsourced knowledge social dynamics security implementation i. i ntroduction since its launch in stack overflow so has served as the infrastructure for developers to discuss programmingrelated questions online and provided the community with crowdsourced knowledge .
prior work shows that so is one of the most important information resources that developers rely on .
meanwhile researchers also revealed that some highly upvoted or even accepted answers on so this work was supported by onr grant n00014 .contained insecure code .
more alarmingly fischer et al.found that insecure code snippets from so were copied and pasted into android applications available on google play .
several high profile applications containing particular instances of these insecure snippets were successfully attacked and user credentials credit card numbers and other private data were stolen as a result .
these observations made us curious about so s reliability regarding suggestions for security implementations.
taking a pessimistic view such insecure suggestions can be expected to be prevalent on the q a site and consistent corrective feedback by the programming community may be amiss.
consequently novice developers may learn about incorrect crowdsourced knowledge from such q a sites propagate the misleading information to their software products or other developers and eventually make our software systems vulnerable to known security attacks.
therefore within this paper we conducted a comprehensive in depth investigation of the popularity of both secure and insecure coding suggestions on so and the community activities around them .
to ensure a fair comparison between secure and insecure suggestions we focused on the discussion threads related to java security.
we used baker to mine for answer posts that contain any code using security libraries and extracted such code snippets.
we reused the security domain expertise summarized by prior work to manually label whether a given code snippet is secure or not.
however different from prior work that studied the application of insecure so answers to production code our work focuses on the so suggestions themselves.
more specifically we studied coding suggestions popularity social dynamics and duplication.
we also inquired how developers may be misled by insecure answers on so.
to identify prevalent topics on so we used ccfinder to detect code clones i.e.
duplicated code in the data extracted by baker.
these clones are clustered within clone groups.
clone groups were observed to use security library apis and implement functionalities like ssl tls symmetric and asymmetric encryption etc.
moreover we found that code examples within clone groups are more likely to be viewed than non duplicated code snippets on so.
this further motivates our sampling method as we can expect clones to have a higher impact on users and production code.
among the clone groups there were groups of duplicated secure ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
code groups of similar insecure code and groups with a mixture of secure and insecure code snippets.
these clone groups covered secure code snippets and insecure ones.
by mapping cloned code to their container posts we contrasted insecure suggestions with secure ones in terms of their popularity users feedback degree of duplication and causes for duplication.
we explored the following research questions rqs rq1 how prevalent are insecure coding suggestions on so?
prior work witnessed the existence of vulnerable code on so and indicates that such code can mislead developers and compromise the quality of their software products .
to understand the number and growth of secure and insecure options that developers have to choose from we compared the occurrence counts of insecure and secure answers and observed the distributions of both kinds of answers across a year time frame .
rq2 do the community dynamics or so s reputation mechanism help developers choose secure answers over insecure ones?
reputation mechanisms and voting were introduced to crowdsourcing platforms to incentivize contributors to provide high quality solutions and facilitate question askers to identify responders with high expertise .
we conducted statistical testing to compare secure and insecure answers in terms of votes answerers reputations etc.
rq3 do secure coding suggestions have more duplicates than insecure ones?
when certain answers are repetitively suggested it is likely that developers will encounter such answers more often.
moreover if these answers are provided by different users the phenomenon might facilitate users trust in the answers correctness.
therefore we compared the degree of repetitiveness for insecure and secure answers.
rq4 why did users suggest duplicated secure or insecure answers on so?
we were curious about why certain code was repetitively suggested and we explored this facet of community behavior by examining the duplicated answers posted by the same or different users.
in our study we made four major observations as with secure answers insecure answers are prevalent on so across the entire studied time frame.
the inspected snippets from different clone groups correspond to secure posts and insecure ones.
among the ssl tls related posts posts suggest insecure solutions which makes ssl tlsrelated answers the most unreliable ones on so.
at least of the security related answers posted every year are insecure which shows that security knowledge on so in general is not significantly improving over time.
the community dynamics and so s reputation mechanisms are not reliable indicators for secure and insecure answers.
compared with secure posts insecure ones !
!
... ... ... fig.
a typical so discussion thread contains one question post and one or multiple answer posts obtained higher scores more comments more favorites and more views .
although the providers of secure answers received significantly higher reputation scores the effect size is negligible .
.
of the examined accepted answers are insecure.
out of the posts suggested by trusted users with 20k reputation scores are insecure.
these observations imply that reputation and voting on so are not reliable to help users distinguish between secure and insecure answers.
the degree of duplication among insecure answers is significantly higher than that of secure ones.
on average there are more clones in an insecure group than a secure one .
vs. .
.
it means that users may have to deal with a large supply of insecure examples for certain questions before obtaining secure solutions.
users seem to post duplicated answers while ignoring security as a key property.
duplicated answers were provided due to duplicated questions or users intent to answer more questions by reusing code examples.
this behavior is incentivized by the reputation system on so.
the more answers are posted by a user and up ranked by the community the higher reputation the user gains.
our source code and data set are available at com mileschen360 higgs.
ii.
b ackground to facilitate the discussion of so community activities around security implementations we will first introduce so s crowdsourcing model and then summarize the domain knowledge used to label secure and insecure code snippets.
a. stack overflow as a crowdsourcing platform some observers believe that the success of so lies in its crowdsourcing model and the reputation system .
the four most common forms of participation are i question asking ii question answering iii commenting and iv voting scoring .
figure presents an exemplar so discussion thread which contains one question and one or many answers.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i criteria used to decide code s security property category parameter insecure ssl tlshostnamev erifier allow all hosts trust manager trust all v ersion tlsv1.
cipher suite rc4 3des aes cbc md5 md2 onreceivedsslerror proceed cipher moderc2 rc4 des 3des aes ecb blowfish symmetric key static bad derivation initialization v ector iv zeroed static bad derivation password based encryption pbe 1k iterations bit salt static salt asymmetric key rsa bit ecc bit pbkdf sha224 md2 md5 hash digital signature sha1 md2 md5 credentials sha1 md2 md5 type random random seedingsetseed nextbytes setseed with static values when multiple answers are available the asker decides which answer to accept and marks it with .
after a user posts a question an answer or a comment other users can vote for or against the post.
users gain reputation for each up vote their posts receive.
for instance answers earn their authors points per up vote questions earn and comments earn .
all users initially have only one reputation point.
as users gain more reputation they are granted more administrative privileges to help maintain so posts .
for instance a user with points can vote up posts.
a user with points can vote down posts.
users with at least 20k points are considered trusted users and can edit or delete other people s posts.
the score of a question or answer post is decided by the upvotes and down votes the post received.
users can favorite a question post if they want to bookmark the question and keep track of any update on the discussion thread.
each question contains one or many tags which are words or phrases to describe topics of the question.
each post has a timestamp to show when it was created.
each discussion thread has a view count to indicate how many times the thread has been viewed.
b. categorization of java security implementations based on state of the art security knowledge researchers defined five categories of security issues relevant to library misuses .
table i shows their criteria which we use in this project to decide whether a code snippet is insecure or not.
ssl tls there are five key points concerning how tosecurely establish ssl tls connections.
first developers should use an implementation of the hostnameverifier interface to verify servers hostnames instead of allowing all hosts .
second when implementing a custom trustmanager developers should validate certificates instead of blindly trusting all certificates.
third when tls is passed as a parameter to sslcontext.getinstance ... developers should explicitly specify the version number to be at least .
because tls lower versions are insecure .
fourth the usage of insecure cipher suites should be avoided.
fifth when overriding onreceivedsslerror developers should handleinstead of skipping any certificate validation error.
listing shows a vulnerable snippet that allows all hosts trusts all certificates and uses tls v1.
.
listing an example to demonstrate three scenarios of insecurely using ssl tls apis create a trust manager that does not validate certificate chains trust all private tru stmanager t rustallcerts n e w trustmanager new x509trustmanager public java .
security .
cert .
x509certificate getacceptedissuers return null public void checkclienttrusted ... public void checkservertrusted ... public serviceconnectionse string url throws i oexception try use the default tlsv1.
protocol sslcontext sc sslcontext .
getinstance tls install the trust all trust manager sc .
init null trustallcerts n e w java .
security .
securerandom .
.
.
... connection httpsurlconnection new u r l url .
openconnection use allowallhostnameverifier that allows all hosts httpsurlconnection connection .
sethostnameverifier n e w allowallhostnameverifier symmetric there are ciphers and modes of operations known to be insecure.
cryptographic keys and initialization vectors iv are insecure if they are statically assigned zeroed or directly derived from text.
password based encryption pbe is insecure if the iteration number is less than the salt s size is smaller than bits or a static salt is in use.
listing presents a vulnerable code example that insecurely declares a cipher a key and an iv .
listing an example to present several insecure usage scenarios of symmetric cryptography declare a key parameter with a static value private st atic byte k e y .
getbytes declare an iv parameter with a static value private st atic byte iv .
getbytes public stat ic string enc rypt string in string cypert in try ivparameterspec ivspec new ivparameterspec iv create a secret key with the des cipher secretkeyspec k new secretkeyspec key d e s declare a des cipher cipher c cipher .
getinstance des c b c pkcs7padding c .
i n i t c i p h e r .
encrypt mode k i v s p e c ... asymmetric suppose that a code snippet uses either rsa or ecc apis to generate keys.
when the specified key lengths for rsa and ecc are separately shorter than bits and bits we consider the api usage to be insecure.
listing shows a vulnerable code example.
listing an example that insecurely uses rsa by specifying the key size to be keypairgenerator kpg keypairgenerator .
getinstance r s a k p g. initialize keypair kp kpg.
generatekeypair rsapublickey pub rsapublickey kp.
getpublic rsaprivatekey priv rsaprivatekey kp .
getprivate hash in the context of password based key derivation digital signatures and authentication authorization developers may explicitly invoke broken hash functions.
listing shows an example using md5.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
listing insecurely creating a message digest with md5 final messagedigest m d messagedigest .
getinstance m d it is also insecure to hardcode the plaintext password final byte digestofpassword m d. digest hg58yz3cr9 .
getbytes utf random to make the generated random numbers unpredictable and secure developers should use securerandom instead of random .
when using securerandom developers can either call nextbytes only or call nextbytes first and setseed next.
developers should not call setseed with static values.
listing presents an example using securerandom insecurely.
listing using securerandom with a static seed byte keystart encryption key .
getbytes securerandom sr securerandom .
getinstance sha1prng sr .
setseed keystart iii.
m ethodology to collect secure and insecure answer posts we first extracted code snippets from so that used any security api section iii a .
next we sampled the extracted code corpus by detecting duplicated code section iii b .
finally we manually labeled sampled code as secure insecure or irrelevant and mapped the code to related posts section iii c .
additionally we compared the view counts of the sampled posts vs. unselected posts to check samples prevalence section iii d .
a. code extraction to identify coding suggestions this step extracts securityrelated answer posts by analyzing tags of question posts and the code snippets api usage of answer posts.
after downloading the stack overflow data as xml files we used a tool stackexchange dump to postgres to convert the xml files to postgres database tables.
each row in the database table posts corresponds to one post.
a post s body text may use the html tag pair code and code to enclose source code so we leveraged this tag pair to extract code.
since there were over million posts under processing and one post could contain multiple code snippets it is very challenging to efficiently identify security implementations from a huge amount of noisy code data.
thus we built two heuristic filters to quickly skip irrelevant posts and snippets.
table ii tags used to locate relevant so discussion threads category tags java platforms android applet eclipse java java1.
java java ee javamail jax ws jdbc jndi jni ... third party tools librariesaxis2 bouncycastle gssapi httpclient java metroframework openssh openssl spring security ... security aes authentication certificate cryptography des encoding jce jks jsse key random rsa security sha sha512 single sign on ssl tls x509certificate ... filtering by question tags as tags are defined by askers to describe the topics of questions we relied on tags to skip obviously irrelevant posts.
to identify as many security coding suggestions as possible we inspected the cryptographyrelated posts mentioned in prior work and identified 93tags.
if a question post contains any of these tags we extracted code snippets from the corresponding answer posts.
as shown in table ii these tags are either related to java platforms thirdparty security libraries or tools or security concepts.
filtering by security api usage similar to prior work we used baker to decide whether a snippet calls any security api.
this paper focuses on the following apis java platform security org.jetf.jgss.
android.security.
com.sun.security.
java.security.
javax.crypto.
javax.net.ssl.
javax.security.
javax.xml.crypto.
third party security libraries bouncycastle gnu crypto jasypt keyczar scribejava spongycastle .
after taking in a set of libraries and a code snippet baker extracts all apis of types methods and fields from the libraries extracts names of types methods and fields used in the code snippet and iteratively deduces identifier mappings between the extracted information.
intuitively when multiple type apis e.g.
a.b.c andd.e.c can match a used type name c baker compares the invoked methods on cagainst the method apis declared by each candidate type and chooses the candidate that contains more matching methods.
we included a code snippet if baker finds at least one api class or method with an exact match.
however baker s result set is not fully accurate and requires a number of postprocessing steps to reduce false positives.
these include a blacklist filter for standard java types e.g.
string and very popular methods e.g.
get .
baker s oracle contains only the given security apis which helped reduce false positives when detecting secure code but did not help reduce false negatives.
b. clone detection with the filters described above we identified code snippets from posts that are probably security related.
since it is almost impossible to manually check all these snippets to identify secure and insecure code we decided to sample representative extracted code via clone detection and then manually label the samples.
in addition to sampling clone detection facilitates our research in two further ways.
first by identifying duplicated code with ccfinder we could explore the degree of duplication among secure and insecure code.
second through clustering code based on their similarity we could efficiently read similar code fragments and determine their security property in a consistent way.
with the default parameter setting in ccfinder we identified clone groups that contained code snippets with each group having at least two snippets.
c. code labeling we manually examined each of those snippets and labeled code based on the criteria mentioned in section ii.
if a snippet meets any criteria of insecure code shown in table i it is labeled as insecure .
if the snippet uses any security api but does not meet any criteria it is labeled as secure otherwise it is irrelevant .
depending on the apis involved we also decided to which security category a relevant post authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii code labeling results for clone groups secure insecure mixed irrelevant total of clone groups of snippets of answer posts fig.
cdfs of view count among the included answers excluded ones and all answers related to baker s output belongs.
when unsure about certain posts we had discussions to achieve consensus.
finally we randomly explored a subset of the labeled data to double check the correctness.
table iii presents our labeling results for the inspected clone groups.
after checking individual code snippets we identified secure groups insecure groups mixed groups and irrelevant groups.
in particular a mixed group has both secure snippets and insecure ones which are similar to each other.
although two filters were used see section iii a of the clone groups from refined data were still irrelevant to security which evidences the difficulty of precisely identifying security implementation with baker.
the clone groups cover secure snippets insecure ones and irrelevant ones.
when mapping these snippets to the answer posts which contain them we identified secure answers insecure ones and irrelevant ones.
one answer can have multiple snippets of different clone groups.
therefore we consider a post insecure if it contains any labeled insecure code.
a post was labeled secure if it has no insecure snippet but at least one secure snippet.
if a post does not contain any in secure snippet it is labeled as irrelevant .
d. v erifying the prevalence of sampled posts to check whether our clone based approach actually included representative so posts we separately computed the cumulative distribution functions cdf of view count for the included posts as mentioned in table iii the excluded posts and the complete set of posts identified by baker.
as shown in fig.
the included curve is beneath the all and excluded curves.
this shows that the highly viewed answers take up a higher percentage in our sample set than the excluded answers.
!
!
fig.
the distribution of posts among different categories iv .
m ajor findings in this section we present our results and discuss the main findings regarding our stated research questions.
a. popularity of secure and insecure code suggestions figure presents the distribution of answer posts among the security categories.
since some posts contain multiple snippets of different categories the total number of plotted secure and insecure posts in figure is slightly larger than .
among the categories ssl tls contains the most posts while random has the fewest posts .
two reasons can explain such a distribution.
first developers frequently use or are more concerned about apis of ssl tls symmetric and hash .
second the criteria we used to label code contain more diverse rules for the above mentioned three categories so we could identify more instances of such code.
there are many more insecure snippets than secure ones in thessl tls vs. category indicating that developers should be quite cautious when searching for such code.
meanwhile secure answers dominate the other categories accounting for of asymmetric posts of hash posts of symmetric posts and of random posts.
however notice that across these categories only of the posts are secure that is considerable room for error remains.
finding out of the inspected answer posts are insecure meaning that insecure suggestions popularly exist on so.
insecure answers dominate in particular the ssl tls category.
to explore the distribution of secure and insecure answers over time we clustered answers based on their timestamps.
as shown in figure both types of answers increased yearby year from to and decreased in .
this may be because so reached its saturation for java securityrelated discussions in .
in and insecure answers were posted more often than secure ones taking up of the sampled data of each year.
for the other years secure posts constitute the majority within the yearly sampled data set accounting for .
to further determine whether older posts are more likely to be insecure we considered post ids as logical timestamps.
we applied a mann whitney u test which does not require normally distributed data and calculated the cliff s delta authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
the distribution of posts over during size which measures the difference s magnitude .
the resulting p value is .
with cliff s .
.
it means that secure answers are significantly more recent than insecure ones but the effect size is negligible.
two reasons can explain this finding.
first some vulnerabilities were recently revealed.
among the insecure posts in and answers use md5 answers trust all certificates and answers use tls .
.
however these security functions were found broken in which made the answers obsolete and insecure.
second some secure answers were posted to correct insecure suggestions.
for instance we found a question inquiring about fast and simple string encryption decryption in java .
the accepted answer in suggested des an insecure symmetric key algorithm.
later various comments pinpointed the vulnerability and a secure answer was provided in .
note that there can be a significant lag until the community adopts new secure technologies and phases out technologies known to be insecure.
although md5 s vulnerability was exploited by flame malware in as shown in fig.
md5 was still popularly suggested afterwards obtaining a peak number of related answers in .
finding insecure posts led the sampled data in while secure ones were dominant afterwards.
older security related posts are less reliable likely because recently revealed vulnerabilities outdated older suggestions.
we found only few secure answers suggested to correct outdated insecure ones.
b. community dynamics towards secure and insecure code for each labeled secure or insecure post we extracted the following information score comment count the answerer s reputation score the question s favorite count and the discussion thread s view count.
comparison of mean values.
table iv compares these information categories for the secure posts and insecure ones and applies mann whitney u tests to determine significant results.
on average secure posts answerersfig.
distributions of md5 and sha256 related posts have higher reputation vs. .
however for the ssl tls posts the insecure answer providers have higher reputation vs. .
moreover insecure posts have higher scores and more comments favorites and views.
users seemed to be more attracted by insecure posts which is counterintuitive .
we would expect secure answers to be seen more favorable with more votes comments and views.
three reasons can explain our observation.
first software developers often face time constraints.
when stuck with coding issues e.g.
runtime errors developers are tempted to take insecure but simpler solutions .
take the vulnerable ssl tls usage in listing for example.
the insecure code was frequently suggested on so and many users voted for it mainly because the code is simple and useful to resolve connection exceptions.
nevertheless the simple solution essentially skips ssl verification and voids the protection mechanism.
in comparison a better solution should use certificates from a certification authority ca or self signed certificates to drive the customization of trustmanager and verify certificates with more complicated logic .
second some insecure algorithms are widely supported by java based libraries which can promote developers tendency to code insecurely.
for instance up till the current version java java platform implementations have been required to support md5 the well known broken hash function .
third insecure posts are less recent and may have accumulated more positive scores than recent secure posts.
finding on aver age insecure posts received higher scores more comments more favorites and more views.
it implies that more user attention is attracted by insecure answers and users cannot rely on the voting system to identify secure answers.
comparison of p values and cliff s .table iv shows that among all posts insecure ones obtained significantly more comments p .
and views p .5e while the effect sizes are negligible.
specifically for the random category insecure posts have significantly higher view counts p .
and the effect size is large.
meanwhile the owners of secure answer posts have significantly higher reputation p .
but the magnitude is also negligible.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv comparison between secure and insecure posts score comment count reputation favorite count view count allsecure mean insecure mean p value .
.
.
.
.5e cliff s .
negligible .
negligible .
negligible category secure mean insecure mean ssl tlsp value .
.3e .
.
.
cliff s .
small category secure mean insecure mean symmetricp value .
.
.
.
.
cliff s category secure mean insecure mean asymmetricp value .
.
.
.
.
cliff s category secure mean insecure mean hashp value .
.
.
.
.
cliff s category secure mean insecure mean randomp value .
.
.
.
.
cliff s .
large .
large .
large .
large similar to prior work we interpreted the computed cliff s delta value vin the following way if v .
the effect size is negligible if .
v .
the effect size is small if .
v .
the effect size is medium otherwise the effect size is large .
fig.
the answer distribution based on owners reputation figure further clusters answers based on their owners reputation scores.
we used logarithmic scales for the horizontal axis because the scores vary a lot within the range .
overall the secure and insecure answers have similar distributions among different reputation groups.
for instance most answers were provided by users with scores within accounting for of secure posts and of insecure posts.
among the posts by trusted users answers are insecure and not reliable.
one reason to explain why high reputation scores do not guarantee secure answers can be that users earned scores for being an expert in areas other than security.
responders reputation scores do not necessarily indicate the security property of the provided answers.
therefore so users should not blindly trust the suggestions given by highly reputable contributors.
finding the users who provided secure answers have significantly higher reputation than the providers of insecure answers but the difference in magnitude is negligible.
users cannot rely on the reputation mechanism to identify secure answers.fig.
the distribution of clone groups based on their sizes comparison of accepted answers.
it is natural for so users to trust accepted answers.
among the posts we found accepted answers .
accepted answers are secure accounting for of the inspected secure posts.
accepted answers are insecure accounting for of the inspected insecure posts.
it seems that accepted answers evenly distribute among secure and insecure posts they are not good indicators of suggestions security property.
finding accepted answers are also not reliable for users to identify secure coding suggestions.
c. duplication of secure and insecure code among the security related clone groups we explored the degree of code duplication for secure clone groups insecure groups and mixed groups.
figure shows the distribution of clone groups based on their sizes.
similar to fig.
we used logarithmic scales for both the horizontal and vertical axes.
in fig.
most clone groups are small with similar snippets.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table v comparison between secure and insecure groups in terms of their group sizes secure groups meaninsecure groups meanp value cliff s size .
.
.3e .
negligible the number of groups decreases dramatically as the group size increases.
interestingly within there are more insecure groups than secure ones.
table v compares the sizes of secure and insecure groups.
surprisingly insecure groups have significantly larger sizes than secure ones although the difference is negligible.
our observations imply that the frequently mentioned code snippets on so are not necessarily more secure than less frequent ones .
users cannot trust code s repetitiveness to decide the security property.
finding repetitiveness does not guarantee security so users cannot assume a snippet to be secure simply because it is recommended many times.
to understand why there are mixed groups that contain similar secure and insecure implementations we conducted a case study on randomly selected mixed groups.
among allthese groups secure snippets differ from insecure ones by using distinct parameters when calling security apis.
this implies a great opportunity to build security bug detection tools that check for the parameter values of specific apis.
listing a clone group with both secure and insecure code an insecure snippet using aes ecb to create a cipher cipher cipher cipher .
getinstance aes ecb pkcs5padding sunjce key skeyspec keygenerator .
getinstance a e s .
generatekey cipher .
init cipher .e n crypt m o d e skeyspec system.
out .
println arrays .
tostring cipher .
do final n e w byte a secure snippet using aes cfb to create a cipher final cipher cipher cipher .
getinstance a e s c f b nopadding sunjce final secretkey skeyspec keygenerator .
getinstance a e s .
generatekey cipher .
init cipher .e n crypt m o d e skeyspec system.
out .
println arrays .
tostring cipher .
do final n e w byte listing shows a mixed clone group where the insecure code uses aes ecb to create a cipher and the secure code uses aes cfb .
actually both snippets were provided by the same user which explains why they are so similar.
these answers are different because the askers inquired for different modes ecb vs. cfb .
although the answerer is an expert in using both apis and has a high reputation score .7k he she did not mention anything about the vulnerability of ecb.
this may imply a lack of security expertise or vulnerability awareness of highly reputable so users and a well motivated need for automatic tools to detect and fix insecure code.
finding secure and insecure code in the same mixed group often differs by passing distinct parameters to the same security apis highlighting opportunities for automatic tools to handle security weaknesses.d.
creation of duplicated secure and insecure code we conducted two case studies to explore why duplicated code was suggested.
case study i duplicated answers by different users.
we examined the largest secure group and largest insecure group.
the secure group has clone instances which are similar to the code in listing .
these snippets were offered to answer questions on how to enable an android app to log into facebook.
the questions are similar but different in terms of the askers software environments e.g.
libraries and tools used and potential solutions they tried.
among the answers only were marked as accepted answers.
the majority of duplicated suggestions are relevant to the questions but cannot solve the issues.
so users seemed to repetitively provide generally best practices probably because they wanted to earn points by answering more questions.
listing an exemplar snippet to generate a key hash for facebook login packageinfo info getpackagemanager .
getpackageinfo com.
facebook .
samples .
hellofacebook packagemanager .
get signatures for signature signature info .
si gnatures messagedigest m d messagedigest .
getinstance s h a m d. update signature .
tobytearray log.d keyhash base64 .
encodetostring m d. digest base64 .d e f a u l t the largest insecure group contains clone instances which are similar to the code in listing .
the questions are all about how to implement ssl tls or resolve ssl connection exceptions.
of these answers were accepted.
we noticed that only one answer warns do not implement this in production code .
.
.
.
six answers have at least one comment talking about the vulnerability.
the remaining answers include nothing to indicate the security issue.
case study ii.
duplicated answers by the same users.
in total users reused code snippets to answer multiple questions.
among the clone groups these users produced there are secure groups insecure groups and mixed groups.
users repetitively posted secure answers and users posted duplicated insecure answers.
six among these users posted both secure and insecure answers.
most users i.e.
only copied code once and produced two duplicates.
one user posted nine insecure snippets with seven snippets using an insecure version of tls and two snippets trusting all certificates.
this user has .7k reputation top overall and is an expert in android.
by examining the user s profile we did not find any evidence to show that the user intentionally misled people.
it seems that the user was not aware of the vulnerability when posting these snippets.
to understand whether duplicated code helps answer questions we randomly sampled of the clone groups resulting in secure clone pairs insecure pairs and mixed pairs.
unexpectedly we found that pairs did not directly answer the questions.
for instance a user posted code without reading the question and received down vote i.e.
.
in the other cases duplicated code was provided to answer similar or identical questions.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
finding duplicated answers were created because users asked similar or related questions and some users blindly copied and pasted code to answer more questions and earn points.
however we did not identify any user that intentionally misled people by posting insecure answers.
v. r ela ted work a. security api misuses prior studies showed that api misuses caused security vulnerabilities .
for instance lazar et al.
analyzed published cryptographic vulnerabilities in the cve database and found that of them were caused by api misuses .
egele et al.
built a static checker for six well defined android cryptographic api usage rules e.g.
do not use ecb mode for encryption .
they analyzed android applications for any rule violation and found of the applications violating at least one checked rule.
instead of checking for insecure code in cve or software products we focused on so.
because the insecure coding suggestions on so can be read and reused by many developers they have a profound impact on software quality.
the research by fischer et al.
is closely related to our work.
in their work secure and insecure snippets from so were used to search for code clones in android apps.
our research is different in three aspects.
first it investigates the evolution and distribution of secure and insecure coding suggestions within the so ecosystem itself.
second while compares average score and view counts for secure and insecure snippets they merely do this for snippets whose exact copies have migrated into apps but not for our much broader set of snippets on so.
therefore the dataset of is not representative to evaluate the impact of severity community s awareness and popularity of unreliable so suggestions on secure coding.
third we conducted not only statistical testing on a comprehensive dataset to quantitatively contrast score view count comment count reputation and favorite count but also case studies to qualitatively analyze the differences.
we further explored the missing link between gamification and security advice quality on crowdsourcing platforms.
b. developer studies researchers conducted interviews or surveys to understand developers security coding practices .
for example nadi et al.
surveyed developers and revealed that developers found it difficult to use cryptographic algorithms correctly .
xie et al.
interviewed developers and found that most developers had reasonable knowledge about software security but they did not consider security assurance as their own responsibility .
acar et al.
surveyed developers and conducted a lab user study with students and professional android developers .
they observed that most developers used search engines and so to address security issues.
these studies inspired us to explore how much we can trust the crowdsourced knowledge of security coding on so.c.
empirical studies on stack overflow researchers conducted various studies on so .
specifically zhang et al.
studied the jdk api usage recommended by so and observed that of the studied posts misused apis .
meng et al.
manually inspected so discussion threads related to java security .
they revealed various secure coding challenges e.g.
hardto configure third party frameworks and vulnerable coding suggestions e.g.
ssl tls misuses .
mamykina et al.
revealed several reasons e.g.
high response rate to explain why so is one of the most visible venues for expert knowledge sharing .
v asilescu et al.
studied the associations between so and github and found that github committers usually ask fewer questions and provide more answers .
bosu et al.analyzed the dynamics of reputation building on so and found that answering as many questions as possible can help users quickly earn reputation .
in comparison our paper quantitatively and qualitatively analyzed secure and insecure so suggestions in terms of their popularity answerers reputations the community s feedback to answers e.g.
votes and comments and the degree and causes of duplicated answers.
we are not aware of any prior work that analyzes so posts in these aspects.
d. duplication detection related to so or vulnerabilities researchers used clone detection to identify duplication within so or between so and software products .
specifically ahasanuzzaman et al.
detected duplicated so questions with machine learning .
an et al.
compared code between so and android apps and observed unethical code reuse phenomena on so .
other researchers used static analysis to detect vulnerabilities caused by code cloning .
for instance kim et al.
generate a fingerprint for each java method to efficiently search for clones of a given vulnerable snippet .
different from prior work we did not invent new clone detection techniques or compare code between so and software projects.
we used clone detection to sample crawled security related code and explore why so users posted similar code to answer questions.
vi.
o urrecommenda tions by analyzing so answer posts relevant to java based security library usage we observed the wide spread existence of insecure code.
it is worrisome to learn that so users cannot rely on either the reputation mechanism or voting system to infer an answer s security property a recent meta exchange discussion thread also shows the frustration of so developers to keep outdated security answers up to date .
below are our recommendations based on this analysis.
a for tool builders explore approaches that accurately and flexibly detect and fix security bugs.
although a few tools identify security api misuses through static program analysis or machine learning they are unsatisfactory due to the hard to extend api misuse patterns hardcoded in tools and hard to explain machine learning results.
people report vulnerabilities and patches on authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
cve and in security papers.
tools like lase were built to i generalize program transformation from concrete code changes and ii leverage the transformation to locate code for similar edits.
if tool developers can extend such tools to compare secure insecure counterparts they can automatically fix vulnerabilities in a flexible way.
b for so developers integrate static checkers to scan existing corpus and so posts under submission.
automatically add warning messages or special tags to any post that has vulnerable code.
encourage moderators or trusted users to exploit clone detection technologies in order to efficiently detect and remove both duplicated questions and answers.
such deduplication practices will not only save users time and effort of reading answering useless duplicates but also mitigate the misleading consensus among multiple similar insecure suggestions.
as user profiles include top tags to reflect the frequently asked answered questions by users.
instead of accumulating a single reputation score for each user so developers can compute one score for each top tag to better characterize users expertise.
c for designers of crowdsourcing platforms provide incentives to users for downvoting or detailing vulnerabilities and suggesting secure alternatives.
introduce certain mechanisms to encourage owners of outdated or insecure answers to proactively archive or close such posts.
we expect researchers from the usable security and hci domain to evaluate and test new design patterns that integrate security evaluation in the gamification approach.
vii.
t hrea ts to validity a threat to external v alidity this study labels insecure code based on the java security rules summarized by prior work so our studied insecure snippets are limited to java code and these rules.
since we used the state of the art insecurity criteria our analysis revealed as diverse insecure code as possible.
in the future we plan to identify more kinds of insecure code by considering different programming languages and exploiting multiple vulnerability detection tools .
b threat to construct v alidity although we tried our best to accurately label code our analysis may be still subject to human bias and cannot scale to handle all crawled data or more security categories.
we conservatively assume a snippet to be secure if it does not match any given rule.
however it is possible that some labeled secure snippets actually match the insecurity criteria not covered by this study or will turn out to be insecure when future attack technologies are created.
we concluded that insecure answers are popular on so and gain high scores votes and views.
even if the labels of some existing secure answers will be corrected as insecure in the future our conclusion generally holds.
c threat to internal v alidity we leveraged clone detection to sample the extracted code snippets and reduce our manual analysis workload.
based on code s occurrence repetition clone detection can ensure the representativeness of sampled data.
however the measurement on a sample data set may be still different from that of the whole data set.
oncewe build automatic approaches to precisely identify security api misuses we can resolve this threat.
viii.
c onclusion we aimed to assess the reliability of the crowdsourced knowledge on security implementation.
our analysis of answer posts on so revealed insights.
in general secure and insecure advices more or less balance each other secure and insecure .
users without security knowledge may heavily rely on the community to provide helpful feedback in order to identify secure advice.
unfortunately we found the community s feedback to be almost useless.
for certain cryptographic api usage scenarios the situation is even worse insecure coding suggestions about ssl tls dominate the available options.
this is particularly alarming as ssl tls is one of the most common use cases in production systems according to prior work .
the reputation mechanism and voting system popularly used in crowdsourcing platforms turn out to be powerless to remove or discourage insecure suggestions.
insecure answers were suggested by people with high reputation and widely accepted as easy fixes for programming errors.
on average insecure answers received more votes comments favorites and views than secure answers.
as a countermeasure security evaluation can be included in the voting and reputation system to establish missing incentives for providing secure and correcting insecure content.
when users are motivated to earn reputation by answering more questions the platform encourages contributors to provide duplicated less useful or insecure coding suggestions.
therefore with respect to security so s gamification approach counteracts its original purpose as it promotes distribution of secure and insecure code.
although we did not identify any malicious user that misuses so to propagate insecure code we do not see any mechanism designed to prevent such malicious behaviors either.
when developers refer to crowdsourced knowledge as one of the most important information resources it is crucially important to enhance the quality control of crowdsourcing platforms.
this calls for a strong collaboration between developers security experts tool builders educators and platform providers.
by educating developers to contribute high quality security related information and integrating vulnerability and duplication detection tools into platforms we can improve software quality via crowdsourcing.
our future work will focus on building the needed tool support.
acknowledgment we thank reviewers for their insightful comments.
we also thank dr. kurt luther for his valuable feedback.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.