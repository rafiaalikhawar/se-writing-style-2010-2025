steelix program state based binary fuzzing yuekang li school of computer science and engineering nanyang technological university singaporebihuan chen school of computer science and shanghai key lab.
of data science fudan university chinamahinthan chandramohan school of computer science and engineering nanyang technological university singapore shang wei lin school of computer science and engineering nanyang technological university singaporeyang liu school of computer science and engineering nanyang technological university singaporealwen tiu school of computer science and engineering nanyang technological university singapore abstract coverage based fuzzing is one of the most effective techniques to find vulnerabilities bugs or crashes.
however existing techniques suffer from the difficulty in exercising the paths that are protected by magic bytes comparisons e.g.
string equality comparisons .
several approaches have been proposed to use heavy weight program analysis to break through magic bytes comparisons and hence are less scalable.
in this paper we propose a program state based binary fuzzing approach named steelix which improves the penetration power of a fuzzer at the cost of an acceptable slow down of the execution speed.
in particular we use light weight static analysis and binary instrumentation to provide not only coverage information but also comparison progress information to a fuzzer.
such program state information informs a fuzzer about where the magic bytes are located in the test input andhow to perform mutations to match the magic bytes efficiently .
we have implemented steelix and evaluated it on three datasets lava m dataset darpa cgc sample binaries and five real life programs.
the results show that steelix has better code coverage and bug detection capability than the state of the art fuzzers.
moreover we found one cve and nine new bugs.
ccs concepts security and privacy software security engineering keywords binary fuzzing coverage based fuzzing binary instrumentation acm reference format yuekang li bihuan chen mahinthan chandramohan shang wei lin yang liu and alwen tiu.
.
steelix program state based binary fuzzing.
in corresponding author.
also with nanyang technological university singapore.
shang wei lin and yang liu have equal contribution in this work.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse september paderborn germany association for computing machinery.
acm isbn .
.
.
.
of 11th joint meeting of the european software engineering conference and the acm sigsoft symposium on the foundations of software engineering paderborn germany september esec fse pages.
introduction since its introduction in early 1990s fuzzing has become one of the most effective and scalable testing techniques to find vulnerabilities bugs or crashes in commercial off the shelf cots software.
it has also been widely used by mainstream software companies such as google microsoft and adobe to ensure the quality of their software products.
the key idea of fuzzing is to feed the program under test put with a large amount of malformed test inputs to trigger unintended program behaviors such as crashes or hangs.
the existing fuzzing approaches can be classified by two dimensions.
based on how the structural knowledge of the put is utilized fuzzers can be classified as white box black box or grey box.
whitebox fuzzers e.g.
either have access to the source code of the put or rely on binary lifting to translate assembly into an intermediate language.
they usually apply heavy weight program analysis such as symbolic execution to improve the effectiveness but may have scalability problems.
black box fuzzers e.g.
have no knowledge about the internals of the put and thus are less effective.
grey box fuzzers e.g.
are in between.
they apply light weight program analysis to extract partial information of the put without sacrificing the fast execution speed of tests.
on the other hand based on how the test inputs to the put are generated fuzzers can be classified as mutation based or generationbased.
mutation based fuzzers e.g.
start with a set of preprovided test inputs i.e.
seeds and generate new test inputs by mutating these test inputs e.g.
byte flipping .
they are effective to fuzz programs that process compact and unstructured data formats e.g.
image .
generation based fuzzers e.g.
start with no test inputs and construct test inputs based on the knowledge of the input format or grammar.
they are more suitable for programs that process highly structured inputs e.g.
xml .
in this paper we focus on grey box mutation based fuzzing.
one of the most successful techniques is coverage based fuzzing which uses light weight instrumentation to extract coverage information for each executed test input in order to determine which test inputs 627esec fse september paderborn germany y. li b. chen m. chandramohan s. w. lin y. liu and a. tiu 1int main void char str gets str if strcmp str maze trigger the crash return a sample code 11int main void if getchar m if getchar a if getchar z if getchar e trigger the crash return b sample code figure motivation examples should be retained for fuzzing.
specifically if a test input can trigger the execution of a new basic block it is considered as interesting and retained otherwise it is discarded.
thus coverage based fuzzers explore execution paths of a put in an incremental manner.
afl is the state of the art coverage based fuzzer and has discovered hundreds of high profile vulnerabilities .
however coverage based fuzzing has limited penetration power to exercise the paths protected by magic bytes comparisons .
magic bytes refer to the bytes in the test input which are uses in comparison instructions.
for example the string maze in the program in fig.
1a is considered as four magic bytes.
in this case afl has to mutate all the four magic bytes correctly at once to trigger the crash because mutating one two or three bytes correctly cannot lead to new coverage.
thus it is very difficult for afl to trigger the crash i.e.
afl needs at most 8executions of the program in fig.
1a.
the challenge is that coverage based fuzzers do not have the knowledge of where the magic bytes are located in the test input andhow to perform mutations to match the magic bytes efficiently .
several advances have been already made to combine coveragebased fuzzing with some program analysis techniques to address the challenge.
for example driller uses concolic execution to solve those comparison constraints.
vuzzer uses dynamic taint analysis to penetrate those comparisons.
afl lafintel applies program transformation at llvm ir level to convert a magic bytes comparison into multiple nested one byte comparisons.
although they have shown promising results both driller and vuzzer rely on heavy weight program analysis i.e.
concolic execution suffers from the infamous path explosion problem and dynamic taint analysis can greatly slow down the execution speed and afl lafintel works at the source code level and fails to know where the magic bytes are located in the test input.
in this paper we propose a program state based fuzzer steelix1 which works at the binary level and can exercise paths protected by magic bytes comparisons at the cost of an acceptable slow down of the execution speed.
the key idea of steelix is that we not only collect the coverage information but also collect the comparison progress information i.e.
whether more bytes are correctly matched in magic bytes comparisons .
thus program state in this paper refers to coverage and comparison progress.
whenever a test input generated by mutating some byte triggers new program states we infer the location of the magic bytes as the mutated byte and its neighbors in the test input and retain the test input for further fuzzing.
in particular instead of relying on heavy weight program analysis steelix leverages light weight static analysis and binary instrumentation to collect the coverage and comparison progress information as the dynamic feedbacks to guide the mutation.
static analysis filters out uninteresting comparisons e.g.
one byte comparisons 1a pok mon that can dig deep below the surface.and extracts the information of interesting comparisons.
based on the extracted information binary instrumentation instruments the put to obtain the actual value of comparison operands and generate comparison progress information during runtime.
then the fuzzer takes the instrumented put and uses the collected feedbacks to perform adaptive mutation.
we have implemented the proposed approach by extending afl and evaluated the effectiveness of steelix using two sets of widelyused benchmark programs i.e.
lava m and darpa cgc sample binaries and five real life programs i.e.
pngfix tcpdump tiffcp tiff2pdf andgzip .
steelix outperformed both vuzzer and afl lafintel in three out of the four binaries from lava m and found an average of more bugs.
moreover steelix covered an average of respectively .
.
and .
more lines of code functions and branches than afl dyninst in three out of the five real life programs where magic bytes comparisons are very common and found more bugs than afl dyninst in cgc sample binaries and real life programs.
specifically we found one cve and nine new bugs and three of them were not found by afl dyninst.
in summary this work makes the following contributions.
we proposed a program state based binary fuzzing approach to exercise paths protected by magic bytes comparisons at the cost of an acceptable slow down of the execution speed.
we proposed light weight static analysis and binary instrumentation to collect both coverage and comparison progress information as the dynamic feedbacks to guide adaptive mutation.
we implemented and evaluated steelix on various benchmark and real life programs which showed promising results.
we found one cve and nine previously unknown bugs in some widely used real life programs.
overview in this section we first introduce a motivating example and then present an overview of the proposed approach.
.
motivation example coverage based fuzzers such as afl use the coverage information to determine which mutated test input should be kept.
for example for the program in fig.
1b given the test input xxxx afl will keep the test input mxxx after mutating the first byte correctly because mxxx can pass the first ifconditional and trigger new code coverage.
based on mxxx afl can generate the test input maxx that will also be kept.
in this incremental way afl can eventually generate the test input maze and trigger the crash.
however for the program in fig.
1a that has the same logic as the program in fig.
1b afl will have difficulty in triggering the crash because mutating one byte correctly does not trigger new code coverage.
for example given the test input xxxx afl can generate mxxx after some mutations but mxxx does not trigger new coverage.
thus afl will discard mxxx although some progress has been made to pass the magic bytes comparison.
in this case afl has to mutate the whole four magic bytes correctly at once to trigger the crash.
afl needs at most 8executions to trigger the crash in fig.
1a but needs at most 28executions for fig.
1b.
to break through the magic bytes comparison in fig.
1a afllafintel attempts to transform the program in fig.
1a into the 628steelix program state based binary fuzzing esec fse september paderborn germany program binarystatic analysisbasic block comparison info.binary instrumentationinstrumented binaryprogram executionadaptive mutationcoverage comparison progress location info.mutated test inputthe fuzzing loop figure an overview of the proposed approach steelix program in fig.
1b and relies on afl s capability to incrementally trigger the crash.
however if the test input of the program in fig.
1b contains bytes and the magic bytes are just four of them which is quite common in real life programs afl will still have difficulty in triggering the crash because it does not know where the magic bytes are located in the test input and thus cannot mutate the test input efficiently.
on the other hand driller and vuzzer respectively use concolic execution and dynamic taint analysis to break through magic bytes comparisons.
however as concolic execution and dynamic taint analysis are often known as heavy weight techniques driller and vuzzer can handle the program in fig.
1a but may suffer from scalability problems for real life programs.
following the previous examples we have two observations.
first the test input mxxx has made some progress to match the magic bytes and should be kept for further fuzzing.
second mxxx is mutated from xxxx which shows that part of the magic bytes is located at the first byte and may also be located at the neighbors of the first byte.
motivated by these observations we propose to collect both coverage and comparison progress information infer the location information of magic bytes by tracking if mutating certain byte can lead to new coverage or comparison progress and use such information to guide the mutation.
.
approach overview our approach is designed to fuzz a put directly on its executable binary with two considerations.
first the source code of a put is not always available.
by working at the binary level steelix can be applicable to both open and close source programs.
second the comparison operands in assembly code lose their type information.
the comparisons of integer float or string buffer become the comparisons of bytes.
hence comparisons at assembly code level are more explicit for analysis than those at the source code level.
fig.
gives an overview of steelix which contains three main components static analysis binary instrumentation and the fuzzing loop.
in particular static analysis see section .
takes the program binary as an input and disassembles it.
based on the assembly code it filters out uninteresting comparisons according to several rules so that only a portion of the comparisons are dynamically analyzed during fuzzing.
then it extracts the information of those interesting comparisons and the information of basic blocks which tells binary instrumentation where to instrument andwhat to instrument .
note that basic blocks are used to collect coverage information for the fuzzer which are instrumented in the same way as current coveragebased fuzzing approaches e.g.
afl .
thus we will not discuss how to analyze and instrument basic blocks in section .
and .
.
the statically extracted information together with the program binary are then passed to binary instrumentation see section .
.
thebinary instrumentation has two main concerns.
first we need to mark comparison progress in a compact way as comparison progress is recorded in the shared memory whose size is designed to be limited 64kb for efficiency .
second we instrument the program to get the actual value of comparison operands and generate comparison progress information during fuzzing.
finally the fuzzing loop see section .
takes the instrumented binary and starts the fuzzing.
specifically after executing the instrumented program the fuzzer will get the coverage and comparison progress feedback and derive the location information of the magic bytes based on the feedback.
the coverage comparison progress and location information are then used to guide the adaptive mutation i.e.
choosing suitable mutation operators.
methodology in this section we elaborate each component in fig.
in details.
.
static analysis the purpose of static analysis in steelix is to provide the basic block and comparison information for binary instrumentation section .
.
here we only discuss the comparison information.
.
.
comparison instructions.
static analysis first disassembles the program binary.
the instruction set for assembly varies on different platforms.
in this work we focus on the x86 bit instruction set.
the comparisons in x86 assembly can be achieved by using the cmp test instructions or function calls.
both test andcmpinstructions have two operands.
the test instruction performs a bitwise logical andoperation and sets the flags.
for example the instrument test ebx ebx will set the zero flag zf if the value of register ebxis0.
thecmpinstruction subtracts the operands and set the flags.
for example the instrument cmp dword ptr will set the zf if the memory content of ebp is9.
the operands of cmpandtest instructions can be a register memory reference or immediate value.
the size of an operand can be bytes dword 2bytes word or 1byte byte .
for comparing strings or buffer values the program first pushes the values of the function arguments onto the stack and then invokes the corresponding functions e.g.
strcmp strncmp .
.
.
filtering out uninteresting comparisons.
in steelix we only perform instrumentation on the interesting comparison instructions because the instrumentation slows down the program execution.
we want to add them as precise as possible to reduce the execution overhead.
interesting cmp test instructions are those whose comparison operands are meaningful for steelix.
the following rules describe how uninteresting instructions are filtered out.
629esec fse september paderborn germany y. li b. chen m. chandramohan s. w. lin y. liu and a. tiu 1int main void int magic number int in num scanf d in num if in num magic number trigger the crash return a sample code 31int main void int magic number char in str int in num gets in str in num hash in str if in num magic number trigger the crash return b sample code figure examples of comparisons one byte comparisons are not instrumented .
as discussed the size of operands used in a cmp test instruction can be 2or4bytes.
one byte comparisons can be easily matched with those default bit flippings or arithmetic plus minus mutations used by afl.
comparisons of function return values are not instrumented .
the reason is that the computations in functions can make the link between comparison operands and input bytes less explicit.
for example for the program in fig.
3a the comparison between in num andmagic number is interesting as in num is directly from the test input.
however the comparison in the program in fig.
3b is uninteresting.
this is because the comparison uses the result of a hash function that is linked with all bytes in the test input.
to match one byte correctly at the comparison requires mutating many bytes in the test input and the complexity is not reduced.
.
.
extracting comparison information.
after filtering out the uninteresting comparisons steelix extracts the information of the remaining comparisons with static analysis by scanning through the assembly and generating two lists of comparison information.
the first list keeps the information of the interesting cmpandtest instructions.
each entry of this list is in the following format instruction address operand1 info operand2 info where instruction address is the address of the instruction and operand info holds the type of the operand i.e.
whether it is a register a memory reference or an immediate value.
it also contains some other useful information for getting the actual value of the operand at runtime.
for example in the following statement the offset 4is also included in operand1 info .
cmp dword ptr the second list keeps the information of function calls of strcmp strncmp ormemcmp .
each entry of this list contains the address of the function call and the name of the called function function call instruction address function name note that the address of instructions in each entry informs the binary instrumentation of where to add the instrumentation.
.
binary instrumentation static analysis only provides static information of the interesting comparisons in the program binary and the actual value of a comparison operand remains unknown during the static analysis unless it is an immediate value.
thus based on the statically extracted comparison information we adopt program instrumentation to provide runtime feedback i.e.
get the actual value of comparison operands and generate comparison progress information for the fuzzer.
.
.
comparison progress.
comparison progress together with the coverage information is recorded in the shared memory whose 12346578910111213141516figure the states of a four byte comparison a shaded block means a matched byte size is designed to be limited 64kb for efficiency .
as we record the progress for all comparisons we need to mark the comparison progress in a compact way to fit with the shared memory.
here we define comparison progress as how many consecutive bytes starting from the first or last byte of the comparison operands are matched .
for example a four byte comparison has different states as shown in fig.
.
it is too costly to keep the information of all the states because the number of states will explode when the number of magic bytes grows.
to avoid the state explosion we selectively use some of the states to mark the progress of a comparison.
from fig.
we can see that there are paths from state to state .
according to our definition of the comparison progress we use the states on the path 16and the states on the path 16to infer the comparison progress.
the reason for choosing those two paths is that given any two consecutive states on those paths we can know which exact byte the fuzzer should mutate in the next iteration.
for example given state with the first byte matched and state with the first and second bytes matched we can infer that we should mutate the next byte in the forward direction i.e.
the third byte.
similarly given state with the last two bytes matched and state with the last three bytes matched we can infer that we should mutate the next byte in the backward direction i.e.
the first byte.
furthermore states on the same row in fig.
can be merged into one situation.
for example both state 2and 5are matching one byte correctly and can be merged into one situation.
the difference is that to make comparison progress we need to mutate the next byte in forward direction for state 2but in backward direction for state and the direction of mutation can be inferred as discussed above.
thus instead of considering all the 16states we only consider 5situations to represent the progress of a four byte comparison matching and 4bytes.
these 5situations correspond to rows 1to5in fig.
respectively.
matching 0byte means that there is no progress at all.
matching bytes means that the magic bytes are found.
the situations in between are intermediate steps .
for example if we have a test input at state any mutation leading to new test inputs at states other than state 6will not be counted as making progress and the fuzzer will focus on producing a test input at state .
the detail of how the mutation operator utilizes the progress information will be discussed in section .
.
by categorizing comparison states into different situations we can reduce the number of shared memory entries for a n byte comparison from 2nton .
.
.
instrumentation mechanisms.
the instrumentations we add to the put are to generate the program state feedback i.e.
the coverage change and comparison progress for the fuzzer.
here we focus on the instrumentations for comparisons.
630steelix program state based binary fuzzing esec fse september paderborn germany xxxxmxxxmaxxmazxmazeinput 0input 1input 2input 3input 7bit flipping arithmetic operations ...exhaustive mutationexhaustive mutationexhaustive mutation figure an example of adaptive mutation as introduced in section .
.
two lists of comparison information are generated by static analysis.
one list keeps the information of the cmp test instructions and the other one keeps the information of the comparison function calls.
these two lists are used for providing guidance about where and what to instrument.
specifically for cmpandtest instructions we add the instrumentations before them based on the address information in the list.
the logic flow inside the instrumentations is as follows.
first the actual values of comparison operands are extracted during runtime.
for a register operand its value can be directly accessed given the register name.
for a memory reference operand the memory address is computed and the operand value is generated by dereferencing the corresponding memory addresses.
then the operand values are used for generating the comparison progress information as discussed in section .
.
.
finally the fuzzer is informed about the comparison progress information via the shared memory.
for the comparisons using function calls since the function arguments can be hard to access from the stack we replace the function calls with calls to our implemented version which accepts the same number and type of arguments.
our implemented versions have the same functionality as the original ones and additional logic to generate the comparison progress information and inform the fuzzer.
the instrumentations help the fuzzer to keep the test inputs that can trigger program state changes allowing the fuzzer to match the magic bytes comparison byte by byte.
for instance in a n byte comparison if we want to match all the whole nbytes correctly at once the search space is in the complexity of n. however if we match the magic bytes byte by byte the search space will be reduced to the complexity of n which is a magnitude reduction.
thus the instrumentations contribute to solving the problem of how to perform mutations to match the magic bytes.
.
the fuzzing loop the fuzzing loop takes the instrumented binary and starts fuzzing.
the instrumentations section .
can inform the fuzzer of whether a test input makes comparison coverage progress or not.
this information alone is still not sufficient to efficiently match the magic bytes as we do not know where the magic bytes locate in the test input.
to know the location information of the magic bytes one possible approach is to use taint analysis to extract the informationalgorithm the fuzzing loop 1s s is the test input queue 2load s with the user provided test input s 3while time budget reached or abort signal received do s next s s is the current input ifsisan intermediate step test input then apply local exhaustive mutations lem n is the new test input iflem generates input n that triggers new program state then append n to s ifn improves comparison progress but not coverage then mark n as an intermediate step test input keep the location of the mutated byte remove s from s continue apply normal mutations nm n is the new test input ifnm generates input n that triggers new program state then append n to s ifn improves comparison progress but not coverage then mark n as an intermediate step test input keep the location of the mutated byte ifsisan intermediate step test input then remove s from s of how the comparison operands are linked with the test input.
for example vuzzer uses dynamic taint analysis to gather information of comparisons.
however though powerful and precise taint analysis is not suitable for fast program execution .
here we propose an approach using feedback of the instrumentations to get the location information.
the approach uses the heuristic that if a byte of a test input is used in a comparison then the bytes nearby may also be used in that comparison.
in steelix after the fuzzer makes a mutation if it is informed by the instrumentations that it makes progress in matching magic bytes it will keep the new test input together with the position of the byte that it just mutated.
when the fuzzer tries to mutate the new test input it will exhaustively try all the possibilities of the two neighbor bytes according to different situations i.e.
local exhaustive mutation .
algorithm gives the procedure of the fuzzing loop where the normal mutations and our local exhaustive mutation are applied adaptively.
we will use fig.
as an example to show how these mutations are guided by the coverage and comparison progress information.
assume that the magic string used for comparison is maze and the corresponding bytes in the initial input are xxxx .
the circles in fig.
are the bytes that the fuzzer tries to mutate.
first the byte at offset 2is mutated from x to m which can be easily achieved by normal mutation operators like bit flipping or arithmetic plus minus line .
after this mutation input 1is generated.
a coveragebased fuzzer will not be aware of this change and will discard input .
however the instrumentation used by steelix will inform the fuzzer of hitting one byte of a magic bytes comparison line and .
thus steelix will keep input 1as an intermediate step input keep the location of the mutated byte and discard input line .
when the fuzzer retrieves input 1from the input queue it will get 631esec fse september paderborn germany y. li b. chen m. chandramohan s. w. lin y. liu and a. tiu this information input 1is an intermediate step input and the last mutated location is at offset line .
then the fuzzer will try out all the 256possibilities for the byte at offset line .
it will not get any feedback because the byte at offset 1is just a dummy byte in this example.
thus the fuzzer will try with the byte at offset3 and will be notified of making progress in matching bytes for comparisons when it generates input .
the fuzzer will keep input discard input and continue fuzzing with input line .
when the fuzzer retrieves input 2from the queue it will receive two more pieces of information input 2is generated with the local exhaustive mutation and input 2is generated by mutating in the direction of increasing offsets line .
then the fuzzer will only try out all the possibilities of the byte at offset .
like input input 3will be generated and used for generating input .
when input 4is generated and applied to execution it will trigger a new execution path.
the basic block instrumentation will inform the fuzzer that input 4leads to new basic block coverage and it is no longer an intermediate step input.
thus the fuzzer will not apply the local exhaustive mutation on input .
from the example we can see that with the comparison progress and location information the fuzzer will generate a lot of inputs.
however not every one of them is of the same importance.
in steelix the intermediate step inputs become useless after the input holding the final magic bytes is generated.
steelix will drop an intermediate step input from the queue once the fuzzer makes progress in solving magic byte comparisons based on that input line and .
as discussed the location information is based on the heuristic that the magic bytes used in a comparison are clustered in the input.
however it is possible that the magic bytes used in a comparison are from different parts of the input.
in such a case steelix will not be informed of making any progress after applying the local exhaustive mutations.
steelix will keep the intermediate step input and apply the normal mutations on other bytes line instead of removing that intermediate step input from the queue.
implementation and evaluation we have implemented steelix in python c and c .
specifically static analysis was implemented using idapython and binary instrumentation was implemented using dyninst .
we extended afl .33b to be the fuzzer in steelix.
all the experimental results are available at our website .
.
evaluation setup to evaluate the effectiveness of steelix we compared steelix with several state of the art fuzzers on a variety of programs.
evaluation datasets.
we used two sets of widely used benchmarks i.e.
lava m and darpa cgc sample binaries and five real life programs i.e.
tiff2pdf tiffcp pngfix gzip and tcpdump for our evaluation.
the benchmark programs are known to have certain vulnerabilities and hence form a ground truth corpora for tool evaluation.
the real life programs are used to demonstrate the scalability and effectiveness of steelix on large programs.
lava m dataset.
lava m consists of buggy version of linux utilities i.e.
base64 md5sum uniq andwho.
it was generated by automatically injecting hard to reach bugs into existing program source code and was designed as a benchmark for evaluatingthe bug detection capability of fuzzers.
the lava authors have demonstrated that a coverage based fuzzer fuzzer and a satbased approach ses cannot find the injected bugs effectively .
recent fuzzers e.g.
vuzzer all used this benchmark.
darpa cgc sample binaries.
in the defense advanced research projects agency darpa held a cyber grand challenge cgc which was the first all computer capture the flag tournament .
darpa released the binaries used in the qualification and final event of cgc and the representative sample binaries.
however these binaries run under the darpa experimental cyber research evaluation environment decree while steelix relies on dyninst and it is hard to port dyninst into decree.
although the team trailofbits migrated these binaries into the linux system it is difficult to set up the fuzzing environment for some binaries due to some migration problems.
therefore we only used the representative sample binaries.
compared to lava m cgc sample binaries are smaller in size and contain fewer bugs per program which are more suitable for detailed analysis of how steelix helps bug detection.
real life programs.
we selected five real life programs i.e.
pngfix libpng tcpdump libpcap tiffcp libtiff tiff2pdf libtiff and gzip based on the following two criteria.
first each program is officially published together with the widely used libraries.
we also instrumented the libraries used by these programs to fuzz the program logic inside those libraries.
second the programs libraries represent different types of reallife programs.
pngfix tiffcp andtcpdump are about data parsing while tiff2pdf andgzip are to perform calculations.
state of the art tools.
we compared steelix with three most related state of the art fuzzers afl dyninst vuzzer and afl lafintel .
note that driller is also closely related to steelix but its current release was designed and built for only decree binaries.
thus we did not compare with driller in the evaluation.
afl only works on programs with source code provided.
to enable afl to fuzz program binaries effectively researchers have proposed several extensions such as afl qemu aflpin and afl dyninst .
among them afl dyninst is the closest one to steelix since our implementation also relies on dyninst.
thus we compared with afl dyninst on all the three datasets.
vuzzer is a recently published fuzzer that also aims at solving the magic bytes comparison problem.
the tool was not released when we conducted the experiments.
hence we compared with vuzzer on the lava m dataset using the data provided in their paper.
afl lafintel unlike afl dyninst vuzzer and steelix that work on binaries requires the source code of the put.
we decided to compare with afl lafintel as its divide and conquer approach is similar to our utilization of comparison progress and used the lava m dataset for the comparison across these four approaches.
experimental infrastructure.
we ran all our experiments on a machine with intel r xeon r cpu e5 v3 cores and 8gb memory running bit ubuntu .
lts system.
although afl supports the master slave fuzzing paradigm for all the afl based fuzzers including steelix afl dyninst and afl lafintel we only used one master fuzzer instance for the experiments.
this is not only to align with vuzzer which does not support parallel fuzzing currently but also to reduce the bias introduced by parallel fuzzing.
632steelix program state based binary fuzzing esec fse september paderborn germany table detected bugs on lava m dataset program total bugs fuzzer ses vuzzer afl lafintel steelix base64 md5sum uniq who total research questions.
the experiments were designed to answer the following three research questions rq1.
how good is the bug detection capability of steelix?
rq2.
how good is the code coverage of steelix?
rq3.
how is the overhead of steelix on the fuzzing loop?
.
results on lava m dataset rq1 the authors of lava evaluated a coverage based fuzzer fuzzer and a sat based approach ses on the lava m dataset for five hours but did not reveal any detailed