an empirical study towards characterizing deep learning development and deployment across different frameworks and platforms qianyu guo1 sen chen2 xiaofei xie2 lei ma3 qiang hu3 hongtao liu1 yang liu2 jianjun zhao3 xiaohong li1 1college of intelligence and computing tianjin university china 2nanyang technological university singapore3kyushu university japan abstract deep learning dl has recently achieved tremendous success.
a variety of dl frameworks and platforms play a key role to catalyze such progress.
however the differences in architecture designs and implementations of existing frameworks and platforms bring new challenges for dl software development and deployment.
till now there is no study on how various mainstream frameworks and platforms influence both dl software development and deployment in practice.
to fill this gap we take the first step towards understanding how the most widely used dl frameworks and platforms support the dl software development and deployment.
we conduct a systematic study on these frameworks and platforms by using two types of dnn architectures and three popular datasets.
for development process we investigate the prediction accuracy under the same runtime training configuration or same model weights biases.
we also study the adversarial robustness of trained models by leveraging the existing adversarial attack techniques.
the experimental results show that the computing differences across frameworks could result in an obvious prediction accuracy decline which should draw the attention of dl developers.
for deployment process we investigate the prediction accuracy and performance refers to time cost and memory consumption when the trained models are migrated quantized from pc to real mobile devices and web browsers.
the dl platform study unveils that the migration and quantization still suffer from compatibility and reliability issues.
meanwhile we find several dl software bugs by using the results as a benchmark.
we further validate the results through bug confirmation from stakeholders and industrial positive feedback to highlight the implications of our study.
through our study we summarize practical guidelines identify challenges and pinpoint new research directions such as understanding the characteristics of dl frameworks and platforms avoiding compatibility and reliability issues detecting dl software bugs and reducing time cost and memory consumption towards developing and deploying high quality dl systems effectively.
index t erms deep learning frameworks deep learning platforms deep learning deployment empirical study i. i ntroduction with the big data explosion and hardware evolution over the past decade deep learning dl has achieved tremendous success in many cutting edge domains such as real time strategy game image processing speech and language processing and autonomous vehicle .
the deep neural sen chen chensen ntu.edu.sg and xiaohongli xiaohongli tju.edu.cn are the corresponding authors.network dnn plays a key role behind such recent success of dl applications.
it automatically learns the decision logic from the training data which is represented in the form of a neural network and the connection strengths among neurons.
to transfer the learning theory into practice a number of dl frameworks e.g.
tensor flow and pytorch are developed towards realizing the demands of intelligent software.
although most of the existing dl frameworks share either static or dynamic computation paradigms the detailed architecture design and implementation of frameworks are quite different.
actually even the same dnn architecture design with exactly the same runtime configuration i.e.
random seed for initialization and hyper parameters for training might result in different decisions when implemented under different dl frameworks which brings new challenges for dl software development process.
several dl benchmarking studies have focused on some basic metrics of dl frameworks such as training and testing accuracy the influence of hardwares i.e.
gpu and cpu and also compared different frameworks with their default configuration settings and training data specific parameters .
however there lacks an empirical study on the impacts that various dl frameworks under the same runtime configuration or same model weigths biases have on the dl software development process.
moreover with the great demand on deploying the dl software to different platforms it further poses new challenges when dl models on the pc platform are migrated quantized and deployed on other platforms such as real mobile devices and web browsers.
while a computational intensive dl software could be executed efficiently on pc platform with the gpu support such dl models usually cannot be directly deployed and executed on other platforms supported by small devices due to various limitations such as the computation power memory size and energy.
therefore some dl frameworks are specifically designed for mobile platforms such as tensor flow lite for android and core ml for ios.
similarly tensor flow .js for web dl applications is also proposed.
meanwhile in terms of mobile devices it is a common practice that a dl model needs to undergo a quantization process before the deployment considering the 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
limited resources of memory and energy on mobile devices .
there lacks an empirical study focusing on the process of migration and quantization on mobile and web platforms.
although the diverse dl frameworks and platforms promote the evolution of dl software understanding the characteristics of them becomes a time consuming task for dl software developers and researchers.
moreover the differences compared with the traditional software brings new challenges for dl software development and deployment processes.
these challenges include that for the development process there lacks a deep understanding of various frameworks under a the training and prediction accuracy given the same runtime configuration b the prediction accuracy given the same model weights biases and c the robustness of trained models.
for the deployment process when deploying the trained models from pc server to different platforms there lacks a benchmarking understanding of the migration and quantization processes such as the impacts on prediction accuracy performance i.e.
time cost and memory consumption .
to address the aforementioned challenges with an over ten man month effort we design and perform an empirical study on the state of the art dl frameworks and platforms from two aspects to investigate the following research questions.
as for the development process rq1 accuracy on different frameworks.
given the same runtime configuration or same model weights biases what are the differences of training and prediction accuracy when implemented with different dl frameworks?
rq2 adversarial robustness of trained models.
do dl models trained from different dl frameworks exhibit the same adversarial robustness against adversarial examples?
as for the deployment process rq3 performance after migration and quantization.
what are the differences of performance i.e.
time cost and memory consumption in the capabilities of supporting dl software when migrating or quantizing the trained models to the real mobile devices and web browsers?
rq4 prediction accuracy after migration and quantization.
given the same trained dl model what is the prediction accuracy of the migrated model for mobile and web platforms?
how do quantization methods influence the prediction accuracy of quantized model on mobile devices?
through answering these research questions we aim to characterize the impacts of current dl frameworks and platforms on dl software development and deployment processes and provide practical guidelines to developers and researchers from different research communities such as se and ai fields and under different practical scenarios.
in summary we make the following main contributions to the best of our knowledge this is the first empirical study on how the current dl frameworks and platforms influence the development and deployment processes especially for the study on the migration and quantization processes on different dl platforms.
for the development process we find the computing differences across frameworks might result in an obvious prediction accuracy decline.
that would be a great warning to the dl developers and se testing researchers.
our further investigation finds the adverarial robustness of trained models from different frameworks is also different.
for the deployment process real mobile devices and web browsers have different performance in capabilities of supporting dl software.
mobile platforms have a better prediction accuracy of migration than that of current web platforms and the web platforms have an obvious compatibility issue i.e.
prediction accuracy drops over .
we find a real bug according to the phenomenon and report to the stakeholders.
it is confirmed and appreciated by developers.
more bug information can be found on our website .
moreover the quantization of mobile platforms suffer from significant reliability issues on our generated testing dataset and it is hard to trigger such issue by the widely used original testing data.
that would motivate the se researchers to conduct a further test in this field.
we also conduct an online questionnaire to validate the usefulness of our study and receive industrial positive feedback from the ai research teams in baidu china huawei signapore and netease china which confirms the usefulness of our study.
in addition we make all generated testing dataset used in our evaluation on migrated and quantized models publicly available to facilitate further study towards more systematic investigation.
we highlight the challenges and propose new research directions.
meanwhile our empirical study can be used as a benchmark and baseline for issues and bugs detection to evaluate new dl frameworks and platforms.
ii.
b ackground in this section we briefly introduce the current practice of dl software development and deployment.
a. dl software development dl software development contains several phases e.g.
data collection and labelling dnn design runtime training and testing validation .
dl developers design the dnn architecture and specify runtime configuration e.g.
random seed and hyper parameters before training on selected dataset.
it is a common practice that using the state of the art dl frameworks to accomplish training followed by the validation testing stage for accuracy evaluation on the trained models.
b. dl software deployment a dl software that has been well tested and validated and reaches a certain level of quality standard is ready to be deployed for application e.g.
web and mobile platforms .
developers need to consider calibration e.g.
migration and quantization when deploying dl software across different platforms.
for web platform several solutions e.g.
tensor flow .js are proposed for deploying dl models under the web environment.
for mobile platform although the rapid advances authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
.
!
.
!
!
.
.
.. .
!
!
!
.
.
!
!
.
!
!
.
!
!
.
!
fig.
overview of our study in system on chip soc facilitate the ai applications for mobile use existing trained dl models on pc could still not be directly deployed on mobile devices due to the limitations such as computing power memory size and energy capacity.
some lightweight solutions e.g.
tensor flow lite and core ml are proposed to support this migration.
moreover it is a common practice to conduct a quantization process before deploying dl models on mobile devices so as to reduce memory cost and computing overhead .
tensor flow provides two options for quantization i.e.
post training quantization and quantization aware training both of which fixedly convert model weights to 8bits integers from floating points using a linear weights representation.
core ml supports flexible quantization modes i.e.
linear linear lut kmeans lut and custom lut along with a nbits option which allows to customize the bits of per quantized weight e.g.
bits to bits .
iii.
o verview in this section we briefly introduce the overview of our study and the evaluation objects and metrics.
a. study design fig.
shows the overview of our study which contains two main phases i.e.
development and deployment to answer the four research questions.
for the development process we investigate the training and prediction accuracy and adversarial robustness of trained models across different frameworks.
to achieve these goals we select widely used frameworks i.e.
tensor flow pytorch cntk and mxn et as our evaluation objects and use publicly available datasets i.e.
mnist cifar and imdb for training and prediction on each of them.
correspondingly we choose popular dnn models i.e.
lenet lenet5 restnet vgg textcnn lstm rnn and gru rnn for inspection including cnn and rnn architectures.
for the deployment process we focus on the model performance and prediction accuracy after migrated and quantized to different platforms.
to conduct these evaluations popular platforms are selected to evaluate popular web browsers chrome firefox and safari and real mobile devices android devices i.e.
nexus nexus 6p and huawei mate 20x and ios devices i.e.
iphone 6s iphone and ipad pro .
we migrate and deploy the models trained in the development process to the two types of platforms.
meanwhile we follow the common practice to further conduct model quantization for mobile devices to investigate their performance and prediction accuracy.
b. dl frameworks and platforms dl frameworks play an important role to bridge the dl theory to the practice of dl software.
we select the most updated versions of four representative frameworks i.e.
tensor flow .
.
from google pytorch .
.
from facebook cntk .
from microsoft and mxn et .
.
maintained by apache for investigation where tensor flow and cntk adopt the static computational graph paradigm while pytorch follows a dynamic computational paradigm.
mxn etadopts both two types.
we investigate three dl platforms where an urgent demand on dl software solutions exists from industry.
pc the mainstream platform where most dl models are trained.
mobile platform such as android and ios mobile devices.
web platform i.e.
chrome firefox and safari .
c. datasets and dnn models in order to conduct our study we select three publicly available datasets i.e.
mnist cifar and imdb for training and prediction all of them are widely used in dl community.
for each dataset we follow the best dl practice and choose diverse dnn models i.e.
lenet lenet restnet vgg textcnn lstm rnn and gru rnn that are able to achieve competitive results in terms of training and testing accuracy.
we detail the hyperparameters of each dnn model on specific dataset on .
mnist is a collection of gray scale images used for handwritten digit recognition.
for mnist we use two well known models from the lenet family i.e.
lenet and lenet5 .
cifar is a collection of colored images e.g.
airplane automobile and bird for object classification.
for cifar we select two popular dnn models i.e.
resnet20 and vgg for inspection both of which could authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
achieve competitive prediction accuracy.
imdb is a collection of text based movie reviews from the online database imdb which is widely used for text sentiment classification in the field of natural language processing.
as for imdb we select a cnn based model textcnn and an rnnbased model textrnn for inspection both of which are classical models in nlp .
there are two types of implementations for textrnn i.e.
lstm and gru .
d. evaluation metrics accuracy in training and prediction.
at the training stage we first ensure the same runtime configuration across different frameworks.
then we train the models with multiple combinations of hyper parameters on these frameworks and evaluate the training and validation accuracy in this stage.
we select one combination as example shown in this paper which achieves comparable training accuracy for all selected frameworks.
for prediction stage we evaluate the accuracy and time cost using the testing data.
particularly to investigate the computing difference of different frameworks we further ensure the same weights biases of the same model by using mm dnn across different frameworks and evaluate the prediction accuracy.
adversarial robustness.
robustness indicates the quality and security of the trained dl models .
we focus on a typical robustness property adversarial robustness in this paper.
the adversarial robustness concerns whether there exists an example x prime close to a given input x that xandx primeare misclassified by the dnn.
such x prime once exists is called an adversarial example ofxand the dnn is not adversarial robust at x. formally a dnn s adversarial robustness could be analyzed by checking the d local robustness at an input xw.r.t a distance parameter dif we have the following relation x prime x prime x d c x c x prime where xcould be correctly predicted by the dnn.
we follow the currently best practice in machine learning to generate adversarial examples by exerting adversarial attacks on dl models.
accuracy and performance in migration and quantization.
it is common that a dl model with complex structure could achieve competitive results on pc or cloud but inevitably introduce large computing and memory overheads at the same time.
when dl models are migrated from pc to web and mobile platforms we observe the accuracy and performance i.e.
time cost and memory consumption change in this process.
moreover to deploy such dl models on the resource limited mobile devices quantization is a common practice to ensure the smooth running .
we study how quantization technique influences the accuracy and time cost in prediction.
iv .
e mpirical study in this section we first briefly introduce the experimental environment for our study and then we detail the numerous experiments to answer the research questions highlighted in section i. for the development study we train dl models on types datasets using dl frameworks respectively.
we use multiple combinations of hyper parameters for each model in the training stage aiming to obtain a relatively good training accuracy on each framework and avoiding overfitting under fitting as much as possible.
meanwhile we repeat each model training and testing processes times.
for the deployment study trained models from tensor flow are migrated and executed on web browsers and of them are also converted to mobile devices.
real mobile devices including android ios devices are selected to run the migrated quantized models.
for each web browser mobile device we conduct parallel evaluations on each model to minimize the random impacts as much as possible.
the study takes months including the substantial effort on model training migration quantization and cross platform evaluations.
experimental environment.
we run all the pc application experiments on a high performance computer cluster.
each cluster node runs a gnu linux system with linux kernel .
.
on core .3ghz intel xeon cpu e5 with gb ram equipped with a nvidia tesla p40 gpus.
web application experiments are conducted on a laptop with bit chrome .
.
.
firefox .
.
and safari .
.
.
the host laptop is macbook pro with macos .
.
on a .7ghz intel core i7 cpu with 16gb ram.
the mobile application experiments are conducted on real android devices i.e.
huawei mate 20x huawei nexus 6p and motorola nexus with android .
api .
.
api and .
.
api and ios devices i.e.
iphone iphone 6s and ipad pro with ios .
.
.
a. rq1 accuracy on different frameworks training accuracy to investigate the training accuracy across different dl frameworks dnn models i.e.
lenet1 and lenet for mnist resnet and vgg for cifar textcnn lstm rnn and gru rnn for imdb are trained on four different frameworks.
for each model we ensure the same runtime configuration on different frameworks.
for example we set identical learning rate i.e.
.
training epochs i.e.
optimizer i.e.
sgd batch size i.e.
etc.
for lenet on all frameworks.
each dnn model is repeatedly trained for times under each framework and one with the highest validation accuracy is selected for comparison.
we only demonstrate the accuracy of training and prediction by using dnn models i.e.
lenet vgg and gru rnn based on three data types due to the space limitation.
more training plots can be found on our website .
fig.
and show the training and validation plots of lenet5 vgg and gru rnn on gpu with the same runtime configurations under different dl frameworks respectively.
we can see that all frameworks exhibit similar training behaviours but pytorch behaves more stably in both training and validation processes and generally has higher training accuracy compared to the other frameworks in our study.
it is even more obvious for lenet and vgg which have authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a lenet b vgg c gru fig.
training accuracy of lenet vgg and gru with different dl frameworks a lenet b vgg c gru fig.
v alidation accuracy of lenet vgg and gru with different dl frameworks much larger amplitudes on these frameworks than pytorch as shown in fig 2a 2b and fig 3a 3b respectively.
prediction accuracy for each dnn model we select one with the highest validation accuracy to conduct prediction on the testing dataset.
we repeat predictions on each model and find the prediction accuracy is quite similar with time costs varying slightly.
so we record the average accuracy and average time cost for evaluation.
as shown in table i for each model the prediction accuracy of frameworks is similar with a little difference.
the result is reasonable because these frameworks rely on different computing libraries and provide different operator implementations e.g.
convolution operator which finally makes the weights biases on the same layer different from each other.
but when it comes to time costs models on the four frameworks behave quite differently.
we take gru as an example marked in gray it takes only .
seconds on mxn etto predict samples but spends .88s and .69s on tensor flow and cntk respectively.
meanwhile it exhibits an out of memory error under pytorch as marked by o m in table i. this is mainly because pytorch dynamically loads the data along with the graph building at each batch without feeding in advance.
thus pytorch inevitably generates a large number of temporary variables in an instant leading to the memory overflow.
according to the results of prediction accuracy and time costs even given the same configuration models under different frameworks achieve different weights biases resulting in different prediction accuracy and time costs.
this phenomenon inspires us to think if the difference is caused by the inner implementation when conduct computing.
driven by the above observations we further investigate the prediction accuracy of different frameworks with the same weights biases rather than the same runtime configuration.
specifically we take the tensor flow models as benchmark table i average prediction accuracy and average time costs with input data samples on different frameworks dnn modelstensorflow cntk pytorch mxnet acc time s acc time s acc time s acc time s lenet .
.
.
.
.
.
.
.
lenet .
.
.
.
.
.
.
.
resnet .
.
.
.
.
o m .
.
vgg .
.
.
.
.
o m .
.
textcnn .
.
.
.
.
.
.
.
lstm .
.
.
.
.
o m .
.
gru .
.
.
.
.
o m .
.
table ii the layer outputs in resnet on tensor flow model and cntk variant.
idx.
refers to label index.
a activation layer tensorflow cntk .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.62817895layer output .
.
b dense layer last weight layer idx.
tensorflow cntk .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.9673457layer output .
.
and further convert them to variants fit for other frameworks using the existing model conversion tool mm dnn .
the outputs i.e the variants of mm dnn are able to share identical weights biases with the benchmarking tensor flow for each dnn model.
then we conduct predictions on them using the same testing dataset.
most of the prediction accuracy across the four models are the same but an obvious accuracy decline i.e .
to .
occurs on resnet after converted from tensor flow tocntk .
to understand the reason we sample the images that have inconsistent classification results by resnet on tensor flow and cntk .
taking these samples as inputs for the two models we print the outputs of their each hidden layer.
strikingly the outputs of each corresponding layer in the two models are gradually diverging as the layer deepens.
as shown in table iia for activation 1 the first activation layer there are only slight differences between tensor flow and cntk see the pair data marked by gray .
when it comes to the dense layer i.e.
the last weight layer the two frameworks exhibit an obvious distinction leading to diverging classification.
consider the table iib the tensor flow model predicts the image as label with the maximal output being .
.
while the cntk variant predicts it as label with the maximal output being .
.
actually we also find similar issues between other frameworks but not obvious enough to impact the prediction logic.
the phenomenon indicates that computation differences indeed exist between tensor flow and cntk which could be amplified in models with deep layers and introduce prediction errors.
that should draw the attention of developers and researchers who aim to train a model on a framework and deploy on another with the help of model conversion tools.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
answer to rq1 given dl models with the same runtime configuration pytorch generally provides more stable training and validation process than tensor flow cntk and mxn etin our study.
although it is understandable that the computing differences exist across frameworks such differences can sometimes be very obvious under certain scenarios e.g.
model conversion leading to a misclassification on dl models.
the existing model conversion between frameworks is currently not reliable due to the computing differences which requires special attention and inspection before applying directly.
note that participates in the questionnaire are interested in the quantitative differences across frameworks and the corresponding results can be used to provide development insights.
challenge how to identify real framework bugs according to the computing differences?
how to amplify the computing differences to help find more similar issues in se testing field?
b. rq2 robustness of trained model in this section we investigate the robustness of dl models trained from different dl frameworks.
for each model evaluated in table i we examine the robustness against adversarial examples in terms of success rate by leveraging three stateof the art representative adversarial attacks i.e.
fgsm single pixel attack and boundary attack .
given an input each attack generates crafted test cases to fool the model with following criteria fgsm adds perturbations along the model s gradient to craft adversarial examples.
single pixel attack adds human unnoticeable noises on image pixel to generate adversarial images.
boundary attack firstly performs large adversarial perturbations on input and then minimizes the l2 norm of perturbations while staying adversarial.
in particular we randomly select images in mnist and cifar which are correctly predicted by all the models.
and these images are used as the inputs of aforementioned attacks.
to reduce randomness each attack is repeated times to calculate the average success rate.
thus we perform configurations of attacks models frameworks types of attacks repetitions .
fig.
shows the average attack success rates on models trained from different frameworks.
we can see boundaryattack achieves success rate on all dl models because it is the most effective decision based adversarial attack to date.
this indicates that models trained from the state ofthe art frameworks are still vulnerable against the advanced attacks .
moreover models also behave distinctly against other two attacks.
formally we define the following equations to quantify the model robustness under attacks.
p mi a braceleftbigg smi a min max minmin max min max r mi p mi a1 ... p mi ak k where m1 ... m n n represent the nmodels trained from different frameworks and akare the ktypes of attacks.
sm arepresents the average success rate of attack a on model m. thus the min min sm1 a ... smn a and max max sm1 a ... smn a in equation indicate the minimum and maximum success rate of all models involved under attack a respectively.
based on these statistics we can compute the final robustness indicator r mi with equation which quantifies the robustness of model miin terms of attacks a1 ... a n. the smaller value r mi is the better robustness model miexhibits.
in this study m1 m2 m3 m4 represent models from tensor flow pytorch cntk and mxn et respectively.
and a1 a2 a3indicate fgsm attack single pixel attack and boundary attack respectively.
using above equations we find that trained from the same runtime configurations the cntk models generally exhibit the best robustness compared to the models from the other three frameworks.
because r m3 comes to the minimum on lenet lenet and vgg with the value being .
.
and .
respectively.
by contrast pytorch and mxn et are more vulnerable to attacks by adversarial samples.
more results can be found on our website .
answer to rq2 given the same architecture design and runtime configuration dl models from different frameworks exhibit diverse robustness against adversarial attacks.
generally cntk achieves the most robust result in our evaluated settings among all the frameworks when training dl models and models trained from pytorch and mxn et tend to be more vulnerable to adversarial attacks.
challenge how to improve the robustness of dl models in training stage from the perspective of engineering dl frameworks?
how to develop advanced testing techniques to generate specific tests for improving robustness?
c. rq3 time and memory performance of migration and quantization on diff platforms in this section we investigate the differences of capability in supporting dl software across platforms after the model migration quantization from the pc server platform.
we mainly focus on the time costs and memory consumption during prediction which are the key runtime metrics of small devices.
the mobile platforms e.g.
android os and ios systems and web platforms e.g.
web browsers are selected for evaluation.
for the mobile platform tensor flow and core ml are used to migrate the trained dl models to android and ios platforms respectively.
specifically for each dnn model trained by tensor flow we select one with the highest prediction accuracy.
after that the api tococonverter intensor flow .
.
helps migrate these trained models to the android platforms and the tensor flow lite package in android applications provides runtime support for the migrated model execution on android devices.
similarly the coremltools incore ml .
.
can convert the trained models to the ios platforms.
apart from the model migration tensor flow and core ml also provide quantization techniques to optimize a model authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fgsm single pixel boundary tensorflow pytorch cntk mxnet attack success rate a lenet fgsm single pixel boundary tensorflow pytorch cntk mxnet attack success rate b lenet fgsm single pixel boundary tensorflow pytorch cntk mxnet attack success rate c resnet fgsm single pixel boundary tensorflow pytorch cntk mxnet attack success rate d vgg fig.
the robustness evaluation of dl models against adversarial attacks so that it can execute faster and more efficiently on mobile devices .
tensor flow and core ml provide different options to quantize the trained models for mobile platforms.
since the post training quantization is recommended as priority by the documentation of tensor flow and it fixedly converts weight in trained models from bits floating point to bit integer using a liner weight representation.
we initially set the nbits option to and select the linear mode incore ml for all dl models to ensure the consistency.
additionally since the vgg model cannot be quantized to bits in practice we only use a bits quantization for vgg .
in this study representative real mobile devices i.e.
huawei mate x huawei nexus 6p and motorola nexus with android os and iphone iphone 6s and ipad pro with ios are selected for evaluation.
for the web platform tensor flow .js0.
.
is used to migrate the trained tensor flow models to the format which could be loaded by web browsers.
the web platform refers to the browsers on pc rather than on mobile devices.
we select mainstream browsers i.e.
chrome firefox and safari for web evaluation and run them on a macbook pro.
table iii iv and v show the results of prediction accuracy and time cost on different platforms and the effects of migration and quantization for mobile devices and web browsers.
for mobile platforms four cnn models are evaluated because we cannot convert the rnn models i.e.
lstm and gru to mobile platforms due to the unsupported operation error which indicates that the current supporting of dl tasks on mobile platforms is unfledged.
note that quantization is only performed on mobile devices in our study because there is no quantization support for web platforms until now.
for web browsers all the seven trained dl models are selected to migrate.
we record the system memory consumption in prediction process.
notably we do not record the system memory consumption and energy of mobile devices since the record process is inaccurate due to many limitations such as the impacts of mobile system and runtime environment.
time performance for mobile platform android and ios devices exhibit different time performance which depends on dl model type.
as shown in table iii column pred.
time for the lenet and lenet there is a big difference in time performance on ios and android devices.
android devices take less than 9s to predict while ios devices spendtable iii prediction accuracy and time cost on different mobile devices dnn mod.plat.
device quan.
sizeoriginal generated acc.
pred.
time s acc.
lenet 1pc server no 16kb .
.
.42androidnexus 6no 15kb .
.
.
yes .4kb .
.
.
nexus 6pno 15kb .
.
.
yes .4kb .
.
.
mate 20xno 15kb .
.
.
yes .4kb .
.
.
iosiphone 6sno 14kb .
.
.
yes .5kb .
.
.
iphone 8no 14kb .
.
.
yes .5kb .
.
.
ipad prono 14kb .
.
.
yes .5kb .
.
.46lenet 5pc server no 178kb .
.
.24androidnexus 6no 176kb .
.
.
yes 50kb .
.
.
nexus 6pno 176kb .
.
.
yes 50kb .
.
.
mate 20xno 176kb .
.
.
yes 50kb .
.
.
iosiphone 6sno 175kb .
.
.
yes 47kb .
.
.
iphone 8no 175kb .
.
.
yes 47kb .
.
.
ipad prono 175kb .
.
.
yes 47kb .
.
.61resnet 20pc server no .1mb .
.
.70androidnexus 6no .1mb .
.
.
yes 290kb .
.
.
nexus 6pno .1mb .
.
.
yes 290kb .
.
.
mate 20xno .1mb .
.
.
yes 290kb .
.
.
iosiphone 6sno .1mb .
.
.
yes 281kb .
.
.
iphone 8no .1mb .
.
.
yes 281kb .
.
.
ipad prono .1mb .
.
.
yes 281kb .
.
.13vgg 16pc server no 129mb .
.
.25androidnexus 6no 129mb .
.
.
yes 33mb .
.
.
nexus 6pno 129mb .
.
.
yes 33mb .
.
.
mate 20xno 129mb .
.
.
yes 33mb .
.
.
iosiphone 6sno 129mb .
.
.
yes 65mb .
.
.
iphone 8no 129mb .
.
.
yes 65mb .
.
.
ipad prono 129mb .
.
.
yes 65mb .
.
.
dnn mod.
dnn models plat.
platform quan.
quantization acc accuracy pred.
time prediction time original original dataset generated generated dataset authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv prediction performance of dnn models on mnist and cifar with different web browsers original data generated datadnn mod.plat.
size browser acc.
pred.
timesystem memoryacc.
pred.
timesystem memory pc 52kb .
.
.
.
chrome .
.
.
.
firefox .
.
.
.
lenet 1web 20kb safari .
.
.
.
pc 380kb .
.
.
.
chrome .
.
.
.
firefox .
.
.
.
lenet 5web 184kb safari .
.
.
.
pc .4mb .
.
.
.
chrome .
.
.41gb .
.
.46gb firefox .
.
.52gb .
.
resnet 20web .1mb safari .
.
.37gb .
.
.49gb pc 258mb .
.
.
.
chrome .
.
.06gb .
.
.52gb firefox .
.
.30gb .
.
vgg 16web 129mb safari .
.
.66gb .
.
.69gb mod.
models plat.
platform size model size acc accuracy pred.
time prediction time s mem.
memory means the exception on firefox due to allocation size overflow.
more than 100s and even up to .92s i.e.
iphone 6s for lenet .
different from the lenet family ios devices predict faster than android devices for resnet and vgg16.
it seems that as the complexity of the model increases the performance advantage of ios devices gradually emerges.
in terms of the prediction time of quantized models predicting on android devices after quantization is faster than the original model the improvement is more obvious for complex models e.g.
resnet and vgg .
strikingly quantization on ios slows down the prediction speed a little as shown in column original pred.
time in gray in table iii which is an overall trend and confused phenomenon.
note that we have reported the issue to core ml.
as shown in table iii we use two types of mobile devices i.e.
nexus and nexus 6p to observe the time performance.
most cases reflect the trend i.e.
nexus 6p is an upgraded version of nexus therefore the prediction time on nexus 6p should be less than nexus .
.
however as shown in column original pred.
time in bold italic nexus 6p spends more time than nexus when running vgg which indicates the platforms capability of supporting dl software is likely related to specific model type.
for the time on web browsers chrome generally outperforms the other two browsers in our study.
as shown in column original data pred.
time in table iv and v it spends less time on chrome than firefox and safari in predicting the same amount of testing data.
there is only one anomaly occurs for vgg which chrome costs .62s longer than the .45s on safari.
memory performance as shown in table iv and v apart from prediction time we also record the system memory consumption on web platforms.
system memory consumption is a more representative metric than prediction time when evaluating the supporting capability for dl software.
note that we do not record the system memory on lenet and lenet5 because their fleeting prediction processes make it hard totable v prediction performance of dnn models on imdb with different web browsers.
dnn modelsplatformmodel sizebrowseroriginal data accuracy pred.
time s system memory pc 40mb .
.
chrome .
.
.65mb firefox .
.
417mbtextcnnweb 13mb safari .
.
.07gb pc 48mb .
.
chrome .
.
.2mb firefox .
.
.24gblstmweb 16mb safari .
.
.83gb pc 45mb .
.
chrome .
.
.9mb firefox .
.
.37gbgru web 15mb safari .
.
.64gb record the corresponding system memory.
as shown in column system memory predicting on web browsers are memory consuming for all models.
among the browsers safari consumes the largest system memory.
and according to our observation the huge consumption of system memory has affected the performance of the host computer.
although the memory performance of firefox and chrome is better than safari their memory overheads still reach several gb size in most cases.
for example the memory overhead is over .4gb when running resnet on the browsers indicating the browsers capability of supporting dl software is not satisfactory till now.
combined the metrics of prediction time and system memory consumption chrome exhibits the best performance in supporting dl tasks which could be a better choice when running dl applications on browsers.
answer to rq3 different platform devices hold different time and memory performance in capability of supporting dl software.
for mobile devices android devices take much less time than ios devices for simple dnn models.
however as the complexity of the model increases ios devices achieve better time performance.
moreover the capability of supporting dl software on mobile platform is likely related to the types of specific dnn models.
for web platforms chrome generally outperforms others in both prediction time cost and system memory consumption in our study.
the overall performance for web dl software is unsatisfactory especially running complex dl models.
challenge how to reduce the time cost memory consumption after model migration and quantization?
how to further test the performance of different platforms when deploying and running dl software systematically?
d. rq4 accuracy of migration and quantization on diffplatforms in this section we investigate the prediction accuracy after dl model migration and quantization on different platforms i.e.
mobile and web platforms .
model migration for different platforms as shown in table iii iv and v for each dnn model we first compare the accuracy of each model without quantization on different authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table vi the layer outputs of resnet on pc and chrome.
idx.
refers to label index.
a conv2d layer pc chrome .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.08801108layer output .
.
b dense layer last weight layer idx.
pc chrome .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.38548911layer output .
.
mobile platforms marked as noin column quan.
.
we find that the dnn model size does not change a lot after migrating the tensor flow model to mobile platforms.
however the size of each model for web platform decreases by a large margin.
using the original test data the accuracy of the mobile migration is almost unchanged the biggest change comes from the data of iphone 6s on vgg i.e.
.
vs. .
and iphone on resnet i.e.
.
vs. .
.
similarly the accuracy of web migration generally shares the same trend.
however a significant accuracy decline occurs on all browsers for resnet i.e.
.
vs. .
as shown in table iv.
to analyze and explain the reason for this severe compatibility issue we first compare the model structure and weights between the two platforms i.e.
pc and web and confirm that they share the same properties of them.
so we further inspect the outputs of each layer for resnet on pc and web browsers.
strikingly given the same input image we find the outputs of each layer on pc and web browsers are different.
moreover the deeper the layer is the more obvious difference they exhibit.
we take chrome as example to give an in depth comparative analysis on a certain image.
as shown in table via for conv2d the first weight layer connecting to the input there are only slight differences between chrome and pc see the pair data marked by gray .
when it comes to the dense layer i.e.
the last weight layer the two platforms exhibit an obvious distinction leading to a misclassification on chrome.
as shown in table vib the pc model predicts the image as label with the maximal output being .
.
while chrome predicts it as label with the maximal output being .
.
other two browsers also show the similar behaviours.
the result indicates that browsers differ from pc in inner model computing leading to the accuracy decline on resnet .
actually similar compatibility issues also occur on lenet lenet and vgg when migrated from pc to browsers although the final prediction logic are not been influenced.
we reported these issues to the team of tensor flow .js and the developers have acknowledged as a real bug when webgl handles 1conv2d kernels and will fix it in the new release version.answer to rq4 the prediction accuracy on original data has not been affected much by the migration process.
however compatibility issues persist in model migration from pc to browsers e.g.
.
vs. .
on resnet20 .
even worse there still exists a obvious difference on computation mechanism between pc and web browsers leading to a computing distinction of each layer within the model which has been acknowledged and confirmed by the team of tensor flow .js.
this result explains why the industry has failed to meet expectations after model migration based on our online questionnaire which provides a reasonable explanation for the industrial developers.
model quantization for mobile platforms considering the models marked as yes in column quan.
in table iii the model size decreases roughly to after quantization.
it saves much storage and memory for mobile devices exactly according with the intentions for designing quantization.
the quantization process does not significantly affect the prediction accuracy on original testing data.
specifically the biggest change comes from huawei mate x on resnet i.e.
.
vs. .
.
even in some cases the accuracy of quantized model is higher.
for example the accuracy of the quantized resnet model on other android devices increases by .
and the quantized vgg model on iphone 6s and ipad pro rises by .
.
answer to rq4 quantization does not affect the prediction accuracy obviously.
prediction on android devices after quantization is faster than the original model and the improvement is more significant for complex models.
strikingly quantization on ios devices slows down the prediction speed which deserves further optimization for core ml.
migration and quantization on generated data according to section iv d1 and iv d2 the migration quantization does not affect the prediction accuracy obviously there still exist some cases that the accuracy decreases especially for the quantization process.
the results of accuracy in above two sections are based on the original testing data.
to further investigate the quality of migrated quantized models we combine the existing tools tensor fuzz and deep hunter as data generator.
we generate a largescale testing data by using mnist and cifar as inputs to capture the differential behaviors between the pc model and the migrated quantized model.
mutated mnist data are created for lenet and lenet respectively.
mutated cifar data are generated for resnet and vgg respectively.
we generate samples for both mobile and browser in total.
we run the migrated models repeatedly on our generated data for the two platforms.
as shown in table iii the prediction accuracy of migrated models remain unaltered on android devices consistent to the result on original testing data.
however ios devices go through a relatively obvious accuracy decline on our generated testing data.
for example authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
iphone 6s iphone and ipad pro achieve .
.
and .
accuracy on resnet respectively which are less than the .
on server.
in addition lenet and lenet show the similar phenomenon which indicates the migration process on ios devices suffers from reliability issues on the generated data.
as for web platforms the accuracy of resnet still drops more than accuracy i.e.
.
vs. .
which agrees with the result on the original data i.e.
.
vs. .
.
the similar result on generated data validates our findings about the compatibility issues in migration process.
strikingly as shown in column generated acc.
in gray the accuracy of all quantized models has a significant decline indicating the reliability of a quantizated model is unsatisfactory to date.
however the different results on the two datasets i.e.
original testing data and generated testing data show that it is hard to trigger the reliability issue with the original widely used datasets.
last but not least for ios devices the accuracy of quantized models on vgg only drops a little since we follows a different modes i.e.
bits to bits compared to other three models when reducing the floating point.
to investigate whether the accuracy of quantized models is relevant to the value of nbits in float reduction we further obverse the resnet as an example and configure the nbits as and .
results show that the accuracy gradually declines with a decreasing bit value.
the accuracy are .
.
and .
corresponding to the floating point from bits to bits bits and bits on ipad pro respectively.
remarks for inspection of generated data the accuracy of migrated models does not change in our evaluation on android devices while has a relatively obvious decline on ios devices.
as for the web platforms the results i.e.
compatibility bugs are consistent to that on original data.
the accuracy of all quantized models has a significant decline on our generated testing data which indicates the quantization process still suffers from severe reliability issues tested by generated data.
meanwhile the decline is correlated with the value nbits when reducing the floating point on ios devices.
furthermore we conduct statistical analysis on the accuracy dropping cases in column generated after quantization of table iii.
the results give a p .
indicating there exists a statistically significant difference in accuracy on generated data which reconfirms the reliability issues.
challenge how to detect and fix the compatibility issues bugs when migrating the trained models to web platforms and ios devices and the reliability issues when quantizing the trained models to mobile platforms?
e. threats to v alidity the dnn models and datasets we used might not be complete thus our findings are not general for all situations.
but we select models with cnn rnn architecture from various domains ranging from image classification to textual sentiment analysis.
moreover the datasets containdiverse types including gray color images and textual review to reduce such a threat.
the selected versions of dl frameworks in our study might not be complete.
however we do not focus on the multi version evolution but on revealing challenges issues that developers and researchers need to consider in development and deployment processes.
three android devices and three ios devices with fixed versions are used to study the prediction performance on mobile platforms.
we mainly focus on the performance change after the model migration quantization from pc to mobile devices the impacts of mobile hardware and mobile system version on prediction performance are beyond the scope of this work.
v. r ela ted work in this section we review the related work in two aspects study of deep learning frameworks and platforms.
actually for the studies of model migration and quantization on different deep learning platforms i.e.
mobile devices and browsers to the best our knowledge we take the first step towards this research field.
several deep learning benchmarking studies have been done on the basic results of deep learning frameworks such as the influence of different hardwares and training accuracy and time and also compared different frameworks using their default configuration settings and parameters .
however there lacks a systemic study on the different impacts that various deep learning frameworks under the same runtime configuration or same model weights biases have on the deep learning software development and deployment and also lacks an investigation on quantitative showing the differences of frameworks for developers and researchers.
a. study of dl platforms kaoru et al.
made a survey on deep learning for mobile multimedia and introduced the low complexity deep learning algorithms an optimized software framework for mobile environments and the specialized hardware for supporting the computationally expensive processes of deep network training and inference.
ai benchmark proposed a ai performance ranking for current mainstream mobile phones.
nine testing tasks such as object recognition and face recognition are used as criteria for performance comparison.
alsing et al.
summarized the latest mobile object detection methods using t ensor flow lite and analyzed the performance and latency payoff of different deep learning models on mobile devices.
wang et al.
provided an overview of the current achievements about mobile deep learning technologies and applications.
xu et al.
conducted an empirical study on a large scale android apps to investigate how deep learning technique is adopted in practice.
ma et al.
investigated seven javascript based deep learning frameworks and measured their performance gaps when running different deep learning tasks on chrome.
however we focus on the difference of supporting capabilities when deep learning tasks are deployed on various web browsers i.e.
chrome firefox and safari .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
b. study of dl frameworks the rapid emergence of deep learning frameworks attracts researchers attention on the performance of deep learning frameworks.
the most related work is from liu et al.
they conducted a comparative study of three frameworks i.e.
tensor flow caffe and torch .
however they observed from various aspects such as the impacts of default settings and dataset dependent default settings and framework dependent default settings in deep learning frameworks which are totally different from us.
moreover bahrampour et al.
presented a comparative study on four deep learning frameworks i.e.
caffe n eon t heano and t orch .
they evaluated these frameworks from three aspects i.e.
extensibility hardware utilization and speed .
shams et al.
analyzed c affe tensor flow and a pache singa over sev eral hardware environments.
in order to investigate the performance they measured the time per training iteration and the number of images trained with in a millisecond for comparison.
kochura et al.
compared the basic features i.e.
gpu support gui operating systems and language support of tensor flow d eep learning 4jand h2o and conducted throughout performance tests.
in particular h20 was tested under single threaded mode and multi threaded mode.
li et al.
evaluated the energy efficiency of cnns on cpus and gpus by calculating the energy and power consumption of ten deep learning frameworks k20 t orch t x caffe etc.
.
shaohuai et al.
calculated the time per mini batch with different threads i.e.
and deep neural network models fcn s resnet etc.
within c affe cntk tensor flow mxn et and t orch .
amershi et al.
provided a description of how several microsoft software engineering teams work on developing ai applications.
apart from the above work on deep learning frameworks several work focused on the bug detection of deep learning frameworks.
for example zhang et al.
studied t ensor flow bugs and examied the root causes of these bugs.
pham el al.
proposed cradle a new approach that cross checks multiple backends to find and localize bugs in deep learning software libraries.
c. deep learning testing some existing techniques have been proposed to detect the problems issues during deep learning development and deployment.
deepxplore and deepgauge proposed the new testing criteria for deep learning testing.
deeptest deephunter and tensorfuzz proposed coverageguided testing techniques which mainly focus on feedforward neural networks.
deepstellar is proposed to perform the quantitative analysis for recurrent neural networks rnn .
deepmutation adopts the mutation testing techniques to evaluate the quality of test data for a deep neural network.
in addition diffchaser proposed a differential testing technique to capture the minor disagreements of two deepneural networks.
the approach can be applied to detect the issues of deep neural networks caused by deep learning platforms and frameworks.
in summary compared to these studies on deep learning frameworks and platforms our study conducted a systematic study including training performance and prediction accuracy when given the same runtime configuration or model weights biases adversarial robustness model migration and quantization on different frameworks and platforms and the capabilities and reliability of supporting deep learning software on different platforms.
moreover we not only conduct evaluations on the pc server platform but also shift the testing on the real mobile devices and web browsers.
meanwhile based on our study we also reported several real deep learning software bugs and provide useful guidance for deep learning developers and researchers.
in addition our study motivates many new research directions such as deep learning software bug detection when model migrated and quantized under different deep learning platforms and model conversion.
vi.
c onclusion in this paper we initiate the first step to investigate how existing deep learning frameworks and platforms influence the development and deployment of deep learning software.
our study provides many practical guidelines for developers and researchers under different scenarios for different research communities.
given the same model weights biases an obvious accuracy decline occurs when the model is converted from one framework to another.
the compatibility and reliability issues and accuracy loss would arise when migrating and quantizing a deep learning model from the pc platform to other platforms and the accuracy loss is due to several deep learning software bugs we found.
in addition the universal deep learning solutions across platforms are desperately on demand especially for mobile and web platforms.
this study makes the first step along this direction towards building universal deep learning software across various platforms based on our practical guidelines.
we hope our work draws the attention of deep learning software community altogether to address the urgent demands towards the new challenges in deep learning software development and deployment processes.
vii.
a cknowledgments this research was partially been supported by the national science foundation of china no.
.
it was also sponsored by the national research foundation prime ministers office singapore under its national cybersecurity r d program award no.
nrf2018ncr ncr0050001 national satellite of excellence in trustworthy software system award no.
nrf2018ncr nsoe003 administered by the national cybersecurity r d directorate and jsps kakenhi grant 19k24348 19h04086 and qdaijump research program no.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.