bayesian specification learning for finding api usage errors vijayaraghavan murali rice university usa vijay rice .eduswarat chaudhuri rice university usa swarat rice .educhris jermaine rice university usa cmj4 rice .edu abstract we present a bayesian framework that can learn probabilistic specifications from large unstructured code corpora and then use these specifications to statically detect anomalous hence likely buggy program behavior.
our key insight is to build a statistical model that correlates specifications hidden inside a corpus with the syntax and observed behavior of their implementations.
while analyzing a program we condition this model into a posterior distribution that prioritizes specifications that are relevant to the program.
the problem of finding anomalies is framed quantitatively as a problem of computing a distance between a reference distribution over program behaviors that our model expects from the program and the distribution over behaviors that the program actually produces.
we implement our ideas in a system called salento for finding api usage errors in android programs.
salento learns specifications using a combination of a topic model and a neural network model.
our experiments show that the system can discover subtle errors in android applications in the wild and outperforms a comparable non bayesian approach.
ccs concepts computing methodologies anomaly detection software and its engineering automated static analysis software defect analysis keywords anomaly detection specification learning bug finding apis acm reference format vijayaraghavan murali swarat chaudhuri and chris jermaine.
.
bayesian specification learning for finding api usage errors.
in proceedings of 11th joint meeting of the european software engineering conference and the acm sigsoft symposium on the foundations of software engineering paderborn germany september esec fse pages.
.org .
.
introduction over the years research on automated bug finding in programs has had many real world successes .
however one perennial source of difficulty is the need for formal specifications.
traditional approaches require the user to specify correctness properties any permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse september paderborn germany association for computing machinery.
acm isbn .
.
.
.
.org .
.3106284property that is not specified is outside the scope of reasoning.
however formally specifying real world software is a difficult task that users often refuse to undertake.
a natural response to this difficulty is to automatically learn specifications of popular software components like apis and frameworks.
the availability of large corpora of open source code makes this idea especially appealing .
by analyzing these corpora one can generate numerous examples of how real world programs use a set of components.
statistical methods can then be used to learn common patterns in these examples.
according to the well known thesis that bugs are anomalous behaviors a program whose use of the components significantly deviates from these typical usage patterns can be flagged as erroneous.
the problem of specification learning has been studied for a long time .
however existing approaches to the problem face two basic issues when applied to large code corpora.
first examples derived from such a corpus can be noisy .
while programs in a mature corpus are likely to be mostly correct not all examples extracted from such a corpus represent correct behavior.
second such a corpus is fundamentally heterogeneous and may contain many different specifications some of them mutually contradictory.
for example it may be legitimate to use a set of apis in many different ways and a large enough corpus would contain instances of all these usage patterns.
a specification learning tool should distinguish between these patterns and a bug finding tool should only compare a program with the patterns that are relevant to it.
among existing methods for specification learning the majority follow a traditional qualitative view of program correctness.
in this view a specification is a set of program behaviors e.g.
sequences of calls to api methods and a behavior is either correct in the specification or incorrect outside the specification .
such an approach is not robust to noise because its belief in the correctness of a behavior does not change smoothly with the behavior s observed frequency.
a small number of incorrect training examples can wrongly persuade the method that a behavior is correct.
an obvious fix to this problem is to view a specification as a probabilistic rather than a boolean model.
such a specification assigns quantitative likelihood values to observed program behaviors with higher likelihood representing greater confidence in a behavior s correctness.
some recent work adopts this view by modeling program behaviors using models like n grams and recurrent neural networks .
to find bugs using such a model one generates behaviors of the target program using static or dynamic analysis then evaluates the likelihood of these behaviors .
while robust to noise approaches of this sort have a basic difficulty with heterogeneity.
the root of this difficulty is that these methods learn a single probability distribution over program behaviors.
for example if z1andz2are two common but distinct patterns in which programs in a corpus use a set of apis these approaches would learn a specification that is a mixture ofz1and 151esec fse september paderborn germany vijayaraghavan murali swarat chaudhuri and chris jermaine z2.
during program analysis such a mixture would assign low likelihoods to behaviors that match one of but not both z1andz2.
as behaviors from a program are likely to follow only one of the two patterns this phenomenon would lead to inaccurate analysis.
in this paper we present a bayesian approach to specification learning and bug finding that is robust to heterogeneity and noise.
our key insight is to build a statistical model that captures the entire gamut of specifications in an unstructured code corpus.
more precisely our model learns a joint probability distribution over a random variable zrepresenting hidden specifications and a random variable xrepresenting syntactic features of implementations of these specifications.
when using this model to analyze a particular program fwith feature set xf we specialize it into a posterior distribution p z x xf over specifications.
intuitively this distribution assigns higher weight to specifications for programs that similar to f and can be seen as the part of the model that is relevant to f. this model architecture can tolerate high amounts of heterogeneity in the corpus.
suppose that the programs in the corpus use a set of apis following distinct patterns z1 .
.
.
zn but that programs that look like f i.e.
have feature set xf tend to follow z1.
during training our framework learns this correlation between xfandz1.
this means that the posterior distribution p z x xf puts a high weight on z1and low weights on z2 .
.
.
zn and that correctness analysis of fhappens only with respect to z1.
our second key idea is to frame the detection of likely errors as an operation over distributions.
we assume for each program f a distribution pf y over the behaviors yof the program.
this distribution a probabilistic behavior model may be learned from data or as in this paper be a definition that is a parameter of the framework.
this allows us to develop a model p y z z of the behaviors yof a program that follows a specification z. when combined with the posterior p z x xf forz this model gives us a reference distribution p y x xf over behaviors that the model expects from a program that looks like f. the anomaly score off which quantifies the extent to which fbehaves abnormally is now defined as a statistical distance in particular the kullbackleibler divergence between p y x xf andpf y .
our bayesian approach is a framework meaning that it can be implemented using various concrete statistical models.
in this paper we instantiate it with a combination of the popular topic model latent dirichlet allocation lda and a class of neural networks that are conditioned on a topic model .
to compute the anomaly score for a program f we repeatedly query this model for the likelihood of different behaviors of f and then aggregate these likelihood values into an estimate of the anomaly score.
we implement our ideas in a system called salento and use the system to detect api misuse in android applications.
using three apis as benchmarks we show that salento can automatically discover subtle api bugs in android applications in the wild.
these violations range from gui bugs to inadequate encryption strength.
some of these errors are difficult to characterize in logic based specification notations indicating the promise of our approach in settings where traditional formal methods are hard to apply.
we also show that the method has good precision and recall and is more robust to heterogeneity than a comparable non bayesian approach.
now we summarize the contributions of this paper we present a novel bayesian framework for learning specifications from large code corpora section .
we offer a novel formulation of the problem of finding anomalous program behavior as the problem of computing a distance between a program and a reference distribution section .
we present an instantiation our framework with a topic model and a topic conditioned recurrent neural network section .
we evaluate the approach on the problem of detecting anomalous api usage in a suite of android applications section .
overview in this section we present an overview of our approach with the help of an illustrative example.
.
modeling framework and workflow our approach has the following key aspects.
first we assume the existence of a specification zfor each program f. however unlike traditional approaches that start with a formal specification z in our context is not observable.
instead what is observable is xf a set of syntactic features forf.
the features are evidence or data that inform our opinion as to the unseen specification z. in bayesian fashion our uncertainty about zis formalized as a posterior distribution p z x xf where zis a random variable over specifications and xis a random variable over features.
this distribution assigns higher likelihood to a specification if we believe it is more likely to be the correct specification for programs that look like f given the evidence.
second we allow for uncertainty regarding the behaviors y defined as sequences of observable actions that a given program f produces.
this uncertainty comes from the fact that we do not fully know the inputs on which the program will run and is captured by a distribution pf y where yis a random variable ranging over behaviors.
the framework also allows for a distribution p y z z over the behaviors of programs that implement a given specification z. this uncertainty can come from the fact that we do not know the inputs to implementations of z or the fact that we may have never seen a specification exactly like zbefore so that we have to guess the behavior of a program implementing z. our a priori belief about the relationships between specifications and the features and behaviors of their implementations is given by a joint distribution p x y z .
our third key idea is that this distribution is informed by data extracted from a corpus of code.
this information is taken into account formally during a learning phase that fits the joint distribution prior model to the data.
finally in the inference phase we frame bug detection as a problem of computing a quantitative anomaly score .
in traditional correctness analysis the semantics of programs and specifications are given by sets and one checks if the set difference between a program and a specification is empty.
our formulation is a quantitative generalization of this and defines the anomaly score for a program fas the kullback leibler kl divergence between the behavior distribution pf y forf and the posterior distribution p y x xf that the model expects from f. correctness analysis amounts to checking whether this score is below a threshold.
the workflow of our method is as in figure .
the training and inference phases are denoted by green solid edges and red 152bayesian specification learning for finding api usage errors esec fse september paderborn germany trainingcorpus!
!
... features behaviorsfrom corpustest program finference .
.
.
.
.
.81probabilistic behavior model ... !
......... !
...features behaviorsof test program topic conditionedrnn topic model !
!
kl divergence !
!
figure workflow with instantiations in grey boxes dashed edges respectively.
during training from each program fi in a corpus of programs f1 f2 .
.
.
we extract a set of features xfi and sample a set of behaviors from the distribution pfi y forming the training data.
from this data we learn the joint distribution p x y z m where mrepresents the model parameters.
during inference we extract the features xfof a given program f and query the trained model for the distribution p y x xf m that tells us how fshould behave.
separately we obtain the distribution pf y over observed behaviors of f. the anomaly score of f is then computed as the kl divergence between these distributions.
.
instantiating the framework an instantiation of our framework must concretely define program features and behaviors and the way in which the distributions p x y z m andpf y are obtained.
in this paper we consider a particular instantiation embodied in the salento tool where the goal is to learn patterns in the way programs call methods in a set of apis.
we abstract each such call as a symbol from a finite set and define a behavior yas a sequence of symbols.
the feature xf for a program fis the set of symbols that fcan generate.
a key idea in this instantiation is to capture hidden specifications using a topic model .
here topic is an abstraction of the hidden semantic structure of a program.
a specification for a program fis a vector of probabilities whose the i th component is the probability thatffollows the i th topic.
for example the topics in a given corpus may correspond to gui programs and bit manipulating programs.
a program that makes many calls to gui apis will likely have a higher probability for the former topic.
specifically we use latent dirichlet allocation lda to learn a joint distribution p z x m over the topics and features of programs.
a topic conditioned recurrent neural network model is used to learn conditional distributions of the form p y z z m .
the joint distribution p x y z m that our framework maintains can be factored into these two distributions.
our probabilistic model pf y for behaviors of programs fisnot data driven.
this is because to learn this distribution statistically we would need data on the inputs that freceives in the real world.
since such data is hard to get we simply assume a definition ofpf y .
while many such definitions are possible the one we pick models fas a class of automata called generative probabilistic automata .
the distribution pf y is simply the semantics of this automaton.
.
example consider the problem of finding bugs in guis where the right and wrong ways of invoking gui api methods are seldom formally defined.
specifically consider a dialog box in a gui that does not give the user an option to close the box and a dialog box that does not display any textual content.
clearly such boxes violate user expectations and are buggy in that sense.
two such boxes produced by real world android apps are shown in figure a .
the code snippets responsible for these boxes are shown in figure .
for example in figure b i bis a dialog box the method b.setitems ... adds content to the dialog box the method b.show displays the box.
if the branches in lines and are not taken then b.show opens the box without a close button.
note that the sequences of api calls that lead to these bugs are not forbidden by the api and would not be caught by a traditional program analysis.
in contrast a statistical method like ours can observe thousands of programs and learn that these sequences are abnormal.
operationally to debug this program using salento we generate features and behaviors from a corpus of android apps.
using these features lda learns to classify programs by the apis they use and to also distinguish between different usage patterns in the same api.
consider the examples of dialog box creation in figure b where program f1in b i explicitly specifies the items that go into the box and the program f2in b ii provides a view that encompasses the items that go into the box.
lda can assign different topics to these usage patterns.
for example the pattern used inf1could be assigned the first topic resulting in a topic vector z .
.
.
and the pattern used in f2could be assigned the second topic resulting in the topic vector .
.
.
.
conditioned on such a topic vector z a topic conditioned rnn provides the probability of an api call sequence y that is p y y z z .
for instance given the former topic vector a topicconditioned rnn trained on thousands of examples of topics and behaviors would provide a high probability to a sequence such as new a settitle ... setitems ... show and a low probability to an abnormal sequence such as new a settitle ... show as it shows a dialog without any content.
however our probabilistic automaton model pf1 y off1assigns about .
and .
probability respectively to these sequences.
in general the kl divergence between the two distributions is high causing f1to be flagged as anomalous.
bayesian specification framework in this section we formalize our framework along with the problems of specification learning and anomaly detection.
.
program behaviors and features our framework is parameterized by a programming language.
each program in the language has a syntax and an operational semantics.
because the details of the language do not matter to the framework 153esec fse september paderborn germany vijayaraghavan murali swarat chaudhuri and chris jermaine 1alertdialog.builder b new alertdialog.builder this 2b.settitle r.string.title variable to insert 3if focus.getid r.id.tmpl item b.setitems r.array.templatebodyvars this 5else if focus.getid r.id.tmpl footer b.setitems r.array.templateheaderfootervars this 7b.show b i 1alertdialog.builder b new alertdialog.builder this 2b.setmessage parametres?
3b.setcancelable false 4b.setview dlglayout 5b.setpositivebutton ok new onclicklistener .
.
.
6b.settitle aide 7b.show a i a ii b ii figure a abnormal dialog boxes discovered by our anomaly detection b code snippets corresponding to the dialog boxes we do not concretely define this syntax and semantics.
instead we assume that the syntax of each program fcan be abstracted into afeature set xf.
for instance such features can include syntactic constructs assertions and natural language comments.
we also assume that program actions during execution can be abstracted into a finite alphabet ofobservable symbols including an empty symbol .
we model program executions as behaviors y defined to be words in .
a behavior is the result of a probabilistic generative process that takes place when a program is executed.
accordingly we assume a probabilistic behavior model off defined as a distributionpf y over the behaviors of f. .
specification learning our framework builds a probabilistic model p x y z that factorizes as p x y z p y z p x z p z .
the model captures the intuition that every program is implementing some unknown specification in the space of all specifications p z which determines the program s behavior p y z and features p x z .
building this model requires data in the form of a large corpus of example programs.
as in all statistical learning methods we first develop an appropriate statistical model which is typically a distribution family and then learn that model choose the parameters for the model family so they match reality by training it on data.
to this end p x y z also takes as input a set of model parameters m. fully parameterized this distribution becomes p x y z m p y z m p x z m p z m the available data are then used to choose an appropriate set of parameters m. for this we follow the standard recipe of maximum likelihood .
suppose that we are given a large corpus of programs f1 .
.
.
fn and for each program fiwe have extracted the pair xfi yi 1yi .
.
.
consisting of its feature set and a number of examples of its behavior sampled from its behavior model.
given this data our goal is to choose mthat maximizes the function ny i .
z z .
y yi jp yi j z z m p xfi z z m p z m dz .note that we integrate out z since this is an unseen random variable as we typically do not know the value of the precise specification associated with each code in the corpus.
once mis learned the distribution would represent our prior belief as to what the typical specification behavior and features look like informed by the programs in the corpus.
.
anomaly detection suppose that we are given a new program fand would like to obtain a quantitative measure of the bugginess of f. on the one hand since we already have learned a joint distribution over behaviors features and specifications p x y z m we can condition this distribution with the newly observed xf to obtain the posterior p y z x xf m p y z x xf m p x xf m from equation we have p y z x xf m p y z m p x xf z m p z m p x xf m applying bayes rule to the term p x xf z m we rewrite p y z x xf m as p y z m p z x xf m p x xf m p z m p z m p x xf m p y z m p z x xf m from this since we do not know the precise specification that fis implementing we can integrate out zto obtain the marginalized posterior distribution over behaviors p y x xf m z zp y z z m p z xf m dz this form is amenable to monte carlo integration which estimates an integral through random sampling.
intuitively it gives us a distribution over the program behaviors y that would be anticipated given learned parameters m for a program with feature set xf.
on the other hand we have a distribution pf y over the actual behaviors of fwhen it is executed.
the final step is to then compare this actual distribution with the anticipated distribution over 154bayesian specification learning for finding api usage errors esec fse september paderborn germany behaviors that is p y x xf m .
a measure such as the kullbackleibler kl divergence between distributions is appropriate here.
the kl divergence between two distributions p1andp2over the domain iis a quantitative measure defined as dkl p1 p2 x ip1 i logp1 i p2 i using this measure we can compute the anomaly score offby setting p1andp2to the distributions pf y andp y x xf m respectively and ranging iover the domain of all possible program behaviors in the language x y pf y y logpf y y p y y x xf m choosing an abstraction.
when instantiating the framework the exact form of the feature set xfmust be chosen with some care.
if the feature set xfdoes not provide any abstraction for the program i.e.
xfis the program itself and the model and learner are arbitrarily powerful then p y x xf m equation could in theory describe the compiler and symbolic executor used to produce the training data.
this would mean that the kl divergence equation is zero for any program.
when applying the framework to a problem we protect against this possibility by choosing a feature set xfthat abstracts the program adequately.
for example when debugging api usage it makes sense to choose xfas the bag of api calls made by the code.
this ensures that p y x xf m is limited to attaching probabilities to sequences that can be made out of those calls and it is impossible for the learner to learn to compile and execute a program.
instantiation of the framework now we present a concrete instantiation of our framework.
.
probabilistic behavior model pf y first our instantiation includes a definition of the probabilistic behavior model pf y .
this definition relies on the abstraction of programs as generative probabilistic automata .
program model.
a generative probabilistic automaton is a tuple f q q0 qa whereqis a finite set of states is the alphabet of observable symbols that was introduced earlier q0 q is the initial state qa q is a set of final or accepting states and q r qis atransition relation .
we have qi s p qj if the automaton can transition between states qiandqjwith a probability p generating the symbol s. we write qis p qjif such a transition exists.
transitions with probability or infeasible transitions are excluded from the automaton.
a program in a high level language is transformed into the above representation through symbolic execution in a preprocessing phase.
symbolic execution runs a program with symbolic inputs and keeps track of symbolic states analogous to a program s memory.
the symbolic states encountered become the states q and the accepting states qaare typically the states at a final location or some location of interest in the program.
unbounded loops can be handled by imposing a bound on symbolic loop unrolls or through a predicate abstraction of the program to make variable domains t newa ... settitle ... setitems ... show .
.
.
t show .0setitems ... .
.
.
11 t show .0 0.33figure automaton for the example in figure b i finite.
the detection of infeasible states in general an undecidable problem depends on the underlying theorem prover that is used.
as symbolic execution is a standard method in formal methods this section only gives an example of the method s use.
as it is applied at a preprocessing level we often use the term program to refer to an automaton generated via symbolic execution rather than a higher level program to which preprocessing is applied.
semantics.
arun offis defined as a finite sequence of transitions q0s1 p1 q1s2 p2 sn pn qnbeginning at the initial state q0.
isaccepting ifqn qa.
the probability of is p qn i 1pi.
every run generates a behavior y denoted as s1s2 sn.
let fbe the set of all accepting runs of f and f y fbe the set of all accepting runs such that y. the probabilistic behavior model pf y is pf y y x f y p where p fp is anormalization factor .
it is easy to see that pf y defines a probability distribution over behaviors.
to generate a random behavior of f we simply sample from the distribution pf y .
features.
given a program f the feature set xfis defined as s qis p qj i.e.
the set of all non empty symbols in the transition system of f. example.
the automaton for the code in figure b i is shown in figure .
each state in the automaton is labeled with a program location with multiple instances of the same location being primed.
the initial state is the first location and the accepting states in bold are all instances of a special terminal location tin the program.
the transitions follow the structure of the code for brevity we collapse sequential statements into a single transition emitting as symbols api methods called at each location.
note that we gave a uniform probability at each state to transition to the next possible states but this can be controlled through other means.
for instance one can apply model counting on a branch condition and compute the probability of the program executing one branch over another.
such a definition is not necessarily a better choice than ours as it would assign low probabilities to corner cases that get triggered on a small number of inputs but 155esec fse september paderborn germany vijayaraghavan murali swarat chaudhuri and chris jermaine are often of interest to users of static analysis.
the two definitions simply make different tradeoffs.
we use a uniform distribution at branches because it is simpler and worked well in our experiments.
new a settitle .
.
.
setitems .
.
.
show is the feature set for this program.
there are three accepting runs of f and two behaviors generated by these accepting runs y1 new a settitle .
.
.
setitems .
.
.
show y2 new a settitle .
.
.
show we have .
the sum of the probabilities of all accepting runs.
hence pf y1 .
.
.
.66andpf y2 .
.
assume now that after training on a large number of behaviors the model had learned that conditioned on specifications such as .
.
.
that gave a high probability to the first topic program behaviors tend to always add a title and items to dialog boxes.
this might result in the behavior y1having a very high probability say .
and all other behaviors having a very low probability.
particularly a behavior that only calls settitle without setitems would be assigned a very low probability say .
in our program f we saw that pf y1 .66andpf y2 .
and the probability of any other yis .
thus the anomaly score of fis .66log0.
.
.33log0.
.16suppose now that the state in the program model was infeasible.
then both accepting runs in the model would only generate y1 and so pf y1 .
the anomaly score of this correct program would then be log1 .
.
.
.
topic models for p z x m topic models are used in natural language processing to automatically extract topics from a large number of documents containing textual data as words.
in our case a document is the feature set of a program words are symbols from the observable alphabet that a program uses and the topic distribution of a document is its unknown specification.
lda is a popular topic model that models the generative process of documents in a corpus where each document xficontains a bag of words.
the inputs to lda are the number kof topics to be extracted and two hyper parameters and .
lda models a document as a distribution over topics and a topic as a distribution over words in the vocabulary.
an lda model is characterized by the variables i and hyper parameters of a dirichlet prior that chooses the topic distribution of each document and the word distribution of each topic respectively ii zfi the topic distribution of document xfi iii k the word distribution of topic k. the result of training an lda model is a learned value for all the latent variables zfiand k which forms our model parameter m. during inference we are given a document xf and we would like to compute the posterior distribution p z x xf m .
since lda has already learned a joint distribution p z x m this is simply a matter of conditioning this distribution with the newly observed xfto get a posterior distribution over z which is often approximated through a technique called gibbs sampling .
.
recurrent neural networks for p y z m neural networks have been used to solve classification problems such as image recognition and part of speech tagging.
these problems involve classifying an input xinto a set of output classes y using the conditional distribution p y x m .suppose we are given a value of x a given sequence of symbols characters s1s2.
.
.st 1where each symbol is from the alphabet and we would like the model to generate the next symbol st. we can cast this generative problem as a classification task by creating x1x2.
.
.xt where each xkis the one hot vector ofsk and querying the model to classify the sequence x1x2.
.
.xt 1into classes.
the output vector ytis then interpreted as a distribution over from which a symbol stcan be sampled .
let us denote the probability of a symbol sgiven by the distribution ytasyt s .
a topic conditioned neural network takes in addition to x an input zrepresenting the topic distribution of a document obtained from a topic model.
to handle unbounded length input sequences a recurrent neural network rnn is used.
an rnn uses a hidden state to neurally encode the sequence it has seen so far.
at time point t the hidden state htand the output ytare computed as ht f wht vz uxt bh yt tht by where w v uandtare the weight matrices of the rnn bhand byare the bias vectors of the hidden states and outputs respectively fis a non linear activation function such as the sigmoid and is a softmax function that ensures that the output is a distribution.
training the model involves defining an error function between the output of the rnn and the observed output in the training data.
specifically if the training data is of the form xfi yi yi .
.
.
then each training step of the rnn will consist of the input xbeing yi j target output ybeing yi jshifted by one position to the left since at time point tthe outputytis interpreted as the distribution over the next symbol in the sequence and zbeing a sample from p z x xf m given by the trained topic model.
a standard error function such as cross entropy between the output of the rnn and the target output can be used.
since the error function and all non linear functions used in the rnn are differentiable training is done using stochastic gradient descent.
the result of training is a learned value for all matrices in the rnn which together form a part of our model parameter m. during inference we are given a value zofzand a particular y s1 .
.
.
sn and would like to compute p y y z z m .
this is straightforward we set xtas the one hot vector of stfor t n. then p y y z z m qn t 1yt st whereytis computed using equation .
.
estimation of the anomaly score there are two difficulties associated with computing the anomaly score in our instantiation of the framework.
first in general the computation in equation requires summing over a possibly infinite number of program behaviors y which is not feasible.
second it also requires computing p y x xf m which in turn requires integrating out the unknown specification z equation .
both of these difficulties can be addressed via sampling.
we note that in general to estimate a summation of the formp i ip1 i p2 i where p1 i is a probability mass function over the possibly infinite domain iandp2is a function on i it suffices to take a number of samples i1 i2 .
.
.
im p1 i .
one can then use x i ip1 i p2 i mx k mp2 ik 156bayesian specification learning for finding api usage errors esec fse september paderborn germany as an unbiased estimate for the desired sum.
it is well known from standard sampling theory that the variance of this estimator denoted as 2 reduces linearly as mincreases.
we can apply this process to estimate the anomaly score for fby letting the domain ibe the set of all possible behaviors in and sampling a large number of behaviors ywith probability proportional to pf y then letting p2 y log pf y y log p y y x xf m and using the estimator described above.
we can keep sampling until the variance of the estimate is sufficiently small.
fortunately sampling a behavior from the distribution pf y is easy we can use rejection sampling to sample an accepting run offand then simply obtain its behavior y .
however we do not yet have a complete solution to our problem.
the difficulty is that for a sampled behavior y it is not possible to compute p2 y y easily because of two reasons.
first the term pf y y equation requires summing over possibly infinite number of accepting runs f and second as mentioned before computing p y y x xf m requires integrating over the unseen zvalue.
to handle this we extend our sampling based algorithm.
rather than just sampling behaviors we sample the set iof y f f fzf triples where f fis itself a set of accepting runs of fsampled using the same method and fzfis a set of values sampled from p z x xf m .
the latter set of samples can easily be obtained via gibbs sampling.
one could then estimate the divergence as i x y f f fzf ilog .. x f f y f f log .. x z fzfp y y z z m wheref f y is the set of paths f fsuch that y. the sum in the first log term estimates the fraction of sampled accepting runs whose behavior is y thus estimating pf y y and the sum in the second log term estimates p y y x xf m .
the problem is that this estimate will be biased since one cannot commute the expectation operator ewith a logarithm.
that is e log x f f y f f log e x f f y f f a similar problem exists for the second summation used to estimate the logarithm of p y y x xf m .
intuitively this bias is not surprising since an over estimate for the probability pf y y by some constant amount is likely to have little effect on an estimate of the logarithm of the probability.
however an under estimate by the same amount can cause a radical reduction in the estimate of the logarithm and we expect a negative bias.
a sampling based estimate for this bias can be computed using a taylor series expansion about the expected value of the biased estimator which obtains an expression for the bias in terms of the central moments of a normal distribution estimating those moments leads to an estimate for the bias.
assume that this estimator is encapsulated in a procedure bias y f f fzf that computes the bias of an estimate.
our final estimate for the anomaly score is i x y f f fzf ilog .. x f f y f f log .. x hz fzfp y y z z m bias y f f fzf .topic topic a.setmessage int a.settitle int new a context a.setpositivebutton string .
.
.
a.setnegativebutton string .
.
.
a.setmessage string topic topic a.setview view new a context a.settitle string a.setitems string .
.
.
a.setneutralbutton int .
.
.
a.show topic topic c.getinstance string c.init int key .
.
.
c.dofinal byte b.connect b.getinputstream b.getoutputstream figure top methods from topics extracted by lda a alertdialog .builder b bluetoothsocket c cipher evaluation in this section we present an evaluation of our method on the task of finding api misuses in android apps.
specifically we seek to answer the following questions can we find useful de facto specifications followed by android developers section .
?
using the specifications can we find possible bugs in the usage of the android api in a corpus section .
?
how does specification learning help in anomaly detection section .
?
how does the bayesian framework help in handling heterogeneity in the specifications section .
?
.
implementation and experimental setup now we briefly describe the system salento that implements our method.
salento usessoot to implement symbolic execution and transform code in an android app into our automaton model tensorflow to implement the topic conditioned rnn and scipy to implement lda.
salento builds a coarse model of the android app life cycle by collecting all entry points in the application which are callback methods from the android kernel.
it also uses soot s class hierarchy analysis and throw analysis to overapproximate the set of possible call or exception targets and soot s built in constant propagator to detect infeasible paths.
in addition to api methods in salento also collects some semantic information about the state of the program when an api call is made.
this is done through the use of simple boolean predicates that capture for example constraints on the arguments of a call or record whether an exception was thrown by the call.
this allows us to learn specification on more complex programming constructs.
the training corpus consisted of android apps from and the testing corpus consisted of apps from .
the two repositories did not overlap perhaps since the latter is open source and the former is not.
we conducted experiments on three android apis alert dialogs android .app .alertdialog .builder bluetooth sockets android .bluetooth .bluetoothsocket and cryptographic ciphers javax .crypto .cipher .
the apis were chosen to represent common yet varied facets of a typical android app ui functionality security .
from the training and testing repositories we created 157esec fse september paderborn germany vijayaraghavan murali swarat chaudhuri and chris jermaine about and automata models henceforth just called programs respectively.
while so we set the accepting location of the program as various locations of interest that is locations where a method in one of these apis was invoked.
this helps in localizing an anomaly to a particular location.
all experiments were run on a core .
ghz machine with gb of memory and an nvidia quadro m2000 gpu.
.
specification learning with a goal to discover specifications of android api usage we applied lda on the training corpus of programs where the alphabet consisted of methods from the three apis.
we used .
for each topic and for all words in a topic.
running lda with 15topics k took a few seconds to complete.
figure shows the top words methods from six topics extracted from the corpus that we picked to exemplify.
at a first glance it may seem that lda is simply categorizing methods from different apis into separate topics which can raise the question of why we need topic models if we already knew the apis beforehand.
lda however does more than that.
topic andtopic contain methods from the same api but interestingly different polymorphic versions with intand string arguments.
the model has discovered that the polymorphic versions fall under separate topics meaning that they are not often used together in practice .
indeed some android apps declare all resources they need in a separate xml file and provide the resource id as the intargument.
other apps do not make use of this feature and instead directly provide the string to use in the dialog box.
therefore it makes sense that an app would seldom use both versions together.
similarly topic also contains methods from the same api however it describes yet another way to create dialog boxes.
note the lack of the setmessage method in this topic as the message would already have been enveloped in theview passed to setview using both methods together can lead to the display of corrupted dialog boxes as shown in figure a ii .
as these examples show the topic model can expose specifications of how methods in an api or different apis are used together.
.
anomaly and bug detection to evaluate salento on anomaly detection we first trained the topic conditioned rnn on behaviors sampled from the training programs.
training took minutes to complete.
we then computed anomaly scores for the programs in our testing corpus.
the time to compute each score was around seconds.
the histogram of scores in figure a shows a high concentration of small values such as or less and a very low concentration of high values.
we chose to further investigate programs appearing in the top of anomaly scores above the red line for possible bugs.
specifically since each program provides a localization to a location in the app through its accepting states we investigated the behaviors that were sampled from the program s probabilistic behavior model that would have determined its anomaly score.
our definition of a possible bug is based on the following is a behavior an instance of android api usage that is questionable enough that we would expect it to be raised as an issue in a formal code review?
note that an issue raised in a code review may relate to a design choice and not necessarily cause the program to crash an unusual button text for example .
nonetheless such an issue would be raised and likely fixed by engineers examining a code.
one problem with counting an anomaly as a possible bug is that multiple anomalies in an app can have the same cause an incorrect statement or set of statements in the code and we would like to avoid double counting different anomalies with the same cause as different bugs.
it is a hard software engineering problem to establish the cause of an anomaly bug which is out of scope of this paper.
to avoid this problem however we conservatively consider only the top most anomaly in each app in the top as clearly anomalies in two different apps cannot have the same cause.
through manual inspection and triage by the first author we found different types of possible bugs in our testing corpus figure ranging from the benign to the insidious.
we have already seen anomalies and figure that could display corrupted or unclosable dialog boxes.
could lead to an exception being thrown due to a failed connection would create a crypto object that defaults to the semantically insecure ecb encryption mode and could cause future attempts to open a socket to be blocked.
figure b i shows the precision recall plot for these possible bugs in the top of anomaly scores.
it can be seen that at around the top we reach full recall with precision or false positive rate.
this is reasonable compared to industrial static analysis tools such as coverity that advocates a false positive rate for stable checkers .
our method does not rely on specified properties to check and many of these bugs cannot be easily expressed as a formal property for traditional static analyzers to check.
after this threshold the precision continues to drop and we conjecture that it will not increase any further because almost all the possible bugs have already been found.
to substantiate this conjecture we would have to manually inspect thousands of programs to qualitatively declare that all anomalies have been triaged.
due to the practical infeasibility of this task we instead quantitatively injected anomalies into the remaining of programs through mutations and measured whether our model is able to detect those mutations.
for each program we mutated the api call before its accepting states into one chosen randomly from .
figure c shows the anomaly scores before dark and after light the mutation and the cumulative mean of the relative increase in the score dashed line secondary axis .
as a result of the mutation the scores are greatly increased sometimes by times or more and the mean of the increase is about 4x.
that is a mutation on average caused the anomaly score to increase by times indicating that our model detected the mutation.
note that a random mutation has the possibility of reducing the anomaly score of a program if it had a possible bug and the mutation happened to fix it.
however it is not very likely for a random mutation to fix a bug and so these instances rarely occurred.
.
role of learning in anomaly detection to evaluate the role of learning we compared with a traditional outlier detection method that does not require learning.
k nearest neighbor k nn outlier detection uses a distance measure to compute the knearest neighbors of a given point within a dataset.
the larger the average distance to the k nn the more likely it is that the point is an outlier or anomaly.
we already have a distance 158bayesian specification learning for finding api usage errors esec fse september paderborn germany .
.
.
.
.
.
.
.
.
.
.
top k anomalous programsprecisionrecall .
.
.
.
.
.
.
.
.
.
.
top k anomalous programsprecisionrecall 0x2x4x6x8x10x12x14x16x18x 050010001500avg.
relative increaseanomaly scoresprogramsoriginalmutated a b i b ii c figure a histogram of anomaly score values b precision recall for the possible bugs in figure for i bayesian model ii non bayesian model and c anomaly scores of remaining programs before and after mutation count avg anomaly score .
csingle crypto object used to encrypt decrypt multiple data .
bconnecting to the same socket more than once .
battempt to close unopened socket .
ausing string andintpolymorphic methods together .
ccrypto object created without specifying mode .
ausing setmessage with setview .
adialog displayed without message .
bfailed socket connection left unclosed .
aunusual button text .
adialog displayed without buttons figure anomalies that are possible bugs found in the top of anomalous programs measure between distributions the kl divergence between the behavior model for the given program and a program in the corpus.
we implemented such a k nn and compared our method with it by conservatively setting k .
that is the anomaly score of a given program is the smallest kl divergence with any program in the corpus.
however even with this nn anomaly score a substantial top of programs had a distance of infinity to the corpus thus providing no useful information about their anomalies.
the reason is that these programs happened to generate a behavior that was not generated by anyprogram in the corpus.
this sets p1 y to a non zero value and p2 y to zero in the kl divergence formula equation immediately making the sum infinity.
this is unreasonable because we clearly do not want to call every behavior we have not observed in the training data an anomaly but instead would like to assign probabilities even to behaviors that were never seen before.
that is we would like to generalize from the corpus.
this is why probabilistic specification learning is needed.
.
comparison with non bayesian methods to see how the bayesian framework helps in handling heterogeneity in the corpus we compared our method with a non bayesian specification learning method.
existing state of the art methods use n grams or rnns to learn a non bayesian single 0x1x2x3x4x5x6x051015202530354045avg.
relative increaseprogramsnon bayesianbayesian a 0x1x2x3x4x5x6x051015202530354045avg.
relative increaseprogramsnon bayesianbayesian b figure average relative increase in anomaly scores ofbluetoothsocket programs when the training corpus only uses the apis a bluetoothsocket cipher b alertdialog .builder bluetoothsocket cipher probabilistic specification of program behaviors.
we implemented a non bayesian specification learner as an rnn nottopic conditioned and trained it directly on the behaviors in our training corpus.
we then performed the same anomaly and bug detection experiment in section .
querying the trained model with behaviors in the testing program for inference.
figure b ii shows the precision recall rate for the top of anomaly scores.
compared to our bayesian method the nonbayesian method fared poorly.
consider again a stable checker s false positive rate of or precision.
at this threshold marked by the red line our bayesian method has about recall compared to only for the non bayesian method.
this shows that given a reasonable precision threshold our method is able to discover significantly more bugs compared to the non bayesian method.
it is also worth noting that the non bayesian method was unable to discover any possible bug that was not found by our method.
effect of heterogeneity.
we finally performed a series of experiments by incrementally increasing the heterogeneity of the training programs.
first as a baseline we considered only programs that use thebluetoothsocket api and learned from them both bayesian and non bayesian specifications of their behaviors.
we then computed anomaly scores of the testing programs that use this api.
159esec fse september paderborn germany vijayaraghavan murali swarat chaudhuri and chris jermaine in the next step we added to the training corpus programs that also use the cipher api making the corpus more heterogeneous and learned new specifications.
we then computed anomaly scores again but using the new learned specifications.
figure a shows the average relative increase in anomaly scores from using the old versus the new specifications.
ideally one would expect the scores to not change because the addition of programs that use the cipher api behaviors on which are unrelated to the bluetoothsocket api should not have any effect on the scores.
this is observed in the bayesian specification dashed line that lingers close to .
on average.
however the non bayesian specification solid line suffers from about a 2x increase.
this was further evident when programs that also use the api alertdialog .builder were considered for training making the corpus even more heterogeneous this is the same training corpus in section .
.
in figure b the relative increase in scores using the bayesian specification is on average close to .
showing that it is robust to the increased heterogeneity.
however the non bayesian specification induces a further increase of about .5x in the scores.
we expect the gap to keep widening as more heterogeneous programs are added to the corpus at some point making the scores from the non bayesian model meaningless.
in contrast the scores from our bayesian model would remain almost the same showing that the model is able to focus on relevant parts of the learned specification in principle tolerating arbitrary heterogeneity.
.
limitations we conclude by summarizing the limitations of our experiments .our evaluation used android a platform where programs are apis heavy and apis are fairly well structured.
while our experiments show good results in this domain whether they generalize to other domains that do not share these characteristics such as c programs is an open question.
.our evaluation used a small subset of the android api space due to the manual effort needed to report precision recall numbers.
it is possible for the results to be different for a different set of apis.
.finally as the domains that we study often lack crisp definitions of correctness the first author of this paper manually triaged the anomalies reported in our experiments into true and false positives.
while this step was performed carefully it is possible that a different person could have triaged some of these reports differently.
related work learning qualitative specifications.
the thesis that common patterns of execution can serve as a proxy for specifications has been around since the early 2000s.
most efforts in this area focus on qualitative specifications typically finite automata.
as mentioned earlier such qualitative specifications are problematic in the presence of noise in the training data.
learning probabilistic specifications.
there is also a literature on learning probabilistic specifications from programs.
kremenek et al.
use factor graphs constructed using static analysis to learn specifications on resource allocation and release.
anek uses annotations in apis to infer specifications.
merlin starts with a given initial specification andrefines it through factor graph construction and inference.
octeau et al.
use domain knowledge to train probabilistic models of android inter component communication.
jsnice uses a probabilistic graphical model to learn lexical and syntactical properties of programs such as variable names and types for the purpose of de obfuscating javascript programs.
some recent efforts have also used n gram models to learn specifications on source code structure.
deepapi uses a neural encoder decoder to learn correlations between natural language annotations and api sequences.
haggis uses statistical techniques to learn the structure of small code snippets or idioms from a corpus.
the work in this space that is the closest to ours are two methods by raychev et al.
which learn probabilistic models of program behavior from large code corpora using rnns among other models.
the key difference between the above approaches and ours is that these methods learn a single probabilistic specification.
in contrast our approach learns a family of probabilistic specifications simultaneously and then specializes this model to particular analysis tasks using bayes rule.
as demonstrated in our experiments this hierarchical architecture is key to tolerating heterogeneity.
in very recent work raychev et al.
also argue that having a single universal probabilistic model for code can be inadequate and propose a decision tree algorithm that is used to choose among a bag of statistical models for tasks such as next statement prediction.
while philosophically aligned with our work their efforts are quite different in that while we argue for conditioning of models at the program level they argue for conditioning of models at the statement level and focus their efforts on localized prediction tasks.
one could imagine using a model similar to what they have proposed within our framework as a replacement for our rnn based p y z .
anomaly detection.
there is prior work on using learned models of executions in anomaly detection .
aside from differing in the nature of specifications used methods in these categories tend to assign anomaly scores to individual behaviors.
while our method is able to assign such scores it is also able to produce aggregate anomaly scores for programs.
conclusion we have presented a bayesian framework that can learn probabilistic specifications from large heterogeneous code corpora and then use these specifications to find likely software errors.
we have used an implementation of this framework based on a topic model and a recurrent neural network to detect api misuse in android and shown that it can find multiple subtle bugs.
a key appeal of our framework is that it does not impose an a priori limit on the size or heterogeneity of the corpus.
in principle our training corpus could contain all the world s code and it is our vision to scale our method to settings close to this ideal.
engineering instantiations of the framework that work at such scale is a challenge for future work.
acknowledgement this research was supported by darpa muse award fa8750 .
160bayesian specification learning for finding api usage errors esec fse september paderborn germany