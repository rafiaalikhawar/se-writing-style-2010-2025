achieving test automation with testers without coding skills an industrial report davrondzhon gafurov arne erik hurum martin markman norwegian directorate of ehealth oslo norway davrondzhon.gafurov ehelse.no abstract wepresentaprocessdriventestautomationsolutionwhichenables delegating partof automationtasksfromtestautomationengineer expensive resource to test analyst non developer less expensive .
in our approach a test automation engineer implements test steps or actions which are executed automatically.
such automated test steps represent user actions in the system under test and specified by a natural language which is understandable by a non technical person.
then a test analyst with a domain knowledge organizes automated steps combined with test input to create an automated test case.
it should be emphasized that the test analyst does not need to possess programming skills to create modify or execute automated test cases.
we refine benchmark test automation architecture to be better suitable for an effective separation and sharing of responsibilities between the test automation engineer with coding skills and test analyst with a domain knowledge .
in addition we propose a metricto empirically estimate cooperation between testautomationengineerandtestanalyst sworks.theproposed automationsolutionhasbeendefinedbasedonourexperiencein thedevelopmentandmaintenanceofhelsenorge thenationalelectronichealthservicesinnorwaywhichhashadoveronemillion of visits per month past year and we still use it to automate the execution of regression tests.
ccs concepts software and its engineering software testing and debugging keywords test automation process driven test automation keyword driven test automation dsl for test automation helsenorge acm reference format davrondzhon gafurov arne erik hurum and martin markman.
.
achieving test automation with testers without coding skills an industrial report.
in proceedings of the 33rd acm ieee international permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
on automated software engineering ase september montpellier france.
acm new york ny usa 8pages.https introduction time to market quicker feedbacks from end users risk of large changes and similarfactors push companies andorganizations towards continuous or more often software product releases.
testing isanessentialpartofanysoftwaredevelopmentlifecyclemodel .
consequently suchfrequentdeliveries havedirect impactontest activity.
this is especially true for regression testing due to its naturalgrowthbecausetoday stestingofanewfeaturebecomes tomorrow s regression test.
to cope with increasing demand on frequent testing usually with limited resources test automation is animportantstrategytoaddressthischallenge.however fromone hand atestautomationisneithersimplenorstraightforward .
in addition to the process adjustment it requires a set of high technical skills important of which is the ability of writing a computer code.
on the other hand usually a test automation engineer whopossesseshighprogrammingskillswithatesting mindsetis scarcer when compared to a typical test analyst functional tester who does not need to have programming experience or a technical background.
ateststepisanactionorprocesstobeperformedonthesystem under test.
it is typically equivalent to the action of an end user while using the system.
examples of a test step can be signing intothesystem signingoutfromthesystem agreeingtothe termsofuse disagreeingtothetermsofuse sendingamessage deletingamessage andsoon.atestcaseisasequenceoflogically organizedteststepsthatverifiesdesiredsystemfunctionality.we refer to the test case which can be executed automatically as an automated test case atc .
a test automation can be implemented byapplyingdifferenttechniques rangingfromasimplecaptureandreplayandfinishingwithmoresophisticatedonessuchaskeyword andprocess drivenapproaches .anothertermwhichisused for process driven test automation is domain specific languages dsl for test automation for instance .
in this paper we present a process driven test automation solutionwhichallowstestcasestobedefinedfromaworkflowperspective .inourapproach atestautomationengineerimplements teststepswhichareexecutedautomatically.suchautomatedtest steps represent user actions on the system under test and specified by a natural language which is understandable by a non technical person with a domain knowledge.
then a test analyst organizes authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france davrondzhon gafurov arne erik hurum and martin markman automated steps combined with test input to create an automated test case.
it should be emphasized that the test analyst does not need to possess programming skills to create update or execute automated test cases.
we refine benchmark test automation architecture to be better suitable for effective separation and sharing of responsibilitiesbetweenatestautomationengineer withcoding skills and a test analyst with domain knowledge .
in addition we propose a metric to empirically estimate impact of test automation engineer s work on the work of test analyst.
we implement and apply our test automation concept on real world web application namely automating regression test of national e health internet portal in norway helsenorge .
themaincontributionofthepaperisonleveragingfromourexperiencewithhelsenorgeanddevelopingatestautomationsolution to move part of automation work from test automation engineer developer expensive resource to a test analyst non developer less expensive resource .
our approach also contributes towards a better cross functional software development teams since a test analyst in the development team can carry out test automation tasks without depending on others than team members.
the rest of the paper is structured as follow.
section 2briefly presentsanoverviewofhelsenorgeandsection 3describesourtest automationsolution.section 4presentsametricfortestcreation efficiency.
section 5summarizes main benefits limitations and lessons learned and section 6concludes the paper.
system under test helsenorge .
helsenorge overview oursystemundertest sut ishelsenorge.itisanationalportalof e healthservicesforresidentsinnorway.theportalwasintroduced in .
in on average it had over .
million visits per month .helsenorgeisintendedtobeasingle point of entry to electronic health services for residents.
it consists of two parts namely public and private.
the public part is open for all andcontains general information about diseases treatments patient rightsetc.theprivatepartoftheportalrequiresauthenticationand contains individual s health related information.
the total number ofusersign instotheprivatepartofhelsenorgedoubledin2017 compared to from .
million to about million .
fig1 showsatypicaluserinterfaceofthesystemwhenapersonislogged into helsenorge1.
an authenticated individual can see his or her health related informationsuchasthelistofactiveandinactivemedicines history ofhospitalvisits verifyalistofhealth relatedpayments etc.he or she can also take an active part in one s health workflow via helsenorgebyperformingvariousactions.forinstance anindividual can change general practitioner order cancel or change doctor appointments sendrequesttorenewalofmedicine send receive messagesto fromdoctorordoctoroffices haveadialogwithdistricthealthservices self registerownsickness submitapplications forreimbursementandsoon.althoughmanyoftheseelectronic servicesarenational fewofthemareinpilotstate andtherefore depend on the region where a person resides.
furthermore a user has possibility to administer his or her own profile settings and 1language of the portal is norwegian.
figure e health services in helsenorge.
access control levels.
for instance a user can agree or disagree forstoringmessagesanddocumentsinapersonalhealtharchive pha restrict certain type of health personnel to access part of journal kjernejournal information decide not to use electronic servicesviahelsenorgeanymoreatanytime righttobeforgotten and so on.
one important characteristic of the system is that users utilize e health services not only on their own behalf but can also onbehalfoftheirchildren relativesorotherperson.thismeans one person can authorize access to another person to one or more predefinedserviceareasinhelsenorge.forexample oldparentscan give access to their adult child to carry out a digital dialog with a health personnel on behalf of them via helsenorge.
some services depend on the age and status of the users.
such access controlflexibilitycomesatthecostofenhancedsystemcomplexity.
inaddition medicalandhealthinformationisregardedasavery sensitiveandcriticaltypeofinformation.theseallrequiremore rigorous test and quality assurance activities of the system.
.
helsenorge release helsenorge has had four main releases per year excluding hotfix and other miscellaneous releases.
however from helsenorge authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
achieving test automation with testers without coding skills ase september montpellier france table helsenorge s scrum teams team responsibility areas in helsenorge pot profile and access control hoi health medical information tod appointments and dialog r f reimbursements economy r i open part of helsenorge is expected to double number of main releases which consequently will increase test activity.
until introducing the test automation significantamountofregressiontestbedonhelsenorgehasbeen carried out manually.
however with increased number of software releases and testing iterations achieving required level of test coverage with continuation of manual testing effort appeared to be unfeasible.
we apply automation on helsenorge s execution of regression test.
our test automation targets mainly private part of the portal helsenorge.
.
roles and teams we have defined two main roles within our automation concept namely test automation engineer tae who possesses programmingskillsandtestanalyst ta whodoesnotneedtohavecoding experience.softwaredevelopmentlife cyclemodelofhelsenorge follows the agile methodology .
currently helsenorge consists offivescrumteamswhicharelistedintable .eachteamconsists typically of a product owner scrum master several programmers and one or two tas i.e.
team testers .
a ta is a full member of thedevelopmentteam with100 timededicationwhereastae is notafullmemberoftheteam.heorshecanbe50 inoneteam and50 inanotherteam ordedicate100 tooneteamtemporarily.
currentlyathelsenorgetestgroup thenumberoftaesislessthan thenumberoftas.asoftodaythereare7tarolesand2.5tae roles.
helsenorge development teams are self organizing and crossfunctionalscrumteams.self organizationmeansthattheteam itself decides how best to accomplish its work rather than being instructedbyothers outsidetheteam .cross functionalteam possesses all the skills that are necessary for the team to complete its tasks .
test automation solution .
architecture figure2depicts generic test automation architecture taa proposed by international software testing qualification board .
a drawback with this architecture is placing test data and test library components at the same level.
we expect that managing testdatacomponentdoesnotrequireprogrammingskillsifone hasadomainknowledge whereasformanagingtestscriptcomponent one must have programming knowledge.
so test data andtestscriptcomponentscanberesponsibilityoftaandtae respectively.
we refine this generic taa and propose new architecture for helsenorge which is shown in figure .
as it can be seen from this figure generic test automation architecture by international software testing qualification board .
figure in our architecture test generation layer is omitted since we manually carry out the test design and have not yet developed a model for helsenorge.
however we introduce a new layer for testimplementationtomakeeasierseparationofresponsibilities betweentaeandtaroles.inourarchitecturetaisresponsiblefor testdefinitionandtestexecutionlayerswhiletaeisresponsible for test implementation and test adaptation layers.
as it can be seenfromthefigures unlikegenerictaainourarchitecturewe movedtestlibraryfromtestdefinitionlayertotestimplementation layer.
this enables test data to be managed by ta whereas test library script to be maintained by tae.
we use microsoft s team foundation server tfs as a configurationandtestmanagementtool.tfsisalsousedasamanagementtoolforhelsenorge srequirements.thisfacilitatesautomatictraceability between a test caseand a requirement.
in other words one canalwaysdeterminewhichrequirementistestedbywhichtest case or vice versa.
more details of the architecture are described in subsequent subsections.
.
test implementation layer as mentioned earlier tae implements a test step to be executed automatically and is responsible for maintenance of library of test scripts.anautomatedstepisspecifiedasastructuredexpression authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france davrondzhon gafurov arne erik hurum and martin markman figure helsenorge s test automation architecture.
non freetext withorwithoutparameters.theexpressionisformulated such that it is understandable by non technical person with domain knowledge.
each automated test step is implemented as a c classand bound via regular expression.
figure 4shows an automated test stepexpression choose a representation .
with its implementation code.
storing standaloneautomated steps isnot so meaningfultherefore they are organized into atc by tae.
we have defined two categoriesofatc namelytemplateoneandordinaryone.taecreates and implements template atcs that also serve as a repository ofautomatedteststeps.tacreatesordinaryatcsusingautomated test steps from the template atcs.
.
test definition layer attestdefinitionlayertacreatesnewatcusingautomatedtest stepscreatedinpreviouslayerbytae.usually conventional manual test cases specify expected outcome in each step.
this enables tato be aware whatwill happen after executionof each step and thencompareactualandexpectedoutcomes.however inouratc we do not specify expected outcome in every step since we do not compare outcome in every step but rather have one explicit step for verifying expected outcome of the whole atc.
it is designed sobecausefailureofcomparisoninacurrenttest step ignoresexecution of the rest of the test steps in the atc.
in short a single atcverifiesasinglefunctionality.furthermore inouratc test figure implementation of 2nd step in atc shown in fig ures5and6.
input is an integral part of test case which helps ta to create more familiar not very different from manual test cases readable in termsofbusinessprocess andself descriptiveautomatedtestcases.
in fact the same test management tool i.e.
tfs is used both for manual and automated test cases.
test inputs can be specified both as a value and as a variable.
for example in one atc a test step canbeinputtedwithvaluewhileinanotheratcthesameteststep getsinputfromvariable.figures 5and6showtwoatcs2where the test step given that i logged in as ... has input as a variable pnrandasavalue .tathemselvescanchoosewhich way they want to specify input e.g.
depending on repeatability of theinputwithin agivenatc.atcinfigure 5iteratestwicewith twosetsoftestinput whileatcinfigure 6iterates runs once.in general an atc can be iterated with any number of test inputs.
.
test execution layer ta is responsible for arranging set of atcs into test suites executing them and observing test execution report.
test suites are executeddaily atspecified timeor canbe triggeredon demandby ta.
however the task of failure analysis is a shared responsibility betweentaandtae.sourceoffailurecanbedifferent defectin sut primary we are interested in error in test environment e.g.
a service is down outdated test script or test data and so on.
ifexecution of atc fails then at first ta attempts to analyze and investigate failure.
if ta cannot determine the failure reason only then tae starts failureanalysis and investigation see figure 7for this workflow.
by letting first ta to analyze and possibly partially or fully resolve failures we avoid tae to be a bottle neck in the 2testcasesarespecifiedinnorwegianlanguage.heretheyaretranslatedintoenglish for understandability purpose.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
achieving test automation with testers without coding skills ase september montpellier france figure example of the automated test case.
process.
for ta to analyze independently it is important to report meaningful error messages when a failure occurs.
.
test adaptation layer at this layer tae implements test interface at which atc shall interact with helsenorge.
once this layer is completed usually it does not require further modifications unless new interactionlevel is necessary to implement.
most of the manual test cases thattashavecreatedrunatgraphicaluserinterface gui level.
however we have chosen to apply test automation at the rest representationalstatetransfer service level sinceelements on gui tends to be changed frequently.
although our approach maynotdetectguispecificbugs itprovidesopportunityfortato create atc that can discover back end defects by bypassing frontend validation.
ta can create the so called negative atc which tests sut with unexpected illegal or incorrect inputs and verifies relevant error messages are reported.
such back end defects are difficultorimpossibletodiscoverbymanualguitests.forinstance in helsenorge portal the valid health region codes are and .
figure8shows an example of negative atc which attempts to set theregioncodetosomeinvalidvalues i.e.
2and0 .thelast step in this atc verifies that the correct error message is reported.
thistestisnotpossibletorunmanuallybecauseguidoesnotallow the user to select the values other than or for health region.
figure example of another automated test case.
test creation efficiency .
automation phases with and without test artifacts intermsofmeasurabletestartifacts workonthetestautomation can be divided into two phases the ones that generate explicit measurable test artifacts non measurable test artifacts.
inourarchitecturefromfigure 3anautomationworkonthetest implementation testdefinitionandtestexecutionlayersproduce measurable test artifacts.
it means at these layers one can ask ques tionssuchas howmanyautomatedteststeps automatedtestcases or test execution reports are implemented created or produced respectively.
however the automation work on test adaptation layer does not produce any direct test artifact.
a test adaptationlayer produces a test code that enables interaction with sut but no explicit test artifacts that ta can reuse or work with.
.
test creation efficiency asnotedpreviously tocreateanewatcthetausesautomated teststepsfromthetemplateatcs.althoughknowinghowmany atcs have been created by tae or ta is important for monitoring workprogress itwouldalsobeusefultoknowtheimpactoftae s authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france davrondzhon gafurov arne erik hurum and martin markman figure helsenorge s defect investigation process.
figure example of a negative automated test case.table test creation efficiency for helsenorge teams team atc by tae atc by ta total r pot .
hoi .
tod .
r f r i n a total .
work on ta s work.
for instance how many new atcs the ta can create based on the existing template atcs created by tae.
in otherwords checkingwhetheritispossibletopredictta swork based on tae s work.
for answering this we define the test case creation efficiency ratio as follows r total atc created by ta total atc created by tae table2shows helsenorge s test case creation efficiency ratio perteam.thehighnumberforpotteamisduetothefactthatthe corefunctionalityisdevelopedbythisteam andtheautomation project started with this team.
in fact teams in table 2are ordered in chronological order of using test automation i.e.
we applied our solutionfirstonpotandlastonr f.fortestingactivityinr i team open part of the helsenorge our automation solution is not appliedyet.asoftoday thetotaltestcreationefficiencyratiofor helsenorge is .
.
it means if tae created atcs then for ta it waspossibletoincreasethecoveragebycreatingandadding4or5 newatcsbasedonthis10.however itshouldbenotedthatthis numberreflectsonlycreation anddeletion ofnewtestcasesbut doesnotconsidersmodificationorupdateofexistingtestcases.for example if ta adds new test input to already existing atc then it is not reflected in this number.
benefits lessons learned and limitations the work on designing architecture implementation and deployment of test automation solution for helsenorge started early in .
consequently benefits limitations lessons and findings presentedinthispaperarethosewehaveexperiencedsofar.however we plan to observe and collect further experiences and findings which we will report in future publications.
.
benefits the followings are the main benefits we achieved using our approach saved time and improved coverage.
byapplyingthisautomation thegreatestbenefitsthatweachievedwere notsurprisingly saved manualregressiontesting effortandimproved testcoverage.theautomationallowedustocarryoutnot only breadth but also depth testing.
we refer to the breadth testing when we have several atcs that verify separate features of the sut.
by depth testing we mean a single atc is iterated with several test data.
for example there are five authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
achieving test automation with testers without coding skills ase september montpellier france helsenorge s service areas which are available via authorization to give access to another person .
test scenarios ofallpossiblecombinationsofthisfeatureare32.asingle atc is created to iterate over all these combinations.
according to the ta in pot team it takes about minutes forhertomanuallytestoneiterationofthisfeature.however automatic execution of one iteration takes about seconds.
better cross functional teams.
anotherimportantbenefitof ourapproachwasitscontributiontowardsbettercross functionaldevelopment teams.
cross functional team has all necessaryskillstoaccomplishitstaskwithoutdependingonothersnot partoftheteam .incaseoftestingtasks ta whoisa full member of the development team can be also in charge of test automation because independently he or she can create a new atc update existing atcs organize atc into test suites manage execution of test suites and analyze test report.
thus ta sautomationworkdoesnotdependontae swork aslongasrequiredteststepsareautomated i.e.implemented by tae .
in addition being able to independently carry out atest automationmay helptainbetter estimatingtesting tasks during work sprint planning.
negative tests.
as it was pointed out our approach enables creating negative atc with illegal or incorrect test inputs that verify fail safe scenario of the system see for example figure8 .infact weplantoincreasethenumberofnegative atcaswebelievemanyback enddefectscanbedetected by bypassing front end validations which are not feasible via manual gui tests.
.
lessons learned thefollowingisashortsummaryofthemainlessonslearnedfrom our experience understand before code.
taeshouldhaveaholisticperspective to design and implement efficient reusable automated test steps.
he or she needs to have a good understanding of functionality and interdependencies among various parts of the sut before commencing to write a test code.
it is also importantachoiceoflanguageformulationforspecificationofateststepthatadequatelyreflectssutfunctionality.this is especially true for frequently used test steps which are sharedandusedbyseveralteams.otherwise itmayresult in several implementation iterations or code duplication for the same or similar functionality.
therefore good collaborationbetweentaeanddevelopmentteams especiallytas is essential.
always have maintenance perspective.
almost every test task can be automated and test managers may have high expectationswithrespecttoautomation.however testautomation is not a one time job it is a continuous processand therefore maintainability is essential.
in fact maintenanceofatccanbechallengingandfailuresourceofmany test automation projects .
consequently tae shallevaluate every test automation task not only from the implementationperspective short termgoal butalsointerms of maintainability long term goal .
if maintenance effort of the task appears to outperform its automation benefits then it shall not be automated.
our approach enabled delegating partofmaintenanceefforttota e.g.updatingatc man aging test data .
this is important because of minimizing riskof bottle necks intheprocessduetolimitednumber of tae resources in the organization.
in addition to haveeffective maintenance one must create guidelines both for taeandta forexampleonhowatcswillbeimplemented created updated and eventually removed and criteria for selecting test tasks for automation.
inform managers about non measurable phases.
projectandtestmanagersshallbeinformedandawareabout automation phases that do not produce explicit measurable testartifacts.otherwise theymaygetawrongimpression thatthetestautomationworkisnotprogressingasexpected.
tool unification.
it is desirable to have the same management tool for both manual and automated test cases as well as for requirements.
this simplifies automatic generationof various test execution and test coverage reports.
oth erwise one needs to estimate additional work for ta to manually synchronize combinetestreportsformanualand automated test execution from two separate sources and maintaintraceabilitybetweentestcasesandrequirements possibly manually.
.
limitation and opportunities for future work below is the list of some main limitation and opportunities for future work tool limitation.
several limitations that we came across duringimplementationwereintrinsictothetestmanagement tool i.e.
tfs.
one of them was not being able to control executionorderoftheatcswithinatestsuiteotherwiseone could create more compact test suites to achieve the samelevel of test coverage.
another functionality that the tool could provide is an automatic suggestion of test steps while ta typing the first letters or words of the test case.
this could help to avoid false negatives due to spelling errors in the test step language.
automated test data generation.
inourapproach tamanuallyupdatesatcwithtestdata.althoughmanuallyupdating or editing test input in an atc is easy and straightforward itcanbetedioustaskwhenthenumberofatcstoupdate is large.
in addition it may take time for ta to find test data withtherequiredcharacteristics e.g.findingatestperson which has a child with digital gp or electronic prescription .
we investigate possibility to automate updating test data in atc i.e.
automating test data generation.
automated test case generation.
in our approach creation of automated test cases is performed manually.
if sut ismodified in a way that requires a modification of existing atcs then it creates extra work for ta to edit or even recreatethemmanually.however availabilityofsutmodel authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france davrondzhon gafurov arne erik hurum and martin markman fromwhereatcscanbegeneratedautomaticallywillreduce this work.
for instance after sut changes only its model isupdatedandthentestcasesaregeneratedautomaticallyfrom the model.
we plan to investigate possibility to develop a model of helsenorge for automated generation of test cases.
conclusion weproposedatestautomationsolutionwhichwasimplemented by using process driven test automation.
it has been applied and still in operation on a large web application of electronic health services in norway helsenorge.no which has over one million visits per month.
our solution enabled moving part of test automation tasks from test automation engineer with coding skills expensiveresource totestanalystwithdomainknowledge less expensive knowledge .
besides expected benefits of saved man ual testing effort and improved test coverage another importantadvantage of our approach is that it contributed towards better cross functional development teams.
this enables a test analyst to independently carry out necessary test automation activities.
such activities include creating new or updating existing automated test cases executing them and analyzing test report.
an important lesson we have learned is that a test automation engineer needs to haveagoodunderstandingoffunctionalityandinterdependenceof the system to implement efficient automated test steps i.e.
understanding before coding .
in addition the test automation engineer should always remember maintainability aspect while considering automation of the test task.
asoftoday helsenorgehas139automatedtestcases andtest creation efficiency ratio is .
which means almost of 139testcasesarecreatedbytestanalystswhiletherestiscreatedby the test automation engineer.
our experience indicates promising results andweplantoapplytheapproachonotherproductsand development teams within our organization.