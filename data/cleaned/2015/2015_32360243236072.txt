how well are regular expressions tested in the wild?
peipei wang department of computer science north carolina state university raleigh nc usa pwang7 ncsu .edukathryn t. stolee department of computer science north carolina state university raleigh nc usa ktstolee ncsu .edu abstract developers report testing their regular expressions less than the rest of their code.
in this work we explore how thoroughly tested regular expressions are by examining open source projects.
using standard metrics of coverage such as line and branch coverage gives an incomplete picture of the test coverage of regular expressions.
we adopt graph based coverage metrics for the dfa representation of regular expressions providing fine grained test coverage metrics.
using over tested regular expressions in java projects on github we measure node edge and edge pair coverage.
our results show that only of the regular expressions in the repositories are tested at all.
for those that are tested the median number of test inputs is two.
for nearly of the tested regular expressions only one test input is used.
average node and edge coverage levels on the dfas for tested regular expressions are and respectively.
due to the lack of testing of regular expressions we explore whether a string generation tool for regular expressions rex achieves high coverage levels.
with some exceptions we found that tools such as rex can be used to write test inputs with similar coverage to the developer tests.
ccs concepts software and its engineering software testing and debugging language features keywords regular expressions test coverage metrics deterministic finite automaton acm reference format peipei wang and kathryn t. stolee.
.
how well are regular expressions tested in the wild?.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
.org .
.
introduction a survey of professional developers reveals that they test their regular expressions lessthan the rest of their code .
in this work permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa association for computing machinery.
acm isbn .
.
.
.
.org .
.3236072we explore how thoroughly tested regular expressions are by examining open source projects.
traditional code coverage criteria are rather coarse grained when it comes to regular expressions.
statement coverage requires the regular expression to be invoked at least once.
if the regular expression call site appears in a predicate branch coverage requires that the regular expression is tested with at minimum two strings one in the language of the regular expression and one not.
however these metrics ignore the complex structure represented by a regular expression.
we propose to use test metrics for graph based coverage over the dfa representation of regular expressions.
regular expression tools can help support developers in their creation and testing of regular expressions.
these tools either automatically generate strings according to the given regular expressions or automatically generate regular expressions according to the given list of strings .
rex is a tool for analyzing regular expressions through symbolic analysis.
given a regular expression r rex uses the z3 smt solver to generate members of the language by treating it as a satisfiability problem.
like automatic test case generation tools integrating these generated results into software testing can help automate the process but it is not clear how well covered the regular expressions would be compared to developer written tests.
in this work we focus on empirically measuring how well tested regular expressions are and further explore the potential for using existing tools specifically rex to improve the test coverage.
first we measure the test coverage of regular expressions in the wild based on a set of java projects on github containing tested regular expressions.
second we measure the test coverage of strings generated by rex and compare the coverage achieved against the strings generated by developers in the github projects.
our contributions are application of graph based metrics for test coverage of regular expressions node coverage edge coverage and edge pair coverage section .
test coverage evaluation of regular expressions based on nearly input strings from java projects from github rq1 .
evaluation of test coverage achieved by the rex symbolic analysis tool for regular expressions rq2 .
our main findings are of call sites for three pattern matching api methods identified statically in github projects only .
are ever executed by test suites rq1 .
of regular expressions captured during test suite execution of github projects .
use only failing inputs or only matching inputs rq1 .
esec fse november lake buena vista fl usa peipei wang and kathryn t. stolee the rex generated test inputs achieve similar coverage levels to the developer written tests rq2 .
background and motivation a regular expression is a sequence of characters that defines a search pattern.
the set of strings matched by the regular expression is a language.
that is a regular expression rrepresents a language l r over an alphabet where l r is a possibly infinite set of strings.
for a given language there are many regular expressions that can describe it.
a regular expression can be represented as a string of tokens a finite state automaton in deterministic dfa form or in non deterministic nfa form.
in this work we explore test coverage metrics over the dfa representing a regular expression.
this requires three informal explorations to ensure feasibility and assess the potential impact.
first we explore the potential of building dfas from regular expressions by analyzing regular expressions collected from an existing python dataset and testing them for regularity .
second we show intuitively how existing coverage metrics are insufficient.
third to motivate the structural coverage metrics we explore whether faults can lie along untested paths in a dfa.
.
how regular are regular expressions?
regular expressions in source code can contain non regular features such as backreferences.
an example is the regular expression which matches a repeated word in a string such as appleapple .
building a dfa is not possible for this since this regular expression is non regular.
for regular expressions in source code that are indeed regular we can build dfas and measure coverage based on a test suite.
here we are testing how many of the regular expressions in the wild are truly regular.
we explore an existing and publicly available dataset of regular expressions scraped from python projects on github.
to test for regularity we use an empirical approach since the ability to build a dfa from a regular expression implies that it is regular .
of the python regular expressions .
are regular in that we were successful in building dfas for each using the re2 regular expression processing engine.
for the remaining we investigated each by hand.
one regular expression was removed because its repetition exceeds the re2 limits.
while it may indeed be regular to be conservative we mark it as non regular.
an additional contained comments within the regular expressions which are unsupported in re2 so these were also assumed to be non regular contained unsupported characters.
the remaining were non regular as they contained backreferences.
in the end with nearly of the regular expressions being regular as a low estimate we conclude that most regular expressions found in the wild are regular and thus can be modeled with dfas.
.
limitations of code coverage in this work we posit that code coverage metrics such as statement branch and path are too coarse grained for regular expressions.
statement coverage requires that the code containing the regular expression is reached leading to a minimum of one test input for the regular expression.
if the regular expressionis in a statement where the control flow is dependent on the matching outcome branch coverage requires that the regular expression have at least two inputs one that evaluates to true and another that evaluates to false.
consider the following java code snippet.
the call site for method pattern.matches is on line .
the regular expression is d data .
if pattern .
matches d data strinput system .
out .
println yes ... else system .
out .
println no ... statement coverage of the regular expression requires that line is executed and branch coverage requires two test inputs one to cover the true branch and one to cover the false branch.
using coverage metrics based on the dfa representation of the regular expression on the other hand would require each branch to be covered and each casein the regular expression d and data to be covered.
such metrics measure test coverage of the regular expression s control flow i.e.
the dfa just like branch coverage measures test coverage of source code s control flow graph.
existing tools and techniques can direct test input generation toward areas of untested paths.
one technique among these is symbolic execution and rex has been developed for symbolic analysis of regular expressions.
however rex focuses solely on the matching behavior which limits its ability to cover the false branch in the java example above.
hampi and brics similarly only generates passing strings.
while useful there are no guarantees of structural coverage.
.
dfa coverage example bug reports related to regular expressions abound.
a search for regex or regular expression in github yields over issues with of those still being open.
one in particular illustrates how coverage metrics on the dfa could have brought a particular bug to the developer s attention sooner.
this bug report1describes an issue with the regular expression d .d in the nar plugin for maven.
figure shows the dfa of this regular expression built using re2 and we take this opportunity to describe the dfa notation used throughout this paper2.
node is the start state indicated by the incoming arrow.
nodes with double circles are accept states such as node .
node e is the error state denoting a mismatch.
the edges are labeled with transitions often using syntactic sugar for ease of interpretation.
the edge 01is traversed when a digit from 9is read.
if any other character is read at node i.e.
not edge 0eis traversed.
there is a self loop on node for digits .
if the period character is read from node then edge 12is traversed.
in re2 when reading an input string byte is added as a text end marker.
for example the input string .
is transformed to the byte stream as is the byte for is for .
and marks the end of the string.
byte is matched on edges not not d or any except and .
.
.com maven nar nar maven plugin issues 2the regular expression in the bug is triggered by matcher.find with a manymatch dfa.
for simplicity we show the fullmatch dfa a subgraph of the manymatch.
669how well are regular expressions tested in the wild?
esec fse november lake buena vista fl usa enot any except and .
.
not d 3d not d 5d not d d figure full match dfa for regular expression d .d the bug report mentions that the regular expression d .d is buggy and the patch adds an escape before the second d d .
d .
the intended behavior is to match input strings with one or more digits followed by a period followed by one or more digits.
in this work the structural metrics could reveal this fault.
with the dfa in figure when node is reached the fault may be revealed.
input .d traverses 4and ends in an accept state when it should fail.
however input .d3 traverses eand ends in an error state as expected.
covering edge 2emay also reveal the fault input .
traverses eand ends in and error state when it should be accepted.
requiring coverage of all feasible nodes and edges could have revealed this fault in the regular expression.
as with code coverage uncovered artifacts alert the programmer to untested behavior.
such coverage information can indicate that a regular expression is not well tested and for some inputs it may not behave as intended as is the case here.
test coverage metrics we explore fine grained coverage metrics for regular expressions based on a dfa representation.
the intuition is that since regular expressions are equivalent to dfas and of regular expressions in the wild were found to be regular section .
then graph coverage metrics over the dfa can be used to test the behavior within most regular expressions.
we discuss three levels of coverage node coverage nc edge coverage ec and edge pair coverage epc .
these coverage metrics are adopted from graph coverage metrics proposed by ammann and offutt .
.
graph notation for ease of exposition we expand on the traditional definition of a dfa.
in this work a dfa graph g n n0 nm ne e where nis the set of all nodes n0is the initial node nmis the final matching accept node neis the final failing error node and eis a set of all edges.
for the dfas in this work there is only one initial state one accept state and one error state.
the states in a dfa are the nodes n n0 n1 .
.
.
nk .
for any two nodes n1andn2such that n1 n2 n if there is a transition from n1ton2in dfa then the edge n1n2 e the start and end state of the path may be the same node as is the case of self loops.
edge pairs are defined by paths of length two in the dfa.
for example if n1n2 n2n3 e we denote the edge pair as n1n2n3.
in the case of self loops n2n2n2is also a valid edge pair.
given an input string and a regular expression the initial node n0is visited first.
transitions are taken as each character in the 1in a fullmatch dfa see section .
there could be several matching nodes and only one accept.
we simplified to use only one accept state.
enot not not 9figure full match dfa from re2 for the regular expression d .
re2 interprets every string as a byte stream the range of bytes is where is added to mark the end of a string.
thus the input string would be represented as and traverse the following path .
the edges marked 9represent the byte range edges not represent the byte ranges .
string is consumed.
the result of the matching process ends in either the accept node nmor the error node ne.
in standard dfas a traversal can end in any node.
however the dfa generation algorithm used in this work is based on the re2 tool which always ends processing in an explicit matching accept nm or error ne state.
in this tool given a regular expression and an input string the input string is interpreted as a byte stream with byte added to the end to mark the end of the string.
thus an input string would be interpreted as and the input string would be interpreted as .
as a running example consider regular expression r d and graph gin figure .
in g n e n0 nm ne e e 0e 3e and ep 13e 23e .
edges 9cover bytes and edges not cover the byte ranges we use the decimal representation to improve clarity.
at this point we note that this is not the smallest dfa for the regular expression d .
as the same tool is used for the construction of all the dfas any impact of the dfas not being minimal e.g.
extra nodes or edges compared to the minimal representation is distributed throughout the whole data set and consistent across all experiments.
while we refer to re2 for full details of the dfa construction though some intuition is provided in section .
.
.
.
coverage criteria given a set of strings sand a dfa g for all n n we mark nas covered ifnis visited during the processing of some s s. similarly edges e eand edge pairs ep epare marked as covered if they are traversed during the processing of some s s. the sets of covered nodes edges and edge pairs are denoted ncov ecov and epcov respectively.
these sets are aggregated over all s s. as defined in prior work we adopt coverage definitions for node coverage nc edge coverage ec and edge pair coverage epc as follows definition .
node coverage .
nc ncov n definition .
edge coverage .
ec ecov e definition .
edge pair coverage .
epc epcov ep to illustrate the coverage levels consider the graph gfor the regular expression d in figure and the string s0 with 670esec fse november lake buena vista fl usa peipei wang and kathryn t. stolee table coverage of d s u 100u ssucc and sf ail u 100u .
s s succ sf ail nc .
.
.
ec .
.
.
epc .
.
.
s s0 .
traversing gvisits recall that is interpreted as the byte stream .
node 3is the accept node which denotes that the regular expression matches the input string i.e.
s l r .
during the traversal of g nodes are visited meaning that ncov ecov and epcov .
the coverage levels for d by input strings s s0 are nc ec .
and epc .
.
next consider adding the string s1 which is interpreted as the byte stream .
now s s0 s1 .
traversinggons1traverses the following path adding node 2toncov edges and 23toecov and edge pairs and 223toepcov.
as a result the coverage levels for the regular expression d by input strings s s0 s1 are nc ec .
and ep .
.
as an example of a non matching string let s2 u which is interpreted as the byte stream .
the path traversed in gis0 e after reaching e the processing stops.
node eis added toncov edge 0eis added to ecov and there is no change to epcov.
considering s s0 s1 s2 the combined coverage levels are nc ec .
and epc .
.
for another example of a non matching string let s3 100u which is interpreted as the byte stream .
the path traversed in gis0 e. while this input visits all nodes in g nc already so no nodes are added to ncov.
edge 3eis added to ecov edge pair 23eis added to epcov.
considering s s0 s1 s2 s3 the combined coverage levels are nc ec and epc .
for each coverage metric we compute coverage over the entire set of input strings total and two subsets success and failure .
the numbers reported in this section are for the total set of input strings that is s s0 s1 s2 s3 .
after we split the input strings into those that terminate in an accept state in nm which we call ssucc and those that terminate in the error state ne which we call sf ail.
with this example ssucc s0 s1 andsf ail s2 s3 .
table presents a summary of the coverage levels for each set of input strings.
achieving for any of the coverage metrics is infeasible for ssucc alone because the error state ewill never be reached missing that node and the edges leading to it.
in this example ec for ssucc is .
while ec for sis .
achieving coverage for epc is the most difficult but it is possible in this example.
the missing edge pairs are computed byep epcov 13e .
two additional input strings can lead to epc.
input 1u would be interpreted as the byte stream and traverses the path e hence covering 13e.
input 11u would lead to byte stream traverse the path eand cover .
note that it is possible to have a dfa which is simply two nodes connected by a single edge.
thus edge pairs may not exist.
forthis case we treat edge pair coverage as identical to edge coverage.
among the regular expressions studied in this work only two regular expressions have this structure.
research questions to explore the potential of using graph coverage metrics for regular expressions we evaluate the following research questions rq1 how well are regular expressions tested in github?
to answer rq1 we identify java projects that have existing test suites covering the regular expressions.
from these we extract regular expressions and total test input strings measuring nc ec and epc for each regular expression.
to obtain the regular expressions and their corresponding strings which are covered by test cases we use the java bytecode manipulation framework javassist to record the regular expressions when pattern matching methods are triggered by test cases.
rq2 how well can the regular expression string generation tool rex improve the test coverage of regular expressions?
using the regular expressions from rq1 we generate test strings using rex and calculate the regular expression coverage comparing it to the coverage of the user defined test suites from rq1.
using rex we generate test suites of three sizes one to match the size of the user defined test suites from the github projects one 5x that size and one 10x that size.
by comparing the coverage statistics we got in rq2 to those in rq1 we evaluate the test coverage possibilities through using an automated tool.
study applying the coverage metrics defined in section .
to regular expressions from the wild requires instrumentation to capture the regular expressions and strings matched against them section .
a tool to measure coverage given a regular expression and a set of strings section .
and a large corpus of projects with regular expressions and test suites that execute the regular expressions section .
.
to address rq2 we use the rex tool to generate input strings for the regular expressions in our study section .
.
.
instrumentation this section describes our approach to collecting regular expressions from github projects and the strings evaluated against the regular expressions during testing.
.
.
instrumented functions.
there are different types of matching between a regular expression and a string.
the java function pattern.matches requires the regular expression to match a string from its beginning to its end python s re.match requires the regular expression to match a string only from its beginning not necessarily match to the end of the string and the c function regex.match requires the regular expression to match only a substring of the input string.
these are called fullmatch firstmatch and manymatch respectively.
in this work we consider only fullmatch matches and related functions in java projects.
the related functions for fullmatch in java are java.lang.string.matches string regex java.util.regex.matcher.matches 671how well are regular expressions tested in the wild?
esec fse november lake buena vista fl usa java.util.regex.pattern.matches string regex charsequence input in these functions the entire string is required to match the regular expression .
thus a regular expression with end point anchors i.e.
and and without are no different.
.
.
bytecode manipulation.
our instrumentation is built on top of the java bytecode manipulation framework javassist which can dynamically change the class bytecode in the jvm.
all the projects are run in jdk1.
.
we intercepted fullmatch function invocations in java.
for each invocation we collect information about the regular expression itself its location in the code and any strings matched against it during test suite execution.
these strings matched against the regular expression are referred to as theinput strings ortest inputs i.e.
sfrom section .
.
since a regular expression may also appear in third party libraries we use the java reflection api to additionally record the caller function stack of the instrumented methods and extract the file name class name and method name of their caller methods.
this allows us to identify when the regular expression being executed is from the system under test and when it is from a third party library.
we are dependent on two libraries during the experimentation org.junit andorg.apache.maven .
because maven uses regular expressions to automate unit tests all recorded regular expressions whose test classes are from package org.junit.runner.
or from package org.apache.maven.plugins.
are treated as regular expressions from third party libraries and dropped.
.
.
recorded information.
we illustrate the recorded information for the regular expression w and a string onename from a project used in our study1 system under test mikko apo kirouter.java test file sinatrarouteparser.java test class kirouter.sinatrarouteparser test method compileroutepattern call site line regular expression w input string one name in section .
the regular expression in the call site on line is hard coded.
however often the regular expression is passed as a variable allowing multiple regular expressions to be observed during testing at the same call site i.e.
there is a many to one relationship between regular expressions and call sites .
when this occurs the recorded information is the same as above except regular expression andinput string would be different.
.
coverage analysis this section details the construction of dfas for computing coverage.
given a regular expression rand a set of input strings s we first build a dfa for l r and then track the nodes and edges visited in the dfa during pattern matching with each string s s. we built our infrastructure on top of re2 a regular expression engine similar to those used in pcre perl and other languages.
.com mikko apo kirouter .java 2original re2 at .com google re2 and modified code at https github .com wangpeipei90 re25.
.
dfa types.
given a regular expression and an input string to match we could build multiple dfas with different considerations.
we could build a static dfa with a regular expression alone or build a dfa on the fly dynamic dfa considering both a regular expression and an input string.
for the same regular expression different input strings will yield different dynamic dfas.
we can also build a forward dfa and backward dfa depending on the direction of scanning the regular expression.
these decisions come with various performance tradeoffs during the matching process.
for the purpose of our work we need each dfa to be built consistently regardless of the input string so we use a static dfa.
we chose the forward direction as it seems the most natural for interpretation.
.
.
dfa mapping.
when matching an input string to a regular expression re2 builds a dynamic dfa.
however our coverage is computed over a static dfa.
this requires mapping to aggregate coverage of a regular expression given multiple input strings.
for a single regular expression different input strings often result in different dynamic dfas.
to make matters worse these dfas have inconsistent naming of their states.
therefore to calculate the coverage of a certain regular expression based on the same dfa these dynamic dfas have to be mapped to the same static dfa and then coverage is computed on the static dfa.
this is usually straightforward as the dynamic dfa is always an isomorphic subgraph of the static dfa and n0 neandnmare consistently labeled in the static and dynamic dfas.
consider the regular expression d ands s0 s1 s2 s3 from section .
where s0 s1 s2 u and s3 100u .
figure 3a shows the static forward dfa.
the dynamic dfas corresponding to these four inputs are shown in figure 3b figure 3c figure 3d and figure 3e respectively.
blue arrows are used to identify the visited edges in the dynamic dfas when the input string is a match.
red edges are used to identify the visited edges when the input string is not a match.
note that in figure for simplicity we have already mapped and renamed the nodes in the dynamic dfas according to the static dfa.
.
.
re2 limitations and modifications.
we enlarged the default memory size of a cached dfa so that it could accommodate large dfa graphs.
due to linux environment limitations string length is limited to and null type is not allowed.
these situations are rare impacting of the collected regular expressions see section .
.
.
.
coverage calculation.
with the consistent naming between a static dfa and a dynamic dfa all nodes edges and edge pairs in the latter are regarded as visited nodes edges and edge pairs of the former.
that is a node only appears in a dynamic dfa when it is visited during matching these can be thought of as just intime dfa constructions in the context of a string to match.
the coverage metrics from section .
are computed over the static dfas aggregating over all input strings observed during testing.
.
artifacts for rq1 reporeaper provides a curated list of github projects with the ability to sort based on project properties such as the availability of test suites which is a pre requisite for our study.
we focused on 672esec fse november lake buena vista fl usa peipei wang and kathryn t. stolee enot not not a fully specified static dfa for d b dynamic dfa for regular expression d and input c dynamic dfa for regular expression d and input eu d dynamic dfa for regular expression d and input u 11e u0 e dynamic dfa for regular expression d and input 100u figure visited dfa subgraphs for the regular expression d .
for each figure n0is the initial node nmis the accept node neis the error node e. the arrows colored blue represent transitions in successful matches.
the arrows colored red represent transitions in failed matches.
the characters without square brackets are the literal characters in state transitions.
for example u prompts the transition from node to node e. implies that there are no more bytes from the input string.
java projects due to its popularity on github and the availability of a bytecode analysis framework for instrumentation.
.
.
project selection.
in december we selected the java projects whose unit test ratio reported in reporeaper is greater than zero.
because the density of regular expressions in projects tends to be low we automated project builds and test suite execution in order to collect sufficient data.
as such we require all projects we analyze to use maven andjunit to automatically run unit tests.
we identified java maven projects that used java pattern matchings functions mentioned in section .
.
from those we selected the ones that could be successfully compiled and tested in maven leaving projects on which we attempted to collect coverage information.
.
.
regular expression and test input collection.
to collect the input strings for each regular expression we instrumented each project and executed the test suites.
we changed the configurations of the plugin maven surefire plugin by adding javaagent argument toargline so that when maven forks a vm to run the unit tests the vm can load the instrumentation library.
each project module that runs tests executes in different vms and the information is recorded in different files.
testfailureignore is configured to trueso that one test failure does not affect the other tests allowing us to record as many regular expressions in the project as possible.table description of java projects analyzed.
all numbers are rounded to nearest integer except the test ratio and kloc.
attributes mean tested regular exp.
stars test ratio .
.
.
.
.
.
kloc .
.
.
.
.
.
size kb call sites tested call sites reg.
exp.
tested site of the projects with maven test suites and pattern matching functions projects contained regular expressions executed by test suites.
the remaining projects contained regular expressions notexecuted by the test suites and thus could not be instrumented.
.
.
filtering out third party regular expressions.
fullmatch invocations from maven and junit have been removed already at this point but other third party libraries also use regular expressions.
we can detect this by looking for syntactically identical regular expressions with invocations on the same file same class same method but in different github projects.
if the number of projects is larger than one then it is regarded as a third party regular expression and all records related to the same stack information are dropped.
a limitation of this approach is that we miss some thirdparty invocations that are only present in a single project.
given the large number of projects analyzed the impact of this is likely to be small.
we identified regular expressions as coming from thirdparty libraries.
the resulting dataset contains projects and regular expressions of which are syntactically unique.
.
.
re2 analysis.
since re2 only supports the most common regular expression language features we filtered out the regular expressions containing advanced and non regular features.
re2 failed to construct dfas for regular expressions leaving regular expressions spread across projects.1the re2 limitations on input string length and the null byte affected regular expressions and input strings and nine of the regular expressions are removed from coverage analysis because their only input string is dropped.
these projects contain call sites of the instrumented functions.
only call sites are executed by the test suites the same call site can have many regular expressions in the case of dynamically generated regular expressions.
the final dataset used for analysis contains projects call sites regular expressions of which are syntactically unique.
as the same regular expression can appear in multiple projects or multiple places in the same project all are retained since each is potentially tested differently.
these regular expressions are executed by test inputs.
1assuming all are non regular this means over of the regular expressions sampled are regular echoing findings from the python analysis in section .
.
673how well are regular expressions tested in the wild?
esec fse november lake buena vista fl usa table description of regular expressions analyzed for rq1.
all numbers are rounded to nearest integer.
attributes mean nodes n edges e edge pairs ep regular exp.
len.
input strings s input string len.
.
.
project characteristics.
table describes the projects in terms of tested regular exp.
numbers of tested regular expressions per project stars a measure of popularity kloc lines of code in thousands size size of the repository in kb test ratio the ratio of number of lines of code in test files to the total lines of code in repository as reported by reporeaper call sites the number of fullmatch methods in the source code tested call sites the number of fullmatch call sites executed by the tests and reg.
exp.
tested site the number of regular expressions passed to each tested call site .
the mean column describes the average value for each attribute.
columns and show the distribution of each attribute at percentile median percentile percentile and percentile respectively.
the average number of tested regular expressions collected per project was with a range of to .
.
.
regular expression characteristics.
table shows the dfa information for regular expressions.
nodes edges and edge pairs are the total number of nodes edges edge pairs in the dfa graph of a regular expression.
the average regular expression is quite large with nodes though this is skewed as the median is nodes.
regular exp.
len.
measures the length of the string representing the regular expression itself in characters.
input strings is the number of syntactically unique input strings executed by a project s test suite per regular expression.
the average number of syntactically unique test inputs per regular expression is but the median is .input string len.
shows the lengths of the input strings i.e.
each s s in terms of the number of characters.
.
artifacts for rq2 to explore the coverage of regular expressions using tools we selected rex due to its high language feature coverage .
.
.
artifact selection.
we need a set of regular expressions with the following characteristics are covered by tests can be analyzed by re2 for coverage analysis and can be analyzed by rex for test input generation.
to satisfy and we begin with the dataset from rq1 of projects and regular expressions.
to satisfy we select all the regular expressions that rex supports and for which ssucc since rex only generates matching strings leaving regular expressions of which are syntactically unique.
.
.
rex setup.
rex defaults to manymatch as opposed to the fullmatch behavior of our dataset.
to force rex to treat each regular expression as a full match we added endpoint anchors i.e.
and to each regular expression.
because rex may get stuck in generating input strings for certain regular expressions we set a timeout of one hour for rex to generate strings regular expressions that exceed thetable description of regular expressions analyzed for rq2.
all numbers are rounded to nearest integer.
attributes mean nodes n edges e edge pairs ep regular exp.
len.
input strings s ssucc timeout are discarded.
of the regular expressions in github whose ssucc rex encountered the timeout for only two.
another complication comes at the intersection of the rex and re2 language support rex generated strings must be processed by re2 for the coverage analysis.
for example the character class s in rex accepts six whitespace characters and re2 accepts five.
in another example some generated unicode strings in rex could not be processed in re2 because their unicode encoding in rex is utf while re2 handles unicode sequences encoded in utf8 or latin .
to simplify the experiment we configured rex to generated strings in ascii.
we also dropped strings which contain unsupported features or characters in either re2 or python .
we also dropped strings which lead to failed matchings and reported the coverage based on successful matchings.
after filtering out all the unsupported regular expressions our reported coverages by rex strings in ascii encoding are based on regular expressions of github projects of them are syntactically unique.
table shows the attributes of regular expressions for which rex could generate strings.
.
.
input string generation.
for each regular expression r we use rex to generate input string sets relative to the size of the matching strings ssucc .
we generate input string sets of three sizes equal to ssucc equal to ssucc and equal to ssucc .
we refer to these experiments as rex1m rex5m and rex10m respectively.
for each experiment we repeated the string generation using the system time as the random seed to encourage diversity among the generated strings.
the averages over five runs rex5m andrex10m or ten runs rex1m for each metric are reported as rex s coverage of r. for example say a regular expression rfrom github has five input strings s .
three of the input strings are matching ssucc .
for this experiment rex would generate three strings ten times then strings five times then strings five times totaling 255generated strings.
for each set of strings nc ec and epc are computed averaged over runs.
in the case of finite languages rex may fail to generate sufficient input strings.
for example the total number of matching input strings in ascii for a regular expression dis ten i.e.
.
if in the repository there are also three matching input strings rex could generate three strings ten times but would fail to generate 15strings.
the calculation of nc ec and epc are based on the best effort for each run of every regular expression we calculate coverage with input strings up to ssucc inrex1m 5x of ssucc inrex5m and 10x of ssucc inrex10m and coverage of every regular expression is the averages of its coverages over runs in rex1m rex5m and rex10m .
in other words if 674esec fse november lake buena vista fl usa peipei wang and kathryn t. stolee rex failed to generate the required number of input strings the coverage is calculated based on the input strings rex can generate.
in the ten runs of generating input string sets equal to ssucc forrex1m there are regular expressions that have fewer input strings than ssucc in at least one run.
in the five runs of generating input string sets 5x of ssucc forrex5m there are regular expressions that have fewer input strings than 5x of ssucc in at least one run.
in the five runs of generating input string sets 10x of ssucc forrex10m there are regular expressions that have fewer input strings than 10x of ssucc in at least one run.
results here we present the results of rq1 and rq2 in turn.
.
rq1 test coverage of regular expressions we address rq1 is two ways.
first we look at the number of call sites to fullmatch methods that are actually tested.
next we look at the test coverage for each tested regular expression .
.
tested call sites.
in the projects there are call sites of the instrumented functions in section .
.
.
however only call sites are executed by the test suites.
this means that .
of the call sites are not covered by the test suites.
for those that are the median of unique regular expressions per tested call site is one with an average of five .
summary of the call sites for fullmatch methods in github projects only .
are executed by the test suites.
.
.
coverage of tested regular expressions.
we successfully generated static dfas for regular expressions from java github projects and dynamic dfas for regular expression input string pairs.1among the regular expressions .
have only failing inputs i.e.
ssucc and .
have only inputs of successful matching i.e.
sf ail .
this means that .
of the regular expressions do not contain test inputs that exercise both the matching and non matching scenarios.
of these .
regular expressions contain only one test string i.e.
s .
there are .
regular expressions with both failed and successful matchings.
table describes properties of the test input sets for each regular expression s is the size of the test suite computed as the number of unique input strings for a regular expression ssucc means the number of matching inputs sf ail means the number of failing inputs succ ratio shows the ratio of successful matchings to all matchings for each regular expression fail ratio shows the ratio of failed matchings to all matchings for each regular expression.
generally tested regular expressions use more failing inputs than successful inputs.
table describes the distributions of node coverage nc edge coverage ec and edge pair coverage epc over s ssucc and sf ail.
figure displays this information graphically with coverage percentage on the y axis and the input string sets s ssucc and sf ail on the x axis.
most of the regular expressions are not tested 1we note that is less than because the mean of input strings s is .
and rounded up to .
2data at .com wangpeipei90 regextestingcoveragedata .git.table description of regular expressions test suites.
all numbers are rounded to the nearest integer except the ratios which are rounded to two decimal places.
attributes mean s ssucc sf ail succ ratio .
.
.
.
.
.
fail ratio .
.
.
.
.
.
table coverage values in figure .
coverage suite mean nc s .
.
.
.
.
.
nc ssucc .
.
.
.
.
.
nc sf ail .
.
.
.
.
.
ec s .
.
.
.
.
.
ec ssucc .
.
.
.
.
.
ec sf ail .
.
.
.
.
.
epc s .
.
.
.
.
.
epc ssucc .
.
.
.
.
.
epc sf ail .
.
.
.
.
.
s ssucc sfail0 100nodenode coverage s ssucc sfail0 100edgeedge coverage s ssucc sfail0 100edge pairedge pair coverage figure coverage for regular expressions.
thoroughly since the mean values of coverage are low especially for edge and edge pair coverage.
although the coverages on failed matchings are relatively small they contribute to a high overall test coverage.
failed matching tests are a necessary part of testing regular expressions and as shown in table sf ail ssucc .
summary a majority of regular expressions .
are tested with exclusively passing .
or exclusively failing .
test inputs.
edge and edge pair coverage are both very low.
on average the set of test inputs contains more failing inputs than successful inputs.
.
rq2 coverage with rex figure shows the analysis results given the generated inputs in ascii encoding organized by each of five datasets.
repo bsand repo bmshow the coverages over sandssucc respectively from regular expressions using the developer defined test suite in 675how well are regular expressions tested in the wild?
esec fse november lake buena vista fl usa repo b srepo b mrex1mrex5mrex10m 100node node coverage 100repo b srepo b mrex1mrex5mrex10m 100edge edge coverage 100repo b srepo b mrex1mrex5mrex10m 100edge pair edge pair coverage figure node edge edge pair coverage of regular expressions with rex generated ascii inputs rex1m rex5m rex10m of regular expressions in github which are used in rex repo bs repo bm .
table coverage values of the regular expressions in github for repo bmandrepo bsin figure .
coverage expr mean nc repo bm .
.
.
.
.
.
ec repo bm .
.
.
.
.
.
epc repo bm .
.
.
.
.
.
nc repo bs .
.
.
.
.
.
ec repo bs .
.
.
.
.
.
epc repo bs .
.
.
.
.
.
table coverage values of the regular expressions using rex for rex1m rex5m and rex10m in figure .
coverage expr mean nc rex1m .
.
.
.
.
.
ec rex1m .
.
.
.
.
.
epc rex1m .
.
.
.
.
.
nc rex5m .
.
.
.
.
.
ec rex5m .
.
.
.
.
.
epc rex5m .
.
.
.
.
.
nc rex10m .
.
.
.
.
.
ec rex10m .
.
.
.
.
.
epc rex10m .
.
.
.
.
.
github details are in table .
rex1m rex5m and rex10m show the coverages of regular expressions based on the rex generated test inputs with sizes of 1x 5x and 10x of ssucc the user defined test suite respectively.
coverage details are shown in table .
table illustrates the differences in coverage between the repository repo bmandrepo bs and rex rex1m rex5m and rex10m .
using a paired wilcoxon signed rank test we find that for all three coverage metrics repo bmsignificantly outperforms rex1m with .
.
however as test suite size is strongly correlated with coverage as soon as the rex test set is amplified to 5x and 10x the size the coverage of rex outperforms the developer coverage.
when considering all test inputs from the repository and not just the successful ones with test inputs sets of the same size repo bs outperforms rex1m .
however this comparison is unfair since rex does not generate non matching strings.
that said as soon as the rex dataset is amplified as in rex5m andrex10m there is no clear winner compared to all test inputs from the repository.
while ittable differences in coverage based on datasets in figure .
hypothesis tests used paired wilcoxon signed rank test.
bold text identifies when one of the datasets had significantly higher coverage for all three metrics.
if there was a conflict between the metrics e.g.
set1 set2 for nc and set1 set2 for epc there was no winner h0 set1d set2 set1 set2 nc ec epc repo bm rex1m p .
p .
p .
repo bm rex5m p .
p .
p .
repo bm rex10m p .
p .
p .
repo bs rex1m p .
p .
p .
repo bs rex5m p .
p .
p .
repo bs rex10m p .
p .
p .
repo bs repo bm p .
p .
p .
may appear that rex can do as well as the repository the reality is that the error node will never be covered by rex a fact which is not apparent by looking at the numbers alone.
summary rex can handle approximately .
of the regular expressions from our dataset.
considering only the matching test inputs and test sets of the same size rex does not achieve coverage as high as the developer written tests.
however the coverage numbers are extremely close.
this indicates that tools such as rex can be used to write test inputs with similar coverage to the developer tests but will always miss neand all edges incident to it.
discussion this section summarizes future work based on our findings and discusses threats to validity.
.
opportunities for future work coverage provides useful stopping criteria for testing.
however high coverage does not necessarily imply test suite effectiveness in source code which may also hold true for regular expressions.
at the same time as regular expressions are responsible for many software faults it is important to explore how to make them less error prone.
our approach in this work is through test metrics and there are many areas of future work that follow 676esec fse november lake buena vista fl usa peipei wang and kathryn t. stolee string generation tools given the low coverage of regular expressions shown in figure a natural next step could be to generate strings to achieve high coverage.
adding a mutation step to the input string may be effective at forcing the rex generated strings into the error state to cover the uncovered edges and node.
an alternate approach may be to provide the complement of the regular expression to rex as another way to generate failing inputs.
with automatically generated strings one threat is usability.
for the developer written tests it is likely that the regular expression strings are more meaningful in context than they are for the rexgenerated strings.
future work will look at the overlap in content between the test inputs from the repository and from rex.
however it may not always be possible to achieve test coverage even with a perfect string generation tool.
there are regular expressions that are untested because they are unreachable.
some regular expressions have hard coded matching inputs which makes it impossible to improve the coverage for example boolean ismatch pattern.matches a b ab future work for improving coverage levels should also consider the potential for improvement based on such factors.
beyond structural coverage the metrics we explore are structural metrics which can identify faults that are revealed in the structure of the dfa such as the example in section .
.
alternately as suggested in prior work refactoring could potentially reveal this particular fault as the numeric representation was found to be more understandable than d. performing the replacement might alert the developer that dshould be d. in terms of improving regular expression testing structural metrics are a first step.
building on the example in section achieving coverage requires a minimum number of test inputs that vary in string length and content.
in the example of d there are strings of length one to length four though strings could be longer to test multiple iterations on the self loop.
strings can contain only digits only non digits or both digits and non digits.
strings can start with digits or start with non digits.
defining such input space partitions may lead to intuitive test sets with high behavioral coverage.
.
threats to validity internal we measure the test coverage of regular expression used in functions of full matching with fullmatch dfas in the forward direction.
the experimental results may not reflect the test coverage of regular expressions used in other functions nor the test coverage of regular expressions which could not be converted into a dfa.
external the java regular expressions used in this evaluation were collected from reporeaper java maven projects compiled with java jdk1.
which is only a small portion of all github java projects and may not generalize to all java projects and to other languages.
it is possible that there are still regular expressions from third party libraries in the dataset which could bias results.
due to limitations of re2 and rex the results of test coverage applies exclusively to the features supported.
all our projects had test suites which may overestimate the test coverage levels for typical regular expressions.
related work regular expressions are used widely in software programs but are often difficult to understand and error prone .
prior work onregular expression comprehension raises a concern about how well the regular expressions used in programs are tested.
although there are papers on program test coverage none of them have specifically discussed testing regular expressions.
software test coverage can be measured at different levels of granularity such as method statement branch integration and unit e.g.
.
symbolic execution is one way to generate inputs and to obtain program test coverage at the level of branches.
there are many tools for automated test generation .
for example reggae aims to mitigate the large space exploration issues in generating test inputs for programs with regular expressions.
with respect to the finite automaton constructed from regular expressions brics contains a dfa implementation with very limited operations while re2 provides a dfa implementation which runs much faster than traditional regular expression engines.
rex builds a symbolic representation of finite automata sfa .
some string solvers and tools for generating testing inputs which use string solvers build finite state automata based on string constraints.
visualizations to aid debugging are powerful techniques for regular expression comprehension and may provide some explanation for low test coverage of regular expressions in source code that is developers use online tools instead.
other techniques and tools have been developed in string generation or regular expression extraction for system fault detection and performance optimization.
rex generates testing inputs for the regular expression according to its sfa representation.
brics generates inputs by traversing the dfa and building strings from the smallest bytes to the largest bytes of every dfa states.
some string generation tools need user specified string length .
egret is focused on generating unexpected test strings to expose the regular expression errors but it is based on common mistakes when creating regular expression rather than maximizing test coverage of regular expressions.
mutrex employs distinguishing strings which can separate a mutated regular expression from the original one to expose system faults.
genetic programming has also been applied to find equivalent alternative regular expressions which exhibit improved performances.
conclusion in this paper we explore coverage over the dfa representation of a regular expression and measure coverage of regular expressions from github java maven projects.
we find that over offullmatch functions are not tested and that most of the tested regular expressions have a low edge and edge pair coverage.
we also show that with the help of the regular expression tool rex it is possible to improve the regular expression testing coverage by adding input strings but that there is an upper bound for this type of improvement.
this work is a first step toward better understanding how regular expressions are tested in the wild future work will explore how various coverage metrics can reduce the bugs associated with regular expressions.