optimizing customized program coverage peter ohmann ohmann cs.wisc.edudavid bingham brown bingham cs.wisc.edu naveen neelakandan neelakandan cs.wisc.edujeff linderoth linderoth wisc.eduben liblit liblit cs.wisc.edu university of wisconsin madison madison wi usa abstract program coverage is used across many stages of software development.
while common during testing program coverage has also found use outside the test lab in production software.
however production software has stricter requirements on run time overheads and may limit possible program instrumentation.
thus optimizing the placement of probes to gather program coverage is important.
we introduce and study the problem of customized program coverage optimization.
we generalize previous work that optimizes for complete coverage instrumentation with a system that adapts optimization to customizable program coverage requirements.
specifically our system allows a user to specify desired coverage locations and to limit legal instrumentation locations.
we prove that the problem of determining optimal coverage probes is np hard and we present a solution based on mixed integer linear programming.
due to the computational complexity of the problem we also provide two practical approximation approaches.
we evaluate the e ectiveness of our approximations across a diverse set of benchmarks and show that our techniques can substantially reduce instrumentation while allowing the user immense freedom in defining coverage requirements.
when na ve instrumentation is dense or expensive our optimizations succeed in lowering execution time overheads.
ccs concepts software and its engineering !software testing and debugging software post development issues software performance mathematics of computing !integer programming keywords debugging mixed integer linear optimization program coverage .
introduction program coverage data identifies which program features executed during one or more runs of a program.
program coverage is commonly used as a quality metric for test suites developers wish to ensure that a test suite exercises an adequate portion of their code base.
however developers also use program coverage in othercontexts such as postmortem program analysis and fault localization .
many granularities of coverage are possible.
for example statement coverage identifies the set of statements that executed during a run.
coarser granularities such as function coverage gather coverage data for a smaller set of program points providing less detailed information but with lower run time overhead.
finer granularities such as path coverage make the opposite trade higher run time overhead for more detailed execution information.
this paper targets uses of program coverage in low overhead monitoring of deployed applications.
specifically we optimize instrumentation for binarized control flow coverage metrics i.e.
coverage data marks each program location as covered or uncovered rather than counting the number of occurrences .
we focus on statement and edge coverage which prior work has shown to be useful in postmortem debugging and amenable to residual monitoring .
that is we reduce the instrumentation required to track which program points were covered for a particular execution .
in many scenarios one may not require or cannot a ord to gather full coverage information for a program run.
this is especially true after deployment deployed software is already partially tested and only tolerates small run time overheads.
sparse tracing also means sending less data back to developers in field reports.
further developers often do not require full information from these reports.
for example developers may focus on code features e.g.
call sites likely to be useful for debugging or program analysis.
alternately they may desire coverage only for newly added code or code not adequately tested before release .
conversely security sensitive code tightly optimized code or code with strict real time requirements may be o limits for monitoring.
optimization for gathering program coverage is well studied see section .
agrawal and tikir and hollingsworth optimize probe placement for binarized statement coverage.
unfortunately agrawal s approach is not applicable for incomplete executions such as those that terminate unexpectedly due to a fatal signal.
support for aborted runs is important if post deployment failure data is to include coverage information .
however low cost coverage tracing is especially important in these deployed scenarios as only small amounts of run time overhead are tolerable.
further neither agrawal nor tikir and hollingsworth optimizes for incomplete or constrained coverage requirements.
deployed software calls for customized coverage information coverage at a subset of program locations such as those not exercised by a test suite or those containing features interesting for debugging .
in this paper we present three approaches that select a smaller set of coverage probes given instrumentation restrictions and a set of program points of interest.
we prove that the resulting problem 1source code is available as part of the csi instrumentation framework at http pages.cs.wisc.edu liblit ase b code .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
is np hard so the existence of a fast algorithm for computing the optimal set of probes is unlikely.
our first approach constructs a mixed integer linear program milp whose solution identifies the optimal probe set however solving this milp to optimality requires prohibitive analysis time during instrumentation.
we therefore o er two approximation approaches.
the first approximation is very inexpensive to compute but provides no optimality guarantees the second finds a locally optimal approximation.
the primary contributions of this work are as follows we define the customized coverage probing problem and formalize the notion of a coverage set for customized coverage criteria.
we argue the problem s significance and applicability to common problems in monitoring deployed applications.
we prove that the customized coverage probing problem is np hard via a reduction from work by maheshwari .
we present three approaches to tackle this problem an optimal solution implemented as a milp and two approximations with varying degrees of optimality and computation cost.
we perform an extensive evaluation of our approaches.
in agreement with prior work on full coverage optimization we find that even coarse approximations can statically eliminate much instrumentation.
when na ve instrumentation imposes large overhead our optimizations significantly reduce both compilation and run time costs.
this paper is organized as follows.
section formally defines the customized coverage probing problem and argues for its applicability to common problems using program coverage for deployed applications.
section describes our three approaches which we then evaluate in section .
section positions our work in the context of prior research.
section concludes.
.
customized coverage our goal is to determine an optimal instrumentation plan to gather customized binarized program coverage information.
more concretely we are given a single procedure s control flow graph cfg g some subset of the vertices in gfor which the developer desires information d and another subset of the vertices in gdefining legal observation points i. the problem is to determine the cheapest set of probes to insert into locations from isuch that for any given path pthrough g the set of probes encountered along pis su cient to determine which vertices from dwere traversed along p. .
input the input to the problem is as follows g v e a directed graph with vertices vand edges e e2v a unique source or entry vertex with in degree i v a subset of vertices that may be probed instrumented ci the cost of probing vertex i2i where8i2i ci d v a set of desired vertices that must be covered x v a set of possible termination points .
problem definition definition forv1 v22v v1!v2denotes the set of all paths from v1tov2ing.
ifv1 v2 then the trivial path crossing no edges is included in this set.
definition v p denotes the set of all vertices encountered along path p including the start and end vertices of p. ifpis the trivial path from vertex v crossing no edges then v p is the singleton setfvg.e a original control flow graphe q b multiple function executions figure example control flow graph with transformation for multiple function executions definition a set of vertices s iis called a coverage set ofd if8x2xand8p1 p22e!x v p1 s v p2 s v p1 d v p2 d. that is two executions ending at the same termination point x2xthat encounter the same svertices must encounter the same dvertices as well.
contrapositively paths that encounter di erent dvertices must be distinguishable by encountering di erent s vertices as well.
problem statement thecustomized coverage probing problem is to find a coverage set sofdsuch thatp s2scsis minimal.
.
discussion we desire the lowest cost coverage set of d. put another way the goal is to find the cheapest set of probe vertices s i such that the resulting observations v p1 sandv p2 s are su cient to derive desired coverage information v p1 dandv p2 d for all executions whether terminating normally or abnormally 8x2x .
ifd i then a coverage set of dexists since we can set s d. however the existence of some sthat satisfies definition does not imply that d i. that is we may be able to infer coverage information for d2dwithout probing ddirectly.
the cost of probing each vertex ci is input to the problem.
to minimize the expected run time cost of instrumentation these values should represent the expected execution frequency of each i2i which could be derived from static heuristics or profile data .
however other cost functions can minimize the static number of probes inserted or prioritize instrumentation locations based on real time requirements or security concerns.
see section for computation of these values in our evaluation.
.
encoding specific problems we now describe how to encode specific realistic requirements as instances of our problem.
figure 1a shows an example cfg with entry vertex e. using this graph as g v e one can obtain full local statement coverage data with i d vnfeg.
assuming the program could crash at any statement we can also let x v. we thus obtain full coverage data for any local execution i.e.
if coverage information is stored in the program stack and for functions known to execute exactly once e.g.
the main function .
to handle multiple executions of the instrumented function one performs a simple graph modification add a new vertex qrepre28e xd y1 all paths not crossing fdg y2 all paths not crossing fdgp some path not crossing sny fdgp d some path not crossingsnypd some pathnot crossing sny figure pictorial representation of an ambiguous triangle senting any execution from the rest of the program as shown in fig.
1b.
for full statement coverage we then let i d vnfe qg.
usually we say that q2x indicating that execution may terminate outside the current function.
if we can statically determine that the program cannot crash in the function or we only need coverage data for complete executions we can set x fqg.
for edge coverage instead of vertex coverage we split each edge in the cfg.
let v0 be the set of new vertices added on these split edges.
full edge coverage is then encoded by i d v0.
in some contexts one need only gather coverage information for a specific set of statements or edges.
for example prior work in debugging and program slicing focuses on call statements .
in this case dis the set of basic blocks containing call statements.
other work gathers residual coverage information for deployed applications based on statements or branches not covered during in house testing .
here dis the set of non covered blocks or edges using the edge splitting method described above .
beyond well studied cases many others are possible.
one might reduce runtime cost by removing some portion of the hottest blocks from i as identified by standard profiling.
with previous post deployment failure analysis data one might set dto program locations whose execution status was unknown in the failing execution.
after a product release developers could isolate new failures by setting d to recently changed code.
alternately one might exclude securitysensitive code or code with real time requirements from i. .
proof of np hardness to show that the customized coverage probing problem is nphard we show that a known np complete problem reduces to our problem in polynomial time.
maheshwari proves that determining the optimal placement for traversal markers in acyclic cfgs is np complete.
specifically given an acyclic cfg g v e one can enumerate the set of source sink paths through g p g then for all p2p g define e p as the set of edges along p. maheshwari proves that determining the minimum size set of edge traversal markers m e such that each p2p g traverses a unique set of traversal markers is an np complete problem.
formally the problem is to find m esuch that for all distinct p1 p22p g m e p1 m e p2 and for all m0such thatjm0j jmj there exist distinct p1 p22p g such that m0 e p1 m0 e p2 .
note that traversal markers and coverage probes yield precisely the same information for acyclic graphs no edge may occur more than once in any path because there are no cycles and the order of any pair of edges is fixed if both may occur along the same path because there would otherwise be a path containing a cycle .
thus while maheshwari s original intent was to prove that minimal probing to distinguish all paths in an acyclic cfg is np complete the same proof also shows that minimizing the number of edge probes to obtain full edge coverage information is np complete.
transforming a traversal marker placement problem into a customized coverage probing problem is straightforward.
given a cfgg v e we split each edge to instrument for edge coverage as in section .
.
then an optimal solution to the customized coverage probing problem with input i d v0nv c i for all i2i is also an optimal traversal marker placement.
the transformation is polynomial as splitting each edge is simply an o e operation.
therefore the customized coverage probing problem is np hard.
.
approach this section describes our solution to the customized coverage probing problem and two approximations.
first in section .
we give a characterization of a coverage set that can be checked in polynomial time.
using this new characterization section .
outlines a milp to identify the optimal coverage set.
section .
describes a dominance based approximation however this approximation provides no optimality guarantees.
we build on this approach in section .
to formulate a second approximation that finds a locally minimal coverage set.
finally section .
touches on recovery of full coverage information from optimized instrumentation.
.
checking sufficiency of coverage sets as a first step we must devise a su ciency check for a candidate coverage set s i. that is we would like a simplified condition relative to definition in order to check whether any given set s is a coverage set of d. recall that dis the set of desired vertices and that sis a coverage set of dif and only if coverage information forsunambiguously allows one to determine coverage information fordon any execution path.
definition is given with respect to all paths through gending at some x2x for any graph with loops there may be infinitely many such paths.
intuitively however many of these paths are redundant with respect to s s coverage set status.
we formalize this intuition by narrowing our search to finding ambiguous triangles in which some d2dmay or may not occur between observation vertices and .
the condition is represented pictorially in fig.
.
as input we have all items from section .
and some s i a candidate coverage set for d. in fig.
wavy lines represent paths crossing or more edges.
the core of this approach lies in finding an ambiguous triangle composed of paths p d p and pd .
such a triangle represents an ambiguous region of execution between observation points that demonstrates that salone is not su cient to determine if dexecuted.
conversely sis a coverage set of difsallows no ambiguous triangles in g. an ambiguous triangle is a triple d such that is either the entry vertex or an observation point from s is either from sor a possible termination location and d2d and dmay or may not occur on paths !
that contain no other new observations.
29to define new observations above we must define sets y1 y2 and y. the set y1contains all d free paths from the entry vertex to .
the set y2contains all d free paths from to a possible termination location.
if d2x then dis excluded as a possible final location since ending at dimplies the observation and hence execution of d. the set ycontains all vertices along paths in y1 y2.
these vertices may occur before or after !
paths and hence any vertices in y sprovide no new information along !
paths.
if y1 then ddominates on all paths through g hence will not provide a useful witness as doccurs on allpaths through .
conversely if y2 then dpost dominates with respect to all termination points hence will not provide a useful witness as d will occur on allpaths through .
note that we can form paths p1 andp2from definition by conjoining appropriate paths from y1 andy2to the two paths through the ambiguous triangle.
to formalize the above we require one new definition definition connected excluding for vandv1 v22v letv1 !v2denote the set of paths from v1tov2thatdo not cross any edges with a source or target vertex .
this definition includes trivial paths.
that is for v2v v !v is nonempty for any v even if v2 .
then for all d triples where 2s feg 2s x d2dns we define the following sets y1 e fdg !
p d sny !
d y2 x2xnfdg fdg !
x p sny fdg !
y 2y1 y2v pd d sny !
then set sis a coverage set of dif and only if y1 y2 p d p pd for all d triples defined above.
note that these five disjuncts correspond precisely to the five necessary parts of the ambiguous triangle pictured in fig.
and those necessary to form paths p1and p2from definition .
thus if all five of these subpaths exist for any d triple then sis not a coverage set of d. as an example consider the cfg in fig.
1a and the input configuration x f6gand d f5g.
candidate coverage set s f1 7gis not su cient to cover d because the paths he 6iand he 6icontain the same set of svertices f1 6g but 2contains 52d while 1does not.
note the key di erence highlighted in bold the instrumentation cannot distinguish a h3 6iloop iteration from a h3 6iiteration.
in terms of an ambiguous triangle we have y f1 6g h3 5i2p d y1.vertices f1 6g h 6i2p y2.vertices f2 6g h 6i2pd again we see the exact same ambiguity.
because of observations on prior and or future loop iterations y1andy2 the execution of vertex does not preclude the execution of vertex and we have an ambiguous triangle formed from subpaths h3 6iandh3 6i.
consider a few special cases.
if s d then sis always a coverage set of d as no possible vertex for dexists i.e.
dns .this aligns with section .
s claim that if d i the instrumentable set then iitself is a coverage set of d. ifs then sis a coverage set of di 8d2d doccurs on either all or no paths from the entry to any termination point.
in this case e 2x and y s .
thus by the definition of p d p and pd sis not a coverage set of difdmay or may not occur on paths from eto 2x.
all of our approaches assume that iis a coverage set of d. in practice one might consider cases where this is untrue and ask for maximalcoverage given a limited iset .
fortunately because each d2d is independent we can find the maximal d0 dthatican possibly cover by letting d0 fd2dsuch that iis a coverage set of fdgg.
.
optimal milp formulation as shown in section .
obtaining an optimal solution to the customized coverage probing problem is np hard.
using the characterization in section .
we are able to construct a mixed integer linear optimization problem milp whose solution identifies the optimal coverage set.
due to space limitations and the intractability of obtaining an optimal solution see section we give only an overview of the formulation the complete milp model can be found in our companion technical report .
to begin we can define all possible ambiguous triangles for all possible sets s ias the set of triples of vertices t f d i feg i x dg.
then for each d 2t we define the additional set of vertices y d x2x e fdg !
fdg !
x v for each d triple the set y dcorresponds exactly to the y set from section .
.
that is it contains all vertices along d free paths from eto y1 or to some termination point y2 .
we can compute this set by checking basic graph connectivity.
these sets are provided as input to the milp model.
the goal is to find s a minimal cost coverage set of d. we first introduce the binary selection variables zi i i2s to represent the selected coverage set.
next we use five sets of binary variables one for each path set in the coverage set characterization from section .
to force the associated set to be empty s d will imply that e fdg !
t d will imply that fdg !
x 8x2xnfdg u d will imply that sny d !
d v d will imply that sny d fdg !
w d will imply that d sny d !
the model is constructed as a network flow problem.
each of the above variables is accompanied by a set of constraints that force the non existence of the respective path by constraining the dual flow equations induced by the program s control flow graph and basic linear programming duality theory farkas lemma .
recall from section .
that sis a coverage set of dif and only if at least one of these five sets of paths is empty for all d 2t.
these paths are only relevant when zd because instrumented vertices are always observed.
to force this condition we thus introduce the constraint s d t d u d v d w d zd d 2t 30e figure dominator tree for fig.
1a global willinst the set of vertices that will be probed global willcover the set of vertices for which coverage information will be available input g v e a single function control flow graph input e2v the entry vertex input i v vertices that may be probed input c v7!r costs for vertices input d v vertices with desired coverage input x v possible ending vertices output willinst i a coverage set of d t dominator tree for g with entry vertex e ord t any bottom up ordering of t.vertices willinst willcover cancover needinst foreach vinord t do coveredchildren t.children of v willcover if exitwithout v coveredchildren x then willcover fvg cancover fvg else cancoverchildren t.children of v cancover vneedinst exitwithout v cancoverchildren x ifv2i vneedinst then cancover fvg ifvneedinst then needinst fvg ifv2dthen ifv cancover then return fail else cover v cancover needinst t x c return willinst figure dominator based approximation in the end our objective is to minimize cost x i2vcizi subject to the above forcing constraint on program paths and the relevant constraints for each of the five classes of paths.
this approach is guaranteed to provide a provably optimal coverage set but unfortunately is too slow in practice.
in fact we were only able to evaluate the fully optimal approach on our smallest test subjects see section .
there are a number of reasons for this.
the formulation requires pre computation of the sets y d which is quartic in the number of vertices in g. further even with powerful commercial software solving a large scale milp still relies on enumerating an often large branch and bound search tree.
fortunately safe and fast approximations of the optimal result are possible.
.
an inexpensive approximation several prior approaches optimize coverage probes by using the dominance relation among basic blocks .
a basic block vfunction exitwithout v children x input v the vertex possibly covered input children a subset of v s immediate dominator children that may provide coverage information for v input x possible ending vertices return9xsuch that x2xandvdoes not dominate xand v children !
x figure test for an exit bypassing dominator children dominates a basic block wif and only if e fvg !
w .
immediate dominance relations for any single entry directed graph form a tree and algorithms for computing dominators are well known .
figure shows the dominator tree for the example from fig.
1a.
in this section we develop an inexpensive approximation algorithm based on dominator information rather than the su ciency condition from section .
.
our approach performs a bottom up traversal of the dominator tree covering a block s subtrees only as necessitated by the desired set d. this approach is inspired by agrawal and tikir and hollingsworth but supports customized coverage.
most accurately our approach generalizes these prior approaches which could be considered special cases of our algorithm for only complete executions and full coverage .
a vertex v can be covered i.e.
guaranteed accurate coverage information for any execution in two possible ways.
first vitself may be instrumented so that its coverage is observed directly.
second we might instrument an appropriate subset of v s dominator tree descendants such that all executions through vmust execute at least one vertex in the descendant set.
clearly for this approximation we must instrument all leaves of the tree.
internal block vmust be instrumented only if v s dominator tree children cannot cover v. in our case vis instrumented if a path exists in g from vto some x2xthat bypasses all of v s covered children in the dominator tree and such that vdoes not dominate x .
by the definition of dominance any time a descendant of vexecutes including a crashing execution it implies the execution of v. intuitively if the program can halt after executing vwithout an observation implying v s execution then v s coverage data is unknown on some execution.
for example consider vertex in fig.
and a crash x i.e.
the program halts in block .
then the subset of dominator children f4 5gis su cient to cover in fig.
all paths from to must pass through some element of f4 5g.
likewise f6gwould also cover any cfg path from to must pass through .
of course both alternatives assume that iincludes the necessary instrumentation points.
if idisallows bothf4 5gandf6gas instrumentation plans then can only be covered by direct instrumentation of itself.
figure details our algorithm.
the global set willinst builds up the final result the set of basic blocks to be probed for coverage.
the global set willcover tracks which blocks will be guaranteed to have accurate coverage information available.
hence as vertices are added to willinst willcover is updated to reflect the newly covered nodes.
the overall goal is to make d willcover .
first we compute t the dominator tree of g and any bottom up ordering oft s vertices ord t .
then we iterate over each vertex in ord t adding those vertices from ithat require instrumentation to the set willinst .
during this iteration we discover which vertices can only be covered via direct instrumentation stored in set needinst and which could possibly be covered either via direct instrumentation or via their dominator descendants stored in set cancover .
in the loop we first find v s dominator children that are already covered coveredchildren .
if these vertices are already su cient to cover v no path exists from vto an exit or crash bypassing 31procedure cover v cancover needinst t x c input v2cancover the vertex to cover input cancover a pre computed set of vertices that could be covered input needinst a pre computed set of vertices whose coverage information can only be determined by direct probing input t the dominator tree for the function containing v input x possible ending vertices input c costs for vertices ifv2needinst then willinst fvg else cancoverchildren t.children of v cancover assert exitwithout v cancoverchildren x removablechildren cancoverchildren nwillcover foreach winremovablechildren ordered by cdo ifexitwithout v cancoverchildren nfwg x then cover w cancover needinst t x c else cancoverchildren n fwg willcover fvg figure cover a dominator tree vertex the covered children as defined in function exitwithout from fig.
then vis added to willcover andcancover .
otherwise we gather all of v s dominator children that possibly could be covered cancoverchildren .
because we process tbottom up cancover already contains all of v s dominator children that could possibly be covered.
if cancoverchildren is insu cient to cover v then vis added to needinst .
ifvcan be covered by its dominator children or can be directly instrumented vis added to cancover .
at this point ifv2d we want to find a cheap coverage set for v. however note that this approximation assumes that a vertex can only be covered by its dominator descendants which is not always true.
if we desire coverage for vbutv cancover then the algorithm fails to find a coverage set for d. this situation is rare in practice and another approach see section .
could reduce the size of iin this case.
if v2cancover we find a coverage set for vvia a call to cover .
procedure cover in fig.
walks back down the dominator tree in order to cheaply cover vertex v. first if vcannot be covered by its dominator children i.e.
v2needinst then we instrument vto obtain its coverage data.
otherwise we iterate over all of v s dominator children that can be covered sorted by cost to try to avoid instrumenting the costliest vertices.
for each child w ifwis already covered we skip it.
otherwise if wis necessary to cover v as determined by the call to exitwithout we must recursively cover w. after the completion of cover vis covered either via direct instrumentation or via calls to cover on its descendants.
thus we pass each vertex as argument vto cover at most once since vis added to willcover at the conclusion of cover and will be excluded from removablechildren in future calls.
our approach is most similar to that of tikir and hollingsworth who instrument a basic block v whenever vis either a leaf vertex in the dominator tree or has an outgoing edge in g to a block that vdoes not dominate.
this is equivalent to our approach in the un customized special case of i d x v since any such outgoing edge from vtargets a possible halting location.
however our approach handles the full range of input from section allowing us to optimize coverage with far more degrees of flexibility.
we look for paths to any non dominated termination point and only cover vertices where necessitated by d .input i v vertices that may be probed input c v7!r costs for vertices input d v vertices with desired coverage output s i a locally optimal coverage set of d assert iis a coverage set of d s copy i tryremove sortibyc foreach iintryremove do ifsnfigis a coverage set of d then sn fig return s figure locally optimal approximation .
locally optimal approximation the approach in section .
is computationally inexpensive it calls cover on each block at most once and therefore traverses each dominator tree vertex at most twice.
however it provides no guarantees on the optimality of the obtained willinst set.
in fact as noted in section .
it is possible that the dominator based approximation will be unable to find any coverage set s i even if at least one such set exists.
this is the return fail case in fig.
.
we can compute a locally optimal coverage set in polynomial time by iteratively testing smaller and smaller candidate coverage sets via the conditions in section .
.
by these conditions a candidate coverage set scan clearly be checked in polynomial time.
for each d triple arising from our current choice of s we .compute y which requires two depth first or breadth first search passes one to gather all possible vertices along paths e fdg !
and one to gather vertices along paths fdg !
x .
check for the existence of any path sny !
d .
check for the existence of any path sny fdg !
and .
check for the existence of any path d sny !
.
each of the three connected excluding tests again requires a single depth first or breadth first search.
if for any d triple each of the collected vertex sets from item are non empty and a path exists for all items to then sisnota coverage set of d. a coverage set sis locally minimal with respect to dwhen s is a coverage set of d and8s0 s s0is not a coverage set of d. figure gives the direct approach.
we begin with s i a coverage set of dby assumption and iteratively attempt to remove each element of s. removing vertices from scan never cause sto cover more vertices.
thus if sis a coverage set of d then8s s s is also a coverage set of d. contrapositively if sisnota coverage set ofd then8s s s is not a coverage set of deither.
this approach has polynomial time complexity but performs redundant computation and is too ine cient for practical use.
we improve performance using a number of optimizations and heuristics.
we begin by reducing our initial iset by a call to our dominatorbased approximation .
if this approximation returns fail then icannot be proven a coverage set of dusing only dominance relations and we begin with the full user specified iset.
as fig.
shows we heuristically attempt to first remove the costliest vertices from s. we pre compute v y1 for each d pair and v y2 for each d pair as these sets are not dependent on the choice of s. we also perform substantial pruning of possible d triples.
for example as fig.
illustrates all possible vertices must precede d 32table evaluated applications ordered by size.
compilation times are scaled relative to for standard clang with no instrumentation.
marks compilations that did not complete within hours.
relative compilation time basic block coverage call coverage application description versions mean loc none dominators local none dominators local tcas siemens schedule2 siemens schedule siemens replace siemens tot info siemens print tokens2 siemens print tokens siemens ccrypt linux utility gzip linux utility space adl interpreter exif linux utility bc linux utility sed linux utility flex linux utility grep linux utility bash linux shell gcc c compiler and all must follow d. finally we find that in practice ambiguous triangles tend to exist in close proximity to the un covered d2d.
in other words the length of paths in sny !
d sny fdg !
andd sny !
tends to be short.
thus we prioritize testing and vertices crossing the fewest edges from d. overall though our approach does not fundamentally di er from fig.
.
we are actively searching for optimizations and heuristics that increase performance particularly for large complex cfgs.
recall that the approach is approximate any solution scontains no unnecessary blocks to cover d but other less costly instrumentation plans may exist.
thus as stated in the context of our milp from section .
this approach results in a locally optimal solution.
.
recovering coverage data extracting desired coverage data from gathered probes can be somewhat complex in cases of aggressive probe optimization.
for most prior work in coverage optimization full coverage data can be derived using nothing more than gathered coverage data and a function s dominator post dominator trees.
however our approaches except for that in section .
use more complex reasoning.
fortunately our prior research recovers complete coverage information based on incomplete data.
the data we collect here can be fed directly into our existing recovery algorithms with no changes to the latter whatsoever.
.
ev aluation we evaluated our techniques across a wide variety of c benchmarks.
our evaluations assess the e ciency of our instrumentation as compile time overhead to optimize coverage probes and generated probing schemes as probe counts and run time overhead .
.
experimental design we implemented the techniques described in section for c c programs.
we extended our existing instrumenting compiler csi cc built with clang llvm .
.
csi cc already has support formaintaining in memory coverage data post crash.
we use llvm s built in blockfrequency analyses to determine costs cifor each i2i as input to our approach.
this statically approximates the execution frequency of each block but is realistic since even a run time profile approximates post deployment behavior.
we ran two sets of experiments.
first we optimized for full statement coverage i d v. second we optimized to gather coverage at call sites i d fbasic blocks containing at least one call site g. call site coverage is an example of customized coverage that cannot be optimized by any prior approach.
note the slight di erence from call site coverage as described in section .
where we propose allowing instrumentation anywhere i.e.
i v .
in practice we have found that llvm s static cost model is not always a good representation of run time costs which means that our approaches may be driven to choose more expensive instrumentation plans.
by setting i d we ensure that our optimizations can only remove probes they cannot for example cover basic block bby inserting new probes into b s dominator descendants present in ibut absent from d to assure coverage of b. note that inaccurate cost data is a threat to run time e ciency but never to correctness.
that is our approaches can never select a result sthat is not a coverage set ofd even if sresults in suboptimal run time performance.
in all cases we optimize coverage assuming programs may crash at any statement x v. we ran all experiments on a quad core intel core i5 cpu clocked at ghz with gb of ram and running red hat enterprise linux .
.
table provides details for our subject programs.
we obtained most of these applications from the software artifact infrastructure repository .
the exceptions are bc ccrypt exif and gcc these are real world programs.
we ran experiments over the nonfaulty builds of most applications gcc and exif used builds with a known fault.
some of the applications had multiple versions as indicated by the versions column of table .
note that we exclude fully optimal coverage results from all experiments.
our implementation of the milp formulation from section .
either exceeds our compilation time limit hours or runs out of memory for all but a selection of the small siemens 33siemens ccrypt gzip space exif bc sed flex grep bash gcc0 352percent of unoptimized probe count a static probe counts for full basic block coverage siemens ccrypt gzip space exif bc sed flex grep bash gcc0 377percent of unoptimized probe count b static probe counts for call site coverage no optimization dominator approximation locally optimal figure coverage probe counts.
all bars are scaled to for no optimization to show how much relative reduction the locally optimal and dominator based approximations achieve.
numbers within each bar are mean counts without scaling.
for example at the left edge of fig.
8a the siemens benchmarks average probes with no optimization but just probes with the dominator based approximation probes have been optimized away.
in relative terms these siemens benchmarks have just as many probes with dominator based optimization as they do with no optimization .
benchmarks.
our locally optimal implementation from section .
compiles of our benchmarks for full statement coverage and benchmarks for call site coverage within the time limit.
.
optimization and compile time for each version of each application we first measured the wallclock time to perform each of our optimization approaches and instrument the program.
these results are shown in table relative to a base build with clang o3 a value of .
indicates no compilation time overhead.
we built each application version at least three times and divided by base compilation time.
we then took the geometric mean to aggregate across all versions to avoid over representing specific versions .
the none columns indicate compilation overhead for instrumenting all i2ifor the selected option.
the dominators columns show overhead for the dominator based approximation from section .
.
the local columns show overhead to obtain a locally minimal solution.
in all cases we instrumented functions to gather local coverage data see section .
storing coverage data within the program stack at run time.
storing coverage data in memory results in substantially smaller absolute overheads and is common in practice .
the results are grouped into statement coverage results gathered as basic block coverage and call site coverage results.
without optimization there is a cost of to compile benchmarks for coverage.
however the dominator based optimization is extremely inexpensive often saving time over full instrumentation.
we believe that the extra cost results from generating and inserting the required probing code.
the overhead of locally minimal optimization varies greatly between benchmarks.
we find that large complex functions take a disproportionately long time to optimize.
for example gzip s base compile time averages under seconds but computing a locally optimal solution requires over .
hours dominated by 3functions that consume over of the total time.
as we discuss in section .
the approach has polynomial time complexity however the description in section .
indicates that in the worst case we must consider all possible d triples in order to prove that a particular s iis a coverage set of our desired set d. restricting the set of desired blocks d reduces the number of d triples considered by our locally optimal approach and should reduce optimization time.
our call site coverage compilation results confirm this we find substantially smaller compile time overheads when compiling for coverage only at call sites.
for example while gzip s compile time increases from .
seconds to just over minutes this is far below the increase we see for optimizing full statement coverage.
these improvements allow us to compute locally optimal solutions for two additional benchmarks grep and sed .
however benchmarks still do not complete compilation and sed exhibits a slowdown thus scalability remains a concern for our locally optimal formulation.
.
static probe counts we also gathered the total number of probes inserted by each approach to examine the static reduction in probe insertions for our optimizations.
we again took the mean of probe counts for di erent versions of each application.
we also aggregated results for all siemens applications to simplify presentation.
probe reductions are very similar across all siemens benchmarks of non trivial size.
figure 8a shows results for full statement coverage.
as noted in section .
since i d x vfor full statement coverage our dominator based approximation is equivalent to the optimizations of tikir and hollingsworth in this specific scenario.
stacked bars indicate the percentage of the unoptimized probes still included after the specified optimization.
hence for example bc with the dominator based approximation reduces the probe count by approx34siemens ccrypt gzip space exif bc sed flex grep gcc0 percent of unoptimized probe count a dynamic probe executions for full basic block coverage siemens ccrypt gzip space exif bc sed flex grep bash gcc0 percent of unoptimized probe count b dynamic probe executions for call site coverage no optimization dominator approximation locally optimal figure dynamic probe executions.
all bars are scaled to for no optimization to show how much relative reduction the locally optimal and dominator based approximations achieve.
mean counts without scaling are omitted due to space limitations.
imately relative to unoptimized instrumentation.
the locally optimal approach further reduces the probe count cutting the remaining probes to just below half of the original set.
those applications that cannot be compiled within our time limit exclude locally optimal results in the figure.
overall probe reductions are substantial.
our dominator based approximation is inexpensive but still reduces probe counts by over on average.
the locally optimal approach is substantially more expensive as seen in table but further reduces necessary instrumentation to just of unoptimized instrumentation for completed benchmarks on average.
the main thrust of our approaches however comes in their ability to optimize instrumentation based on customized coverage requirements.
figure 8b presents results for call site coverage.
note that prior work cannot optimize coverage probes in this scenario.
here the unoptimized instrumentation set is much more selective.
reductions are smaller across all benchmarks but for most applications we still see substantially less instrumentation.
the dominator based approximation reduces probe counts by up to space and averages a reduction across all benchmarks.
the benefits of the locally optimal approach are very pronounced.
for those applications that completed local optimization we see an average further reduction of from the dominator based approximation with total reductions as high as space relative to unoptimized .
.
dynamic probe counts with the completed builds we then gathered the total number of probe executions at run time to assess the dynamic impact of optimizations.
we ran each application through its corresponding test suite.
we gathered the count for each trial and computed the percentage reduction for each level of optimization.
we took the arithmetic mean to aggregate across each complete test suite and aggregated the resulting values across all versions of each application to avoid over representing specific versions or long running test cases .
we again aggregated results for the siemens applications which exhibit similar run time performance.figure 9a shows dynamic probe execution reductions for full statement coverage.
we excluded one test case for gzip that exceeds our hour timeout for extracting probe counts.
we omit bash results as bash s test suite is highly sensitive to our probe counting infrastructure with dense statement coverage.
stacked bars are scaled to the number of executed probes for the unoptimized variant.
again i d x v and our dominator based approximation is equivalent to tikir and hollingsworth .
for all of the applications even this approximation results in a substantial drop in overheads in fact all applications lose at least of their probe executions while simultaneously shrinking compile time per table .
ccrypt sees the largest reduction executing just of the unoptimized probe count.
although expensive to compute overhead reductions from further reducing probes via the locally optimal formulation are sometimes substantial.
for example after the dominator based approximation reduces gzip s probe executions by our locally optimal approach removes more probes reducing probe executions to just relative to uninstrumented code ccrypt is reduced to just of the unoptimized count.
of course as mentioned earlier this run time performance may come at a cost gzip s compile time increases from seconds to hours when moving to a locally optimal solution.
overall the performance of the dominator based approximation is quite impressive.
our locally optimal approach presents a significant trade o it does often remove significantly more probes see fig.
8a but at a very high compilation cost see table .
figure 9b presents call site coverage results.
we exclude out of bash test cases due to time out.
here unoptimized probe executions are much smaller and reductions from the dominator based approximation are less pronounced.
nevertheless some applications see significant benefit.
for example exif and space both execute just of the unoptimized probe counts.
our locally optimal approach however is very impressive.
while some applications see less benefit e.g.
gzip many applications see enormous reductions.
for example bc and ccrypt both reduce probe executions by beyond the reductions of the dominator based approximation.
35we also assessed the statistical significance of the results from fig.
.
we conducted a wilcoxon signed rank test between test cases with each level of optimization.
for all results we find sufficient evidence p to reject the null hypothesis that our optimizations have no e ect on dynamic probe executions.
.
running time the results from figure do not depend on probe costs but real impacts on running time depend on the cost to execute each probe.
we measured execution times of each program s test suite measuring overheads relative to clang o3 as a baseline.
we used inline in memory probes which impose far smaller overheads than would be seen if data were occasionally flushed to disk or if probes required function calls to record data.
even so we observe significant reductions particularly with statement coverage.
mean overhead for the non trivial benchmarks shrinks from .
to .
using the dominator based approximation.
although expensive to compute the locally optimal formulation can provide substantial additional benefit.
for example the dominator based approximation reduces gzip s overhead from .
to .
our locally optimal formulation reduces this further to just .
relative to uninstrumented code.
for call site coverage our optimizations did not measurably reduce running time.
this is surprising given the reductions shown in fig.
9b.
however our in memory binary probes are already quite fast and the majority of our test cases do not run long enough to exhibit large overheads.
if probes were more costly we would expect much more pronounced results.
further the larger numbers of probes used for statement coverage show a correspondingly larger optimization benefit.
we again used a wilcoxon test and found our statement coverage reductions to be statistically significant p for each non zero overhead reduction .
overall our results show we can significantly reduce the static and dynamic cost of customized coverage instrumentation.
we specifically evaluate customized coverage of call sites where required coverage information is already substantially reduced.
even so our techniques reduce static probe counts by as much as space in fig.
8b and dynamic probe executions by up to ccrypt in fig.
9b .
even when the absolute numbers are not large these reductions should not be discounted these may be very important in systems with real time requirements or for deployed software.
.
related work closely related work optimizes placement of binarized coverage probes.
agrawal optimizes probes by forming superblocks from sets of basic blocks based on dominance and post dominance relations.
later agrawal extends this work to interprocedural dominance relations li et al.
and xu et al.
extend these optimizations beyond superblocks.
tikir and hollingsworth also optimize coverage probe placement via dominators but use a faster simpler approach and no post dominance information for online instrumentation.
our approximation in section .
is inspired by many of these prior approaches.
however because we support multiple crash points via input parameter x we cannot directly take advantage of post dominator information as in agrawal.
further because we allow customization of desired and instrumentable locations we develop a generalization of these existing approaches facilitating many coverage optimization scenarios that are not supported by any prior work.
particularly for local coverage data i.e.
without the transformation from fig.
1b our approaches can optimize instrumentation more aggressively than any prior approach.
binarized coverage only needs to observe each probed location one time once a coverage value becomes true it stays true.
building on this insight prior work optimizes coverage gathering via dynamicinsertion and deletion of probes .
these techniques are complimentary to our own we optimize where to insert probes while such techniques address how andwhen to insert probes.
many commercial tools gather program coverage over test suites e.g.
.
these tools gather complete program coverage whereas our work allows a developer to focus tracing to reduce overheads and or limit possible instrumentation.
prior work has optimized instrumentation to gather frequency counts of statements or edges often to identify program hot spots.
knuth and stevenson optimize frequency counter placement for program statements and knuth optimizes instrumentation for edge counts.
ball and larus formalize these classic approaches and generalize the counting problems for vertices and edges.
while these classic approaches run in polynomial time their solutions cannot be used for binarized instrumentation they rely on kircho s current law which does not hold of binarized indicators.
further many use cases that we consider would not make use of the more detailed count information.
coverage data can obviously be derived from count data but the cost of gathering counts is higher than the cost of gathering coverage.
in contexts where counts are not required binarized coverage has a number of advantages each probe is less expensive to execute each probe requires only one bit of storage rather than a larger overflow vulnerable integer instrumentation is easily made thread safe on all architectures and probes can be removed after they are first triggered.
pavlopoulou and young monitor residual coverage of code missed during testing.
the gamma project adapts postdeployment instrumentation for data collection aggregated across large user communities each individual entity only traces a subset of desired data.
our optimizations are directly applicable here further reducing required coverage probes for each deployed instance.
prior work optimizes the set of test cases required to achieve a specific coverage criterion .
early approaches to test suite minimization have much in common with approaches to minimizing coverage probes for example all can make use of dominance information for implied coverage.
however our problem is di erent in that desired coverage information must be guaranteed foranyrun rather than attained from a minimal setof runs.
other work has developed the idea of relative coverage in the context of web services .
our work can also facilitate customizing coverage metrics to context dependent targets but deals with optimizing coverage probe placement rather than how to gather and present this data to users of a web service.
.
conclusion binarized program coverage information is used in a wide variety of scenarios from the testing lab to post deployment monitoring.
di erent situations yield very di erent requirements for coverage as well as di erent run time overhead restrictions.
we present a system that allows users to specify customized coverage criteria desired coverage locations as well as the set of locations that are valid for instrumentation.
while we show that the customized coverage probing problem is np hard we also develop inexpensive approximations and show that even coarse approximations can lead to significant reductions in instrumentation cost.
.