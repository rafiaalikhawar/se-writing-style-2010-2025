how do api selections affect the runtime performance of data analytics tasks?
yida tao1 shan tang1 yepang liu2 zhiwu xu1 and shengchao qin3 1college of computer science and software engineering shenzhen university shenzhen china yidatao tangshan2018 xuzhiwu szu.edu.cn 2department of computer science engineering southern university of science and technology shenzhen china liuyp1 sustech.edu.cn 3school of computing digital technologies teesside university uk s.qin tees.ac.uk abstract as data volume and complexity grow at an unprecedented rate the performance of data analytics programs is becoming a major concern for developers.
we observed that developers sometimes use alternative data analytics apis to improve program runtime performance while preserving functional equivalence.
however little is known on the characteristics and performance attributes of alternative data analytics apis.
in this paper we propose a novel approach to extracting alternative implementations that invoke different data analytics apis to solve the same tasks.
a key appeal of our approach is that it exploits the comparative structures in stack overflow discussions to discover programming alternatives.
we show that our approach is promising as of the extracted code pairs were validated as true alternative implementations.
in over of these pairs the faster implementation was reported to achieve a 10x or more speedup over its slower alternative.
we hope that our study offers a new perspective of api recommendation and motivates future research on optimizing data analytics programs.
index t erms api selection data analytics performance optimization stack overflow i. i ntroduction data analytics is the process of transforming raw data to actionable intelligence and it is becoming increasingly important in this fast developing era of ai and big data .
as the volume and complexity of data grow at an unprecedented rate developers are often challenged by performance problems in the development of data analytics programs .
although upgrading hardware or using more computing power could directly speed up data analytics tasks such solutions are often expensive or impractical.
we observed that a more feasible and economic approach to optimizing data analytics programs is to exploit software redundancy for reliability and usability concerns modern software often offers multiple ways to complete the same tasks .
for this reason developers have the opportunity to boost program performance by replacing the usage of a library api or api sequence with a faster alternative.
fig.
shows a real example.
the code fragments at line and line both compute the magnitude of a given list of vectors line .
yet they use different apis of numpy a popular python library for data analytics .
the runtime zhiwu xu is the corresponding author.1in importnumpy asnp input data 4in a np.arange .
.reshape solution 7in timeit 8100loops best of .23ms per loop execution time solution 11in timeit np.sqrt a a .sum axis 12100000loops best of .9 s per loop execution time verify that the two solutions have the same output 16in np.allclose np.sqrt a a .sum axis 17out true fig.
.
computing the magnitude of vectors using different numpy apis excerpt from stack overflow post .
one implementation is significantly faster than the other.
difference of these two solutions is tremendous the one that uses numpy.ndarray.sum andnumpy.sqrt is nearly 224x faster than the one that uses numpy.linalg.norm .
we refer to code fragment pairs like line and line in fig.
as alternative implementations which invoke alternative apis to solve the same task by producing the same output for the same task input see line .
developers could leverage alternative apis as a cost effective way to speed up their data analytics programs.
previous studies have also suggested that different api usages could affect program performance.
selakovic and pradel found inefficient api usage to be the most common root cause of performance issues in javascript programs .
yang et al.
reported that half of the performance issues in rails applications can be improved by changing how the rails apis are used .
however these studies focus on different domains and their evaluations on inefficient api usages were carried out manually on a small scale.
in this paper we propose a novel approach to automatically identifying alternative data analytics implementations which lays the foundation for further studies on the prevalence characteristics and runtime performance attributes of alternative data analytics apis.
identifying alternative implementations for practical data analytics tasks is challenging since developers typically do not keep alternative implementations in their code if one 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
implementation is already sufficient for the task.
even if alternative solutions are implemented by different developers or in different contexts it is hard to determine that they indeed solve the same tasks.
in fact identifying programming alternatives is a particular case of determining program equivalence which is undecidable in general .
previous work leverages techniques such as data flow analysis and random testing to detect functionally similar or equivalent programs.
in this paper we tackle this problem from a novel perspective.
we observed that alternative implementations are often discussed on q a sites such as stack overflow so for short and such discussions usually involve some sort of comparison between the alternatives e.g.
fig.
compares the execution time of two implementations .
according to so guidelines users should post answers that directly address the question.
unconstructive or irrelevant answers might be downvoted or removed.
for this reason if two implementations are compared in an so answer post it is likely that they are alternative solutions to the task described in the corresponding question post.
this observation motivates us to exploit the comparative structures in so posts to discover alternative implementations.
ii.
e xtracting alternative implementations a. extracting from consecutive profiling statements if a data analytics task has multiple solutions with different runtime performance developers may profile these solutions in the same context in order to select the most efficient one.
based on this observation we propose to extract alternative implementations from consecutive profiling statements which can be found in so code blocks encompassed by the pre code tag.
the type of profiling statements we search for is the one that executes timeit which is the standard python profiling command that measures execution time of small code fragments .
we match patterns where timeit is used from the command line the python interface and from ipython .
based on the respective timeit usage syntax we extract the code fragment that is being profiled and the corresponding execution time which is typically reported right after the timeit statement in so code blocks.
for example from the code block shown in fig.
we extract code fragments at line and line since they are being profiled by timeit consecutively.
we also extract .
ms and .
s as the corresponding execution time.
note that two profiling statements are consecutive if there is no non timeit code statements i.e.
regular code between them since non timeit code may alter the input data which violates the principle of input equivalence in our definition of alternative implementations.
in addition if there are n consecutive profiling statements in an so code block we extract all combinations of them.
b. extracting from comparative sentences in addition to consecutive profiling statements we also leverage the comparative structures in natural language to detect alternative implementations.
first we extract natural language text from so answer posts and use the stanfordnn rbr nn semgrex pattern word faster anchor nsubj word codefrag.
entity1 nmod than word codefrag.
entity2anchor entity1 entity2nsubj nmod than i am iterating through all the rows of the dataframe using codefrag1 which is faster than codefrag2 fig.
.
an example of extracting alternative implementations using pos tagging dependency parsing and semgrex matching at the sentence level.
corenlp toolkit to split the text into sentences.
we then identify comparative sentences that contain efficiency related comparative keywords such as faster slower and more efficient .
we proceed to identify the code fragments that are being compared in the comparative sentences.
following the common practice on detecting code like terms from informal natural language discussions we develop a set of regular expressions based on the target libraries usage syntax.
contents matching these regular expressions or embedded in the code tag are considered code fragments.
since the presence of code fragments might negatively affect subsequent nlp tasks we replace each detected code fragment with a unique identifier e.g.
codefrag1 which will be recovered once all nlp tasks are finished.
next we perform part of speech pos tagging and dependency parsing to annotate each sentence with pos tags of each word e.g.
noun adjective and relations among words e.g.
nominal subject conjunct .
we then use semgrex a stanford corenlp package that allows users to specify regular expression like patterns based on lemmas pos tags and dependency labels to extract code fragments that are being compared.
we have developed semgrex patterns for this purpose.
these patterns use comparative keywords as anchors and follow certain dependency labels to search for words that start with codefrag .
take the sentence i am iterating through all the rows of the dataframe using code .itertuples code which is faster than code .iterrows code from so post as an example.
this sentence is first identified as comparative for containing the word faster .
contents inside the code tag are replaced with codefrag1 and codefrag2 respectively.
after annotating the sentence using pos tagging and dependency parsing we find a matching semgrex pattern that has outgoing edges nsubj and nmod than from faster to codefrag words which are extracted as the compared entities .
finally we recover the original code fragments and determine their performance ordering based on the meaning of the anchor word.
in this example .itertuples is identified as a faster alternative to .iterrows .
iii.
e merging results a. dataset our dataset includes so threads tagged with numpy pandas and scipy which are popular data analytics libraries in the python data science ecosystem .
we used the official so data dump released on december for data collection.
to ensure that the extracted information is trustworthy we consider only answer posts that are accepted authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i dataset statistics and the of v alidated alternative implementation pairs for each library .
library s o s o validated alternative threads answers implementations numpy pandas scipy or have positive scores i.e.
they received more upvotes than downvotes .
table i shows the number of so threads and trustworthy answer posts for each library.
b. alternative implementations we applied the approach described in section ii on the so dataset and extracted candidate implementation pairs.
we programmatically validated whether each pair is truly alternative based on the input and output equivalence.
specifically for each candidate implementation pair we constructed a validation program that executes the pair on the same input to solve the task described in its so thread.
for most pairs extracted from consecutive profiling statements their input variable definitions were directly extracted from the same code blocks e.g.
line in fig.
.
we manually restored the input definitions for the remaining pairs since those definitions typically locate in separate code blocks or other posts of the same so thread.
to determine output equivalence our validation program checks the type of execution result and calls the corresponding object comparison method.
for example if two outputs of type numpy.ndarray are equivalent then calling numpy.allclose on them will yield to true line in fig.
.
among the extracted candidate pairs pairs .
were validated as true alternative implementations.
2regarding the extraction methodology candidate pairs were extracted from consecutive profiling statements and of them were validated as true alternatives.
on the other hand candidate pairs were extracted from comparative sentences and were validated as true alternatives.
this indicates that comparative structures in so posts can indeed be leveraged to effectively reveal programming alternatives.
table ii shows two examples of the extracted alternative implementations.
table i shows the number of validated alternative implementations for each target library.
the majority of alternative implementations use apis of pandas and numpy whereas only a few use scipy .
apart from the fact that pandas and numpy have a larger amount of so posts another reason for this phenomenon is probably because these two libraries are designed to work with low level data structures.
specifically numpy is used to work with arrays and pandas is used to work with tabular and time series data.
developers might have more flexibility when using these two libraries since they would be 1the sum of so threads for all libraries is larger than since a thread might have multiple tags.
2the sum of validated alternative implementation pairs in table i is larger than since a pair might invoke apis of multiple libraries.
1000x100 1000x10 100x5 10x3 5x2 3x 2x of alternative implementation pairsruntime speedup x fig.
.
performance speedup of alternative implementation pairs.
able to directly manipulate the data.
scipy on the other hand provides high level algorithmic apis for commonly used tasks in scientific computing.
therefore it may not offer as much flexibility of using different apis for the same tasks as pandas and numpy do.
c. performance impact of alternative implementations as described in section ii a we extracted an implementation s execution time as well when we processed consecutive profiling statements in so code blocks.
these profiling results allowed us to analyze the performance difference of the alternative implementation pairs extracted from consecutive profiling statements.
fig.
presents the results.
we observed that in pairs .
the faster implementations improve the task runtime performance by less than 2x.
for the remaining pairs .
the faster implementations achieve 2x or more speedup over their alternatives.
in particular the faster implementations in .
and .
pairs achieve 100x and 1000x speedup respectively.
the faster implementations in .
pairs even achieve more than 1000x speedup over their slower alternatives.
the results show that alternative implementations using different data analytics apis do improve task runtime performance and sometimes the improvement is quite significant.
hence we believe that leveraging alternative apis to optimize data analytics programs is a promising future direction.
d. consistency across input data sizes various factors can affect the performance of alternative implementations.
in our experiments we observed that .
of the so posts containing consecutive profiling statements have compared the same alternative implementation pairs over different sizes of input data.
this indicates that developers consider input data size to be important when evaluating the performance difference of alternative implementations.
to further understand this issue we quantify the performance difference of the extracted alternative implementations under five synthesized input data with sizes i.e.
of rows ranging from to .
our experiments were performed on an intel core i9 cpu .9ghz machine with 32gb memory running bit windows and python .
.
.
our preliminary results show that input data size can dramatically affect the extent of performance improvements.
fig.
shows two examples.
in the first example authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii examples of alternative implementations their task descriptions and the corresponding alternative api pairs .
task alternative implementations alternative apis so post df.pivot table index columns pandas.dataframe.pivot table count the frequency of term aggfunc size fill value groups pd.crosstab df.term pandas.crosstab so post np.sum rr a numpy.sum count the occurrence of np.count nonzero rr a numpy.count nonzero a character in an array numpy.where andpandas.series.map are both used to alter data given a threshold and numpy.where has a trivial speedup .5x over pandas.series.map when the input data is small.
however the speedup becomes significant 100x for input sizes larger than 100k.
in the second example numpy.ndarray.dot andnumpy.tensordot are both used to compute the dot product of matrices andnumpy.ndarray.dot exhibits a non trivial speedup 12x over numpy.tensordot when the input size is small.
however their performance gap narrows as the input size grows.
when the input size reaches million the two implementations have nearly comparable performance.
we also found cases where an alternative implementation exhibited both performance improvement and degradation on different input data sizes.
for example we found that pandas.read csv is faster than pandas.read hdf for input sizes less than 1k whereas pandas.read hdf takes the lead for larger inputs.
our results show that input data size can be a critical factor that affects the outcome of performance optimization using alternative implementations.
specifically an alternative solution that is allegedly much faster than the original implementation according to so posts may turn out to be alike or even slower when the input data size varies.
we believe that this issue requires further investigation in order to reduce potential risk of unintended optimization consequences.
iv .
c onclusions we have presented a novel idea of leveraging comparative structures in stack overflow discussions to discover alternative data analytics implementations.
our approach exploits crowd knowledge and the very nature of comparison to reveal programming alternatives which is essentially different from conventional approaches that harness program analysis and testing.
the alternative implementations extracted in this manner appear to have substantial performance difference according to the profiling results reported from stack overflow.
this further indicates that a technique for detecting faster api alternatives is desirable.
we also found that input data sizes often affect the performance comparison outcomes of alternative implementations which however has been rarely studied in previous research.
in the future we plan to dive into the characteristics root causes and caveats of alternative data analytics apis.
we hope that our results establish a basis for developing techniques that automatically and reliably optimize data analytics programs.fig.
.
cases where an implementation remains faster than its alternative but the extent of performance improvements varies dramatically.