detecting incorrect build rules n andor licker andrew rice department of computer science and technology university of cambridge cambridge uk nl364 acr31 cam.ac.uk abstract automated build systems are routinely used by software engineers to minimize the number of objects that need to be recompiled after incremental changes to the source files ofa project.
in order to achieve efficient and correct builds devel opers must provide the build tools with dependency informationbetween the files and modules of a project usually expressed ina macro language specific to each build tool.
most build systemsoffer good support for well known languages and compilers butas projects grow larger engineers tend to include source filesgenerated using custom tools.
in order to guarantee correctness the authors of these tools are responsible for enumerating allthe files whose contents an output depends on.
unfortunately this is a tedious process and not all dependencies are capturedin practice which leads to incorrect builds.
we automaticallyuncover such missing dependencies through a novel method thatwe call build fuzzing.
the correctness of build definitions isverified by modifying files in a project triggering incrementalbuilds and comparing the set of changed files to the set ofexpected changes.
these sets are determined using a dependencygraph inferred by tracing the system calls executed during aclean build.
we evaluate our method by exhaustively testingbuild rules of open source projects uncovering issues leadingto race conditions and faulty builds in of them.
we provide adiscussion of the bugs we detect identifying anti patterns in theuse of the macro languages.
we fix some of the issues in projectswhere the features of build systems allow a clean solution.
index t erms build tools exhaustive testing verification i. i ntroduction automated build systems are at the heart of all software projects executing the set of actions required to build applications either from scratch or by incorporating incrementalchanges into temporary outputs.
clean builds of modern soft ware engineering projects such as the linux kernel or mysqlserver can take a significant amount of time but developersrarely change more than a handful of files between subsequentbuilds.
in order to maintain productivity incremental builds arevital whenever some files change automated build systemsrecompile only the minimal subset of outputs which depend onthe changes.
to enable incremental builds build tools must bemade aware of the dependencies among the files and modulesin a project.
our goal is to automatically find errors in thedefinitions of these dependencies.
in the case of projects which span hundreds of thousands of lines of code contain multiple modules and include alarge number of dependencies the dependency graphs arecomplex and tedious to describe manually.
languages suchas c c java and rust carry in their syntax dependencyinformation which can be exploited to construct dependencygraphs.
instead of manually specifying arguments to compilerinvocations in the macro languages of tools like gnu make or ninja developers provide brief definitions to buildfile generators such as cmake autotools and scons describing the high level structure of a project.
build filesare generated out of these definitions along with dependencyinformation extracted by partially parsing the source codeof languages known to the build system generator.
suchgenerators also permit the integration of custom tools butrequire developers to manually enumerate dependencies.
when engineers write build definitions manually or integrate custom tools into definitions generated by build system genera tors they might forget to enumerate all dependencies correctly.these mistakes lead to incorrect incremental builds where thefinal executables are linked with stale objects which were notrecompiled despite changes to their sources.
parallel cleanbuilds can also fail because of race conditions if the buildsystems does not know about a dependency between an inputand an output the job generating the input can be scheduled atthe same time as the job reading it failing the build.
detectingand identifying such issues is a time consuming process gnu make itself was developed because of frustration withstale builds .
a single threaded clean build which discardsall temporary objects is the easy yet timewise expensivefix wasting engineering resources which could be used moreproductively.
lack of proper tooling increases the difficulty ofcreating correct build definitions and integrating custom toolswhich generate source files into builds.
consider the following cmake rule from an open source project with over stars 1on github add custom command output expanded files h depends cmake current source dir root .h.tcommand python executable python dash b cmake current binary dir generate helper.py root root .h.t argn even though the input file is mentioned among the dependencies the python script is not included nor are the other python files imported into the root script.
a change toany of those scripts will fail re generate the desired headerand recompile the binaries that might include it leading tobugs which are hard to detect.
this is just one example ofa buggy build definition throughout our evaluation we un cover issues with out of source builds dependencies on tools ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
complex build scripts the handling of external dependencies and manual dependency management as well as attempts to address these problems which lead to redundant work.
we describe a new technique which we call build fuzzing to detect these problems.
we treat a build as a black box without inspecting any of the user provided or automatically generated definitions relying solely on observing the interactions between the build process and the underlying operating system.
we identify the input files of a project and we update each of them in turn triggering an incremental build afterwards.
the set of outputs changed during a build is compared with the set of files expected to change based on the inferred dependency graph.
we report whether the build tool fails to rebuild any of the expected targets or rebuilds targets which do not actually depend on the changed input.
we identify race conditions by locating rules which can be triggered before all of their dependencies are built.
we evaluate our method using open source projects from github.
the contributions of this paper are a novel method to infer dependency graphs check the correctness of incremental and parallel builds discovering missing dependencies and race conditions evidence that our approach solves a significant problem we tested a large number of open source projects and found redundant or missing dependencies in of them including the linux kernel mysql server and redis an analysis and characterisation of the uncovered bugs along with a discussion of the deficiencies of build systems and engineering practices which cause those bugs all our tools are released under the mit license and available at artefacts are available at ii.
b ackground and rela ted work build systems come in many flavours but at their core they parse a set of definitions typically defined in macro languages with imperative or functional syntax .
these definitions describe the dependency graph among the modules and files of a project statically before a build make ninja scons or specify the steps required to determine the graphs dynamically during the build bazel .
relying on these dependency graphs build tools can compile projects from scratch or identify the minimal set of actions to be executed to correctly rebuild all outputs after incremental changes.
in the past there has been little motivation to study issues with build rules especially with the goal of finding systematic problems in build definitions.
previous research considered the correlation between the size and complexity of projects and the size and complexity of the build rules that compile them as well as the evolution of the build definitions along with the evolution of the source code compiled by them .
such studies show that most developers frequently fix build issues they encounter but only a few knowledgeable contributors create new build rules or improve existing ones.
the high impact of build definition maintenance on developerproductivity was quantified without considering the root cause of the bugs on which developers waste time .
we are mostly concerned with extensibility even though most solutions satisfy the needs of end users and offer good support for the languages they were designed for the macro languages they expose to developers of custom tools are fairly limited and difficult to use.
projects frequently include sources generated from domain specific languages using external tools requiring custom definitions to be integrated with other build rules.
unfortunately even modern build systems assume that those definitions are developed by a few knowledgeable people and fail to offer features to ensure correctness.
only a few of them offer built in features which allow the underlying build graphs to be visualised.
we describe the widely used build systems and build system generators we inspected along with their debugging facilities in section ii a. existing verification methods which analyse the actions executed by build systems along with the source code of the rules defining the actions explored in section ii b do not generalise well because of the difficulties involved in parsing and understanding the static definitions which are fundamentally different across all the build tools.
a. build systems make has been around for the past years and still sees widespread use.
it trakcs the dependencies of individual modules rebuilding the minimal set of targets which depend on a particular file.
nowadays developers can avoid writing raw makefiles relying on build system generators which can output makefiles from brief definitions instead automatically detecting and tracking certain dependencies.
make has multiple implementations and variations available on gnu bsd and microsoft systems.
bmake available on bsd incorporates dynamic information from system call traces to rebuild targets whenever system libraries or utilities change in addition to the dependencies specified in build rules.
the target of our evaluation was the canonical gnu make implementation available on most linux distributions.
ninja is a more recent build tool which performs similar functions to make except it was not designed to be humanreadable.
instead rules are meant to be generated from higherlevel definitions the tool was first used in the chromium project alongside the gyp generate your project generator.
ninja outperforms gnu make when comparing incremental build speeds and most build system generators support it.
the tool aids debugging by producing a visual representation of the graph it parses from definitions.
scons is a highly extensible build system which does not rely on a custom macro language allowing developers to write definitions in python instead.
it has built in support for automatically discovering c and c dependencies dynamically and can dump a textual representation of dependency graphs.
cmake is a widely used build system generator.
it natively supports a large number of languages such as c c fortran and various assembly dialects.
cmake generates complex recursive makefiles from concise definitions detecting and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
updating c and c dependencies .
both ninja and gnu make definitions can be generated.
the macro language allows developers to specify custom rules but requires all dependencies to be manually enumerated in order to ensure the correctness of incremental builds.
build system generators require significantly less effort from developers for example in the case of mysql server lines of cmake definitions generate more than lines of gnu make rules.
bazel and buck are modern distributed build systems.
they distinguish themselves by allowing developers to define their build rules in languages similar to python and by building individual targets in the cloud instead of a single local workstation.
they offer some support for automatically detecting dependencies between c files however they encourage programmers to specify the full dependency graphs manually.
in the case of custom rules they still require dependencies to be manually enumerated.
similarly to ninja dependency graphs can be queried and visualised.
b. dependency graph inference in a typical build system the actions required to build some output are specified along with all the inputs to the underlying tools.
the dependency information is used to enforce the order in which actions are executed and to identify the set of outdated targets during an incremental build.
since the tools are arbitrary processes the build system has no means of preventing those tools from inspecting files other than the ones listed as dependencies.
because of this dependency graphs defined by users of build tools cannot be trusted however more accurate information can be extracted by inspecting the interactions among processes and the file system by capturing the system calls executed during a build.
system call tracing has been previously used to recover true dependency graphs by connecting the files written by a process to files produced by processes which read them.
these graphs were applied to build system migration linting and refactoring.
cloudmake is a distributed build system by microsoft which exposes an interface based on typescript to specify build definitions.
as with all new build systems this project faced adoption issues as well the company already had millions of lines of code compiled using definitions based on another system.
to ease the transition existing build scripts were automatically migrated.
in order to translate an existing set of build definitions dependency graphs were recovered through system call tracing by instrumenting calls to the win32 apis.
through pattern matching the nodes represented by processes were replaced with human readable build rules defined in a higher level language.
automatic refactoring was applied to simplify and coalesce build rules.
the build language of cloudmake was formally specified and verified however the proofs are limited to a subset of known tools specified through axioms .
depslint is a python script for linting build rules of projects using the ninja build system.
it traces system calls during clean builds and validates incremental builds emitting warnings whenever files other than the ones mentioned amongthe dependencies are read from during the execution of a build action.
this tool is limited by the fact that it only supports a single build system whose definitions were not meant to be written manually by design.
this creates difficulties in correlating the warnings emitted by the tool with the highlevel definitions which yield the erroneous definitions.
makao is a dependency graph inference tool successfully used to reverse engineer the build definitions of the linux kernel .
this tool is tailored for the gnu make build systems and recovers dependency information through a hybrid approach by parsing makefiles and the command line strings used to invoke the gcc compiler captured through the bourne shell s xtrace option.
the dependency information was used to gain a deeper understanding of the linux kernel s source code by visualising the dependency graph.
iii.
o urapproach our testing approach is inspired by existing tools which inspect system calls in order to gain more information about the underlying dependencies.
instead of using this information to migrate build rules to a new language or refactor build rules we check the correctness of build definitions regardless of the build system in order to find mistakes causing incorrect incremental builds or race conditions during clean parallel builds.
this approach applies to build systems which performs compilation in a separate process invoked by the build tool.
we assume that clean builds succeed and that all actions defined in the rules are correct if that is not the case tools such as mkfault can be used to localise errors.
in order to obtain accurate dependency information for a project we perform system call tracing presented in section iii a to infer the dependency graphs outlined in section iii b. these graphs can be used to check the correctness of incremental builds interactively as developers work on a project however we focus on fuzz testing open source projects.
we describe a method to automatically detect missing dependencies in section iii c and race conditions in section iii d. our system call tracer can infer dependency graphs for arbitrary projects provided clean builds are correct.
a. system call tracing any data persisted by a process must be either an argument to a system call written to a memory mapped files or passed to another process using an inter process communication mechanism such as shared memory or pipes.
a process can be viewed as a pure function transforming input files into one or more output files.
the goal of system call tracing is to recover the inputs and outputs which link the functions together.
most systems offer facilities to trace the system calls executed by a process through the operating system on linux by instrumenting library calls on windows through the win32 apis and on os x through libc or by instrumenting the kernel dtrace on os x and ebpf on linux .
performance and complexity vary wildly.
dependency graph reconstruction requires capturing a subset of all system calls those which authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
perform i o read write mmap ... and those which transfer data between processes pipes shmget ... .
ptrace is a linux system call allowing a tracer process to stop and inspect the registers and memory of a tracee process whenever a system call is entered or exited in the tracee.
through ptrace all system calls executed by a process can be captured.
this approach is expensive besides the two context switches between the kernel and the tracee at least other context switches are required between the tracer and the kernel to inspect and resume a syscall.
the tracee must be stopped even when the syscall is not relevant to the graph.
dtrace and ebpf probes can be used to trace relevant system calls on os x linux and solaris.
unfortunately this method requires disabling system integrity protection on os x and the installation of additional kernel modules on linux.
even though this approach offers significantly better performance compared to ptrace it is highly inconvenient.
furthermore dtrace does not guarantee intercepting all system calls since information might be dropped in order to maintain performance under heavy loads.
on windows and os x system calls are performed through the standard library manually invoking the syscall instruction is highly discouraged.
by relying on the functionality of dynamic loaders or other readily available instrumentation tools the interfaces between builds tools and the system libraries can be modified in order to capture all system calls.
unfortunately this approach is more complex as it not only requires changes to all system call wrappers open close write etc.
but most standard c functions must be modified as well fopen fread etc.
since the system call wrappers might be inlined inside the library.
our inference method uses ptrace targeting unix based build environments.
unlike existing tools such as bsd make s meta mode our approach correctly traces and handles pipes and the close on exec behaviour of file descriptors.
support for pipes is important since tools which dump their output to stdout are commonly used to generate code during builds.
some build systems make network requests to download packages for example it is fairly common for a build based on cmake to download external dependencies through wget .
in such cases we assume that the remote resources never change once they are downloaded.
we do not consider system calls which read system parameters such as getrlimit and getrusage since these parameters seldom change nor do we intercept calls returning the current time which in the glibc implementation rely on vdso instead of executing actual system calls gettimeofday .
b. dependency graphs relying on the arguments and return values of system call intercepted by ptrace we use algorithm to capture information about all files and processes involved in a build.
the result is a graph with two kinds of nodes representing files and processes along with specific metadata.
file nodes track whether the file is a temporary or a persisted object along with a list of dependencies to represent renamed files andsymbolic links.
process nodes track their inputs outputs and parent processes.
during the execution of the algorithm the file descriptors introduced by open are tracked and files are added to the set of inputs or outputs of a process when an i o action is performed read mmap ... .
the close on execute cloexec flag is tracked in order to correctly propagate file descriptors from parent to child processes.
for example when the pipe system call is encountered in cat a.txt md5 b.txt the tracer adds two virtual files to the state of the process corresponding to the read and write ends of the pipe.
an additional dependency is added between the read end and the write end of the pipe.
md5 receives the read end of the pipe and calls read on it adding the virtual file to its inputs.
cat receives the write end and outputs to it using write adding the virtual file to its outputs allowing the dependency from a.txt tob.txt tobe followed transitively through the virtual files and the additional dependency between them.
algorithm dependency graph inference procs traced process files while a child is running do pid call details ptrace p procs switch call details docase child fork procs p procs .pid child procs .parent p.pid case exit p.running false case execve image p.ins p.outs p.image image p.files files without cloexec from p.files case fd open path cloexec files deleted false p.files path cloexec case rd wr pipe cloexec rdn wrn create unique names for pipes p.files rdn cloexec p.files wrn cloexec files .deps files .deps wrn case read fd p.ins p.ins p.files .path case write fd p.outs p.outs p.files .path case unlink path files .deleted true case rename src dst files .deleted true files .deps files .deps src end while figure illustrates a dependency graph recovered through system call tracing during a typical build.
nodes and edges in green represent the process hierarchy encoded in the parent field of the process objects of the tools invoked by gnu make as well as the various other tools invoked by the gcc compiler driver.
incoming black edges ins field originate from inputs while outgoing edges point to outputs outs field .
some output files are temporary indicated by red text these are temporary objects deleted by the compiler after emitting the object files.
they are still relevant to the graph as the input sources are connected transitively to the output objects through the intermediary assembly files.
additionally dependencies between files stored in the deps field of files exist between the two ends of a unix pipe and also occur when files are moved or authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a.cgcc cc1 a.h cc1cc1 cc1 b.c gccb.hc.c gcc c.h main.c gcc tmp cc6tophe.s as tmp ccbnur2c.s as tmp ccjwblha.s as tmp ccvev01v.s asout c.o out b.oout a.o out main.ogcc ld collect2 out main fig.
dependency graph inferred from a c project built by gnu make.
green edges and nodes represent the process hierarchy of the invoked build tools the black nodes and edges represent the files which are the inputs and outputs of processes.
the files in red are not persisted after the build.
the process running gnu make itself was omitted.
symbolic links are created.
this allows us to correctly handle pipes ignored by existing tools such as depslint orbmake .
for the purpose of our analyses process nodes are only used to identify the name of the executable which generated a file.
such nodes are otherwise collapsed forming a dependency graph of files.
even though inter process edges carry a data dependency through the arguments and environment passed from a parent to a child process they are ignored.
in a typical build the process belonging to the build tool reads from every file without writing to any creating a cycle from outputs to inputs through the process edge which connects the build system to the tools it invokes.
ignoring these edges excludes dependencies on build files read by the build tool potentially containing the command line arguments passed on to compilers.
since build files are usually generated from thirdparty sources before a build we are not including them in our analyses as they would uncover issues with generators which are unlikely to occur instead of validating handwritten rules.
our graphs are only an approximation of all data dependencies between all objects involved in a build.
since some edges might be missing underconstraining or some outputs might be redundantly connected to some inputs overconstraining our analyses can result in false positives or negatives.
overconstraining an overconstrained graph introduces false positives and negatives the analysis might report that a file should be changed when an input is touched while in reality data from the touched file does not actually determine the output.
if the build system unnecessarily rebuilds an output after an input is changed and a redundant path is present in the graph the analysis fails to identify the problem.
the granularity of the dependency graph is limited to processes if a process produces multiple outputs dependency inference cannot distinguish which inputs determine which output considering all outputs to be dependants of all inputs.
this is usually not a concern in c c assembly projects compiled using gnu make or cmake since most tools involved in a build either generate a single outputs or all outputs they generate depend on all inputs.
the lack of information about the flow of data inside aprocess prevents our analyses from running java projects.
java build systems such as maven and gradle invoke the compiler as a library instead of creating a separate process.
since our analysis would create a node having all source files as inputs and all class files as outputs the results would not be relevant.
an example of such a graph inferred by our tool is shown in figure .
in large java projects which rely on the java native interface jni our approach could still be used to determine the correctness of the native components.
another source of false positives are unix pipes.
even though only data derived from a subset of the inputs might be transmitted over the pipe all inputs are dependencies of the outputs of the reading process due to transitivity.
pipes are routinely used in shell scripts but we have not encountered a script large enough to introduce redundant edges.
pom.xml javamulti module server ... greeter.class single module ... greeter.classmulti module pom.xml multi module server pom.xml multi module webapp pom.xml single module pom.xml multi module server ... greeter.java single module ... greeter.java fig.
an example of an overconstrained graph obtained by tracing a maven build on a sample project.
since java builds run in a single process all inputs are connected to all outputs through the single process running the java virtual machine.
underconstraining the inferred dependency graphs might lack edges between files whose contents depend on each other leading to both false negatives and positives in our analyses.
if an edge is missing but the build system specifies a dependency between the two files the output is considered to be redundantly rebuilt.
if a dependency exists but neither our graph nor the build system are aware of it then we fail to emit a warning if the dependant object is not recompiled.
despite capturing all interactions between a process and the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
operating system some edges might be missing from the recovered graph.
our analysis only considers system calls which succeed however failing ones are also important.
for example c compilers search through a large number of directories in order to locate input files during their preprocessing step creating a file in such a directory should trigger a build.
we do not consider the addition or deletion of files to a project as we are only concerned with checking existing dependencies thus this issue does not affect our results.
another source of problems are arguments and environment variables passed to child processes through execve and its variants the parameters passed introduce a data dependency which we omit to avoid cycles in our graphs potentially introduced by the build tools which spawn processes.
this prevents our analysis of builds which involve tools reading arguments from files passing them on to child processes.
algorithm fuzz testing procedure dependencies ins outs built by for file files dofor dep file.deps do dependencies dependencies file end forend forfor proc procs do ins ins proc.ins outs outs proc.outs for out proc.outs do built by proc.image for in proc.ins do dependencies dependencies out end forend forend forfunction all deps file deps iffile deps then deps deps file for f dependencies do deps deps all deps f deps end forend ifreturn deps end functionfor file ins outs do t0 read timestamps outs touch and build file t1 read timestamps outs changed t t outs t1 t0 for f all deps file changed do report missing f built by end forfor f changed all deps file do report redundant f built by end forend for c. fuzz testing our build fuzzing method which identifies the files in a project which trigger incorrect incremental builds is outlined in algorithm .
first the dependency graph is simplified by collapsing process nodes and temporary files retaining a mapping from output files to the processes that write them.
next all relevant input files are identified and incremental builds are triggered by modifying each file in turn.
in the case of build systems which rely on content hashing an additional null terminator or newline is added to the file.
otherwise the modification timestamp is simply updated.
the set of filesaffected by a build is identified by comparing the timestamps of files before and after the build retaining the changed ones.
if the set of changed files does not match the set of expected changes computed using a depth first traversal of the dependency graph starting from the changed file a diagnostic message is emitted identifying the dependencies which were not rebuilt or were redundantly rewritten along with the tools which should have been invoked to build them.
the set of tested files is determined based on the type of the tested project.
only those files which were read without being modified during a clean build are considered in the dependency graph these are the file nodes without any incoming edges.
files involved in built in rules as files created by the configuration step of the project specific to each build system are excluded to speed up testing as they are likely correct.
a.c out a.o a.h out b.o out c.o out main.ob.c b.hc.c c.h main.cout main fig.
missing dependencies blue edges represent the dependencies defined in the makefile red edges the missing ones figure illustrates a dependency graph used by build fuzzing obtained by collapsing the processes and temporary files of the inferred graph shown in figure .
fuzzing triggers an incremental build after modifying each of the inputs the c header and source files.
incorrect builds are triggered after of the headers are modified as they are not enumerated in the dependencies of the object files in the makefile.
the missing edges obtained by intersecting the set of outgoing edges of a node with the set of stale dependants are highlighted in red.
d. race condition detection in addition to identifying files which trigger incorrect incremental builds our method can be extended to detect potential race conditions in builds.
we consider that a race condition occurs during a build if the job building an object is executed before all of its dependencies are built.
because of race conditions clean parallel builds can fail spuriously as rules can be scheduled to read from missing files.
during incremental builds objects might be rebuilt from stale inputs.
our method to detect races is outlined in algorithm .
through fuzzing we first find the missing outgoing edges by intersecting the set of objects reported missing by algorithm with the set of outgoing edges of a node for all files involved in a build not only inputs.
for each object we find the set of all of its transitive dependencies excluding inputs in the inferred dependency graph the size of the sets indicates how many authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
objects need to be built before the command generating an object can be triggered.
if the execution order of all commands was linearised the size of the set represents the earliest point in time an object can be built.
we compute this index in the graph with the missing edges removed as well if the index of a file is less in this graph it means that the build system might trigger the rule generating it sooner in time before all dependencies are generated indicating a potential race condition.
algorithm race condition detection function find schedule g gt transpose g deps schedule for file topo sort g do for pred gt outs do deps deps pred deps end forend forfor file gdo schedule deps end forreturn scheduleend functionpartial dependencies for from to missing edges do partial partial to end fors0 find schedule dependencies s1 find schedule partial for f files s0 report race f end ifend for figure illustrates a dependency graph with a race condition detected by our method b.c includes a.h but the dependency is not present in the build file.
the build tool is free to schedule the compilation of b.c before the generation ofa.h leading to an error.
in the correct graph a.o can be scheduled earliest at time and b.o can be scheduled at time .
in the graph defined in the build file both objects can be scheduled at time indicating the possibility of a race.
a.in a.ha.c a.o b.o b.inb.h b.ca.out b.out fig.
race condition the missing dependency shown in red allows b.o to be built before a.h failing a parallel build iv .
e v alua tion a. supported build systems even though we only subjected projects relying on cmake gnu make and scons to build fuzzing we tested our tools on a wide range of build systems to ensure we can recover useful dependency graphs.
for various languages and build systems we evaluated existing projects or we created small projects to compile multiple isolated modules of the same language into an executable.
we inspected the dependency graphs tocheck whether they had any redundant edges connecting the two isolated modules negatively affecting our analyses.
build tool language supported issues gnu make c check ninja c check scons c check bazel c deadlock under ptrace maven java overconstraining ocamlbuild ocaml check go build go check cargo rust check cabal haskell check table i dependency graph inference from build systems table i reports the automated build tools we have evaluated and the issues we encountered with dependency graph inference.
the list does not include build system generators only the tools for which they generate inputs.
our method generalises well across various build systems allowing a larger range of projects to be tested compared to what was possible with existing tools.
we encounter problems with build systems that invoke compilers as libraries instead of shelling out to a separate process as in the case of java.
due to our reliance onptrace we serialize system calls executed by all parallel threads in a process deadlocking tracees such as bazel.
using another provider which does not alter the tracees behaviour such as dtrace would avoid such problems.
b. build fuzzing we evaluated the effectiveness of our tool by automatically identifying incorrect builds and race conditions in a large number of projects built using cmake gnu make and scons.
we searched for projects using the github code search api to find roughly projects which relied on handwritten makefiles or included custom rules into cmake or scons builds using add custom command orenv.command .
we built and tested projects satisfying the following criteria projects had to contain a cmakelists.txt a makefile or asconstruct in the root folder this excluded some poorly written projects with no documentation or large projects with complex build instructions projects which bundled large external dependencies were excluded issues found in the dependencies would have outnumbered the issues in the smaller project and would have been representative of the build system of the dependency not the one used to build the project itself projects had to compile out of the box or with minimal changes we excluded old projects which were outdated to the point of irrelevance and relied on deprecated libraries.
cmake can generate both ninja builds files and gnu makefiles however some projects rely on features which can only be translated to gnu make.
where possible we have tested projects using both build systems obtaining identical results.
we filtered cmake specific configuration files and c c header and source files from the inputs as the built in authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
rules emitted by cmake can correctly handle these.
for the same reason we also excluded c c sources and headers from scons projects.
scons can detect changes by checking both timestamps and content hashes we have modified scons to force the use of the timestamp mechanism for our tests.
all files were considered in projects relying on handwritten makefiles with the exception of the linux kernel where we omitted reliable configuration files and c source files.
tables ii iii and iv present the list of projects where we encountered errors or false positives.
each row indicates the authors and names of the projects the number of stars on github which is correlated with the relevance of a project the number of tested files the number of files which triggered incorrect incremental builds and the number of files which triggered builds that recomputed unnecessary targets a check mark indicating whether we fixed the build or an explanation why a fix was not possible otherwise along with a short explanation of the root cause of the uncovered build problems.
in order to confirm the validity of our results we identified the faulty build rules associated with each of the files reported by our evaluation aided by the information emitted in diagnostic messages.
wherever a fix possible in a reasonable amount of time without substantially re engineering a project we modified the makefiles or cmake definitions to fix the project stars files errors fixed issues torvalds linux 1missing dependencies false positives antirez redis 2races subproject dependencies tinycc tcc 4races manual c dependencies pyssling namespaced parser races manual c c dependencies jkbenaim cboy 4races manual c c dependencies dcdelia tinyvm manual c c dependencies nicknytko x86 thing 1unconditional rules manual deps sadiredd sv cachesimulator manual c c dependencies coldbloodx lec manual c c dependencies kostrahb generic c project 2manual c c dependencies percivalgambit hindsight is 2manual c c dependencies radekvit reon 4manual deps and globbing apron 4races manual c dependencies table ii gnu make stale redundant incremental builds project stars files errors fixed issues mysql mysql server 1inputs to custom tools anbox anbox 2unconditional inputs to custom tools icteam28 pifox 2races manual dependencies bastibl gr ieee802 python import uwsampa grappa 1unconditional rules qknight automate 3races manual deps regmi007 alang manual deps geodynamics specfem3d geotech 3races unsupported language davidpeicho tiny3dloader unconditional rules false positives davidzchen decaf in source prozum sppl 3unconditional rules lukedodd pixslam races in source tool dependency leidav tetris no dependency on tool calendarium romanum libcalrom in source table iii cmake stale redundant incremental builds project stars files errors fixed issues nieklinnenbank freenos false positives due to scons blitz baresifter 2unconditional rules profmaad steppinrazor 2no dependencies between asm files brouhaha nonpareil 2custom build rules fsp fsp unconditional rule false positives due to scons table iv scons stale redundant incremental builds 1requires extensive changes to project structure 2build system lacks features or language support3broken third party build rule 4project too large for correct manual dependency management authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
build rules and re tested the project identifying no issues and proving that the initial original rules were faulty.
out of the projects we found problems in we managed to fix .
we added additional dependencies to makefiles an adjusted add custom command macros in cmake to include all outputs even transitive dependencies of the generator scripts.
some projects were too large to fix manually tracking dependencies for a significant number of sources or required extensive reorganisation to eliminate certain targets which were unconditionally rebuilt at all times.
others required features which were not present in the build systems discovering dependencies dynamically as targets are built extracting them from the contents of the files they are building.
in certain cmake projects we found issues in third party rules we did not fix.
most notably in projects using flex and bison w e found that the build rules generating the c headers and sources do not enumerate all outputs.
where we could not fix issues we confirmed them by adding breaking changes to files and triggering incremental builds which succeeded since nothing was recompiled due to missing dependency information.
the projects we tested contained too many files for us to manually check for the presence of false negatives however we encountered false positives due to missing or unnecessary edges in the inferred graphs.
in projects namely davidpeicho tiny3dloader nieklinnenbank freenos and fsp fsp w e report false positives due to the granularity of processes the build system s process performs a significant amount of work copying files from one location to another.
based on our graph we expect the whole batch to unnecessarily change even though only one file is updated.
in the linux kernel a header file is regenerated every minute containing a minute accurate timestamp.
we do not expect files dependant on the header to change as we do not model the time as an input to our graph.
c. classes of bugs by manually inspecting and checking the issues reported through testing we discovered some patterns in the bugs allowing us to relate the issues to problems with the feature sets of modern build systems.
we discuss why these bugs occur in some build systems and how other tools or environments might be able to solve them.
since we do not correlate problems with their definitions in the macro languages of build systems this process is not automated.
issues with out of source builds this issue was uncovered before testing even though one of the selling points of cmake are out of source builds which allow compilation artefacts to be placed in a directory tree separate from the sources some of the projects did not compile correctly if the build folder was separate.
the developers of the projects did not use the proper macros to point to the expected location of inputs and outputs to their tools leading to failed builds.
more recent build systems such as buck and bazel provide more intuitive syntax to define the inputs and outputs to the rules automatically formatting them to point to a correct isolated location.
encountered in davidzchen decaf lukedodd pixslam calendarium romanum libcalromdependencies on tools build rules for automatically generated files must include dependencies on the inputs to the tools as well as on the tools themselves.
even if the tool is external and provided by the system a dependency on it should exist to ensure that outputs are rebuilt when the system is updated.
in some cases this issue is avoided by running tools unconditionally during each build or by generating files once when the project is configured.
none of these solutions are satisfactory as generating files and recompiling files generated during each build can be time consuming.
some build systems solve this issue by offering more complex macro languages requiring the tool to be a target defined in the project not an arbitrary shell command passed to a shell.
encountered in prozum sppl lukedodd pixslam leidav tetris ghewgill emulino transitive dependencies adding a dependency on the entry point of an interpreted script is not enough scripts include other modules from inside the project which are not marked as dependencies.
this problem exists when using languages which do not bundle all their sources into compact executables.
unfortunately python perl and ruby are popular choices for generator scripts and they fall into this category.
some build system generators such as cmake bundle template engines to generate configuration files which solve this issue however the languages are not powerful or intuitive enough to ensure wide use.
encountered in torvalds linux bastibl gr ieee80211 tinycc tcc prozum sppl brouhaha nonpareil handling of external dependencies c and c do not have standard package management systems thus most projects rely on the package managers of operating systems to place headers and shared objects in locations known to the project.
if the project requires a specific version of the package developers then to include it as a submodule or as a copy in their projects.
build fuzzing is likely to identify all files from the dependency as erroneous as there no link between the shared object built from them and the final executable into which they are linked.
languages such as haskell rust and go integrate package management in their build systems and distributed tools systems such as buck and bazel offer only very limited support for external dependencies adhering to the monorepo philosophy .
encountered in antirez redis unconditional rules in order to avoid all the problems that arise from having to correctly integrate automatically generated sources and track all dependencies some create unconditional rules that recompile everything without considering the changes since the last build at all.
such a design increases the cost of incremental builds as the files might be expensive to generate as is the case with thrift protocols.
encountered in nicknytko x86 thing prozum sppl uwsampa grappa fsp fsp anbox anbox davidpeicho tiny3dloader manual and static dependency management we found issues in all non trivial projects we considered which defined their build rules in handwritten makefiles.
most build systems rely on static dependency graphs the dependencies of a file cannot be defined in the file itself as is the case with c c headers.
the presence of these bugs in makefiles justifies the existence of build system generators authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
such as cmake or autotools and the use of build systems with dynamic graphs such as bazel.
encountered in pyssling namespaced parser jkbenaim cboy dcdelia tinyvm mysql mysql server tinycc tcc sadiredd sv cachesimulator kostrahb generic c project qknight automate anbox anbox apron coldbloodx lec percivalgambit hindsight is8080 radekvit reon geodynamics specfem3d geotech regmi007 alang race conditions this issue does not usually affect clean single threaded builds since the scheduling algorithm in most build systems is likely to deterministically and accidentally order jobs correctly however the non determinism introduced by parallelism is likely to reveal these problems causing builds to fail.
usually developers avoid these problems by disabling parallelism wasting valuable time.
encountered in tinycc tcc antirez redis pyssling namespaced parser jkbenaim cboy apron icteam28 pif ox qknight automate geodynamics specfem3d geotech lukedodd pixslam d. severity the severity of the bugs which can be detected using our tool varies if a buggy target has few dependants developer time is wasted since a time consuming clean build is required after each change.
in such a case a solution is valuable.
if a large portion of a project depends on the target then an incremental build might be as slow as a clean one and investing time in a fix might not be worthwhile.
the detected race conditions reduce parallelism increasing build times and wasting resources due to randomly failing builds.
e. performance all tracing methods involve some overhead on the traced process.
our tool which relies on ptrace slows down builds by a factor of two and is around faster than strace as measured on clean builds running on threads.
other tracing approaches such as dtrace or instrumentation should reduce this overhead to around .
this should not impact developers who create custom build rules as we only trace clean builds once to infer the dependency graph.
fuzzing times depend on project incremental build times.
even though it is valuable to subject a project to such tests they do not need to be executed often as build rules are seldom changed thus it is acceptable to wait for some amount of time for the tests to finish.
since build definitions might contain race conditions and multiple projects are free to write to shared files located outside their project folders we did not parallelise the clean builds to ensure the correctness of build graphs.
v. a lterna tive methods a. dynamic taint analysis since system call tracing cannot track how a process uses its inputs to produce outputs we considered finer grained instrumentation in order to refine the dependency graph and enable the verification of java builds which run in a single process.
in order to test the idea we created a custom llvm pass and a support library to instrument gnu make withdynamic taint tracking in an attempt to identify which files are inspected before a build is triggered.
unfortunately we identified issues with build systems that prevent this method from yielding useful results.
such tools are likely to rely on traversing a directed acyclic graph building targets after all of their dependencies.
a build stops whenever a target fails to build which means that the set of taint values affecting control flow constantly increases due to the conditional branches which determine whether a target succeeded or not.
control flow information is both absolutely necessary and useless taint must be propagated from the comparison which inspects the timestamps of the stat system call but the control flow decisions involved graph traversals lead to a large amount of overtainting.
b. parsing build definitions in an attempt to increase the efficiency of the verification process and to verify our results we considered parsing build definitions in order to compare the defined dependency graphs with the inferred ones.
even though the two graphs can be trivially compared statically analysing makefiles can be quite problematic especially when they are handwritten and not generated.
some projects contain makefiles for multiple build systems mixing python s setuptools with gnu make for example preventing dependencies to be traced through arbitrary processes.
creating custom parsers also involves substantial engineering effort since a new parser must be created for each build system gnu make ninja scons etc .
vi.
c oncluding remarks we developed a novel method build fuzzing to test the correctness of the build definitions in automated build systems by finding missing dependencies and race conditions.
we evaluated our implementation of build fuzzing and race condition detection on publicly available open source projects relying on different build systems and build system generators.
based on the diagnostic messages emitted by our tools we provided solutions to the issues in some of the evaluated projects.
unlike existing systems our approach relies solely on capturing the interactions of build tools with the underlying operating system or file system.
we do not rely on parsing build definitions thus our tool can be used to test a large number of projects built using arbitrary code generators and compilers managed by a wide range of build systems.
our search revealed numerous problems in projects producing only a small number of false positives.
we found issues in both small hobby projects as well as in mature ones such as the linux kernel.
we analysed the bugs to categorise the underlying problems identifying anti patterns and scenarios where the feature sets of existing build systems do not provide adequate support.
the issues we found can potentially waste valuable developer time if users are forced to run single threaded builds to constantly perform clean builds after changing files or to debug issues introduced by stale files.
our tools can be integrated into the workflows of developers saving on time spent debugging or waiting for builds.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.