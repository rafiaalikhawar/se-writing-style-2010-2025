does the failing test execute a single or multiple faults?
an approach to classifying failing tests zhongxing yu chenggang bai kai yuan cai department of automatic control beihang university beijing china yuzhongxing88 gmail.com bcg kycai buaa.edu.cn abstract debugging is an indispensable yet frustrating activity in software development and maintenance.
thus numerous techniques have been proposed to aid this task.
despite the demonstrated effectiveness and future potential of these techniques many of them have the unrealistic single fault failure assumption.
to alleviate this problem we propose a technique that can be used to distinguish failing tests that executed a single fault from those that executed multiple faults in this paper.
the technique suitably combines information from i a set of fault localization ranked lists each produced for a certain failing test and ii the distance between a failing test and the passing test that most resembles it to achieve this goal.
an experiment on real life medium sized programs with multiple fault versions which are shipped with number of faults ranging from to has been conducted to evaluate the technique.
the results indicate that the performance of the technique in terms of evaluation measures precision recall and f measure is promising.
in addition for the identified failing tests that executed a single fault the technique can also properly cluster them.
index terms distance calculation fault localization binary classification debugging.
i. introduction debugging is a notoriously difficult and time consuming activity that can easily account for a significant part of costs in a typical software development and maintenance project .
to tackle the ever growing problem of high costs involved in it researchers and practitioners have developed numerous techniques as an aid for programmers during debugging.
representative examples include fault localization e.g.
failure clustering e.g.
and automated program repair e.g.
which in particular is gaining a growing interest in recent years.
collectively these techniques have advanced the state of art in the area of program debugging.
while these techniques have been shown to be effective they have some questionably unrealistic assumptions that have restricted their application.
the latter two of the above three techniques in particular explicitly or implicitly assume that every failure is caused by a single fault.
yet real world programs will generally contain more than one fault and some failures are caused by multiple faults.
for these multiple fault failures the effectiveness of the proposed techniques is likely to degrade at best and to completely lose at worst.
first failure clustering techniques ideally aim to produce pure clusters i.e.
failures in each cluster are caused by exactly the same faults and each generated cluster contains only failures due to a single fault.
obviously the existence of multi fault failures will make the ideal goal unrealistic .
second program repair techniques typically use genetic programming to guide the generation of repairs that make passing test cases still pass and failing test cases also pass.
the repair space that needs to be searched will increase significantly with the number of faults that a particular failure is involved with which then will make the technique too expensive to be used in practice.
to make these techniques more generally effective in this paper we propose a technique to alleviate this problem.
given a test suite in which each test has been labeled as passing or failing our technique aims to distinguish failing tests that have executed a single fault for simplicity hereafter referred to as single fault execution failing tests from those that have executed multiple faults referred to as multiple fault execution failing tests hereafter .
such a technique could potentially be served as a preprocessing step for techniques that have the singlefault failure assumption.
program repair techniques for example can target only the identified single fault execution failures.
by so the repair success rate may be not too low making the technique practically feasible .
our technique builds on top of two observations.
for each failing test tf in a given test suite suppose we combine it with all the passing tests to get a specific test suite and then use th is specific test suite and a certain fault localization algorithm to produce a ranked list of the possibly faulty program elements.
this list actually embodies the opinion of tf on the likely fault location s .
the first observation is that the ranked list i produced for a failing test ti can be contrasted with the other ranked lists produced for the other failing tests to provide with clues about the fault s that ti has executed .
this paper presents an exploratory study of deriving and using the clues.
similarly for each failing test tf in a test suite according to a certain distance criterion let us compute the distance between it and the passing test that most resembles it in the test suite.
the second observation is that such a calculated distance for a multiple fault execution failing test let s represent the set of faults executed is likely to be larger than that for failing tests that have executed only part of s. our proposed technique is built upon these two observations to infer fault indicators.
each fault indicator is made up of a set of statements that are able to indicate the execution of a certain fault once these statements have been executed aiming at getting a classification of the failing tests into single fault execution ones and multiple faultexecution ones ultimately.
meanwhile for the identified single2015 ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee ieee acm 37th ieee international conference on software engineering .
ieee icse florence italy fig.
.
the three faults of a three fault version of program gzip.
fault execution failing tests our technique can also group failing tests due to the same fault together.
we evaluated the technique using five real life mediumsized programs including grep sed gzip flex and space.
for each program we generated multiple fault versions and the number of faults included in each version ranges from to .
in total the technique is evaluated on multiplefault versions and the number of test cases executed is over million.
the experimental results indicate that the performance of the technique in terms of the commonly used evaluation measures precision recall and f measure in binary classification is promising.
also the result of clustering the identified singlefault execution failing tests is sa tisfactory.
in summary the two main contributions of this paper are the proposal of a novel technique that can be used to classify failing tests into single fault execution ones and multiple fault execution ones which in turn can potentially be used to support techniques that have the singlefault failure assumption.
to the best of our knowledge this paper is the first one to do this kind of classification.
an empirical evaluation of the technique on real life medium sized c programs with multiple fault versions demonstrates the effectiveness of the technique .
the rest of this paper is structured as follows.
section ii uses a motivating example to explain our technique and section iii describes the algorithm of the technique in detail.
section iv presents the experimental evaluation followed by section v which discusses the related work.
finally section vi concludes this paper and gives future perspectives.
ii.
motivating example we use an example to explain our technique in this section.
figure shows a three fault version of program gzip.
when this program is executed with a test suite t a set of passing test s tp and a set of failing test s tf will be produced.
among the tests in tf some of them have executed only one fault while the remaining will have executed more than one fault.
a. information from fault localization fault localization techniques aim to identify the locations of faults when failure occurs and have been widely studied in the past two decades.
d ue to its simplicity and effectiveness one promising family of fault localization techniques is spectrumbased fault localization hereafter referred to as sbfl .
sbfl techniques e.g.
typically contrast the program spectra obtained from the execution of failing tests and that obtained from the execution of passing tests to highlight suspicious program spectrum and output a ranked list of them accordingly.
though sbfl techniques are generally applied using the entire failing test set and passing test set they are not restricted in so.
in fact each failing test tf in a given test suite can be combined with all the passing tests in this suite to get a specific test suite and then a particular sbfl algorithm can use this specific test suite to do fault localization that is to produce a ranked list of the program spectrum.
this ranked list then actually embodies tf s opinion on the likely fault location s .
for the three fault version of gzip suppose we combine each failing test case in tf with tp to get a test suite and use an ideal sbfl algorithm which will always rank a faulty statement at the top of the ranked list.
then to identify multiplefault execution failing tests we can first establish a set s of statements such that each statement in s has at least ever appeared at the top of one rank ed list produced for a certain failing test i.e.
the statements in s are faulty and then figure out which tests have executed more than one statement of the established set.
unfortunately up to present such an ideal sbfl algorithm does not exist in practice.
table i lists part of the fault localization information produced by naish2 algorithm using seven failing tests of tf for the space reason the ranked lists are slightly modified .
the stat column shows the statement index the index here counts only executable lines of code while the ran sus column represents the ranking and suspiciousness score of the corresponding statement.
the numbers shown in bold font are the actual faulty statements.
according to the formula of naish2 see section iii for any failing tests that have executed a certain statement the suspiciousness score of the statement will be larger than and the same in the ranked lists produced for these tests.
note as the sbfl algorithm may give the same suspicious ness score to different statements the sequential order of statements is used as the tiebreaking scheme to rank such statements in this paper.
obviously the faulty statements are likely not at the top of the ranked lists and can even be very low for some failing tests.
despite the absence of such an ideal sbfl algorithm we can still get useful information from the produced rank ed lists.
with regard to a particular faulty statement si that a failing test ti has executed the statements ranked higher than it in the ranked list produced for ti can generally be classified into two categories.
the first category consists of statements that are executed by every failing test that has executed si while the selocal void fill window ... if more unsigned eof more else if strstart wsize max dist ... for n n hash size n m head head pos m wsize ?
nil m wsize fault .
correct head pos m wsize ?
m wsize nil ... else if strstart wsize max dist ... fill window int zip in out int in out ... if save orig name char p base name ifname don t save the directory part.
do put char p fault .
correct put char p while p if save orig name ... return ok zip in out .
off t deflate ... while lookahead !
... if hash head !
nil strstart hash head max dist fault .
correct if hash head !
nil prev length max lazy match strstart hash head max dist ... ... while if match available ct tally window return flush block eof deflate icse florence italytable i. part of the fault localization ranked lists produced for seven failing tests of the three fault version of gzip .
tf1 tf2 tf3 tf4 tf5 tf6 tf7 stat ran sus stat ran sus stat ran sus stat ran sus stat ran sus stat ran sus stat ran sus .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
... ... ... ... .
.
.
.
.
.
.
.
.
.
.
... ... .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cond category consists of statements that are executed by some but not all failing tests that have executed si.
the statements in the first category can be interpreted as a deputy for the real faulty statement si.
note for the application of tie breaking scheme the suspiciousness scores of the statements included in the deputy may be the same as that of si.
considering the seven failing tests in table i as the execution of the statement set is always accompanied with the execution of fault statement it can be regarded as a deputy for fault .
similarly the statement sets and can be interpreted as the deputy for fault statement and fault statement respectively.
differently for instance though the statement set is accompanied with the execution of fault in tf2 and tf4 it is not executed by tf1 tf3 tf5 and tf6 which also have executed fault thus it belongs to the second category and cannot be regarded as a deputy for fault .
meanwhile after the application of the tie breaking scheme there may exist some other statements which are ranked lower than si yet have the same suspiciousness score with si and for failing tests the execution of si is always followed with the execution of these statements.
these statements can be interpretted as a pursuer of si.
again let us consider the seven tests in table i as the execution of the statement set is always followed with the execution of fault statement then it can be deemed as a pursuer of fault however the statement set is not a pursuer of fault as it is executed by tf7 yet not by tf2.
definition complete fault indicator a complete fault indicator for a particular fault f whose faulty statement is s is made up of statements from the following three sets i a set that contains the deputy for s ii a set that contains s iii a set that contains the pursuer of s. for statement deleting fault the statement preceding the missing one can be considered to be faulty following the convention adopted by .
should we establish a mechanism to derive complete fault indicators for possible faults in the program it is similar to that we have an ideal sbfl algorithm.
in practice deriving a complete fault indicator for a certain fault can also be difficult.
however note any subset of the statements included in the complete fault indicator for a certain fault f can be used to indicate the execution of f for failing tests to a large extent.
in particular we can view a subset of them whose suspiciousness scores in a ranked list produced for a failing test that has executed f are equal and larger than that of any other statements included in the complete fault indicator for f as the succinct fault indicator for f. for instance the complete fault indicator for fault of the three fault version of gzip is the statement set ... and the succinct fault indicator is the statement set as statement has the highest suspiciousness score .
.
the fault indicator referr ed to in the remainder of this paper is the succinct fault indicator and we will show how to derive it in detail in next section.
b. information from distance calculation execution comparison has been widely used for debugging programs or explaining progra m behavior.
among the various techniques proposed a simple yet effective technique is based on program spectra .
specifically in the nearest neighbor based model for a given failing test ti in a test suite t spectra have been used to select a passing test which most resembles ti according to a certain distance criteri on from t. intuitively the more faults a failing test executes the further the behavior of it is likely to away from the correct behavior it is assumed to be.
modern program development features the creation of a relatively large test suite and thus a correct test that most resembles a failing test in a given test suite can partially represent what behavior the failing test is assumed to be.
these two aspects explain the following observation that we have made during the experimental process observation distance the distance between a multiplefault execution failing test t m let s represent the set of faults executed and its nearest passing test is likely to be larger than the distance between a failing test t f which has executed only part of s and its nearest passing test.
for the three fault version of gzip table ii shows the distance information calculated for failing tests.
the test fault column shows the index of the failing test and the set of faults the failing test has executed while the distance column illustrates the distance between the failing test and the passing test that most resembles it in tp using the ulam distance measure .
icse florence italytable ii.
the ulam distance of the failing tests to their nearest passing tests .
test fault distance test fault distance test fault distance tf5 tf2 tf3 tf6 tf4 tf7 tf1 the underlined tests are the seven tests in table i. the ulamdistance is an edit distance between permutations.
to count ulam distance each profile is first transformed into an ordered sequence of basic blocks of the program sorted by their execution frequencies.
then the distance between two profiles is the number of operations necessary to transform the sorted list of basic blocks from one into that from another.
the merit of ulam distance over euclidean distance is that it makes use of the relevant execution counts but not the counts themselves.
using directly the counts may lead to illogical results.
as an example if two runs just diff er greatly in the execution number of a loop vs using the execution counts to calculate the distance will lead to a great value while the two runs are in fact very close.
we can see from the table that the th failing test which executes all the three faults has the largest calculated distance measure and the calculated distance measures of failing tests that have executed two faults are generally larger than that of failing tests that have executed a single fault.
this observation can be used to help us more accurately derive the fault indicators for possible faults in the program and we will describe this aspect in detail in next section.
iii.
algorithm the inputs to the algorithm include a program p and a test suite t consisting of a set of test cases tp which have passed and another set of test cases tf t1 t2 ... tn which have failed.
the output of the algorithm is a subset ts of tf such that each test in ts has executed a single fault and another subset tm of tf such that each test in tm has executed multiple faults.
our algorithm operates in three main steps.
the first step involves using a certain fault localization algorithm to produce a ranked list for each failing test in tf.
in the second step we contrast the ranked lists produced for different failing tests to derive each failing test s opinion on the potential fault indicator.
finally we synthesize the opinions on potential fault indicators from different failing tests to get real fault indicators and classify the failing tests into ts and tm accordingly.
a. derivation of opinions on likely fault location s for each failing test ti tf it can be combined with tp to form a new test suite ti which can be used by a fault localization algorithm fl to generate a ranked list i of program spectrum i.e.
i fl ti tp ti tf i ... n as discussed in the previous section i actually embodies ti s opinion on the likely fault location s .
any fault localization technique that works with one failing test and a set of passing tests and outputs a ranked list of program spectrum can be us ed e.g.
.
in this paper we use a particular sbfl algorithm naish2 because it is simple and has been demonstrated theoretically as an optimal sbfl formula for single fault scenario .
the formula for naish2 can be represented as suspiciousness si aefi aepi aepi anpi where aefi and aepi represent the number of tests in a given test suite that execute statement si and return the testing result of fail and pass respectively and a npi denotes the number of tests that do not execute si and have the pass testing result.
we expect other suitable fault localization algorithms to deliver similar results and will study this question in future work.
b. derivation of opinions on potential fault indicators though the individual ranked list i may not always pinpoint the actual faulty statement s that failing test ti has executed we can explore it to get useful feedback.
as discussed in the previous section if we can establish a mechanism to derive fault indicators for possible faults in the program then it is similar to that we have an ideal sbfl algorithm .
to achieve this goal we first derive each failing test s opinion on the potential fault indicator.
suppose a failing test ti has executed a certain fault f whose faulty statement is fs.
as described in the previous section the fault indicator for f we try to derive consists of a set a of statements with the same suspiciousness score ss in the ranked list i produced for ti.
according to the characteristic of fault indicator and formula the set a of statements should be executed by all failing tests that have executed f and the suspiciousness scores of them will also be ss in the ranked lists produced for these failing tests .
in general there will be more than one failing test that has executed f in a given test suite.
meanwhile the larger the suspiciousness score of a statement sta in i the more likely it is fs and as the value ss will always be larger than or equal to the suspiciousness score of fs in i consequently the more likely sta belongs to the set a. thus to get ti s opinion on the potential fault indicator we can search i from top to down to find the first common subsequence between it and other individual ranked lists.
note the common here requires not only the same statement index but also the same corresponding suspiciousness score.
in case ti has executed multiple faults the potential fault indicator established is likely for the fault s whose fault indicator s suspiciousness score in i is larger than that of other faults ti has executed.
if a certain fault f has been executed by only one failing test ti and ti has not executed any other faults we may not find a common subsequence between the ranked list i produced for ti and other ranked lists even at the suspiciousness score level l of the actual faulty statement of f in i. searching common subsequences below the level l will return spurious potential fault indicators.
thus we need to set a threshold value miniscore which represents the estimated lowest suspiciousness score of an actual faulty statement in a ranked list and can be set according to the recognition of how seriously coincidental correctness occurs in tp.
as the level of coincidental correctness has been shown to below in most cases especially for the studied programs in this paper whose sizes are relatively icse florence italylarge we use .
as the miniscore throughout the experiment according to i.e .
.
.
formally this step operates in two phases.
algorithm shows the two phases in detail.
the algorithm takes as input a set of ranked lists i i ... n each produced for a failing test and a threshold value miniscore on the minimum suspiciousness score and outputs a set of potential fault indicators pfii i ... n each of which embodies a failing test s opinion on the potential fault indicator and a set of suspiciousness scores ssi i ... n each of which represents the suspiciousness score of the corresponding potential fault indicator.
phase identifying the suspiciousness score for each failing test s opinion on the potential fault indicator.
the aim of the first phase is to identify at what suspiciousness score level the opinion of each failing test on the potential fault indicator can be found.
to achieve this for each failing test ti i ... n line we first use a boolean flag finished to illustrate whether the common subsequence search process has finished or not and set it to false initially line and then we search its corresponding ranked list i from top to down line where length i returns the number of statements in the ranked list i until we find a statement statdesire line which is the statement with the rank rank in i and is returned using the function stat i rank such that a statement statdesire exists at least in one of e e ... n e!
i with the same suspiciousness score as it in i lines where function sus i statdesire returns the suspiciousness score of statement statdesire in i b the suspiciousness score sus i statdesire of statement statdesire is larger than or equal to miniscore .
if statement statdesire has been successfully found we assign its corresponding suspiciousness score sus i statdesire to ssi and finish the search process lines .
otherwise we set ssi to and also finish the search process lines which implies that we believe the fault s that ti has executed has not been executed by other failing tests.
phase deriving each failing test s opinion on the potential fault indicator.
in this phase we will establish each failing test s opinion on the potential fault indicator based on the identified suspiciousness scores.
for each failing test ti line in case ssi equals to pfii will be an empty set as we have no information to establish the fault indicator s for the fault s that ti has executed lines .
otherwise pfii consists of the set of statements with suspiciousness score ssi in i initially line .
on the one hand the suspiciousness scores of different fault indicators may be the same thus pfii may contain multiple potential fault indicators for different faults.
on the other hand even if pfii contains only a single potential fault indicator pfii established this way may include redun dant statements that are executed by ti but not all failing test cases that have executed the corresponding fault of pfii.
note the statements included in a potential fault indicator should be executed by all failing tests that have executed the corresponding fault.
thus to exclude the redundant statements and get possible multiple potential fault indicators we first search each k k ... n k!
i of the other n failing tests to get a test case set testset i wh algorithm derivation of opinions on potential fault indicators input a set of ranked lists i i ... n each produced for a failing test a threshold value miniscore on the minimum suspiciousness score output a set of potential fault indicators pfii i ... n and a set of suspiciousness scores ssi i ... n for i to n phase boolean finished false for rank to length i statdesire stat i rank if sus i statdesire miniscore then ssi finished true else for e to n e !
i if sus e statdesire sus i statdesire then ssi sus i statdesire finished true break endfor if finished true then break endfor endfor phase for i to n phase if ssi then pfii else pfii s sus i s ssi for k to n k !
i if pfii s sus k s ssi !
then testset i k endfor statset pfii if each stata statset is executed by exactly the same test set a testset i i statb pfi i statset statb is not executed by every test of a then indicator i statset pfii indicator i endfor phase return pfii i ... n and ssi i ... n ich contains indexes of failing tests that have common subsequences with pfii lines .
we then search for any subset statset of pfii such that i each statement stata of statset is executed by exactly the same test case set a which is a subset of testset i i and ii for any statement statb that belongs to the subtraction of set pfii and statset statb is not executed by every test of a. if so statset is regarded as a potential fault indicator and will be added to the set indicator i which contains distinct potential fa ult indicators from the viewpoint of ti and will be finally assigned to pfii lines .
example.
take tf7 of the three fault version of gzip as an example as the statement exists in 1 and 2 with the same suspiciousness score .
as it in 7 phase will assign .
to ss7.
in phase pfi7 initially equals to the set of statements with suspiciousness score .
in 7 that is .
as 1 contains a statement set and 2 contains a statement set that have common subsequences with initial pfi7 will be finally returned as tf7 s opinion on the potential fault indicator according to the search mechanism .
similarly the statement sets and will be returned as the opinions on the potential fault indicator for tf1 to tf6 respectively and the corresponding suspiciousness score sets are .
.
.
.
.
and .
respectively.
in this example the opinion of each failing test on the potential fault indicator contains only a single potential fault indicator.
icse florence italyc.
synthesis of potential fault indicators and classification after deriving each failing test s opinion on the potential fault indicator in the previous step we need to synthesize them to get the real fault indicators .
the synthesis and classification process also operates in two phases.
phase establishing child parent relationship between different potential fault indicators and initial classification.
phase involves some initial processing .
first the opinions from different failing tests may directly contain the same potential fault indicator.
the duplicate ones should be deleted .
second a fault may be triggered in different ways.
imagine the situation where m tests fail due to a certain fault f. among the m tests m1 m1 m tests go through a branch b that has seldom been executed by passing tests.
according to the previous steps described the statements inside the branch b will get a high suspiciousness score in the ranked lists produced for these m1 failing tests and are like ly to be returned as a potential fault indicator pfi from the viewpoint of these m1 failing tests.
however pfi is in fact not indicative enough of f. this kind of spurious fault indicator can be interpreted as a child of the real fault indicator of f. note that a real fault indicator may have many children.
commonly we can distinguish a real fault indicator rfi from its child fault indicator cfi as failing tests which return a cfi as or as part of their opinions on the potential fault indicator will always also execute the r fi.
phase will use this characteristic to identify real fault indicators and get an initial classification of the failing tests.
algorithm shows the detailed process.
the algorithm takes as input the set tf of failing tests a set of potential fault indicators pfii i ... n and their corresponding suspiciousness score set ssi i ... n derived in the previous step and outputs single fault execution failing test set ts and multiple fault execution failing test set tm.
phase begins with a set of initialization and preparation steps.
in line the function dupremove i removes the duplicate potential fault indicators in the input set i and assigns the remaining unique elements to a set ini the set r which contains the real fault indicators and the returned sets ts and tm are initialized to be empty set s. then the function descendingsort ini sorts the potential fault indicators in ini by suspiciousness score in descending order and assigns the result to an array arr line .
finally for each potential fault indicator arr in arr a set arr .child which contains all possible children of arr is set up and initialized to be an empty set lines .
then we try to establish the possible child parent relationship between different potential fault indicators.
as a child fault indicator s suspiciousness score is always larger than that of its parent real fault indicator the process starts with the array index .
for each array index i we first establish a set testset which contains failing tests whose opinions on the potential fault indicator include arr line where opinion t returns test t s opinion on the potential fault indicator .
then we check each potential fault indicator with array index j larger than i line such that i arr is a non empty set ii the suspiciousness score of arr sus arr is not equal to that of arr sus arr and iii arr is executed by every test of testset lines .
if so arr is deemed as a child of arr line .
algorithm synthesis of potential fault indicators and classification input a set tf of failing tests a set i of potential fault indicators pfii i ... n and a set of suspiciousness scores ssi i ... n output ts and tm ini dupremove i r tm ts phase arr descendingsort ini for i to arr.length arr .
child endfor for i to arr.length testset t t tf arr opinion t for j i to arr.length if arr !
sus arr !
sus arr then if each test in testset has executed arr then arr .
child arr endfor endfor for i to arr.length if j i j arr.length arr arr .
child then r arr endfor foreach rfi r update rfi.child endfor foreach t tf if t executes more than one element from r then tm t else ts t endfor phase foreach rfi r phase if rfi.child !
then newtestset tests1 rfi boolean repeat true while repeat if c rfi.child t1 a tests2 c t2 newtestset a ulam t1 np t1 ulam t2 np t2 then repeat true tm a ts a newtestset a rfi.child c else repeat false endwhile endfor phase return ts tm according to the possible child parent relationship established a child of a real fault indicator can possibly become the parent of another child of this real fault indicator.
to get the real fault indicators we identify a set of potential fault indicators such that each of them cannot be a child of any other potential fault indicators and add them to the real fault indicator set r lines .
moreover it may happen that a is a child of b and b is a child of c but a is not a child of c. to address this for each real fault indicator rfi from r we update its children information by iteratively viewing the children of its current children also as its children lines .
finally for each failing test t of tf we check the number of fault indicators from r t has executed if the number is larger than t is added to tm otherwise it is added to ts lines .
phase refining the initial classification using ulamdistance measures.
this phase refines the classification made in phase .
while failing tests that return a child fault indicator as or as part of their opinions on the potential fault indicator will always execute the real fault indicator the phenomenon that a set of failing tests whose opinions on the potential fault indicator include a all execute another potential fault indicator b whose suspiciousness score is smaller than that of a does not necessarily mean that a is a child of b. consider a two fault faults f1 and f2 version program where failing tests execute f1 icse florence italyconstitute a set s1 and failing tests execute f2 constitute a set s2 and s1 happens to be a subset of s2.
since the execution of f1 is likely to be accompanied with the execution of f2 but not vice versa that is the number of passing tests execute f2 is likely to be larger than that execute f1 the suspiciousness score of the real fault indicator rfi1of f1 in a ranked list is likely to be larger than that of the real fault indicator rfi2 of f2 in a ranked list according to .
consequently suppose the potential fault indicators returned by the tests in sets s1 and s2 s1 are real fault indicators then the potential fault indicators returned by the tests in set s1 are likely to be rfi1 and the potential fault indicators returned by the tests in set s2 s1 are likely to be rfi2.
however obviously rfi2 will also be executed by tests in s1.
to determine whether an established child of a real fault indicator rfi from the set r in phase is really a child of rfi or is in fact indicative of a new fault we use the observation made in the previous section about ulam distance between tests.
the major idea is that if a child of a real fault indicator rfi is indicative of a new fault then the ulam distance measures between tests related with this child in ts to their nearest passing tests are likely to be larger than the ulam distance measures between some other tests related with the rfi in ts to their nearest passing tests.
phase of algorithm gives the detailed mechanism.
for each real fault indicator rfi that belongs to r and has at least one child lines the algorithm first creates a test case set newtestset line using the following function tests1 rfi t t ts rfi pfis t opinion t rfi.child!
fi r fi pfis t where function pfis t returns the set of potential fault indicators that test t has executed.
in other words newtestset contains a subset of ts such that each of them has executed rfi or has not executed any real fault indicators yet its opinion on the potential fault indicator includes a child of rfi.
then it checks whether there exists a child fault indicator c of rfi such that for any test t1 of the test set a which contains tests of newtestset that have executed c and is returned using the following function tests2 c t t newtestset c pfis t the ulam distance between it and its nearest passing test ulam t1 np t1 is larger than the ulam distance between any test t2 of the set newtestset a and its nearest passing test ulam t2 np t2 line .
if such a c exists c is deemed to be indicative of a new fault and tests of set a are removed from ts and added to tm line .
after removing tests of a from newtestset and c from the set that contains rfi s children line the check process repeats to see whether there exists a child of the updated rfi which in fact is indicative of a new fault.
in this paper for a child c of a real fault indicator rfi to be indicative of a new fault we require that the ulam distance measures of all tests i.e.
related with c in ts to their nearest passing tests are larger than that of any other tests related with rfi in ts to their nearest passing tests we will study the results of using a high percentage e.g.
in future work.
example.
for the three fault version of gzip as tf2 and tf4 which return as their opinions on the potential fault indicator both execute the potential fault indicator whose suspiciousness score is smaller than that of the poten tial fault indicator will be viewed as a child of the potential fault indicator .
similarly the potential fault indicator will be viewed as a child of the potential fault indicator .
as the potential fault indicators and cannot be children of any other potential fault indicators they will be added to the real fault indicator set r. consequently as tf1 and tf2 have executed more than one fault indicator of r they will be classified as multiple fault execution failing tests and the other five are classified as single fault execution failing tests in phase .
in phase as we can see from table ii that tf5 which has executed a child of the real fault indicator has the largest ulam distance measure to the nearest passing test among the four tests tf3 tf4 tf5 and tf6 which have only executed the real fault indicator and its possible children and then is deemed to be indicative of a new fault and tf5 will be classified as a multiple fault execution failing test.
remark after the establishment of single fault execution failing tests we can also group failing tests due to the same fault together.
test cases of ts that have executed a common real fault indicator rfi from r or have not executed any real fault indicators yet their opinions on the potential fault indicators include a child of rfi could be clustered together i.e.
they are deemed to have executed the same fault .
in case an identified single fault execution failing test t s opinion on the potential fault indicator is an empty set t forms a cluster that contains only t. in this example the identified single fault execution failing tests tf3 tf4 and tf6 have executed the same real fault indicator from r and thus form a cluster.
the remaining identified single fault execution failing test tf7 forms another cluster.
iv.
evaluation a. subject programs we used five medium sized c language programs that have been popular for software engineering research in the experimental evaluation e.g.
the four unix utilities sed flex grep and gzip and the program space developed at the europe space agency.
all of them were obtained from the subject infrastructure repository sir along with their test cases.
programs sed flex grep and gzip have the number of test cases and respectively.
as the original test suite provided in sir for space contains over test cases to enable the experiment to scale we used a subset of it.
the subset was obtained by first randomly selecting five small test suites with a size of from the original test suite and then uniting these five test suites.
finally the number of test cases used for space is .
for each program our experiment required faults.
to achieve this we used faults provided in sir as well as faults generated by way of random mutation following the methods described in .
overall we attempt to cover typical faults programmers made in practice.
b. experimental setup to enable the examination of our technique s performance we first created a set of multiple fault versions for each program.
for each program we created all the two fault versions icse florence italy choose then all the three fault versions choose and on up to all the eight fault versions choose that could be derived from the program s faults.
in other words for each program the number of multiple fault versions created is n ii next for each multiple fault version we executed the entire test suite storing the output and profile for each test.
then we compared the outputs against the outputs derived from a reference version of the program that contained none of the injected faults to determine the passing or failing results of the tests.
in total the technique is evaluated on multiple fault versions and the number of tests executed is over million.
the coverage of each test is captured using the gcov utility.
all the experiments were carried out on an ubuntu .
machine with .
ghz intel quad core cpu and gb of memory.
c. evaluation measures to evaluate our technique we use the following measures that have been widely used to evaluate classification results precision recall and f measure.
precision the ratio of the number of failing tests correctly classified as ones that have executed a single fault n s s to the total number of failing tests classified as ones that have execu ted a single fault ns s nm s .
single fault precision p s ns s ns s nm s recall the ratio of the number of failing tests correctly classified as ones that have executed a single fault ns s to the total number of failing tests that have actually executed a single fault ns s ns m .
single fault recall r s ns s ns s ns m f measure a composite measure of precision and recall.
specifically we use the f measure that weights recall and precision equally.
single fault f measure f s p s r s p s r s d. results and analysis classification performance table iii shows the average performance of our technique.
the fault number column represents the number of faults seeded in the program.
the column titled a displays the percentage of actual single fault execution failing tests in our experimental evaluation whereas the p r f columns show the results for evaluation measures precision recall and f measure respectively .
for each program and fault seeded number n the results depicted are the products of averaging the results across all n fault versions .
we can see from column a of this table that with the increase of the fault seeded number n the number of multiple faultexecution failing tests is also increasing significantly .
therefore the separation of the single fault execution and multiplefault execution failing tests is of significant value.
with regard to the precision of the technique it can be seen from this table that for all program and fault seeded number combinations the precision achieved by our technique is much better than the precision obtained by assuming all failing tests are single fault execution ones i.e.
the values depicted in column a. the larger the fault seeded number the more significant the difference.
for the fault version of space for example the distinction can be as large as .
.
.
.
thus the precision can be viewed as satisfactory.
in certain cases we not only want to achieve a high precision but also demand as many single fault execution failing tests as possible.
thus the recall evaluation measure is also crucial.
in terms of recall our approach also achieves promising results.
first the recall values are relatively large for all program and fault seeded number combinations.
for of the programs besides space the recall values are equal or above .
for all fault seeded number values.
second the recall values generally differ not much with the variation of the fault seeded number.
the f measure synthesizes the precision and recall measures and has been widely used to evaluate the overall performance of a method.
even for the fault versions of the five programs the average f measure achieved by our technique is around or above .
which is a reasonable value to certify the effectiveness of our technique.
collectively the performance of our technique is promising.
the detailed evaluation results are presented in figs.
and as distributions.
for each fault seeded number n the horizontal axis presents the three evaluation measures denoted as n p n r and n f respectively and another precision measure which is the precision obtained by assuming all failing tests are single fault execution tests and is denoted directly usi ng n and the vertical axis depicts the calculated values.
for each faultseeded number n the data points contained in the four corresponding box plots equal to the number of all the n fault versions i.e.
choose n. the line inside each box marks the median value and the edges of the box mark the first and third quartiles.
the whiskers extend from the quartiles and cover of the distribution outliers are shown as points beyond the whiskers.
by comparing the distributions regarding the two precisio n measures we can see that our technique can consistently offer great gain especially when the fault seeded number n is large.
for the three evaluation measures the median value line is generally closer to the third quartile box edge than the first quartile box edge.
also the whisker line extended from the third quartile box edge is nearly always much shorter than the whifig.
.
performance evaluation measure s distribution for sed.
icse florence italytable iii.
the average classification performance of our technique on the five subject programs .
fault number sed flex grep gzip space a p r f a p r f a p r f a p r f a p r f .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
fig.
.
performance evaluation measure s distribution for flex grep gzip and space.
sker line extended from the first quartile box edge.
these two aspects suggest it is highly probable that our technique can offer a relatively accurate classification.
clustering result as described above our technique can also cluster the identified single fault execution failing test cases.
to evaluate the clustering result we use two measures cluster purity and quantity of clusters .
for a cluster c the purity of it is defined using the most represented fault f that is the number of actual single fault execution failing test cases that executed f within c is larger than that executed any other faults involved with c. formally cluster purity is defined as t c t actullay has executed only faul t f t c .
table iv presents the av erage results of these two measures across all n fault versions for each fault seeded number n and each program.
the parent hesized number is measure quantity of clusters .
for measure cluster purity we first average the results obtained for differrent clusters to get a value for each particular program version.
we can see from this table that the quanti ty of clusters is generally small which means the number of redundant clusters is generally small and the cluster purity is all above .
which implies most failing tests within a certain cluster are actual single fault execution failing tests that have executed the same fault.
overall the clustering result of the identified single fault execution failing tests is satisfactory.
discussion an important limitation of our current technique is that it suffers from the occurrence of accompanyexecution fault set.
the accompany execution fault set refers to a set f of faults where for any fault f f failing tests execute f will always also execute the other faults of f. acco932 icse florence italytable iv.
clustering results of the identified single faultexecution failing tests for the five subject programs .
fault number sed flex grep gzip space .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rding to the mechanism of our technique in deriving fault indicators for possible faults it is very likely that a single fault indicator will be returned for all faults involved in an accompany execution fault set.
then if a set t of failing tests execute only faults involved in an accompany execution fault set these failing tests will be wrongly classified as single faultexecution tests .
deriving fault indicators for faults involved in an accompany execution fault set is inherently difficult and we will explore this theme as well as other threads of directions to improve the accuracy of inferring fault indicators for possible faults in future work.
threats to validity the primary threat to external validity of this paper arises because only five medium sized c programs have been used in the experimental evaluation.
however all these programs are real life programs and for each program our technique is evaluated across multiple fault versions.
hence we expect the results from our study to be representative.
another concern with generalization is that we only evaluated the subjects from two to eight faults and therefore we cannot make any claims about how the results will generalize above eight faults.
however the results in table iii and figs.
and display a consistent trend i.e.
the more faults a program contains the larger number of multiple faultexecution failing tests it is likely to have and the more actual benefit our technique will have.
a final issue is that some faults used are created using mutation based fault injection and thus are potentially not representative of real faults.
to minimize this issue we strictly followed the methods described by offutt et al.
during the mutant generation process.
in addition mutation based fault injection has been shown to be an effective approach to simulating realistic faults that can be used in research to yield trustworthy results .
the main threat to internal validity for our study is that there may be faults in our implementation of the algorithm.
to reduce this threat we carefully inspect all of the code produced and test it on known concrete examples.
the major threat to construct validity for this study concerns the appropriateness of the evaluation measures used.
we used evaluation measures precision recall and f measure that have been widely used to evaluate a binary classification method to reduce this threat.
v. related work contrasting each failing test with all the passing tests in a given test suite to get an individual ranked list of program elements has already been used in some failure clustering techniques .
while our technique seeks to infer fault indicators for possible faults by searching the earliest common subsequence between each ranked list and the other ranked lists failure clustering techniques typically use a distance function to quantify the agreement between different ranked lists and then group failures that are likely due to the same fault s together based on the calculated distances.
the distance measure used varies by the characteristic of the elements in the ranked lists.
the kendall s tau distance is used in while the jaccard set similarity is employed to calculate distance in .
besides hsu et al.
studied the longest common subsequence among all the ranked lists to help understand the fault in single fault scenario.
the calculation of the distance between a failing test and other passing tests has also been used in other debugging tasks.
to isolate the location of the bug renieris and reiss propose the nearest neighbor model which first finds a passing test that has coverage that is most similar to the coverage of the failing test according to the ulam distance metric and then removes the set of statements executed by the selected passing test from the set of statements executed by the failing test.
the programmer should start his her search for the fault from the resulting set of program statements.
the nearest neighbor model has further been introduced as a means for selecting execution peers in .
in addition several works regarding debuging try to generate passing tests that are as close as to the failing tests to improve debugging effectiveness from different perspectives .
in this paper our observation explores the distance between failing tests and passing tests from a totally new perspective.
vi.
conclusions and future work being able to distinguish single fault execution failing tests from multiple fault execution failing tests supports debugging techniques that suffer from the single fault failure assumption.
we presented a technique which suitably combines information from i a set of fault localization ranked lists each produced for a certain failing test and ii the distance between a failing test and its nearest passing test to infer fault indicators for possible faults to achieve this goal in this paper.
our evaluation of the technique provides initial yet strong evidence that the performance of the technique in terms of evaluation measures precision recall and f measure is promising.
in addition for the identified single fault execution failing tests the proposed technique can also appropriately cluster them.
for future work we will apply the technique to larger programs and programs shipped with more than eight faults to verify the performance of the technique in general.
we would also like to investigate how to improve the accuracy of inferring fault indicators for possible faults of the program especially for faults involved in an accompany execution fault set.
acknowledgment we thank the anonymous reviewers very much for their invaluable comments and suggestions.
we are also grateful to professor tsong yueh chen for his feedback on the earlier version of this paper.
the work is supported in part by grants from national natural science foundation of china nos.
and .
icse florence italyreferences s. artzi j. dolby f. tip and m. pistoia practical fau lt localization for dynamic web applications i n international conference on software engineering icse pp.
.
j.f.
bowring j.m.
rehg and m.j. harrold active learning for automatic classification of software behavior i n international symposium on software testing and analysis issta pp.
.
d. cotroneo r. pietrantuono s. russo a learning based method for combining testing techniques i n international conference on software engineering icse pp.
.
v. dallmeier a. zeller and b. meyer generating fixes from object behavior anomalies i n international conference on automated software engineering ase pp.
.
w. dickinson d. leon and a. podgurski finding failures by cluster analysis of execution profiles i n international conference on software engineering icse pp.
.
n. digiuseppe and j.a.
jones on the in fluence of multiple faults on coverage based fault localization i n international symposium on software testing and analysis issta pp.
.
n. digiuseppe and j.a.
jones software behavior and failure clustering an empirical study of fault causality i n international conference on software testing verification and validation icst pp.
.
h. do and g. rothermel on the use of mutation faults in empirical assessments of test case prioritization techniques ieee transactions on software engineering tse .
h. do s. elbaum and g. rothermel supporting controlled experimentation with testing techniques an infrastructure and its potential impact empirical software engineering an international journal ese .
s. horwitz b. liblit and m. polishchuk better debugging via output tracing and callstack sensitive slicing ieee transactions on software engineering tse .
h. y. hsu j. a. jones and a. orso rapid identifying bug signatures to support debugging activities i n international conference on automated software engineering ase pp.
.
d. jeffrey n. gupta and r. gupta fault localization using value replacement i n international symposium on software testing and analysis issta pp.
.
t. jiang l. tan and s. kim personalized defect prediction in international conference on automated software engineering ase pp.
.
j.a.
jones j.f.
bowring and m.j. harrold debugging in parallel i n international symposium on software testing and analysis issta pp.
.
j.a.
jones m.j. harrold and j. stasko fault localization using visualization of test information i n international conference on software engineering icse pp.
.
j.a.
jones and m.j. harrold empirical evaluation of the tarantula automatic fault localization technique in international conference on automated software engineering ase pp.
.
r. just d. jalali l. inozemtseva m. d. ernst r. holmes and g. fraser are mutants a valid substitute for real faults in software testing?
in international symposium on the foundations of software engineering esec fse pp.
.
s. kaleeswaran v. tulsian a. kanade and a. orso minthint automated synthesis of repair hints i n international conference on software engineering icse pp.
.
d. kim j. nam j. song and s. kim automatic patch generation learned from human written patches in international conference on software engineering icse pp.
.
s. kim h. zhang r. wu and l. gong dealing with noise in defect prediction i n international conference on software engineering icse pp.
.
b. liblit m. naik a.x.
zheng a. aiken and m.i.
jordan scalable statistical bug isolation i n programming language design and implementation pldi pp.
.
c. liu and j. han failure proximity a fault localization based approach i n international symposium on the foundations of software engineering esec fse p p. .
w. masri ra.
assi prevalence of coincidental correctness and mitigation of its impact on fault localization acm transactions on software engineering and methodology tosem article .
j. nam s. j. pan and s. kim transfer defect learning i n international conference on software engineering icse pp.
.
h.d.t.
nguyen d. qi a. roychoudhury and s. chandra semfix program repair via semantic analysis i n international conference on software engineering icse pp.
.
a.j.
offutt a. lee g. rothermel r.h. untch and c. zapf an experimental determination of sufficient mutation operators .
acm transactions on software engineering and methodology tosem .
a. podgurski d. leon p. francis w. masri m. minch j. sun and b. wang automated support for classifying software failure reports i n international conference on software engineering icse pp.
.
y. qi x. mao y. lei z. dai and c. wang the strength of random search on automated program repair i n international conference on software engineering icse pp.
.
d. qi a. roychoudhury z. liang and k. vaswani darwin an approach to debugging evolving programs acm transactions on software engineering and methodology tosem article .
m. renieris and s.p.
reiss fault localization with nearest neighbor queries in international conference on automated software engineering ase pp.
.
h. seo and s. kim predicting recurring crash stacks in international conference on automated software engineering ase pp.
.
w.n.
sumner t. bao and x. zhang selecting peers for execution comparison i n international symposium on software testing and analysis issta pp.
.
c. sun and s. c. khoo mining succinct predicated bug signatures i n international symposium on the foundations of software engineering esec fse p p. .
i. vessey expertise in debugging computer programs a process analysis international journal of man machine studies .
icse florence italy x. wang s. cheung w. chan and z. zhang taming coincidental correctness coverage refinement with context patterns to improve fault localization i n international conference on software engineering icse pp.
.
t. wang and a. roychoudhury automated path generation for software fault localization in international conference on automated software engineering ase pp.
.
w. weimer t. nguyen c. le goues and s. forrest automatically finding patches using genetic programming in international conference on software engineering icse pp.
.
j. xuan and m. monperrus test case purification for improving fault localization i n international symposium on the foundations of software engineering esec fse pp.
.
x. xie t. y. chen f. c. kuo and b. xu a theoretical analysis of the risk evaluation formulas for spectrum based fault localization acm transactions on software engineering and methodology tosem article .
z. yu c. bai and k. y. cai mutation oriented test data augmentation for gui software fault localization information and software technology ist .
z. yu h. hu c. bai and k. y. cai gui software fault localization using n gram analysis in international symposium on high assurance systems engineering hase pp.
.
y. yu j.a.
jones and m.j. harrold an empirical study of the effects of test suite reduction on fault localization i n international conference on software engineering icse pp.
.
a. zeller yesterday my program worked.
today it does not.
why?
i n international symposium on the foundations of software engineering esec fse p p. .
a. zeller and r. hildebrandt simplifying and isolating failureinducing input ieee transactions on software engineering tse .
x. zhang n. gupta and r. gupta locating faults through automated predicate switching i n international conference on software engineering icse pp.
.
x. zhang s. tallam n. gupta and r. gupta towards locating execution omission errors i n programming language design and implementation pldi pp.
.
icse florence italy