predicting licenses for changed source code xiaoyu liu1 liguo huang1 jidong ge2and vincent ng3 1department of computer science southern methodist university dallas tx usa 2state key laboratory for novel software technology nanjing university nanjing china 3human language technology research institute university of texas at dallas richardson tx usa abstract open source software licenses regulate the circumstances under which software can be redistributed reused and modified.
ensuring license compatibility and preventing license restriction conflicts among source code during software changes are the key to protect their commercial use.
however selecting the appropriate licenses for software changes requires lots of experience and manual effort that involve examining assimilating and comparing various licenses as well as understanding their relationships with software changes.
worse still there is no stateof the art methodology to provide this capability.
motivated by this observation we propose in this paper automatic license prediction alp a novel learning based method and tool for predicting licenses as software changes.
an extensive evaluation of alp on predicting licenses in open source projects demonstrate its effectiveness alp can achieve not only a high overall prediction accuracy .
in micro f1 score but also high accuracies across all license types.
index t erms software license prediction mining software repository i. i ntroduction in recent decades more and more free and open source software foss projects have been made available online by developers.
the shift towards foss projects allows developers to not only contribute to the software community but also benefit themselves .
for example by hosting their foss projects on web based version control platforms e.g.
github sourceforge etc.
developers can receive help from thirdparty testers and other developers to improve the quality of their software systems.
nevertheless developers who are interested in releasing their projects to the open source community should be aware that the redistribution reuse and modification of their projects must be regulated under software licenses.
software licenses are important because they are designed to protect the intellectual property of foss using licensing mechanisms and copyright notices that determine how an open source software can be re used .
to apply appropriate software licenses to their software projects developers need to select from a variety of licenses either the ones that allow redistributors to incorporate the reused software under different licenses i.e.
permissive licenses or the ones that require developers to use the same license when distributing new software that incorporates the reused software i.e.
restrictive licenses .
these licenses range from highly restrictive e.g.
the general public license gpl family which requires developers to use gpl to distribute new software that reuses gpl software to less restrictive e.g.
the mit license which permits a third partyto freely modify reuse and redistribute the project by keeping term notices .
therefore selecting the appropriate license for a given piece of software requires a great deal of experience and manual review effort on the part of developers.
while there exists methods that help developers choose appropriate licenses when a software project is initially released an important question remains how can licenses be updated when changes are made in software systems?
v endome et al.
shed light on the aforementioned question by investigating the rationales behind license changes due to software changes from both quantitative and qualitative points of view.
their study reveals that updating the license in the presence of software changes is an even more timeconsuming and labor intensive process than determining the license for a newly released software project.
specifically a developer has to review each changed source code file against the existing licenses to determine whether there is any license incompatibility such as the violation of existing license terms copyright or the presence of a license that is incompatible with the license of another piece of changed source code.
consider the example in figure which shows that a co changed source code module 1logentry is imported to the source code file xmlpacker .java that was originally licensed under mpl v1.
according to its file header.
to determine if a change of license is needed the developer would begin by determining that logentry is distributed under license gpl v3 .
then it requires a careful review and comparison of the license restrictions of mpl v1.
and those of gpl v3 to reveal a potential incompatibility between them.
that is a software system that imports or uses logentry is required to adopt gpl v3 which imposes a stronger restriction than mpl v1.
.
detecting and resolving such incompatibilities thus places a lot of burden on developers.
unfortunately according to v endome et al.
existing methods and tools for license prediction are insufficient for the task of predicting licenses in the presence of software changes .
for instance ninka a stateof the art license detection method uses regular expressions to predict licenses by detecting the presence of license copyright and terms in the header comments of the source code files i.e.
the file header .
hence ninka has no problem with independently detecting mpl v1.
as the license adopted 1a source code file f1is a co changed file of another source code file f2 if the two files both changed in a single change commit.
34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
changed imports in xmlpacker.java xmlpacker.java was licensed with mpl v1.
read code logentry uses gpl v3 extract license read gpl v3 restrictions read mpl v1.
restrictions from header comment comparedecide to apply gpl v3 developer bgpl v3 restriction snippet mpl v1.
restriction snippet fig.
example illustrating licensing incompatibility byxmlpacker .java before the code change and gpl v3 as the license adopted by logentry .
however ninka cannot detect file dependencies.
so in our example it cannot take into account the license restriction imposed by the newly imported code module.
failure to do so deprives ninka of its ability to address the license compatibility issues that arise from code changes.
our goal in this paper is to advance the state of the art in license prediction for software changes.
specifically we propose automatic license prediction alp a novel method and supporting tool for automatically predicting source code file level licenses for code changes.
leveraging the recent successes of machine learning methods in empirical se research we propose a learning based alp system.
at the core of alp are four key ideas exploiting a rich set of features extracted from the inline text of the changed file under consideration modeling the license of the previous version of the file exploiting features extracted from the associated software documents and co changed files and identifying and resolving incompatibilities such as those illustrated in figure .
our contributions in this paper are three fold.
first we manually annotate the licenses of changed source code files taken from java projects hosted on github.
to our knowledge this is the first large scale effort aiming to create an annotated corpus for license prediction.
second we propose alp the first machine learning approach to license prediction which considers the dependencies among the licenses of the source code modules.
note that the development of alp is made possible by the availability of the large amount of annotated training data provided by our corpus.
finally extensive experiments demonstrate the effectiveness of our approach.
in an evaluation on java projects involving the prediction of software licenses alp achieves a micro f1 score of .
highly significantly surpassing the performance of three baseline systems including ninka which only achieves a micro f1 score of .
on the same corpus.
we believe our results have another important ramification.
v endome et al.
s study of the rationales behind license changes due to software changes were based on the automatic annotations provided by ninka .
however ninka s rather mediocre performance on our corpus casts doubts on thedegree to which the conclusions drawn by v endome et al.
are valid.
we believe that it is worthwhile to re examine their conclusions by re conducting their study using alp s output which is considerably more accurate than ninka s. ii.
d ata prepara tion we collect a large set of historical change repositories from java projects hosted on github.
these projects and their historical change repositories are previously used by v endome et al.
in the aforementioned empirical study.
we determine the ground truth license name e.g.
gpl mit etc.
and version e.g.
v1 v2 etc.
of each changed file in each change commit via an open coding procedure.
all changed files are coded by two coders both of whom are senior software engineering ph.d. students who have extensive experience in industry as developers.
initially one of the coders conducted a pilot study on a subset of the changed files and their associated software documents.
this subset was chosen in the following manner.
first projects and their change commit histories were randomly chosen from the dataset.
then one file was selected randomly from each of the change commit histories.
the purpose was to obtain as many different types of licenses and relevant text statements as possible.
the pilot study resulted in a list of preliminary coding criteria.
each criterion either describes the conditions under which a license is applicable and or enumerates the license s for which a given term is a possible indicator.
for example one criterion says that if the term as is appears in a license s text then either lgpl v3 a highly restrictive license or bsd a fairly restrictive license should be the license.
moreover the choice depends on whether an incompatibility between the licenses exists if there is no incompatibility then bsd suffices.
then this coder trained the other coder on the coding criteria.
after training both coders simultaneously coded all the changed files in the dataset.
as for inter coder agreement the coders achieved an agreement ratio i.e.
the percentage of changed files that are assigned the same license by the two coders of .
and a cohen s kappa of .
which indicates moderate agreement .
disagreements in their annotations were resolved by open discussion.
disagreement primarily stems from the coders differing interpretations of the terms of the licenses.
for example one coder mistakenly assigned authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i annotation examples changed file software doc co changed file example n a .
.
.
you can redistribute it and or modify it under the terms of the gnu general public license version ...can redistribute it and or modify it under the terms of the gnu lesser general public license as published by the free software foundation either version .
of the license or at your option any later version ... example .
.
.
licensed under the apache license version .
...program is made available under the terms of the eclipse public license v1.
which accompanies this distribution.
.
.the mit license original work sponsored and donated b y ... lgpl v3 as the license after seeing the term as is because he determined that a license incompatibility exists due to his interpretation of the terms.
every case of disagreement was resolved when the coders reach a common interpretation of the terms.
to enable the reader to get a better idea of how the files are annotated table i shows two examples.
as can be seen each example is composed of the changed file under consideration the associated software document and its cochanged file.
owing to space limitations only the snippet of each file document that is relevant to license prediction is shown.
in example the software document suggests that gpl v2 should be adopted while the co changed file suggests that lgpl v2.
should be adopted.
there is a license conflict between gpl v2 and lgpl v2.
.
since lgpl v2.
has a stronger copyleft than gpl v2 in order to accommodate the strong copyleft imposed by the co changed file this changed file should be labeled as lgpl v2.
.
in example the three different resources suggest three different licenses the changed file suggests apache v2 the document suggests epl v1 and the co changed file suggests mit.
since apache v2 epl v1 and mit are all permissive licenses with no incompatible clauses declared there is no need to alter the changed file s license.
in other words the changed file should be labeled as apache v2.
statistics of the resulting dataset which contains changed files annotated with their licenses are shown in table ii.
from table ii a we can see that there are totally licenses2that have appeared at least once in the projects.
table ii b shows the distribution of the licenses over the changed files non licensed is used when a license is absent in a changed file while other shows the statistics aggregated 2according to german et al.
all licenses are frequent foss licenses and are detectable by ninka .table ii dataset statistics of systems of commits of changed files a overall statisticslicenses of changed files apache v2 .
gpl v2 .
gpl v3 .
mit .
lgpl v3 .
lgpl v2.
.
bsd .
epl v1 .
other .
non licensed .
b per license frequencies of license changed files .
of license unchanged files .
c license change statistics over the remaining lowest frequency licenses.
.
as we can see from table ii b the most frequently used license is apache v2 .
.
this is perhaps not surprising apache v2 extends software users enough freedom to use it for any purpose.
table ii c shows the percentages of changed files that involved a license change in the collected projects.
as we can see .
of them have their license changed.
given this dataset we create a multi class prediction task where we seek to predict each changed file as having either one of the licenses or non licensed i.e.
the associated file does not have a license .
for the sake of brevity we will refer to the class non licensed simply as one of the licenses to be predicted in the rest of the paper.
iii.
b aseline approaches this section introduces three baseline approaches that we implement for controlled experiments with our alp system.
a. ninka as our first baseline we employ a state of the art license prediction system ninka .
ninka is inspired by the observation that the information about a source code file license is typically found in the inline textual comment at the beginning of a source code file i.e.
the file header .
in other words ninka detects the license of a changed source code file by relying on its file header.
specifically given a changed source code file ninka first extracts the file header and segments it into a sequence of sentences each of which is normalized by replacing each of its phrases with its equivalent common version without changing its meaning.
then it leverages a set of pre defined regular expressions built upon these common terms to detect the presence of the license copyrights and terms.
finally it outputs a list of licenses that are matched by their corresponding copyrights or terms in the file header.
in our experiments we use a publicly available implementation 3these licenses and their percentages are mpl v1.
.
ecl v2 .
lgpl v2.
.
lgpl v3 .
sharealike v3 .
osl v3 .
ecl v1 .
lgpl v1 .
cpl v1 .
apache v1.
.
microsoft .
cddl v1 .
public domain .
gpl v1 .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ofninka 4considering its prediction for a changed file correct as long as one of the licenses in the list of predictions it returns is correct.
note that since we allow ninka to return more than one prediction for a given file we are effectively giving it an unfair advantage over other systems that return only one prediction per file.
to give the reader a better sense of ninka s weakness we apply ninka to the example shown in figure .
ninka starts by extracting and normalizing the file header of xmlpacker .java .
then all the pre defined regular expressions are applied to the file header.
among them the regular expression built for detecting the license mpl v1.
matches the term mpl in the file header sentence if you do not delete the provisions above a recipient may use your version of this file under the terms of any one of the mpl .
hence ninka incorrectly predicts that xmlpacker .java adopts mpl v1.
.
it fails to make the correct prediction gpl v2 because it does not consider the potential conflict with the license restrictions imposed by the changed import code module logentry licensed under gpl v2 which specify that you may not propagate or modify a covered work except as expressly provided under this license .
b. caller callee cc as mentioned in the introduction developers often reason about license changes based on code imports.
german et al.
conduct an empirical study showing that software package dependency needs to be combined with license information to identify potential cases of redistribution with license incompatibilities.
in other words any change in the licenses of the imports imports are often referred to as the callee may affect the license of the changed file under consideration changed files are often referred to as the caller .
for example if a caller a.java licensed under apache v2 imports callee b.class while b.class s license is updated to gpl v3 then both b.class and a.java should adopt gpl v3 since gpl v3 is more restrictive than apache v2.
consequently developers examine the imported code modules and their licenses typically assigning to the changed file the license that is associated with the largest number of imported code modules.
our second baseline caller callee cc attempts to mimic this human decision process.
note that it is applicable to both imported third party external libraries as well as projectinternal classes.
we implement cc as follows.
given a changed file whose license is to be predicted cc first extracts all imports using an off the shelf tool called qdox .
next it extracts the licenses associated with the imported code modules.
we leverage two tools to do this ninka which extracts the licenses of imported local classes and licensefinder which extracts the licenses of imported third party libraries.
using the extracted licenses cc assigns a license to the changed file under consideration based on the majority rule .
specifically the extracted licenses are ranked by the number of imported code modules that adopt them a.k.a.
the import vote and fig.
an example of imported code modules and licenses of fluentlist.java the license with the largest number of votes is returned.
our decision to employ the import vote is inspired by german et al.
s finding that software package dependency needs to be combined with license information to identify potential cases of redistribution with license incompatibilities and the intuition that developers simply license a piece of software under the one adopted by a majority of its imports.
if none of the imports are licensed cc will classify the changed file as non licensed .
to give the reader a better sense of cc s weakness we apply it to the example shown in figure .
cc starts by extracting all imported classes and libraries of fluentlist.java and then determines which license each of them adopts.
all imports and their licenses are listed in figure .
to decide which license to choose for fluentlist.java cc determines that imported code modules adopt apache v2 one adopts gpl v2 and two arenon licensed .
using the import vote it incorrectly predicts that the license of fluentlist.java is apache v2.
in particular it fails to predict the correct license gpl v2 because it does not take into account the license compatibility of the different license restrictions from the imported code modules.
c. previous v ersion prev our third baseline previous v ersion is motivated by the observation that only .
of the license of a code file changes from one version to another see table ii c .
to exploit this observation prev first predicts the license of the first version of each file and for each subsequent change to the file it simply predicts its license to be the same as the one that was used in its previous version which essentially is the one predicted for the first version .
in our experiments prev uses the basic alp system see the next subsection to predict the license of the first version of each file.
iv .
o urapproach in this section we present alp our learning based system for predicting licenses in changed source code files.
alp trains a classifier to classify the file as belonging to one of the licenses in our corpus.
for ease of exposition we will decompose the description of alp into four steps starting authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
with the basic system and then incrementally augmenting it in subsequent steps.
a. step building the basic alp system the basic alp system trains a class classifier for classifying a file as belonging to one of licenses.
below we present the details on how this classifier is trained and applied.
a training the classifier to train the classifier we create one training instance for each changed file in the training set.
the label of an instance is the license of the corresponding file or non licensed if the file does not have a license .
each training instance is represented by two types of features.
the first type of features code inline text features are extracted from each line of the source code inline text.
the motivation behind these features should be fairly obvious the inline text of a source code file may reflect the settings of this file including its license adoption.
we generate three kinds of code inline text features unigrams i.e.
word tokens bigrams each of which is a pair of consecutive word tokens and skipgrams each of which is a pair of word tokens that are separated by exactly one other word token .
we obtain word tokens from each line of the source code inline text using the tokenizer in the stanford corenlp toolkit .
all code inline text features are binary features encoding the presence value or absence value of the corresponding unigram bigram skipgram in any line of the code inline text.
for example given a line in the header comment openemrconnect is distributed in the hope that it will be useful but without any w arranty the following skipgram features will have their values set to openemrconnectdistributed is in distributed the in hope the that hope it that will it be will useful but any without warranty .
intuitively any change in the source code inline text of a changed file from its previous version may reflect the intents behind source code changes especially those that are directly relevant to the adoption and update of software licenses.
we exploit changes in the source code inline text for license prediction by encoding them as diff features .
specifically diff features are extracted from each line of the source code inline text that differs from its immediately previous version according to the linux diff command.
like the code inline text features we generate three kinds of diff features unigrams bigrams and skipgrams.
we extract these features from each changed line of the source code and encode them as binary features each of which indicates the presence value or absence value of the corresponding unigram bigram skipgram in any changed line of the codeinline text.
to train the class classifier we employ the linear chain conditional random field crf learning algorithm as implemented in the wapiti software package .
the motivation behind our choice of crf as the underlying learner will become obvious when we describe the next step.
b applying the classifier after training the resulting classifier can be used to label each test instance.
test instancesare created in the same way as the training instances.
as described before we use the trained crf to classify a test instance as having one of the licenses.
b. step modeling the previous license license adoption depends not only on the current state of the changed file but also on its past states.
for example if a changed file a.java was licensed with gpl v3 there is no need to update its license when a new import with mpl v1.
is added because gpl v3 has more copyleft than mpl v1.
.
however since basic alp predicts the license of each changed file independently of the other files it does not exploit a changed file s previous license s .
alp2 is an extension of basic alp that attempts to implicitly exploit the license of a changed file s immediately previous version.
more specifically rather than predicting each changed file s license independently we cast our license prediction task as a sequence prediction task.
recall that given a sequence x1x2...x nas input the goal of sequence prediction is to output a sequence y1y2...y nof the same length.
in other words output element yiis assumed to be the predicted class for input element xi.
in the context of license prediction each input sequence x1x2is a sequence of length where x2corresponds to the changed file and x1corresponds to the previous version of the changed file.
hence y1y2 the output sequence produced for x1x2 will also be of length where y2is the predicted license for x2and y1is the predicted license for x1.
alp2 uses crfs as implemented in the wapiti software package to learn how to label sequences.
recall that crfs are inherently sequence labelers.
in fact its sequence labeling capability distinguishes itself from the majority of the widely used machine learning algorithms.
during training a crf is trained to maximize the probability of seeing the correct output sequence given an input training sequence.
during testing the viterbi algorithm is used to decode the most probable output sequence given an input test sequence.
an important aspect of viterbi is that it captures the relationship between consecutive elements in an output sequence.
since we only have sequences of length crf helps us capture the relationship between license y1and license y2in the prediction process.
for instance if license y1is rarely followed by license y2in the training data the crf learning algorithm will learn a model that assigns a low probability to this and other unlikely license sequences.
in contrast if y1is frequently followed by y2in the training data the crf learner will learn a model that assigns a high probability to this and other likely license sequences.
hence a crf can potentially allow us to improve the prediction of y2 the license of the changed file by exploiting y1 the license of the previous version of the changed file .
we represent x1andx2using the same features 5we could employ longer sequences to capture a longer history of a given changed file s previous licenses but preliminary experiments indicate that employing sequences of length more than does not provide additional gains presumably because a file s license is primarily dependent on that of its immediately preceding version.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
that we used in basic alp for encoding a changed file and its previous version.
two points deserve mention.
first for each output sequence y1y2 we use y2to be the predicted license for changed file x2.
however we do not usey1to be the predicted license for x1.
the reason is that in practice when predicting the license forx1 x2may not even exist.
hence it does not make sense to use information from x2when predicting x1.
second we mentioned above that each input output sequence for our license prediction task is of length .
this is not true in a small number of cases however.
recall that a changed file may not have a previous version e.g.
it is a newly created file .
in that case we will create a length one training test sequence for each of these changed files that appears in the training test set.
c. step adding new knowledge sources next we augment alp2 s feature set with additional features extracted from two sources the software documents associated with the changed file under consideration and its co changed files.
extracting features from software documents the software documents associated with a changed file can sometimes provide important clues as to which license the file should adopt.
as an example consider the software document shown in figure which is a license file.6the phrases highlighted in yellow including retain the above copyright notice reproduce the above copyright notice and name of the author may not be used to endorse or promote are relevant to determining that the license that the file should adopt is bsd as they are consistent with the terms of the bsd license.
while a software document may contain useful information as far as license prediction is concerned this example illustrates why automatically extracting such information is not always straightforward.
first only a small portion of the document may be relevant so one challenge involves locating where the useful information is.
second the useful information may not be expressed as explicitly as the name of the license that the file should adopt.
third the license declared in the document may not be applicable to all the changed files while the source code changes.
nevertheless being learning based our alp system should be able to learn the association between phrases and licenses.
motivated by these observations we propose to extract document text features from all the software documents i.e.
the readme the pom file and the license file that are related to the changed file under consideration.
specifically given a changed source code file all the related software documents are first retrieved based on the relevance to the change.
then a set of document text features are extracted from each line of the retrieved software documents to represent their textual contents.
like code inline text features we also have three types of document text features namely unigrams bigrams and skipgrams.
for each document text feature its value is if 6only a snippet of the document is shown owing to space limitations.
fig.
a snippet of a software document the corresponding feature is present in the software document file.
otherwise its value is .
extracting features from co changed files like software documents co changed files can similarly be useful for predicting the license of a given changed file.
recall that a file f1co changed with another file f2if they both changed in a single change commit.
our example in the introduction which was shown in figure illustrated why co changed files are potentially useful for license prediction.
in that example the file xmlpacker .java was originally licensed under mpl v1.
according to its file header but when a co changed source code module logentry was imported it should adopt the stricter license that logentry adopts gpl v3 .
as mentioned before without analyzing the dependencies among different files it would not be possible to identify gpl v3 as the correct license to use after the code change.
however neither basic alp nor alp2 the two systems we introduced in steps and exploits the potentially useful information from co changed files.
in light of this weakness we seek to extract co change features from a source code file co changed with the changed file whose license is to be determined.
motivated in part by the features used in basic alp and alp2 we similarly extract from a co changed file codeinline text features i.e.
unigrams bigrams and skipgrams as well as diff features which encode the difference in content between the co changed file and its previous version.
a natural question is how many co changed files should we use to extract co change features from?
using all of them could pose a computational efficiency problem so we could use a subset of them.
however if only a subset of them were to be used which ones should be chosen?
recall from the example in figure that a co changed file will be most useful for license prediction if it suggests a license that is different from the one suggested by the changed file under consideration.
hence it makes sense for us to use those co changed files that suggest a different license.
of course it is possible that none of the co changed file suggests a different license than the one that the changed file suggests.
if this happens the co changed files will be randomly chosen.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
since we prefer to choose those co changed files that suggest a different license the question then is how many of them should be used?
to answer this question we employ an empirical observation of our corpus rarely do we see more than two different licenses suggested by a set of co changed files.
given this observation it is plausible that using just one co changed file may suffice as long as it suggests a different license.
to empirically determine how the number of cochanged files used to extract co change features would impact overall performance we will conduct experiments where we extract co change features from five co changed files7and from just one co changed file.
an important question that we have eluded so far is how do we know whether a co changed file suggests a different license than the one that the changed file under consideration suggests?
our idea is to use our alp2 system.
specifically we will use alp2 to predict the license of a changed file and all of its co changed files and select from those co changed files whose predicted license is different from the original changed file s predicted license according to alp2.
of course alp2 is not perfect but it provides a viable way of identifying such co changed files.
we retrain alp2 by augmenting its feature set with the document text features and the co change features.8note that these two additional types of features can be used in combination and in isolation.
when they are used in combination we name the resulting system alp2 doc co as alp2 is trained with three types of features document text features co change features and the original features extracted from the changed file under consideration.
when they are used in isolation we end up with two systems alp2 doc and alp2 co depending on which of them is used to augment alp2.
however if software documents or co changed files are not available for the changed file under consideration no document text features and co change features can be extracted in which case we will simply set the values of these features to .
d. step modeling conflicts as discussed before software documents and co changed files are most useful for license prediction if they suggest a different license than the one suggested by the changed file under consideration.
in the previous subsection the conflicts that resulted from the different licenses suggested by different sources of information are resolved implicitly by the crf.
more specifically the crf has access to one set of features extracted from the different sources and determines the license for the changed file under consideration.
we hypothesize that license prediction performance could be improved if we model the aforementioned conflicts ex7if fewer than five co changed files are present we will just use all of them.
8what this means is that the document text features and the co change features need to be computed for both the training instances and the test instances.
in particular to select which co changed files to compute co change features from for a given changed file in the training set we use alp2 to predict the license of each changed and co changed file by performing fivefold cross validation on the training set.plicitly .
specifically we propose to first identify the set of instances with conflicts i.e.
the instances for which more than one license is suggested by different sources and then learn to determine which source of information should be used to predict the license of a changed file when conflicts arise.
before we explain why we believe this explicit approach is potentially better than the implicit approach used in step we provide the details of our explicit approach which is composed of two stages.
stage centers around one question how can we identify the conflict instances?
given a changed file we first train three crfs to predict its license.
the first crf is trained only on all and only the features extracted from each changed file i.e.
the code inline text features and the diff features in the training set.
the second crf is trained only on all and only the document text features extracted from a changed file s associated software documents.
the third crf is trained on all and only the co change features extracted from cochanged files.
we identify an instance as a conflict instance if at least two of the three crfs predict more than one license for the changed file under consideration.
note that if a changed file does not have any associated software documents or cochanged files the corresponding instance will not be marked as a conflict instance.
stage centers around another question how can we resolve the conflicts that arise in the conflict instances identified in stage ?
we answer this question by training a conflict resolver .
our idea is to cast the conflict resolution task as a ranking task where we train a discriminative ranker to resolve conflicts using the ranker learning algorithm implemented in the libsvm software package .
specifically we create one ranking problem for each conflict instance i.e.
each changed file determined to have a license conflict identified in stage .
the instances to be ranked in a ranking problem are created as follows.
the first instance is represented using all and only the features extracted from the changed file under consideration.
the second instance is represented using all and only the document text features extracted from all of the associated software documents.
for each co changed file we will create one instance that is represented using all and only the co change features extracted from the co changed file.
as mentioned in step we will experiment with using one cochanged file and using five co changed file.
this means that each ranking problem will be composed of instances we know that it will contain at least two instances because the changed file was determined to have a conflict in stage at the same time we know the upper bound is because besides the changed file with license to be predicted we can have at most one instance representing the software document and at most five instances corresponding to the five co changed files.
the goal of the ranker learning algorithm is to rank the instances in each ranking problem so that the ones that predict 9note that we need to identify conflict instances from both the training set and the test set.
we use the three crfs to predict the license s of a changed file in the training set by performing fold cross validation on the training set.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the correct license are ranked higher than those that predict an incorrect license.
with this goal in mind we assign the rank value to each instance in each ranking problem as follows.
if the license associated with an instance is correct its rank value is high otherwise its rank value is low.
note that the license associated with an instance is predicted by one of the three crfs in stage .
for instance the license associated with the instance corresponding to the software documents is the one predicted by the second crf in stage .
the resulting ranker can be applied to the conflict instances in the test set.
for each conflict instance in the test set a ranking problem will be created.
this ranking problem is created in the same way as those in the training set.
the ranker is then used to rank the instances in the ranking problem.
the license associated with the highest ranked instance according to the ranker will be our system s predicted license for the changed file under consideration.
note that the ranker will be applied to all and only those changed files that are determined to have a license conflict.
we believe our approach of explicitly modeling conflicts has at least two advantages over the implicit approach described in step .
first explicitly identifying conflict instances enables us to learn a ranker to handle them specifically.
this contrasts with the implicit approach where all of the instances regardless of whether they are conflict instances or not are being classified by one model.
in other words the conflict instances which are supposedly the difficult cases in license prediction may be given less attention by the crf model in the implicit approach because the crf is being trained on both the easier non conflict instances and the difficult conflict instances.
second our ranker is not trained to directly predict licenses.
rather it ranks instances corresponding to different sources of information.
consequently compared to the crfs trained in steps the ranker will have less bias towards classifying a conflict instance as belonging to one of the frequently occurring licenses in our corpus.
v. e mpirical ev alua tion a. experimental setup the goal of our empirical evaluation is to determine how accurately alp can predict licenses in software changes.
our evaluation dataset is composed of changed source code files collected from java projects where each file can be classified as belonging to one of licenses.
evaluation settings.
we did not apply any text preprocessing to the relevant software documents we retrieved or the changed files.
hence all systems including the three baselines and all variants of our alp system are performed on the original un preprocessed software documents and or changed files.
given that alp is learning based we evaluate it by adopting a five fold cross validation strategy in which the subject projects are evenly distributed into five folds.
in each fold experiment we use three folds for training alp one fold for development i.e.
parameter tuning and the remaining fold as our held out test set.two points deserve mention.
first using a five fold crossvalidation strategy ensures that the entire dataset is used for training parameter tuning and testing.
for parameter tuning we tune the regularization parameter cassociated with each crf and each svm ranker we train.
intuitively the larger thecvalue is the higher the penalty on training error is.
we choose the cvalue that maximizes the overall micro f1 score see below for details on development data.
second note that we divide the subject projects into five folds meaning that all the files associated with a particular project will appear in the same fold.
the reason for this is simple in reality a license prediction system will likely be used to predict licenses for the files in a totally new project.
in other words we cannot assume that there is any relationship between the training projects and the test projects.
hence our dividing the projects into folds mimics this real life application scenario.
not surprisingly the learning task resulting from this particular way of creating the five folds is also harder as it renders any project specific knowledge that our system learns from the training data useless when the system is applied to the unseen projects in the test data.
evaluation metrics.
we use per license precision recall and f1 score to measure the performance of our systems.
the precision p for license lis the percentage of changed files predicted as lthat are correct with respect to the gold set i.e.
precision tp tp fp .
the recall r for license lis the percentage of changed files licensed under lthat are correctly predicted as l i.e.
recall tp tp fn .
the f1 score is the harmonic mean of precision and recall i.e.
f1 r p r p to facilitate comparisons between different systems we also compute the overall performance of each system by aggregating the per license results.
specifically we employ two commonly used metrics macro f1 and micro f1.
macro f1 is the unweighted average of the per license f1 scores.
micro f1 is the fraction of instances that are correctly classified.
hence macro f1 gives equal importance to each license whereas micro f1 puts more weights on more frequently occurring licenses.
statistical significance and effect size.
to determine whether the performance difference between two systems is statistically significant or not we conduct the wilcoxon ranksum test.
the type of distribution used for wilcoxon ranksum test is normal distribution.
following miller the result of a significance test can be interpreted as follows the performance difference between the two systems under comparison is highly significant if the null hypothesis i.e.
there is no performance difference between the two systems can be rejected at the .
level significant if it can be rejected at the .
level and moderately significant if it can be rejected at the .
level.
otherwise the difference is statistically indistinguishable.
moreover to evaluate the amount of performance difference between the two systems under comparison we compute cliffs delta a non parametric effect size measure.
according to romano et al.
the difference implies a large effect size if the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii five fold cross validation results.
the strongest result in each column is boldfaced.
systems macro f1 micro f1 ninka .
.
cc .
.
prev .
.
basic alp .
.
alp2 .
.
alp2 co1 .
.
alp2 co5 .
.
alp2 doc .
.
alp2 doc co1 .
.
alp2 doc co5 .
.
alp2 ranker1 .
.
alp2 ranker5 .
.
delta value is greater than .
a medium effect size if the delta value is greater than .
and a small effect size otherwise.
b. results and discussion this section empirically answers our research questions.
rq1 which license prediction system performs the best?
five fold cross validation results are shown in table iii.
each row shows the macro and micro f1 scores of one system.
a few points deserve mention.
first ninka is the best of the three baselines rows to achieving a micro f1 of .
and a macro f1 of .
.
in particular it highly significantly outperforms prev the second best baseline with a large effect size in terms of macro f1 and significantly outperforms it with a large effect size in terms of micro f1.
prev in turn highly significantly outperforms cc the weakest baseline with a large effect size in terms of both macro and micro f1.
second basic alp row the most basic variant of alp performs as least as well as ninka row the best baseline.
specifically basic alp achieves micro and macro f1 scores of .
and .
which represents a highly significant improvement of .
points with a large effect size in micro f1 and a moderately significant improvement of .
points with a large effect size in macro f1.
third alp2 row which casts license prediction as a sequence prediction problem highly significantly outperforms basic alp row with a large effect size in terms of micro f1 and moderately significantly outperforms it with a large effect size in terms of macro f1.
these results provide suggestive evidence that modeling the immediately previous license is useful for predicting both frequent licenses because of the improvement in micro f1 and infrequent licenses because of the improvement in macro f1 .
fourth incorporating additional knowledge derived from software documents and co changed files as features for training alp2 is generally though not always helpful for license prediction.
as mentioned before the document text features derived from the software documents and the cochange features derived from the co changed files can be applied in isolation and in combination with the changed file s features that are originally used to train alp2.
resultsof adding only co change files to alp2 are shown in row alp2 co1 where co change features were derived from just one co changed file and row alp2 co5 where cochange features were derived from five co changed files .
as we can see adding co change features may not always yield better performance.
in contrast adding only documenttext features alp2 doc row yields small but moderately significant improvements with a medium effect size in terms of both macro and micro f1 scores.
when the two types of features are applied in combination we see small insignificant gains in both micro and macro f1 scores when one co changed file was used alp2 doc co1 row .
overall these results seem to suggest that document text features are more useful than co change features for license prediction when used in combination with the features derived from the changed file.
in addition deriving features from five co changed files yields results that are statistically indistinguishable from those obtained using only one co changed file.
finally comparing rows and with rows to we see that explicitly modeling and resolving conflicts using a ranker alp ranker1 and alp ranker5 is much more effective in improving alp2 than implicitly resolving conflicts by incorporating features derived from different sources into just one feature set .
again we have two sets of ranking results one obtained by employing one co changed file and the other five co changed files.
note that the difference between these two sets of results is indistinguishable.
both sets of ranking results are highly significantly better than the best implicit results row with a large effect size in terms of macro f1 and significantly better than it with a large effect size in terms of micro f1.
it is worth noting that in comparison to row the best implicit results the macro f1 score improves by more than points.
this is very encouraging since it is common for learning based systems to sacrifice minority class performance for majority class performance because of their bias towards classifying an instance as belonging to a majority class .
these results suggest that our idea of training a ranker tonot predict licenses directly can effectively mitigate the problem that skewed class distributions typically bring about.
rq2.
how do the systems perform on the easy difficult and conflict instances?
to gain additional insights into the different alp variants we report the performance of different systems including the baselines on three subsets of the instances in our dataset.
first we compare system performance on only the ninkadetectable instances i.e.
the set of instances whose license can be predicted by ninka .
they account for .
of the instances in our dataset.
they are of interest because they are the easy to classify instances their licenses can be simply extracted using one of ninka s high precision regular expressions.
macro and micro f1 scores on these easy instances are shown under the ninka det column in table iv .
as we can see ninka achieves near perfect performance on these 10due to randomness involved in the selection of the one five co changed files we repeat each of these experiments five times and report the average f1 scores in table iii.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv five fold cross validation results of systems on ninka detectable ninka undetectable and conflict instances ninka det ninka undet conflict systems ma mi ma mi ma mi f1 f1 f1 f1 f1 f1 ninka .
.
.
.
.
.
cc .
.
.
.
.
.
prev .
.
.
.
.
.
basic alp .
.
.
.
.
.
alp2 .
.
.
.
.
.
alp2 co1 .
.
.
.
.
.
alp2 co5 .
.
.
.
.
.
alp2 doc .
.
.
.
.
.
alp2 doc co1 .
.
.
.
.
.
alp2 doc co5 .
.
.
.
.
.
alp2 ranker1 .
.
.
.
.
.
alp2 ranker5 .
.
.
.
.
.
instances which is not surprising.
moreover all of the alp variants perform at least as well as ninka with the best results achieved by the rankers rows and .
second we compare system performance on only the ninka undetectable instances i.e.
the set of instances for which ninka failed to predict any license .
they account for .
of the instances in our dataset.
these instances are of interest for one important reason since ninka is a state of the art system and these instances cannot be classified by ninka a n y success in predicting their licenses represents a solid advance over the current state of the art.
macro and micro f1 scores on these difficult instances are shown under the column ninkaundet in table iv .
as we can see more sophisticated alp variants tend to yield better performance on these difficult instances than their simpler counterparts.
in fact comparing the results on the ninka detectable instances and the ninkaundetectable instances we can see that our extensions to the basic alp system have primarily helped to predict the licenses of the difficult instances.
the best performance on the difficult instances is achieved by alp2 ranker1 row macro and micro f1 scores of and respectively.
finally we compare system performance on only the instances that are determined to be conflict instances according to alp2 ranker1.
results on the conflict instances will shed light on how well the alp variants particularly the rankers are in resolving conflicts.
macro and micro f1 scores on these instances are shown under the conflict column in table iv .
as we can see ninka achieves a micro f1 score of .
meaning that not all conflict instances are difficult to classify.
a closer examination of the conflict instances reveals the reason.
recall that these instances are predicted to be conflict instances.
specifically some easy ninka detectable instances that do not have conflicts are mis predicted to have conflicts.
as an example ninka predicts an instance as having license a and the associated license file simply says a license is needed without specifying which license should be used .
this is an instance that does not have a conflict but the crf classifies the software document as nonlicensed thus erroneously creating a conflict instance for an easy instance.
nevertheless the substantially higher macro andtable v examples of errors made by alp2 ranker1 changed file sofware doc co changed file example .
.
.
you can redistribute it and or modify it under the terms of the gnu general public license version ...y o u may not impose any further restriction on the recipients exercise of the rights granted herein.
.
.n a .
.
.
under the conditions of the gnu general public license version .
.
.
you may add to a covered work material governed by the terms of that license document provided that the further restriction does not survive such relicensing or conveying.
.
.
example .
.
.
licensed under the apache license version .
.... .
.
under the terms of the gnu general public license version .
...n a micro f1 scores achieved by the rankers show that they have successfully classified many difficult conflict instances.
rq3.
what are some of the errors made by our best alp variant alp2 ranker1?
to address this research question we show in table v two conflict instances that the ranker misclassified.
as can be seen each example is composed of the changed file under consideration the associated sofware document and the cochanged file.
owing to space limitations only the snippet of each file document that is relevant to license prediction is shown.
example shows that the changed file originally adopts gpl v2 while the co changed file adopts gpl v3 .
both gpl v2 and gpl v3 are weak copyleft licenses.
while the correct license is gpl v2 the conflict resolver suggests a license change to gpl v3 .
in cases like this developers will typically keep gpl v2 as the changed file s license since it is a major license .
of the source code files across all subject projects in our dataset have this license .
to improve the accuracy of alp2 ranker1 one can encode the license type e.g.
weak copyleft and the popularity of a license as features.
example shows that the changed file originally adopts apache v2 while the software document suggests gpl v2.
both licenses are loss copyleft either weak or no copyleft licenses.
while the correct license is gpl v2 the conflict resolver mistakenly labels the changed file as apache v2.
to correctly classify this instance however the resolver may need to understand that gpl v2 does not permit incorporating one program into another proprietary program such as linking proprietary applications with the library created by the author.
in other words given its stricter license clauses gpl v2 should be used as the license when a conflict instance involves both apache v2 and gpl v2.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
vi.
t hrea ts to validity threats to internal validity can occur in our training and test sets.
to address this concern we used five fold cross validation in which we trained tested and tuned our alp systems in different random splits of subject projects.
in addition threats to external validity can occur during data collection.
to avoid such threats we collected data for our experiments i.e.
changed source code files from different commits across open source projects of different types and domains from github.
the code level licenses applied in changed files were distributed into different kinds of licenses in different categories i.e.
permissive and restrictive .
vii.
r ela ted works a. software license identification and classification techniques have been introduced to automatically identify and classify software licenses.
tuunanen et al.
proposed asla a tool aimed at identifying licenses in foss systems.
german et al.
proposed a tool called ninka to identify license statements that takes as input text files and outputs license names and versions using a pattern matching approach.
di penta et al.
proposed approaches to automatically identify licenses of jar files via combined code search and textual analysis.
v endome et al.
applied a machine learning approach to detect exceptions of software licenses.
hoffmann et al.
analyzed actual license choices and correlated project growth from ten years of open source projects and discovered closed analytical models.
stewart et al.
found that business friendly open source licenses had a correlation with project success.
alspaugh et al.
developed a metamodel to analyze the interaction of licenses from the viewpoint of software architecture.
mlouki et al.
investigated license violations and the evolution of these violations over time in the android ecosystem.
german et al.
detected license inconsistencies in code clones between linux and other openbsd and freebsd.
while all the existing works help developers to tackle the license identification problem none of them proposed an approach or developed a tool to predict software licenses at file level changes.
b. license adoption and evolution our research is also related to software license adoption and evolution.
di penta et al.
studied licensing evolution on six open sources systems and found that license version and type changed during software evolution.
manabe et al.
studied licenses on freebsd openbsd eclipse and argouml evolution and discussed characteristics of license evolution.
german and hassan built a model to investigate specific licenses about applicability advantages and disadvantages.
german et al.
conducted an empirical study on binary packages of the fedora linux distribution to understand and audit licensing consistency between packages and source files and claimed that it was challenging to audit licensing issues.
german et al.
also studied the cloned code fragments between the linux kernel and two distributions of bsd and concluded that code migration was causedby additional restrictions of software licenses.
wu et al.
found that the license could be inconsistent among cloned files.
v endome et al.
conducted a survey with developers and found that facilitating commercial reuse was a common reason for license changes.
they further investigated open source projects to gain insights of causes of license migration .
they found that licensing adoption and changes could be triggered by various factors.
they also pointed out that there was a lack of traceability of when and why licensing changes were made.
almeida et al.
conducted a survey that posed development scenarios involving three popular open source licenses and found that developers struggled when multiple licenses were involved and developed a tool to recommend when adoption and evolution of license would be needed.
sen et al.
explored factors that affected the choice of a license for a project through analysis of open source project artifacts.
these studies discussed the challenges and importance of predicting software licenses in software changes.
however none of the studies proposed a method or developed tools to predict licenses for software changes.
to the best of our knowledge we are the first to propose a coherent method and supporting tool to predict software licenses for software changes and provide a quantitative measure.
viii.
c onclusions and future work making appropriate selection of software licenses to adopt or update after software changes usually requires a great deal of experience and manual effort.
to address this challenge we annotated a large corpus of changed files with their licenses and developed alp a novel method and tool for automatic code level license prediction for software changes.
in an evaluation on open source projects with a rich code change history alp2 ranker1 the best variant of alp achieves an accuracy of .
micro f1 score and .
macro f1 score on licensed code changes significantly surpassing the performance of three baselines including a state of the art license prediction system ninka .
future work will investigate additional impact factors in predicting licenses for software changes such as software code dependencies.